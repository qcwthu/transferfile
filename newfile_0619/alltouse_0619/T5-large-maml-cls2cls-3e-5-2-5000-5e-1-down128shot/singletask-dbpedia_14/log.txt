05/21/2022 21:27:25 - INFO - __main__ - Namespace(task_dir='data_128/dbpedia_14/', task_name='dbpedia_14', identifier='T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down128shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down128shot/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-maml-cls2cls-3e-5-2-5000-5e-1/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='0,1')
05/21/2022 21:27:25 - INFO - __main__ - models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down128shot/singletask-dbpedia_14
05/21/2022 21:27:25 - INFO - __main__ - Namespace(task_dir='data_128/dbpedia_14/', task_name='dbpedia_14', identifier='T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down128shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down128shot/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-maml-cls2cls-3e-5-2-5000-5e-1/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='0,1')
05/21/2022 21:27:25 - INFO - __main__ - models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down128shot/singletask-dbpedia_14
05/21/2022 21:27:27 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
05/21/2022 21:27:27 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
05/21/2022 21:27:27 - INFO - __main__ - args.device: cuda:0
05/21/2022 21:27:27 - INFO - __main__ - Using 2 gpus
05/21/2022 21:27:27 - INFO - __main__ - Fine-tuning the following samples: ['dbpedia_14_128_100', 'dbpedia_14_128_13', 'dbpedia_14_128_21', 'dbpedia_14_128_42', 'dbpedia_14_128_87']
05/21/2022 21:27:27 - INFO - __main__ - args.device: cuda:1
05/21/2022 21:27:27 - INFO - __main__ - Using 2 gpus
05/21/2022 21:27:27 - INFO - __main__ - Fine-tuning the following samples: ['dbpedia_14_128_100', 'dbpedia_14_128_13', 'dbpedia_14_128_21', 'dbpedia_14_128_42', 'dbpedia_14_128_87']
05/21/2022 21:27:33 - INFO - __main__ - Running ... prefix=dbpedia_14_128_100, lr=0.5, bsz=8 ...
06/16/2022 07:52:08 - INFO - __main__ - Namespace(task_dir='data_128/dbpedia_14/', task_name='dbpedia_14', identifier='T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down128shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down128shot/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-maml-cls2cls-3e-5-2-5000-5e-1/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='0,1')
06/16/2022 07:52:08 - INFO - __main__ - models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down128shot/singletask-dbpedia_14
06/16/2022 07:52:08 - INFO - __main__ - Namespace(task_dir='data_128/dbpedia_14/', task_name='dbpedia_14', identifier='T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down128shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down128shot/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-maml-cls2cls-3e-5-2-5000-5e-1/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='0,1')
06/16/2022 07:52:08 - INFO - __main__ - models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down128shot/singletask-dbpedia_14
06/16/2022 07:52:10 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
06/16/2022 07:52:10 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
06/16/2022 07:52:10 - INFO - __main__ - args.device: cuda:0
06/16/2022 07:52:10 - INFO - __main__ - args.device: cuda:1
06/16/2022 07:52:10 - INFO - __main__ - Using 2 gpus
06/16/2022 07:52:10 - INFO - __main__ - Using 2 gpus
06/16/2022 07:52:10 - INFO - __main__ - Fine-tuning the following samples: ['dbpedia_14_128_100', 'dbpedia_14_128_13', 'dbpedia_14_128_21', 'dbpedia_14_128_42', 'dbpedia_14_128_87']
06/16/2022 07:52:10 - INFO - __main__ - Fine-tuning the following samples: ['dbpedia_14_128_100', 'dbpedia_14_128_13', 'dbpedia_14_128_21', 'dbpedia_14_128_42', 'dbpedia_14_128_87']
06/16/2022 07:52:15 - INFO - __main__ - Running ... prefix=dbpedia_14_128_100, lr=0.5, bsz=8 ...
06/16/2022 07:52:16 - INFO - __main__ - Start tokenizing ... 1792 instances
06/16/2022 07:52:16 - INFO - __main__ - Printing 3 examples
06/16/2022 07:52:16 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/16/2022 07:52:16 - INFO - __main__ - ['Animal']
06/16/2022 07:52:16 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/16/2022 07:52:16 - INFO - __main__ - ['Animal']
06/16/2022 07:52:16 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/16/2022 07:52:16 - INFO - __main__ - ['Animal']
06/16/2022 07:52:16 - INFO - __main__ - Tokenizing Input ...
06/16/2022 07:52:16 - INFO - __main__ - Start tokenizing ... 1792 instances
06/16/2022 07:52:16 - INFO - __main__ - Printing 3 examples
06/16/2022 07:52:16 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/16/2022 07:52:16 - INFO - __main__ - ['Animal']
06/16/2022 07:52:16 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/16/2022 07:52:16 - INFO - __main__ - ['Animal']
06/16/2022 07:52:16 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/16/2022 07:52:16 - INFO - __main__ - ['Animal']
06/16/2022 07:52:16 - INFO - __main__ - Tokenizing Input ...
06/16/2022 07:52:18 - INFO - __main__ - Tokenizing Output ...
06/16/2022 07:52:18 - INFO - __main__ - Tokenizing Output ...
06/16/2022 07:52:20 - INFO - __main__ - Loaded 1792 examples from train data
06/16/2022 07:52:20 - INFO - __main__ - Start tokenizing ... 1792 instances
06/16/2022 07:52:20 - INFO - __main__ - Printing 3 examples
06/16/2022 07:52:20 - INFO - __main__ -  [dbpedia_14] Palaephatus fusciterminus is a moth of the Palaephatidae family. It is found in the Valdivian forests of southern Argentina and Chile.The length of the forewings is 10-12 mm for males and 10.5-11.5 mm for females. Adults have a buff to brown head and thorax and dark brownish fuscous forewings with a pale buff hindmargin. They are on wing from October to March possibly in multiple generations per year.
06/16/2022 07:52:20 - INFO - __main__ - ['Animal']
06/16/2022 07:52:20 - INFO - __main__ -  [dbpedia_14] Labus is an indomalayan genus of potter wasps.
06/16/2022 07:52:20 - INFO - __main__ - ['Animal']
06/16/2022 07:52:20 - INFO - __main__ -  [dbpedia_14] Trifurcula beirnei is a moth of the Nepticulidae family. It is found in Great Britain Denmark and parts of Germany and Poland Austria the Czech Republic Slovakia and Hungary. It is also found in the Volga and Ural region of Russia.The wingspan is 8–11 mm. Adults are on wing from the end of June to late September.The larvae feed on Genista species including Genista tinctoria Genista germanica and Genista pilosa.
06/16/2022 07:52:20 - INFO - __main__ - ['Animal']
06/16/2022 07:52:20 - INFO - __main__ - Tokenizing Input ...
06/16/2022 07:52:20 - INFO - __main__ - Loaded 1792 examples from train data
06/16/2022 07:52:20 - INFO - __main__ - Start tokenizing ... 1792 instances
06/16/2022 07:52:20 - INFO - __main__ - Printing 3 examples
06/16/2022 07:52:20 - INFO - __main__ -  [dbpedia_14] Palaephatus fusciterminus is a moth of the Palaephatidae family. It is found in the Valdivian forests of southern Argentina and Chile.The length of the forewings is 10-12 mm for males and 10.5-11.5 mm for females. Adults have a buff to brown head and thorax and dark brownish fuscous forewings with a pale buff hindmargin. They are on wing from October to March possibly in multiple generations per year.
06/16/2022 07:52:20 - INFO - __main__ - ['Animal']
06/16/2022 07:52:20 - INFO - __main__ -  [dbpedia_14] Labus is an indomalayan genus of potter wasps.
06/16/2022 07:52:20 - INFO - __main__ - ['Animal']
06/16/2022 07:52:20 - INFO - __main__ -  [dbpedia_14] Trifurcula beirnei is a moth of the Nepticulidae family. It is found in Great Britain Denmark and parts of Germany and Poland Austria the Czech Republic Slovakia and Hungary. It is also found in the Volga and Ural region of Russia.The wingspan is 8–11 mm. Adults are on wing from the end of June to late September.The larvae feed on Genista species including Genista tinctoria Genista germanica and Genista pilosa.
06/16/2022 07:52:20 - INFO - __main__ - ['Animal']
06/16/2022 07:52:20 - INFO - __main__ - Tokenizing Input ...
06/16/2022 07:52:21 - INFO - __main__ - Tokenizing Output ...
06/16/2022 07:52:22 - INFO - __main__ - Tokenizing Output ...
06/16/2022 07:52:24 - INFO - __main__ - Loaded 1792 examples from dev data
06/16/2022 07:52:24 - INFO - __main__ - Loaded 1792 examples from dev data
06/16/2022 07:52:45 - INFO - __main__ - load prompt embedding from ckpt
06/16/2022 07:52:46 - INFO - __main__ - load prompt embedding from ckpt
06/16/2022 07:52:46 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/16/2022 07:52:46 - INFO - __main__ - Starting training!
06/16/2022 07:52:52 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/16/2022 07:52:52 - INFO - __main__ - Starting training!
06/16/2022 07:52:57 - INFO - __main__ - Step 10 Global step 10 Train loss 4.45 on epoch=0
06/16/2022 07:53:00 - INFO - __main__ - Step 20 Global step 20 Train loss 2.84 on epoch=0
06/16/2022 07:53:03 - INFO - __main__ - Step 30 Global step 30 Train loss 1.78 on epoch=0
06/16/2022 07:53:06 - INFO - __main__ - Step 40 Global step 40 Train loss 1.48 on epoch=0
06/16/2022 07:53:09 - INFO - __main__ - Step 50 Global step 50 Train loss 1.17 on epoch=0
06/16/2022 07:54:03 - INFO - __main__ - Global step 50 Train loss 2.35 Classification-F1 0.264077365724551 on epoch=0
06/16/2022 07:54:03 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.264077365724551 on epoch=0, global_step=50
06/16/2022 07:54:06 - INFO - __main__ - Step 60 Global step 60 Train loss 0.96 on epoch=0
06/16/2022 07:54:09 - INFO - __main__ - Step 70 Global step 70 Train loss 1.02 on epoch=0
06/16/2022 07:54:12 - INFO - __main__ - Step 80 Global step 80 Train loss 0.77 on epoch=0
06/16/2022 07:54:15 - INFO - __main__ - Step 90 Global step 90 Train loss 0.95 on epoch=0
06/16/2022 07:54:18 - INFO - __main__ - Step 100 Global step 100 Train loss 0.72 on epoch=0
06/16/2022 07:55:18 - INFO - __main__ - Global step 100 Train loss 0.88 Classification-F1 0.4223169059148913 on epoch=0
06/16/2022 07:55:18 - INFO - __main__ - Saving model with best Classification-F1: 0.264077365724551 -> 0.4223169059148913 on epoch=0, global_step=100
06/16/2022 07:55:21 - INFO - __main__ - Step 110 Global step 110 Train loss 0.71 on epoch=0
06/16/2022 07:55:24 - INFO - __main__ - Step 120 Global step 120 Train loss 0.56 on epoch=1
06/16/2022 07:55:27 - INFO - __main__ - Step 130 Global step 130 Train loss 0.55 on epoch=1
06/16/2022 07:55:31 - INFO - __main__ - Step 140 Global step 140 Train loss 0.51 on epoch=1
06/16/2022 07:55:34 - INFO - __main__ - Step 150 Global step 150 Train loss 0.44 on epoch=1
06/16/2022 07:56:37 - INFO - __main__ - Global step 150 Train loss 0.55 Classification-F1 0.3546529560401616 on epoch=1
06/16/2022 07:56:39 - INFO - __main__ - Step 160 Global step 160 Train loss 0.44 on epoch=1
06/16/2022 07:56:42 - INFO - __main__ - Step 170 Global step 170 Train loss 0.38 on epoch=1
06/16/2022 07:56:45 - INFO - __main__ - Step 180 Global step 180 Train loss 0.55 on epoch=1
06/16/2022 07:56:48 - INFO - __main__ - Step 190 Global step 190 Train loss 0.37 on epoch=1
06/16/2022 07:56:51 - INFO - __main__ - Step 200 Global step 200 Train loss 0.48 on epoch=1
06/16/2022 07:57:53 - INFO - __main__ - Global step 200 Train loss 0.44 Classification-F1 0.44183986123623936 on epoch=1
06/16/2022 07:57:53 - INFO - __main__ - Saving model with best Classification-F1: 0.4223169059148913 -> 0.44183986123623936 on epoch=1, global_step=200
06/16/2022 07:57:55 - INFO - __main__ - Step 210 Global step 210 Train loss 0.41 on epoch=1
06/16/2022 07:57:58 - INFO - __main__ - Step 220 Global step 220 Train loss 0.45 on epoch=1
06/16/2022 07:58:01 - INFO - __main__ - Step 230 Global step 230 Train loss 0.30 on epoch=2
06/16/2022 07:58:04 - INFO - __main__ - Step 240 Global step 240 Train loss 0.31 on epoch=2
06/16/2022 07:58:07 - INFO - __main__ - Step 250 Global step 250 Train loss 0.43 on epoch=2
06/16/2022 07:59:09 - INFO - __main__ - Global step 250 Train loss 0.38 Classification-F1 0.39577778218943843 on epoch=2
06/16/2022 07:59:12 - INFO - __main__ - Step 260 Global step 260 Train loss 0.30 on epoch=2
06/16/2022 07:59:15 - INFO - __main__ - Step 270 Global step 270 Train loss 0.34 on epoch=2
06/16/2022 07:59:17 - INFO - __main__ - Step 280 Global step 280 Train loss 0.33 on epoch=2
06/16/2022 07:59:20 - INFO - __main__ - Step 290 Global step 290 Train loss 0.40 on epoch=2
06/16/2022 07:59:23 - INFO - __main__ - Step 300 Global step 300 Train loss 0.36 on epoch=2
06/16/2022 08:00:25 - INFO - __main__ - Global step 300 Train loss 0.35 Classification-F1 0.4766664152934074 on epoch=2
06/16/2022 08:00:25 - INFO - __main__ - Saving model with best Classification-F1: 0.44183986123623936 -> 0.4766664152934074 on epoch=2, global_step=300
06/16/2022 08:00:28 - INFO - __main__ - Step 310 Global step 310 Train loss 0.29 on epoch=2
06/16/2022 08:00:30 - INFO - __main__ - Step 320 Global step 320 Train loss 0.30 on epoch=2
06/16/2022 08:00:33 - INFO - __main__ - Step 330 Global step 330 Train loss 0.25 on epoch=2
06/16/2022 08:00:36 - INFO - __main__ - Step 340 Global step 340 Train loss 0.22 on epoch=3
06/16/2022 08:00:39 - INFO - __main__ - Step 350 Global step 350 Train loss 0.28 on epoch=3
06/16/2022 08:01:42 - INFO - __main__ - Global step 350 Train loss 0.27 Classification-F1 0.4843117758626708 on epoch=3
06/16/2022 08:01:42 - INFO - __main__ - Saving model with best Classification-F1: 0.4766664152934074 -> 0.4843117758626708 on epoch=3, global_step=350
06/16/2022 08:01:45 - INFO - __main__ - Step 360 Global step 360 Train loss 0.29 on epoch=3
06/16/2022 08:01:48 - INFO - __main__ - Step 370 Global step 370 Train loss 0.26 on epoch=3
06/16/2022 08:01:51 - INFO - __main__ - Step 380 Global step 380 Train loss 0.22 on epoch=3
06/16/2022 08:01:54 - INFO - __main__ - Step 390 Global step 390 Train loss 0.30 on epoch=3
06/16/2022 08:01:57 - INFO - __main__ - Step 400 Global step 400 Train loss 0.23 on epoch=3
06/16/2022 08:02:58 - INFO - __main__ - Global step 400 Train loss 0.26 Classification-F1 0.43660010238173413 on epoch=3
06/16/2022 08:03:01 - INFO - __main__ - Step 410 Global step 410 Train loss 0.24 on epoch=3
06/16/2022 08:03:04 - INFO - __main__ - Step 420 Global step 420 Train loss 0.19 on epoch=3
06/16/2022 08:03:07 - INFO - __main__ - Step 430 Global step 430 Train loss 0.24 on epoch=3
06/16/2022 08:03:09 - INFO - __main__ - Step 440 Global step 440 Train loss 0.23 on epoch=3
06/16/2022 08:03:12 - INFO - __main__ - Step 450 Global step 450 Train loss 0.21 on epoch=4
06/16/2022 08:04:20 - INFO - __main__ - Global step 450 Train loss 0.22 Classification-F1 0.6137762959564997 on epoch=4
06/16/2022 08:04:20 - INFO - __main__ - Saving model with best Classification-F1: 0.4843117758626708 -> 0.6137762959564997 on epoch=4, global_step=450
06/16/2022 08:04:22 - INFO - __main__ - Step 460 Global step 460 Train loss 0.12 on epoch=4
06/16/2022 08:04:25 - INFO - __main__ - Step 470 Global step 470 Train loss 0.21 on epoch=4
06/16/2022 08:04:28 - INFO - __main__ - Step 480 Global step 480 Train loss 0.23 on epoch=4
06/16/2022 08:04:30 - INFO - __main__ - Step 490 Global step 490 Train loss 0.15 on epoch=4
06/16/2022 08:04:33 - INFO - __main__ - Step 500 Global step 500 Train loss 0.20 on epoch=4
06/16/2022 08:05:43 - INFO - __main__ - Global step 500 Train loss 0.18 Classification-F1 0.8408060507651489 on epoch=4
06/16/2022 08:05:43 - INFO - __main__ - Saving model with best Classification-F1: 0.6137762959564997 -> 0.8408060507651489 on epoch=4, global_step=500
06/16/2022 08:05:46 - INFO - __main__ - Step 510 Global step 510 Train loss 0.19 on epoch=4
06/16/2022 08:05:49 - INFO - __main__ - Step 520 Global step 520 Train loss 0.25 on epoch=4
06/16/2022 08:05:52 - INFO - __main__ - Step 530 Global step 530 Train loss 0.16 on epoch=4
06/16/2022 08:05:54 - INFO - __main__ - Step 540 Global step 540 Train loss 0.15 on epoch=4
06/16/2022 08:05:57 - INFO - __main__ - Step 550 Global step 550 Train loss 0.21 on epoch=4
06/16/2022 08:07:06 - INFO - __main__ - Global step 550 Train loss 0.19 Classification-F1 0.6149017112799675 on epoch=4
06/16/2022 08:07:09 - INFO - __main__ - Step 560 Global step 560 Train loss 0.17 on epoch=4
06/16/2022 08:07:12 - INFO - __main__ - Step 570 Global step 570 Train loss 0.13 on epoch=5
06/16/2022 08:07:15 - INFO - __main__ - Step 580 Global step 580 Train loss 0.16 on epoch=5
06/16/2022 08:07:17 - INFO - __main__ - Step 590 Global step 590 Train loss 0.20 on epoch=5
06/16/2022 08:07:20 - INFO - __main__ - Step 600 Global step 600 Train loss 0.13 on epoch=5
06/16/2022 08:08:25 - INFO - __main__ - Global step 600 Train loss 0.16 Classification-F1 0.42668619013087616 on epoch=5
06/16/2022 08:08:28 - INFO - __main__ - Step 610 Global step 610 Train loss 0.15 on epoch=5
06/16/2022 08:08:31 - INFO - __main__ - Step 620 Global step 620 Train loss 0.16 on epoch=5
06/16/2022 08:08:34 - INFO - __main__ - Step 630 Global step 630 Train loss 0.22 on epoch=5
06/16/2022 08:08:37 - INFO - __main__ - Step 640 Global step 640 Train loss 0.10 on epoch=5
06/16/2022 08:08:39 - INFO - __main__ - Step 650 Global step 650 Train loss 0.22 on epoch=5
06/16/2022 08:09:43 - INFO - __main__ - Global step 650 Train loss 0.17 Classification-F1 0.7508588892631974 on epoch=5
06/16/2022 08:09:46 - INFO - __main__ - Step 660 Global step 660 Train loss 0.16 on epoch=5
06/16/2022 08:09:48 - INFO - __main__ - Step 670 Global step 670 Train loss 0.12 on epoch=5
06/16/2022 08:09:51 - INFO - __main__ - Step 680 Global step 680 Train loss 0.15 on epoch=6
06/16/2022 08:09:54 - INFO - __main__ - Step 690 Global step 690 Train loss 0.15 on epoch=6
06/16/2022 08:09:57 - INFO - __main__ - Step 700 Global step 700 Train loss 0.18 on epoch=6
06/16/2022 08:11:00 - INFO - __main__ - Global step 700 Train loss 0.15 Classification-F1 0.7586354526839736 on epoch=6
06/16/2022 08:11:03 - INFO - __main__ - Step 710 Global step 710 Train loss 0.10 on epoch=6
06/16/2022 08:11:06 - INFO - __main__ - Step 720 Global step 720 Train loss 0.24 on epoch=6
06/16/2022 08:11:08 - INFO - __main__ - Step 730 Global step 730 Train loss 0.11 on epoch=6
06/16/2022 08:11:11 - INFO - __main__ - Step 740 Global step 740 Train loss 0.21 on epoch=6
06/16/2022 08:11:14 - INFO - __main__ - Step 750 Global step 750 Train loss 0.10 on epoch=6
06/16/2022 08:12:22 - INFO - __main__ - Global step 750 Train loss 0.15 Classification-F1 0.8534532688523223 on epoch=6
06/16/2022 08:12:22 - INFO - __main__ - Saving model with best Classification-F1: 0.8408060507651489 -> 0.8534532688523223 on epoch=6, global_step=750
06/16/2022 08:12:25 - INFO - __main__ - Step 760 Global step 760 Train loss 0.08 on epoch=6
06/16/2022 08:12:28 - INFO - __main__ - Step 770 Global step 770 Train loss 0.13 on epoch=6
06/16/2022 08:12:31 - INFO - __main__ - Step 780 Global step 780 Train loss 0.10 on epoch=6
06/16/2022 08:12:34 - INFO - __main__ - Step 790 Global step 790 Train loss 0.11 on epoch=7
06/16/2022 08:12:37 - INFO - __main__ - Step 800 Global step 800 Train loss 0.10 on epoch=7
06/16/2022 08:13:27 - INFO - __main__ - Global step 800 Train loss 0.11 Classification-F1 0.7510361149914884 on epoch=7
06/16/2022 08:13:30 - INFO - __main__ - Step 810 Global step 810 Train loss 0.19 on epoch=7
06/16/2022 08:13:33 - INFO - __main__ - Step 820 Global step 820 Train loss 0.09 on epoch=7
06/16/2022 08:13:36 - INFO - __main__ - Step 830 Global step 830 Train loss 0.06 on epoch=7
06/16/2022 08:13:38 - INFO - __main__ - Step 840 Global step 840 Train loss 0.13 on epoch=7
06/16/2022 08:13:41 - INFO - __main__ - Step 850 Global step 850 Train loss 0.13 on epoch=7
06/16/2022 08:14:46 - INFO - __main__ - Global step 850 Train loss 0.12 Classification-F1 0.7570524360292094 on epoch=7
06/16/2022 08:14:49 - INFO - __main__ - Step 860 Global step 860 Train loss 0.12 on epoch=7
06/16/2022 08:14:52 - INFO - __main__ - Step 870 Global step 870 Train loss 0.09 on epoch=7
06/16/2022 08:14:54 - INFO - __main__ - Step 880 Global step 880 Train loss 0.08 on epoch=7
06/16/2022 08:14:57 - INFO - __main__ - Step 890 Global step 890 Train loss 0.09 on epoch=7
06/16/2022 08:15:00 - INFO - __main__ - Step 900 Global step 900 Train loss 0.07 on epoch=8
06/16/2022 08:16:10 - INFO - __main__ - Global step 900 Train loss 0.09 Classification-F1 0.6174489034790199 on epoch=8
06/16/2022 08:16:13 - INFO - __main__ - Step 910 Global step 910 Train loss 0.09 on epoch=8
06/16/2022 08:16:16 - INFO - __main__ - Step 920 Global step 920 Train loss 0.11 on epoch=8
06/16/2022 08:16:19 - INFO - __main__ - Step 930 Global step 930 Train loss 0.10 on epoch=8
06/16/2022 08:16:22 - INFO - __main__ - Step 940 Global step 940 Train loss 0.08 on epoch=8
06/16/2022 08:16:25 - INFO - __main__ - Step 950 Global step 950 Train loss 0.07 on epoch=8
06/16/2022 08:17:26 - INFO - __main__ - Global step 950 Train loss 0.09 Classification-F1 0.8003423973354182 on epoch=8
06/16/2022 08:17:29 - INFO - __main__ - Step 960 Global step 960 Train loss 0.09 on epoch=8
06/16/2022 08:17:32 - INFO - __main__ - Step 970 Global step 970 Train loss 0.07 on epoch=8
06/16/2022 08:17:34 - INFO - __main__ - Step 980 Global step 980 Train loss 0.06 on epoch=8
06/16/2022 08:17:37 - INFO - __main__ - Step 990 Global step 990 Train loss 0.10 on epoch=8
06/16/2022 08:17:40 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.09 on epoch=8
06/16/2022 08:18:34 - INFO - __main__ - Global step 1000 Train loss 0.08 Classification-F1 0.7577516862582451 on epoch=8
06/16/2022 08:18:37 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.05 on epoch=9
06/16/2022 08:18:39 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.13 on epoch=9
06/16/2022 08:18:42 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.08 on epoch=9
06/16/2022 08:18:45 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.07 on epoch=9
06/16/2022 08:18:48 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.07 on epoch=9
06/16/2022 08:19:45 - INFO - __main__ - Global step 1050 Train loss 0.08 Classification-F1 0.6121011800967431 on epoch=9
06/16/2022 08:19:48 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.06 on epoch=9
06/16/2022 08:19:51 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.10 on epoch=9
06/16/2022 08:19:54 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.07 on epoch=9
06/16/2022 08:19:56 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.03 on epoch=9
06/16/2022 08:19:59 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.15 on epoch=9
06/16/2022 08:20:52 - INFO - __main__ - Global step 1100 Train loss 0.08 Classification-F1 0.7185161549909144 on epoch=9
06/16/2022 08:20:54 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.06 on epoch=9
06/16/2022 08:20:57 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.04 on epoch=9
06/16/2022 08:21:00 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.08 on epoch=10
06/16/2022 08:21:03 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.13 on epoch=10
06/16/2022 08:21:06 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.09 on epoch=10
06/16/2022 08:22:02 - INFO - __main__ - Global step 1150 Train loss 0.08 Classification-F1 0.7174296272542232 on epoch=10
06/16/2022 08:22:05 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.07 on epoch=10
06/16/2022 08:22:08 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.09 on epoch=10
06/16/2022 08:22:11 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.05 on epoch=10
06/16/2022 08:22:14 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.05 on epoch=10
06/16/2022 08:22:17 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.05 on epoch=10
06/16/2022 08:23:14 - INFO - __main__ - Global step 1200 Train loss 0.06 Classification-F1 0.6837074799831705 on epoch=10
06/16/2022 08:23:17 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.17 on epoch=10
06/16/2022 08:23:20 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.11 on epoch=10
06/16/2022 08:23:23 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.13 on epoch=10
06/16/2022 08:23:25 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.10 on epoch=11
06/16/2022 08:23:29 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.07 on epoch=11
06/16/2022 08:24:20 - INFO - __main__ - Global step 1250 Train loss 0.12 Classification-F1 0.7106796356629952 on epoch=11
06/16/2022 08:24:22 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.13 on epoch=11
06/16/2022 08:24:25 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.05 on epoch=11
06/16/2022 08:24:28 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.07 on epoch=11
06/16/2022 08:24:31 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.04 on epoch=11
06/16/2022 08:24:33 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.06 on epoch=11
06/16/2022 08:25:27 - INFO - __main__ - Global step 1300 Train loss 0.07 Classification-F1 0.5835514488903609 on epoch=11
06/16/2022 08:25:30 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.07 on epoch=11
06/16/2022 08:25:32 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.05 on epoch=11
06/16/2022 08:25:35 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.12 on epoch=11
06/16/2022 08:25:38 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.06 on epoch=11
06/16/2022 08:25:41 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.03 on epoch=12
06/16/2022 08:26:31 - INFO - __main__ - Global step 1350 Train loss 0.07 Classification-F1 0.8605417171013481 on epoch=12
06/16/2022 08:26:31 - INFO - __main__ - Saving model with best Classification-F1: 0.8534532688523223 -> 0.8605417171013481 on epoch=12, global_step=1350
06/16/2022 08:26:34 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.09 on epoch=12
06/16/2022 08:26:36 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.12 on epoch=12
06/16/2022 08:26:39 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.05 on epoch=12
06/16/2022 08:26:42 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.05 on epoch=12
06/16/2022 08:26:45 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.04 on epoch=12
06/16/2022 08:27:39 - INFO - __main__ - Global step 1400 Train loss 0.07 Classification-F1 0.6468270365735022 on epoch=12
06/16/2022 08:27:41 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.06 on epoch=12
06/16/2022 08:27:44 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.07 on epoch=12
06/16/2022 08:27:47 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.07 on epoch=12
06/16/2022 08:27:50 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.06 on epoch=12
06/16/2022 08:27:52 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.08 on epoch=12
06/16/2022 08:28:47 - INFO - __main__ - Global step 1450 Train loss 0.07 Classification-F1 0.5152250729142431 on epoch=12
06/16/2022 08:28:50 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.03 on epoch=13
06/16/2022 08:28:53 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.08 on epoch=13
06/16/2022 08:28:56 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.06 on epoch=13
06/16/2022 08:28:59 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.04 on epoch=13
06/16/2022 08:29:01 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.06 on epoch=13
06/16/2022 08:29:49 - INFO - __main__ - Global step 1500 Train loss 0.05 Classification-F1 0.5828600035196959 on epoch=13
06/16/2022 08:29:52 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.04 on epoch=13
06/16/2022 08:29:54 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.06 on epoch=13
06/16/2022 08:29:57 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.09 on epoch=13
06/16/2022 08:30:00 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.07 on epoch=13
06/16/2022 08:30:03 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.08 on epoch=13
06/16/2022 08:31:02 - INFO - __main__ - Global step 1550 Train loss 0.07 Classification-F1 0.7258552846584028 on epoch=13
06/16/2022 08:31:05 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.08 on epoch=13
06/16/2022 08:31:08 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.03 on epoch=14
06/16/2022 08:31:11 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.10 on epoch=14
06/16/2022 08:31:14 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.06 on epoch=14
06/16/2022 08:31:17 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.13 on epoch=14
06/16/2022 08:32:10 - INFO - __main__ - Global step 1600 Train loss 0.08 Classification-F1 0.6883919734368849 on epoch=14
06/16/2022 08:32:13 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=14
06/16/2022 08:32:16 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=14
06/16/2022 08:32:19 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.03 on epoch=14
06/16/2022 08:32:22 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.02 on epoch=14
06/16/2022 08:32:25 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=14
06/16/2022 08:33:18 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.8127133311518608 on epoch=14
06/16/2022 08:33:20 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.09 on epoch=14
06/16/2022 08:33:23 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.08 on epoch=14
06/16/2022 08:33:26 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=14
06/16/2022 08:33:29 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.09 on epoch=15
06/16/2022 08:33:31 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=15
06/16/2022 08:34:20 - INFO - __main__ - Global step 1700 Train loss 0.06 Classification-F1 0.6561628898728414 on epoch=15
06/16/2022 08:34:23 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.08 on epoch=15
06/16/2022 08:34:25 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.06 on epoch=15
06/16/2022 08:34:28 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.03 on epoch=15
06/16/2022 08:34:31 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.07 on epoch=15
06/16/2022 08:34:34 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.06 on epoch=15
06/16/2022 08:35:22 - INFO - __main__ - Global step 1750 Train loss 0.06 Classification-F1 0.6222971612130995 on epoch=15
06/16/2022 08:35:25 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.07 on epoch=15
06/16/2022 08:35:28 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.08 on epoch=15
06/16/2022 08:35:31 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.15 on epoch=15
06/16/2022 08:35:34 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.03 on epoch=15
06/16/2022 08:35:37 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.05 on epoch=16
06/16/2022 08:36:28 - INFO - __main__ - Global step 1800 Train loss 0.08 Classification-F1 0.7630028996617764 on epoch=16
06/16/2022 08:36:30 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.11 on epoch=16
06/16/2022 08:36:33 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.08 on epoch=16
06/16/2022 08:36:36 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.05 on epoch=16
06/16/2022 08:36:39 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.05 on epoch=16
06/16/2022 08:36:41 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.08 on epoch=16
06/16/2022 08:37:32 - INFO - __main__ - Global step 1850 Train loss 0.07 Classification-F1 0.7147882430678208 on epoch=16
06/16/2022 08:37:35 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.03 on epoch=16
06/16/2022 08:37:38 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.03 on epoch=16
06/16/2022 08:37:40 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.06 on epoch=16
06/16/2022 08:37:43 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.06 on epoch=16
06/16/2022 08:37:46 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.05 on epoch=16
06/16/2022 08:38:33 - INFO - __main__ - Global step 1900 Train loss 0.05 Classification-F1 0.7681149976535065 on epoch=16
06/16/2022 08:38:36 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.04 on epoch=17
06/16/2022 08:38:39 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.11 on epoch=17
06/16/2022 08:38:41 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.08 on epoch=17
06/16/2022 08:38:44 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=17
06/16/2022 08:38:47 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.05 on epoch=17
06/16/2022 08:39:34 - INFO - __main__ - Global step 1950 Train loss 0.06 Classification-F1 0.8003561813405654 on epoch=17
06/16/2022 08:39:36 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.03 on epoch=17
06/16/2022 08:39:39 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.04 on epoch=17
06/16/2022 08:39:42 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.05 on epoch=17
06/16/2022 08:39:45 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.09 on epoch=17
06/16/2022 08:39:48 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.06 on epoch=17
06/16/2022 08:40:36 - INFO - __main__ - Global step 2000 Train loss 0.06 Classification-F1 0.7227742562746864 on epoch=17
06/16/2022 08:40:39 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.07 on epoch=17
06/16/2022 08:40:42 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=18
06/16/2022 08:40:45 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.08 on epoch=18
06/16/2022 08:40:48 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.09 on epoch=18
06/16/2022 08:40:51 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.06 on epoch=18
06/16/2022 08:41:46 - INFO - __main__ - Global step 2050 Train loss 0.06 Classification-F1 0.6862283896993335 on epoch=18
06/16/2022 08:41:49 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=18
06/16/2022 08:41:52 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.03 on epoch=18
06/16/2022 08:41:55 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=18
06/16/2022 08:41:58 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.07 on epoch=18
06/16/2022 08:42:01 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=18
06/16/2022 08:43:08 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.8164082781928027 on epoch=18
06/16/2022 08:43:11 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.06 on epoch=18
06/16/2022 08:43:14 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.05 on epoch=18
06/16/2022 08:43:17 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=19
06/16/2022 08:43:20 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=19
06/16/2022 08:43:23 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=19
06/16/2022 08:44:21 - INFO - __main__ - Global step 2150 Train loss 0.03 Classification-F1 0.7181827515442704 on epoch=19
06/16/2022 08:44:24 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.06 on epoch=19
06/16/2022 08:44:27 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=19
06/16/2022 08:44:29 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.07 on epoch=19
06/16/2022 08:44:32 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=19
06/16/2022 08:44:35 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=19
06/16/2022 08:45:31 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.8114829532786478 on epoch=19
06/16/2022 08:45:34 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=19
06/16/2022 08:45:36 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.10 on epoch=19
06/16/2022 08:45:39 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.06 on epoch=19
06/16/2022 08:45:42 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=19
06/16/2022 08:45:45 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.05 on epoch=20
06/16/2022 08:46:34 - INFO - __main__ - Global step 2250 Train loss 0.05 Classification-F1 0.7273062563206034 on epoch=20
06/16/2022 08:46:36 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.05 on epoch=20
06/16/2022 08:46:39 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.06 on epoch=20
06/16/2022 08:46:42 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=20
06/16/2022 08:46:45 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.04 on epoch=20
06/16/2022 08:46:47 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.04 on epoch=20
06/16/2022 08:47:39 - INFO - __main__ - Global step 2300 Train loss 0.04 Classification-F1 0.7637334150544828 on epoch=20
06/16/2022 08:47:42 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=20
06/16/2022 08:47:44 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=20
06/16/2022 08:47:47 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.04 on epoch=20
06/16/2022 08:47:50 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.09 on epoch=20
06/16/2022 08:47:53 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=20
06/16/2022 08:48:39 - INFO - __main__ - Global step 2350 Train loss 0.04 Classification-F1 0.5732469924556939 on epoch=20
06/16/2022 08:48:41 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=21
06/16/2022 08:48:44 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=21
06/16/2022 08:48:47 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.05 on epoch=21
06/16/2022 08:48:50 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=21
06/16/2022 08:48:52 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.05 on epoch=21
06/16/2022 08:49:40 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.6522400294786268 on epoch=21
06/16/2022 08:49:42 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.03 on epoch=21
06/16/2022 08:49:45 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=21
06/16/2022 08:49:48 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=21
06/16/2022 08:49:51 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.03 on epoch=21
06/16/2022 08:49:53 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.13 on epoch=21
06/16/2022 08:50:40 - INFO - __main__ - Global step 2450 Train loss 0.05 Classification-F1 0.5506348565619547 on epoch=21
06/16/2022 08:50:43 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=21
06/16/2022 08:50:46 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=22
06/16/2022 08:50:48 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=22
06/16/2022 08:50:51 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.04 on epoch=22
06/16/2022 08:50:54 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=22
06/16/2022 08:51:44 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.7667220631909616 on epoch=22
06/16/2022 08:51:46 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.09 on epoch=22
06/16/2022 08:51:49 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.03 on epoch=22
06/16/2022 08:51:52 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=22
06/16/2022 08:51:55 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=22
06/16/2022 08:51:57 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.04 on epoch=22
06/16/2022 08:52:48 - INFO - __main__ - Global step 2550 Train loss 0.04 Classification-F1 0.9179544444088069 on epoch=22
06/16/2022 08:52:48 - INFO - __main__ - Saving model with best Classification-F1: 0.8605417171013481 -> 0.9179544444088069 on epoch=22, global_step=2550
06/16/2022 08:52:51 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.05 on epoch=22
06/16/2022 08:52:54 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.09 on epoch=22
06/16/2022 08:52:57 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=23
06/16/2022 08:52:59 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.05 on epoch=23
06/16/2022 08:53:02 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.04 on epoch=23
06/16/2022 08:53:50 - INFO - __main__ - Global step 2600 Train loss 0.05 Classification-F1 0.4527474975627504 on epoch=23
06/16/2022 08:53:52 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=23
06/16/2022 08:53:55 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=23
06/16/2022 08:53:58 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=23
06/16/2022 08:54:01 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=23
06/16/2022 08:54:04 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=23
06/16/2022 08:54:56 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.6198427039493783 on epoch=23
06/16/2022 08:54:58 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=23
06/16/2022 08:55:01 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=23
06/16/2022 08:55:04 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.06 on epoch=23
06/16/2022 08:55:07 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=24
06/16/2022 08:55:10 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.03 on epoch=24
06/16/2022 08:56:08 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.683879623182089 on epoch=24
06/16/2022 08:56:11 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.04 on epoch=24
06/16/2022 08:56:13 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.06 on epoch=24
06/16/2022 08:56:16 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=24
06/16/2022 08:56:19 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=24
06/16/2022 08:56:22 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.07 on epoch=24
06/16/2022 08:57:16 - INFO - __main__ - Global step 2750 Train loss 0.04 Classification-F1 0.49784233516038645 on epoch=24
06/16/2022 08:57:19 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.04 on epoch=24
06/16/2022 08:57:21 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=24
06/16/2022 08:57:24 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.05 on epoch=24
06/16/2022 08:57:27 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.07 on epoch=24
06/16/2022 08:57:30 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.03 on epoch=24
06/16/2022 08:58:25 - INFO - __main__ - Global step 2800 Train loss 0.04 Classification-F1 0.7246943089393448 on epoch=24
06/16/2022 08:58:28 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.03 on epoch=25
06/16/2022 08:58:30 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=25
06/16/2022 08:58:33 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.05 on epoch=25
06/16/2022 08:58:36 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.06 on epoch=25
06/16/2022 08:58:39 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=25
06/16/2022 08:59:28 - INFO - __main__ - Global step 2850 Train loss 0.03 Classification-F1 0.5924837137841541 on epoch=25
06/16/2022 08:59:30 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=25
06/16/2022 08:59:33 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=25
06/16/2022 08:59:36 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=25
06/16/2022 08:59:40 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.04 on epoch=25
06/16/2022 08:59:43 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.07 on epoch=25
06/16/2022 09:00:34 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.7597873127280365 on epoch=25
06/16/2022 09:00:37 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=25
06/16/2022 09:00:40 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=26
06/16/2022 09:00:43 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.04 on epoch=26
06/16/2022 09:00:46 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.03 on epoch=26
06/16/2022 09:00:49 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=26
06/16/2022 09:01:44 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.8048316071609255 on epoch=26
06/16/2022 09:01:47 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.03 on epoch=26
06/16/2022 09:01:50 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.06 on epoch=26
06/16/2022 09:01:53 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=26
06/16/2022 09:01:56 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=26
06/16/2022 09:01:59 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.04 on epoch=26
06/16/2022 09:02:01 - INFO - __main__ - Start tokenizing ... 1792 instances
06/16/2022 09:02:01 - INFO - __main__ - Printing 3 examples
06/16/2022 09:02:01 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/16/2022 09:02:01 - INFO - __main__ - ['Animal']
06/16/2022 09:02:01 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/16/2022 09:02:01 - INFO - __main__ - ['Animal']
06/16/2022 09:02:01 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/16/2022 09:02:01 - INFO - __main__ - ['Animal']
06/16/2022 09:02:01 - INFO - __main__ - Tokenizing Input ...
06/16/2022 09:02:02 - INFO - __main__ - Tokenizing Output ...
06/16/2022 09:02:05 - INFO - __main__ - Loaded 1792 examples from train data
06/16/2022 09:02:05 - INFO - __main__ - Start tokenizing ... 1792 instances
06/16/2022 09:02:05 - INFO - __main__ - Printing 3 examples
06/16/2022 09:02:05 - INFO - __main__ -  [dbpedia_14] Palaephatus fusciterminus is a moth of the Palaephatidae family. It is found in the Valdivian forests of southern Argentina and Chile.The length of the forewings is 10-12 mm for males and 10.5-11.5 mm for females. Adults have a buff to brown head and thorax and dark brownish fuscous forewings with a pale buff hindmargin. They are on wing from October to March possibly in multiple generations per year.
06/16/2022 09:02:05 - INFO - __main__ - ['Animal']
06/16/2022 09:02:05 - INFO - __main__ -  [dbpedia_14] Labus is an indomalayan genus of potter wasps.
06/16/2022 09:02:05 - INFO - __main__ - ['Animal']
06/16/2022 09:02:05 - INFO - __main__ -  [dbpedia_14] Trifurcula beirnei is a moth of the Nepticulidae family. It is found in Great Britain Denmark and parts of Germany and Poland Austria the Czech Republic Slovakia and Hungary. It is also found in the Volga and Ural region of Russia.The wingspan is 8–11 mm. Adults are on wing from the end of June to late September.The larvae feed on Genista species including Genista tinctoria Genista germanica and Genista pilosa.
06/16/2022 09:02:05 - INFO - __main__ - ['Animal']
06/16/2022 09:02:05 - INFO - __main__ - Tokenizing Input ...
06/16/2022 09:02:06 - INFO - __main__ - Tokenizing Output ...
06/16/2022 09:02:08 - INFO - __main__ - Loaded 1792 examples from dev data
06/16/2022 09:02:30 - INFO - __main__ - load prompt embedding from ckpt
06/16/2022 09:02:31 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/16/2022 09:02:31 - INFO - __main__ - Starting training!
06/16/2022 09:02:58 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.8127424768227755 on epoch=26
06/16/2022 09:02:58 - INFO - __main__ - save last model!
06/16/2022 09:02:58 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/16/2022 09:02:58 - INFO - __main__ - Start tokenizing ... 3500 instances
06/16/2022 09:02:58 - INFO - __main__ - Printing 3 examples
06/16/2022 09:02:58 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/16/2022 09:02:58 - INFO - __main__ - ['Animal']
06/16/2022 09:02:58 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/16/2022 09:02:58 - INFO - __main__ - ['Animal']
06/16/2022 09:02:58 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/16/2022 09:02:58 - INFO - __main__ - ['Village']
06/16/2022 09:02:58 - INFO - __main__ - Tokenizing Input ...
06/16/2022 09:03:00 - INFO - __main__ - Tokenizing Output ...
06/16/2022 09:03:04 - INFO - __main__ - Loaded 3500 examples from test data
06/16/2022 09:05:31 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down128shot/singletask-dbpedia_14/dbpedia_14_128_100_0.5_8_predictions.txt
06/16/2022 09:05:31 - INFO - __main__ - Classification-F1 on test data: 0.6552
06/16/2022 09:05:31 - INFO - __main__ - prefix=dbpedia_14_128_100, lr=0.5, bsz=8, dev_performance=0.9179544444088069, test_performance=0.6552179989950958
06/16/2022 09:05:31 - INFO - __main__ - Running ... prefix=dbpedia_14_128_100, lr=0.4, bsz=8 ...
06/16/2022 09:05:32 - INFO - __main__ - Start tokenizing ... 1792 instances
06/16/2022 09:05:32 - INFO - __main__ - Printing 3 examples
06/16/2022 09:05:32 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/16/2022 09:05:32 - INFO - __main__ - ['Animal']
06/16/2022 09:05:32 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/16/2022 09:05:32 - INFO - __main__ - ['Animal']
06/16/2022 09:05:32 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/16/2022 09:05:32 - INFO - __main__ - ['Animal']
06/16/2022 09:05:32 - INFO - __main__ - Tokenizing Input ...
06/16/2022 09:05:33 - INFO - __main__ - Tokenizing Output ...
06/16/2022 09:05:36 - INFO - __main__ - Loaded 1792 examples from train data
06/16/2022 09:05:36 - INFO - __main__ - Start tokenizing ... 1792 instances
06/16/2022 09:05:36 - INFO - __main__ - Printing 3 examples
06/16/2022 09:05:36 - INFO - __main__ -  [dbpedia_14] Palaephatus fusciterminus is a moth of the Palaephatidae family. It is found in the Valdivian forests of southern Argentina and Chile.The length of the forewings is 10-12 mm for males and 10.5-11.5 mm for females. Adults have a buff to brown head and thorax and dark brownish fuscous forewings with a pale buff hindmargin. They are on wing from October to March possibly in multiple generations per year.
06/16/2022 09:05:36 - INFO - __main__ - ['Animal']
06/16/2022 09:05:36 - INFO - __main__ -  [dbpedia_14] Labus is an indomalayan genus of potter wasps.
06/16/2022 09:05:36 - INFO - __main__ - ['Animal']
06/16/2022 09:05:36 - INFO - __main__ -  [dbpedia_14] Trifurcula beirnei is a moth of the Nepticulidae family. It is found in Great Britain Denmark and parts of Germany and Poland Austria the Czech Republic Slovakia and Hungary. It is also found in the Volga and Ural region of Russia.The wingspan is 8–11 mm. Adults are on wing from the end of June to late September.The larvae feed on Genista species including Genista tinctoria Genista germanica and Genista pilosa.
06/16/2022 09:05:36 - INFO - __main__ - ['Animal']
06/16/2022 09:05:36 - INFO - __main__ - Tokenizing Input ...
06/16/2022 09:05:37 - INFO - __main__ - Tokenizing Output ...
06/16/2022 09:05:40 - INFO - __main__ - Loaded 1792 examples from dev data
06/16/2022 09:05:57 - INFO - __main__ - load prompt embedding from ckpt
06/16/2022 09:05:58 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/16/2022 09:05:58 - INFO - __main__ - Starting training!
06/16/2022 09:06:02 - INFO - __main__ - Step 10 Global step 10 Train loss 4.50 on epoch=0
06/16/2022 09:06:05 - INFO - __main__ - Step 20 Global step 20 Train loss 3.01 on epoch=0
06/16/2022 09:06:08 - INFO - __main__ - Step 30 Global step 30 Train loss 1.93 on epoch=0
06/16/2022 09:06:11 - INFO - __main__ - Step 40 Global step 40 Train loss 1.63 on epoch=0
06/16/2022 09:06:14 - INFO - __main__ - Step 50 Global step 50 Train loss 1.24 on epoch=0
06/16/2022 09:07:07 - INFO - __main__ - Global step 50 Train loss 2.46 Classification-F1 0.18895274900419218 on epoch=0
06/16/2022 09:07:07 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.18895274900419218 on epoch=0, global_step=50
06/16/2022 09:07:10 - INFO - __main__ - Step 60 Global step 60 Train loss 1.10 on epoch=0
06/16/2022 09:07:12 - INFO - __main__ - Step 70 Global step 70 Train loss 1.14 on epoch=0
06/16/2022 09:07:15 - INFO - __main__ - Step 80 Global step 80 Train loss 0.74 on epoch=0
06/16/2022 09:07:18 - INFO - __main__ - Step 90 Global step 90 Train loss 0.74 on epoch=0
06/16/2022 09:07:21 - INFO - __main__ - Step 100 Global step 100 Train loss 0.69 on epoch=0
06/16/2022 09:08:18 - INFO - __main__ - Global step 100 Train loss 0.88 Classification-F1 0.3716068096641906 on epoch=0
06/16/2022 09:08:18 - INFO - __main__ - Saving model with best Classification-F1: 0.18895274900419218 -> 0.3716068096641906 on epoch=0, global_step=100
06/16/2022 09:08:20 - INFO - __main__ - Step 110 Global step 110 Train loss 0.77 on epoch=0
06/16/2022 09:08:23 - INFO - __main__ - Step 120 Global step 120 Train loss 0.56 on epoch=1
06/16/2022 09:08:26 - INFO - __main__ - Step 130 Global step 130 Train loss 0.60 on epoch=1
06/16/2022 09:08:29 - INFO - __main__ - Step 140 Global step 140 Train loss 0.60 on epoch=1
06/16/2022 09:08:32 - INFO - __main__ - Step 150 Global step 150 Train loss 0.44 on epoch=1
06/16/2022 09:09:26 - INFO - __main__ - Global step 150 Train loss 0.59 Classification-F1 0.27488568076544706 on epoch=1
06/16/2022 09:09:29 - INFO - __main__ - Step 160 Global step 160 Train loss 0.54 on epoch=1
06/16/2022 09:09:32 - INFO - __main__ - Step 170 Global step 170 Train loss 0.48 on epoch=1
06/16/2022 09:09:35 - INFO - __main__ - Step 180 Global step 180 Train loss 0.53 on epoch=1
06/16/2022 09:09:37 - INFO - __main__ - Step 190 Global step 190 Train loss 0.39 on epoch=1
06/16/2022 09:09:40 - INFO - __main__ - Step 200 Global step 200 Train loss 0.40 on epoch=1
06/16/2022 09:10:37 - INFO - __main__ - Global step 200 Train loss 0.47 Classification-F1 0.41955840736749717 on epoch=1
06/16/2022 09:10:37 - INFO - __main__ - Saving model with best Classification-F1: 0.3716068096641906 -> 0.41955840736749717 on epoch=1, global_step=200
06/16/2022 09:10:40 - INFO - __main__ - Step 210 Global step 210 Train loss 0.38 on epoch=1
06/16/2022 09:10:42 - INFO - __main__ - Step 220 Global step 220 Train loss 0.35 on epoch=1
06/16/2022 09:10:45 - INFO - __main__ - Step 230 Global step 230 Train loss 0.28 on epoch=2
06/16/2022 09:10:48 - INFO - __main__ - Step 240 Global step 240 Train loss 0.36 on epoch=2
06/16/2022 09:10:50 - INFO - __main__ - Step 250 Global step 250 Train loss 0.27 on epoch=2
06/16/2022 09:11:46 - INFO - __main__ - Global step 250 Train loss 0.33 Classification-F1 0.47167444235089306 on epoch=2
06/16/2022 09:11:46 - INFO - __main__ - Saving model with best Classification-F1: 0.41955840736749717 -> 0.47167444235089306 on epoch=2, global_step=250
06/16/2022 09:11:48 - INFO - __main__ - Step 260 Global step 260 Train loss 0.26 on epoch=2
06/16/2022 09:11:51 - INFO - __main__ - Step 270 Global step 270 Train loss 0.26 on epoch=2
06/16/2022 09:11:54 - INFO - __main__ - Step 280 Global step 280 Train loss 0.28 on epoch=2
06/16/2022 09:11:57 - INFO - __main__ - Step 290 Global step 290 Train loss 0.30 on epoch=2
06/16/2022 09:11:59 - INFO - __main__ - Step 300 Global step 300 Train loss 0.31 on epoch=2
06/16/2022 09:13:03 - INFO - __main__ - Global step 300 Train loss 0.28 Classification-F1 0.4827899183178963 on epoch=2
06/16/2022 09:13:03 - INFO - __main__ - Saving model with best Classification-F1: 0.47167444235089306 -> 0.4827899183178963 on epoch=2, global_step=300
06/16/2022 09:13:06 - INFO - __main__ - Step 310 Global step 310 Train loss 0.19 on epoch=2
06/16/2022 09:13:08 - INFO - __main__ - Step 320 Global step 320 Train loss 0.22 on epoch=2
06/16/2022 09:13:11 - INFO - __main__ - Step 330 Global step 330 Train loss 0.30 on epoch=2
06/16/2022 09:13:14 - INFO - __main__ - Step 340 Global step 340 Train loss 0.15 on epoch=3
06/16/2022 09:13:17 - INFO - __main__ - Step 350 Global step 350 Train loss 0.23 on epoch=3
06/16/2022 09:14:16 - INFO - __main__ - Global step 350 Train loss 0.22 Classification-F1 0.5713319236413481 on epoch=3
06/16/2022 09:14:16 - INFO - __main__ - Saving model with best Classification-F1: 0.4827899183178963 -> 0.5713319236413481 on epoch=3, global_step=350
06/16/2022 09:14:19 - INFO - __main__ - Step 360 Global step 360 Train loss 0.26 on epoch=3
06/16/2022 09:14:21 - INFO - __main__ - Step 370 Global step 370 Train loss 0.45 on epoch=3
06/16/2022 09:14:24 - INFO - __main__ - Step 380 Global step 380 Train loss 0.34 on epoch=3
06/16/2022 09:14:27 - INFO - __main__ - Step 390 Global step 390 Train loss 0.30 on epoch=3
06/16/2022 09:14:30 - INFO - __main__ - Step 400 Global step 400 Train loss 0.26 on epoch=3
06/16/2022 09:15:22 - INFO - __main__ - Global step 400 Train loss 0.32 Classification-F1 0.5237230382506665 on epoch=3
06/16/2022 09:15:26 - INFO - __main__ - Step 410 Global step 410 Train loss 0.27 on epoch=3
06/16/2022 09:15:29 - INFO - __main__ - Step 420 Global step 420 Train loss 0.22 on epoch=3
06/16/2022 09:15:32 - INFO - __main__ - Step 430 Global step 430 Train loss 0.26 on epoch=3
06/16/2022 09:15:36 - INFO - __main__ - Step 440 Global step 440 Train loss 0.25 on epoch=3
06/16/2022 09:15:39 - INFO - __main__ - Step 450 Global step 450 Train loss 0.20 on epoch=4
06/16/2022 09:16:40 - INFO - __main__ - Global step 450 Train loss 0.24 Classification-F1 0.6105986750868878 on epoch=4
06/16/2022 09:16:40 - INFO - __main__ - Saving model with best Classification-F1: 0.5713319236413481 -> 0.6105986750868878 on epoch=4, global_step=450
06/16/2022 09:16:43 - INFO - __main__ - Step 460 Global step 460 Train loss 0.23 on epoch=4
06/16/2022 09:16:46 - INFO - __main__ - Step 470 Global step 470 Train loss 0.20 on epoch=4
06/16/2022 09:16:49 - INFO - __main__ - Step 480 Global step 480 Train loss 0.29 on epoch=4
06/16/2022 09:16:52 - INFO - __main__ - Step 490 Global step 490 Train loss 0.16 on epoch=4
06/16/2022 09:16:55 - INFO - __main__ - Step 500 Global step 500 Train loss 0.21 on epoch=4
06/16/2022 09:17:58 - INFO - __main__ - Global step 500 Train loss 0.22 Classification-F1 0.6730447586212434 on epoch=4
06/16/2022 09:17:58 - INFO - __main__ - Saving model with best Classification-F1: 0.6105986750868878 -> 0.6730447586212434 on epoch=4, global_step=500
06/16/2022 09:18:01 - INFO - __main__ - Step 510 Global step 510 Train loss 0.25 on epoch=4
06/16/2022 09:18:04 - INFO - __main__ - Step 520 Global step 520 Train loss 0.22 on epoch=4
06/16/2022 09:18:07 - INFO - __main__ - Step 530 Global step 530 Train loss 0.14 on epoch=4
06/16/2022 09:18:10 - INFO - __main__ - Step 540 Global step 540 Train loss 0.18 on epoch=4
06/16/2022 09:18:13 - INFO - __main__ - Step 550 Global step 550 Train loss 0.21 on epoch=4
06/16/2022 09:19:12 - INFO - __main__ - Global step 550 Train loss 0.20 Classification-F1 0.6444315601046434 on epoch=4
06/16/2022 09:19:15 - INFO - __main__ - Step 560 Global step 560 Train loss 0.12 on epoch=4
06/16/2022 09:19:18 - INFO - __main__ - Step 570 Global step 570 Train loss 0.16 on epoch=5
06/16/2022 09:19:21 - INFO - __main__ - Step 580 Global step 580 Train loss 0.20 on epoch=5
06/16/2022 09:19:23 - INFO - __main__ - Step 590 Global step 590 Train loss 0.16 on epoch=5
06/16/2022 09:19:26 - INFO - __main__ - Step 600 Global step 600 Train loss 0.12 on epoch=5
06/16/2022 09:20:22 - INFO - __main__ - Global step 600 Train loss 0.15 Classification-F1 0.6642528828850423 on epoch=5
06/16/2022 09:20:25 - INFO - __main__ - Step 610 Global step 610 Train loss 0.21 on epoch=5
06/16/2022 09:20:28 - INFO - __main__ - Step 620 Global step 620 Train loss 0.22 on epoch=5
06/16/2022 09:20:31 - INFO - __main__ - Step 630 Global step 630 Train loss 0.18 on epoch=5
06/16/2022 09:20:34 - INFO - __main__ - Step 640 Global step 640 Train loss 0.08 on epoch=5
06/16/2022 09:20:37 - INFO - __main__ - Step 650 Global step 650 Train loss 0.18 on epoch=5
06/16/2022 09:21:37 - INFO - __main__ - Global step 650 Train loss 0.18 Classification-F1 0.7572867342401403 on epoch=5
06/16/2022 09:21:37 - INFO - __main__ - Saving model with best Classification-F1: 0.6730447586212434 -> 0.7572867342401403 on epoch=5, global_step=650
06/16/2022 09:21:39 - INFO - __main__ - Step 660 Global step 660 Train loss 0.18 on epoch=5
06/16/2022 09:21:42 - INFO - __main__ - Step 670 Global step 670 Train loss 0.09 on epoch=5
06/16/2022 09:21:45 - INFO - __main__ - Step 680 Global step 680 Train loss 0.14 on epoch=6
06/16/2022 09:21:47 - INFO - __main__ - Step 690 Global step 690 Train loss 0.10 on epoch=6
06/16/2022 09:21:50 - INFO - __main__ - Step 700 Global step 700 Train loss 0.17 on epoch=6
06/16/2022 09:22:43 - INFO - __main__ - Global step 700 Train loss 0.14 Classification-F1 0.6540884728607986 on epoch=6
06/16/2022 09:22:46 - INFO - __main__ - Step 710 Global step 710 Train loss 0.06 on epoch=6
06/16/2022 09:22:49 - INFO - __main__ - Step 720 Global step 720 Train loss 0.15 on epoch=6
06/16/2022 09:22:51 - INFO - __main__ - Step 730 Global step 730 Train loss 0.15 on epoch=6
06/16/2022 09:22:54 - INFO - __main__ - Step 740 Global step 740 Train loss 0.13 on epoch=6
06/16/2022 09:22:57 - INFO - __main__ - Step 750 Global step 750 Train loss 0.11 on epoch=6
06/16/2022 09:23:53 - INFO - __main__ - Global step 750 Train loss 0.12 Classification-F1 0.7573084801701977 on epoch=6
06/16/2022 09:23:53 - INFO - __main__ - Saving model with best Classification-F1: 0.7572867342401403 -> 0.7573084801701977 on epoch=6, global_step=750
06/16/2022 09:23:56 - INFO - __main__ - Step 760 Global step 760 Train loss 0.10 on epoch=6
06/16/2022 09:23:58 - INFO - __main__ - Step 770 Global step 770 Train loss 0.10 on epoch=6
06/16/2022 09:24:01 - INFO - __main__ - Step 780 Global step 780 Train loss 0.13 on epoch=6
06/16/2022 09:24:04 - INFO - __main__ - Step 790 Global step 790 Train loss 0.05 on epoch=7
06/16/2022 09:24:06 - INFO - __main__ - Step 800 Global step 800 Train loss 0.13 on epoch=7
06/16/2022 09:24:59 - INFO - __main__ - Global step 800 Train loss 0.10 Classification-F1 0.6904174197763961 on epoch=7
06/16/2022 09:25:01 - INFO - __main__ - Step 810 Global step 810 Train loss 0.10 on epoch=7
06/16/2022 09:25:04 - INFO - __main__ - Step 820 Global step 820 Train loss 0.09 on epoch=7
06/16/2022 09:25:07 - INFO - __main__ - Step 830 Global step 830 Train loss 0.13 on epoch=7
06/16/2022 09:25:10 - INFO - __main__ - Step 840 Global step 840 Train loss 0.11 on epoch=7
06/16/2022 09:25:13 - INFO - __main__ - Step 850 Global step 850 Train loss 0.13 on epoch=7
06/16/2022 09:26:10 - INFO - __main__ - Global step 850 Train loss 0.11 Classification-F1 0.7609001645484817 on epoch=7
06/16/2022 09:26:10 - INFO - __main__ - Saving model with best Classification-F1: 0.7573084801701977 -> 0.7609001645484817 on epoch=7, global_step=850
06/16/2022 09:26:12 - INFO - __main__ - Step 860 Global step 860 Train loss 0.05 on epoch=7
06/16/2022 09:26:15 - INFO - __main__ - Step 870 Global step 870 Train loss 0.14 on epoch=7
06/16/2022 09:26:18 - INFO - __main__ - Step 880 Global step 880 Train loss 0.11 on epoch=7
06/16/2022 09:26:21 - INFO - __main__ - Step 890 Global step 890 Train loss 0.12 on epoch=7
06/16/2022 09:26:23 - INFO - __main__ - Step 900 Global step 900 Train loss 0.06 on epoch=8
06/16/2022 09:27:11 - INFO - __main__ - Global step 900 Train loss 0.10 Classification-F1 0.6856965539887051 on epoch=8
06/16/2022 09:27:14 - INFO - __main__ - Step 910 Global step 910 Train loss 0.05 on epoch=8
06/16/2022 09:27:17 - INFO - __main__ - Step 920 Global step 920 Train loss 0.10 on epoch=8
06/16/2022 09:27:20 - INFO - __main__ - Step 930 Global step 930 Train loss 0.07 on epoch=8
06/16/2022 09:27:23 - INFO - __main__ - Step 940 Global step 940 Train loss 0.06 on epoch=8
06/16/2022 09:27:26 - INFO - __main__ - Step 950 Global step 950 Train loss 0.06 on epoch=8
06/16/2022 09:28:23 - INFO - __main__ - Global step 950 Train loss 0.07 Classification-F1 0.6249297672765867 on epoch=8
06/16/2022 09:28:26 - INFO - __main__ - Step 960 Global step 960 Train loss 0.13 on epoch=8
06/16/2022 09:28:29 - INFO - __main__ - Step 970 Global step 970 Train loss 0.17 on epoch=8
06/16/2022 09:28:31 - INFO - __main__ - Step 980 Global step 980 Train loss 0.08 on epoch=8
06/16/2022 09:28:34 - INFO - __main__ - Step 990 Global step 990 Train loss 0.06 on epoch=8
06/16/2022 09:28:37 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.10 on epoch=8
06/16/2022 09:29:27 - INFO - __main__ - Global step 1000 Train loss 0.11 Classification-F1 0.7218363780454223 on epoch=8
06/16/2022 09:29:29 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.08 on epoch=9
06/16/2022 09:29:32 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.05 on epoch=9
06/16/2022 09:29:35 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.08 on epoch=9
06/16/2022 09:29:38 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.08 on epoch=9
06/16/2022 09:29:40 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.06 on epoch=9
06/16/2022 09:30:30 - INFO - __main__ - Global step 1050 Train loss 0.07 Classification-F1 0.6116755325396166 on epoch=9
06/16/2022 09:30:32 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.09 on epoch=9
06/16/2022 09:30:35 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.08 on epoch=9
06/16/2022 09:30:38 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.12 on epoch=9
06/16/2022 09:30:41 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.06 on epoch=9
06/16/2022 09:30:43 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.07 on epoch=9
06/16/2022 09:31:34 - INFO - __main__ - Global step 1100 Train loss 0.08 Classification-F1 0.6227745712562707 on epoch=9
06/16/2022 09:31:36 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.07 on epoch=9
06/16/2022 09:31:39 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.04 on epoch=9
06/16/2022 09:31:42 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.06 on epoch=10
06/16/2022 09:31:45 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.06 on epoch=10
06/16/2022 09:31:47 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.13 on epoch=10
06/16/2022 09:32:37 - INFO - __main__ - Global step 1150 Train loss 0.07 Classification-F1 0.506049608681428 on epoch=10
06/16/2022 09:32:39 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.11 on epoch=10
06/16/2022 09:32:42 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.08 on epoch=10
06/16/2022 09:32:45 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.05 on epoch=10
06/16/2022 09:32:48 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.11 on epoch=10
06/16/2022 09:32:50 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.04 on epoch=10
06/16/2022 09:33:46 - INFO - __main__ - Global step 1200 Train loss 0.08 Classification-F1 0.5669630632950157 on epoch=10
06/16/2022 09:33:49 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.05 on epoch=10
06/16/2022 09:33:52 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.12 on epoch=10
06/16/2022 09:33:55 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.06 on epoch=10
06/16/2022 09:33:57 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.05 on epoch=11
06/16/2022 09:34:00 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.07 on epoch=11
06/16/2022 09:34:48 - INFO - __main__ - Global step 1250 Train loss 0.07 Classification-F1 0.4715323151021436 on epoch=11
06/16/2022 09:34:50 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.05 on epoch=11
06/16/2022 09:34:53 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.05 on epoch=11
06/16/2022 09:34:56 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.08 on epoch=11
06/16/2022 09:34:59 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.03 on epoch=11
06/16/2022 09:35:01 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.07 on epoch=11
06/16/2022 09:35:54 - INFO - __main__ - Global step 1300 Train loss 0.05 Classification-F1 0.74906786489551 on epoch=11
06/16/2022 09:35:57 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.05 on epoch=11
06/16/2022 09:36:00 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.13 on epoch=11
06/16/2022 09:36:03 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.08 on epoch=11
06/16/2022 09:36:06 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.06 on epoch=11
06/16/2022 09:36:08 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.03 on epoch=12
06/16/2022 09:36:56 - INFO - __main__ - Global step 1350 Train loss 0.07 Classification-F1 0.40052560725202047 on epoch=12
06/16/2022 09:36:59 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.09 on epoch=12
06/16/2022 09:37:02 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.13 on epoch=12
06/16/2022 09:37:04 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.03 on epoch=12
06/16/2022 09:37:07 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.03 on epoch=12
06/16/2022 09:37:10 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=12
06/16/2022 09:38:07 - INFO - __main__ - Global step 1400 Train loss 0.06 Classification-F1 0.5167565170575608 on epoch=12
06/16/2022 09:38:10 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.06 on epoch=12
06/16/2022 09:38:13 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.03 on epoch=12
06/16/2022 09:38:16 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.05 on epoch=12
06/16/2022 09:38:19 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.05 on epoch=12
06/16/2022 09:38:22 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.07 on epoch=12
06/16/2022 09:39:08 - INFO - __main__ - Global step 1450 Train loss 0.05 Classification-F1 0.608710370928439 on epoch=12
06/16/2022 09:39:11 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.03 on epoch=13
06/16/2022 09:39:14 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.07 on epoch=13
06/16/2022 09:39:17 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.13 on epoch=13
06/16/2022 09:39:20 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.07 on epoch=13
06/16/2022 09:39:23 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.04 on epoch=13
06/16/2022 09:40:11 - INFO - __main__ - Global step 1500 Train loss 0.07 Classification-F1 0.5007985384056508 on epoch=13
06/16/2022 09:40:14 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.04 on epoch=13
06/16/2022 09:40:17 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.07 on epoch=13
06/16/2022 09:40:20 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.03 on epoch=13
06/16/2022 09:40:23 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=13
06/16/2022 09:40:26 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.07 on epoch=13
06/16/2022 09:41:15 - INFO - __main__ - Global step 1550 Train loss 0.05 Classification-F1 0.650769017644356 on epoch=13
06/16/2022 09:41:18 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.08 on epoch=13
06/16/2022 09:41:22 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.05 on epoch=14
06/16/2022 09:41:25 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.06 on epoch=14
06/16/2022 09:41:28 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.11 on epoch=14
06/16/2022 09:41:31 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.13 on epoch=14
06/16/2022 09:42:17 - INFO - __main__ - Global step 1600 Train loss 0.09 Classification-F1 0.48305627323418804 on epoch=14
06/16/2022 09:42:20 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.07 on epoch=14
06/16/2022 09:42:23 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.09 on epoch=14
06/16/2022 09:42:26 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.10 on epoch=14
06/16/2022 09:42:29 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.04 on epoch=14
06/16/2022 09:42:31 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=14
06/16/2022 09:43:31 - INFO - __main__ - Global step 1650 Train loss 0.07 Classification-F1 0.5374859279154806 on epoch=14
06/16/2022 09:43:34 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.05 on epoch=14
06/16/2022 09:43:37 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.08 on epoch=14
06/16/2022 09:43:40 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=14
06/16/2022 09:43:43 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.05 on epoch=15
06/16/2022 09:43:46 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.05 on epoch=15
06/16/2022 09:44:33 - INFO - __main__ - Global step 1700 Train loss 0.05 Classification-F1 0.4801224381010104 on epoch=15
06/16/2022 09:44:36 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.09 on epoch=15
06/16/2022 09:44:39 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.04 on epoch=15
06/16/2022 09:44:43 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.04 on epoch=15
06/16/2022 09:44:46 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.05 on epoch=15
06/16/2022 09:44:49 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=15
06/16/2022 09:45:42 - INFO - __main__ - Global step 1750 Train loss 0.05 Classification-F1 0.7651520787602103 on epoch=15
06/16/2022 09:45:42 - INFO - __main__ - Saving model with best Classification-F1: 0.7609001645484817 -> 0.7651520787602103 on epoch=15, global_step=1750
06/16/2022 09:45:45 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=15
06/16/2022 09:45:48 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.11 on epoch=15
06/16/2022 09:45:52 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.07 on epoch=15
06/16/2022 09:45:55 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.07 on epoch=15
06/16/2022 09:45:58 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=16
06/16/2022 09:46:47 - INFO - __main__ - Global step 1800 Train loss 0.06 Classification-F1 0.5629191361043643 on epoch=16
06/16/2022 09:46:50 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.07 on epoch=16
06/16/2022 09:46:53 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.08 on epoch=16
06/16/2022 09:46:57 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=16
06/16/2022 09:47:00 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=16
06/16/2022 09:47:03 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=16
06/16/2022 09:47:56 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.5994748066550412 on epoch=16
06/16/2022 09:47:59 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.07 on epoch=16
06/16/2022 09:48:02 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.05 on epoch=16
06/16/2022 09:48:05 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.11 on epoch=16
06/16/2022 09:48:09 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.09 on epoch=16
06/16/2022 09:48:12 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.04 on epoch=16
06/16/2022 09:49:03 - INFO - __main__ - Global step 1900 Train loss 0.08 Classification-F1 0.619629467656077 on epoch=16
06/16/2022 09:49:06 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=17
06/16/2022 09:49:10 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.05 on epoch=17
06/16/2022 09:49:12 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.07 on epoch=17
06/16/2022 09:49:15 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=17
06/16/2022 09:49:18 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.03 on epoch=17
06/16/2022 09:50:12 - INFO - __main__ - Global step 1950 Train loss 0.04 Classification-F1 0.584898953333859 on epoch=17
06/16/2022 09:50:15 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.03 on epoch=17
06/16/2022 09:50:18 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=17
06/16/2022 09:50:21 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=17
06/16/2022 09:50:24 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.07 on epoch=17
06/16/2022 09:50:27 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=17
06/16/2022 09:51:17 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.5894133080028682 on epoch=17
06/16/2022 09:51:20 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.05 on epoch=17
06/16/2022 09:51:23 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=18
06/16/2022 09:51:26 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.04 on epoch=18
06/16/2022 09:51:29 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.08 on epoch=18
06/16/2022 09:51:31 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.04 on epoch=18
06/16/2022 09:52:19 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.5769906483147169 on epoch=18
06/16/2022 09:52:21 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.04 on epoch=18
06/16/2022 09:52:24 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.04 on epoch=18
06/16/2022 09:52:27 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=18
06/16/2022 09:52:30 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.08 on epoch=18
06/16/2022 09:52:33 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=18
06/16/2022 09:53:29 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.7671977169541733 on epoch=18
06/16/2022 09:53:29 - INFO - __main__ - Saving model with best Classification-F1: 0.7651520787602103 -> 0.7671977169541733 on epoch=18, global_step=2100
06/16/2022 09:53:32 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.08 on epoch=18
06/16/2022 09:53:35 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.03 on epoch=18
06/16/2022 09:53:38 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=19
06/16/2022 09:53:40 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.04 on epoch=19
06/16/2022 09:53:43 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.05 on epoch=19
06/16/2022 09:54:31 - INFO - __main__ - Global step 2150 Train loss 0.05 Classification-F1 0.6523690282830282 on epoch=19
06/16/2022 09:54:33 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.05 on epoch=19
06/16/2022 09:54:36 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=19
06/16/2022 09:54:39 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=19
06/16/2022 09:54:41 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=19
06/16/2022 09:54:44 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.03 on epoch=19
06/16/2022 09:55:31 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.5934995557548703 on epoch=19
06/16/2022 09:55:34 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=19
06/16/2022 09:55:37 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.05 on epoch=19
06/16/2022 09:55:39 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.08 on epoch=19
06/16/2022 09:55:42 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=19
06/16/2022 09:55:44 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.03 on epoch=20
06/16/2022 09:56:30 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.5220078167718089 on epoch=20
06/16/2022 09:56:33 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=20
06/16/2022 09:56:36 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.04 on epoch=20
06/16/2022 09:56:38 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=20
06/16/2022 09:56:41 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.03 on epoch=20
06/16/2022 09:56:44 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=20
06/16/2022 09:57:32 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.6543802029649074 on epoch=20
06/16/2022 09:57:35 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.05 on epoch=20
06/16/2022 09:57:38 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.04 on epoch=20
06/16/2022 09:57:40 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.05 on epoch=20
06/16/2022 09:57:43 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.07 on epoch=20
06/16/2022 09:57:46 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=20
06/16/2022 09:58:33 - INFO - __main__ - Global step 2350 Train loss 0.05 Classification-F1 0.6161603803053876 on epoch=20
06/16/2022 09:58:36 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=21
06/16/2022 09:58:39 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.04 on epoch=21
06/16/2022 09:58:42 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.07 on epoch=21
06/16/2022 09:58:45 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.04 on epoch=21
06/16/2022 09:58:47 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.04 on epoch=21
06/16/2022 09:59:38 - INFO - __main__ - Global step 2400 Train loss 0.04 Classification-F1 0.538244781115676 on epoch=21
06/16/2022 09:59:41 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.03 on epoch=21
06/16/2022 09:59:44 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=21
06/16/2022 09:59:46 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=21
06/16/2022 09:59:49 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.05 on epoch=21
06/16/2022 09:59:52 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.06 on epoch=21
06/16/2022 10:00:40 - INFO - __main__ - Global step 2450 Train loss 0.04 Classification-F1 0.351523592220118 on epoch=21
06/16/2022 10:00:43 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.04 on epoch=21
06/16/2022 10:00:46 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.17 on epoch=22
06/16/2022 10:00:49 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.03 on epoch=22
06/16/2022 10:00:51 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.04 on epoch=22
06/16/2022 10:00:54 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=22
06/16/2022 10:01:40 - INFO - __main__ - Global step 2500 Train loss 0.06 Classification-F1 0.48832023314084483 on epoch=22
06/16/2022 10:01:43 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=22
06/16/2022 10:01:45 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.04 on epoch=22
06/16/2022 10:01:48 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.06 on epoch=22
06/16/2022 10:01:51 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.03 on epoch=22
06/16/2022 10:01:54 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.13 on epoch=22
06/16/2022 10:02:43 - INFO - __main__ - Global step 2550 Train loss 0.06 Classification-F1 0.4752708031003287 on epoch=22
06/16/2022 10:02:45 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.04 on epoch=22
06/16/2022 10:02:48 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.05 on epoch=22
06/16/2022 10:02:51 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=23
06/16/2022 10:02:54 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=23
06/16/2022 10:02:57 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.07 on epoch=23
06/16/2022 10:03:50 - INFO - __main__ - Global step 2600 Train loss 0.04 Classification-F1 0.44396439988414055 on epoch=23
06/16/2022 10:03:53 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=23
06/16/2022 10:03:56 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.04 on epoch=23
06/16/2022 10:03:58 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=23
06/16/2022 10:04:01 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=23
06/16/2022 10:04:04 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.05 on epoch=23
06/16/2022 10:04:52 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.5035866124801395 on epoch=23
06/16/2022 10:04:55 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=23
06/16/2022 10:04:58 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.05 on epoch=23
06/16/2022 10:05:01 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.08 on epoch=23
06/16/2022 10:05:04 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.03 on epoch=24
06/16/2022 10:05:07 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=24
06/16/2022 10:05:54 - INFO - __main__ - Global step 2700 Train loss 0.04 Classification-F1 0.5914736231597061 on epoch=24
06/16/2022 10:05:57 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=24
06/16/2022 10:06:00 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.07 on epoch=24
06/16/2022 10:06:02 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.04 on epoch=24
06/16/2022 10:06:05 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=24
06/16/2022 10:06:08 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.07 on epoch=24
06/16/2022 10:06:56 - INFO - __main__ - Global step 2750 Train loss 0.04 Classification-F1 0.5680001541560332 on epoch=24
06/16/2022 10:06:59 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.03 on epoch=24
06/16/2022 10:07:02 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=24
06/16/2022 10:07:05 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.05 on epoch=24
06/16/2022 10:07:08 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.04 on epoch=24
06/16/2022 10:07:11 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=24
06/16/2022 10:08:02 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.5113482311812609 on epoch=24
06/16/2022 10:08:05 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=25
06/16/2022 10:08:08 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=25
06/16/2022 10:08:11 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.04 on epoch=25
06/16/2022 10:08:14 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.03 on epoch=25
06/16/2022 10:08:16 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.03 on epoch=25
06/16/2022 10:09:10 - INFO - __main__ - Global step 2850 Train loss 0.03 Classification-F1 0.44729208881846005 on epoch=25
06/16/2022 10:09:13 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=25
06/16/2022 10:09:16 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.04 on epoch=25
06/16/2022 10:09:19 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=25
06/16/2022 10:09:22 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.10 on epoch=25
06/16/2022 10:09:25 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.05 on epoch=25
06/16/2022 10:10:16 - INFO - __main__ - Global step 2900 Train loss 0.04 Classification-F1 0.6449128188345096 on epoch=25
06/16/2022 10:10:19 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.04 on epoch=25
06/16/2022 10:10:22 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=26
06/16/2022 10:10:25 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.06 on epoch=26
06/16/2022 10:10:28 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.08 on epoch=26
06/16/2022 10:10:31 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=26
06/16/2022 10:11:22 - INFO - __main__ - Global step 2950 Train loss 0.04 Classification-F1 0.7221118379969343 on epoch=26
06/16/2022 10:11:25 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=26
06/16/2022 10:11:28 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.05 on epoch=26
06/16/2022 10:11:31 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=26
06/16/2022 10:11:34 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=26
06/16/2022 10:11:37 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.05 on epoch=26
06/16/2022 10:11:38 - INFO - __main__ - Start tokenizing ... 1792 instances
06/16/2022 10:11:38 - INFO - __main__ - Printing 3 examples
06/16/2022 10:11:38 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/16/2022 10:11:38 - INFO - __main__ - ['Animal']
06/16/2022 10:11:38 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/16/2022 10:11:38 - INFO - __main__ - ['Animal']
06/16/2022 10:11:38 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/16/2022 10:11:38 - INFO - __main__ - ['Animal']
06/16/2022 10:11:38 - INFO - __main__ - Tokenizing Input ...
06/16/2022 10:11:39 - INFO - __main__ - Tokenizing Output ...
06/16/2022 10:11:41 - INFO - __main__ - Loaded 1792 examples from train data
06/16/2022 10:11:41 - INFO - __main__ - Start tokenizing ... 1792 instances
06/16/2022 10:11:41 - INFO - __main__ - Printing 3 examples
06/16/2022 10:11:41 - INFO - __main__ -  [dbpedia_14] Palaephatus fusciterminus is a moth of the Palaephatidae family. It is found in the Valdivian forests of southern Argentina and Chile.The length of the forewings is 10-12 mm for males and 10.5-11.5 mm for females. Adults have a buff to brown head and thorax and dark brownish fuscous forewings with a pale buff hindmargin. They are on wing from October to March possibly in multiple generations per year.
06/16/2022 10:11:41 - INFO - __main__ - ['Animal']
06/16/2022 10:11:41 - INFO - __main__ -  [dbpedia_14] Labus is an indomalayan genus of potter wasps.
06/16/2022 10:11:41 - INFO - __main__ - ['Animal']
06/16/2022 10:11:41 - INFO - __main__ -  [dbpedia_14] Trifurcula beirnei is a moth of the Nepticulidae family. It is found in Great Britain Denmark and parts of Germany and Poland Austria the Czech Republic Slovakia and Hungary. It is also found in the Volga and Ural region of Russia.The wingspan is 8–11 mm. Adults are on wing from the end of June to late September.The larvae feed on Genista species including Genista tinctoria Genista germanica and Genista pilosa.
06/16/2022 10:11:41 - INFO - __main__ - ['Animal']
06/16/2022 10:11:41 - INFO - __main__ - Tokenizing Input ...
06/16/2022 10:11:42 - INFO - __main__ - Tokenizing Output ...
06/16/2022 10:11:44 - INFO - __main__ - Loaded 1792 examples from dev data
06/16/2022 10:12:03 - INFO - __main__ - load prompt embedding from ckpt
06/16/2022 10:12:03 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/16/2022 10:12:03 - INFO - __main__ - Starting training!
06/16/2022 10:12:32 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.6831833413931762 on epoch=26
06/16/2022 10:12:32 - INFO - __main__ - save last model!
06/16/2022 10:12:32 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/16/2022 10:12:32 - INFO - __main__ - Start tokenizing ... 3500 instances
06/16/2022 10:12:32 - INFO - __main__ - Printing 3 examples
06/16/2022 10:12:33 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/16/2022 10:12:33 - INFO - __main__ - ['Animal']
06/16/2022 10:12:33 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/16/2022 10:12:33 - INFO - __main__ - ['Animal']
06/16/2022 10:12:33 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/16/2022 10:12:33 - INFO - __main__ - ['Village']
06/16/2022 10:12:33 - INFO - __main__ - Tokenizing Input ...
06/16/2022 10:12:35 - INFO - __main__ - Tokenizing Output ...
06/16/2022 10:12:40 - INFO - __main__ - Loaded 3500 examples from test data
06/16/2022 10:14:52 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down128shot/singletask-dbpedia_14/dbpedia_14_128_100_0.4_8_predictions.txt
06/16/2022 10:14:53 - INFO - __main__ - Classification-F1 on test data: 0.6160
06/16/2022 10:14:53 - INFO - __main__ - prefix=dbpedia_14_128_100, lr=0.4, bsz=8, dev_performance=0.7671977169541733, test_performance=0.6159940936044372
06/16/2022 10:14:53 - INFO - __main__ - Running ... prefix=dbpedia_14_128_100, lr=0.3, bsz=8 ...
06/16/2022 10:14:54 - INFO - __main__ - Start tokenizing ... 1792 instances
06/16/2022 10:14:54 - INFO - __main__ - Printing 3 examples
06/16/2022 10:14:54 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/16/2022 10:14:54 - INFO - __main__ - ['Animal']
06/16/2022 10:14:54 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/16/2022 10:14:54 - INFO - __main__ - ['Animal']
06/16/2022 10:14:54 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/16/2022 10:14:54 - INFO - __main__ - ['Animal']
06/16/2022 10:14:54 - INFO - __main__ - Tokenizing Input ...
06/16/2022 10:14:55 - INFO - __main__ - Tokenizing Output ...
06/16/2022 10:14:57 - INFO - __main__ - Loaded 1792 examples from train data
06/16/2022 10:14:57 - INFO - __main__ - Start tokenizing ... 1792 instances
06/16/2022 10:14:57 - INFO - __main__ - Printing 3 examples
06/16/2022 10:14:57 - INFO - __main__ -  [dbpedia_14] Palaephatus fusciterminus is a moth of the Palaephatidae family. It is found in the Valdivian forests of southern Argentina and Chile.The length of the forewings is 10-12 mm for males and 10.5-11.5 mm for females. Adults have a buff to brown head and thorax and dark brownish fuscous forewings with a pale buff hindmargin. They are on wing from October to March possibly in multiple generations per year.
06/16/2022 10:14:57 - INFO - __main__ - ['Animal']
06/16/2022 10:14:57 - INFO - __main__ -  [dbpedia_14] Labus is an indomalayan genus of potter wasps.
06/16/2022 10:14:57 - INFO - __main__ - ['Animal']
06/16/2022 10:14:57 - INFO - __main__ -  [dbpedia_14] Trifurcula beirnei is a moth of the Nepticulidae family. It is found in Great Britain Denmark and parts of Germany and Poland Austria the Czech Republic Slovakia and Hungary. It is also found in the Volga and Ural region of Russia.The wingspan is 8–11 mm. Adults are on wing from the end of June to late September.The larvae feed on Genista species including Genista tinctoria Genista germanica and Genista pilosa.
06/16/2022 10:14:57 - INFO - __main__ - ['Animal']
06/16/2022 10:14:57 - INFO - __main__ - Tokenizing Input ...
06/16/2022 10:14:58 - INFO - __main__ - Tokenizing Output ...
06/16/2022 10:14:59 - INFO - __main__ - Loaded 1792 examples from dev data
06/16/2022 10:15:21 - INFO - __main__ - load prompt embedding from ckpt
06/16/2022 10:15:22 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/16/2022 10:15:22 - INFO - __main__ - Starting training!
06/16/2022 10:15:26 - INFO - __main__ - Step 10 Global step 10 Train loss 5.00 on epoch=0
06/16/2022 10:15:29 - INFO - __main__ - Step 20 Global step 20 Train loss 3.23 on epoch=0
06/16/2022 10:15:32 - INFO - __main__ - Step 30 Global step 30 Train loss 2.25 on epoch=0
06/16/2022 10:15:35 - INFO - __main__ - Step 40 Global step 40 Train loss 1.83 on epoch=0
06/16/2022 10:15:38 - INFO - __main__ - Step 50 Global step 50 Train loss 1.50 on epoch=0
06/16/2022 10:16:27 - INFO - __main__ - Global step 50 Train loss 2.76 Classification-F1 0.1253860500963431 on epoch=0
06/16/2022 10:16:27 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.1253860500963431 on epoch=0, global_step=50
06/16/2022 10:16:30 - INFO - __main__ - Step 60 Global step 60 Train loss 1.27 on epoch=0
06/16/2022 10:16:33 - INFO - __main__ - Step 70 Global step 70 Train loss 1.14 on epoch=0
06/16/2022 10:16:36 - INFO - __main__ - Step 80 Global step 80 Train loss 0.93 on epoch=0
06/16/2022 10:16:39 - INFO - __main__ - Step 90 Global step 90 Train loss 0.92 on epoch=0
06/16/2022 10:16:42 - INFO - __main__ - Step 100 Global step 100 Train loss 0.75 on epoch=0
06/16/2022 10:17:38 - INFO - __main__ - Global step 100 Train loss 1.00 Classification-F1 0.23724173132705476 on epoch=0
06/16/2022 10:17:38 - INFO - __main__ - Saving model with best Classification-F1: 0.1253860500963431 -> 0.23724173132705476 on epoch=0, global_step=100
06/16/2022 10:17:41 - INFO - __main__ - Step 110 Global step 110 Train loss 0.72 on epoch=0
06/16/2022 10:17:43 - INFO - __main__ - Step 120 Global step 120 Train loss 0.78 on epoch=1
06/16/2022 10:17:46 - INFO - __main__ - Step 130 Global step 130 Train loss 0.65 on epoch=1
06/16/2022 10:17:49 - INFO - __main__ - Step 140 Global step 140 Train loss 0.69 on epoch=1
06/16/2022 10:17:52 - INFO - __main__ - Step 150 Global step 150 Train loss 0.51 on epoch=1
06/16/2022 10:18:46 - INFO - __main__ - Global step 150 Train loss 0.67 Classification-F1 0.43444942997184366 on epoch=1
06/16/2022 10:18:46 - INFO - __main__ - Saving model with best Classification-F1: 0.23724173132705476 -> 0.43444942997184366 on epoch=1, global_step=150
06/16/2022 10:18:49 - INFO - __main__ - Step 160 Global step 160 Train loss 0.59 on epoch=1
06/16/2022 10:18:52 - INFO - __main__ - Step 170 Global step 170 Train loss 0.47 on epoch=1
06/16/2022 10:18:55 - INFO - __main__ - Step 180 Global step 180 Train loss 0.67 on epoch=1
06/16/2022 10:18:57 - INFO - __main__ - Step 190 Global step 190 Train loss 0.59 on epoch=1
06/16/2022 10:19:00 - INFO - __main__ - Step 200 Global step 200 Train loss 0.58 on epoch=1
06/16/2022 10:19:57 - INFO - __main__ - Global step 200 Train loss 0.58 Classification-F1 0.41495676060330616 on epoch=1
06/16/2022 10:19:59 - INFO - __main__ - Step 210 Global step 210 Train loss 0.44 on epoch=1
06/16/2022 10:20:02 - INFO - __main__ - Step 220 Global step 220 Train loss 0.52 on epoch=1
06/16/2022 10:20:05 - INFO - __main__ - Step 230 Global step 230 Train loss 0.49 on epoch=2
06/16/2022 10:20:07 - INFO - __main__ - Step 240 Global step 240 Train loss 0.40 on epoch=2
06/16/2022 10:20:10 - INFO - __main__ - Step 250 Global step 250 Train loss 0.44 on epoch=2
06/16/2022 10:21:06 - INFO - __main__ - Global step 250 Train loss 0.46 Classification-F1 0.41461082186310166 on epoch=2
06/16/2022 10:21:09 - INFO - __main__ - Step 260 Global step 260 Train loss 0.35 on epoch=2
06/16/2022 10:21:12 - INFO - __main__ - Step 270 Global step 270 Train loss 0.34 on epoch=2
06/16/2022 10:21:14 - INFO - __main__ - Step 280 Global step 280 Train loss 0.39 on epoch=2
06/16/2022 10:21:17 - INFO - __main__ - Step 290 Global step 290 Train loss 0.37 on epoch=2
06/16/2022 10:21:20 - INFO - __main__ - Step 300 Global step 300 Train loss 0.27 on epoch=2
06/16/2022 10:22:15 - INFO - __main__ - Global step 300 Train loss 0.34 Classification-F1 0.32913939135070314 on epoch=2
06/16/2022 10:22:18 - INFO - __main__ - Step 310 Global step 310 Train loss 0.36 on epoch=2
06/16/2022 10:22:21 - INFO - __main__ - Step 320 Global step 320 Train loss 0.32 on epoch=2
06/16/2022 10:22:23 - INFO - __main__ - Step 330 Global step 330 Train loss 0.33 on epoch=2
06/16/2022 10:22:26 - INFO - __main__ - Step 340 Global step 340 Train loss 0.24 on epoch=3
06/16/2022 10:22:29 - INFO - __main__ - Step 350 Global step 350 Train loss 0.23 on epoch=3
06/16/2022 10:23:22 - INFO - __main__ - Global step 350 Train loss 0.30 Classification-F1 0.5744682770956578 on epoch=3
06/16/2022 10:23:22 - INFO - __main__ - Saving model with best Classification-F1: 0.43444942997184366 -> 0.5744682770956578 on epoch=3, global_step=350
06/16/2022 10:23:24 - INFO - __main__ - Step 360 Global step 360 Train loss 0.30 on epoch=3
06/16/2022 10:23:27 - INFO - __main__ - Step 370 Global step 370 Train loss 0.23 on epoch=3
06/16/2022 10:23:30 - INFO - __main__ - Step 380 Global step 380 Train loss 0.22 on epoch=3
06/16/2022 10:23:33 - INFO - __main__ - Step 390 Global step 390 Train loss 0.35 on epoch=3
06/16/2022 10:23:35 - INFO - __main__ - Step 400 Global step 400 Train loss 0.29 on epoch=3
06/16/2022 10:24:28 - INFO - __main__ - Global step 400 Train loss 0.28 Classification-F1 0.621854728239412 on epoch=3
06/16/2022 10:24:28 - INFO - __main__ - Saving model with best Classification-F1: 0.5744682770956578 -> 0.621854728239412 on epoch=3, global_step=400
06/16/2022 10:24:31 - INFO - __main__ - Step 410 Global step 410 Train loss 0.28 on epoch=3
06/16/2022 10:24:34 - INFO - __main__ - Step 420 Global step 420 Train loss 0.24 on epoch=3
06/16/2022 10:24:36 - INFO - __main__ - Step 430 Global step 430 Train loss 0.20 on epoch=3
06/16/2022 10:24:39 - INFO - __main__ - Step 440 Global step 440 Train loss 0.19 on epoch=3
06/16/2022 10:24:42 - INFO - __main__ - Step 450 Global step 450 Train loss 0.17 on epoch=4
06/16/2022 10:25:42 - INFO - __main__ - Global step 450 Train loss 0.22 Classification-F1 0.5569432847084129 on epoch=4
06/16/2022 10:25:44 - INFO - __main__ - Step 460 Global step 460 Train loss 0.15 on epoch=4
06/16/2022 10:25:47 - INFO - __main__ - Step 470 Global step 470 Train loss 0.19 on epoch=4
06/16/2022 10:25:50 - INFO - __main__ - Step 480 Global step 480 Train loss 0.23 on epoch=4
06/16/2022 10:25:52 - INFO - __main__ - Step 490 Global step 490 Train loss 0.14 on epoch=4
06/16/2022 10:25:55 - INFO - __main__ - Step 500 Global step 500 Train loss 0.18 on epoch=4
06/16/2022 10:26:58 - INFO - __main__ - Global step 500 Train loss 0.18 Classification-F1 0.6723659628616631 on epoch=4
06/16/2022 10:26:58 - INFO - __main__ - Saving model with best Classification-F1: 0.621854728239412 -> 0.6723659628616631 on epoch=4, global_step=500
06/16/2022 10:27:01 - INFO - __main__ - Step 510 Global step 510 Train loss 0.24 on epoch=4
06/16/2022 10:27:03 - INFO - __main__ - Step 520 Global step 520 Train loss 0.21 on epoch=4
06/16/2022 10:27:06 - INFO - __main__ - Step 530 Global step 530 Train loss 0.13 on epoch=4
06/16/2022 10:27:09 - INFO - __main__ - Step 540 Global step 540 Train loss 0.21 on epoch=4
06/16/2022 10:27:11 - INFO - __main__ - Step 550 Global step 550 Train loss 0.18 on epoch=4
06/16/2022 10:28:07 - INFO - __main__ - Global step 550 Train loss 0.19 Classification-F1 0.7148292511659262 on epoch=4
06/16/2022 10:28:07 - INFO - __main__ - Saving model with best Classification-F1: 0.6723659628616631 -> 0.7148292511659262 on epoch=4, global_step=550
06/16/2022 10:28:10 - INFO - __main__ - Step 560 Global step 560 Train loss 0.20 on epoch=4
06/16/2022 10:28:13 - INFO - __main__ - Step 570 Global step 570 Train loss 0.13 on epoch=5
06/16/2022 10:28:15 - INFO - __main__ - Step 580 Global step 580 Train loss 0.13 on epoch=5
06/16/2022 10:28:18 - INFO - __main__ - Step 590 Global step 590 Train loss 0.22 on epoch=5
06/16/2022 10:28:21 - INFO - __main__ - Step 600 Global step 600 Train loss 0.16 on epoch=5
06/16/2022 10:29:14 - INFO - __main__ - Global step 600 Train loss 0.17 Classification-F1 0.7120449148937485 on epoch=5
06/16/2022 10:29:17 - INFO - __main__ - Step 610 Global step 610 Train loss 0.20 on epoch=5
06/16/2022 10:29:20 - INFO - __main__ - Step 620 Global step 620 Train loss 0.12 on epoch=5
06/16/2022 10:29:22 - INFO - __main__ - Step 630 Global step 630 Train loss 0.12 on epoch=5
06/16/2022 10:29:25 - INFO - __main__ - Step 640 Global step 640 Train loss 0.09 on epoch=5
06/16/2022 10:29:28 - INFO - __main__ - Step 650 Global step 650 Train loss 0.19 on epoch=5
06/16/2022 10:30:26 - INFO - __main__ - Global step 650 Train loss 0.14 Classification-F1 0.799326005441271 on epoch=5
06/16/2022 10:30:26 - INFO - __main__ - Saving model with best Classification-F1: 0.7148292511659262 -> 0.799326005441271 on epoch=5, global_step=650
06/16/2022 10:30:28 - INFO - __main__ - Step 660 Global step 660 Train loss 0.11 on epoch=5
06/16/2022 10:30:31 - INFO - __main__ - Step 670 Global step 670 Train loss 0.11 on epoch=5
06/16/2022 10:30:34 - INFO - __main__ - Step 680 Global step 680 Train loss 0.08 on epoch=6
06/16/2022 10:30:37 - INFO - __main__ - Step 690 Global step 690 Train loss 0.14 on epoch=6
06/16/2022 10:30:39 - INFO - __main__ - Step 700 Global step 700 Train loss 0.17 on epoch=6
06/16/2022 10:31:34 - INFO - __main__ - Global step 700 Train loss 0.12 Classification-F1 0.7197889422009662 on epoch=6
06/16/2022 10:31:37 - INFO - __main__ - Step 710 Global step 710 Train loss 0.12 on epoch=6
06/16/2022 10:31:39 - INFO - __main__ - Step 720 Global step 720 Train loss 0.09 on epoch=6
06/16/2022 10:31:42 - INFO - __main__ - Step 730 Global step 730 Train loss 0.12 on epoch=6
06/16/2022 10:31:45 - INFO - __main__ - Step 740 Global step 740 Train loss 0.19 on epoch=6
06/16/2022 10:31:47 - INFO - __main__ - Step 750 Global step 750 Train loss 0.07 on epoch=6
06/16/2022 10:32:42 - INFO - __main__ - Global step 750 Train loss 0.12 Classification-F1 0.6177608410839839 on epoch=6
06/16/2022 10:32:45 - INFO - __main__ - Step 760 Global step 760 Train loss 0.12 on epoch=6
06/16/2022 10:32:47 - INFO - __main__ - Step 770 Global step 770 Train loss 0.14 on epoch=6
06/16/2022 10:32:50 - INFO - __main__ - Step 780 Global step 780 Train loss 0.14 on epoch=6
06/16/2022 10:32:53 - INFO - __main__ - Step 790 Global step 790 Train loss 0.12 on epoch=7
06/16/2022 10:32:55 - INFO - __main__ - Step 800 Global step 800 Train loss 0.10 on epoch=7
06/16/2022 10:33:49 - INFO - __main__ - Global step 800 Train loss 0.12 Classification-F1 0.6504173388004922 on epoch=7
06/16/2022 10:33:51 - INFO - __main__ - Step 810 Global step 810 Train loss 0.20 on epoch=7
06/16/2022 10:33:54 - INFO - __main__ - Step 820 Global step 820 Train loss 0.11 on epoch=7
06/16/2022 10:33:57 - INFO - __main__ - Step 830 Global step 830 Train loss 0.07 on epoch=7
06/16/2022 10:34:00 - INFO - __main__ - Step 840 Global step 840 Train loss 0.08 on epoch=7
06/16/2022 10:34:02 - INFO - __main__ - Step 850 Global step 850 Train loss 0.10 on epoch=7
06/16/2022 10:34:56 - INFO - __main__ - Global step 850 Train loss 0.11 Classification-F1 0.766471995888845 on epoch=7
06/16/2022 10:34:58 - INFO - __main__ - Step 860 Global step 860 Train loss 0.07 on epoch=7
06/16/2022 10:35:01 - INFO - __main__ - Step 870 Global step 870 Train loss 0.07 on epoch=7
06/16/2022 10:35:04 - INFO - __main__ - Step 880 Global step 880 Train loss 0.14 on epoch=7
06/16/2022 10:35:07 - INFO - __main__ - Step 890 Global step 890 Train loss 0.09 on epoch=7
06/16/2022 10:35:10 - INFO - __main__ - Step 900 Global step 900 Train loss 0.15 on epoch=8
06/16/2022 10:36:09 - INFO - __main__ - Global step 900 Train loss 0.10 Classification-F1 0.5925727248629965 on epoch=8
06/16/2022 10:36:12 - INFO - __main__ - Step 910 Global step 910 Train loss 0.12 on epoch=8
06/16/2022 10:36:14 - INFO - __main__ - Step 920 Global step 920 Train loss 0.12 on epoch=8
06/16/2022 10:36:17 - INFO - __main__ - Step 930 Global step 930 Train loss 0.13 on epoch=8
06/16/2022 10:36:20 - INFO - __main__ - Step 940 Global step 940 Train loss 0.11 on epoch=8
06/16/2022 10:36:23 - INFO - __main__ - Step 950 Global step 950 Train loss 0.12 on epoch=8
06/16/2022 10:37:18 - INFO - __main__ - Global step 950 Train loss 0.12 Classification-F1 0.6543458995752429 on epoch=8
06/16/2022 10:37:20 - INFO - __main__ - Step 960 Global step 960 Train loss 0.14 on epoch=8
06/16/2022 10:37:23 - INFO - __main__ - Step 970 Global step 970 Train loss 0.16 on epoch=8
06/16/2022 10:37:26 - INFO - __main__ - Step 980 Global step 980 Train loss 0.07 on epoch=8
06/16/2022 10:37:28 - INFO - __main__ - Step 990 Global step 990 Train loss 0.13 on epoch=8
06/16/2022 10:37:31 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.14 on epoch=8
06/16/2022 10:38:29 - INFO - __main__ - Global step 1000 Train loss 0.13 Classification-F1 0.723443430604287 on epoch=8
06/16/2022 10:38:31 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.09 on epoch=9
06/16/2022 10:38:34 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.09 on epoch=9
06/16/2022 10:38:37 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.07 on epoch=9
06/16/2022 10:38:39 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.11 on epoch=9
06/16/2022 10:38:42 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.11 on epoch=9
06/16/2022 10:39:33 - INFO - __main__ - Global step 1050 Train loss 0.09 Classification-F1 0.8102101378287276 on epoch=9
06/16/2022 10:39:33 - INFO - __main__ - Saving model with best Classification-F1: 0.799326005441271 -> 0.8102101378287276 on epoch=9, global_step=1050
06/16/2022 10:39:36 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.10 on epoch=9
06/16/2022 10:39:38 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.12 on epoch=9
06/16/2022 10:39:41 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.16 on epoch=9
06/16/2022 10:39:44 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.10 on epoch=9
06/16/2022 10:39:47 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.10 on epoch=9
06/16/2022 10:40:38 - INFO - __main__ - Global step 1100 Train loss 0.12 Classification-F1 0.6788858674750217 on epoch=9
06/16/2022 10:40:41 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.09 on epoch=9
06/16/2022 10:40:43 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.11 on epoch=9
06/16/2022 10:40:46 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.09 on epoch=10
06/16/2022 10:40:49 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.14 on epoch=10
06/16/2022 10:40:51 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.08 on epoch=10
06/16/2022 10:41:45 - INFO - __main__ - Global step 1150 Train loss 0.10 Classification-F1 0.6035597831387889 on epoch=10
06/16/2022 10:41:48 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.05 on epoch=10
06/16/2022 10:41:50 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.10 on epoch=10
06/16/2022 10:41:53 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.19 on epoch=10
06/16/2022 10:41:56 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.21 on epoch=10
06/16/2022 10:41:59 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.13 on epoch=10
06/16/2022 10:42:54 - INFO - __main__ - Global step 1200 Train loss 0.14 Classification-F1 0.5034062762745922 on epoch=10
06/16/2022 10:42:57 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.16 on epoch=10
06/16/2022 10:42:59 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.15 on epoch=10
06/16/2022 10:43:02 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.13 on epoch=10
06/16/2022 10:43:05 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.15 on epoch=11
06/16/2022 10:43:08 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.08 on epoch=11
06/16/2022 10:44:00 - INFO - __main__ - Global step 1250 Train loss 0.14 Classification-F1 0.6260198130553747 on epoch=11
06/16/2022 10:44:03 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.15 on epoch=11
06/16/2022 10:44:05 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.15 on epoch=11
06/16/2022 10:44:08 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.11 on epoch=11
06/16/2022 10:44:11 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.10 on epoch=11
06/16/2022 10:44:14 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.10 on epoch=11
06/16/2022 10:45:16 - INFO - __main__ - Global step 1300 Train loss 0.12 Classification-F1 0.7267835356081136 on epoch=11
06/16/2022 10:45:19 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.06 on epoch=11
06/16/2022 10:45:22 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.08 on epoch=11
06/16/2022 10:45:24 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.11 on epoch=11
06/16/2022 10:45:27 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.12 on epoch=11
06/16/2022 10:45:30 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.09 on epoch=12
06/16/2022 10:46:20 - INFO - __main__ - Global step 1350 Train loss 0.09 Classification-F1 0.8613477364090303 on epoch=12
06/16/2022 10:46:20 - INFO - __main__ - Saving model with best Classification-F1: 0.8102101378287276 -> 0.8613477364090303 on epoch=12, global_step=1350
06/16/2022 10:46:23 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.10 on epoch=12
06/16/2022 10:46:26 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.15 on epoch=12
06/16/2022 10:46:28 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.09 on epoch=12
06/16/2022 10:46:31 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.05 on epoch=12
06/16/2022 10:46:34 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.05 on epoch=12
06/16/2022 10:47:25 - INFO - __main__ - Global step 1400 Train loss 0.09 Classification-F1 0.7255490580728811 on epoch=12
06/16/2022 10:47:27 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.20 on epoch=12
06/16/2022 10:47:30 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.11 on epoch=12
06/16/2022 10:47:33 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.09 on epoch=12
06/16/2022 10:47:35 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.06 on epoch=12
06/16/2022 10:47:38 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.15 on epoch=12
06/16/2022 10:48:31 - INFO - __main__ - Global step 1450 Train loss 0.12 Classification-F1 0.6539951661001443 on epoch=12
06/16/2022 10:48:33 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.03 on epoch=13
06/16/2022 10:48:36 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.11 on epoch=13
06/16/2022 10:48:39 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.14 on epoch=13
06/16/2022 10:48:41 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.03 on epoch=13
06/16/2022 10:48:44 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.05 on epoch=13
06/16/2022 10:49:33 - INFO - __main__ - Global step 1500 Train loss 0.07 Classification-F1 0.5469879966362292 on epoch=13
06/16/2022 10:49:36 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.05 on epoch=13
06/16/2022 10:49:39 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.08 on epoch=13
06/16/2022 10:49:41 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.06 on epoch=13
06/16/2022 10:49:44 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.05 on epoch=13
06/16/2022 10:49:47 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.09 on epoch=13
06/16/2022 10:50:39 - INFO - __main__ - Global step 1550 Train loss 0.07 Classification-F1 0.5930811569924493 on epoch=13
06/16/2022 10:50:41 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.12 on epoch=13
06/16/2022 10:50:44 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.03 on epoch=14
06/16/2022 10:50:47 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.06 on epoch=14
06/16/2022 10:50:49 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.06 on epoch=14
06/16/2022 10:50:52 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.09 on epoch=14
06/16/2022 10:51:41 - INFO - __main__ - Global step 1600 Train loss 0.07 Classification-F1 0.42300012531193065 on epoch=14
06/16/2022 10:51:43 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=14
06/16/2022 10:51:46 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.06 on epoch=14
06/16/2022 10:51:49 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.07 on epoch=14
06/16/2022 10:51:52 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.08 on epoch=14
06/16/2022 10:51:54 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.04 on epoch=14
06/16/2022 10:52:45 - INFO - __main__ - Global step 1650 Train loss 0.06 Classification-F1 0.5946169725907291 on epoch=14
06/16/2022 10:52:47 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.07 on epoch=14
06/16/2022 10:52:50 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.07 on epoch=14
06/16/2022 10:52:53 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.07 on epoch=14
06/16/2022 10:52:56 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.04 on epoch=15
06/16/2022 10:52:58 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.06 on epoch=15
06/16/2022 10:53:51 - INFO - __main__ - Global step 1700 Train loss 0.06 Classification-F1 0.6183630990688905 on epoch=15
06/16/2022 10:53:53 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.11 on epoch=15
06/16/2022 10:53:56 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.04 on epoch=15
06/16/2022 10:53:59 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.09 on epoch=15
06/16/2022 10:54:02 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.08 on epoch=15
06/16/2022 10:54:04 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.10 on epoch=15
06/16/2022 10:54:58 - INFO - __main__ - Global step 1750 Train loss 0.08 Classification-F1 0.8117828420814229 on epoch=15
06/16/2022 10:55:01 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.05 on epoch=15
06/16/2022 10:55:04 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.07 on epoch=15
06/16/2022 10:55:07 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.08 on epoch=15
06/16/2022 10:55:09 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.05 on epoch=15
06/16/2022 10:55:12 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.05 on epoch=16
06/16/2022 10:56:02 - INFO - __main__ - Global step 1800 Train loss 0.06 Classification-F1 0.6319067526360355 on epoch=16
06/16/2022 10:56:05 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.05 on epoch=16
06/16/2022 10:56:08 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.11 on epoch=16
06/16/2022 10:56:11 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.04 on epoch=16
06/16/2022 10:56:14 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.05 on epoch=16
06/16/2022 10:56:17 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=16
06/16/2022 10:57:12 - INFO - __main__ - Global step 1850 Train loss 0.06 Classification-F1 0.7612123494262155 on epoch=16
06/16/2022 10:57:15 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.07 on epoch=16
06/16/2022 10:57:18 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.11 on epoch=16
06/16/2022 10:57:21 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.08 on epoch=16
06/16/2022 10:57:23 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.08 on epoch=16
06/16/2022 10:57:26 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.07 on epoch=16
06/16/2022 10:58:22 - INFO - __main__ - Global step 1900 Train loss 0.08 Classification-F1 0.5631632651669238 on epoch=16
06/16/2022 10:58:25 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=17
06/16/2022 10:58:27 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.05 on epoch=17
06/16/2022 10:58:30 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.07 on epoch=17
06/16/2022 10:58:33 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=17
06/16/2022 10:58:36 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.06 on epoch=17
06/16/2022 10:59:32 - INFO - __main__ - Global step 1950 Train loss 0.05 Classification-F1 0.4773087489619111 on epoch=17
06/16/2022 10:59:34 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.05 on epoch=17
06/16/2022 10:59:37 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.06 on epoch=17
06/16/2022 10:59:40 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.07 on epoch=17
06/16/2022 10:59:43 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.04 on epoch=17
06/16/2022 10:59:46 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.04 on epoch=17
06/16/2022 11:00:39 - INFO - __main__ - Global step 2000 Train loss 0.05 Classification-F1 0.47322887974906447 on epoch=17
06/16/2022 11:00:41 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.09 on epoch=17
06/16/2022 11:00:44 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=18
06/16/2022 11:00:47 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.05 on epoch=18
06/16/2022 11:00:50 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.08 on epoch=18
06/16/2022 11:00:53 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.02 on epoch=18
06/16/2022 11:01:52 - INFO - __main__ - Global step 2050 Train loss 0.05 Classification-F1 0.5178634835632958 on epoch=18
06/16/2022 11:01:54 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.04 on epoch=18
06/16/2022 11:01:57 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.04 on epoch=18
06/16/2022 11:02:00 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.05 on epoch=18
06/16/2022 11:02:03 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.04 on epoch=18
06/16/2022 11:02:06 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=18
06/16/2022 11:03:02 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.6096916135570104 on epoch=18
06/16/2022 11:03:05 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.04 on epoch=18
06/16/2022 11:03:08 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.05 on epoch=18
06/16/2022 11:03:11 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.07 on epoch=19
06/16/2022 11:03:14 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.04 on epoch=19
06/16/2022 11:03:17 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.07 on epoch=19
06/16/2022 11:04:09 - INFO - __main__ - Global step 2150 Train loss 0.06 Classification-F1 0.5857079928143274 on epoch=19
06/16/2022 11:04:12 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.05 on epoch=19
06/16/2022 11:04:14 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=19
06/16/2022 11:04:17 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.06 on epoch=19
06/16/2022 11:04:20 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=19
06/16/2022 11:04:23 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.03 on epoch=19
06/16/2022 11:05:23 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.6454703396160316 on epoch=19
06/16/2022 11:05:25 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=19
06/16/2022 11:05:28 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.09 on epoch=19
06/16/2022 11:05:31 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.07 on epoch=19
06/16/2022 11:05:33 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.05 on epoch=19
06/16/2022 11:05:36 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.06 on epoch=20
06/16/2022 11:06:29 - INFO - __main__ - Global step 2250 Train loss 0.06 Classification-F1 0.610426191521949 on epoch=20
06/16/2022 11:06:31 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.04 on epoch=20
06/16/2022 11:06:34 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.08 on epoch=20
06/16/2022 11:06:37 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.04 on epoch=20
06/16/2022 11:06:39 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.06 on epoch=20
06/16/2022 11:06:42 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=20
06/16/2022 11:07:37 - INFO - __main__ - Global step 2300 Train loss 0.05 Classification-F1 0.6870209336716536 on epoch=20
06/16/2022 11:07:40 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=20
06/16/2022 11:07:43 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=20
06/16/2022 11:07:45 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.07 on epoch=20
06/16/2022 11:07:48 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.04 on epoch=20
06/16/2022 11:07:51 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=20
06/16/2022 11:08:41 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.6429004811125693 on epoch=20
06/16/2022 11:08:44 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=21
06/16/2022 11:08:47 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.04 on epoch=21
06/16/2022 11:08:50 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.07 on epoch=21
06/16/2022 11:08:52 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=21
06/16/2022 11:08:55 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.11 on epoch=21
06/16/2022 11:09:45 - INFO - __main__ - Global step 2400 Train loss 0.05 Classification-F1 0.5830060275842394 on epoch=21
06/16/2022 11:09:48 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=21
06/16/2022 11:09:51 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.06 on epoch=21
06/16/2022 11:09:54 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=21
06/16/2022 11:09:57 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.06 on epoch=21
06/16/2022 11:10:00 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.06 on epoch=21
06/16/2022 11:10:50 - INFO - __main__ - Global step 2450 Train loss 0.04 Classification-F1 0.589354438330803 on epoch=21
06/16/2022 11:10:53 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=21
06/16/2022 11:10:56 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=22
06/16/2022 11:10:59 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.05 on epoch=22
06/16/2022 11:11:01 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.09 on epoch=22
06/16/2022 11:11:05 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.04 on epoch=22
06/16/2022 11:11:57 - INFO - __main__ - Global step 2500 Train loss 0.04 Classification-F1 0.5360622852926419 on epoch=22
06/16/2022 11:12:00 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=22
06/16/2022 11:12:03 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.04 on epoch=22
06/16/2022 11:12:05 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.06 on epoch=22
06/16/2022 11:12:08 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=22
06/16/2022 11:12:12 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.05 on epoch=22
06/16/2022 11:13:06 - INFO - __main__ - Global step 2550 Train loss 0.04 Classification-F1 0.6551467671507467 on epoch=22
06/16/2022 11:13:08 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.06 on epoch=22
06/16/2022 11:13:12 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.06 on epoch=22
06/16/2022 11:13:15 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.04 on epoch=23
06/16/2022 11:13:18 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.05 on epoch=23
06/16/2022 11:13:21 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.11 on epoch=23
06/16/2022 11:14:11 - INFO - __main__ - Global step 2600 Train loss 0.06 Classification-F1 0.5484036505758786 on epoch=23
06/16/2022 11:14:14 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=23
06/16/2022 11:14:17 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.04 on epoch=23
06/16/2022 11:14:19 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=23
06/16/2022 11:14:22 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=23
06/16/2022 11:14:25 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.04 on epoch=23
06/16/2022 11:15:23 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.8143401144032173 on epoch=23
06/16/2022 11:15:26 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=23
06/16/2022 11:15:29 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.05 on epoch=23
06/16/2022 11:15:31 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.04 on epoch=23
06/16/2022 11:15:34 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=24
06/16/2022 11:15:37 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.07 on epoch=24
06/16/2022 11:16:33 - INFO - __main__ - Global step 2700 Train loss 0.04 Classification-F1 0.8652528443460021 on epoch=24
06/16/2022 11:16:33 - INFO - __main__ - Saving model with best Classification-F1: 0.8613477364090303 -> 0.8652528443460021 on epoch=24, global_step=2700
06/16/2022 11:16:36 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.06 on epoch=24
06/16/2022 11:16:39 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.07 on epoch=24
06/16/2022 11:16:42 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.05 on epoch=24
06/16/2022 11:16:45 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=24
06/16/2022 11:16:48 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.03 on epoch=24
06/16/2022 11:17:45 - INFO - __main__ - Global step 2750 Train loss 0.04 Classification-F1 0.6541858040044978 on epoch=24
06/16/2022 11:17:48 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.05 on epoch=24
06/16/2022 11:17:51 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=24
06/16/2022 11:17:53 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.04 on epoch=24
06/16/2022 11:17:56 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.07 on epoch=24
06/16/2022 11:17:59 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.06 on epoch=24
06/16/2022 11:18:48 - INFO - __main__ - Global step 2800 Train loss 0.05 Classification-F1 0.8092376676257474 on epoch=24
06/16/2022 11:18:51 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.03 on epoch=25
06/16/2022 11:18:54 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.07 on epoch=25
06/16/2022 11:18:57 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.08 on epoch=25
06/16/2022 11:18:59 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.03 on epoch=25
06/16/2022 11:19:02 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.03 on epoch=25
06/16/2022 11:19:53 - INFO - __main__ - Global step 2850 Train loss 0.05 Classification-F1 0.687824431169219 on epoch=25
06/16/2022 11:19:55 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=25
06/16/2022 11:19:58 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.09 on epoch=25
06/16/2022 11:20:01 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=25
06/16/2022 11:20:04 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.04 on epoch=25
06/16/2022 11:20:06 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.06 on epoch=25
06/16/2022 11:20:57 - INFO - __main__ - Global step 2900 Train loss 0.05 Classification-F1 0.5894248996701092 on epoch=25
06/16/2022 11:21:00 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=25
06/16/2022 11:21:02 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=26
06/16/2022 11:21:05 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.03 on epoch=26
06/16/2022 11:21:08 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.06 on epoch=26
06/16/2022 11:21:10 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=26
06/16/2022 11:21:58 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.6125673021624638 on epoch=26
06/16/2022 11:22:01 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=26
06/16/2022 11:22:03 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.05 on epoch=26
06/16/2022 11:22:06 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.07 on epoch=26
06/16/2022 11:22:09 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=26
06/16/2022 11:22:12 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.05 on epoch=26
06/16/2022 11:22:13 - INFO - __main__ - Start tokenizing ... 1792 instances
06/16/2022 11:22:13 - INFO - __main__ - Printing 3 examples
06/16/2022 11:22:13 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/16/2022 11:22:13 - INFO - __main__ - ['Animal']
06/16/2022 11:22:13 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/16/2022 11:22:13 - INFO - __main__ - ['Animal']
06/16/2022 11:22:13 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/16/2022 11:22:13 - INFO - __main__ - ['Animal']
06/16/2022 11:22:13 - INFO - __main__ - Tokenizing Input ...
06/16/2022 11:22:15 - INFO - __main__ - Tokenizing Output ...
06/16/2022 11:22:17 - INFO - __main__ - Loaded 1792 examples from train data
06/16/2022 11:22:17 - INFO - __main__ - Start tokenizing ... 1792 instances
06/16/2022 11:22:17 - INFO - __main__ - Printing 3 examples
06/16/2022 11:22:17 - INFO - __main__ -  [dbpedia_14] Palaephatus fusciterminus is a moth of the Palaephatidae family. It is found in the Valdivian forests of southern Argentina and Chile.The length of the forewings is 10-12 mm for males and 10.5-11.5 mm for females. Adults have a buff to brown head and thorax and dark brownish fuscous forewings with a pale buff hindmargin. They are on wing from October to March possibly in multiple generations per year.
06/16/2022 11:22:17 - INFO - __main__ - ['Animal']
06/16/2022 11:22:17 - INFO - __main__ -  [dbpedia_14] Labus is an indomalayan genus of potter wasps.
06/16/2022 11:22:17 - INFO - __main__ - ['Animal']
06/16/2022 11:22:17 - INFO - __main__ -  [dbpedia_14] Trifurcula beirnei is a moth of the Nepticulidae family. It is found in Great Britain Denmark and parts of Germany and Poland Austria the Czech Republic Slovakia and Hungary. It is also found in the Volga and Ural region of Russia.The wingspan is 8–11 mm. Adults are on wing from the end of June to late September.The larvae feed on Genista species including Genista tinctoria Genista germanica and Genista pilosa.
06/16/2022 11:22:17 - INFO - __main__ - ['Animal']
06/16/2022 11:22:17 - INFO - __main__ - Tokenizing Input ...
06/16/2022 11:22:19 - INFO - __main__ - Tokenizing Output ...
06/16/2022 11:22:21 - INFO - __main__ - Loaded 1792 examples from dev data
06/16/2022 11:22:38 - INFO - __main__ - load prompt embedding from ckpt
06/16/2022 11:22:39 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/16/2022 11:22:39 - INFO - __main__ - Starting training!
06/16/2022 11:23:10 - INFO - __main__ - Global step 3000 Train loss 0.04 Classification-F1 0.7591422875454713 on epoch=26
06/16/2022 11:23:10 - INFO - __main__ - save last model!
06/16/2022 11:23:10 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/16/2022 11:23:10 - INFO - __main__ - Start tokenizing ... 3500 instances
06/16/2022 11:23:10 - INFO - __main__ - Printing 3 examples
06/16/2022 11:23:10 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/16/2022 11:23:10 - INFO - __main__ - ['Animal']
06/16/2022 11:23:10 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/16/2022 11:23:10 - INFO - __main__ - ['Animal']
06/16/2022 11:23:10 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/16/2022 11:23:10 - INFO - __main__ - ['Village']
06/16/2022 11:23:10 - INFO - __main__ - Tokenizing Input ...
06/16/2022 11:23:12 - INFO - __main__ - Tokenizing Output ...
06/16/2022 11:23:16 - INFO - __main__ - Loaded 3500 examples from test data
06/16/2022 11:25:31 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down128shot/singletask-dbpedia_14/dbpedia_14_128_100_0.3_8_predictions.txt
06/16/2022 11:25:31 - INFO - __main__ - Classification-F1 on test data: 0.5916
06/16/2022 11:25:32 - INFO - __main__ - prefix=dbpedia_14_128_100, lr=0.3, bsz=8, dev_performance=0.8652528443460021, test_performance=0.5915861658180885
06/16/2022 11:25:32 - INFO - __main__ - Running ... prefix=dbpedia_14_128_100, lr=0.2, bsz=8 ...
06/16/2022 11:25:33 - INFO - __main__ - Start tokenizing ... 1792 instances
06/16/2022 11:25:33 - INFO - __main__ - Printing 3 examples
06/16/2022 11:25:33 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/16/2022 11:25:33 - INFO - __main__ - ['Animal']
06/16/2022 11:25:33 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/16/2022 11:25:33 - INFO - __main__ - ['Animal']
06/16/2022 11:25:33 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/16/2022 11:25:33 - INFO - __main__ - ['Animal']
06/16/2022 11:25:33 - INFO - __main__ - Tokenizing Input ...
06/16/2022 11:25:34 - INFO - __main__ - Tokenizing Output ...
06/16/2022 11:25:35 - INFO - __main__ - Loaded 1792 examples from train data
06/16/2022 11:25:35 - INFO - __main__ - Start tokenizing ... 1792 instances
06/16/2022 11:25:35 - INFO - __main__ - Printing 3 examples
06/16/2022 11:25:35 - INFO - __main__ -  [dbpedia_14] Palaephatus fusciterminus is a moth of the Palaephatidae family. It is found in the Valdivian forests of southern Argentina and Chile.The length of the forewings is 10-12 mm for males and 10.5-11.5 mm for females. Adults have a buff to brown head and thorax and dark brownish fuscous forewings with a pale buff hindmargin. They are on wing from October to March possibly in multiple generations per year.
06/16/2022 11:25:35 - INFO - __main__ - ['Animal']
06/16/2022 11:25:35 - INFO - __main__ -  [dbpedia_14] Labus is an indomalayan genus of potter wasps.
06/16/2022 11:25:35 - INFO - __main__ - ['Animal']
06/16/2022 11:25:35 - INFO - __main__ -  [dbpedia_14] Trifurcula beirnei is a moth of the Nepticulidae family. It is found in Great Britain Denmark and parts of Germany and Poland Austria the Czech Republic Slovakia and Hungary. It is also found in the Volga and Ural region of Russia.The wingspan is 8–11 mm. Adults are on wing from the end of June to late September.The larvae feed on Genista species including Genista tinctoria Genista germanica and Genista pilosa.
06/16/2022 11:25:35 - INFO - __main__ - ['Animal']
06/16/2022 11:25:35 - INFO - __main__ - Tokenizing Input ...
06/16/2022 11:25:36 - INFO - __main__ - Tokenizing Output ...
06/16/2022 11:25:38 - INFO - __main__ - Loaded 1792 examples from dev data
06/16/2022 11:25:55 - INFO - __main__ - load prompt embedding from ckpt
06/16/2022 11:25:55 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/16/2022 11:25:55 - INFO - __main__ - Starting training!
06/16/2022 11:25:59 - INFO - __main__ - Step 10 Global step 10 Train loss 5.25 on epoch=0
06/16/2022 11:26:02 - INFO - __main__ - Step 20 Global step 20 Train loss 3.98 on epoch=0
06/16/2022 11:26:04 - INFO - __main__ - Step 30 Global step 30 Train loss 3.02 on epoch=0
06/16/2022 11:26:07 - INFO - __main__ - Step 40 Global step 40 Train loss 2.51 on epoch=0
06/16/2022 11:26:10 - INFO - __main__ - Step 50 Global step 50 Train loss 1.99 on epoch=0
06/16/2022 11:26:54 - INFO - __main__ - Global step 50 Train loss 3.35 Classification-F1 0.038989037140804636 on epoch=0
06/16/2022 11:26:54 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.038989037140804636 on epoch=0, global_step=50
06/16/2022 11:26:57 - INFO - __main__ - Step 60 Global step 60 Train loss 1.74 on epoch=0
06/16/2022 11:27:00 - INFO - __main__ - Step 70 Global step 70 Train loss 1.58 on epoch=0
06/16/2022 11:27:02 - INFO - __main__ - Step 80 Global step 80 Train loss 1.48 on epoch=0
06/16/2022 11:27:05 - INFO - __main__ - Step 90 Global step 90 Train loss 1.25 on epoch=0
06/16/2022 11:27:08 - INFO - __main__ - Step 100 Global step 100 Train loss 1.08 on epoch=0
06/16/2022 11:27:55 - INFO - __main__ - Global step 100 Train loss 1.43 Classification-F1 0.1552260675436601 on epoch=0
06/16/2022 11:27:55 - INFO - __main__ - Saving model with best Classification-F1: 0.038989037140804636 -> 0.1552260675436601 on epoch=0, global_step=100
06/16/2022 11:27:58 - INFO - __main__ - Step 110 Global step 110 Train loss 1.07 on epoch=0
06/16/2022 11:28:01 - INFO - __main__ - Step 120 Global step 120 Train loss 0.93 on epoch=1
06/16/2022 11:28:04 - INFO - __main__ - Step 130 Global step 130 Train loss 0.85 on epoch=1
06/16/2022 11:28:06 - INFO - __main__ - Step 140 Global step 140 Train loss 0.84 on epoch=1
06/16/2022 11:28:09 - INFO - __main__ - Step 150 Global step 150 Train loss 0.74 on epoch=1
06/16/2022 11:29:05 - INFO - __main__ - Global step 150 Train loss 0.89 Classification-F1 0.25688612170439995 on epoch=1
06/16/2022 11:29:05 - INFO - __main__ - Saving model with best Classification-F1: 0.1552260675436601 -> 0.25688612170439995 on epoch=1, global_step=150
06/16/2022 11:29:08 - INFO - __main__ - Step 160 Global step 160 Train loss 0.74 on epoch=1
06/16/2022 11:29:11 - INFO - __main__ - Step 170 Global step 170 Train loss 0.75 on epoch=1
06/16/2022 11:29:14 - INFO - __main__ - Step 180 Global step 180 Train loss 0.72 on epoch=1
06/16/2022 11:29:17 - INFO - __main__ - Step 190 Global step 190 Train loss 0.67 on epoch=1
06/16/2022 11:29:19 - INFO - __main__ - Step 200 Global step 200 Train loss 0.68 on epoch=1
06/16/2022 11:30:15 - INFO - __main__ - Global step 200 Train loss 0.71 Classification-F1 0.3461283339049992 on epoch=1
06/16/2022 11:30:15 - INFO - __main__ - Saving model with best Classification-F1: 0.25688612170439995 -> 0.3461283339049992 on epoch=1, global_step=200
06/16/2022 11:30:18 - INFO - __main__ - Step 210 Global step 210 Train loss 0.51 on epoch=1
06/16/2022 11:30:21 - INFO - __main__ - Step 220 Global step 220 Train loss 0.56 on epoch=1
06/16/2022 11:30:24 - INFO - __main__ - Step 230 Global step 230 Train loss 0.51 on epoch=2
06/16/2022 11:30:26 - INFO - __main__ - Step 240 Global step 240 Train loss 0.58 on epoch=2
06/16/2022 11:30:29 - INFO - __main__ - Step 250 Global step 250 Train loss 0.53 on epoch=2
06/16/2022 11:31:24 - INFO - __main__ - Global step 250 Train loss 0.54 Classification-F1 0.434500373321731 on epoch=2
06/16/2022 11:31:24 - INFO - __main__ - Saving model with best Classification-F1: 0.3461283339049992 -> 0.434500373321731 on epoch=2, global_step=250
06/16/2022 11:31:27 - INFO - __main__ - Step 260 Global step 260 Train loss 0.40 on epoch=2
06/16/2022 11:31:30 - INFO - __main__ - Step 270 Global step 270 Train loss 0.48 on epoch=2
06/16/2022 11:31:33 - INFO - __main__ - Step 280 Global step 280 Train loss 0.44 on epoch=2
06/16/2022 11:31:36 - INFO - __main__ - Step 290 Global step 290 Train loss 0.49 on epoch=2
06/16/2022 11:31:39 - INFO - __main__ - Step 300 Global step 300 Train loss 0.48 on epoch=2
06/16/2022 11:32:35 - INFO - __main__ - Global step 300 Train loss 0.46 Classification-F1 0.4397338352055824 on epoch=2
06/16/2022 11:32:35 - INFO - __main__ - Saving model with best Classification-F1: 0.434500373321731 -> 0.4397338352055824 on epoch=2, global_step=300
06/16/2022 11:32:38 - INFO - __main__ - Step 310 Global step 310 Train loss 0.40 on epoch=2
06/16/2022 11:32:41 - INFO - __main__ - Step 320 Global step 320 Train loss 0.44 on epoch=2
06/16/2022 11:32:43 - INFO - __main__ - Step 330 Global step 330 Train loss 0.43 on epoch=2
06/16/2022 11:32:46 - INFO - __main__ - Step 340 Global step 340 Train loss 0.36 on epoch=3
06/16/2022 11:32:49 - INFO - __main__ - Step 350 Global step 350 Train loss 0.39 on epoch=3
06/16/2022 11:33:49 - INFO - __main__ - Global step 350 Train loss 0.41 Classification-F1 0.424659241924792 on epoch=3
06/16/2022 11:33:51 - INFO - __main__ - Step 360 Global step 360 Train loss 0.33 on epoch=3
06/16/2022 11:33:54 - INFO - __main__ - Step 370 Global step 370 Train loss 0.40 on epoch=3
06/16/2022 11:33:57 - INFO - __main__ - Step 380 Global step 380 Train loss 0.29 on epoch=3
06/16/2022 11:34:00 - INFO - __main__ - Step 390 Global step 390 Train loss 0.32 on epoch=3
06/16/2022 11:34:03 - INFO - __main__ - Step 400 Global step 400 Train loss 0.45 on epoch=3
06/16/2022 11:35:00 - INFO - __main__ - Global step 400 Train loss 0.36 Classification-F1 0.5571679036832498 on epoch=3
06/16/2022 11:35:00 - INFO - __main__ - Saving model with best Classification-F1: 0.4397338352055824 -> 0.5571679036832498 on epoch=3, global_step=400
06/16/2022 11:35:03 - INFO - __main__ - Step 410 Global step 410 Train loss 0.34 on epoch=3
06/16/2022 11:35:06 - INFO - __main__ - Step 420 Global step 420 Train loss 0.28 on epoch=3
06/16/2022 11:35:08 - INFO - __main__ - Step 430 Global step 430 Train loss 0.41 on epoch=3
06/16/2022 11:35:11 - INFO - __main__ - Step 440 Global step 440 Train loss 0.31 on epoch=3
06/16/2022 11:35:14 - INFO - __main__ - Step 450 Global step 450 Train loss 0.31 on epoch=4
06/16/2022 11:36:19 - INFO - __main__ - Global step 450 Train loss 0.33 Classification-F1 0.4270204874350186 on epoch=4
06/16/2022 11:36:22 - INFO - __main__ - Step 460 Global step 460 Train loss 0.25 on epoch=4
06/16/2022 11:36:25 - INFO - __main__ - Step 470 Global step 470 Train loss 0.33 on epoch=4
06/16/2022 11:36:27 - INFO - __main__ - Step 480 Global step 480 Train loss 0.30 on epoch=4
06/16/2022 11:36:30 - INFO - __main__ - Step 490 Global step 490 Train loss 0.28 on epoch=4
06/16/2022 11:36:33 - INFO - __main__ - Step 500 Global step 500 Train loss 0.20 on epoch=4
06/16/2022 11:37:34 - INFO - __main__ - Global step 500 Train loss 0.27 Classification-F1 0.5865837536070997 on epoch=4
06/16/2022 11:37:35 - INFO - __main__ - Saving model with best Classification-F1: 0.5571679036832498 -> 0.5865837536070997 on epoch=4, global_step=500
06/16/2022 11:37:37 - INFO - __main__ - Step 510 Global step 510 Train loss 0.25 on epoch=4
06/16/2022 11:37:40 - INFO - __main__ - Step 520 Global step 520 Train loss 0.30 on epoch=4
06/16/2022 11:37:43 - INFO - __main__ - Step 530 Global step 530 Train loss 0.21 on epoch=4
06/16/2022 11:37:46 - INFO - __main__ - Step 540 Global step 540 Train loss 0.27 on epoch=4
06/16/2022 11:37:49 - INFO - __main__ - Step 550 Global step 550 Train loss 0.32 on epoch=4
06/16/2022 11:38:46 - INFO - __main__ - Global step 550 Train loss 0.27 Classification-F1 0.4617091941553109 on epoch=4
06/16/2022 11:38:49 - INFO - __main__ - Step 560 Global step 560 Train loss 0.24 on epoch=4
06/16/2022 11:38:52 - INFO - __main__ - Step 570 Global step 570 Train loss 0.29 on epoch=5
06/16/2022 11:38:55 - INFO - __main__ - Step 580 Global step 580 Train loss 0.27 on epoch=5
06/16/2022 11:38:58 - INFO - __main__ - Step 590 Global step 590 Train loss 0.22 on epoch=5
06/16/2022 11:39:01 - INFO - __main__ - Step 600 Global step 600 Train loss 0.26 on epoch=5
06/16/2022 11:40:05 - INFO - __main__ - Global step 600 Train loss 0.25 Classification-F1 0.47757325475254575 on epoch=5
06/16/2022 11:40:08 - INFO - __main__ - Step 610 Global step 610 Train loss 0.23 on epoch=5
06/16/2022 11:40:11 - INFO - __main__ - Step 620 Global step 620 Train loss 0.23 on epoch=5
06/16/2022 11:40:14 - INFO - __main__ - Step 630 Global step 630 Train loss 0.26 on epoch=5
06/16/2022 11:40:17 - INFO - __main__ - Step 640 Global step 640 Train loss 0.18 on epoch=5
06/16/2022 11:40:20 - INFO - __main__ - Step 650 Global step 650 Train loss 0.20 on epoch=5
06/16/2022 11:41:23 - INFO - __main__ - Global step 650 Train loss 0.22 Classification-F1 0.598604725767304 on epoch=5
06/16/2022 11:41:23 - INFO - __main__ - Saving model with best Classification-F1: 0.5865837536070997 -> 0.598604725767304 on epoch=5, global_step=650
06/16/2022 11:41:26 - INFO - __main__ - Step 660 Global step 660 Train loss 0.29 on epoch=5
06/16/2022 11:41:29 - INFO - __main__ - Step 670 Global step 670 Train loss 0.20 on epoch=5
06/16/2022 11:41:32 - INFO - __main__ - Step 680 Global step 680 Train loss 0.19 on epoch=6
06/16/2022 11:41:34 - INFO - __main__ - Step 690 Global step 690 Train loss 0.22 on epoch=6
06/16/2022 11:41:37 - INFO - __main__ - Step 700 Global step 700 Train loss 0.24 on epoch=6
06/16/2022 11:42:34 - INFO - __main__ - Global step 700 Train loss 0.23 Classification-F1 0.528576509133417 on epoch=6
06/16/2022 11:42:36 - INFO - __main__ - Step 710 Global step 710 Train loss 0.24 on epoch=6
06/16/2022 11:42:39 - INFO - __main__ - Step 720 Global step 720 Train loss 0.27 on epoch=6
06/16/2022 11:42:42 - INFO - __main__ - Step 730 Global step 730 Train loss 0.19 on epoch=6
06/16/2022 11:42:45 - INFO - __main__ - Step 740 Global step 740 Train loss 0.28 on epoch=6
06/16/2022 11:42:48 - INFO - __main__ - Step 750 Global step 750 Train loss 0.14 on epoch=6
06/16/2022 11:43:49 - INFO - __main__ - Global step 750 Train loss 0.22 Classification-F1 0.57590119934184 on epoch=6
06/16/2022 11:43:52 - INFO - __main__ - Step 760 Global step 760 Train loss 0.15 on epoch=6
06/16/2022 11:43:54 - INFO - __main__ - Step 770 Global step 770 Train loss 0.24 on epoch=6
06/16/2022 11:43:57 - INFO - __main__ - Step 780 Global step 780 Train loss 0.19 on epoch=6
06/16/2022 11:44:00 - INFO - __main__ - Step 790 Global step 790 Train loss 0.15 on epoch=7
06/16/2022 11:44:03 - INFO - __main__ - Step 800 Global step 800 Train loss 0.19 on epoch=7
06/16/2022 11:45:12 - INFO - __main__ - Global step 800 Train loss 0.18 Classification-F1 0.5270972571488914 on epoch=7
06/16/2022 11:45:14 - INFO - __main__ - Step 810 Global step 810 Train loss 0.28 on epoch=7
06/16/2022 11:45:17 - INFO - __main__ - Step 820 Global step 820 Train loss 0.14 on epoch=7
06/16/2022 11:45:20 - INFO - __main__ - Step 830 Global step 830 Train loss 0.21 on epoch=7
06/16/2022 11:45:23 - INFO - __main__ - Step 840 Global step 840 Train loss 0.25 on epoch=7
06/16/2022 11:45:26 - INFO - __main__ - Step 850 Global step 850 Train loss 0.15 on epoch=7
06/16/2022 11:46:29 - INFO - __main__ - Global step 850 Train loss 0.20 Classification-F1 0.5242922536178257 on epoch=7
06/16/2022 11:46:32 - INFO - __main__ - Step 860 Global step 860 Train loss 0.17 on epoch=7
06/16/2022 11:46:35 - INFO - __main__ - Step 870 Global step 870 Train loss 0.18 on epoch=7
06/16/2022 11:46:38 - INFO - __main__ - Step 880 Global step 880 Train loss 0.20 on epoch=7
06/16/2022 11:46:41 - INFO - __main__ - Step 890 Global step 890 Train loss 0.20 on epoch=7
06/16/2022 11:46:44 - INFO - __main__ - Step 900 Global step 900 Train loss 0.15 on epoch=8
06/16/2022 11:47:51 - INFO - __main__ - Global step 900 Train loss 0.18 Classification-F1 0.49592400839725054 on epoch=8
06/16/2022 11:47:53 - INFO - __main__ - Step 910 Global step 910 Train loss 0.14 on epoch=8
06/16/2022 11:47:56 - INFO - __main__ - Step 920 Global step 920 Train loss 0.22 on epoch=8
06/16/2022 11:47:59 - INFO - __main__ - Step 930 Global step 930 Train loss 0.20 on epoch=8
06/16/2022 11:48:02 - INFO - __main__ - Step 940 Global step 940 Train loss 0.09 on epoch=8
06/16/2022 11:48:05 - INFO - __main__ - Step 950 Global step 950 Train loss 0.11 on epoch=8
06/16/2022 11:49:15 - INFO - __main__ - Global step 950 Train loss 0.15 Classification-F1 0.6455305423138356 on epoch=8
06/16/2022 11:49:15 - INFO - __main__ - Saving model with best Classification-F1: 0.598604725767304 -> 0.6455305423138356 on epoch=8, global_step=950
06/16/2022 11:49:18 - INFO - __main__ - Step 960 Global step 960 Train loss 0.16 on epoch=8
06/16/2022 11:49:21 - INFO - __main__ - Step 970 Global step 970 Train loss 0.21 on epoch=8
06/16/2022 11:49:24 - INFO - __main__ - Step 980 Global step 980 Train loss 0.14 on epoch=8
06/16/2022 11:49:27 - INFO - __main__ - Step 990 Global step 990 Train loss 0.17 on epoch=8
06/16/2022 11:49:30 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.15 on epoch=8
06/16/2022 11:50:37 - INFO - __main__ - Global step 1000 Train loss 0.17 Classification-F1 0.5280862031920018 on epoch=8
06/16/2022 11:50:40 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.14 on epoch=9
06/16/2022 11:50:43 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.15 on epoch=9
06/16/2022 11:50:45 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.13 on epoch=9
06/16/2022 11:50:48 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.20 on epoch=9
06/16/2022 11:50:51 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.08 on epoch=9
06/16/2022 11:51:54 - INFO - __main__ - Global step 1050 Train loss 0.14 Classification-F1 0.5052314116692124 on epoch=9
06/16/2022 11:51:57 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.15 on epoch=9
06/16/2022 11:52:00 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.21 on epoch=9
06/16/2022 11:52:03 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.17 on epoch=9
06/16/2022 11:52:06 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.08 on epoch=9
06/16/2022 11:52:08 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.18 on epoch=9
06/16/2022 11:53:07 - INFO - __main__ - Global step 1100 Train loss 0.16 Classification-F1 0.48612893474503655 on epoch=9
06/16/2022 11:53:10 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.18 on epoch=9
06/16/2022 11:53:12 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.08 on epoch=9
06/16/2022 11:53:15 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.10 on epoch=10
06/16/2022 11:53:18 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.15 on epoch=10
06/16/2022 11:53:21 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.16 on epoch=10
06/16/2022 11:54:20 - INFO - __main__ - Global step 1150 Train loss 0.14 Classification-F1 0.4845020809785722 on epoch=10
06/16/2022 11:54:23 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.08 on epoch=10
06/16/2022 11:54:26 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.10 on epoch=10
06/16/2022 11:54:29 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.14 on epoch=10
06/16/2022 11:54:32 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.24 on epoch=10
06/16/2022 11:54:35 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.07 on epoch=10
06/16/2022 11:55:39 - INFO - __main__ - Global step 1200 Train loss 0.13 Classification-F1 0.6067970308050338 on epoch=10
06/16/2022 11:55:41 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.12 on epoch=10
06/16/2022 11:55:44 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.16 on epoch=10
06/16/2022 11:55:47 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.20 on epoch=10
06/16/2022 11:55:50 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.10 on epoch=11
06/16/2022 11:55:53 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.08 on epoch=11
06/16/2022 11:56:51 - INFO - __main__ - Global step 1250 Train loss 0.13 Classification-F1 0.6118525679114419 on epoch=11
06/16/2022 11:56:54 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.19 on epoch=11
06/16/2022 11:56:57 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.08 on epoch=11
06/16/2022 11:57:00 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.11 on epoch=11
06/16/2022 11:57:03 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.15 on epoch=11
06/16/2022 11:57:05 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.15 on epoch=11
06/16/2022 11:58:02 - INFO - __main__ - Global step 1300 Train loss 0.14 Classification-F1 0.5692701764078394 on epoch=11
06/16/2022 11:58:04 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.09 on epoch=11
06/16/2022 11:58:07 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.10 on epoch=11
06/16/2022 11:58:10 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.14 on epoch=11
06/16/2022 11:58:13 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.15 on epoch=11
06/16/2022 11:58:16 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.12 on epoch=12
06/16/2022 11:59:17 - INFO - __main__ - Global step 1350 Train loss 0.12 Classification-F1 0.5958565221609642 on epoch=12
06/16/2022 11:59:20 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.14 on epoch=12
06/16/2022 11:59:22 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.12 on epoch=12
06/16/2022 11:59:25 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.09 on epoch=12
06/16/2022 11:59:28 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.09 on epoch=12
06/16/2022 11:59:31 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.12 on epoch=12
06/16/2022 12:00:32 - INFO - __main__ - Global step 1400 Train loss 0.11 Classification-F1 0.6989191615323328 on epoch=12
06/16/2022 12:00:33 - INFO - __main__ - Saving model with best Classification-F1: 0.6455305423138356 -> 0.6989191615323328 on epoch=12, global_step=1400
06/16/2022 12:00:35 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.10 on epoch=12
06/16/2022 12:00:38 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.09 on epoch=12
06/16/2022 12:00:41 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.07 on epoch=12
06/16/2022 12:00:44 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.15 on epoch=12
06/16/2022 12:00:47 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.11 on epoch=12
06/16/2022 12:01:46 - INFO - __main__ - Global step 1450 Train loss 0.10 Classification-F1 0.6515224931557884 on epoch=12
06/16/2022 12:01:48 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.05 on epoch=13
06/16/2022 12:01:51 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.10 on epoch=13
06/16/2022 12:01:54 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.17 on epoch=13
06/16/2022 12:01:56 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.11 on epoch=13
06/16/2022 12:01:59 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.04 on epoch=13
06/16/2022 12:02:55 - INFO - __main__ - Global step 1500 Train loss 0.09 Classification-F1 0.6517775174995177 on epoch=13
06/16/2022 12:02:57 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.11 on epoch=13
06/16/2022 12:03:00 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.10 on epoch=13
06/16/2022 12:03:03 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.11 on epoch=13
06/16/2022 12:03:06 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.05 on epoch=13
06/16/2022 12:03:09 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.08 on epoch=13
06/16/2022 12:04:04 - INFO - __main__ - Global step 1550 Train loss 0.09 Classification-F1 0.7236670371305858 on epoch=13
06/16/2022 12:04:04 - INFO - __main__ - Saving model with best Classification-F1: 0.6989191615323328 -> 0.7236670371305858 on epoch=13, global_step=1550
06/16/2022 12:04:07 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.15 on epoch=13
06/16/2022 12:04:09 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.05 on epoch=14
06/16/2022 12:04:12 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.05 on epoch=14
06/16/2022 12:04:15 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.07 on epoch=14
06/16/2022 12:04:17 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.30 on epoch=14
06/16/2022 12:05:06 - INFO - __main__ - Global step 1600 Train loss 0.13 Classification-F1 0.6881595227607369 on epoch=14
06/16/2022 12:05:09 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.07 on epoch=14
06/16/2022 12:05:11 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.13 on epoch=14
06/16/2022 12:05:14 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.11 on epoch=14
06/16/2022 12:05:17 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.09 on epoch=14
06/16/2022 12:05:19 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.04 on epoch=14
06/16/2022 12:06:11 - INFO - __main__ - Global step 1650 Train loss 0.09 Classification-F1 0.5977108027059128 on epoch=14
06/16/2022 12:06:14 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.10 on epoch=14
06/16/2022 12:06:16 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.10 on epoch=14
06/16/2022 12:06:19 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.08 on epoch=14
06/16/2022 12:06:22 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.06 on epoch=15
06/16/2022 12:06:25 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.10 on epoch=15
06/16/2022 12:07:12 - INFO - __main__ - Global step 1700 Train loss 0.09 Classification-F1 0.6287486020085801 on epoch=15
06/16/2022 12:07:14 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.08 on epoch=15
06/16/2022 12:07:17 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.06 on epoch=15
06/16/2022 12:07:20 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.13 on epoch=15
06/16/2022 12:07:22 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.07 on epoch=15
06/16/2022 12:07:25 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.09 on epoch=15
06/16/2022 12:08:14 - INFO - __main__ - Global step 1750 Train loss 0.08 Classification-F1 0.7213787581045379 on epoch=15
06/16/2022 12:08:17 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.05 on epoch=15
06/16/2022 12:08:20 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.11 on epoch=15
06/16/2022 12:08:22 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.12 on epoch=15
06/16/2022 12:08:25 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.06 on epoch=15
06/16/2022 12:08:28 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.08 on epoch=16
06/16/2022 12:09:15 - INFO - __main__ - Global step 1800 Train loss 0.08 Classification-F1 0.7637395771470172 on epoch=16
06/16/2022 12:09:15 - INFO - __main__ - Saving model with best Classification-F1: 0.7236670371305858 -> 0.7637395771470172 on epoch=16, global_step=1800
06/16/2022 12:09:17 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.06 on epoch=16
06/16/2022 12:09:20 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.14 on epoch=16
06/16/2022 12:09:23 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=16
06/16/2022 12:09:26 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.04 on epoch=16
06/16/2022 12:09:28 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.12 on epoch=16
06/16/2022 12:10:18 - INFO - __main__ - Global step 1850 Train loss 0.08 Classification-F1 0.8128956472300027 on epoch=16
06/16/2022 12:10:18 - INFO - __main__ - Saving model with best Classification-F1: 0.7637395771470172 -> 0.8128956472300027 on epoch=16, global_step=1850
06/16/2022 12:10:21 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.04 on epoch=16
06/16/2022 12:10:24 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.04 on epoch=16
06/16/2022 12:10:26 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.15 on epoch=16
06/16/2022 12:10:29 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.05 on epoch=16
06/16/2022 12:10:32 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.09 on epoch=16
06/16/2022 12:11:18 - INFO - __main__ - Global step 1900 Train loss 0.07 Classification-F1 0.5821633158158127 on epoch=16
06/16/2022 12:11:21 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=17
06/16/2022 12:11:24 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.20 on epoch=17
06/16/2022 12:11:26 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.11 on epoch=17
06/16/2022 12:11:29 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.16 on epoch=17
06/16/2022 12:11:32 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.06 on epoch=17
06/16/2022 12:12:18 - INFO - __main__ - Global step 1950 Train loss 0.11 Classification-F1 0.6834870090372117 on epoch=17
06/16/2022 12:12:21 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.06 on epoch=17
06/16/2022 12:12:24 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.05 on epoch=17
06/16/2022 12:12:27 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.08 on epoch=17
06/16/2022 12:12:30 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.05 on epoch=17
06/16/2022 12:12:33 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.10 on epoch=17
06/16/2022 12:13:22 - INFO - __main__ - Global step 2000 Train loss 0.07 Classification-F1 0.685646605462774 on epoch=17
06/16/2022 12:13:25 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.05 on epoch=17
06/16/2022 12:13:27 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=18
06/16/2022 12:13:30 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.07 on epoch=18
06/16/2022 12:13:33 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.07 on epoch=18
06/16/2022 12:13:36 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.07 on epoch=18
06/16/2022 12:14:24 - INFO - __main__ - Global step 2050 Train loss 0.06 Classification-F1 0.6508475937141922 on epoch=18
06/16/2022 12:14:27 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.05 on epoch=18
06/16/2022 12:14:30 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.04 on epoch=18
06/16/2022 12:14:32 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.05 on epoch=18
06/16/2022 12:14:35 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.05 on epoch=18
06/16/2022 12:14:38 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=18
06/16/2022 12:15:28 - INFO - __main__ - Global step 2100 Train loss 0.05 Classification-F1 0.7694643708359948 on epoch=18
06/16/2022 12:15:31 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.08 on epoch=18
06/16/2022 12:15:34 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.14 on epoch=18
06/16/2022 12:15:36 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.09 on epoch=19
06/16/2022 12:15:39 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.07 on epoch=19
06/16/2022 12:15:42 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.03 on epoch=19
06/16/2022 12:16:31 - INFO - __main__ - Global step 2150 Train loss 0.08 Classification-F1 0.7664619467862143 on epoch=19
06/16/2022 12:16:34 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.09 on epoch=19
06/16/2022 12:16:37 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.06 on epoch=19
06/16/2022 12:16:40 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.05 on epoch=19
06/16/2022 12:16:43 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.05 on epoch=19
06/16/2022 12:16:46 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.10 on epoch=19
06/16/2022 12:17:34 - INFO - __main__ - Global step 2200 Train loss 0.07 Classification-F1 0.6807057279040806 on epoch=19
06/16/2022 12:17:36 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=19
06/16/2022 12:17:39 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.09 on epoch=19
06/16/2022 12:17:42 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.12 on epoch=19
06/16/2022 12:17:44 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=19
06/16/2022 12:17:47 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.05 on epoch=20
06/16/2022 12:18:34 - INFO - __main__ - Global step 2250 Train loss 0.06 Classification-F1 0.7230370432307682 on epoch=20
06/16/2022 12:18:37 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.07 on epoch=20
06/16/2022 12:18:39 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.08 on epoch=20
06/16/2022 12:18:42 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.08 on epoch=20
06/16/2022 12:18:45 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.05 on epoch=20
06/16/2022 12:18:47 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.07 on epoch=20
06/16/2022 12:19:36 - INFO - __main__ - Global step 2300 Train loss 0.07 Classification-F1 0.7254135440599508 on epoch=20
06/16/2022 12:19:39 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.07 on epoch=20
06/16/2022 12:19:41 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=20
06/16/2022 12:19:44 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.07 on epoch=20
06/16/2022 12:19:47 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.11 on epoch=20
06/16/2022 12:19:49 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.06 on epoch=20
06/16/2022 12:20:37 - INFO - __main__ - Global step 2350 Train loss 0.07 Classification-F1 0.6845663565088965 on epoch=20
06/16/2022 12:20:40 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.04 on epoch=21
06/16/2022 12:20:43 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.09 on epoch=21
06/16/2022 12:20:45 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.10 on epoch=21
06/16/2022 12:20:48 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.04 on epoch=21
06/16/2022 12:20:51 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.06 on epoch=21
06/16/2022 12:21:39 - INFO - __main__ - Global step 2400 Train loss 0.06 Classification-F1 0.6202114977611636 on epoch=21
06/16/2022 12:21:42 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.04 on epoch=21
06/16/2022 12:21:44 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.08 on epoch=21
06/16/2022 12:21:47 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=21
06/16/2022 12:21:50 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.07 on epoch=21
06/16/2022 12:21:53 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.11 on epoch=21
06/16/2022 12:22:39 - INFO - __main__ - Global step 2450 Train loss 0.06 Classification-F1 0.6054137946465215 on epoch=21
06/16/2022 12:22:41 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.07 on epoch=21
06/16/2022 12:22:44 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=22
06/16/2022 12:22:47 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.06 on epoch=22
06/16/2022 12:22:50 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.07 on epoch=22
06/16/2022 12:22:52 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.05 on epoch=22
06/16/2022 12:23:36 - INFO - __main__ - Global step 2500 Train loss 0.05 Classification-F1 0.5100484584073931 on epoch=22
06/16/2022 12:23:38 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.05 on epoch=22
06/16/2022 12:23:41 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.03 on epoch=22
06/16/2022 12:23:44 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.08 on epoch=22
06/16/2022 12:23:47 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.03 on epoch=22
06/16/2022 12:23:50 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.09 on epoch=22
06/16/2022 12:24:39 - INFO - __main__ - Global step 2550 Train loss 0.06 Classification-F1 0.5914075005185984 on epoch=22
06/16/2022 12:24:42 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.05 on epoch=22
06/16/2022 12:24:45 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.04 on epoch=22
06/16/2022 12:24:48 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=23
06/16/2022 12:24:51 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.03 on epoch=23
06/16/2022 12:24:54 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.10 on epoch=23
06/16/2022 12:25:42 - INFO - __main__ - Global step 2600 Train loss 0.05 Classification-F1 0.5905774631100332 on epoch=23
06/16/2022 12:25:45 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=23
06/16/2022 12:25:48 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.06 on epoch=23
06/16/2022 12:25:51 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=23
06/16/2022 12:25:54 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.05 on epoch=23
06/16/2022 12:25:57 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.09 on epoch=23
06/16/2022 12:26:45 - INFO - __main__ - Global step 2650 Train loss 0.05 Classification-F1 0.684159652032087 on epoch=23
06/16/2022 12:26:48 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=23
06/16/2022 12:26:51 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.08 on epoch=23
06/16/2022 12:26:54 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.08 on epoch=23
06/16/2022 12:26:57 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.04 on epoch=24
06/16/2022 12:27:00 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.06 on epoch=24
06/16/2022 12:27:48 - INFO - __main__ - Global step 2700 Train loss 0.06 Classification-F1 0.8136759265004696 on epoch=24
06/16/2022 12:27:48 - INFO - __main__ - Saving model with best Classification-F1: 0.8128956472300027 -> 0.8136759265004696 on epoch=24, global_step=2700
06/16/2022 12:27:51 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.04 on epoch=24
06/16/2022 12:27:54 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.09 on epoch=24
06/16/2022 12:27:57 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.04 on epoch=24
06/16/2022 12:28:00 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.12 on epoch=24
06/16/2022 12:28:03 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.04 on epoch=24
06/16/2022 12:28:56 - INFO - __main__ - Global step 2750 Train loss 0.07 Classification-F1 0.7651232852436299 on epoch=24
06/16/2022 12:28:59 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.06 on epoch=24
06/16/2022 12:29:02 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=24
06/16/2022 12:29:05 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.06 on epoch=24
06/16/2022 12:29:08 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.09 on epoch=24
06/16/2022 12:29:11 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.05 on epoch=24
06/16/2022 12:30:05 - INFO - __main__ - Global step 2800 Train loss 0.06 Classification-F1 0.6564073248902217 on epoch=24
06/16/2022 12:30:08 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=25
06/16/2022 12:30:11 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.03 on epoch=25
06/16/2022 12:30:14 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.11 on epoch=25
06/16/2022 12:30:17 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.04 on epoch=25
06/16/2022 12:30:20 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.04 on epoch=25
06/16/2022 12:31:11 - INFO - __main__ - Global step 2850 Train loss 0.05 Classification-F1 0.7668512437447165 on epoch=25
06/16/2022 12:31:13 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=25
06/16/2022 12:31:16 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.08 on epoch=25
06/16/2022 12:31:19 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=25
06/16/2022 12:31:22 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.05 on epoch=25
06/16/2022 12:31:24 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.10 on epoch=25
06/16/2022 12:32:10 - INFO - __main__ - Global step 2900 Train loss 0.06 Classification-F1 0.7246778700429699 on epoch=25
06/16/2022 12:32:13 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=25
06/16/2022 12:32:16 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=26
06/16/2022 12:32:19 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.06 on epoch=26
06/16/2022 12:32:21 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.08 on epoch=26
06/16/2022 12:32:24 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.03 on epoch=26
06/16/2022 12:33:12 - INFO - __main__ - Global step 2950 Train loss 0.04 Classification-F1 0.7233334636791638 on epoch=26
06/16/2022 12:33:15 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.08 on epoch=26
06/16/2022 12:33:18 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.08 on epoch=26
06/16/2022 12:33:21 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.08 on epoch=26
06/16/2022 12:33:24 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.04 on epoch=26
06/16/2022 12:33:27 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=26
06/16/2022 12:33:28 - INFO - __main__ - Start tokenizing ... 1792 instances
06/16/2022 12:33:28 - INFO - __main__ - Printing 3 examples
06/16/2022 12:33:28 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/16/2022 12:33:28 - INFO - __main__ - ['Animal']
06/16/2022 12:33:28 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/16/2022 12:33:28 - INFO - __main__ - ['Animal']
06/16/2022 12:33:28 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
06/16/2022 12:33:28 - INFO - __main__ - ['Animal']
06/16/2022 12:33:28 - INFO - __main__ - Tokenizing Input ...
06/16/2022 12:33:29 - INFO - __main__ - Tokenizing Output ...
06/16/2022 12:33:31 - INFO - __main__ - Loaded 1792 examples from train data
06/16/2022 12:33:31 - INFO - __main__ - Start tokenizing ... 1792 instances
06/16/2022 12:33:31 - INFO - __main__ - Printing 3 examples
06/16/2022 12:33:31 - INFO - __main__ -  [dbpedia_14] The Andaman Treepie (Dendrocitta bayleyi) is a species of bird in the Corvidae family.It is endemic to the Andaman Islands of India.Its natural habitat is subtropical or tropical moist lowland forests. It is threatened by habitat loss.The scientific name commemorates the Anglo-Indian statesman Edward Clive Bayley.
06/16/2022 12:33:31 - INFO - __main__ - ['Animal']
06/16/2022 12:33:31 - INFO - __main__ -  [dbpedia_14] Ethmia tyranthes is a moth in the Ethmiidae family. It is found in the Democratic Republic of Congo.
06/16/2022 12:33:31 - INFO - __main__ - ['Animal']
06/16/2022 12:33:31 - INFO - __main__ -  [dbpedia_14] Van Son’s Brown (Stygionympha vansoni) is a butterfly of the Nymphalidae family. It is found in South Africa in the northern Cape from the Kamiesberg to the Springbok area.The wingspan is 36–38 mm for males and 38–40 mm for females. Adults are on wing from August to October. There is one generation per year.The larvae probably feed on Poaceae grasses.
06/16/2022 12:33:31 - INFO - __main__ - ['Animal']
06/16/2022 12:33:31 - INFO - __main__ - Tokenizing Input ...
06/16/2022 12:33:33 - INFO - __main__ - Tokenizing Output ...
06/16/2022 12:33:35 - INFO - __main__ - Loaded 1792 examples from dev data
06/16/2022 12:33:54 - INFO - __main__ - load prompt embedding from ckpt
06/16/2022 12:33:55 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/16/2022 12:33:55 - INFO - __main__ - Starting training!
06/16/2022 12:34:20 - INFO - __main__ - Global step 3000 Train loss 0.06 Classification-F1 0.813624280208532 on epoch=26
06/16/2022 12:34:20 - INFO - __main__ - save last model!
06/16/2022 12:34:20 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/16/2022 12:34:20 - INFO - __main__ - Start tokenizing ... 3500 instances
06/16/2022 12:34:20 - INFO - __main__ - Printing 3 examples
06/16/2022 12:34:20 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/16/2022 12:34:20 - INFO - __main__ - ['Animal']
06/16/2022 12:34:20 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/16/2022 12:34:20 - INFO - __main__ - ['Animal']
06/16/2022 12:34:20 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/16/2022 12:34:20 - INFO - __main__ - ['Village']
06/16/2022 12:34:20 - INFO - __main__ - Tokenizing Input ...
06/16/2022 12:34:22 - INFO - __main__ - Tokenizing Output ...
06/16/2022 12:34:26 - INFO - __main__ - Loaded 3500 examples from test data
06/16/2022 12:36:37 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down128shot/singletask-dbpedia_14/dbpedia_14_128_100_0.2_8_predictions.txt
06/16/2022 12:36:37 - INFO - __main__ - Classification-F1 on test data: 0.7620
06/16/2022 12:36:37 - INFO - __main__ - prefix=dbpedia_14_128_100, lr=0.2, bsz=8, dev_performance=0.8136759265004696, test_performance=0.7619967885824392
06/16/2022 12:36:37 - INFO - __main__ - Running ... prefix=dbpedia_14_128_13, lr=0.5, bsz=8 ...
06/16/2022 12:36:38 - INFO - __main__ - Start tokenizing ... 1792 instances
06/16/2022 12:36:38 - INFO - __main__ - Printing 3 examples
06/16/2022 12:36:38 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/16/2022 12:36:38 - INFO - __main__ - ['Animal']
06/16/2022 12:36:38 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/16/2022 12:36:38 - INFO - __main__ - ['Animal']
06/16/2022 12:36:38 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
06/16/2022 12:36:38 - INFO - __main__ - ['Animal']
06/16/2022 12:36:38 - INFO - __main__ - Tokenizing Input ...
06/16/2022 12:36:39 - INFO - __main__ - Tokenizing Output ...
06/16/2022 12:36:41 - INFO - __main__ - Loaded 1792 examples from train data
06/16/2022 12:36:41 - INFO - __main__ - Start tokenizing ... 1792 instances
06/16/2022 12:36:41 - INFO - __main__ - Printing 3 examples
06/16/2022 12:36:41 - INFO - __main__ -  [dbpedia_14] The Andaman Treepie (Dendrocitta bayleyi) is a species of bird in the Corvidae family.It is endemic to the Andaman Islands of India.Its natural habitat is subtropical or tropical moist lowland forests. It is threatened by habitat loss.The scientific name commemorates the Anglo-Indian statesman Edward Clive Bayley.
06/16/2022 12:36:41 - INFO - __main__ - ['Animal']
06/16/2022 12:36:41 - INFO - __main__ -  [dbpedia_14] Ethmia tyranthes is a moth in the Ethmiidae family. It is found in the Democratic Republic of Congo.
06/16/2022 12:36:41 - INFO - __main__ - ['Animal']
06/16/2022 12:36:41 - INFO - __main__ -  [dbpedia_14] Van Son’s Brown (Stygionympha vansoni) is a butterfly of the Nymphalidae family. It is found in South Africa in the northern Cape from the Kamiesberg to the Springbok area.The wingspan is 36–38 mm for males and 38–40 mm for females. Adults are on wing from August to October. There is one generation per year.The larvae probably feed on Poaceae grasses.
06/16/2022 12:36:41 - INFO - __main__ - ['Animal']
06/16/2022 12:36:41 - INFO - __main__ - Tokenizing Input ...
06/16/2022 12:36:42 - INFO - __main__ - Tokenizing Output ...
06/16/2022 12:36:44 - INFO - __main__ - Loaded 1792 examples from dev data
06/16/2022 12:37:04 - INFO - __main__ - load prompt embedding from ckpt
06/16/2022 12:37:05 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/16/2022 12:37:05 - INFO - __main__ - Starting training!
06/16/2022 12:37:09 - INFO - __main__ - Step 10 Global step 10 Train loss 4.60 on epoch=0
06/16/2022 12:37:12 - INFO - __main__ - Step 20 Global step 20 Train loss 2.61 on epoch=0
06/16/2022 12:37:15 - INFO - __main__ - Step 30 Global step 30 Train loss 1.97 on epoch=0
06/16/2022 12:37:18 - INFO - __main__ - Step 40 Global step 40 Train loss 1.30 on epoch=0
06/16/2022 12:37:21 - INFO - __main__ - Step 50 Global step 50 Train loss 1.19 on epoch=0
06/16/2022 12:38:07 - INFO - __main__ - Global step 50 Train loss 2.33 Classification-F1 0.12631388394206539 on epoch=0
06/16/2022 12:38:07 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.12631388394206539 on epoch=0, global_step=50
06/16/2022 12:38:10 - INFO - __main__ - Step 60 Global step 60 Train loss 1.27 on epoch=0
06/16/2022 12:38:14 - INFO - __main__ - Step 70 Global step 70 Train loss 0.84 on epoch=0
06/16/2022 12:38:17 - INFO - __main__ - Step 80 Global step 80 Train loss 0.70 on epoch=0
06/16/2022 12:38:20 - INFO - __main__ - Step 90 Global step 90 Train loss 0.71 on epoch=0
06/16/2022 12:38:23 - INFO - __main__ - Step 100 Global step 100 Train loss 0.66 on epoch=0
06/16/2022 12:39:17 - INFO - __main__ - Global step 100 Train loss 0.84 Classification-F1 0.3092094584003675 on epoch=0
06/16/2022 12:39:17 - INFO - __main__ - Saving model with best Classification-F1: 0.12631388394206539 -> 0.3092094584003675 on epoch=0, global_step=100
06/16/2022 12:39:20 - INFO - __main__ - Step 110 Global step 110 Train loss 0.77 on epoch=0
06/16/2022 12:39:23 - INFO - __main__ - Step 120 Global step 120 Train loss 0.53 on epoch=1
06/16/2022 12:39:26 - INFO - __main__ - Step 130 Global step 130 Train loss 0.48 on epoch=1
06/16/2022 12:39:29 - INFO - __main__ - Step 140 Global step 140 Train loss 0.55 on epoch=1
06/16/2022 12:39:32 - INFO - __main__ - Step 150 Global step 150 Train loss 0.56 on epoch=1
06/16/2022 12:40:26 - INFO - __main__ - Global step 150 Train loss 0.58 Classification-F1 0.27065830131430463 on epoch=1
06/16/2022 12:40:28 - INFO - __main__ - Step 160 Global step 160 Train loss 0.56 on epoch=1
06/16/2022 12:40:31 - INFO - __main__ - Step 170 Global step 170 Train loss 0.42 on epoch=1
06/16/2022 12:40:34 - INFO - __main__ - Step 180 Global step 180 Train loss 0.45 on epoch=1
06/16/2022 12:40:37 - INFO - __main__ - Step 190 Global step 190 Train loss 0.40 on epoch=1
06/16/2022 12:40:40 - INFO - __main__ - Step 200 Global step 200 Train loss 0.47 on epoch=1
06/16/2022 12:41:31 - INFO - __main__ - Global step 200 Train loss 0.46 Classification-F1 0.4556682620061509 on epoch=1
06/16/2022 12:41:31 - INFO - __main__ - Saving model with best Classification-F1: 0.3092094584003675 -> 0.4556682620061509 on epoch=1, global_step=200
06/16/2022 12:41:34 - INFO - __main__ - Step 210 Global step 210 Train loss 0.42 on epoch=1
06/16/2022 12:41:37 - INFO - __main__ - Step 220 Global step 220 Train loss 0.39 on epoch=1
06/16/2022 12:41:40 - INFO - __main__ - Step 230 Global step 230 Train loss 0.32 on epoch=2
06/16/2022 12:41:42 - INFO - __main__ - Step 240 Global step 240 Train loss 0.37 on epoch=2
06/16/2022 12:41:45 - INFO - __main__ - Step 250 Global step 250 Train loss 0.34 on epoch=2
06/16/2022 12:42:42 - INFO - __main__ - Global step 250 Train loss 0.37 Classification-F1 0.49950334609296804 on epoch=2
06/16/2022 12:42:42 - INFO - __main__ - Saving model with best Classification-F1: 0.4556682620061509 -> 0.49950334609296804 on epoch=2, global_step=250
06/16/2022 12:42:45 - INFO - __main__ - Step 260 Global step 260 Train loss 0.40 on epoch=2
06/16/2022 12:42:48 - INFO - __main__ - Step 270 Global step 270 Train loss 0.25 on epoch=2
06/16/2022 12:42:51 - INFO - __main__ - Step 280 Global step 280 Train loss 0.36 on epoch=2
06/16/2022 12:42:54 - INFO - __main__ - Step 290 Global step 290 Train loss 0.29 on epoch=2
06/16/2022 12:42:57 - INFO - __main__ - Step 300 Global step 300 Train loss 0.28 on epoch=2
06/16/2022 12:43:58 - INFO - __main__ - Global step 300 Train loss 0.32 Classification-F1 0.5229371632463792 on epoch=2
06/16/2022 12:43:59 - INFO - __main__ - Saving model with best Classification-F1: 0.49950334609296804 -> 0.5229371632463792 on epoch=2, global_step=300
06/16/2022 12:44:01 - INFO - __main__ - Step 310 Global step 310 Train loss 0.22 on epoch=2
06/16/2022 12:44:04 - INFO - __main__ - Step 320 Global step 320 Train loss 0.33 on epoch=2
06/16/2022 12:44:07 - INFO - __main__ - Step 330 Global step 330 Train loss 0.29 on epoch=2
06/16/2022 12:44:10 - INFO - __main__ - Step 340 Global step 340 Train loss 0.25 on epoch=3
06/16/2022 12:44:13 - INFO - __main__ - Step 350 Global step 350 Train loss 0.17 on epoch=3
06/16/2022 12:45:24 - INFO - __main__ - Global step 350 Train loss 0.25 Classification-F1 0.5022430325789645 on epoch=3
06/16/2022 12:45:27 - INFO - __main__ - Step 360 Global step 360 Train loss 0.13 on epoch=3
06/16/2022 12:45:30 - INFO - __main__ - Step 370 Global step 370 Train loss 0.23 on epoch=3
06/16/2022 12:45:33 - INFO - __main__ - Step 380 Global step 380 Train loss 0.15 on epoch=3
06/16/2022 12:45:36 - INFO - __main__ - Step 390 Global step 390 Train loss 0.28 on epoch=3
06/16/2022 12:45:39 - INFO - __main__ - Step 400 Global step 400 Train loss 0.19 on epoch=3
06/16/2022 12:46:46 - INFO - __main__ - Global step 400 Train loss 0.19 Classification-F1 0.41638864689280414 on epoch=3
06/16/2022 12:46:49 - INFO - __main__ - Step 410 Global step 410 Train loss 0.20 on epoch=3
06/16/2022 12:46:51 - INFO - __main__ - Step 420 Global step 420 Train loss 0.16 on epoch=3
06/16/2022 12:46:54 - INFO - __main__ - Step 430 Global step 430 Train loss 0.21 on epoch=3
06/16/2022 12:46:57 - INFO - __main__ - Step 440 Global step 440 Train loss 0.12 on epoch=3
06/16/2022 12:47:00 - INFO - __main__ - Step 450 Global step 450 Train loss 0.15 on epoch=4
06/16/2022 12:47:58 - INFO - __main__ - Global step 450 Train loss 0.17 Classification-F1 0.6180182975313371 on epoch=4
06/16/2022 12:47:58 - INFO - __main__ - Saving model with best Classification-F1: 0.5229371632463792 -> 0.6180182975313371 on epoch=4, global_step=450
06/16/2022 12:48:01 - INFO - __main__ - Step 460 Global step 460 Train loss 0.17 on epoch=4
06/16/2022 12:48:04 - INFO - __main__ - Step 470 Global step 470 Train loss 0.11 on epoch=4
06/16/2022 12:48:07 - INFO - __main__ - Step 480 Global step 480 Train loss 0.27 on epoch=4
06/16/2022 12:48:09 - INFO - __main__ - Step 490 Global step 490 Train loss 0.10 on epoch=4
06/16/2022 12:48:12 - INFO - __main__ - Step 500 Global step 500 Train loss 0.22 on epoch=4
06/16/2022 12:49:11 - INFO - __main__ - Global step 500 Train loss 0.18 Classification-F1 0.7144251087982074 on epoch=4
06/16/2022 12:49:11 - INFO - __main__ - Saving model with best Classification-F1: 0.6180182975313371 -> 0.7144251087982074 on epoch=4, global_step=500
06/16/2022 12:49:13 - INFO - __main__ - Step 510 Global step 510 Train loss 0.11 on epoch=4
06/16/2022 12:49:16 - INFO - __main__ - Step 520 Global step 520 Train loss 0.15 on epoch=4
06/16/2022 12:49:19 - INFO - __main__ - Step 530 Global step 530 Train loss 0.09 on epoch=4
06/16/2022 12:49:21 - INFO - __main__ - Step 540 Global step 540 Train loss 0.42 on epoch=4
06/16/2022 12:49:24 - INFO - __main__ - Step 550 Global step 550 Train loss 0.19 on epoch=4
06/16/2022 12:50:20 - INFO - __main__ - Global step 550 Train loss 0.19 Classification-F1 0.7326576748470051 on epoch=4
06/16/2022 12:50:20 - INFO - __main__ - Saving model with best Classification-F1: 0.7144251087982074 -> 0.7326576748470051 on epoch=4, global_step=550
06/16/2022 12:50:23 - INFO - __main__ - Step 560 Global step 560 Train loss 0.07 on epoch=4
06/16/2022 12:50:26 - INFO - __main__ - Step 570 Global step 570 Train loss 0.09 on epoch=5
06/16/2022 12:50:29 - INFO - __main__ - Step 580 Global step 580 Train loss 0.06 on epoch=5
06/16/2022 12:50:32 - INFO - __main__ - Step 590 Global step 590 Train loss 0.19 on epoch=5
06/16/2022 12:50:34 - INFO - __main__ - Step 600 Global step 600 Train loss 0.11 on epoch=5
06/16/2022 12:51:29 - INFO - __main__ - Global step 600 Train loss 0.10 Classification-F1 0.7059628436100828 on epoch=5
06/16/2022 12:51:31 - INFO - __main__ - Step 610 Global step 610 Train loss 0.17 on epoch=5
06/16/2022 12:51:34 - INFO - __main__ - Step 620 Global step 620 Train loss 0.13 on epoch=5
06/16/2022 12:51:37 - INFO - __main__ - Step 630 Global step 630 Train loss 0.14 on epoch=5
06/16/2022 12:51:40 - INFO - __main__ - Step 640 Global step 640 Train loss 0.06 on epoch=5
06/16/2022 12:51:42 - INFO - __main__ - Step 650 Global step 650 Train loss 0.11 on epoch=5
06/16/2022 12:52:35 - INFO - __main__ - Global step 650 Train loss 0.12 Classification-F1 0.7460671485974736 on epoch=5
06/16/2022 12:52:35 - INFO - __main__ - Saving model with best Classification-F1: 0.7326576748470051 -> 0.7460671485974736 on epoch=5, global_step=650
06/16/2022 12:52:37 - INFO - __main__ - Step 660 Global step 660 Train loss 0.13 on epoch=5
06/16/2022 12:52:40 - INFO - __main__ - Step 670 Global step 670 Train loss 0.12 on epoch=5
06/16/2022 12:52:43 - INFO - __main__ - Step 680 Global step 680 Train loss 0.07 on epoch=6
06/16/2022 12:52:46 - INFO - __main__ - Step 690 Global step 690 Train loss 0.07 on epoch=6
06/16/2022 12:52:48 - INFO - __main__ - Step 700 Global step 700 Train loss 0.15 on epoch=6
06/16/2022 12:53:40 - INFO - __main__ - Global step 700 Train loss 0.11 Classification-F1 0.8556193634119298 on epoch=6
06/16/2022 12:53:40 - INFO - __main__ - Saving model with best Classification-F1: 0.7460671485974736 -> 0.8556193634119298 on epoch=6, global_step=700
06/16/2022 12:53:43 - INFO - __main__ - Step 710 Global step 710 Train loss 0.07 on epoch=6
06/16/2022 12:53:46 - INFO - __main__ - Step 720 Global step 720 Train loss 0.15 on epoch=6
06/16/2022 12:53:48 - INFO - __main__ - Step 730 Global step 730 Train loss 0.15 on epoch=6
06/16/2022 12:53:51 - INFO - __main__ - Step 740 Global step 740 Train loss 0.07 on epoch=6
06/16/2022 12:53:54 - INFO - __main__ - Step 750 Global step 750 Train loss 0.12 on epoch=6
06/16/2022 12:54:50 - INFO - __main__ - Global step 750 Train loss 0.11 Classification-F1 0.8501154937477671 on epoch=6
06/16/2022 12:54:53 - INFO - __main__ - Step 760 Global step 760 Train loss 0.15 on epoch=6
06/16/2022 12:54:56 - INFO - __main__ - Step 770 Global step 770 Train loss 0.21 on epoch=6
06/16/2022 12:54:59 - INFO - __main__ - Step 780 Global step 780 Train loss 0.10 on epoch=6
06/16/2022 12:55:02 - INFO - __main__ - Step 790 Global step 790 Train loss 0.04 on epoch=7
06/16/2022 12:55:05 - INFO - __main__ - Step 800 Global step 800 Train loss 0.05 on epoch=7
06/16/2022 12:56:04 - INFO - __main__ - Global step 800 Train loss 0.11 Classification-F1 0.8476077759869941 on epoch=7
06/16/2022 12:56:07 - INFO - __main__ - Step 810 Global step 810 Train loss 0.07 on epoch=7
06/16/2022 12:56:10 - INFO - __main__ - Step 820 Global step 820 Train loss 0.11 on epoch=7
06/16/2022 12:56:12 - INFO - __main__ - Step 830 Global step 830 Train loss 0.06 on epoch=7
06/16/2022 12:56:15 - INFO - __main__ - Step 840 Global step 840 Train loss 0.18 on epoch=7
06/16/2022 12:56:18 - INFO - __main__ - Step 850 Global step 850 Train loss 0.07 on epoch=7
06/16/2022 12:57:16 - INFO - __main__ - Global step 850 Train loss 0.10 Classification-F1 0.8064724169738812 on epoch=7
06/16/2022 12:57:19 - INFO - __main__ - Step 860 Global step 860 Train loss 0.14 on epoch=7
06/16/2022 12:57:22 - INFO - __main__ - Step 870 Global step 870 Train loss 0.06 on epoch=7
06/16/2022 12:57:25 - INFO - __main__ - Step 880 Global step 880 Train loss 0.19 on epoch=7
06/16/2022 12:57:28 - INFO - __main__ - Step 890 Global step 890 Train loss 0.10 on epoch=7
06/16/2022 12:57:31 - INFO - __main__ - Step 900 Global step 900 Train loss 0.10 on epoch=8
06/16/2022 12:58:18 - INFO - __main__ - Global step 900 Train loss 0.12 Classification-F1 0.6222110193070023 on epoch=8
06/16/2022 12:58:21 - INFO - __main__ - Step 910 Global step 910 Train loss 0.03 on epoch=8
06/16/2022 12:58:23 - INFO - __main__ - Step 920 Global step 920 Train loss 0.05 on epoch=8
06/16/2022 12:58:26 - INFO - __main__ - Step 930 Global step 930 Train loss 0.08 on epoch=8
06/16/2022 12:58:29 - INFO - __main__ - Step 940 Global step 940 Train loss 0.08 on epoch=8
06/16/2022 12:58:31 - INFO - __main__ - Step 950 Global step 950 Train loss 0.14 on epoch=8
06/16/2022 12:59:24 - INFO - __main__ - Global step 950 Train loss 0.07 Classification-F1 0.7140433604213933 on epoch=8
06/16/2022 12:59:26 - INFO - __main__ - Step 960 Global step 960 Train loss 0.05 on epoch=8
06/16/2022 12:59:29 - INFO - __main__ - Step 970 Global step 970 Train loss 0.09 on epoch=8
06/16/2022 12:59:32 - INFO - __main__ - Step 980 Global step 980 Train loss 0.04 on epoch=8
06/16/2022 12:59:34 - INFO - __main__ - Step 990 Global step 990 Train loss 0.12 on epoch=8
06/16/2022 12:59:37 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.07 on epoch=8
06/16/2022 13:00:28 - INFO - __main__ - Global step 1000 Train loss 0.07 Classification-F1 0.6451670582579102 on epoch=8
06/16/2022 13:00:31 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.07 on epoch=9
06/16/2022 13:00:34 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.05 on epoch=9
06/16/2022 13:00:36 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.02 on epoch=9
06/16/2022 13:00:39 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.08 on epoch=9
06/16/2022 13:00:42 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.08 on epoch=9
06/16/2022 13:01:31 - INFO - __main__ - Global step 1050 Train loss 0.06 Classification-F1 0.7958949562288327 on epoch=9
06/16/2022 13:01:34 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.14 on epoch=9
06/16/2022 13:01:36 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.06 on epoch=9
06/16/2022 13:01:39 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.09 on epoch=9
06/16/2022 13:01:42 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.04 on epoch=9
06/16/2022 13:01:45 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.14 on epoch=9
06/16/2022 13:02:35 - INFO - __main__ - Global step 1100 Train loss 0.09 Classification-F1 0.7604377398141532 on epoch=9
06/16/2022 13:02:37 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.11 on epoch=9
06/16/2022 13:02:40 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.02 on epoch=9
06/16/2022 13:02:43 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.06 on epoch=10
06/16/2022 13:02:46 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.04 on epoch=10
06/16/2022 13:02:48 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.12 on epoch=10
06/16/2022 13:03:36 - INFO - __main__ - Global step 1150 Train loss 0.07 Classification-F1 0.6854479931010868 on epoch=10
06/16/2022 13:03:39 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.04 on epoch=10
06/16/2022 13:03:41 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.10 on epoch=10
06/16/2022 13:03:44 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.11 on epoch=10
06/16/2022 13:03:47 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.05 on epoch=10
06/16/2022 13:03:50 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.03 on epoch=10
06/16/2022 13:04:37 - INFO - __main__ - Global step 1200 Train loss 0.07 Classification-F1 0.8103716705858355 on epoch=10
06/16/2022 13:04:40 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.11 on epoch=10
06/16/2022 13:04:43 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.05 on epoch=10
06/16/2022 13:04:46 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.05 on epoch=10
06/16/2022 13:04:49 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.03 on epoch=11
06/16/2022 13:04:52 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.05 on epoch=11
06/16/2022 13:05:41 - INFO - __main__ - Global step 1250 Train loss 0.06 Classification-F1 0.852813045664802 on epoch=11
06/16/2022 13:05:44 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.08 on epoch=11
06/16/2022 13:05:46 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.09 on epoch=11
06/16/2022 13:05:49 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.07 on epoch=11
06/16/2022 13:05:52 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.06 on epoch=11
06/16/2022 13:05:55 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.04 on epoch=11
06/16/2022 13:06:42 - INFO - __main__ - Global step 1300 Train loss 0.07 Classification-F1 0.635971123951446 on epoch=11
06/16/2022 13:06:45 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.05 on epoch=11
06/16/2022 13:06:47 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.08 on epoch=11
06/16/2022 13:06:50 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.12 on epoch=11
06/16/2022 13:06:53 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.11 on epoch=11
06/16/2022 13:06:56 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.03 on epoch=12
06/16/2022 13:07:47 - INFO - __main__ - Global step 1350 Train loss 0.08 Classification-F1 0.750034646237209 on epoch=12
06/16/2022 13:07:50 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.04 on epoch=12
06/16/2022 13:07:53 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.03 on epoch=12
06/16/2022 13:07:55 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.06 on epoch=12
06/16/2022 13:07:58 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.07 on epoch=12
06/16/2022 13:08:01 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.14 on epoch=12
06/16/2022 13:08:47 - INFO - __main__ - Global step 1400 Train loss 0.07 Classification-F1 0.5446842120452282 on epoch=12
06/16/2022 13:08:50 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.05 on epoch=12
06/16/2022 13:08:52 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.08 on epoch=12
06/16/2022 13:08:55 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.03 on epoch=12
06/16/2022 13:08:58 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.15 on epoch=12
06/16/2022 13:09:01 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.07 on epoch=12
06/16/2022 13:09:48 - INFO - __main__ - Global step 1450 Train loss 0.08 Classification-F1 0.524847101422339 on epoch=12
06/16/2022 13:09:50 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.04 on epoch=13
06/16/2022 13:09:53 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.04 on epoch=13
06/16/2022 13:09:56 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.03 on epoch=13
06/16/2022 13:09:59 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.12 on epoch=13
06/16/2022 13:10:01 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.02 on epoch=13
06/16/2022 13:10:47 - INFO - __main__ - Global step 1500 Train loss 0.05 Classification-F1 0.7482058643226006 on epoch=13
06/16/2022 13:10:49 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.14 on epoch=13
06/16/2022 13:10:52 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.03 on epoch=13
06/16/2022 13:10:55 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.05 on epoch=13
06/16/2022 13:10:57 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=13
06/16/2022 13:11:00 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.11 on epoch=13
06/16/2022 13:11:46 - INFO - __main__ - Global step 1550 Train loss 0.07 Classification-F1 0.4095418646944469 on epoch=13
06/16/2022 13:11:49 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.10 on epoch=13
06/16/2022 13:11:52 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=14
06/16/2022 13:11:55 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.05 on epoch=14
06/16/2022 13:11:57 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.07 on epoch=14
06/16/2022 13:12:00 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.10 on epoch=14
06/16/2022 13:12:43 - INFO - __main__ - Global step 1600 Train loss 0.07 Classification-F1 0.5384583567240767 on epoch=14
06/16/2022 13:12:46 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=14
06/16/2022 13:12:49 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.07 on epoch=14
06/16/2022 13:12:51 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.04 on epoch=14
06/16/2022 13:12:54 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.03 on epoch=14
06/16/2022 13:12:57 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.03 on epoch=14
06/16/2022 13:13:41 - INFO - __main__ - Global step 1650 Train loss 0.04 Classification-F1 0.5540430053124213 on epoch=14
06/16/2022 13:13:44 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.07 on epoch=14
06/16/2022 13:13:47 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.12 on epoch=14
06/16/2022 13:13:49 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.07 on epoch=14
06/16/2022 13:13:52 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.02 on epoch=15
06/16/2022 13:13:55 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=15
06/16/2022 13:14:41 - INFO - __main__ - Global step 1700 Train loss 0.06 Classification-F1 0.5083514961827043 on epoch=15
06/16/2022 13:14:44 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.06 on epoch=15
06/16/2022 13:14:47 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.05 on epoch=15
06/16/2022 13:14:50 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.07 on epoch=15
06/16/2022 13:14:52 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=15
06/16/2022 13:14:55 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=15
06/16/2022 13:15:45 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.603630681850188 on epoch=15
06/16/2022 13:15:48 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=15
06/16/2022 13:15:51 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.08 on epoch=15
06/16/2022 13:15:53 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.09 on epoch=15
06/16/2022 13:15:56 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.05 on epoch=15
06/16/2022 13:15:59 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=16
06/16/2022 13:16:50 - INFO - __main__ - Global step 1800 Train loss 0.05 Classification-F1 0.758280992480119 on epoch=16
06/16/2022 13:16:52 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=16
06/16/2022 13:16:55 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.04 on epoch=16
06/16/2022 13:16:58 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.05 on epoch=16
06/16/2022 13:17:00 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.06 on epoch=16
06/16/2022 13:17:03 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.04 on epoch=16
06/16/2022 13:17:48 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.5450903488807509 on epoch=16
06/16/2022 13:17:50 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=16
06/16/2022 13:17:53 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.07 on epoch=16
06/16/2022 13:17:56 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.04 on epoch=16
06/16/2022 13:17:59 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.07 on epoch=16
06/16/2022 13:18:01 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=16
06/16/2022 13:18:48 - INFO - __main__ - Global step 1900 Train loss 0.05 Classification-F1 0.6587368004594087 on epoch=16
06/16/2022 13:18:51 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=17
06/16/2022 13:18:53 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=17
06/16/2022 13:18:56 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=17
06/16/2022 13:18:59 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.06 on epoch=17
06/16/2022 13:19:01 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=17
06/16/2022 13:19:46 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.4959808154170442 on epoch=17
06/16/2022 13:19:48 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.08 on epoch=17
06/16/2022 13:19:51 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.05 on epoch=17
06/16/2022 13:19:54 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=17
06/16/2022 13:19:56 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=17
06/16/2022 13:19:59 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.18 on epoch=17
06/16/2022 13:20:44 - INFO - __main__ - Global step 2000 Train loss 0.07 Classification-F1 0.4717204531036438 on epoch=17
06/16/2022 13:20:47 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.09 on epoch=17
06/16/2022 13:20:50 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=18
06/16/2022 13:20:53 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=18
06/16/2022 13:20:55 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=18
06/16/2022 13:20:58 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.06 on epoch=18
06/16/2022 13:21:44 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.6908354773409854 on epoch=18
06/16/2022 13:21:47 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.02 on epoch=18
06/16/2022 13:21:49 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.06 on epoch=18
06/16/2022 13:21:52 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.03 on epoch=18
06/16/2022 13:21:55 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=18
06/16/2022 13:21:57 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=18
06/16/2022 13:22:43 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.6672337258791665 on epoch=18
06/16/2022 13:22:46 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.08 on epoch=18
06/16/2022 13:22:48 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.05 on epoch=18
06/16/2022 13:22:51 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.04 on epoch=19
06/16/2022 13:22:54 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=19
06/16/2022 13:22:56 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=19
06/16/2022 13:23:45 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.6019653027355619 on epoch=19
06/16/2022 13:23:48 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.06 on epoch=19
06/16/2022 13:23:51 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=19
06/16/2022 13:23:54 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.13 on epoch=19
06/16/2022 13:23:56 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=19
06/16/2022 13:23:59 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.08 on epoch=19
06/16/2022 13:24:45 - INFO - __main__ - Global step 2200 Train loss 0.06 Classification-F1 0.514379645815858 on epoch=19
06/16/2022 13:24:47 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=19
06/16/2022 13:24:50 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.07 on epoch=19
06/16/2022 13:24:53 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.08 on epoch=19
06/16/2022 13:24:56 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.06 on epoch=19
06/16/2022 13:24:58 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=20
06/16/2022 13:25:45 - INFO - __main__ - Global step 2250 Train loss 0.05 Classification-F1 0.44526405345391595 on epoch=20
06/16/2022 13:25:48 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=20
06/16/2022 13:25:51 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.03 on epoch=20
06/16/2022 13:25:54 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=20
06/16/2022 13:25:56 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.08 on epoch=20
06/16/2022 13:25:59 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=20
06/16/2022 13:26:42 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.46925775269195935 on epoch=20
06/16/2022 13:26:44 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=20
06/16/2022 13:26:47 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=20
06/16/2022 13:26:50 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.04 on epoch=20
06/16/2022 13:26:52 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.10 on epoch=20
06/16/2022 13:26:55 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=20
06/16/2022 13:27:39 - INFO - __main__ - Global step 2350 Train loss 0.04 Classification-F1 0.6814575296387273 on epoch=20
06/16/2022 13:27:42 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=21
06/16/2022 13:27:45 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=21
06/16/2022 13:27:47 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.03 on epoch=21
06/16/2022 13:27:50 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.07 on epoch=21
06/16/2022 13:27:53 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.04 on epoch=21
06/16/2022 13:28:37 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.43334312500998884 on epoch=21
06/16/2022 13:28:39 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=21
06/16/2022 13:28:42 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.05 on epoch=21
06/16/2022 13:28:45 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.05 on epoch=21
06/16/2022 13:28:47 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.04 on epoch=21
06/16/2022 13:28:50 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.07 on epoch=21
06/16/2022 13:29:34 - INFO - __main__ - Global step 2450 Train loss 0.04 Classification-F1 0.44843893944497415 on epoch=21
06/16/2022 13:29:37 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.04 on epoch=21
06/16/2022 13:29:40 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=22
06/16/2022 13:29:42 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=22
06/16/2022 13:29:45 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.03 on epoch=22
06/16/2022 13:29:48 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.05 on epoch=22
06/16/2022 13:30:32 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.36964086548066805 on epoch=22
06/16/2022 13:30:34 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.03 on epoch=22
06/16/2022 13:30:37 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=22
06/16/2022 13:30:40 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=22
06/16/2022 13:30:42 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.03 on epoch=22
06/16/2022 13:30:45 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=22
06/16/2022 13:31:30 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.573041979976665 on epoch=22
06/16/2022 13:31:33 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.11 on epoch=22
06/16/2022 13:31:36 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=22
06/16/2022 13:31:38 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=23
06/16/2022 13:31:41 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=23
06/16/2022 13:31:44 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=23
06/16/2022 13:32:37 - INFO - __main__ - Global step 2600 Train loss 0.04 Classification-F1 0.920072047243542 on epoch=23
06/16/2022 13:32:37 - INFO - __main__ - Saving model with best Classification-F1: 0.8556193634119298 -> 0.920072047243542 on epoch=23, global_step=2600
06/16/2022 13:32:40 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.09 on epoch=23
06/16/2022 13:32:43 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=23
06/16/2022 13:32:46 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.05 on epoch=23
06/16/2022 13:32:49 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.06 on epoch=23
06/16/2022 13:32:52 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.04 on epoch=23
06/16/2022 13:33:37 - INFO - __main__ - Global step 2650 Train loss 0.05 Classification-F1 0.6464142418451606 on epoch=23
06/16/2022 13:33:39 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=23
06/16/2022 13:33:42 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.09 on epoch=23
06/16/2022 13:33:44 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.03 on epoch=23
06/16/2022 13:33:47 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=24
06/16/2022 13:33:50 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.06 on epoch=24
06/16/2022 13:34:37 - INFO - __main__ - Global step 2700 Train loss 0.04 Classification-F1 0.6120196100236909 on epoch=24
06/16/2022 13:34:40 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.03 on epoch=24
06/16/2022 13:34:43 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.04 on epoch=24
06/16/2022 13:34:46 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=24
06/16/2022 13:34:48 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.05 on epoch=24
06/16/2022 13:34:51 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.04 on epoch=24
06/16/2022 13:35:37 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.6118494454307422 on epoch=24
06/16/2022 13:35:40 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=24
06/16/2022 13:35:43 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=24
06/16/2022 13:35:45 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.07 on epoch=24
06/16/2022 13:35:48 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.04 on epoch=24
06/16/2022 13:35:51 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.03 on epoch=24
06/16/2022 13:36:36 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.6911349795591013 on epoch=24
06/16/2022 13:36:39 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=25
06/16/2022 13:36:42 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=25
06/16/2022 13:36:44 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.03 on epoch=25
06/16/2022 13:36:47 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=25
06/16/2022 13:36:50 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=25
06/16/2022 13:37:34 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.7626904644598415 on epoch=25
06/16/2022 13:37:37 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.05 on epoch=25
06/16/2022 13:37:39 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.03 on epoch=25
06/16/2022 13:37:42 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=25
06/16/2022 13:37:45 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.04 on epoch=25
06/16/2022 13:37:47 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.08 on epoch=25
06/16/2022 13:38:34 - INFO - __main__ - Global step 2900 Train loss 0.04 Classification-F1 0.4532715647971647 on epoch=25
06/16/2022 13:38:37 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=25
06/16/2022 13:38:40 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=26
06/16/2022 13:38:43 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=26
06/16/2022 13:38:46 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=26
06/16/2022 13:38:49 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.06 on epoch=26
06/16/2022 13:39:33 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.4289361083000262 on epoch=26
06/16/2022 13:39:35 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.05 on epoch=26
06/16/2022 13:39:38 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=26
06/16/2022 13:39:41 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=26
06/16/2022 13:39:44 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=26
06/16/2022 13:39:47 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.05 on epoch=26
06/16/2022 13:39:48 - INFO - __main__ - Start tokenizing ... 1792 instances
06/16/2022 13:39:48 - INFO - __main__ - Printing 3 examples
06/16/2022 13:39:49 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/16/2022 13:39:49 - INFO - __main__ - ['Animal']
06/16/2022 13:39:49 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/16/2022 13:39:49 - INFO - __main__ - ['Animal']
06/16/2022 13:39:49 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
06/16/2022 13:39:49 - INFO - __main__ - ['Animal']
06/16/2022 13:39:49 - INFO - __main__ - Tokenizing Input ...
06/16/2022 13:39:50 - INFO - __main__ - Tokenizing Output ...
06/16/2022 13:39:52 - INFO - __main__ - Loaded 1792 examples from train data
06/16/2022 13:39:52 - INFO - __main__ - Start tokenizing ... 1792 instances
06/16/2022 13:39:52 - INFO - __main__ - Printing 3 examples
06/16/2022 13:39:52 - INFO - __main__ -  [dbpedia_14] The Andaman Treepie (Dendrocitta bayleyi) is a species of bird in the Corvidae family.It is endemic to the Andaman Islands of India.Its natural habitat is subtropical or tropical moist lowland forests. It is threatened by habitat loss.The scientific name commemorates the Anglo-Indian statesman Edward Clive Bayley.
06/16/2022 13:39:52 - INFO - __main__ - ['Animal']
06/16/2022 13:39:52 - INFO - __main__ -  [dbpedia_14] Ethmia tyranthes is a moth in the Ethmiidae family. It is found in the Democratic Republic of Congo.
06/16/2022 13:39:52 - INFO - __main__ - ['Animal']
06/16/2022 13:39:52 - INFO - __main__ -  [dbpedia_14] Van Son’s Brown (Stygionympha vansoni) is a butterfly of the Nymphalidae family. It is found in South Africa in the northern Cape from the Kamiesberg to the Springbok area.The wingspan is 36–38 mm for males and 38–40 mm for females. Adults are on wing from August to October. There is one generation per year.The larvae probably feed on Poaceae grasses.
06/16/2022 13:39:52 - INFO - __main__ - ['Animal']
06/16/2022 13:39:52 - INFO - __main__ - Tokenizing Input ...
06/16/2022 13:39:54 - INFO - __main__ - Tokenizing Output ...
06/16/2022 13:39:55 - INFO - __main__ - Loaded 1792 examples from dev data
06/16/2022 13:40:12 - INFO - __main__ - load prompt embedding from ckpt
06/16/2022 13:40:13 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/16/2022 13:40:13 - INFO - __main__ - Starting training!
06/16/2022 13:40:33 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.6346251823695923 on epoch=26
06/16/2022 13:40:33 - INFO - __main__ - save last model!
06/16/2022 13:40:33 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/16/2022 13:40:33 - INFO - __main__ - Start tokenizing ... 3500 instances
06/16/2022 13:40:33 - INFO - __main__ - Printing 3 examples
06/16/2022 13:40:33 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/16/2022 13:40:33 - INFO - __main__ - ['Animal']
06/16/2022 13:40:33 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/16/2022 13:40:33 - INFO - __main__ - ['Animal']
06/16/2022 13:40:33 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/16/2022 13:40:33 - INFO - __main__ - ['Village']
06/16/2022 13:40:33 - INFO - __main__ - Tokenizing Input ...
06/16/2022 13:40:35 - INFO - __main__ - Tokenizing Output ...
06/16/2022 13:40:38 - INFO - __main__ - Loaded 3500 examples from test data
06/16/2022 13:42:45 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down128shot/singletask-dbpedia_14/dbpedia_14_128_13_0.5_8_predictions.txt
06/16/2022 13:42:45 - INFO - __main__ - Classification-F1 on test data: 0.5474
06/16/2022 13:42:45 - INFO - __main__ - prefix=dbpedia_14_128_13, lr=0.5, bsz=8, dev_performance=0.920072047243542, test_performance=0.5473969533947095
06/16/2022 13:42:45 - INFO - __main__ - Running ... prefix=dbpedia_14_128_13, lr=0.4, bsz=8 ...
06/16/2022 13:42:46 - INFO - __main__ - Start tokenizing ... 1792 instances
06/16/2022 13:42:46 - INFO - __main__ - Printing 3 examples
06/16/2022 13:42:46 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/16/2022 13:42:46 - INFO - __main__ - ['Animal']
06/16/2022 13:42:46 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/16/2022 13:42:46 - INFO - __main__ - ['Animal']
06/16/2022 13:42:46 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
06/16/2022 13:42:46 - INFO - __main__ - ['Animal']
06/16/2022 13:42:46 - INFO - __main__ - Tokenizing Input ...
06/16/2022 13:42:48 - INFO - __main__ - Tokenizing Output ...
06/16/2022 13:42:50 - INFO - __main__ - Loaded 1792 examples from train data
06/16/2022 13:42:50 - INFO - __main__ - Start tokenizing ... 1792 instances
06/16/2022 13:42:50 - INFO - __main__ - Printing 3 examples
06/16/2022 13:42:50 - INFO - __main__ -  [dbpedia_14] The Andaman Treepie (Dendrocitta bayleyi) is a species of bird in the Corvidae family.It is endemic to the Andaman Islands of India.Its natural habitat is subtropical or tropical moist lowland forests. It is threatened by habitat loss.The scientific name commemorates the Anglo-Indian statesman Edward Clive Bayley.
06/16/2022 13:42:50 - INFO - __main__ - ['Animal']
06/16/2022 13:42:50 - INFO - __main__ -  [dbpedia_14] Ethmia tyranthes is a moth in the Ethmiidae family. It is found in the Democratic Republic of Congo.
06/16/2022 13:42:50 - INFO - __main__ - ['Animal']
06/16/2022 13:42:50 - INFO - __main__ -  [dbpedia_14] Van Son’s Brown (Stygionympha vansoni) is a butterfly of the Nymphalidae family. It is found in South Africa in the northern Cape from the Kamiesberg to the Springbok area.The wingspan is 36–38 mm for males and 38–40 mm for females. Adults are on wing from August to October. There is one generation per year.The larvae probably feed on Poaceae grasses.
06/16/2022 13:42:50 - INFO - __main__ - ['Animal']
06/16/2022 13:42:50 - INFO - __main__ - Tokenizing Input ...
06/16/2022 13:42:51 - INFO - __main__ - Tokenizing Output ...
06/16/2022 13:42:52 - INFO - __main__ - Loaded 1792 examples from dev data
06/16/2022 13:43:08 - INFO - __main__ - load prompt embedding from ckpt
06/16/2022 13:43:09 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/16/2022 13:43:09 - INFO - __main__ - Starting training!
06/16/2022 13:43:13 - INFO - __main__ - Step 10 Global step 10 Train loss 4.77 on epoch=0
06/16/2022 13:43:16 - INFO - __main__ - Step 20 Global step 20 Train loss 2.88 on epoch=0
06/16/2022 13:43:19 - INFO - __main__ - Step 30 Global step 30 Train loss 2.13 on epoch=0
06/16/2022 13:43:22 - INFO - __main__ - Step 40 Global step 40 Train loss 1.97 on epoch=0
06/16/2022 13:43:25 - INFO - __main__ - Step 50 Global step 50 Train loss 1.59 on epoch=0
06/16/2022 13:44:09 - INFO - __main__ - Global step 50 Train loss 2.67 Classification-F1 0.15495567757791015 on epoch=0
06/16/2022 13:44:09 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.15495567757791015 on epoch=0, global_step=50
06/16/2022 13:44:12 - INFO - __main__ - Step 60 Global step 60 Train loss 1.26 on epoch=0
06/16/2022 13:44:15 - INFO - __main__ - Step 70 Global step 70 Train loss 1.10 on epoch=0
06/16/2022 13:44:18 - INFO - __main__ - Step 80 Global step 80 Train loss 0.85 on epoch=0
06/16/2022 13:44:20 - INFO - __main__ - Step 90 Global step 90 Train loss 1.68 on epoch=0
06/16/2022 13:44:23 - INFO - __main__ - Step 100 Global step 100 Train loss 0.83 on epoch=0
06/16/2022 13:45:11 - INFO - __main__ - Global step 100 Train loss 1.15 Classification-F1 0.29796540314716713 on epoch=0
06/16/2022 13:45:11 - INFO - __main__ - Saving model with best Classification-F1: 0.15495567757791015 -> 0.29796540314716713 on epoch=0, global_step=100
06/16/2022 13:45:14 - INFO - __main__ - Step 110 Global step 110 Train loss 0.98 on epoch=0
06/16/2022 13:45:17 - INFO - __main__ - Step 120 Global step 120 Train loss 0.75 on epoch=1
06/16/2022 13:45:20 - INFO - __main__ - Step 130 Global step 130 Train loss 0.86 on epoch=1
06/16/2022 13:45:23 - INFO - __main__ - Step 140 Global step 140 Train loss 0.76 on epoch=1
06/16/2022 13:45:26 - INFO - __main__ - Step 150 Global step 150 Train loss 0.78 on epoch=1
06/16/2022 13:46:17 - INFO - __main__ - Global step 150 Train loss 0.82 Classification-F1 0.3373448477351505 on epoch=1
06/16/2022 13:46:17 - INFO - __main__ - Saving model with best Classification-F1: 0.29796540314716713 -> 0.3373448477351505 on epoch=1, global_step=150
06/16/2022 13:46:20 - INFO - __main__ - Step 160 Global step 160 Train loss 0.80 on epoch=1
06/16/2022 13:46:22 - INFO - __main__ - Step 170 Global step 170 Train loss 0.79 on epoch=1
06/16/2022 13:46:25 - INFO - __main__ - Step 180 Global step 180 Train loss 0.76 on epoch=1
06/16/2022 13:46:28 - INFO - __main__ - Step 190 Global step 190 Train loss 0.70 on epoch=1
06/16/2022 13:46:31 - INFO - __main__ - Step 200 Global step 200 Train loss 0.63 on epoch=1
06/16/2022 13:47:21 - INFO - __main__ - Global step 200 Train loss 0.74 Classification-F1 0.3604389378303709 on epoch=1
06/16/2022 13:47:21 - INFO - __main__ - Saving model with best Classification-F1: 0.3373448477351505 -> 0.3604389378303709 on epoch=1, global_step=200
06/16/2022 13:47:24 - INFO - __main__ - Step 210 Global step 210 Train loss 0.66 on epoch=1
06/16/2022 13:47:27 - INFO - __main__ - Step 220 Global step 220 Train loss 0.60 on epoch=1
06/16/2022 13:47:29 - INFO - __main__ - Step 230 Global step 230 Train loss 0.66 on epoch=2
06/16/2022 13:47:32 - INFO - __main__ - Step 240 Global step 240 Train loss 0.61 on epoch=2
06/16/2022 13:47:35 - INFO - __main__ - Step 250 Global step 250 Train loss 1.07 on epoch=2
06/16/2022 13:48:27 - INFO - __main__ - Global step 250 Train loss 0.72 Classification-F1 0.40385917731824433 on epoch=2
06/16/2022 13:48:27 - INFO - __main__ - Saving model with best Classification-F1: 0.3604389378303709 -> 0.40385917731824433 on epoch=2, global_step=250
06/16/2022 13:48:29 - INFO - __main__ - Step 260 Global step 260 Train loss 0.63 on epoch=2
06/16/2022 13:48:32 - INFO - __main__ - Step 270 Global step 270 Train loss 0.56 on epoch=2
06/16/2022 13:48:35 - INFO - __main__ - Step 280 Global step 280 Train loss 0.68 on epoch=2
06/16/2022 13:48:38 - INFO - __main__ - Step 290 Global step 290 Train loss 0.53 on epoch=2
06/16/2022 13:48:41 - INFO - __main__ - Step 300 Global step 300 Train loss 0.60 on epoch=2
06/16/2022 13:49:33 - INFO - __main__ - Global step 300 Train loss 0.60 Classification-F1 0.5731426367331239 on epoch=2
06/16/2022 13:49:33 - INFO - __main__ - Saving model with best Classification-F1: 0.40385917731824433 -> 0.5731426367331239 on epoch=2, global_step=300
06/16/2022 13:49:36 - INFO - __main__ - Step 310 Global step 310 Train loss 0.55 on epoch=2
06/16/2022 13:49:39 - INFO - __main__ - Step 320 Global step 320 Train loss 0.57 on epoch=2
06/16/2022 13:49:42 - INFO - __main__ - Step 330 Global step 330 Train loss 0.43 on epoch=2
06/16/2022 13:49:45 - INFO - __main__ - Step 340 Global step 340 Train loss 0.42 on epoch=3
06/16/2022 13:49:48 - INFO - __main__ - Step 350 Global step 350 Train loss 0.48 on epoch=3
06/16/2022 13:50:44 - INFO - __main__ - Global step 350 Train loss 0.49 Classification-F1 0.4742632105542985 on epoch=3
06/16/2022 13:50:46 - INFO - __main__ - Step 360 Global step 360 Train loss 0.43 on epoch=3
06/16/2022 13:50:49 - INFO - __main__ - Step 370 Global step 370 Train loss 0.61 on epoch=3
06/16/2022 13:50:52 - INFO - __main__ - Step 380 Global step 380 Train loss 0.51 on epoch=3
06/16/2022 13:50:55 - INFO - __main__ - Step 390 Global step 390 Train loss 0.48 on epoch=3
06/16/2022 13:50:58 - INFO - __main__ - Step 400 Global step 400 Train loss 0.52 on epoch=3
06/16/2022 13:51:50 - INFO - __main__ - Global step 400 Train loss 0.51 Classification-F1 0.5667146264156765 on epoch=3
06/16/2022 13:51:53 - INFO - __main__ - Step 410 Global step 410 Train loss 0.50 on epoch=3
06/16/2022 13:51:55 - INFO - __main__ - Step 420 Global step 420 Train loss 0.44 on epoch=3
06/16/2022 13:51:58 - INFO - __main__ - Step 430 Global step 430 Train loss 0.54 on epoch=3
06/16/2022 13:52:01 - INFO - __main__ - Step 440 Global step 440 Train loss 0.49 on epoch=3
06/16/2022 13:52:04 - INFO - __main__ - Step 450 Global step 450 Train loss 0.37 on epoch=4
06/16/2022 13:52:59 - INFO - __main__ - Global step 450 Train loss 0.47 Classification-F1 0.6662353420816566 on epoch=4
06/16/2022 13:52:59 - INFO - __main__ - Saving model with best Classification-F1: 0.5731426367331239 -> 0.6662353420816566 on epoch=4, global_step=450
06/16/2022 13:53:02 - INFO - __main__ - Step 460 Global step 460 Train loss 0.38 on epoch=4
06/16/2022 13:53:05 - INFO - __main__ - Step 470 Global step 470 Train loss 0.43 on epoch=4
06/16/2022 13:53:08 - INFO - __main__ - Step 480 Global step 480 Train loss 0.49 on epoch=4
06/16/2022 13:53:10 - INFO - __main__ - Step 490 Global step 490 Train loss 0.35 on epoch=4
06/16/2022 13:53:13 - INFO - __main__ - Step 500 Global step 500 Train loss 0.49 on epoch=4
06/16/2022 13:54:10 - INFO - __main__ - Global step 500 Train loss 0.43 Classification-F1 0.4774621435366827 on epoch=4
06/16/2022 13:54:13 - INFO - __main__ - Step 510 Global step 510 Train loss 0.43 on epoch=4
06/16/2022 13:54:16 - INFO - __main__ - Step 520 Global step 520 Train loss 0.44 on epoch=4
06/16/2022 13:54:18 - INFO - __main__ - Step 530 Global step 530 Train loss 0.32 on epoch=4
06/16/2022 13:54:21 - INFO - __main__ - Step 540 Global step 540 Train loss 0.54 on epoch=4
06/16/2022 13:54:24 - INFO - __main__ - Step 550 Global step 550 Train loss 0.41 on epoch=4
06/16/2022 13:55:17 - INFO - __main__ - Global step 550 Train loss 0.43 Classification-F1 0.45152762856031553 on epoch=4
06/16/2022 13:55:19 - INFO - __main__ - Step 560 Global step 560 Train loss 0.41 on epoch=4
06/16/2022 13:55:22 - INFO - __main__ - Step 570 Global step 570 Train loss 0.34 on epoch=5
06/16/2022 13:55:25 - INFO - __main__ - Step 580 Global step 580 Train loss 0.34 on epoch=5
06/16/2022 13:55:28 - INFO - __main__ - Step 590 Global step 590 Train loss 0.44 on epoch=5
06/16/2022 13:55:31 - INFO - __main__ - Step 600 Global step 600 Train loss 0.32 on epoch=5
06/16/2022 13:56:27 - INFO - __main__ - Global step 600 Train loss 0.37 Classification-F1 0.5496947755841838 on epoch=5
06/16/2022 13:56:30 - INFO - __main__ - Step 610 Global step 610 Train loss 0.38 on epoch=5
06/16/2022 13:56:33 - INFO - __main__ - Step 620 Global step 620 Train loss 0.39 on epoch=5
06/16/2022 13:56:35 - INFO - __main__ - Step 630 Global step 630 Train loss 0.37 on epoch=5
06/16/2022 13:56:38 - INFO - __main__ - Step 640 Global step 640 Train loss 0.31 on epoch=5
06/16/2022 13:56:41 - INFO - __main__ - Step 650 Global step 650 Train loss 0.32 on epoch=5
06/16/2022 13:57:39 - INFO - __main__ - Global step 650 Train loss 0.35 Classification-F1 0.6675596272309315 on epoch=5
06/16/2022 13:57:39 - INFO - __main__ - Saving model with best Classification-F1: 0.6662353420816566 -> 0.6675596272309315 on epoch=5, global_step=650
06/16/2022 13:57:42 - INFO - __main__ - Step 660 Global step 660 Train loss 0.29 on epoch=5
06/16/2022 13:57:45 - INFO - __main__ - Step 670 Global step 670 Train loss 0.35 on epoch=5
06/16/2022 13:57:48 - INFO - __main__ - Step 680 Global step 680 Train loss 0.32 on epoch=6
06/16/2022 13:57:50 - INFO - __main__ - Step 690 Global step 690 Train loss 0.32 on epoch=6
06/16/2022 13:57:53 - INFO - __main__ - Step 700 Global step 700 Train loss 0.28 on epoch=6
06/16/2022 13:58:48 - INFO - __main__ - Global step 700 Train loss 0.31 Classification-F1 0.49241563655892295 on epoch=6
06/16/2022 13:58:51 - INFO - __main__ - Step 710 Global step 710 Train loss 0.30 on epoch=6
06/16/2022 13:58:54 - INFO - __main__ - Step 720 Global step 720 Train loss 0.32 on epoch=6
06/16/2022 13:58:57 - INFO - __main__ - Step 730 Global step 730 Train loss 0.27 on epoch=6
06/16/2022 13:59:00 - INFO - __main__ - Step 740 Global step 740 Train loss 0.26 on epoch=6
06/16/2022 13:59:02 - INFO - __main__ - Step 750 Global step 750 Train loss 0.24 on epoch=6
06/16/2022 14:00:00 - INFO - __main__ - Global step 750 Train loss 0.28 Classification-F1 0.5767304555186741 on epoch=6
06/16/2022 14:00:02 - INFO - __main__ - Step 760 Global step 760 Train loss 0.30 on epoch=6
06/16/2022 14:00:05 - INFO - __main__ - Step 770 Global step 770 Train loss 0.34 on epoch=6
06/16/2022 14:00:08 - INFO - __main__ - Step 780 Global step 780 Train loss 0.29 on epoch=6
06/16/2022 14:00:11 - INFO - __main__ - Step 790 Global step 790 Train loss 0.23 on epoch=7
06/16/2022 14:00:14 - INFO - __main__ - Step 800 Global step 800 Train loss 0.15 on epoch=7
06/16/2022 14:01:19 - INFO - __main__ - Global step 800 Train loss 0.26 Classification-F1 0.5479183381077978 on epoch=7
06/16/2022 14:01:22 - INFO - __main__ - Step 810 Global step 810 Train loss 0.26 on epoch=7
06/16/2022 14:01:25 - INFO - __main__ - Step 820 Global step 820 Train loss 0.29 on epoch=7
06/16/2022 14:01:28 - INFO - __main__ - Step 830 Global step 830 Train loss 0.24 on epoch=7
06/16/2022 14:01:31 - INFO - __main__ - Step 840 Global step 840 Train loss 0.34 on epoch=7
06/16/2022 14:01:34 - INFO - __main__ - Step 850 Global step 850 Train loss 0.19 on epoch=7
06/16/2022 14:02:33 - INFO - __main__ - Global step 850 Train loss 0.26 Classification-F1 0.6011189293763007 on epoch=7
06/16/2022 14:02:36 - INFO - __main__ - Step 860 Global step 860 Train loss 0.21 on epoch=7
06/16/2022 14:02:39 - INFO - __main__ - Step 870 Global step 870 Train loss 0.17 on epoch=7
06/16/2022 14:02:42 - INFO - __main__ - Step 880 Global step 880 Train loss 0.28 on epoch=7
06/16/2022 14:02:46 - INFO - __main__ - Step 890 Global step 890 Train loss 0.20 on epoch=7
06/16/2022 14:02:49 - INFO - __main__ - Step 900 Global step 900 Train loss 0.20 on epoch=8
06/16/2022 14:03:50 - INFO - __main__ - Global step 900 Train loss 0.21 Classification-F1 0.5935210500727391 on epoch=8
06/16/2022 14:03:53 - INFO - __main__ - Step 910 Global step 910 Train loss 0.22 on epoch=8
06/16/2022 14:03:56 - INFO - __main__ - Step 920 Global step 920 Train loss 0.16 on epoch=8
06/16/2022 14:03:59 - INFO - __main__ - Step 930 Global step 930 Train loss 0.36 on epoch=8
06/16/2022 14:04:02 - INFO - __main__ - Step 940 Global step 940 Train loss 0.14 on epoch=8
06/16/2022 14:04:04 - INFO - __main__ - Step 950 Global step 950 Train loss 0.34 on epoch=8
06/16/2022 14:05:03 - INFO - __main__ - Global step 950 Train loss 0.24 Classification-F1 0.5176171987926282 on epoch=8
06/16/2022 14:05:06 - INFO - __main__ - Step 960 Global step 960 Train loss 0.19 on epoch=8
06/16/2022 14:05:09 - INFO - __main__ - Step 970 Global step 970 Train loss 0.27 on epoch=8
06/16/2022 14:05:12 - INFO - __main__ - Step 980 Global step 980 Train loss 0.18 on epoch=8
06/16/2022 14:05:15 - INFO - __main__ - Step 990 Global step 990 Train loss 0.24 on epoch=8
06/16/2022 14:05:18 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.15 on epoch=8
06/16/2022 14:06:27 - INFO - __main__ - Global step 1000 Train loss 0.21 Classification-F1 0.6288341497553992 on epoch=8
06/16/2022 14:06:30 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.18 on epoch=9
06/16/2022 14:06:33 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.15 on epoch=9
06/16/2022 14:06:36 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.14 on epoch=9
06/16/2022 14:06:39 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.27 on epoch=9
06/16/2022 14:06:42 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.12 on epoch=9
06/16/2022 14:07:51 - INFO - __main__ - Global step 1050 Train loss 0.17 Classification-F1 0.7193857129195947 on epoch=9
06/16/2022 14:07:51 - INFO - __main__ - Saving model with best Classification-F1: 0.6675596272309315 -> 0.7193857129195947 on epoch=9, global_step=1050
06/16/2022 14:07:54 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.22 on epoch=9
06/16/2022 14:07:57 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.19 on epoch=9
06/16/2022 14:08:00 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.23 on epoch=9
06/16/2022 14:08:03 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.17 on epoch=9
06/16/2022 14:08:06 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.16 on epoch=9
06/16/2022 14:09:11 - INFO - __main__ - Global step 1100 Train loss 0.19 Classification-F1 0.6062046063448299 on epoch=9
06/16/2022 14:09:14 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.15 on epoch=9
06/16/2022 14:09:17 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.25 on epoch=9
06/16/2022 14:09:20 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.09 on epoch=10
06/16/2022 14:09:23 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.13 on epoch=10
06/16/2022 14:09:26 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.16 on epoch=10
06/16/2022 14:10:21 - INFO - __main__ - Global step 1150 Train loss 0.15 Classification-F1 0.6986662061905192 on epoch=10
06/16/2022 14:10:24 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.14 on epoch=10
06/16/2022 14:10:27 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.14 on epoch=10
06/16/2022 14:10:30 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.17 on epoch=10
06/16/2022 14:10:32 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.14 on epoch=10
06/16/2022 14:10:35 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.16 on epoch=10
06/16/2022 14:11:32 - INFO - __main__ - Global step 1200 Train loss 0.15 Classification-F1 0.5896330633448053 on epoch=10
06/16/2022 14:11:35 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.17 on epoch=10
06/16/2022 14:11:38 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.19 on epoch=10
06/16/2022 14:11:41 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.13 on epoch=10
06/16/2022 14:11:44 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.16 on epoch=11
06/16/2022 14:11:46 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.12 on epoch=11
06/16/2022 14:12:44 - INFO - __main__ - Global step 1250 Train loss 0.15 Classification-F1 0.7451483613781275 on epoch=11
06/16/2022 14:12:44 - INFO - __main__ - Saving model with best Classification-F1: 0.7193857129195947 -> 0.7451483613781275 on epoch=11, global_step=1250
06/16/2022 14:12:47 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.16 on epoch=11
06/16/2022 14:12:49 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.15 on epoch=11
06/16/2022 14:12:52 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.09 on epoch=11
06/16/2022 14:12:55 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.13 on epoch=11
06/16/2022 14:12:58 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.14 on epoch=11
06/16/2022 14:13:57 - INFO - __main__ - Global step 1300 Train loss 0.13 Classification-F1 0.6543180018133773 on epoch=11
06/16/2022 14:14:00 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.13 on epoch=11
06/16/2022 14:14:03 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.17 on epoch=11
06/16/2022 14:14:06 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.15 on epoch=11
06/16/2022 14:14:09 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.10 on epoch=11
06/16/2022 14:14:11 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.09 on epoch=12
06/16/2022 14:15:09 - INFO - __main__ - Global step 1350 Train loss 0.13 Classification-F1 0.6943597552319937 on epoch=12
06/16/2022 14:15:12 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.07 on epoch=12
06/16/2022 14:15:14 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.18 on epoch=12
06/16/2022 14:15:17 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.13 on epoch=12
06/16/2022 14:15:20 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.09 on epoch=12
06/16/2022 14:15:23 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.15 on epoch=12
06/16/2022 14:16:20 - INFO - __main__ - Global step 1400 Train loss 0.12 Classification-F1 0.6252290195226193 on epoch=12
06/16/2022 14:16:23 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.11 on epoch=12
06/16/2022 14:16:25 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.11 on epoch=12
06/16/2022 14:16:28 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.12 on epoch=12
06/16/2022 14:16:31 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.28 on epoch=12
06/16/2022 14:16:34 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.12 on epoch=12
06/16/2022 14:17:31 - INFO - __main__ - Global step 1450 Train loss 0.15 Classification-F1 0.70619836374446 on epoch=12
06/16/2022 14:17:34 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.09 on epoch=13
06/16/2022 14:17:37 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.15 on epoch=13
06/16/2022 14:17:39 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.10 on epoch=13
06/16/2022 14:17:42 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.16 on epoch=13
06/16/2022 14:17:45 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.08 on epoch=13
06/16/2022 14:18:41 - INFO - __main__ - Global step 1500 Train loss 0.12 Classification-F1 0.7471111757765605 on epoch=13
06/16/2022 14:18:41 - INFO - __main__ - Saving model with best Classification-F1: 0.7451483613781275 -> 0.7471111757765605 on epoch=13, global_step=1500
06/16/2022 14:18:44 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.17 on epoch=13
06/16/2022 14:18:47 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.10 on epoch=13
06/16/2022 14:18:50 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.13 on epoch=13
06/16/2022 14:18:53 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.07 on epoch=13
06/16/2022 14:18:55 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.17 on epoch=13
06/16/2022 14:19:54 - INFO - __main__ - Global step 1550 Train loss 0.13 Classification-F1 0.6765802905371818 on epoch=13
06/16/2022 14:19:56 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.12 on epoch=13
06/16/2022 14:19:59 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.04 on epoch=14
06/16/2022 14:20:02 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.09 on epoch=14
06/16/2022 14:20:05 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.10 on epoch=14
06/16/2022 14:20:08 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.17 on epoch=14
06/16/2022 14:21:03 - INFO - __main__ - Global step 1600 Train loss 0.10 Classification-F1 0.7815618470246334 on epoch=14
06/16/2022 14:21:03 - INFO - __main__ - Saving model with best Classification-F1: 0.7471111757765605 -> 0.7815618470246334 on epoch=14, global_step=1600
06/16/2022 14:21:06 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.06 on epoch=14
06/16/2022 14:21:09 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.10 on epoch=14
06/16/2022 14:21:12 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.09 on epoch=14
06/16/2022 14:21:14 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.10 on epoch=14
06/16/2022 14:21:17 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.07 on epoch=14
06/16/2022 14:22:12 - INFO - __main__ - Global step 1650 Train loss 0.08 Classification-F1 0.7923568220561199 on epoch=14
06/16/2022 14:22:12 - INFO - __main__ - Saving model with best Classification-F1: 0.7815618470246334 -> 0.7923568220561199 on epoch=14, global_step=1650
06/16/2022 14:22:15 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.16 on epoch=14
06/16/2022 14:22:18 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.06 on epoch=14
06/16/2022 14:22:21 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.07 on epoch=14
06/16/2022 14:22:24 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.05 on epoch=15
06/16/2022 14:22:27 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.06 on epoch=15
06/16/2022 14:23:23 - INFO - __main__ - Global step 1700 Train loss 0.08 Classification-F1 0.8102614221407464 on epoch=15
06/16/2022 14:23:23 - INFO - __main__ - Saving model with best Classification-F1: 0.7923568220561199 -> 0.8102614221407464 on epoch=15, global_step=1700
06/16/2022 14:23:26 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.17 on epoch=15
06/16/2022 14:23:29 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.05 on epoch=15
06/16/2022 14:23:31 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.08 on epoch=15
06/16/2022 14:23:34 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.14 on epoch=15
06/16/2022 14:23:37 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.09 on epoch=15
06/16/2022 14:24:32 - INFO - __main__ - Global step 1750 Train loss 0.11 Classification-F1 0.7407835826148199 on epoch=15
06/16/2022 14:24:35 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.07 on epoch=15
06/16/2022 14:24:38 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.09 on epoch=15
06/16/2022 14:24:40 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.16 on epoch=15
06/16/2022 14:24:43 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.11 on epoch=15
06/16/2022 14:24:46 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=16
06/16/2022 14:25:41 - INFO - __main__ - Global step 1800 Train loss 0.09 Classification-F1 0.7645139440058243 on epoch=16
06/16/2022 14:25:44 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.06 on epoch=16
06/16/2022 14:25:47 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.16 on epoch=16
06/16/2022 14:25:50 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.06 on epoch=16
06/16/2022 14:25:53 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.08 on epoch=16
06/16/2022 14:25:56 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.07 on epoch=16
06/16/2022 14:26:53 - INFO - __main__ - Global step 1850 Train loss 0.09 Classification-F1 0.6526634501303018 on epoch=16
06/16/2022 14:26:56 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.03 on epoch=16
06/16/2022 14:26:58 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.17 on epoch=16
06/16/2022 14:27:01 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.11 on epoch=16
06/16/2022 14:27:04 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.08 on epoch=16
06/16/2022 14:27:07 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.10 on epoch=16
06/16/2022 14:28:07 - INFO - __main__ - Global step 1900 Train loss 0.10 Classification-F1 0.8122486531902138 on epoch=16
06/16/2022 14:28:07 - INFO - __main__ - Saving model with best Classification-F1: 0.8102614221407464 -> 0.8122486531902138 on epoch=16, global_step=1900
06/16/2022 14:28:10 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.04 on epoch=17
06/16/2022 14:28:12 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=17
06/16/2022 14:28:15 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.08 on epoch=17
06/16/2022 14:28:18 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.10 on epoch=17
06/16/2022 14:28:21 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.06 on epoch=17
06/16/2022 14:29:19 - INFO - __main__ - Global step 1950 Train loss 0.06 Classification-F1 0.913184102664539 on epoch=17
06/16/2022 14:29:19 - INFO - __main__ - Saving model with best Classification-F1: 0.8122486531902138 -> 0.913184102664539 on epoch=17, global_step=1950
06/16/2022 14:29:22 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.16 on epoch=17
06/16/2022 14:29:25 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.06 on epoch=17
06/16/2022 14:29:27 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.06 on epoch=17
06/16/2022 14:29:30 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.04 on epoch=17
06/16/2022 14:29:33 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.22 on epoch=17
06/16/2022 14:30:31 - INFO - __main__ - Global step 2000 Train loss 0.11 Classification-F1 0.7225936485018034 on epoch=17
06/16/2022 14:30:34 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.07 on epoch=17
06/16/2022 14:30:37 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.05 on epoch=18
06/16/2022 14:30:40 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.03 on epoch=18
06/16/2022 14:30:43 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=18
06/16/2022 14:30:45 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.13 on epoch=18
06/16/2022 14:31:43 - INFO - __main__ - Global step 2050 Train loss 0.06 Classification-F1 0.7258670711138234 on epoch=18
06/16/2022 14:31:46 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.06 on epoch=18
06/16/2022 14:31:48 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.15 on epoch=18
06/16/2022 14:31:51 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.12 on epoch=18
06/16/2022 14:31:54 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.11 on epoch=18
06/16/2022 14:31:57 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=18
06/16/2022 14:32:49 - INFO - __main__ - Global step 2100 Train loss 0.10 Classification-F1 0.9153705553969845 on epoch=18
06/16/2022 14:32:49 - INFO - __main__ - Saving model with best Classification-F1: 0.913184102664539 -> 0.9153705553969845 on epoch=18, global_step=2100
06/16/2022 14:32:52 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.18 on epoch=18
06/16/2022 14:32:55 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.05 on epoch=18
06/16/2022 14:32:58 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.06 on epoch=19
06/16/2022 14:33:00 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.04 on epoch=19
06/16/2022 14:33:03 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=19
06/16/2022 14:33:55 - INFO - __main__ - Global step 2150 Train loss 0.07 Classification-F1 0.7631539565121621 on epoch=19
06/16/2022 14:33:58 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.13 on epoch=19
06/16/2022 14:34:01 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.06 on epoch=19
06/16/2022 14:34:04 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.12 on epoch=19
06/16/2022 14:34:07 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.06 on epoch=19
06/16/2022 14:34:09 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.03 on epoch=19
06/16/2022 14:35:05 - INFO - __main__ - Global step 2200 Train loss 0.08 Classification-F1 0.8048918572871087 on epoch=19
06/16/2022 14:35:08 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.03 on epoch=19
06/16/2022 14:35:10 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.10 on epoch=19
06/16/2022 14:35:13 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.12 on epoch=19
06/16/2022 14:35:16 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.07 on epoch=19
06/16/2022 14:35:19 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.04 on epoch=20
06/16/2022 14:36:11 - INFO - __main__ - Global step 2250 Train loss 0.07 Classification-F1 0.6458818099322104 on epoch=20
06/16/2022 14:36:13 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.06 on epoch=20
06/16/2022 14:36:16 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.09 on epoch=20
06/16/2022 14:36:19 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=20
06/16/2022 14:36:22 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.08 on epoch=20
06/16/2022 14:36:25 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.06 on epoch=20
06/16/2022 14:37:20 - INFO - __main__ - Global step 2300 Train loss 0.07 Classification-F1 0.642442744130207 on epoch=20
06/16/2022 14:37:23 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.07 on epoch=20
06/16/2022 14:37:25 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.04 on epoch=20
06/16/2022 14:37:28 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.07 on epoch=20
06/16/2022 14:37:31 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.12 on epoch=20
06/16/2022 14:37:34 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.04 on epoch=20
06/16/2022 14:38:27 - INFO - __main__ - Global step 2350 Train loss 0.07 Classification-F1 0.8481398502576057 on epoch=20
06/16/2022 14:38:30 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=21
06/16/2022 14:38:33 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.03 on epoch=21
06/16/2022 14:38:35 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.16 on epoch=21
06/16/2022 14:38:38 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.09 on epoch=21
06/16/2022 14:38:41 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.06 on epoch=21
06/16/2022 14:39:36 - INFO - __main__ - Global step 2400 Train loss 0.07 Classification-F1 0.8542327245521306 on epoch=21
06/16/2022 14:39:39 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.13 on epoch=21
06/16/2022 14:39:41 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.04 on epoch=21
06/16/2022 14:39:44 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.05 on epoch=21
06/16/2022 14:39:47 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.07 on epoch=21
06/16/2022 14:39:50 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.09 on epoch=21
06/16/2022 14:40:46 - INFO - __main__ - Global step 2450 Train loss 0.07 Classification-F1 0.9195311904603184 on epoch=21
06/16/2022 14:40:46 - INFO - __main__ - Saving model with best Classification-F1: 0.9153705553969845 -> 0.9195311904603184 on epoch=21, global_step=2450
06/16/2022 14:40:49 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.06 on epoch=21
06/16/2022 14:40:52 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.04 on epoch=22
06/16/2022 14:40:54 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.03 on epoch=22
06/16/2022 14:40:57 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.08 on epoch=22
06/16/2022 14:41:00 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.05 on epoch=22
06/16/2022 14:41:51 - INFO - __main__ - Global step 2500 Train loss 0.05 Classification-F1 0.8122647185535201 on epoch=22
06/16/2022 14:41:54 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.06 on epoch=22
06/16/2022 14:41:57 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.05 on epoch=22
06/16/2022 14:41:59 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.04 on epoch=22
06/16/2022 14:42:02 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.05 on epoch=22
06/16/2022 14:42:05 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=22
06/16/2022 14:43:08 - INFO - __main__ - Global step 2550 Train loss 0.05 Classification-F1 0.9163120690868719 on epoch=22
06/16/2022 14:43:11 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.13 on epoch=22
06/16/2022 14:43:14 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.07 on epoch=22
06/16/2022 14:43:17 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.03 on epoch=23
06/16/2022 14:43:20 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.08 on epoch=23
06/16/2022 14:43:23 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=23
06/16/2022 14:44:27 - INFO - __main__ - Global step 2600 Train loss 0.06 Classification-F1 0.9216003217507189 on epoch=23
06/16/2022 14:44:28 - INFO - __main__ - Saving model with best Classification-F1: 0.9195311904603184 -> 0.9216003217507189 on epoch=23, global_step=2600
06/16/2022 14:44:30 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.11 on epoch=23
06/16/2022 14:44:33 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.10 on epoch=23
06/16/2022 14:44:36 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.05 on epoch=23
06/16/2022 14:44:39 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.14 on epoch=23
06/16/2022 14:44:41 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.06 on epoch=23
06/16/2022 14:45:35 - INFO - __main__ - Global step 2650 Train loss 0.09 Classification-F1 0.8642545285831295 on epoch=23
06/16/2022 14:45:38 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=23
06/16/2022 14:45:41 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.13 on epoch=23
06/16/2022 14:45:44 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.04 on epoch=23
06/16/2022 14:45:46 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=24
06/16/2022 14:45:49 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.03 on epoch=24
06/16/2022 14:46:41 - INFO - __main__ - Global step 2700 Train loss 0.05 Classification-F1 0.9216056049291482 on epoch=24
06/16/2022 14:46:41 - INFO - __main__ - Saving model with best Classification-F1: 0.9216003217507189 -> 0.9216056049291482 on epoch=24, global_step=2700
06/16/2022 14:46:44 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=24
06/16/2022 14:46:46 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.11 on epoch=24
06/16/2022 14:46:49 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=24
06/16/2022 14:46:52 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.06 on epoch=24
06/16/2022 14:46:54 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.10 on epoch=24
06/16/2022 14:47:48 - INFO - __main__ - Global step 2750 Train loss 0.06 Classification-F1 0.6865680795570778 on epoch=24
06/16/2022 14:47:50 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.09 on epoch=24
06/16/2022 14:47:53 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.03 on epoch=24
06/16/2022 14:47:56 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.09 on epoch=24
06/16/2022 14:47:59 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.09 on epoch=24
06/16/2022 14:48:02 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.04 on epoch=24
06/16/2022 14:49:00 - INFO - __main__ - Global step 2800 Train loss 0.07 Classification-F1 0.8608258723530935 on epoch=24
06/16/2022 14:49:02 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=25
06/16/2022 14:49:05 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.03 on epoch=25
06/16/2022 14:49:08 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.05 on epoch=25
06/16/2022 14:49:10 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=25
06/16/2022 14:49:13 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.07 on epoch=25
06/16/2022 14:50:10 - INFO - __main__ - Global step 2850 Train loss 0.04 Classification-F1 0.9192114206841774 on epoch=25
06/16/2022 14:50:13 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.03 on epoch=25
06/16/2022 14:50:16 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.05 on epoch=25
06/16/2022 14:50:19 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=25
06/16/2022 14:50:21 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.08 on epoch=25
06/16/2022 14:50:24 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.05 on epoch=25
06/16/2022 14:51:19 - INFO - __main__ - Global step 2900 Train loss 0.05 Classification-F1 0.9216023168845294 on epoch=25
06/16/2022 14:51:22 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.07 on epoch=25
06/16/2022 14:51:25 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=26
06/16/2022 14:51:27 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=26
06/16/2022 14:51:30 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.07 on epoch=26
06/16/2022 14:51:33 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.08 on epoch=26
06/16/2022 14:52:27 - INFO - __main__ - Global step 2950 Train loss 0.05 Classification-F1 0.9871613647176414 on epoch=26
06/16/2022 14:52:27 - INFO - __main__ - Saving model with best Classification-F1: 0.9216056049291482 -> 0.9871613647176414 on epoch=26, global_step=2950
06/16/2022 14:52:30 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.07 on epoch=26
06/16/2022 14:52:32 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.03 on epoch=26
06/16/2022 14:52:35 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=26
06/16/2022 14:52:38 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.03 on epoch=26
06/16/2022 14:52:40 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.04 on epoch=26
06/16/2022 14:52:42 - INFO - __main__ - Start tokenizing ... 1792 instances
06/16/2022 14:52:42 - INFO - __main__ - Printing 3 examples
06/16/2022 14:52:42 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/16/2022 14:52:42 - INFO - __main__ - ['Animal']
06/16/2022 14:52:42 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/16/2022 14:52:42 - INFO - __main__ - ['Animal']
06/16/2022 14:52:42 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
06/16/2022 14:52:42 - INFO - __main__ - ['Animal']
06/16/2022 14:52:42 - INFO - __main__ - Tokenizing Input ...
06/16/2022 14:52:43 - INFO - __main__ - Tokenizing Output ...
06/16/2022 14:52:45 - INFO - __main__ - Loaded 1792 examples from train data
06/16/2022 14:52:45 - INFO - __main__ - Start tokenizing ... 1792 instances
06/16/2022 14:52:45 - INFO - __main__ - Printing 3 examples
06/16/2022 14:52:45 - INFO - __main__ -  [dbpedia_14] The Andaman Treepie (Dendrocitta bayleyi) is a species of bird in the Corvidae family.It is endemic to the Andaman Islands of India.Its natural habitat is subtropical or tropical moist lowland forests. It is threatened by habitat loss.The scientific name commemorates the Anglo-Indian statesman Edward Clive Bayley.
06/16/2022 14:52:45 - INFO - __main__ - ['Animal']
06/16/2022 14:52:45 - INFO - __main__ -  [dbpedia_14] Ethmia tyranthes is a moth in the Ethmiidae family. It is found in the Democratic Republic of Congo.
06/16/2022 14:52:45 - INFO - __main__ - ['Animal']
06/16/2022 14:52:45 - INFO - __main__ -  [dbpedia_14] Van Son’s Brown (Stygionympha vansoni) is a butterfly of the Nymphalidae family. It is found in South Africa in the northern Cape from the Kamiesberg to the Springbok area.The wingspan is 36–38 mm for males and 38–40 mm for females. Adults are on wing from August to October. There is one generation per year.The larvae probably feed on Poaceae grasses.
06/16/2022 14:52:45 - INFO - __main__ - ['Animal']
06/16/2022 14:52:45 - INFO - __main__ - Tokenizing Input ...
06/16/2022 14:52:46 - INFO - __main__ - Tokenizing Output ...
06/16/2022 14:52:48 - INFO - __main__ - Loaded 1792 examples from dev data
06/16/2022 14:53:08 - INFO - __main__ - load prompt embedding from ckpt
06/16/2022 14:53:09 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/16/2022 14:53:09 - INFO - __main__ - Starting training!
06/16/2022 14:53:34 - INFO - __main__ - Global step 3000 Train loss 0.04 Classification-F1 0.914799169615635 on epoch=26
06/16/2022 14:53:35 - INFO - __main__ - save last model!
06/16/2022 14:53:35 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/16/2022 14:53:35 - INFO - __main__ - Start tokenizing ... 3500 instances
06/16/2022 14:53:35 - INFO - __main__ - Printing 3 examples
06/16/2022 14:53:35 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/16/2022 14:53:35 - INFO - __main__ - ['Animal']
06/16/2022 14:53:35 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/16/2022 14:53:35 - INFO - __main__ - ['Animal']
06/16/2022 14:53:35 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/16/2022 14:53:35 - INFO - __main__ - ['Village']
06/16/2022 14:53:35 - INFO - __main__ - Tokenizing Input ...
06/16/2022 14:53:37 - INFO - __main__ - Tokenizing Output ...
06/16/2022 14:53:42 - INFO - __main__ - Loaded 3500 examples from test data
06/16/2022 14:55:51 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down128shot/singletask-dbpedia_14/dbpedia_14_128_13_0.4_8_predictions.txt
06/16/2022 14:55:51 - INFO - __main__ - Classification-F1 on test data: 0.7225
06/16/2022 14:55:51 - INFO - __main__ - prefix=dbpedia_14_128_13, lr=0.4, bsz=8, dev_performance=0.9871613647176414, test_performance=0.7225357611239405
06/16/2022 14:55:51 - INFO - __main__ - Running ... prefix=dbpedia_14_128_13, lr=0.3, bsz=8 ...
06/16/2022 14:55:52 - INFO - __main__ - Start tokenizing ... 1792 instances
06/16/2022 14:55:52 - INFO - __main__ - Printing 3 examples
06/16/2022 14:55:52 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/16/2022 14:55:52 - INFO - __main__ - ['Animal']
06/16/2022 14:55:52 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/16/2022 14:55:52 - INFO - __main__ - ['Animal']
06/16/2022 14:55:52 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
06/16/2022 14:55:52 - INFO - __main__ - ['Animal']
06/16/2022 14:55:52 - INFO - __main__ - Tokenizing Input ...
06/16/2022 14:55:54 - INFO - __main__ - Tokenizing Output ...
06/16/2022 14:55:56 - INFO - __main__ - Loaded 1792 examples from train data
06/16/2022 14:55:56 - INFO - __main__ - Start tokenizing ... 1792 instances
06/16/2022 14:55:56 - INFO - __main__ - Printing 3 examples
06/16/2022 14:55:56 - INFO - __main__ -  [dbpedia_14] The Andaman Treepie (Dendrocitta bayleyi) is a species of bird in the Corvidae family.It is endemic to the Andaman Islands of India.Its natural habitat is subtropical or tropical moist lowland forests. It is threatened by habitat loss.The scientific name commemorates the Anglo-Indian statesman Edward Clive Bayley.
06/16/2022 14:55:56 - INFO - __main__ - ['Animal']
06/16/2022 14:55:56 - INFO - __main__ -  [dbpedia_14] Ethmia tyranthes is a moth in the Ethmiidae family. It is found in the Democratic Republic of Congo.
06/16/2022 14:55:56 - INFO - __main__ - ['Animal']
06/16/2022 14:55:56 - INFO - __main__ -  [dbpedia_14] Van Son’s Brown (Stygionympha vansoni) is a butterfly of the Nymphalidae family. It is found in South Africa in the northern Cape from the Kamiesberg to the Springbok area.The wingspan is 36–38 mm for males and 38–40 mm for females. Adults are on wing from August to October. There is one generation per year.The larvae probably feed on Poaceae grasses.
06/16/2022 14:55:56 - INFO - __main__ - ['Animal']
06/16/2022 14:55:56 - INFO - __main__ - Tokenizing Input ...
06/16/2022 14:55:58 - INFO - __main__ - Tokenizing Output ...
06/16/2022 14:56:00 - INFO - __main__ - Loaded 1792 examples from dev data
06/16/2022 14:56:19 - INFO - __main__ - load prompt embedding from ckpt
06/16/2022 14:56:20 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/16/2022 14:56:20 - INFO - __main__ - Starting training!
06/16/2022 14:56:24 - INFO - __main__ - Step 10 Global step 10 Train loss 4.83 on epoch=0
06/16/2022 14:56:27 - INFO - __main__ - Step 20 Global step 20 Train loss 3.40 on epoch=0
06/16/2022 14:56:29 - INFO - __main__ - Step 30 Global step 30 Train loss 2.42 on epoch=0
06/16/2022 14:56:32 - INFO - __main__ - Step 40 Global step 40 Train loss 1.99 on epoch=0
06/16/2022 14:56:35 - INFO - __main__ - Step 50 Global step 50 Train loss 1.71 on epoch=0
06/16/2022 14:57:19 - INFO - __main__ - Global step 50 Train loss 2.87 Classification-F1 0.1006430727385248 on epoch=0
06/16/2022 14:57:19 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.1006430727385248 on epoch=0, global_step=50
06/16/2022 14:57:22 - INFO - __main__ - Step 60 Global step 60 Train loss 1.34 on epoch=0
06/16/2022 14:57:25 - INFO - __main__ - Step 70 Global step 70 Train loss 1.04 on epoch=0
06/16/2022 14:57:28 - INFO - __main__ - Step 80 Global step 80 Train loss 1.06 on epoch=0
06/16/2022 14:57:31 - INFO - __main__ - Step 90 Global step 90 Train loss 0.96 on epoch=0
06/16/2022 14:57:34 - INFO - __main__ - Step 100 Global step 100 Train loss 0.81 on epoch=0
06/16/2022 14:58:22 - INFO - __main__ - Global step 100 Train loss 1.04 Classification-F1 0.38386316204163073 on epoch=0
06/16/2022 14:58:22 - INFO - __main__ - Saving model with best Classification-F1: 0.1006430727385248 -> 0.38386316204163073 on epoch=0, global_step=100
06/16/2022 14:58:26 - INFO - __main__ - Step 110 Global step 110 Train loss 0.77 on epoch=0
06/16/2022 14:58:29 - INFO - __main__ - Step 120 Global step 120 Train loss 0.71 on epoch=1
06/16/2022 14:58:32 - INFO - __main__ - Step 130 Global step 130 Train loss 0.58 on epoch=1
06/16/2022 14:58:35 - INFO - __main__ - Step 140 Global step 140 Train loss 0.60 on epoch=1
06/16/2022 14:58:38 - INFO - __main__ - Step 150 Global step 150 Train loss 0.53 on epoch=1
06/16/2022 14:59:27 - INFO - __main__ - Global step 150 Train loss 0.64 Classification-F1 0.438742466450207 on epoch=1
06/16/2022 14:59:27 - INFO - __main__ - Saving model with best Classification-F1: 0.38386316204163073 -> 0.438742466450207 on epoch=1, global_step=150
06/16/2022 14:59:30 - INFO - __main__ - Step 160 Global step 160 Train loss 0.63 on epoch=1
06/16/2022 14:59:33 - INFO - __main__ - Step 170 Global step 170 Train loss 0.59 on epoch=1
06/16/2022 14:59:36 - INFO - __main__ - Step 180 Global step 180 Train loss 0.47 on epoch=1
06/16/2022 14:59:39 - INFO - __main__ - Step 190 Global step 190 Train loss 0.46 on epoch=1
06/16/2022 14:59:42 - INFO - __main__ - Step 200 Global step 200 Train loss 0.40 on epoch=1
06/16/2022 15:00:34 - INFO - __main__ - Global step 200 Train loss 0.51 Classification-F1 0.47402261297175213 on epoch=1
06/16/2022 15:00:34 - INFO - __main__ - Saving model with best Classification-F1: 0.438742466450207 -> 0.47402261297175213 on epoch=1, global_step=200
06/16/2022 15:00:37 - INFO - __main__ - Step 210 Global step 210 Train loss 0.54 on epoch=1
06/16/2022 15:00:40 - INFO - __main__ - Step 220 Global step 220 Train loss 0.54 on epoch=1
06/16/2022 15:00:42 - INFO - __main__ - Step 230 Global step 230 Train loss 0.46 on epoch=2
06/16/2022 15:00:45 - INFO - __main__ - Step 240 Global step 240 Train loss 0.31 on epoch=2
06/16/2022 15:00:48 - INFO - __main__ - Step 250 Global step 250 Train loss 0.33 on epoch=2
06/16/2022 15:01:49 - INFO - __main__ - Global step 250 Train loss 0.44 Classification-F1 0.5418634675226051 on epoch=2
06/16/2022 15:01:49 - INFO - __main__ - Saving model with best Classification-F1: 0.47402261297175213 -> 0.5418634675226051 on epoch=2, global_step=250
06/16/2022 15:01:52 - INFO - __main__ - Step 260 Global step 260 Train loss 0.39 on epoch=2
06/16/2022 15:01:55 - INFO - __main__ - Step 270 Global step 270 Train loss 0.33 on epoch=2
06/16/2022 15:01:58 - INFO - __main__ - Step 280 Global step 280 Train loss 0.37 on epoch=2
06/16/2022 15:02:01 - INFO - __main__ - Step 290 Global step 290 Train loss 0.31 on epoch=2
06/16/2022 15:02:04 - INFO - __main__ - Step 300 Global step 300 Train loss 0.34 on epoch=2
06/16/2022 15:02:58 - INFO - __main__ - Global step 300 Train loss 0.35 Classification-F1 0.4570849554102663 on epoch=2
06/16/2022 15:03:01 - INFO - __main__ - Step 310 Global step 310 Train loss 0.31 on epoch=2
06/16/2022 15:03:04 - INFO - __main__ - Step 320 Global step 320 Train loss 0.42 on epoch=2
06/16/2022 15:03:07 - INFO - __main__ - Step 330 Global step 330 Train loss 0.32 on epoch=2
06/16/2022 15:03:10 - INFO - __main__ - Step 340 Global step 340 Train loss 0.24 on epoch=3
06/16/2022 15:03:13 - INFO - __main__ - Step 350 Global step 350 Train loss 0.22 on epoch=3
06/16/2022 15:04:13 - INFO - __main__ - Global step 350 Train loss 0.30 Classification-F1 0.5641942028362812 on epoch=3
06/16/2022 15:04:13 - INFO - __main__ - Saving model with best Classification-F1: 0.5418634675226051 -> 0.5641942028362812 on epoch=3, global_step=350
06/16/2022 15:04:15 - INFO - __main__ - Step 360 Global step 360 Train loss 0.19 on epoch=3
06/16/2022 15:04:18 - INFO - __main__ - Step 370 Global step 370 Train loss 0.31 on epoch=3
06/16/2022 15:04:21 - INFO - __main__ - Step 380 Global step 380 Train loss 0.22 on epoch=3
06/16/2022 15:04:24 - INFO - __main__ - Step 390 Global step 390 Train loss 0.29 on epoch=3
06/16/2022 15:04:27 - INFO - __main__ - Step 400 Global step 400 Train loss 0.17 on epoch=3
06/16/2022 15:05:33 - INFO - __main__ - Global step 400 Train loss 0.24 Classification-F1 0.5861658079517267 on epoch=3
06/16/2022 15:05:33 - INFO - __main__ - Saving model with best Classification-F1: 0.5641942028362812 -> 0.5861658079517267 on epoch=3, global_step=400
06/16/2022 15:05:36 - INFO - __main__ - Step 410 Global step 410 Train loss 0.24 on epoch=3
06/16/2022 15:05:39 - INFO - __main__ - Step 420 Global step 420 Train loss 0.26 on epoch=3
06/16/2022 15:05:41 - INFO - __main__ - Step 430 Global step 430 Train loss 0.34 on epoch=3
06/16/2022 15:05:44 - INFO - __main__ - Step 440 Global step 440 Train loss 0.22 on epoch=3
06/16/2022 15:05:47 - INFO - __main__ - Step 450 Global step 450 Train loss 0.20 on epoch=4
06/16/2022 15:06:54 - INFO - __main__ - Global step 450 Train loss 0.25 Classification-F1 0.7111534136954996 on epoch=4
06/16/2022 15:06:54 - INFO - __main__ - Saving model with best Classification-F1: 0.5861658079517267 -> 0.7111534136954996 on epoch=4, global_step=450
06/16/2022 15:06:56 - INFO - __main__ - Step 460 Global step 460 Train loss 0.18 on epoch=4
06/16/2022 15:06:59 - INFO - __main__ - Step 470 Global step 470 Train loss 0.15 on epoch=4
06/16/2022 15:07:02 - INFO - __main__ - Step 480 Global step 480 Train loss 0.22 on epoch=4
06/16/2022 15:07:05 - INFO - __main__ - Step 490 Global step 490 Train loss 0.20 on epoch=4
06/16/2022 15:07:08 - INFO - __main__ - Step 500 Global step 500 Train loss 0.23 on epoch=4
06/16/2022 15:08:15 - INFO - __main__ - Global step 500 Train loss 0.19 Classification-F1 0.5351177337871116 on epoch=4
06/16/2022 15:08:18 - INFO - __main__ - Step 510 Global step 510 Train loss 0.19 on epoch=4
06/16/2022 15:08:21 - INFO - __main__ - Step 520 Global step 520 Train loss 0.17 on epoch=4
06/16/2022 15:08:23 - INFO - __main__ - Step 530 Global step 530 Train loss 0.20 on epoch=4
06/16/2022 15:08:26 - INFO - __main__ - Step 540 Global step 540 Train loss 0.26 on epoch=4
06/16/2022 15:08:29 - INFO - __main__ - Step 550 Global step 550 Train loss 0.20 on epoch=4
06/16/2022 15:09:32 - INFO - __main__ - Global step 550 Train loss 0.20 Classification-F1 0.6435186019398098 on epoch=4
06/16/2022 15:09:35 - INFO - __main__ - Step 560 Global step 560 Train loss 0.20 on epoch=4
06/16/2022 15:09:37 - INFO - __main__ - Step 570 Global step 570 Train loss 0.17 on epoch=5
06/16/2022 15:09:40 - INFO - __main__ - Step 580 Global step 580 Train loss 0.16 on epoch=5
06/16/2022 15:09:43 - INFO - __main__ - Step 590 Global step 590 Train loss 0.18 on epoch=5
06/16/2022 15:09:46 - INFO - __main__ - Step 600 Global step 600 Train loss 0.15 on epoch=5
06/16/2022 15:10:48 - INFO - __main__ - Global step 600 Train loss 0.17 Classification-F1 0.6599756741747571 on epoch=5
06/16/2022 15:10:51 - INFO - __main__ - Step 610 Global step 610 Train loss 0.18 on epoch=5
06/16/2022 15:10:53 - INFO - __main__ - Step 620 Global step 620 Train loss 0.21 on epoch=5
06/16/2022 15:10:56 - INFO - __main__ - Step 630 Global step 630 Train loss 0.10 on epoch=5
06/16/2022 15:10:59 - INFO - __main__ - Step 640 Global step 640 Train loss 0.14 on epoch=5
06/16/2022 15:11:02 - INFO - __main__ - Step 650 Global step 650 Train loss 0.33 on epoch=5
06/16/2022 15:12:08 - INFO - __main__ - Global step 650 Train loss 0.19 Classification-F1 0.711635336540965 on epoch=5
06/16/2022 15:12:08 - INFO - __main__ - Saving model with best Classification-F1: 0.7111534136954996 -> 0.711635336540965 on epoch=5, global_step=650
06/16/2022 15:12:11 - INFO - __main__ - Step 660 Global step 660 Train loss 0.22 on epoch=5
06/16/2022 15:12:14 - INFO - __main__ - Step 670 Global step 670 Train loss 0.20 on epoch=5
06/16/2022 15:12:16 - INFO - __main__ - Step 680 Global step 680 Train loss 0.14 on epoch=6
06/16/2022 15:12:19 - INFO - __main__ - Step 690 Global step 690 Train loss 0.12 on epoch=6
06/16/2022 15:12:22 - INFO - __main__ - Step 700 Global step 700 Train loss 0.26 on epoch=6
06/16/2022 15:13:24 - INFO - __main__ - Global step 700 Train loss 0.19 Classification-F1 0.701004667010979 on epoch=6
06/16/2022 15:13:27 - INFO - __main__ - Step 710 Global step 710 Train loss 0.16 on epoch=6
06/16/2022 15:13:30 - INFO - __main__ - Step 720 Global step 720 Train loss 0.10 on epoch=6
06/16/2022 15:13:33 - INFO - __main__ - Step 730 Global step 730 Train loss 0.14 on epoch=6
06/16/2022 15:13:35 - INFO - __main__ - Step 740 Global step 740 Train loss 0.10 on epoch=6
06/16/2022 15:13:38 - INFO - __main__ - Step 750 Global step 750 Train loss 0.09 on epoch=6
06/16/2022 15:14:41 - INFO - __main__ - Global step 750 Train loss 0.12 Classification-F1 0.7569684472394678 on epoch=6
06/16/2022 15:14:41 - INFO - __main__ - Saving model with best Classification-F1: 0.711635336540965 -> 0.7569684472394678 on epoch=6, global_step=750
06/16/2022 15:14:43 - INFO - __main__ - Step 760 Global step 760 Train loss 0.15 on epoch=6
06/16/2022 15:14:46 - INFO - __main__ - Step 770 Global step 770 Train loss 0.18 on epoch=6
06/16/2022 15:14:49 - INFO - __main__ - Step 780 Global step 780 Train loss 0.16 on epoch=6
06/16/2022 15:14:52 - INFO - __main__ - Step 790 Global step 790 Train loss 0.08 on epoch=7
06/16/2022 15:14:55 - INFO - __main__ - Step 800 Global step 800 Train loss 0.12 on epoch=7
06/16/2022 15:16:01 - INFO - __main__ - Global step 800 Train loss 0.14 Classification-F1 0.5605562724963238 on epoch=7
06/16/2022 15:16:03 - INFO - __main__ - Step 810 Global step 810 Train loss 0.15 on epoch=7
06/16/2022 15:16:06 - INFO - __main__ - Step 820 Global step 820 Train loss 0.11 on epoch=7
06/16/2022 15:16:09 - INFO - __main__ - Step 830 Global step 830 Train loss 0.12 on epoch=7
06/16/2022 15:16:12 - INFO - __main__ - Step 840 Global step 840 Train loss 0.19 on epoch=7
06/16/2022 15:16:14 - INFO - __main__ - Step 850 Global step 850 Train loss 0.11 on epoch=7
06/16/2022 15:17:21 - INFO - __main__ - Global step 850 Train loss 0.13 Classification-F1 0.9081263869695367 on epoch=7
06/16/2022 15:17:21 - INFO - __main__ - Saving model with best Classification-F1: 0.7569684472394678 -> 0.9081263869695367 on epoch=7, global_step=850
06/16/2022 15:17:23 - INFO - __main__ - Step 860 Global step 860 Train loss 0.19 on epoch=7
06/16/2022 15:17:26 - INFO - __main__ - Step 870 Global step 870 Train loss 0.09 on epoch=7
06/16/2022 15:17:29 - INFO - __main__ - Step 880 Global step 880 Train loss 0.21 on epoch=7
06/16/2022 15:17:32 - INFO - __main__ - Step 890 Global step 890 Train loss 0.17 on epoch=7
06/16/2022 15:17:35 - INFO - __main__ - Step 900 Global step 900 Train loss 0.08 on epoch=8
06/16/2022 15:18:39 - INFO - __main__ - Global step 900 Train loss 0.15 Classification-F1 0.9164201789813736 on epoch=8
06/16/2022 15:18:39 - INFO - __main__ - Saving model with best Classification-F1: 0.9081263869695367 -> 0.9164201789813736 on epoch=8, global_step=900
06/16/2022 15:18:42 - INFO - __main__ - Step 910 Global step 910 Train loss 0.10 on epoch=8
06/16/2022 15:18:45 - INFO - __main__ - Step 920 Global step 920 Train loss 0.09 on epoch=8
06/16/2022 15:18:47 - INFO - __main__ - Step 930 Global step 930 Train loss 0.12 on epoch=8
06/16/2022 15:18:50 - INFO - __main__ - Step 940 Global step 940 Train loss 0.07 on epoch=8
06/16/2022 15:18:53 - INFO - __main__ - Step 950 Global step 950 Train loss 0.11 on epoch=8
06/16/2022 15:19:55 - INFO - __main__ - Global step 950 Train loss 0.10 Classification-F1 0.8034416427331915 on epoch=8
06/16/2022 15:19:58 - INFO - __main__ - Step 960 Global step 960 Train loss 0.12 on epoch=8
06/16/2022 15:20:01 - INFO - __main__ - Step 970 Global step 970 Train loss 0.16 on epoch=8
06/16/2022 15:20:04 - INFO - __main__ - Step 980 Global step 980 Train loss 0.08 on epoch=8
06/16/2022 15:20:06 - INFO - __main__ - Step 990 Global step 990 Train loss 0.26 on epoch=8
06/16/2022 15:20:09 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.11 on epoch=8
06/16/2022 15:21:15 - INFO - __main__ - Global step 1000 Train loss 0.15 Classification-F1 0.9107008189191991 on epoch=8
06/16/2022 15:21:18 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.08 on epoch=9
06/16/2022 15:21:21 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.06 on epoch=9
06/16/2022 15:21:23 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.07 on epoch=9
06/16/2022 15:21:26 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.18 on epoch=9
06/16/2022 15:21:29 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.09 on epoch=9
06/16/2022 15:22:28 - INFO - __main__ - Global step 1050 Train loss 0.09 Classification-F1 0.7567729296303649 on epoch=9
06/16/2022 15:22:31 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.07 on epoch=9
06/16/2022 15:22:33 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.07 on epoch=9
06/16/2022 15:22:36 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.14 on epoch=9
06/16/2022 15:22:39 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.07 on epoch=9
06/16/2022 15:22:42 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.13 on epoch=9
06/16/2022 15:23:45 - INFO - __main__ - Global step 1100 Train loss 0.10 Classification-F1 0.9028824896639545 on epoch=9
06/16/2022 15:23:48 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.17 on epoch=9
06/16/2022 15:23:51 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.13 on epoch=9
06/16/2022 15:23:54 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.04 on epoch=10
06/16/2022 15:23:56 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.08 on epoch=10
06/16/2022 15:23:59 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.21 on epoch=10
06/16/2022 15:24:59 - INFO - __main__ - Global step 1150 Train loss 0.13 Classification-F1 0.6825679046631636 on epoch=10
06/16/2022 15:25:01 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.09 on epoch=10
06/16/2022 15:25:04 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.10 on epoch=10
06/16/2022 15:25:07 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.11 on epoch=10
06/16/2022 15:25:10 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.06 on epoch=10
06/16/2022 15:25:12 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.11 on epoch=10
06/16/2022 15:26:09 - INFO - __main__ - Global step 1200 Train loss 0.09 Classification-F1 0.6299387104896182 on epoch=10
06/16/2022 15:26:12 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.11 on epoch=10
06/16/2022 15:26:15 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.11 on epoch=10
06/16/2022 15:26:18 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.10 on epoch=10
06/16/2022 15:26:20 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.04 on epoch=11
06/16/2022 15:26:23 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.08 on epoch=11
06/16/2022 15:27:26 - INFO - __main__ - Global step 1250 Train loss 0.09 Classification-F1 0.8571225381859999 on epoch=11
06/16/2022 15:27:29 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.10 on epoch=11
06/16/2022 15:27:32 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.11 on epoch=11
06/16/2022 15:27:34 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.08 on epoch=11
06/16/2022 15:27:37 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.10 on epoch=11
06/16/2022 15:27:40 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.07 on epoch=11
06/16/2022 15:28:41 - INFO - __main__ - Global step 1300 Train loss 0.09 Classification-F1 0.861812811361086 on epoch=11
06/16/2022 15:28:44 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.09 on epoch=11
06/16/2022 15:28:46 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.12 on epoch=11
06/16/2022 15:28:49 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.22 on epoch=11
06/16/2022 15:28:52 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.10 on epoch=11
06/16/2022 15:28:55 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.04 on epoch=12
06/16/2022 15:29:55 - INFO - __main__ - Global step 1350 Train loss 0.11 Classification-F1 0.8106554019705675 on epoch=12
06/16/2022 15:29:58 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.09 on epoch=12
06/16/2022 15:30:00 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.12 on epoch=12
06/16/2022 15:30:03 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.12 on epoch=12
06/16/2022 15:30:06 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.06 on epoch=12
06/16/2022 15:30:09 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.07 on epoch=12
06/16/2022 15:31:16 - INFO - __main__ - Global step 1400 Train loss 0.09 Classification-F1 0.859412179089281 on epoch=12
06/16/2022 15:31:19 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.06 on epoch=12
06/16/2022 15:31:21 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.10 on epoch=12
06/16/2022 15:31:24 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.05 on epoch=12
06/16/2022 15:31:27 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.20 on epoch=12
06/16/2022 15:31:30 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.09 on epoch=12
06/16/2022 15:32:29 - INFO - __main__ - Global step 1450 Train loss 0.10 Classification-F1 0.8090067385760014 on epoch=12
06/16/2022 15:32:32 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.04 on epoch=13
06/16/2022 15:32:35 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.07 on epoch=13
06/16/2022 15:32:37 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.04 on epoch=13
06/16/2022 15:32:40 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.21 on epoch=13
06/16/2022 15:32:43 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.06 on epoch=13
06/16/2022 15:33:43 - INFO - __main__ - Global step 1500 Train loss 0.08 Classification-F1 0.6519763243152233 on epoch=13
06/16/2022 15:33:46 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.15 on epoch=13
06/16/2022 15:33:49 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.09 on epoch=13
06/16/2022 15:33:51 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.08 on epoch=13
06/16/2022 15:33:54 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.04 on epoch=13
06/16/2022 15:33:57 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.17 on epoch=13
06/16/2022 15:34:54 - INFO - __main__ - Global step 1550 Train loss 0.11 Classification-F1 0.6447062073276006 on epoch=13
06/16/2022 15:34:56 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.09 on epoch=13
06/16/2022 15:34:59 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.04 on epoch=14
06/16/2022 15:35:02 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.03 on epoch=14
06/16/2022 15:35:05 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.03 on epoch=14
06/16/2022 15:35:07 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.13 on epoch=14
06/16/2022 15:36:06 - INFO - __main__ - Global step 1600 Train loss 0.06 Classification-F1 0.8064338062362534 on epoch=14
06/16/2022 15:36:09 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.04 on epoch=14
06/16/2022 15:36:12 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.09 on epoch=14
06/16/2022 15:36:15 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.09 on epoch=14
06/16/2022 15:36:18 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.10 on epoch=14
06/16/2022 15:36:21 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.04 on epoch=14
06/16/2022 15:37:23 - INFO - __main__ - Global step 1650 Train loss 0.08 Classification-F1 0.5951766007968816 on epoch=14
06/16/2022 15:37:26 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.08 on epoch=14
06/16/2022 15:37:29 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.05 on epoch=14
06/16/2022 15:37:32 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.09 on epoch=14
06/16/2022 15:37:35 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.05 on epoch=15
06/16/2022 15:37:38 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.04 on epoch=15
06/16/2022 15:38:42 - INFO - __main__ - Global step 1700 Train loss 0.06 Classification-F1 0.8080926157352926 on epoch=15
06/16/2022 15:38:45 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.05 on epoch=15
06/16/2022 15:38:48 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.06 on epoch=15
06/16/2022 15:38:50 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.05 on epoch=15
06/16/2022 15:38:53 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.08 on epoch=15
06/16/2022 15:38:56 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.05 on epoch=15
06/16/2022 15:39:55 - INFO - __main__ - Global step 1750 Train loss 0.06 Classification-F1 0.7203556567994864 on epoch=15
06/16/2022 15:39:58 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.03 on epoch=15
06/16/2022 15:40:00 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.06 on epoch=15
06/16/2022 15:40:03 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.06 on epoch=15
06/16/2022 15:40:06 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.05 on epoch=15
06/16/2022 15:40:09 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=16
06/16/2022 15:41:08 - INFO - __main__ - Global step 1800 Train loss 0.05 Classification-F1 0.9156511840303907 on epoch=16
06/16/2022 15:41:11 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=16
06/16/2022 15:41:14 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.06 on epoch=16
06/16/2022 15:41:17 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.06 on epoch=16
06/16/2022 15:41:19 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.05 on epoch=16
06/16/2022 15:41:22 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.04 on epoch=16
06/16/2022 15:42:21 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.856065646998923 on epoch=16
06/16/2022 15:42:24 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.06 on epoch=16
06/16/2022 15:42:27 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.08 on epoch=16
06/16/2022 15:42:29 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.07 on epoch=16
06/16/2022 15:42:32 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.10 on epoch=16
06/16/2022 15:42:35 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.07 on epoch=16
06/16/2022 15:43:33 - INFO - __main__ - Global step 1900 Train loss 0.08 Classification-F1 0.806230188761661 on epoch=16
06/16/2022 15:43:36 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.04 on epoch=17
06/16/2022 15:43:39 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=17
06/16/2022 15:43:42 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.06 on epoch=17
06/16/2022 15:43:45 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.06 on epoch=17
06/16/2022 15:43:47 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.04 on epoch=17
06/16/2022 15:44:41 - INFO - __main__ - Global step 1950 Train loss 0.05 Classification-F1 0.6957206252790317 on epoch=17
06/16/2022 15:44:44 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.06 on epoch=17
06/16/2022 15:44:46 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.05 on epoch=17
06/16/2022 15:44:49 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.07 on epoch=17
06/16/2022 15:44:52 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=17
06/16/2022 15:44:54 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.14 on epoch=17
06/16/2022 15:45:52 - INFO - __main__ - Global step 2000 Train loss 0.07 Classification-F1 0.8509172072690401 on epoch=17
06/16/2022 15:45:54 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.10 on epoch=17
06/16/2022 15:45:57 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=18
06/16/2022 15:46:00 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.03 on epoch=18
06/16/2022 15:46:02 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.03 on epoch=18
06/16/2022 15:46:05 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.08 on epoch=18
06/16/2022 15:46:59 - INFO - __main__ - Global step 2050 Train loss 0.05 Classification-F1 0.669446899226262 on epoch=18
06/16/2022 15:47:01 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.03 on epoch=18
06/16/2022 15:47:04 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.06 on epoch=18
06/16/2022 15:47:06 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.05 on epoch=18
06/16/2022 15:47:09 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=18
06/16/2022 15:47:11 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.05 on epoch=18
06/16/2022 15:48:04 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.8309824669913742 on epoch=18
06/16/2022 15:48:07 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.16 on epoch=18
06/16/2022 15:48:09 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.07 on epoch=18
06/16/2022 15:48:12 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=19
06/16/2022 15:48:14 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=19
06/16/2022 15:48:17 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.03 on epoch=19
06/16/2022 15:49:11 - INFO - __main__ - Global step 2150 Train loss 0.06 Classification-F1 0.6861948466299534 on epoch=19
06/16/2022 15:49:14 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.09 on epoch=19
06/16/2022 15:49:16 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.05 on epoch=19
06/16/2022 15:49:19 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.09 on epoch=19
06/16/2022 15:49:22 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.05 on epoch=19
06/16/2022 15:49:24 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=19
06/16/2022 15:50:19 - INFO - __main__ - Global step 2200 Train loss 0.06 Classification-F1 0.7593423944753941 on epoch=19
06/16/2022 15:50:22 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=19
06/16/2022 15:50:25 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.08 on epoch=19
06/16/2022 15:50:27 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.05 on epoch=19
06/16/2022 15:50:30 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.03 on epoch=19
06/16/2022 15:50:32 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=20
06/16/2022 15:51:28 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.7907008646296644 on epoch=20
06/16/2022 15:51:30 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=20
06/16/2022 15:51:33 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.05 on epoch=20
06/16/2022 15:51:35 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=20
06/16/2022 15:51:38 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.09 on epoch=20
06/16/2022 15:51:41 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.05 on epoch=20
06/16/2022 15:52:37 - INFO - __main__ - Global step 2300 Train loss 0.04 Classification-F1 0.8632531374973691 on epoch=20
06/16/2022 15:52:40 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.04 on epoch=20
06/16/2022 15:52:42 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.04 on epoch=20
06/16/2022 15:52:45 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.05 on epoch=20
06/16/2022 15:52:47 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.05 on epoch=20
06/16/2022 15:52:50 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.07 on epoch=20
06/16/2022 15:53:44 - INFO - __main__ - Global step 2350 Train loss 0.05 Classification-F1 0.6056508279441023 on epoch=20
06/16/2022 15:53:47 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=21
06/16/2022 15:53:49 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.03 on epoch=21
06/16/2022 15:53:52 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.07 on epoch=21
06/16/2022 15:53:54 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.12 on epoch=21
06/16/2022 15:53:57 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=21
06/16/2022 15:54:48 - INFO - __main__ - Global step 2400 Train loss 0.05 Classification-F1 0.6835404813018864 on epoch=21
06/16/2022 15:54:51 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=21
06/16/2022 15:54:53 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.04 on epoch=21
06/16/2022 15:54:56 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=21
06/16/2022 15:54:58 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.09 on epoch=21
06/16/2022 15:55:01 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.09 on epoch=21
06/16/2022 15:55:57 - INFO - __main__ - Global step 2450 Train loss 0.05 Classification-F1 0.8103395774491591 on epoch=21
06/16/2022 15:56:00 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.09 on epoch=21
06/16/2022 15:56:03 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=22
06/16/2022 15:56:05 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=22
06/16/2022 15:56:08 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=22
06/16/2022 15:56:10 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.04 on epoch=22
06/16/2022 15:57:01 - INFO - __main__ - Global step 2500 Train loss 0.04 Classification-F1 0.6127553264235288 on epoch=22
06/16/2022 15:57:03 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=22
06/16/2022 15:57:06 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.05 on epoch=22
06/16/2022 15:57:08 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=22
06/16/2022 15:57:11 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=22
06/16/2022 15:57:14 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=22
06/16/2022 15:58:05 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.8587821429935854 on epoch=22
06/16/2022 15:58:08 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.09 on epoch=22
06/16/2022 15:58:11 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=22
06/16/2022 15:58:13 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=23
06/16/2022 15:58:16 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=23
06/16/2022 15:58:18 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=23
06/16/2022 15:59:10 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.7235518941766417 on epoch=23
06/16/2022 15:59:13 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.08 on epoch=23
06/16/2022 15:59:15 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.05 on epoch=23
06/16/2022 15:59:18 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=23
06/16/2022 15:59:20 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.04 on epoch=23
06/16/2022 15:59:23 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.11 on epoch=23
06/16/2022 16:00:14 - INFO - __main__ - Global step 2650 Train loss 0.06 Classification-F1 0.7494663201537906 on epoch=23
06/16/2022 16:00:17 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=23
06/16/2022 16:00:19 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.07 on epoch=23
06/16/2022 16:00:22 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.11 on epoch=23
06/16/2022 16:00:25 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=24
06/16/2022 16:00:27 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=24
06/16/2022 16:01:20 - INFO - __main__ - Global step 2700 Train loss 0.04 Classification-F1 0.7123083410964844 on epoch=24
06/16/2022 16:01:23 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=24
06/16/2022 16:01:26 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.08 on epoch=24
06/16/2022 16:01:28 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=24
06/16/2022 16:01:31 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.04 on epoch=24
06/16/2022 16:01:33 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.06 on epoch=24
06/16/2022 16:02:26 - INFO - __main__ - Global step 2750 Train loss 0.04 Classification-F1 0.7994526430724619 on epoch=24
06/16/2022 16:02:28 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.05 on epoch=24
06/16/2022 16:02:31 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=24
06/16/2022 16:02:33 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.05 on epoch=24
06/16/2022 16:02:36 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.08 on epoch=24
06/16/2022 16:02:39 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=24
06/16/2022 16:03:28 - INFO - __main__ - Global step 2800 Train loss 0.04 Classification-F1 0.5542863863196318 on epoch=24
06/16/2022 16:03:30 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=25
06/16/2022 16:03:33 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=25
06/16/2022 16:03:35 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.04 on epoch=25
06/16/2022 16:03:38 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=25
06/16/2022 16:03:41 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.05 on epoch=25
06/16/2022 16:04:31 - INFO - __main__ - Global step 2850 Train loss 0.03 Classification-F1 0.6885394372333161 on epoch=25
06/16/2022 16:04:34 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.04 on epoch=25
06/16/2022 16:04:36 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=25
06/16/2022 16:04:39 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=25
06/16/2022 16:04:42 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.04 on epoch=25
06/16/2022 16:04:44 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.13 on epoch=25
06/16/2022 16:05:35 - INFO - __main__ - Global step 2900 Train loss 0.05 Classification-F1 0.7823591063512072 on epoch=25
06/16/2022 16:05:37 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.04 on epoch=25
06/16/2022 16:05:40 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=26
06/16/2022 16:05:42 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=26
06/16/2022 16:05:45 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.08 on epoch=26
06/16/2022 16:05:47 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.04 on epoch=26
06/16/2022 16:06:38 - INFO - __main__ - Global step 2950 Train loss 0.04 Classification-F1 0.7833172043454987 on epoch=26
06/16/2022 16:06:41 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=26
06/16/2022 16:06:43 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=26
06/16/2022 16:06:46 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=26
06/16/2022 16:06:49 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.05 on epoch=26
06/16/2022 16:06:51 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=26
06/16/2022 16:06:53 - INFO - __main__ - Start tokenizing ... 1792 instances
06/16/2022 16:06:53 - INFO - __main__ - Printing 3 examples
06/16/2022 16:06:53 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/16/2022 16:06:53 - INFO - __main__ - ['Animal']
06/16/2022 16:06:53 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/16/2022 16:06:53 - INFO - __main__ - ['Animal']
06/16/2022 16:06:53 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
06/16/2022 16:06:53 - INFO - __main__ - ['Animal']
06/16/2022 16:06:53 - INFO - __main__ - Tokenizing Input ...
06/16/2022 16:06:54 - INFO - __main__ - Tokenizing Output ...
06/16/2022 16:06:56 - INFO - __main__ - Loaded 1792 examples from train data
06/16/2022 16:06:56 - INFO - __main__ - Start tokenizing ... 1792 instances
06/16/2022 16:06:56 - INFO - __main__ - Printing 3 examples
06/16/2022 16:06:56 - INFO - __main__ -  [dbpedia_14] The Andaman Treepie (Dendrocitta bayleyi) is a species of bird in the Corvidae family.It is endemic to the Andaman Islands of India.Its natural habitat is subtropical or tropical moist lowland forests. It is threatened by habitat loss.The scientific name commemorates the Anglo-Indian statesman Edward Clive Bayley.
06/16/2022 16:06:56 - INFO - __main__ - ['Animal']
06/16/2022 16:06:56 - INFO - __main__ -  [dbpedia_14] Ethmia tyranthes is a moth in the Ethmiidae family. It is found in the Democratic Republic of Congo.
06/16/2022 16:06:56 - INFO - __main__ - ['Animal']
06/16/2022 16:06:56 - INFO - __main__ -  [dbpedia_14] Van Son’s Brown (Stygionympha vansoni) is a butterfly of the Nymphalidae family. It is found in South Africa in the northern Cape from the Kamiesberg to the Springbok area.The wingspan is 36–38 mm for males and 38–40 mm for females. Adults are on wing from August to October. There is one generation per year.The larvae probably feed on Poaceae grasses.
06/16/2022 16:06:56 - INFO - __main__ - ['Animal']
06/16/2022 16:06:56 - INFO - __main__ - Tokenizing Input ...
06/16/2022 16:06:57 - INFO - __main__ - Tokenizing Output ...
06/16/2022 16:06:58 - INFO - __main__ - Loaded 1792 examples from dev data
06/16/2022 16:07:16 - INFO - __main__ - load prompt embedding from ckpt
06/16/2022 16:07:17 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/16/2022 16:07:17 - INFO - __main__ - Starting training!
06/16/2022 16:07:46 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.7995009216783331 on epoch=26
06/16/2022 16:07:46 - INFO - __main__ - save last model!
06/16/2022 16:07:46 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/16/2022 16:07:46 - INFO - __main__ - Start tokenizing ... 3500 instances
06/16/2022 16:07:46 - INFO - __main__ - Printing 3 examples
06/16/2022 16:07:46 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/16/2022 16:07:46 - INFO - __main__ - ['Animal']
06/16/2022 16:07:46 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/16/2022 16:07:46 - INFO - __main__ - ['Animal']
06/16/2022 16:07:46 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/16/2022 16:07:46 - INFO - __main__ - ['Village']
06/16/2022 16:07:46 - INFO - __main__ - Tokenizing Input ...
06/16/2022 16:07:48 - INFO - __main__ - Tokenizing Output ...
06/16/2022 16:07:52 - INFO - __main__ - Loaded 3500 examples from test data
06/16/2022 16:10:03 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down128shot/singletask-dbpedia_14/dbpedia_14_128_13_0.3_8_predictions.txt
06/16/2022 16:10:03 - INFO - __main__ - Classification-F1 on test data: 0.6479
06/16/2022 16:10:04 - INFO - __main__ - prefix=dbpedia_14_128_13, lr=0.3, bsz=8, dev_performance=0.9164201789813736, test_performance=0.6478760155212179
06/16/2022 16:10:04 - INFO - __main__ - Running ... prefix=dbpedia_14_128_13, lr=0.2, bsz=8 ...
06/16/2022 16:10:05 - INFO - __main__ - Start tokenizing ... 1792 instances
06/16/2022 16:10:05 - INFO - __main__ - Printing 3 examples
06/16/2022 16:10:05 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/16/2022 16:10:05 - INFO - __main__ - ['Animal']
06/16/2022 16:10:05 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/16/2022 16:10:05 - INFO - __main__ - ['Animal']
06/16/2022 16:10:05 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
06/16/2022 16:10:05 - INFO - __main__ - ['Animal']
06/16/2022 16:10:05 - INFO - __main__ - Tokenizing Input ...
06/16/2022 16:10:06 - INFO - __main__ - Tokenizing Output ...
06/16/2022 16:10:07 - INFO - __main__ - Loaded 1792 examples from train data
06/16/2022 16:10:07 - INFO - __main__ - Start tokenizing ... 1792 instances
06/16/2022 16:10:07 - INFO - __main__ - Printing 3 examples
06/16/2022 16:10:07 - INFO - __main__ -  [dbpedia_14] The Andaman Treepie (Dendrocitta bayleyi) is a species of bird in the Corvidae family.It is endemic to the Andaman Islands of India.Its natural habitat is subtropical or tropical moist lowland forests. It is threatened by habitat loss.The scientific name commemorates the Anglo-Indian statesman Edward Clive Bayley.
06/16/2022 16:10:07 - INFO - __main__ - ['Animal']
06/16/2022 16:10:07 - INFO - __main__ -  [dbpedia_14] Ethmia tyranthes is a moth in the Ethmiidae family. It is found in the Democratic Republic of Congo.
06/16/2022 16:10:07 - INFO - __main__ - ['Animal']
06/16/2022 16:10:07 - INFO - __main__ -  [dbpedia_14] Van Son’s Brown (Stygionympha vansoni) is a butterfly of the Nymphalidae family. It is found in South Africa in the northern Cape from the Kamiesberg to the Springbok area.The wingspan is 36–38 mm for males and 38–40 mm for females. Adults are on wing from August to October. There is one generation per year.The larvae probably feed on Poaceae grasses.
06/16/2022 16:10:07 - INFO - __main__ - ['Animal']
06/16/2022 16:10:07 - INFO - __main__ - Tokenizing Input ...
06/16/2022 16:10:08 - INFO - __main__ - Tokenizing Output ...
06/16/2022 16:10:10 - INFO - __main__ - Loaded 1792 examples from dev data
06/16/2022 16:10:26 - INFO - __main__ - load prompt embedding from ckpt
06/16/2022 16:10:26 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/16/2022 16:10:26 - INFO - __main__ - Starting training!
06/16/2022 16:10:30 - INFO - __main__ - Step 10 Global step 10 Train loss 5.23 on epoch=0
06/16/2022 16:10:33 - INFO - __main__ - Step 20 Global step 20 Train loss 3.74 on epoch=0
06/16/2022 16:10:35 - INFO - __main__ - Step 30 Global step 30 Train loss 2.83 on epoch=0
06/16/2022 16:10:38 - INFO - __main__ - Step 40 Global step 40 Train loss 2.57 on epoch=0
06/16/2022 16:10:41 - INFO - __main__ - Step 50 Global step 50 Train loss 2.20 on epoch=0
06/16/2022 16:11:25 - INFO - __main__ - Global step 50 Train loss 3.31 Classification-F1 0.04526612762494593 on epoch=0
06/16/2022 16:11:25 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.04526612762494593 on epoch=0, global_step=50
06/16/2022 16:11:28 - INFO - __main__ - Step 60 Global step 60 Train loss 1.74 on epoch=0
06/16/2022 16:11:31 - INFO - __main__ - Step 70 Global step 70 Train loss 1.56 on epoch=0
06/16/2022 16:11:33 - INFO - __main__ - Step 80 Global step 80 Train loss 1.49 on epoch=0
06/16/2022 16:11:36 - INFO - __main__ - Step 90 Global step 90 Train loss 1.23 on epoch=0
06/16/2022 16:11:39 - INFO - __main__ - Step 100 Global step 100 Train loss 1.16 on epoch=0
06/16/2022 16:12:27 - INFO - __main__ - Global step 100 Train loss 1.44 Classification-F1 0.2327989576069689 on epoch=0
06/16/2022 16:12:27 - INFO - __main__ - Saving model with best Classification-F1: 0.04526612762494593 -> 0.2327989576069689 on epoch=0, global_step=100
06/16/2022 16:12:29 - INFO - __main__ - Step 110 Global step 110 Train loss 1.10 on epoch=0
06/16/2022 16:12:32 - INFO - __main__ - Step 120 Global step 120 Train loss 0.93 on epoch=1
06/16/2022 16:12:34 - INFO - __main__ - Step 130 Global step 130 Train loss 0.83 on epoch=1
06/16/2022 16:12:37 - INFO - __main__ - Step 140 Global step 140 Train loss 0.86 on epoch=1
06/16/2022 16:12:40 - INFO - __main__ - Step 150 Global step 150 Train loss 0.81 on epoch=1
06/16/2022 16:13:30 - INFO - __main__ - Global step 150 Train loss 0.91 Classification-F1 0.3407990097645638 on epoch=1
06/16/2022 16:13:30 - INFO - __main__ - Saving model with best Classification-F1: 0.2327989576069689 -> 0.3407990097645638 on epoch=1, global_step=150
06/16/2022 16:13:33 - INFO - __main__ - Step 160 Global step 160 Train loss 0.89 on epoch=1
06/16/2022 16:13:35 - INFO - __main__ - Step 170 Global step 170 Train loss 0.90 on epoch=1
06/16/2022 16:13:38 - INFO - __main__ - Step 180 Global step 180 Train loss 0.70 on epoch=1
06/16/2022 16:13:40 - INFO - __main__ - Step 190 Global step 190 Train loss 0.75 on epoch=1
06/16/2022 16:13:43 - INFO - __main__ - Step 200 Global step 200 Train loss 0.64 on epoch=1
06/16/2022 16:14:37 - INFO - __main__ - Global step 200 Train loss 0.78 Classification-F1 0.41333210407925136 on epoch=1
06/16/2022 16:14:37 - INFO - __main__ - Saving model with best Classification-F1: 0.3407990097645638 -> 0.41333210407925136 on epoch=1, global_step=200
06/16/2022 16:14:39 - INFO - __main__ - Step 210 Global step 210 Train loss 0.65 on epoch=1
06/16/2022 16:14:42 - INFO - __main__ - Step 220 Global step 220 Train loss 0.58 on epoch=1
06/16/2022 16:14:45 - INFO - __main__ - Step 230 Global step 230 Train loss 0.52 on epoch=2
06/16/2022 16:14:47 - INFO - __main__ - Step 240 Global step 240 Train loss 0.52 on epoch=2
06/16/2022 16:14:50 - INFO - __main__ - Step 250 Global step 250 Train loss 0.54 on epoch=2
06/16/2022 16:15:41 - INFO - __main__ - Global step 250 Train loss 0.56 Classification-F1 0.5422520154970895 on epoch=2
06/16/2022 16:15:41 - INFO - __main__ - Saving model with best Classification-F1: 0.41333210407925136 -> 0.5422520154970895 on epoch=2, global_step=250
06/16/2022 16:15:44 - INFO - __main__ - Step 260 Global step 260 Train loss 0.54 on epoch=2
06/16/2022 16:15:47 - INFO - __main__ - Step 270 Global step 270 Train loss 0.54 on epoch=2
06/16/2022 16:15:49 - INFO - __main__ - Step 280 Global step 280 Train loss 0.52 on epoch=2
06/16/2022 16:15:52 - INFO - __main__ - Step 290 Global step 290 Train loss 0.47 on epoch=2
06/16/2022 16:15:54 - INFO - __main__ - Step 300 Global step 300 Train loss 0.50 on epoch=2
06/16/2022 16:16:46 - INFO - __main__ - Global step 300 Train loss 0.52 Classification-F1 0.6499988384737079 on epoch=2
06/16/2022 16:16:46 - INFO - __main__ - Saving model with best Classification-F1: 0.5422520154970895 -> 0.6499988384737079 on epoch=2, global_step=300
06/16/2022 16:16:48 - INFO - __main__ - Step 310 Global step 310 Train loss 0.47 on epoch=2
06/16/2022 16:16:51 - INFO - __main__ - Step 320 Global step 320 Train loss 0.39 on epoch=2
06/16/2022 16:16:54 - INFO - __main__ - Step 330 Global step 330 Train loss 0.43 on epoch=2
06/16/2022 16:16:56 - INFO - __main__ - Step 340 Global step 340 Train loss 0.41 on epoch=3
06/16/2022 16:16:59 - INFO - __main__ - Step 350 Global step 350 Train loss 0.46 on epoch=3
06/16/2022 16:17:56 - INFO - __main__ - Global step 350 Train loss 0.43 Classification-F1 0.46070258299942074 on epoch=3
06/16/2022 16:17:59 - INFO - __main__ - Step 360 Global step 360 Train loss 0.30 on epoch=3
06/16/2022 16:18:02 - INFO - __main__ - Step 370 Global step 370 Train loss 0.46 on epoch=3
06/16/2022 16:18:04 - INFO - __main__ - Step 380 Global step 380 Train loss 0.30 on epoch=3
06/16/2022 16:18:07 - INFO - __main__ - Step 390 Global step 390 Train loss 0.42 on epoch=3
06/16/2022 16:18:09 - INFO - __main__ - Step 400 Global step 400 Train loss 0.32 on epoch=3
06/16/2022 16:19:07 - INFO - __main__ - Global step 400 Train loss 0.36 Classification-F1 0.5207424217832423 on epoch=3
06/16/2022 16:19:09 - INFO - __main__ - Step 410 Global step 410 Train loss 0.38 on epoch=3
06/16/2022 16:19:12 - INFO - __main__ - Step 420 Global step 420 Train loss 0.43 on epoch=3
06/16/2022 16:19:14 - INFO - __main__ - Step 430 Global step 430 Train loss 0.48 on epoch=3
06/16/2022 16:19:17 - INFO - __main__ - Step 440 Global step 440 Train loss 0.20 on epoch=3
06/16/2022 16:19:20 - INFO - __main__ - Step 450 Global step 450 Train loss 0.23 on epoch=4
06/16/2022 16:20:18 - INFO - __main__ - Global step 450 Train loss 0.34 Classification-F1 0.40944551589508615 on epoch=4
06/16/2022 16:20:20 - INFO - __main__ - Step 460 Global step 460 Train loss 0.25 on epoch=4
06/16/2022 16:20:23 - INFO - __main__ - Step 470 Global step 470 Train loss 0.27 on epoch=4
06/16/2022 16:20:26 - INFO - __main__ - Step 480 Global step 480 Train loss 0.39 on epoch=4
06/16/2022 16:20:28 - INFO - __main__ - Step 490 Global step 490 Train loss 0.22 on epoch=4
06/16/2022 16:20:31 - INFO - __main__ - Step 500 Global step 500 Train loss 0.36 on epoch=4
06/16/2022 16:21:32 - INFO - __main__ - Global step 500 Train loss 0.30 Classification-F1 0.4237430580787467 on epoch=4
06/16/2022 16:21:34 - INFO - __main__ - Step 510 Global step 510 Train loss 0.36 on epoch=4
06/16/2022 16:21:37 - INFO - __main__ - Step 520 Global step 520 Train loss 0.29 on epoch=4
06/16/2022 16:21:40 - INFO - __main__ - Step 530 Global step 530 Train loss 0.27 on epoch=4
06/16/2022 16:21:42 - INFO - __main__ - Step 540 Global step 540 Train loss 0.30 on epoch=4
06/16/2022 16:21:45 - INFO - __main__ - Step 550 Global step 550 Train loss 0.22 on epoch=4
06/16/2022 16:22:50 - INFO - __main__ - Global step 550 Train loss 0.29 Classification-F1 0.6370911064298035 on epoch=4
06/16/2022 16:22:53 - INFO - __main__ - Step 560 Global step 560 Train loss 0.33 on epoch=4
06/16/2022 16:22:55 - INFO - __main__ - Step 570 Global step 570 Train loss 0.32 on epoch=5
06/16/2022 16:22:58 - INFO - __main__ - Step 580 Global step 580 Train loss 0.21 on epoch=5
06/16/2022 16:23:00 - INFO - __main__ - Step 590 Global step 590 Train loss 0.28 on epoch=5
06/16/2022 16:23:03 - INFO - __main__ - Step 600 Global step 600 Train loss 0.16 on epoch=5
06/16/2022 16:24:03 - INFO - __main__ - Global step 600 Train loss 0.26 Classification-F1 0.5839044952911658 on epoch=5
06/16/2022 16:24:06 - INFO - __main__ - Step 610 Global step 610 Train loss 0.29 on epoch=5
06/16/2022 16:24:08 - INFO - __main__ - Step 620 Global step 620 Train loss 0.29 on epoch=5
06/16/2022 16:24:11 - INFO - __main__ - Step 630 Global step 630 Train loss 0.22 on epoch=5
06/16/2022 16:24:13 - INFO - __main__ - Step 640 Global step 640 Train loss 0.17 on epoch=5
06/16/2022 16:24:16 - INFO - __main__ - Step 650 Global step 650 Train loss 0.21 on epoch=5
06/16/2022 16:25:20 - INFO - __main__ - Global step 650 Train loss 0.24 Classification-F1 0.587861937357319 on epoch=5
06/16/2022 16:25:23 - INFO - __main__ - Step 660 Global step 660 Train loss 0.22 on epoch=5
06/16/2022 16:25:25 - INFO - __main__ - Step 670 Global step 670 Train loss 0.22 on epoch=5
06/16/2022 16:25:28 - INFO - __main__ - Step 680 Global step 680 Train loss 0.25 on epoch=6
06/16/2022 16:25:31 - INFO - __main__ - Step 690 Global step 690 Train loss 0.19 on epoch=6
06/16/2022 16:25:33 - INFO - __main__ - Step 700 Global step 700 Train loss 0.22 on epoch=6
06/16/2022 16:26:37 - INFO - __main__ - Global step 700 Train loss 0.22 Classification-F1 0.7901694945521852 on epoch=6
06/16/2022 16:26:37 - INFO - __main__ - Saving model with best Classification-F1: 0.6499988384737079 -> 0.7901694945521852 on epoch=6, global_step=700
06/16/2022 16:26:40 - INFO - __main__ - Step 710 Global step 710 Train loss 0.19 on epoch=6
06/16/2022 16:26:42 - INFO - __main__ - Step 720 Global step 720 Train loss 0.19 on epoch=6
06/16/2022 16:26:45 - INFO - __main__ - Step 730 Global step 730 Train loss 0.16 on epoch=6
06/16/2022 16:26:48 - INFO - __main__ - Step 740 Global step 740 Train loss 0.21 on epoch=6
06/16/2022 16:26:50 - INFO - __main__ - Step 750 Global step 750 Train loss 0.32 on epoch=6
06/16/2022 16:27:54 - INFO - __main__ - Global step 750 Train loss 0.21 Classification-F1 0.4854972399526254 on epoch=6
06/16/2022 16:27:56 - INFO - __main__ - Step 760 Global step 760 Train loss 0.28 on epoch=6
06/16/2022 16:27:59 - INFO - __main__ - Step 770 Global step 770 Train loss 0.20 on epoch=6
06/16/2022 16:28:01 - INFO - __main__ - Step 780 Global step 780 Train loss 0.26 on epoch=6
06/16/2022 16:28:04 - INFO - __main__ - Step 790 Global step 790 Train loss 0.18 on epoch=7
06/16/2022 16:28:07 - INFO - __main__ - Step 800 Global step 800 Train loss 0.21 on epoch=7
06/16/2022 16:29:11 - INFO - __main__ - Global step 800 Train loss 0.22 Classification-F1 0.5273229025228868 on epoch=7
06/16/2022 16:29:13 - INFO - __main__ - Step 810 Global step 810 Train loss 0.18 on epoch=7
06/16/2022 16:29:16 - INFO - __main__ - Step 820 Global step 820 Train loss 0.26 on epoch=7
06/16/2022 16:29:18 - INFO - __main__ - Step 830 Global step 830 Train loss 0.20 on epoch=7
06/16/2022 16:29:21 - INFO - __main__ - Step 840 Global step 840 Train loss 0.23 on epoch=7
06/16/2022 16:29:23 - INFO - __main__ - Step 850 Global step 850 Train loss 0.17 on epoch=7
06/16/2022 16:30:28 - INFO - __main__ - Global step 850 Train loss 0.21 Classification-F1 0.6212150206456624 on epoch=7
06/16/2022 16:30:31 - INFO - __main__ - Step 860 Global step 860 Train loss 0.18 on epoch=7
06/16/2022 16:30:34 - INFO - __main__ - Step 870 Global step 870 Train loss 0.18 on epoch=7
06/16/2022 16:30:36 - INFO - __main__ - Step 880 Global step 880 Train loss 0.28 on epoch=7
06/16/2022 16:30:39 - INFO - __main__ - Step 890 Global step 890 Train loss 0.17 on epoch=7
06/16/2022 16:30:41 - INFO - __main__ - Step 900 Global step 900 Train loss 0.20 on epoch=8
06/16/2022 16:31:46 - INFO - __main__ - Global step 900 Train loss 0.20 Classification-F1 0.7182240285711184 on epoch=8
06/16/2022 16:31:48 - INFO - __main__ - Step 910 Global step 910 Train loss 0.14 on epoch=8
06/16/2022 16:31:51 - INFO - __main__ - Step 920 Global step 920 Train loss 0.13 on epoch=8
06/16/2022 16:31:54 - INFO - __main__ - Step 930 Global step 930 Train loss 0.20 on epoch=8
06/16/2022 16:31:56 - INFO - __main__ - Step 940 Global step 940 Train loss 0.12 on epoch=8
06/16/2022 16:31:59 - INFO - __main__ - Step 950 Global step 950 Train loss 0.20 on epoch=8
06/16/2022 16:32:59 - INFO - __main__ - Global step 950 Train loss 0.16 Classification-F1 0.6702768652037295 on epoch=8
06/16/2022 16:33:02 - INFO - __main__ - Step 960 Global step 960 Train loss 0.15 on epoch=8
06/16/2022 16:33:05 - INFO - __main__ - Step 970 Global step 970 Train loss 0.17 on epoch=8
06/16/2022 16:33:07 - INFO - __main__ - Step 980 Global step 980 Train loss 0.15 on epoch=8
06/16/2022 16:33:10 - INFO - __main__ - Step 990 Global step 990 Train loss 0.20 on epoch=8
06/16/2022 16:33:13 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.18 on epoch=8
06/16/2022 16:34:10 - INFO - __main__ - Global step 1000 Train loss 0.17 Classification-F1 0.6729861185086585 on epoch=8
06/16/2022 16:34:12 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.18 on epoch=9
06/16/2022 16:34:15 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.14 on epoch=9
06/16/2022 16:34:18 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.12 on epoch=9
06/16/2022 16:34:20 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.20 on epoch=9
06/16/2022 16:34:23 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.13 on epoch=9
06/16/2022 16:35:26 - INFO - __main__ - Global step 1050 Train loss 0.15 Classification-F1 0.7615408988939748 on epoch=9
06/16/2022 16:35:28 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.16 on epoch=9
06/16/2022 16:35:31 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.06 on epoch=9
06/16/2022 16:35:34 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.17 on epoch=9
06/16/2022 16:35:36 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.08 on epoch=9
06/16/2022 16:35:39 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.17 on epoch=9
06/16/2022 16:36:43 - INFO - __main__ - Global step 1100 Train loss 0.13 Classification-F1 0.8569852789397823 on epoch=9
06/16/2022 16:36:43 - INFO - __main__ - Saving model with best Classification-F1: 0.7901694945521852 -> 0.8569852789397823 on epoch=9, global_step=1100
06/16/2022 16:36:46 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.11 on epoch=9
06/16/2022 16:36:48 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.18 on epoch=9
06/16/2022 16:36:51 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.11 on epoch=10
06/16/2022 16:36:54 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.09 on epoch=10
06/16/2022 16:36:56 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.19 on epoch=10
06/16/2022 16:37:54 - INFO - __main__ - Global step 1150 Train loss 0.14 Classification-F1 0.7450521577876109 on epoch=10
06/16/2022 16:37:57 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.11 on epoch=10
06/16/2022 16:37:59 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.15 on epoch=10
06/16/2022 16:38:02 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.21 on epoch=10
06/16/2022 16:38:05 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.11 on epoch=10
06/16/2022 16:38:07 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.07 on epoch=10
06/16/2022 16:39:05 - INFO - __main__ - Global step 1200 Train loss 0.13 Classification-F1 0.7979523717736315 on epoch=10
06/16/2022 16:39:08 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.11 on epoch=10
06/16/2022 16:39:11 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.11 on epoch=10
06/16/2022 16:39:13 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.14 on epoch=10
06/16/2022 16:39:16 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.09 on epoch=11
06/16/2022 16:39:19 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.08 on epoch=11
06/16/2022 16:40:15 - INFO - __main__ - Global step 1250 Train loss 0.11 Classification-F1 0.673165149653294 on epoch=11
06/16/2022 16:40:18 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.14 on epoch=11
06/16/2022 16:40:21 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.15 on epoch=11
06/16/2022 16:40:23 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.09 on epoch=11
06/16/2022 16:40:26 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.12 on epoch=11
06/16/2022 16:40:28 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.10 on epoch=11
06/16/2022 16:41:28 - INFO - __main__ - Global step 1300 Train loss 0.12 Classification-F1 0.7660358640226408 on epoch=11
06/16/2022 16:41:31 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.13 on epoch=11
06/16/2022 16:41:33 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.20 on epoch=11
06/16/2022 16:41:36 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.23 on epoch=11
06/16/2022 16:41:39 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.09 on epoch=11
06/16/2022 16:41:42 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.06 on epoch=12
06/16/2022 16:42:40 - INFO - __main__ - Global step 1350 Train loss 0.14 Classification-F1 0.708997641644488 on epoch=12
06/16/2022 16:42:43 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.06 on epoch=12
06/16/2022 16:42:45 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.14 on epoch=12
06/16/2022 16:42:48 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.11 on epoch=12
06/16/2022 16:42:51 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.09 on epoch=12
06/16/2022 16:42:53 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.17 on epoch=12
06/16/2022 16:43:48 - INFO - __main__ - Global step 1400 Train loss 0.11 Classification-F1 0.7969816902767122 on epoch=12
06/16/2022 16:43:51 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.08 on epoch=12
06/16/2022 16:43:54 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.10 on epoch=12
06/16/2022 16:43:56 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.08 on epoch=12
06/16/2022 16:43:59 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.22 on epoch=12
06/16/2022 16:44:02 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.07 on epoch=12
06/16/2022 16:45:02 - INFO - __main__ - Global step 1450 Train loss 0.11 Classification-F1 0.8020944949212641 on epoch=12
06/16/2022 16:45:05 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.08 on epoch=13
06/16/2022 16:45:08 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.09 on epoch=13
06/16/2022 16:45:10 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.08 on epoch=13
06/16/2022 16:45:13 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.10 on epoch=13
06/16/2022 16:45:15 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.07 on epoch=13
06/16/2022 16:46:13 - INFO - __main__ - Global step 1500 Train loss 0.08 Classification-F1 0.8452765976356933 on epoch=13
06/16/2022 16:46:16 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.13 on epoch=13
06/16/2022 16:46:18 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.08 on epoch=13
06/16/2022 16:46:21 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.12 on epoch=13
06/16/2022 16:46:24 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.06 on epoch=13
06/16/2022 16:46:26 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.19 on epoch=13
06/16/2022 16:47:27 - INFO - __main__ - Global step 1550 Train loss 0.12 Classification-F1 0.709007985896285 on epoch=13
06/16/2022 16:47:30 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.07 on epoch=13
06/16/2022 16:47:32 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.10 on epoch=14
06/16/2022 16:47:35 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.07 on epoch=14
06/16/2022 16:47:37 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.11 on epoch=14
06/16/2022 16:47:40 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.13 on epoch=14
06/16/2022 16:48:41 - INFO - __main__ - Global step 1600 Train loss 0.10 Classification-F1 0.7977917032249883 on epoch=14
06/16/2022 16:48:44 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.08 on epoch=14
06/16/2022 16:48:46 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.11 on epoch=14
06/16/2022 16:48:49 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.09 on epoch=14
06/16/2022 16:48:52 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.08 on epoch=14
06/16/2022 16:48:54 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.09 on epoch=14
06/16/2022 16:49:50 - INFO - __main__ - Global step 1650 Train loss 0.09 Classification-F1 0.9050168338706441 on epoch=14
06/16/2022 16:49:50 - INFO - __main__ - Saving model with best Classification-F1: 0.8569852789397823 -> 0.9050168338706441 on epoch=14, global_step=1650
06/16/2022 16:49:52 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.11 on epoch=14
06/16/2022 16:49:55 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.15 on epoch=14
06/16/2022 16:49:58 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.08 on epoch=14
06/16/2022 16:50:00 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.08 on epoch=15
06/16/2022 16:50:03 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.04 on epoch=15
06/16/2022 16:51:02 - INFO - __main__ - Global step 1700 Train loss 0.09 Classification-F1 0.7165159756485814 on epoch=15
06/16/2022 16:51:05 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.10 on epoch=15
06/16/2022 16:51:07 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.04 on epoch=15
06/16/2022 16:51:10 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.09 on epoch=15
06/16/2022 16:51:13 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.10 on epoch=15
06/16/2022 16:51:15 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.07 on epoch=15
06/16/2022 16:52:12 - INFO - __main__ - Global step 1750 Train loss 0.08 Classification-F1 0.7609844636807814 on epoch=15
06/16/2022 16:52:14 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.05 on epoch=15
06/16/2022 16:52:17 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.06 on epoch=15
06/16/2022 16:52:20 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.15 on epoch=15
06/16/2022 16:52:23 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.10 on epoch=15
06/16/2022 16:52:25 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=16
06/16/2022 16:53:22 - INFO - __main__ - Global step 1800 Train loss 0.08 Classification-F1 0.7976999482261334 on epoch=16
06/16/2022 16:53:25 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.05 on epoch=16
06/16/2022 16:53:27 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.10 on epoch=16
06/16/2022 16:53:30 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.16 on epoch=16
06/16/2022 16:53:33 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.05 on epoch=16
06/16/2022 16:53:35 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.10 on epoch=16
06/16/2022 16:54:35 - INFO - __main__ - Global step 1850 Train loss 0.09 Classification-F1 0.8601861874261214 on epoch=16
06/16/2022 16:54:37 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.05 on epoch=16
06/16/2022 16:54:40 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.08 on epoch=16
06/16/2022 16:54:43 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.10 on epoch=16
06/16/2022 16:54:45 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.14 on epoch=16
06/16/2022 16:54:48 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.05 on epoch=16
06/16/2022 16:55:42 - INFO - __main__ - Global step 1900 Train loss 0.08 Classification-F1 0.7993535530536433 on epoch=16
06/16/2022 16:55:45 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.05 on epoch=17
06/16/2022 16:55:48 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.07 on epoch=17
06/16/2022 16:55:50 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.07 on epoch=17
06/16/2022 16:55:53 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.12 on epoch=17
06/16/2022 16:55:55 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.06 on epoch=17
06/16/2022 16:56:51 - INFO - __main__ - Global step 1950 Train loss 0.07 Classification-F1 0.803056156955365 on epoch=17
06/16/2022 16:56:54 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.09 on epoch=17
06/16/2022 16:56:56 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.05 on epoch=17
06/16/2022 16:56:59 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.10 on epoch=17
06/16/2022 16:57:02 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.06 on epoch=17
06/16/2022 16:57:04 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.14 on epoch=17
06/16/2022 16:58:04 - INFO - __main__ - Global step 2000 Train loss 0.09 Classification-F1 0.8499037292774029 on epoch=17
06/16/2022 16:58:06 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.06 on epoch=17
06/16/2022 16:58:09 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.08 on epoch=18
06/16/2022 16:58:12 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.03 on epoch=18
06/16/2022 16:58:14 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=18
06/16/2022 16:58:17 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.16 on epoch=18
06/16/2022 16:59:11 - INFO - __main__ - Global step 2050 Train loss 0.07 Classification-F1 0.7980882003261741 on epoch=18
06/16/2022 16:59:14 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.05 on epoch=18
06/16/2022 16:59:16 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.11 on epoch=18
06/16/2022 16:59:19 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.05 on epoch=18
06/16/2022 16:59:22 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.06 on epoch=18
06/16/2022 16:59:24 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=18
06/16/2022 17:00:19 - INFO - __main__ - Global step 2100 Train loss 0.06 Classification-F1 0.8490555747917303 on epoch=18
06/16/2022 17:00:22 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.11 on epoch=18
06/16/2022 17:00:25 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.07 on epoch=18
06/16/2022 17:00:27 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=19
06/16/2022 17:00:30 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.11 on epoch=19
06/16/2022 17:00:32 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.07 on epoch=19
06/16/2022 17:01:26 - INFO - __main__ - Global step 2150 Train loss 0.08 Classification-F1 0.7601684863952585 on epoch=19
06/16/2022 17:01:29 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.10 on epoch=19
06/16/2022 17:01:31 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.09 on epoch=19
06/16/2022 17:01:34 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.14 on epoch=19
06/16/2022 17:01:36 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.08 on epoch=19
06/16/2022 17:01:39 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.07 on epoch=19
06/16/2022 17:02:34 - INFO - __main__ - Global step 2200 Train loss 0.09 Classification-F1 0.9143322000616353 on epoch=19
06/16/2022 17:02:34 - INFO - __main__ - Saving model with best Classification-F1: 0.9050168338706441 -> 0.9143322000616353 on epoch=19, global_step=2200
06/16/2022 17:02:36 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.06 on epoch=19
06/16/2022 17:02:39 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.09 on epoch=19
06/16/2022 17:02:42 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.07 on epoch=19
06/16/2022 17:02:44 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.10 on epoch=19
06/16/2022 17:02:47 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.05 on epoch=20
06/16/2022 17:03:44 - INFO - __main__ - Global step 2250 Train loss 0.08 Classification-F1 0.8559285916831052 on epoch=20
06/16/2022 17:03:47 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.04 on epoch=20
06/16/2022 17:03:49 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.22 on epoch=20
06/16/2022 17:03:52 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.08 on epoch=20
06/16/2022 17:03:54 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.05 on epoch=20
06/16/2022 17:03:57 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.17 on epoch=20
06/16/2022 17:04:55 - INFO - __main__ - Global step 2300 Train loss 0.11 Classification-F1 0.9150691449075729 on epoch=20
06/16/2022 17:04:55 - INFO - __main__ - Saving model with best Classification-F1: 0.9143322000616353 -> 0.9150691449075729 on epoch=20, global_step=2300
06/16/2022 17:04:58 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=20
06/16/2022 17:05:00 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=20
06/16/2022 17:05:03 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.11 on epoch=20
06/16/2022 17:05:06 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.11 on epoch=20
06/16/2022 17:05:08 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.07 on epoch=20
06/16/2022 17:06:02 - INFO - __main__ - Global step 2350 Train loss 0.07 Classification-F1 0.9046912837491541 on epoch=20
06/16/2022 17:06:05 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.05 on epoch=21
06/16/2022 17:06:08 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.03 on epoch=21
06/16/2022 17:06:10 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.05 on epoch=21
06/16/2022 17:06:13 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.09 on epoch=21
06/16/2022 17:06:16 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.07 on epoch=21
06/16/2022 17:07:10 - INFO - __main__ - Global step 2400 Train loss 0.06 Classification-F1 0.8048239948204804 on epoch=21
06/16/2022 17:07:13 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.07 on epoch=21
06/16/2022 17:07:16 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.04 on epoch=21
06/16/2022 17:07:18 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.06 on epoch=21
06/16/2022 17:07:21 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.06 on epoch=21
06/16/2022 17:07:24 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.07 on epoch=21
06/16/2022 17:08:19 - INFO - __main__ - Global step 2450 Train loss 0.06 Classification-F1 0.9149977487360491 on epoch=21
06/16/2022 17:08:21 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.05 on epoch=21
06/16/2022 17:08:24 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=22
06/16/2022 17:08:27 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.03 on epoch=22
06/16/2022 17:08:29 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.04 on epoch=22
06/16/2022 17:08:32 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.10 on epoch=22
06/16/2022 17:09:27 - INFO - __main__ - Global step 2500 Train loss 0.05 Classification-F1 0.857791254224676 on epoch=22
06/16/2022 17:09:29 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.11 on epoch=22
06/16/2022 17:09:32 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.10 on epoch=22
06/16/2022 17:09:34 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.04 on epoch=22
06/16/2022 17:09:37 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.04 on epoch=22
06/16/2022 17:09:40 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=22
06/16/2022 17:10:34 - INFO - __main__ - Global step 2550 Train loss 0.06 Classification-F1 0.8605791275526238 on epoch=22
06/16/2022 17:10:36 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.10 on epoch=22
06/16/2022 17:10:39 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.04 on epoch=22
06/16/2022 17:10:42 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.05 on epoch=23
06/16/2022 17:10:44 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.03 on epoch=23
06/16/2022 17:10:47 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.04 on epoch=23
06/16/2022 17:11:43 - INFO - __main__ - Global step 2600 Train loss 0.05 Classification-F1 0.7642833114580942 on epoch=23
06/16/2022 17:11:45 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.13 on epoch=23
06/16/2022 17:11:48 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.05 on epoch=23
06/16/2022 17:11:50 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.13 on epoch=23
06/16/2022 17:11:53 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=23
06/16/2022 17:11:56 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.04 on epoch=23
06/16/2022 17:12:47 - INFO - __main__ - Global step 2650 Train loss 0.07 Classification-F1 0.8532759831435417 on epoch=23
06/16/2022 17:12:49 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.04 on epoch=23
06/16/2022 17:12:52 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.15 on epoch=23
06/16/2022 17:12:55 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.05 on epoch=23
06/16/2022 17:12:57 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.03 on epoch=24
06/16/2022 17:13:00 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=24
06/16/2022 17:13:56 - INFO - __main__ - Global step 2700 Train loss 0.06 Classification-F1 0.8040485695365418 on epoch=24
06/16/2022 17:13:59 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.03 on epoch=24
06/16/2022 17:14:01 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.06 on epoch=24
06/16/2022 17:14:04 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.07 on epoch=24
06/16/2022 17:14:06 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.09 on epoch=24
06/16/2022 17:14:09 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.05 on epoch=24
06/16/2022 17:15:07 - INFO - __main__ - Global step 2750 Train loss 0.06 Classification-F1 0.8540775392979851 on epoch=24
06/16/2022 17:15:10 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.03 on epoch=24
06/16/2022 17:15:13 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.03 on epoch=24
06/16/2022 17:15:15 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.10 on epoch=24
06/16/2022 17:15:18 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.08 on epoch=24
06/16/2022 17:15:21 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.07 on epoch=24
06/16/2022 17:16:19 - INFO - __main__ - Global step 2800 Train loss 0.06 Classification-F1 0.8575522090798205 on epoch=24
06/16/2022 17:16:21 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.03 on epoch=25
06/16/2022 17:16:24 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.06 on epoch=25
06/16/2022 17:16:27 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.07 on epoch=25
06/16/2022 17:16:29 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=25
06/16/2022 17:16:32 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.05 on epoch=25
06/16/2022 17:17:26 - INFO - __main__ - Global step 2850 Train loss 0.04 Classification-F1 0.8024559955453548 on epoch=25
06/16/2022 17:17:28 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.08 on epoch=25
06/16/2022 17:17:31 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=25
06/16/2022 17:17:34 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.05 on epoch=25
06/16/2022 17:17:36 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.07 on epoch=25
06/16/2022 17:17:39 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.07 on epoch=25
06/16/2022 17:18:35 - INFO - __main__ - Global step 2900 Train loss 0.06 Classification-F1 0.8581341632890628 on epoch=25
06/16/2022 17:18:37 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.09 on epoch=25
06/16/2022 17:18:40 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.03 on epoch=26
06/16/2022 17:18:43 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.12 on epoch=26
06/16/2022 17:18:45 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.05 on epoch=26
06/16/2022 17:18:48 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.09 on epoch=26
06/16/2022 17:19:42 - INFO - __main__ - Global step 2950 Train loss 0.08 Classification-F1 0.8087442581187361 on epoch=26
06/16/2022 17:19:44 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.05 on epoch=26
06/16/2022 17:19:47 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.08 on epoch=26
06/16/2022 17:19:49 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.05 on epoch=26
06/16/2022 17:19:52 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.12 on epoch=26
06/16/2022 17:19:55 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.04 on epoch=26
06/16/2022 17:19:56 - INFO - __main__ - Start tokenizing ... 1792 instances
06/16/2022 17:19:56 - INFO - __main__ - Printing 3 examples
06/16/2022 17:19:56 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/16/2022 17:19:56 - INFO - __main__ - ['Plant']
06/16/2022 17:19:56 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/16/2022 17:19:56 - INFO - __main__ - ['Plant']
06/16/2022 17:19:56 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/16/2022 17:19:56 - INFO - __main__ - ['Plant']
06/16/2022 17:19:56 - INFO - __main__ - Tokenizing Input ...
06/16/2022 17:19:57 - INFO - __main__ - Tokenizing Output ...
06/16/2022 17:19:59 - INFO - __main__ - Loaded 1792 examples from train data
06/16/2022 17:19:59 - INFO - __main__ - Start tokenizing ... 1792 instances
06/16/2022 17:19:59 - INFO - __main__ - Printing 3 examples
06/16/2022 17:19:59 - INFO - __main__ -  [dbpedia_14] Sabal pumos is a species of flowering plant in the palm tree family Arecaceae. It is native to the dry forests along the Balsas River in central Mexico (Guanajuato Guerrero Jalisco Michoacán Morelos Zacatecas and the State of México). It is threatened by habitat loss.
06/16/2022 17:19:59 - INFO - __main__ - ['Plant']
06/16/2022 17:19:59 - INFO - __main__ -  [dbpedia_14] Bulbophyllum intricatum is a species of orchid in the genus Bulbophyllum.
06/16/2022 17:19:59 - INFO - __main__ - ['Plant']
06/16/2022 17:19:59 - INFO - __main__ -  [dbpedia_14] Gentiana parryi (Parry's Gentian) is a species of the genus Gentiana.
06/16/2022 17:19:59 - INFO - __main__ - ['Plant']
06/16/2022 17:19:59 - INFO - __main__ - Tokenizing Input ...
06/16/2022 17:20:00 - INFO - __main__ - Tokenizing Output ...
06/16/2022 17:20:02 - INFO - __main__ - Loaded 1792 examples from dev data
06/16/2022 17:20:18 - INFO - __main__ - load prompt embedding from ckpt
06/16/2022 17:20:19 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/16/2022 17:20:19 - INFO - __main__ - Starting training!
06/16/2022 17:20:48 - INFO - __main__ - Global step 3000 Train loss 0.07 Classification-F1 0.8594523033699345 on epoch=26
06/16/2022 17:20:48 - INFO - __main__ - save last model!
06/16/2022 17:20:48 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/16/2022 17:20:48 - INFO - __main__ - Start tokenizing ... 3500 instances
06/16/2022 17:20:48 - INFO - __main__ - Printing 3 examples
06/16/2022 17:20:48 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/16/2022 17:20:48 - INFO - __main__ - ['Animal']
06/16/2022 17:20:48 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/16/2022 17:20:48 - INFO - __main__ - ['Animal']
06/16/2022 17:20:48 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/16/2022 17:20:48 - INFO - __main__ - ['Village']
06/16/2022 17:20:48 - INFO - __main__ - Tokenizing Input ...
06/16/2022 17:20:50 - INFO - __main__ - Tokenizing Output ...
06/16/2022 17:20:54 - INFO - __main__ - Loaded 3500 examples from test data
06/16/2022 17:23:02 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down128shot/singletask-dbpedia_14/dbpedia_14_128_13_0.2_8_predictions.txt
06/16/2022 17:23:02 - INFO - __main__ - Classification-F1 on test data: 0.7199
06/16/2022 17:23:03 - INFO - __main__ - prefix=dbpedia_14_128_13, lr=0.2, bsz=8, dev_performance=0.9150691449075729, test_performance=0.719910347278344
06/16/2022 17:23:03 - INFO - __main__ - Running ... prefix=dbpedia_14_128_21, lr=0.5, bsz=8 ...
06/16/2022 17:23:04 - INFO - __main__ - Start tokenizing ... 1792 instances
06/16/2022 17:23:04 - INFO - __main__ - Printing 3 examples
06/16/2022 17:23:04 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/16/2022 17:23:04 - INFO - __main__ - ['Plant']
06/16/2022 17:23:04 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/16/2022 17:23:04 - INFO - __main__ - ['Plant']
06/16/2022 17:23:04 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/16/2022 17:23:04 - INFO - __main__ - ['Plant']
06/16/2022 17:23:04 - INFO - __main__ - Tokenizing Input ...
06/16/2022 17:23:05 - INFO - __main__ - Tokenizing Output ...
06/16/2022 17:23:07 - INFO - __main__ - Loaded 1792 examples from train data
06/16/2022 17:23:07 - INFO - __main__ - Start tokenizing ... 1792 instances
06/16/2022 17:23:07 - INFO - __main__ - Printing 3 examples
06/16/2022 17:23:07 - INFO - __main__ -  [dbpedia_14] Sabal pumos is a species of flowering plant in the palm tree family Arecaceae. It is native to the dry forests along the Balsas River in central Mexico (Guanajuato Guerrero Jalisco Michoacán Morelos Zacatecas and the State of México). It is threatened by habitat loss.
06/16/2022 17:23:07 - INFO - __main__ - ['Plant']
06/16/2022 17:23:07 - INFO - __main__ -  [dbpedia_14] Bulbophyllum intricatum is a species of orchid in the genus Bulbophyllum.
06/16/2022 17:23:07 - INFO - __main__ - ['Plant']
06/16/2022 17:23:07 - INFO - __main__ -  [dbpedia_14] Gentiana parryi (Parry's Gentian) is a species of the genus Gentiana.
06/16/2022 17:23:07 - INFO - __main__ - ['Plant']
06/16/2022 17:23:07 - INFO - __main__ - Tokenizing Input ...
06/16/2022 17:23:08 - INFO - __main__ - Tokenizing Output ...
06/16/2022 17:23:09 - INFO - __main__ - Loaded 1792 examples from dev data
06/16/2022 17:23:25 - INFO - __main__ - load prompt embedding from ckpt
06/16/2022 17:23:25 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/16/2022 17:23:25 - INFO - __main__ - Starting training!
06/16/2022 17:23:29 - INFO - __main__ - Step 10 Global step 10 Train loss 4.46 on epoch=0
06/16/2022 17:23:32 - INFO - __main__ - Step 20 Global step 20 Train loss 2.84 on epoch=0
06/16/2022 17:23:35 - INFO - __main__ - Step 30 Global step 30 Train loss 1.88 on epoch=0
06/16/2022 17:23:37 - INFO - __main__ - Step 40 Global step 40 Train loss 1.30 on epoch=0
06/16/2022 17:23:40 - INFO - __main__ - Step 50 Global step 50 Train loss 1.18 on epoch=0
06/16/2022 17:24:31 - INFO - __main__ - Global step 50 Train loss 2.33 Classification-F1 0.17060465685931625 on epoch=0
06/16/2022 17:24:31 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.17060465685931625 on epoch=0, global_step=50
06/16/2022 17:24:33 - INFO - __main__ - Step 60 Global step 60 Train loss 0.88 on epoch=0
06/16/2022 17:24:36 - INFO - __main__ - Step 70 Global step 70 Train loss 0.73 on epoch=0
06/16/2022 17:24:40 - INFO - __main__ - Step 80 Global step 80 Train loss 0.80 on epoch=0
06/16/2022 17:24:42 - INFO - __main__ - Step 90 Global step 90 Train loss 0.75 on epoch=0
06/16/2022 17:24:45 - INFO - __main__ - Step 100 Global step 100 Train loss 0.67 on epoch=0
06/16/2022 17:25:36 - INFO - __main__ - Global step 100 Train loss 0.77 Classification-F1 0.4542977787217864 on epoch=0
06/16/2022 17:25:36 - INFO - __main__ - Saving model with best Classification-F1: 0.17060465685931625 -> 0.4542977787217864 on epoch=0, global_step=100
06/16/2022 17:25:38 - INFO - __main__ - Step 110 Global step 110 Train loss 0.58 on epoch=0
06/16/2022 17:25:41 - INFO - __main__ - Step 120 Global step 120 Train loss 0.55 on epoch=1
06/16/2022 17:25:44 - INFO - __main__ - Step 130 Global step 130 Train loss 0.52 on epoch=1
06/16/2022 17:25:46 - INFO - __main__ - Step 140 Global step 140 Train loss 0.51 on epoch=1
06/16/2022 17:25:49 - INFO - __main__ - Step 150 Global step 150 Train loss 0.41 on epoch=1
06/16/2022 17:26:45 - INFO - __main__ - Global step 150 Train loss 0.51 Classification-F1 0.6315488942529276 on epoch=1
06/16/2022 17:26:45 - INFO - __main__ - Saving model with best Classification-F1: 0.4542977787217864 -> 0.6315488942529276 on epoch=1, global_step=150
06/16/2022 17:26:47 - INFO - __main__ - Step 160 Global step 160 Train loss 0.39 on epoch=1
06/16/2022 17:26:50 - INFO - __main__ - Step 170 Global step 170 Train loss 0.41 on epoch=1
06/16/2022 17:26:52 - INFO - __main__ - Step 180 Global step 180 Train loss 0.47 on epoch=1
06/16/2022 17:26:55 - INFO - __main__ - Step 190 Global step 190 Train loss 0.39 on epoch=1
06/16/2022 17:26:58 - INFO - __main__ - Step 200 Global step 200 Train loss 0.43 on epoch=1
06/16/2022 17:28:01 - INFO - __main__ - Global step 200 Train loss 0.42 Classification-F1 0.4051876695823485 on epoch=1
06/16/2022 17:28:04 - INFO - __main__ - Step 210 Global step 210 Train loss 0.37 on epoch=1
06/16/2022 17:28:06 - INFO - __main__ - Step 220 Global step 220 Train loss 0.38 on epoch=1
06/16/2022 17:28:09 - INFO - __main__ - Step 230 Global step 230 Train loss 0.28 on epoch=2
06/16/2022 17:28:12 - INFO - __main__ - Step 240 Global step 240 Train loss 0.26 on epoch=2
06/16/2022 17:28:14 - INFO - __main__ - Step 250 Global step 250 Train loss 0.25 on epoch=2
06/16/2022 17:29:17 - INFO - __main__ - Global step 250 Train loss 0.31 Classification-F1 0.7009087666833917 on epoch=2
06/16/2022 17:29:17 - INFO - __main__ - Saving model with best Classification-F1: 0.6315488942529276 -> 0.7009087666833917 on epoch=2, global_step=250
06/16/2022 17:29:20 - INFO - __main__ - Step 260 Global step 260 Train loss 0.20 on epoch=2
06/16/2022 17:29:22 - INFO - __main__ - Step 270 Global step 270 Train loss 0.22 on epoch=2
06/16/2022 17:29:25 - INFO - __main__ - Step 280 Global step 280 Train loss 0.32 on epoch=2
06/16/2022 17:29:28 - INFO - __main__ - Step 290 Global step 290 Train loss 0.19 on epoch=2
06/16/2022 17:29:30 - INFO - __main__ - Step 300 Global step 300 Train loss 0.29 on epoch=2
06/16/2022 17:30:35 - INFO - __main__ - Global step 300 Train loss 0.24 Classification-F1 0.4910285018888568 on epoch=2
06/16/2022 17:30:38 - INFO - __main__ - Step 310 Global step 310 Train loss 0.26 on epoch=2
06/16/2022 17:30:41 - INFO - __main__ - Step 320 Global step 320 Train loss 0.16 on epoch=2
06/16/2022 17:30:43 - INFO - __main__ - Step 330 Global step 330 Train loss 0.25 on epoch=2
06/16/2022 17:30:46 - INFO - __main__ - Step 340 Global step 340 Train loss 0.19 on epoch=3
06/16/2022 17:30:49 - INFO - __main__ - Step 350 Global step 350 Train loss 0.15 on epoch=3
06/16/2022 17:31:53 - INFO - __main__ - Global step 350 Train loss 0.20 Classification-F1 0.6122974119613922 on epoch=3
06/16/2022 17:31:56 - INFO - __main__ - Step 360 Global step 360 Train loss 0.17 on epoch=3
06/16/2022 17:31:58 - INFO - __main__ - Step 370 Global step 370 Train loss 0.17 on epoch=3
06/16/2022 17:32:01 - INFO - __main__ - Step 380 Global step 380 Train loss 0.15 on epoch=3
06/16/2022 17:32:03 - INFO - __main__ - Step 390 Global step 390 Train loss 0.17 on epoch=3
06/16/2022 17:32:06 - INFO - __main__ - Step 400 Global step 400 Train loss 0.20 on epoch=3
06/16/2022 17:33:07 - INFO - __main__ - Global step 400 Train loss 0.17 Classification-F1 0.7941553380840469 on epoch=3
06/16/2022 17:33:07 - INFO - __main__ - Saving model with best Classification-F1: 0.7009087666833917 -> 0.7941553380840469 on epoch=3, global_step=400
06/16/2022 17:33:10 - INFO - __main__ - Step 410 Global step 410 Train loss 0.21 on epoch=3
06/16/2022 17:33:12 - INFO - __main__ - Step 420 Global step 420 Train loss 0.14 on epoch=3
06/16/2022 17:33:15 - INFO - __main__ - Step 430 Global step 430 Train loss 0.15 on epoch=3
06/16/2022 17:33:18 - INFO - __main__ - Step 440 Global step 440 Train loss 0.18 on epoch=3
06/16/2022 17:33:20 - INFO - __main__ - Step 450 Global step 450 Train loss 0.15 on epoch=4
06/16/2022 17:34:25 - INFO - __main__ - Global step 450 Train loss 0.17 Classification-F1 0.7992841839977197 on epoch=4
06/16/2022 17:34:25 - INFO - __main__ - Saving model with best Classification-F1: 0.7941553380840469 -> 0.7992841839977197 on epoch=4, global_step=450
06/16/2022 17:34:27 - INFO - __main__ - Step 460 Global step 460 Train loss 0.10 on epoch=4
06/16/2022 17:34:30 - INFO - __main__ - Step 470 Global step 470 Train loss 0.12 on epoch=4
06/16/2022 17:34:33 - INFO - __main__ - Step 480 Global step 480 Train loss 0.14 on epoch=4
06/16/2022 17:34:35 - INFO - __main__ - Step 490 Global step 490 Train loss 0.18 on epoch=4
06/16/2022 17:34:38 - INFO - __main__ - Step 500 Global step 500 Train loss 0.12 on epoch=4
06/16/2022 17:35:41 - INFO - __main__ - Global step 500 Train loss 0.13 Classification-F1 0.8508181905347224 on epoch=4
06/16/2022 17:35:41 - INFO - __main__ - Saving model with best Classification-F1: 0.7992841839977197 -> 0.8508181905347224 on epoch=4, global_step=500
06/16/2022 17:35:44 - INFO - __main__ - Step 510 Global step 510 Train loss 0.14 on epoch=4
06/16/2022 17:35:46 - INFO - __main__ - Step 520 Global step 520 Train loss 0.09 on epoch=4
06/16/2022 17:35:49 - INFO - __main__ - Step 530 Global step 530 Train loss 0.09 on epoch=4
06/16/2022 17:35:52 - INFO - __main__ - Step 540 Global step 540 Train loss 0.15 on epoch=4
06/16/2022 17:35:54 - INFO - __main__ - Step 550 Global step 550 Train loss 0.09 on epoch=4
06/16/2022 17:36:56 - INFO - __main__ - Global step 550 Train loss 0.11 Classification-F1 0.7419989733163797 on epoch=4
06/16/2022 17:36:59 - INFO - __main__ - Step 560 Global step 560 Train loss 0.12 on epoch=4
06/16/2022 17:37:01 - INFO - __main__ - Step 570 Global step 570 Train loss 0.14 on epoch=5
06/16/2022 17:37:04 - INFO - __main__ - Step 580 Global step 580 Train loss 0.06 on epoch=5
06/16/2022 17:37:07 - INFO - __main__ - Step 590 Global step 590 Train loss 0.10 on epoch=5
06/16/2022 17:37:09 - INFO - __main__ - Step 600 Global step 600 Train loss 0.08 on epoch=5
06/16/2022 17:38:08 - INFO - __main__ - Global step 600 Train loss 0.10 Classification-F1 0.7180787619483622 on epoch=5
06/16/2022 17:38:11 - INFO - __main__ - Step 610 Global step 610 Train loss 0.19 on epoch=5
06/16/2022 17:38:13 - INFO - __main__ - Step 620 Global step 620 Train loss 0.11 on epoch=5
06/16/2022 17:38:16 - INFO - __main__ - Step 630 Global step 630 Train loss 0.06 on epoch=5
06/16/2022 17:38:19 - INFO - __main__ - Step 640 Global step 640 Train loss 0.07 on epoch=5
06/16/2022 17:38:21 - INFO - __main__ - Step 650 Global step 650 Train loss 0.10 on epoch=5
06/16/2022 17:39:20 - INFO - __main__ - Global step 650 Train loss 0.11 Classification-F1 0.6776633637421842 on epoch=5
06/16/2022 17:39:23 - INFO - __main__ - Step 660 Global step 660 Train loss 0.09 on epoch=5
06/16/2022 17:39:26 - INFO - __main__ - Step 670 Global step 670 Train loss 0.09 on epoch=5
06/16/2022 17:39:28 - INFO - __main__ - Step 680 Global step 680 Train loss 0.10 on epoch=6
06/16/2022 17:39:31 - INFO - __main__ - Step 690 Global step 690 Train loss 0.06 on epoch=6
06/16/2022 17:39:34 - INFO - __main__ - Step 700 Global step 700 Train loss 0.06 on epoch=6
06/16/2022 17:40:27 - INFO - __main__ - Global step 700 Train loss 0.08 Classification-F1 0.917971857566848 on epoch=6
06/16/2022 17:40:27 - INFO - __main__ - Saving model with best Classification-F1: 0.8508181905347224 -> 0.917971857566848 on epoch=6, global_step=700
06/16/2022 17:40:29 - INFO - __main__ - Step 710 Global step 710 Train loss 0.12 on epoch=6
06/16/2022 17:40:32 - INFO - __main__ - Step 720 Global step 720 Train loss 0.09 on epoch=6
06/16/2022 17:40:34 - INFO - __main__ - Step 730 Global step 730 Train loss 0.06 on epoch=6
06/16/2022 17:40:37 - INFO - __main__ - Step 740 Global step 740 Train loss 0.10 on epoch=6
06/16/2022 17:40:40 - INFO - __main__ - Step 750 Global step 750 Train loss 0.10 on epoch=6
06/16/2022 17:41:31 - INFO - __main__ - Global step 750 Train loss 0.09 Classification-F1 0.7618822442388415 on epoch=6
06/16/2022 17:41:34 - INFO - __main__ - Step 760 Global step 760 Train loss 0.09 on epoch=6
06/16/2022 17:41:37 - INFO - __main__ - Step 770 Global step 770 Train loss 0.08 on epoch=6
06/16/2022 17:41:39 - INFO - __main__ - Step 780 Global step 780 Train loss 0.08 on epoch=6
06/16/2022 17:41:42 - INFO - __main__ - Step 790 Global step 790 Train loss 0.10 on epoch=7
06/16/2022 17:41:45 - INFO - __main__ - Step 800 Global step 800 Train loss 0.05 on epoch=7
06/16/2022 17:42:38 - INFO - __main__ - Global step 800 Train loss 0.08 Classification-F1 0.910755521131612 on epoch=7
06/16/2022 17:42:41 - INFO - __main__ - Step 810 Global step 810 Train loss 0.08 on epoch=7
06/16/2022 17:42:43 - INFO - __main__ - Step 820 Global step 820 Train loss 0.03 on epoch=7
06/16/2022 17:42:46 - INFO - __main__ - Step 830 Global step 830 Train loss 0.06 on epoch=7
06/16/2022 17:42:48 - INFO - __main__ - Step 840 Global step 840 Train loss 0.08 on epoch=7
06/16/2022 17:42:51 - INFO - __main__ - Step 850 Global step 850 Train loss 0.10 on epoch=7
06/16/2022 17:43:41 - INFO - __main__ - Global step 850 Train loss 0.07 Classification-F1 0.8593738203500494 on epoch=7
06/16/2022 17:43:44 - INFO - __main__ - Step 860 Global step 860 Train loss 0.09 on epoch=7
06/16/2022 17:43:47 - INFO - __main__ - Step 870 Global step 870 Train loss 0.06 on epoch=7
06/16/2022 17:43:49 - INFO - __main__ - Step 880 Global step 880 Train loss 0.05 on epoch=7
06/16/2022 17:43:52 - INFO - __main__ - Step 890 Global step 890 Train loss 0.08 on epoch=7
06/16/2022 17:43:55 - INFO - __main__ - Step 900 Global step 900 Train loss 0.12 on epoch=8
06/16/2022 17:44:46 - INFO - __main__ - Global step 900 Train loss 0.08 Classification-F1 0.9195950012387741 on epoch=8
06/16/2022 17:44:46 - INFO - __main__ - Saving model with best Classification-F1: 0.917971857566848 -> 0.9195950012387741 on epoch=8, global_step=900
06/16/2022 17:44:49 - INFO - __main__ - Step 910 Global step 910 Train loss 0.02 on epoch=8
06/16/2022 17:44:51 - INFO - __main__ - Step 920 Global step 920 Train loss 0.03 on epoch=8
06/16/2022 17:44:54 - INFO - __main__ - Step 930 Global step 930 Train loss 0.04 on epoch=8
06/16/2022 17:44:57 - INFO - __main__ - Step 940 Global step 940 Train loss 0.07 on epoch=8
06/16/2022 17:44:59 - INFO - __main__ - Step 950 Global step 950 Train loss 0.09 on epoch=8
06/16/2022 17:45:51 - INFO - __main__ - Global step 950 Train loss 0.05 Classification-F1 0.50963144974599 on epoch=8
06/16/2022 17:45:53 - INFO - __main__ - Step 960 Global step 960 Train loss 0.05 on epoch=8
06/16/2022 17:45:56 - INFO - __main__ - Step 970 Global step 970 Train loss 0.05 on epoch=8
06/16/2022 17:45:59 - INFO - __main__ - Step 980 Global step 980 Train loss 0.02 on epoch=8
06/16/2022 17:46:01 - INFO - __main__ - Step 990 Global step 990 Train loss 0.04 on epoch=8
06/16/2022 17:46:04 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.07 on epoch=8
06/16/2022 17:46:54 - INFO - __main__ - Global step 1000 Train loss 0.04 Classification-F1 0.598426377604211 on epoch=8
06/16/2022 17:46:56 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.06 on epoch=9
06/16/2022 17:46:59 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.04 on epoch=9
06/16/2022 17:47:02 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.05 on epoch=9
06/16/2022 17:47:04 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.06 on epoch=9
06/16/2022 17:47:07 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.05 on epoch=9
06/16/2022 17:47:58 - INFO - __main__ - Global step 1050 Train loss 0.05 Classification-F1 0.8503490994589502 on epoch=9
06/16/2022 17:48:01 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.05 on epoch=9
06/16/2022 17:48:03 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.08 on epoch=9
06/16/2022 17:48:06 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.04 on epoch=9
06/16/2022 17:48:09 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.02 on epoch=9
06/16/2022 17:48:11 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.04 on epoch=9
06/16/2022 17:49:05 - INFO - __main__ - Global step 1100 Train loss 0.05 Classification-F1 0.9158652175243339 on epoch=9
06/16/2022 17:49:08 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.06 on epoch=9
06/16/2022 17:49:10 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.08 on epoch=9
06/16/2022 17:49:13 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.03 on epoch=10
06/16/2022 17:49:16 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.02 on epoch=10
06/16/2022 17:49:18 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.11 on epoch=10
06/16/2022 17:50:06 - INFO - __main__ - Global step 1150 Train loss 0.06 Classification-F1 0.700224161472972 on epoch=10
06/16/2022 17:50:09 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.06 on epoch=10
06/16/2022 17:50:11 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.07 on epoch=10
06/16/2022 17:50:14 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.02 on epoch=10
06/16/2022 17:50:16 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.09 on epoch=10
06/16/2022 17:50:19 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.06 on epoch=10
06/16/2022 17:51:10 - INFO - __main__ - Global step 1200 Train loss 0.06 Classification-F1 0.8591356595386443 on epoch=10
06/16/2022 17:51:13 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.04 on epoch=10
06/16/2022 17:51:15 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.06 on epoch=10
06/16/2022 17:51:18 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.04 on epoch=10
06/16/2022 17:51:20 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.04 on epoch=11
06/16/2022 17:51:23 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.02 on epoch=11
06/16/2022 17:52:20 - INFO - __main__ - Global step 1250 Train loss 0.04 Classification-F1 0.9132868996281438 on epoch=11
06/16/2022 17:52:22 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.09 on epoch=11
06/16/2022 17:52:25 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.11 on epoch=11
06/16/2022 17:52:28 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.06 on epoch=11
06/16/2022 17:52:30 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.07 on epoch=11
06/16/2022 17:52:33 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.05 on epoch=11
06/16/2022 17:53:26 - INFO - __main__ - Global step 1300 Train loss 0.08 Classification-F1 0.8092616848223173 on epoch=11
06/16/2022 17:53:29 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.04 on epoch=11
06/16/2022 17:53:31 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.10 on epoch=11
06/16/2022 17:53:34 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.06 on epoch=11
06/16/2022 17:53:37 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.05 on epoch=11
06/16/2022 17:53:39 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.03 on epoch=12
06/16/2022 17:54:31 - INFO - __main__ - Global step 1350 Train loss 0.06 Classification-F1 0.8632767949473796 on epoch=12
06/16/2022 17:54:34 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.03 on epoch=12
06/16/2022 17:54:37 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.03 on epoch=12
06/16/2022 17:54:39 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.05 on epoch=12
06/16/2022 17:54:42 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.02 on epoch=12
06/16/2022 17:54:45 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=12
06/16/2022 17:55:36 - INFO - __main__ - Global step 1400 Train loss 0.03 Classification-F1 0.9844021633910552 on epoch=12
06/16/2022 17:55:36 - INFO - __main__ - Saving model with best Classification-F1: 0.9195950012387741 -> 0.9844021633910552 on epoch=12, global_step=1400
06/16/2022 17:55:39 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.05 on epoch=12
06/16/2022 17:55:42 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=12
06/16/2022 17:55:44 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.02 on epoch=12
06/16/2022 17:55:47 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.04 on epoch=12
06/16/2022 17:55:50 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.03 on epoch=12
06/16/2022 17:56:49 - INFO - __main__ - Global step 1450 Train loss 0.03 Classification-F1 0.9832959905602513 on epoch=12
06/16/2022 17:56:52 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.06 on epoch=13
06/16/2022 17:56:55 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=13
06/16/2022 17:56:57 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=13
06/16/2022 17:57:00 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.05 on epoch=13
06/16/2022 17:57:02 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=13
06/16/2022 17:57:55 - INFO - __main__ - Global step 1500 Train loss 0.03 Classification-F1 0.9215964349461293 on epoch=13
06/16/2022 17:57:58 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.05 on epoch=13
06/16/2022 17:58:00 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.03 on epoch=13
06/16/2022 17:58:03 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.03 on epoch=13
06/16/2022 17:58:06 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=13
06/16/2022 17:58:08 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=13
06/16/2022 17:59:03 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.9815777951877547 on epoch=13
06/16/2022 17:59:06 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.03 on epoch=13
06/16/2022 17:59:08 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.05 on epoch=14
06/16/2022 17:59:11 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.02 on epoch=14
06/16/2022 17:59:14 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.02 on epoch=14
06/16/2022 17:59:17 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=14
06/16/2022 18:00:12 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.8594881579609248 on epoch=14
06/16/2022 18:00:15 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.05 on epoch=14
06/16/2022 18:00:17 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.08 on epoch=14
06/16/2022 18:00:20 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.06 on epoch=14
06/16/2022 18:00:23 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.04 on epoch=14
06/16/2022 18:00:25 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=14
06/16/2022 18:01:14 - INFO - __main__ - Global step 1650 Train loss 0.05 Classification-F1 0.7166883720761801 on epoch=14
06/16/2022 18:01:17 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.05 on epoch=14
06/16/2022 18:01:19 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.03 on epoch=14
06/16/2022 18:01:22 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.04 on epoch=14
06/16/2022 18:01:25 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=15
06/16/2022 18:01:27 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=15
06/16/2022 18:02:25 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.7587909862422393 on epoch=15
06/16/2022 18:02:27 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.04 on epoch=15
06/16/2022 18:02:30 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=15
06/16/2022 18:02:33 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=15
06/16/2022 18:02:35 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=15
06/16/2022 18:02:38 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.08 on epoch=15
06/16/2022 18:03:31 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.7357319153004888 on epoch=15
06/16/2022 18:03:34 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.03 on epoch=15
06/16/2022 18:03:36 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=15
06/16/2022 18:03:39 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=15
06/16/2022 18:03:42 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.04 on epoch=15
06/16/2022 18:03:44 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=16
06/16/2022 18:04:36 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.8632577554462361 on epoch=16
06/16/2022 18:04:39 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=16
06/16/2022 18:04:41 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.05 on epoch=16
06/16/2022 18:04:44 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=16
06/16/2022 18:04:47 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.06 on epoch=16
06/16/2022 18:04:49 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=16
06/16/2022 18:05:41 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.7234013731104074 on epoch=16
06/16/2022 18:05:44 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.06 on epoch=16
06/16/2022 18:05:47 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.03 on epoch=16
06/16/2022 18:05:49 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.03 on epoch=16
06/16/2022 18:05:52 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.04 on epoch=16
06/16/2022 18:05:54 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=16
06/16/2022 18:06:46 - INFO - __main__ - Global step 1900 Train loss 0.04 Classification-F1 0.810421419027338 on epoch=16
06/16/2022 18:06:48 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.04 on epoch=17
06/16/2022 18:06:51 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.04 on epoch=17
06/16/2022 18:06:54 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=17
06/16/2022 18:06:56 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.06 on epoch=17
06/16/2022 18:06:59 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=17
06/16/2022 18:07:51 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.7156921882368156 on epoch=17
06/16/2022 18:07:54 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.04 on epoch=17
06/16/2022 18:07:56 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=17
06/16/2022 18:07:59 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=17
06/16/2022 18:08:02 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=17
06/16/2022 18:08:04 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.07 on epoch=17
06/16/2022 18:08:53 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.6361392248731732 on epoch=17
06/16/2022 18:08:55 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=17
06/16/2022 18:08:58 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.05 on epoch=18
06/16/2022 18:09:01 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.03 on epoch=18
06/16/2022 18:09:03 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=18
06/16/2022 18:09:06 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.05 on epoch=18
06/16/2022 18:09:59 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.6482062787143963 on epoch=18
06/16/2022 18:10:02 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.04 on epoch=18
06/16/2022 18:10:04 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.03 on epoch=18
06/16/2022 18:10:07 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=18
06/16/2022 18:10:10 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.06 on epoch=18
06/16/2022 18:10:13 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.13 on epoch=18
06/16/2022 18:11:02 - INFO - __main__ - Global step 2100 Train loss 0.06 Classification-F1 0.5216853124391847 on epoch=18
06/16/2022 18:11:05 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=18
06/16/2022 18:11:07 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.06 on epoch=18
06/16/2022 18:11:10 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.04 on epoch=19
06/16/2022 18:11:12 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=19
06/16/2022 18:11:15 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=19
06/16/2022 18:12:07 - INFO - __main__ - Global step 2150 Train loss 0.03 Classification-F1 0.8448133491142136 on epoch=19
06/16/2022 18:12:09 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=19
06/16/2022 18:12:12 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=19
06/16/2022 18:12:14 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=19
06/16/2022 18:12:17 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.04 on epoch=19
06/16/2022 18:12:20 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=19
06/16/2022 18:13:12 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.8602081178450569 on epoch=19
06/16/2022 18:13:15 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=19
06/16/2022 18:13:17 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=19
06/16/2022 18:13:20 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.04 on epoch=19
06/16/2022 18:13:22 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.04 on epoch=19
06/16/2022 18:13:25 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=20
06/16/2022 18:14:15 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.7578454086504014 on epoch=20
06/16/2022 18:14:17 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.03 on epoch=20
06/16/2022 18:14:20 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=20
06/16/2022 18:14:23 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=20
06/16/2022 18:14:25 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.04 on epoch=20
06/16/2022 18:14:28 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=20
06/16/2022 18:15:18 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.7236602186460779 on epoch=20
06/16/2022 18:15:21 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=20
06/16/2022 18:15:24 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=20
06/16/2022 18:15:26 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=20
06/16/2022 18:15:29 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.07 on epoch=20
06/16/2022 18:15:32 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=20
06/16/2022 18:16:23 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.7630242634882165 on epoch=20
06/16/2022 18:16:26 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=21
06/16/2022 18:16:29 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=21
06/16/2022 18:16:31 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=21
06/16/2022 18:16:34 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.05 on epoch=21
06/16/2022 18:16:37 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=21
06/16/2022 18:17:31 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.7235314386243802 on epoch=21
06/16/2022 18:17:34 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=21
06/16/2022 18:17:36 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.04 on epoch=21
06/16/2022 18:17:39 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=21
06/16/2022 18:17:42 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=21
06/16/2022 18:17:44 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.05 on epoch=21
06/16/2022 18:18:36 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.8118029811750129 on epoch=21
06/16/2022 18:18:39 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.02 on epoch=21
06/16/2022 18:18:41 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=22
06/16/2022 18:18:44 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=22
06/16/2022 18:18:47 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=22
06/16/2022 18:18:49 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.04 on epoch=22
06/16/2022 18:19:40 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.862801823924979 on epoch=22
06/16/2022 18:19:42 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=22
06/16/2022 18:19:45 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=22
06/16/2022 18:19:48 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.03 on epoch=22
06/16/2022 18:19:51 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=22
06/16/2022 18:19:53 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.04 on epoch=22
06/16/2022 18:20:39 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.7414876597238986 on epoch=22
06/16/2022 18:20:42 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=22
06/16/2022 18:20:45 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=22
06/16/2022 18:20:47 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.04 on epoch=23
06/16/2022 18:20:50 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=23
06/16/2022 18:20:53 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=23
06/16/2022 18:21:41 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.7629537358502465 on epoch=23
06/16/2022 18:21:43 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=23
06/16/2022 18:21:46 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.04 on epoch=23
06/16/2022 18:21:49 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.03 on epoch=23
06/16/2022 18:21:51 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=23
06/16/2022 18:21:54 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=23
06/16/2022 18:22:41 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.636793269913271 on epoch=23
06/16/2022 18:22:44 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=23
06/16/2022 18:22:46 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=23
06/16/2022 18:22:49 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.03 on epoch=23
06/16/2022 18:22:52 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=24
06/16/2022 18:22:54 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=24
06/16/2022 18:23:41 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.7636947272632799 on epoch=24
06/16/2022 18:23:44 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=24
06/16/2022 18:23:46 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=24
06/16/2022 18:23:49 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.03 on epoch=24
06/16/2022 18:23:52 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=24
06/16/2022 18:23:54 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=24
06/16/2022 18:24:43 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.6976175369909169 on epoch=24
06/16/2022 18:24:45 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.05 on epoch=24
06/16/2022 18:24:48 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=24
06/16/2022 18:24:51 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.04 on epoch=24
06/16/2022 18:24:53 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=24
06/16/2022 18:24:56 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=24
06/16/2022 18:25:47 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.9197845354623975 on epoch=24
06/16/2022 18:25:49 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=25
06/16/2022 18:25:52 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=25
06/16/2022 18:25:55 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.04 on epoch=25
06/16/2022 18:25:57 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=25
06/16/2022 18:26:00 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.04 on epoch=25
06/16/2022 18:26:51 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.9843548938600445 on epoch=25
06/16/2022 18:26:53 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=25
06/16/2022 18:26:56 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=25
06/16/2022 18:26:59 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=25
06/16/2022 18:27:01 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=25
06/16/2022 18:27:04 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.04 on epoch=25
06/16/2022 18:27:52 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.796700892526556 on epoch=25
06/16/2022 18:27:55 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=25
06/16/2022 18:27:58 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=26
06/16/2022 18:28:01 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=26
06/16/2022 18:28:03 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.05 on epoch=26
06/16/2022 18:28:06 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.03 on epoch=26
06/16/2022 18:28:58 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.8036703312670257 on epoch=26
06/16/2022 18:29:01 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=26
06/16/2022 18:29:04 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.05 on epoch=26
06/16/2022 18:29:06 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.04 on epoch=26
06/16/2022 18:29:09 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=26
06/16/2022 18:29:12 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=26
06/16/2022 18:29:13 - INFO - __main__ - Start tokenizing ... 1792 instances
06/16/2022 18:29:13 - INFO - __main__ - Printing 3 examples
06/16/2022 18:29:13 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/16/2022 18:29:13 - INFO - __main__ - ['Plant']
06/16/2022 18:29:13 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/16/2022 18:29:13 - INFO - __main__ - ['Plant']
06/16/2022 18:29:13 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/16/2022 18:29:13 - INFO - __main__ - ['Plant']
06/16/2022 18:29:13 - INFO - __main__ - Tokenizing Input ...
06/16/2022 18:29:14 - INFO - __main__ - Tokenizing Output ...
06/16/2022 18:29:16 - INFO - __main__ - Loaded 1792 examples from train data
06/16/2022 18:29:16 - INFO - __main__ - Start tokenizing ... 1792 instances
06/16/2022 18:29:16 - INFO - __main__ - Printing 3 examples
06/16/2022 18:29:16 - INFO - __main__ -  [dbpedia_14] Sabal pumos is a species of flowering plant in the palm tree family Arecaceae. It is native to the dry forests along the Balsas River in central Mexico (Guanajuato Guerrero Jalisco Michoacán Morelos Zacatecas and the State of México). It is threatened by habitat loss.
06/16/2022 18:29:16 - INFO - __main__ - ['Plant']
06/16/2022 18:29:16 - INFO - __main__ -  [dbpedia_14] Bulbophyllum intricatum is a species of orchid in the genus Bulbophyllum.
06/16/2022 18:29:16 - INFO - __main__ - ['Plant']
06/16/2022 18:29:16 - INFO - __main__ -  [dbpedia_14] Gentiana parryi (Parry's Gentian) is a species of the genus Gentiana.
06/16/2022 18:29:16 - INFO - __main__ - ['Plant']
06/16/2022 18:29:16 - INFO - __main__ - Tokenizing Input ...
06/16/2022 18:29:17 - INFO - __main__ - Tokenizing Output ...
06/16/2022 18:29:19 - INFO - __main__ - Loaded 1792 examples from dev data
06/16/2022 18:29:35 - INFO - __main__ - load prompt embedding from ckpt
06/16/2022 18:29:35 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/16/2022 18:29:36 - INFO - __main__ - Starting training!
06/16/2022 18:30:01 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.7659062824921511 on epoch=26
06/16/2022 18:30:01 - INFO - __main__ - save last model!
06/16/2022 18:30:01 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/16/2022 18:30:01 - INFO - __main__ - Start tokenizing ... 3500 instances
06/16/2022 18:30:01 - INFO - __main__ - Printing 3 examples
06/16/2022 18:30:01 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/16/2022 18:30:01 - INFO - __main__ - ['Animal']
06/16/2022 18:30:01 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/16/2022 18:30:01 - INFO - __main__ - ['Animal']
06/16/2022 18:30:01 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/16/2022 18:30:01 - INFO - __main__ - ['Village']
06/16/2022 18:30:01 - INFO - __main__ - Tokenizing Input ...
06/16/2022 18:30:03 - INFO - __main__ - Tokenizing Output ...
06/16/2022 18:30:07 - INFO - __main__ - Loaded 3500 examples from test data
06/16/2022 18:32:06 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down128shot/singletask-dbpedia_14/dbpedia_14_128_21_0.5_8_predictions.txt
06/16/2022 18:32:07 - INFO - __main__ - Classification-F1 on test data: 0.5256
06/16/2022 18:32:07 - INFO - __main__ - prefix=dbpedia_14_128_21, lr=0.5, bsz=8, dev_performance=0.9844021633910552, test_performance=0.5255592646141514
06/16/2022 18:32:07 - INFO - __main__ - Running ... prefix=dbpedia_14_128_21, lr=0.4, bsz=8 ...
06/16/2022 18:32:08 - INFO - __main__ - Start tokenizing ... 1792 instances
06/16/2022 18:32:08 - INFO - __main__ - Printing 3 examples
06/16/2022 18:32:08 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/16/2022 18:32:08 - INFO - __main__ - ['Plant']
06/16/2022 18:32:08 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/16/2022 18:32:08 - INFO - __main__ - ['Plant']
06/16/2022 18:32:08 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/16/2022 18:32:08 - INFO - __main__ - ['Plant']
06/16/2022 18:32:08 - INFO - __main__ - Tokenizing Input ...
06/16/2022 18:32:09 - INFO - __main__ - Tokenizing Output ...
06/16/2022 18:32:10 - INFO - __main__ - Loaded 1792 examples from train data
06/16/2022 18:32:10 - INFO - __main__ - Start tokenizing ... 1792 instances
06/16/2022 18:32:10 - INFO - __main__ - Printing 3 examples
06/16/2022 18:32:10 - INFO - __main__ -  [dbpedia_14] Sabal pumos is a species of flowering plant in the palm tree family Arecaceae. It is native to the dry forests along the Balsas River in central Mexico (Guanajuato Guerrero Jalisco Michoacán Morelos Zacatecas and the State of México). It is threatened by habitat loss.
06/16/2022 18:32:10 - INFO - __main__ - ['Plant']
06/16/2022 18:32:10 - INFO - __main__ -  [dbpedia_14] Bulbophyllum intricatum is a species of orchid in the genus Bulbophyllum.
06/16/2022 18:32:10 - INFO - __main__ - ['Plant']
06/16/2022 18:32:10 - INFO - __main__ -  [dbpedia_14] Gentiana parryi (Parry's Gentian) is a species of the genus Gentiana.
06/16/2022 18:32:10 - INFO - __main__ - ['Plant']
06/16/2022 18:32:10 - INFO - __main__ - Tokenizing Input ...
06/16/2022 18:32:11 - INFO - __main__ - Tokenizing Output ...
06/16/2022 18:32:13 - INFO - __main__ - Loaded 1792 examples from dev data
06/16/2022 18:32:32 - INFO - __main__ - load prompt embedding from ckpt
06/16/2022 18:32:32 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/16/2022 18:32:33 - INFO - __main__ - Starting training!
06/16/2022 18:32:36 - INFO - __main__ - Step 10 Global step 10 Train loss 4.75 on epoch=0
06/16/2022 18:32:39 - INFO - __main__ - Step 20 Global step 20 Train loss 3.11 on epoch=0
06/16/2022 18:32:42 - INFO - __main__ - Step 30 Global step 30 Train loss 1.94 on epoch=0
06/16/2022 18:32:44 - INFO - __main__ - Step 40 Global step 40 Train loss 1.56 on epoch=0
06/16/2022 18:32:47 - INFO - __main__ - Step 50 Global step 50 Train loss 1.38 on epoch=0
06/16/2022 18:33:40 - INFO - __main__ - Global step 50 Train loss 2.55 Classification-F1 0.1380371201277487 on epoch=0
06/16/2022 18:33:40 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.1380371201277487 on epoch=0, global_step=50
06/16/2022 18:33:42 - INFO - __main__ - Step 60 Global step 60 Train loss 1.14 on epoch=0
06/16/2022 18:33:45 - INFO - __main__ - Step 70 Global step 70 Train loss 0.76 on epoch=0
06/16/2022 18:33:48 - INFO - __main__ - Step 80 Global step 80 Train loss 0.81 on epoch=0
06/16/2022 18:33:51 - INFO - __main__ - Step 90 Global step 90 Train loss 0.78 on epoch=0
06/16/2022 18:33:54 - INFO - __main__ - Step 100 Global step 100 Train loss 0.65 on epoch=0
06/16/2022 18:34:49 - INFO - __main__ - Global step 100 Train loss 0.83 Classification-F1 0.29912424658833997 on epoch=0
06/16/2022 18:34:49 - INFO - __main__ - Saving model with best Classification-F1: 0.1380371201277487 -> 0.29912424658833997 on epoch=0, global_step=100
06/16/2022 18:34:51 - INFO - __main__ - Step 110 Global step 110 Train loss 0.66 on epoch=0
06/16/2022 18:34:54 - INFO - __main__ - Step 120 Global step 120 Train loss 0.64 on epoch=1
06/16/2022 18:34:57 - INFO - __main__ - Step 130 Global step 130 Train loss 0.42 on epoch=1
06/16/2022 18:34:59 - INFO - __main__ - Step 140 Global step 140 Train loss 0.52 on epoch=1
06/16/2022 18:35:02 - INFO - __main__ - Step 150 Global step 150 Train loss 0.45 on epoch=1
06/16/2022 18:36:01 - INFO - __main__ - Global step 150 Train loss 0.54 Classification-F1 0.48306269962012177 on epoch=1
06/16/2022 18:36:01 - INFO - __main__ - Saving model with best Classification-F1: 0.29912424658833997 -> 0.48306269962012177 on epoch=1, global_step=150
06/16/2022 18:36:04 - INFO - __main__ - Step 160 Global step 160 Train loss 0.51 on epoch=1
06/16/2022 18:36:06 - INFO - __main__ - Step 170 Global step 170 Train loss 0.49 on epoch=1
06/16/2022 18:36:09 - INFO - __main__ - Step 180 Global step 180 Train loss 0.53 on epoch=1
06/16/2022 18:36:12 - INFO - __main__ - Step 190 Global step 190 Train loss 0.43 on epoch=1
06/16/2022 18:36:14 - INFO - __main__ - Step 200 Global step 200 Train loss 0.43 on epoch=1
06/16/2022 18:37:13 - INFO - __main__ - Global step 200 Train loss 0.48 Classification-F1 0.5566951653746371 on epoch=1
06/16/2022 18:37:13 - INFO - __main__ - Saving model with best Classification-F1: 0.48306269962012177 -> 0.5566951653746371 on epoch=1, global_step=200
06/16/2022 18:37:16 - INFO - __main__ - Step 210 Global step 210 Train loss 0.37 on epoch=1
06/16/2022 18:37:18 - INFO - __main__ - Step 220 Global step 220 Train loss 0.42 on epoch=1
06/16/2022 18:37:21 - INFO - __main__ - Step 230 Global step 230 Train loss 0.36 on epoch=2
06/16/2022 18:37:24 - INFO - __main__ - Step 240 Global step 240 Train loss 0.36 on epoch=2
06/16/2022 18:37:26 - INFO - __main__ - Step 250 Global step 250 Train loss 0.26 on epoch=2
06/16/2022 18:38:23 - INFO - __main__ - Global step 250 Train loss 0.35 Classification-F1 0.5056889797583674 on epoch=2
06/16/2022 18:38:26 - INFO - __main__ - Step 260 Global step 260 Train loss 0.35 on epoch=2
06/16/2022 18:38:28 - INFO - __main__ - Step 270 Global step 270 Train loss 0.27 on epoch=2
06/16/2022 18:38:31 - INFO - __main__ - Step 280 Global step 280 Train loss 0.35 on epoch=2
06/16/2022 18:38:33 - INFO - __main__ - Step 290 Global step 290 Train loss 0.28 on epoch=2
06/16/2022 18:38:36 - INFO - __main__ - Step 300 Global step 300 Train loss 0.27 on epoch=2
06/16/2022 18:39:27 - INFO - __main__ - Global step 300 Train loss 0.30 Classification-F1 0.5584800356791649 on epoch=2
06/16/2022 18:39:27 - INFO - __main__ - Saving model with best Classification-F1: 0.5566951653746371 -> 0.5584800356791649 on epoch=2, global_step=300
06/16/2022 18:39:29 - INFO - __main__ - Step 310 Global step 310 Train loss 0.28 on epoch=2
06/16/2022 18:39:32 - INFO - __main__ - Step 320 Global step 320 Train loss 0.28 on epoch=2
06/16/2022 18:39:35 - INFO - __main__ - Step 330 Global step 330 Train loss 0.24 on epoch=2
06/16/2022 18:39:37 - INFO - __main__ - Step 340 Global step 340 Train loss 0.25 on epoch=3
06/16/2022 18:39:40 - INFO - __main__ - Step 350 Global step 350 Train loss 0.19 on epoch=3
06/16/2022 18:40:37 - INFO - __main__ - Global step 350 Train loss 0.24 Classification-F1 0.6235018742453293 on epoch=3
06/16/2022 18:40:37 - INFO - __main__ - Saving model with best Classification-F1: 0.5584800356791649 -> 0.6235018742453293 on epoch=3, global_step=350
06/16/2022 18:40:40 - INFO - __main__ - Step 360 Global step 360 Train loss 0.16 on epoch=3
06/16/2022 18:40:43 - INFO - __main__ - Step 370 Global step 370 Train loss 0.20 on epoch=3
06/16/2022 18:40:45 - INFO - __main__ - Step 380 Global step 380 Train loss 0.23 on epoch=3
06/16/2022 18:40:48 - INFO - __main__ - Step 390 Global step 390 Train loss 0.24 on epoch=3
06/16/2022 18:40:50 - INFO - __main__ - Step 400 Global step 400 Train loss 0.18 on epoch=3
06/16/2022 18:41:41 - INFO - __main__ - Global step 400 Train loss 0.21 Classification-F1 0.6310736755101453 on epoch=3
06/16/2022 18:41:41 - INFO - __main__ - Saving model with best Classification-F1: 0.6235018742453293 -> 0.6310736755101453 on epoch=3, global_step=400
06/16/2022 18:41:44 - INFO - __main__ - Step 410 Global step 410 Train loss 0.24 on epoch=3
06/16/2022 18:41:47 - INFO - __main__ - Step 420 Global step 420 Train loss 0.16 on epoch=3
06/16/2022 18:41:49 - INFO - __main__ - Step 430 Global step 430 Train loss 0.15 on epoch=3
06/16/2022 18:41:52 - INFO - __main__ - Step 440 Global step 440 Train loss 0.17 on epoch=3
06/16/2022 18:41:54 - INFO - __main__ - Step 450 Global step 450 Train loss 0.15 on epoch=4
06/16/2022 18:42:52 - INFO - __main__ - Global step 450 Train loss 0.17 Classification-F1 0.8559051872623136 on epoch=4
06/16/2022 18:42:52 - INFO - __main__ - Saving model with best Classification-F1: 0.6310736755101453 -> 0.8559051872623136 on epoch=4, global_step=450
06/16/2022 18:42:55 - INFO - __main__ - Step 460 Global step 460 Train loss 0.09 on epoch=4
06/16/2022 18:42:58 - INFO - __main__ - Step 470 Global step 470 Train loss 0.09 on epoch=4
06/16/2022 18:43:00 - INFO - __main__ - Step 480 Global step 480 Train loss 0.10 on epoch=4
06/16/2022 18:43:03 - INFO - __main__ - Step 490 Global step 490 Train loss 0.12 on epoch=4
06/16/2022 18:43:05 - INFO - __main__ - Step 500 Global step 500 Train loss 0.12 on epoch=4
06/16/2022 18:43:57 - INFO - __main__ - Global step 500 Train loss 0.10 Classification-F1 0.6916809727853894 on epoch=4
06/16/2022 18:43:59 - INFO - __main__ - Step 510 Global step 510 Train loss 0.11 on epoch=4
06/16/2022 18:44:02 - INFO - __main__ - Step 520 Global step 520 Train loss 0.17 on epoch=4
06/16/2022 18:44:05 - INFO - __main__ - Step 530 Global step 530 Train loss 0.18 on epoch=4
06/16/2022 18:44:07 - INFO - __main__ - Step 540 Global step 540 Train loss 0.22 on epoch=4
06/16/2022 18:44:10 - INFO - __main__ - Step 550 Global step 550 Train loss 0.15 on epoch=4
06/16/2022 18:45:02 - INFO - __main__ - Global step 550 Train loss 0.17 Classification-F1 0.7130429983340454 on epoch=4
06/16/2022 18:45:04 - INFO - __main__ - Step 560 Global step 560 Train loss 0.18 on epoch=4
06/16/2022 18:45:07 - INFO - __main__ - Step 570 Global step 570 Train loss 0.11 on epoch=5
06/16/2022 18:45:09 - INFO - __main__ - Step 580 Global step 580 Train loss 0.11 on epoch=5
06/16/2022 18:45:12 - INFO - __main__ - Step 590 Global step 590 Train loss 0.15 on epoch=5
06/16/2022 18:45:15 - INFO - __main__ - Step 600 Global step 600 Train loss 0.17 on epoch=5
06/16/2022 18:46:07 - INFO - __main__ - Global step 600 Train loss 0.14 Classification-F1 0.6743934833021878 on epoch=5
06/16/2022 18:46:10 - INFO - __main__ - Step 610 Global step 610 Train loss 0.19 on epoch=5
06/16/2022 18:46:12 - INFO - __main__ - Step 620 Global step 620 Train loss 0.12 on epoch=5
06/16/2022 18:46:15 - INFO - __main__ - Step 630 Global step 630 Train loss 0.10 on epoch=5
06/16/2022 18:46:17 - INFO - __main__ - Step 640 Global step 640 Train loss 0.09 on epoch=5
06/16/2022 18:46:20 - INFO - __main__ - Step 650 Global step 650 Train loss 0.26 on epoch=5
06/16/2022 18:47:06 - INFO - __main__ - Global step 650 Train loss 0.15 Classification-F1 0.6744708566444643 on epoch=5
06/16/2022 18:47:09 - INFO - __main__ - Step 660 Global step 660 Train loss 0.19 on epoch=5
06/16/2022 18:47:11 - INFO - __main__ - Step 670 Global step 670 Train loss 0.08 on epoch=5
06/16/2022 18:47:14 - INFO - __main__ - Step 680 Global step 680 Train loss 0.07 on epoch=6
06/16/2022 18:47:17 - INFO - __main__ - Step 690 Global step 690 Train loss 0.10 on epoch=6
06/16/2022 18:47:19 - INFO - __main__ - Step 700 Global step 700 Train loss 0.12 on epoch=6
06/16/2022 18:48:07 - INFO - __main__ - Global step 700 Train loss 0.11 Classification-F1 0.7586373009242106 on epoch=6
06/16/2022 18:48:09 - INFO - __main__ - Step 710 Global step 710 Train loss 0.11 on epoch=6
06/16/2022 18:48:12 - INFO - __main__ - Step 720 Global step 720 Train loss 0.10 on epoch=6
06/16/2022 18:48:14 - INFO - __main__ - Step 730 Global step 730 Train loss 0.11 on epoch=6
06/16/2022 18:48:17 - INFO - __main__ - Step 740 Global step 740 Train loss 0.09 on epoch=6
06/16/2022 18:48:20 - INFO - __main__ - Step 750 Global step 750 Train loss 0.07 on epoch=6
06/16/2022 18:49:10 - INFO - __main__ - Global step 750 Train loss 0.10 Classification-F1 0.6826118717994654 on epoch=6
06/16/2022 18:49:13 - INFO - __main__ - Step 760 Global step 760 Train loss 0.06 on epoch=6
06/16/2022 18:49:15 - INFO - __main__ - Step 770 Global step 770 Train loss 0.12 on epoch=6
06/16/2022 18:49:18 - INFO - __main__ - Step 780 Global step 780 Train loss 0.09 on epoch=6
06/16/2022 18:49:20 - INFO - __main__ - Step 790 Global step 790 Train loss 0.13 on epoch=7
06/16/2022 18:49:23 - INFO - __main__ - Step 800 Global step 800 Train loss 0.07 on epoch=7
06/16/2022 18:50:13 - INFO - __main__ - Global step 800 Train loss 0.09 Classification-F1 0.7537968638280577 on epoch=7
06/16/2022 18:50:15 - INFO - __main__ - Step 810 Global step 810 Train loss 0.07 on epoch=7
06/16/2022 18:50:18 - INFO - __main__ - Step 820 Global step 820 Train loss 0.09 on epoch=7
06/16/2022 18:50:20 - INFO - __main__ - Step 830 Global step 830 Train loss 0.05 on epoch=7
06/16/2022 18:50:23 - INFO - __main__ - Step 840 Global step 840 Train loss 0.05 on epoch=7
06/16/2022 18:50:25 - INFO - __main__ - Step 850 Global step 850 Train loss 0.11 on epoch=7
06/16/2022 18:51:14 - INFO - __main__ - Global step 850 Train loss 0.07 Classification-F1 0.676454211727701 on epoch=7
06/16/2022 18:51:17 - INFO - __main__ - Step 860 Global step 860 Train loss 0.07 on epoch=7
06/16/2022 18:51:20 - INFO - __main__ - Step 870 Global step 870 Train loss 0.05 on epoch=7
06/16/2022 18:51:22 - INFO - __main__ - Step 880 Global step 880 Train loss 0.11 on epoch=7
06/16/2022 18:51:25 - INFO - __main__ - Step 890 Global step 890 Train loss 0.08 on epoch=7
06/16/2022 18:51:27 - INFO - __main__ - Step 900 Global step 900 Train loss 0.09 on epoch=8
06/16/2022 18:52:15 - INFO - __main__ - Global step 900 Train loss 0.08 Classification-F1 0.6789781495003397 on epoch=8
06/16/2022 18:52:17 - INFO - __main__ - Step 910 Global step 910 Train loss 0.08 on epoch=8
06/16/2022 18:52:20 - INFO - __main__ - Step 920 Global step 920 Train loss 0.06 on epoch=8
06/16/2022 18:52:22 - INFO - __main__ - Step 930 Global step 930 Train loss 0.05 on epoch=8
06/16/2022 18:52:25 - INFO - __main__ - Step 940 Global step 940 Train loss 0.05 on epoch=8
06/16/2022 18:52:28 - INFO - __main__ - Step 950 Global step 950 Train loss 0.09 on epoch=8
06/16/2022 18:53:15 - INFO - __main__ - Global step 950 Train loss 0.06 Classification-F1 0.5919321459093788 on epoch=8
06/16/2022 18:53:18 - INFO - __main__ - Step 960 Global step 960 Train loss 0.07 on epoch=8
06/16/2022 18:53:20 - INFO - __main__ - Step 970 Global step 970 Train loss 0.05 on epoch=8
06/16/2022 18:53:23 - INFO - __main__ - Step 980 Global step 980 Train loss 0.05 on epoch=8
06/16/2022 18:53:25 - INFO - __main__ - Step 990 Global step 990 Train loss 0.04 on epoch=8
06/16/2022 18:53:28 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.09 on epoch=8
06/16/2022 18:54:15 - INFO - __main__ - Global step 1000 Train loss 0.06 Classification-F1 0.6382030937649391 on epoch=8
06/16/2022 18:54:18 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.04 on epoch=9
06/16/2022 18:54:20 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.02 on epoch=9
06/16/2022 18:54:23 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.03 on epoch=9
06/16/2022 18:54:25 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.06 on epoch=9
06/16/2022 18:54:28 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.13 on epoch=9
06/16/2022 18:55:15 - INFO - __main__ - Global step 1050 Train loss 0.06 Classification-F1 0.7093033743926188 on epoch=9
06/16/2022 18:55:18 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.08 on epoch=9
06/16/2022 18:55:20 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.08 on epoch=9
06/16/2022 18:55:23 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.07 on epoch=9
06/16/2022 18:55:26 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.04 on epoch=9
06/16/2022 18:55:28 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.07 on epoch=9
06/16/2022 18:56:16 - INFO - __main__ - Global step 1100 Train loss 0.07 Classification-F1 0.6029102371035201 on epoch=9
06/16/2022 18:56:18 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.06 on epoch=9
06/16/2022 18:56:21 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.04 on epoch=9
06/16/2022 18:56:24 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.02 on epoch=10
06/16/2022 18:56:26 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.02 on epoch=10
06/16/2022 18:56:29 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.07 on epoch=10
06/16/2022 18:57:15 - INFO - __main__ - Global step 1150 Train loss 0.04 Classification-F1 0.6804112255201172 on epoch=10
06/16/2022 18:57:18 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.04 on epoch=10
06/16/2022 18:57:20 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.09 on epoch=10
06/16/2022 18:57:23 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.03 on epoch=10
06/16/2022 18:57:26 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.09 on epoch=10
06/16/2022 18:57:28 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.03 on epoch=10
06/16/2022 18:58:16 - INFO - __main__ - Global step 1200 Train loss 0.05 Classification-F1 0.6520674174447038 on epoch=10
06/16/2022 18:58:18 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.08 on epoch=10
06/16/2022 18:58:21 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.04 on epoch=10
06/16/2022 18:58:23 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.03 on epoch=10
06/16/2022 18:58:26 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.04 on epoch=11
06/16/2022 18:58:29 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.04 on epoch=11
06/16/2022 18:59:15 - INFO - __main__ - Global step 1250 Train loss 0.05 Classification-F1 0.6807471873805918 on epoch=11
06/16/2022 18:59:18 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.06 on epoch=11
06/16/2022 18:59:20 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.05 on epoch=11
06/16/2022 18:59:23 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.04 on epoch=11
06/16/2022 18:59:25 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.08 on epoch=11
06/16/2022 18:59:28 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.04 on epoch=11
06/16/2022 19:00:16 - INFO - __main__ - Global step 1300 Train loss 0.05 Classification-F1 0.7466759457816203 on epoch=11
06/16/2022 19:00:19 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.04 on epoch=11
06/16/2022 19:00:21 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.05 on epoch=11
06/16/2022 19:00:24 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.02 on epoch=11
06/16/2022 19:00:27 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.07 on epoch=11
06/16/2022 19:00:29 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.04 on epoch=12
06/16/2022 19:01:16 - INFO - __main__ - Global step 1350 Train loss 0.04 Classification-F1 0.6761177900498645 on epoch=12
06/16/2022 19:01:19 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.02 on epoch=12
06/16/2022 19:01:21 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.04 on epoch=12
06/16/2022 19:01:24 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.05 on epoch=12
06/16/2022 19:01:26 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.02 on epoch=12
06/16/2022 19:01:29 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=12
06/16/2022 19:02:15 - INFO - __main__ - Global step 1400 Train loss 0.03 Classification-F1 0.6566796911697838 on epoch=12
06/16/2022 19:02:18 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.04 on epoch=12
06/16/2022 19:02:21 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.04 on epoch=12
06/16/2022 19:02:23 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.02 on epoch=12
06/16/2022 19:02:26 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.09 on epoch=12
06/16/2022 19:02:29 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.05 on epoch=12
06/16/2022 19:03:15 - INFO - __main__ - Global step 1450 Train loss 0.05 Classification-F1 0.5920561004858043 on epoch=12
06/16/2022 19:03:17 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.04 on epoch=13
06/16/2022 19:03:20 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.02 on epoch=13
06/16/2022 19:03:22 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=13
06/16/2022 19:03:25 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.05 on epoch=13
06/16/2022 19:03:28 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.06 on epoch=13
06/16/2022 19:04:15 - INFO - __main__ - Global step 1500 Train loss 0.03 Classification-F1 0.754464695757886 on epoch=13
06/16/2022 19:04:17 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.10 on epoch=13
06/16/2022 19:04:20 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.03 on epoch=13
06/16/2022 19:04:22 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.05 on epoch=13
06/16/2022 19:04:25 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=13
06/16/2022 19:04:28 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=13
06/16/2022 19:05:14 - INFO - __main__ - Global step 1550 Train loss 0.04 Classification-F1 0.7187682335418789 on epoch=13
06/16/2022 19:05:17 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.06 on epoch=13
06/16/2022 19:05:19 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.09 on epoch=14
06/16/2022 19:05:22 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.03 on epoch=14
06/16/2022 19:05:25 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.03 on epoch=14
06/16/2022 19:05:27 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.03 on epoch=14
06/16/2022 19:06:14 - INFO - __main__ - Global step 1600 Train loss 0.05 Classification-F1 0.6386717812957449 on epoch=14
06/16/2022 19:06:17 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.07 on epoch=14
06/16/2022 19:06:20 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.06 on epoch=14
06/16/2022 19:06:22 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.10 on epoch=14
06/16/2022 19:06:25 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.06 on epoch=14
06/16/2022 19:06:27 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=14
06/16/2022 19:07:13 - INFO - __main__ - Global step 1650 Train loss 0.06 Classification-F1 0.5464468901507672 on epoch=14
06/16/2022 19:07:15 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.03 on epoch=14
06/16/2022 19:07:18 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.03 on epoch=14
06/16/2022 19:07:20 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.06 on epoch=14
06/16/2022 19:07:23 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=15
06/16/2022 19:07:25 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=15
06/16/2022 19:08:14 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.5776967811836391 on epoch=15
06/16/2022 19:08:16 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=15
06/16/2022 19:08:19 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.02 on epoch=15
06/16/2022 19:08:21 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.04 on epoch=15
06/16/2022 19:08:24 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.04 on epoch=15
06/16/2022 19:08:26 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.06 on epoch=15
06/16/2022 19:09:13 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.5244874297994967 on epoch=15
06/16/2022 19:09:15 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=15
06/16/2022 19:09:18 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.04 on epoch=15
06/16/2022 19:09:20 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.04 on epoch=15
06/16/2022 19:09:23 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.03 on epoch=15
06/16/2022 19:09:25 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=16
06/16/2022 19:10:10 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.49897756841439217 on epoch=16
06/16/2022 19:10:13 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.04 on epoch=16
06/16/2022 19:10:16 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.11 on epoch=16
06/16/2022 19:10:18 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.05 on epoch=16
06/16/2022 19:10:21 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.04 on epoch=16
06/16/2022 19:10:23 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.04 on epoch=16
06/16/2022 19:11:08 - INFO - __main__ - Global step 1850 Train loss 0.06 Classification-F1 0.5990843733546357 on epoch=16
06/16/2022 19:11:10 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=16
06/16/2022 19:11:13 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.03 on epoch=16
06/16/2022 19:11:16 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.03 on epoch=16
06/16/2022 19:11:18 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.05 on epoch=16
06/16/2022 19:11:21 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.02 on epoch=16
06/16/2022 19:12:06 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.5241236508404118 on epoch=16
06/16/2022 19:12:09 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.04 on epoch=17
06/16/2022 19:12:12 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=17
06/16/2022 19:12:14 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=17
06/16/2022 19:12:17 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=17
06/16/2022 19:12:19 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=17
06/16/2022 19:13:06 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.6102094308256683 on epoch=17
06/16/2022 19:13:08 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=17
06/16/2022 19:13:11 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.05 on epoch=17
06/16/2022 19:13:13 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=17
06/16/2022 19:13:16 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=17
06/16/2022 19:13:19 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=17
06/16/2022 19:14:06 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.6427498914479697 on epoch=17
06/16/2022 19:14:08 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=17
06/16/2022 19:14:11 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.03 on epoch=18
06/16/2022 19:14:14 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.04 on epoch=18
06/16/2022 19:14:16 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=18
06/16/2022 19:14:19 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=18
06/16/2022 19:15:07 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.6720416114186365 on epoch=18
06/16/2022 19:15:09 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=18
06/16/2022 19:15:12 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.05 on epoch=18
06/16/2022 19:15:14 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.07 on epoch=18
06/16/2022 19:15:17 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=18
06/16/2022 19:15:20 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=18
06/16/2022 19:16:07 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.5556505485280018 on epoch=18
06/16/2022 19:16:09 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=18
06/16/2022 19:16:12 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.03 on epoch=18
06/16/2022 19:16:14 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.04 on epoch=19
06/16/2022 19:16:17 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=19
06/16/2022 19:16:20 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=19
06/16/2022 19:17:07 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.6226422507214585 on epoch=19
06/16/2022 19:17:10 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=19
06/16/2022 19:17:12 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.08 on epoch=19
06/16/2022 19:17:15 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=19
06/16/2022 19:17:17 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.06 on epoch=19
06/16/2022 19:17:20 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.04 on epoch=19
06/16/2022 19:18:06 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.512448517166001 on epoch=19
06/16/2022 19:18:09 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=19
06/16/2022 19:18:11 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=19
06/16/2022 19:18:14 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=19
06/16/2022 19:18:16 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.05 on epoch=19
06/16/2022 19:18:19 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=20
06/16/2022 19:19:07 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.6844517893600033 on epoch=20
06/16/2022 19:19:10 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=20
06/16/2022 19:19:12 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=20
06/16/2022 19:19:15 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.04 on epoch=20
06/16/2022 19:19:17 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.09 on epoch=20
06/16/2022 19:19:20 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=20
06/16/2022 19:20:07 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.6377593924277454 on epoch=20
06/16/2022 19:20:09 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.05 on epoch=20
06/16/2022 19:20:12 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.04 on epoch=20
06/16/2022 19:20:14 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=20
06/16/2022 19:20:17 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.04 on epoch=20
06/16/2022 19:20:19 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=20
06/16/2022 19:21:04 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.5844207735767332 on epoch=20
06/16/2022 19:21:07 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=21
06/16/2022 19:21:10 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=21
06/16/2022 19:21:12 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=21
06/16/2022 19:21:15 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.04 on epoch=21
06/16/2022 19:21:17 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=21
06/16/2022 19:22:02 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.5683799397033636 on epoch=21
06/16/2022 19:22:05 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.04 on epoch=21
06/16/2022 19:22:07 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.06 on epoch=21
06/16/2022 19:22:10 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=21
06/16/2022 19:22:13 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=21
06/16/2022 19:22:15 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=21
06/16/2022 19:23:01 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.5167939870838478 on epoch=21
06/16/2022 19:23:03 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=21
06/16/2022 19:23:06 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=22
06/16/2022 19:23:09 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=22
06/16/2022 19:23:11 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=22
06/16/2022 19:23:14 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.03 on epoch=22
06/16/2022 19:23:59 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.585842217065029 on epoch=22
06/16/2022 19:24:01 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=22
06/16/2022 19:24:04 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.05 on epoch=22
06/16/2022 19:24:06 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.04 on epoch=22
06/16/2022 19:24:09 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=22
06/16/2022 19:24:12 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=22
06/16/2022 19:24:57 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.7585246132914222 on epoch=22
06/16/2022 19:25:00 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=22
06/16/2022 19:25:02 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=22
06/16/2022 19:25:05 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=23
06/16/2022 19:25:08 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=23
06/16/2022 19:25:10 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=23
06/16/2022 19:25:56 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.6407746098255048 on epoch=23
06/16/2022 19:25:58 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=23
06/16/2022 19:26:01 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=23
06/16/2022 19:26:03 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.05 on epoch=23
06/16/2022 19:26:06 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.05 on epoch=23
06/16/2022 19:26:09 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.04 on epoch=23
06/16/2022 19:26:55 - INFO - __main__ - Global step 2650 Train loss 0.04 Classification-F1 0.5764062650099951 on epoch=23
06/16/2022 19:26:57 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.04 on epoch=23
06/16/2022 19:27:00 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=23
06/16/2022 19:27:02 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.04 on epoch=23
06/16/2022 19:27:05 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.07 on epoch=24
06/16/2022 19:27:08 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=24
06/16/2022 19:27:53 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.5695046459689265 on epoch=24
06/16/2022 19:27:56 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=24
06/16/2022 19:27:59 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=24
06/16/2022 19:28:01 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.04 on epoch=24
06/16/2022 19:28:04 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.03 on epoch=24
06/16/2022 19:28:06 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=24
06/16/2022 19:28:51 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.590040843443286 on epoch=24
06/16/2022 19:28:53 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=24
06/16/2022 19:28:56 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=24
06/16/2022 19:28:58 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=24
06/16/2022 19:29:01 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=24
06/16/2022 19:29:04 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=24
06/16/2022 19:29:49 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.6384169160068249 on epoch=24
06/16/2022 19:29:52 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=25
06/16/2022 19:29:54 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=25
06/16/2022 19:29:57 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=25
06/16/2022 19:30:00 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=25
06/16/2022 19:30:02 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=25
06/16/2022 19:30:47 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.6610063448277501 on epoch=25
06/16/2022 19:30:49 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=25
06/16/2022 19:30:52 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.03 on epoch=25
06/16/2022 19:30:55 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=25
06/16/2022 19:30:57 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.03 on epoch=25
06/16/2022 19:31:00 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.04 on epoch=25
06/16/2022 19:31:44 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.5301918737518619 on epoch=25
06/16/2022 19:31:46 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=25
06/16/2022 19:31:49 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=26
06/16/2022 19:31:52 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=26
06/16/2022 19:31:54 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=26
06/16/2022 19:31:57 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=26
06/16/2022 19:32:44 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.6772037156297566 on epoch=26
06/16/2022 19:32:46 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=26
06/16/2022 19:32:49 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=26
06/16/2022 19:32:51 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.04 on epoch=26
06/16/2022 19:32:54 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=26
06/16/2022 19:32:57 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.03 on epoch=26
06/16/2022 19:32:58 - INFO - __main__ - Start tokenizing ... 1792 instances
06/16/2022 19:32:58 - INFO - __main__ - Printing 3 examples
06/16/2022 19:32:58 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/16/2022 19:32:58 - INFO - __main__ - ['Plant']
06/16/2022 19:32:58 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/16/2022 19:32:58 - INFO - __main__ - ['Plant']
06/16/2022 19:32:58 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/16/2022 19:32:58 - INFO - __main__ - ['Plant']
06/16/2022 19:32:58 - INFO - __main__ - Tokenizing Input ...
06/16/2022 19:32:59 - INFO - __main__ - Tokenizing Output ...
06/16/2022 19:33:01 - INFO - __main__ - Loaded 1792 examples from train data
06/16/2022 19:33:01 - INFO - __main__ - Start tokenizing ... 1792 instances
06/16/2022 19:33:01 - INFO - __main__ - Printing 3 examples
06/16/2022 19:33:01 - INFO - __main__ -  [dbpedia_14] Sabal pumos is a species of flowering plant in the palm tree family Arecaceae. It is native to the dry forests along the Balsas River in central Mexico (Guanajuato Guerrero Jalisco Michoacán Morelos Zacatecas and the State of México). It is threatened by habitat loss.
06/16/2022 19:33:01 - INFO - __main__ - ['Plant']
06/16/2022 19:33:01 - INFO - __main__ -  [dbpedia_14] Bulbophyllum intricatum is a species of orchid in the genus Bulbophyllum.
06/16/2022 19:33:01 - INFO - __main__ - ['Plant']
06/16/2022 19:33:01 - INFO - __main__ -  [dbpedia_14] Gentiana parryi (Parry's Gentian) is a species of the genus Gentiana.
06/16/2022 19:33:01 - INFO - __main__ - ['Plant']
06/16/2022 19:33:01 - INFO - __main__ - Tokenizing Input ...
06/16/2022 19:33:02 - INFO - __main__ - Tokenizing Output ...
06/16/2022 19:33:03 - INFO - __main__ - Loaded 1792 examples from dev data
06/16/2022 19:33:21 - INFO - __main__ - load prompt embedding from ckpt
06/16/2022 19:33:22 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/16/2022 19:33:22 - INFO - __main__ - Starting training!
06/16/2022 19:33:41 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.6619853696877979 on epoch=26
06/16/2022 19:33:41 - INFO - __main__ - save last model!
06/16/2022 19:33:41 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/16/2022 19:33:41 - INFO - __main__ - Start tokenizing ... 3500 instances
06/16/2022 19:33:41 - INFO - __main__ - Printing 3 examples
06/16/2022 19:33:41 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/16/2022 19:33:41 - INFO - __main__ - ['Animal']
06/16/2022 19:33:41 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/16/2022 19:33:41 - INFO - __main__ - ['Animal']
06/16/2022 19:33:41 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/16/2022 19:33:41 - INFO - __main__ - ['Village']
06/16/2022 19:33:41 - INFO - __main__ - Tokenizing Input ...
06/16/2022 19:33:43 - INFO - __main__ - Tokenizing Output ...
06/16/2022 19:33:46 - INFO - __main__ - Loaded 3500 examples from test data
06/16/2022 19:35:48 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down128shot/singletask-dbpedia_14/dbpedia_14_128_21_0.4_8_predictions.txt
06/16/2022 19:35:48 - INFO - __main__ - Classification-F1 on test data: 0.5056
06/16/2022 19:35:48 - INFO - __main__ - prefix=dbpedia_14_128_21, lr=0.4, bsz=8, dev_performance=0.8559051872623136, test_performance=0.5056052001564058
06/16/2022 19:35:48 - INFO - __main__ - Running ... prefix=dbpedia_14_128_21, lr=0.3, bsz=8 ...
06/16/2022 19:35:49 - INFO - __main__ - Start tokenizing ... 1792 instances
06/16/2022 19:35:49 - INFO - __main__ - Printing 3 examples
06/16/2022 19:35:49 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/16/2022 19:35:49 - INFO - __main__ - ['Plant']
06/16/2022 19:35:49 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/16/2022 19:35:49 - INFO - __main__ - ['Plant']
06/16/2022 19:35:49 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/16/2022 19:35:49 - INFO - __main__ - ['Plant']
06/16/2022 19:35:49 - INFO - __main__ - Tokenizing Input ...
06/16/2022 19:35:50 - INFO - __main__ - Tokenizing Output ...
06/16/2022 19:35:52 - INFO - __main__ - Loaded 1792 examples from train data
06/16/2022 19:35:52 - INFO - __main__ - Start tokenizing ... 1792 instances
06/16/2022 19:35:52 - INFO - __main__ - Printing 3 examples
06/16/2022 19:35:52 - INFO - __main__ -  [dbpedia_14] Sabal pumos is a species of flowering plant in the palm tree family Arecaceae. It is native to the dry forests along the Balsas River in central Mexico (Guanajuato Guerrero Jalisco Michoacán Morelos Zacatecas and the State of México). It is threatened by habitat loss.
06/16/2022 19:35:52 - INFO - __main__ - ['Plant']
06/16/2022 19:35:52 - INFO - __main__ -  [dbpedia_14] Bulbophyllum intricatum is a species of orchid in the genus Bulbophyllum.
06/16/2022 19:35:52 - INFO - __main__ - ['Plant']
06/16/2022 19:35:52 - INFO - __main__ -  [dbpedia_14] Gentiana parryi (Parry's Gentian) is a species of the genus Gentiana.
06/16/2022 19:35:52 - INFO - __main__ - ['Plant']
06/16/2022 19:35:52 - INFO - __main__ - Tokenizing Input ...
06/16/2022 19:35:53 - INFO - __main__ - Tokenizing Output ...
06/16/2022 19:35:54 - INFO - __main__ - Loaded 1792 examples from dev data
06/16/2022 19:36:10 - INFO - __main__ - load prompt embedding from ckpt
06/16/2022 19:36:10 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/16/2022 19:36:10 - INFO - __main__ - Starting training!
06/16/2022 19:36:14 - INFO - __main__ - Step 10 Global step 10 Train loss 5.12 on epoch=0
06/16/2022 19:36:17 - INFO - __main__ - Step 20 Global step 20 Train loss 3.43 on epoch=0
06/16/2022 19:36:20 - INFO - __main__ - Step 30 Global step 30 Train loss 2.47 on epoch=0
06/16/2022 19:36:22 - INFO - __main__ - Step 40 Global step 40 Train loss 1.90 on epoch=0
06/16/2022 19:36:25 - INFO - __main__ - Step 50 Global step 50 Train loss 1.80 on epoch=0
06/16/2022 19:37:12 - INFO - __main__ - Global step 50 Train loss 2.95 Classification-F1 0.047646024962900074 on epoch=0
06/16/2022 19:37:12 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.047646024962900074 on epoch=0, global_step=50
06/16/2022 19:37:14 - INFO - __main__ - Step 60 Global step 60 Train loss 1.59 on epoch=0
06/16/2022 19:37:17 - INFO - __main__ - Step 70 Global step 70 Train loss 1.14 on epoch=0
06/16/2022 19:37:20 - INFO - __main__ - Step 80 Global step 80 Train loss 1.14 on epoch=0
06/16/2022 19:37:23 - INFO - __main__ - Step 90 Global step 90 Train loss 1.12 on epoch=0
06/16/2022 19:37:26 - INFO - __main__ - Step 100 Global step 100 Train loss 0.75 on epoch=0
06/16/2022 19:38:19 - INFO - __main__ - Global step 100 Train loss 1.15 Classification-F1 0.26444021419543556 on epoch=0
06/16/2022 19:38:19 - INFO - __main__ - Saving model with best Classification-F1: 0.047646024962900074 -> 0.26444021419543556 on epoch=0, global_step=100
06/16/2022 19:38:22 - INFO - __main__ - Step 110 Global step 110 Train loss 0.83 on epoch=0
06/16/2022 19:38:25 - INFO - __main__ - Step 120 Global step 120 Train loss 0.78 on epoch=1
06/16/2022 19:38:27 - INFO - __main__ - Step 130 Global step 130 Train loss 0.70 on epoch=1
06/16/2022 19:38:30 - INFO - __main__ - Step 140 Global step 140 Train loss 0.71 on epoch=1
06/16/2022 19:38:33 - INFO - __main__ - Step 150 Global step 150 Train loss 0.55 on epoch=1
06/16/2022 19:39:25 - INFO - __main__ - Global step 150 Train loss 0.71 Classification-F1 0.41880371049732035 on epoch=1
06/16/2022 19:39:25 - INFO - __main__ - Saving model with best Classification-F1: 0.26444021419543556 -> 0.41880371049732035 on epoch=1, global_step=150
06/16/2022 19:39:28 - INFO - __main__ - Step 160 Global step 160 Train loss 0.55 on epoch=1
06/16/2022 19:39:30 - INFO - __main__ - Step 170 Global step 170 Train loss 0.65 on epoch=1
06/16/2022 19:39:33 - INFO - __main__ - Step 180 Global step 180 Train loss 0.57 on epoch=1
06/16/2022 19:39:35 - INFO - __main__ - Step 190 Global step 190 Train loss 0.54 on epoch=1
06/16/2022 19:39:38 - INFO - __main__ - Step 200 Global step 200 Train loss 0.61 on epoch=1
06/16/2022 19:40:33 - INFO - __main__ - Global step 200 Train loss 0.58 Classification-F1 0.4626312368710891 on epoch=1
06/16/2022 19:40:34 - INFO - __main__ - Saving model with best Classification-F1: 0.41880371049732035 -> 0.4626312368710891 on epoch=1, global_step=200
06/16/2022 19:40:36 - INFO - __main__ - Step 210 Global step 210 Train loss 0.48 on epoch=1
06/16/2022 19:40:39 - INFO - __main__ - Step 220 Global step 220 Train loss 0.45 on epoch=1
06/16/2022 19:40:41 - INFO - __main__ - Step 230 Global step 230 Train loss 0.42 on epoch=2
06/16/2022 19:40:44 - INFO - __main__ - Step 240 Global step 240 Train loss 0.40 on epoch=2
06/16/2022 19:40:47 - INFO - __main__ - Step 250 Global step 250 Train loss 0.47 on epoch=2
06/16/2022 19:41:41 - INFO - __main__ - Global step 250 Train loss 0.44 Classification-F1 0.5669830642704577 on epoch=2
06/16/2022 19:41:41 - INFO - __main__ - Saving model with best Classification-F1: 0.4626312368710891 -> 0.5669830642704577 on epoch=2, global_step=250
06/16/2022 19:41:44 - INFO - __main__ - Step 260 Global step 260 Train loss 0.37 on epoch=2
06/16/2022 19:41:46 - INFO - __main__ - Step 270 Global step 270 Train loss 0.36 on epoch=2
06/16/2022 19:41:49 - INFO - __main__ - Step 280 Global step 280 Train loss 0.39 on epoch=2
06/16/2022 19:41:51 - INFO - __main__ - Step 290 Global step 290 Train loss 0.33 on epoch=2
06/16/2022 19:41:54 - INFO - __main__ - Step 300 Global step 300 Train loss 0.33 on epoch=2
06/16/2022 19:42:50 - INFO - __main__ - Global step 300 Train loss 0.36 Classification-F1 0.5469651705095762 on epoch=2
06/16/2022 19:42:52 - INFO - __main__ - Step 310 Global step 310 Train loss 0.40 on epoch=2
06/16/2022 19:42:55 - INFO - __main__ - Step 320 Global step 320 Train loss 0.43 on epoch=2
06/16/2022 19:42:57 - INFO - __main__ - Step 330 Global step 330 Train loss 0.39 on epoch=2
06/16/2022 19:43:00 - INFO - __main__ - Step 340 Global step 340 Train loss 0.34 on epoch=3
06/16/2022 19:43:03 - INFO - __main__ - Step 350 Global step 350 Train loss 0.29 on epoch=3
06/16/2022 19:44:00 - INFO - __main__ - Global step 350 Train loss 0.37 Classification-F1 0.6324122008532947 on epoch=3
06/16/2022 19:44:00 - INFO - __main__ - Saving model with best Classification-F1: 0.5669830642704577 -> 0.6324122008532947 on epoch=3, global_step=350
06/16/2022 19:44:03 - INFO - __main__ - Step 360 Global step 360 Train loss 0.22 on epoch=3
06/16/2022 19:44:05 - INFO - __main__ - Step 370 Global step 370 Train loss 0.28 on epoch=3
06/16/2022 19:44:08 - INFO - __main__ - Step 380 Global step 380 Train loss 0.24 on epoch=3
06/16/2022 19:44:11 - INFO - __main__ - Step 390 Global step 390 Train loss 0.30 on epoch=3
06/16/2022 19:44:13 - INFO - __main__ - Step 400 Global step 400 Train loss 0.27 on epoch=3
06/16/2022 19:45:18 - INFO - __main__ - Global step 400 Train loss 0.26 Classification-F1 0.7734101477660057 on epoch=3
06/16/2022 19:45:18 - INFO - __main__ - Saving model with best Classification-F1: 0.6324122008532947 -> 0.7734101477660057 on epoch=3, global_step=400
06/16/2022 19:45:20 - INFO - __main__ - Step 410 Global step 410 Train loss 0.31 on epoch=3
06/16/2022 19:45:23 - INFO - __main__ - Step 420 Global step 420 Train loss 0.16 on epoch=3
06/16/2022 19:45:26 - INFO - __main__ - Step 430 Global step 430 Train loss 0.24 on epoch=3
06/16/2022 19:45:28 - INFO - __main__ - Step 440 Global step 440 Train loss 0.27 on epoch=3
06/16/2022 19:45:31 - INFO - __main__ - Step 450 Global step 450 Train loss 0.23 on epoch=4
06/16/2022 19:46:33 - INFO - __main__ - Global step 450 Train loss 0.24 Classification-F1 0.589703391780047 on epoch=4
06/16/2022 19:46:36 - INFO - __main__ - Step 460 Global step 460 Train loss 0.22 on epoch=4
06/16/2022 19:46:38 - INFO - __main__ - Step 470 Global step 470 Train loss 0.24 on epoch=4
06/16/2022 19:46:41 - INFO - __main__ - Step 480 Global step 480 Train loss 0.19 on epoch=4
06/16/2022 19:46:44 - INFO - __main__ - Step 490 Global step 490 Train loss 0.30 on epoch=4
06/16/2022 19:46:46 - INFO - __main__ - Step 500 Global step 500 Train loss 0.21 on epoch=4
06/16/2022 19:47:48 - INFO - __main__ - Global step 500 Train loss 0.23 Classification-F1 0.6647995460346512 on epoch=4
06/16/2022 19:47:50 - INFO - __main__ - Step 510 Global step 510 Train loss 0.24 on epoch=4
06/16/2022 19:47:53 - INFO - __main__ - Step 520 Global step 520 Train loss 0.21 on epoch=4
06/16/2022 19:47:56 - INFO - __main__ - Step 530 Global step 530 Train loss 0.17 on epoch=4
06/16/2022 19:47:58 - INFO - __main__ - Step 540 Global step 540 Train loss 0.24 on epoch=4
06/16/2022 19:48:01 - INFO - __main__ - Step 550 Global step 550 Train loss 0.11 on epoch=4
06/16/2022 19:49:05 - INFO - __main__ - Global step 550 Train loss 0.20 Classification-F1 0.7814760314200938 on epoch=4
06/16/2022 19:49:05 - INFO - __main__ - Saving model with best Classification-F1: 0.7734101477660057 -> 0.7814760314200938 on epoch=4, global_step=550
06/16/2022 19:49:08 - INFO - __main__ - Step 560 Global step 560 Train loss 0.24 on epoch=4
06/16/2022 19:49:11 - INFO - __main__ - Step 570 Global step 570 Train loss 0.12 on epoch=5
06/16/2022 19:49:14 - INFO - __main__ - Step 580 Global step 580 Train loss 0.11 on epoch=5
06/16/2022 19:49:16 - INFO - __main__ - Step 590 Global step 590 Train loss 0.16 on epoch=5
06/16/2022 19:49:19 - INFO - __main__ - Step 600 Global step 600 Train loss 0.26 on epoch=5
06/16/2022 19:50:22 - INFO - __main__ - Global step 600 Train loss 0.18 Classification-F1 0.7497345409415955 on epoch=5
06/16/2022 19:50:25 - INFO - __main__ - Step 610 Global step 610 Train loss 0.24 on epoch=5
06/16/2022 19:50:27 - INFO - __main__ - Step 620 Global step 620 Train loss 0.24 on epoch=5
06/16/2022 19:50:30 - INFO - __main__ - Step 630 Global step 630 Train loss 0.17 on epoch=5
06/16/2022 19:50:33 - INFO - __main__ - Step 640 Global step 640 Train loss 0.18 on epoch=5
06/16/2022 19:50:35 - INFO - __main__ - Step 650 Global step 650 Train loss 0.22 on epoch=5
06/16/2022 19:51:34 - INFO - __main__ - Global step 650 Train loss 0.21 Classification-F1 0.7074273391122139 on epoch=5
06/16/2022 19:51:37 - INFO - __main__ - Step 660 Global step 660 Train loss 0.14 on epoch=5
06/16/2022 19:51:39 - INFO - __main__ - Step 670 Global step 670 Train loss 0.23 on epoch=5
06/16/2022 19:51:42 - INFO - __main__ - Step 680 Global step 680 Train loss 0.19 on epoch=6
06/16/2022 19:51:45 - INFO - __main__ - Step 690 Global step 690 Train loss 0.12 on epoch=6
06/16/2022 19:51:47 - INFO - __main__ - Step 700 Global step 700 Train loss 0.16 on epoch=6
06/16/2022 19:52:47 - INFO - __main__ - Global step 700 Train loss 0.17 Classification-F1 0.759576844734923 on epoch=6
06/16/2022 19:52:50 - INFO - __main__ - Step 710 Global step 710 Train loss 0.14 on epoch=6
06/16/2022 19:52:52 - INFO - __main__ - Step 720 Global step 720 Train loss 0.14 on epoch=6
06/16/2022 19:52:55 - INFO - __main__ - Step 730 Global step 730 Train loss 0.16 on epoch=6
06/16/2022 19:52:58 - INFO - __main__ - Step 740 Global step 740 Train loss 0.16 on epoch=6
06/16/2022 19:53:00 - INFO - __main__ - Step 750 Global step 750 Train loss 0.11 on epoch=6
06/16/2022 19:54:02 - INFO - __main__ - Global step 750 Train loss 0.14 Classification-F1 0.8561306038991838 on epoch=6
06/16/2022 19:54:02 - INFO - __main__ - Saving model with best Classification-F1: 0.7814760314200938 -> 0.8561306038991838 on epoch=6, global_step=750
06/16/2022 19:54:05 - INFO - __main__ - Step 760 Global step 760 Train loss 0.19 on epoch=6
06/16/2022 19:54:08 - INFO - __main__ - Step 770 Global step 770 Train loss 0.22 on epoch=6
06/16/2022 19:54:10 - INFO - __main__ - Step 780 Global step 780 Train loss 0.11 on epoch=6
06/16/2022 19:54:13 - INFO - __main__ - Step 790 Global step 790 Train loss 0.11 on epoch=7
06/16/2022 19:54:16 - INFO - __main__ - Step 800 Global step 800 Train loss 0.12 on epoch=7
06/16/2022 19:55:13 - INFO - __main__ - Global step 800 Train loss 0.15 Classification-F1 0.6727513664441075 on epoch=7
06/16/2022 19:55:16 - INFO - __main__ - Step 810 Global step 810 Train loss 0.13 on epoch=7
06/16/2022 19:55:18 - INFO - __main__ - Step 820 Global step 820 Train loss 0.13 on epoch=7
06/16/2022 19:55:21 - INFO - __main__ - Step 830 Global step 830 Train loss 0.11 on epoch=7
06/16/2022 19:55:24 - INFO - __main__ - Step 840 Global step 840 Train loss 0.16 on epoch=7
06/16/2022 19:55:26 - INFO - __main__ - Step 850 Global step 850 Train loss 0.12 on epoch=7
06/16/2022 19:56:26 - INFO - __main__ - Global step 850 Train loss 0.13 Classification-F1 0.74529004836775 on epoch=7
06/16/2022 19:56:29 - INFO - __main__ - Step 860 Global step 860 Train loss 0.14 on epoch=7
06/16/2022 19:56:31 - INFO - __main__ - Step 870 Global step 870 Train loss 0.11 on epoch=7
06/16/2022 19:56:34 - INFO - __main__ - Step 880 Global step 880 Train loss 0.10 on epoch=7
06/16/2022 19:56:36 - INFO - __main__ - Step 890 Global step 890 Train loss 0.11 on epoch=7
06/16/2022 19:56:39 - INFO - __main__ - Step 900 Global step 900 Train loss 0.17 on epoch=8
06/16/2022 19:57:41 - INFO - __main__ - Global step 900 Train loss 0.13 Classification-F1 0.858371196456198 on epoch=8
06/16/2022 19:57:41 - INFO - __main__ - Saving model with best Classification-F1: 0.8561306038991838 -> 0.858371196456198 on epoch=8, global_step=900
06/16/2022 19:57:44 - INFO - __main__ - Step 910 Global step 910 Train loss 0.11 on epoch=8
06/16/2022 19:57:47 - INFO - __main__ - Step 920 Global step 920 Train loss 0.11 on epoch=8
06/16/2022 19:57:49 - INFO - __main__ - Step 930 Global step 930 Train loss 0.10 on epoch=8
06/16/2022 19:57:52 - INFO - __main__ - Step 940 Global step 940 Train loss 0.11 on epoch=8
06/16/2022 19:57:54 - INFO - __main__ - Step 950 Global step 950 Train loss 0.16 on epoch=8
06/16/2022 19:58:49 - INFO - __main__ - Global step 950 Train loss 0.12 Classification-F1 0.7295680622024314 on epoch=8
06/16/2022 19:58:51 - INFO - __main__ - Step 960 Global step 960 Train loss 0.11 on epoch=8
06/16/2022 19:58:54 - INFO - __main__ - Step 970 Global step 970 Train loss 0.09 on epoch=8
06/16/2022 19:58:57 - INFO - __main__ - Step 980 Global step 980 Train loss 0.13 on epoch=8
06/16/2022 19:58:59 - INFO - __main__ - Step 990 Global step 990 Train loss 0.11 on epoch=8
06/16/2022 19:59:02 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.12 on epoch=8
06/16/2022 20:00:03 - INFO - __main__ - Global step 1000 Train loss 0.11 Classification-F1 0.8574264742864486 on epoch=8
06/16/2022 20:00:06 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.14 on epoch=9
06/16/2022 20:00:09 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.10 on epoch=9
06/16/2022 20:00:11 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.05 on epoch=9
06/16/2022 20:00:14 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.06 on epoch=9
06/16/2022 20:00:17 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.09 on epoch=9
06/16/2022 20:01:16 - INFO - __main__ - Global step 1050 Train loss 0.09 Classification-F1 0.7632327053718859 on epoch=9
06/16/2022 20:01:18 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.10 on epoch=9
06/16/2022 20:01:21 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.14 on epoch=9
06/16/2022 20:01:24 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.09 on epoch=9
06/16/2022 20:01:26 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.08 on epoch=9
06/16/2022 20:01:29 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.12 on epoch=9
06/16/2022 20:02:29 - INFO - __main__ - Global step 1100 Train loss 0.11 Classification-F1 0.7522777046631703 on epoch=9
06/16/2022 20:02:31 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.13 on epoch=9
06/16/2022 20:02:34 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.09 on epoch=9
06/16/2022 20:02:37 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.07 on epoch=10
06/16/2022 20:02:39 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.06 on epoch=10
06/16/2022 20:02:42 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.05 on epoch=10
06/16/2022 20:03:39 - INFO - __main__ - Global step 1150 Train loss 0.08 Classification-F1 0.809959459790413 on epoch=10
06/16/2022 20:03:42 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.08 on epoch=10
06/16/2022 20:03:44 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.16 on epoch=10
06/16/2022 20:03:47 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.09 on epoch=10
06/16/2022 20:03:49 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.06 on epoch=10
06/16/2022 20:03:52 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.05 on epoch=10
06/16/2022 20:04:52 - INFO - __main__ - Global step 1200 Train loss 0.09 Classification-F1 0.8035059381293652 on epoch=10
06/16/2022 20:04:55 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.15 on epoch=10
06/16/2022 20:04:57 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.08 on epoch=10
06/16/2022 20:05:00 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.05 on epoch=10
06/16/2022 20:05:02 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.14 on epoch=11
06/16/2022 20:05:05 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.06 on epoch=11
06/16/2022 20:06:05 - INFO - __main__ - Global step 1250 Train loss 0.10 Classification-F1 0.861070144087502 on epoch=11
06/16/2022 20:06:05 - INFO - __main__ - Saving model with best Classification-F1: 0.858371196456198 -> 0.861070144087502 on epoch=11, global_step=1250
06/16/2022 20:06:07 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.08 on epoch=11
06/16/2022 20:06:10 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.06 on epoch=11
06/16/2022 20:06:12 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.03 on epoch=11
06/16/2022 20:06:15 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.03 on epoch=11
06/16/2022 20:06:18 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.09 on epoch=11
06/16/2022 20:07:19 - INFO - __main__ - Global step 1300 Train loss 0.06 Classification-F1 0.8608299920545504 on epoch=11
06/16/2022 20:07:21 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.15 on epoch=11
06/16/2022 20:07:24 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.05 on epoch=11
06/16/2022 20:07:27 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.09 on epoch=11
06/16/2022 20:07:29 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.07 on epoch=11
06/16/2022 20:07:32 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.05 on epoch=12
06/16/2022 20:08:30 - INFO - __main__ - Global step 1350 Train loss 0.08 Classification-F1 0.9205502293953051 on epoch=12
06/16/2022 20:08:30 - INFO - __main__ - Saving model with best Classification-F1: 0.861070144087502 -> 0.9205502293953051 on epoch=12, global_step=1350
06/16/2022 20:08:33 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.03 on epoch=12
06/16/2022 20:08:35 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.05 on epoch=12
06/16/2022 20:08:38 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.04 on epoch=12
06/16/2022 20:08:41 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.06 on epoch=12
06/16/2022 20:08:43 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.10 on epoch=12
06/16/2022 20:09:43 - INFO - __main__ - Global step 1400 Train loss 0.06 Classification-F1 0.8060482274747507 on epoch=12
06/16/2022 20:09:45 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.09 on epoch=12
06/16/2022 20:09:48 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.03 on epoch=12
06/16/2022 20:09:51 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.09 on epoch=12
06/16/2022 20:09:53 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.06 on epoch=12
06/16/2022 20:09:56 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.10 on epoch=12
06/16/2022 20:10:54 - INFO - __main__ - Global step 1450 Train loss 0.07 Classification-F1 0.8097159313835703 on epoch=12
06/16/2022 20:10:56 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.18 on epoch=13
06/16/2022 20:10:59 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.04 on epoch=13
06/16/2022 20:11:02 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.02 on epoch=13
06/16/2022 20:11:04 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.07 on epoch=13
06/16/2022 20:11:07 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.06 on epoch=13
06/16/2022 20:12:05 - INFO - __main__ - Global step 1500 Train loss 0.08 Classification-F1 0.8104076848177153 on epoch=13
06/16/2022 20:12:07 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.12 on epoch=13
06/16/2022 20:12:10 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.06 on epoch=13
06/16/2022 20:12:13 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.08 on epoch=13
06/16/2022 20:12:16 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.04 on epoch=13
06/16/2022 20:12:18 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.05 on epoch=13
06/16/2022 20:13:15 - INFO - __main__ - Global step 1550 Train loss 0.07 Classification-F1 0.917938872807906 on epoch=13
06/16/2022 20:13:18 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.08 on epoch=13
06/16/2022 20:13:21 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.10 on epoch=14
06/16/2022 20:13:23 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.06 on epoch=14
06/16/2022 20:13:26 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.04 on epoch=14
06/16/2022 20:13:29 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=14
06/16/2022 20:14:22 - INFO - __main__ - Global step 1600 Train loss 0.06 Classification-F1 0.7638103671012026 on epoch=14
06/16/2022 20:14:24 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.07 on epoch=14
06/16/2022 20:14:27 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.06 on epoch=14
06/16/2022 20:14:30 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.06 on epoch=14
06/16/2022 20:14:32 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.05 on epoch=14
06/16/2022 20:14:35 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.04 on epoch=14
06/16/2022 20:15:32 - INFO - __main__ - Global step 1650 Train loss 0.06 Classification-F1 0.6826054484845374 on epoch=14
06/16/2022 20:15:34 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.04 on epoch=14
06/16/2022 20:15:37 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.06 on epoch=14
06/16/2022 20:15:40 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.06 on epoch=14
06/16/2022 20:15:42 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.02 on epoch=15
06/16/2022 20:15:45 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=15
06/16/2022 20:16:42 - INFO - __main__ - Global step 1700 Train loss 0.04 Classification-F1 0.8087901744237239 on epoch=15
06/16/2022 20:16:44 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.06 on epoch=15
06/16/2022 20:16:47 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=15
06/16/2022 20:16:49 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.07 on epoch=15
06/16/2022 20:16:52 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.07 on epoch=15
06/16/2022 20:16:55 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.07 on epoch=15
06/16/2022 20:17:51 - INFO - __main__ - Global step 1750 Train loss 0.06 Classification-F1 0.9174488715704754 on epoch=15
06/16/2022 20:17:53 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.05 on epoch=15
06/16/2022 20:17:56 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.10 on epoch=15
06/16/2022 20:17:59 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.07 on epoch=15
06/16/2022 20:18:01 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.03 on epoch=15
06/16/2022 20:18:04 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.03 on epoch=16
06/16/2022 20:18:59 - INFO - __main__ - Global step 1800 Train loss 0.05 Classification-F1 0.922133934812845 on epoch=16
06/16/2022 20:18:59 - INFO - __main__ - Saving model with best Classification-F1: 0.9205502293953051 -> 0.922133934812845 on epoch=16, global_step=1800
06/16/2022 20:19:01 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.04 on epoch=16
06/16/2022 20:19:04 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.05 on epoch=16
06/16/2022 20:19:07 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=16
06/16/2022 20:19:09 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.04 on epoch=16
06/16/2022 20:19:12 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.10 on epoch=16
06/16/2022 20:20:07 - INFO - __main__ - Global step 1850 Train loss 0.05 Classification-F1 0.8625339085791581 on epoch=16
06/16/2022 20:20:10 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.04 on epoch=16
06/16/2022 20:20:12 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=16
06/16/2022 20:20:15 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.04 on epoch=16
06/16/2022 20:20:18 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=16
06/16/2022 20:20:20 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.06 on epoch=16
06/16/2022 20:21:16 - INFO - __main__ - Global step 1900 Train loss 0.04 Classification-F1 0.8571779468458256 on epoch=16
06/16/2022 20:21:19 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.08 on epoch=17
06/16/2022 20:21:21 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.07 on epoch=17
06/16/2022 20:21:24 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.07 on epoch=17
06/16/2022 20:21:27 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=17
06/16/2022 20:21:29 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.05 on epoch=17
06/16/2022 20:22:26 - INFO - __main__ - Global step 1950 Train loss 0.06 Classification-F1 0.9192842828860773 on epoch=17
06/16/2022 20:22:29 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.07 on epoch=17
06/16/2022 20:22:32 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=17
06/16/2022 20:22:35 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.05 on epoch=17
06/16/2022 20:22:37 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.06 on epoch=17
06/16/2022 20:22:40 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.06 on epoch=17
06/16/2022 20:23:34 - INFO - __main__ - Global step 2000 Train loss 0.05 Classification-F1 0.9837964660231949 on epoch=17
06/16/2022 20:23:34 - INFO - __main__ - Saving model with best Classification-F1: 0.922133934812845 -> 0.9837964660231949 on epoch=17, global_step=2000
06/16/2022 20:23:37 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.06 on epoch=17
06/16/2022 20:23:39 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.07 on epoch=18
06/16/2022 20:23:42 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.02 on epoch=18
06/16/2022 20:23:45 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.08 on epoch=18
06/16/2022 20:23:48 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.05 on epoch=18
06/16/2022 20:24:42 - INFO - __main__ - Global step 2050 Train loss 0.05 Classification-F1 0.9200501920354545 on epoch=18
06/16/2022 20:24:45 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.02 on epoch=18
06/16/2022 20:24:47 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.05 on epoch=18
06/16/2022 20:24:50 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.04 on epoch=18
06/16/2022 20:24:53 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.04 on epoch=18
06/16/2022 20:24:55 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.06 on epoch=18
06/16/2022 20:25:48 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.7197114173231464 on epoch=18
06/16/2022 20:25:51 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=18
06/16/2022 20:25:53 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.07 on epoch=18
06/16/2022 20:25:56 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.09 on epoch=19
06/16/2022 20:25:59 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=19
06/16/2022 20:26:01 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.07 on epoch=19
06/16/2022 20:26:55 - INFO - __main__ - Global step 2150 Train loss 0.05 Classification-F1 0.757320367704722 on epoch=19
06/16/2022 20:26:58 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.05 on epoch=19
06/16/2022 20:27:00 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=19
06/16/2022 20:27:03 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=19
06/16/2022 20:27:06 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.04 on epoch=19
06/16/2022 20:27:08 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=19
06/16/2022 20:27:58 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.8476648031698415 on epoch=19
06/16/2022 20:28:01 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=19
06/16/2022 20:28:03 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=19
06/16/2022 20:28:06 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.05 on epoch=19
06/16/2022 20:28:08 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.03 on epoch=19
06/16/2022 20:28:11 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.03 on epoch=20
06/16/2022 20:29:06 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.7597600838723559 on epoch=20
06/16/2022 20:29:09 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.03 on epoch=20
06/16/2022 20:29:11 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.06 on epoch=20
06/16/2022 20:29:14 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=20
06/16/2022 20:29:16 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.05 on epoch=20
06/16/2022 20:29:19 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.05 on epoch=20
06/16/2022 20:30:15 - INFO - __main__ - Global step 2300 Train loss 0.04 Classification-F1 0.7653758985966692 on epoch=20
06/16/2022 20:30:18 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.04 on epoch=20
06/16/2022 20:30:20 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.04 on epoch=20
06/16/2022 20:30:23 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=20
06/16/2022 20:30:26 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.05 on epoch=20
06/16/2022 20:30:28 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=20
06/16/2022 20:31:23 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.7391376749757999 on epoch=20
06/16/2022 20:31:25 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.06 on epoch=21
06/16/2022 20:31:28 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=21
06/16/2022 20:31:31 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.03 on epoch=21
06/16/2022 20:31:33 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=21
06/16/2022 20:31:36 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.08 on epoch=21
06/16/2022 20:32:31 - INFO - __main__ - Global step 2400 Train loss 0.04 Classification-F1 0.6838725467553093 on epoch=21
06/16/2022 20:32:33 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.06 on epoch=21
06/16/2022 20:32:36 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.08 on epoch=21
06/16/2022 20:32:39 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.04 on epoch=21
06/16/2022 20:32:41 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=21
06/16/2022 20:32:44 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.05 on epoch=21
06/16/2022 20:33:37 - INFO - __main__ - Global step 2450 Train loss 0.05 Classification-F1 0.7147497213543107 on epoch=21
06/16/2022 20:33:39 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.05 on epoch=21
06/16/2022 20:33:42 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.04 on epoch=22
06/16/2022 20:33:45 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=22
06/16/2022 20:33:47 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=22
06/16/2022 20:33:50 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.09 on epoch=22
06/16/2022 20:34:41 - INFO - __main__ - Global step 2500 Train loss 0.04 Classification-F1 0.9189941162533738 on epoch=22
06/16/2022 20:34:43 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=22
06/16/2022 20:34:46 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.10 on epoch=22
06/16/2022 20:34:49 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.03 on epoch=22
06/16/2022 20:34:51 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.03 on epoch=22
06/16/2022 20:34:54 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=22
06/16/2022 20:35:50 - INFO - __main__ - Global step 2550 Train loss 0.04 Classification-F1 0.8615923685694256 on epoch=22
06/16/2022 20:35:52 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.07 on epoch=22
06/16/2022 20:35:55 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.05 on epoch=22
06/16/2022 20:35:57 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.04 on epoch=23
06/16/2022 20:36:00 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=23
06/16/2022 20:36:03 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.05 on epoch=23
06/16/2022 20:36:57 - INFO - __main__ - Global step 2600 Train loss 0.04 Classification-F1 0.9195246643614385 on epoch=23
06/16/2022 20:37:00 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=23
06/16/2022 20:37:03 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=23
06/16/2022 20:37:05 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.06 on epoch=23
06/16/2022 20:37:08 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.04 on epoch=23
06/16/2022 20:37:11 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.05 on epoch=23
06/16/2022 20:38:01 - INFO - __main__ - Global step 2650 Train loss 0.04 Classification-F1 0.8608042660466443 on epoch=23
06/16/2022 20:38:04 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.07 on epoch=23
06/16/2022 20:38:07 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=23
06/16/2022 20:38:09 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=23
06/16/2022 20:38:12 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=24
06/16/2022 20:38:15 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=24
06/16/2022 20:39:11 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.8618092647608149 on epoch=24
06/16/2022 20:39:13 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=24
06/16/2022 20:39:16 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=24
06/16/2022 20:39:19 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=24
06/16/2022 20:39:21 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.12 on epoch=24
06/16/2022 20:39:24 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.05 on epoch=24
06/16/2022 20:40:14 - INFO - __main__ - Global step 2750 Train loss 0.05 Classification-F1 0.7624641020449394 on epoch=24
06/16/2022 20:40:17 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.05 on epoch=24
06/16/2022 20:40:19 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=24
06/16/2022 20:40:22 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=24
06/16/2022 20:40:24 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=24
06/16/2022 20:40:27 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.05 on epoch=24
06/16/2022 20:41:17 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.7226331520448018 on epoch=24
06/16/2022 20:41:20 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=25
06/16/2022 20:41:22 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.03 on epoch=25
06/16/2022 20:41:25 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.05 on epoch=25
06/16/2022 20:41:28 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=25
06/16/2022 20:41:30 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.07 on epoch=25
06/16/2022 20:42:27 - INFO - __main__ - Global step 2850 Train loss 0.03 Classification-F1 0.6876270390226586 on epoch=25
06/16/2022 20:42:30 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=25
06/16/2022 20:42:33 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.08 on epoch=25
06/16/2022 20:42:35 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=25
06/16/2022 20:42:38 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=25
06/16/2022 20:42:40 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.10 on epoch=25
06/16/2022 20:43:37 - INFO - __main__ - Global step 2900 Train loss 0.05 Classification-F1 0.7193882054225581 on epoch=25
06/16/2022 20:43:39 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=25
06/16/2022 20:43:42 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=26
06/16/2022 20:43:45 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=26
06/16/2022 20:43:47 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=26
06/16/2022 20:43:50 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=26
06/16/2022 20:44:48 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.9205608448517808 on epoch=26
06/16/2022 20:44:50 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=26
06/16/2022 20:44:53 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=26
06/16/2022 20:44:56 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.05 on epoch=26
06/16/2022 20:44:58 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=26
06/16/2022 20:45:01 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.04 on epoch=26
06/16/2022 20:45:02 - INFO - __main__ - Start tokenizing ... 1792 instances
06/16/2022 20:45:02 - INFO - __main__ - Printing 3 examples
06/16/2022 20:45:02 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/16/2022 20:45:02 - INFO - __main__ - ['Plant']
06/16/2022 20:45:02 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/16/2022 20:45:02 - INFO - __main__ - ['Plant']
06/16/2022 20:45:02 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/16/2022 20:45:02 - INFO - __main__ - ['Plant']
06/16/2022 20:45:02 - INFO - __main__ - Tokenizing Input ...
06/16/2022 20:45:03 - INFO - __main__ - Tokenizing Output ...
06/16/2022 20:45:05 - INFO - __main__ - Loaded 1792 examples from train data
06/16/2022 20:45:05 - INFO - __main__ - Start tokenizing ... 1792 instances
06/16/2022 20:45:05 - INFO - __main__ - Printing 3 examples
06/16/2022 20:45:05 - INFO - __main__ -  [dbpedia_14] Sabal pumos is a species of flowering plant in the palm tree family Arecaceae. It is native to the dry forests along the Balsas River in central Mexico (Guanajuato Guerrero Jalisco Michoacán Morelos Zacatecas and the State of México). It is threatened by habitat loss.
06/16/2022 20:45:05 - INFO - __main__ - ['Plant']
06/16/2022 20:45:05 - INFO - __main__ -  [dbpedia_14] Bulbophyllum intricatum is a species of orchid in the genus Bulbophyllum.
06/16/2022 20:45:05 - INFO - __main__ - ['Plant']
06/16/2022 20:45:05 - INFO - __main__ -  [dbpedia_14] Gentiana parryi (Parry's Gentian) is a species of the genus Gentiana.
06/16/2022 20:45:05 - INFO - __main__ - ['Plant']
06/16/2022 20:45:05 - INFO - __main__ - Tokenizing Input ...
06/16/2022 20:45:06 - INFO - __main__ - Tokenizing Output ...
06/16/2022 20:45:08 - INFO - __main__ - Loaded 1792 examples from dev data
06/16/2022 20:45:24 - INFO - __main__ - load prompt embedding from ckpt
06/16/2022 20:45:25 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/16/2022 20:45:25 - INFO - __main__ - Starting training!
06/16/2022 20:45:49 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.7604924755756005 on epoch=26
06/16/2022 20:45:49 - INFO - __main__ - save last model!
06/16/2022 20:45:49 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/16/2022 20:45:49 - INFO - __main__ - Start tokenizing ... 3500 instances
06/16/2022 20:45:49 - INFO - __main__ - Printing 3 examples
06/16/2022 20:45:49 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/16/2022 20:45:49 - INFO - __main__ - ['Animal']
06/16/2022 20:45:49 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/16/2022 20:45:49 - INFO - __main__ - ['Animal']
06/16/2022 20:45:49 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/16/2022 20:45:49 - INFO - __main__ - ['Village']
06/16/2022 20:45:49 - INFO - __main__ - Tokenizing Input ...
06/16/2022 20:45:51 - INFO - __main__ - Tokenizing Output ...
06/16/2022 20:45:54 - INFO - __main__ - Loaded 3500 examples from test data
06/16/2022 20:47:59 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down128shot/singletask-dbpedia_14/dbpedia_14_128_21_0.3_8_predictions.txt
06/16/2022 20:47:59 - INFO - __main__ - Classification-F1 on test data: 0.5951
06/16/2022 20:47:59 - INFO - __main__ - prefix=dbpedia_14_128_21, lr=0.3, bsz=8, dev_performance=0.9837964660231949, test_performance=0.5951114034381277
06/16/2022 20:47:59 - INFO - __main__ - Running ... prefix=dbpedia_14_128_21, lr=0.2, bsz=8 ...
06/16/2022 20:48:00 - INFO - __main__ - Start tokenizing ... 1792 instances
06/16/2022 20:48:00 - INFO - __main__ - Printing 3 examples
06/16/2022 20:48:00 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/16/2022 20:48:00 - INFO - __main__ - ['Plant']
06/16/2022 20:48:00 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/16/2022 20:48:00 - INFO - __main__ - ['Plant']
06/16/2022 20:48:00 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/16/2022 20:48:00 - INFO - __main__ - ['Plant']
06/16/2022 20:48:00 - INFO - __main__ - Tokenizing Input ...
06/16/2022 20:48:01 - INFO - __main__ - Tokenizing Output ...
06/16/2022 20:48:02 - INFO - __main__ - Loaded 1792 examples from train data
06/16/2022 20:48:02 - INFO - __main__ - Start tokenizing ... 1792 instances
06/16/2022 20:48:02 - INFO - __main__ - Printing 3 examples
06/16/2022 20:48:02 - INFO - __main__ -  [dbpedia_14] Sabal pumos is a species of flowering plant in the palm tree family Arecaceae. It is native to the dry forests along the Balsas River in central Mexico (Guanajuato Guerrero Jalisco Michoacán Morelos Zacatecas and the State of México). It is threatened by habitat loss.
06/16/2022 20:48:02 - INFO - __main__ - ['Plant']
06/16/2022 20:48:02 - INFO - __main__ -  [dbpedia_14] Bulbophyllum intricatum is a species of orchid in the genus Bulbophyllum.
06/16/2022 20:48:02 - INFO - __main__ - ['Plant']
06/16/2022 20:48:02 - INFO - __main__ -  [dbpedia_14] Gentiana parryi (Parry's Gentian) is a species of the genus Gentiana.
06/16/2022 20:48:02 - INFO - __main__ - ['Plant']
06/16/2022 20:48:02 - INFO - __main__ - Tokenizing Input ...
06/16/2022 20:48:03 - INFO - __main__ - Tokenizing Output ...
06/16/2022 20:48:05 - INFO - __main__ - Loaded 1792 examples from dev data
06/16/2022 20:48:21 - INFO - __main__ - load prompt embedding from ckpt
06/16/2022 20:48:21 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/16/2022 20:48:21 - INFO - __main__ - Starting training!
06/16/2022 20:48:25 - INFO - __main__ - Step 10 Global step 10 Train loss 5.40 on epoch=0
06/16/2022 20:48:28 - INFO - __main__ - Step 20 Global step 20 Train loss 3.89 on epoch=0
06/16/2022 20:48:31 - INFO - __main__ - Step 30 Global step 30 Train loss 2.86 on epoch=0
06/16/2022 20:48:33 - INFO - __main__ - Step 40 Global step 40 Train loss 2.27 on epoch=0
06/16/2022 20:48:36 - INFO - __main__ - Step 50 Global step 50 Train loss 2.25 on epoch=0
06/16/2022 20:49:20 - INFO - __main__ - Global step 50 Train loss 3.33 Classification-F1 0.028539924925230237 on epoch=0
06/16/2022 20:49:20 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.028539924925230237 on epoch=0, global_step=50
06/16/2022 20:49:22 - INFO - __main__ - Step 60 Global step 60 Train loss 1.95 on epoch=0
06/16/2022 20:49:25 - INFO - __main__ - Step 70 Global step 70 Train loss 1.54 on epoch=0
06/16/2022 20:49:29 - INFO - __main__ - Step 80 Global step 80 Train loss 1.34 on epoch=0
06/16/2022 20:49:31 - INFO - __main__ - Step 90 Global step 90 Train loss 1.39 on epoch=0
06/16/2022 20:49:34 - INFO - __main__ - Step 100 Global step 100 Train loss 1.00 on epoch=0
06/16/2022 20:50:21 - INFO - __main__ - Global step 100 Train loss 1.44 Classification-F1 0.19917180954510602 on epoch=0
06/16/2022 20:50:21 - INFO - __main__ - Saving model with best Classification-F1: 0.028539924925230237 -> 0.19917180954510602 on epoch=0, global_step=100
06/16/2022 20:50:24 - INFO - __main__ - Step 110 Global step 110 Train loss 0.97 on epoch=0
06/16/2022 20:50:26 - INFO - __main__ - Step 120 Global step 120 Train loss 0.81 on epoch=1
06/16/2022 20:50:29 - INFO - __main__ - Step 130 Global step 130 Train loss 0.91 on epoch=1
06/16/2022 20:50:32 - INFO - __main__ - Step 140 Global step 140 Train loss 0.76 on epoch=1
06/16/2022 20:50:34 - INFO - __main__ - Step 150 Global step 150 Train loss 0.64 on epoch=1
06/16/2022 20:51:27 - INFO - __main__ - Global step 150 Train loss 0.82 Classification-F1 0.35479649533070373 on epoch=1
06/16/2022 20:51:27 - INFO - __main__ - Saving model with best Classification-F1: 0.19917180954510602 -> 0.35479649533070373 on epoch=1, global_step=150
06/16/2022 20:51:29 - INFO - __main__ - Step 160 Global step 160 Train loss 0.75 on epoch=1
06/16/2022 20:51:32 - INFO - __main__ - Step 170 Global step 170 Train loss 0.73 on epoch=1
06/16/2022 20:51:34 - INFO - __main__ - Step 180 Global step 180 Train loss 0.64 on epoch=1
06/16/2022 20:51:37 - INFO - __main__ - Step 190 Global step 190 Train loss 0.54 on epoch=1
06/16/2022 20:51:40 - INFO - __main__ - Step 200 Global step 200 Train loss 0.64 on epoch=1
06/16/2022 20:52:34 - INFO - __main__ - Global step 200 Train loss 0.66 Classification-F1 0.33007556766080953 on epoch=1
06/16/2022 20:52:36 - INFO - __main__ - Step 210 Global step 210 Train loss 0.69 on epoch=1
06/16/2022 20:52:39 - INFO - __main__ - Step 220 Global step 220 Train loss 0.57 on epoch=1
06/16/2022 20:52:42 - INFO - __main__ - Step 230 Global step 230 Train loss 0.53 on epoch=2
06/16/2022 20:52:44 - INFO - __main__ - Step 240 Global step 240 Train loss 0.53 on epoch=2
06/16/2022 20:52:47 - INFO - __main__ - Step 250 Global step 250 Train loss 0.50 on epoch=2
06/16/2022 20:53:39 - INFO - __main__ - Global step 250 Train loss 0.56 Classification-F1 0.47469843539513223 on epoch=2
06/16/2022 20:53:39 - INFO - __main__ - Saving model with best Classification-F1: 0.35479649533070373 -> 0.47469843539513223 on epoch=2, global_step=250
06/16/2022 20:53:41 - INFO - __main__ - Step 260 Global step 260 Train loss 0.51 on epoch=2
06/16/2022 20:53:44 - INFO - __main__ - Step 270 Global step 270 Train loss 0.54 on epoch=2
06/16/2022 20:53:46 - INFO - __main__ - Step 280 Global step 280 Train loss 0.60 on epoch=2
06/16/2022 20:53:49 - INFO - __main__ - Step 290 Global step 290 Train loss 0.46 on epoch=2
06/16/2022 20:53:52 - INFO - __main__ - Step 300 Global step 300 Train loss 0.46 on epoch=2
06/16/2022 20:54:48 - INFO - __main__ - Global step 300 Train loss 0.51 Classification-F1 0.39242841129209854 on epoch=2
06/16/2022 20:54:51 - INFO - __main__ - Step 310 Global step 310 Train loss 0.45 on epoch=2
06/16/2022 20:54:53 - INFO - __main__ - Step 320 Global step 320 Train loss 0.43 on epoch=2
06/16/2022 20:54:56 - INFO - __main__ - Step 330 Global step 330 Train loss 0.41 on epoch=2
06/16/2022 20:54:59 - INFO - __main__ - Step 340 Global step 340 Train loss 0.45 on epoch=3
06/16/2022 20:55:01 - INFO - __main__ - Step 350 Global step 350 Train loss 0.37 on epoch=3
06/16/2022 20:55:55 - INFO - __main__ - Global step 350 Train loss 0.42 Classification-F1 0.46839202773764194 on epoch=3
06/16/2022 20:55:58 - INFO - __main__ - Step 360 Global step 360 Train loss 0.37 on epoch=3
06/16/2022 20:56:00 - INFO - __main__ - Step 370 Global step 370 Train loss 0.34 on epoch=3
06/16/2022 20:56:03 - INFO - __main__ - Step 380 Global step 380 Train loss 0.38 on epoch=3
06/16/2022 20:56:05 - INFO - __main__ - Step 390 Global step 390 Train loss 0.40 on epoch=3
06/16/2022 20:56:08 - INFO - __main__ - Step 400 Global step 400 Train loss 0.33 on epoch=3
06/16/2022 20:57:05 - INFO - __main__ - Global step 400 Train loss 0.36 Classification-F1 0.45967611511182704 on epoch=3
06/16/2022 20:57:08 - INFO - __main__ - Step 410 Global step 410 Train loss 0.33 on epoch=3
06/16/2022 20:57:10 - INFO - __main__ - Step 420 Global step 420 Train loss 0.30 on epoch=3
06/16/2022 20:57:13 - INFO - __main__ - Step 430 Global step 430 Train loss 0.33 on epoch=3
06/16/2022 20:57:15 - INFO - __main__ - Step 440 Global step 440 Train loss 0.35 on epoch=3
06/16/2022 20:57:18 - INFO - __main__ - Step 450 Global step 450 Train loss 0.31 on epoch=4
06/16/2022 20:58:10 - INFO - __main__ - Global step 450 Train loss 0.32 Classification-F1 0.5741336916007287 on epoch=4
06/16/2022 20:58:10 - INFO - __main__ - Saving model with best Classification-F1: 0.47469843539513223 -> 0.5741336916007287 on epoch=4, global_step=450
06/16/2022 20:58:12 - INFO - __main__ - Step 460 Global step 460 Train loss 0.24 on epoch=4
06/16/2022 20:58:15 - INFO - __main__ - Step 470 Global step 470 Train loss 0.32 on epoch=4
06/16/2022 20:58:18 - INFO - __main__ - Step 480 Global step 480 Train loss 0.22 on epoch=4
06/16/2022 20:58:20 - INFO - __main__ - Step 490 Global step 490 Train loss 0.23 on epoch=4
06/16/2022 20:58:23 - INFO - __main__ - Step 500 Global step 500 Train loss 0.26 on epoch=4
06/16/2022 20:59:18 - INFO - __main__ - Global step 500 Train loss 0.26 Classification-F1 0.5412146938317053 on epoch=4
06/16/2022 20:59:20 - INFO - __main__ - Step 510 Global step 510 Train loss 0.33 on epoch=4
06/16/2022 20:59:23 - INFO - __main__ - Step 520 Global step 520 Train loss 0.22 on epoch=4
06/16/2022 20:59:26 - INFO - __main__ - Step 530 Global step 530 Train loss 0.21 on epoch=4
06/16/2022 20:59:28 - INFO - __main__ - Step 540 Global step 540 Train loss 0.31 on epoch=4
06/16/2022 20:59:31 - INFO - __main__ - Step 550 Global step 550 Train loss 0.27 on epoch=4
06/16/2022 21:00:27 - INFO - __main__ - Global step 550 Train loss 0.26 Classification-F1 0.4582519628673471 on epoch=4
06/16/2022 21:00:30 - INFO - __main__ - Step 560 Global step 560 Train loss 0.41 on epoch=4
06/16/2022 21:00:33 - INFO - __main__ - Step 570 Global step 570 Train loss 0.24 on epoch=5
06/16/2022 21:00:35 - INFO - __main__ - Step 580 Global step 580 Train loss 0.16 on epoch=5
06/16/2022 21:00:38 - INFO - __main__ - Step 590 Global step 590 Train loss 0.24 on epoch=5
06/16/2022 21:00:40 - INFO - __main__ - Step 600 Global step 600 Train loss 0.17 on epoch=5
06/16/2022 21:01:36 - INFO - __main__ - Global step 600 Train loss 0.24 Classification-F1 0.5611578851373806 on epoch=5
06/16/2022 21:01:39 - INFO - __main__ - Step 610 Global step 610 Train loss 0.29 on epoch=5
06/16/2022 21:01:41 - INFO - __main__ - Step 620 Global step 620 Train loss 0.21 on epoch=5
06/16/2022 21:01:44 - INFO - __main__ - Step 630 Global step 630 Train loss 0.23 on epoch=5
06/16/2022 21:01:47 - INFO - __main__ - Step 640 Global step 640 Train loss 0.21 on epoch=5
06/16/2022 21:01:49 - INFO - __main__ - Step 650 Global step 650 Train loss 0.35 on epoch=5
06/16/2022 21:02:43 - INFO - __main__ - Global step 650 Train loss 0.26 Classification-F1 0.6443509690954177 on epoch=5
06/16/2022 21:02:43 - INFO - __main__ - Saving model with best Classification-F1: 0.5741336916007287 -> 0.6443509690954177 on epoch=5, global_step=650
06/16/2022 21:02:46 - INFO - __main__ - Step 660 Global step 660 Train loss 0.24 on epoch=5
06/16/2022 21:02:48 - INFO - __main__ - Step 670 Global step 670 Train loss 0.26 on epoch=5
06/16/2022 21:02:51 - INFO - __main__ - Step 680 Global step 680 Train loss 0.23 on epoch=6
06/16/2022 21:02:54 - INFO - __main__ - Step 690 Global step 690 Train loss 0.23 on epoch=6
06/16/2022 21:02:56 - INFO - __main__ - Step 700 Global step 700 Train loss 0.23 on epoch=6
06/16/2022 21:03:51 - INFO - __main__ - Global step 700 Train loss 0.24 Classification-F1 0.6172963136467218 on epoch=6
06/16/2022 21:03:54 - INFO - __main__ - Step 710 Global step 710 Train loss 0.16 on epoch=6
06/16/2022 21:03:56 - INFO - __main__ - Step 720 Global step 720 Train loss 0.20 on epoch=6
06/16/2022 21:03:59 - INFO - __main__ - Step 730 Global step 730 Train loss 0.23 on epoch=6
06/16/2022 21:04:02 - INFO - __main__ - Step 740 Global step 740 Train loss 0.21 on epoch=6
06/16/2022 21:04:04 - INFO - __main__ - Step 750 Global step 750 Train loss 0.14 on epoch=6
06/16/2022 21:05:03 - INFO - __main__ - Global step 750 Train loss 0.19 Classification-F1 0.5852624839148165 on epoch=6
06/16/2022 21:05:06 - INFO - __main__ - Step 760 Global step 760 Train loss 0.16 on epoch=6
06/16/2022 21:05:08 - INFO - __main__ - Step 770 Global step 770 Train loss 0.24 on epoch=6
06/16/2022 21:05:11 - INFO - __main__ - Step 780 Global step 780 Train loss 0.28 on epoch=6
06/16/2022 21:05:14 - INFO - __main__ - Step 790 Global step 790 Train loss 0.20 on epoch=7
06/16/2022 21:05:16 - INFO - __main__ - Step 800 Global step 800 Train loss 0.18 on epoch=7
06/16/2022 21:06:11 - INFO - __main__ - Global step 800 Train loss 0.21 Classification-F1 0.6493944749906971 on epoch=7
06/16/2022 21:06:11 - INFO - __main__ - Saving model with best Classification-F1: 0.6443509690954177 -> 0.6493944749906971 on epoch=7, global_step=800
06/16/2022 21:06:14 - INFO - __main__ - Step 810 Global step 810 Train loss 0.22 on epoch=7
06/16/2022 21:06:16 - INFO - __main__ - Step 820 Global step 820 Train loss 0.14 on epoch=7
06/16/2022 21:06:19 - INFO - __main__ - Step 830 Global step 830 Train loss 0.11 on epoch=7
06/16/2022 21:06:21 - INFO - __main__ - Step 840 Global step 840 Train loss 0.18 on epoch=7
06/16/2022 21:06:24 - INFO - __main__ - Step 850 Global step 850 Train loss 0.18 on epoch=7
06/16/2022 21:07:18 - INFO - __main__ - Global step 850 Train loss 0.16 Classification-F1 0.5708961763744612 on epoch=7
06/16/2022 21:07:21 - INFO - __main__ - Step 860 Global step 860 Train loss 0.19 on epoch=7
06/16/2022 21:07:24 - INFO - __main__ - Step 870 Global step 870 Train loss 0.16 on epoch=7
06/16/2022 21:07:26 - INFO - __main__ - Step 880 Global step 880 Train loss 0.12 on epoch=7
06/16/2022 21:07:29 - INFO - __main__ - Step 890 Global step 890 Train loss 0.14 on epoch=7
06/16/2022 21:07:31 - INFO - __main__ - Step 900 Global step 900 Train loss 0.14 on epoch=8
06/16/2022 21:08:23 - INFO - __main__ - Global step 900 Train loss 0.15 Classification-F1 0.6193089412973644 on epoch=8
06/16/2022 21:08:25 - INFO - __main__ - Step 910 Global step 910 Train loss 0.13 on epoch=8
06/16/2022 21:08:28 - INFO - __main__ - Step 920 Global step 920 Train loss 0.12 on epoch=8
06/16/2022 21:08:30 - INFO - __main__ - Step 930 Global step 930 Train loss 0.14 on epoch=8
06/16/2022 21:08:33 - INFO - __main__ - Step 940 Global step 940 Train loss 0.15 on epoch=8
06/16/2022 21:08:36 - INFO - __main__ - Step 950 Global step 950 Train loss 0.15 on epoch=8
06/16/2022 21:09:31 - INFO - __main__ - Global step 950 Train loss 0.14 Classification-F1 0.5361610872083733 on epoch=8
06/16/2022 21:09:33 - INFO - __main__ - Step 960 Global step 960 Train loss 0.13 on epoch=8
06/16/2022 21:09:36 - INFO - __main__ - Step 970 Global step 970 Train loss 0.15 on epoch=8
06/16/2022 21:09:38 - INFO - __main__ - Step 980 Global step 980 Train loss 0.14 on epoch=8
06/16/2022 21:09:41 - INFO - __main__ - Step 990 Global step 990 Train loss 0.15 on epoch=8
06/16/2022 21:09:44 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.19 on epoch=8
06/16/2022 21:10:40 - INFO - __main__ - Global step 1000 Train loss 0.15 Classification-F1 0.5403047992049559 on epoch=8
06/16/2022 21:10:42 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.20 on epoch=9
06/16/2022 21:10:45 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.12 on epoch=9
06/16/2022 21:10:48 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.09 on epoch=9
06/16/2022 21:10:50 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.06 on epoch=9
06/16/2022 21:10:53 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.14 on epoch=9
06/16/2022 21:11:50 - INFO - __main__ - Global step 1050 Train loss 0.12 Classification-F1 0.6083560536780284 on epoch=9
06/16/2022 21:11:53 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.10 on epoch=9
06/16/2022 21:11:55 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.18 on epoch=9
06/16/2022 21:11:58 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.09 on epoch=9
06/16/2022 21:12:00 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.12 on epoch=9
06/16/2022 21:12:03 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.12 on epoch=9
06/16/2022 21:12:59 - INFO - __main__ - Global step 1100 Train loss 0.12 Classification-F1 0.736617931988572 on epoch=9
06/16/2022 21:12:59 - INFO - __main__ - Saving model with best Classification-F1: 0.6493944749906971 -> 0.736617931988572 on epoch=9, global_step=1100
06/16/2022 21:13:02 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.13 on epoch=9
06/16/2022 21:13:05 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.19 on epoch=9
06/16/2022 21:13:07 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.12 on epoch=10
06/16/2022 21:13:10 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.14 on epoch=10
06/16/2022 21:13:12 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.10 on epoch=10
06/16/2022 21:14:12 - INFO - __main__ - Global step 1150 Train loss 0.14 Classification-F1 0.6322050156533611 on epoch=10
06/16/2022 21:14:15 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.10 on epoch=10
06/16/2022 21:14:17 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.13 on epoch=10
06/16/2022 21:14:20 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.08 on epoch=10
06/16/2022 21:14:22 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.06 on epoch=10
06/16/2022 21:14:25 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.10 on epoch=10
06/16/2022 21:15:20 - INFO - __main__ - Global step 1200 Train loss 0.09 Classification-F1 0.6658852117663775 on epoch=10
06/16/2022 21:15:23 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.12 on epoch=10
06/16/2022 21:15:25 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.17 on epoch=10
06/16/2022 21:15:28 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.09 on epoch=10
06/16/2022 21:15:30 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.08 on epoch=11
06/16/2022 21:15:33 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.07 on epoch=11
06/16/2022 21:16:30 - INFO - __main__ - Global step 1250 Train loss 0.11 Classification-F1 0.7612495496163708 on epoch=11
06/16/2022 21:16:30 - INFO - __main__ - Saving model with best Classification-F1: 0.736617931988572 -> 0.7612495496163708 on epoch=11, global_step=1250
06/16/2022 21:16:33 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.11 on epoch=11
06/16/2022 21:16:35 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.09 on epoch=11
06/16/2022 21:16:38 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.08 on epoch=11
06/16/2022 21:16:41 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.10 on epoch=11
06/16/2022 21:16:43 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.08 on epoch=11
06/16/2022 21:17:35 - INFO - __main__ - Global step 1300 Train loss 0.09 Classification-F1 0.713748222022399 on epoch=11
06/16/2022 21:17:38 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.07 on epoch=11
06/16/2022 21:17:41 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.11 on epoch=11
06/16/2022 21:17:43 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.08 on epoch=11
06/16/2022 21:17:46 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.06 on epoch=11
06/16/2022 21:17:48 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.09 on epoch=12
06/16/2022 21:18:40 - INFO - __main__ - Global step 1350 Train loss 0.08 Classification-F1 0.7630037539003275 on epoch=12
06/16/2022 21:18:40 - INFO - __main__ - Saving model with best Classification-F1: 0.7612495496163708 -> 0.7630037539003275 on epoch=12, global_step=1350
06/16/2022 21:18:42 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.10 on epoch=12
06/16/2022 21:18:45 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.06 on epoch=12
06/16/2022 21:18:47 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.13 on epoch=12
06/16/2022 21:18:50 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.07 on epoch=12
06/16/2022 21:18:53 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.12 on epoch=12
06/16/2022 21:19:44 - INFO - __main__ - Global step 1400 Train loss 0.10 Classification-F1 0.8065386785764638 on epoch=12
06/16/2022 21:19:44 - INFO - __main__ - Saving model with best Classification-F1: 0.7630037539003275 -> 0.8065386785764638 on epoch=12, global_step=1400
06/16/2022 21:19:47 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.09 on epoch=12
06/16/2022 21:19:49 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.16 on epoch=12
06/16/2022 21:19:52 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.12 on epoch=12
06/16/2022 21:19:55 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.10 on epoch=12
06/16/2022 21:19:57 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.08 on epoch=12
06/16/2022 21:20:50 - INFO - __main__ - Global step 1450 Train loss 0.11 Classification-F1 0.8595774808601462 on epoch=12
06/16/2022 21:20:50 - INFO - __main__ - Saving model with best Classification-F1: 0.8065386785764638 -> 0.8595774808601462 on epoch=12, global_step=1450
06/16/2022 21:20:52 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.07 on epoch=13
06/16/2022 21:20:55 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.04 on epoch=13
06/16/2022 21:20:58 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.07 on epoch=13
06/16/2022 21:21:00 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.09 on epoch=13
06/16/2022 21:21:03 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.08 on epoch=13
06/16/2022 21:21:55 - INFO - __main__ - Global step 1500 Train loss 0.07 Classification-F1 0.854012572738958 on epoch=13
06/16/2022 21:21:57 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.09 on epoch=13
06/16/2022 21:22:00 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.06 on epoch=13
06/16/2022 21:22:03 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.13 on epoch=13
06/16/2022 21:22:05 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.05 on epoch=13
06/16/2022 21:22:08 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.08 on epoch=13
06/16/2022 21:22:59 - INFO - __main__ - Global step 1550 Train loss 0.08 Classification-F1 0.8613333445647327 on epoch=13
06/16/2022 21:22:59 - INFO - __main__ - Saving model with best Classification-F1: 0.8595774808601462 -> 0.8613333445647327 on epoch=13, global_step=1550
06/16/2022 21:23:01 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.09 on epoch=13
06/16/2022 21:23:04 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.10 on epoch=14
06/16/2022 21:23:06 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.03 on epoch=14
06/16/2022 21:23:09 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.04 on epoch=14
06/16/2022 21:23:12 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.04 on epoch=14
06/16/2022 21:24:04 - INFO - __main__ - Global step 1600 Train loss 0.06 Classification-F1 0.8596301458769138 on epoch=14
06/16/2022 21:24:07 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.07 on epoch=14
06/16/2022 21:24:09 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.09 on epoch=14
06/16/2022 21:24:12 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.11 on epoch=14
06/16/2022 21:24:15 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.09 on epoch=14
06/16/2022 21:24:17 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.04 on epoch=14
06/16/2022 21:25:07 - INFO - __main__ - Global step 1650 Train loss 0.08 Classification-F1 0.8557385793240031 on epoch=14
06/16/2022 21:25:10 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.07 on epoch=14
06/16/2022 21:25:12 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.13 on epoch=14
06/16/2022 21:25:15 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.08 on epoch=14
06/16/2022 21:25:17 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.05 on epoch=15
06/16/2022 21:25:20 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.06 on epoch=15
06/16/2022 21:26:10 - INFO - __main__ - Global step 1700 Train loss 0.08 Classification-F1 0.8076454784503487 on epoch=15
06/16/2022 21:26:13 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.05 on epoch=15
06/16/2022 21:26:15 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.04 on epoch=15
06/16/2022 21:26:18 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.10 on epoch=15
06/16/2022 21:26:20 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.06 on epoch=15
06/16/2022 21:26:23 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.04 on epoch=15
06/16/2022 21:27:15 - INFO - __main__ - Global step 1750 Train loss 0.06 Classification-F1 0.8081270928534979 on epoch=15
06/16/2022 21:27:18 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.06 on epoch=15
06/16/2022 21:27:20 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.07 on epoch=15
06/16/2022 21:27:23 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.09 on epoch=15
06/16/2022 21:27:26 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.05 on epoch=15
06/16/2022 21:27:28 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.07 on epoch=16
06/16/2022 21:28:19 - INFO - __main__ - Global step 1800 Train loss 0.07 Classification-F1 0.8605947182882925 on epoch=16
06/16/2022 21:28:22 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.03 on epoch=16
06/16/2022 21:28:24 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.06 on epoch=16
06/16/2022 21:28:27 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.06 on epoch=16
06/16/2022 21:28:29 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.06 on epoch=16
06/16/2022 21:28:32 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.07 on epoch=16
06/16/2022 21:29:20 - INFO - __main__ - Global step 1850 Train loss 0.06 Classification-F1 0.7627560819923861 on epoch=16
06/16/2022 21:29:23 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.06 on epoch=16
06/16/2022 21:29:26 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.04 on epoch=16
06/16/2022 21:29:28 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.03 on epoch=16
06/16/2022 21:29:31 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.05 on epoch=16
06/16/2022 21:29:33 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=16
06/16/2022 21:30:23 - INFO - __main__ - Global step 1900 Train loss 0.05 Classification-F1 0.807799091263859 on epoch=16
06/16/2022 21:30:25 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.08 on epoch=17
06/16/2022 21:30:28 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.04 on epoch=17
06/16/2022 21:30:31 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.04 on epoch=17
06/16/2022 21:30:33 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.13 on epoch=17
06/16/2022 21:30:36 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.05 on epoch=17
06/16/2022 21:31:23 - INFO - __main__ - Global step 1950 Train loss 0.07 Classification-F1 0.7162438373690133 on epoch=17
06/16/2022 21:31:26 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.06 on epoch=17
06/16/2022 21:31:29 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.11 on epoch=17
06/16/2022 21:31:31 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.05 on epoch=17
06/16/2022 21:31:34 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.04 on epoch=17
06/16/2022 21:31:37 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.05 on epoch=17
06/16/2022 21:32:25 - INFO - __main__ - Global step 2000 Train loss 0.06 Classification-F1 0.8026813810673606 on epoch=17
06/16/2022 21:32:28 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.04 on epoch=17
06/16/2022 21:32:30 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.11 on epoch=18
06/16/2022 21:32:33 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.05 on epoch=18
06/16/2022 21:32:35 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.08 on epoch=18
06/16/2022 21:32:38 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.05 on epoch=18
06/16/2022 21:33:27 - INFO - __main__ - Global step 2050 Train loss 0.07 Classification-F1 0.7198451948959569 on epoch=18
06/16/2022 21:33:30 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.06 on epoch=18
06/16/2022 21:33:32 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.09 on epoch=18
06/16/2022 21:33:35 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.07 on epoch=18
06/16/2022 21:33:38 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=18
06/16/2022 21:33:40 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=18
06/16/2022 21:34:29 - INFO - __main__ - Global step 2100 Train loss 0.06 Classification-F1 0.7634192065334737 on epoch=18
06/16/2022 21:34:32 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.03 on epoch=18
06/16/2022 21:34:34 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.04 on epoch=18
06/16/2022 21:34:37 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.08 on epoch=19
06/16/2022 21:34:40 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.04 on epoch=19
06/16/2022 21:34:42 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.05 on epoch=19
06/16/2022 21:35:33 - INFO - __main__ - Global step 2150 Train loss 0.05 Classification-F1 0.8045979311796844 on epoch=19
06/16/2022 21:35:35 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.04 on epoch=19
06/16/2022 21:35:38 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=19
06/16/2022 21:35:40 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.06 on epoch=19
06/16/2022 21:35:43 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.06 on epoch=19
06/16/2022 21:35:46 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.03 on epoch=19
06/16/2022 21:36:35 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.8069271585428297 on epoch=19
06/16/2022 21:36:38 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=19
06/16/2022 21:36:40 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=19
06/16/2022 21:36:43 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.03 on epoch=19
06/16/2022 21:36:45 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.08 on epoch=19
06/16/2022 21:36:48 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.04 on epoch=20
06/16/2022 21:37:38 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.9062183767855282 on epoch=20
06/16/2022 21:37:38 - INFO - __main__ - Saving model with best Classification-F1: 0.8613333445647327 -> 0.9062183767855282 on epoch=20, global_step=2250
06/16/2022 21:37:41 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.03 on epoch=20
06/16/2022 21:37:43 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.05 on epoch=20
06/16/2022 21:37:46 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.05 on epoch=20
06/16/2022 21:37:48 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.06 on epoch=20
06/16/2022 21:37:51 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=20
06/16/2022 21:38:39 - INFO - __main__ - Global step 2300 Train loss 0.04 Classification-F1 0.7621941626655726 on epoch=20
06/16/2022 21:38:42 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.05 on epoch=20
06/16/2022 21:38:45 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=20
06/16/2022 21:38:47 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=20
06/16/2022 21:38:50 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=20
06/16/2022 21:38:52 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=20
06/16/2022 21:39:41 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.8596235431609374 on epoch=20
06/16/2022 21:39:43 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=21
06/16/2022 21:39:46 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.06 on epoch=21
06/16/2022 21:39:48 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.05 on epoch=21
06/16/2022 21:39:51 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=21
06/16/2022 21:39:53 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.06 on epoch=21
06/16/2022 21:40:42 - INFO - __main__ - Global step 2400 Train loss 0.05 Classification-F1 0.8618377751300158 on epoch=21
06/16/2022 21:40:45 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.06 on epoch=21
06/16/2022 21:40:47 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.03 on epoch=21
06/16/2022 21:40:50 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.07 on epoch=21
06/16/2022 21:40:53 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.05 on epoch=21
06/16/2022 21:40:55 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.05 on epoch=21
06/16/2022 21:41:45 - INFO - __main__ - Global step 2450 Train loss 0.05 Classification-F1 0.8613173119736 on epoch=21
06/16/2022 21:41:48 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.04 on epoch=21
06/16/2022 21:41:50 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.05 on epoch=22
06/16/2022 21:41:53 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.06 on epoch=22
06/16/2022 21:41:56 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.04 on epoch=22
06/16/2022 21:41:58 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=22
06/16/2022 21:42:49 - INFO - __main__ - Global step 2500 Train loss 0.04 Classification-F1 0.6847333609104022 on epoch=22
06/16/2022 21:42:52 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.03 on epoch=22
06/16/2022 21:42:54 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.07 on epoch=22
06/16/2022 21:42:57 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.06 on epoch=22
06/16/2022 21:43:00 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.03 on epoch=22
06/16/2022 21:43:02 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=22
06/16/2022 21:43:53 - INFO - __main__ - Global step 2550 Train loss 0.04 Classification-F1 0.7646302729579705 on epoch=22
06/16/2022 21:43:56 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.03 on epoch=22
06/16/2022 21:43:58 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.05 on epoch=22
06/16/2022 21:44:01 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.07 on epoch=23
06/16/2022 21:44:04 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=23
06/16/2022 21:44:06 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=23
06/16/2022 21:44:59 - INFO - __main__ - Global step 2600 Train loss 0.04 Classification-F1 0.688659135991623 on epoch=23
06/16/2022 21:45:01 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.04 on epoch=23
06/16/2022 21:45:04 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=23
06/16/2022 21:45:07 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.07 on epoch=23
06/16/2022 21:45:09 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.08 on epoch=23
06/16/2022 21:45:12 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.03 on epoch=23
06/16/2022 21:46:05 - INFO - __main__ - Global step 2650 Train loss 0.05 Classification-F1 0.7221479097729656 on epoch=23
06/16/2022 21:46:07 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=23
06/16/2022 21:46:10 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.05 on epoch=23
06/16/2022 21:46:12 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.03 on epoch=23
06/16/2022 21:46:15 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.06 on epoch=24
06/16/2022 21:46:18 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=24
06/16/2022 21:47:10 - INFO - __main__ - Global step 2700 Train loss 0.04 Classification-F1 0.805491256766613 on epoch=24
06/16/2022 21:47:12 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.05 on epoch=24
06/16/2022 21:47:15 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=24
06/16/2022 21:47:18 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=24
06/16/2022 21:47:20 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.04 on epoch=24
06/16/2022 21:47:23 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.06 on epoch=24
06/16/2022 21:48:15 - INFO - __main__ - Global step 2750 Train loss 0.04 Classification-F1 0.8096925321374225 on epoch=24
06/16/2022 21:48:18 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.04 on epoch=24
06/16/2022 21:48:20 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=24
06/16/2022 21:48:23 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.05 on epoch=24
06/16/2022 21:48:26 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.04 on epoch=24
06/16/2022 21:48:28 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.05 on epoch=24
06/16/2022 21:49:19 - INFO - __main__ - Global step 2800 Train loss 0.04 Classification-F1 0.8118128818281817 on epoch=24
06/16/2022 21:49:22 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.03 on epoch=25
06/16/2022 21:49:24 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=25
06/16/2022 21:49:27 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=25
06/16/2022 21:49:30 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.06 on epoch=25
06/16/2022 21:49:32 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.06 on epoch=25
06/16/2022 21:50:22 - INFO - __main__ - Global step 2850 Train loss 0.04 Classification-F1 0.9174441384547641 on epoch=25
06/16/2022 21:50:22 - INFO - __main__ - Saving model with best Classification-F1: 0.9062183767855282 -> 0.9174441384547641 on epoch=25, global_step=2850
06/16/2022 21:50:25 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=25
06/16/2022 21:50:27 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.03 on epoch=25
06/16/2022 21:50:30 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.04 on epoch=25
06/16/2022 21:50:33 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=25
06/16/2022 21:50:35 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=25
06/16/2022 21:51:26 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.8618307367871402 on epoch=25
06/16/2022 21:51:28 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=25
06/16/2022 21:51:31 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.10 on epoch=26
06/16/2022 21:51:34 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.06 on epoch=26
06/16/2022 21:51:37 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.05 on epoch=26
06/16/2022 21:51:39 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=26
06/16/2022 21:52:30 - INFO - __main__ - Global step 2950 Train loss 0.05 Classification-F1 0.8627656060742308 on epoch=26
06/16/2022 21:52:33 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=26
06/16/2022 21:52:35 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.04 on epoch=26
06/16/2022 21:52:38 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=26
06/16/2022 21:52:41 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=26
06/16/2022 21:52:43 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.03 on epoch=26
06/16/2022 21:52:45 - INFO - __main__ - Start tokenizing ... 1792 instances
06/16/2022 21:52:45 - INFO - __main__ - Printing 3 examples
06/16/2022 21:52:45 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/16/2022 21:52:45 - INFO - __main__ - ['Company']
06/16/2022 21:52:45 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/16/2022 21:52:45 - INFO - __main__ - ['Company']
06/16/2022 21:52:45 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/16/2022 21:52:45 - INFO - __main__ - ['Company']
06/16/2022 21:52:45 - INFO - __main__ - Tokenizing Input ...
06/16/2022 21:52:46 - INFO - __main__ - Tokenizing Output ...
06/16/2022 21:52:47 - INFO - __main__ - Loaded 1792 examples from train data
06/16/2022 21:52:47 - INFO - __main__ - Start tokenizing ... 1792 instances
06/16/2022 21:52:47 - INFO - __main__ - Printing 3 examples
06/16/2022 21:52:47 - INFO - __main__ -  [dbpedia_14] The Aya Group of Companies commonly referred to as the Aya Group is a business conglomerate based in Uganda.
06/16/2022 21:52:47 - INFO - __main__ - ['Company']
06/16/2022 21:52:47 - INFO - __main__ -  [dbpedia_14] Casengo (founded in 2011) is a Dutch company that provides customer service tools for website and webshop owners available as a SaaS. The Amsterdam-based company was founded by Floris and Thijs van der Veen. Both brothers started off with software named Livecom used mainly by large companies such as Philips and DSM. When they decided to develop customer service software for small businesses Casengo was born.
06/16/2022 21:52:47 - INFO - __main__ - ['Company']
06/16/2022 21:52:47 - INFO - __main__ -  [dbpedia_14] KeySpan Corporation now part of National Grid USA was the fifth largest distributor of natural gas in the United States. KeySpan was formed in 1998 as result of the merger of Brooklyn Union Gas Company (founded 1895 by merging several smaller companies) and Long Island Lighting Company (LILCO).
06/16/2022 21:52:47 - INFO - __main__ - ['Company']
06/16/2022 21:52:47 - INFO - __main__ - Tokenizing Input ...
06/16/2022 21:52:48 - INFO - __main__ - Tokenizing Output ...
06/16/2022 21:52:50 - INFO - __main__ - Loaded 1792 examples from dev data
06/16/2022 21:53:06 - INFO - __main__ - load prompt embedding from ckpt
06/16/2022 21:53:07 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/16/2022 21:53:07 - INFO - __main__ - Starting training!
06/16/2022 21:53:34 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.9849484733022607 on epoch=26
06/16/2022 21:53:35 - INFO - __main__ - Saving model with best Classification-F1: 0.9174441384547641 -> 0.9849484733022607 on epoch=26, global_step=3000
06/16/2022 21:53:35 - INFO - __main__ - save last model!
06/16/2022 21:53:35 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/16/2022 21:53:35 - INFO - __main__ - Start tokenizing ... 3500 instances
06/16/2022 21:53:35 - INFO - __main__ - Printing 3 examples
06/16/2022 21:53:35 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/16/2022 21:53:35 - INFO - __main__ - ['Animal']
06/16/2022 21:53:35 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/16/2022 21:53:35 - INFO - __main__ - ['Animal']
06/16/2022 21:53:35 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/16/2022 21:53:35 - INFO - __main__ - ['Village']
06/16/2022 21:53:35 - INFO - __main__ - Tokenizing Input ...
06/16/2022 21:53:37 - INFO - __main__ - Tokenizing Output ...
06/16/2022 21:53:40 - INFO - __main__ - Loaded 3500 examples from test data
06/16/2022 21:55:53 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down128shot/singletask-dbpedia_14/dbpedia_14_128_21_0.2_8_predictions.txt
06/16/2022 21:55:53 - INFO - __main__ - Classification-F1 on test data: 0.7242
06/16/2022 21:55:53 - INFO - __main__ - prefix=dbpedia_14_128_21, lr=0.2, bsz=8, dev_performance=0.9849484733022607, test_performance=0.7241537765390277
06/16/2022 21:55:53 - INFO - __main__ - Running ... prefix=dbpedia_14_128_42, lr=0.5, bsz=8 ...
06/16/2022 21:55:54 - INFO - __main__ - Start tokenizing ... 1792 instances
06/16/2022 21:55:54 - INFO - __main__ - Printing 3 examples
06/16/2022 21:55:54 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/16/2022 21:55:54 - INFO - __main__ - ['Company']
06/16/2022 21:55:54 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/16/2022 21:55:54 - INFO - __main__ - ['Company']
06/16/2022 21:55:54 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/16/2022 21:55:54 - INFO - __main__ - ['Company']
06/16/2022 21:55:54 - INFO - __main__ - Tokenizing Input ...
06/16/2022 21:55:55 - INFO - __main__ - Tokenizing Output ...
06/16/2022 21:55:57 - INFO - __main__ - Loaded 1792 examples from train data
06/16/2022 21:55:57 - INFO - __main__ - Start tokenizing ... 1792 instances
06/16/2022 21:55:57 - INFO - __main__ - Printing 3 examples
06/16/2022 21:55:57 - INFO - __main__ -  [dbpedia_14] The Aya Group of Companies commonly referred to as the Aya Group is a business conglomerate based in Uganda.
06/16/2022 21:55:57 - INFO - __main__ - ['Company']
06/16/2022 21:55:57 - INFO - __main__ -  [dbpedia_14] Casengo (founded in 2011) is a Dutch company that provides customer service tools for website and webshop owners available as a SaaS. The Amsterdam-based company was founded by Floris and Thijs van der Veen. Both brothers started off with software named Livecom used mainly by large companies such as Philips and DSM. When they decided to develop customer service software for small businesses Casengo was born.
06/16/2022 21:55:57 - INFO - __main__ - ['Company']
06/16/2022 21:55:57 - INFO - __main__ -  [dbpedia_14] KeySpan Corporation now part of National Grid USA was the fifth largest distributor of natural gas in the United States. KeySpan was formed in 1998 as result of the merger of Brooklyn Union Gas Company (founded 1895 by merging several smaller companies) and Long Island Lighting Company (LILCO).
06/16/2022 21:55:57 - INFO - __main__ - ['Company']
06/16/2022 21:55:57 - INFO - __main__ - Tokenizing Input ...
06/16/2022 21:55:58 - INFO - __main__ - Tokenizing Output ...
06/16/2022 21:55:59 - INFO - __main__ - Loaded 1792 examples from dev data
06/16/2022 21:56:18 - INFO - __main__ - load prompt embedding from ckpt
06/16/2022 21:56:19 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/16/2022 21:56:19 - INFO - __main__ - Starting training!
06/16/2022 21:56:22 - INFO - __main__ - Step 10 Global step 10 Train loss 4.72 on epoch=0
06/16/2022 21:56:25 - INFO - __main__ - Step 20 Global step 20 Train loss 2.48 on epoch=0
06/16/2022 21:56:28 - INFO - __main__ - Step 30 Global step 30 Train loss 1.64 on epoch=0
06/16/2022 21:56:31 - INFO - __main__ - Step 40 Global step 40 Train loss 1.31 on epoch=0
06/16/2022 21:56:33 - INFO - __main__ - Step 50 Global step 50 Train loss 1.16 on epoch=0
06/16/2022 21:57:23 - INFO - __main__ - Global step 50 Train loss 2.26 Classification-F1 0.25953903808772566 on epoch=0
06/16/2022 21:57:23 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.25953903808772566 on epoch=0, global_step=50
06/16/2022 21:57:26 - INFO - __main__ - Step 60 Global step 60 Train loss 0.90 on epoch=0
06/16/2022 21:57:29 - INFO - __main__ - Step 70 Global step 70 Train loss 0.79 on epoch=0
06/16/2022 21:57:32 - INFO - __main__ - Step 80 Global step 80 Train loss 0.65 on epoch=0
06/16/2022 21:57:34 - INFO - __main__ - Step 90 Global step 90 Train loss 0.62 on epoch=0
06/16/2022 21:57:37 - INFO - __main__ - Step 100 Global step 100 Train loss 0.64 on epoch=0
06/16/2022 21:58:35 - INFO - __main__ - Global step 100 Train loss 0.72 Classification-F1 0.3678210195205759 on epoch=0
06/16/2022 21:58:35 - INFO - __main__ - Saving model with best Classification-F1: 0.25953903808772566 -> 0.3678210195205759 on epoch=0, global_step=100
06/16/2022 21:58:38 - INFO - __main__ - Step 110 Global step 110 Train loss 0.55 on epoch=0
06/16/2022 21:58:41 - INFO - __main__ - Step 120 Global step 120 Train loss 0.44 on epoch=1
06/16/2022 21:58:43 - INFO - __main__ - Step 130 Global step 130 Train loss 0.50 on epoch=1
06/16/2022 21:58:46 - INFO - __main__ - Step 140 Global step 140 Train loss 0.52 on epoch=1
06/16/2022 21:58:49 - INFO - __main__ - Step 150 Global step 150 Train loss 0.47 on epoch=1
06/16/2022 21:59:45 - INFO - __main__ - Global step 150 Train loss 0.50 Classification-F1 0.6355141954153256 on epoch=1
06/16/2022 21:59:45 - INFO - __main__ - Saving model with best Classification-F1: 0.3678210195205759 -> 0.6355141954153256 on epoch=1, global_step=150
06/16/2022 21:59:48 - INFO - __main__ - Step 160 Global step 160 Train loss 0.37 on epoch=1
06/16/2022 21:59:51 - INFO - __main__ - Step 170 Global step 170 Train loss 0.42 on epoch=1
06/16/2022 21:59:53 - INFO - __main__ - Step 180 Global step 180 Train loss 0.32 on epoch=1
06/16/2022 21:59:56 - INFO - __main__ - Step 190 Global step 190 Train loss 0.31 on epoch=1
06/16/2022 21:59:59 - INFO - __main__ - Step 200 Global step 200 Train loss 0.35 on epoch=1
06/16/2022 22:00:54 - INFO - __main__ - Global step 200 Train loss 0.35 Classification-F1 0.6792694886841315 on epoch=1
06/16/2022 22:00:54 - INFO - __main__ - Saving model with best Classification-F1: 0.6355141954153256 -> 0.6792694886841315 on epoch=1, global_step=200
06/16/2022 22:00:56 - INFO - __main__ - Step 210 Global step 210 Train loss 0.47 on epoch=1
06/16/2022 22:00:59 - INFO - __main__ - Step 220 Global step 220 Train loss 0.42 on epoch=1
06/16/2022 22:01:02 - INFO - __main__ - Step 230 Global step 230 Train loss 0.32 on epoch=2
06/16/2022 22:01:04 - INFO - __main__ - Step 240 Global step 240 Train loss 0.42 on epoch=2
06/16/2022 22:01:07 - INFO - __main__ - Step 250 Global step 250 Train loss 0.27 on epoch=2
06/16/2022 22:02:00 - INFO - __main__ - Global step 250 Train loss 0.38 Classification-F1 0.5971253615271144 on epoch=2
06/16/2022 22:02:03 - INFO - __main__ - Step 260 Global step 260 Train loss 0.26 on epoch=2
06/16/2022 22:02:05 - INFO - __main__ - Step 270 Global step 270 Train loss 0.34 on epoch=2
06/16/2022 22:02:08 - INFO - __main__ - Step 280 Global step 280 Train loss 0.29 on epoch=2
06/16/2022 22:02:10 - INFO - __main__ - Step 290 Global step 290 Train loss 0.25 on epoch=2
06/16/2022 22:02:13 - INFO - __main__ - Step 300 Global step 300 Train loss 0.24 on epoch=2
06/16/2022 22:03:09 - INFO - __main__ - Global step 300 Train loss 0.28 Classification-F1 0.36466114322671284 on epoch=2
06/16/2022 22:03:12 - INFO - __main__ - Step 310 Global step 310 Train loss 0.22 on epoch=2
06/16/2022 22:03:15 - INFO - __main__ - Step 320 Global step 320 Train loss 0.28 on epoch=2
06/16/2022 22:03:17 - INFO - __main__ - Step 330 Global step 330 Train loss 0.22 on epoch=2
06/16/2022 22:03:20 - INFO - __main__ - Step 340 Global step 340 Train loss 0.17 on epoch=3
06/16/2022 22:03:22 - INFO - __main__ - Step 350 Global step 350 Train loss 0.32 on epoch=3
06/16/2022 22:04:27 - INFO - __main__ - Global step 350 Train loss 0.24 Classification-F1 0.440092043233831 on epoch=3
06/16/2022 22:04:29 - INFO - __main__ - Step 360 Global step 360 Train loss 0.18 on epoch=3
06/16/2022 22:04:32 - INFO - __main__ - Step 370 Global step 370 Train loss 0.16 on epoch=3
06/16/2022 22:04:35 - INFO - __main__ - Step 380 Global step 380 Train loss 0.22 on epoch=3
06/16/2022 22:04:37 - INFO - __main__ - Step 390 Global step 390 Train loss 0.19 on epoch=3
06/16/2022 22:04:40 - INFO - __main__ - Step 400 Global step 400 Train loss 0.26 on epoch=3
06/16/2022 22:05:37 - INFO - __main__ - Global step 400 Train loss 0.20 Classification-F1 0.5193050888180266 on epoch=3
06/16/2022 22:05:39 - INFO - __main__ - Step 410 Global step 410 Train loss 0.16 on epoch=3
06/16/2022 22:05:42 - INFO - __main__ - Step 420 Global step 420 Train loss 0.11 on epoch=3
06/16/2022 22:05:45 - INFO - __main__ - Step 430 Global step 430 Train loss 0.21 on epoch=3
06/16/2022 22:05:47 - INFO - __main__ - Step 440 Global step 440 Train loss 0.13 on epoch=3
06/16/2022 22:05:50 - INFO - __main__ - Step 450 Global step 450 Train loss 0.11 on epoch=4
06/16/2022 22:06:51 - INFO - __main__ - Global step 450 Train loss 0.14 Classification-F1 0.8325074293998536 on epoch=4
06/16/2022 22:06:51 - INFO - __main__ - Saving model with best Classification-F1: 0.6792694886841315 -> 0.8325074293998536 on epoch=4, global_step=450
06/16/2022 22:06:54 - INFO - __main__ - Step 460 Global step 460 Train loss 0.17 on epoch=4
06/16/2022 22:06:57 - INFO - __main__ - Step 470 Global step 470 Train loss 0.20 on epoch=4
06/16/2022 22:06:59 - INFO - __main__ - Step 480 Global step 480 Train loss 0.13 on epoch=4
06/16/2022 22:07:02 - INFO - __main__ - Step 490 Global step 490 Train loss 0.18 on epoch=4
06/16/2022 22:07:04 - INFO - __main__ - Step 500 Global step 500 Train loss 0.13 on epoch=4
06/16/2022 22:08:05 - INFO - __main__ - Global step 500 Train loss 0.16 Classification-F1 0.836795189669039 on epoch=4
06/16/2022 22:08:05 - INFO - __main__ - Saving model with best Classification-F1: 0.8325074293998536 -> 0.836795189669039 on epoch=4, global_step=500
06/16/2022 22:08:08 - INFO - __main__ - Step 510 Global step 510 Train loss 0.18 on epoch=4
06/16/2022 22:08:10 - INFO - __main__ - Step 520 Global step 520 Train loss 0.22 on epoch=4
06/16/2022 22:08:13 - INFO - __main__ - Step 530 Global step 530 Train loss 0.11 on epoch=4
06/16/2022 22:08:16 - INFO - __main__ - Step 540 Global step 540 Train loss 0.15 on epoch=4
06/16/2022 22:08:18 - INFO - __main__ - Step 550 Global step 550 Train loss 0.14 on epoch=4
06/16/2022 22:09:18 - INFO - __main__ - Global step 550 Train loss 0.16 Classification-F1 0.7854801614766169 on epoch=4
06/16/2022 22:09:21 - INFO - __main__ - Step 560 Global step 560 Train loss 0.09 on epoch=4
06/16/2022 22:09:24 - INFO - __main__ - Step 570 Global step 570 Train loss 0.14 on epoch=5
06/16/2022 22:09:26 - INFO - __main__ - Step 580 Global step 580 Train loss 0.18 on epoch=5
06/16/2022 22:09:29 - INFO - __main__ - Step 590 Global step 590 Train loss 0.07 on epoch=5
06/16/2022 22:09:32 - INFO - __main__ - Step 600 Global step 600 Train loss 0.11 on epoch=5
06/16/2022 22:10:28 - INFO - __main__ - Global step 600 Train loss 0.12 Classification-F1 0.7838165546410761 on epoch=5
06/16/2022 22:10:31 - INFO - __main__ - Step 610 Global step 610 Train loss 0.15 on epoch=5
06/16/2022 22:10:33 - INFO - __main__ - Step 620 Global step 620 Train loss 0.11 on epoch=5
06/16/2022 22:10:36 - INFO - __main__ - Step 630 Global step 630 Train loss 0.10 on epoch=5
06/16/2022 22:10:39 - INFO - __main__ - Step 640 Global step 640 Train loss 0.12 on epoch=5
06/16/2022 22:10:41 - INFO - __main__ - Step 650 Global step 650 Train loss 0.11 on epoch=5
06/16/2022 22:11:40 - INFO - __main__ - Global step 650 Train loss 0.12 Classification-F1 0.7090977467044371 on epoch=5
06/16/2022 22:11:43 - INFO - __main__ - Step 660 Global step 660 Train loss 0.16 on epoch=5
06/16/2022 22:11:45 - INFO - __main__ - Step 670 Global step 670 Train loss 0.08 on epoch=5
06/16/2022 22:11:48 - INFO - __main__ - Step 680 Global step 680 Train loss 0.08 on epoch=6
06/16/2022 22:11:51 - INFO - __main__ - Step 690 Global step 690 Train loss 0.16 on epoch=6
06/16/2022 22:11:53 - INFO - __main__ - Step 700 Global step 700 Train loss 0.13 on epoch=6
06/16/2022 22:12:49 - INFO - __main__ - Global step 700 Train loss 0.12 Classification-F1 0.6596030687207363 on epoch=6
06/16/2022 22:12:52 - INFO - __main__ - Step 710 Global step 710 Train loss 0.06 on epoch=6
06/16/2022 22:12:54 - INFO - __main__ - Step 720 Global step 720 Train loss 0.14 on epoch=6
06/16/2022 22:12:57 - INFO - __main__ - Step 730 Global step 730 Train loss 0.10 on epoch=6
06/16/2022 22:12:59 - INFO - __main__ - Step 740 Global step 740 Train loss 0.12 on epoch=6
06/16/2022 22:13:02 - INFO - __main__ - Step 750 Global step 750 Train loss 0.06 on epoch=6
06/16/2022 22:13:59 - INFO - __main__ - Global step 750 Train loss 0.10 Classification-F1 0.7959311965061824 on epoch=6
06/16/2022 22:14:02 - INFO - __main__ - Step 760 Global step 760 Train loss 0.08 on epoch=6
06/16/2022 22:14:04 - INFO - __main__ - Step 770 Global step 770 Train loss 0.12 on epoch=6
06/16/2022 22:14:07 - INFO - __main__ - Step 780 Global step 780 Train loss 0.06 on epoch=6
06/16/2022 22:14:10 - INFO - __main__ - Step 790 Global step 790 Train loss 0.09 on epoch=7
06/16/2022 22:14:12 - INFO - __main__ - Step 800 Global step 800 Train loss 0.10 on epoch=7
06/16/2022 22:15:06 - INFO - __main__ - Global step 800 Train loss 0.09 Classification-F1 0.9092304903837806 on epoch=7
06/16/2022 22:15:07 - INFO - __main__ - Saving model with best Classification-F1: 0.836795189669039 -> 0.9092304903837806 on epoch=7, global_step=800
06/16/2022 22:15:09 - INFO - __main__ - Step 810 Global step 810 Train loss 0.07 on epoch=7
06/16/2022 22:15:12 - INFO - __main__ - Step 820 Global step 820 Train loss 0.06 on epoch=7
06/16/2022 22:15:14 - INFO - __main__ - Step 830 Global step 830 Train loss 0.10 on epoch=7
06/16/2022 22:15:17 - INFO - __main__ - Step 840 Global step 840 Train loss 0.08 on epoch=7
06/16/2022 22:15:20 - INFO - __main__ - Step 850 Global step 850 Train loss 0.05 on epoch=7
06/16/2022 22:16:19 - INFO - __main__ - Global step 850 Train loss 0.07 Classification-F1 0.9814295994654205 on epoch=7
06/16/2022 22:16:19 - INFO - __main__ - Saving model with best Classification-F1: 0.9092304903837806 -> 0.9814295994654205 on epoch=7, global_step=850
06/16/2022 22:16:22 - INFO - __main__ - Step 860 Global step 860 Train loss 0.09 on epoch=7
06/16/2022 22:16:25 - INFO - __main__ - Step 870 Global step 870 Train loss 0.07 on epoch=7
06/16/2022 22:16:27 - INFO - __main__ - Step 880 Global step 880 Train loss 0.10 on epoch=7
06/16/2022 22:16:30 - INFO - __main__ - Step 890 Global step 890 Train loss 0.06 on epoch=7
06/16/2022 22:16:33 - INFO - __main__ - Step 900 Global step 900 Train loss 0.09 on epoch=8
06/16/2022 22:17:35 - INFO - __main__ - Global step 900 Train loss 0.08 Classification-F1 0.9073434251587185 on epoch=8
06/16/2022 22:17:37 - INFO - __main__ - Step 910 Global step 910 Train loss 0.12 on epoch=8
06/16/2022 22:17:40 - INFO - __main__ - Step 920 Global step 920 Train loss 0.13 on epoch=8
06/16/2022 22:17:42 - INFO - __main__ - Step 930 Global step 930 Train loss 0.06 on epoch=8
06/16/2022 22:17:45 - INFO - __main__ - Step 940 Global step 940 Train loss 0.11 on epoch=8
06/16/2022 22:17:48 - INFO - __main__ - Step 950 Global step 950 Train loss 0.05 on epoch=8
06/16/2022 22:18:43 - INFO - __main__ - Global step 950 Train loss 0.09 Classification-F1 0.8064824413345181 on epoch=8
06/16/2022 22:18:45 - INFO - __main__ - Step 960 Global step 960 Train loss 0.08 on epoch=8
06/16/2022 22:18:48 - INFO - __main__ - Step 970 Global step 970 Train loss 0.07 on epoch=8
06/16/2022 22:18:51 - INFO - __main__ - Step 980 Global step 980 Train loss 0.04 on epoch=8
06/16/2022 22:18:53 - INFO - __main__ - Step 990 Global step 990 Train loss 0.11 on epoch=8
06/16/2022 22:18:56 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.07 on epoch=8
06/16/2022 22:19:54 - INFO - __main__ - Global step 1000 Train loss 0.07 Classification-F1 0.7576233875562767 on epoch=8
06/16/2022 22:19:57 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.05 on epoch=9
06/16/2022 22:19:59 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.13 on epoch=9
06/16/2022 22:20:02 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.08 on epoch=9
06/16/2022 22:20:05 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.06 on epoch=9
06/16/2022 22:20:07 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.08 on epoch=9
06/16/2022 22:21:04 - INFO - __main__ - Global step 1050 Train loss 0.08 Classification-F1 0.8976398266831779 on epoch=9
06/16/2022 22:21:06 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.06 on epoch=9
06/16/2022 22:21:09 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.05 on epoch=9
06/16/2022 22:21:12 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.04 on epoch=9
06/16/2022 22:21:14 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.04 on epoch=9
06/16/2022 22:21:17 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.10 on epoch=9
06/16/2022 22:22:13 - INFO - __main__ - Global step 1100 Train loss 0.06 Classification-F1 0.8651962570532462 on epoch=9
06/16/2022 22:22:16 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.06 on epoch=9
06/16/2022 22:22:19 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.03 on epoch=9
06/16/2022 22:22:21 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.07 on epoch=10
06/16/2022 22:22:24 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.12 on epoch=10
06/16/2022 22:22:27 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.06 on epoch=10
06/16/2022 22:23:22 - INFO - __main__ - Global step 1150 Train loss 0.07 Classification-F1 0.7941965412880068 on epoch=10
06/16/2022 22:23:24 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.05 on epoch=10
06/16/2022 22:23:27 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.09 on epoch=10
06/16/2022 22:23:30 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.05 on epoch=10
06/16/2022 22:23:32 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.03 on epoch=10
06/16/2022 22:23:35 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.02 on epoch=10
06/16/2022 22:24:29 - INFO - __main__ - Global step 1200 Train loss 0.05 Classification-F1 0.6473560507238532 on epoch=10
06/16/2022 22:24:32 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.07 on epoch=10
06/16/2022 22:24:34 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.07 on epoch=10
06/16/2022 22:24:37 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.03 on epoch=10
06/16/2022 22:24:40 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.12 on epoch=11
06/16/2022 22:24:42 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.13 on epoch=11
06/16/2022 22:25:38 - INFO - __main__ - Global step 1250 Train loss 0.08 Classification-F1 0.987715932821679 on epoch=11
06/16/2022 22:25:38 - INFO - __main__ - Saving model with best Classification-F1: 0.9814295994654205 -> 0.987715932821679 on epoch=11, global_step=1250
06/16/2022 22:25:41 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.03 on epoch=11
06/16/2022 22:25:44 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.05 on epoch=11
06/16/2022 22:25:46 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.04 on epoch=11
06/16/2022 22:25:49 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.03 on epoch=11
06/16/2022 22:25:52 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.06 on epoch=11
06/16/2022 22:26:50 - INFO - __main__ - Global step 1300 Train loss 0.04 Classification-F1 0.8587078356391049 on epoch=11
06/16/2022 22:26:53 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.03 on epoch=11
06/16/2022 22:26:55 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.12 on epoch=11
06/16/2022 22:26:58 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.08 on epoch=11
06/16/2022 22:27:01 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.03 on epoch=11
06/16/2022 22:27:03 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.05 on epoch=12
06/16/2022 22:27:59 - INFO - __main__ - Global step 1350 Train loss 0.06 Classification-F1 0.8045267159095496 on epoch=12
06/16/2022 22:28:02 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.07 on epoch=12
06/16/2022 22:28:04 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.05 on epoch=12
06/16/2022 22:28:07 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.02 on epoch=12
06/16/2022 22:28:09 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.07 on epoch=12
06/16/2022 22:28:12 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=12
06/16/2022 22:29:05 - INFO - __main__ - Global step 1400 Train loss 0.04 Classification-F1 0.7978690705067221 on epoch=12
06/16/2022 22:29:08 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.06 on epoch=12
06/16/2022 22:29:11 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.03 on epoch=12
06/16/2022 22:29:13 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.04 on epoch=12
06/16/2022 22:29:16 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.14 on epoch=12
06/16/2022 22:29:19 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.03 on epoch=12
06/16/2022 22:30:11 - INFO - __main__ - Global step 1450 Train loss 0.06 Classification-F1 0.7531830764064624 on epoch=12
06/16/2022 22:30:13 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.07 on epoch=13
06/16/2022 22:30:16 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.11 on epoch=13
06/16/2022 22:30:19 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.05 on epoch=13
06/16/2022 22:30:21 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.02 on epoch=13
06/16/2022 22:30:24 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.09 on epoch=13
06/16/2022 22:31:19 - INFO - __main__ - Global step 1500 Train loss 0.07 Classification-F1 0.7102476798155211 on epoch=13
06/16/2022 22:31:21 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.03 on epoch=13
06/16/2022 22:31:24 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.05 on epoch=13
06/16/2022 22:31:27 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.03 on epoch=13
06/16/2022 22:31:29 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=13
06/16/2022 22:31:32 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.03 on epoch=13
06/16/2022 22:32:21 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.8530824324312137 on epoch=13
06/16/2022 22:32:24 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.04 on epoch=13
06/16/2022 22:32:26 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.03 on epoch=14
06/16/2022 22:32:29 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.09 on epoch=14
06/16/2022 22:32:32 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.05 on epoch=14
06/16/2022 22:32:34 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.03 on epoch=14
06/16/2022 22:33:33 - INFO - __main__ - Global step 1600 Train loss 0.05 Classification-F1 0.8087909467594027 on epoch=14
06/16/2022 22:33:36 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.05 on epoch=14
06/16/2022 22:33:38 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.09 on epoch=14
06/16/2022 22:33:41 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.05 on epoch=14
06/16/2022 22:33:44 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.04 on epoch=14
06/16/2022 22:33:46 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=14
06/16/2022 22:34:35 - INFO - __main__ - Global step 1650 Train loss 0.05 Classification-F1 0.6762078509341791 on epoch=14
06/16/2022 22:34:38 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.05 on epoch=14
06/16/2022 22:34:41 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.06 on epoch=14
06/16/2022 22:34:43 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=14
06/16/2022 22:34:46 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.09 on epoch=15
06/16/2022 22:34:49 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.10 on epoch=15
06/16/2022 22:35:39 - INFO - __main__ - Global step 1700 Train loss 0.06 Classification-F1 0.7574307383187499 on epoch=15
06/16/2022 22:35:42 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.05 on epoch=15
06/16/2022 22:35:45 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.02 on epoch=15
06/16/2022 22:35:47 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.16 on epoch=15
06/16/2022 22:35:50 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=15
06/16/2022 22:35:53 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.05 on epoch=15
06/16/2022 22:36:41 - INFO - __main__ - Global step 1750 Train loss 0.06 Classification-F1 0.6818765761799552 on epoch=15
06/16/2022 22:36:44 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=15
06/16/2022 22:36:47 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.08 on epoch=15
06/16/2022 22:36:49 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.08 on epoch=15
06/16/2022 22:36:52 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=15
06/16/2022 22:36:54 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=16
06/16/2022 22:37:44 - INFO - __main__ - Global step 1800 Train loss 0.04 Classification-F1 0.8054532610095864 on epoch=16
06/16/2022 22:37:46 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.06 on epoch=16
06/16/2022 22:37:49 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=16
06/16/2022 22:37:52 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=16
06/16/2022 22:37:54 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.04 on epoch=16
06/16/2022 22:37:57 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=16
06/16/2022 22:38:49 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.8572852992836204 on epoch=16
06/16/2022 22:38:52 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.07 on epoch=16
06/16/2022 22:38:54 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.05 on epoch=16
06/16/2022 22:38:57 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.07 on epoch=16
06/16/2022 22:39:00 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.06 on epoch=16
06/16/2022 22:39:02 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=16
06/16/2022 22:40:00 - INFO - __main__ - Global step 1900 Train loss 0.05 Classification-F1 0.6396950483571529 on epoch=16
06/16/2022 22:40:03 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=17
06/16/2022 22:40:05 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.05 on epoch=17
06/16/2022 22:40:08 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.04 on epoch=17
06/16/2022 22:40:10 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=17
06/16/2022 22:40:13 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.04 on epoch=17
06/16/2022 22:41:04 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.7049323407568416 on epoch=17
06/16/2022 22:41:07 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=17
06/16/2022 22:41:09 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.04 on epoch=17
06/16/2022 22:41:12 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=17
06/16/2022 22:41:15 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=17
06/16/2022 22:41:17 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.04 on epoch=17
06/16/2022 22:42:12 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.7768046733521445 on epoch=17
06/16/2022 22:42:15 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=17
06/16/2022 22:42:18 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.03 on epoch=18
06/16/2022 22:42:20 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.11 on epoch=18
06/16/2022 22:42:23 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=18
06/16/2022 22:42:25 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.04 on epoch=18
06/16/2022 22:43:16 - INFO - __main__ - Global step 2050 Train loss 0.05 Classification-F1 0.5087494163506817 on epoch=18
06/16/2022 22:43:18 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.04 on epoch=18
06/16/2022 22:43:21 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.05 on epoch=18
06/16/2022 22:43:24 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.05 on epoch=18
06/16/2022 22:43:26 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=18
06/16/2022 22:43:29 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=18
06/16/2022 22:44:21 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.7970482277806622 on epoch=18
06/16/2022 22:44:24 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.11 on epoch=18
06/16/2022 22:44:27 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.03 on epoch=18
06/16/2022 22:44:29 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=19
06/16/2022 22:44:32 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.05 on epoch=19
06/16/2022 22:44:34 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=19
06/16/2022 22:45:26 - INFO - __main__ - Global step 2150 Train loss 0.05 Classification-F1 0.9150354187112473 on epoch=19
06/16/2022 22:45:29 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=19
06/16/2022 22:45:32 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.04 on epoch=19
06/16/2022 22:45:34 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=19
06/16/2022 22:45:37 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.04 on epoch=19
06/16/2022 22:45:39 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.07 on epoch=19
06/16/2022 22:46:27 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.6849066024817345 on epoch=19
06/16/2022 22:46:30 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=19
06/16/2022 22:46:32 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=19
06/16/2022 22:46:35 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.06 on epoch=19
06/16/2022 22:46:38 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=19
06/16/2022 22:46:40 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.03 on epoch=20
06/16/2022 22:47:28 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.6990678235369235 on epoch=20
06/16/2022 22:47:30 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.09 on epoch=20
06/16/2022 22:47:33 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.06 on epoch=20
06/16/2022 22:47:36 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=20
06/16/2022 22:47:38 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.05 on epoch=20
06/16/2022 22:47:41 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=20
06/16/2022 22:48:27 - INFO - __main__ - Global step 2300 Train loss 0.04 Classification-F1 0.7446529572209213 on epoch=20
06/16/2022 22:48:30 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=20
06/16/2022 22:48:33 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.06 on epoch=20
06/16/2022 22:48:35 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.09 on epoch=20
06/16/2022 22:48:38 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.05 on epoch=20
06/16/2022 22:48:41 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=20
06/16/2022 22:49:32 - INFO - __main__ - Global step 2350 Train loss 0.05 Classification-F1 0.7902601943689909 on epoch=20
06/16/2022 22:49:35 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=21
06/16/2022 22:49:37 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.04 on epoch=21
06/16/2022 22:49:40 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=21
06/16/2022 22:49:43 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=21
06/16/2022 22:49:45 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.04 on epoch=21
06/16/2022 22:50:35 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.850045117916091 on epoch=21
06/16/2022 22:50:38 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=21
06/16/2022 22:50:40 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.04 on epoch=21
06/16/2022 22:50:43 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=21
06/16/2022 22:50:46 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.04 on epoch=21
06/16/2022 22:50:48 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.05 on epoch=21
06/16/2022 22:51:42 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.805891529034804 on epoch=21
06/16/2022 22:51:44 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.04 on epoch=21
06/16/2022 22:51:47 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=22
06/16/2022 22:51:50 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.06 on epoch=22
06/16/2022 22:51:52 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.07 on epoch=22
06/16/2022 22:51:55 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=22
06/16/2022 22:52:48 - INFO - __main__ - Global step 2500 Train loss 0.04 Classification-F1 0.8581158506018276 on epoch=22
06/16/2022 22:52:50 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.04 on epoch=22
06/16/2022 22:52:53 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=22
06/16/2022 22:52:55 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=22
06/16/2022 22:52:58 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.04 on epoch=22
06/16/2022 22:53:01 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.05 on epoch=22
06/16/2022 22:53:52 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.6999976647456126 on epoch=22
06/16/2022 22:53:55 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.10 on epoch=22
06/16/2022 22:53:58 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.04 on epoch=22
06/16/2022 22:54:00 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=23
06/16/2022 22:54:03 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.05 on epoch=23
06/16/2022 22:54:06 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=23
06/16/2022 22:54:56 - INFO - __main__ - Global step 2600 Train loss 0.05 Classification-F1 0.805309908544168 on epoch=23
06/16/2022 22:54:58 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=23
06/16/2022 22:55:01 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=23
06/16/2022 22:55:04 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=23
06/16/2022 22:55:06 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.04 on epoch=23
06/16/2022 22:55:09 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=23
06/16/2022 22:55:56 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.7175903793219448 on epoch=23
06/16/2022 22:55:58 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.04 on epoch=23
06/16/2022 22:56:01 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.05 on epoch=23
06/16/2022 22:56:03 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=23
06/16/2022 22:56:06 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=24
06/16/2022 22:56:09 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.12 on epoch=24
06/16/2022 22:56:54 - INFO - __main__ - Global step 2700 Train loss 0.04 Classification-F1 0.7875939527615096 on epoch=24
06/16/2022 22:56:57 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.03 on epoch=24
06/16/2022 22:57:00 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.03 on epoch=24
06/16/2022 22:57:02 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=24
06/16/2022 22:57:05 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=24
06/16/2022 22:57:07 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.03 on epoch=24
06/16/2022 22:58:00 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.914694742649152 on epoch=24
06/16/2022 22:58:03 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.03 on epoch=24
06/16/2022 22:58:06 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=24
06/16/2022 22:58:08 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.08 on epoch=24
06/16/2022 22:58:11 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=24
06/16/2022 22:58:14 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=24
06/16/2022 22:59:01 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.9168280852952343 on epoch=24
06/16/2022 22:59:04 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=25
06/16/2022 22:59:06 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.06 on epoch=25
06/16/2022 22:59:09 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=25
06/16/2022 22:59:12 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.03 on epoch=25
06/16/2022 22:59:14 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.04 on epoch=25
06/16/2022 23:00:01 - INFO - __main__ - Global step 2850 Train loss 0.03 Classification-F1 0.8429833958564992 on epoch=25
06/16/2022 23:00:04 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=25
06/16/2022 23:00:06 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=25
06/16/2022 23:00:09 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=25
06/16/2022 23:00:11 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.09 on epoch=25
06/16/2022 23:00:14 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=25
06/16/2022 23:01:05 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.8533534153920557 on epoch=25
06/16/2022 23:01:07 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=25
06/16/2022 23:01:10 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=26
06/16/2022 23:01:12 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=26
06/16/2022 23:01:15 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=26
06/16/2022 23:01:18 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.05 on epoch=26
06/16/2022 23:02:04 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.9147591640046308 on epoch=26
06/16/2022 23:02:06 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.07 on epoch=26
06/16/2022 23:02:09 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=26
06/16/2022 23:02:12 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.05 on epoch=26
06/16/2022 23:02:14 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=26
06/16/2022 23:02:17 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=26
06/16/2022 23:02:18 - INFO - __main__ - Start tokenizing ... 1792 instances
06/16/2022 23:02:18 - INFO - __main__ - Printing 3 examples
06/16/2022 23:02:18 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/16/2022 23:02:18 - INFO - __main__ - ['Company']
06/16/2022 23:02:18 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/16/2022 23:02:18 - INFO - __main__ - ['Company']
06/16/2022 23:02:18 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/16/2022 23:02:18 - INFO - __main__ - ['Company']
06/16/2022 23:02:18 - INFO - __main__ - Tokenizing Input ...
06/16/2022 23:02:19 - INFO - __main__ - Tokenizing Output ...
06/16/2022 23:02:21 - INFO - __main__ - Loaded 1792 examples from train data
06/16/2022 23:02:21 - INFO - __main__ - Start tokenizing ... 1792 instances
06/16/2022 23:02:21 - INFO - __main__ - Printing 3 examples
06/16/2022 23:02:21 - INFO - __main__ -  [dbpedia_14] The Aya Group of Companies commonly referred to as the Aya Group is a business conglomerate based in Uganda.
06/16/2022 23:02:21 - INFO - __main__ - ['Company']
06/16/2022 23:02:21 - INFO - __main__ -  [dbpedia_14] Casengo (founded in 2011) is a Dutch company that provides customer service tools for website and webshop owners available as a SaaS. The Amsterdam-based company was founded by Floris and Thijs van der Veen. Both brothers started off with software named Livecom used mainly by large companies such as Philips and DSM. When they decided to develop customer service software for small businesses Casengo was born.
06/16/2022 23:02:21 - INFO - __main__ - ['Company']
06/16/2022 23:02:21 - INFO - __main__ -  [dbpedia_14] KeySpan Corporation now part of National Grid USA was the fifth largest distributor of natural gas in the United States. KeySpan was formed in 1998 as result of the merger of Brooklyn Union Gas Company (founded 1895 by merging several smaller companies) and Long Island Lighting Company (LILCO).
06/16/2022 23:02:21 - INFO - __main__ - ['Company']
06/16/2022 23:02:21 - INFO - __main__ - Tokenizing Input ...
06/16/2022 23:02:22 - INFO - __main__ - Tokenizing Output ...
06/16/2022 23:02:24 - INFO - __main__ - Loaded 1792 examples from dev data
06/16/2022 23:02:42 - INFO - __main__ - load prompt embedding from ckpt
06/16/2022 23:02:42 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/16/2022 23:02:42 - INFO - __main__ - Starting training!
06/16/2022 23:03:05 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.915279004883466 on epoch=26
06/16/2022 23:03:05 - INFO - __main__ - save last model!
06/16/2022 23:03:05 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/16/2022 23:03:05 - INFO - __main__ - Start tokenizing ... 3500 instances
06/16/2022 23:03:05 - INFO - __main__ - Printing 3 examples
06/16/2022 23:03:05 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/16/2022 23:03:05 - INFO - __main__ - ['Animal']
06/16/2022 23:03:05 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/16/2022 23:03:05 - INFO - __main__ - ['Animal']
06/16/2022 23:03:05 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/16/2022 23:03:05 - INFO - __main__ - ['Village']
06/16/2022 23:03:05 - INFO - __main__ - Tokenizing Input ...
06/16/2022 23:03:07 - INFO - __main__ - Tokenizing Output ...
06/16/2022 23:03:10 - INFO - __main__ - Loaded 3500 examples from test data
06/16/2022 23:05:16 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down128shot/singletask-dbpedia_14/dbpedia_14_128_42_0.5_8_predictions.txt
06/16/2022 23:05:16 - INFO - __main__ - Classification-F1 on test data: 0.7238
06/16/2022 23:05:17 - INFO - __main__ - prefix=dbpedia_14_128_42, lr=0.5, bsz=8, dev_performance=0.987715932821679, test_performance=0.7238154407156179
06/16/2022 23:05:17 - INFO - __main__ - Running ... prefix=dbpedia_14_128_42, lr=0.4, bsz=8 ...
06/16/2022 23:05:18 - INFO - __main__ - Start tokenizing ... 1792 instances
06/16/2022 23:05:18 - INFO - __main__ - Printing 3 examples
06/16/2022 23:05:18 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/16/2022 23:05:18 - INFO - __main__ - ['Company']
06/16/2022 23:05:18 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/16/2022 23:05:18 - INFO - __main__ - ['Company']
06/16/2022 23:05:18 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/16/2022 23:05:18 - INFO - __main__ - ['Company']
06/16/2022 23:05:18 - INFO - __main__ - Tokenizing Input ...
06/16/2022 23:05:19 - INFO - __main__ - Tokenizing Output ...
06/16/2022 23:05:20 - INFO - __main__ - Loaded 1792 examples from train data
06/16/2022 23:05:21 - INFO - __main__ - Start tokenizing ... 1792 instances
06/16/2022 23:05:21 - INFO - __main__ - Printing 3 examples
06/16/2022 23:05:21 - INFO - __main__ -  [dbpedia_14] The Aya Group of Companies commonly referred to as the Aya Group is a business conglomerate based in Uganda.
06/16/2022 23:05:21 - INFO - __main__ - ['Company']
06/16/2022 23:05:21 - INFO - __main__ -  [dbpedia_14] Casengo (founded in 2011) is a Dutch company that provides customer service tools for website and webshop owners available as a SaaS. The Amsterdam-based company was founded by Floris and Thijs van der Veen. Both brothers started off with software named Livecom used mainly by large companies such as Philips and DSM. When they decided to develop customer service software for small businesses Casengo was born.
06/16/2022 23:05:21 - INFO - __main__ - ['Company']
06/16/2022 23:05:21 - INFO - __main__ -  [dbpedia_14] KeySpan Corporation now part of National Grid USA was the fifth largest distributor of natural gas in the United States. KeySpan was formed in 1998 as result of the merger of Brooklyn Union Gas Company (founded 1895 by merging several smaller companies) and Long Island Lighting Company (LILCO).
06/16/2022 23:05:21 - INFO - __main__ - ['Company']
06/16/2022 23:05:21 - INFO - __main__ - Tokenizing Input ...
06/16/2022 23:05:21 - INFO - __main__ - Tokenizing Output ...
06/16/2022 23:05:23 - INFO - __main__ - Loaded 1792 examples from dev data
06/16/2022 23:05:42 - INFO - __main__ - load prompt embedding from ckpt
06/16/2022 23:05:43 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/16/2022 23:05:43 - INFO - __main__ - Starting training!
06/16/2022 23:05:46 - INFO - __main__ - Step 10 Global step 10 Train loss 4.75 on epoch=0
06/16/2022 23:05:49 - INFO - __main__ - Step 20 Global step 20 Train loss 2.77 on epoch=0
06/16/2022 23:05:52 - INFO - __main__ - Step 30 Global step 30 Train loss 2.11 on epoch=0
06/16/2022 23:05:54 - INFO - __main__ - Step 40 Global step 40 Train loss 1.81 on epoch=0
06/16/2022 23:05:57 - INFO - __main__ - Step 50 Global step 50 Train loss 1.50 on epoch=0
06/16/2022 23:06:46 - INFO - __main__ - Global step 50 Train loss 2.59 Classification-F1 0.19706190127061593 on epoch=0
06/16/2022 23:06:46 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.19706190127061593 on epoch=0, global_step=50
06/16/2022 23:06:49 - INFO - __main__ - Step 60 Global step 60 Train loss 1.06 on epoch=0
06/16/2022 23:06:51 - INFO - __main__ - Step 70 Global step 70 Train loss 1.03 on epoch=0
06/16/2022 23:06:54 - INFO - __main__ - Step 80 Global step 80 Train loss 0.82 on epoch=0
06/16/2022 23:06:56 - INFO - __main__ - Step 90 Global step 90 Train loss 0.78 on epoch=0
06/16/2022 23:06:59 - INFO - __main__ - Step 100 Global step 100 Train loss 0.94 on epoch=0
06/16/2022 23:07:53 - INFO - __main__ - Global step 100 Train loss 0.93 Classification-F1 0.4757988751086388 on epoch=0
06/16/2022 23:07:53 - INFO - __main__ - Saving model with best Classification-F1: 0.19706190127061593 -> 0.4757988751086388 on epoch=0, global_step=100
06/16/2022 23:07:55 - INFO - __main__ - Step 110 Global step 110 Train loss 0.88 on epoch=0
06/16/2022 23:07:58 - INFO - __main__ - Step 120 Global step 120 Train loss 0.61 on epoch=1
06/16/2022 23:08:00 - INFO - __main__ - Step 130 Global step 130 Train loss 0.63 on epoch=1
06/16/2022 23:08:03 - INFO - __main__ - Step 140 Global step 140 Train loss 0.64 on epoch=1
06/16/2022 23:08:05 - INFO - __main__ - Step 150 Global step 150 Train loss 0.55 on epoch=1
06/16/2022 23:09:01 - INFO - __main__ - Global step 150 Train loss 0.66 Classification-F1 0.43548280604431844 on epoch=1
06/16/2022 23:09:04 - INFO - __main__ - Step 160 Global step 160 Train loss 0.56 on epoch=1
06/16/2022 23:09:06 - INFO - __main__ - Step 170 Global step 170 Train loss 0.53 on epoch=1
06/16/2022 23:09:09 - INFO - __main__ - Step 180 Global step 180 Train loss 0.52 on epoch=1
06/16/2022 23:09:11 - INFO - __main__ - Step 190 Global step 190 Train loss 0.40 on epoch=1
06/16/2022 23:09:14 - INFO - __main__ - Step 200 Global step 200 Train loss 0.45 on epoch=1
06/16/2022 23:10:16 - INFO - __main__ - Global step 200 Train loss 0.49 Classification-F1 0.4990484302861725 on epoch=1
06/16/2022 23:10:16 - INFO - __main__ - Saving model with best Classification-F1: 0.4757988751086388 -> 0.4990484302861725 on epoch=1, global_step=200
06/16/2022 23:10:19 - INFO - __main__ - Step 210 Global step 210 Train loss 0.50 on epoch=1
06/16/2022 23:10:21 - INFO - __main__ - Step 220 Global step 220 Train loss 0.40 on epoch=1
06/16/2022 23:10:24 - INFO - __main__ - Step 230 Global step 230 Train loss 0.37 on epoch=2
06/16/2022 23:10:26 - INFO - __main__ - Step 240 Global step 240 Train loss 0.38 on epoch=2
06/16/2022 23:10:29 - INFO - __main__ - Step 250 Global step 250 Train loss 0.37 on epoch=2
06/16/2022 23:11:23 - INFO - __main__ - Global step 250 Train loss 0.40 Classification-F1 0.5936491900180287 on epoch=2
06/16/2022 23:11:23 - INFO - __main__ - Saving model with best Classification-F1: 0.4990484302861725 -> 0.5936491900180287 on epoch=2, global_step=250
06/16/2022 23:11:26 - INFO - __main__ - Step 260 Global step 260 Train loss 0.26 on epoch=2
06/16/2022 23:11:28 - INFO - __main__ - Step 270 Global step 270 Train loss 0.41 on epoch=2
06/16/2022 23:11:31 - INFO - __main__ - Step 280 Global step 280 Train loss 0.34 on epoch=2
06/16/2022 23:11:33 - INFO - __main__ - Step 290 Global step 290 Train loss 0.29 on epoch=2
06/16/2022 23:11:36 - INFO - __main__ - Step 300 Global step 300 Train loss 0.21 on epoch=2
06/16/2022 23:12:34 - INFO - __main__ - Global step 300 Train loss 0.30 Classification-F1 0.5287203551997819 on epoch=2
06/16/2022 23:12:36 - INFO - __main__ - Step 310 Global step 310 Train loss 0.23 on epoch=2
06/16/2022 23:12:39 - INFO - __main__ - Step 320 Global step 320 Train loss 0.34 on epoch=2
06/16/2022 23:12:41 - INFO - __main__ - Step 330 Global step 330 Train loss 0.29 on epoch=2
06/16/2022 23:12:44 - INFO - __main__ - Step 340 Global step 340 Train loss 0.28 on epoch=3
06/16/2022 23:12:46 - INFO - __main__ - Step 350 Global step 350 Train loss 0.27 on epoch=3
06/16/2022 23:13:45 - INFO - __main__ - Global step 350 Train loss 0.28 Classification-F1 0.6932538059354585 on epoch=3
06/16/2022 23:13:45 - INFO - __main__ - Saving model with best Classification-F1: 0.5936491900180287 -> 0.6932538059354585 on epoch=3, global_step=350
06/16/2022 23:13:47 - INFO - __main__ - Step 360 Global step 360 Train loss 0.24 on epoch=3
06/16/2022 23:13:50 - INFO - __main__ - Step 370 Global step 370 Train loss 0.19 on epoch=3
06/16/2022 23:13:52 - INFO - __main__ - Step 380 Global step 380 Train loss 0.23 on epoch=3
06/16/2022 23:13:55 - INFO - __main__ - Step 390 Global step 390 Train loss 0.17 on epoch=3
06/16/2022 23:13:57 - INFO - __main__ - Step 400 Global step 400 Train loss 0.30 on epoch=3
06/16/2022 23:14:56 - INFO - __main__ - Global step 400 Train loss 0.23 Classification-F1 0.7063084917466126 on epoch=3
06/16/2022 23:14:56 - INFO - __main__ - Saving model with best Classification-F1: 0.6932538059354585 -> 0.7063084917466126 on epoch=3, global_step=400
06/16/2022 23:14:59 - INFO - __main__ - Step 410 Global step 410 Train loss 0.18 on epoch=3
06/16/2022 23:15:01 - INFO - __main__ - Step 420 Global step 420 Train loss 0.12 on epoch=3
06/16/2022 23:15:04 - INFO - __main__ - Step 430 Global step 430 Train loss 0.20 on epoch=3
06/16/2022 23:15:06 - INFO - __main__ - Step 440 Global step 440 Train loss 0.21 on epoch=3
06/16/2022 23:15:09 - INFO - __main__ - Step 450 Global step 450 Train loss 0.11 on epoch=4
06/16/2022 23:16:11 - INFO - __main__ - Global step 450 Train loss 0.16 Classification-F1 0.6581971532145093 on epoch=4
06/16/2022 23:16:14 - INFO - __main__ - Step 460 Global step 460 Train loss 0.15 on epoch=4
06/16/2022 23:16:16 - INFO - __main__ - Step 470 Global step 470 Train loss 0.19 on epoch=4
06/16/2022 23:16:19 - INFO - __main__ - Step 480 Global step 480 Train loss 0.16 on epoch=4
06/16/2022 23:16:21 - INFO - __main__ - Step 490 Global step 490 Train loss 0.13 on epoch=4
06/16/2022 23:16:24 - INFO - __main__ - Step 500 Global step 500 Train loss 0.18 on epoch=4
06/16/2022 23:17:25 - INFO - __main__ - Global step 500 Train loss 0.16 Classification-F1 0.5785870091145037 on epoch=4
06/16/2022 23:17:27 - INFO - __main__ - Step 510 Global step 510 Train loss 0.13 on epoch=4
06/16/2022 23:17:30 - INFO - __main__ - Step 520 Global step 520 Train loss 0.15 on epoch=4
06/16/2022 23:17:32 - INFO - __main__ - Step 530 Global step 530 Train loss 0.13 on epoch=4
06/16/2022 23:17:35 - INFO - __main__ - Step 540 Global step 540 Train loss 0.15 on epoch=4
06/16/2022 23:17:38 - INFO - __main__ - Step 550 Global step 550 Train loss 0.14 on epoch=4
06/16/2022 23:18:39 - INFO - __main__ - Global step 550 Train loss 0.14 Classification-F1 0.8352647316363312 on epoch=4
06/16/2022 23:18:39 - INFO - __main__ - Saving model with best Classification-F1: 0.7063084917466126 -> 0.8352647316363312 on epoch=4, global_step=550
06/16/2022 23:18:42 - INFO - __main__ - Step 560 Global step 560 Train loss 0.13 on epoch=4
06/16/2022 23:18:45 - INFO - __main__ - Step 570 Global step 570 Train loss 0.12 on epoch=5
06/16/2022 23:18:47 - INFO - __main__ - Step 580 Global step 580 Train loss 0.17 on epoch=5
06/16/2022 23:18:50 - INFO - __main__ - Step 590 Global step 590 Train loss 0.10 on epoch=5
06/16/2022 23:18:52 - INFO - __main__ - Step 600 Global step 600 Train loss 0.14 on epoch=5
06/16/2022 23:19:51 - INFO - __main__ - Global step 600 Train loss 0.13 Classification-F1 0.635381456650533 on epoch=5
06/16/2022 23:19:54 - INFO - __main__ - Step 610 Global step 610 Train loss 0.13 on epoch=5
06/16/2022 23:19:57 - INFO - __main__ - Step 620 Global step 620 Train loss 0.14 on epoch=5
06/16/2022 23:19:59 - INFO - __main__ - Step 630 Global step 630 Train loss 0.09 on epoch=5
06/16/2022 23:20:02 - INFO - __main__ - Step 640 Global step 640 Train loss 0.16 on epoch=5
06/16/2022 23:20:04 - INFO - __main__ - Step 650 Global step 650 Train loss 0.16 on epoch=5
06/16/2022 23:21:00 - INFO - __main__ - Global step 650 Train loss 0.14 Classification-F1 0.4634884093179089 on epoch=5
06/16/2022 23:21:02 - INFO - __main__ - Step 660 Global step 660 Train loss 0.16 on epoch=5
06/16/2022 23:21:05 - INFO - __main__ - Step 670 Global step 670 Train loss 0.15 on epoch=5
06/16/2022 23:21:07 - INFO - __main__ - Step 680 Global step 680 Train loss 0.12 on epoch=6
06/16/2022 23:21:10 - INFO - __main__ - Step 690 Global step 690 Train loss 0.13 on epoch=6
06/16/2022 23:21:12 - INFO - __main__ - Step 700 Global step 700 Train loss 0.09 on epoch=6
06/16/2022 23:22:03 - INFO - __main__ - Global step 700 Train loss 0.13 Classification-F1 0.5491596994971467 on epoch=6
06/16/2022 23:22:06 - INFO - __main__ - Step 710 Global step 710 Train loss 0.06 on epoch=6
06/16/2022 23:22:08 - INFO - __main__ - Step 720 Global step 720 Train loss 0.14 on epoch=6
06/16/2022 23:22:11 - INFO - __main__ - Step 730 Global step 730 Train loss 0.08 on epoch=6
06/16/2022 23:22:13 - INFO - __main__ - Step 740 Global step 740 Train loss 0.16 on epoch=6
06/16/2022 23:22:16 - INFO - __main__ - Step 750 Global step 750 Train loss 0.14 on epoch=6
06/16/2022 23:23:11 - INFO - __main__ - Global step 750 Train loss 0.11 Classification-F1 0.4978883923185077 on epoch=6
06/16/2022 23:23:14 - INFO - __main__ - Step 760 Global step 760 Train loss 0.13 on epoch=6
06/16/2022 23:23:16 - INFO - __main__ - Step 770 Global step 770 Train loss 0.14 on epoch=6
06/16/2022 23:23:19 - INFO - __main__ - Step 780 Global step 780 Train loss 0.14 on epoch=6
06/16/2022 23:23:21 - INFO - __main__ - Step 790 Global step 790 Train loss 0.09 on epoch=7
06/16/2022 23:23:24 - INFO - __main__ - Step 800 Global step 800 Train loss 0.18 on epoch=7
06/16/2022 23:24:13 - INFO - __main__ - Global step 800 Train loss 0.14 Classification-F1 0.4988443344479139 on epoch=7
06/16/2022 23:24:15 - INFO - __main__ - Step 810 Global step 810 Train loss 0.07 on epoch=7
06/16/2022 23:24:18 - INFO - __main__ - Step 820 Global step 820 Train loss 0.04 on epoch=7
06/16/2022 23:24:20 - INFO - __main__ - Step 830 Global step 830 Train loss 0.14 on epoch=7
06/16/2022 23:24:23 - INFO - __main__ - Step 840 Global step 840 Train loss 0.07 on epoch=7
06/16/2022 23:24:25 - INFO - __main__ - Step 850 Global step 850 Train loss 0.14 on epoch=7
06/16/2022 23:25:21 - INFO - __main__ - Global step 850 Train loss 0.09 Classification-F1 0.6679779487955062 on epoch=7
06/16/2022 23:25:23 - INFO - __main__ - Step 860 Global step 860 Train loss 0.12 on epoch=7
06/16/2022 23:25:26 - INFO - __main__ - Step 870 Global step 870 Train loss 0.05 on epoch=7
06/16/2022 23:25:28 - INFO - __main__ - Step 880 Global step 880 Train loss 0.14 on epoch=7
06/16/2022 23:25:31 - INFO - __main__ - Step 890 Global step 890 Train loss 0.08 on epoch=7
06/16/2022 23:25:33 - INFO - __main__ - Step 900 Global step 900 Train loss 0.05 on epoch=8
06/16/2022 23:26:30 - INFO - __main__ - Global step 900 Train loss 0.09 Classification-F1 0.851216304795946 on epoch=8
06/16/2022 23:26:30 - INFO - __main__ - Saving model with best Classification-F1: 0.8352647316363312 -> 0.851216304795946 on epoch=8, global_step=900
06/16/2022 23:26:33 - INFO - __main__ - Step 910 Global step 910 Train loss 0.12 on epoch=8
06/16/2022 23:26:35 - INFO - __main__ - Step 920 Global step 920 Train loss 0.04 on epoch=8
06/16/2022 23:26:38 - INFO - __main__ - Step 930 Global step 930 Train loss 0.08 on epoch=8
06/16/2022 23:26:40 - INFO - __main__ - Step 940 Global step 940 Train loss 0.09 on epoch=8
06/16/2022 23:26:43 - INFO - __main__ - Step 950 Global step 950 Train loss 0.05 on epoch=8
06/16/2022 23:27:34 - INFO - __main__ - Global step 950 Train loss 0.07 Classification-F1 0.6993543235486218 on epoch=8
06/16/2022 23:27:36 - INFO - __main__ - Step 960 Global step 960 Train loss 0.10 on epoch=8
06/16/2022 23:27:39 - INFO - __main__ - Step 970 Global step 970 Train loss 0.11 on epoch=8
06/16/2022 23:27:41 - INFO - __main__ - Step 980 Global step 980 Train loss 0.04 on epoch=8
06/16/2022 23:27:44 - INFO - __main__ - Step 990 Global step 990 Train loss 0.12 on epoch=8
06/16/2022 23:27:47 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.09 on epoch=8
06/16/2022 23:28:43 - INFO - __main__ - Global step 1000 Train loss 0.09 Classification-F1 0.8588744835183967 on epoch=8
06/16/2022 23:28:43 - INFO - __main__ - Saving model with best Classification-F1: 0.851216304795946 -> 0.8588744835183967 on epoch=8, global_step=1000
06/16/2022 23:28:46 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.09 on epoch=9
06/16/2022 23:28:48 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.09 on epoch=9
06/16/2022 23:28:51 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.08 on epoch=9
06/16/2022 23:28:53 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.07 on epoch=9
06/16/2022 23:28:56 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.11 on epoch=9
06/16/2022 23:29:58 - INFO - __main__ - Global step 1050 Train loss 0.09 Classification-F1 0.7488483067575757 on epoch=9
06/16/2022 23:30:00 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.08 on epoch=9
06/16/2022 23:30:03 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.07 on epoch=9
06/16/2022 23:30:06 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.07 on epoch=9
06/16/2022 23:30:08 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.06 on epoch=9
06/16/2022 23:30:11 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.12 on epoch=9
06/16/2022 23:31:13 - INFO - __main__ - Global step 1100 Train loss 0.08 Classification-F1 0.745497420211823 on epoch=9
06/16/2022 23:31:16 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.04 on epoch=9
06/16/2022 23:31:18 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.07 on epoch=9
06/16/2022 23:31:21 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.07 on epoch=10
06/16/2022 23:31:24 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.11 on epoch=10
06/16/2022 23:31:26 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.08 on epoch=10
06/16/2022 23:32:22 - INFO - __main__ - Global step 1150 Train loss 0.07 Classification-F1 0.7260085650876218 on epoch=10
06/16/2022 23:32:24 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.03 on epoch=10
06/16/2022 23:32:27 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.09 on epoch=10
06/16/2022 23:32:29 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.03 on epoch=10
06/16/2022 23:32:32 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.10 on epoch=10
06/16/2022 23:32:34 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.02 on epoch=10
06/16/2022 23:33:31 - INFO - __main__ - Global step 1200 Train loss 0.05 Classification-F1 0.7009416916369772 on epoch=10
06/16/2022 23:33:33 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.10 on epoch=10
06/16/2022 23:33:36 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.15 on epoch=10
06/16/2022 23:33:38 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.04 on epoch=10
06/16/2022 23:33:41 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.04 on epoch=11
06/16/2022 23:33:43 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.07 on epoch=11
06/16/2022 23:34:34 - INFO - __main__ - Global step 1250 Train loss 0.08 Classification-F1 0.6055122385699732 on epoch=11
06/16/2022 23:34:36 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.02 on epoch=11
06/16/2022 23:34:39 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.02 on epoch=11
06/16/2022 23:34:41 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.07 on epoch=11
06/16/2022 23:34:44 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.03 on epoch=11
06/16/2022 23:34:47 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.04 on epoch=11
06/16/2022 23:35:36 - INFO - __main__ - Global step 1300 Train loss 0.03 Classification-F1 0.710243285841851 on epoch=11
06/16/2022 23:35:38 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.04 on epoch=11
06/16/2022 23:35:41 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.05 on epoch=11
06/16/2022 23:35:43 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.06 on epoch=11
06/16/2022 23:35:46 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.04 on epoch=11
06/16/2022 23:35:49 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.08 on epoch=12
06/16/2022 23:36:40 - INFO - __main__ - Global step 1350 Train loss 0.05 Classification-F1 0.7435392265866138 on epoch=12
06/16/2022 23:36:43 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.07 on epoch=12
06/16/2022 23:36:46 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.05 on epoch=12
06/16/2022 23:36:48 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.02 on epoch=12
06/16/2022 23:36:51 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.02 on epoch=12
06/16/2022 23:36:53 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.06 on epoch=12
06/16/2022 23:37:48 - INFO - __main__ - Global step 1400 Train loss 0.04 Classification-F1 0.740136449618719 on epoch=12
06/16/2022 23:37:51 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.04 on epoch=12
06/16/2022 23:37:53 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.05 on epoch=12
06/16/2022 23:37:56 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.06 on epoch=12
06/16/2022 23:37:58 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.13 on epoch=12
06/16/2022 23:38:01 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.04 on epoch=12
06/16/2022 23:38:57 - INFO - __main__ - Global step 1450 Train loss 0.06 Classification-F1 0.7120250402417875 on epoch=12
06/16/2022 23:38:59 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.04 on epoch=13
06/16/2022 23:39:02 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.09 on epoch=13
06/16/2022 23:39:04 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.07 on epoch=13
06/16/2022 23:39:07 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.02 on epoch=13
06/16/2022 23:39:09 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.07 on epoch=13
06/16/2022 23:40:03 - INFO - __main__ - Global step 1500 Train loss 0.06 Classification-F1 0.7833208363340018 on epoch=13
06/16/2022 23:40:05 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.05 on epoch=13
06/16/2022 23:40:08 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.03 on epoch=13
06/16/2022 23:40:10 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.04 on epoch=13
06/16/2022 23:40:13 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.05 on epoch=13
06/16/2022 23:40:15 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.13 on epoch=13
06/16/2022 23:41:04 - INFO - __main__ - Global step 1550 Train loss 0.06 Classification-F1 0.6685257180860446 on epoch=13
06/16/2022 23:41:06 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.02 on epoch=13
06/16/2022 23:41:09 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.05 on epoch=14
06/16/2022 23:41:11 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.14 on epoch=14
06/16/2022 23:41:14 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.04 on epoch=14
06/16/2022 23:41:17 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=14
06/16/2022 23:42:05 - INFO - __main__ - Global step 1600 Train loss 0.05 Classification-F1 0.7943406642922977 on epoch=14
06/16/2022 23:42:08 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=14
06/16/2022 23:42:11 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.02 on epoch=14
06/16/2022 23:42:13 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.09 on epoch=14
06/16/2022 23:42:16 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.06 on epoch=14
06/16/2022 23:42:18 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=14
06/16/2022 23:43:06 - INFO - __main__ - Global step 1650 Train loss 0.04 Classification-F1 0.8019406682655145 on epoch=14
06/16/2022 23:43:09 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.07 on epoch=14
06/16/2022 23:43:12 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.06 on epoch=14
06/16/2022 23:43:14 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=14
06/16/2022 23:43:17 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.04 on epoch=15
06/16/2022 23:43:19 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.08 on epoch=15
06/16/2022 23:44:10 - INFO - __main__ - Global step 1700 Train loss 0.05 Classification-F1 0.8071279866168197 on epoch=15
06/16/2022 23:44:12 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=15
06/16/2022 23:44:15 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.02 on epoch=15
06/16/2022 23:44:17 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.03 on epoch=15
06/16/2022 23:44:20 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=15
06/16/2022 23:44:23 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.04 on epoch=15
06/16/2022 23:45:18 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.762963702788382 on epoch=15
06/16/2022 23:45:20 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=15
06/16/2022 23:45:23 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.06 on epoch=15
06/16/2022 23:45:25 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.04 on epoch=15
06/16/2022 23:45:28 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.03 on epoch=15
06/16/2022 23:45:31 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.03 on epoch=16
06/16/2022 23:46:20 - INFO - __main__ - Global step 1800 Train loss 0.04 Classification-F1 0.7104474548359756 on epoch=16
06/16/2022 23:46:23 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.07 on epoch=16
06/16/2022 23:46:26 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=16
06/16/2022 23:46:28 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=16
06/16/2022 23:46:31 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=16
06/16/2022 23:46:33 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=16
06/16/2022 23:47:24 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.7078961181206667 on epoch=16
06/16/2022 23:47:26 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.08 on epoch=16
06/16/2022 23:47:29 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=16
06/16/2022 23:47:31 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.06 on epoch=16
06/16/2022 23:47:34 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.11 on epoch=16
06/16/2022 23:47:36 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=16
06/16/2022 23:48:30 - INFO - __main__ - Global step 1900 Train loss 0.06 Classification-F1 0.7584237005306406 on epoch=16
06/16/2022 23:48:32 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=17
06/16/2022 23:48:35 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.08 on epoch=17
06/16/2022 23:48:37 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=17
06/16/2022 23:48:40 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=17
06/16/2022 23:48:42 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.04 on epoch=17
06/16/2022 23:49:27 - INFO - __main__ - Global step 1950 Train loss 0.04 Classification-F1 0.8342224829990303 on epoch=17
06/16/2022 23:49:29 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=17
06/16/2022 23:49:32 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.04 on epoch=17
06/16/2022 23:49:34 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=17
06/16/2022 23:49:37 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=17
06/16/2022 23:49:39 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.07 on epoch=17
06/16/2022 23:50:28 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.7881254470672507 on epoch=17
06/16/2022 23:50:31 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.06 on epoch=17
06/16/2022 23:50:33 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=18
06/16/2022 23:50:36 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.08 on epoch=18
06/16/2022 23:50:38 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=18
06/16/2022 23:50:41 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=18
06/16/2022 23:51:29 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.7475818423095204 on epoch=18
06/16/2022 23:51:31 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.07 on epoch=18
06/16/2022 23:51:34 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=18
06/16/2022 23:51:36 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.03 on epoch=18
06/16/2022 23:51:39 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=18
06/16/2022 23:51:42 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=18
06/16/2022 23:52:28 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.7192842584888732 on epoch=18
06/16/2022 23:52:31 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.19 on epoch=18
06/16/2022 23:52:33 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.04 on epoch=18
06/16/2022 23:52:36 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=19
06/16/2022 23:52:39 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.08 on epoch=19
06/16/2022 23:52:41 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.03 on epoch=19
06/16/2022 23:53:32 - INFO - __main__ - Global step 2150 Train loss 0.07 Classification-F1 0.7128283900559825 on epoch=19
06/16/2022 23:53:34 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=19
06/16/2022 23:53:37 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=19
06/16/2022 23:53:40 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.19 on epoch=19
06/16/2022 23:53:42 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=19
06/16/2022 23:53:45 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=19
06/16/2022 23:54:33 - INFO - __main__ - Global step 2200 Train loss 0.05 Classification-F1 0.806785844629247 on epoch=19
06/16/2022 23:54:36 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=19
06/16/2022 23:54:38 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.05 on epoch=19
06/16/2022 23:54:41 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.10 on epoch=19
06/16/2022 23:54:43 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.03 on epoch=19
06/16/2022 23:54:46 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=20
06/16/2022 23:55:34 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.8555810242442861 on epoch=20
06/16/2022 23:55:37 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.07 on epoch=20
06/16/2022 23:55:40 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.04 on epoch=20
06/16/2022 23:55:42 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=20
06/16/2022 23:55:45 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.06 on epoch=20
06/16/2022 23:55:47 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.04 on epoch=20
06/16/2022 23:56:34 - INFO - __main__ - Global step 2300 Train loss 0.05 Classification-F1 0.6473094857505143 on epoch=20
06/16/2022 23:56:36 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=20
06/16/2022 23:56:39 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=20
06/16/2022 23:56:41 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.05 on epoch=20
06/16/2022 23:56:44 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.07 on epoch=20
06/16/2022 23:56:47 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=20
06/16/2022 23:57:34 - INFO - __main__ - Global step 2350 Train loss 0.04 Classification-F1 0.6467661254857549 on epoch=20
06/16/2022 23:57:37 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.04 on epoch=21
06/16/2022 23:57:39 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.14 on epoch=21
06/16/2022 23:57:42 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=21
06/16/2022 23:57:44 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=21
06/16/2022 23:57:47 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.06 on epoch=21
06/16/2022 23:58:36 - INFO - __main__ - Global step 2400 Train loss 0.06 Classification-F1 0.548480474961713 on epoch=21
06/16/2022 23:58:38 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=21
06/16/2022 23:58:41 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=21
06/16/2022 23:58:43 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=21
06/16/2022 23:58:46 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.04 on epoch=21
06/16/2022 23:58:48 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.03 on epoch=21
06/16/2022 23:59:37 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.6327728574491152 on epoch=21
06/16/2022 23:59:40 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=21
06/16/2022 23:59:42 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.04 on epoch=22
06/16/2022 23:59:45 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.04 on epoch=22
06/16/2022 23:59:47 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=22
06/16/2022 23:59:50 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=22
06/17/2022 00:00:37 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.7605864997505876 on epoch=22
06/17/2022 00:00:40 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=22
06/17/2022 00:00:42 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=22
06/17/2022 00:00:45 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.04 on epoch=22
06/17/2022 00:00:48 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.04 on epoch=22
06/17/2022 00:00:50 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=22
06/17/2022 00:01:37 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.7421498499487956 on epoch=22
06/17/2022 00:01:40 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.12 on epoch=22
06/17/2022 00:01:42 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.06 on epoch=22
06/17/2022 00:01:45 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.03 on epoch=23
06/17/2022 00:01:47 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.05 on epoch=23
06/17/2022 00:01:50 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=23
06/17/2022 00:02:38 - INFO - __main__ - Global step 2600 Train loss 0.05 Classification-F1 0.615016942393567 on epoch=23
06/17/2022 00:02:40 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=23
06/17/2022 00:02:43 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.03 on epoch=23
06/17/2022 00:02:45 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=23
06/17/2022 00:02:48 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.04 on epoch=23
06/17/2022 00:02:51 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=23
06/17/2022 00:03:37 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.8380756092117334 on epoch=23
06/17/2022 00:03:40 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.07 on epoch=23
06/17/2022 00:03:43 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.08 on epoch=23
06/17/2022 00:03:45 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=23
06/17/2022 00:03:48 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=24
06/17/2022 00:03:50 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=24
06/17/2022 00:04:38 - INFO - __main__ - Global step 2700 Train loss 0.04 Classification-F1 0.7300931348322591 on epoch=24
06/17/2022 00:04:41 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=24
06/17/2022 00:04:43 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=24
06/17/2022 00:04:46 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=24
06/17/2022 00:04:48 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=24
06/17/2022 00:04:51 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.05 on epoch=24
06/17/2022 00:05:38 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.7434888960749076 on epoch=24
06/17/2022 00:05:40 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=24
06/17/2022 00:05:43 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=24
06/17/2022 00:05:46 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.05 on epoch=24
06/17/2022 00:05:48 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=24
06/17/2022 00:05:51 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=24
06/17/2022 00:06:41 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.7608124707086866 on epoch=24
06/17/2022 00:06:43 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.03 on epoch=25
06/17/2022 00:06:46 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.09 on epoch=25
06/17/2022 00:06:48 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=25
06/17/2022 00:06:51 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=25
06/17/2022 00:06:53 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.04 on epoch=25
06/17/2022 00:07:41 - INFO - __main__ - Global step 2850 Train loss 0.03 Classification-F1 0.809568959704063 on epoch=25
06/17/2022 00:07:43 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.03 on epoch=25
06/17/2022 00:07:46 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=25
06/17/2022 00:07:48 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=25
06/17/2022 00:07:51 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.06 on epoch=25
06/17/2022 00:07:53 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.06 on epoch=25
06/17/2022 00:08:40 - INFO - __main__ - Global step 2900 Train loss 0.04 Classification-F1 0.8030150642180935 on epoch=25
06/17/2022 00:08:43 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=25
06/17/2022 00:08:46 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.03 on epoch=26
06/17/2022 00:08:48 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.05 on epoch=26
06/17/2022 00:08:51 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=26
06/17/2022 00:08:53 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=26
06/17/2022 00:09:39 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.9194772646831174 on epoch=26
06/17/2022 00:09:39 - INFO - __main__ - Saving model with best Classification-F1: 0.8588744835183967 -> 0.9194772646831174 on epoch=26, global_step=2950
06/17/2022 00:09:42 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.04 on epoch=26
06/17/2022 00:09:44 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.03 on epoch=26
06/17/2022 00:09:47 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.03 on epoch=26
06/17/2022 00:09:49 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=26
06/17/2022 00:09:52 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.03 on epoch=26
06/17/2022 00:09:54 - INFO - __main__ - Start tokenizing ... 1792 instances
06/17/2022 00:09:54 - INFO - __main__ - Printing 3 examples
06/17/2022 00:09:54 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/17/2022 00:09:54 - INFO - __main__ - ['Company']
06/17/2022 00:09:54 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/17/2022 00:09:54 - INFO - __main__ - ['Company']
06/17/2022 00:09:54 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/17/2022 00:09:54 - INFO - __main__ - ['Company']
06/17/2022 00:09:54 - INFO - __main__ - Tokenizing Input ...
06/17/2022 00:09:54 - INFO - __main__ - Tokenizing Output ...
06/17/2022 00:09:56 - INFO - __main__ - Loaded 1792 examples from train data
06/17/2022 00:09:56 - INFO - __main__ - Start tokenizing ... 1792 instances
06/17/2022 00:09:56 - INFO - __main__ - Printing 3 examples
06/17/2022 00:09:56 - INFO - __main__ -  [dbpedia_14] The Aya Group of Companies commonly referred to as the Aya Group is a business conglomerate based in Uganda.
06/17/2022 00:09:56 - INFO - __main__ - ['Company']
06/17/2022 00:09:56 - INFO - __main__ -  [dbpedia_14] Casengo (founded in 2011) is a Dutch company that provides customer service tools for website and webshop owners available as a SaaS. The Amsterdam-based company was founded by Floris and Thijs van der Veen. Both brothers started off with software named Livecom used mainly by large companies such as Philips and DSM. When they decided to develop customer service software for small businesses Casengo was born.
06/17/2022 00:09:56 - INFO - __main__ - ['Company']
06/17/2022 00:09:56 - INFO - __main__ -  [dbpedia_14] KeySpan Corporation now part of National Grid USA was the fifth largest distributor of natural gas in the United States. KeySpan was formed in 1998 as result of the merger of Brooklyn Union Gas Company (founded 1895 by merging several smaller companies) and Long Island Lighting Company (LILCO).
06/17/2022 00:09:56 - INFO - __main__ - ['Company']
06/17/2022 00:09:56 - INFO - __main__ - Tokenizing Input ...
06/17/2022 00:09:57 - INFO - __main__ - Tokenizing Output ...
06/17/2022 00:09:59 - INFO - __main__ - Loaded 1792 examples from dev data
06/17/2022 00:10:15 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 00:10:16 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/17/2022 00:10:16 - INFO - __main__ - Starting training!
06/17/2022 00:10:38 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.8000851450641848 on epoch=26
06/17/2022 00:10:38 - INFO - __main__ - save last model!
06/17/2022 00:10:38 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/17/2022 00:10:38 - INFO - __main__ - Start tokenizing ... 3500 instances
06/17/2022 00:10:38 - INFO - __main__ - Printing 3 examples
06/17/2022 00:10:38 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/17/2022 00:10:38 - INFO - __main__ - ['Animal']
06/17/2022 00:10:38 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/17/2022 00:10:38 - INFO - __main__ - ['Animal']
06/17/2022 00:10:38 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/17/2022 00:10:38 - INFO - __main__ - ['Village']
06/17/2022 00:10:38 - INFO - __main__ - Tokenizing Input ...
06/17/2022 00:10:40 - INFO - __main__ - Tokenizing Output ...
06/17/2022 00:10:44 - INFO - __main__ - Loaded 3500 examples from test data
06/17/2022 00:12:47 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down128shot/singletask-dbpedia_14/dbpedia_14_128_42_0.4_8_predictions.txt
06/17/2022 00:12:47 - INFO - __main__ - Classification-F1 on test data: 0.5661
06/17/2022 00:12:48 - INFO - __main__ - prefix=dbpedia_14_128_42, lr=0.4, bsz=8, dev_performance=0.9194772646831174, test_performance=0.5661109461722988
06/17/2022 00:12:48 - INFO - __main__ - Running ... prefix=dbpedia_14_128_42, lr=0.3, bsz=8 ...
06/17/2022 00:12:49 - INFO - __main__ - Start tokenizing ... 1792 instances
06/17/2022 00:12:49 - INFO - __main__ - Printing 3 examples
06/17/2022 00:12:49 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/17/2022 00:12:49 - INFO - __main__ - ['Company']
06/17/2022 00:12:49 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/17/2022 00:12:49 - INFO - __main__ - ['Company']
06/17/2022 00:12:49 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/17/2022 00:12:49 - INFO - __main__ - ['Company']
06/17/2022 00:12:49 - INFO - __main__ - Tokenizing Input ...
06/17/2022 00:12:50 - INFO - __main__ - Tokenizing Output ...
06/17/2022 00:12:51 - INFO - __main__ - Loaded 1792 examples from train data
06/17/2022 00:12:51 - INFO - __main__ - Start tokenizing ... 1792 instances
06/17/2022 00:12:51 - INFO - __main__ - Printing 3 examples
06/17/2022 00:12:51 - INFO - __main__ -  [dbpedia_14] The Aya Group of Companies commonly referred to as the Aya Group is a business conglomerate based in Uganda.
06/17/2022 00:12:51 - INFO - __main__ - ['Company']
06/17/2022 00:12:51 - INFO - __main__ -  [dbpedia_14] Casengo (founded in 2011) is a Dutch company that provides customer service tools for website and webshop owners available as a SaaS. The Amsterdam-based company was founded by Floris and Thijs van der Veen. Both brothers started off with software named Livecom used mainly by large companies such as Philips and DSM. When they decided to develop customer service software for small businesses Casengo was born.
06/17/2022 00:12:51 - INFO - __main__ - ['Company']
06/17/2022 00:12:51 - INFO - __main__ -  [dbpedia_14] KeySpan Corporation now part of National Grid USA was the fifth largest distributor of natural gas in the United States. KeySpan was formed in 1998 as result of the merger of Brooklyn Union Gas Company (founded 1895 by merging several smaller companies) and Long Island Lighting Company (LILCO).
06/17/2022 00:12:51 - INFO - __main__ - ['Company']
06/17/2022 00:12:51 - INFO - __main__ - Tokenizing Input ...
06/17/2022 00:12:52 - INFO - __main__ - Tokenizing Output ...
06/17/2022 00:12:54 - INFO - __main__ - Loaded 1792 examples from dev data
06/17/2022 00:13:12 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 00:13:13 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/17/2022 00:13:13 - INFO - __main__ - Starting training!
06/17/2022 00:13:17 - INFO - __main__ - Step 10 Global step 10 Train loss 4.89 on epoch=0
06/17/2022 00:13:20 - INFO - __main__ - Step 20 Global step 20 Train loss 3.11 on epoch=0
06/17/2022 00:13:22 - INFO - __main__ - Step 30 Global step 30 Train loss 2.34 on epoch=0
06/17/2022 00:13:25 - INFO - __main__ - Step 40 Global step 40 Train loss 2.01 on epoch=0
06/17/2022 00:13:28 - INFO - __main__ - Step 50 Global step 50 Train loss 1.78 on epoch=0
06/17/2022 00:14:12 - INFO - __main__ - Global step 50 Train loss 2.82 Classification-F1 0.12097273681510418 on epoch=0
06/17/2022 00:14:12 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.12097273681510418 on epoch=0, global_step=50
06/17/2022 00:14:15 - INFO - __main__ - Step 60 Global step 60 Train loss 1.37 on epoch=0
06/17/2022 00:14:18 - INFO - __main__ - Step 70 Global step 70 Train loss 1.13 on epoch=0
06/17/2022 00:14:20 - INFO - __main__ - Step 80 Global step 80 Train loss 0.91 on epoch=0
06/17/2022 00:14:23 - INFO - __main__ - Step 90 Global step 90 Train loss 1.00 on epoch=0
06/17/2022 00:14:25 - INFO - __main__ - Step 100 Global step 100 Train loss 0.89 on epoch=0
06/17/2022 00:15:16 - INFO - __main__ - Global step 100 Train loss 1.06 Classification-F1 0.23774340265417682 on epoch=0
06/17/2022 00:15:16 - INFO - __main__ - Saving model with best Classification-F1: 0.12097273681510418 -> 0.23774340265417682 on epoch=0, global_step=100
06/17/2022 00:15:19 - INFO - __main__ - Step 110 Global step 110 Train loss 0.87 on epoch=0
06/17/2022 00:15:21 - INFO - __main__ - Step 120 Global step 120 Train loss 0.73 on epoch=1
06/17/2022 00:15:24 - INFO - __main__ - Step 130 Global step 130 Train loss 0.81 on epoch=1
06/17/2022 00:15:27 - INFO - __main__ - Step 140 Global step 140 Train loss 0.62 on epoch=1
06/17/2022 00:15:29 - INFO - __main__ - Step 150 Global step 150 Train loss 0.63 on epoch=1
06/17/2022 00:16:22 - INFO - __main__ - Global step 150 Train loss 0.73 Classification-F1 0.35384088750617754 on epoch=1
06/17/2022 00:16:22 - INFO - __main__ - Saving model with best Classification-F1: 0.23774340265417682 -> 0.35384088750617754 on epoch=1, global_step=150
06/17/2022 00:16:24 - INFO - __main__ - Step 160 Global step 160 Train loss 0.52 on epoch=1
06/17/2022 00:16:27 - INFO - __main__ - Step 170 Global step 170 Train loss 0.55 on epoch=1
06/17/2022 00:16:29 - INFO - __main__ - Step 180 Global step 180 Train loss 0.52 on epoch=1
06/17/2022 00:16:32 - INFO - __main__ - Step 190 Global step 190 Train loss 0.43 on epoch=1
06/17/2022 00:16:35 - INFO - __main__ - Step 200 Global step 200 Train loss 0.40 on epoch=1
06/17/2022 00:17:27 - INFO - __main__ - Global step 200 Train loss 0.48 Classification-F1 0.47104234118072397 on epoch=1
06/17/2022 00:17:27 - INFO - __main__ - Saving model with best Classification-F1: 0.35384088750617754 -> 0.47104234118072397 on epoch=1, global_step=200
06/17/2022 00:17:29 - INFO - __main__ - Step 210 Global step 210 Train loss 0.61 on epoch=1
06/17/2022 00:17:32 - INFO - __main__ - Step 220 Global step 220 Train loss 0.45 on epoch=1
06/17/2022 00:17:34 - INFO - __main__ - Step 230 Global step 230 Train loss 0.44 on epoch=2
06/17/2022 00:17:37 - INFO - __main__ - Step 240 Global step 240 Train loss 0.38 on epoch=2
06/17/2022 00:17:40 - INFO - __main__ - Step 250 Global step 250 Train loss 0.37 on epoch=2
06/17/2022 00:18:34 - INFO - __main__ - Global step 250 Train loss 0.45 Classification-F1 0.5029441628094041 on epoch=2
06/17/2022 00:18:35 - INFO - __main__ - Saving model with best Classification-F1: 0.47104234118072397 -> 0.5029441628094041 on epoch=2, global_step=250
06/17/2022 00:18:37 - INFO - __main__ - Step 260 Global step 260 Train loss 0.31 on epoch=2
06/17/2022 00:18:40 - INFO - __main__ - Step 270 Global step 270 Train loss 0.41 on epoch=2
06/17/2022 00:18:42 - INFO - __main__ - Step 280 Global step 280 Train loss 0.41 on epoch=2
06/17/2022 00:18:45 - INFO - __main__ - Step 290 Global step 290 Train loss 0.30 on epoch=2
06/17/2022 00:18:47 - INFO - __main__ - Step 300 Global step 300 Train loss 0.26 on epoch=2
06/17/2022 00:19:43 - INFO - __main__ - Global step 300 Train loss 0.34 Classification-F1 0.3810879621848332 on epoch=2
06/17/2022 00:19:45 - INFO - __main__ - Step 310 Global step 310 Train loss 0.27 on epoch=2
06/17/2022 00:19:48 - INFO - __main__ - Step 320 Global step 320 Train loss 0.31 on epoch=2
06/17/2022 00:19:51 - INFO - __main__ - Step 330 Global step 330 Train loss 0.26 on epoch=2
06/17/2022 00:19:53 - INFO - __main__ - Step 340 Global step 340 Train loss 0.34 on epoch=3
06/17/2022 00:19:56 - INFO - __main__ - Step 350 Global step 350 Train loss 0.32 on epoch=3
06/17/2022 00:20:55 - INFO - __main__ - Global step 350 Train loss 0.30 Classification-F1 0.4574582517786267 on epoch=3
06/17/2022 00:20:58 - INFO - __main__ - Step 360 Global step 360 Train loss 0.30 on epoch=3
06/17/2022 00:21:00 - INFO - __main__ - Step 370 Global step 370 Train loss 0.25 on epoch=3
06/17/2022 00:21:03 - INFO - __main__ - Step 380 Global step 380 Train loss 0.24 on epoch=3
06/17/2022 00:21:06 - INFO - __main__ - Step 390 Global step 390 Train loss 0.34 on epoch=3
06/17/2022 00:21:08 - INFO - __main__ - Step 400 Global step 400 Train loss 0.31 on epoch=3
06/17/2022 00:22:04 - INFO - __main__ - Global step 400 Train loss 0.29 Classification-F1 0.5072454804874306 on epoch=3
06/17/2022 00:22:04 - INFO - __main__ - Saving model with best Classification-F1: 0.5029441628094041 -> 0.5072454804874306 on epoch=3, global_step=400
06/17/2022 00:22:07 - INFO - __main__ - Step 410 Global step 410 Train loss 0.29 on epoch=3
06/17/2022 00:22:09 - INFO - __main__ - Step 420 Global step 420 Train loss 0.21 on epoch=3
06/17/2022 00:22:12 - INFO - __main__ - Step 430 Global step 430 Train loss 0.25 on epoch=3
06/17/2022 00:22:15 - INFO - __main__ - Step 440 Global step 440 Train loss 0.25 on epoch=3
06/17/2022 00:22:17 - INFO - __main__ - Step 450 Global step 450 Train loss 0.19 on epoch=4
06/17/2022 00:23:18 - INFO - __main__ - Global step 450 Train loss 0.24 Classification-F1 0.5732383061348507 on epoch=4
06/17/2022 00:23:18 - INFO - __main__ - Saving model with best Classification-F1: 0.5072454804874306 -> 0.5732383061348507 on epoch=4, global_step=450
06/17/2022 00:23:21 - INFO - __main__ - Step 460 Global step 460 Train loss 0.26 on epoch=4
06/17/2022 00:23:24 - INFO - __main__ - Step 470 Global step 470 Train loss 0.23 on epoch=4
06/17/2022 00:23:26 - INFO - __main__ - Step 480 Global step 480 Train loss 0.18 on epoch=4
06/17/2022 00:23:29 - INFO - __main__ - Step 490 Global step 490 Train loss 0.26 on epoch=4
06/17/2022 00:23:31 - INFO - __main__ - Step 500 Global step 500 Train loss 0.22 on epoch=4
06/17/2022 00:24:29 - INFO - __main__ - Global step 500 Train loss 0.23 Classification-F1 0.6565138878575215 on epoch=4
06/17/2022 00:24:30 - INFO - __main__ - Saving model with best Classification-F1: 0.5732383061348507 -> 0.6565138878575215 on epoch=4, global_step=500
06/17/2022 00:24:32 - INFO - __main__ - Step 510 Global step 510 Train loss 0.22 on epoch=4
06/17/2022 00:24:35 - INFO - __main__ - Step 520 Global step 520 Train loss 0.17 on epoch=4
06/17/2022 00:24:38 - INFO - __main__ - Step 530 Global step 530 Train loss 0.16 on epoch=4
06/17/2022 00:24:40 - INFO - __main__ - Step 540 Global step 540 Train loss 0.18 on epoch=4
06/17/2022 00:24:43 - INFO - __main__ - Step 550 Global step 550 Train loss 0.21 on epoch=4
06/17/2022 00:25:44 - INFO - __main__ - Global step 550 Train loss 0.19 Classification-F1 0.8915415449431837 on epoch=4
06/17/2022 00:25:44 - INFO - __main__ - Saving model with best Classification-F1: 0.6565138878575215 -> 0.8915415449431837 on epoch=4, global_step=550
06/17/2022 00:25:47 - INFO - __main__ - Step 560 Global step 560 Train loss 0.12 on epoch=4
06/17/2022 00:25:49 - INFO - __main__ - Step 570 Global step 570 Train loss 0.12 on epoch=5
06/17/2022 00:25:52 - INFO - __main__ - Step 580 Global step 580 Train loss 0.16 on epoch=5
06/17/2022 00:25:55 - INFO - __main__ - Step 590 Global step 590 Train loss 0.21 on epoch=5
06/17/2022 00:25:57 - INFO - __main__ - Step 600 Global step 600 Train loss 0.12 on epoch=5
06/17/2022 00:26:57 - INFO - __main__ - Global step 600 Train loss 0.15 Classification-F1 0.9111938043577215 on epoch=5
06/17/2022 00:26:57 - INFO - __main__ - Saving model with best Classification-F1: 0.8915415449431837 -> 0.9111938043577215 on epoch=5, global_step=600
06/17/2022 00:27:00 - INFO - __main__ - Step 610 Global step 610 Train loss 0.10 on epoch=5
06/17/2022 00:27:03 - INFO - __main__ - Step 620 Global step 620 Train loss 0.20 on epoch=5
06/17/2022 00:27:05 - INFO - __main__ - Step 630 Global step 630 Train loss 0.19 on epoch=5
06/17/2022 00:27:08 - INFO - __main__ - Step 640 Global step 640 Train loss 0.14 on epoch=5
06/17/2022 00:27:11 - INFO - __main__ - Step 650 Global step 650 Train loss 0.15 on epoch=5
06/17/2022 00:28:08 - INFO - __main__ - Global step 650 Train loss 0.15 Classification-F1 0.8039835422418421 on epoch=5
06/17/2022 00:28:11 - INFO - __main__ - Step 660 Global step 660 Train loss 0.21 on epoch=5
06/17/2022 00:28:13 - INFO - __main__ - Step 670 Global step 670 Train loss 0.13 on epoch=5
06/17/2022 00:28:16 - INFO - __main__ - Step 680 Global step 680 Train loss 0.18 on epoch=6
06/17/2022 00:28:19 - INFO - __main__ - Step 690 Global step 690 Train loss 0.18 on epoch=6
06/17/2022 00:28:21 - INFO - __main__ - Step 700 Global step 700 Train loss 0.12 on epoch=6
06/17/2022 00:29:22 - INFO - __main__ - Global step 700 Train loss 0.17 Classification-F1 0.9090825067991108 on epoch=6
06/17/2022 00:29:25 - INFO - __main__ - Step 710 Global step 710 Train loss 0.14 on epoch=6
06/17/2022 00:29:28 - INFO - __main__ - Step 720 Global step 720 Train loss 0.17 on epoch=6
06/17/2022 00:29:30 - INFO - __main__ - Step 730 Global step 730 Train loss 0.09 on epoch=6
06/17/2022 00:29:33 - INFO - __main__ - Step 740 Global step 740 Train loss 0.11 on epoch=6
06/17/2022 00:29:36 - INFO - __main__ - Step 750 Global step 750 Train loss 0.10 on epoch=6
06/17/2022 00:30:31 - INFO - __main__ - Global step 750 Train loss 0.12 Classification-F1 0.7179499397788174 on epoch=6
06/17/2022 00:30:34 - INFO - __main__ - Step 760 Global step 760 Train loss 0.12 on epoch=6
06/17/2022 00:30:36 - INFO - __main__ - Step 770 Global step 770 Train loss 0.11 on epoch=6
06/17/2022 00:30:39 - INFO - __main__ - Step 780 Global step 780 Train loss 0.11 on epoch=6
06/17/2022 00:30:42 - INFO - __main__ - Step 790 Global step 790 Train loss 0.14 on epoch=7
06/17/2022 00:30:44 - INFO - __main__ - Step 800 Global step 800 Train loss 0.17 on epoch=7
06/17/2022 00:31:41 - INFO - __main__ - Global step 800 Train loss 0.13 Classification-F1 0.7603741646110389 on epoch=7
06/17/2022 00:31:44 - INFO - __main__ - Step 810 Global step 810 Train loss 0.08 on epoch=7
06/17/2022 00:31:47 - INFO - __main__ - Step 820 Global step 820 Train loss 0.11 on epoch=7
06/17/2022 00:31:49 - INFO - __main__ - Step 830 Global step 830 Train loss 0.11 on epoch=7
06/17/2022 00:31:52 - INFO - __main__ - Step 840 Global step 840 Train loss 0.07 on epoch=7
06/17/2022 00:31:55 - INFO - __main__ - Step 850 Global step 850 Train loss 0.12 on epoch=7
06/17/2022 00:32:49 - INFO - __main__ - Global step 850 Train loss 0.10 Classification-F1 0.8032402859640948 on epoch=7
06/17/2022 00:32:52 - INFO - __main__ - Step 860 Global step 860 Train loss 0.06 on epoch=7
06/17/2022 00:32:54 - INFO - __main__ - Step 870 Global step 870 Train loss 0.06 on epoch=7
06/17/2022 00:32:57 - INFO - __main__ - Step 880 Global step 880 Train loss 0.13 on epoch=7
06/17/2022 00:33:00 - INFO - __main__ - Step 890 Global step 890 Train loss 0.17 on epoch=7
06/17/2022 00:33:02 - INFO - __main__ - Step 900 Global step 900 Train loss 0.12 on epoch=8
06/17/2022 00:34:00 - INFO - __main__ - Global step 900 Train loss 0.11 Classification-F1 0.904150573344246 on epoch=8
06/17/2022 00:34:02 - INFO - __main__ - Step 910 Global step 910 Train loss 0.19 on epoch=8
06/17/2022 00:34:05 - INFO - __main__ - Step 920 Global step 920 Train loss 0.08 on epoch=8
06/17/2022 00:34:08 - INFO - __main__ - Step 930 Global step 930 Train loss 0.10 on epoch=8
06/17/2022 00:34:10 - INFO - __main__ - Step 940 Global step 940 Train loss 0.12 on epoch=8
06/17/2022 00:34:13 - INFO - __main__ - Step 950 Global step 950 Train loss 0.13 on epoch=8
06/17/2022 00:35:08 - INFO - __main__ - Global step 950 Train loss 0.12 Classification-F1 0.9096078740201888 on epoch=8
06/17/2022 00:35:11 - INFO - __main__ - Step 960 Global step 960 Train loss 0.09 on epoch=8
06/17/2022 00:35:14 - INFO - __main__ - Step 970 Global step 970 Train loss 0.10 on epoch=8
06/17/2022 00:35:16 - INFO - __main__ - Step 980 Global step 980 Train loss 0.03 on epoch=8
06/17/2022 00:35:19 - INFO - __main__ - Step 990 Global step 990 Train loss 0.12 on epoch=8
06/17/2022 00:35:22 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.13 on epoch=8
06/17/2022 00:36:12 - INFO - __main__ - Global step 1000 Train loss 0.10 Classification-F1 0.8581673144514994 on epoch=8
06/17/2022 00:36:15 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.07 on epoch=9
06/17/2022 00:36:18 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.17 on epoch=9
06/17/2022 00:36:20 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.09 on epoch=9
06/17/2022 00:36:23 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.08 on epoch=9
06/17/2022 00:36:26 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.10 on epoch=9
06/17/2022 00:37:18 - INFO - __main__ - Global step 1050 Train loss 0.10 Classification-F1 0.978800558885711 on epoch=9
06/17/2022 00:37:18 - INFO - __main__ - Saving model with best Classification-F1: 0.9111938043577215 -> 0.978800558885711 on epoch=9, global_step=1050
06/17/2022 00:37:21 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.04 on epoch=9
06/17/2022 00:37:24 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.08 on epoch=9
06/17/2022 00:37:26 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.05 on epoch=9
06/17/2022 00:37:29 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.07 on epoch=9
06/17/2022 00:37:31 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.13 on epoch=9
06/17/2022 00:38:23 - INFO - __main__ - Global step 1100 Train loss 0.08 Classification-F1 0.803843488233348 on epoch=9
06/17/2022 00:38:26 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.11 on epoch=9
06/17/2022 00:38:28 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.06 on epoch=9
06/17/2022 00:38:31 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.08 on epoch=10
06/17/2022 00:38:34 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.11 on epoch=10
06/17/2022 00:38:36 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.06 on epoch=10
06/17/2022 00:39:29 - INFO - __main__ - Global step 1150 Train loss 0.09 Classification-F1 0.9149773496351613 on epoch=10
06/17/2022 00:39:31 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.06 on epoch=10
06/17/2022 00:39:34 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.11 on epoch=10
06/17/2022 00:39:37 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.09 on epoch=10
06/17/2022 00:39:39 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.06 on epoch=10
06/17/2022 00:39:42 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.08 on epoch=10
06/17/2022 00:40:33 - INFO - __main__ - Global step 1200 Train loss 0.08 Classification-F1 0.915328588965544 on epoch=10
06/17/2022 00:40:36 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.06 on epoch=10
06/17/2022 00:40:39 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.16 on epoch=10
06/17/2022 00:40:41 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.07 on epoch=10
06/17/2022 00:40:44 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.07 on epoch=11
06/17/2022 00:40:47 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.17 on epoch=11
06/17/2022 00:41:38 - INFO - __main__ - Global step 1250 Train loss 0.11 Classification-F1 0.8571095522312551 on epoch=11
06/17/2022 00:41:41 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.04 on epoch=11
06/17/2022 00:41:43 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.03 on epoch=11
06/17/2022 00:41:46 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.07 on epoch=11
06/17/2022 00:41:49 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.08 on epoch=11
06/17/2022 00:41:51 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.09 on epoch=11
06/17/2022 00:42:42 - INFO - __main__ - Global step 1300 Train loss 0.07 Classification-F1 0.835923777236541 on epoch=11
06/17/2022 00:42:45 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.05 on epoch=11
06/17/2022 00:42:47 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.07 on epoch=11
06/17/2022 00:42:50 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.10 on epoch=11
06/17/2022 00:42:53 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.06 on epoch=11
06/17/2022 00:42:55 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.04 on epoch=12
06/17/2022 00:43:47 - INFO - __main__ - Global step 1350 Train loss 0.06 Classification-F1 0.8456320679274435 on epoch=12
06/17/2022 00:43:50 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.08 on epoch=12
06/17/2022 00:43:53 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.04 on epoch=12
06/17/2022 00:43:55 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.03 on epoch=12
06/17/2022 00:43:58 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.11 on epoch=12
06/17/2022 00:44:01 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.09 on epoch=12
06/17/2022 00:44:53 - INFO - __main__ - Global step 1400 Train loss 0.07 Classification-F1 0.8569754651195152 on epoch=12
06/17/2022 00:44:55 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.08 on epoch=12
06/17/2022 00:44:58 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.03 on epoch=12
06/17/2022 00:45:01 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.03 on epoch=12
06/17/2022 00:45:03 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.09 on epoch=12
06/17/2022 00:45:06 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.09 on epoch=12
06/17/2022 00:45:58 - INFO - __main__ - Global step 1450 Train loss 0.06 Classification-F1 0.9161359559861911 on epoch=12
06/17/2022 00:46:00 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.04 on epoch=13
06/17/2022 00:46:03 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.13 on epoch=13
06/17/2022 00:46:06 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.08 on epoch=13
06/17/2022 00:46:08 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.05 on epoch=13
06/17/2022 00:46:11 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.07 on epoch=13
06/17/2022 00:47:01 - INFO - __main__ - Global step 1500 Train loss 0.08 Classification-F1 0.7603952129884215 on epoch=13
06/17/2022 00:47:04 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.03 on epoch=13
06/17/2022 00:47:06 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.07 on epoch=13
06/17/2022 00:47:09 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.06 on epoch=13
06/17/2022 00:47:11 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.04 on epoch=13
06/17/2022 00:47:14 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.06 on epoch=13
06/17/2022 00:48:05 - INFO - __main__ - Global step 1550 Train loss 0.05 Classification-F1 0.7594188426632498 on epoch=13
06/17/2022 00:48:07 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.05 on epoch=13
06/17/2022 00:48:10 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.03 on epoch=14
06/17/2022 00:48:13 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.12 on epoch=14
06/17/2022 00:48:15 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.04 on epoch=14
06/17/2022 00:48:18 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.04 on epoch=14
06/17/2022 00:49:08 - INFO - __main__ - Global step 1600 Train loss 0.06 Classification-F1 0.8520361958115131 on epoch=14
06/17/2022 00:49:10 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.04 on epoch=14
06/17/2022 00:49:13 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=14
06/17/2022 00:49:16 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.04 on epoch=14
06/17/2022 00:49:18 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.04 on epoch=14
06/17/2022 00:49:21 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.03 on epoch=14
06/17/2022 00:50:13 - INFO - __main__ - Global step 1650 Train loss 0.04 Classification-F1 0.8079342406530453 on epoch=14
06/17/2022 00:50:16 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.09 on epoch=14
06/17/2022 00:50:18 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.04 on epoch=14
06/17/2022 00:50:21 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.03 on epoch=14
06/17/2022 00:50:24 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.05 on epoch=15
06/17/2022 00:50:26 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.05 on epoch=15
06/17/2022 00:51:17 - INFO - __main__ - Global step 1700 Train loss 0.05 Classification-F1 0.8543582198816152 on epoch=15
06/17/2022 00:51:20 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=15
06/17/2022 00:51:23 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.04 on epoch=15
06/17/2022 00:51:25 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.03 on epoch=15
06/17/2022 00:51:28 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.05 on epoch=15
06/17/2022 00:51:31 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.04 on epoch=15
06/17/2022 00:52:22 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.8483459353367201 on epoch=15
06/17/2022 00:52:25 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.05 on epoch=15
06/17/2022 00:52:27 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.14 on epoch=15
06/17/2022 00:52:30 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.11 on epoch=15
06/17/2022 00:52:33 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.06 on epoch=15
06/17/2022 00:52:35 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.07 on epoch=16
06/17/2022 00:53:24 - INFO - __main__ - Global step 1800 Train loss 0.08 Classification-F1 0.7184773836971136 on epoch=16
06/17/2022 00:53:26 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.09 on epoch=16
06/17/2022 00:53:29 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.09 on epoch=16
06/17/2022 00:53:32 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=16
06/17/2022 00:53:34 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.06 on epoch=16
06/17/2022 00:53:37 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=16
06/17/2022 00:54:25 - INFO - __main__ - Global step 1850 Train loss 0.06 Classification-F1 0.5387888071313754 on epoch=16
06/17/2022 00:54:28 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.06 on epoch=16
06/17/2022 00:54:30 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=16
06/17/2022 00:54:33 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.09 on epoch=16
06/17/2022 00:54:36 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.11 on epoch=16
06/17/2022 00:54:38 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.06 on epoch=16
06/17/2022 00:55:29 - INFO - __main__ - Global step 1900 Train loss 0.06 Classification-F1 0.7627427948369863 on epoch=16
06/17/2022 00:55:31 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=17
06/17/2022 00:55:34 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.06 on epoch=17
06/17/2022 00:55:37 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.04 on epoch=17
06/17/2022 00:55:39 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=17
06/17/2022 00:55:42 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.03 on epoch=17
06/17/2022 00:56:32 - INFO - __main__ - Global step 1950 Train loss 0.04 Classification-F1 0.8451907006488022 on epoch=17
06/17/2022 00:56:34 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=17
06/17/2022 00:56:37 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.06 on epoch=17
06/17/2022 00:56:40 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.05 on epoch=17
06/17/2022 00:56:42 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.05 on epoch=17
06/17/2022 00:56:45 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.07 on epoch=17
06/17/2022 00:57:33 - INFO - __main__ - Global step 2000 Train loss 0.05 Classification-F1 0.8419078240501375 on epoch=17
06/17/2022 00:57:36 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=17
06/17/2022 00:57:39 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=18
06/17/2022 00:57:41 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.08 on epoch=18
06/17/2022 00:57:44 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=18
06/17/2022 00:57:47 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.02 on epoch=18
06/17/2022 00:58:35 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.8444759768468011 on epoch=18
06/17/2022 00:58:38 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.07 on epoch=18
06/17/2022 00:58:41 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.03 on epoch=18
06/17/2022 00:58:43 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.08 on epoch=18
06/17/2022 00:58:46 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.06 on epoch=18
06/17/2022 00:58:49 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=18
06/17/2022 00:59:39 - INFO - __main__ - Global step 2100 Train loss 0.05 Classification-F1 0.8520091497952182 on epoch=18
06/17/2022 00:59:42 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.09 on epoch=18
06/17/2022 00:59:44 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=18
06/17/2022 00:59:47 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=19
06/17/2022 00:59:50 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.06 on epoch=19
06/17/2022 00:59:52 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=19
06/17/2022 01:00:42 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.9051922136224351 on epoch=19
06/17/2022 01:00:44 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=19
06/17/2022 01:00:47 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.04 on epoch=19
06/17/2022 01:00:50 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=19
06/17/2022 01:00:52 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.05 on epoch=19
06/17/2022 01:00:55 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=19
06/17/2022 01:01:45 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.845607379491708 on epoch=19
06/17/2022 01:01:47 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=19
06/17/2022 01:01:50 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.08 on epoch=19
06/17/2022 01:01:53 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.04 on epoch=19
06/17/2022 01:01:55 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=19
06/17/2022 01:01:58 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.04 on epoch=20
06/17/2022 01:02:46 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.8463941191517522 on epoch=20
06/17/2022 01:02:49 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.10 on epoch=20
06/17/2022 01:02:52 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.03 on epoch=20
06/17/2022 01:02:54 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.05 on epoch=20
06/17/2022 01:02:57 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.03 on epoch=20
06/17/2022 01:03:00 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=20
06/17/2022 01:03:50 - INFO - __main__ - Global step 2300 Train loss 0.05 Classification-F1 0.7560412474792216 on epoch=20
06/17/2022 01:03:52 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.07 on epoch=20
06/17/2022 01:03:55 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.09 on epoch=20
06/17/2022 01:03:58 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.05 on epoch=20
06/17/2022 01:04:00 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.10 on epoch=20
06/17/2022 01:04:03 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.04 on epoch=20
06/17/2022 01:04:53 - INFO - __main__ - Global step 2350 Train loss 0.07 Classification-F1 0.6922289702620276 on epoch=20
06/17/2022 01:04:55 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.04 on epoch=21
06/17/2022 01:04:58 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.08 on epoch=21
06/17/2022 01:05:01 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.03 on epoch=21
06/17/2022 01:05:03 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=21
06/17/2022 01:05:06 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.05 on epoch=21
06/17/2022 01:05:55 - INFO - __main__ - Global step 2400 Train loss 0.05 Classification-F1 0.7992484153313619 on epoch=21
06/17/2022 01:05:58 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.07 on epoch=21
06/17/2022 01:06:01 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.05 on epoch=21
06/17/2022 01:06:04 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=21
06/17/2022 01:06:06 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.05 on epoch=21
06/17/2022 01:06:09 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.03 on epoch=21
06/17/2022 01:07:03 - INFO - __main__ - Global step 2450 Train loss 0.05 Classification-F1 0.9002068734752753 on epoch=21
06/17/2022 01:07:06 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.02 on epoch=21
06/17/2022 01:07:08 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=22
06/17/2022 01:07:11 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.10 on epoch=22
06/17/2022 01:07:14 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=22
06/17/2022 01:07:16 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=22
06/17/2022 01:08:07 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.8049631917130763 on epoch=22
06/17/2022 01:08:10 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.03 on epoch=22
06/17/2022 01:08:12 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=22
06/17/2022 01:08:15 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=22
06/17/2022 01:08:18 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.06 on epoch=22
06/17/2022 01:08:20 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=22
06/17/2022 01:09:09 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.8449488461632335 on epoch=22
06/17/2022 01:09:12 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.05 on epoch=22
06/17/2022 01:09:14 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=22
06/17/2022 01:09:17 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=23
06/17/2022 01:09:20 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.13 on epoch=23
06/17/2022 01:09:22 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=23
06/17/2022 01:10:10 - INFO - __main__ - Global step 2600 Train loss 0.05 Classification-F1 0.7940542061162427 on epoch=23
06/17/2022 01:10:12 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=23
06/17/2022 01:10:15 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.04 on epoch=23
06/17/2022 01:10:17 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=23
06/17/2022 01:10:20 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.04 on epoch=23
06/17/2022 01:10:23 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.03 on epoch=23
06/17/2022 01:11:09 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.9039985892535193 on epoch=23
06/17/2022 01:11:12 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=23
06/17/2022 01:11:15 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.06 on epoch=23
06/17/2022 01:11:17 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=23
06/17/2022 01:11:20 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=24
06/17/2022 01:11:22 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.13 on epoch=24
06/17/2022 01:12:09 - INFO - __main__ - Global step 2700 Train loss 0.05 Classification-F1 0.8333605467689416 on epoch=24
06/17/2022 01:12:12 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.03 on epoch=24
06/17/2022 01:12:14 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=24
06/17/2022 01:12:17 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=24
06/17/2022 01:12:20 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=24
06/17/2022 01:12:22 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.03 on epoch=24
06/17/2022 01:13:09 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.8287342135211846 on epoch=24
06/17/2022 01:13:12 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.03 on epoch=24
06/17/2022 01:13:15 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=24
06/17/2022 01:13:17 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.06 on epoch=24
06/17/2022 01:13:20 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.05 on epoch=24
06/17/2022 01:13:22 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=24
06/17/2022 01:14:09 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.7848084893603002 on epoch=24
06/17/2022 01:14:12 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.05 on epoch=25
06/17/2022 01:14:14 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.06 on epoch=25
06/17/2022 01:14:17 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=25
06/17/2022 01:14:20 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.03 on epoch=25
06/17/2022 01:14:22 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=25
06/17/2022 01:15:09 - INFO - __main__ - Global step 2850 Train loss 0.04 Classification-F1 0.8335686068287018 on epoch=25
06/17/2022 01:15:11 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=25
06/17/2022 01:15:14 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=25
06/17/2022 01:15:17 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.06 on epoch=25
06/17/2022 01:15:19 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.07 on epoch=25
06/17/2022 01:15:22 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=25
06/17/2022 01:16:10 - INFO - __main__ - Global step 2900 Train loss 0.04 Classification-F1 0.7361404299327478 on epoch=25
06/17/2022 01:16:13 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=25
06/17/2022 01:16:15 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=26
06/17/2022 01:16:18 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.07 on epoch=26
06/17/2022 01:16:20 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.04 on epoch=26
06/17/2022 01:16:23 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=26
06/17/2022 01:17:09 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.7068393001292227 on epoch=26
06/17/2022 01:17:12 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.03 on epoch=26
06/17/2022 01:17:14 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=26
06/17/2022 01:17:17 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.03 on epoch=26
06/17/2022 01:17:20 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=26
06/17/2022 01:17:22 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.06 on epoch=26
06/17/2022 01:17:24 - INFO - __main__ - Start tokenizing ... 1792 instances
06/17/2022 01:17:24 - INFO - __main__ - Printing 3 examples
06/17/2022 01:17:24 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/17/2022 01:17:24 - INFO - __main__ - ['Company']
06/17/2022 01:17:24 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/17/2022 01:17:24 - INFO - __main__ - ['Company']
06/17/2022 01:17:24 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/17/2022 01:17:24 - INFO - __main__ - ['Company']
06/17/2022 01:17:24 - INFO - __main__ - Tokenizing Input ...
06/17/2022 01:17:25 - INFO - __main__ - Tokenizing Output ...
06/17/2022 01:17:26 - INFO - __main__ - Loaded 1792 examples from train data
06/17/2022 01:17:26 - INFO - __main__ - Start tokenizing ... 1792 instances
06/17/2022 01:17:26 - INFO - __main__ - Printing 3 examples
06/17/2022 01:17:26 - INFO - __main__ -  [dbpedia_14] The Aya Group of Companies commonly referred to as the Aya Group is a business conglomerate based in Uganda.
06/17/2022 01:17:26 - INFO - __main__ - ['Company']
06/17/2022 01:17:26 - INFO - __main__ -  [dbpedia_14] Casengo (founded in 2011) is a Dutch company that provides customer service tools for website and webshop owners available as a SaaS. The Amsterdam-based company was founded by Floris and Thijs van der Veen. Both brothers started off with software named Livecom used mainly by large companies such as Philips and DSM. When they decided to develop customer service software for small businesses Casengo was born.
06/17/2022 01:17:26 - INFO - __main__ - ['Company']
06/17/2022 01:17:26 - INFO - __main__ -  [dbpedia_14] KeySpan Corporation now part of National Grid USA was the fifth largest distributor of natural gas in the United States. KeySpan was formed in 1998 as result of the merger of Brooklyn Union Gas Company (founded 1895 by merging several smaller companies) and Long Island Lighting Company (LILCO).
06/17/2022 01:17:26 - INFO - __main__ - ['Company']
06/17/2022 01:17:26 - INFO - __main__ - Tokenizing Input ...
06/17/2022 01:17:27 - INFO - __main__ - Tokenizing Output ...
06/17/2022 01:17:29 - INFO - __main__ - Loaded 1792 examples from dev data
06/17/2022 01:17:45 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 01:17:46 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/17/2022 01:17:46 - INFO - __main__ - Starting training!
06/17/2022 01:18:09 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.6279472713830427 on epoch=26
06/17/2022 01:18:09 - INFO - __main__ - save last model!
06/17/2022 01:18:09 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/17/2022 01:18:09 - INFO - __main__ - Start tokenizing ... 3500 instances
06/17/2022 01:18:09 - INFO - __main__ - Printing 3 examples
06/17/2022 01:18:09 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/17/2022 01:18:09 - INFO - __main__ - ['Animal']
06/17/2022 01:18:09 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/17/2022 01:18:09 - INFO - __main__ - ['Animal']
06/17/2022 01:18:09 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/17/2022 01:18:09 - INFO - __main__ - ['Village']
06/17/2022 01:18:09 - INFO - __main__ - Tokenizing Input ...
06/17/2022 01:18:11 - INFO - __main__ - Tokenizing Output ...
06/17/2022 01:18:15 - INFO - __main__ - Loaded 3500 examples from test data
06/17/2022 01:20:18 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down128shot/singletask-dbpedia_14/dbpedia_14_128_42_0.3_8_predictions.txt
06/17/2022 01:20:18 - INFO - __main__ - Classification-F1 on test data: 0.4899
06/17/2022 01:20:18 - INFO - __main__ - prefix=dbpedia_14_128_42, lr=0.3, bsz=8, dev_performance=0.978800558885711, test_performance=0.489855845758573
06/17/2022 01:20:18 - INFO - __main__ - Running ... prefix=dbpedia_14_128_42, lr=0.2, bsz=8 ...
06/17/2022 01:20:19 - INFO - __main__ - Start tokenizing ... 1792 instances
06/17/2022 01:20:19 - INFO - __main__ - Printing 3 examples
06/17/2022 01:20:19 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/17/2022 01:20:19 - INFO - __main__ - ['Company']
06/17/2022 01:20:19 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/17/2022 01:20:19 - INFO - __main__ - ['Company']
06/17/2022 01:20:19 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/17/2022 01:20:19 - INFO - __main__ - ['Company']
06/17/2022 01:20:19 - INFO - __main__ - Tokenizing Input ...
06/17/2022 01:20:20 - INFO - __main__ - Tokenizing Output ...
06/17/2022 01:20:22 - INFO - __main__ - Loaded 1792 examples from train data
06/17/2022 01:20:22 - INFO - __main__ - Start tokenizing ... 1792 instances
06/17/2022 01:20:22 - INFO - __main__ - Printing 3 examples
06/17/2022 01:20:22 - INFO - __main__ -  [dbpedia_14] The Aya Group of Companies commonly referred to as the Aya Group is a business conglomerate based in Uganda.
06/17/2022 01:20:22 - INFO - __main__ - ['Company']
06/17/2022 01:20:22 - INFO - __main__ -  [dbpedia_14] Casengo (founded in 2011) is a Dutch company that provides customer service tools for website and webshop owners available as a SaaS. The Amsterdam-based company was founded by Floris and Thijs van der Veen. Both brothers started off with software named Livecom used mainly by large companies such as Philips and DSM. When they decided to develop customer service software for small businesses Casengo was born.
06/17/2022 01:20:22 - INFO - __main__ - ['Company']
06/17/2022 01:20:22 - INFO - __main__ -  [dbpedia_14] KeySpan Corporation now part of National Grid USA was the fifth largest distributor of natural gas in the United States. KeySpan was formed in 1998 as result of the merger of Brooklyn Union Gas Company (founded 1895 by merging several smaller companies) and Long Island Lighting Company (LILCO).
06/17/2022 01:20:22 - INFO - __main__ - ['Company']
06/17/2022 01:20:22 - INFO - __main__ - Tokenizing Input ...
06/17/2022 01:20:23 - INFO - __main__ - Tokenizing Output ...
06/17/2022 01:20:25 - INFO - __main__ - Loaded 1792 examples from dev data
06/17/2022 01:20:43 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 01:20:44 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/17/2022 01:20:44 - INFO - __main__ - Starting training!
06/17/2022 01:20:48 - INFO - __main__ - Step 10 Global step 10 Train loss 5.33 on epoch=0
06/17/2022 01:20:50 - INFO - __main__ - Step 20 Global step 20 Train loss 3.82 on epoch=0
06/17/2022 01:20:53 - INFO - __main__ - Step 30 Global step 30 Train loss 3.11 on epoch=0
06/17/2022 01:20:55 - INFO - __main__ - Step 40 Global step 40 Train loss 2.63 on epoch=0
06/17/2022 01:20:58 - INFO - __main__ - Step 50 Global step 50 Train loss 2.19 on epoch=0
06/17/2022 01:21:42 - INFO - __main__ - Global step 50 Train loss 3.41 Classification-F1 0.03518301883595265 on epoch=0
06/17/2022 01:21:42 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.03518301883595265 on epoch=0, global_step=50
06/17/2022 01:21:45 - INFO - __main__ - Step 60 Global step 60 Train loss 1.75 on epoch=0
06/17/2022 01:21:47 - INFO - __main__ - Step 70 Global step 70 Train loss 1.51 on epoch=0
06/17/2022 01:21:50 - INFO - __main__ - Step 80 Global step 80 Train loss 1.22 on epoch=0
06/17/2022 01:21:52 - INFO - __main__ - Step 90 Global step 90 Train loss 1.14 on epoch=0
06/17/2022 01:21:55 - INFO - __main__ - Step 100 Global step 100 Train loss 1.10 on epoch=0
06/17/2022 01:22:44 - INFO - __main__ - Global step 100 Train loss 1.34 Classification-F1 0.31161868602845316 on epoch=0
06/17/2022 01:22:44 - INFO - __main__ - Saving model with best Classification-F1: 0.03518301883595265 -> 0.31161868602845316 on epoch=0, global_step=100
06/17/2022 01:22:47 - INFO - __main__ - Step 110 Global step 110 Train loss 0.96 on epoch=0
06/17/2022 01:22:49 - INFO - __main__ - Step 120 Global step 120 Train loss 0.86 on epoch=1
06/17/2022 01:22:52 - INFO - __main__ - Step 130 Global step 130 Train loss 0.84 on epoch=1
06/17/2022 01:22:55 - INFO - __main__ - Step 140 Global step 140 Train loss 0.80 on epoch=1
06/17/2022 01:22:57 - INFO - __main__ - Step 150 Global step 150 Train loss 0.71 on epoch=1
06/17/2022 01:23:55 - INFO - __main__ - Global step 150 Train loss 0.83 Classification-F1 0.2928376858829244 on epoch=1
06/17/2022 01:23:57 - INFO - __main__ - Step 160 Global step 160 Train loss 0.75 on epoch=1
06/17/2022 01:24:00 - INFO - __main__ - Step 170 Global step 170 Train loss 0.77 on epoch=1
06/17/2022 01:24:02 - INFO - __main__ - Step 180 Global step 180 Train loss 0.62 on epoch=1
06/17/2022 01:24:05 - INFO - __main__ - Step 190 Global step 190 Train loss 0.58 on epoch=1
06/17/2022 01:24:07 - INFO - __main__ - Step 200 Global step 200 Train loss 0.55 on epoch=1
06/17/2022 01:25:02 - INFO - __main__ - Global step 200 Train loss 0.65 Classification-F1 0.48765064145995135 on epoch=1
06/17/2022 01:25:02 - INFO - __main__ - Saving model with best Classification-F1: 0.31161868602845316 -> 0.48765064145995135 on epoch=1, global_step=200
06/17/2022 01:25:05 - INFO - __main__ - Step 210 Global step 210 Train loss 0.65 on epoch=1
06/17/2022 01:25:07 - INFO - __main__ - Step 220 Global step 220 Train loss 0.55 on epoch=1
06/17/2022 01:25:10 - INFO - __main__ - Step 230 Global step 230 Train loss 0.62 on epoch=2
06/17/2022 01:25:12 - INFO - __main__ - Step 240 Global step 240 Train loss 0.48 on epoch=2
06/17/2022 01:25:15 - INFO - __main__ - Step 250 Global step 250 Train loss 0.40 on epoch=2
06/17/2022 01:26:07 - INFO - __main__ - Global step 250 Train loss 0.54 Classification-F1 0.38047343411069934 on epoch=2
06/17/2022 01:26:10 - INFO - __main__ - Step 260 Global step 260 Train loss 0.50 on epoch=2
06/17/2022 01:26:12 - INFO - __main__ - Step 270 Global step 270 Train loss 0.50 on epoch=2
06/17/2022 01:26:15 - INFO - __main__ - Step 280 Global step 280 Train loss 0.48 on epoch=2
06/17/2022 01:26:17 - INFO - __main__ - Step 290 Global step 290 Train loss 0.39 on epoch=2
06/17/2022 01:26:20 - INFO - __main__ - Step 300 Global step 300 Train loss 0.35 on epoch=2
06/17/2022 01:27:13 - INFO - __main__ - Global step 300 Train loss 0.44 Classification-F1 0.4371376104926765 on epoch=2
06/17/2022 01:27:15 - INFO - __main__ - Step 310 Global step 310 Train loss 0.41 on epoch=2
06/17/2022 01:27:18 - INFO - __main__ - Step 320 Global step 320 Train loss 0.41 on epoch=2
06/17/2022 01:27:21 - INFO - __main__ - Step 330 Global step 330 Train loss 0.41 on epoch=2
06/17/2022 01:27:23 - INFO - __main__ - Step 340 Global step 340 Train loss 0.38 on epoch=3
06/17/2022 01:27:26 - INFO - __main__ - Step 350 Global step 350 Train loss 0.38 on epoch=3
06/17/2022 01:28:19 - INFO - __main__ - Global step 350 Train loss 0.40 Classification-F1 0.4179806456579411 on epoch=3
06/17/2022 01:28:22 - INFO - __main__ - Step 360 Global step 360 Train loss 0.29 on epoch=3
06/17/2022 01:28:24 - INFO - __main__ - Step 370 Global step 370 Train loss 0.25 on epoch=3
06/17/2022 01:28:27 - INFO - __main__ - Step 380 Global step 380 Train loss 0.37 on epoch=3
06/17/2022 01:28:29 - INFO - __main__ - Step 390 Global step 390 Train loss 0.35 on epoch=3
06/17/2022 01:28:32 - INFO - __main__ - Step 400 Global step 400 Train loss 0.27 on epoch=3
06/17/2022 01:29:26 - INFO - __main__ - Global step 400 Train loss 0.31 Classification-F1 0.42683140128327635 on epoch=3
06/17/2022 01:29:28 - INFO - __main__ - Step 410 Global step 410 Train loss 0.27 on epoch=3
06/17/2022 01:29:31 - INFO - __main__ - Step 420 Global step 420 Train loss 0.34 on epoch=3
06/17/2022 01:29:33 - INFO - __main__ - Step 430 Global step 430 Train loss 0.35 on epoch=3
06/17/2022 01:29:36 - INFO - __main__ - Step 440 Global step 440 Train loss 0.29 on epoch=3
06/17/2022 01:29:39 - INFO - __main__ - Step 450 Global step 450 Train loss 0.29 on epoch=4
06/17/2022 01:30:36 - INFO - __main__ - Global step 450 Train loss 0.31 Classification-F1 0.4832659478422695 on epoch=4
06/17/2022 01:30:39 - INFO - __main__ - Step 460 Global step 460 Train loss 0.35 on epoch=4
06/17/2022 01:30:41 - INFO - __main__ - Step 470 Global step 470 Train loss 0.32 on epoch=4
06/17/2022 01:30:44 - INFO - __main__ - Step 480 Global step 480 Train loss 0.25 on epoch=4
06/17/2022 01:30:46 - INFO - __main__ - Step 490 Global step 490 Train loss 0.27 on epoch=4
06/17/2022 01:30:49 - INFO - __main__ - Step 500 Global step 500 Train loss 0.26 on epoch=4
06/17/2022 01:31:47 - INFO - __main__ - Global step 500 Train loss 0.29 Classification-F1 0.5843207617557097 on epoch=4
06/17/2022 01:31:47 - INFO - __main__ - Saving model with best Classification-F1: 0.48765064145995135 -> 0.5843207617557097 on epoch=4, global_step=500
06/17/2022 01:31:49 - INFO - __main__ - Step 510 Global step 510 Train loss 0.29 on epoch=4
06/17/2022 01:31:52 - INFO - __main__ - Step 520 Global step 520 Train loss 0.20 on epoch=4
06/17/2022 01:31:54 - INFO - __main__ - Step 530 Global step 530 Train loss 0.17 on epoch=4
06/17/2022 01:31:57 - INFO - __main__ - Step 540 Global step 540 Train loss 0.25 on epoch=4
06/17/2022 01:31:59 - INFO - __main__ - Step 550 Global step 550 Train loss 0.27 on epoch=4
06/17/2022 01:32:56 - INFO - __main__ - Global step 550 Train loss 0.24 Classification-F1 0.6401757286916626 on epoch=4
06/17/2022 01:32:56 - INFO - __main__ - Saving model with best Classification-F1: 0.5843207617557097 -> 0.6401757286916626 on epoch=4, global_step=550
06/17/2022 01:32:59 - INFO - __main__ - Step 560 Global step 560 Train loss 0.19 on epoch=4
06/17/2022 01:33:01 - INFO - __main__ - Step 570 Global step 570 Train loss 0.23 on epoch=5
06/17/2022 01:33:04 - INFO - __main__ - Step 580 Global step 580 Train loss 0.27 on epoch=5
06/17/2022 01:33:06 - INFO - __main__ - Step 590 Global step 590 Train loss 0.22 on epoch=5
06/17/2022 01:33:09 - INFO - __main__ - Step 600 Global step 600 Train loss 0.20 on epoch=5
06/17/2022 01:34:05 - INFO - __main__ - Global step 600 Train loss 0.22 Classification-F1 0.547674324621661 on epoch=5
06/17/2022 01:34:08 - INFO - __main__ - Step 610 Global step 610 Train loss 0.20 on epoch=5
06/17/2022 01:34:11 - INFO - __main__ - Step 620 Global step 620 Train loss 0.27 on epoch=5
06/17/2022 01:34:13 - INFO - __main__ - Step 630 Global step 630 Train loss 0.18 on epoch=5
06/17/2022 01:34:16 - INFO - __main__ - Step 640 Global step 640 Train loss 0.15 on epoch=5
06/17/2022 01:34:18 - INFO - __main__ - Step 650 Global step 650 Train loss 0.27 on epoch=5
06/17/2022 01:35:15 - INFO - __main__ - Global step 650 Train loss 0.21 Classification-F1 0.5885689942452217 on epoch=5
06/17/2022 01:35:17 - INFO - __main__ - Step 660 Global step 660 Train loss 0.26 on epoch=5
06/17/2022 01:35:20 - INFO - __main__ - Step 670 Global step 670 Train loss 0.22 on epoch=5
06/17/2022 01:35:23 - INFO - __main__ - Step 680 Global step 680 Train loss 0.26 on epoch=6
06/17/2022 01:35:25 - INFO - __main__ - Step 690 Global step 690 Train loss 0.21 on epoch=6
06/17/2022 01:35:28 - INFO - __main__ - Step 700 Global step 700 Train loss 0.24 on epoch=6
06/17/2022 01:36:27 - INFO - __main__ - Global step 700 Train loss 0.24 Classification-F1 0.6261327104332168 on epoch=6
06/17/2022 01:36:30 - INFO - __main__ - Step 710 Global step 710 Train loss 0.19 on epoch=6
06/17/2022 01:36:33 - INFO - __main__ - Step 720 Global step 720 Train loss 0.20 on epoch=6
06/17/2022 01:36:35 - INFO - __main__ - Step 730 Global step 730 Train loss 0.15 on epoch=6
06/17/2022 01:36:38 - INFO - __main__ - Step 740 Global step 740 Train loss 0.22 on epoch=6
06/17/2022 01:36:41 - INFO - __main__ - Step 750 Global step 750 Train loss 0.09 on epoch=6
06/17/2022 01:37:37 - INFO - __main__ - Global step 750 Train loss 0.17 Classification-F1 0.43742369253125307 on epoch=6
06/17/2022 01:37:40 - INFO - __main__ - Step 760 Global step 760 Train loss 0.25 on epoch=6
06/17/2022 01:37:42 - INFO - __main__ - Step 770 Global step 770 Train loss 0.23 on epoch=6
06/17/2022 01:37:45 - INFO - __main__ - Step 780 Global step 780 Train loss 0.15 on epoch=6
06/17/2022 01:37:47 - INFO - __main__ - Step 790 Global step 790 Train loss 0.19 on epoch=7
06/17/2022 01:37:50 - INFO - __main__ - Step 800 Global step 800 Train loss 0.21 on epoch=7
06/17/2022 01:38:53 - INFO - __main__ - Global step 800 Train loss 0.20 Classification-F1 0.5217531234999033 on epoch=7
06/17/2022 01:38:55 - INFO - __main__ - Step 810 Global step 810 Train loss 0.14 on epoch=7
06/17/2022 01:38:58 - INFO - __main__ - Step 820 Global step 820 Train loss 0.14 on epoch=7
06/17/2022 01:39:00 - INFO - __main__ - Step 830 Global step 830 Train loss 0.17 on epoch=7
06/17/2022 01:39:03 - INFO - __main__ - Step 840 Global step 840 Train loss 0.14 on epoch=7
06/17/2022 01:39:05 - INFO - __main__ - Step 850 Global step 850 Train loss 0.17 on epoch=7
06/17/2022 01:40:07 - INFO - __main__ - Global step 850 Train loss 0.15 Classification-F1 0.5059764032567864 on epoch=7
06/17/2022 01:40:09 - INFO - __main__ - Step 860 Global step 860 Train loss 0.16 on epoch=7
06/17/2022 01:40:12 - INFO - __main__ - Step 870 Global step 870 Train loss 0.09 on epoch=7
06/17/2022 01:40:15 - INFO - __main__ - Step 880 Global step 880 Train loss 0.23 on epoch=7
06/17/2022 01:40:17 - INFO - __main__ - Step 890 Global step 890 Train loss 0.15 on epoch=7
06/17/2022 01:40:20 - INFO - __main__ - Step 900 Global step 900 Train loss 0.21 on epoch=8
06/17/2022 01:41:17 - INFO - __main__ - Global step 900 Train loss 0.17 Classification-F1 0.588110050872054 on epoch=8
06/17/2022 01:41:20 - INFO - __main__ - Step 910 Global step 910 Train loss 0.15 on epoch=8
06/17/2022 01:41:23 - INFO - __main__ - Step 920 Global step 920 Train loss 0.18 on epoch=8
06/17/2022 01:41:25 - INFO - __main__ - Step 930 Global step 930 Train loss 0.11 on epoch=8
06/17/2022 01:41:28 - INFO - __main__ - Step 940 Global step 940 Train loss 0.17 on epoch=8
06/17/2022 01:41:30 - INFO - __main__ - Step 950 Global step 950 Train loss 0.11 on epoch=8
06/17/2022 01:42:26 - INFO - __main__ - Global step 950 Train loss 0.14 Classification-F1 0.7497438361146359 on epoch=8
06/17/2022 01:42:26 - INFO - __main__ - Saving model with best Classification-F1: 0.6401757286916626 -> 0.7497438361146359 on epoch=8, global_step=950
06/17/2022 01:42:28 - INFO - __main__ - Step 960 Global step 960 Train loss 0.13 on epoch=8
06/17/2022 01:42:31 - INFO - __main__ - Step 970 Global step 970 Train loss 0.10 on epoch=8
06/17/2022 01:42:34 - INFO - __main__ - Step 980 Global step 980 Train loss 0.17 on epoch=8
06/17/2022 01:42:36 - INFO - __main__ - Step 990 Global step 990 Train loss 0.19 on epoch=8
06/17/2022 01:42:39 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.13 on epoch=8
06/17/2022 01:43:36 - INFO - __main__ - Global step 1000 Train loss 0.14 Classification-F1 0.7425945732010952 on epoch=8
06/17/2022 01:43:38 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.07 on epoch=9
06/17/2022 01:43:41 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.14 on epoch=9
06/17/2022 01:43:44 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.13 on epoch=9
06/17/2022 01:43:46 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.08 on epoch=9
06/17/2022 01:43:49 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.12 on epoch=9
06/17/2022 01:44:45 - INFO - __main__ - Global step 1050 Train loss 0.11 Classification-F1 0.6446198465066916 on epoch=9
06/17/2022 01:44:48 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.14 on epoch=9
06/17/2022 01:44:50 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.11 on epoch=9
06/17/2022 01:44:53 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.13 on epoch=9
06/17/2022 01:44:56 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.08 on epoch=9
06/17/2022 01:44:58 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.12 on epoch=9
06/17/2022 01:45:58 - INFO - __main__ - Global step 1100 Train loss 0.11 Classification-F1 0.7370612636095549 on epoch=9
06/17/2022 01:46:01 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.13 on epoch=9
06/17/2022 01:46:03 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.08 on epoch=9
06/17/2022 01:46:06 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.12 on epoch=10
06/17/2022 01:46:08 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.12 on epoch=10
06/17/2022 01:46:11 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.10 on epoch=10
06/17/2022 01:47:09 - INFO - __main__ - Global step 1150 Train loss 0.11 Classification-F1 0.7805162810711009 on epoch=10
06/17/2022 01:47:09 - INFO - __main__ - Saving model with best Classification-F1: 0.7497438361146359 -> 0.7805162810711009 on epoch=10, global_step=1150
06/17/2022 01:47:12 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.05 on epoch=10
06/17/2022 01:47:14 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.16 on epoch=10
06/17/2022 01:47:17 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.08 on epoch=10
06/17/2022 01:47:19 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.12 on epoch=10
06/17/2022 01:47:22 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.12 on epoch=10
06/17/2022 01:48:16 - INFO - __main__ - Global step 1200 Train loss 0.11 Classification-F1 0.5759327629485941 on epoch=10
06/17/2022 01:48:18 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.10 on epoch=10
06/17/2022 01:48:21 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.14 on epoch=10
06/17/2022 01:48:23 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.08 on epoch=10
06/17/2022 01:48:26 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.09 on epoch=11
06/17/2022 01:48:29 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.24 on epoch=11
06/17/2022 01:49:22 - INFO - __main__ - Global step 1250 Train loss 0.13 Classification-F1 0.6677485654279877 on epoch=11
06/17/2022 01:49:25 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.14 on epoch=11
06/17/2022 01:49:27 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.12 on epoch=11
06/17/2022 01:49:30 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.10 on epoch=11
06/17/2022 01:49:32 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.12 on epoch=11
06/17/2022 01:49:35 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.12 on epoch=11
06/17/2022 01:50:31 - INFO - __main__ - Global step 1300 Train loss 0.12 Classification-F1 0.6659133897141372 on epoch=11
06/17/2022 01:50:34 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.04 on epoch=11
06/17/2022 01:50:37 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.11 on epoch=11
06/17/2022 01:50:39 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.14 on epoch=11
06/17/2022 01:50:42 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.09 on epoch=11
06/17/2022 01:50:44 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.07 on epoch=12
06/17/2022 01:51:44 - INFO - __main__ - Global step 1350 Train loss 0.09 Classification-F1 0.8513300373008016 on epoch=12
06/17/2022 01:51:44 - INFO - __main__ - Saving model with best Classification-F1: 0.7805162810711009 -> 0.8513300373008016 on epoch=12, global_step=1350
06/17/2022 01:51:47 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.24 on epoch=12
06/17/2022 01:51:49 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.10 on epoch=12
06/17/2022 01:51:52 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.08 on epoch=12
06/17/2022 01:51:55 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.17 on epoch=12
06/17/2022 01:51:57 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.10 on epoch=12
06/17/2022 01:52:55 - INFO - __main__ - Global step 1400 Train loss 0.14 Classification-F1 0.8516346681566993 on epoch=12
06/17/2022 01:52:55 - INFO - __main__ - Saving model with best Classification-F1: 0.8513300373008016 -> 0.8516346681566993 on epoch=12, global_step=1400
06/17/2022 01:52:57 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.09 on epoch=12
06/17/2022 01:53:00 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.12 on epoch=12
06/17/2022 01:53:03 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.08 on epoch=12
06/17/2022 01:53:05 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.15 on epoch=12
06/17/2022 01:53:08 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.11 on epoch=12
06/17/2022 01:54:06 - INFO - __main__ - Global step 1450 Train loss 0.11 Classification-F1 0.7516168970197348 on epoch=12
06/17/2022 01:54:09 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.08 on epoch=13
06/17/2022 01:54:12 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.17 on epoch=13
06/17/2022 01:54:14 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.08 on epoch=13
06/17/2022 01:54:17 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.09 on epoch=13
06/17/2022 01:54:19 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.07 on epoch=13
06/17/2022 01:55:18 - INFO - __main__ - Global step 1500 Train loss 0.10 Classification-F1 0.7991344143563928 on epoch=13
06/17/2022 01:55:20 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.06 on epoch=13
06/17/2022 01:55:23 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.08 on epoch=13
06/17/2022 01:55:26 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.07 on epoch=13
06/17/2022 01:55:28 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.05 on epoch=13
06/17/2022 01:55:31 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.11 on epoch=13
06/17/2022 01:56:28 - INFO - __main__ - Global step 1550 Train loss 0.07 Classification-F1 0.84549846344274 on epoch=13
06/17/2022 01:56:31 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.06 on epoch=13
06/17/2022 01:56:34 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.06 on epoch=14
06/17/2022 01:56:36 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.13 on epoch=14
06/17/2022 01:56:39 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.11 on epoch=14
06/17/2022 01:56:41 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.09 on epoch=14
06/17/2022 01:57:40 - INFO - __main__ - Global step 1600 Train loss 0.09 Classification-F1 0.7500524729092046 on epoch=14
06/17/2022 01:57:43 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.10 on epoch=14
06/17/2022 01:57:45 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.06 on epoch=14
06/17/2022 01:57:48 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.08 on epoch=14
06/17/2022 01:57:51 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.10 on epoch=14
06/17/2022 01:57:53 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.09 on epoch=14
06/17/2022 01:58:56 - INFO - __main__ - Global step 1650 Train loss 0.09 Classification-F1 0.7024375253998961 on epoch=14
06/17/2022 01:58:59 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.14 on epoch=14
06/17/2022 01:59:02 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.18 on epoch=14
06/17/2022 01:59:04 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.04 on epoch=14
06/17/2022 01:59:07 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.06 on epoch=15
06/17/2022 01:59:09 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.18 on epoch=15
06/17/2022 02:00:06 - INFO - __main__ - Global step 1700 Train loss 0.12 Classification-F1 0.8030813991099522 on epoch=15
06/17/2022 02:00:08 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.08 on epoch=15
06/17/2022 02:00:11 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.07 on epoch=15
06/17/2022 02:00:13 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.10 on epoch=15
06/17/2022 02:00:16 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.08 on epoch=15
06/17/2022 02:00:19 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.04 on epoch=15
06/17/2022 02:01:13 - INFO - __main__ - Global step 1750 Train loss 0.07 Classification-F1 0.750037797867011 on epoch=15
06/17/2022 02:01:16 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.05 on epoch=15
06/17/2022 02:01:18 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.11 on epoch=15
06/17/2022 02:01:21 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.07 on epoch=15
06/17/2022 02:01:24 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.04 on epoch=15
06/17/2022 02:01:26 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.06 on epoch=16
06/17/2022 02:02:24 - INFO - __main__ - Global step 1800 Train loss 0.07 Classification-F1 0.6983790624859872 on epoch=16
06/17/2022 02:02:27 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.06 on epoch=16
06/17/2022 02:02:29 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.04 on epoch=16
06/17/2022 02:02:32 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.05 on epoch=16
06/17/2022 02:02:34 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.05 on epoch=16
06/17/2022 02:02:37 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.06 on epoch=16
06/17/2022 02:03:36 - INFO - __main__ - Global step 1850 Train loss 0.05 Classification-F1 0.7961838736514975 on epoch=16
06/17/2022 02:03:39 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.12 on epoch=16
06/17/2022 02:03:42 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.07 on epoch=16
06/17/2022 02:03:44 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.09 on epoch=16
06/17/2022 02:03:47 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.08 on epoch=16
06/17/2022 02:03:49 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.06 on epoch=16
06/17/2022 02:04:48 - INFO - __main__ - Global step 1900 Train loss 0.09 Classification-F1 0.7949540356534123 on epoch=16
06/17/2022 02:04:51 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.05 on epoch=17
06/17/2022 02:04:54 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.10 on epoch=17
06/17/2022 02:04:56 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.08 on epoch=17
06/17/2022 02:04:59 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=17
06/17/2022 02:05:01 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.07 on epoch=17
06/17/2022 02:05:55 - INFO - __main__ - Global step 1950 Train loss 0.07 Classification-F1 0.7853748232540684 on epoch=17
06/17/2022 02:05:58 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.07 on epoch=17
06/17/2022 02:06:00 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.05 on epoch=17
06/17/2022 02:06:03 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.05 on epoch=17
06/17/2022 02:06:05 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.08 on epoch=17
06/17/2022 02:06:08 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.10 on epoch=17
06/17/2022 02:07:04 - INFO - __main__ - Global step 2000 Train loss 0.07 Classification-F1 0.8457062262849095 on epoch=17
06/17/2022 02:07:06 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.11 on epoch=17
06/17/2022 02:07:09 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.05 on epoch=18
06/17/2022 02:07:12 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.14 on epoch=18
06/17/2022 02:07:14 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=18
06/17/2022 02:07:17 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.03 on epoch=18
06/17/2022 02:08:13 - INFO - __main__ - Global step 2050 Train loss 0.07 Classification-F1 0.8325885860530045 on epoch=18
06/17/2022 02:08:15 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.09 on epoch=18
06/17/2022 02:08:18 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.10 on epoch=18
06/17/2022 02:08:20 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.07 on epoch=18
06/17/2022 02:08:23 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=18
06/17/2022 02:08:26 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.06 on epoch=18
06/17/2022 02:09:17 - INFO - __main__ - Global step 2100 Train loss 0.07 Classification-F1 0.7005376556868739 on epoch=18
06/17/2022 02:09:19 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.13 on epoch=18
06/17/2022 02:09:22 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.07 on epoch=18
06/17/2022 02:09:25 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.04 on epoch=19
06/17/2022 02:09:27 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.13 on epoch=19
06/17/2022 02:09:30 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.03 on epoch=19
06/17/2022 02:10:21 - INFO - __main__ - Global step 2150 Train loss 0.08 Classification-F1 0.827437322314424 on epoch=19
06/17/2022 02:10:24 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.04 on epoch=19
06/17/2022 02:10:26 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.06 on epoch=19
06/17/2022 02:10:29 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.05 on epoch=19
06/17/2022 02:10:32 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.05 on epoch=19
06/17/2022 02:10:34 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.09 on epoch=19
06/17/2022 02:11:27 - INFO - __main__ - Global step 2200 Train loss 0.06 Classification-F1 0.7899852865760345 on epoch=19
06/17/2022 02:11:30 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=19
06/17/2022 02:11:32 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.05 on epoch=19
06/17/2022 02:11:35 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.11 on epoch=19
06/17/2022 02:11:38 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=19
06/17/2022 02:11:40 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.05 on epoch=20
06/17/2022 02:12:36 - INFO - __main__ - Global step 2250 Train loss 0.05 Classification-F1 0.7432530293996343 on epoch=20
06/17/2022 02:12:39 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.14 on epoch=20
06/17/2022 02:12:42 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.09 on epoch=20
06/17/2022 02:12:44 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=20
06/17/2022 02:12:47 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.07 on epoch=20
06/17/2022 02:12:49 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=20
06/17/2022 02:13:41 - INFO - __main__ - Global step 2300 Train loss 0.07 Classification-F1 0.7499141928475698 on epoch=20
06/17/2022 02:13:44 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.05 on epoch=20
06/17/2022 02:13:46 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.04 on epoch=20
06/17/2022 02:13:49 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.05 on epoch=20
06/17/2022 02:13:52 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.10 on epoch=20
06/17/2022 02:13:54 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.05 on epoch=20
06/17/2022 02:14:46 - INFO - __main__ - Global step 2350 Train loss 0.06 Classification-F1 0.8334987388320512 on epoch=20
06/17/2022 02:14:49 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.05 on epoch=21
06/17/2022 02:14:51 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.09 on epoch=21
06/17/2022 02:14:54 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=21
06/17/2022 02:14:57 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.04 on epoch=21
06/17/2022 02:14:59 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.03 on epoch=21
06/17/2022 02:15:49 - INFO - __main__ - Global step 2400 Train loss 0.05 Classification-F1 0.6327604053834881 on epoch=21
06/17/2022 02:15:51 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.03 on epoch=21
06/17/2022 02:15:54 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.04 on epoch=21
06/17/2022 02:15:57 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=21
06/17/2022 02:15:59 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.03 on epoch=21
06/17/2022 02:16:02 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.07 on epoch=21
06/17/2022 02:16:56 - INFO - __main__ - Global step 2450 Train loss 0.04 Classification-F1 0.7481730811490991 on epoch=21
06/17/2022 02:16:58 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.04 on epoch=21
06/17/2022 02:17:01 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.07 on epoch=22
06/17/2022 02:17:04 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.11 on epoch=22
06/17/2022 02:17:06 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.04 on epoch=22
06/17/2022 02:17:09 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.05 on epoch=22
06/17/2022 02:17:59 - INFO - __main__ - Global step 2500 Train loss 0.06 Classification-F1 0.7253323505748737 on epoch=22
06/17/2022 02:18:02 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.07 on epoch=22
06/17/2022 02:18:04 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.06 on epoch=22
06/17/2022 02:18:07 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.06 on epoch=22
06/17/2022 02:18:09 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=22
06/17/2022 02:18:12 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=22
06/17/2022 02:19:05 - INFO - __main__ - Global step 2550 Train loss 0.04 Classification-F1 0.7615449810302153 on epoch=22
06/17/2022 02:19:07 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.05 on epoch=22
06/17/2022 02:19:10 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.05 on epoch=22
06/17/2022 02:19:13 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.03 on epoch=23
06/17/2022 02:19:15 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.17 on epoch=23
06/17/2022 02:19:18 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=23
06/17/2022 02:20:13 - INFO - __main__ - Global step 2600 Train loss 0.07 Classification-F1 0.7495786179075381 on epoch=23
06/17/2022 02:20:15 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.03 on epoch=23
06/17/2022 02:20:18 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.07 on epoch=23
06/17/2022 02:20:20 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.03 on epoch=23
06/17/2022 02:20:23 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.09 on epoch=23
06/17/2022 02:20:26 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=23
06/17/2022 02:21:18 - INFO - __main__ - Global step 2650 Train loss 0.05 Classification-F1 0.7781351045120257 on epoch=23
06/17/2022 02:21:20 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=23
06/17/2022 02:21:23 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.11 on epoch=23
06/17/2022 02:21:25 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.08 on epoch=23
06/17/2022 02:21:28 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.03 on epoch=24
06/17/2022 02:21:31 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.07 on epoch=24
06/17/2022 02:22:22 - INFO - __main__ - Global step 2700 Train loss 0.06 Classification-F1 0.6796464277205669 on epoch=24
06/17/2022 02:22:25 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=24
06/17/2022 02:22:28 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.03 on epoch=24
06/17/2022 02:22:30 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.04 on epoch=24
06/17/2022 02:22:33 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.06 on epoch=24
06/17/2022 02:22:35 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.03 on epoch=24
06/17/2022 02:23:24 - INFO - __main__ - Global step 2750 Train loss 0.04 Classification-F1 0.7413995323931071 on epoch=24
06/17/2022 02:23:26 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.05 on epoch=24
06/17/2022 02:23:29 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=24
06/17/2022 02:23:31 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.09 on epoch=24
06/17/2022 02:23:34 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.03 on epoch=24
06/17/2022 02:23:37 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.03 on epoch=24
06/17/2022 02:24:28 - INFO - __main__ - Global step 2800 Train loss 0.04 Classification-F1 0.7340179569224952 on epoch=24
06/17/2022 02:24:31 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.05 on epoch=25
06/17/2022 02:24:33 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.12 on epoch=25
06/17/2022 02:24:36 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.05 on epoch=25
06/17/2022 02:24:39 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.04 on epoch=25
06/17/2022 02:24:41 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.08 on epoch=25
06/17/2022 02:25:29 - INFO - __main__ - Global step 2850 Train loss 0.07 Classification-F1 0.5848046926550515 on epoch=25
06/17/2022 02:25:32 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.04 on epoch=25
06/17/2022 02:25:35 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.05 on epoch=25
06/17/2022 02:25:37 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=25
06/17/2022 02:25:40 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=25
06/17/2022 02:25:43 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=25
06/17/2022 02:26:32 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.6097392753994612 on epoch=25
06/17/2022 02:26:34 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.04 on epoch=25
06/17/2022 02:26:37 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.04 on epoch=26
06/17/2022 02:26:40 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.09 on epoch=26
06/17/2022 02:26:42 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.05 on epoch=26
06/17/2022 02:26:45 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.04 on epoch=26
06/17/2022 02:27:37 - INFO - __main__ - Global step 2950 Train loss 0.05 Classification-F1 0.7690859291271046 on epoch=26
06/17/2022 02:27:39 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.04 on epoch=26
06/17/2022 02:27:42 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.03 on epoch=26
06/17/2022 02:27:45 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.11 on epoch=26
06/17/2022 02:27:47 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=26
06/17/2022 02:27:50 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.04 on epoch=26
06/17/2022 02:27:51 - INFO - __main__ - Start tokenizing ... 1792 instances
06/17/2022 02:27:51 - INFO - __main__ - Printing 3 examples
06/17/2022 02:27:51 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
06/17/2022 02:27:51 - INFO - __main__ - ['Film']
06/17/2022 02:27:51 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/17/2022 02:27:51 - INFO - __main__ - ['Film']
06/17/2022 02:27:51 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/17/2022 02:27:51 - INFO - __main__ - ['Film']
06/17/2022 02:27:51 - INFO - __main__ - Tokenizing Input ...
06/17/2022 02:27:52 - INFO - __main__ - Tokenizing Output ...
06/17/2022 02:27:54 - INFO - __main__ - Loaded 1792 examples from train data
06/17/2022 02:27:54 - INFO - __main__ - Start tokenizing ... 1792 instances
06/17/2022 02:27:54 - INFO - __main__ - Printing 3 examples
06/17/2022 02:27:54 - INFO - __main__ -  [dbpedia_14] The Debt is a 2011 American/British drama-thriller film directed by John Madden from a screenplay by Matthew Vaughn Jane Goldman and Peter Straughan. It stars Helen Mirren Sam Worthington Jessica Chastain Ciarán Hinds Tom Wilkinson Marton Csokas and Jesper Christensen. It's a remake of the 2007 Israeli film Ha-Hov directed by Assaf BernsteinOriginally scheduled for a December 2010 release the film was released in the United States on August 31 2011.
06/17/2022 02:27:54 - INFO - __main__ - ['Film']
06/17/2022 02:27:54 - INFO - __main__ -  [dbpedia_14] Naga Bonar Jadi 2 (Naga Bonar Becomes 2) is 2007 comedy film directed by Deddy Mizwar. It is starring Deddy Mizwar Tora Sudiro Lukman Sardi Darius Sinathrya and Michael Muliardo. It is a sequel to the Indonesian film Nagabonar (1987).
06/17/2022 02:27:54 - INFO - __main__ - ['Film']
06/17/2022 02:27:54 - INFO - __main__ -  [dbpedia_14] La Garce is a 1984 French thriller film directed by Christine Pascal and starring Isabelle Huppert.
06/17/2022 02:27:54 - INFO - __main__ - ['Film']
06/17/2022 02:27:54 - INFO - __main__ - Tokenizing Input ...
06/17/2022 02:27:55 - INFO - __main__ - Tokenizing Output ...
06/17/2022 02:27:57 - INFO - __main__ - Loaded 1792 examples from dev data
06/17/2022 02:28:13 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 02:28:14 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/17/2022 02:28:14 - INFO - __main__ - Starting training!
06/17/2022 02:28:40 - INFO - __main__ - Global step 3000 Train loss 0.04 Classification-F1 0.7268321870113349 on epoch=26
06/17/2022 02:28:40 - INFO - __main__ - save last model!
06/17/2022 02:28:40 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/17/2022 02:28:40 - INFO - __main__ - Start tokenizing ... 3500 instances
06/17/2022 02:28:40 - INFO - __main__ - Printing 3 examples
06/17/2022 02:28:40 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/17/2022 02:28:40 - INFO - __main__ - ['Animal']
06/17/2022 02:28:40 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/17/2022 02:28:40 - INFO - __main__ - ['Animal']
06/17/2022 02:28:40 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/17/2022 02:28:40 - INFO - __main__ - ['Village']
06/17/2022 02:28:40 - INFO - __main__ - Tokenizing Input ...
06/17/2022 02:28:42 - INFO - __main__ - Tokenizing Output ...
06/17/2022 02:28:45 - INFO - __main__ - Loaded 3500 examples from test data
06/17/2022 02:30:51 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down128shot/singletask-dbpedia_14/dbpedia_14_128_42_0.2_8_predictions.txt
06/17/2022 02:30:51 - INFO - __main__ - Classification-F1 on test data: 0.6278
06/17/2022 02:30:52 - INFO - __main__ - prefix=dbpedia_14_128_42, lr=0.2, bsz=8, dev_performance=0.8516346681566993, test_performance=0.6278105614063957
06/17/2022 02:30:52 - INFO - __main__ - Running ... prefix=dbpedia_14_128_87, lr=0.5, bsz=8 ...
06/17/2022 02:30:52 - INFO - __main__ - Start tokenizing ... 1792 instances
06/17/2022 02:30:52 - INFO - __main__ - Printing 3 examples
06/17/2022 02:30:52 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
06/17/2022 02:30:52 - INFO - __main__ - ['Film']
06/17/2022 02:30:52 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/17/2022 02:30:52 - INFO - __main__ - ['Film']
06/17/2022 02:30:52 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/17/2022 02:30:52 - INFO - __main__ - ['Film']
06/17/2022 02:30:52 - INFO - __main__ - Tokenizing Input ...
06/17/2022 02:30:53 - INFO - __main__ - Tokenizing Output ...
06/17/2022 02:30:55 - INFO - __main__ - Loaded 1792 examples from train data
06/17/2022 02:30:55 - INFO - __main__ - Start tokenizing ... 1792 instances
06/17/2022 02:30:55 - INFO - __main__ - Printing 3 examples
06/17/2022 02:30:55 - INFO - __main__ -  [dbpedia_14] The Debt is a 2011 American/British drama-thriller film directed by John Madden from a screenplay by Matthew Vaughn Jane Goldman and Peter Straughan. It stars Helen Mirren Sam Worthington Jessica Chastain Ciarán Hinds Tom Wilkinson Marton Csokas and Jesper Christensen. It's a remake of the 2007 Israeli film Ha-Hov directed by Assaf BernsteinOriginally scheduled for a December 2010 release the film was released in the United States on August 31 2011.
06/17/2022 02:30:55 - INFO - __main__ - ['Film']
06/17/2022 02:30:55 - INFO - __main__ -  [dbpedia_14] Naga Bonar Jadi 2 (Naga Bonar Becomes 2) is 2007 comedy film directed by Deddy Mizwar. It is starring Deddy Mizwar Tora Sudiro Lukman Sardi Darius Sinathrya and Michael Muliardo. It is a sequel to the Indonesian film Nagabonar (1987).
06/17/2022 02:30:55 - INFO - __main__ - ['Film']
06/17/2022 02:30:55 - INFO - __main__ -  [dbpedia_14] La Garce is a 1984 French thriller film directed by Christine Pascal and starring Isabelle Huppert.
06/17/2022 02:30:55 - INFO - __main__ - ['Film']
06/17/2022 02:30:55 - INFO - __main__ - Tokenizing Input ...
06/17/2022 02:30:56 - INFO - __main__ - Tokenizing Output ...
06/17/2022 02:30:58 - INFO - __main__ - Loaded 1792 examples from dev data
06/17/2022 02:31:14 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 02:31:14 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/17/2022 02:31:14 - INFO - __main__ - Starting training!
06/17/2022 02:31:18 - INFO - __main__ - Step 10 Global step 10 Train loss 4.24 on epoch=0
06/17/2022 02:31:20 - INFO - __main__ - Step 20 Global step 20 Train loss 2.59 on epoch=0
06/17/2022 02:31:23 - INFO - __main__ - Step 30 Global step 30 Train loss 1.70 on epoch=0
06/17/2022 02:31:26 - INFO - __main__ - Step 40 Global step 40 Train loss 1.17 on epoch=0
06/17/2022 02:31:28 - INFO - __main__ - Step 50 Global step 50 Train loss 1.12 on epoch=0
06/17/2022 02:32:13 - INFO - __main__ - Global step 50 Train loss 2.16 Classification-F1 0.23272731259769808 on epoch=0
06/17/2022 02:32:13 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.23272731259769808 on epoch=0, global_step=50
06/17/2022 02:32:16 - INFO - __main__ - Step 60 Global step 60 Train loss 0.79 on epoch=0
06/17/2022 02:32:19 - INFO - __main__ - Step 70 Global step 70 Train loss 0.90 on epoch=0
06/17/2022 02:32:21 - INFO - __main__ - Step 80 Global step 80 Train loss 0.74 on epoch=0
06/17/2022 02:32:24 - INFO - __main__ - Step 90 Global step 90 Train loss 0.61 on epoch=0
06/17/2022 02:32:26 - INFO - __main__ - Step 100 Global step 100 Train loss 0.53 on epoch=0
06/17/2022 02:33:16 - INFO - __main__ - Global step 100 Train loss 0.71 Classification-F1 0.3008846285376446 on epoch=0
06/17/2022 02:33:16 - INFO - __main__ - Saving model with best Classification-F1: 0.23272731259769808 -> 0.3008846285376446 on epoch=0, global_step=100
06/17/2022 02:33:19 - INFO - __main__ - Step 110 Global step 110 Train loss 0.50 on epoch=0
06/17/2022 02:33:22 - INFO - __main__ - Step 120 Global step 120 Train loss 0.44 on epoch=1
06/17/2022 02:33:24 - INFO - __main__ - Step 130 Global step 130 Train loss 0.37 on epoch=1
06/17/2022 02:33:27 - INFO - __main__ - Step 140 Global step 140 Train loss 0.48 on epoch=1
06/17/2022 02:33:29 - INFO - __main__ - Step 150 Global step 150 Train loss 0.47 on epoch=1
06/17/2022 02:34:21 - INFO - __main__ - Global step 150 Train loss 0.45 Classification-F1 0.3321027701712713 on epoch=1
06/17/2022 02:34:21 - INFO - __main__ - Saving model with best Classification-F1: 0.3008846285376446 -> 0.3321027701712713 on epoch=1, global_step=150
06/17/2022 02:34:24 - INFO - __main__ - Step 160 Global step 160 Train loss 0.41 on epoch=1
06/17/2022 02:34:26 - INFO - __main__ - Step 170 Global step 170 Train loss 0.42 on epoch=1
06/17/2022 02:34:29 - INFO - __main__ - Step 180 Global step 180 Train loss 0.43 on epoch=1
06/17/2022 02:34:32 - INFO - __main__ - Step 190 Global step 190 Train loss 0.40 on epoch=1
06/17/2022 02:34:34 - INFO - __main__ - Step 200 Global step 200 Train loss 0.35 on epoch=1
06/17/2022 02:35:26 - INFO - __main__ - Global step 200 Train loss 0.40 Classification-F1 0.4291766242406145 on epoch=1
06/17/2022 02:35:26 - INFO - __main__ - Saving model with best Classification-F1: 0.3321027701712713 -> 0.4291766242406145 on epoch=1, global_step=200
06/17/2022 02:35:29 - INFO - __main__ - Step 210 Global step 210 Train loss 0.32 on epoch=1
06/17/2022 02:35:31 - INFO - __main__ - Step 220 Global step 220 Train loss 0.40 on epoch=1
06/17/2022 02:35:34 - INFO - __main__ - Step 230 Global step 230 Train loss 0.33 on epoch=2
06/17/2022 02:35:36 - INFO - __main__ - Step 240 Global step 240 Train loss 0.18 on epoch=2
06/17/2022 02:35:39 - INFO - __main__ - Step 250 Global step 250 Train loss 0.28 on epoch=2
06/17/2022 02:36:37 - INFO - __main__ - Global step 250 Train loss 0.30 Classification-F1 0.4781605987952193 on epoch=2
06/17/2022 02:36:37 - INFO - __main__ - Saving model with best Classification-F1: 0.4291766242406145 -> 0.4781605987952193 on epoch=2, global_step=250
06/17/2022 02:36:39 - INFO - __main__ - Step 260 Global step 260 Train loss 0.31 on epoch=2
06/17/2022 02:36:42 - INFO - __main__ - Step 270 Global step 270 Train loss 0.24 on epoch=2
06/17/2022 02:36:44 - INFO - __main__ - Step 280 Global step 280 Train loss 0.23 on epoch=2
06/17/2022 02:36:47 - INFO - __main__ - Step 290 Global step 290 Train loss 0.22 on epoch=2
06/17/2022 02:36:50 - INFO - __main__ - Step 300 Global step 300 Train loss 0.28 on epoch=2
06/17/2022 02:37:40 - INFO - __main__ - Global step 300 Train loss 0.26 Classification-F1 0.490798240753351 on epoch=2
06/17/2022 02:37:40 - INFO - __main__ - Saving model with best Classification-F1: 0.4781605987952193 -> 0.490798240753351 on epoch=2, global_step=300
06/17/2022 02:37:43 - INFO - __main__ - Step 310 Global step 310 Train loss 0.26 on epoch=2
06/17/2022 02:37:45 - INFO - __main__ - Step 320 Global step 320 Train loss 0.22 on epoch=2
06/17/2022 02:37:48 - INFO - __main__ - Step 330 Global step 330 Train loss 0.18 on epoch=2
06/17/2022 02:37:51 - INFO - __main__ - Step 340 Global step 340 Train loss 0.27 on epoch=3
06/17/2022 02:37:53 - INFO - __main__ - Step 350 Global step 350 Train loss 0.20 on epoch=3
06/17/2022 02:38:53 - INFO - __main__ - Global step 350 Train loss 0.22 Classification-F1 0.4659326539058761 on epoch=3
06/17/2022 02:38:56 - INFO - __main__ - Step 360 Global step 360 Train loss 0.19 on epoch=3
06/17/2022 02:38:59 - INFO - __main__ - Step 370 Global step 370 Train loss 0.21 on epoch=3
06/17/2022 02:39:01 - INFO - __main__ - Step 380 Global step 380 Train loss 0.16 on epoch=3
06/17/2022 02:39:04 - INFO - __main__ - Step 390 Global step 390 Train loss 0.16 on epoch=3
06/17/2022 02:39:06 - INFO - __main__ - Step 400 Global step 400 Train loss 0.20 on epoch=3
06/17/2022 02:40:05 - INFO - __main__ - Global step 400 Train loss 0.18 Classification-F1 0.5418657950242474 on epoch=3
06/17/2022 02:40:05 - INFO - __main__ - Saving model with best Classification-F1: 0.490798240753351 -> 0.5418657950242474 on epoch=3, global_step=400
06/17/2022 02:40:07 - INFO - __main__ - Step 410 Global step 410 Train loss 0.17 on epoch=3
06/17/2022 02:40:10 - INFO - __main__ - Step 420 Global step 420 Train loss 0.23 on epoch=3
06/17/2022 02:40:13 - INFO - __main__ - Step 430 Global step 430 Train loss 0.21 on epoch=3
06/17/2022 02:40:15 - INFO - __main__ - Step 440 Global step 440 Train loss 0.14 on epoch=3
06/17/2022 02:40:18 - INFO - __main__ - Step 450 Global step 450 Train loss 0.22 on epoch=4
06/17/2022 02:41:19 - INFO - __main__ - Global step 450 Train loss 0.19 Classification-F1 0.5746930162713201 on epoch=4
06/17/2022 02:41:19 - INFO - __main__ - Saving model with best Classification-F1: 0.5418657950242474 -> 0.5746930162713201 on epoch=4, global_step=450
06/17/2022 02:41:22 - INFO - __main__ - Step 460 Global step 460 Train loss 0.17 on epoch=4
06/17/2022 02:41:24 - INFO - __main__ - Step 470 Global step 470 Train loss 0.12 on epoch=4
06/17/2022 02:41:27 - INFO - __main__ - Step 480 Global step 480 Train loss 0.21 on epoch=4
06/17/2022 02:41:30 - INFO - __main__ - Step 490 Global step 490 Train loss 0.23 on epoch=4
06/17/2022 02:41:32 - INFO - __main__ - Step 500 Global step 500 Train loss 0.11 on epoch=4
06/17/2022 02:42:24 - INFO - __main__ - Global step 500 Train loss 0.17 Classification-F1 0.5127817512214624 on epoch=4
06/17/2022 02:42:26 - INFO - __main__ - Step 510 Global step 510 Train loss 0.11 on epoch=4
06/17/2022 02:42:29 - INFO - __main__ - Step 520 Global step 520 Train loss 0.12 on epoch=4
06/17/2022 02:42:31 - INFO - __main__ - Step 530 Global step 530 Train loss 0.19 on epoch=4
06/17/2022 02:42:34 - INFO - __main__ - Step 540 Global step 540 Train loss 0.09 on epoch=4
06/17/2022 02:42:37 - INFO - __main__ - Step 550 Global step 550 Train loss 0.09 on epoch=4
06/17/2022 02:43:31 - INFO - __main__ - Global step 550 Train loss 0.12 Classification-F1 0.6567192658015693 on epoch=4
06/17/2022 02:43:31 - INFO - __main__ - Saving model with best Classification-F1: 0.5746930162713201 -> 0.6567192658015693 on epoch=4, global_step=550
06/17/2022 02:43:33 - INFO - __main__ - Step 560 Global step 560 Train loss 0.16 on epoch=4
06/17/2022 02:43:36 - INFO - __main__ - Step 570 Global step 570 Train loss 0.17 on epoch=5
06/17/2022 02:43:38 - INFO - __main__ - Step 580 Global step 580 Train loss 0.07 on epoch=5
06/17/2022 02:43:41 - INFO - __main__ - Step 590 Global step 590 Train loss 0.13 on epoch=5
06/17/2022 02:43:44 - INFO - __main__ - Step 600 Global step 600 Train loss 0.09 on epoch=5
06/17/2022 02:44:37 - INFO - __main__ - Global step 600 Train loss 0.12 Classification-F1 0.47796302311751054 on epoch=5
06/17/2022 02:44:40 - INFO - __main__ - Step 610 Global step 610 Train loss 0.12 on epoch=5
06/17/2022 02:44:43 - INFO - __main__ - Step 620 Global step 620 Train loss 0.11 on epoch=5
06/17/2022 02:44:45 - INFO - __main__ - Step 630 Global step 630 Train loss 0.12 on epoch=5
06/17/2022 02:44:48 - INFO - __main__ - Step 640 Global step 640 Train loss 0.12 on epoch=5
06/17/2022 02:44:50 - INFO - __main__ - Step 650 Global step 650 Train loss 0.06 on epoch=5
06/17/2022 02:45:50 - INFO - __main__ - Global step 650 Train loss 0.11 Classification-F1 0.6873797511208515 on epoch=5
06/17/2022 02:45:50 - INFO - __main__ - Saving model with best Classification-F1: 0.6567192658015693 -> 0.6873797511208515 on epoch=5, global_step=650
06/17/2022 02:45:52 - INFO - __main__ - Step 660 Global step 660 Train loss 0.07 on epoch=5
06/17/2022 02:45:55 - INFO - __main__ - Step 670 Global step 670 Train loss 0.21 on epoch=5
06/17/2022 02:45:58 - INFO - __main__ - Step 680 Global step 680 Train loss 0.09 on epoch=6
06/17/2022 02:46:00 - INFO - __main__ - Step 690 Global step 690 Train loss 0.08 on epoch=6
06/17/2022 02:46:03 - INFO - __main__ - Step 700 Global step 700 Train loss 0.08 on epoch=6
06/17/2022 02:46:55 - INFO - __main__ - Global step 700 Train loss 0.10 Classification-F1 0.6407348138085036 on epoch=6
06/17/2022 02:46:58 - INFO - __main__ - Step 710 Global step 710 Train loss 0.15 on epoch=6
06/17/2022 02:47:01 - INFO - __main__ - Step 720 Global step 720 Train loss 0.09 on epoch=6
06/17/2022 02:47:03 - INFO - __main__ - Step 730 Global step 730 Train loss 0.07 on epoch=6
06/17/2022 02:47:06 - INFO - __main__ - Step 740 Global step 740 Train loss 0.05 on epoch=6
06/17/2022 02:47:08 - INFO - __main__ - Step 750 Global step 750 Train loss 0.10 on epoch=6
06/17/2022 02:47:59 - INFO - __main__ - Global step 750 Train loss 0.09 Classification-F1 0.7587631679725949 on epoch=6
06/17/2022 02:47:59 - INFO - __main__ - Saving model with best Classification-F1: 0.6873797511208515 -> 0.7587631679725949 on epoch=6, global_step=750
06/17/2022 02:48:01 - INFO - __main__ - Step 760 Global step 760 Train loss 0.10 on epoch=6
06/17/2022 02:48:04 - INFO - __main__ - Step 770 Global step 770 Train loss 0.06 on epoch=6
06/17/2022 02:48:07 - INFO - __main__ - Step 780 Global step 780 Train loss 0.12 on epoch=6
06/17/2022 02:48:09 - INFO - __main__ - Step 790 Global step 790 Train loss 0.09 on epoch=7
06/17/2022 02:48:12 - INFO - __main__ - Step 800 Global step 800 Train loss 0.08 on epoch=7
06/17/2022 02:49:03 - INFO - __main__ - Global step 800 Train loss 0.09 Classification-F1 0.6075846714541547 on epoch=7
06/17/2022 02:49:06 - INFO - __main__ - Step 810 Global step 810 Train loss 0.07 on epoch=7
06/17/2022 02:49:09 - INFO - __main__ - Step 820 Global step 820 Train loss 0.07 on epoch=7
06/17/2022 02:49:11 - INFO - __main__ - Step 830 Global step 830 Train loss 0.10 on epoch=7
06/17/2022 02:49:14 - INFO - __main__ - Step 840 Global step 840 Train loss 0.04 on epoch=7
06/17/2022 02:49:16 - INFO - __main__ - Step 850 Global step 850 Train loss 0.09 on epoch=7
06/17/2022 02:50:06 - INFO - __main__ - Global step 850 Train loss 0.07 Classification-F1 0.7022273148409712 on epoch=7
06/17/2022 02:50:09 - INFO - __main__ - Step 860 Global step 860 Train loss 0.06 on epoch=7
06/17/2022 02:50:11 - INFO - __main__ - Step 870 Global step 870 Train loss 0.04 on epoch=7
06/17/2022 02:50:14 - INFO - __main__ - Step 880 Global step 880 Train loss 0.08 on epoch=7
06/17/2022 02:50:16 - INFO - __main__ - Step 890 Global step 890 Train loss 0.07 on epoch=7
06/17/2022 02:50:19 - INFO - __main__ - Step 900 Global step 900 Train loss 0.13 on epoch=8
06/17/2022 02:51:08 - INFO - __main__ - Global step 900 Train loss 0.08 Classification-F1 0.7831532443569145 on epoch=8
06/17/2022 02:51:08 - INFO - __main__ - Saving model with best Classification-F1: 0.7587631679725949 -> 0.7831532443569145 on epoch=8, global_step=900
06/17/2022 02:51:11 - INFO - __main__ - Step 910 Global step 910 Train loss 0.04 on epoch=8
06/17/2022 02:51:14 - INFO - __main__ - Step 920 Global step 920 Train loss 0.03 on epoch=8
06/17/2022 02:51:16 - INFO - __main__ - Step 930 Global step 930 Train loss 0.06 on epoch=8
06/17/2022 02:51:19 - INFO - __main__ - Step 940 Global step 940 Train loss 0.14 on epoch=8
06/17/2022 02:51:21 - INFO - __main__ - Step 950 Global step 950 Train loss 0.05 on epoch=8
06/17/2022 02:52:09 - INFO - __main__ - Global step 950 Train loss 0.07 Classification-F1 0.5305547156377378 on epoch=8
06/17/2022 02:52:12 - INFO - __main__ - Step 960 Global step 960 Train loss 0.06 on epoch=8
06/17/2022 02:52:14 - INFO - __main__ - Step 970 Global step 970 Train loss 0.03 on epoch=8
06/17/2022 02:52:17 - INFO - __main__ - Step 980 Global step 980 Train loss 0.07 on epoch=8
06/17/2022 02:52:19 - INFO - __main__ - Step 990 Global step 990 Train loss 0.04 on epoch=8
06/17/2022 02:52:22 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.03 on epoch=8
06/17/2022 02:53:13 - INFO - __main__ - Global step 1000 Train loss 0.05 Classification-F1 0.7207536718928843 on epoch=8
06/17/2022 02:53:16 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.10 on epoch=9
06/17/2022 02:53:19 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.05 on epoch=9
06/17/2022 02:53:21 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.02 on epoch=9
06/17/2022 02:53:24 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.08 on epoch=9
06/17/2022 02:53:26 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.07 on epoch=9
06/17/2022 02:54:24 - INFO - __main__ - Global step 1050 Train loss 0.07 Classification-F1 0.6134765685617559 on epoch=9
06/17/2022 02:54:26 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.05 on epoch=9
06/17/2022 02:54:29 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.08 on epoch=9
06/17/2022 02:54:31 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.04 on epoch=9
06/17/2022 02:54:34 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.08 on epoch=9
06/17/2022 02:54:37 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.04 on epoch=9
06/17/2022 02:55:26 - INFO - __main__ - Global step 1100 Train loss 0.06 Classification-F1 0.563202831666222 on epoch=9
06/17/2022 02:55:29 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.02 on epoch=9
06/17/2022 02:55:31 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.10 on epoch=9
06/17/2022 02:55:34 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.03 on epoch=10
06/17/2022 02:55:36 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.04 on epoch=10
06/17/2022 02:55:39 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.06 on epoch=10
06/17/2022 02:56:27 - INFO - __main__ - Global step 1150 Train loss 0.05 Classification-F1 0.6289421029111462 on epoch=10
06/17/2022 02:56:30 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.07 on epoch=10
06/17/2022 02:56:32 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.07 on epoch=10
06/17/2022 02:56:35 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.04 on epoch=10
06/17/2022 02:56:38 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.03 on epoch=10
06/17/2022 02:56:40 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.04 on epoch=10
06/17/2022 02:57:33 - INFO - __main__ - Global step 1200 Train loss 0.05 Classification-F1 0.6196134787327945 on epoch=10
06/17/2022 02:57:35 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.02 on epoch=10
06/17/2022 02:57:38 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.03 on epoch=10
06/17/2022 02:57:41 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.05 on epoch=10
06/17/2022 02:57:43 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.02 on epoch=11
06/17/2022 02:57:46 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.06 on epoch=11
06/17/2022 02:58:35 - INFO - __main__ - Global step 1250 Train loss 0.04 Classification-F1 0.7141220398070589 on epoch=11
06/17/2022 02:58:38 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.05 on epoch=11
06/17/2022 02:58:41 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.02 on epoch=11
06/17/2022 02:58:43 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.06 on epoch=11
06/17/2022 02:58:46 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.02 on epoch=11
06/17/2022 02:58:49 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.04 on epoch=11
06/17/2022 02:59:40 - INFO - __main__ - Global step 1300 Train loss 0.04 Classification-F1 0.6562326900512593 on epoch=11
06/17/2022 02:59:43 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.03 on epoch=11
06/17/2022 02:59:46 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.14 on epoch=11
06/17/2022 02:59:48 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.05 on epoch=11
06/17/2022 02:59:51 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.05 on epoch=11
06/17/2022 02:59:53 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.06 on epoch=12
06/17/2022 03:00:43 - INFO - __main__ - Global step 1350 Train loss 0.06 Classification-F1 0.5472508066932719 on epoch=12
06/17/2022 03:00:45 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.03 on epoch=12
06/17/2022 03:00:48 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.08 on epoch=12
06/17/2022 03:00:50 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.10 on epoch=12
06/17/2022 03:00:53 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.04 on epoch=12
06/17/2022 03:00:56 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=12
06/17/2022 03:01:42 - INFO - __main__ - Global step 1400 Train loss 0.06 Classification-F1 0.6102295871918751 on epoch=12
06/17/2022 03:01:45 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.06 on epoch=12
06/17/2022 03:01:47 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=12
06/17/2022 03:01:50 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.07 on epoch=12
06/17/2022 03:01:53 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.04 on epoch=12
06/17/2022 03:01:55 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.04 on epoch=12
06/17/2022 03:02:42 - INFO - __main__ - Global step 1450 Train loss 0.05 Classification-F1 0.6283055137894931 on epoch=12
06/17/2022 03:02:45 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.05 on epoch=13
06/17/2022 03:02:48 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=13
06/17/2022 03:02:50 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.02 on epoch=13
06/17/2022 03:02:53 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.07 on epoch=13
06/17/2022 03:02:55 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.02 on epoch=13
06/17/2022 03:03:44 - INFO - __main__ - Global step 1500 Train loss 0.03 Classification-F1 0.7487516718133537 on epoch=13
06/17/2022 03:03:46 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=13
06/17/2022 03:03:49 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.03 on epoch=13
06/17/2022 03:03:51 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.05 on epoch=13
06/17/2022 03:03:54 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=13
06/17/2022 03:03:57 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.03 on epoch=13
06/17/2022 03:04:46 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.724171717847882 on epoch=13
06/17/2022 03:04:48 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.04 on epoch=13
06/17/2022 03:04:51 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.06 on epoch=14
06/17/2022 03:04:54 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.08 on epoch=14
06/17/2022 03:04:56 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.04 on epoch=14
06/17/2022 03:04:59 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.10 on epoch=14
06/17/2022 03:05:48 - INFO - __main__ - Global step 1600 Train loss 0.06 Classification-F1 0.6422080459262854 on epoch=14
06/17/2022 03:05:50 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.11 on epoch=14
06/17/2022 03:05:53 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=14
06/17/2022 03:05:55 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.05 on epoch=14
06/17/2022 03:05:58 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.06 on epoch=14
06/17/2022 03:06:01 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.05 on epoch=14
06/17/2022 03:06:48 - INFO - __main__ - Global step 1650 Train loss 0.06 Classification-F1 0.7392437138461883 on epoch=14
06/17/2022 03:06:51 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.03 on epoch=14
06/17/2022 03:06:54 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.07 on epoch=14
06/17/2022 03:06:56 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=14
06/17/2022 03:06:59 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.07 on epoch=15
06/17/2022 03:07:01 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.05 on epoch=15
06/17/2022 03:07:49 - INFO - __main__ - Global step 1700 Train loss 0.05 Classification-F1 0.5870955991306134 on epoch=15
06/17/2022 03:07:52 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=15
06/17/2022 03:07:54 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.05 on epoch=15
06/17/2022 03:07:57 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.09 on epoch=15
06/17/2022 03:07:59 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=15
06/17/2022 03:08:02 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=15
06/17/2022 03:08:50 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.5600741803434949 on epoch=15
06/17/2022 03:08:53 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.03 on epoch=15
06/17/2022 03:08:55 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.05 on epoch=15
06/17/2022 03:08:58 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=15
06/17/2022 03:09:01 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.05 on epoch=15
06/17/2022 03:09:03 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.03 on epoch=16
06/17/2022 03:09:55 - INFO - __main__ - Global step 1800 Train loss 0.04 Classification-F1 0.856056931090895 on epoch=16
06/17/2022 03:09:55 - INFO - __main__ - Saving model with best Classification-F1: 0.7831532443569145 -> 0.856056931090895 on epoch=16, global_step=1800
06/17/2022 03:09:58 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=16
06/17/2022 03:10:00 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.13 on epoch=16
06/17/2022 03:10:03 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.04 on epoch=16
06/17/2022 03:10:05 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.09 on epoch=16
06/17/2022 03:10:08 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=16
06/17/2022 03:10:57 - INFO - __main__ - Global step 1850 Train loss 0.06 Classification-F1 0.7172238849154245 on epoch=16
06/17/2022 03:11:00 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=16
06/17/2022 03:11:02 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=16
06/17/2022 03:11:05 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=16
06/17/2022 03:11:07 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=16
06/17/2022 03:11:10 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.06 on epoch=16
06/17/2022 03:11:57 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.6776249869394613 on epoch=16
06/17/2022 03:11:59 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=17
06/17/2022 03:12:02 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=17
06/17/2022 03:12:05 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.10 on epoch=17
06/17/2022 03:12:07 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=17
06/17/2022 03:12:10 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.03 on epoch=17
06/17/2022 03:12:57 - INFO - __main__ - Global step 1950 Train loss 0.04 Classification-F1 0.7076201776621782 on epoch=17
06/17/2022 03:13:00 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.05 on epoch=17
06/17/2022 03:13:02 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.04 on epoch=17
06/17/2022 03:13:05 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=17
06/17/2022 03:13:08 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.08 on epoch=17
06/17/2022 03:13:10 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.04 on epoch=17
06/17/2022 03:13:59 - INFO - __main__ - Global step 2000 Train loss 0.05 Classification-F1 0.8506666567389234 on epoch=17
06/17/2022 03:14:01 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.09 on epoch=17
06/17/2022 03:14:04 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=18
06/17/2022 03:14:07 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.04 on epoch=18
06/17/2022 03:14:09 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=18
06/17/2022 03:14:12 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.06 on epoch=18
06/17/2022 03:15:00 - INFO - __main__ - Global step 2050 Train loss 0.05 Classification-F1 0.7482811515368938 on epoch=18
06/17/2022 03:15:02 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.07 on epoch=18
06/17/2022 03:15:05 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=18
06/17/2022 03:15:08 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=18
06/17/2022 03:15:10 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.04 on epoch=18
06/17/2022 03:15:13 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=18
06/17/2022 03:16:01 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.6333355403245117 on epoch=18
06/17/2022 03:16:03 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=18
06/17/2022 03:16:06 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=18
06/17/2022 03:16:09 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.08 on epoch=19
06/17/2022 03:16:11 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=19
06/17/2022 03:16:14 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.04 on epoch=19
06/17/2022 03:17:02 - INFO - __main__ - Global step 2150 Train loss 0.03 Classification-F1 0.7804430156224504 on epoch=19
06/17/2022 03:17:04 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=19
06/17/2022 03:17:07 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.04 on epoch=19
06/17/2022 03:17:10 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.04 on epoch=19
06/17/2022 03:17:12 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=19
06/17/2022 03:17:15 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=19
06/17/2022 03:18:01 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.6760255223909786 on epoch=19
06/17/2022 03:18:04 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.03 on epoch=19
06/17/2022 03:18:07 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=19
06/17/2022 03:18:09 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=19
06/17/2022 03:18:12 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=19
06/17/2022 03:18:14 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=20
06/17/2022 03:19:02 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.6070748225967787 on epoch=20
06/17/2022 03:19:04 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.03 on epoch=20
06/17/2022 03:19:07 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=20
06/17/2022 03:19:10 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.11 on epoch=20
06/17/2022 03:19:12 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.04 on epoch=20
06/17/2022 03:19:15 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=20
06/17/2022 03:20:01 - INFO - __main__ - Global step 2300 Train loss 0.04 Classification-F1 0.721326636650312 on epoch=20
06/17/2022 03:20:03 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=20
06/17/2022 03:20:06 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=20
06/17/2022 03:20:08 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=20
06/17/2022 03:20:11 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=20
06/17/2022 03:20:14 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=20
06/17/2022 03:21:01 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.6808903919381943 on epoch=20
06/17/2022 03:21:04 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=21
06/17/2022 03:21:06 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=21
06/17/2022 03:21:09 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=21
06/17/2022 03:21:12 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=21
06/17/2022 03:21:14 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.06 on epoch=21
06/17/2022 03:22:05 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.6437338443842651 on epoch=21
06/17/2022 03:22:07 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.03 on epoch=21
06/17/2022 03:22:10 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=21
06/17/2022 03:22:13 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=21
06/17/2022 03:22:15 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.05 on epoch=21
06/17/2022 03:22:18 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.03 on epoch=21
06/17/2022 03:23:05 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.654741559777335 on epoch=21
06/17/2022 03:23:07 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.04 on epoch=21
06/17/2022 03:23:10 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=22
06/17/2022 03:23:13 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=22
06/17/2022 03:23:15 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=22
06/17/2022 03:23:18 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.03 on epoch=22
06/17/2022 03:24:05 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.9184284584484034 on epoch=22
06/17/2022 03:24:05 - INFO - __main__ - Saving model with best Classification-F1: 0.856056931090895 -> 0.9184284584484034 on epoch=22, global_step=2500
06/17/2022 03:24:07 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=22
06/17/2022 03:24:10 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.03 on epoch=22
06/17/2022 03:24:13 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=22
06/17/2022 03:24:15 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.03 on epoch=22
06/17/2022 03:24:18 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=22
06/17/2022 03:25:05 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.9877246152533369 on epoch=22
06/17/2022 03:25:05 - INFO - __main__ - Saving model with best Classification-F1: 0.9184284584484034 -> 0.9877246152533369 on epoch=22, global_step=2550
06/17/2022 03:25:08 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=22
06/17/2022 03:25:11 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=22
06/17/2022 03:25:13 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.03 on epoch=23
06/17/2022 03:25:16 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=23
06/17/2022 03:25:19 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=23
06/17/2022 03:26:06 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.8632475284909363 on epoch=23
06/17/2022 03:26:09 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.08 on epoch=23
06/17/2022 03:26:12 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.04 on epoch=23
06/17/2022 03:26:14 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.09 on epoch=23
06/17/2022 03:26:17 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=23
06/17/2022 03:26:19 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=23
06/17/2022 03:27:09 - INFO - __main__ - Global step 2650 Train loss 0.05 Classification-F1 0.8605066122729695 on epoch=23
06/17/2022 03:27:12 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.04 on epoch=23
06/17/2022 03:27:14 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=23
06/17/2022 03:27:17 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.03 on epoch=23
06/17/2022 03:27:19 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.06 on epoch=24
06/17/2022 03:27:22 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=24
06/17/2022 03:28:08 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.6233813823187174 on epoch=24
06/17/2022 03:28:11 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.06 on epoch=24
06/17/2022 03:28:13 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=24
06/17/2022 03:28:16 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=24
06/17/2022 03:28:19 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.03 on epoch=24
06/17/2022 03:28:21 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.04 on epoch=24
06/17/2022 03:29:09 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.6537663667021458 on epoch=24
06/17/2022 03:29:12 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=24
06/17/2022 03:29:14 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=24
06/17/2022 03:29:17 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.09 on epoch=24
06/17/2022 03:29:20 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=24
06/17/2022 03:29:22 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=24
06/17/2022 03:30:09 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.7223652546568012 on epoch=24
06/17/2022 03:30:11 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=25
06/17/2022 03:30:14 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=25
06/17/2022 03:30:17 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.03 on epoch=25
06/17/2022 03:30:19 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=25
06/17/2022 03:30:22 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.09 on epoch=25
06/17/2022 03:31:10 - INFO - __main__ - Global step 2850 Train loss 0.03 Classification-F1 0.7376803519392274 on epoch=25
06/17/2022 03:31:12 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.05 on epoch=25
06/17/2022 03:31:15 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=25
06/17/2022 03:31:18 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=25
06/17/2022 03:31:20 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=25
06/17/2022 03:31:23 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=25
06/17/2022 03:32:10 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.7694782367433863 on epoch=25
06/17/2022 03:32:12 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.05 on epoch=25
06/17/2022 03:32:15 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.04 on epoch=26
06/17/2022 03:32:17 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=26
06/17/2022 03:32:20 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.07 on epoch=26
06/17/2022 03:32:23 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=26
06/17/2022 03:33:11 - INFO - __main__ - Global step 2950 Train loss 0.04 Classification-F1 0.8072658836178598 on epoch=26
06/17/2022 03:33:14 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=26
06/17/2022 03:33:17 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=26
06/17/2022 03:33:19 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.04 on epoch=26
06/17/2022 03:33:22 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=26
06/17/2022 03:33:24 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.03 on epoch=26
06/17/2022 03:33:26 - INFO - __main__ - Start tokenizing ... 1792 instances
06/17/2022 03:33:26 - INFO - __main__ - Printing 3 examples
06/17/2022 03:33:26 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
06/17/2022 03:33:26 - INFO - __main__ - ['Film']
06/17/2022 03:33:26 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/17/2022 03:33:26 - INFO - __main__ - ['Film']
06/17/2022 03:33:26 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/17/2022 03:33:26 - INFO - __main__ - ['Film']
06/17/2022 03:33:26 - INFO - __main__ - Tokenizing Input ...
06/17/2022 03:33:27 - INFO - __main__ - Tokenizing Output ...
06/17/2022 03:33:29 - INFO - __main__ - Loaded 1792 examples from train data
06/17/2022 03:33:29 - INFO - __main__ - Start tokenizing ... 1792 instances
06/17/2022 03:33:29 - INFO - __main__ - Printing 3 examples
06/17/2022 03:33:29 - INFO - __main__ -  [dbpedia_14] The Debt is a 2011 American/British drama-thriller film directed by John Madden from a screenplay by Matthew Vaughn Jane Goldman and Peter Straughan. It stars Helen Mirren Sam Worthington Jessica Chastain Ciarán Hinds Tom Wilkinson Marton Csokas and Jesper Christensen. It's a remake of the 2007 Israeli film Ha-Hov directed by Assaf BernsteinOriginally scheduled for a December 2010 release the film was released in the United States on August 31 2011.
06/17/2022 03:33:29 - INFO - __main__ - ['Film']
06/17/2022 03:33:29 - INFO - __main__ -  [dbpedia_14] Naga Bonar Jadi 2 (Naga Bonar Becomes 2) is 2007 comedy film directed by Deddy Mizwar. It is starring Deddy Mizwar Tora Sudiro Lukman Sardi Darius Sinathrya and Michael Muliardo. It is a sequel to the Indonesian film Nagabonar (1987).
06/17/2022 03:33:29 - INFO - __main__ - ['Film']
06/17/2022 03:33:29 - INFO - __main__ -  [dbpedia_14] La Garce is a 1984 French thriller film directed by Christine Pascal and starring Isabelle Huppert.
06/17/2022 03:33:29 - INFO - __main__ - ['Film']
06/17/2022 03:33:29 - INFO - __main__ - Tokenizing Input ...
06/17/2022 03:33:30 - INFO - __main__ - Tokenizing Output ...
06/17/2022 03:33:31 - INFO - __main__ - Loaded 1792 examples from dev data
06/17/2022 03:33:48 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 03:33:48 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/17/2022 03:33:48 - INFO - __main__ - Starting training!
06/17/2022 03:34:09 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.8073352838858888 on epoch=26
06/17/2022 03:34:09 - INFO - __main__ - save last model!
06/17/2022 03:34:09 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/17/2022 03:34:09 - INFO - __main__ - Start tokenizing ... 3500 instances
06/17/2022 03:34:09 - INFO - __main__ - Printing 3 examples
06/17/2022 03:34:09 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/17/2022 03:34:09 - INFO - __main__ - ['Animal']
06/17/2022 03:34:09 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/17/2022 03:34:09 - INFO - __main__ - ['Animal']
06/17/2022 03:34:09 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/17/2022 03:34:09 - INFO - __main__ - ['Village']
06/17/2022 03:34:09 - INFO - __main__ - Tokenizing Input ...
06/17/2022 03:34:11 - INFO - __main__ - Tokenizing Output ...
06/17/2022 03:34:14 - INFO - __main__ - Loaded 3500 examples from test data
06/17/2022 03:36:18 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down128shot/singletask-dbpedia_14/dbpedia_14_128_87_0.5_8_predictions.txt
06/17/2022 03:36:18 - INFO - __main__ - Classification-F1 on test data: 0.6473
06/17/2022 03:36:19 - INFO - __main__ - prefix=dbpedia_14_128_87, lr=0.5, bsz=8, dev_performance=0.9877246152533369, test_performance=0.6472724863221855
06/17/2022 03:36:19 - INFO - __main__ - Running ... prefix=dbpedia_14_128_87, lr=0.4, bsz=8 ...
06/17/2022 03:36:19 - INFO - __main__ - Start tokenizing ... 1792 instances
06/17/2022 03:36:20 - INFO - __main__ - Printing 3 examples
06/17/2022 03:36:20 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
06/17/2022 03:36:20 - INFO - __main__ - ['Film']
06/17/2022 03:36:20 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/17/2022 03:36:20 - INFO - __main__ - ['Film']
06/17/2022 03:36:20 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/17/2022 03:36:20 - INFO - __main__ - ['Film']
06/17/2022 03:36:20 - INFO - __main__ - Tokenizing Input ...
06/17/2022 03:36:20 - INFO - __main__ - Tokenizing Output ...
06/17/2022 03:36:22 - INFO - __main__ - Loaded 1792 examples from train data
06/17/2022 03:36:22 - INFO - __main__ - Start tokenizing ... 1792 instances
06/17/2022 03:36:22 - INFO - __main__ - Printing 3 examples
06/17/2022 03:36:22 - INFO - __main__ -  [dbpedia_14] The Debt is a 2011 American/British drama-thriller film directed by John Madden from a screenplay by Matthew Vaughn Jane Goldman and Peter Straughan. It stars Helen Mirren Sam Worthington Jessica Chastain Ciarán Hinds Tom Wilkinson Marton Csokas and Jesper Christensen. It's a remake of the 2007 Israeli film Ha-Hov directed by Assaf BernsteinOriginally scheduled for a December 2010 release the film was released in the United States on August 31 2011.
06/17/2022 03:36:22 - INFO - __main__ - ['Film']
06/17/2022 03:36:22 - INFO - __main__ -  [dbpedia_14] Naga Bonar Jadi 2 (Naga Bonar Becomes 2) is 2007 comedy film directed by Deddy Mizwar. It is starring Deddy Mizwar Tora Sudiro Lukman Sardi Darius Sinathrya and Michael Muliardo. It is a sequel to the Indonesian film Nagabonar (1987).
06/17/2022 03:36:22 - INFO - __main__ - ['Film']
06/17/2022 03:36:22 - INFO - __main__ -  [dbpedia_14] La Garce is a 1984 French thriller film directed by Christine Pascal and starring Isabelle Huppert.
06/17/2022 03:36:22 - INFO - __main__ - ['Film']
06/17/2022 03:36:22 - INFO - __main__ - Tokenizing Input ...
06/17/2022 03:36:23 - INFO - __main__ - Tokenizing Output ...
06/17/2022 03:36:25 - INFO - __main__ - Loaded 1792 examples from dev data
06/17/2022 03:36:44 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 03:36:44 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/17/2022 03:36:44 - INFO - __main__ - Starting training!
06/17/2022 03:36:48 - INFO - __main__ - Step 10 Global step 10 Train loss 4.40 on epoch=0
06/17/2022 03:36:51 - INFO - __main__ - Step 20 Global step 20 Train loss 2.80 on epoch=0
06/17/2022 03:36:53 - INFO - __main__ - Step 30 Global step 30 Train loss 2.10 on epoch=0
06/17/2022 03:36:56 - INFO - __main__ - Step 40 Global step 40 Train loss 1.33 on epoch=0
06/17/2022 03:36:58 - INFO - __main__ - Step 50 Global step 50 Train loss 1.20 on epoch=0
06/17/2022 03:37:43 - INFO - __main__ - Global step 50 Train loss 2.37 Classification-F1 0.14524459687244254 on epoch=0
06/17/2022 03:37:43 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.14524459687244254 on epoch=0, global_step=50
06/17/2022 03:37:45 - INFO - __main__ - Step 60 Global step 60 Train loss 0.97 on epoch=0
06/17/2022 03:37:48 - INFO - __main__ - Step 70 Global step 70 Train loss 0.81 on epoch=0
06/17/2022 03:37:50 - INFO - __main__ - Step 80 Global step 80 Train loss 0.83 on epoch=0
06/17/2022 03:37:53 - INFO - __main__ - Step 90 Global step 90 Train loss 0.83 on epoch=0
06/17/2022 03:37:55 - INFO - __main__ - Step 100 Global step 100 Train loss 0.68 on epoch=0
06/17/2022 03:38:48 - INFO - __main__ - Global step 100 Train loss 0.82 Classification-F1 0.23639967990534572 on epoch=0
06/17/2022 03:38:48 - INFO - __main__ - Saving model with best Classification-F1: 0.14524459687244254 -> 0.23639967990534572 on epoch=0, global_step=100
06/17/2022 03:38:51 - INFO - __main__ - Step 110 Global step 110 Train loss 0.77 on epoch=0
06/17/2022 03:38:53 - INFO - __main__ - Step 120 Global step 120 Train loss 0.52 on epoch=1
06/17/2022 03:38:56 - INFO - __main__ - Step 130 Global step 130 Train loss 0.49 on epoch=1
06/17/2022 03:38:59 - INFO - __main__ - Step 140 Global step 140 Train loss 0.54 on epoch=1
06/17/2022 03:39:01 - INFO - __main__ - Step 150 Global step 150 Train loss 0.44 on epoch=1
06/17/2022 03:39:55 - INFO - __main__ - Global step 150 Train loss 0.55 Classification-F1 0.3912916867387755 on epoch=1
06/17/2022 03:39:55 - INFO - __main__ - Saving model with best Classification-F1: 0.23639967990534572 -> 0.3912916867387755 on epoch=1, global_step=150
06/17/2022 03:39:57 - INFO - __main__ - Step 160 Global step 160 Train loss 0.56 on epoch=1
06/17/2022 03:40:00 - INFO - __main__ - Step 170 Global step 170 Train loss 0.44 on epoch=1
06/17/2022 03:40:03 - INFO - __main__ - Step 180 Global step 180 Train loss 0.45 on epoch=1
06/17/2022 03:40:05 - INFO - __main__ - Step 190 Global step 190 Train loss 0.41 on epoch=1
06/17/2022 03:40:08 - INFO - __main__ - Step 200 Global step 200 Train loss 0.44 on epoch=1
06/17/2022 03:41:03 - INFO - __main__ - Global step 200 Train loss 0.46 Classification-F1 0.48392198029401834 on epoch=1
06/17/2022 03:41:03 - INFO - __main__ - Saving model with best Classification-F1: 0.3912916867387755 -> 0.48392198029401834 on epoch=1, global_step=200
06/17/2022 03:41:06 - INFO - __main__ - Step 210 Global step 210 Train loss 0.32 on epoch=1
06/17/2022 03:41:08 - INFO - __main__ - Step 220 Global step 220 Train loss 0.45 on epoch=1
06/17/2022 03:41:11 - INFO - __main__ - Step 230 Global step 230 Train loss 0.25 on epoch=2
06/17/2022 03:41:14 - INFO - __main__ - Step 240 Global step 240 Train loss 0.29 on epoch=2
06/17/2022 03:41:16 - INFO - __main__ - Step 250 Global step 250 Train loss 0.31 on epoch=2
06/17/2022 03:42:13 - INFO - __main__ - Global step 250 Train loss 0.32 Classification-F1 0.5311780994789972 on epoch=2
06/17/2022 03:42:13 - INFO - __main__ - Saving model with best Classification-F1: 0.48392198029401834 -> 0.5311780994789972 on epoch=2, global_step=250
06/17/2022 03:42:15 - INFO - __main__ - Step 260 Global step 260 Train loss 0.30 on epoch=2
06/17/2022 03:42:18 - INFO - __main__ - Step 270 Global step 270 Train loss 0.35 on epoch=2
06/17/2022 03:42:20 - INFO - __main__ - Step 280 Global step 280 Train loss 0.29 on epoch=2
06/17/2022 03:42:23 - INFO - __main__ - Step 290 Global step 290 Train loss 0.19 on epoch=2
06/17/2022 03:42:25 - INFO - __main__ - Step 300 Global step 300 Train loss 0.26 on epoch=2
06/17/2022 03:43:22 - INFO - __main__ - Global step 300 Train loss 0.28 Classification-F1 0.5349560253545966 on epoch=2
06/17/2022 03:43:22 - INFO - __main__ - Saving model with best Classification-F1: 0.5311780994789972 -> 0.5349560253545966 on epoch=2, global_step=300
06/17/2022 03:43:25 - INFO - __main__ - Step 310 Global step 310 Train loss 0.26 on epoch=2
06/17/2022 03:43:27 - INFO - __main__ - Step 320 Global step 320 Train loss 0.27 on epoch=2
06/17/2022 03:43:30 - INFO - __main__ - Step 330 Global step 330 Train loss 0.23 on epoch=2
06/17/2022 03:43:32 - INFO - __main__ - Step 340 Global step 340 Train loss 0.27 on epoch=3
06/17/2022 03:43:35 - INFO - __main__ - Step 350 Global step 350 Train loss 0.17 on epoch=3
06/17/2022 03:44:31 - INFO - __main__ - Global step 350 Train loss 0.24 Classification-F1 0.41145576410195456 on epoch=3
06/17/2022 03:44:33 - INFO - __main__ - Step 360 Global step 360 Train loss 0.20 on epoch=3
06/17/2022 03:44:36 - INFO - __main__ - Step 370 Global step 370 Train loss 0.15 on epoch=3
06/17/2022 03:44:38 - INFO - __main__ - Step 380 Global step 380 Train loss 0.16 on epoch=3
06/17/2022 03:44:41 - INFO - __main__ - Step 390 Global step 390 Train loss 0.11 on epoch=3
06/17/2022 03:44:43 - INFO - __main__ - Step 400 Global step 400 Train loss 0.24 on epoch=3
06/17/2022 03:45:38 - INFO - __main__ - Global step 400 Train loss 0.17 Classification-F1 0.4530600451991176 on epoch=3
06/17/2022 03:45:40 - INFO - __main__ - Step 410 Global step 410 Train loss 0.24 on epoch=3
06/17/2022 03:45:43 - INFO - __main__ - Step 420 Global step 420 Train loss 0.26 on epoch=3
06/17/2022 03:45:45 - INFO - __main__ - Step 430 Global step 430 Train loss 0.20 on epoch=3
06/17/2022 03:45:48 - INFO - __main__ - Step 440 Global step 440 Train loss 0.14 on epoch=3
06/17/2022 03:45:51 - INFO - __main__ - Step 450 Global step 450 Train loss 0.23 on epoch=4
06/17/2022 03:46:49 - INFO - __main__ - Global step 450 Train loss 0.22 Classification-F1 0.5161472699682007 on epoch=4
06/17/2022 03:46:52 - INFO - __main__ - Step 460 Global step 460 Train loss 0.11 on epoch=4
06/17/2022 03:46:54 - INFO - __main__ - Step 470 Global step 470 Train loss 0.12 on epoch=4
06/17/2022 03:46:57 - INFO - __main__ - Step 480 Global step 480 Train loss 0.17 on epoch=4
06/17/2022 03:47:00 - INFO - __main__ - Step 490 Global step 490 Train loss 0.16 on epoch=4
06/17/2022 03:47:02 - INFO - __main__ - Step 500 Global step 500 Train loss 0.12 on epoch=4
06/17/2022 03:47:51 - INFO - __main__ - Global step 500 Train loss 0.13 Classification-F1 0.4975555587603088 on epoch=4
06/17/2022 03:47:53 - INFO - __main__ - Step 510 Global step 510 Train loss 0.14 on epoch=4
06/17/2022 03:47:56 - INFO - __main__ - Step 520 Global step 520 Train loss 0.13 on epoch=4
06/17/2022 03:47:58 - INFO - __main__ - Step 530 Global step 530 Train loss 0.15 on epoch=4
06/17/2022 03:48:01 - INFO - __main__ - Step 540 Global step 540 Train loss 0.15 on epoch=4
06/17/2022 03:48:03 - INFO - __main__ - Step 550 Global step 550 Train loss 0.06 on epoch=4
06/17/2022 03:48:54 - INFO - __main__ - Global step 550 Train loss 0.13 Classification-F1 0.6198357484236968 on epoch=4
06/17/2022 03:48:54 - INFO - __main__ - Saving model with best Classification-F1: 0.5349560253545966 -> 0.6198357484236968 on epoch=4, global_step=550
06/17/2022 03:48:57 - INFO - __main__ - Step 560 Global step 560 Train loss 0.19 on epoch=4
06/17/2022 03:48:59 - INFO - __main__ - Step 570 Global step 570 Train loss 0.13 on epoch=5
06/17/2022 03:49:02 - INFO - __main__ - Step 580 Global step 580 Train loss 0.14 on epoch=5
06/17/2022 03:49:04 - INFO - __main__ - Step 590 Global step 590 Train loss 0.19 on epoch=5
06/17/2022 03:49:07 - INFO - __main__ - Step 600 Global step 600 Train loss 0.13 on epoch=5
06/17/2022 03:49:59 - INFO - __main__ - Global step 600 Train loss 0.15 Classification-F1 0.6336830714298103 on epoch=5
06/17/2022 03:49:59 - INFO - __main__ - Saving model with best Classification-F1: 0.6198357484236968 -> 0.6336830714298103 on epoch=5, global_step=600
06/17/2022 03:50:02 - INFO - __main__ - Step 610 Global step 610 Train loss 0.17 on epoch=5
06/17/2022 03:50:04 - INFO - __main__ - Step 620 Global step 620 Train loss 0.08 on epoch=5
06/17/2022 03:50:07 - INFO - __main__ - Step 630 Global step 630 Train loss 0.08 on epoch=5
06/17/2022 03:50:09 - INFO - __main__ - Step 640 Global step 640 Train loss 0.11 on epoch=5
06/17/2022 03:50:12 - INFO - __main__ - Step 650 Global step 650 Train loss 0.13 on epoch=5
06/17/2022 03:51:08 - INFO - __main__ - Global step 650 Train loss 0.11 Classification-F1 0.6486918456261408 on epoch=5
06/17/2022 03:51:09 - INFO - __main__ - Saving model with best Classification-F1: 0.6336830714298103 -> 0.6486918456261408 on epoch=5, global_step=650
06/17/2022 03:51:11 - INFO - __main__ - Step 660 Global step 660 Train loss 0.12 on epoch=5
06/17/2022 03:51:14 - INFO - __main__ - Step 670 Global step 670 Train loss 0.10 on epoch=5
06/17/2022 03:51:16 - INFO - __main__ - Step 680 Global step 680 Train loss 0.09 on epoch=6
06/17/2022 03:51:19 - INFO - __main__ - Step 690 Global step 690 Train loss 0.08 on epoch=6
06/17/2022 03:51:21 - INFO - __main__ - Step 700 Global step 700 Train loss 0.10 on epoch=6
06/17/2022 03:52:14 - INFO - __main__ - Global step 700 Train loss 0.09 Classification-F1 0.5650797800138657 on epoch=6
06/17/2022 03:52:17 - INFO - __main__ - Step 710 Global step 710 Train loss 0.08 on epoch=6
06/17/2022 03:52:19 - INFO - __main__ - Step 720 Global step 720 Train loss 0.14 on epoch=6
06/17/2022 03:52:22 - INFO - __main__ - Step 730 Global step 730 Train loss 0.10 on epoch=6
06/17/2022 03:52:24 - INFO - __main__ - Step 740 Global step 740 Train loss 0.10 on epoch=6
06/17/2022 03:52:27 - INFO - __main__ - Step 750 Global step 750 Train loss 0.09 on epoch=6
06/17/2022 03:53:16 - INFO - __main__ - Global step 750 Train loss 0.10 Classification-F1 0.46241321611767855 on epoch=6
06/17/2022 03:53:19 - INFO - __main__ - Step 760 Global step 760 Train loss 0.08 on epoch=6
06/17/2022 03:53:21 - INFO - __main__ - Step 770 Global step 770 Train loss 0.07 on epoch=6
06/17/2022 03:53:24 - INFO - __main__ - Step 780 Global step 780 Train loss 0.12 on epoch=6
06/17/2022 03:53:26 - INFO - __main__ - Step 790 Global step 790 Train loss 0.16 on epoch=7
06/17/2022 03:53:29 - INFO - __main__ - Step 800 Global step 800 Train loss 0.04 on epoch=7
06/17/2022 03:54:24 - INFO - __main__ - Global step 800 Train loss 0.10 Classification-F1 0.7433126314608286 on epoch=7
06/17/2022 03:54:24 - INFO - __main__ - Saving model with best Classification-F1: 0.6486918456261408 -> 0.7433126314608286 on epoch=7, global_step=800
06/17/2022 03:54:27 - INFO - __main__ - Step 810 Global step 810 Train loss 0.06 on epoch=7
06/17/2022 03:54:29 - INFO - __main__ - Step 820 Global step 820 Train loss 0.12 on epoch=7
06/17/2022 03:54:32 - INFO - __main__ - Step 830 Global step 830 Train loss 0.10 on epoch=7
06/17/2022 03:54:34 - INFO - __main__ - Step 840 Global step 840 Train loss 0.06 on epoch=7
06/17/2022 03:54:37 - INFO - __main__ - Step 850 Global step 850 Train loss 0.12 on epoch=7
06/17/2022 03:55:27 - INFO - __main__ - Global step 850 Train loss 0.09 Classification-F1 0.6357938914472067 on epoch=7
06/17/2022 03:55:29 - INFO - __main__ - Step 860 Global step 860 Train loss 0.05 on epoch=7
06/17/2022 03:55:32 - INFO - __main__ - Step 870 Global step 870 Train loss 0.11 on epoch=7
06/17/2022 03:55:34 - INFO - __main__ - Step 880 Global step 880 Train loss 0.07 on epoch=7
06/17/2022 03:55:37 - INFO - __main__ - Step 890 Global step 890 Train loss 0.23 on epoch=7
06/17/2022 03:55:39 - INFO - __main__ - Step 900 Global step 900 Train loss 0.12 on epoch=8
06/17/2022 03:56:29 - INFO - __main__ - Global step 900 Train loss 0.12 Classification-F1 0.6396485301454524 on epoch=8
06/17/2022 03:56:31 - INFO - __main__ - Step 910 Global step 910 Train loss 0.05 on epoch=8
06/17/2022 03:56:34 - INFO - __main__ - Step 920 Global step 920 Train loss 0.07 on epoch=8
06/17/2022 03:56:37 - INFO - __main__ - Step 930 Global step 930 Train loss 0.11 on epoch=8
06/17/2022 03:56:39 - INFO - __main__ - Step 940 Global step 940 Train loss 0.08 on epoch=8
06/17/2022 03:56:42 - INFO - __main__ - Step 950 Global step 950 Train loss 0.09 on epoch=8
06/17/2022 03:57:29 - INFO - __main__ - Global step 950 Train loss 0.08 Classification-F1 0.47839140381705386 on epoch=8
06/17/2022 03:57:32 - INFO - __main__ - Step 960 Global step 960 Train loss 0.08 on epoch=8
06/17/2022 03:57:35 - INFO - __main__ - Step 970 Global step 970 Train loss 0.06 on epoch=8
06/17/2022 03:57:37 - INFO - __main__ - Step 980 Global step 980 Train loss 0.11 on epoch=8
06/17/2022 03:57:40 - INFO - __main__ - Step 990 Global step 990 Train loss 0.09 on epoch=8
06/17/2022 03:57:42 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.07 on epoch=8
06/17/2022 03:58:31 - INFO - __main__ - Global step 1000 Train loss 0.08 Classification-F1 0.6130784588582101 on epoch=8
06/17/2022 03:58:33 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.11 on epoch=9
06/17/2022 03:58:36 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.04 on epoch=9
06/17/2022 03:58:38 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.07 on epoch=9
06/17/2022 03:58:41 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.10 on epoch=9
06/17/2022 03:58:43 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.10 on epoch=9
06/17/2022 03:59:33 - INFO - __main__ - Global step 1050 Train loss 0.08 Classification-F1 0.6023321311490908 on epoch=9
06/17/2022 03:59:35 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.07 on epoch=9
06/17/2022 03:59:38 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.04 on epoch=9
06/17/2022 03:59:40 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.05 on epoch=9
06/17/2022 03:59:43 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.05 on epoch=9
06/17/2022 03:59:45 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.05 on epoch=9
06/17/2022 04:00:36 - INFO - __main__ - Global step 1100 Train loss 0.05 Classification-F1 0.7062243593214504 on epoch=9
06/17/2022 04:00:38 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.07 on epoch=9
06/17/2022 04:00:41 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.16 on epoch=9
06/17/2022 04:00:43 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.09 on epoch=10
06/17/2022 04:00:46 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.06 on epoch=10
06/17/2022 04:00:48 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.10 on epoch=10
06/17/2022 04:01:42 - INFO - __main__ - Global step 1150 Train loss 0.10 Classification-F1 0.7769943125952042 on epoch=10
06/17/2022 04:01:42 - INFO - __main__ - Saving model with best Classification-F1: 0.7433126314608286 -> 0.7769943125952042 on epoch=10, global_step=1150
06/17/2022 04:01:45 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.05 on epoch=10
06/17/2022 04:01:47 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.05 on epoch=10
06/17/2022 04:01:50 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.04 on epoch=10
06/17/2022 04:01:52 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.08 on epoch=10
06/17/2022 04:01:55 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.13 on epoch=10
06/17/2022 04:02:42 - INFO - __main__ - Global step 1200 Train loss 0.07 Classification-F1 0.5810817070895536 on epoch=10
06/17/2022 04:02:44 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.07 on epoch=10
06/17/2022 04:02:47 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.02 on epoch=10
06/17/2022 04:02:49 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.08 on epoch=10
06/17/2022 04:02:52 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.02 on epoch=11
06/17/2022 04:02:54 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.03 on epoch=11
06/17/2022 04:03:44 - INFO - __main__ - Global step 1250 Train loss 0.05 Classification-F1 0.7889693532279938 on epoch=11
06/17/2022 04:03:44 - INFO - __main__ - Saving model with best Classification-F1: 0.7769943125952042 -> 0.7889693532279938 on epoch=11, global_step=1250
06/17/2022 04:03:47 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.09 on epoch=11
06/17/2022 04:03:49 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.06 on epoch=11
06/17/2022 04:03:52 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.08 on epoch=11
06/17/2022 04:03:54 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.02 on epoch=11
06/17/2022 04:03:57 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.04 on epoch=11
06/17/2022 04:04:45 - INFO - __main__ - Global step 1300 Train loss 0.06 Classification-F1 0.7966013982137042 on epoch=11
06/17/2022 04:04:45 - INFO - __main__ - Saving model with best Classification-F1: 0.7889693532279938 -> 0.7966013982137042 on epoch=11, global_step=1300
06/17/2022 04:04:47 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.03 on epoch=11
06/17/2022 04:04:50 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.05 on epoch=11
06/17/2022 04:04:52 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.05 on epoch=11
06/17/2022 04:04:55 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.06 on epoch=11
06/17/2022 04:04:58 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.04 on epoch=12
06/17/2022 04:05:47 - INFO - __main__ - Global step 1350 Train loss 0.05 Classification-F1 0.7252898810875298 on epoch=12
06/17/2022 04:05:50 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.05 on epoch=12
06/17/2022 04:05:52 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.06 on epoch=12
06/17/2022 04:05:55 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.10 on epoch=12
06/17/2022 04:05:57 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.05 on epoch=12
06/17/2022 04:06:00 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=12
06/17/2022 04:06:50 - INFO - __main__ - Global step 1400 Train loss 0.06 Classification-F1 0.7236304586760728 on epoch=12
06/17/2022 04:06:52 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.10 on epoch=12
06/17/2022 04:06:55 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.05 on epoch=12
06/17/2022 04:06:57 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.05 on epoch=12
06/17/2022 04:07:00 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.04 on epoch=12
06/17/2022 04:07:03 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.04 on epoch=12
06/17/2022 04:07:54 - INFO - __main__ - Global step 1450 Train loss 0.06 Classification-F1 0.8016564066813702 on epoch=12
06/17/2022 04:07:54 - INFO - __main__ - Saving model with best Classification-F1: 0.7966013982137042 -> 0.8016564066813702 on epoch=12, global_step=1450
06/17/2022 04:07:56 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.06 on epoch=13
06/17/2022 04:07:59 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.04 on epoch=13
06/17/2022 04:08:01 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.04 on epoch=13
06/17/2022 04:08:04 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.02 on epoch=13
06/17/2022 04:08:07 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.07 on epoch=13
06/17/2022 04:08:56 - INFO - __main__ - Global step 1500 Train loss 0.05 Classification-F1 0.6788686783812838 on epoch=13
06/17/2022 04:08:58 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.05 on epoch=13
06/17/2022 04:09:01 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.06 on epoch=13
06/17/2022 04:09:03 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.04 on epoch=13
06/17/2022 04:09:06 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=13
06/17/2022 04:09:08 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.05 on epoch=13
06/17/2022 04:09:56 - INFO - __main__ - Global step 1550 Train loss 0.05 Classification-F1 0.7036586851468549 on epoch=13
06/17/2022 04:09:59 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.06 on epoch=13
06/17/2022 04:10:01 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.04 on epoch=14
06/17/2022 04:10:04 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.03 on epoch=14
06/17/2022 04:10:06 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.06 on epoch=14
06/17/2022 04:10:09 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=14
06/17/2022 04:10:58 - INFO - __main__ - Global step 1600 Train loss 0.04 Classification-F1 0.7659783636230162 on epoch=14
06/17/2022 04:11:01 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.05 on epoch=14
06/17/2022 04:11:03 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.04 on epoch=14
06/17/2022 04:11:06 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.03 on epoch=14
06/17/2022 04:11:09 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.02 on epoch=14
06/17/2022 04:11:11 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.04 on epoch=14
06/17/2022 04:11:59 - INFO - __main__ - Global step 1650 Train loss 0.04 Classification-F1 0.810767565788152 on epoch=14
06/17/2022 04:11:59 - INFO - __main__ - Saving model with best Classification-F1: 0.8016564066813702 -> 0.810767565788152 on epoch=14, global_step=1650
06/17/2022 04:12:02 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.06 on epoch=14
06/17/2022 04:12:04 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.03 on epoch=14
06/17/2022 04:12:07 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.04 on epoch=14
06/17/2022 04:12:09 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.03 on epoch=15
06/17/2022 04:12:12 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=15
06/17/2022 04:12:58 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.8001036072229614 on epoch=15
06/17/2022 04:13:01 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.05 on epoch=15
06/17/2022 04:13:03 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.02 on epoch=15
06/17/2022 04:13:06 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.08 on epoch=15
06/17/2022 04:13:09 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=15
06/17/2022 04:13:11 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.06 on epoch=15
06/17/2022 04:13:58 - INFO - __main__ - Global step 1750 Train loss 0.05 Classification-F1 0.8607289148998636 on epoch=15
06/17/2022 04:13:58 - INFO - __main__ - Saving model with best Classification-F1: 0.810767565788152 -> 0.8607289148998636 on epoch=15, global_step=1750
06/17/2022 04:14:00 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.06 on epoch=15
06/17/2022 04:14:03 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.03 on epoch=15
06/17/2022 04:14:06 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=15
06/17/2022 04:14:08 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.15 on epoch=15
06/17/2022 04:14:11 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=16
06/17/2022 04:14:59 - INFO - __main__ - Global step 1800 Train loss 0.06 Classification-F1 0.862479580959722 on epoch=16
06/17/2022 04:14:59 - INFO - __main__ - Saving model with best Classification-F1: 0.8607289148998636 -> 0.862479580959722 on epoch=16, global_step=1800
06/17/2022 04:15:02 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=16
06/17/2022 04:15:04 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.06 on epoch=16
06/17/2022 04:15:07 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.04 on epoch=16
06/17/2022 04:15:09 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.11 on epoch=16
06/17/2022 04:15:12 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.04 on epoch=16
06/17/2022 04:16:01 - INFO - __main__ - Global step 1850 Train loss 0.05 Classification-F1 0.7249061697995997 on epoch=16
06/17/2022 04:16:03 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.07 on epoch=16
06/17/2022 04:16:06 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.07 on epoch=16
06/17/2022 04:16:08 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.03 on epoch=16
06/17/2022 04:16:11 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.04 on epoch=16
06/17/2022 04:16:13 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.05 on epoch=16
06/17/2022 04:17:02 - INFO - __main__ - Global step 1900 Train loss 0.05 Classification-F1 0.8102884107222179 on epoch=16
06/17/2022 04:17:05 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=17
06/17/2022 04:17:08 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=17
06/17/2022 04:17:10 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.04 on epoch=17
06/17/2022 04:17:13 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.06 on epoch=17
06/17/2022 04:17:15 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.07 on epoch=17
06/17/2022 04:18:03 - INFO - __main__ - Global step 1950 Train loss 0.04 Classification-F1 0.8101014994216804 on epoch=17
06/17/2022 04:18:05 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.05 on epoch=17
06/17/2022 04:18:08 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.05 on epoch=17
06/17/2022 04:18:10 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=17
06/17/2022 04:18:13 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.11 on epoch=17
06/17/2022 04:18:16 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.05 on epoch=17
06/17/2022 04:19:02 - INFO - __main__ - Global step 2000 Train loss 0.06 Classification-F1 0.8092104425520331 on epoch=17
06/17/2022 04:19:05 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.03 on epoch=17
06/17/2022 04:19:07 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.04 on epoch=18
06/17/2022 04:19:10 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.05 on epoch=18
06/17/2022 04:19:12 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.06 on epoch=18
06/17/2022 04:19:15 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.08 on epoch=18
06/17/2022 04:20:02 - INFO - __main__ - Global step 2050 Train loss 0.05 Classification-F1 0.6821655273492218 on epoch=18
06/17/2022 04:20:04 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.05 on epoch=18
06/17/2022 04:20:07 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.05 on epoch=18
06/17/2022 04:20:09 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.08 on epoch=18
06/17/2022 04:20:12 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.04 on epoch=18
06/17/2022 04:20:15 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.06 on epoch=18
06/17/2022 04:21:02 - INFO - __main__ - Global step 2100 Train loss 0.06 Classification-F1 0.7624700174973168 on epoch=18
06/17/2022 04:21:04 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=18
06/17/2022 04:21:07 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.04 on epoch=18
06/17/2022 04:21:09 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.05 on epoch=19
06/17/2022 04:21:12 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=19
06/17/2022 04:21:14 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.03 on epoch=19
06/17/2022 04:22:02 - INFO - __main__ - Global step 2150 Train loss 0.03 Classification-F1 0.8430852334389908 on epoch=19
06/17/2022 04:22:05 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.04 on epoch=19
06/17/2022 04:22:07 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.06 on epoch=19
06/17/2022 04:22:10 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=19
06/17/2022 04:22:12 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.06 on epoch=19
06/17/2022 04:22:15 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.04 on epoch=19
06/17/2022 04:23:02 - INFO - __main__ - Global step 2200 Train loss 0.05 Classification-F1 0.8632271792565631 on epoch=19
06/17/2022 04:23:02 - INFO - __main__ - Saving model with best Classification-F1: 0.862479580959722 -> 0.8632271792565631 on epoch=19, global_step=2200
06/17/2022 04:23:04 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=19
06/17/2022 04:23:07 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.04 on epoch=19
06/17/2022 04:23:09 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.07 on epoch=19
06/17/2022 04:23:12 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=19
06/17/2022 04:23:15 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=20
06/17/2022 04:24:00 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.861470626023957 on epoch=20
06/17/2022 04:24:03 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.03 on epoch=20
06/17/2022 04:24:05 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=20
06/17/2022 04:24:08 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.04 on epoch=20
06/17/2022 04:24:10 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.03 on epoch=20
06/17/2022 04:24:13 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=20
06/17/2022 04:25:01 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.8045186662098951 on epoch=20
06/17/2022 04:25:04 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=20
06/17/2022 04:25:07 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.09 on epoch=20
06/17/2022 04:25:09 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=20
06/17/2022 04:25:12 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=20
06/17/2022 04:25:14 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=20
06/17/2022 04:26:00 - INFO - __main__ - Global step 2350 Train loss 0.04 Classification-F1 0.809351141572358 on epoch=20
06/17/2022 04:26:03 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.04 on epoch=21
06/17/2022 04:26:05 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.03 on epoch=21
06/17/2022 04:26:08 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.04 on epoch=21
06/17/2022 04:26:10 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=21
06/17/2022 04:26:13 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=21
06/17/2022 04:27:00 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.9183488393550218 on epoch=21
06/17/2022 04:27:00 - INFO - __main__ - Saving model with best Classification-F1: 0.8632271792565631 -> 0.9183488393550218 on epoch=21, global_step=2400
06/17/2022 04:27:03 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.03 on epoch=21
06/17/2022 04:27:05 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.03 on epoch=21
06/17/2022 04:27:08 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.08 on epoch=21
06/17/2022 04:27:10 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=21
06/17/2022 04:27:13 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.05 on epoch=21
06/17/2022 04:28:00 - INFO - __main__ - Global step 2450 Train loss 0.04 Classification-F1 0.9151617409655164 on epoch=21
06/17/2022 04:28:03 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.14 on epoch=21
06/17/2022 04:28:06 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.06 on epoch=22
06/17/2022 04:28:08 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=22
06/17/2022 04:28:11 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.05 on epoch=22
06/17/2022 04:28:13 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.04 on epoch=22
06/17/2022 04:29:00 - INFO - __main__ - Global step 2500 Train loss 0.06 Classification-F1 0.8616824504033533 on epoch=22
06/17/2022 04:29:02 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=22
06/17/2022 04:29:05 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=22
06/17/2022 04:29:07 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.03 on epoch=22
06/17/2022 04:29:10 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.04 on epoch=22
06/17/2022 04:29:12 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=22
06/17/2022 04:30:00 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.8617081999012716 on epoch=22
06/17/2022 04:30:03 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.04 on epoch=22
06/17/2022 04:30:05 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.07 on epoch=22
06/17/2022 04:30:08 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.03 on epoch=23
06/17/2022 04:30:10 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=23
06/17/2022 04:30:13 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.05 on epoch=23
06/17/2022 04:31:00 - INFO - __main__ - Global step 2600 Train loss 0.04 Classification-F1 0.8565891284963276 on epoch=23
06/17/2022 04:31:02 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.04 on epoch=23
06/17/2022 04:31:05 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.04 on epoch=23
06/17/2022 04:31:08 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=23
06/17/2022 04:31:10 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=23
06/17/2022 04:31:13 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.03 on epoch=23
06/17/2022 04:32:01 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.7645355399308307 on epoch=23
06/17/2022 04:32:04 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=23
06/17/2022 04:32:06 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.03 on epoch=23
06/17/2022 04:32:09 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=23
06/17/2022 04:32:11 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.13 on epoch=24
06/17/2022 04:32:14 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=24
06/17/2022 04:33:00 - INFO - __main__ - Global step 2700 Train loss 0.05 Classification-F1 0.9209646752518418 on epoch=24
06/17/2022 04:33:01 - INFO - __main__ - Saving model with best Classification-F1: 0.9183488393550218 -> 0.9209646752518418 on epoch=24, global_step=2700
06/17/2022 04:33:03 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.03 on epoch=24
06/17/2022 04:33:06 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.03 on epoch=24
06/17/2022 04:33:08 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.05 on epoch=24
06/17/2022 04:33:11 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=24
06/17/2022 04:33:13 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=24
06/17/2022 04:34:02 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.9174171534432879 on epoch=24
06/17/2022 04:34:04 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.04 on epoch=24
06/17/2022 04:34:07 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=24
06/17/2022 04:34:10 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=24
06/17/2022 04:34:12 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=24
06/17/2022 04:34:15 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=24
06/17/2022 04:35:02 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.858210822092826 on epoch=24
06/17/2022 04:35:05 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=25
06/17/2022 04:35:08 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.03 on epoch=25
06/17/2022 04:35:10 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=25
06/17/2022 04:35:13 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.03 on epoch=25
06/17/2022 04:35:15 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=25
06/17/2022 04:36:03 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.7638020875862055 on epoch=25
06/17/2022 04:36:05 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=25
06/17/2022 04:36:08 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.09 on epoch=25
06/17/2022 04:36:10 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=25
06/17/2022 04:36:13 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=25
06/17/2022 04:36:15 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=25
06/17/2022 04:37:01 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.7604233758920634 on epoch=25
06/17/2022 04:37:04 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=25
06/17/2022 04:37:06 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=26
06/17/2022 04:37:09 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=26
06/17/2022 04:37:11 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.05 on epoch=26
06/17/2022 04:37:14 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=26
06/17/2022 04:38:02 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.6669950169958614 on epoch=26
06/17/2022 04:38:04 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=26
06/17/2022 04:38:07 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=26
06/17/2022 04:38:09 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.06 on epoch=26
06/17/2022 04:38:12 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=26
06/17/2022 04:38:14 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=26
06/17/2022 04:38:16 - INFO - __main__ - Start tokenizing ... 1792 instances
06/17/2022 04:38:16 - INFO - __main__ - Printing 3 examples
06/17/2022 04:38:16 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
06/17/2022 04:38:16 - INFO - __main__ - ['Film']
06/17/2022 04:38:16 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/17/2022 04:38:16 - INFO - __main__ - ['Film']
06/17/2022 04:38:16 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/17/2022 04:38:16 - INFO - __main__ - ['Film']
06/17/2022 04:38:16 - INFO - __main__ - Tokenizing Input ...
06/17/2022 04:38:17 - INFO - __main__ - Tokenizing Output ...
06/17/2022 04:38:19 - INFO - __main__ - Loaded 1792 examples from train data
06/17/2022 04:38:19 - INFO - __main__ - Start tokenizing ... 1792 instances
06/17/2022 04:38:19 - INFO - __main__ - Printing 3 examples
06/17/2022 04:38:19 - INFO - __main__ -  [dbpedia_14] The Debt is a 2011 American/British drama-thriller film directed by John Madden from a screenplay by Matthew Vaughn Jane Goldman and Peter Straughan. It stars Helen Mirren Sam Worthington Jessica Chastain Ciarán Hinds Tom Wilkinson Marton Csokas and Jesper Christensen. It's a remake of the 2007 Israeli film Ha-Hov directed by Assaf BernsteinOriginally scheduled for a December 2010 release the film was released in the United States on August 31 2011.
06/17/2022 04:38:19 - INFO - __main__ - ['Film']
06/17/2022 04:38:19 - INFO - __main__ -  [dbpedia_14] Naga Bonar Jadi 2 (Naga Bonar Becomes 2) is 2007 comedy film directed by Deddy Mizwar. It is starring Deddy Mizwar Tora Sudiro Lukman Sardi Darius Sinathrya and Michael Muliardo. It is a sequel to the Indonesian film Nagabonar (1987).
06/17/2022 04:38:19 - INFO - __main__ - ['Film']
06/17/2022 04:38:19 - INFO - __main__ -  [dbpedia_14] La Garce is a 1984 French thriller film directed by Christine Pascal and starring Isabelle Huppert.
06/17/2022 04:38:19 - INFO - __main__ - ['Film']
06/17/2022 04:38:19 - INFO - __main__ - Tokenizing Input ...
06/17/2022 04:38:20 - INFO - __main__ - Tokenizing Output ...
06/17/2022 04:38:21 - INFO - __main__ - Loaded 1792 examples from dev data
06/17/2022 04:38:38 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 04:38:38 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/17/2022 04:38:38 - INFO - __main__ - Starting training!
06/17/2022 04:39:01 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.8529423305428585 on epoch=26
06/17/2022 04:39:01 - INFO - __main__ - save last model!
06/17/2022 04:39:01 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/17/2022 04:39:01 - INFO - __main__ - Start tokenizing ... 3500 instances
06/17/2022 04:39:01 - INFO - __main__ - Printing 3 examples
06/17/2022 04:39:01 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/17/2022 04:39:01 - INFO - __main__ - ['Animal']
06/17/2022 04:39:01 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/17/2022 04:39:01 - INFO - __main__ - ['Animal']
06/17/2022 04:39:01 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/17/2022 04:39:01 - INFO - __main__ - ['Village']
06/17/2022 04:39:01 - INFO - __main__ - Tokenizing Input ...
06/17/2022 04:39:03 - INFO - __main__ - Tokenizing Output ...
06/17/2022 04:39:07 - INFO - __main__ - Loaded 3500 examples from test data
06/17/2022 04:41:11 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down128shot/singletask-dbpedia_14/dbpedia_14_128_87_0.4_8_predictions.txt
06/17/2022 04:41:11 - INFO - __main__ - Classification-F1 on test data: 0.6768
06/17/2022 04:41:11 - INFO - __main__ - prefix=dbpedia_14_128_87, lr=0.4, bsz=8, dev_performance=0.9209646752518418, test_performance=0.6768214804161933
06/17/2022 04:41:11 - INFO - __main__ - Running ... prefix=dbpedia_14_128_87, lr=0.3, bsz=8 ...
06/17/2022 04:41:12 - INFO - __main__ - Start tokenizing ... 1792 instances
06/17/2022 04:41:12 - INFO - __main__ - Printing 3 examples
06/17/2022 04:41:12 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
06/17/2022 04:41:12 - INFO - __main__ - ['Film']
06/17/2022 04:41:12 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/17/2022 04:41:12 - INFO - __main__ - ['Film']
06/17/2022 04:41:12 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/17/2022 04:41:12 - INFO - __main__ - ['Film']
06/17/2022 04:41:12 - INFO - __main__ - Tokenizing Input ...
06/17/2022 04:41:13 - INFO - __main__ - Tokenizing Output ...
06/17/2022 04:41:15 - INFO - __main__ - Loaded 1792 examples from train data
06/17/2022 04:41:15 - INFO - __main__ - Start tokenizing ... 1792 instances
06/17/2022 04:41:15 - INFO - __main__ - Printing 3 examples
06/17/2022 04:41:15 - INFO - __main__ -  [dbpedia_14] The Debt is a 2011 American/British drama-thriller film directed by John Madden from a screenplay by Matthew Vaughn Jane Goldman and Peter Straughan. It stars Helen Mirren Sam Worthington Jessica Chastain Ciarán Hinds Tom Wilkinson Marton Csokas and Jesper Christensen. It's a remake of the 2007 Israeli film Ha-Hov directed by Assaf BernsteinOriginally scheduled for a December 2010 release the film was released in the United States on August 31 2011.
06/17/2022 04:41:15 - INFO - __main__ - ['Film']
06/17/2022 04:41:15 - INFO - __main__ -  [dbpedia_14] Naga Bonar Jadi 2 (Naga Bonar Becomes 2) is 2007 comedy film directed by Deddy Mizwar. It is starring Deddy Mizwar Tora Sudiro Lukman Sardi Darius Sinathrya and Michael Muliardo. It is a sequel to the Indonesian film Nagabonar (1987).
06/17/2022 04:41:15 - INFO - __main__ - ['Film']
06/17/2022 04:41:15 - INFO - __main__ -  [dbpedia_14] La Garce is a 1984 French thriller film directed by Christine Pascal and starring Isabelle Huppert.
06/17/2022 04:41:15 - INFO - __main__ - ['Film']
06/17/2022 04:41:15 - INFO - __main__ - Tokenizing Input ...
06/17/2022 04:41:16 - INFO - __main__ - Tokenizing Output ...
06/17/2022 04:41:18 - INFO - __main__ - Loaded 1792 examples from dev data
06/17/2022 04:41:36 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 04:41:37 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/17/2022 04:41:37 - INFO - __main__ - Starting training!
06/17/2022 04:41:41 - INFO - __main__ - Step 10 Global step 10 Train loss 4.70 on epoch=0
06/17/2022 04:41:43 - INFO - __main__ - Step 20 Global step 20 Train loss 3.20 on epoch=0
06/17/2022 04:41:46 - INFO - __main__ - Step 30 Global step 30 Train loss 2.24 on epoch=0
06/17/2022 04:41:49 - INFO - __main__ - Step 40 Global step 40 Train loss 1.65 on epoch=0
06/17/2022 04:41:51 - INFO - __main__ - Step 50 Global step 50 Train loss 1.41 on epoch=0
06/17/2022 04:42:36 - INFO - __main__ - Global step 50 Train loss 2.64 Classification-F1 0.08787767863291464 on epoch=0
06/17/2022 04:42:36 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.08787767863291464 on epoch=0, global_step=50
06/17/2022 04:42:38 - INFO - __main__ - Step 60 Global step 60 Train loss 1.24 on epoch=0
06/17/2022 04:42:41 - INFO - __main__ - Step 70 Global step 70 Train loss 1.02 on epoch=0
06/17/2022 04:42:43 - INFO - __main__ - Step 80 Global step 80 Train loss 0.97 on epoch=0
06/17/2022 04:42:46 - INFO - __main__ - Step 90 Global step 90 Train loss 0.98 on epoch=0
06/17/2022 04:42:48 - INFO - __main__ - Step 100 Global step 100 Train loss 0.72 on epoch=0
06/17/2022 04:43:43 - INFO - __main__ - Global step 100 Train loss 0.99 Classification-F1 0.31373659539312293 on epoch=0
06/17/2022 04:43:43 - INFO - __main__ - Saving model with best Classification-F1: 0.08787767863291464 -> 0.31373659539312293 on epoch=0, global_step=100
06/17/2022 04:43:46 - INFO - __main__ - Step 110 Global step 110 Train loss 0.85 on epoch=0
06/17/2022 04:43:48 - INFO - __main__ - Step 120 Global step 120 Train loss 0.66 on epoch=1
06/17/2022 04:43:51 - INFO - __main__ - Step 130 Global step 130 Train loss 0.73 on epoch=1
06/17/2022 04:43:53 - INFO - __main__ - Step 140 Global step 140 Train loss 0.57 on epoch=1
06/17/2022 04:43:56 - INFO - __main__ - Step 150 Global step 150 Train loss 0.54 on epoch=1
06/17/2022 04:44:52 - INFO - __main__ - Global step 150 Train loss 0.67 Classification-F1 0.25456386533953607 on epoch=1
06/17/2022 04:44:55 - INFO - __main__ - Step 160 Global step 160 Train loss 0.62 on epoch=1
06/17/2022 04:44:57 - INFO - __main__ - Step 170 Global step 170 Train loss 0.49 on epoch=1
06/17/2022 04:45:00 - INFO - __main__ - Step 180 Global step 180 Train loss 0.50 on epoch=1
06/17/2022 04:45:02 - INFO - __main__ - Step 190 Global step 190 Train loss 0.59 on epoch=1
06/17/2022 04:45:05 - INFO - __main__ - Step 200 Global step 200 Train loss 0.48 on epoch=1
06/17/2022 04:45:58 - INFO - __main__ - Global step 200 Train loss 0.54 Classification-F1 0.5364194569757706 on epoch=1
06/17/2022 04:45:58 - INFO - __main__ - Saving model with best Classification-F1: 0.31373659539312293 -> 0.5364194569757706 on epoch=1, global_step=200
06/17/2022 04:46:00 - INFO - __main__ - Step 210 Global step 210 Train loss 0.40 on epoch=1
06/17/2022 04:46:03 - INFO - __main__ - Step 220 Global step 220 Train loss 0.51 on epoch=1
06/17/2022 04:46:06 - INFO - __main__ - Step 230 Global step 230 Train loss 0.50 on epoch=2
06/17/2022 04:46:08 - INFO - __main__ - Step 240 Global step 240 Train loss 0.31 on epoch=2
06/17/2022 04:46:11 - INFO - __main__ - Step 250 Global step 250 Train loss 0.36 on epoch=2
06/17/2022 04:47:07 - INFO - __main__ - Global step 250 Train loss 0.41 Classification-F1 0.6619100799328846 on epoch=2
06/17/2022 04:47:07 - INFO - __main__ - Saving model with best Classification-F1: 0.5364194569757706 -> 0.6619100799328846 on epoch=2, global_step=250
06/17/2022 04:47:09 - INFO - __main__ - Step 260 Global step 260 Train loss 0.35 on epoch=2
06/17/2022 04:47:12 - INFO - __main__ - Step 270 Global step 270 Train loss 0.40 on epoch=2
06/17/2022 04:47:14 - INFO - __main__ - Step 280 Global step 280 Train loss 0.39 on epoch=2
06/17/2022 04:47:17 - INFO - __main__ - Step 290 Global step 290 Train loss 0.36 on epoch=2
06/17/2022 04:47:19 - INFO - __main__ - Step 300 Global step 300 Train loss 0.33 on epoch=2
06/17/2022 04:48:21 - INFO - __main__ - Global step 300 Train loss 0.37 Classification-F1 0.5515177734738465 on epoch=2
06/17/2022 04:48:24 - INFO - __main__ - Step 310 Global step 310 Train loss 0.48 on epoch=2
06/17/2022 04:48:26 - INFO - __main__ - Step 320 Global step 320 Train loss 0.30 on epoch=2
06/17/2022 04:48:29 - INFO - __main__ - Step 330 Global step 330 Train loss 0.26 on epoch=2
06/17/2022 04:48:32 - INFO - __main__ - Step 340 Global step 340 Train loss 0.32 on epoch=3
06/17/2022 04:48:34 - INFO - __main__ - Step 350 Global step 350 Train loss 0.27 on epoch=3
06/17/2022 04:49:34 - INFO - __main__ - Global step 350 Train loss 0.33 Classification-F1 0.46260699274587697 on epoch=3
06/17/2022 04:49:37 - INFO - __main__ - Step 360 Global step 360 Train loss 0.28 on epoch=3
06/17/2022 04:49:39 - INFO - __main__ - Step 370 Global step 370 Train loss 0.24 on epoch=3
06/17/2022 04:49:42 - INFO - __main__ - Step 380 Global step 380 Train loss 0.29 on epoch=3
06/17/2022 04:49:44 - INFO - __main__ - Step 390 Global step 390 Train loss 0.32 on epoch=3
06/17/2022 04:49:47 - INFO - __main__ - Step 400 Global step 400 Train loss 0.36 on epoch=3
06/17/2022 04:50:46 - INFO - __main__ - Global step 400 Train loss 0.30 Classification-F1 0.5448903904458678 on epoch=3
06/17/2022 04:50:48 - INFO - __main__ - Step 410 Global step 410 Train loss 0.28 on epoch=3
06/17/2022 04:50:51 - INFO - __main__ - Step 420 Global step 420 Train loss 0.25 on epoch=3
06/17/2022 04:50:53 - INFO - __main__ - Step 430 Global step 430 Train loss 0.33 on epoch=3
06/17/2022 04:50:56 - INFO - __main__ - Step 440 Global step 440 Train loss 0.34 on epoch=3
06/17/2022 04:50:58 - INFO - __main__ - Step 450 Global step 450 Train loss 0.33 on epoch=4
06/17/2022 04:52:02 - INFO - __main__ - Global step 450 Train loss 0.31 Classification-F1 0.5709901148937073 on epoch=4
06/17/2022 04:52:05 - INFO - __main__ - Step 460 Global step 460 Train loss 0.23 on epoch=4
06/17/2022 04:52:07 - INFO - __main__ - Step 470 Global step 470 Train loss 0.27 on epoch=4
06/17/2022 04:52:10 - INFO - __main__ - Step 480 Global step 480 Train loss 0.17 on epoch=4
06/17/2022 04:52:12 - INFO - __main__ - Step 490 Global step 490 Train loss 0.20 on epoch=4
06/17/2022 04:52:15 - INFO - __main__ - Step 500 Global step 500 Train loss 0.30 on epoch=4
06/17/2022 04:53:09 - INFO - __main__ - Global step 500 Train loss 0.24 Classification-F1 0.5533460973448995 on epoch=4
06/17/2022 04:53:12 - INFO - __main__ - Step 510 Global step 510 Train loss 0.20 on epoch=4
06/17/2022 04:53:14 - INFO - __main__ - Step 520 Global step 520 Train loss 0.28 on epoch=4
06/17/2022 04:53:17 - INFO - __main__ - Step 530 Global step 530 Train loss 0.27 on epoch=4
06/17/2022 04:53:19 - INFO - __main__ - Step 540 Global step 540 Train loss 0.23 on epoch=4
06/17/2022 04:53:22 - INFO - __main__ - Step 550 Global step 550 Train loss 0.18 on epoch=4
06/17/2022 04:54:20 - INFO - __main__ - Global step 550 Train loss 0.23 Classification-F1 0.7925146210635678 on epoch=4
06/17/2022 04:54:20 - INFO - __main__ - Saving model with best Classification-F1: 0.6619100799328846 -> 0.7925146210635678 on epoch=4, global_step=550
06/17/2022 04:54:23 - INFO - __main__ - Step 560 Global step 560 Train loss 0.18 on epoch=4
06/17/2022 04:54:25 - INFO - __main__ - Step 570 Global step 570 Train loss 0.15 on epoch=5
06/17/2022 04:54:28 - INFO - __main__ - Step 580 Global step 580 Train loss 0.19 on epoch=5
06/17/2022 04:54:30 - INFO - __main__ - Step 590 Global step 590 Train loss 0.19 on epoch=5
06/17/2022 04:54:33 - INFO - __main__ - Step 600 Global step 600 Train loss 0.22 on epoch=5
06/17/2022 04:55:35 - INFO - __main__ - Global step 600 Train loss 0.19 Classification-F1 0.5870987527427672 on epoch=5
06/17/2022 04:55:37 - INFO - __main__ - Step 610 Global step 610 Train loss 0.18 on epoch=5
06/17/2022 04:55:40 - INFO - __main__ - Step 620 Global step 620 Train loss 0.17 on epoch=5
06/17/2022 04:55:42 - INFO - __main__ - Step 630 Global step 630 Train loss 0.25 on epoch=5
06/17/2022 04:55:45 - INFO - __main__ - Step 640 Global step 640 Train loss 0.18 on epoch=5
06/17/2022 04:55:47 - INFO - __main__ - Step 650 Global step 650 Train loss 0.23 on epoch=5
06/17/2022 04:56:53 - INFO - __main__ - Global step 650 Train loss 0.20 Classification-F1 0.906401734932039 on epoch=5
06/17/2022 04:56:53 - INFO - __main__ - Saving model with best Classification-F1: 0.7925146210635678 -> 0.906401734932039 on epoch=5, global_step=650
06/17/2022 04:56:56 - INFO - __main__ - Step 660 Global step 660 Train loss 0.09 on epoch=5
06/17/2022 04:56:58 - INFO - __main__ - Step 670 Global step 670 Train loss 0.20 on epoch=5
06/17/2022 04:57:01 - INFO - __main__ - Step 680 Global step 680 Train loss 0.13 on epoch=6
06/17/2022 04:57:03 - INFO - __main__ - Step 690 Global step 690 Train loss 0.14 on epoch=6
06/17/2022 04:57:06 - INFO - __main__ - Step 700 Global step 700 Train loss 0.09 on epoch=6
06/17/2022 04:58:11 - INFO - __main__ - Global step 700 Train loss 0.13 Classification-F1 0.5688425330169247 on epoch=6
06/17/2022 04:58:14 - INFO - __main__ - Step 710 Global step 710 Train loss 0.13 on epoch=6
06/17/2022 04:58:16 - INFO - __main__ - Step 720 Global step 720 Train loss 0.26 on epoch=6
06/17/2022 04:58:19 - INFO - __main__ - Step 730 Global step 730 Train loss 0.14 on epoch=6
06/17/2022 04:58:21 - INFO - __main__ - Step 740 Global step 740 Train loss 0.20 on epoch=6
06/17/2022 04:58:24 - INFO - __main__ - Step 750 Global step 750 Train loss 0.17 on epoch=6
06/17/2022 04:59:23 - INFO - __main__ - Global step 750 Train loss 0.18 Classification-F1 0.6831907432410056 on epoch=6
06/17/2022 04:59:25 - INFO - __main__ - Step 760 Global step 760 Train loss 0.20 on epoch=6
06/17/2022 04:59:28 - INFO - __main__ - Step 770 Global step 770 Train loss 0.14 on epoch=6
06/17/2022 04:59:30 - INFO - __main__ - Step 780 Global step 780 Train loss 0.21 on epoch=6
06/17/2022 04:59:33 - INFO - __main__ - Step 790 Global step 790 Train loss 0.16 on epoch=7
06/17/2022 04:59:35 - INFO - __main__ - Step 800 Global step 800 Train loss 0.10 on epoch=7
06/17/2022 05:00:40 - INFO - __main__ - Global step 800 Train loss 0.16 Classification-F1 0.7989957397990922 on epoch=7
06/17/2022 05:00:43 - INFO - __main__ - Step 810 Global step 810 Train loss 0.15 on epoch=7
06/17/2022 05:00:45 - INFO - __main__ - Step 820 Global step 820 Train loss 0.12 on epoch=7
06/17/2022 05:00:48 - INFO - __main__ - Step 830 Global step 830 Train loss 0.15 on epoch=7
06/17/2022 05:00:51 - INFO - __main__ - Step 840 Global step 840 Train loss 0.09 on epoch=7
06/17/2022 05:00:53 - INFO - __main__ - Step 850 Global step 850 Train loss 0.12 on epoch=7
06/17/2022 05:01:55 - INFO - __main__ - Global step 850 Train loss 0.13 Classification-F1 0.9111125233917511 on epoch=7
06/17/2022 05:01:55 - INFO - __main__ - Saving model with best Classification-F1: 0.906401734932039 -> 0.9111125233917511 on epoch=7, global_step=850
06/17/2022 05:01:58 - INFO - __main__ - Step 860 Global step 860 Train loss 0.06 on epoch=7
06/17/2022 05:02:00 - INFO - __main__ - Step 870 Global step 870 Train loss 0.12 on epoch=7
06/17/2022 05:02:03 - INFO - __main__ - Step 880 Global step 880 Train loss 0.12 on epoch=7
06/17/2022 05:02:05 - INFO - __main__ - Step 890 Global step 890 Train loss 0.19 on epoch=7
06/17/2022 05:02:08 - INFO - __main__ - Step 900 Global step 900 Train loss 0.14 on epoch=8
06/17/2022 05:03:04 - INFO - __main__ - Global step 900 Train loss 0.13 Classification-F1 0.7547612575743124 on epoch=8
06/17/2022 05:03:06 - INFO - __main__ - Step 910 Global step 910 Train loss 0.09 on epoch=8
06/17/2022 05:03:09 - INFO - __main__ - Step 920 Global step 920 Train loss 0.11 on epoch=8
06/17/2022 05:03:12 - INFO - __main__ - Step 930 Global step 930 Train loss 0.08 on epoch=8
06/17/2022 05:03:14 - INFO - __main__ - Step 940 Global step 940 Train loss 0.14 on epoch=8
06/17/2022 05:03:17 - INFO - __main__ - Step 950 Global step 950 Train loss 0.11 on epoch=8
06/17/2022 05:04:11 - INFO - __main__ - Global step 950 Train loss 0.11 Classification-F1 0.7504081175498721 on epoch=8
06/17/2022 05:04:13 - INFO - __main__ - Step 960 Global step 960 Train loss 0.10 on epoch=8
06/17/2022 05:04:16 - INFO - __main__ - Step 970 Global step 970 Train loss 0.07 on epoch=8
06/17/2022 05:04:18 - INFO - __main__ - Step 980 Global step 980 Train loss 0.12 on epoch=8
06/17/2022 05:04:21 - INFO - __main__ - Step 990 Global step 990 Train loss 0.08 on epoch=8
06/17/2022 05:04:24 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.07 on epoch=8
06/17/2022 05:05:19 - INFO - __main__ - Global step 1000 Train loss 0.09 Classification-F1 0.8483347068789181 on epoch=8
06/17/2022 05:05:21 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.14 on epoch=9
06/17/2022 05:05:24 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.09 on epoch=9
06/17/2022 05:05:26 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.08 on epoch=9
06/17/2022 05:05:29 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.06 on epoch=9
06/17/2022 05:05:31 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.10 on epoch=9
06/17/2022 05:06:25 - INFO - __main__ - Global step 1050 Train loss 0.09 Classification-F1 0.8079370867154415 on epoch=9
06/17/2022 05:06:27 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.06 on epoch=9
06/17/2022 05:06:30 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.06 on epoch=9
06/17/2022 05:06:32 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.07 on epoch=9
06/17/2022 05:06:35 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.09 on epoch=9
06/17/2022 05:06:37 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.10 on epoch=9
06/17/2022 05:07:31 - INFO - __main__ - Global step 1100 Train loss 0.08 Classification-F1 0.805651301927698 on epoch=9
06/17/2022 05:07:34 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.08 on epoch=9
06/17/2022 05:07:36 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.11 on epoch=9
06/17/2022 05:07:39 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.05 on epoch=10
06/17/2022 05:07:42 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.06 on epoch=10
06/17/2022 05:07:44 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.08 on epoch=10
06/17/2022 05:08:39 - INFO - __main__ - Global step 1150 Train loss 0.08 Classification-F1 0.825180699721195 on epoch=10
06/17/2022 05:08:42 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.06 on epoch=10
06/17/2022 05:08:44 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.08 on epoch=10
06/17/2022 05:08:47 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.05 on epoch=10
06/17/2022 05:08:50 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.10 on epoch=10
06/17/2022 05:08:52 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.06 on epoch=10
06/17/2022 05:09:47 - INFO - __main__ - Global step 1200 Train loss 0.07 Classification-F1 0.8071030236909038 on epoch=10
06/17/2022 05:09:49 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.05 on epoch=10
06/17/2022 05:09:52 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.05 on epoch=10
06/17/2022 05:09:54 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.13 on epoch=10
06/17/2022 05:09:57 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.04 on epoch=11
06/17/2022 05:09:59 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.04 on epoch=11
06/17/2022 05:10:52 - INFO - __main__ - Global step 1250 Train loss 0.06 Classification-F1 0.8047918650722242 on epoch=11
06/17/2022 05:10:55 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.10 on epoch=11
06/17/2022 05:10:57 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.08 on epoch=11
06/17/2022 05:11:00 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.09 on epoch=11
06/17/2022 05:11:02 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.05 on epoch=11
06/17/2022 05:11:05 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.07 on epoch=11
06/17/2022 05:11:55 - INFO - __main__ - Global step 1300 Train loss 0.08 Classification-F1 0.8551504660292294 on epoch=11
06/17/2022 05:11:57 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.12 on epoch=11
06/17/2022 05:12:00 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.09 on epoch=11
06/17/2022 05:12:03 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.04 on epoch=11
06/17/2022 05:12:05 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.15 on epoch=11
06/17/2022 05:12:08 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.04 on epoch=12
06/17/2022 05:12:58 - INFO - __main__ - Global step 1350 Train loss 0.09 Classification-F1 0.8084756621691279 on epoch=12
06/17/2022 05:13:01 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.04 on epoch=12
06/17/2022 05:13:04 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.14 on epoch=12
06/17/2022 05:13:06 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.11 on epoch=12
06/17/2022 05:13:09 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.16 on epoch=12
06/17/2022 05:13:11 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.03 on epoch=12
06/17/2022 05:14:03 - INFO - __main__ - Global step 1400 Train loss 0.10 Classification-F1 0.5984195303299585 on epoch=12
06/17/2022 05:14:05 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.10 on epoch=12
06/17/2022 05:14:08 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.05 on epoch=12
06/17/2022 05:14:11 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.06 on epoch=12
06/17/2022 05:14:13 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.05 on epoch=12
06/17/2022 05:14:16 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.08 on epoch=12
06/17/2022 05:15:13 - INFO - __main__ - Global step 1450 Train loss 0.07 Classification-F1 0.9095827764238993 on epoch=12
06/17/2022 05:15:15 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.07 on epoch=13
06/17/2022 05:15:18 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.07 on epoch=13
06/17/2022 05:15:20 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.04 on epoch=13
06/17/2022 05:15:23 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.06 on epoch=13
06/17/2022 05:15:25 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.10 on epoch=13
06/17/2022 05:16:26 - INFO - __main__ - Global step 1500 Train loss 0.07 Classification-F1 0.9126083100819755 on epoch=13
06/17/2022 05:16:26 - INFO - __main__ - Saving model with best Classification-F1: 0.9111125233917511 -> 0.9126083100819755 on epoch=13, global_step=1500
06/17/2022 05:16:28 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.04 on epoch=13
06/17/2022 05:16:31 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.03 on epoch=13
06/17/2022 05:16:34 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.07 on epoch=13
06/17/2022 05:16:36 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=13
06/17/2022 05:16:39 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=13
06/17/2022 05:17:32 - INFO - __main__ - Global step 1550 Train loss 0.04 Classification-F1 0.8620086877277127 on epoch=13
06/17/2022 05:17:34 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.08 on epoch=13
06/17/2022 05:17:37 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.04 on epoch=14
06/17/2022 05:17:40 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.06 on epoch=14
06/17/2022 05:17:42 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.05 on epoch=14
06/17/2022 05:17:45 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.06 on epoch=14
06/17/2022 05:18:39 - INFO - __main__ - Global step 1600 Train loss 0.06 Classification-F1 0.8098930092278219 on epoch=14
06/17/2022 05:18:41 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.06 on epoch=14
06/17/2022 05:18:44 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.06 on epoch=14
06/17/2022 05:18:46 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.03 on epoch=14
06/17/2022 05:18:49 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.07 on epoch=14
06/17/2022 05:18:52 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.03 on epoch=14
06/17/2022 05:19:42 - INFO - __main__ - Global step 1650 Train loss 0.05 Classification-F1 0.9207780690852053 on epoch=14
06/17/2022 05:19:42 - INFO - __main__ - Saving model with best Classification-F1: 0.9126083100819755 -> 0.9207780690852053 on epoch=14, global_step=1650
06/17/2022 05:19:44 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.12 on epoch=14
06/17/2022 05:19:47 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=14
06/17/2022 05:19:50 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.08 on epoch=14
06/17/2022 05:19:52 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.02 on epoch=15
06/17/2022 05:19:55 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=15
06/17/2022 05:20:50 - INFO - __main__ - Global step 1700 Train loss 0.06 Classification-F1 0.8055697582838462 on epoch=15
06/17/2022 05:20:52 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.03 on epoch=15
06/17/2022 05:20:55 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.04 on epoch=15
06/17/2022 05:20:58 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.09 on epoch=15
06/17/2022 05:21:00 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=15
06/17/2022 05:21:03 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.05 on epoch=15
06/17/2022 05:21:59 - INFO - __main__ - Global step 1750 Train loss 0.05 Classification-F1 0.855407034065367 on epoch=15
06/17/2022 05:22:02 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.06 on epoch=15
06/17/2022 05:22:04 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.07 on epoch=15
06/17/2022 05:22:07 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.04 on epoch=15
06/17/2022 05:22:10 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.04 on epoch=15
06/17/2022 05:22:12 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.03 on epoch=16
06/17/2022 05:23:04 - INFO - __main__ - Global step 1800 Train loss 0.05 Classification-F1 0.7644230608645611 on epoch=16
06/17/2022 05:23:07 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.04 on epoch=16
06/17/2022 05:23:09 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.10 on epoch=16
06/17/2022 05:23:12 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.07 on epoch=16
06/17/2022 05:23:15 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.13 on epoch=16
06/17/2022 05:23:17 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.04 on epoch=16
06/17/2022 05:24:05 - INFO - __main__ - Global step 1850 Train loss 0.08 Classification-F1 0.6358043530635743 on epoch=16
06/17/2022 05:24:08 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.06 on epoch=16
06/17/2022 05:24:11 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.07 on epoch=16
06/17/2022 05:24:13 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.05 on epoch=16
06/17/2022 05:24:16 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=16
06/17/2022 05:24:18 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.08 on epoch=16
06/17/2022 05:25:08 - INFO - __main__ - Global step 1900 Train loss 0.05 Classification-F1 0.9071968524294413 on epoch=16
06/17/2022 05:25:10 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.05 on epoch=17
06/17/2022 05:25:13 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.04 on epoch=17
06/17/2022 05:25:16 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.06 on epoch=17
06/17/2022 05:25:18 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.06 on epoch=17
06/17/2022 05:25:21 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.05 on epoch=17
06/17/2022 05:26:10 - INFO - __main__ - Global step 1950 Train loss 0.05 Classification-F1 0.8244072298583938 on epoch=17
06/17/2022 05:26:13 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.04 on epoch=17
06/17/2022 05:26:15 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.05 on epoch=17
06/17/2022 05:26:18 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=17
06/17/2022 05:26:21 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=17
06/17/2022 05:26:23 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=17
06/17/2022 05:27:12 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.864471523745946 on epoch=17
06/17/2022 05:27:15 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.09 on epoch=17
06/17/2022 05:27:17 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.06 on epoch=18
06/17/2022 05:27:20 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.04 on epoch=18
06/17/2022 05:27:23 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.03 on epoch=18
06/17/2022 05:27:25 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.03 on epoch=18
06/17/2022 05:28:17 - INFO - __main__ - Global step 2050 Train loss 0.05 Classification-F1 0.9114391338565231 on epoch=18
06/17/2022 05:28:20 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.05 on epoch=18
06/17/2022 05:28:23 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.05 on epoch=18
06/17/2022 05:28:25 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.06 on epoch=18
06/17/2022 05:28:28 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.03 on epoch=18
06/17/2022 05:28:30 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=18
06/17/2022 05:29:20 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.8075175625261872 on epoch=18
06/17/2022 05:29:23 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.04 on epoch=18
06/17/2022 05:29:25 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=18
06/17/2022 05:29:28 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.05 on epoch=19
06/17/2022 05:29:30 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=19
06/17/2022 05:29:33 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.08 on epoch=19
06/17/2022 05:30:26 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.9097585338587597 on epoch=19
06/17/2022 05:30:28 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.07 on epoch=19
06/17/2022 05:30:31 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=19
06/17/2022 05:30:34 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=19
06/17/2022 05:30:36 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.05 on epoch=19
06/17/2022 05:30:39 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.04 on epoch=19
06/17/2022 05:31:28 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.7607519382626016 on epoch=19
06/17/2022 05:31:30 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.09 on epoch=19
06/17/2022 05:31:33 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.04 on epoch=19
06/17/2022 05:31:36 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=19
06/17/2022 05:31:38 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.03 on epoch=19
06/17/2022 05:31:41 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=20
06/17/2022 05:32:30 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.9172342175175038 on epoch=20
06/17/2022 05:32:32 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.03 on epoch=20
06/17/2022 05:32:35 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.04 on epoch=20
06/17/2022 05:32:37 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.06 on epoch=20
06/17/2022 05:32:40 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.05 on epoch=20
06/17/2022 05:32:43 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=20
06/17/2022 05:33:31 - INFO - __main__ - Global step 2300 Train loss 0.04 Classification-F1 0.9825512609495509 on epoch=20
06/17/2022 05:33:31 - INFO - __main__ - Saving model with best Classification-F1: 0.9207780690852053 -> 0.9825512609495509 on epoch=20, global_step=2300
06/17/2022 05:33:34 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=20
06/17/2022 05:33:37 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.04 on epoch=20
06/17/2022 05:33:40 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=20
06/17/2022 05:33:42 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=20
06/17/2022 05:33:45 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.07 on epoch=20
06/17/2022 05:34:33 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.9196009411155843 on epoch=20
06/17/2022 05:34:35 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.06 on epoch=21
06/17/2022 05:34:38 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=21
06/17/2022 05:34:40 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.06 on epoch=21
06/17/2022 05:34:43 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.04 on epoch=21
06/17/2022 05:34:46 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.11 on epoch=21
06/17/2022 05:35:31 - INFO - __main__ - Global step 2400 Train loss 0.06 Classification-F1 0.8612446775053832 on epoch=21
06/17/2022 05:35:34 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.04 on epoch=21
06/17/2022 05:35:37 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.05 on epoch=21
06/17/2022 05:35:39 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=21
06/17/2022 05:35:42 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.03 on epoch=21
06/17/2022 05:35:44 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.03 on epoch=21
06/17/2022 05:36:35 - INFO - __main__ - Global step 2450 Train loss 0.04 Classification-F1 0.6816682038765748 on epoch=21
06/17/2022 05:36:38 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.07 on epoch=21
06/17/2022 05:36:40 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=22
06/17/2022 05:36:43 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.05 on epoch=22
06/17/2022 05:36:45 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.06 on epoch=22
06/17/2022 05:36:48 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.04 on epoch=22
06/17/2022 05:37:37 - INFO - __main__ - Global step 2500 Train loss 0.05 Classification-F1 0.9120355526210061 on epoch=22
06/17/2022 05:37:40 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=22
06/17/2022 05:37:43 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.06 on epoch=22
06/17/2022 05:37:45 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.04 on epoch=22
06/17/2022 05:37:48 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.03 on epoch=22
06/17/2022 05:37:50 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.06 on epoch=22
06/17/2022 05:38:38 - INFO - __main__ - Global step 2550 Train loss 0.04 Classification-F1 0.856843209262905 on epoch=22
06/17/2022 05:38:41 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=22
06/17/2022 05:38:43 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.04 on epoch=22
06/17/2022 05:38:46 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.04 on epoch=23
06/17/2022 05:38:49 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=23
06/17/2022 05:38:51 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.05 on epoch=23
06/17/2022 05:39:40 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.906104268627906 on epoch=23
06/17/2022 05:39:43 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.08 on epoch=23
06/17/2022 05:39:46 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.07 on epoch=23
06/17/2022 05:39:48 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.05 on epoch=23
06/17/2022 05:39:51 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.04 on epoch=23
06/17/2022 05:39:54 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.03 on epoch=23
06/17/2022 05:40:43 - INFO - __main__ - Global step 2650 Train loss 0.06 Classification-F1 0.8587180366608305 on epoch=23
06/17/2022 05:40:45 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=23
06/17/2022 05:40:48 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=23
06/17/2022 05:40:50 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.04 on epoch=23
06/17/2022 05:40:53 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.08 on epoch=24
06/17/2022 05:40:56 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=24
06/17/2022 05:41:43 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.917849925532104 on epoch=24
06/17/2022 05:41:45 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.04 on epoch=24
06/17/2022 05:41:48 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=24
06/17/2022 05:41:51 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.08 on epoch=24
06/17/2022 05:41:53 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.04 on epoch=24
06/17/2022 05:41:56 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.03 on epoch=24
06/17/2022 05:42:45 - INFO - __main__ - Global step 2750 Train loss 0.04 Classification-F1 0.7522060883609086 on epoch=24
06/17/2022 05:42:48 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=24
06/17/2022 05:42:50 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=24
06/17/2022 05:42:53 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=24
06/17/2022 05:42:56 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=24
06/17/2022 05:42:58 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.05 on epoch=24
06/17/2022 05:43:45 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.8487134093160468 on epoch=24
06/17/2022 05:43:48 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.03 on epoch=25
06/17/2022 05:43:51 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.06 on epoch=25
06/17/2022 05:43:53 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=25
06/17/2022 05:43:56 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=25
06/17/2022 05:43:58 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.06 on epoch=25
06/17/2022 05:44:45 - INFO - __main__ - Global step 2850 Train loss 0.04 Classification-F1 0.8452409937217366 on epoch=25
06/17/2022 05:44:48 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=25
06/17/2022 05:44:51 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.04 on epoch=25
06/17/2022 05:44:53 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=25
06/17/2022 05:44:56 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.06 on epoch=25
06/17/2022 05:44:58 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=25
06/17/2022 05:45:47 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.751083656660911 on epoch=25
06/17/2022 05:45:49 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.05 on epoch=25
06/17/2022 05:45:52 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.03 on epoch=26
06/17/2022 05:45:54 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=26
06/17/2022 05:45:57 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.03 on epoch=26
06/17/2022 05:46:00 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.03 on epoch=26
06/17/2022 05:46:48 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.8585002998147195 on epoch=26
06/17/2022 05:46:50 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.04 on epoch=26
06/17/2022 05:46:53 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=26
06/17/2022 05:46:56 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=26
06/17/2022 05:46:58 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.05 on epoch=26
06/17/2022 05:47:01 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.03 on epoch=26
06/17/2022 05:47:02 - INFO - __main__ - Start tokenizing ... 1792 instances
06/17/2022 05:47:02 - INFO - __main__ - Printing 3 examples
06/17/2022 05:47:02 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
06/17/2022 05:47:02 - INFO - __main__ - ['Film']
06/17/2022 05:47:02 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/17/2022 05:47:02 - INFO - __main__ - ['Film']
06/17/2022 05:47:02 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/17/2022 05:47:02 - INFO - __main__ - ['Film']
06/17/2022 05:47:02 - INFO - __main__ - Tokenizing Input ...
06/17/2022 05:47:03 - INFO - __main__ - Tokenizing Output ...
06/17/2022 05:47:05 - INFO - __main__ - Loaded 1792 examples from train data
06/17/2022 05:47:05 - INFO - __main__ - Start tokenizing ... 1792 instances
06/17/2022 05:47:05 - INFO - __main__ - Printing 3 examples
06/17/2022 05:47:05 - INFO - __main__ -  [dbpedia_14] The Debt is a 2011 American/British drama-thriller film directed by John Madden from a screenplay by Matthew Vaughn Jane Goldman and Peter Straughan. It stars Helen Mirren Sam Worthington Jessica Chastain Ciarán Hinds Tom Wilkinson Marton Csokas and Jesper Christensen. It's a remake of the 2007 Israeli film Ha-Hov directed by Assaf BernsteinOriginally scheduled for a December 2010 release the film was released in the United States on August 31 2011.
06/17/2022 05:47:05 - INFO - __main__ - ['Film']
06/17/2022 05:47:05 - INFO - __main__ -  [dbpedia_14] Naga Bonar Jadi 2 (Naga Bonar Becomes 2) is 2007 comedy film directed by Deddy Mizwar. It is starring Deddy Mizwar Tora Sudiro Lukman Sardi Darius Sinathrya and Michael Muliardo. It is a sequel to the Indonesian film Nagabonar (1987).
06/17/2022 05:47:05 - INFO - __main__ - ['Film']
06/17/2022 05:47:05 - INFO - __main__ -  [dbpedia_14] La Garce is a 1984 French thriller film directed by Christine Pascal and starring Isabelle Huppert.
06/17/2022 05:47:05 - INFO - __main__ - ['Film']
06/17/2022 05:47:05 - INFO - __main__ - Tokenizing Input ...
06/17/2022 05:47:06 - INFO - __main__ - Tokenizing Output ...
06/17/2022 05:47:08 - INFO - __main__ - Loaded 1792 examples from dev data
06/17/2022 05:47:24 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 05:47:25 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/17/2022 05:47:25 - INFO - __main__ - Starting training!
06/17/2022 05:47:50 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.8147629208536671 on epoch=26
06/17/2022 05:47:50 - INFO - __main__ - save last model!
06/17/2022 05:47:50 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/17/2022 05:47:50 - INFO - __main__ - Start tokenizing ... 3500 instances
06/17/2022 05:47:50 - INFO - __main__ - Printing 3 examples
06/17/2022 05:47:50 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/17/2022 05:47:50 - INFO - __main__ - ['Animal']
06/17/2022 05:47:50 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/17/2022 05:47:50 - INFO - __main__ - ['Animal']
06/17/2022 05:47:50 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/17/2022 05:47:50 - INFO - __main__ - ['Village']
06/17/2022 05:47:50 - INFO - __main__ - Tokenizing Input ...
06/17/2022 05:47:52 - INFO - __main__ - Tokenizing Output ...
06/17/2022 05:47:55 - INFO - __main__ - Loaded 3500 examples from test data
06/17/2022 05:50:04 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down128shot/singletask-dbpedia_14/dbpedia_14_128_87_0.3_8_predictions.txt
06/17/2022 05:50:04 - INFO - __main__ - Classification-F1 on test data: 0.6888
06/17/2022 05:50:04 - INFO - __main__ - prefix=dbpedia_14_128_87, lr=0.3, bsz=8, dev_performance=0.9825512609495509, test_performance=0.6888427012453193
06/17/2022 05:50:04 - INFO - __main__ - Running ... prefix=dbpedia_14_128_87, lr=0.2, bsz=8 ...
06/17/2022 05:50:05 - INFO - __main__ - Start tokenizing ... 1792 instances
06/17/2022 05:50:05 - INFO - __main__ - Printing 3 examples
06/17/2022 05:50:05 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
06/17/2022 05:50:05 - INFO - __main__ - ['Film']
06/17/2022 05:50:05 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/17/2022 05:50:05 - INFO - __main__ - ['Film']
06/17/2022 05:50:05 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/17/2022 05:50:05 - INFO - __main__ - ['Film']
06/17/2022 05:50:05 - INFO - __main__ - Tokenizing Input ...
06/17/2022 05:50:06 - INFO - __main__ - Tokenizing Output ...
06/17/2022 05:50:08 - INFO - __main__ - Loaded 1792 examples from train data
06/17/2022 05:50:08 - INFO - __main__ - Start tokenizing ... 1792 instances
06/17/2022 05:50:08 - INFO - __main__ - Printing 3 examples
06/17/2022 05:50:08 - INFO - __main__ -  [dbpedia_14] The Debt is a 2011 American/British drama-thriller film directed by John Madden from a screenplay by Matthew Vaughn Jane Goldman and Peter Straughan. It stars Helen Mirren Sam Worthington Jessica Chastain Ciarán Hinds Tom Wilkinson Marton Csokas and Jesper Christensen. It's a remake of the 2007 Israeli film Ha-Hov directed by Assaf BernsteinOriginally scheduled for a December 2010 release the film was released in the United States on August 31 2011.
06/17/2022 05:50:08 - INFO - __main__ - ['Film']
06/17/2022 05:50:08 - INFO - __main__ -  [dbpedia_14] Naga Bonar Jadi 2 (Naga Bonar Becomes 2) is 2007 comedy film directed by Deddy Mizwar. It is starring Deddy Mizwar Tora Sudiro Lukman Sardi Darius Sinathrya and Michael Muliardo. It is a sequel to the Indonesian film Nagabonar (1987).
06/17/2022 05:50:08 - INFO - __main__ - ['Film']
06/17/2022 05:50:08 - INFO - __main__ -  [dbpedia_14] La Garce is a 1984 French thriller film directed by Christine Pascal and starring Isabelle Huppert.
06/17/2022 05:50:08 - INFO - __main__ - ['Film']
06/17/2022 05:50:08 - INFO - __main__ - Tokenizing Input ...
06/17/2022 05:50:09 - INFO - __main__ - Tokenizing Output ...
06/17/2022 05:50:11 - INFO - __main__ - Loaded 1792 examples from dev data
06/17/2022 05:50:29 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 05:50:30 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/17/2022 05:50:30 - INFO - __main__ - Starting training!
06/17/2022 05:50:34 - INFO - __main__ - Step 10 Global step 10 Train loss 5.02 on epoch=0
06/17/2022 05:50:36 - INFO - __main__ - Step 20 Global step 20 Train loss 3.64 on epoch=0
06/17/2022 05:50:39 - INFO - __main__ - Step 30 Global step 30 Train loss 2.88 on epoch=0
06/17/2022 05:50:42 - INFO - __main__ - Step 40 Global step 40 Train loss 2.17 on epoch=0
06/17/2022 05:50:44 - INFO - __main__ - Step 50 Global step 50 Train loss 2.15 on epoch=0
06/17/2022 05:51:29 - INFO - __main__ - Global step 50 Train loss 3.17 Classification-F1 0.04997874055968981 on epoch=0
06/17/2022 05:51:29 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.04997874055968981 on epoch=0, global_step=50
06/17/2022 05:51:31 - INFO - __main__ - Step 60 Global step 60 Train loss 1.80 on epoch=0
06/17/2022 05:51:34 - INFO - __main__ - Step 70 Global step 70 Train loss 1.53 on epoch=0
06/17/2022 05:51:36 - INFO - __main__ - Step 80 Global step 80 Train loss 1.37 on epoch=0
06/17/2022 05:51:39 - INFO - __main__ - Step 90 Global step 90 Train loss 1.33 on epoch=0
06/17/2022 05:51:41 - INFO - __main__ - Step 100 Global step 100 Train loss 1.02 on epoch=0
06/17/2022 05:52:29 - INFO - __main__ - Global step 100 Train loss 1.41 Classification-F1 0.18935359573152044 on epoch=0
06/17/2022 05:52:29 - INFO - __main__ - Saving model with best Classification-F1: 0.04997874055968981 -> 0.18935359573152044 on epoch=0, global_step=100
06/17/2022 05:52:31 - INFO - __main__ - Step 110 Global step 110 Train loss 1.11 on epoch=0
06/17/2022 05:52:34 - INFO - __main__ - Step 120 Global step 120 Train loss 0.76 on epoch=1
06/17/2022 05:52:36 - INFO - __main__ - Step 130 Global step 130 Train loss 0.91 on epoch=1
06/17/2022 05:52:39 - INFO - __main__ - Step 140 Global step 140 Train loss 0.88 on epoch=1
06/17/2022 05:52:42 - INFO - __main__ - Step 150 Global step 150 Train loss 0.71 on epoch=1
06/17/2022 05:53:34 - INFO - __main__ - Global step 150 Train loss 0.87 Classification-F1 0.21947623962262078 on epoch=1
06/17/2022 05:53:34 - INFO - __main__ - Saving model with best Classification-F1: 0.18935359573152044 -> 0.21947623962262078 on epoch=1, global_step=150
06/17/2022 05:53:37 - INFO - __main__ - Step 160 Global step 160 Train loss 0.81 on epoch=1
06/17/2022 05:53:40 - INFO - __main__ - Step 170 Global step 170 Train loss 0.67 on epoch=1
06/17/2022 05:53:42 - INFO - __main__ - Step 180 Global step 180 Train loss 0.58 on epoch=1
06/17/2022 05:53:45 - INFO - __main__ - Step 190 Global step 190 Train loss 0.61 on epoch=1
06/17/2022 05:53:47 - INFO - __main__ - Step 200 Global step 200 Train loss 0.63 on epoch=1
06/17/2022 05:54:41 - INFO - __main__ - Global step 200 Train loss 0.66 Classification-F1 0.4224038025577911 on epoch=1
06/17/2022 05:54:41 - INFO - __main__ - Saving model with best Classification-F1: 0.21947623962262078 -> 0.4224038025577911 on epoch=1, global_step=200
06/17/2022 05:54:43 - INFO - __main__ - Step 210 Global step 210 Train loss 0.69 on epoch=1
06/17/2022 05:54:46 - INFO - __main__ - Step 220 Global step 220 Train loss 0.60 on epoch=1
06/17/2022 05:54:48 - INFO - __main__ - Step 230 Global step 230 Train loss 0.57 on epoch=2
06/17/2022 05:54:51 - INFO - __main__ - Step 240 Global step 240 Train loss 0.44 on epoch=2
06/17/2022 05:54:54 - INFO - __main__ - Step 250 Global step 250 Train loss 0.48 on epoch=2
06/17/2022 05:55:46 - INFO - __main__ - Global step 250 Train loss 0.56 Classification-F1 0.35196471609089675 on epoch=2
06/17/2022 05:55:49 - INFO - __main__ - Step 260 Global step 260 Train loss 0.49 on epoch=2
06/17/2022 05:55:51 - INFO - __main__ - Step 270 Global step 270 Train loss 0.50 on epoch=2
06/17/2022 05:55:54 - INFO - __main__ - Step 280 Global step 280 Train loss 0.49 on epoch=2
06/17/2022 05:55:56 - INFO - __main__ - Step 290 Global step 290 Train loss 0.43 on epoch=2
06/17/2022 05:55:59 - INFO - __main__ - Step 300 Global step 300 Train loss 0.47 on epoch=2
06/17/2022 05:56:52 - INFO - __main__ - Global step 300 Train loss 0.48 Classification-F1 0.4402593990340687 on epoch=2
06/17/2022 05:56:52 - INFO - __main__ - Saving model with best Classification-F1: 0.4224038025577911 -> 0.4402593990340687 on epoch=2, global_step=300
06/17/2022 05:56:54 - INFO - __main__ - Step 310 Global step 310 Train loss 0.60 on epoch=2
06/17/2022 05:56:57 - INFO - __main__ - Step 320 Global step 320 Train loss 0.46 on epoch=2
06/17/2022 05:56:59 - INFO - __main__ - Step 330 Global step 330 Train loss 0.38 on epoch=2
06/17/2022 05:57:02 - INFO - __main__ - Step 340 Global step 340 Train loss 0.51 on epoch=3
06/17/2022 05:57:05 - INFO - __main__ - Step 350 Global step 350 Train loss 0.33 on epoch=3
06/17/2022 05:58:01 - INFO - __main__ - Global step 350 Train loss 0.46 Classification-F1 0.447230751139783 on epoch=3
06/17/2022 05:58:01 - INFO - __main__ - Saving model with best Classification-F1: 0.4402593990340687 -> 0.447230751139783 on epoch=3, global_step=350
06/17/2022 05:58:04 - INFO - __main__ - Step 360 Global step 360 Train loss 0.42 on epoch=3
06/17/2022 05:58:06 - INFO - __main__ - Step 370 Global step 370 Train loss 0.37 on epoch=3
06/17/2022 05:58:09 - INFO - __main__ - Step 380 Global step 380 Train loss 0.34 on epoch=3
06/17/2022 05:58:11 - INFO - __main__ - Step 390 Global step 390 Train loss 0.32 on epoch=3
06/17/2022 05:58:14 - INFO - __main__ - Step 400 Global step 400 Train loss 0.35 on epoch=3
06/17/2022 05:59:13 - INFO - __main__ - Global step 400 Train loss 0.36 Classification-F1 0.4480180722443939 on epoch=3
06/17/2022 05:59:13 - INFO - __main__ - Saving model with best Classification-F1: 0.447230751139783 -> 0.4480180722443939 on epoch=3, global_step=400
06/17/2022 05:59:15 - INFO - __main__ - Step 410 Global step 410 Train loss 0.44 on epoch=3
06/17/2022 05:59:18 - INFO - __main__ - Step 420 Global step 420 Train loss 0.35 on epoch=3
06/17/2022 05:59:21 - INFO - __main__ - Step 430 Global step 430 Train loss 0.32 on epoch=3
06/17/2022 05:59:23 - INFO - __main__ - Step 440 Global step 440 Train loss 0.32 on epoch=3
06/17/2022 05:59:26 - INFO - __main__ - Step 450 Global step 450 Train loss 0.38 on epoch=4
06/17/2022 06:00:32 - INFO - __main__ - Global step 450 Train loss 0.36 Classification-F1 0.4518723764271435 on epoch=4
06/17/2022 06:00:32 - INFO - __main__ - Saving model with best Classification-F1: 0.4480180722443939 -> 0.4518723764271435 on epoch=4, global_step=450
06/17/2022 06:00:34 - INFO - __main__ - Step 460 Global step 460 Train loss 0.30 on epoch=4
06/17/2022 06:00:37 - INFO - __main__ - Step 470 Global step 470 Train loss 0.32 on epoch=4
06/17/2022 06:00:40 - INFO - __main__ - Step 480 Global step 480 Train loss 0.23 on epoch=4
06/17/2022 06:00:42 - INFO - __main__ - Step 490 Global step 490 Train loss 0.30 on epoch=4
06/17/2022 06:00:45 - INFO - __main__ - Step 500 Global step 500 Train loss 0.32 on epoch=4
06/17/2022 06:01:43 - INFO - __main__ - Global step 500 Train loss 0.29 Classification-F1 0.5336087425888761 on epoch=4
06/17/2022 06:01:43 - INFO - __main__ - Saving model with best Classification-F1: 0.4518723764271435 -> 0.5336087425888761 on epoch=4, global_step=500
06/17/2022 06:01:46 - INFO - __main__ - Step 510 Global step 510 Train loss 0.31 on epoch=4
06/17/2022 06:01:48 - INFO - __main__ - Step 520 Global step 520 Train loss 0.22 on epoch=4
06/17/2022 06:01:51 - INFO - __main__ - Step 530 Global step 530 Train loss 0.31 on epoch=4
06/17/2022 06:01:54 - INFO - __main__ - Step 540 Global step 540 Train loss 0.29 on epoch=4
06/17/2022 06:01:56 - INFO - __main__ - Step 550 Global step 550 Train loss 0.20 on epoch=4
06/17/2022 06:02:55 - INFO - __main__ - Global step 550 Train loss 0.27 Classification-F1 0.5294360097237815 on epoch=4
06/17/2022 06:02:57 - INFO - __main__ - Step 560 Global step 560 Train loss 0.33 on epoch=4
06/17/2022 06:03:00 - INFO - __main__ - Step 570 Global step 570 Train loss 0.22 on epoch=5
06/17/2022 06:03:03 - INFO - __main__ - Step 580 Global step 580 Train loss 0.24 on epoch=5
06/17/2022 06:03:05 - INFO - __main__ - Step 590 Global step 590 Train loss 0.22 on epoch=5
06/17/2022 06:03:08 - INFO - __main__ - Step 600 Global step 600 Train loss 0.25 on epoch=5
06/17/2022 06:04:08 - INFO - __main__ - Global step 600 Train loss 0.25 Classification-F1 0.4716299619175046 on epoch=5
06/17/2022 06:04:10 - INFO - __main__ - Step 610 Global step 610 Train loss 0.26 on epoch=5
06/17/2022 06:04:13 - INFO - __main__ - Step 620 Global step 620 Train loss 0.25 on epoch=5
06/17/2022 06:04:15 - INFO - __main__ - Step 630 Global step 630 Train loss 0.29 on epoch=5
06/17/2022 06:04:18 - INFO - __main__ - Step 640 Global step 640 Train loss 0.20 on epoch=5
06/17/2022 06:04:21 - INFO - __main__ - Step 650 Global step 650 Train loss 0.18 on epoch=5
06/17/2022 06:05:24 - INFO - __main__ - Global step 650 Train loss 0.24 Classification-F1 0.5675196838873301 on epoch=5
06/17/2022 06:05:24 - INFO - __main__ - Saving model with best Classification-F1: 0.5336087425888761 -> 0.5675196838873301 on epoch=5, global_step=650
06/17/2022 06:05:26 - INFO - __main__ - Step 660 Global step 660 Train loss 0.15 on epoch=5
06/17/2022 06:05:29 - INFO - __main__ - Step 670 Global step 670 Train loss 0.28 on epoch=5
06/17/2022 06:05:31 - INFO - __main__ - Step 680 Global step 680 Train loss 0.21 on epoch=6
06/17/2022 06:05:34 - INFO - __main__ - Step 690 Global step 690 Train loss 0.20 on epoch=6
06/17/2022 06:05:36 - INFO - __main__ - Step 700 Global step 700 Train loss 0.17 on epoch=6
06/17/2022 06:06:38 - INFO - __main__ - Global step 700 Train loss 0.20 Classification-F1 0.4894343857565324 on epoch=6
06/17/2022 06:06:41 - INFO - __main__ - Step 710 Global step 710 Train loss 0.24 on epoch=6
06/17/2022 06:06:43 - INFO - __main__ - Step 720 Global step 720 Train loss 0.21 on epoch=6
06/17/2022 06:06:46 - INFO - __main__ - Step 730 Global step 730 Train loss 0.14 on epoch=6
06/17/2022 06:06:48 - INFO - __main__ - Step 740 Global step 740 Train loss 0.23 on epoch=6
06/17/2022 06:06:51 - INFO - __main__ - Step 750 Global step 750 Train loss 0.25 on epoch=6
06/17/2022 06:07:54 - INFO - __main__ - Global step 750 Train loss 0.21 Classification-F1 0.5559574823992699 on epoch=6
06/17/2022 06:07:57 - INFO - __main__ - Step 760 Global step 760 Train loss 0.22 on epoch=6
06/17/2022 06:07:59 - INFO - __main__ - Step 770 Global step 770 Train loss 0.19 on epoch=6
06/17/2022 06:08:02 - INFO - __main__ - Step 780 Global step 780 Train loss 0.19 on epoch=6
06/17/2022 06:08:05 - INFO - __main__ - Step 790 Global step 790 Train loss 0.17 on epoch=7
06/17/2022 06:08:07 - INFO - __main__ - Step 800 Global step 800 Train loss 0.13 on epoch=7
06/17/2022 06:09:11 - INFO - __main__ - Global step 800 Train loss 0.18 Classification-F1 0.5767958769933759 on epoch=7
06/17/2022 06:09:11 - INFO - __main__ - Saving model with best Classification-F1: 0.5675196838873301 -> 0.5767958769933759 on epoch=7, global_step=800
06/17/2022 06:09:14 - INFO - __main__ - Step 810 Global step 810 Train loss 0.19 on epoch=7
06/17/2022 06:09:16 - INFO - __main__ - Step 820 Global step 820 Train loss 0.15 on epoch=7
06/17/2022 06:09:19 - INFO - __main__ - Step 830 Global step 830 Train loss 0.28 on epoch=7
06/17/2022 06:09:21 - INFO - __main__ - Step 840 Global step 840 Train loss 0.10 on epoch=7
06/17/2022 06:09:24 - INFO - __main__ - Step 850 Global step 850 Train loss 0.15 on epoch=7
06/17/2022 06:10:24 - INFO - __main__ - Global step 850 Train loss 0.18 Classification-F1 0.6083950900829455 on epoch=7
06/17/2022 06:10:24 - INFO - __main__ - Saving model with best Classification-F1: 0.5767958769933759 -> 0.6083950900829455 on epoch=7, global_step=850
06/17/2022 06:10:27 - INFO - __main__ - Step 860 Global step 860 Train loss 0.14 on epoch=7
06/17/2022 06:10:30 - INFO - __main__ - Step 870 Global step 870 Train loss 0.17 on epoch=7
06/17/2022 06:10:32 - INFO - __main__ - Step 880 Global step 880 Train loss 0.20 on epoch=7
06/17/2022 06:10:35 - INFO - __main__ - Step 890 Global step 890 Train loss 0.31 on epoch=7
06/17/2022 06:10:38 - INFO - __main__ - Step 900 Global step 900 Train loss 0.16 on epoch=8
06/17/2022 06:11:39 - INFO - __main__ - Global step 900 Train loss 0.20 Classification-F1 0.5816677681473227 on epoch=8
06/17/2022 06:11:42 - INFO - __main__ - Step 910 Global step 910 Train loss 0.11 on epoch=8
06/17/2022 06:11:44 - INFO - __main__ - Step 920 Global step 920 Train loss 0.11 on epoch=8
06/17/2022 06:11:47 - INFO - __main__ - Step 930 Global step 930 Train loss 0.10 on epoch=8
06/17/2022 06:11:50 - INFO - __main__ - Step 940 Global step 940 Train loss 0.14 on epoch=8
06/17/2022 06:11:52 - INFO - __main__ - Step 950 Global step 950 Train loss 0.09 on epoch=8
06/17/2022 06:12:52 - INFO - __main__ - Global step 950 Train loss 0.11 Classification-F1 0.6397813549329877 on epoch=8
06/17/2022 06:12:52 - INFO - __main__ - Saving model with best Classification-F1: 0.6083950900829455 -> 0.6397813549329877 on epoch=8, global_step=950
06/17/2022 06:12:54 - INFO - __main__ - Step 960 Global step 960 Train loss 0.17 on epoch=8
06/17/2022 06:12:57 - INFO - __main__ - Step 970 Global step 970 Train loss 0.12 on epoch=8
06/17/2022 06:13:00 - INFO - __main__ - Step 980 Global step 980 Train loss 0.11 on epoch=8
06/17/2022 06:13:02 - INFO - __main__ - Step 990 Global step 990 Train loss 0.11 on epoch=8
06/17/2022 06:13:05 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.08 on epoch=8
06/17/2022 06:14:06 - INFO - __main__ - Global step 1000 Train loss 0.12 Classification-F1 0.7146017469776995 on epoch=8
06/17/2022 06:14:06 - INFO - __main__ - Saving model with best Classification-F1: 0.6397813549329877 -> 0.7146017469776995 on epoch=8, global_step=1000
06/17/2022 06:14:09 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.16 on epoch=9
06/17/2022 06:14:11 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.12 on epoch=9
06/17/2022 06:14:14 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.15 on epoch=9
06/17/2022 06:14:17 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.17 on epoch=9
06/17/2022 06:14:19 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.10 on epoch=9
06/17/2022 06:15:15 - INFO - __main__ - Global step 1050 Train loss 0.14 Classification-F1 0.596226595837848 on epoch=9
06/17/2022 06:15:18 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.12 on epoch=9
06/17/2022 06:15:20 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.09 on epoch=9
06/17/2022 06:15:23 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.07 on epoch=9
06/17/2022 06:15:25 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.20 on epoch=9
06/17/2022 06:15:28 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.12 on epoch=9
06/17/2022 06:16:27 - INFO - __main__ - Global step 1100 Train loss 0.12 Classification-F1 0.7128335948460651 on epoch=9
06/17/2022 06:16:30 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.11 on epoch=9
06/17/2022 06:16:33 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.18 on epoch=9
06/17/2022 06:16:35 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.08 on epoch=10
06/17/2022 06:16:38 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.10 on epoch=10
06/17/2022 06:16:40 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.10 on epoch=10
06/17/2022 06:17:33 - INFO - __main__ - Global step 1150 Train loss 0.11 Classification-F1 0.851804570222781 on epoch=10
06/17/2022 06:17:33 - INFO - __main__ - Saving model with best Classification-F1: 0.7146017469776995 -> 0.851804570222781 on epoch=10, global_step=1150
06/17/2022 06:17:36 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.13 on epoch=10
06/17/2022 06:17:38 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.12 on epoch=10
06/17/2022 06:17:41 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.14 on epoch=10
06/17/2022 06:17:44 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.10 on epoch=10
06/17/2022 06:17:46 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.10 on epoch=10
06/17/2022 06:18:39 - INFO - __main__ - Global step 1200 Train loss 0.12 Classification-F1 0.7193072743327672 on epoch=10
06/17/2022 06:18:41 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.09 on epoch=10
06/17/2022 06:18:44 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.06 on epoch=10
06/17/2022 06:18:46 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.11 on epoch=10
06/17/2022 06:18:49 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.08 on epoch=11
06/17/2022 06:18:52 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.10 on epoch=11
06/17/2022 06:19:44 - INFO - __main__ - Global step 1250 Train loss 0.09 Classification-F1 0.8453211248002674 on epoch=11
06/17/2022 06:19:47 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.07 on epoch=11
06/17/2022 06:19:50 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.08 on epoch=11
06/17/2022 06:19:52 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.10 on epoch=11
06/17/2022 06:19:55 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.08 on epoch=11
06/17/2022 06:19:57 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.17 on epoch=11
06/17/2022 06:20:50 - INFO - __main__ - Global step 1300 Train loss 0.10 Classification-F1 0.8860009694233589 on epoch=11
06/17/2022 06:20:50 - INFO - __main__ - Saving model with best Classification-F1: 0.851804570222781 -> 0.8860009694233589 on epoch=11, global_step=1300
06/17/2022 06:20:53 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.09 on epoch=11
06/17/2022 06:20:55 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.10 on epoch=11
06/17/2022 06:20:58 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.08 on epoch=11
06/17/2022 06:21:00 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.10 on epoch=11
06/17/2022 06:21:03 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.04 on epoch=12
06/17/2022 06:21:54 - INFO - __main__ - Global step 1350 Train loss 0.08 Classification-F1 0.8479057285171981 on epoch=12
06/17/2022 06:21:56 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.05 on epoch=12
06/17/2022 06:21:59 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.09 on epoch=12
06/17/2022 06:22:02 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.10 on epoch=12
06/17/2022 06:22:04 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.12 on epoch=12
06/17/2022 06:22:07 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.06 on epoch=12
06/17/2022 06:22:57 - INFO - __main__ - Global step 1400 Train loss 0.08 Classification-F1 0.7991593853943006 on epoch=12
06/17/2022 06:22:59 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.10 on epoch=12
06/17/2022 06:23:02 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.06 on epoch=12
06/17/2022 06:23:04 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.07 on epoch=12
06/17/2022 06:23:07 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.04 on epoch=12
06/17/2022 06:23:10 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.11 on epoch=12
06/17/2022 06:24:01 - INFO - __main__ - Global step 1450 Train loss 0.07 Classification-F1 0.912314563086487 on epoch=12
06/17/2022 06:24:01 - INFO - __main__ - Saving model with best Classification-F1: 0.8860009694233589 -> 0.912314563086487 on epoch=12, global_step=1450
06/17/2022 06:24:04 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.08 on epoch=13
06/17/2022 06:24:06 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.06 on epoch=13
06/17/2022 06:24:09 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.05 on epoch=13
06/17/2022 06:24:12 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.06 on epoch=13
06/17/2022 06:24:14 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.12 on epoch=13
06/17/2022 06:25:07 - INFO - __main__ - Global step 1500 Train loss 0.08 Classification-F1 0.8488686691078112 on epoch=13
06/17/2022 06:25:09 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.08 on epoch=13
06/17/2022 06:25:12 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.09 on epoch=13
06/17/2022 06:25:14 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.09 on epoch=13
06/17/2022 06:25:17 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.09 on epoch=13
06/17/2022 06:25:20 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.11 on epoch=13
06/17/2022 06:26:10 - INFO - __main__ - Global step 1550 Train loss 0.09 Classification-F1 0.9117820745658725 on epoch=13
06/17/2022 06:26:13 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.06 on epoch=13
06/17/2022 06:26:15 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.11 on epoch=14
06/17/2022 06:26:18 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.10 on epoch=14
06/17/2022 06:26:20 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.07 on epoch=14
06/17/2022 06:26:23 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.16 on epoch=14
06/17/2022 06:27:15 - INFO - __main__ - Global step 1600 Train loss 0.10 Classification-F1 0.8563502391387492 on epoch=14
06/17/2022 06:27:17 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.13 on epoch=14
06/17/2022 06:27:20 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.06 on epoch=14
06/17/2022 06:27:22 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.05 on epoch=14
06/17/2022 06:27:25 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.06 on epoch=14
06/17/2022 06:27:28 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.05 on epoch=14
06/17/2022 06:28:20 - INFO - __main__ - Global step 1650 Train loss 0.07 Classification-F1 0.8041521380110135 on epoch=14
06/17/2022 06:28:23 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.08 on epoch=14
06/17/2022 06:28:25 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.04 on epoch=14
06/17/2022 06:28:28 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.12 on epoch=14
06/17/2022 06:28:31 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.07 on epoch=15
06/17/2022 06:28:33 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.10 on epoch=15
06/17/2022 06:29:23 - INFO - __main__ - Global step 1700 Train loss 0.08 Classification-F1 0.9105132394231691 on epoch=15
06/17/2022 06:29:26 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.08 on epoch=15
06/17/2022 06:29:29 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.06 on epoch=15
06/17/2022 06:29:31 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.11 on epoch=15
06/17/2022 06:29:34 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.05 on epoch=15
06/17/2022 06:29:36 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.06 on epoch=15
06/17/2022 06:30:28 - INFO - __main__ - Global step 1750 Train loss 0.07 Classification-F1 0.9107056419842225 on epoch=15
06/17/2022 06:30:30 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.03 on epoch=15
06/17/2022 06:30:33 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.11 on epoch=15
06/17/2022 06:30:36 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.04 on epoch=15
06/17/2022 06:30:38 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.09 on epoch=15
06/17/2022 06:30:41 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.07 on epoch=16
06/17/2022 06:31:33 - INFO - __main__ - Global step 1800 Train loss 0.07 Classification-F1 0.9167278330721423 on epoch=16
06/17/2022 06:31:33 - INFO - __main__ - Saving model with best Classification-F1: 0.912314563086487 -> 0.9167278330721423 on epoch=16, global_step=1800
06/17/2022 06:31:36 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.03 on epoch=16
06/17/2022 06:31:38 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.05 on epoch=16
06/17/2022 06:31:41 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.11 on epoch=16
06/17/2022 06:31:43 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.11 on epoch=16
06/17/2022 06:31:46 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.07 on epoch=16
06/17/2022 06:32:33 - INFO - __main__ - Global step 1850 Train loss 0.07 Classification-F1 0.9162807243435311 on epoch=16
06/17/2022 06:32:36 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.11 on epoch=16
06/17/2022 06:32:39 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.10 on epoch=16
06/17/2022 06:32:41 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.06 on epoch=16
06/17/2022 06:32:44 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.04 on epoch=16
06/17/2022 06:32:46 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.08 on epoch=16
06/17/2022 06:33:37 - INFO - __main__ - Global step 1900 Train loss 0.08 Classification-F1 0.9139059751334232 on epoch=16
06/17/2022 06:33:39 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=17
06/17/2022 06:33:42 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.04 on epoch=17
06/17/2022 06:33:45 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.06 on epoch=17
06/17/2022 06:33:47 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.05 on epoch=17
06/17/2022 06:33:50 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.08 on epoch=17
06/17/2022 06:34:39 - INFO - __main__ - Global step 1950 Train loss 0.05 Classification-F1 0.8009020680852653 on epoch=17
06/17/2022 06:34:41 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=17
06/17/2022 06:34:44 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.15 on epoch=17
06/17/2022 06:34:46 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.05 on epoch=17
06/17/2022 06:34:49 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=17
06/17/2022 06:34:52 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.04 on epoch=17
06/17/2022 06:35:39 - INFO - __main__ - Global step 2000 Train loss 0.05 Classification-F1 0.8062634263047638 on epoch=17
06/17/2022 06:35:42 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=17
06/17/2022 06:35:45 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.04 on epoch=18
06/17/2022 06:35:47 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.04 on epoch=18
06/17/2022 06:35:50 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.07 on epoch=18
06/17/2022 06:35:53 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.05 on epoch=18
06/17/2022 06:36:42 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.8037612509562162 on epoch=18
06/17/2022 06:36:44 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.13 on epoch=18
06/17/2022 06:36:47 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.09 on epoch=18
06/17/2022 06:36:50 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.06 on epoch=18
06/17/2022 06:36:52 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.03 on epoch=18
06/17/2022 06:36:55 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.09 on epoch=18
06/17/2022 06:37:46 - INFO - __main__ - Global step 2100 Train loss 0.08 Classification-F1 0.8089514569719176 on epoch=18
06/17/2022 06:37:48 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.06 on epoch=18
06/17/2022 06:37:51 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.05 on epoch=18
06/17/2022 06:37:53 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.08 on epoch=19
06/17/2022 06:37:56 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=19
06/17/2022 06:37:59 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.03 on epoch=19
06/17/2022 06:38:50 - INFO - __main__ - Global step 2150 Train loss 0.05 Classification-F1 0.8496840269843406 on epoch=19
06/17/2022 06:38:52 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.03 on epoch=19
06/17/2022 06:38:55 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.08 on epoch=19
06/17/2022 06:38:58 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.04 on epoch=19
06/17/2022 06:39:00 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=19
06/17/2022 06:39:03 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=19
06/17/2022 06:39:53 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.8587922533227853 on epoch=19
06/17/2022 06:39:55 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.06 on epoch=19
06/17/2022 06:39:58 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.05 on epoch=19
06/17/2022 06:40:01 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.06 on epoch=19
06/17/2022 06:40:03 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.04 on epoch=19
06/17/2022 06:40:06 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=20
06/17/2022 06:41:00 - INFO - __main__ - Global step 2250 Train loss 0.05 Classification-F1 0.8048748781496137 on epoch=20
06/17/2022 06:41:02 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.04 on epoch=20
06/17/2022 06:41:05 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.07 on epoch=20
06/17/2022 06:41:08 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.07 on epoch=20
06/17/2022 06:41:10 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.05 on epoch=20
06/17/2022 06:41:13 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=20
06/17/2022 06:42:06 - INFO - __main__ - Global step 2300 Train loss 0.05 Classification-F1 0.891145846690463 on epoch=20
06/17/2022 06:42:09 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.08 on epoch=20
06/17/2022 06:42:11 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.06 on epoch=20
06/17/2022 06:42:14 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.04 on epoch=20
06/17/2022 06:42:16 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=20
06/17/2022 06:42:19 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.05 on epoch=20
06/17/2022 06:43:10 - INFO - __main__ - Global step 2350 Train loss 0.05 Classification-F1 0.7790698961002063 on epoch=20
06/17/2022 06:43:13 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.04 on epoch=21
06/17/2022 06:43:15 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=21
06/17/2022 06:43:18 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.11 on epoch=21
06/17/2022 06:43:21 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.04 on epoch=21
06/17/2022 06:43:23 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.04 on epoch=21
06/17/2022 06:44:13 - INFO - __main__ - Global step 2400 Train loss 0.05 Classification-F1 0.7940119736735723 on epoch=21
06/17/2022 06:44:15 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=21
06/17/2022 06:44:18 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.03 on epoch=21
06/17/2022 06:44:20 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.04 on epoch=21
06/17/2022 06:44:23 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.06 on epoch=21
06/17/2022 06:44:26 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.03 on epoch=21
06/17/2022 06:45:14 - INFO - __main__ - Global step 2450 Train loss 0.04 Classification-F1 0.7931521283882861 on epoch=21
06/17/2022 06:45:16 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.06 on epoch=21
06/17/2022 06:45:19 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=22
06/17/2022 06:45:22 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.05 on epoch=22
06/17/2022 06:45:24 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.09 on epoch=22
06/17/2022 06:45:27 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.05 on epoch=22
06/17/2022 06:46:16 - INFO - __main__ - Global step 2500 Train loss 0.06 Classification-F1 0.8010713159984229 on epoch=22
06/17/2022 06:46:18 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.11 on epoch=22
06/17/2022 06:46:21 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=22
06/17/2022 06:46:23 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.05 on epoch=22
06/17/2022 06:46:26 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.06 on epoch=22
06/17/2022 06:46:29 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=22
06/17/2022 06:47:17 - INFO - __main__ - Global step 2550 Train loss 0.05 Classification-F1 0.9167213014996789 on epoch=22
06/17/2022 06:47:20 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.04 on epoch=22
06/17/2022 06:47:22 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.04 on epoch=22
06/17/2022 06:47:25 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.09 on epoch=23
06/17/2022 06:47:28 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=23
06/17/2022 06:47:30 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=23
06/17/2022 06:48:21 - INFO - __main__ - Global step 2600 Train loss 0.04 Classification-F1 0.90287373314727 on epoch=23
06/17/2022 06:48:23 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.04 on epoch=23
06/17/2022 06:48:26 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.10 on epoch=23
06/17/2022 06:48:29 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.03 on epoch=23
06/17/2022 06:48:31 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.05 on epoch=23
06/17/2022 06:48:34 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.03 on epoch=23
06/17/2022 06:49:25 - INFO - __main__ - Global step 2650 Train loss 0.05 Classification-F1 0.8547858947659186 on epoch=23
06/17/2022 06:49:27 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=23
06/17/2022 06:49:30 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.08 on epoch=23
06/17/2022 06:49:32 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=23
06/17/2022 06:49:35 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.07 on epoch=24
06/17/2022 06:49:38 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.07 on epoch=24
06/17/2022 06:50:28 - INFO - __main__ - Global step 2700 Train loss 0.05 Classification-F1 0.9170566139656822 on epoch=24
06/17/2022 06:50:28 - INFO - __main__ - Saving model with best Classification-F1: 0.9167278330721423 -> 0.9170566139656822 on epoch=24, global_step=2700
06/17/2022 06:50:31 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.06 on epoch=24
06/17/2022 06:50:34 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.04 on epoch=24
06/17/2022 06:50:36 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.05 on epoch=24
06/17/2022 06:50:39 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.04 on epoch=24
06/17/2022 06:50:42 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.07 on epoch=24
06/17/2022 06:51:32 - INFO - __main__ - Global step 2750 Train loss 0.05 Classification-F1 0.8587596536220025 on epoch=24
06/17/2022 06:51:35 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.05 on epoch=24
06/17/2022 06:51:37 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.05 on epoch=24
06/17/2022 06:51:40 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.04 on epoch=24
06/17/2022 06:51:43 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=24
06/17/2022 06:51:45 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.10 on epoch=24
06/17/2022 06:52:35 - INFO - __main__ - Global step 2800 Train loss 0.05 Classification-F1 0.9207722887286676 on epoch=24
06/17/2022 06:52:35 - INFO - __main__ - Saving model with best Classification-F1: 0.9170566139656822 -> 0.9207722887286676 on epoch=24, global_step=2800
06/17/2022 06:52:38 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.05 on epoch=25
06/17/2022 06:52:40 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.05 on epoch=25
06/17/2022 06:52:43 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.04 on epoch=25
06/17/2022 06:52:45 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.05 on epoch=25
06/17/2022 06:52:48 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.04 on epoch=25
06/17/2022 06:53:39 - INFO - __main__ - Global step 2850 Train loss 0.05 Classification-F1 0.8076841983642705 on epoch=25
06/17/2022 06:53:42 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=25
06/17/2022 06:53:44 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.05 on epoch=25
06/17/2022 06:53:47 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.04 on epoch=25
06/17/2022 06:53:49 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.03 on epoch=25
06/17/2022 06:53:52 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=25
06/17/2022 06:54:43 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.9189472865087647 on epoch=25
06/17/2022 06:54:46 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.04 on epoch=25
06/17/2022 06:54:48 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=26
06/17/2022 06:54:51 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=26
06/17/2022 06:54:54 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=26
06/17/2022 06:54:56 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=26
06/17/2022 06:55:47 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.9166370553666443 on epoch=26
06/17/2022 06:55:49 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.03 on epoch=26
06/17/2022 06:55:52 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=26
06/17/2022 06:55:54 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.04 on epoch=26
06/17/2022 06:55:57 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=26
06/17/2022 06:56:00 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=26
06/17/2022 06:56:48 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.8696679671695068 on epoch=26
06/17/2022 06:56:48 - INFO - __main__ - save last model!
06/17/2022 06:56:48 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/17/2022 06:56:48 - INFO - __main__ - Start tokenizing ... 3500 instances
06/17/2022 06:56:48 - INFO - __main__ - Printing 3 examples
06/17/2022 06:56:48 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/17/2022 06:56:48 - INFO - __main__ - ['Animal']
06/17/2022 06:56:48 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/17/2022 06:56:48 - INFO - __main__ - ['Animal']
06/17/2022 06:56:48 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/17/2022 06:56:48 - INFO - __main__ - ['Village']
06/17/2022 06:56:48 - INFO - __main__ - Tokenizing Input ...
06/17/2022 06:56:50 - INFO - __main__ - Tokenizing Output ...
06/17/2022 06:56:53 - INFO - __main__ - Loaded 3500 examples from test data
06/17/2022 06:59:02 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down128shot/singletask-dbpedia_14/dbpedia_14_128_87_0.2_8_predictions.txt
06/17/2022 06:59:02 - INFO - __main__ - Classification-F1 on test data: 0.6946
06/17/2022 06:59:03 - INFO - __main__ - prefix=dbpedia_14_128_87, lr=0.2, bsz=8, dev_performance=0.9207722887286676, test_performance=0.6945716107710118
