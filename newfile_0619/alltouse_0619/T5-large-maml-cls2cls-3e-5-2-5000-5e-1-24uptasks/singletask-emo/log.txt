05/30/2022 16:55:13 - INFO - __main__ - Namespace(task_dir='data/emo/', task_name='emo', identifier='T5-large-maml-cls2cls-3e-5-2-5000-5e-1-24uptasks', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-24uptasks/singletask-emo', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-maml-cls2cls-3e-5-2-5000-5e-1-24uptasks/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='0,1')
05/30/2022 16:55:13 - INFO - __main__ - models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-24uptasks/singletask-emo
05/30/2022 16:55:13 - INFO - __main__ - Namespace(task_dir='data/emo/', task_name='emo', identifier='T5-large-maml-cls2cls-3e-5-2-5000-5e-1-24uptasks', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-24uptasks/singletask-emo', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-maml-cls2cls-3e-5-2-5000-5e-1-24uptasks/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='0,1')
05/30/2022 16:55:13 - INFO - __main__ - models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-24uptasks/singletask-emo
05/30/2022 16:55:14 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
05/30/2022 16:55:14 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
05/30/2022 16:55:14 - INFO - __main__ - args.device: cuda:0
05/30/2022 16:55:14 - INFO - __main__ - Using 2 gpus
05/30/2022 16:55:14 - INFO - __main__ - args.device: cuda:1
05/30/2022 16:55:14 - INFO - __main__ - Using 2 gpus
05/30/2022 16:55:14 - INFO - __main__ - Fine-tuning the following samples: ['emo_16_100', 'emo_16_13', 'emo_16_21', 'emo_16_42', 'emo_16_87']
05/30/2022 16:55:14 - INFO - __main__ - Fine-tuning the following samples: ['emo_16_100', 'emo_16_13', 'emo_16_21', 'emo_16_42', 'emo_16_87']
05/30/2022 16:55:18 - INFO - __main__ - Running ... prefix=emo_16_100, lr=0.5, bsz=8 ...
05/30/2022 16:55:19 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 16:55:19 - INFO - __main__ - Printing 3 examples
05/30/2022 16:55:19 - INFO - __main__ -  [emo] how cause yes am listening
05/30/2022 16:55:19 - INFO - __main__ - ['others']
05/30/2022 16:55:19 - INFO - __main__ -  [emo] ok that way i like living wwrong
05/30/2022 16:55:19 - INFO - __main__ - ['others']
05/30/2022 16:55:19 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
05/30/2022 16:55:19 - INFO - __main__ - ['others']
05/30/2022 16:55:19 - INFO - __main__ - Tokenizing Input ...
05/30/2022 16:55:19 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 16:55:19 - INFO - __main__ - Printing 3 examples
05/30/2022 16:55:19 - INFO - __main__ -  [emo] how cause yes am listening
05/30/2022 16:55:19 - INFO - __main__ - ['others']
05/30/2022 16:55:19 - INFO - __main__ -  [emo] ok that way i like living wwrong
05/30/2022 16:55:19 - INFO - __main__ - ['others']
05/30/2022 16:55:19 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
05/30/2022 16:55:19 - INFO - __main__ - ['others']
05/30/2022 16:55:19 - INFO - __main__ - Tokenizing Input ...
05/30/2022 16:55:19 - INFO - __main__ - Tokenizing Output ...
05/30/2022 16:55:19 - INFO - __main__ - Tokenizing Output ...
05/30/2022 16:55:19 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 16:55:19 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 16:55:19 - INFO - __main__ - Printing 3 examples
05/30/2022 16:55:19 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
05/30/2022 16:55:19 - INFO - __main__ - ['others']
05/30/2022 16:55:19 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
05/30/2022 16:55:19 - INFO - __main__ - ['others']
05/30/2022 16:55:19 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
05/30/2022 16:55:19 - INFO - __main__ - ['others']
05/30/2022 16:55:19 - INFO - __main__ - Tokenizing Input ...
05/30/2022 16:55:19 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 16:55:19 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 16:55:19 - INFO - __main__ - Printing 3 examples
05/30/2022 16:55:19 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
05/30/2022 16:55:19 - INFO - __main__ - ['others']
05/30/2022 16:55:19 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
05/30/2022 16:55:19 - INFO - __main__ - ['others']
05/30/2022 16:55:19 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
05/30/2022 16:55:19 - INFO - __main__ - ['others']
05/30/2022 16:55:19 - INFO - __main__ - Tokenizing Input ...
05/30/2022 16:55:19 - INFO - __main__ - Tokenizing Output ...
05/30/2022 16:55:19 - INFO - __main__ - Tokenizing Output ...
05/30/2022 16:55:19 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 16:55:19 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 16:55:37 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 16:55:37 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 16:55:38 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/30/2022 16:55:38 - INFO - __main__ - Starting training!
05/30/2022 16:55:43 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/30/2022 16:55:43 - INFO - __main__ - Starting training!
05/30/2022 16:55:46 - INFO - __main__ - Step 10 Global step 10 Train loss 3.33 on epoch=2
05/30/2022 16:55:49 - INFO - __main__ - Step 20 Global step 20 Train loss 1.48 on epoch=4
05/30/2022 16:55:51 - INFO - __main__ - Step 30 Global step 30 Train loss 1.20 on epoch=7
05/30/2022 16:55:53 - INFO - __main__ - Step 40 Global step 40 Train loss 1.04 on epoch=9
05/30/2022 16:55:56 - INFO - __main__ - Step 50 Global step 50 Train loss 0.99 on epoch=12
05/30/2022 16:55:57 - INFO - __main__ - Global step 50 Train loss 1.61 Classification-F1 0.439089309812994 on epoch=12
05/30/2022 16:55:57 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.439089309812994 on epoch=12, global_step=50
05/30/2022 16:55:59 - INFO - __main__ - Step 60 Global step 60 Train loss 0.78 on epoch=14
05/30/2022 16:56:01 - INFO - __main__ - Step 70 Global step 70 Train loss 0.96 on epoch=17
05/30/2022 16:56:04 - INFO - __main__ - Step 80 Global step 80 Train loss 0.78 on epoch=19
05/30/2022 16:56:06 - INFO - __main__ - Step 90 Global step 90 Train loss 0.89 on epoch=22
05/30/2022 16:56:08 - INFO - __main__ - Step 100 Global step 100 Train loss 0.82 on epoch=24
05/30/2022 16:56:09 - INFO - __main__ - Global step 100 Train loss 0.85 Classification-F1 0.1581196581196581 on epoch=24
05/30/2022 16:56:12 - INFO - __main__ - Step 110 Global step 110 Train loss 0.79 on epoch=27
05/30/2022 16:56:14 - INFO - __main__ - Step 120 Global step 120 Train loss 0.72 on epoch=29
05/30/2022 16:56:16 - INFO - __main__ - Step 130 Global step 130 Train loss 0.81 on epoch=32
05/30/2022 16:56:19 - INFO - __main__ - Step 140 Global step 140 Train loss 0.83 on epoch=34
05/30/2022 16:56:21 - INFO - __main__ - Step 150 Global step 150 Train loss 0.74 on epoch=37
05/30/2022 16:56:22 - INFO - __main__ - Global step 150 Train loss 0.78 Classification-F1 0.5652803468395673 on epoch=37
05/30/2022 16:56:22 - INFO - __main__ - Saving model with best Classification-F1: 0.439089309812994 -> 0.5652803468395673 on epoch=37, global_step=150
05/30/2022 16:56:24 - INFO - __main__ - Step 160 Global step 160 Train loss 0.64 on epoch=39
05/30/2022 16:56:27 - INFO - __main__ - Step 170 Global step 170 Train loss 0.67 on epoch=42
05/30/2022 16:56:29 - INFO - __main__ - Step 180 Global step 180 Train loss 0.71 on epoch=44
05/30/2022 16:56:32 - INFO - __main__ - Step 190 Global step 190 Train loss 0.70 on epoch=47
05/30/2022 16:56:34 - INFO - __main__ - Step 200 Global step 200 Train loss 0.65 on epoch=49
05/30/2022 16:56:35 - INFO - __main__ - Global step 200 Train loss 0.68 Classification-F1 0.6233774961597542 on epoch=49
05/30/2022 16:56:35 - INFO - __main__ - Saving model with best Classification-F1: 0.5652803468395673 -> 0.6233774961597542 on epoch=49, global_step=200
05/30/2022 16:56:37 - INFO - __main__ - Step 210 Global step 210 Train loss 0.61 on epoch=52
05/30/2022 16:56:40 - INFO - __main__ - Step 220 Global step 220 Train loss 0.66 on epoch=54
05/30/2022 16:56:42 - INFO - __main__ - Step 230 Global step 230 Train loss 0.60 on epoch=57
05/30/2022 16:56:44 - INFO - __main__ - Step 240 Global step 240 Train loss 0.52 on epoch=59
05/30/2022 16:56:47 - INFO - __main__ - Step 250 Global step 250 Train loss 0.49 on epoch=62
05/30/2022 16:56:48 - INFO - __main__ - Global step 250 Train loss 0.58 Classification-F1 0.6066494627250835 on epoch=62
05/30/2022 16:56:50 - INFO - __main__ - Step 260 Global step 260 Train loss 0.59 on epoch=64
05/30/2022 16:56:52 - INFO - __main__ - Step 270 Global step 270 Train loss 0.54 on epoch=67
05/30/2022 16:56:55 - INFO - __main__ - Step 280 Global step 280 Train loss 0.48 on epoch=69
05/30/2022 16:56:57 - INFO - __main__ - Step 290 Global step 290 Train loss 0.45 on epoch=72
05/30/2022 16:57:00 - INFO - __main__ - Step 300 Global step 300 Train loss 0.48 on epoch=74
05/30/2022 16:57:00 - INFO - __main__ - Global step 300 Train loss 0.51 Classification-F1 0.5234068296199046 on epoch=74
05/30/2022 16:57:03 - INFO - __main__ - Step 310 Global step 310 Train loss 0.40 on epoch=77
05/30/2022 16:57:05 - INFO - __main__ - Step 320 Global step 320 Train loss 0.35 on epoch=79
05/30/2022 16:57:07 - INFO - __main__ - Step 330 Global step 330 Train loss 0.49 on epoch=82
05/30/2022 16:57:10 - INFO - __main__ - Step 340 Global step 340 Train loss 0.34 on epoch=84
05/30/2022 16:57:12 - INFO - __main__ - Step 350 Global step 350 Train loss 0.50 on epoch=87
05/30/2022 16:57:13 - INFO - __main__ - Global step 350 Train loss 0.42 Classification-F1 0.6671222976370036 on epoch=87
05/30/2022 16:57:13 - INFO - __main__ - Saving model with best Classification-F1: 0.6233774961597542 -> 0.6671222976370036 on epoch=87, global_step=350
05/30/2022 16:57:15 - INFO - __main__ - Step 360 Global step 360 Train loss 0.42 on epoch=89
05/30/2022 16:57:18 - INFO - __main__ - Step 370 Global step 370 Train loss 0.44 on epoch=92
05/30/2022 16:57:20 - INFO - __main__ - Step 380 Global step 380 Train loss 0.36 on epoch=94
05/30/2022 16:57:23 - INFO - __main__ - Step 390 Global step 390 Train loss 0.33 on epoch=97
05/30/2022 16:57:25 - INFO - __main__ - Step 400 Global step 400 Train loss 0.33 on epoch=99
05/30/2022 16:57:26 - INFO - __main__ - Global step 400 Train loss 0.37 Classification-F1 0.6494484559900382 on epoch=99
05/30/2022 16:57:28 - INFO - __main__ - Step 410 Global step 410 Train loss 0.37 on epoch=102
05/30/2022 16:57:30 - INFO - __main__ - Step 420 Global step 420 Train loss 0.34 on epoch=104
05/30/2022 16:57:33 - INFO - __main__ - Step 430 Global step 430 Train loss 0.35 on epoch=107
05/30/2022 16:57:35 - INFO - __main__ - Step 440 Global step 440 Train loss 0.28 on epoch=109
05/30/2022 16:57:38 - INFO - __main__ - Step 450 Global step 450 Train loss 0.27 on epoch=112
05/30/2022 16:57:38 - INFO - __main__ - Global step 450 Train loss 0.32 Classification-F1 0.5965666508538899 on epoch=112
05/30/2022 16:57:41 - INFO - __main__ - Step 460 Global step 460 Train loss 0.33 on epoch=114
05/30/2022 16:57:43 - INFO - __main__ - Step 470 Global step 470 Train loss 0.31 on epoch=117
05/30/2022 16:57:46 - INFO - __main__ - Step 480 Global step 480 Train loss 0.30 on epoch=119
05/30/2022 16:57:48 - INFO - __main__ - Step 490 Global step 490 Train loss 0.21 on epoch=122
05/30/2022 16:57:50 - INFO - __main__ - Step 500 Global step 500 Train loss 0.26 on epoch=124
05/30/2022 16:57:51 - INFO - __main__ - Global step 500 Train loss 0.28 Classification-F1 0.6834097275273746 on epoch=124
05/30/2022 16:57:51 - INFO - __main__ - Saving model with best Classification-F1: 0.6671222976370036 -> 0.6834097275273746 on epoch=124, global_step=500
05/30/2022 16:57:54 - INFO - __main__ - Step 510 Global step 510 Train loss 0.22 on epoch=127
05/30/2022 16:57:56 - INFO - __main__ - Step 520 Global step 520 Train loss 0.13 on epoch=129
05/30/2022 16:57:58 - INFO - __main__ - Step 530 Global step 530 Train loss 0.16 on epoch=132
05/30/2022 16:58:01 - INFO - __main__ - Step 540 Global step 540 Train loss 0.14 on epoch=134
05/30/2022 16:58:03 - INFO - __main__ - Step 550 Global step 550 Train loss 0.13 on epoch=137
05/30/2022 16:58:04 - INFO - __main__ - Global step 550 Train loss 0.15 Classification-F1 0.6221240512333965 on epoch=137
05/30/2022 16:58:06 - INFO - __main__ - Step 560 Global step 560 Train loss 0.15 on epoch=139
05/30/2022 16:58:09 - INFO - __main__ - Step 570 Global step 570 Train loss 0.11 on epoch=142
05/30/2022 16:58:11 - INFO - __main__ - Step 580 Global step 580 Train loss 0.18 on epoch=144
05/30/2022 16:58:14 - INFO - __main__ - Step 590 Global step 590 Train loss 0.03 on epoch=147
05/30/2022 16:58:16 - INFO - __main__ - Step 600 Global step 600 Train loss 0.27 on epoch=149
05/30/2022 16:58:17 - INFO - __main__ - Global step 600 Train loss 0.15 Classification-F1 0.6090241056273664 on epoch=149
05/30/2022 16:58:19 - INFO - __main__ - Step 610 Global step 610 Train loss 0.14 on epoch=152
05/30/2022 16:58:22 - INFO - __main__ - Step 620 Global step 620 Train loss 0.11 on epoch=154
05/30/2022 16:58:24 - INFO - __main__ - Step 630 Global step 630 Train loss 0.08 on epoch=157
05/30/2022 16:58:26 - INFO - __main__ - Step 640 Global step 640 Train loss 0.12 on epoch=159
05/30/2022 16:58:29 - INFO - __main__ - Step 650 Global step 650 Train loss 0.14 on epoch=162
05/30/2022 16:58:29 - INFO - __main__ - Global step 650 Train loss 0.12 Classification-F1 0.6827380952380953 on epoch=162
05/30/2022 16:58:32 - INFO - __main__ - Step 660 Global step 660 Train loss 0.15 on epoch=164
05/30/2022 16:58:34 - INFO - __main__ - Step 670 Global step 670 Train loss 0.12 on epoch=167
05/30/2022 16:58:37 - INFO - __main__ - Step 680 Global step 680 Train loss 0.09 on epoch=169
05/30/2022 16:58:39 - INFO - __main__ - Step 690 Global step 690 Train loss 0.06 on epoch=172
05/30/2022 16:58:41 - INFO - __main__ - Step 700 Global step 700 Train loss 0.16 on epoch=174
05/30/2022 16:58:42 - INFO - __main__ - Global step 700 Train loss 0.12 Classification-F1 0.6374803055383818 on epoch=174
05/30/2022 16:58:45 - INFO - __main__ - Step 710 Global step 710 Train loss 0.16 on epoch=177
05/30/2022 16:58:47 - INFO - __main__ - Step 720 Global step 720 Train loss 0.11 on epoch=179
05/30/2022 16:58:49 - INFO - __main__ - Step 730 Global step 730 Train loss 0.03 on epoch=182
05/30/2022 16:58:52 - INFO - __main__ - Step 740 Global step 740 Train loss 0.10 on epoch=184
05/30/2022 16:58:54 - INFO - __main__ - Step 750 Global step 750 Train loss 0.06 on epoch=187
05/30/2022 16:58:55 - INFO - __main__ - Global step 750 Train loss 0.09 Classification-F1 0.6351201201201201 on epoch=187
05/30/2022 16:58:57 - INFO - __main__ - Step 760 Global step 760 Train loss 0.08 on epoch=189
05/30/2022 16:59:00 - INFO - __main__ - Step 770 Global step 770 Train loss 0.07 on epoch=192
05/30/2022 16:59:02 - INFO - __main__ - Step 780 Global step 780 Train loss 0.04 on epoch=194
05/30/2022 16:59:04 - INFO - __main__ - Step 790 Global step 790 Train loss 0.05 on epoch=197
05/30/2022 16:59:07 - INFO - __main__ - Step 800 Global step 800 Train loss 0.05 on epoch=199
05/30/2022 16:59:08 - INFO - __main__ - Global step 800 Train loss 0.06 Classification-F1 0.6681226565861453 on epoch=199
05/30/2022 16:59:10 - INFO - __main__ - Step 810 Global step 810 Train loss 0.02 on epoch=202
05/30/2022 16:59:12 - INFO - __main__ - Step 820 Global step 820 Train loss 0.16 on epoch=204
05/30/2022 16:59:15 - INFO - __main__ - Step 830 Global step 830 Train loss 0.06 on epoch=207
05/30/2022 16:59:17 - INFO - __main__ - Step 840 Global step 840 Train loss 0.09 on epoch=209
05/30/2022 16:59:20 - INFO - __main__ - Step 850 Global step 850 Train loss 0.05 on epoch=212
05/30/2022 16:59:20 - INFO - __main__ - Global step 850 Train loss 0.08 Classification-F1 0.632233028784753 on epoch=212
05/30/2022 16:59:23 - INFO - __main__ - Step 860 Global step 860 Train loss 0.02 on epoch=214
05/30/2022 16:59:25 - INFO - __main__ - Step 870 Global step 870 Train loss 0.02 on epoch=217
05/30/2022 16:59:28 - INFO - __main__ - Step 880 Global step 880 Train loss 0.14 on epoch=219
05/30/2022 16:59:30 - INFO - __main__ - Step 890 Global step 890 Train loss 0.03 on epoch=222
05/30/2022 16:59:32 - INFO - __main__ - Step 900 Global step 900 Train loss 0.02 on epoch=224
05/30/2022 16:59:33 - INFO - __main__ - Global step 900 Train loss 0.05 Classification-F1 0.6477885804203665 on epoch=224
05/30/2022 16:59:36 - INFO - __main__ - Step 910 Global step 910 Train loss 0.03 on epoch=227
05/30/2022 16:59:38 - INFO - __main__ - Step 920 Global step 920 Train loss 0.06 on epoch=229
05/30/2022 16:59:40 - INFO - __main__ - Step 930 Global step 930 Train loss 0.09 on epoch=232
05/30/2022 16:59:43 - INFO - __main__ - Step 940 Global step 940 Train loss 0.05 on epoch=234
05/30/2022 16:59:45 - INFO - __main__ - Step 950 Global step 950 Train loss 0.11 on epoch=237
05/30/2022 16:59:46 - INFO - __main__ - Global step 950 Train loss 0.07 Classification-F1 0.6659042033235582 on epoch=237
05/30/2022 16:59:48 - INFO - __main__ - Step 960 Global step 960 Train loss 0.15 on epoch=239
05/30/2022 16:59:51 - INFO - __main__ - Step 970 Global step 970 Train loss 0.03 on epoch=242
05/30/2022 16:59:53 - INFO - __main__ - Step 980 Global step 980 Train loss 0.08 on epoch=244
05/30/2022 16:59:55 - INFO - __main__ - Step 990 Global step 990 Train loss 0.05 on epoch=247
05/30/2022 16:59:58 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.07 on epoch=249
05/30/2022 16:59:59 - INFO - __main__ - Global step 1000 Train loss 0.07 Classification-F1 0.6820768537299977 on epoch=249
05/30/2022 17:00:01 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.05 on epoch=252
05/30/2022 17:00:03 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.04 on epoch=254
05/30/2022 17:00:06 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.06 on epoch=257
05/30/2022 17:00:08 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.06 on epoch=259
05/30/2022 17:00:11 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.02 on epoch=262
05/30/2022 17:00:11 - INFO - __main__ - Global step 1050 Train loss 0.05 Classification-F1 0.6583771225611833 on epoch=262
05/30/2022 17:00:14 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.06 on epoch=264
05/30/2022 17:00:16 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.01 on epoch=267
05/30/2022 17:00:19 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.02 on epoch=269
05/30/2022 17:00:21 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.02 on epoch=272
05/30/2022 17:00:23 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.01 on epoch=274
05/30/2022 17:00:24 - INFO - __main__ - Global step 1100 Train loss 0.02 Classification-F1 0.6330049261083744 on epoch=274
05/30/2022 17:00:27 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.01 on epoch=277
05/30/2022 17:00:29 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.05 on epoch=279
05/30/2022 17:00:31 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.03 on epoch=282
05/30/2022 17:00:34 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.01 on epoch=284
05/30/2022 17:00:36 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=287
05/30/2022 17:00:37 - INFO - __main__ - Global step 1150 Train loss 0.02 Classification-F1 0.6992845117845118 on epoch=287
05/30/2022 17:00:37 - INFO - __main__ - Saving model with best Classification-F1: 0.6834097275273746 -> 0.6992845117845118 on epoch=287, global_step=1150
05/30/2022 17:00:39 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.01 on epoch=289
05/30/2022 17:00:42 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.02 on epoch=292
05/30/2022 17:00:44 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.06 on epoch=294
05/30/2022 17:00:47 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.04 on epoch=297
05/30/2022 17:00:49 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.02 on epoch=299
05/30/2022 17:00:50 - INFO - __main__ - Global step 1200 Train loss 0.03 Classification-F1 0.7123758594346831 on epoch=299
05/30/2022 17:00:50 - INFO - __main__ - Saving model with best Classification-F1: 0.6992845117845118 -> 0.7123758594346831 on epoch=299, global_step=1200
05/30/2022 17:00:52 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.00 on epoch=302
05/30/2022 17:00:55 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=304
05/30/2022 17:00:58 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.09 on epoch=307
05/30/2022 17:01:01 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.02 on epoch=309
05/30/2022 17:01:03 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.15 on epoch=312
05/30/2022 17:01:04 - INFO - __main__ - Global step 1250 Train loss 0.05 Classification-F1 0.6845238095238095 on epoch=312
05/30/2022 17:01:07 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.00 on epoch=314
05/30/2022 17:01:09 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.02 on epoch=317
05/30/2022 17:01:11 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.05 on epoch=319
05/30/2022 17:01:14 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.04 on epoch=322
05/30/2022 17:01:16 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=324
05/30/2022 17:01:17 - INFO - __main__ - Global step 1300 Train loss 0.03 Classification-F1 0.7011107891432435 on epoch=324
05/30/2022 17:01:19 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.00 on epoch=327
05/30/2022 17:01:22 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.13 on epoch=329
05/30/2022 17:01:24 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=332
05/30/2022 17:01:27 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=334
05/30/2022 17:01:29 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.00 on epoch=337
05/30/2022 17:01:30 - INFO - __main__ - Global step 1350 Train loss 0.03 Classification-F1 0.6847248576850096 on epoch=337
05/30/2022 17:01:32 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.04 on epoch=339
05/30/2022 17:01:35 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.00 on epoch=342
05/30/2022 17:01:37 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.06 on epoch=344
05/30/2022 17:01:39 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.00 on epoch=347
05/30/2022 17:01:42 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=349
05/30/2022 17:01:43 - INFO - __main__ - Global step 1400 Train loss 0.03 Classification-F1 0.6803708133971292 on epoch=349
05/30/2022 17:01:45 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.02 on epoch=352
05/30/2022 17:01:47 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.03 on epoch=354
05/30/2022 17:01:50 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.03 on epoch=357
05/30/2022 17:01:52 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=359
05/30/2022 17:01:54 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.04 on epoch=362
05/30/2022 17:01:55 - INFO - __main__ - Global step 1450 Train loss 0.03 Classification-F1 0.7130566801619433 on epoch=362
05/30/2022 17:01:55 - INFO - __main__ - Saving model with best Classification-F1: 0.7123758594346831 -> 0.7130566801619433 on epoch=362, global_step=1450
05/30/2022 17:01:58 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.02 on epoch=364
05/30/2022 17:02:00 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.02 on epoch=367
05/30/2022 17:02:02 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.03 on epoch=369
05/30/2022 17:02:05 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=372
05/30/2022 17:02:07 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=374
05/30/2022 17:02:08 - INFO - __main__ - Global step 1500 Train loss 0.02 Classification-F1 0.6993448045362345 on epoch=374
05/30/2022 17:02:10 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=377
05/30/2022 17:02:13 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=379
05/30/2022 17:02:15 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=382
05/30/2022 17:02:18 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=384
05/30/2022 17:02:20 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=387
05/30/2022 17:02:21 - INFO - __main__ - Global step 1550 Train loss 0.01 Classification-F1 0.6934389140271493 on epoch=387
05/30/2022 17:02:23 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=389
05/30/2022 17:02:26 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=392
05/30/2022 17:02:28 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.05 on epoch=394
05/30/2022 17:02:31 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=397
05/30/2022 17:02:33 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.03 on epoch=399
05/30/2022 17:02:34 - INFO - __main__ - Global step 1600 Train loss 0.02 Classification-F1 0.6987554112554113 on epoch=399
05/30/2022 17:02:37 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.04 on epoch=402
05/30/2022 17:02:39 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=404
05/30/2022 17:02:42 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=407
05/30/2022 17:02:44 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=409
05/30/2022 17:02:47 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=412
05/30/2022 17:02:48 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.7000418935902808 on epoch=412
05/30/2022 17:02:50 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=414
05/30/2022 17:02:53 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=417
05/30/2022 17:02:55 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=419
05/30/2022 17:02:58 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=422
05/30/2022 17:03:00 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=424
05/30/2022 17:03:01 - INFO - __main__ - Global step 1700 Train loss 0.01 Classification-F1 0.7317376989980946 on epoch=424
05/30/2022 17:03:01 - INFO - __main__ - Saving model with best Classification-F1: 0.7130566801619433 -> 0.7317376989980946 on epoch=424, global_step=1700
05/30/2022 17:03:04 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=427
05/30/2022 17:03:06 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=429
05/30/2022 17:03:09 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=432
05/30/2022 17:03:11 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=434
05/30/2022 17:03:14 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=437
05/30/2022 17:03:15 - INFO - __main__ - Global step 1750 Train loss 0.01 Classification-F1 0.72750504000504 on epoch=437
05/30/2022 17:03:17 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.08 on epoch=439
05/30/2022 17:03:20 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=442
05/30/2022 17:03:22 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=444
05/30/2022 17:03:25 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=447
05/30/2022 17:03:27 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=449
05/30/2022 17:03:28 - INFO - __main__ - Global step 1800 Train loss 0.02 Classification-F1 0.7331177045598298 on epoch=449
05/30/2022 17:03:28 - INFO - __main__ - Saving model with best Classification-F1: 0.7317376989980946 -> 0.7331177045598298 on epoch=449, global_step=1800
05/30/2022 17:03:31 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=452
05/30/2022 17:03:33 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=454
05/30/2022 17:03:35 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=457
05/30/2022 17:03:38 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=459
05/30/2022 17:03:40 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=462
05/30/2022 17:03:41 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.6934389140271493 on epoch=462
05/30/2022 17:03:44 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=464
05/30/2022 17:03:46 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=467
05/30/2022 17:03:49 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=469
05/30/2022 17:03:51 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.07 on epoch=472
05/30/2022 17:03:54 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=474
05/30/2022 17:03:55 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.6832983193277311 on epoch=474
05/30/2022 17:03:57 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=477
05/30/2022 17:04:00 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.08 on epoch=479
05/30/2022 17:04:02 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=482
05/30/2022 17:04:05 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=484
05/30/2022 17:04:07 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=487
05/30/2022 17:04:08 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.7145362130762575 on epoch=487
05/30/2022 17:04:11 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=489
05/30/2022 17:04:13 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=492
05/30/2022 17:04:16 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.04 on epoch=494
05/30/2022 17:04:18 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=497
05/30/2022 17:04:21 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=499
05/30/2022 17:04:22 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.6985612426788899 on epoch=499
05/30/2022 17:04:24 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.03 on epoch=502
05/30/2022 17:04:27 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
05/30/2022 17:04:29 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.08 on epoch=507
05/30/2022 17:04:32 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=509
05/30/2022 17:04:34 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.03 on epoch=512
05/30/2022 17:04:35 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.6957441040932503 on epoch=512
05/30/2022 17:04:38 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=514
05/30/2022 17:04:40 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=517
05/30/2022 17:04:43 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=519
05/30/2022 17:04:45 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=522
05/30/2022 17:04:48 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=524
05/30/2022 17:04:49 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.7161709258483453 on epoch=524
05/30/2022 17:04:51 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
05/30/2022 17:04:54 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=529
05/30/2022 17:04:56 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
05/30/2022 17:04:59 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=534
05/30/2022 17:05:01 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=537
05/30/2022 17:05:02 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.6976699770817418 on epoch=537
05/30/2022 17:05:05 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=539
05/30/2022 17:05:07 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
05/30/2022 17:05:10 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=544
05/30/2022 17:05:12 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
05/30/2022 17:05:15 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
05/30/2022 17:05:16 - INFO - __main__ - Global step 2200 Train loss 0.00 Classification-F1 0.6976699770817418 on epoch=549
05/30/2022 17:05:18 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
05/30/2022 17:05:21 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
05/30/2022 17:05:23 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=557
05/30/2022 17:05:26 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
05/30/2022 17:05:28 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
05/30/2022 17:05:29 - INFO - __main__ - Global step 2250 Train loss 0.00 Classification-F1 0.6976699770817418 on epoch=562
05/30/2022 17:05:32 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
05/30/2022 17:05:34 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=567
05/30/2022 17:05:37 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
05/30/2022 17:05:39 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
05/30/2022 17:05:42 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
05/30/2022 17:05:43 - INFO - __main__ - Global step 2300 Train loss 0.00 Classification-F1 0.6817911255411256 on epoch=574
05/30/2022 17:05:45 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
05/30/2022 17:05:48 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=579
05/30/2022 17:05:50 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
05/30/2022 17:05:53 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
05/30/2022 17:05:55 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
05/30/2022 17:05:56 - INFO - __main__ - Global step 2350 Train loss 0.00 Classification-F1 0.6817911255411256 on epoch=587
05/30/2022 17:05:59 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
05/30/2022 17:06:01 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=592
05/30/2022 17:06:04 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
05/30/2022 17:06:06 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=597
05/30/2022 17:06:09 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
05/30/2022 17:06:10 - INFO - __main__ - Global step 2400 Train loss 0.00 Classification-F1 0.7149419524863236 on epoch=599
05/30/2022 17:06:13 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
05/30/2022 17:06:15 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
05/30/2022 17:06:18 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
05/30/2022 17:06:20 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
05/30/2022 17:06:23 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
05/30/2022 17:06:24 - INFO - __main__ - Global step 2450 Train loss 0.00 Classification-F1 0.7123758594346831 on epoch=612
05/30/2022 17:06:26 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=614
05/30/2022 17:06:29 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
05/30/2022 17:06:31 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=619
05/30/2022 17:06:34 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=622
05/30/2022 17:06:36 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
05/30/2022 17:06:37 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.6844696969696971 on epoch=624
05/30/2022 17:06:40 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
05/30/2022 17:06:42 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=629
05/30/2022 17:06:45 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
05/30/2022 17:06:47 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.03 on epoch=634
05/30/2022 17:06:50 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=637
05/30/2022 17:06:51 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.6953239360260233 on epoch=637
05/30/2022 17:06:53 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=639
05/30/2022 17:06:56 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=642
05/30/2022 17:06:58 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
05/30/2022 17:07:01 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
05/30/2022 17:07:03 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=649
05/30/2022 17:07:04 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.6778408452287288 on epoch=649
05/30/2022 17:07:07 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=652
05/30/2022 17:07:09 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
05/30/2022 17:07:12 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=657
05/30/2022 17:07:14 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
05/30/2022 17:07:17 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
05/30/2022 17:07:18 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.6948657121070915 on epoch=662
05/30/2022 17:07:21 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
05/30/2022 17:07:23 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
05/30/2022 17:07:26 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=669
05/30/2022 17:07:28 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=672
05/30/2022 17:07:31 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.05 on epoch=674
05/30/2022 17:07:32 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.7103839721006369 on epoch=674
05/30/2022 17:07:34 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
05/30/2022 17:07:37 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
05/30/2022 17:07:39 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
05/30/2022 17:07:42 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=684
05/30/2022 17:07:44 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
05/30/2022 17:07:46 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.7303450965025509 on epoch=687
05/30/2022 17:07:48 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=689
05/30/2022 17:07:51 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
05/30/2022 17:07:53 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
05/30/2022 17:07:56 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.03 on epoch=697
05/30/2022 17:07:58 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
05/30/2022 17:07:59 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.7452731092436975 on epoch=699
05/30/2022 17:07:59 - INFO - __main__ - Saving model with best Classification-F1: 0.7331177045598298 -> 0.7452731092436975 on epoch=699, global_step=2800
05/30/2022 17:08:02 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
05/30/2022 17:08:04 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
05/30/2022 17:08:07 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
05/30/2022 17:08:09 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=709
05/30/2022 17:08:12 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
05/30/2022 17:08:13 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.7490543394777266 on epoch=712
05/30/2022 17:08:13 - INFO - __main__ - Saving model with best Classification-F1: 0.7452731092436975 -> 0.7490543394777266 on epoch=712, global_step=2850
05/30/2022 17:08:16 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=714
05/30/2022 17:08:18 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.03 on epoch=717
05/30/2022 17:08:21 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
05/30/2022 17:08:23 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
05/30/2022 17:08:26 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.05 on epoch=724
05/30/2022 17:08:27 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.7255964755964757 on epoch=724
05/30/2022 17:08:29 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
05/30/2022 17:08:32 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.09 on epoch=729
05/30/2022 17:08:35 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
05/30/2022 17:08:37 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
05/30/2022 17:08:40 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
05/30/2022 17:08:41 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.7117845117845116 on epoch=737
05/30/2022 17:08:43 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
05/30/2022 17:08:46 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
05/30/2022 17:08:48 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
05/30/2022 17:08:51 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=747
05/30/2022 17:08:53 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
05/30/2022 17:08:55 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.7134357191152324 on epoch=749
05/30/2022 17:08:55 - INFO - __main__ - save last model!
05/30/2022 17:08:55 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/30/2022 17:08:55 - INFO - __main__ - Start tokenizing ... 5509 instances
05/30/2022 17:08:55 - INFO - __main__ - Printing 3 examples
05/30/2022 17:08:55 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/30/2022 17:08:55 - INFO - __main__ - ['others']
05/30/2022 17:08:55 - INFO - __main__ -  [emo] what you like very little things ok
05/30/2022 17:08:55 - INFO - __main__ - ['others']
05/30/2022 17:08:55 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/30/2022 17:08:55 - INFO - __main__ - ['others']
05/30/2022 17:08:55 - INFO - __main__ - Tokenizing Input ...
05/30/2022 17:08:55 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 17:08:55 - INFO - __main__ - Printing 3 examples
05/30/2022 17:08:55 - INFO - __main__ -  [emo] how cause yes am listening
05/30/2022 17:08:55 - INFO - __main__ - ['others']
05/30/2022 17:08:55 - INFO - __main__ -  [emo] ok that way i like living wwrong
05/30/2022 17:08:55 - INFO - __main__ - ['others']
05/30/2022 17:08:55 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
05/30/2022 17:08:55 - INFO - __main__ - ['others']
05/30/2022 17:08:55 - INFO - __main__ - Tokenizing Input ...
05/30/2022 17:08:55 - INFO - __main__ - Tokenizing Output ...
05/30/2022 17:08:55 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 17:08:55 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 17:08:55 - INFO - __main__ - Printing 3 examples
05/30/2022 17:08:55 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
05/30/2022 17:08:55 - INFO - __main__ - ['others']
05/30/2022 17:08:55 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
05/30/2022 17:08:55 - INFO - __main__ - ['others']
05/30/2022 17:08:55 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
05/30/2022 17:08:55 - INFO - __main__ - ['others']
05/30/2022 17:08:55 - INFO - __main__ - Tokenizing Input ...
05/30/2022 17:08:55 - INFO - __main__ - Tokenizing Output ...
05/30/2022 17:08:55 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 17:08:57 - INFO - __main__ - Tokenizing Output ...
05/30/2022 17:09:02 - INFO - __main__ - Loaded 5509 examples from test data
05/30/2022 17:09:13 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 17:09:14 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/30/2022 17:09:14 - INFO - __main__ - Starting training!
05/30/2022 17:10:35 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-24uptasks/singletask-emo/emo_16_100_0.5_8_predictions.txt
05/30/2022 17:10:35 - INFO - __main__ - Classification-F1 on test data: 0.3098
05/30/2022 17:10:36 - INFO - __main__ - prefix=emo_16_100, lr=0.5, bsz=8, dev_performance=0.7490543394777266, test_performance=0.3097757621174354
05/30/2022 17:10:36 - INFO - __main__ - Running ... prefix=emo_16_100, lr=0.4, bsz=8 ...
05/30/2022 17:10:37 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 17:10:37 - INFO - __main__ - Printing 3 examples
05/30/2022 17:10:37 - INFO - __main__ -  [emo] how cause yes am listening
05/30/2022 17:10:37 - INFO - __main__ - ['others']
05/30/2022 17:10:37 - INFO - __main__ -  [emo] ok that way i like living wwrong
05/30/2022 17:10:37 - INFO - __main__ - ['others']
05/30/2022 17:10:37 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
05/30/2022 17:10:37 - INFO - __main__ - ['others']
05/30/2022 17:10:37 - INFO - __main__ - Tokenizing Input ...
05/30/2022 17:10:37 - INFO - __main__ - Tokenizing Output ...
05/30/2022 17:10:37 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 17:10:37 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 17:10:37 - INFO - __main__ - Printing 3 examples
05/30/2022 17:10:37 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
05/30/2022 17:10:37 - INFO - __main__ - ['others']
05/30/2022 17:10:37 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
05/30/2022 17:10:37 - INFO - __main__ - ['others']
05/30/2022 17:10:37 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
05/30/2022 17:10:37 - INFO - __main__ - ['others']
05/30/2022 17:10:37 - INFO - __main__ - Tokenizing Input ...
05/30/2022 17:10:37 - INFO - __main__ - Tokenizing Output ...
05/30/2022 17:10:37 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 17:10:52 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 17:10:53 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/30/2022 17:10:53 - INFO - __main__ - Starting training!
05/30/2022 17:10:56 - INFO - __main__ - Step 10 Global step 10 Train loss 3.55 on epoch=2
05/30/2022 17:10:58 - INFO - __main__ - Step 20 Global step 20 Train loss 1.60 on epoch=4
05/30/2022 17:11:00 - INFO - __main__ - Step 30 Global step 30 Train loss 1.35 on epoch=7
05/30/2022 17:11:03 - INFO - __main__ - Step 40 Global step 40 Train loss 1.04 on epoch=9
05/30/2022 17:11:05 - INFO - __main__ - Step 50 Global step 50 Train loss 0.99 on epoch=12
05/30/2022 17:11:06 - INFO - __main__ - Global step 50 Train loss 1.71 Classification-F1 0.13067758749069247 on epoch=12
05/30/2022 17:11:06 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.13067758749069247 on epoch=12, global_step=50
05/30/2022 17:11:08 - INFO - __main__ - Step 60 Global step 60 Train loss 0.93 on epoch=14
05/30/2022 17:11:11 - INFO - __main__ - Step 70 Global step 70 Train loss 0.88 on epoch=17
05/30/2022 17:11:13 - INFO - __main__ - Step 80 Global step 80 Train loss 0.89 on epoch=19
05/30/2022 17:11:16 - INFO - __main__ - Step 90 Global step 90 Train loss 0.82 on epoch=22
05/30/2022 17:11:18 - INFO - __main__ - Step 100 Global step 100 Train loss 0.73 on epoch=24
05/30/2022 17:11:19 - INFO - __main__ - Global step 100 Train loss 0.85 Classification-F1 0.4770136484907283 on epoch=24
05/30/2022 17:11:19 - INFO - __main__ - Saving model with best Classification-F1: 0.13067758749069247 -> 0.4770136484907283 on epoch=24, global_step=100
05/30/2022 17:11:21 - INFO - __main__ - Step 110 Global step 110 Train loss 0.78 on epoch=27
05/30/2022 17:11:24 - INFO - __main__ - Step 120 Global step 120 Train loss 0.79 on epoch=29
05/30/2022 17:11:26 - INFO - __main__ - Step 130 Global step 130 Train loss 0.86 on epoch=32
05/30/2022 17:11:29 - INFO - __main__ - Step 140 Global step 140 Train loss 0.77 on epoch=34
05/30/2022 17:11:31 - INFO - __main__ - Step 150 Global step 150 Train loss 0.79 on epoch=37
05/30/2022 17:11:32 - INFO - __main__ - Global step 150 Train loss 0.80 Classification-F1 0.405958038909984 on epoch=37
05/30/2022 17:11:34 - INFO - __main__ - Step 160 Global step 160 Train loss 0.72 on epoch=39
05/30/2022 17:11:37 - INFO - __main__ - Step 170 Global step 170 Train loss 0.68 on epoch=42
05/30/2022 17:11:39 - INFO - __main__ - Step 180 Global step 180 Train loss 0.67 on epoch=44
05/30/2022 17:11:42 - INFO - __main__ - Step 190 Global step 190 Train loss 0.61 on epoch=47
05/30/2022 17:11:44 - INFO - __main__ - Step 200 Global step 200 Train loss 0.65 on epoch=49
05/30/2022 17:11:45 - INFO - __main__ - Global step 200 Train loss 0.67 Classification-F1 0.4830977845683728 on epoch=49
05/30/2022 17:11:45 - INFO - __main__ - Saving model with best Classification-F1: 0.4770136484907283 -> 0.4830977845683728 on epoch=49, global_step=200
05/30/2022 17:11:48 - INFO - __main__ - Step 210 Global step 210 Train loss 0.68 on epoch=52
05/30/2022 17:11:50 - INFO - __main__ - Step 220 Global step 220 Train loss 0.61 on epoch=54
05/30/2022 17:11:53 - INFO - __main__ - Step 230 Global step 230 Train loss 0.58 on epoch=57
05/30/2022 17:11:55 - INFO - __main__ - Step 240 Global step 240 Train loss 0.62 on epoch=59
05/30/2022 17:11:58 - INFO - __main__ - Step 250 Global step 250 Train loss 0.65 on epoch=62
05/30/2022 17:11:58 - INFO - __main__ - Global step 250 Train loss 0.63 Classification-F1 0.5327710580799826 on epoch=62
05/30/2022 17:11:58 - INFO - __main__ - Saving model with best Classification-F1: 0.4830977845683728 -> 0.5327710580799826 on epoch=62, global_step=250
05/30/2022 17:12:01 - INFO - __main__ - Step 260 Global step 260 Train loss 0.56 on epoch=64
05/30/2022 17:12:03 - INFO - __main__ - Step 270 Global step 270 Train loss 0.59 on epoch=67
05/30/2022 17:12:06 - INFO - __main__ - Step 280 Global step 280 Train loss 0.55 on epoch=69
05/30/2022 17:12:08 - INFO - __main__ - Step 290 Global step 290 Train loss 0.57 on epoch=72
05/30/2022 17:12:11 - INFO - __main__ - Step 300 Global step 300 Train loss 0.40 on epoch=74
05/30/2022 17:12:12 - INFO - __main__ - Global step 300 Train loss 0.54 Classification-F1 0.6153551110447663 on epoch=74
05/30/2022 17:12:12 - INFO - __main__ - Saving model with best Classification-F1: 0.5327710580799826 -> 0.6153551110447663 on epoch=74, global_step=300
05/30/2022 17:12:14 - INFO - __main__ - Step 310 Global step 310 Train loss 0.56 on epoch=77
05/30/2022 17:12:16 - INFO - __main__ - Step 320 Global step 320 Train loss 0.38 on epoch=79
05/30/2022 17:12:19 - INFO - __main__ - Step 330 Global step 330 Train loss 0.45 on epoch=82
05/30/2022 17:12:21 - INFO - __main__ - Step 340 Global step 340 Train loss 0.46 on epoch=84
05/30/2022 17:12:24 - INFO - __main__ - Step 350 Global step 350 Train loss 0.47 on epoch=87
05/30/2022 17:12:25 - INFO - __main__ - Global step 350 Train loss 0.46 Classification-F1 0.6247138278388278 on epoch=87
05/30/2022 17:12:25 - INFO - __main__ - Saving model with best Classification-F1: 0.6153551110447663 -> 0.6247138278388278 on epoch=87, global_step=350
05/30/2022 17:12:27 - INFO - __main__ - Step 360 Global step 360 Train loss 0.43 on epoch=89
05/30/2022 17:12:30 - INFO - __main__ - Step 370 Global step 370 Train loss 0.43 on epoch=92
05/30/2022 17:12:32 - INFO - __main__ - Step 380 Global step 380 Train loss 0.38 on epoch=94
05/30/2022 17:12:35 - INFO - __main__ - Step 390 Global step 390 Train loss 0.33 on epoch=97
05/30/2022 17:12:37 - INFO - __main__ - Step 400 Global step 400 Train loss 0.37 on epoch=99
05/30/2022 17:12:38 - INFO - __main__ - Global step 400 Train loss 0.39 Classification-F1 0.5462269585253456 on epoch=99
05/30/2022 17:12:41 - INFO - __main__ - Step 410 Global step 410 Train loss 0.33 on epoch=102
05/30/2022 17:12:43 - INFO - __main__ - Step 420 Global step 420 Train loss 0.30 on epoch=104
05/30/2022 17:12:46 - INFO - __main__ - Step 430 Global step 430 Train loss 0.38 on epoch=107
05/30/2022 17:12:48 - INFO - __main__ - Step 440 Global step 440 Train loss 0.32 on epoch=109
05/30/2022 17:12:51 - INFO - __main__ - Step 450 Global step 450 Train loss 0.35 on epoch=112
05/30/2022 17:12:51 - INFO - __main__ - Global step 450 Train loss 0.34 Classification-F1 0.6519650113400113 on epoch=112
05/30/2022 17:12:52 - INFO - __main__ - Saving model with best Classification-F1: 0.6247138278388278 -> 0.6519650113400113 on epoch=112, global_step=450
05/30/2022 17:12:54 - INFO - __main__ - Step 460 Global step 460 Train loss 0.31 on epoch=114
05/30/2022 17:12:56 - INFO - __main__ - Step 470 Global step 470 Train loss 0.32 on epoch=117
05/30/2022 17:12:59 - INFO - __main__ - Step 480 Global step 480 Train loss 0.25 on epoch=119
05/30/2022 17:13:01 - INFO - __main__ - Step 490 Global step 490 Train loss 0.35 on epoch=122
05/30/2022 17:13:04 - INFO - __main__ - Step 500 Global step 500 Train loss 0.29 on epoch=124
05/30/2022 17:13:05 - INFO - __main__ - Global step 500 Train loss 0.30 Classification-F1 0.5059079406905495 on epoch=124
05/30/2022 17:13:07 - INFO - __main__ - Step 510 Global step 510 Train loss 0.29 on epoch=127
05/30/2022 17:13:10 - INFO - __main__ - Step 520 Global step 520 Train loss 0.38 on epoch=129
05/30/2022 17:13:12 - INFO - __main__ - Step 530 Global step 530 Train loss 0.23 on epoch=132
05/30/2022 17:13:15 - INFO - __main__ - Step 540 Global step 540 Train loss 0.14 on epoch=134
05/30/2022 17:13:17 - INFO - __main__ - Step 550 Global step 550 Train loss 0.24 on epoch=137
05/30/2022 17:13:18 - INFO - __main__ - Global step 550 Train loss 0.25 Classification-F1 0.6483789507983055 on epoch=137
05/30/2022 17:13:21 - INFO - __main__ - Step 560 Global step 560 Train loss 0.17 on epoch=139
05/30/2022 17:13:23 - INFO - __main__ - Step 570 Global step 570 Train loss 0.19 on epoch=142
05/30/2022 17:13:26 - INFO - __main__ - Step 580 Global step 580 Train loss 0.18 on epoch=144
05/30/2022 17:13:28 - INFO - __main__ - Step 590 Global step 590 Train loss 0.16 on epoch=147
05/30/2022 17:13:31 - INFO - __main__ - Step 600 Global step 600 Train loss 0.25 on epoch=149
05/30/2022 17:13:32 - INFO - __main__ - Global step 600 Train loss 0.19 Classification-F1 0.6873076923076923 on epoch=149
05/30/2022 17:13:32 - INFO - __main__ - Saving model with best Classification-F1: 0.6519650113400113 -> 0.6873076923076923 on epoch=149, global_step=600
05/30/2022 17:13:34 - INFO - __main__ - Step 610 Global step 610 Train loss 0.22 on epoch=152
05/30/2022 17:13:37 - INFO - __main__ - Step 620 Global step 620 Train loss 0.20 on epoch=154
05/30/2022 17:13:39 - INFO - __main__ - Step 630 Global step 630 Train loss 0.19 on epoch=157
05/30/2022 17:13:42 - INFO - __main__ - Step 640 Global step 640 Train loss 0.25 on epoch=159
05/30/2022 17:13:44 - INFO - __main__ - Step 650 Global step 650 Train loss 0.14 on epoch=162
05/30/2022 17:13:45 - INFO - __main__ - Global step 650 Train loss 0.20 Classification-F1 0.6320161160678403 on epoch=162
05/30/2022 17:13:47 - INFO - __main__ - Step 660 Global step 660 Train loss 0.08 on epoch=164
05/30/2022 17:13:50 - INFO - __main__ - Step 670 Global step 670 Train loss 0.24 on epoch=167
05/30/2022 17:13:52 - INFO - __main__ - Step 680 Global step 680 Train loss 0.08 on epoch=169
05/30/2022 17:13:55 - INFO - __main__ - Step 690 Global step 690 Train loss 0.06 on epoch=172
05/30/2022 17:13:57 - INFO - __main__ - Step 700 Global step 700 Train loss 0.08 on epoch=174
05/30/2022 17:13:58 - INFO - __main__ - Global step 700 Train loss 0.11 Classification-F1 0.6671650717703349 on epoch=174
05/30/2022 17:14:01 - INFO - __main__ - Step 710 Global step 710 Train loss 0.16 on epoch=177
05/30/2022 17:14:03 - INFO - __main__ - Step 720 Global step 720 Train loss 0.09 on epoch=179
05/30/2022 17:14:06 - INFO - __main__ - Step 730 Global step 730 Train loss 0.17 on epoch=182
05/30/2022 17:14:08 - INFO - __main__ - Step 740 Global step 740 Train loss 0.06 on epoch=184
05/30/2022 17:14:11 - INFO - __main__ - Step 750 Global step 750 Train loss 0.16 on epoch=187
05/30/2022 17:14:12 - INFO - __main__ - Global step 750 Train loss 0.13 Classification-F1 0.7492291271347249 on epoch=187
05/30/2022 17:14:12 - INFO - __main__ - Saving model with best Classification-F1: 0.6873076923076923 -> 0.7492291271347249 on epoch=187, global_step=750
05/30/2022 17:14:14 - INFO - __main__ - Step 760 Global step 760 Train loss 0.07 on epoch=189
05/30/2022 17:14:17 - INFO - __main__ - Step 770 Global step 770 Train loss 0.12 on epoch=192
05/30/2022 17:14:19 - INFO - __main__ - Step 780 Global step 780 Train loss 0.06 on epoch=194
05/30/2022 17:14:22 - INFO - __main__ - Step 790 Global step 790 Train loss 0.12 on epoch=197
05/30/2022 17:14:24 - INFO - __main__ - Step 800 Global step 800 Train loss 0.12 on epoch=199
05/30/2022 17:14:25 - INFO - __main__ - Global step 800 Train loss 0.10 Classification-F1 0.7015567765567765 on epoch=199
05/30/2022 17:14:28 - INFO - __main__ - Step 810 Global step 810 Train loss 0.07 on epoch=202
05/30/2022 17:14:30 - INFO - __main__ - Step 820 Global step 820 Train loss 0.08 on epoch=204
05/30/2022 17:14:33 - INFO - __main__ - Step 830 Global step 830 Train loss 0.03 on epoch=207
05/30/2022 17:14:35 - INFO - __main__ - Step 840 Global step 840 Train loss 0.04 on epoch=209
05/30/2022 17:14:38 - INFO - __main__ - Step 850 Global step 850 Train loss 0.02 on epoch=212
05/30/2022 17:14:38 - INFO - __main__ - Global step 850 Train loss 0.05 Classification-F1 0.6733397799973887 on epoch=212
05/30/2022 17:14:41 - INFO - __main__ - Step 860 Global step 860 Train loss 0.03 on epoch=214
05/30/2022 17:14:43 - INFO - __main__ - Step 870 Global step 870 Train loss 0.10 on epoch=217
05/30/2022 17:14:46 - INFO - __main__ - Step 880 Global step 880 Train loss 0.06 on epoch=219
05/30/2022 17:14:48 - INFO - __main__ - Step 890 Global step 890 Train loss 0.05 on epoch=222
05/30/2022 17:14:51 - INFO - __main__ - Step 900 Global step 900 Train loss 0.03 on epoch=224
05/30/2022 17:14:52 - INFO - __main__ - Global step 900 Train loss 0.05 Classification-F1 0.6833082509978408 on epoch=224
05/30/2022 17:14:54 - INFO - __main__ - Step 910 Global step 910 Train loss 0.07 on epoch=227
05/30/2022 17:14:57 - INFO - __main__ - Step 920 Global step 920 Train loss 0.06 on epoch=229
05/30/2022 17:14:59 - INFO - __main__ - Step 930 Global step 930 Train loss 0.06 on epoch=232
05/30/2022 17:15:02 - INFO - __main__ - Step 940 Global step 940 Train loss 0.06 on epoch=234
05/30/2022 17:15:04 - INFO - __main__ - Step 950 Global step 950 Train loss 0.09 on epoch=237
05/30/2022 17:15:05 - INFO - __main__ - Global step 950 Train loss 0.07 Classification-F1 0.7022562741312741 on epoch=237
05/30/2022 17:15:08 - INFO - __main__ - Step 960 Global step 960 Train loss 0.06 on epoch=239
05/30/2022 17:15:10 - INFO - __main__ - Step 970 Global step 970 Train loss 0.01 on epoch=242
05/30/2022 17:15:13 - INFO - __main__ - Step 980 Global step 980 Train loss 0.04 on epoch=244
05/30/2022 17:15:15 - INFO - __main__ - Step 990 Global step 990 Train loss 0.05 on epoch=247
05/30/2022 17:15:18 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.03 on epoch=249
05/30/2022 17:15:19 - INFO - __main__ - Global step 1000 Train loss 0.04 Classification-F1 0.7100655539993775 on epoch=249
05/30/2022 17:15:21 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.12 on epoch=252
05/30/2022 17:15:24 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.06 on epoch=254
05/30/2022 17:15:26 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.03 on epoch=257
05/30/2022 17:15:29 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.07 on epoch=259
05/30/2022 17:15:31 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.02 on epoch=262
05/30/2022 17:15:32 - INFO - __main__ - Global step 1050 Train loss 0.06 Classification-F1 0.6930810069871256 on epoch=262
05/30/2022 17:15:34 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.07 on epoch=264
05/30/2022 17:15:37 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.06 on epoch=267
05/30/2022 17:15:39 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.05 on epoch=269
05/30/2022 17:15:42 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.07 on epoch=272
05/30/2022 17:15:44 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.04 on epoch=274
05/30/2022 17:15:45 - INFO - __main__ - Global step 1100 Train loss 0.06 Classification-F1 0.6801759039508586 on epoch=274
05/30/2022 17:15:48 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.01 on epoch=277
05/30/2022 17:15:50 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=279
05/30/2022 17:15:53 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.09 on epoch=282
05/30/2022 17:15:55 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.02 on epoch=284
05/30/2022 17:15:58 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.02 on epoch=287
05/30/2022 17:15:59 - INFO - __main__ - Global step 1150 Train loss 0.03 Classification-F1 0.6516405813417524 on epoch=287
05/30/2022 17:16:02 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.09 on epoch=289
05/30/2022 17:16:04 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.04 on epoch=292
05/30/2022 17:16:06 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.03 on epoch=294
05/30/2022 17:16:09 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.01 on epoch=297
05/30/2022 17:16:11 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.03 on epoch=299
05/30/2022 17:16:12 - INFO - __main__ - Global step 1200 Train loss 0.04 Classification-F1 0.6263168204344676 on epoch=299
05/30/2022 17:16:15 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.03 on epoch=302
05/30/2022 17:16:17 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.02 on epoch=304
05/30/2022 17:16:19 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.06 on epoch=307
05/30/2022 17:16:22 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.05 on epoch=309
05/30/2022 17:16:24 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.03 on epoch=312
05/30/2022 17:16:25 - INFO - __main__ - Global step 1250 Train loss 0.04 Classification-F1 0.6813717532467533 on epoch=312
05/30/2022 17:16:27 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.03 on epoch=314
05/30/2022 17:16:30 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.11 on epoch=317
05/30/2022 17:16:32 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.02 on epoch=319
05/30/2022 17:16:35 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.05 on epoch=322
05/30/2022 17:16:37 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.04 on epoch=324
05/30/2022 17:16:38 - INFO - __main__ - Global step 1300 Train loss 0.05 Classification-F1 0.659375 on epoch=324
05/30/2022 17:16:40 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=327
05/30/2022 17:16:43 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.03 on epoch=329
05/30/2022 17:16:45 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.07 on epoch=332
05/30/2022 17:16:48 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.06 on epoch=334
05/30/2022 17:16:50 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.03 on epoch=337
05/30/2022 17:16:51 - INFO - __main__ - Global step 1350 Train loss 0.04 Classification-F1 0.7074674317617865 on epoch=337
05/30/2022 17:16:53 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.02 on epoch=339
05/30/2022 17:16:56 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.03 on epoch=342
05/30/2022 17:16:58 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=344
05/30/2022 17:17:01 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.02 on epoch=347
05/30/2022 17:17:03 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.03 on epoch=349
05/30/2022 17:17:04 - INFO - __main__ - Global step 1400 Train loss 0.02 Classification-F1 0.6676765080297689 on epoch=349
05/30/2022 17:17:06 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=352
05/30/2022 17:17:09 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=354
05/30/2022 17:17:11 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.02 on epoch=357
05/30/2022 17:17:13 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=359
05/30/2022 17:17:16 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=362
05/30/2022 17:17:17 - INFO - __main__ - Global step 1450 Train loss 0.02 Classification-F1 0.634926854754441 on epoch=362
05/30/2022 17:17:19 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=364
05/30/2022 17:17:22 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.05 on epoch=367
05/30/2022 17:17:24 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=369
05/30/2022 17:17:26 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.02 on epoch=372
05/30/2022 17:17:29 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=374
05/30/2022 17:17:30 - INFO - __main__ - Global step 1500 Train loss 0.02 Classification-F1 0.6944239343137848 on epoch=374
05/30/2022 17:17:32 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=377
05/30/2022 17:17:35 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=379
05/30/2022 17:17:37 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=382
05/30/2022 17:17:39 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=384
05/30/2022 17:17:42 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=387
05/30/2022 17:17:43 - INFO - __main__ - Global step 1550 Train loss 0.01 Classification-F1 0.7490301724137931 on epoch=387
05/30/2022 17:17:45 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.02 on epoch=389
05/30/2022 17:17:48 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.05 on epoch=392
05/30/2022 17:17:50 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=394
05/30/2022 17:17:53 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.09 on epoch=397
05/30/2022 17:17:55 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=399
05/30/2022 17:17:56 - INFO - __main__ - Global step 1600 Train loss 0.04 Classification-F1 0.6888061145510836 on epoch=399
05/30/2022 17:17:58 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=402
05/30/2022 17:18:01 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.02 on epoch=404
05/30/2022 17:18:03 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=407
05/30/2022 17:18:05 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.05 on epoch=409
05/30/2022 17:18:08 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.03 on epoch=412
05/30/2022 17:18:09 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.6444805194805195 on epoch=412
05/30/2022 17:18:11 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=414
05/30/2022 17:18:14 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=417
05/30/2022 17:18:16 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.03 on epoch=419
05/30/2022 17:18:18 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=422
05/30/2022 17:18:21 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=424
05/30/2022 17:18:22 - INFO - __main__ - Global step 1700 Train loss 0.01 Classification-F1 0.6944239343137848 on epoch=424
05/30/2022 17:18:24 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=427
05/30/2022 17:18:27 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.09 on epoch=429
05/30/2022 17:18:29 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.04 on epoch=432
05/30/2022 17:18:31 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=434
05/30/2022 17:18:34 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.04 on epoch=437
05/30/2022 17:18:35 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.6940367875851746 on epoch=437
05/30/2022 17:18:37 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=439
05/30/2022 17:18:40 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.04 on epoch=442
05/30/2022 17:18:42 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=444
05/30/2022 17:18:44 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=447
05/30/2022 17:18:47 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=449
05/30/2022 17:18:48 - INFO - __main__ - Global step 1800 Train loss 0.02 Classification-F1 0.667459749918274 on epoch=449
05/30/2022 17:18:50 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=452
05/30/2022 17:18:53 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=454
05/30/2022 17:18:55 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=457
05/30/2022 17:18:57 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.10 on epoch=459
05/30/2022 17:19:00 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.04 on epoch=462
05/30/2022 17:19:01 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.6728805304172951 on epoch=462
05/30/2022 17:19:03 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=464
05/30/2022 17:19:05 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.04 on epoch=467
05/30/2022 17:19:08 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=469
05/30/2022 17:19:10 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=472
05/30/2022 17:19:13 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=474
05/30/2022 17:19:13 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.6940021929824561 on epoch=474
05/30/2022 17:19:16 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=477
05/30/2022 17:19:18 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=479
05/30/2022 17:19:21 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=482
05/30/2022 17:19:23 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=484
05/30/2022 17:19:26 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.05 on epoch=487
05/30/2022 17:19:27 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.6591972668491798 on epoch=487
05/30/2022 17:19:29 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=489
05/30/2022 17:19:31 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=492
05/30/2022 17:19:34 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=494
05/30/2022 17:19:36 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=497
05/30/2022 17:19:39 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.04 on epoch=499
05/30/2022 17:19:40 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.6393817204301075 on epoch=499
05/30/2022 17:19:42 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=502
05/30/2022 17:19:45 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.04 on epoch=504
05/30/2022 17:19:47 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=507
05/30/2022 17:19:49 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=509
05/30/2022 17:19:52 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=512
05/30/2022 17:19:53 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.7477170303605313 on epoch=512
05/30/2022 17:19:55 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.05 on epoch=514
05/30/2022 17:19:58 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.06 on epoch=517
05/30/2022 17:20:00 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
05/30/2022 17:20:02 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
05/30/2022 17:20:05 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
05/30/2022 17:20:06 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.693844696969697 on epoch=524
05/30/2022 17:20:08 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=527
05/30/2022 17:20:10 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=529
05/30/2022 17:20:13 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
05/30/2022 17:20:15 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=534
05/30/2022 17:20:18 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=537
05/30/2022 17:20:19 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.6932078706272254 on epoch=537
05/30/2022 17:20:21 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
05/30/2022 17:20:23 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
05/30/2022 17:20:26 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=544
05/30/2022 17:20:28 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=547
05/30/2022 17:20:31 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
05/30/2022 17:20:32 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.6734185015435016 on epoch=549
05/30/2022 17:20:34 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
05/30/2022 17:20:37 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
05/30/2022 17:20:39 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=557
05/30/2022 17:20:41 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.03 on epoch=559
05/30/2022 17:20:44 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
05/30/2022 17:20:45 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.7099098020434227 on epoch=562
05/30/2022 17:20:47 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
05/30/2022 17:20:50 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
05/30/2022 17:20:52 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
05/30/2022 17:20:55 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
05/30/2022 17:20:57 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
05/30/2022 17:20:58 - INFO - __main__ - Global step 2300 Train loss 0.00 Classification-F1 0.7323859071808181 on epoch=574
05/30/2022 17:21:01 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
05/30/2022 17:21:04 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=579
05/30/2022 17:21:06 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
05/30/2022 17:21:09 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
05/30/2022 17:21:11 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.04 on epoch=587
05/30/2022 17:21:12 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.6659621802002226 on epoch=587
05/30/2022 17:21:15 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
05/30/2022 17:21:17 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
05/30/2022 17:21:20 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
05/30/2022 17:21:22 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
05/30/2022 17:21:25 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
05/30/2022 17:21:26 - INFO - __main__ - Global step 2400 Train loss 0.00 Classification-F1 0.7135607023677102 on epoch=599
05/30/2022 17:21:28 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
05/30/2022 17:21:31 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
05/30/2022 17:21:34 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
05/30/2022 17:21:36 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
05/30/2022 17:21:39 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
05/30/2022 17:21:40 - INFO - __main__ - Global step 2450 Train loss 0.00 Classification-F1 0.7280796279491832 on epoch=612
05/30/2022 17:21:42 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
05/30/2022 17:21:45 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=617
05/30/2022 17:21:47 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
05/30/2022 17:21:50 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=622
05/30/2022 17:21:52 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.12 on epoch=624
05/30/2022 17:21:53 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.7360850556438793 on epoch=624
05/30/2022 17:21:56 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
05/30/2022 17:21:58 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=629
05/30/2022 17:22:01 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
05/30/2022 17:22:03 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=634
05/30/2022 17:22:06 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.07 on epoch=637
05/30/2022 17:22:07 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.7273223381033229 on epoch=637
05/30/2022 17:22:09 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
05/30/2022 17:22:12 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
05/30/2022 17:22:14 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
05/30/2022 17:22:17 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
05/30/2022 17:22:19 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
05/30/2022 17:22:20 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.6959657426188866 on epoch=649
05/30/2022 17:22:23 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=652
05/30/2022 17:22:25 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
05/30/2022 17:22:28 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=657
05/30/2022 17:22:30 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=659
05/30/2022 17:22:33 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
05/30/2022 17:22:34 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.7096090539829198 on epoch=662
05/30/2022 17:22:37 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
05/30/2022 17:22:39 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
05/30/2022 17:22:42 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=669
05/30/2022 17:22:44 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
05/30/2022 17:22:46 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.03 on epoch=674
05/30/2022 17:22:48 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.697161267850923 on epoch=674
05/30/2022 17:22:50 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=677
05/30/2022 17:22:53 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.09 on epoch=679
05/30/2022 17:22:55 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
05/30/2022 17:22:57 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
05/30/2022 17:23:00 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
05/30/2022 17:23:01 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.6921112996480643 on epoch=687
05/30/2022 17:23:03 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=689
05/30/2022 17:23:06 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
05/30/2022 17:23:08 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=694
05/30/2022 17:23:11 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
05/30/2022 17:23:13 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
05/30/2022 17:23:14 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.7262988437001596 on epoch=699
05/30/2022 17:23:17 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=702
05/30/2022 17:23:19 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
05/30/2022 17:23:22 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
05/30/2022 17:23:24 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
05/30/2022 17:23:27 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
05/30/2022 17:23:28 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.7268504332932646 on epoch=712
05/30/2022 17:23:30 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
05/30/2022 17:23:33 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.04 on epoch=717
05/30/2022 17:23:35 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
05/30/2022 17:23:38 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=722
05/30/2022 17:23:40 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.06 on epoch=724
05/30/2022 17:23:41 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.6974697191431063 on epoch=724
05/30/2022 17:23:43 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
05/30/2022 17:23:46 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=729
05/30/2022 17:23:48 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=732
05/30/2022 17:23:51 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
05/30/2022 17:23:53 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
05/30/2022 17:23:54 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.6742295016478579 on epoch=737
05/30/2022 17:23:57 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=739
05/30/2022 17:23:59 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=742
05/30/2022 17:24:02 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
05/30/2022 17:24:04 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
05/30/2022 17:24:07 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=749
05/30/2022 17:24:08 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.7407009109311741 on epoch=749
05/30/2022 17:24:08 - INFO - __main__ - save last model!
05/30/2022 17:24:08 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/30/2022 17:24:08 - INFO - __main__ - Start tokenizing ... 5509 instances
05/30/2022 17:24:08 - INFO - __main__ - Printing 3 examples
05/30/2022 17:24:08 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/30/2022 17:24:08 - INFO - __main__ - ['others']
05/30/2022 17:24:08 - INFO - __main__ -  [emo] what you like very little things ok
05/30/2022 17:24:08 - INFO - __main__ - ['others']
05/30/2022 17:24:08 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/30/2022 17:24:08 - INFO - __main__ - ['others']
05/30/2022 17:24:08 - INFO - __main__ - Tokenizing Input ...
05/30/2022 17:24:08 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 17:24:08 - INFO - __main__ - Printing 3 examples
05/30/2022 17:24:08 - INFO - __main__ -  [emo] how cause yes am listening
05/30/2022 17:24:08 - INFO - __main__ - ['others']
05/30/2022 17:24:08 - INFO - __main__ -  [emo] ok that way i like living wwrong
05/30/2022 17:24:08 - INFO - __main__ - ['others']
05/30/2022 17:24:08 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
05/30/2022 17:24:08 - INFO - __main__ - ['others']
05/30/2022 17:24:08 - INFO - __main__ - Tokenizing Input ...
05/30/2022 17:24:08 - INFO - __main__ - Tokenizing Output ...
05/30/2022 17:24:08 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 17:24:08 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 17:24:08 - INFO - __main__ - Printing 3 examples
05/30/2022 17:24:08 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
05/30/2022 17:24:08 - INFO - __main__ - ['others']
05/30/2022 17:24:08 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
05/30/2022 17:24:08 - INFO - __main__ - ['others']
05/30/2022 17:24:08 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
05/30/2022 17:24:08 - INFO - __main__ - ['others']
05/30/2022 17:24:08 - INFO - __main__ - Tokenizing Input ...
05/30/2022 17:24:08 - INFO - __main__ - Tokenizing Output ...
05/30/2022 17:24:08 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 17:24:10 - INFO - __main__ - Tokenizing Output ...
05/30/2022 17:24:15 - INFO - __main__ - Loaded 5509 examples from test data
05/30/2022 17:24:24 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 17:24:24 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/30/2022 17:24:24 - INFO - __main__ - Starting training!
05/30/2022 17:25:40 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-24uptasks/singletask-emo/emo_16_100_0.4_8_predictions.txt
05/30/2022 17:25:40 - INFO - __main__ - Classification-F1 on test data: 0.3341
05/30/2022 17:25:41 - INFO - __main__ - prefix=emo_16_100, lr=0.4, bsz=8, dev_performance=0.7492291271347249, test_performance=0.3341274335556241
05/30/2022 17:25:41 - INFO - __main__ - Running ... prefix=emo_16_100, lr=0.3, bsz=8 ...
05/30/2022 17:25:41 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 17:25:41 - INFO - __main__ - Printing 3 examples
05/30/2022 17:25:41 - INFO - __main__ -  [emo] how cause yes am listening
05/30/2022 17:25:41 - INFO - __main__ - ['others']
05/30/2022 17:25:41 - INFO - __main__ -  [emo] ok that way i like living wwrong
05/30/2022 17:25:41 - INFO - __main__ - ['others']
05/30/2022 17:25:41 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
05/30/2022 17:25:41 - INFO - __main__ - ['others']
05/30/2022 17:25:41 - INFO - __main__ - Tokenizing Input ...
05/30/2022 17:25:42 - INFO - __main__ - Tokenizing Output ...
05/30/2022 17:25:42 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 17:25:42 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 17:25:42 - INFO - __main__ - Printing 3 examples
05/30/2022 17:25:42 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
05/30/2022 17:25:42 - INFO - __main__ - ['others']
05/30/2022 17:25:42 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
05/30/2022 17:25:42 - INFO - __main__ - ['others']
05/30/2022 17:25:42 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
05/30/2022 17:25:42 - INFO - __main__ - ['others']
05/30/2022 17:25:42 - INFO - __main__ - Tokenizing Input ...
05/30/2022 17:25:42 - INFO - __main__ - Tokenizing Output ...
05/30/2022 17:25:42 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 17:26:00 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 17:26:01 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/30/2022 17:26:01 - INFO - __main__ - Starting training!
05/30/2022 17:26:04 - INFO - __main__ - Step 10 Global step 10 Train loss 4.07 on epoch=2
05/30/2022 17:26:06 - INFO - __main__ - Step 20 Global step 20 Train loss 1.96 on epoch=4
05/30/2022 17:26:09 - INFO - __main__ - Step 30 Global step 30 Train loss 1.55 on epoch=7
05/30/2022 17:26:11 - INFO - __main__ - Step 40 Global step 40 Train loss 1.16 on epoch=9
05/30/2022 17:26:14 - INFO - __main__ - Step 50 Global step 50 Train loss 1.12 on epoch=12
05/30/2022 17:26:15 - INFO - __main__ - Global step 50 Train loss 1.97 Classification-F1 0.3930555555555556 on epoch=12
05/30/2022 17:26:15 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.3930555555555556 on epoch=12, global_step=50
05/30/2022 17:26:17 - INFO - __main__ - Step 60 Global step 60 Train loss 0.82 on epoch=14
05/30/2022 17:26:20 - INFO - __main__ - Step 70 Global step 70 Train loss 1.00 on epoch=17
05/30/2022 17:26:22 - INFO - __main__ - Step 80 Global step 80 Train loss 0.95 on epoch=19
05/30/2022 17:26:25 - INFO - __main__ - Step 90 Global step 90 Train loss 0.95 on epoch=22
05/30/2022 17:26:27 - INFO - __main__ - Step 100 Global step 100 Train loss 0.98 on epoch=24
05/30/2022 17:26:28 - INFO - __main__ - Global step 100 Train loss 0.94 Classification-F1 0.3986175115207373 on epoch=24
05/30/2022 17:26:28 - INFO - __main__ - Saving model with best Classification-F1: 0.3930555555555556 -> 0.3986175115207373 on epoch=24, global_step=100
05/30/2022 17:26:30 - INFO - __main__ - Step 110 Global step 110 Train loss 0.91 on epoch=27
05/30/2022 17:26:33 - INFO - __main__ - Step 120 Global step 120 Train loss 0.88 on epoch=29
05/30/2022 17:26:35 - INFO - __main__ - Step 130 Global step 130 Train loss 0.80 on epoch=32
05/30/2022 17:26:38 - INFO - __main__ - Step 140 Global step 140 Train loss 0.74 on epoch=34
05/30/2022 17:26:40 - INFO - __main__ - Step 150 Global step 150 Train loss 0.75 on epoch=37
05/30/2022 17:26:41 - INFO - __main__ - Global step 150 Train loss 0.82 Classification-F1 0.5238739641807003 on epoch=37
05/30/2022 17:26:41 - INFO - __main__ - Saving model with best Classification-F1: 0.3986175115207373 -> 0.5238739641807003 on epoch=37, global_step=150
05/30/2022 17:26:44 - INFO - __main__ - Step 160 Global step 160 Train loss 0.72 on epoch=39
05/30/2022 17:26:46 - INFO - __main__ - Step 170 Global step 170 Train loss 0.82 on epoch=42
05/30/2022 17:26:49 - INFO - __main__ - Step 180 Global step 180 Train loss 0.69 on epoch=44
05/30/2022 17:26:51 - INFO - __main__ - Step 190 Global step 190 Train loss 0.71 on epoch=47
05/30/2022 17:26:54 - INFO - __main__ - Step 200 Global step 200 Train loss 0.64 on epoch=49
05/30/2022 17:26:54 - INFO - __main__ - Global step 200 Train loss 0.72 Classification-F1 0.5207985257985258 on epoch=49
05/30/2022 17:26:57 - INFO - __main__ - Step 210 Global step 210 Train loss 0.77 on epoch=52
05/30/2022 17:26:59 - INFO - __main__ - Step 220 Global step 220 Train loss 0.62 on epoch=54
05/30/2022 17:27:02 - INFO - __main__ - Step 230 Global step 230 Train loss 0.75 on epoch=57
05/30/2022 17:27:04 - INFO - __main__ - Step 240 Global step 240 Train loss 0.70 on epoch=59
05/30/2022 17:27:07 - INFO - __main__ - Step 250 Global step 250 Train loss 0.63 on epoch=62
05/30/2022 17:27:08 - INFO - __main__ - Global step 250 Train loss 0.69 Classification-F1 0.5470588235294118 on epoch=62
05/30/2022 17:27:08 - INFO - __main__ - Saving model with best Classification-F1: 0.5238739641807003 -> 0.5470588235294118 on epoch=62, global_step=250
05/30/2022 17:27:10 - INFO - __main__ - Step 260 Global step 260 Train loss 0.53 on epoch=64
05/30/2022 17:27:13 - INFO - __main__ - Step 270 Global step 270 Train loss 0.64 on epoch=67
05/30/2022 17:27:15 - INFO - __main__ - Step 280 Global step 280 Train loss 0.62 on epoch=69
05/30/2022 17:27:17 - INFO - __main__ - Step 290 Global step 290 Train loss 0.56 on epoch=72
05/30/2022 17:27:20 - INFO - __main__ - Step 300 Global step 300 Train loss 0.53 on epoch=74
05/30/2022 17:27:21 - INFO - __main__ - Global step 300 Train loss 0.57 Classification-F1 0.538695652173913 on epoch=74
05/30/2022 17:27:23 - INFO - __main__ - Step 310 Global step 310 Train loss 0.58 on epoch=77
05/30/2022 17:27:26 - INFO - __main__ - Step 320 Global step 320 Train loss 0.51 on epoch=79
05/30/2022 17:27:28 - INFO - __main__ - Step 330 Global step 330 Train loss 0.51 on epoch=82
05/30/2022 17:27:31 - INFO - __main__ - Step 340 Global step 340 Train loss 0.53 on epoch=84
05/30/2022 17:27:33 - INFO - __main__ - Step 350 Global step 350 Train loss 0.57 on epoch=87
05/30/2022 17:27:34 - INFO - __main__ - Global step 350 Train loss 0.54 Classification-F1 0.6717981950844854 on epoch=87
05/30/2022 17:27:34 - INFO - __main__ - Saving model with best Classification-F1: 0.5470588235294118 -> 0.6717981950844854 on epoch=87, global_step=350
05/30/2022 17:27:36 - INFO - __main__ - Step 360 Global step 360 Train loss 0.54 on epoch=89
05/30/2022 17:27:39 - INFO - __main__ - Step 370 Global step 370 Train loss 0.57 on epoch=92
05/30/2022 17:27:41 - INFO - __main__ - Step 380 Global step 380 Train loss 0.49 on epoch=94
05/30/2022 17:27:44 - INFO - __main__ - Step 390 Global step 390 Train loss 0.42 on epoch=97
05/30/2022 17:27:46 - INFO - __main__ - Step 400 Global step 400 Train loss 0.42 on epoch=99
05/30/2022 17:27:47 - INFO - __main__ - Global step 400 Train loss 0.49 Classification-F1 0.5328509852216748 on epoch=99
05/30/2022 17:27:50 - INFO - __main__ - Step 410 Global step 410 Train loss 0.46 on epoch=102
05/30/2022 17:27:52 - INFO - __main__ - Step 420 Global step 420 Train loss 0.37 on epoch=104
05/30/2022 17:27:55 - INFO - __main__ - Step 430 Global step 430 Train loss 0.44 on epoch=107
05/30/2022 17:27:57 - INFO - __main__ - Step 440 Global step 440 Train loss 0.35 on epoch=109
05/30/2022 17:28:00 - INFO - __main__ - Step 450 Global step 450 Train loss 0.47 on epoch=112
05/30/2022 17:28:00 - INFO - __main__ - Global step 450 Train loss 0.42 Classification-F1 0.6536738351254481 on epoch=112
05/30/2022 17:28:03 - INFO - __main__ - Step 460 Global step 460 Train loss 0.33 on epoch=114
05/30/2022 17:28:05 - INFO - __main__ - Step 470 Global step 470 Train loss 0.37 on epoch=117
05/30/2022 17:28:08 - INFO - __main__ - Step 480 Global step 480 Train loss 0.37 on epoch=119
05/30/2022 17:28:10 - INFO - __main__ - Step 490 Global step 490 Train loss 0.45 on epoch=122
05/30/2022 17:28:13 - INFO - __main__ - Step 500 Global step 500 Train loss 0.36 on epoch=124
05/30/2022 17:28:14 - INFO - __main__ - Global step 500 Train loss 0.38 Classification-F1 0.6542191128544386 on epoch=124
05/30/2022 17:28:16 - INFO - __main__ - Step 510 Global step 510 Train loss 0.25 on epoch=127
05/30/2022 17:28:19 - INFO - __main__ - Step 520 Global step 520 Train loss 0.30 on epoch=129
05/30/2022 17:28:21 - INFO - __main__ - Step 530 Global step 530 Train loss 0.38 on epoch=132
05/30/2022 17:28:23 - INFO - __main__ - Step 540 Global step 540 Train loss 0.27 on epoch=134
05/30/2022 17:28:26 - INFO - __main__ - Step 550 Global step 550 Train loss 0.37 on epoch=137
05/30/2022 17:28:27 - INFO - __main__ - Global step 550 Train loss 0.31 Classification-F1 0.6419455169455169 on epoch=137
05/30/2022 17:28:29 - INFO - __main__ - Step 560 Global step 560 Train loss 0.34 on epoch=139
05/30/2022 17:28:32 - INFO - __main__ - Step 570 Global step 570 Train loss 0.31 on epoch=142
05/30/2022 17:28:34 - INFO - __main__ - Step 580 Global step 580 Train loss 0.35 on epoch=144
05/30/2022 17:28:37 - INFO - __main__ - Step 590 Global step 590 Train loss 0.24 on epoch=147
05/30/2022 17:28:39 - INFO - __main__ - Step 600 Global step 600 Train loss 0.22 on epoch=149
05/30/2022 17:28:40 - INFO - __main__ - Global step 600 Train loss 0.29 Classification-F1 0.6358360389610389 on epoch=149
05/30/2022 17:28:42 - INFO - __main__ - Step 610 Global step 610 Train loss 0.40 on epoch=152
05/30/2022 17:28:45 - INFO - __main__ - Step 620 Global step 620 Train loss 0.35 on epoch=154
05/30/2022 17:28:47 - INFO - __main__ - Step 630 Global step 630 Train loss 0.17 on epoch=157
05/30/2022 17:28:50 - INFO - __main__ - Step 640 Global step 640 Train loss 0.19 on epoch=159
05/30/2022 17:28:52 - INFO - __main__ - Step 650 Global step 650 Train loss 0.25 on epoch=162
05/30/2022 17:28:53 - INFO - __main__ - Global step 650 Train loss 0.27 Classification-F1 0.5913978494623656 on epoch=162
05/30/2022 17:28:56 - INFO - __main__ - Step 660 Global step 660 Train loss 0.22 on epoch=164
05/30/2022 17:28:58 - INFO - __main__ - Step 670 Global step 670 Train loss 0.19 on epoch=167
05/30/2022 17:29:00 - INFO - __main__ - Step 680 Global step 680 Train loss 0.15 on epoch=169
05/30/2022 17:29:03 - INFO - __main__ - Step 690 Global step 690 Train loss 0.20 on epoch=172
05/30/2022 17:29:05 - INFO - __main__ - Step 700 Global step 700 Train loss 0.20 on epoch=174
05/30/2022 17:29:06 - INFO - __main__ - Global step 700 Train loss 0.19 Classification-F1 0.703125 on epoch=174
05/30/2022 17:29:06 - INFO - __main__ - Saving model with best Classification-F1: 0.6717981950844854 -> 0.703125 on epoch=174, global_step=700
05/30/2022 17:29:09 - INFO - __main__ - Step 710 Global step 710 Train loss 0.19 on epoch=177
05/30/2022 17:29:11 - INFO - __main__ - Step 720 Global step 720 Train loss 0.14 on epoch=179
05/30/2022 17:29:14 - INFO - __main__ - Step 730 Global step 730 Train loss 0.19 on epoch=182
05/30/2022 17:29:16 - INFO - __main__ - Step 740 Global step 740 Train loss 0.13 on epoch=184
05/30/2022 17:29:19 - INFO - __main__ - Step 750 Global step 750 Train loss 0.21 on epoch=187
05/30/2022 17:29:20 - INFO - __main__ - Global step 750 Train loss 0.17 Classification-F1 0.6380824372759857 on epoch=187
05/30/2022 17:29:22 - INFO - __main__ - Step 760 Global step 760 Train loss 0.19 on epoch=189
05/30/2022 17:29:25 - INFO - __main__ - Step 770 Global step 770 Train loss 0.14 on epoch=192
05/30/2022 17:29:27 - INFO - __main__ - Step 780 Global step 780 Train loss 0.15 on epoch=194
05/30/2022 17:29:29 - INFO - __main__ - Step 790 Global step 790 Train loss 0.16 on epoch=197
05/30/2022 17:29:32 - INFO - __main__ - Step 800 Global step 800 Train loss 0.10 on epoch=199
05/30/2022 17:29:33 - INFO - __main__ - Global step 800 Train loss 0.15 Classification-F1 0.5837163969354912 on epoch=199
05/30/2022 17:29:35 - INFO - __main__ - Step 810 Global step 810 Train loss 0.17 on epoch=202
05/30/2022 17:29:38 - INFO - __main__ - Step 820 Global step 820 Train loss 0.14 on epoch=204
05/30/2022 17:29:40 - INFO - __main__ - Step 830 Global step 830 Train loss 0.10 on epoch=207
05/30/2022 17:29:43 - INFO - __main__ - Step 840 Global step 840 Train loss 0.08 on epoch=209
05/30/2022 17:29:45 - INFO - __main__ - Step 850 Global step 850 Train loss 0.15 on epoch=212
05/30/2022 17:29:46 - INFO - __main__ - Global step 850 Train loss 0.13 Classification-F1 0.6922303535206761 on epoch=212
05/30/2022 17:29:49 - INFO - __main__ - Step 860 Global step 860 Train loss 0.12 on epoch=214
05/30/2022 17:29:51 - INFO - __main__ - Step 870 Global step 870 Train loss 0.21 on epoch=217
05/30/2022 17:29:53 - INFO - __main__ - Step 880 Global step 880 Train loss 0.15 on epoch=219
05/30/2022 17:29:56 - INFO - __main__ - Step 890 Global step 890 Train loss 0.09 on epoch=222
05/30/2022 17:29:58 - INFO - __main__ - Step 900 Global step 900 Train loss 0.09 on epoch=224
05/30/2022 17:29:59 - INFO - __main__ - Global step 900 Train loss 0.13 Classification-F1 0.6654982781643124 on epoch=224
05/30/2022 17:30:02 - INFO - __main__ - Step 910 Global step 910 Train loss 0.07 on epoch=227
05/30/2022 17:30:04 - INFO - __main__ - Step 920 Global step 920 Train loss 0.11 on epoch=229
05/30/2022 17:30:07 - INFO - __main__ - Step 930 Global step 930 Train loss 0.10 on epoch=232
05/30/2022 17:30:09 - INFO - __main__ - Step 940 Global step 940 Train loss 0.06 on epoch=234
05/30/2022 17:30:12 - INFO - __main__ - Step 950 Global step 950 Train loss 0.12 on epoch=237
05/30/2022 17:30:12 - INFO - __main__ - Global step 950 Train loss 0.09 Classification-F1 0.7177489177489177 on epoch=237
05/30/2022 17:30:12 - INFO - __main__ - Saving model with best Classification-F1: 0.703125 -> 0.7177489177489177 on epoch=237, global_step=950
05/30/2022 17:30:15 - INFO - __main__ - Step 960 Global step 960 Train loss 0.10 on epoch=239
05/30/2022 17:30:17 - INFO - __main__ - Step 970 Global step 970 Train loss 0.15 on epoch=242
05/30/2022 17:30:20 - INFO - __main__ - Step 980 Global step 980 Train loss 0.04 on epoch=244
05/30/2022 17:30:22 - INFO - __main__ - Step 990 Global step 990 Train loss 0.08 on epoch=247
05/30/2022 17:30:25 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.13 on epoch=249
05/30/2022 17:30:26 - INFO - __main__ - Global step 1000 Train loss 0.10 Classification-F1 0.7327559872922776 on epoch=249
05/30/2022 17:30:26 - INFO - __main__ - Saving model with best Classification-F1: 0.7177489177489177 -> 0.7327559872922776 on epoch=249, global_step=1000
05/30/2022 17:30:28 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.04 on epoch=252
05/30/2022 17:30:31 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.03 on epoch=254
05/30/2022 17:30:33 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.13 on epoch=257
05/30/2022 17:30:36 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.15 on epoch=259
05/30/2022 17:30:38 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.09 on epoch=262
05/30/2022 17:30:39 - INFO - __main__ - Global step 1050 Train loss 0.09 Classification-F1 0.6574531085778964 on epoch=262
05/30/2022 17:30:41 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.10 on epoch=264
05/30/2022 17:30:44 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.10 on epoch=267
05/30/2022 17:30:46 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.10 on epoch=269
05/30/2022 17:30:49 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.08 on epoch=272
05/30/2022 17:30:51 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.10 on epoch=274
05/30/2022 17:30:52 - INFO - __main__ - Global step 1100 Train loss 0.10 Classification-F1 0.6287942077415761 on epoch=274
05/30/2022 17:30:55 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.06 on epoch=277
05/30/2022 17:30:57 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.04 on epoch=279
05/30/2022 17:31:00 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.05 on epoch=282
05/30/2022 17:31:02 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.05 on epoch=284
05/30/2022 17:31:05 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.07 on epoch=287
05/30/2022 17:31:05 - INFO - __main__ - Global step 1150 Train loss 0.05 Classification-F1 0.7317887931034482 on epoch=287
05/30/2022 17:31:08 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.10 on epoch=289
05/30/2022 17:31:10 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.09 on epoch=292
05/30/2022 17:31:13 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.09 on epoch=294
05/30/2022 17:31:15 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.07 on epoch=297
05/30/2022 17:31:18 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.04 on epoch=299
05/30/2022 17:31:19 - INFO - __main__ - Global step 1200 Train loss 0.07 Classification-F1 0.7188719727702995 on epoch=299
05/30/2022 17:31:21 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.02 on epoch=302
05/30/2022 17:31:24 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.02 on epoch=304
05/30/2022 17:31:26 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.05 on epoch=307
05/30/2022 17:31:29 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.03 on epoch=309
05/30/2022 17:31:31 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.03 on epoch=312
05/30/2022 17:31:32 - INFO - __main__ - Global step 1250 Train loss 0.03 Classification-F1 0.643353384732695 on epoch=312
05/30/2022 17:31:35 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.13 on epoch=314
05/30/2022 17:31:37 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.02 on epoch=317
05/30/2022 17:31:40 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.04 on epoch=319
05/30/2022 17:31:42 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.03 on epoch=322
05/30/2022 17:31:44 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.02 on epoch=324
05/30/2022 17:31:45 - INFO - __main__ - Global step 1300 Train loss 0.05 Classification-F1 0.6995919738863287 on epoch=324
05/30/2022 17:31:48 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.05 on epoch=327
05/30/2022 17:31:50 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.02 on epoch=329
05/30/2022 17:31:53 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=332
05/30/2022 17:31:55 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.03 on epoch=334
05/30/2022 17:31:58 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.02 on epoch=337
05/30/2022 17:31:59 - INFO - __main__ - Global step 1350 Train loss 0.03 Classification-F1 0.7207659121642387 on epoch=337
05/30/2022 17:32:01 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.02 on epoch=339
05/30/2022 17:32:04 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.07 on epoch=342
05/30/2022 17:32:06 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=344
05/30/2022 17:32:09 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.02 on epoch=347
05/30/2022 17:32:11 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.07 on epoch=349
05/30/2022 17:32:12 - INFO - __main__ - Global step 1400 Train loss 0.04 Classification-F1 0.7136886102403344 on epoch=349
05/30/2022 17:32:15 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.10 on epoch=352
05/30/2022 17:32:17 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.04 on epoch=354
05/30/2022 17:32:20 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.02 on epoch=357
05/30/2022 17:32:22 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.03 on epoch=359
05/30/2022 17:32:25 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.08 on epoch=362
05/30/2022 17:32:26 - INFO - __main__ - Global step 1450 Train loss 0.05 Classification-F1 0.7197916666666666 on epoch=362
05/30/2022 17:32:28 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.03 on epoch=364
05/30/2022 17:32:31 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=367
05/30/2022 17:32:33 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=369
05/30/2022 17:32:36 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.05 on epoch=372
05/30/2022 17:32:38 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=374
05/30/2022 17:32:39 - INFO - __main__ - Global step 1500 Train loss 0.02 Classification-F1 0.6515019801023858 on epoch=374
05/30/2022 17:32:42 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.07 on epoch=377
05/30/2022 17:32:44 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.05 on epoch=379
05/30/2022 17:32:46 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.06 on epoch=382
05/30/2022 17:32:49 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=384
05/30/2022 17:32:51 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=387
05/30/2022 17:32:52 - INFO - __main__ - Global step 1550 Train loss 0.04 Classification-F1 0.7127558886091758 on epoch=387
05/30/2022 17:32:55 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.02 on epoch=389
05/30/2022 17:32:57 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.05 on epoch=392
05/30/2022 17:33:00 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.03 on epoch=394
05/30/2022 17:33:02 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.04 on epoch=397
05/30/2022 17:33:05 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.06 on epoch=399
05/30/2022 17:33:06 - INFO - __main__ - Global step 1600 Train loss 0.04 Classification-F1 0.6696862884840783 on epoch=399
05/30/2022 17:33:08 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=402
05/30/2022 17:33:11 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=404
05/30/2022 17:33:13 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.02 on epoch=407
05/30/2022 17:33:16 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.07 on epoch=409
05/30/2022 17:33:18 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=412
05/30/2022 17:33:19 - INFO - __main__ - Global step 1650 Train loss 0.03 Classification-F1 0.658553076402975 on epoch=412
05/30/2022 17:33:22 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.16 on epoch=414
05/30/2022 17:33:24 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.05 on epoch=417
05/30/2022 17:33:27 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.03 on epoch=419
05/30/2022 17:33:29 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=422
05/30/2022 17:33:32 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=424
05/30/2022 17:33:33 - INFO - __main__ - Global step 1700 Train loss 0.05 Classification-F1 0.6339097309685545 on epoch=424
05/30/2022 17:33:35 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=427
05/30/2022 17:33:38 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.02 on epoch=429
05/30/2022 17:33:40 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=432
05/30/2022 17:33:43 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.09 on epoch=434
05/30/2022 17:33:45 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.06 on epoch=437
05/30/2022 17:33:46 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.7477486559139784 on epoch=437
05/30/2022 17:33:46 - INFO - __main__ - Saving model with best Classification-F1: 0.7327559872922776 -> 0.7477486559139784 on epoch=437, global_step=1750
05/30/2022 17:33:49 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.04 on epoch=439
05/30/2022 17:33:51 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=442
05/30/2022 17:33:54 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=444
05/30/2022 17:33:56 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=447
05/30/2022 17:33:59 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.03 on epoch=449
05/30/2022 17:34:00 - INFO - __main__ - Global step 1800 Train loss 0.02 Classification-F1 0.7004289215686275 on epoch=449
05/30/2022 17:34:02 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=452
05/30/2022 17:34:05 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=454
05/30/2022 17:34:07 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=457
05/30/2022 17:34:10 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=459
05/30/2022 17:34:12 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=462
05/30/2022 17:34:13 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.7466733870967742 on epoch=462
05/30/2022 17:34:16 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=464
05/30/2022 17:34:18 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=467
05/30/2022 17:34:21 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=469
05/30/2022 17:34:23 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=472
05/30/2022 17:34:26 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=474
05/30/2022 17:34:27 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.697448872021927 on epoch=474
05/30/2022 17:34:29 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.04 on epoch=477
05/30/2022 17:34:32 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=479
05/30/2022 17:34:34 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=482
05/30/2022 17:34:37 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.06 on epoch=484
05/30/2022 17:34:39 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=487
05/30/2022 17:34:40 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.7135785570052812 on epoch=487
05/30/2022 17:34:43 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=489
05/30/2022 17:34:45 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=492
05/30/2022 17:34:48 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=494
05/30/2022 17:34:50 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=497
05/30/2022 17:34:53 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=499
05/30/2022 17:34:54 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.6919070512820512 on epoch=499
05/30/2022 17:34:56 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.04 on epoch=502
05/30/2022 17:34:59 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.05 on epoch=504
05/30/2022 17:35:01 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
05/30/2022 17:35:04 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=509
05/30/2022 17:35:06 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=512
05/30/2022 17:35:07 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.7641423724915186 on epoch=512
05/30/2022 17:35:07 - INFO - __main__ - Saving model with best Classification-F1: 0.7477486559139784 -> 0.7641423724915186 on epoch=512, global_step=2050
05/30/2022 17:35:10 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=514
05/30/2022 17:35:12 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=517
05/30/2022 17:35:15 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=519
05/30/2022 17:35:17 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=522
05/30/2022 17:35:20 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=524
05/30/2022 17:35:21 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.69922604277443 on epoch=524
05/30/2022 17:35:23 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.03 on epoch=527
05/30/2022 17:35:26 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=529
05/30/2022 17:35:29 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=532
05/30/2022 17:35:31 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=534
05/30/2022 17:35:34 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=537
05/30/2022 17:35:35 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.6882927951239146 on epoch=537
05/30/2022 17:35:37 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.04 on epoch=539
05/30/2022 17:35:40 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
05/30/2022 17:35:42 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.09 on epoch=544
05/30/2022 17:35:45 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=547
05/30/2022 17:35:47 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=549
05/30/2022 17:35:48 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.7191024661612898 on epoch=549
05/30/2022 17:35:51 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.03 on epoch=552
05/30/2022 17:35:53 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.09 on epoch=554
05/30/2022 17:35:55 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.03 on epoch=557
05/30/2022 17:35:58 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.03 on epoch=559
05/30/2022 17:36:01 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
05/30/2022 17:36:02 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.649134199134199 on epoch=562
05/30/2022 17:36:04 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
05/30/2022 17:36:07 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=567
05/30/2022 17:36:09 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=569
05/30/2022 17:36:12 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
05/30/2022 17:36:14 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.05 on epoch=574
05/30/2022 17:36:15 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.7439916405433646 on epoch=574
05/30/2022 17:36:18 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.06 on epoch=577
05/30/2022 17:36:20 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.09 on epoch=579
05/30/2022 17:36:23 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=582
05/30/2022 17:36:25 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=584
05/30/2022 17:36:27 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=587
05/30/2022 17:36:29 - INFO - __main__ - Global step 2350 Train loss 0.04 Classification-F1 0.6746916508538899 on epoch=587
05/30/2022 17:36:31 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=589
05/30/2022 17:36:34 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.12 on epoch=592
05/30/2022 17:36:36 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
05/30/2022 17:36:39 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.10 on epoch=597
05/30/2022 17:36:41 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
05/30/2022 17:36:42 - INFO - __main__ - Global step 2400 Train loss 0.05 Classification-F1 0.6453697737007695 on epoch=599
05/30/2022 17:36:44 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=602
05/30/2022 17:36:47 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=604
05/30/2022 17:36:49 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
05/30/2022 17:36:52 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=609
05/30/2022 17:36:54 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
05/30/2022 17:36:55 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.7168831168831169 on epoch=612
05/30/2022 17:36:58 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.04 on epoch=614
05/30/2022 17:37:00 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
05/30/2022 17:37:03 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.03 on epoch=619
05/30/2022 17:37:05 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
05/30/2022 17:37:08 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
05/30/2022 17:37:09 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.7747172182656055 on epoch=624
05/30/2022 17:37:09 - INFO - __main__ - Saving model with best Classification-F1: 0.7641423724915186 -> 0.7747172182656055 on epoch=624, global_step=2500
05/30/2022 17:37:11 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=627
05/30/2022 17:37:14 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=629
05/30/2022 17:37:16 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=632
05/30/2022 17:37:19 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
05/30/2022 17:37:21 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=637
05/30/2022 17:37:22 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.708000333000333 on epoch=637
05/30/2022 17:37:25 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=639
05/30/2022 17:37:27 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=642
05/30/2022 17:37:30 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.04 on epoch=644
05/30/2022 17:37:32 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
05/30/2022 17:37:35 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
05/30/2022 17:37:36 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.7466733870967742 on epoch=649
05/30/2022 17:37:38 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
05/30/2022 17:37:41 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=654
05/30/2022 17:37:43 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=657
05/30/2022 17:37:46 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
05/30/2022 17:37:48 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=662
05/30/2022 17:37:49 - INFO - __main__ - Global step 2650 Train loss 0.00 Classification-F1 0.7222612691362691 on epoch=662
05/30/2022 17:37:52 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=664
05/30/2022 17:37:54 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=667
05/30/2022 17:37:57 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=669
05/30/2022 17:37:59 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
05/30/2022 17:38:02 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.08 on epoch=674
05/30/2022 17:38:03 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.7222982909379969 on epoch=674
05/30/2022 17:38:05 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
05/30/2022 17:38:08 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.03 on epoch=679
05/30/2022 17:38:10 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=682
05/30/2022 17:38:13 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
05/30/2022 17:38:15 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=687
05/30/2022 17:38:16 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.7434345995451473 on epoch=687
05/30/2022 17:38:19 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=689
05/30/2022 17:38:21 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
05/30/2022 17:38:24 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
05/30/2022 17:38:26 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
05/30/2022 17:38:29 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=699
05/30/2022 17:38:30 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.6948832417582418 on epoch=699
05/30/2022 17:38:32 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
05/30/2022 17:38:35 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
05/30/2022 17:38:37 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
05/30/2022 17:38:40 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
05/30/2022 17:38:42 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=712
05/30/2022 17:38:43 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.6889980158730159 on epoch=712
05/30/2022 17:38:46 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
05/30/2022 17:38:48 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
05/30/2022 17:38:51 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.05 on epoch=719
05/30/2022 17:38:53 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=722
05/30/2022 17:38:56 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
05/30/2022 17:38:57 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.7279623373373373 on epoch=724
05/30/2022 17:38:59 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=727
05/30/2022 17:39:02 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=729
05/30/2022 17:39:04 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.18 on epoch=732
05/30/2022 17:39:07 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=734
05/30/2022 17:39:09 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=737
05/30/2022 17:39:10 - INFO - __main__ - Global step 2950 Train loss 0.04 Classification-F1 0.7275357744107743 on epoch=737
05/30/2022 17:39:13 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
05/30/2022 17:39:15 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
05/30/2022 17:39:18 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
05/30/2022 17:39:21 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
05/30/2022 17:39:23 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.04 on epoch=749
05/30/2022 17:39:24 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.7340005760368663 on epoch=749
05/30/2022 17:39:24 - INFO - __main__ - save last model!
05/30/2022 17:39:24 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/30/2022 17:39:24 - INFO - __main__ - Start tokenizing ... 5509 instances
05/30/2022 17:39:24 - INFO - __main__ - Printing 3 examples
05/30/2022 17:39:24 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/30/2022 17:39:24 - INFO - __main__ - ['others']
05/30/2022 17:39:24 - INFO - __main__ -  [emo] what you like very little things ok
05/30/2022 17:39:24 - INFO - __main__ - ['others']
05/30/2022 17:39:24 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/30/2022 17:39:24 - INFO - __main__ - ['others']
05/30/2022 17:39:24 - INFO - __main__ - Tokenizing Input ...
05/30/2022 17:39:24 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 17:39:24 - INFO - __main__ - Printing 3 examples
05/30/2022 17:39:24 - INFO - __main__ -  [emo] how cause yes am listening
05/30/2022 17:39:24 - INFO - __main__ - ['others']
05/30/2022 17:39:24 - INFO - __main__ -  [emo] ok that way i like living wwrong
05/30/2022 17:39:24 - INFO - __main__ - ['others']
05/30/2022 17:39:24 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
05/30/2022 17:39:24 - INFO - __main__ - ['others']
05/30/2022 17:39:24 - INFO - __main__ - Tokenizing Input ...
05/30/2022 17:39:24 - INFO - __main__ - Tokenizing Output ...
05/30/2022 17:39:24 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 17:39:24 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 17:39:24 - INFO - __main__ - Printing 3 examples
05/30/2022 17:39:24 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
05/30/2022 17:39:24 - INFO - __main__ - ['others']
05/30/2022 17:39:24 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
05/30/2022 17:39:24 - INFO - __main__ - ['others']
05/30/2022 17:39:24 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
05/30/2022 17:39:24 - INFO - __main__ - ['others']
05/30/2022 17:39:24 - INFO - __main__ - Tokenizing Input ...
05/30/2022 17:39:24 - INFO - __main__ - Tokenizing Output ...
05/30/2022 17:39:24 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 17:39:26 - INFO - __main__ - Tokenizing Output ...
05/30/2022 17:39:32 - INFO - __main__ - Loaded 5509 examples from test data
05/30/2022 17:39:43 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 17:39:44 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/30/2022 17:39:44 - INFO - __main__ - Starting training!
05/30/2022 17:41:05 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-24uptasks/singletask-emo/emo_16_100_0.3_8_predictions.txt
05/30/2022 17:41:05 - INFO - __main__ - Classification-F1 on test data: 0.3221
05/30/2022 17:41:05 - INFO - __main__ - prefix=emo_16_100, lr=0.3, bsz=8, dev_performance=0.7747172182656055, test_performance=0.3220596630099415
05/30/2022 17:41:05 - INFO - __main__ - Running ... prefix=emo_16_100, lr=0.2, bsz=8 ...
05/30/2022 17:41:06 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 17:41:06 - INFO - __main__ - Printing 3 examples
05/30/2022 17:41:06 - INFO - __main__ -  [emo] how cause yes am listening
05/30/2022 17:41:06 - INFO - __main__ - ['others']
05/30/2022 17:41:06 - INFO - __main__ -  [emo] ok that way i like living wwrong
05/30/2022 17:41:06 - INFO - __main__ - ['others']
05/30/2022 17:41:06 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
05/30/2022 17:41:06 - INFO - __main__ - ['others']
05/30/2022 17:41:06 - INFO - __main__ - Tokenizing Input ...
05/30/2022 17:41:06 - INFO - __main__ - Tokenizing Output ...
05/30/2022 17:41:07 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 17:41:07 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 17:41:07 - INFO - __main__ - Printing 3 examples
05/30/2022 17:41:07 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
05/30/2022 17:41:07 - INFO - __main__ - ['others']
05/30/2022 17:41:07 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
05/30/2022 17:41:07 - INFO - __main__ - ['others']
05/30/2022 17:41:07 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
05/30/2022 17:41:07 - INFO - __main__ - ['others']
05/30/2022 17:41:07 - INFO - __main__ - Tokenizing Input ...
05/30/2022 17:41:07 - INFO - __main__ - Tokenizing Output ...
05/30/2022 17:41:07 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 17:41:22 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 17:41:23 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/30/2022 17:41:23 - INFO - __main__ - Starting training!
05/30/2022 17:41:26 - INFO - __main__ - Step 10 Global step 10 Train loss 4.09 on epoch=2
05/30/2022 17:41:28 - INFO - __main__ - Step 20 Global step 20 Train loss 2.40 on epoch=4
05/30/2022 17:41:31 - INFO - __main__ - Step 30 Global step 30 Train loss 1.77 on epoch=7
05/30/2022 17:41:33 - INFO - __main__ - Step 40 Global step 40 Train loss 1.33 on epoch=9
05/30/2022 17:41:36 - INFO - __main__ - Step 50 Global step 50 Train loss 1.28 on epoch=12
05/30/2022 17:41:37 - INFO - __main__ - Global step 50 Train loss 2.17 Classification-F1 0.2170950491633603 on epoch=12
05/30/2022 17:41:37 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.2170950491633603 on epoch=12, global_step=50
05/30/2022 17:41:39 - INFO - __main__ - Step 60 Global step 60 Train loss 1.08 on epoch=14
05/30/2022 17:41:42 - INFO - __main__ - Step 70 Global step 70 Train loss 1.03 on epoch=17
05/30/2022 17:41:45 - INFO - __main__ - Step 80 Global step 80 Train loss 1.01 on epoch=19
05/30/2022 17:41:47 - INFO - __main__ - Step 90 Global step 90 Train loss 0.90 on epoch=22
05/30/2022 17:41:50 - INFO - __main__ - Step 100 Global step 100 Train loss 0.84 on epoch=24
05/30/2022 17:41:51 - INFO - __main__ - Global step 100 Train loss 0.97 Classification-F1 0.33008993070912573 on epoch=24
05/30/2022 17:41:51 - INFO - __main__ - Saving model with best Classification-F1: 0.2170950491633603 -> 0.33008993070912573 on epoch=24, global_step=100
05/30/2022 17:41:53 - INFO - __main__ - Step 110 Global step 110 Train loss 0.91 on epoch=27
05/30/2022 17:41:56 - INFO - __main__ - Step 120 Global step 120 Train loss 0.90 on epoch=29
05/30/2022 17:41:58 - INFO - __main__ - Step 130 Global step 130 Train loss 0.90 on epoch=32
05/30/2022 17:42:01 - INFO - __main__ - Step 140 Global step 140 Train loss 0.91 on epoch=34
05/30/2022 17:42:03 - INFO - __main__ - Step 150 Global step 150 Train loss 0.88 on epoch=37
05/30/2022 17:42:04 - INFO - __main__ - Global step 150 Train loss 0.90 Classification-F1 0.48769157088122606 on epoch=37
05/30/2022 17:42:04 - INFO - __main__ - Saving model with best Classification-F1: 0.33008993070912573 -> 0.48769157088122606 on epoch=37, global_step=150
05/30/2022 17:42:07 - INFO - __main__ - Step 160 Global step 160 Train loss 0.77 on epoch=39
05/30/2022 17:42:09 - INFO - __main__ - Step 170 Global step 170 Train loss 0.80 on epoch=42
05/30/2022 17:42:12 - INFO - __main__ - Step 180 Global step 180 Train loss 0.75 on epoch=44
05/30/2022 17:42:14 - INFO - __main__ - Step 190 Global step 190 Train loss 0.85 on epoch=47
05/30/2022 17:42:17 - INFO - __main__ - Step 200 Global step 200 Train loss 0.77 on epoch=49
05/30/2022 17:42:18 - INFO - __main__ - Global step 200 Train loss 0.79 Classification-F1 0.5938943101762901 on epoch=49
05/30/2022 17:42:18 - INFO - __main__ - Saving model with best Classification-F1: 0.48769157088122606 -> 0.5938943101762901 on epoch=49, global_step=200
05/30/2022 17:42:20 - INFO - __main__ - Step 210 Global step 210 Train loss 0.75 on epoch=52
05/30/2022 17:42:23 - INFO - __main__ - Step 220 Global step 220 Train loss 0.84 on epoch=54
05/30/2022 17:42:25 - INFO - __main__ - Step 230 Global step 230 Train loss 0.67 on epoch=57
05/30/2022 17:42:28 - INFO - __main__ - Step 240 Global step 240 Train loss 0.83 on epoch=59
05/30/2022 17:42:30 - INFO - __main__ - Step 250 Global step 250 Train loss 0.66 on epoch=62
05/30/2022 17:42:31 - INFO - __main__ - Global step 250 Train loss 0.75 Classification-F1 0.5579042457091238 on epoch=62
05/30/2022 17:42:34 - INFO - __main__ - Step 260 Global step 260 Train loss 0.68 on epoch=64
05/30/2022 17:42:36 - INFO - __main__ - Step 270 Global step 270 Train loss 0.75 on epoch=67
05/30/2022 17:42:39 - INFO - __main__ - Step 280 Global step 280 Train loss 0.74 on epoch=69
05/30/2022 17:42:41 - INFO - __main__ - Step 290 Global step 290 Train loss 0.66 on epoch=72
05/30/2022 17:42:44 - INFO - __main__ - Step 300 Global step 300 Train loss 0.59 on epoch=74
05/30/2022 17:42:45 - INFO - __main__ - Global step 300 Train loss 0.68 Classification-F1 0.5990812159709619 on epoch=74
05/30/2022 17:42:45 - INFO - __main__ - Saving model with best Classification-F1: 0.5938943101762901 -> 0.5990812159709619 on epoch=74, global_step=300
05/30/2022 17:42:47 - INFO - __main__ - Step 310 Global step 310 Train loss 0.72 on epoch=77
05/30/2022 17:42:50 - INFO - __main__ - Step 320 Global step 320 Train loss 0.63 on epoch=79
05/30/2022 17:42:52 - INFO - __main__ - Step 330 Global step 330 Train loss 0.63 on epoch=82
05/30/2022 17:42:55 - INFO - __main__ - Step 340 Global step 340 Train loss 0.64 on epoch=84
05/30/2022 17:42:58 - INFO - __main__ - Step 350 Global step 350 Train loss 0.58 on epoch=87
05/30/2022 17:42:58 - INFO - __main__ - Global step 350 Train loss 0.64 Classification-F1 0.6130115404308952 on epoch=87
05/30/2022 17:42:58 - INFO - __main__ - Saving model with best Classification-F1: 0.5990812159709619 -> 0.6130115404308952 on epoch=87, global_step=350
05/30/2022 17:43:01 - INFO - __main__ - Step 360 Global step 360 Train loss 0.49 on epoch=89
05/30/2022 17:43:03 - INFO - __main__ - Step 370 Global step 370 Train loss 0.53 on epoch=92
05/30/2022 17:43:06 - INFO - __main__ - Step 380 Global step 380 Train loss 0.56 on epoch=94
05/30/2022 17:43:09 - INFO - __main__ - Step 390 Global step 390 Train loss 0.61 on epoch=97
05/30/2022 17:43:11 - INFO - __main__ - Step 400 Global step 400 Train loss 0.55 on epoch=99
05/30/2022 17:43:12 - INFO - __main__ - Global step 400 Train loss 0.55 Classification-F1 0.541596673254282 on epoch=99
05/30/2022 17:43:14 - INFO - __main__ - Step 410 Global step 410 Train loss 0.53 on epoch=102
05/30/2022 17:43:17 - INFO - __main__ - Step 420 Global step 420 Train loss 0.52 on epoch=104
05/30/2022 17:43:20 - INFO - __main__ - Step 430 Global step 430 Train loss 0.46 on epoch=107
05/30/2022 17:43:22 - INFO - __main__ - Step 440 Global step 440 Train loss 0.54 on epoch=109
05/30/2022 17:43:25 - INFO - __main__ - Step 450 Global step 450 Train loss 0.51 on epoch=112
05/30/2022 17:43:25 - INFO - __main__ - Global step 450 Train loss 0.51 Classification-F1 0.6660173519009727 on epoch=112
05/30/2022 17:43:25 - INFO - __main__ - Saving model with best Classification-F1: 0.6130115404308952 -> 0.6660173519009727 on epoch=112, global_step=450
05/30/2022 17:43:28 - INFO - __main__ - Step 460 Global step 460 Train loss 0.51 on epoch=114
05/30/2022 17:43:31 - INFO - __main__ - Step 470 Global step 470 Train loss 0.47 on epoch=117
05/30/2022 17:43:33 - INFO - __main__ - Step 480 Global step 480 Train loss 0.38 on epoch=119
05/30/2022 17:43:36 - INFO - __main__ - Step 490 Global step 490 Train loss 0.55 on epoch=122
05/30/2022 17:43:38 - INFO - __main__ - Step 500 Global step 500 Train loss 0.45 on epoch=124
05/30/2022 17:43:39 - INFO - __main__ - Global step 500 Train loss 0.47 Classification-F1 0.6606736400854047 on epoch=124
05/30/2022 17:43:42 - INFO - __main__ - Step 510 Global step 510 Train loss 0.58 on epoch=127
05/30/2022 17:43:44 - INFO - __main__ - Step 520 Global step 520 Train loss 0.46 on epoch=129
05/30/2022 17:43:47 - INFO - __main__ - Step 530 Global step 530 Train loss 0.52 on epoch=132
05/30/2022 17:43:49 - INFO - __main__ - Step 540 Global step 540 Train loss 0.39 on epoch=134
05/30/2022 17:43:52 - INFO - __main__ - Step 550 Global step 550 Train loss 0.48 on epoch=137
05/30/2022 17:43:53 - INFO - __main__ - Global step 550 Train loss 0.49 Classification-F1 0.636050307219662 on epoch=137
05/30/2022 17:43:55 - INFO - __main__ - Step 560 Global step 560 Train loss 0.40 on epoch=139
05/30/2022 17:43:58 - INFO - __main__ - Step 570 Global step 570 Train loss 0.52 on epoch=142
05/30/2022 17:44:00 - INFO - __main__ - Step 580 Global step 580 Train loss 0.42 on epoch=144
05/30/2022 17:44:03 - INFO - __main__ - Step 590 Global step 590 Train loss 0.42 on epoch=147
05/30/2022 17:44:05 - INFO - __main__ - Step 600 Global step 600 Train loss 0.31 on epoch=149
05/30/2022 17:44:06 - INFO - __main__ - Global step 600 Train loss 0.41 Classification-F1 0.6316797002280874 on epoch=149
05/30/2022 17:44:09 - INFO - __main__ - Step 610 Global step 610 Train loss 0.41 on epoch=152
05/30/2022 17:44:11 - INFO - __main__ - Step 620 Global step 620 Train loss 0.40 on epoch=154
05/30/2022 17:44:14 - INFO - __main__ - Step 630 Global step 630 Train loss 0.39 on epoch=157
05/30/2022 17:44:16 - INFO - __main__ - Step 640 Global step 640 Train loss 0.37 on epoch=159
05/30/2022 17:44:19 - INFO - __main__ - Step 650 Global step 650 Train loss 0.41 on epoch=162
05/30/2022 17:44:20 - INFO - __main__ - Global step 650 Train loss 0.40 Classification-F1 0.7223529411764706 on epoch=162
05/30/2022 17:44:20 - INFO - __main__ - Saving model with best Classification-F1: 0.6660173519009727 -> 0.7223529411764706 on epoch=162, global_step=650
05/30/2022 17:44:22 - INFO - __main__ - Step 660 Global step 660 Train loss 0.28 on epoch=164
05/30/2022 17:44:25 - INFO - __main__ - Step 670 Global step 670 Train loss 0.30 on epoch=167
05/30/2022 17:44:27 - INFO - __main__ - Step 680 Global step 680 Train loss 0.34 on epoch=169
05/30/2022 17:44:30 - INFO - __main__ - Step 690 Global step 690 Train loss 0.35 on epoch=172
05/30/2022 17:44:32 - INFO - __main__ - Step 700 Global step 700 Train loss 0.29 on epoch=174
05/30/2022 17:44:33 - INFO - __main__ - Global step 700 Train loss 0.31 Classification-F1 0.7076100370218017 on epoch=174
05/30/2022 17:44:36 - INFO - __main__ - Step 710 Global step 710 Train loss 0.39 on epoch=177
05/30/2022 17:44:38 - INFO - __main__ - Step 720 Global step 720 Train loss 0.25 on epoch=179
05/30/2022 17:44:41 - INFO - __main__ - Step 730 Global step 730 Train loss 0.35 on epoch=182
05/30/2022 17:44:43 - INFO - __main__ - Step 740 Global step 740 Train loss 0.32 on epoch=184
05/30/2022 17:44:46 - INFO - __main__ - Step 750 Global step 750 Train loss 0.37 on epoch=187
05/30/2022 17:44:47 - INFO - __main__ - Global step 750 Train loss 0.34 Classification-F1 0.7435398532172726 on epoch=187
05/30/2022 17:44:47 - INFO - __main__ - Saving model with best Classification-F1: 0.7223529411764706 -> 0.7435398532172726 on epoch=187, global_step=750
05/30/2022 17:44:49 - INFO - __main__ - Step 760 Global step 760 Train loss 0.20 on epoch=189
05/30/2022 17:44:52 - INFO - __main__ - Step 770 Global step 770 Train loss 0.33 on epoch=192
05/30/2022 17:44:54 - INFO - __main__ - Step 780 Global step 780 Train loss 0.23 on epoch=194
05/30/2022 17:44:57 - INFO - __main__ - Step 790 Global step 790 Train loss 0.25 on epoch=197
05/30/2022 17:44:59 - INFO - __main__ - Step 800 Global step 800 Train loss 0.24 on epoch=199
05/30/2022 17:45:00 - INFO - __main__ - Global step 800 Train loss 0.25 Classification-F1 0.6323313782991202 on epoch=199
05/30/2022 17:45:03 - INFO - __main__ - Step 810 Global step 810 Train loss 0.30 on epoch=202
05/30/2022 17:45:05 - INFO - __main__ - Step 820 Global step 820 Train loss 0.27 on epoch=204
05/30/2022 17:45:08 - INFO - __main__ - Step 830 Global step 830 Train loss 0.34 on epoch=207
05/30/2022 17:45:10 - INFO - __main__ - Step 840 Global step 840 Train loss 0.25 on epoch=209
05/30/2022 17:45:13 - INFO - __main__ - Step 850 Global step 850 Train loss 0.26 on epoch=212
05/30/2022 17:45:14 - INFO - __main__ - Global step 850 Train loss 0.28 Classification-F1 0.682010582010582 on epoch=212
05/30/2022 17:45:16 - INFO - __main__ - Step 860 Global step 860 Train loss 0.27 on epoch=214
05/30/2022 17:45:19 - INFO - __main__ - Step 870 Global step 870 Train loss 0.21 on epoch=217
05/30/2022 17:45:21 - INFO - __main__ - Step 880 Global step 880 Train loss 0.28 on epoch=219
05/30/2022 17:45:24 - INFO - __main__ - Step 890 Global step 890 Train loss 0.22 on epoch=222
05/30/2022 17:45:26 - INFO - __main__ - Step 900 Global step 900 Train loss 0.25 on epoch=224
05/30/2022 17:45:27 - INFO - __main__ - Global step 900 Train loss 0.25 Classification-F1 0.6203144894321365 on epoch=224
05/30/2022 17:45:29 - INFO - __main__ - Step 910 Global step 910 Train loss 0.24 on epoch=227
05/30/2022 17:45:32 - INFO - __main__ - Step 920 Global step 920 Train loss 0.15 on epoch=229
05/30/2022 17:45:34 - INFO - __main__ - Step 930 Global step 930 Train loss 0.19 on epoch=232
05/30/2022 17:45:37 - INFO - __main__ - Step 940 Global step 940 Train loss 0.18 on epoch=234
05/30/2022 17:45:39 - INFO - __main__ - Step 950 Global step 950 Train loss 0.26 on epoch=237
05/30/2022 17:45:40 - INFO - __main__ - Global step 950 Train loss 0.20 Classification-F1 0.6396424132544271 on epoch=237
05/30/2022 17:45:43 - INFO - __main__ - Step 960 Global step 960 Train loss 0.19 on epoch=239
05/30/2022 17:45:45 - INFO - __main__ - Step 970 Global step 970 Train loss 0.26 on epoch=242
05/30/2022 17:45:48 - INFO - __main__ - Step 980 Global step 980 Train loss 0.12 on epoch=244
05/30/2022 17:45:50 - INFO - __main__ - Step 990 Global step 990 Train loss 0.20 on epoch=247
05/30/2022 17:45:53 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.18 on epoch=249
05/30/2022 17:45:54 - INFO - __main__ - Global step 1000 Train loss 0.19 Classification-F1 0.7265888047138047 on epoch=249
05/30/2022 17:45:56 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.22 on epoch=252
05/30/2022 17:45:59 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.18 on epoch=254
05/30/2022 17:46:01 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.16 on epoch=257
05/30/2022 17:46:04 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.17 on epoch=259
05/30/2022 17:46:06 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.16 on epoch=262
05/30/2022 17:46:07 - INFO - __main__ - Global step 1050 Train loss 0.18 Classification-F1 0.7129030293026473 on epoch=262
05/30/2022 17:46:10 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.19 on epoch=264
05/30/2022 17:46:12 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.16 on epoch=267
05/30/2022 17:46:14 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.13 on epoch=269
05/30/2022 17:46:17 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.17 on epoch=272
05/30/2022 17:46:19 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.16 on epoch=274
05/30/2022 17:46:20 - INFO - __main__ - Global step 1100 Train loss 0.16 Classification-F1 0.6744871794871795 on epoch=274
05/30/2022 17:46:23 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.19 on epoch=277
05/30/2022 17:46:25 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.16 on epoch=279
05/30/2022 17:46:28 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.15 on epoch=282
05/30/2022 17:46:30 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.11 on epoch=284
05/30/2022 17:46:33 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.18 on epoch=287
05/30/2022 17:46:34 - INFO - __main__ - Global step 1150 Train loss 0.16 Classification-F1 0.697448872021927 on epoch=287
05/30/2022 17:46:36 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.14 on epoch=289
05/30/2022 17:46:39 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.11 on epoch=292
05/30/2022 17:46:41 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.12 on epoch=294
05/30/2022 17:46:44 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.16 on epoch=297
05/30/2022 17:46:46 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.16 on epoch=299
05/30/2022 17:46:47 - INFO - __main__ - Global step 1200 Train loss 0.14 Classification-F1 0.6852394916911045 on epoch=299
05/30/2022 17:46:50 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.14 on epoch=302
05/30/2022 17:46:52 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.09 on epoch=304
05/30/2022 17:46:55 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.16 on epoch=307
05/30/2022 17:46:57 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.08 on epoch=309
05/30/2022 17:47:00 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.14 on epoch=312
05/30/2022 17:47:00 - INFO - __main__ - Global step 1250 Train loss 0.12 Classification-F1 0.7167613636363637 on epoch=312
05/30/2022 17:47:03 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.07 on epoch=314
05/30/2022 17:47:05 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.18 on epoch=317
05/30/2022 17:47:08 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.11 on epoch=319
05/30/2022 17:47:10 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.13 on epoch=322
05/30/2022 17:47:13 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.13 on epoch=324
05/30/2022 17:47:14 - INFO - __main__ - Global step 1300 Train loss 0.13 Classification-F1 0.7126488095238095 on epoch=324
05/30/2022 17:47:16 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.10 on epoch=327
05/30/2022 17:47:19 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.18 on epoch=329
05/30/2022 17:47:21 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.09 on epoch=332
05/30/2022 17:47:24 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.14 on epoch=334
05/30/2022 17:47:26 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.15 on epoch=337
05/30/2022 17:47:27 - INFO - __main__ - Global step 1350 Train loss 0.13 Classification-F1 0.6849264705882353 on epoch=337
05/30/2022 17:47:30 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.07 on epoch=339
05/30/2022 17:47:32 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.06 on epoch=342
05/30/2022 17:47:35 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.18 on epoch=344
05/30/2022 17:47:37 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.07 on epoch=347
05/30/2022 17:47:40 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.06 on epoch=349
05/30/2022 17:47:41 - INFO - __main__ - Global step 1400 Train loss 0.09 Classification-F1 0.6974697191431063 on epoch=349
05/30/2022 17:47:43 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.09 on epoch=352
05/30/2022 17:47:45 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.09 on epoch=354
05/30/2022 17:47:48 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.08 on epoch=357
05/30/2022 17:47:50 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.17 on epoch=359
05/30/2022 17:47:53 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.10 on epoch=362
05/30/2022 17:47:54 - INFO - __main__ - Global step 1450 Train loss 0.11 Classification-F1 0.7301724137931034 on epoch=362
05/30/2022 17:47:56 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.04 on epoch=364
05/30/2022 17:47:58 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.06 on epoch=367
05/30/2022 17:48:01 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.09 on epoch=369
05/30/2022 17:48:03 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.07 on epoch=372
05/30/2022 17:48:06 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.04 on epoch=374
05/30/2022 17:48:06 - INFO - __main__ - Global step 1500 Train loss 0.06 Classification-F1 0.7154121863799283 on epoch=374
05/30/2022 17:48:09 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.05 on epoch=377
05/30/2022 17:48:11 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.08 on epoch=379
05/30/2022 17:48:14 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.14 on epoch=382
05/30/2022 17:48:16 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.05 on epoch=384
05/30/2022 17:48:19 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.09 on epoch=387
05/30/2022 17:48:19 - INFO - __main__ - Global step 1550 Train loss 0.08 Classification-F1 0.6802452236719478 on epoch=387
05/30/2022 17:48:22 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.08 on epoch=389
05/30/2022 17:48:24 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.05 on epoch=392
05/30/2022 17:48:27 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.03 on epoch=394
05/30/2022 17:48:29 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.12 on epoch=397
05/30/2022 17:48:32 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.06 on epoch=399
05/30/2022 17:48:32 - INFO - __main__ - Global step 1600 Train loss 0.07 Classification-F1 0.6635785570052811 on epoch=399
05/30/2022 17:48:35 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.13 on epoch=402
05/30/2022 17:48:37 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.11 on epoch=404
05/30/2022 17:48:40 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.09 on epoch=407
05/30/2022 17:48:42 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.10 on epoch=409
05/30/2022 17:48:44 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.09 on epoch=412
05/30/2022 17:48:45 - INFO - __main__ - Global step 1650 Train loss 0.10 Classification-F1 0.7097652681144142 on epoch=412
05/30/2022 17:48:48 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.08 on epoch=414
05/30/2022 17:48:50 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.07 on epoch=417
05/30/2022 17:48:52 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.05 on epoch=419
05/30/2022 17:48:55 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.02 on epoch=422
05/30/2022 17:48:57 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.08 on epoch=424
05/30/2022 17:48:58 - INFO - __main__ - Global step 1700 Train loss 0.06 Classification-F1 0.6967908015078481 on epoch=424
05/30/2022 17:49:01 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.09 on epoch=427
05/30/2022 17:49:03 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.04 on epoch=429
05/30/2022 17:49:06 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.05 on epoch=432
05/30/2022 17:49:08 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.06 on epoch=434
05/30/2022 17:49:10 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=437
05/30/2022 17:49:11 - INFO - __main__ - Global step 1750 Train loss 0.05 Classification-F1 0.6950980392156864 on epoch=437
05/30/2022 17:49:14 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.06 on epoch=439
05/30/2022 17:49:16 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.04 on epoch=442
05/30/2022 17:49:18 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.04 on epoch=444
05/30/2022 17:49:21 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.07 on epoch=447
05/30/2022 17:49:23 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.03 on epoch=449
05/30/2022 17:49:24 - INFO - __main__ - Global step 1800 Train loss 0.05 Classification-F1 0.6809027777777777 on epoch=449
05/30/2022 17:49:27 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.10 on epoch=452
05/30/2022 17:49:29 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=454
05/30/2022 17:49:31 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.04 on epoch=457
05/30/2022 17:49:34 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.06 on epoch=459
05/30/2022 17:49:36 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.06 on epoch=462
05/30/2022 17:49:37 - INFO - __main__ - Global step 1850 Train loss 0.06 Classification-F1 0.6972446236559139 on epoch=462
05/30/2022 17:49:40 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.05 on epoch=464
05/30/2022 17:49:42 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.07 on epoch=467
05/30/2022 17:49:44 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.08 on epoch=469
05/30/2022 17:49:47 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=472
05/30/2022 17:49:49 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=474
05/30/2022 17:49:50 - INFO - __main__ - Global step 1900 Train loss 0.05 Classification-F1 0.726853354978355 on epoch=474
05/30/2022 17:49:53 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.07 on epoch=477
05/30/2022 17:49:55 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.05 on epoch=479
05/30/2022 17:49:58 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.06 on epoch=482
05/30/2022 17:50:00 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=484
05/30/2022 17:50:02 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=487
05/30/2022 17:50:03 - INFO - __main__ - Global step 1950 Train loss 0.04 Classification-F1 0.6979737514011708 on epoch=487
05/30/2022 17:50:06 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.07 on epoch=489
05/30/2022 17:50:08 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.04 on epoch=492
05/30/2022 17:50:11 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.08 on epoch=494
05/30/2022 17:50:13 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.13 on epoch=497
05/30/2022 17:50:16 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=499
05/30/2022 17:50:16 - INFO - __main__ - Global step 2000 Train loss 0.07 Classification-F1 0.6983028982820418 on epoch=499
05/30/2022 17:50:19 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.03 on epoch=502
05/30/2022 17:50:21 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.04 on epoch=504
05/30/2022 17:50:24 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.02 on epoch=507
05/30/2022 17:50:26 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.03 on epoch=509
05/30/2022 17:50:29 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.07 on epoch=512
05/30/2022 17:50:30 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.6944444444444444 on epoch=512
05/30/2022 17:50:32 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.02 on epoch=514
05/30/2022 17:50:34 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.04 on epoch=517
05/30/2022 17:50:37 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.04 on epoch=519
05/30/2022 17:50:39 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=522
05/30/2022 17:50:42 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.05 on epoch=524
05/30/2022 17:50:43 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.6826778982820418 on epoch=524
05/30/2022 17:50:45 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=527
05/30/2022 17:50:48 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=529
05/30/2022 17:50:50 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.07 on epoch=532
05/30/2022 17:50:53 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.06 on epoch=534
05/30/2022 17:50:55 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.08 on epoch=537
05/30/2022 17:50:56 - INFO - __main__ - Global step 2150 Train loss 0.05 Classification-F1 0.7113304093567252 on epoch=537
05/30/2022 17:50:58 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=539
05/30/2022 17:51:01 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=542
05/30/2022 17:51:03 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.04 on epoch=544
05/30/2022 17:51:06 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=547
05/30/2022 17:51:08 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.12 on epoch=549
05/30/2022 17:51:09 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.6821738660239773 on epoch=549
05/30/2022 17:51:11 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=552
05/30/2022 17:51:14 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.07 on epoch=554
05/30/2022 17:51:16 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.03 on epoch=557
05/30/2022 17:51:19 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.03 on epoch=559
05/30/2022 17:51:21 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=562
05/30/2022 17:51:22 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.6825980392156863 on epoch=562
05/30/2022 17:51:25 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.04 on epoch=564
05/30/2022 17:51:27 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.04 on epoch=567
05/30/2022 17:51:30 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=569
05/30/2022 17:51:32 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=572
05/30/2022 17:51:35 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=574
05/30/2022 17:51:36 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.6826164874551971 on epoch=574
05/30/2022 17:51:38 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=577
05/30/2022 17:51:40 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=579
05/30/2022 17:51:43 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.04 on epoch=582
05/30/2022 17:51:45 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=584
05/30/2022 17:51:48 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.05 on epoch=587
05/30/2022 17:51:49 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.6569564694564695 on epoch=587
05/30/2022 17:51:51 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.07 on epoch=589
05/30/2022 17:51:54 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.03 on epoch=592
05/30/2022 17:51:56 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=594
05/30/2022 17:51:59 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=597
05/30/2022 17:52:01 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=599
05/30/2022 17:52:02 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.70751918982409 on epoch=599
05/30/2022 17:52:04 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.05 on epoch=602
05/30/2022 17:52:07 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.06 on epoch=604
05/30/2022 17:52:09 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=607
05/30/2022 17:52:12 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=609
05/30/2022 17:52:14 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=612
05/30/2022 17:52:15 - INFO - __main__ - Global step 2450 Train loss 0.04 Classification-F1 0.6708114381061963 on epoch=612
05/30/2022 17:52:18 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.02 on epoch=614
05/30/2022 17:52:20 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=617
05/30/2022 17:52:22 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.06 on epoch=619
05/30/2022 17:52:25 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=622
05/30/2022 17:52:27 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=624
05/30/2022 17:52:28 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.694976874890229 on epoch=624
05/30/2022 17:52:31 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.08 on epoch=627
05/30/2022 17:52:33 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=629
05/30/2022 17:52:36 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.04 on epoch=632
05/30/2022 17:52:38 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=634
05/30/2022 17:52:40 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=637
05/30/2022 17:52:41 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.6999192775923866 on epoch=637
05/30/2022 17:52:44 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.03 on epoch=639
05/30/2022 17:52:46 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.04 on epoch=642
05/30/2022 17:52:49 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.03 on epoch=644
05/30/2022 17:52:51 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=647
05/30/2022 17:52:54 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=649
05/30/2022 17:52:55 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.6647175540390223 on epoch=649
05/30/2022 17:52:57 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=652
05/30/2022 17:53:00 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=654
05/30/2022 17:53:02 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.11 on epoch=657
05/30/2022 17:53:05 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=659
05/30/2022 17:53:07 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=662
05/30/2022 17:53:08 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.6291911970843846 on epoch=662
05/30/2022 17:53:10 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.04 on epoch=664
05/30/2022 17:53:13 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.07 on epoch=667
05/30/2022 17:53:15 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.13 on epoch=669
05/30/2022 17:53:18 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=672
05/30/2022 17:53:20 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=674
05/30/2022 17:53:21 - INFO - __main__ - Global step 2700 Train loss 0.06 Classification-F1 0.6601870633310796 on epoch=674
05/30/2022 17:53:24 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.03 on epoch=677
05/30/2022 17:53:26 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=679
05/30/2022 17:53:29 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.04 on epoch=682
05/30/2022 17:53:31 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=684
05/30/2022 17:53:33 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=687
05/30/2022 17:53:34 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.6929254700370999 on epoch=687
05/30/2022 17:53:37 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=689
05/30/2022 17:53:39 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
05/30/2022 17:53:42 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=694
05/30/2022 17:53:44 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.03 on epoch=697
05/30/2022 17:53:47 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=699
05/30/2022 17:53:48 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.6969118903386143 on epoch=699
05/30/2022 17:53:50 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=702
05/30/2022 17:53:52 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=704
05/30/2022 17:53:55 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=707
05/30/2022 17:53:57 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=709
05/30/2022 17:54:00 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=712
05/30/2022 17:54:01 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.6609568982234517 on epoch=712
05/30/2022 17:54:03 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
05/30/2022 17:54:06 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=717
05/30/2022 17:54:08 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=719
05/30/2022 17:54:11 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.03 on epoch=722
05/30/2022 17:54:13 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
05/30/2022 17:54:14 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.6847670250896057 on epoch=724
05/30/2022 17:54:16 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=727
05/30/2022 17:54:19 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=729
05/30/2022 17:54:21 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=732
05/30/2022 17:54:24 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.03 on epoch=734
05/30/2022 17:54:26 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=737
05/30/2022 17:54:27 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.7014250067642726 on epoch=737
05/30/2022 17:54:30 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=739
05/30/2022 17:54:32 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=742
05/30/2022 17:54:34 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=744
05/30/2022 17:54:37 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=747
05/30/2022 17:54:39 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=749
05/30/2022 17:54:40 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.6876296082949309 on epoch=749
05/30/2022 17:54:40 - INFO - __main__ - save last model!
05/30/2022 17:54:40 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/30/2022 17:54:40 - INFO - __main__ - Start tokenizing ... 5509 instances
05/30/2022 17:54:40 - INFO - __main__ - Printing 3 examples
05/30/2022 17:54:40 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/30/2022 17:54:40 - INFO - __main__ - ['others']
05/30/2022 17:54:40 - INFO - __main__ -  [emo] what you like very little things ok
05/30/2022 17:54:40 - INFO - __main__ - ['others']
05/30/2022 17:54:40 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/30/2022 17:54:40 - INFO - __main__ - ['others']
05/30/2022 17:54:40 - INFO - __main__ - Tokenizing Input ...
05/30/2022 17:54:41 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 17:54:41 - INFO - __main__ - Printing 3 examples
05/30/2022 17:54:41 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
05/30/2022 17:54:41 - INFO - __main__ - ['others']
05/30/2022 17:54:41 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
05/30/2022 17:54:41 - INFO - __main__ - ['others']
05/30/2022 17:54:41 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
05/30/2022 17:54:41 - INFO - __main__ - ['others']
05/30/2022 17:54:41 - INFO - __main__ - Tokenizing Input ...
05/30/2022 17:54:41 - INFO - __main__ - Tokenizing Output ...
05/30/2022 17:54:41 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 17:54:41 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 17:54:41 - INFO - __main__ - Printing 3 examples
05/30/2022 17:54:41 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
05/30/2022 17:54:41 - INFO - __main__ - ['others']
05/30/2022 17:54:41 - INFO - __main__ -  [emo] i did ask now you did tell ms
05/30/2022 17:54:41 - INFO - __main__ - ['others']
05/30/2022 17:54:41 - INFO - __main__ -  [emo] buddy how you tell me your contact no
05/30/2022 17:54:41 - INFO - __main__ - ['others']
05/30/2022 17:54:41 - INFO - __main__ - Tokenizing Input ...
05/30/2022 17:54:41 - INFO - __main__ - Tokenizing Output ...
05/30/2022 17:54:41 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 17:54:43 - INFO - __main__ - Tokenizing Output ...
05/30/2022 17:54:48 - INFO - __main__ - Loaded 5509 examples from test data
05/30/2022 17:54:59 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 17:55:00 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/30/2022 17:55:00 - INFO - __main__ - Starting training!
05/30/2022 17:56:20 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-24uptasks/singletask-emo/emo_16_100_0.2_8_predictions.txt
05/30/2022 17:56:20 - INFO - __main__ - Classification-F1 on test data: 0.4120
05/30/2022 17:56:21 - INFO - __main__ - prefix=emo_16_100, lr=0.2, bsz=8, dev_performance=0.7435398532172726, test_performance=0.412019271144392
05/30/2022 17:56:21 - INFO - __main__ - Running ... prefix=emo_16_13, lr=0.5, bsz=8 ...
05/30/2022 17:56:22 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 17:56:22 - INFO - __main__ - Printing 3 examples
05/30/2022 17:56:22 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
05/30/2022 17:56:22 - INFO - __main__ - ['others']
05/30/2022 17:56:22 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
05/30/2022 17:56:22 - INFO - __main__ - ['others']
05/30/2022 17:56:22 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
05/30/2022 17:56:22 - INFO - __main__ - ['others']
05/30/2022 17:56:22 - INFO - __main__ - Tokenizing Input ...
05/30/2022 17:56:22 - INFO - __main__ - Tokenizing Output ...
05/30/2022 17:56:22 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 17:56:22 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 17:56:22 - INFO - __main__ - Printing 3 examples
05/30/2022 17:56:22 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
05/30/2022 17:56:22 - INFO - __main__ - ['others']
05/30/2022 17:56:22 - INFO - __main__ -  [emo] i did ask now you did tell ms
05/30/2022 17:56:22 - INFO - __main__ - ['others']
05/30/2022 17:56:22 - INFO - __main__ -  [emo] buddy how you tell me your contact no
05/30/2022 17:56:22 - INFO - __main__ - ['others']
05/30/2022 17:56:22 - INFO - __main__ - Tokenizing Input ...
05/30/2022 17:56:22 - INFO - __main__ - Tokenizing Output ...
05/30/2022 17:56:22 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 17:56:41 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 17:56:41 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/30/2022 17:56:41 - INFO - __main__ - Starting training!
05/30/2022 17:56:44 - INFO - __main__ - Step 10 Global step 10 Train loss 3.65 on epoch=2
05/30/2022 17:56:47 - INFO - __main__ - Step 20 Global step 20 Train loss 1.56 on epoch=4
05/30/2022 17:56:49 - INFO - __main__ - Step 30 Global step 30 Train loss 1.03 on epoch=7
05/30/2022 17:56:52 - INFO - __main__ - Step 40 Global step 40 Train loss 0.92 on epoch=9
05/30/2022 17:56:54 - INFO - __main__ - Step 50 Global step 50 Train loss 0.79 on epoch=12
05/30/2022 17:56:55 - INFO - __main__ - Global step 50 Train loss 1.59 Classification-F1 0.44310406272273695 on epoch=12
05/30/2022 17:56:55 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.44310406272273695 on epoch=12, global_step=50
05/30/2022 17:56:58 - INFO - __main__ - Step 60 Global step 60 Train loss 0.75 on epoch=14
05/30/2022 17:57:00 - INFO - __main__ - Step 70 Global step 70 Train loss 0.78 on epoch=17
05/30/2022 17:57:03 - INFO - __main__ - Step 80 Global step 80 Train loss 0.72 on epoch=19
05/30/2022 17:57:05 - INFO - __main__ - Step 90 Global step 90 Train loss 0.64 on epoch=22
05/30/2022 17:57:08 - INFO - __main__ - Step 100 Global step 100 Train loss 0.54 on epoch=24
05/30/2022 17:57:09 - INFO - __main__ - Global step 100 Train loss 0.69 Classification-F1 0.6042572860409673 on epoch=24
05/30/2022 17:57:09 - INFO - __main__ - Saving model with best Classification-F1: 0.44310406272273695 -> 0.6042572860409673 on epoch=24, global_step=100
05/30/2022 17:57:11 - INFO - __main__ - Step 110 Global step 110 Train loss 0.51 on epoch=27
05/30/2022 17:57:14 - INFO - __main__ - Step 120 Global step 120 Train loss 0.68 on epoch=29
05/30/2022 17:57:16 - INFO - __main__ - Step 130 Global step 130 Train loss 0.56 on epoch=32
05/30/2022 17:57:19 - INFO - __main__ - Step 140 Global step 140 Train loss 0.48 on epoch=34
05/30/2022 17:57:21 - INFO - __main__ - Step 150 Global step 150 Train loss 0.49 on epoch=37
05/30/2022 17:57:22 - INFO - __main__ - Global step 150 Train loss 0.54 Classification-F1 0.6674835309617919 on epoch=37
05/30/2022 17:57:22 - INFO - __main__ - Saving model with best Classification-F1: 0.6042572860409673 -> 0.6674835309617919 on epoch=37, global_step=150
05/30/2022 17:57:25 - INFO - __main__ - Step 160 Global step 160 Train loss 0.48 on epoch=39
05/30/2022 17:57:27 - INFO - __main__ - Step 170 Global step 170 Train loss 0.45 on epoch=42
05/30/2022 17:57:30 - INFO - __main__ - Step 180 Global step 180 Train loss 0.43 on epoch=44
05/30/2022 17:57:32 - INFO - __main__ - Step 190 Global step 190 Train loss 0.49 on epoch=47
05/30/2022 17:57:35 - INFO - __main__ - Step 200 Global step 200 Train loss 0.42 on epoch=49
05/30/2022 17:57:35 - INFO - __main__ - Global step 200 Train loss 0.46 Classification-F1 0.69467228677755 on epoch=49
05/30/2022 17:57:35 - INFO - __main__ - Saving model with best Classification-F1: 0.6674835309617919 -> 0.69467228677755 on epoch=49, global_step=200
05/30/2022 17:57:38 - INFO - __main__ - Step 210 Global step 210 Train loss 0.33 on epoch=52
05/30/2022 17:57:41 - INFO - __main__ - Step 220 Global step 220 Train loss 0.37 on epoch=54
05/30/2022 17:57:43 - INFO - __main__ - Step 230 Global step 230 Train loss 0.41 on epoch=57
05/30/2022 17:57:46 - INFO - __main__ - Step 240 Global step 240 Train loss 0.30 on epoch=59
05/30/2022 17:57:48 - INFO - __main__ - Step 250 Global step 250 Train loss 0.29 on epoch=62
05/30/2022 17:57:49 - INFO - __main__ - Global step 250 Train loss 0.34 Classification-F1 0.7483106931382794 on epoch=62
05/30/2022 17:57:49 - INFO - __main__ - Saving model with best Classification-F1: 0.69467228677755 -> 0.7483106931382794 on epoch=62, global_step=250
05/30/2022 17:57:51 - INFO - __main__ - Step 260 Global step 260 Train loss 0.32 on epoch=64
05/30/2022 17:57:54 - INFO - __main__ - Step 270 Global step 270 Train loss 0.32 on epoch=67
05/30/2022 17:57:56 - INFO - __main__ - Step 280 Global step 280 Train loss 0.27 on epoch=69
05/30/2022 17:57:59 - INFO - __main__ - Step 290 Global step 290 Train loss 0.25 on epoch=72
05/30/2022 17:58:01 - INFO - __main__ - Step 300 Global step 300 Train loss 0.30 on epoch=74
05/30/2022 17:58:02 - INFO - __main__ - Global step 300 Train loss 0.29 Classification-F1 0.693840579710145 on epoch=74
05/30/2022 17:58:05 - INFO - __main__ - Step 310 Global step 310 Train loss 0.24 on epoch=77
05/30/2022 17:58:07 - INFO - __main__ - Step 320 Global step 320 Train loss 0.30 on epoch=79
05/30/2022 17:58:10 - INFO - __main__ - Step 330 Global step 330 Train loss 0.25 on epoch=82
05/30/2022 17:58:12 - INFO - __main__ - Step 340 Global step 340 Train loss 0.15 on epoch=84
05/30/2022 17:58:15 - INFO - __main__ - Step 350 Global step 350 Train loss 0.19 on epoch=87
05/30/2022 17:58:16 - INFO - __main__ - Global step 350 Train loss 0.23 Classification-F1 0.6522983870967742 on epoch=87
05/30/2022 17:58:18 - INFO - __main__ - Step 360 Global step 360 Train loss 0.08 on epoch=89
05/30/2022 17:58:21 - INFO - __main__ - Step 370 Global step 370 Train loss 0.14 on epoch=92
05/30/2022 17:58:23 - INFO - __main__ - Step 380 Global step 380 Train loss 0.12 on epoch=94
05/30/2022 17:58:26 - INFO - __main__ - Step 390 Global step 390 Train loss 0.14 on epoch=97
05/30/2022 17:58:28 - INFO - __main__ - Step 400 Global step 400 Train loss 0.12 on epoch=99
05/30/2022 17:58:29 - INFO - __main__ - Global step 400 Train loss 0.12 Classification-F1 0.5440775558166862 on epoch=99
05/30/2022 17:58:32 - INFO - __main__ - Step 410 Global step 410 Train loss 0.10 on epoch=102
05/30/2022 17:58:34 - INFO - __main__ - Step 420 Global step 420 Train loss 0.12 on epoch=104
05/30/2022 17:58:37 - INFO - __main__ - Step 430 Global step 430 Train loss 0.28 on epoch=107
05/30/2022 17:58:39 - INFO - __main__ - Step 440 Global step 440 Train loss 0.13 on epoch=109
05/30/2022 17:58:42 - INFO - __main__ - Step 450 Global step 450 Train loss 0.11 on epoch=112
05/30/2022 17:58:43 - INFO - __main__ - Global step 450 Train loss 0.15 Classification-F1 0.5171041748291324 on epoch=112
05/30/2022 17:58:45 - INFO - __main__ - Step 460 Global step 460 Train loss 0.13 on epoch=114
05/30/2022 17:58:48 - INFO - __main__ - Step 470 Global step 470 Train loss 0.23 on epoch=117
05/30/2022 17:58:50 - INFO - __main__ - Step 480 Global step 480 Train loss 0.14 on epoch=119
05/30/2022 17:58:53 - INFO - __main__ - Step 490 Global step 490 Train loss 0.13 on epoch=122
05/30/2022 17:58:55 - INFO - __main__ - Step 500 Global step 500 Train loss 0.05 on epoch=124
05/30/2022 17:58:56 - INFO - __main__ - Global step 500 Train loss 0.13 Classification-F1 0.7605418511490618 on epoch=124
05/30/2022 17:58:56 - INFO - __main__ - Saving model with best Classification-F1: 0.7483106931382794 -> 0.7605418511490618 on epoch=124, global_step=500
05/30/2022 17:58:58 - INFO - __main__ - Step 510 Global step 510 Train loss 0.05 on epoch=127
05/30/2022 17:59:01 - INFO - __main__ - Step 520 Global step 520 Train loss 0.04 on epoch=129
05/30/2022 17:59:03 - INFO - __main__ - Step 530 Global step 530 Train loss 0.04 on epoch=132
05/30/2022 17:59:06 - INFO - __main__ - Step 540 Global step 540 Train loss 0.14 on epoch=134
05/30/2022 17:59:09 - INFO - __main__ - Step 550 Global step 550 Train loss 0.06 on epoch=137
05/30/2022 17:59:09 - INFO - __main__ - Global step 550 Train loss 0.06 Classification-F1 0.7637976780357204 on epoch=137
05/30/2022 17:59:09 - INFO - __main__ - Saving model with best Classification-F1: 0.7605418511490618 -> 0.7637976780357204 on epoch=137, global_step=550
05/30/2022 17:59:12 - INFO - __main__ - Step 560 Global step 560 Train loss 0.07 on epoch=139
05/30/2022 17:59:14 - INFO - __main__ - Step 570 Global step 570 Train loss 0.11 on epoch=142
05/30/2022 17:59:17 - INFO - __main__ - Step 580 Global step 580 Train loss 0.10 on epoch=144
05/30/2022 17:59:19 - INFO - __main__ - Step 590 Global step 590 Train loss 0.05 on epoch=147
05/30/2022 17:59:22 - INFO - __main__ - Step 600 Global step 600 Train loss 0.05 on epoch=149
05/30/2022 17:59:23 - INFO - __main__ - Global step 600 Train loss 0.07 Classification-F1 0.5281572481572481 on epoch=149
05/30/2022 17:59:25 - INFO - __main__ - Step 610 Global step 610 Train loss 0.15 on epoch=152
05/30/2022 17:59:28 - INFO - __main__ - Step 620 Global step 620 Train loss 0.08 on epoch=154
05/30/2022 17:59:30 - INFO - __main__ - Step 630 Global step 630 Train loss 0.11 on epoch=157
05/30/2022 17:59:33 - INFO - __main__ - Step 640 Global step 640 Train loss 0.06 on epoch=159
05/30/2022 17:59:35 - INFO - __main__ - Step 650 Global step 650 Train loss 0.03 on epoch=162
05/30/2022 17:59:36 - INFO - __main__ - Global step 650 Train loss 0.08 Classification-F1 0.7496450681934553 on epoch=162
05/30/2022 17:59:39 - INFO - __main__ - Step 660 Global step 660 Train loss 0.02 on epoch=164
05/30/2022 17:59:41 - INFO - __main__ - Step 670 Global step 670 Train loss 0.04 on epoch=167
05/30/2022 17:59:44 - INFO - __main__ - Step 680 Global step 680 Train loss 0.02 on epoch=169
05/30/2022 17:59:46 - INFO - __main__ - Step 690 Global step 690 Train loss 0.06 on epoch=172
05/30/2022 17:59:49 - INFO - __main__ - Step 700 Global step 700 Train loss 0.02 on epoch=174
05/30/2022 17:59:50 - INFO - __main__ - Global step 700 Train loss 0.03 Classification-F1 0.7649380371154565 on epoch=174
05/30/2022 17:59:50 - INFO - __main__ - Saving model with best Classification-F1: 0.7637976780357204 -> 0.7649380371154565 on epoch=174, global_step=700
05/30/2022 17:59:52 - INFO - __main__ - Step 710 Global step 710 Train loss 0.02 on epoch=177
05/30/2022 17:59:55 - INFO - __main__ - Step 720 Global step 720 Train loss 0.02 on epoch=179
05/30/2022 17:59:57 - INFO - __main__ - Step 730 Global step 730 Train loss 0.03 on epoch=182
05/30/2022 18:00:00 - INFO - __main__ - Step 740 Global step 740 Train loss 0.02 on epoch=184
05/30/2022 18:00:02 - INFO - __main__ - Step 750 Global step 750 Train loss 0.11 on epoch=187
05/30/2022 18:00:03 - INFO - __main__ - Global step 750 Train loss 0.04 Classification-F1 0.6710482909379969 on epoch=187
05/30/2022 18:00:06 - INFO - __main__ - Step 760 Global step 760 Train loss 0.06 on epoch=189
05/30/2022 18:00:08 - INFO - __main__ - Step 770 Global step 770 Train loss 0.05 on epoch=192
05/30/2022 18:00:11 - INFO - __main__ - Step 780 Global step 780 Train loss 0.06 on epoch=194
05/30/2022 18:00:13 - INFO - __main__ - Step 790 Global step 790 Train loss 0.01 on epoch=197
05/30/2022 18:00:16 - INFO - __main__ - Step 800 Global step 800 Train loss 0.07 on epoch=199
05/30/2022 18:00:17 - INFO - __main__ - Global step 800 Train loss 0.05 Classification-F1 0.5894938495664448 on epoch=199
05/30/2022 18:00:19 - INFO - __main__ - Step 810 Global step 810 Train loss 0.02 on epoch=202
05/30/2022 18:00:22 - INFO - __main__ - Step 820 Global step 820 Train loss 0.04 on epoch=204
05/30/2022 18:00:24 - INFO - __main__ - Step 830 Global step 830 Train loss 0.04 on epoch=207
05/30/2022 18:00:27 - INFO - __main__ - Step 840 Global step 840 Train loss 0.04 on epoch=209
05/30/2022 18:00:29 - INFO - __main__ - Step 850 Global step 850 Train loss 0.09 on epoch=212
05/30/2022 18:00:30 - INFO - __main__ - Global step 850 Train loss 0.05 Classification-F1 0.5287340301974448 on epoch=212
05/30/2022 18:00:32 - INFO - __main__ - Step 860 Global step 860 Train loss 0.03 on epoch=214
05/30/2022 18:00:35 - INFO - __main__ - Step 870 Global step 870 Train loss 0.03 on epoch=217
05/30/2022 18:00:37 - INFO - __main__ - Step 880 Global step 880 Train loss 0.03 on epoch=219
05/30/2022 18:00:40 - INFO - __main__ - Step 890 Global step 890 Train loss 0.12 on epoch=222
05/30/2022 18:00:42 - INFO - __main__ - Step 900 Global step 900 Train loss 0.01 on epoch=224
05/30/2022 18:00:43 - INFO - __main__ - Global step 900 Train loss 0.05 Classification-F1 0.6978492096139155 on epoch=224
05/30/2022 18:00:46 - INFO - __main__ - Step 910 Global step 910 Train loss 0.01 on epoch=227
05/30/2022 18:00:48 - INFO - __main__ - Step 920 Global step 920 Train loss 0.01 on epoch=229
05/30/2022 18:00:51 - INFO - __main__ - Step 930 Global step 930 Train loss 0.00 on epoch=232
05/30/2022 18:00:53 - INFO - __main__ - Step 940 Global step 940 Train loss 0.01 on epoch=234
05/30/2022 18:00:56 - INFO - __main__ - Step 950 Global step 950 Train loss 0.06 on epoch=237
05/30/2022 18:00:57 - INFO - __main__ - Global step 950 Train loss 0.02 Classification-F1 0.5490810723408346 on epoch=237
05/30/2022 18:00:59 - INFO - __main__ - Step 960 Global step 960 Train loss 0.01 on epoch=239
05/30/2022 18:01:02 - INFO - __main__ - Step 970 Global step 970 Train loss 0.04 on epoch=242
05/30/2022 18:01:04 - INFO - __main__ - Step 980 Global step 980 Train loss 0.02 on epoch=244
05/30/2022 18:01:07 - INFO - __main__ - Step 990 Global step 990 Train loss 0.01 on epoch=247
05/30/2022 18:01:09 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.00 on epoch=249
05/30/2022 18:01:10 - INFO - __main__ - Global step 1000 Train loss 0.02 Classification-F1 0.5879634655567406 on epoch=249
05/30/2022 18:01:12 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.02 on epoch=252
05/30/2022 18:01:15 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.08 on epoch=254
05/30/2022 18:01:18 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.02 on epoch=257
05/30/2022 18:01:20 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.04 on epoch=259
05/30/2022 18:01:23 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.06 on epoch=262
05/30/2022 18:01:23 - INFO - __main__ - Global step 1050 Train loss 0.05 Classification-F1 0.7466824229691876 on epoch=262
05/30/2022 18:01:26 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.02 on epoch=264
05/30/2022 18:01:28 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.02 on epoch=267
05/30/2022 18:01:31 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.01 on epoch=269
05/30/2022 18:01:33 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.01 on epoch=272
05/30/2022 18:01:36 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.02 on epoch=274
05/30/2022 18:01:37 - INFO - __main__ - Global step 1100 Train loss 0.02 Classification-F1 0.5942852991240088 on epoch=274
05/30/2022 18:01:39 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.01 on epoch=277
05/30/2022 18:01:42 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.00 on epoch=279
05/30/2022 18:01:44 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.03 on epoch=282
05/30/2022 18:01:47 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.01 on epoch=284
05/30/2022 18:01:49 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=287
05/30/2022 18:01:50 - INFO - __main__ - Global step 1150 Train loss 0.01 Classification-F1 0.6405139214731531 on epoch=287
05/30/2022 18:01:53 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.05 on epoch=289
05/30/2022 18:01:55 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.01 on epoch=292
05/30/2022 18:01:58 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.01 on epoch=294
05/30/2022 18:02:00 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.01 on epoch=297
05/30/2022 18:02:03 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.05 on epoch=299
05/30/2022 18:02:04 - INFO - __main__ - Global step 1200 Train loss 0.02 Classification-F1 0.7312834224598931 on epoch=299
05/30/2022 18:02:06 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.02 on epoch=302
05/30/2022 18:02:09 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.00 on epoch=304
05/30/2022 18:02:11 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.02 on epoch=307
05/30/2022 18:02:13 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.03 on epoch=309
05/30/2022 18:02:16 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.01 on epoch=312
05/30/2022 18:02:17 - INFO - __main__ - Global step 1250 Train loss 0.01 Classification-F1 0.6991903927387798 on epoch=312
05/30/2022 18:02:20 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=314
05/30/2022 18:02:22 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.00 on epoch=317
05/30/2022 18:02:25 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=319
05/30/2022 18:02:27 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=322
05/30/2022 18:02:30 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=324
05/30/2022 18:02:31 - INFO - __main__ - Global step 1300 Train loss 0.01 Classification-F1 0.7227731092436975 on epoch=324
05/30/2022 18:02:33 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.00 on epoch=327
05/30/2022 18:02:36 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.15 on epoch=329
05/30/2022 18:02:38 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=332
05/30/2022 18:02:41 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=334
05/30/2022 18:02:43 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.00 on epoch=337
05/30/2022 18:02:44 - INFO - __main__ - Global step 1350 Train loss 0.04 Classification-F1 0.714957264957265 on epoch=337
05/30/2022 18:02:46 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.00 on epoch=339
05/30/2022 18:02:49 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=342
05/30/2022 18:02:51 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.02 on epoch=344
05/30/2022 18:02:54 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.00 on epoch=347
05/30/2022 18:02:56 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.00 on epoch=349
05/30/2022 18:02:57 - INFO - __main__ - Global step 1400 Train loss 0.01 Classification-F1 0.5687952694817684 on epoch=349
05/30/2022 18:03:00 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=352
05/30/2022 18:03:02 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.01 on epoch=354
05/30/2022 18:03:05 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=357
05/30/2022 18:03:07 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=359
05/30/2022 18:03:10 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.05 on epoch=362
05/30/2022 18:03:11 - INFO - __main__ - Global step 1450 Train loss 0.02 Classification-F1 0.6790210821170573 on epoch=362
05/30/2022 18:03:13 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=364
05/30/2022 18:03:16 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=367
05/30/2022 18:03:18 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=369
05/30/2022 18:03:21 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.04 on epoch=372
05/30/2022 18:03:23 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.03 on epoch=374
05/30/2022 18:03:24 - INFO - __main__ - Global step 1500 Train loss 0.02 Classification-F1 0.7258041147493479 on epoch=374
05/30/2022 18:03:26 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=377
05/30/2022 18:03:29 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.04 on epoch=379
05/30/2022 18:03:31 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=382
05/30/2022 18:03:34 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=384
05/30/2022 18:03:36 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.10 on epoch=387
05/30/2022 18:03:37 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.5951754010878118 on epoch=387
05/30/2022 18:03:40 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.04 on epoch=389
05/30/2022 18:03:42 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=392
05/30/2022 18:03:45 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=394
05/30/2022 18:03:47 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=397
05/30/2022 18:03:50 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=399
05/30/2022 18:03:51 - INFO - __main__ - Global step 1600 Train loss 0.01 Classification-F1 0.7283982683982684 on epoch=399
05/30/2022 18:03:53 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=402
05/30/2022 18:03:56 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=404
05/30/2022 18:03:58 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.02 on epoch=407
05/30/2022 18:04:01 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=409
05/30/2022 18:04:03 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=412
05/30/2022 18:04:04 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.7499080362195812 on epoch=412
05/30/2022 18:04:07 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.04 on epoch=414
05/30/2022 18:04:09 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=417
05/30/2022 18:04:12 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=419
05/30/2022 18:04:14 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=422
05/30/2022 18:04:17 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=424
05/30/2022 18:04:18 - INFO - __main__ - Global step 1700 Train loss 0.01 Classification-F1 0.5780885780885782 on epoch=424
05/30/2022 18:04:20 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=427
05/30/2022 18:04:23 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=429
05/30/2022 18:04:25 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=432
05/30/2022 18:04:28 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=434
05/30/2022 18:04:30 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=437
05/30/2022 18:04:31 - INFO - __main__ - Global step 1750 Train loss 0.01 Classification-F1 0.7168677148278666 on epoch=437
05/30/2022 18:04:34 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.05 on epoch=439
05/30/2022 18:04:36 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.05 on epoch=442
05/30/2022 18:04:39 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=444
05/30/2022 18:04:41 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=447
05/30/2022 18:04:44 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=449
05/30/2022 18:04:45 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.703125 on epoch=449
05/30/2022 18:04:47 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=452
05/30/2022 18:04:50 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=454
05/30/2022 18:04:52 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.17 on epoch=457
05/30/2022 18:04:55 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=459
05/30/2022 18:04:57 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=462
05/30/2022 18:04:58 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.7591156597774245 on epoch=462
05/30/2022 18:05:01 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=464
05/30/2022 18:05:03 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=467
05/30/2022 18:05:06 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=469
05/30/2022 18:05:08 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=472
05/30/2022 18:05:11 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=474
05/30/2022 18:05:12 - INFO - __main__ - Global step 1900 Train loss 0.00 Classification-F1 0.7739615583075335 on epoch=474
05/30/2022 18:05:12 - INFO - __main__ - Saving model with best Classification-F1: 0.7649380371154565 -> 0.7739615583075335 on epoch=474, global_step=1900
05/30/2022 18:05:14 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=477
05/30/2022 18:05:17 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=479
05/30/2022 18:05:19 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=482
05/30/2022 18:05:22 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=484
05/30/2022 18:05:24 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=487
05/30/2022 18:05:25 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.7238618082368082 on epoch=487
05/30/2022 18:05:28 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=489
05/30/2022 18:05:30 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=492
05/30/2022 18:05:33 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=494
05/30/2022 18:05:35 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=497
05/30/2022 18:05:38 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=499
05/30/2022 18:05:39 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.7336351973899928 on epoch=499
05/30/2022 18:05:41 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=502
05/30/2022 18:05:44 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=504
05/30/2022 18:05:46 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
05/30/2022 18:05:49 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=509
05/30/2022 18:05:51 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
05/30/2022 18:05:53 - INFO - __main__ - Global step 2050 Train loss 0.00 Classification-F1 0.7403893457024388 on epoch=512
05/30/2022 18:05:55 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=514
05/30/2022 18:05:58 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=517
05/30/2022 18:06:00 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
05/30/2022 18:06:03 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
05/30/2022 18:06:05 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
05/30/2022 18:06:06 - INFO - __main__ - Global step 2100 Train loss 0.00 Classification-F1 0.6315524583817267 on epoch=524
05/30/2022 18:06:09 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
05/30/2022 18:06:11 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
05/30/2022 18:06:14 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
05/30/2022 18:06:16 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
05/30/2022 18:06:19 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=537
05/30/2022 18:06:20 - INFO - __main__ - Global step 2150 Train loss 0.00 Classification-F1 0.7485055934599545 on epoch=537
05/30/2022 18:06:22 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
05/30/2022 18:06:25 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=542
05/30/2022 18:06:27 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
05/30/2022 18:06:30 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
05/30/2022 18:06:32 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
05/30/2022 18:06:33 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.6807623271037905 on epoch=549
05/30/2022 18:06:36 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
05/30/2022 18:06:38 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=554
05/30/2022 18:06:41 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
05/30/2022 18:06:43 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
05/30/2022 18:06:46 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
05/30/2022 18:06:47 - INFO - __main__ - Global step 2250 Train loss 0.00 Classification-F1 0.696275918904147 on epoch=562
05/30/2022 18:06:49 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
05/30/2022 18:06:52 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=567
05/30/2022 18:06:54 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
05/30/2022 18:06:57 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=572
05/30/2022 18:06:59 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
05/30/2022 18:07:00 - INFO - __main__ - Global step 2300 Train loss 0.00 Classification-F1 0.740550397877984 on epoch=574
05/30/2022 18:07:03 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
05/30/2022 18:07:05 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
05/30/2022 18:07:08 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
05/30/2022 18:07:10 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.05 on epoch=584
05/30/2022 18:07:13 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
05/30/2022 18:07:14 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.6982517482517483 on epoch=587
05/30/2022 18:07:16 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.12 on epoch=589
05/30/2022 18:07:19 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.08 on epoch=592
05/30/2022 18:07:21 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
05/30/2022 18:07:24 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
05/30/2022 18:07:26 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=599
05/30/2022 18:07:27 - INFO - __main__ - Global step 2400 Train loss 0.04 Classification-F1 0.6964704650188522 on epoch=599
05/30/2022 18:07:30 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
05/30/2022 18:07:32 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
05/30/2022 18:07:35 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=607
05/30/2022 18:07:37 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=609
05/30/2022 18:07:40 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=612
05/30/2022 18:07:41 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.6884523809523809 on epoch=612
05/30/2022 18:07:43 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
05/30/2022 18:07:46 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
05/30/2022 18:07:48 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=619
05/30/2022 18:07:51 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
05/30/2022 18:07:53 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
05/30/2022 18:07:54 - INFO - __main__ - Global step 2500 Train loss 0.00 Classification-F1 0.6533087283087283 on epoch=624
05/30/2022 18:07:57 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
05/30/2022 18:07:59 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.05 on epoch=629
05/30/2022 18:08:02 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
05/30/2022 18:08:04 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
05/30/2022 18:08:07 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=637
05/30/2022 18:08:08 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.7106814753873578 on epoch=637
05/30/2022 18:08:10 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
05/30/2022 18:08:13 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
05/30/2022 18:08:15 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
05/30/2022 18:08:18 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=647
05/30/2022 18:08:20 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=649
05/30/2022 18:08:21 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.5729890488511178 on epoch=649
05/30/2022 18:08:24 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
05/30/2022 18:08:26 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.04 on epoch=654
05/30/2022 18:08:29 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
05/30/2022 18:08:31 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=659
05/30/2022 18:08:34 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.04 on epoch=662
05/30/2022 18:08:35 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.7586406034681896 on epoch=662
05/30/2022 18:08:37 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=664
05/30/2022 18:08:40 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
05/30/2022 18:08:42 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
05/30/2022 18:08:45 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
05/30/2022 18:08:47 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
05/30/2022 18:08:48 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.5565089982481286 on epoch=674
05/30/2022 18:08:51 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=677
05/30/2022 18:08:53 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=679
05/30/2022 18:08:56 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
05/30/2022 18:08:58 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=684
05/30/2022 18:09:01 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=687
05/30/2022 18:09:02 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.7667038275733928 on epoch=687
05/30/2022 18:09:04 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
05/30/2022 18:09:07 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
05/30/2022 18:09:09 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
05/30/2022 18:09:12 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=697
05/30/2022 18:09:14 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
05/30/2022 18:09:15 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.6826135460602727 on epoch=699
05/30/2022 18:09:18 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
05/30/2022 18:09:20 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
05/30/2022 18:09:23 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
05/30/2022 18:09:25 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
05/30/2022 18:09:28 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
05/30/2022 18:09:29 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.7553936100131753 on epoch=712
05/30/2022 18:09:31 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
05/30/2022 18:09:34 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
05/30/2022 18:09:36 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
05/30/2022 18:09:39 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=722
05/30/2022 18:09:41 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
05/30/2022 18:09:42 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.6950358669108669 on epoch=724
05/30/2022 18:09:45 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=727
05/30/2022 18:09:47 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.04 on epoch=729
05/30/2022 18:09:49 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
05/30/2022 18:09:52 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=734
05/30/2022 18:09:54 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=737
05/30/2022 18:09:55 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.5695238095238095 on epoch=737
05/30/2022 18:09:58 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
05/30/2022 18:10:00 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
05/30/2022 18:10:02 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
05/30/2022 18:10:05 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=747
05/30/2022 18:10:07 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
05/30/2022 18:10:08 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.550509705348415 on epoch=749
05/30/2022 18:10:08 - INFO - __main__ - save last model!
05/30/2022 18:10:08 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/30/2022 18:10:08 - INFO - __main__ - Start tokenizing ... 5509 instances
05/30/2022 18:10:08 - INFO - __main__ - Printing 3 examples
05/30/2022 18:10:08 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/30/2022 18:10:08 - INFO - __main__ - ['others']
05/30/2022 18:10:08 - INFO - __main__ -  [emo] what you like very little things ok
05/30/2022 18:10:08 - INFO - __main__ - ['others']
05/30/2022 18:10:08 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/30/2022 18:10:08 - INFO - __main__ - ['others']
05/30/2022 18:10:08 - INFO - __main__ - Tokenizing Input ...
05/30/2022 18:10:09 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 18:10:09 - INFO - __main__ - Printing 3 examples
05/30/2022 18:10:09 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
05/30/2022 18:10:09 - INFO - __main__ - ['others']
05/30/2022 18:10:09 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
05/30/2022 18:10:09 - INFO - __main__ - ['others']
05/30/2022 18:10:09 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
05/30/2022 18:10:09 - INFO - __main__ - ['others']
05/30/2022 18:10:09 - INFO - __main__ - Tokenizing Input ...
05/30/2022 18:10:09 - INFO - __main__ - Tokenizing Output ...
05/30/2022 18:10:09 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 18:10:09 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 18:10:09 - INFO - __main__ - Printing 3 examples
05/30/2022 18:10:09 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
05/30/2022 18:10:09 - INFO - __main__ - ['others']
05/30/2022 18:10:09 - INFO - __main__ -  [emo] i did ask now you did tell ms
05/30/2022 18:10:09 - INFO - __main__ - ['others']
05/30/2022 18:10:09 - INFO - __main__ -  [emo] buddy how you tell me your contact no
05/30/2022 18:10:09 - INFO - __main__ - ['others']
05/30/2022 18:10:09 - INFO - __main__ - Tokenizing Input ...
05/30/2022 18:10:09 - INFO - __main__ - Tokenizing Output ...
05/30/2022 18:10:09 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 18:10:11 - INFO - __main__ - Tokenizing Output ...
05/30/2022 18:10:16 - INFO - __main__ - Loaded 5509 examples from test data
05/30/2022 18:10:27 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 18:10:28 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/30/2022 18:10:28 - INFO - __main__ - Starting training!
05/30/2022 18:11:50 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-24uptasks/singletask-emo/emo_16_13_0.5_8_predictions.txt
05/30/2022 18:11:50 - INFO - __main__ - Classification-F1 on test data: 0.1388
05/30/2022 18:11:50 - INFO - __main__ - prefix=emo_16_13, lr=0.5, bsz=8, dev_performance=0.7739615583075335, test_performance=0.13881425628773567
05/30/2022 18:11:50 - INFO - __main__ - Running ... prefix=emo_16_13, lr=0.4, bsz=8 ...
05/30/2022 18:11:51 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 18:11:51 - INFO - __main__ - Printing 3 examples
05/30/2022 18:11:51 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
05/30/2022 18:11:51 - INFO - __main__ - ['others']
05/30/2022 18:11:51 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
05/30/2022 18:11:51 - INFO - __main__ - ['others']
05/30/2022 18:11:51 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
05/30/2022 18:11:51 - INFO - __main__ - ['others']
05/30/2022 18:11:51 - INFO - __main__ - Tokenizing Input ...
05/30/2022 18:11:51 - INFO - __main__ - Tokenizing Output ...
05/30/2022 18:11:51 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 18:11:51 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 18:11:51 - INFO - __main__ - Printing 3 examples
05/30/2022 18:11:51 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
05/30/2022 18:11:51 - INFO - __main__ - ['others']
05/30/2022 18:11:51 - INFO - __main__ -  [emo] i did ask now you did tell ms
05/30/2022 18:11:51 - INFO - __main__ - ['others']
05/30/2022 18:11:51 - INFO - __main__ -  [emo] buddy how you tell me your contact no
05/30/2022 18:11:51 - INFO - __main__ - ['others']
05/30/2022 18:11:51 - INFO - __main__ - Tokenizing Input ...
05/30/2022 18:11:51 - INFO - __main__ - Tokenizing Output ...
05/30/2022 18:11:51 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 18:12:07 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 18:12:08 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/30/2022 18:12:08 - INFO - __main__ - Starting training!
05/30/2022 18:12:11 - INFO - __main__ - Step 10 Global step 10 Train loss 3.72 on epoch=2
05/30/2022 18:12:14 - INFO - __main__ - Step 20 Global step 20 Train loss 1.79 on epoch=4
05/30/2022 18:12:16 - INFO - __main__ - Step 30 Global step 30 Train loss 1.35 on epoch=7
05/30/2022 18:12:19 - INFO - __main__ - Step 40 Global step 40 Train loss 0.97 on epoch=9
05/30/2022 18:12:21 - INFO - __main__ - Step 50 Global step 50 Train loss 0.93 on epoch=12
05/30/2022 18:12:22 - INFO - __main__ - Global step 50 Train loss 1.75 Classification-F1 0.24757033248081842 on epoch=12
05/30/2022 18:12:22 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.24757033248081842 on epoch=12, global_step=50
05/30/2022 18:12:25 - INFO - __main__ - Step 60 Global step 60 Train loss 0.87 on epoch=14
05/30/2022 18:12:27 - INFO - __main__ - Step 70 Global step 70 Train loss 0.83 on epoch=17
05/30/2022 18:12:30 - INFO - __main__ - Step 80 Global step 80 Train loss 0.75 on epoch=19
05/30/2022 18:12:32 - INFO - __main__ - Step 90 Global step 90 Train loss 0.66 on epoch=22
05/30/2022 18:12:35 - INFO - __main__ - Step 100 Global step 100 Train loss 0.72 on epoch=24
05/30/2022 18:12:36 - INFO - __main__ - Global step 100 Train loss 0.76 Classification-F1 0.4405122655122655 on epoch=24
05/30/2022 18:12:36 - INFO - __main__ - Saving model with best Classification-F1: 0.24757033248081842 -> 0.4405122655122655 on epoch=24, global_step=100
05/30/2022 18:12:38 - INFO - __main__ - Step 110 Global step 110 Train loss 0.68 on epoch=27
05/30/2022 18:12:41 - INFO - __main__ - Step 120 Global step 120 Train loss 0.67 on epoch=29
05/30/2022 18:12:43 - INFO - __main__ - Step 130 Global step 130 Train loss 0.59 on epoch=32
05/30/2022 18:12:46 - INFO - __main__ - Step 140 Global step 140 Train loss 0.64 on epoch=34
05/30/2022 18:12:48 - INFO - __main__ - Step 150 Global step 150 Train loss 0.55 on epoch=37
05/30/2022 18:12:49 - INFO - __main__ - Global step 150 Train loss 0.63 Classification-F1 0.5946196660482375 on epoch=37
05/30/2022 18:12:49 - INFO - __main__ - Saving model with best Classification-F1: 0.4405122655122655 -> 0.5946196660482375 on epoch=37, global_step=150
05/30/2022 18:12:51 - INFO - __main__ - Step 160 Global step 160 Train loss 0.61 on epoch=39
05/30/2022 18:12:54 - INFO - __main__ - Step 170 Global step 170 Train loss 0.55 on epoch=42
05/30/2022 18:12:56 - INFO - __main__ - Step 180 Global step 180 Train loss 0.51 on epoch=44
05/30/2022 18:12:59 - INFO - __main__ - Step 190 Global step 190 Train loss 0.53 on epoch=47
05/30/2022 18:13:01 - INFO - __main__ - Step 200 Global step 200 Train loss 0.48 on epoch=49
05/30/2022 18:13:02 - INFO - __main__ - Global step 200 Train loss 0.54 Classification-F1 0.651217427558891 on epoch=49
05/30/2022 18:13:02 - INFO - __main__ - Saving model with best Classification-F1: 0.5946196660482375 -> 0.651217427558891 on epoch=49, global_step=200
05/30/2022 18:13:05 - INFO - __main__ - Step 210 Global step 210 Train loss 0.41 on epoch=52
05/30/2022 18:13:07 - INFO - __main__ - Step 220 Global step 220 Train loss 0.38 on epoch=54
05/30/2022 18:13:10 - INFO - __main__ - Step 230 Global step 230 Train loss 0.47 on epoch=57
05/30/2022 18:13:12 - INFO - __main__ - Step 240 Global step 240 Train loss 0.40 on epoch=59
05/30/2022 18:13:15 - INFO - __main__ - Step 250 Global step 250 Train loss 0.39 on epoch=62
05/30/2022 18:13:16 - INFO - __main__ - Global step 250 Train loss 0.41 Classification-F1 0.8132616487455198 on epoch=62
05/30/2022 18:13:16 - INFO - __main__ - Saving model with best Classification-F1: 0.651217427558891 -> 0.8132616487455198 on epoch=62, global_step=250
05/30/2022 18:13:18 - INFO - __main__ - Step 260 Global step 260 Train loss 0.33 on epoch=64
05/30/2022 18:13:21 - INFO - __main__ - Step 270 Global step 270 Train loss 0.34 on epoch=67
05/30/2022 18:13:23 - INFO - __main__ - Step 280 Global step 280 Train loss 0.40 on epoch=69
05/30/2022 18:13:26 - INFO - __main__ - Step 290 Global step 290 Train loss 0.49 on epoch=72
05/30/2022 18:13:28 - INFO - __main__ - Step 300 Global step 300 Train loss 0.41 on epoch=74
05/30/2022 18:13:29 - INFO - __main__ - Global step 300 Train loss 0.39 Classification-F1 0.6399663955397716 on epoch=74
05/30/2022 18:13:32 - INFO - __main__ - Step 310 Global step 310 Train loss 0.30 on epoch=77
05/30/2022 18:13:34 - INFO - __main__ - Step 320 Global step 320 Train loss 0.25 on epoch=79
05/30/2022 18:13:37 - INFO - __main__ - Step 330 Global step 330 Train loss 0.29 on epoch=82
05/30/2022 18:13:39 - INFO - __main__ - Step 340 Global step 340 Train loss 0.22 on epoch=84
05/30/2022 18:13:42 - INFO - __main__ - Step 350 Global step 350 Train loss 0.27 on epoch=87
05/30/2022 18:13:42 - INFO - __main__ - Global step 350 Train loss 0.26 Classification-F1 0.7334664786967419 on epoch=87
05/30/2022 18:13:45 - INFO - __main__ - Step 360 Global step 360 Train loss 0.17 on epoch=89
05/30/2022 18:13:47 - INFO - __main__ - Step 370 Global step 370 Train loss 0.25 on epoch=92
05/30/2022 18:13:50 - INFO - __main__ - Step 380 Global step 380 Train loss 0.25 on epoch=94
05/30/2022 18:13:53 - INFO - __main__ - Step 390 Global step 390 Train loss 0.27 on epoch=97
05/30/2022 18:13:55 - INFO - __main__ - Step 400 Global step 400 Train loss 0.23 on epoch=99
05/30/2022 18:13:56 - INFO - __main__ - Global step 400 Train loss 0.24 Classification-F1 0.7486997564861858 on epoch=99
05/30/2022 18:13:58 - INFO - __main__ - Step 410 Global step 410 Train loss 0.19 on epoch=102
05/30/2022 18:14:01 - INFO - __main__ - Step 420 Global step 420 Train loss 0.17 on epoch=104
05/30/2022 18:14:04 - INFO - __main__ - Step 430 Global step 430 Train loss 0.22 on epoch=107
05/30/2022 18:14:06 - INFO - __main__ - Step 440 Global step 440 Train loss 0.17 on epoch=109
05/30/2022 18:14:09 - INFO - __main__ - Step 450 Global step 450 Train loss 0.22 on epoch=112
05/30/2022 18:14:09 - INFO - __main__ - Global step 450 Train loss 0.19 Classification-F1 0.8120098039215686 on epoch=112
05/30/2022 18:14:12 - INFO - __main__ - Step 460 Global step 460 Train loss 0.24 on epoch=114
05/30/2022 18:14:15 - INFO - __main__ - Step 470 Global step 470 Train loss 0.13 on epoch=117
05/30/2022 18:14:17 - INFO - __main__ - Step 480 Global step 480 Train loss 0.17 on epoch=119
05/30/2022 18:14:19 - INFO - __main__ - Step 490 Global step 490 Train loss 0.08 on epoch=122
05/30/2022 18:14:22 - INFO - __main__ - Step 500 Global step 500 Train loss 0.17 on epoch=124
05/30/2022 18:14:23 - INFO - __main__ - Global step 500 Train loss 0.16 Classification-F1 0.5851078846541642 on epoch=124
05/30/2022 18:14:25 - INFO - __main__ - Step 510 Global step 510 Train loss 0.13 on epoch=127
05/30/2022 18:14:28 - INFO - __main__ - Step 520 Global step 520 Train loss 0.13 on epoch=129
05/30/2022 18:14:30 - INFO - __main__ - Step 530 Global step 530 Train loss 0.17 on epoch=132
05/30/2022 18:14:33 - INFO - __main__ - Step 540 Global step 540 Train loss 0.17 on epoch=134
05/30/2022 18:14:35 - INFO - __main__ - Step 550 Global step 550 Train loss 0.09 on epoch=137
05/30/2022 18:14:36 - INFO - __main__ - Global step 550 Train loss 0.14 Classification-F1 0.6160461760461761 on epoch=137
05/30/2022 18:14:39 - INFO - __main__ - Step 560 Global step 560 Train loss 0.12 on epoch=139
05/30/2022 18:14:41 - INFO - __main__ - Step 570 Global step 570 Train loss 0.18 on epoch=142
05/30/2022 18:14:44 - INFO - __main__ - Step 580 Global step 580 Train loss 0.13 on epoch=144
05/30/2022 18:14:46 - INFO - __main__ - Step 590 Global step 590 Train loss 0.07 on epoch=147
05/30/2022 18:14:49 - INFO - __main__ - Step 600 Global step 600 Train loss 0.10 on epoch=149
05/30/2022 18:14:50 - INFO - __main__ - Global step 600 Train loss 0.12 Classification-F1 0.5660558515309408 on epoch=149
05/30/2022 18:14:52 - INFO - __main__ - Step 610 Global step 610 Train loss 0.08 on epoch=152
05/30/2022 18:14:55 - INFO - __main__ - Step 620 Global step 620 Train loss 0.06 on epoch=154
05/30/2022 18:14:57 - INFO - __main__ - Step 630 Global step 630 Train loss 0.10 on epoch=157
05/30/2022 18:15:00 - INFO - __main__ - Step 640 Global step 640 Train loss 0.09 on epoch=159
05/30/2022 18:15:02 - INFO - __main__ - Step 650 Global step 650 Train loss 0.08 on epoch=162
05/30/2022 18:15:03 - INFO - __main__ - Global step 650 Train loss 0.08 Classification-F1 0.5921374099349628 on epoch=162
05/30/2022 18:15:06 - INFO - __main__ - Step 660 Global step 660 Train loss 0.06 on epoch=164
05/30/2022 18:15:08 - INFO - __main__ - Step 670 Global step 670 Train loss 0.11 on epoch=167
05/30/2022 18:15:11 - INFO - __main__ - Step 680 Global step 680 Train loss 0.05 on epoch=169
05/30/2022 18:15:13 - INFO - __main__ - Step 690 Global step 690 Train loss 0.11 on epoch=172
05/30/2022 18:15:16 - INFO - __main__ - Step 700 Global step 700 Train loss 0.09 on epoch=174
05/30/2022 18:15:16 - INFO - __main__ - Global step 700 Train loss 0.08 Classification-F1 0.5797043010752688 on epoch=174
05/30/2022 18:15:19 - INFO - __main__ - Step 710 Global step 710 Train loss 0.09 on epoch=177
05/30/2022 18:15:21 - INFO - __main__ - Step 720 Global step 720 Train loss 0.03 on epoch=179
05/30/2022 18:15:24 - INFO - __main__ - Step 730 Global step 730 Train loss 0.05 on epoch=182
05/30/2022 18:15:26 - INFO - __main__ - Step 740 Global step 740 Train loss 0.03 on epoch=184
05/30/2022 18:15:29 - INFO - __main__ - Step 750 Global step 750 Train loss 0.05 on epoch=187
05/30/2022 18:15:30 - INFO - __main__ - Global step 750 Train loss 0.05 Classification-F1 0.5769458128078818 on epoch=187
05/30/2022 18:15:32 - INFO - __main__ - Step 760 Global step 760 Train loss 0.08 on epoch=189
05/30/2022 18:15:35 - INFO - __main__ - Step 770 Global step 770 Train loss 0.05 on epoch=192
05/30/2022 18:15:37 - INFO - __main__ - Step 780 Global step 780 Train loss 0.02 on epoch=194
05/30/2022 18:15:40 - INFO - __main__ - Step 790 Global step 790 Train loss 0.08 on epoch=197
05/30/2022 18:15:42 - INFO - __main__ - Step 800 Global step 800 Train loss 0.07 on epoch=199
05/30/2022 18:15:43 - INFO - __main__ - Global step 800 Train loss 0.06 Classification-F1 0.6012984412984412 on epoch=199
05/30/2022 18:15:46 - INFO - __main__ - Step 810 Global step 810 Train loss 0.05 on epoch=202
05/30/2022 18:15:48 - INFO - __main__ - Step 820 Global step 820 Train loss 0.09 on epoch=204
05/30/2022 18:15:51 - INFO - __main__ - Step 830 Global step 830 Train loss 0.07 on epoch=207
05/30/2022 18:15:53 - INFO - __main__ - Step 840 Global step 840 Train loss 0.13 on epoch=209
05/30/2022 18:15:56 - INFO - __main__ - Step 850 Global step 850 Train loss 0.06 on epoch=212
05/30/2022 18:15:57 - INFO - __main__ - Global step 850 Train loss 0.08 Classification-F1 0.5877356790669485 on epoch=212
05/30/2022 18:15:59 - INFO - __main__ - Step 860 Global step 860 Train loss 0.03 on epoch=214
05/30/2022 18:16:02 - INFO - __main__ - Step 870 Global step 870 Train loss 0.03 on epoch=217
05/30/2022 18:16:04 - INFO - __main__ - Step 880 Global step 880 Train loss 0.07 on epoch=219
05/30/2022 18:16:07 - INFO - __main__ - Step 890 Global step 890 Train loss 0.13 on epoch=222
05/30/2022 18:16:09 - INFO - __main__ - Step 900 Global step 900 Train loss 0.09 on epoch=224
05/30/2022 18:16:10 - INFO - __main__ - Global step 900 Train loss 0.07 Classification-F1 0.745137579129252 on epoch=224
05/30/2022 18:16:12 - INFO - __main__ - Step 910 Global step 910 Train loss 0.04 on epoch=227
05/30/2022 18:16:15 - INFO - __main__ - Step 920 Global step 920 Train loss 0.04 on epoch=229
05/30/2022 18:16:17 - INFO - __main__ - Step 930 Global step 930 Train loss 0.04 on epoch=232
05/30/2022 18:16:20 - INFO - __main__ - Step 940 Global step 940 Train loss 0.04 on epoch=234
05/30/2022 18:16:23 - INFO - __main__ - Step 950 Global step 950 Train loss 0.03 on epoch=237
05/30/2022 18:16:23 - INFO - __main__ - Global step 950 Train loss 0.04 Classification-F1 0.5884802043422732 on epoch=237
05/30/2022 18:16:26 - INFO - __main__ - Step 960 Global step 960 Train loss 0.02 on epoch=239
05/30/2022 18:16:28 - INFO - __main__ - Step 970 Global step 970 Train loss 0.07 on epoch=242
05/30/2022 18:16:31 - INFO - __main__ - Step 980 Global step 980 Train loss 0.03 on epoch=244
05/30/2022 18:16:34 - INFO - __main__ - Step 990 Global step 990 Train loss 0.02 on epoch=247
05/30/2022 18:16:36 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.03 on epoch=249
05/30/2022 18:16:37 - INFO - __main__ - Global step 1000 Train loss 0.03 Classification-F1 0.5541717541717542 on epoch=249
05/30/2022 18:16:39 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.03 on epoch=252
05/30/2022 18:16:42 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.07 on epoch=254
05/30/2022 18:16:44 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.02 on epoch=257
05/30/2022 18:16:47 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.01 on epoch=259
05/30/2022 18:16:50 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.01 on epoch=262
05/30/2022 18:16:51 - INFO - __main__ - Global step 1050 Train loss 0.03 Classification-F1 0.6068897903989183 on epoch=262
05/30/2022 18:16:53 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.02 on epoch=264
05/30/2022 18:16:56 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.05 on epoch=267
05/30/2022 18:16:58 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.02 on epoch=269
05/30/2022 18:17:01 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.01 on epoch=272
05/30/2022 18:17:03 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.05 on epoch=274
05/30/2022 18:17:04 - INFO - __main__ - Global step 1100 Train loss 0.03 Classification-F1 0.5735505412924768 on epoch=274
05/30/2022 18:17:07 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.03 on epoch=277
05/30/2022 18:17:09 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.04 on epoch=279
05/30/2022 18:17:12 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.07 on epoch=282
05/30/2022 18:17:14 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.01 on epoch=284
05/30/2022 18:17:17 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=287
05/30/2022 18:17:18 - INFO - __main__ - Global step 1150 Train loss 0.03 Classification-F1 0.6103333333333334 on epoch=287
05/30/2022 18:17:20 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.03 on epoch=289
05/30/2022 18:17:23 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.02 on epoch=292
05/30/2022 18:17:25 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.04 on epoch=294
05/30/2022 18:17:28 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.05 on epoch=297
05/30/2022 18:17:31 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.07 on epoch=299
05/30/2022 18:17:32 - INFO - __main__ - Global step 1200 Train loss 0.04 Classification-F1 0.6080598151426438 on epoch=299
05/30/2022 18:17:34 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.01 on epoch=302
05/30/2022 18:17:37 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=304
05/30/2022 18:17:39 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.02 on epoch=307
05/30/2022 18:17:42 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.02 on epoch=309
05/30/2022 18:17:44 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.02 on epoch=312
05/30/2022 18:17:45 - INFO - __main__ - Global step 1250 Train loss 0.02 Classification-F1 0.5733130371751061 on epoch=312
05/30/2022 18:17:48 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.02 on epoch=314
05/30/2022 18:17:50 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.03 on epoch=317
05/30/2022 18:17:53 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.10 on epoch=319
05/30/2022 18:17:55 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=322
05/30/2022 18:17:58 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.05 on epoch=324
05/30/2022 18:17:59 - INFO - __main__ - Global step 1300 Train loss 0.04 Classification-F1 0.5847181996737575 on epoch=324
05/30/2022 18:18:01 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.03 on epoch=327
05/30/2022 18:18:04 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=329
05/30/2022 18:18:06 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=332
05/30/2022 18:18:09 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.03 on epoch=334
05/30/2022 18:18:12 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=337
05/30/2022 18:18:13 - INFO - __main__ - Global step 1350 Train loss 0.02 Classification-F1 0.5501098901098902 on epoch=337
05/30/2022 18:18:15 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.02 on epoch=339
05/30/2022 18:18:18 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=342
05/30/2022 18:18:20 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.02 on epoch=344
05/30/2022 18:18:23 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.02 on epoch=347
05/30/2022 18:18:25 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=349
05/30/2022 18:18:27 - INFO - __main__ - Global step 1400 Train loss 0.01 Classification-F1 0.6117991691881636 on epoch=349
05/30/2022 18:18:29 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.07 on epoch=352
05/30/2022 18:18:32 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.07 on epoch=354
05/30/2022 18:18:34 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.02 on epoch=357
05/30/2022 18:18:37 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=359
05/30/2022 18:18:39 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=362
05/30/2022 18:18:40 - INFO - __main__ - Global step 1450 Train loss 0.04 Classification-F1 0.6134756471598577 on epoch=362
05/30/2022 18:18:43 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=364
05/30/2022 18:18:45 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=367
05/30/2022 18:18:48 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=369
05/30/2022 18:18:50 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.02 on epoch=372
05/30/2022 18:18:53 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=374
05/30/2022 18:18:54 - INFO - __main__ - Global step 1500 Train loss 0.01 Classification-F1 0.5985749792201405 on epoch=374
05/30/2022 18:18:56 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=377
05/30/2022 18:18:59 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=379
05/30/2022 18:19:01 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=382
05/30/2022 18:19:04 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=384
05/30/2022 18:19:06 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=387
05/30/2022 18:19:07 - INFO - __main__ - Global step 1550 Train loss 0.01 Classification-F1 0.6458085392868002 on epoch=387
05/30/2022 18:19:10 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.07 on epoch=389
05/30/2022 18:19:12 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=392
05/30/2022 18:19:15 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=394
05/30/2022 18:19:18 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.04 on epoch=397
05/30/2022 18:19:20 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=399
05/30/2022 18:19:21 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.5602201296318943 on epoch=399
05/30/2022 18:19:24 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=402
05/30/2022 18:19:26 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=404
05/30/2022 18:19:29 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=407
05/30/2022 18:19:31 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=409
05/30/2022 18:19:34 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=412
05/30/2022 18:19:35 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.5685848398702498 on epoch=412
05/30/2022 18:19:37 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=414
05/30/2022 18:19:40 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=417
05/30/2022 18:19:42 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.03 on epoch=419
05/30/2022 18:19:45 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=422
05/30/2022 18:19:47 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=424
05/30/2022 18:19:49 - INFO - __main__ - Global step 1700 Train loss 0.01 Classification-F1 0.5725771003190357 on epoch=424
05/30/2022 18:19:51 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=427
05/30/2022 18:19:54 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=429
05/30/2022 18:19:56 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=432
05/30/2022 18:19:59 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=434
05/30/2022 18:20:01 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=437
05/30/2022 18:20:02 - INFO - __main__ - Global step 1750 Train loss 0.01 Classification-F1 0.7178605178605179 on epoch=437
05/30/2022 18:20:05 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=439
05/30/2022 18:20:07 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=442
05/30/2022 18:20:10 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=444
05/30/2022 18:20:12 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.04 on epoch=447
05/30/2022 18:20:15 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=449
05/30/2022 18:20:16 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.5813319530710835 on epoch=449
05/30/2022 18:20:18 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=452
05/30/2022 18:20:21 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=454
05/30/2022 18:20:23 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=457
05/30/2022 18:20:26 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.07 on epoch=459
05/30/2022 18:20:28 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=462
05/30/2022 18:20:30 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.6270073145245559 on epoch=462
05/30/2022 18:20:32 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.06 on epoch=464
05/30/2022 18:20:35 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=467
05/30/2022 18:20:37 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=469
05/30/2022 18:20:40 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=472
05/30/2022 18:20:42 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=474
05/30/2022 18:20:43 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.601873915558126 on epoch=474
05/30/2022 18:20:46 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=477
05/30/2022 18:20:48 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=479
05/30/2022 18:20:51 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=482
05/30/2022 18:20:53 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=484
05/30/2022 18:20:56 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.11 on epoch=487
05/30/2022 18:20:57 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.7090577121536873 on epoch=487
05/30/2022 18:21:00 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=489
05/30/2022 18:21:02 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=492
05/30/2022 18:21:05 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=494
05/30/2022 18:21:07 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=497
05/30/2022 18:21:10 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=499
05/30/2022 18:21:11 - INFO - __main__ - Global step 2000 Train loss 0.00 Classification-F1 0.6759281829858169 on epoch=499
05/30/2022 18:21:13 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=502
05/30/2022 18:21:16 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
05/30/2022 18:21:18 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
05/30/2022 18:21:21 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=509
05/30/2022 18:21:23 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
05/30/2022 18:21:24 - INFO - __main__ - Global step 2050 Train loss 0.00 Classification-F1 0.6811409179056238 on epoch=512
05/30/2022 18:21:27 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.03 on epoch=514
05/30/2022 18:21:30 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.04 on epoch=517
05/30/2022 18:21:32 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
05/30/2022 18:21:35 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
05/30/2022 18:21:37 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
05/30/2022 18:21:38 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.7420634920634921 on epoch=524
05/30/2022 18:21:41 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.25 on epoch=527
05/30/2022 18:21:43 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
05/30/2022 18:21:46 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=532
05/30/2022 18:21:48 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=534
05/30/2022 18:21:51 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
05/30/2022 18:21:52 - INFO - __main__ - Global step 2150 Train loss 0.06 Classification-F1 0.7430458768873403 on epoch=537
05/30/2022 18:21:54 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
05/30/2022 18:21:57 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=542
05/30/2022 18:22:00 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=544
05/30/2022 18:22:02 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
05/30/2022 18:22:05 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
05/30/2022 18:22:06 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.7266615089890952 on epoch=549
05/30/2022 18:22:08 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=552
05/30/2022 18:22:11 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
05/30/2022 18:22:13 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=557
05/30/2022 18:22:16 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
05/30/2022 18:22:18 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
05/30/2022 18:22:19 - INFO - __main__ - Global step 2250 Train loss 0.00 Classification-F1 0.7455515224843718 on epoch=562
05/30/2022 18:22:22 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=564
05/30/2022 18:22:24 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=567
05/30/2022 18:22:27 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=569
05/30/2022 18:22:29 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
05/30/2022 18:22:32 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=574
05/30/2022 18:22:33 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.7182539682539683 on epoch=574
05/30/2022 18:22:36 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=577
05/30/2022 18:22:38 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
05/30/2022 18:22:41 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
05/30/2022 18:22:43 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.14 on epoch=584
05/30/2022 18:22:46 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.04 on epoch=587
05/30/2022 18:22:47 - INFO - __main__ - Global step 2350 Train loss 0.04 Classification-F1 0.706254504769881 on epoch=587
05/30/2022 18:22:49 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.04 on epoch=589
05/30/2022 18:22:52 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
05/30/2022 18:22:54 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.03 on epoch=594
05/30/2022 18:22:57 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
05/30/2022 18:23:00 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
05/30/2022 18:23:01 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.6120880893300249 on epoch=599
05/30/2022 18:23:03 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=602
05/30/2022 18:23:06 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=604
05/30/2022 18:23:08 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
05/30/2022 18:23:11 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
05/30/2022 18:23:13 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
05/30/2022 18:23:14 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.5778609831029187 on epoch=612
05/30/2022 18:23:17 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=614
05/30/2022 18:23:19 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
05/30/2022 18:23:22 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=619
05/30/2022 18:23:25 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=622
05/30/2022 18:23:27 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
05/30/2022 18:23:28 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.7759652981427175 on epoch=624
05/30/2022 18:23:31 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
05/30/2022 18:23:33 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=629
05/30/2022 18:23:36 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
05/30/2022 18:23:38 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
05/30/2022 18:23:41 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
05/30/2022 18:23:42 - INFO - __main__ - Global step 2550 Train loss 0.00 Classification-F1 0.591635274799575 on epoch=637
05/30/2022 18:23:44 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=639
05/30/2022 18:23:47 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
05/30/2022 18:23:50 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
05/30/2022 18:23:52 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
05/30/2022 18:23:55 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
05/30/2022 18:23:56 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.7152361152361152 on epoch=649
05/30/2022 18:23:58 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
05/30/2022 18:24:01 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
05/30/2022 18:24:03 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
05/30/2022 18:24:06 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
05/30/2022 18:24:08 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
05/30/2022 18:24:09 - INFO - __main__ - Global step 2650 Train loss 0.00 Classification-F1 0.5886174636174636 on epoch=662
05/30/2022 18:24:12 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=664
05/30/2022 18:24:14 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
05/30/2022 18:24:17 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
05/30/2022 18:24:19 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.06 on epoch=672
05/30/2022 18:24:22 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
05/30/2022 18:24:23 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.7164346612622474 on epoch=674
05/30/2022 18:24:25 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
05/30/2022 18:24:28 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
05/30/2022 18:24:30 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
05/30/2022 18:24:33 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=684
05/30/2022 18:24:35 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=687
05/30/2022 18:24:36 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.7603024193548388 on epoch=687
05/30/2022 18:24:39 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=689
05/30/2022 18:24:41 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
05/30/2022 18:24:44 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=694
05/30/2022 18:24:46 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=697
05/30/2022 18:24:49 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
05/30/2022 18:24:50 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.7353311439518335 on epoch=699
05/30/2022 18:24:52 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
05/30/2022 18:24:55 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
05/30/2022 18:24:57 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
05/30/2022 18:25:00 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
05/30/2022 18:25:02 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
05/30/2022 18:25:03 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.7476190476190476 on epoch=712
05/30/2022 18:25:06 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
05/30/2022 18:25:08 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
05/30/2022 18:25:11 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
05/30/2022 18:25:13 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=722
05/30/2022 18:25:16 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
05/30/2022 18:25:17 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.604107505070994 on epoch=724
05/30/2022 18:25:19 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
05/30/2022 18:25:22 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
05/30/2022 18:25:24 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
05/30/2022 18:25:27 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
05/30/2022 18:25:29 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
05/30/2022 18:25:30 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.7061115355233002 on epoch=737
05/30/2022 18:25:33 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
05/30/2022 18:25:35 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
05/30/2022 18:25:38 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
05/30/2022 18:25:41 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
05/30/2022 18:25:43 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.03 on epoch=749
05/30/2022 18:25:44 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.7189623872604963 on epoch=749
05/30/2022 18:25:44 - INFO - __main__ - save last model!
05/30/2022 18:25:44 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/30/2022 18:25:44 - INFO - __main__ - Start tokenizing ... 5509 instances
05/30/2022 18:25:44 - INFO - __main__ - Printing 3 examples
05/30/2022 18:25:44 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/30/2022 18:25:44 - INFO - __main__ - ['others']
05/30/2022 18:25:44 - INFO - __main__ -  [emo] what you like very little things ok
05/30/2022 18:25:44 - INFO - __main__ - ['others']
05/30/2022 18:25:44 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/30/2022 18:25:44 - INFO - __main__ - ['others']
05/30/2022 18:25:44 - INFO - __main__ - Tokenizing Input ...
05/30/2022 18:25:44 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 18:25:44 - INFO - __main__ - Printing 3 examples
05/30/2022 18:25:44 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
05/30/2022 18:25:44 - INFO - __main__ - ['others']
05/30/2022 18:25:44 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
05/30/2022 18:25:44 - INFO - __main__ - ['others']
05/30/2022 18:25:44 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
05/30/2022 18:25:44 - INFO - __main__ - ['others']
05/30/2022 18:25:44 - INFO - __main__ - Tokenizing Input ...
05/30/2022 18:25:44 - INFO - __main__ - Tokenizing Output ...
05/30/2022 18:25:44 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 18:25:44 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 18:25:44 - INFO - __main__ - Printing 3 examples
05/30/2022 18:25:44 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
05/30/2022 18:25:44 - INFO - __main__ - ['others']
05/30/2022 18:25:44 - INFO - __main__ -  [emo] i did ask now you did tell ms
05/30/2022 18:25:44 - INFO - __main__ - ['others']
05/30/2022 18:25:44 - INFO - __main__ -  [emo] buddy how you tell me your contact no
05/30/2022 18:25:44 - INFO - __main__ - ['others']
05/30/2022 18:25:44 - INFO - __main__ - Tokenizing Input ...
05/30/2022 18:25:44 - INFO - __main__ - Tokenizing Output ...
05/30/2022 18:25:44 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 18:25:46 - INFO - __main__ - Tokenizing Output ...
05/30/2022 18:25:52 - INFO - __main__ - Loaded 5509 examples from test data
05/30/2022 18:26:03 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 18:26:04 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/30/2022 18:26:04 - INFO - __main__ - Starting training!
05/30/2022 18:27:26 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-24uptasks/singletask-emo/emo_16_13_0.4_8_predictions.txt
05/30/2022 18:27:26 - INFO - __main__ - Classification-F1 on test data: 0.3184
05/30/2022 18:27:26 - INFO - __main__ - prefix=emo_16_13, lr=0.4, bsz=8, dev_performance=0.8132616487455198, test_performance=0.31843083765096464
05/30/2022 18:27:26 - INFO - __main__ - Running ... prefix=emo_16_13, lr=0.3, bsz=8 ...
05/30/2022 18:27:27 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 18:27:27 - INFO - __main__ - Printing 3 examples
05/30/2022 18:27:27 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
05/30/2022 18:27:27 - INFO - __main__ - ['others']
05/30/2022 18:27:27 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
05/30/2022 18:27:27 - INFO - __main__ - ['others']
05/30/2022 18:27:27 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
05/30/2022 18:27:27 - INFO - __main__ - ['others']
05/30/2022 18:27:27 - INFO - __main__ - Tokenizing Input ...
05/30/2022 18:27:27 - INFO - __main__ - Tokenizing Output ...
05/30/2022 18:27:27 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 18:27:27 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 18:27:27 - INFO - __main__ - Printing 3 examples
05/30/2022 18:27:27 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
05/30/2022 18:27:27 - INFO - __main__ - ['others']
05/30/2022 18:27:27 - INFO - __main__ -  [emo] i did ask now you did tell ms
05/30/2022 18:27:27 - INFO - __main__ - ['others']
05/30/2022 18:27:27 - INFO - __main__ -  [emo] buddy how you tell me your contact no
05/30/2022 18:27:27 - INFO - __main__ - ['others']
05/30/2022 18:27:27 - INFO - __main__ - Tokenizing Input ...
05/30/2022 18:27:27 - INFO - __main__ - Tokenizing Output ...
05/30/2022 18:27:27 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 18:27:43 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 18:27:43 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/30/2022 18:27:43 - INFO - __main__ - Starting training!
05/30/2022 18:27:46 - INFO - __main__ - Step 10 Global step 10 Train loss 4.10 on epoch=2
05/30/2022 18:27:49 - INFO - __main__ - Step 20 Global step 20 Train loss 2.15 on epoch=4
05/30/2022 18:27:51 - INFO - __main__ - Step 30 Global step 30 Train loss 1.52 on epoch=7
05/30/2022 18:27:54 - INFO - __main__ - Step 40 Global step 40 Train loss 1.16 on epoch=9
05/30/2022 18:27:56 - INFO - __main__ - Step 50 Global step 50 Train loss 0.87 on epoch=12
05/30/2022 18:27:57 - INFO - __main__ - Global step 50 Train loss 1.96 Classification-F1 0.4379109415285212 on epoch=12
05/30/2022 18:27:57 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.4379109415285212 on epoch=12, global_step=50
05/30/2022 18:28:00 - INFO - __main__ - Step 60 Global step 60 Train loss 0.80 on epoch=14
05/30/2022 18:28:02 - INFO - __main__ - Step 70 Global step 70 Train loss 0.83 on epoch=17
05/30/2022 18:28:05 - INFO - __main__ - Step 80 Global step 80 Train loss 0.80 on epoch=19
05/30/2022 18:28:07 - INFO - __main__ - Step 90 Global step 90 Train loss 0.73 on epoch=22
05/30/2022 18:28:09 - INFO - __main__ - Step 100 Global step 100 Train loss 0.80 on epoch=24
05/30/2022 18:28:10 - INFO - __main__ - Global step 100 Train loss 0.79 Classification-F1 0.3206238859180036 on epoch=24
05/30/2022 18:28:13 - INFO - __main__ - Step 110 Global step 110 Train loss 0.70 on epoch=27
05/30/2022 18:28:15 - INFO - __main__ - Step 120 Global step 120 Train loss 0.69 on epoch=29
05/30/2022 18:28:18 - INFO - __main__ - Step 130 Global step 130 Train loss 0.71 on epoch=32
05/30/2022 18:28:20 - INFO - __main__ - Step 140 Global step 140 Train loss 0.72 on epoch=34
05/30/2022 18:28:22 - INFO - __main__ - Step 150 Global step 150 Train loss 0.56 on epoch=37
05/30/2022 18:28:23 - INFO - __main__ - Global step 150 Train loss 0.67 Classification-F1 0.5766823641823642 on epoch=37
05/30/2022 18:28:23 - INFO - __main__ - Saving model with best Classification-F1: 0.4379109415285212 -> 0.5766823641823642 on epoch=37, global_step=150
05/30/2022 18:28:26 - INFO - __main__ - Step 160 Global step 160 Train loss 0.53 on epoch=39
05/30/2022 18:28:28 - INFO - __main__ - Step 170 Global step 170 Train loss 0.56 on epoch=42
05/30/2022 18:28:31 - INFO - __main__ - Step 180 Global step 180 Train loss 0.54 on epoch=44
05/30/2022 18:28:33 - INFO - __main__ - Step 190 Global step 190 Train loss 0.60 on epoch=47
05/30/2022 18:28:36 - INFO - __main__ - Step 200 Global step 200 Train loss 0.68 on epoch=49
05/30/2022 18:28:36 - INFO - __main__ - Global step 200 Train loss 0.58 Classification-F1 0.6377910602910603 on epoch=49
05/30/2022 18:28:36 - INFO - __main__ - Saving model with best Classification-F1: 0.5766823641823642 -> 0.6377910602910603 on epoch=49, global_step=200
05/30/2022 18:28:39 - INFO - __main__ - Step 210 Global step 210 Train loss 0.60 on epoch=52
05/30/2022 18:28:41 - INFO - __main__ - Step 220 Global step 220 Train loss 0.59 on epoch=54
05/30/2022 18:28:44 - INFO - __main__ - Step 230 Global step 230 Train loss 0.58 on epoch=57
05/30/2022 18:28:46 - INFO - __main__ - Step 240 Global step 240 Train loss 0.60 on epoch=59
05/30/2022 18:28:49 - INFO - __main__ - Step 250 Global step 250 Train loss 0.42 on epoch=62
05/30/2022 18:28:50 - INFO - __main__ - Global step 250 Train loss 0.56 Classification-F1 0.6707312356380679 on epoch=62
05/30/2022 18:28:50 - INFO - __main__ - Saving model with best Classification-F1: 0.6377910602910603 -> 0.6707312356380679 on epoch=62, global_step=250
05/30/2022 18:28:52 - INFO - __main__ - Step 260 Global step 260 Train loss 0.49 on epoch=64
05/30/2022 18:28:55 - INFO - __main__ - Step 270 Global step 270 Train loss 0.48 on epoch=67
05/30/2022 18:28:57 - INFO - __main__ - Step 280 Global step 280 Train loss 0.44 on epoch=69
05/30/2022 18:28:59 - INFO - __main__ - Step 290 Global step 290 Train loss 0.36 on epoch=72
05/30/2022 18:29:02 - INFO - __main__ - Step 300 Global step 300 Train loss 0.47 on epoch=74
05/30/2022 18:29:03 - INFO - __main__ - Global step 300 Train loss 0.45 Classification-F1 0.6932196902785138 on epoch=74
05/30/2022 18:29:03 - INFO - __main__ - Saving model with best Classification-F1: 0.6707312356380679 -> 0.6932196902785138 on epoch=74, global_step=300
05/30/2022 18:29:05 - INFO - __main__ - Step 310 Global step 310 Train loss 0.38 on epoch=77
05/30/2022 18:29:08 - INFO - __main__ - Step 320 Global step 320 Train loss 0.43 on epoch=79
05/30/2022 18:29:10 - INFO - __main__ - Step 330 Global step 330 Train loss 0.48 on epoch=82
05/30/2022 18:29:13 - INFO - __main__ - Step 340 Global step 340 Train loss 0.39 on epoch=84
05/30/2022 18:29:15 - INFO - __main__ - Step 350 Global step 350 Train loss 0.38 on epoch=87
05/30/2022 18:29:16 - INFO - __main__ - Global step 350 Train loss 0.41 Classification-F1 0.6905377842877843 on epoch=87
05/30/2022 18:29:18 - INFO - __main__ - Step 360 Global step 360 Train loss 0.35 on epoch=89
05/30/2022 18:29:21 - INFO - __main__ - Step 370 Global step 370 Train loss 0.26 on epoch=92
05/30/2022 18:29:23 - INFO - __main__ - Step 380 Global step 380 Train loss 0.35 on epoch=94
05/30/2022 18:29:26 - INFO - __main__ - Step 390 Global step 390 Train loss 0.29 on epoch=97
05/30/2022 18:29:28 - INFO - __main__ - Step 400 Global step 400 Train loss 0.32 on epoch=99
05/30/2022 18:29:29 - INFO - __main__ - Global step 400 Train loss 0.31 Classification-F1 0.6767800944138475 on epoch=99
05/30/2022 18:29:32 - INFO - __main__ - Step 410 Global step 410 Train loss 0.27 on epoch=102
05/30/2022 18:29:34 - INFO - __main__ - Step 420 Global step 420 Train loss 0.22 on epoch=104
05/30/2022 18:29:36 - INFO - __main__ - Step 430 Global step 430 Train loss 0.36 on epoch=107
05/30/2022 18:29:39 - INFO - __main__ - Step 440 Global step 440 Train loss 0.28 on epoch=109
05/30/2022 18:29:41 - INFO - __main__ - Step 450 Global step 450 Train loss 0.30 on epoch=112
05/30/2022 18:29:42 - INFO - __main__ - Global step 450 Train loss 0.29 Classification-F1 0.7262321012321012 on epoch=112
05/30/2022 18:29:42 - INFO - __main__ - Saving model with best Classification-F1: 0.6932196902785138 -> 0.7262321012321012 on epoch=112, global_step=450
05/30/2022 18:29:45 - INFO - __main__ - Step 460 Global step 460 Train loss 0.27 on epoch=114
05/30/2022 18:29:47 - INFO - __main__ - Step 470 Global step 470 Train loss 0.20 on epoch=117
05/30/2022 18:29:49 - INFO - __main__ - Step 480 Global step 480 Train loss 0.29 on epoch=119
05/30/2022 18:29:52 - INFO - __main__ - Step 490 Global step 490 Train loss 0.24 on epoch=122
05/30/2022 18:29:54 - INFO - __main__ - Step 500 Global step 500 Train loss 0.22 on epoch=124
05/30/2022 18:29:55 - INFO - __main__ - Global step 500 Train loss 0.24 Classification-F1 0.7313946489593041 on epoch=124
05/30/2022 18:29:55 - INFO - __main__ - Saving model with best Classification-F1: 0.7262321012321012 -> 0.7313946489593041 on epoch=124, global_step=500
05/30/2022 18:29:58 - INFO - __main__ - Step 510 Global step 510 Train loss 0.37 on epoch=127
05/30/2022 18:30:00 - INFO - __main__ - Step 520 Global step 520 Train loss 0.25 on epoch=129
05/30/2022 18:30:03 - INFO - __main__ - Step 530 Global step 530 Train loss 0.25 on epoch=132
05/30/2022 18:30:05 - INFO - __main__ - Step 540 Global step 540 Train loss 0.29 on epoch=134
05/30/2022 18:30:07 - INFO - __main__ - Step 550 Global step 550 Train loss 0.12 on epoch=137
05/30/2022 18:30:08 - INFO - __main__ - Global step 550 Train loss 0.26 Classification-F1 0.6879730866274181 on epoch=137
05/30/2022 18:30:11 - INFO - __main__ - Step 560 Global step 560 Train loss 0.16 on epoch=139
05/30/2022 18:30:13 - INFO - __main__ - Step 570 Global step 570 Train loss 0.17 on epoch=142
05/30/2022 18:30:16 - INFO - __main__ - Step 580 Global step 580 Train loss 0.17 on epoch=144
05/30/2022 18:30:18 - INFO - __main__ - Step 590 Global step 590 Train loss 0.14 on epoch=147
05/30/2022 18:30:21 - INFO - __main__ - Step 600 Global step 600 Train loss 0.17 on epoch=149
05/30/2022 18:30:21 - INFO - __main__ - Global step 600 Train loss 0.16 Classification-F1 0.5766088524709214 on epoch=149
05/30/2022 18:30:24 - INFO - __main__ - Step 610 Global step 610 Train loss 0.14 on epoch=152
05/30/2022 18:30:26 - INFO - __main__ - Step 620 Global step 620 Train loss 0.16 on epoch=154
05/30/2022 18:30:29 - INFO - __main__ - Step 630 Global step 630 Train loss 0.15 on epoch=157
05/30/2022 18:30:31 - INFO - __main__ - Step 640 Global step 640 Train loss 0.08 on epoch=159
05/30/2022 18:30:34 - INFO - __main__ - Step 650 Global step 650 Train loss 0.10 on epoch=162
05/30/2022 18:30:34 - INFO - __main__ - Global step 650 Train loss 0.12 Classification-F1 0.764516129032258 on epoch=162
05/30/2022 18:30:35 - INFO - __main__ - Saving model with best Classification-F1: 0.7313946489593041 -> 0.764516129032258 on epoch=162, global_step=650
05/30/2022 18:30:37 - INFO - __main__ - Step 660 Global step 660 Train loss 0.15 on epoch=164
05/30/2022 18:30:39 - INFO - __main__ - Step 670 Global step 670 Train loss 0.11 on epoch=167
05/30/2022 18:30:42 - INFO - __main__ - Step 680 Global step 680 Train loss 0.12 on epoch=169
05/30/2022 18:30:44 - INFO - __main__ - Step 690 Global step 690 Train loss 0.15 on epoch=172
05/30/2022 18:30:47 - INFO - __main__ - Step 700 Global step 700 Train loss 0.06 on epoch=174
05/30/2022 18:30:48 - INFO - __main__ - Global step 700 Train loss 0.12 Classification-F1 0.5886291486291486 on epoch=174
05/30/2022 18:30:50 - INFO - __main__ - Step 710 Global step 710 Train loss 0.05 on epoch=177
05/30/2022 18:30:53 - INFO - __main__ - Step 720 Global step 720 Train loss 0.10 on epoch=179
05/30/2022 18:30:55 - INFO - __main__ - Step 730 Global step 730 Train loss 0.07 on epoch=182
05/30/2022 18:30:58 - INFO - __main__ - Step 740 Global step 740 Train loss 0.08 on epoch=184
05/30/2022 18:31:00 - INFO - __main__ - Step 750 Global step 750 Train loss 0.15 on epoch=187
05/30/2022 18:31:01 - INFO - __main__ - Global step 750 Train loss 0.09 Classification-F1 0.6951397420147419 on epoch=187
05/30/2022 18:31:03 - INFO - __main__ - Step 760 Global step 760 Train loss 0.07 on epoch=189
05/30/2022 18:31:06 - INFO - __main__ - Step 770 Global step 770 Train loss 0.05 on epoch=192
05/30/2022 18:31:08 - INFO - __main__ - Step 780 Global step 780 Train loss 0.10 on epoch=194
05/30/2022 18:31:11 - INFO - __main__ - Step 790 Global step 790 Train loss 0.15 on epoch=197
05/30/2022 18:31:13 - INFO - __main__ - Step 800 Global step 800 Train loss 0.06 on epoch=199
05/30/2022 18:31:14 - INFO - __main__ - Global step 800 Train loss 0.09 Classification-F1 0.5783052906083663 on epoch=199
05/30/2022 18:31:16 - INFO - __main__ - Step 810 Global step 810 Train loss 0.09 on epoch=202
05/30/2022 18:31:19 - INFO - __main__ - Step 820 Global step 820 Train loss 0.10 on epoch=204
05/30/2022 18:31:21 - INFO - __main__ - Step 830 Global step 830 Train loss 0.07 on epoch=207
05/30/2022 18:31:24 - INFO - __main__ - Step 840 Global step 840 Train loss 0.09 on epoch=209
05/30/2022 18:31:26 - INFO - __main__ - Step 850 Global step 850 Train loss 0.07 on epoch=212
05/30/2022 18:31:27 - INFO - __main__ - Global step 850 Train loss 0.09 Classification-F1 0.6758558558558557 on epoch=212
05/30/2022 18:31:30 - INFO - __main__ - Step 860 Global step 860 Train loss 0.07 on epoch=214
05/30/2022 18:31:32 - INFO - __main__ - Step 870 Global step 870 Train loss 0.05 on epoch=217
05/30/2022 18:31:35 - INFO - __main__ - Step 880 Global step 880 Train loss 0.07 on epoch=219
05/30/2022 18:31:37 - INFO - __main__ - Step 890 Global step 890 Train loss 0.07 on epoch=222
05/30/2022 18:31:39 - INFO - __main__ - Step 900 Global step 900 Train loss 0.04 on epoch=224
05/30/2022 18:31:40 - INFO - __main__ - Global step 900 Train loss 0.06 Classification-F1 0.6415650406504065 on epoch=224
05/30/2022 18:31:43 - INFO - __main__ - Step 910 Global step 910 Train loss 0.04 on epoch=227
05/30/2022 18:31:45 - INFO - __main__ - Step 920 Global step 920 Train loss 0.06 on epoch=229
05/30/2022 18:31:48 - INFO - __main__ - Step 930 Global step 930 Train loss 0.02 on epoch=232
05/30/2022 18:31:50 - INFO - __main__ - Step 940 Global step 940 Train loss 0.08 on epoch=234
05/30/2022 18:31:53 - INFO - __main__ - Step 950 Global step 950 Train loss 0.04 on epoch=237
05/30/2022 18:31:54 - INFO - __main__ - Global step 950 Train loss 0.05 Classification-F1 0.7649071358748778 on epoch=237
05/30/2022 18:31:54 - INFO - __main__ - Saving model with best Classification-F1: 0.764516129032258 -> 0.7649071358748778 on epoch=237, global_step=950
05/30/2022 18:31:56 - INFO - __main__ - Step 960 Global step 960 Train loss 0.03 on epoch=239
05/30/2022 18:31:59 - INFO - __main__ - Step 970 Global step 970 Train loss 0.05 on epoch=242
05/30/2022 18:32:01 - INFO - __main__ - Step 980 Global step 980 Train loss 0.10 on epoch=244
05/30/2022 18:32:03 - INFO - __main__ - Step 990 Global step 990 Train loss 0.04 on epoch=247
05/30/2022 18:32:06 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.03 on epoch=249
05/30/2022 18:32:07 - INFO - __main__ - Global step 1000 Train loss 0.05 Classification-F1 0.6838881706528765 on epoch=249
05/30/2022 18:32:09 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.06 on epoch=252
05/30/2022 18:32:12 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.03 on epoch=254
05/30/2022 18:32:14 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.03 on epoch=257
05/30/2022 18:32:17 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.06 on epoch=259
05/30/2022 18:32:19 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.03 on epoch=262
05/30/2022 18:32:20 - INFO - __main__ - Global step 1050 Train loss 0.04 Classification-F1 0.7313717532467532 on epoch=262
05/30/2022 18:32:23 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.18 on epoch=264
05/30/2022 18:32:25 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.04 on epoch=267
05/30/2022 18:32:28 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.04 on epoch=269
05/30/2022 18:32:30 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.06 on epoch=272
05/30/2022 18:32:32 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.06 on epoch=274
05/30/2022 18:32:33 - INFO - __main__ - Global step 1100 Train loss 0.07 Classification-F1 0.5891774891774892 on epoch=274
05/30/2022 18:32:36 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.03 on epoch=277
05/30/2022 18:32:38 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.02 on epoch=279
05/30/2022 18:32:41 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.08 on epoch=282
05/30/2022 18:32:43 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.01 on epoch=284
05/30/2022 18:32:46 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.02 on epoch=287
05/30/2022 18:32:47 - INFO - __main__ - Global step 1150 Train loss 0.03 Classification-F1 0.6019448688566336 on epoch=287
05/30/2022 18:32:49 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.01 on epoch=289
05/30/2022 18:32:52 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.05 on epoch=292
05/30/2022 18:32:54 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.09 on epoch=294
05/30/2022 18:32:57 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.05 on epoch=297
05/30/2022 18:32:59 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.03 on epoch=299
05/30/2022 18:33:00 - INFO - __main__ - Global step 1200 Train loss 0.05 Classification-F1 0.5920625610948191 on epoch=299
05/30/2022 18:33:02 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.02 on epoch=302
05/30/2022 18:33:05 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.05 on epoch=304
05/30/2022 18:33:07 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.03 on epoch=307
05/30/2022 18:33:10 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.04 on epoch=309
05/30/2022 18:33:12 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.04 on epoch=312
05/30/2022 18:33:13 - INFO - __main__ - Global step 1250 Train loss 0.03 Classification-F1 0.7286676286676287 on epoch=312
05/30/2022 18:33:16 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.04 on epoch=314
05/30/2022 18:33:18 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.04 on epoch=317
05/30/2022 18:33:21 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.05 on epoch=319
05/30/2022 18:33:23 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.02 on epoch=322
05/30/2022 18:33:26 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.03 on epoch=324
05/30/2022 18:33:27 - INFO - __main__ - Global step 1300 Train loss 0.04 Classification-F1 0.6980590215884334 on epoch=324
05/30/2022 18:33:29 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.02 on epoch=327
05/30/2022 18:33:32 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.02 on epoch=329
05/30/2022 18:33:34 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.02 on epoch=332
05/30/2022 18:33:37 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.05 on epoch=334
05/30/2022 18:33:39 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=337
05/30/2022 18:33:40 - INFO - __main__ - Global step 1350 Train loss 0.02 Classification-F1 0.6444444444444444 on epoch=337
05/30/2022 18:33:43 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.04 on epoch=339
05/30/2022 18:33:45 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.00 on epoch=342
05/30/2022 18:33:47 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=344
05/30/2022 18:33:50 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=347
05/30/2022 18:33:52 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=349
05/30/2022 18:33:53 - INFO - __main__ - Global step 1400 Train loss 0.02 Classification-F1 0.6600174216027875 on epoch=349
05/30/2022 18:33:56 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.02 on epoch=352
05/30/2022 18:33:58 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.01 on epoch=354
05/30/2022 18:34:01 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.00 on epoch=357
05/30/2022 18:34:03 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=359
05/30/2022 18:34:06 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=362
05/30/2022 18:34:07 - INFO - __main__ - Global step 1450 Train loss 0.02 Classification-F1 0.6858286049462521 on epoch=362
05/30/2022 18:34:09 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.06 on epoch=364
05/30/2022 18:34:12 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.05 on epoch=367
05/30/2022 18:34:14 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.02 on epoch=369
05/30/2022 18:34:17 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=372
05/30/2022 18:34:19 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.02 on epoch=374
05/30/2022 18:34:20 - INFO - __main__ - Global step 1500 Train loss 0.03 Classification-F1 0.6135472370766488 on epoch=374
05/30/2022 18:34:23 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.03 on epoch=377
05/30/2022 18:34:25 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=379
05/30/2022 18:34:28 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.07 on epoch=382
05/30/2022 18:34:30 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.13 on epoch=384
05/30/2022 18:34:33 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=387
05/30/2022 18:34:34 - INFO - __main__ - Global step 1550 Train loss 0.05 Classification-F1 0.6842306211634706 on epoch=387
05/30/2022 18:34:36 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.02 on epoch=389
05/30/2022 18:34:39 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.04 on epoch=392
05/30/2022 18:34:41 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.02 on epoch=394
05/30/2022 18:34:43 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=397
05/30/2022 18:34:46 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=399
05/30/2022 18:34:47 - INFO - __main__ - Global step 1600 Train loss 0.02 Classification-F1 0.6126846846846846 on epoch=399
05/30/2022 18:34:49 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=402
05/30/2022 18:34:52 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.02 on epoch=404
05/30/2022 18:34:54 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=407
05/30/2022 18:34:57 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.03 on epoch=409
05/30/2022 18:34:59 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=412
05/30/2022 18:35:00 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.6025878738592211 on epoch=412
05/30/2022 18:35:03 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.08 on epoch=414
05/30/2022 18:35:05 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=417
05/30/2022 18:35:08 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=419
05/30/2022 18:35:10 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.13 on epoch=422
05/30/2022 18:35:12 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=424
05/30/2022 18:35:13 - INFO - __main__ - Global step 1700 Train loss 0.05 Classification-F1 0.7250198412698413 on epoch=424
05/30/2022 18:35:16 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.03 on epoch=427
05/30/2022 18:35:18 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.02 on epoch=429
05/30/2022 18:35:21 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=432
05/30/2022 18:35:23 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=434
05/30/2022 18:35:26 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.10 on epoch=437
05/30/2022 18:35:27 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.5924126013030351 on epoch=437
05/30/2022 18:35:29 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=439
05/30/2022 18:35:32 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=442
05/30/2022 18:35:34 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=444
05/30/2022 18:35:37 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=447
05/30/2022 18:35:39 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=449
05/30/2022 18:35:40 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.580083807716635 on epoch=449
05/30/2022 18:35:42 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=452
05/30/2022 18:35:45 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=454
05/30/2022 18:35:47 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=457
05/30/2022 18:35:50 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.04 on epoch=459
05/30/2022 18:35:52 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=462
05/30/2022 18:35:53 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.6946637426900586 on epoch=462
05/30/2022 18:35:56 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=464
05/30/2022 18:35:58 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=467
05/30/2022 18:36:01 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=469
05/30/2022 18:36:03 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=472
05/30/2022 18:36:06 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.02 on epoch=474
05/30/2022 18:36:07 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.5915440115440116 on epoch=474
05/30/2022 18:36:09 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=477
05/30/2022 18:36:12 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.04 on epoch=479
05/30/2022 18:36:14 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.12 on epoch=482
05/30/2022 18:36:17 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=484
05/30/2022 18:36:19 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=487
05/30/2022 18:36:20 - INFO - __main__ - Global step 1950 Train loss 0.04 Classification-F1 0.7189494566154908 on epoch=487
05/30/2022 18:36:23 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=489
05/30/2022 18:36:25 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=492
05/30/2022 18:36:28 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=494
05/30/2022 18:36:30 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=497
05/30/2022 18:36:33 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=499
05/30/2022 18:36:34 - INFO - __main__ - Global step 2000 Train loss 0.00 Classification-F1 0.5709591944886062 on epoch=499
05/30/2022 18:36:36 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=502
05/30/2022 18:36:39 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
05/30/2022 18:36:41 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
05/30/2022 18:36:44 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=509
05/30/2022 18:36:46 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.04 on epoch=512
05/30/2022 18:36:47 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.5710935073004038 on epoch=512
05/30/2022 18:36:50 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=514
05/30/2022 18:36:52 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=517
05/30/2022 18:36:55 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=519
05/30/2022 18:36:57 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.03 on epoch=522
05/30/2022 18:37:00 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=524
05/30/2022 18:37:01 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.6878595946387709 on epoch=524
05/30/2022 18:37:03 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.05 on epoch=527
05/30/2022 18:37:06 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.06 on epoch=529
05/30/2022 18:37:08 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=532
05/30/2022 18:37:11 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
05/30/2022 18:37:13 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=537
05/30/2022 18:37:14 - INFO - __main__ - Global step 2150 Train loss 0.03 Classification-F1 0.5595410471881059 on epoch=537
05/30/2022 18:37:17 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=539
05/30/2022 18:37:19 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=542
05/30/2022 18:37:21 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=544
05/30/2022 18:37:24 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=547
05/30/2022 18:37:26 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=549
05/30/2022 18:37:28 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.5366732338868562 on epoch=549
05/30/2022 18:37:30 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
05/30/2022 18:37:32 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=554
05/30/2022 18:37:35 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
05/30/2022 18:37:37 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=559
05/30/2022 18:37:40 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=562
05/30/2022 18:37:41 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.5632115583075337 on epoch=562
05/30/2022 18:37:43 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=564
05/30/2022 18:37:46 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.06 on epoch=567
05/30/2022 18:37:48 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=569
05/30/2022 18:37:51 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
05/30/2022 18:37:53 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=574
05/30/2022 18:37:54 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.5428927177278234 on epoch=574
05/30/2022 18:37:57 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=577
05/30/2022 18:37:59 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=579
05/30/2022 18:38:01 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=582
05/30/2022 18:38:04 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=584
05/30/2022 18:38:06 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=587
05/30/2022 18:38:07 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.5425007842399147 on epoch=587
05/30/2022 18:38:10 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=589
05/30/2022 18:38:12 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
05/30/2022 18:38:15 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=594
05/30/2022 18:38:17 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
05/30/2022 18:38:20 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=599
05/30/2022 18:38:21 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.6015148046398047 on epoch=599
05/30/2022 18:38:23 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=602
05/30/2022 18:38:26 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
05/30/2022 18:38:28 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=607
05/30/2022 18:38:31 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
05/30/2022 18:38:33 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=612
05/30/2022 18:38:34 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.6792961410608469 on epoch=612
05/30/2022 18:38:36 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=614
05/30/2022 18:38:39 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
05/30/2022 18:38:41 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=619
05/30/2022 18:38:44 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
05/30/2022 18:38:46 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
05/30/2022 18:38:48 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.5892546791443851 on epoch=624
05/30/2022 18:38:50 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
05/30/2022 18:38:53 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=629
05/30/2022 18:38:55 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
05/30/2022 18:38:58 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.03 on epoch=634
05/30/2022 18:39:00 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=637
05/30/2022 18:39:01 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.6792961410608469 on epoch=637
05/30/2022 18:39:04 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=639
05/30/2022 18:39:06 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=642
05/30/2022 18:39:09 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.04 on epoch=644
05/30/2022 18:39:11 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=647
05/30/2022 18:39:14 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=649
05/30/2022 18:39:15 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.7014421536160665 on epoch=649
05/30/2022 18:39:18 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=652
05/30/2022 18:39:20 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
05/30/2022 18:39:23 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=657
05/30/2022 18:39:25 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
05/30/2022 18:39:28 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.03 on epoch=662
05/30/2022 18:39:29 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.7328815397126592 on epoch=662
05/30/2022 18:39:31 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.14 on epoch=664
05/30/2022 18:39:34 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=667
05/30/2022 18:39:37 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
05/30/2022 18:39:39 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
05/30/2022 18:39:42 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=674
05/30/2022 18:39:43 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.6003663003663003 on epoch=674
05/30/2022 18:39:45 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
05/30/2022 18:39:48 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
05/30/2022 18:39:51 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=682
05/30/2022 18:39:53 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
05/30/2022 18:39:56 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
05/30/2022 18:39:57 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.6809901479019126 on epoch=687
05/30/2022 18:39:59 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
05/30/2022 18:40:02 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=692
05/30/2022 18:40:04 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
05/30/2022 18:40:07 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
05/30/2022 18:40:10 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
05/30/2022 18:40:11 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.6801553043420902 on epoch=699
05/30/2022 18:40:13 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=702
05/30/2022 18:40:16 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=704
05/30/2022 18:40:18 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=707
05/30/2022 18:40:21 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=709
05/30/2022 18:40:24 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
05/30/2022 18:40:25 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.6737906384645515 on epoch=712
05/30/2022 18:40:27 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=714
05/30/2022 18:40:30 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=717
05/30/2022 18:40:32 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=719
05/30/2022 18:40:35 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
05/30/2022 18:40:37 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
05/30/2022 18:40:39 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.7487554112554113 on epoch=724
05/30/2022 18:40:41 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
05/30/2022 18:40:44 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=729
05/30/2022 18:40:46 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
05/30/2022 18:40:49 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=734
05/30/2022 18:40:52 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
05/30/2022 18:40:53 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.7278847296494356 on epoch=737
05/30/2022 18:40:55 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=739
05/30/2022 18:40:58 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
05/30/2022 18:41:00 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=744
05/30/2022 18:41:03 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
05/30/2022 18:41:05 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=749
05/30/2022 18:41:07 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.6874842690699468 on epoch=749
05/30/2022 18:41:07 - INFO - __main__ - save last model!
05/30/2022 18:41:07 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/30/2022 18:41:07 - INFO - __main__ - Start tokenizing ... 5509 instances
05/30/2022 18:41:07 - INFO - __main__ - Printing 3 examples
05/30/2022 18:41:07 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/30/2022 18:41:07 - INFO - __main__ - ['others']
05/30/2022 18:41:07 - INFO - __main__ -  [emo] what you like very little things ok
05/30/2022 18:41:07 - INFO - __main__ - ['others']
05/30/2022 18:41:07 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/30/2022 18:41:07 - INFO - __main__ - ['others']
05/30/2022 18:41:07 - INFO - __main__ - Tokenizing Input ...
05/30/2022 18:41:07 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 18:41:07 - INFO - __main__ - Printing 3 examples
05/30/2022 18:41:07 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
05/30/2022 18:41:07 - INFO - __main__ - ['others']
05/30/2022 18:41:07 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
05/30/2022 18:41:07 - INFO - __main__ - ['others']
05/30/2022 18:41:07 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
05/30/2022 18:41:07 - INFO - __main__ - ['others']
05/30/2022 18:41:07 - INFO - __main__ - Tokenizing Input ...
05/30/2022 18:41:07 - INFO - __main__ - Tokenizing Output ...
05/30/2022 18:41:07 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 18:41:07 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 18:41:07 - INFO - __main__ - Printing 3 examples
05/30/2022 18:41:07 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
05/30/2022 18:41:07 - INFO - __main__ - ['others']
05/30/2022 18:41:07 - INFO - __main__ -  [emo] i did ask now you did tell ms
05/30/2022 18:41:07 - INFO - __main__ - ['others']
05/30/2022 18:41:07 - INFO - __main__ -  [emo] buddy how you tell me your contact no
05/30/2022 18:41:07 - INFO - __main__ - ['others']
05/30/2022 18:41:07 - INFO - __main__ - Tokenizing Input ...
05/30/2022 18:41:07 - INFO - __main__ - Tokenizing Output ...
05/30/2022 18:41:07 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 18:41:09 - INFO - __main__ - Tokenizing Output ...
05/30/2022 18:41:14 - INFO - __main__ - Loaded 5509 examples from test data
05/30/2022 18:41:25 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 18:41:26 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/30/2022 18:41:26 - INFO - __main__ - Starting training!
05/30/2022 18:42:48 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-24uptasks/singletask-emo/emo_16_13_0.3_8_predictions.txt
05/30/2022 18:42:48 - INFO - __main__ - Classification-F1 on test data: 0.1911
05/30/2022 18:42:48 - INFO - __main__ - prefix=emo_16_13, lr=0.3, bsz=8, dev_performance=0.7649071358748778, test_performance=0.1911029704029058
05/30/2022 18:42:48 - INFO - __main__ - Running ... prefix=emo_16_13, lr=0.2, bsz=8 ...
05/30/2022 18:42:49 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 18:42:49 - INFO - __main__ - Printing 3 examples
05/30/2022 18:42:49 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
05/30/2022 18:42:49 - INFO - __main__ - ['others']
05/30/2022 18:42:49 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
05/30/2022 18:42:49 - INFO - __main__ - ['others']
05/30/2022 18:42:49 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
05/30/2022 18:42:49 - INFO - __main__ - ['others']
05/30/2022 18:42:49 - INFO - __main__ - Tokenizing Input ...
05/30/2022 18:42:49 - INFO - __main__ - Tokenizing Output ...
05/30/2022 18:42:49 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 18:42:49 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 18:42:49 - INFO - __main__ - Printing 3 examples
05/30/2022 18:42:49 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
05/30/2022 18:42:49 - INFO - __main__ - ['others']
05/30/2022 18:42:49 - INFO - __main__ -  [emo] i did ask now you did tell ms
05/30/2022 18:42:49 - INFO - __main__ - ['others']
05/30/2022 18:42:49 - INFO - __main__ -  [emo] buddy how you tell me your contact no
05/30/2022 18:42:49 - INFO - __main__ - ['others']
05/30/2022 18:42:49 - INFO - __main__ - Tokenizing Input ...
05/30/2022 18:42:49 - INFO - __main__ - Tokenizing Output ...
05/30/2022 18:42:49 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 18:43:04 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 18:43:05 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/30/2022 18:43:05 - INFO - __main__ - Starting training!
05/30/2022 18:43:08 - INFO - __main__ - Step 10 Global step 10 Train loss 4.43 on epoch=2
05/30/2022 18:43:10 - INFO - __main__ - Step 20 Global step 20 Train loss 2.62 on epoch=4
05/30/2022 18:43:13 - INFO - __main__ - Step 30 Global step 30 Train loss 2.00 on epoch=7
05/30/2022 18:43:15 - INFO - __main__ - Step 40 Global step 40 Train loss 1.38 on epoch=9
05/30/2022 18:43:18 - INFO - __main__ - Step 50 Global step 50 Train loss 1.28 on epoch=12
05/30/2022 18:43:19 - INFO - __main__ - Global step 50 Train loss 2.34 Classification-F1 0.2521091811414392 on epoch=12
05/30/2022 18:43:19 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.2521091811414392 on epoch=12, global_step=50
05/30/2022 18:43:21 - INFO - __main__ - Step 60 Global step 60 Train loss 1.12 on epoch=14
05/30/2022 18:43:24 - INFO - __main__ - Step 70 Global step 70 Train loss 0.89 on epoch=17
05/30/2022 18:43:26 - INFO - __main__ - Step 80 Global step 80 Train loss 0.92 on epoch=19
05/30/2022 18:43:29 - INFO - __main__ - Step 90 Global step 90 Train loss 0.87 on epoch=22
05/30/2022 18:43:31 - INFO - __main__ - Step 100 Global step 100 Train loss 0.78 on epoch=24
05/30/2022 18:43:32 - INFO - __main__ - Global step 100 Train loss 0.92 Classification-F1 0.3810071154898741 on epoch=24
05/30/2022 18:43:32 - INFO - __main__ - Saving model with best Classification-F1: 0.2521091811414392 -> 0.3810071154898741 on epoch=24, global_step=100
05/30/2022 18:43:34 - INFO - __main__ - Step 110 Global step 110 Train loss 0.79 on epoch=27
05/30/2022 18:43:37 - INFO - __main__ - Step 120 Global step 120 Train loss 0.77 on epoch=29
05/30/2022 18:43:39 - INFO - __main__ - Step 130 Global step 130 Train loss 0.80 on epoch=32
05/30/2022 18:43:42 - INFO - __main__ - Step 140 Global step 140 Train loss 0.73 on epoch=34
05/30/2022 18:43:44 - INFO - __main__ - Step 150 Global step 150 Train loss 0.71 on epoch=37
05/30/2022 18:43:45 - INFO - __main__ - Global step 150 Train loss 0.76 Classification-F1 0.4907509157509157 on epoch=37
05/30/2022 18:43:45 - INFO - __main__ - Saving model with best Classification-F1: 0.3810071154898741 -> 0.4907509157509157 on epoch=37, global_step=150
05/30/2022 18:43:48 - INFO - __main__ - Step 160 Global step 160 Train loss 0.61 on epoch=39
05/30/2022 18:43:50 - INFO - __main__ - Step 170 Global step 170 Train loss 0.73 on epoch=42
05/30/2022 18:43:52 - INFO - __main__ - Step 180 Global step 180 Train loss 0.63 on epoch=44
05/30/2022 18:43:55 - INFO - __main__ - Step 190 Global step 190 Train loss 0.58 on epoch=47
05/30/2022 18:43:57 - INFO - __main__ - Step 200 Global step 200 Train loss 0.66 on epoch=49
05/30/2022 18:43:58 - INFO - __main__ - Global step 200 Train loss 0.64 Classification-F1 0.5702851398201432 on epoch=49
05/30/2022 18:43:58 - INFO - __main__ - Saving model with best Classification-F1: 0.4907509157509157 -> 0.5702851398201432 on epoch=49, global_step=200
05/30/2022 18:44:01 - INFO - __main__ - Step 210 Global step 210 Train loss 0.74 on epoch=52
05/30/2022 18:44:03 - INFO - __main__ - Step 220 Global step 220 Train loss 0.55 on epoch=54
05/30/2022 18:44:06 - INFO - __main__ - Step 230 Global step 230 Train loss 0.62 on epoch=57
05/30/2022 18:44:08 - INFO - __main__ - Step 240 Global step 240 Train loss 0.62 on epoch=59
05/30/2022 18:44:11 - INFO - __main__ - Step 250 Global step 250 Train loss 0.64 on epoch=62
05/30/2022 18:44:11 - INFO - __main__ - Global step 250 Train loss 0.63 Classification-F1 0.6566715350335167 on epoch=62
05/30/2022 18:44:11 - INFO - __main__ - Saving model with best Classification-F1: 0.5702851398201432 -> 0.6566715350335167 on epoch=62, global_step=250
05/30/2022 18:44:14 - INFO - __main__ - Step 260 Global step 260 Train loss 0.59 on epoch=64
05/30/2022 18:44:16 - INFO - __main__ - Step 270 Global step 270 Train loss 0.58 on epoch=67
05/30/2022 18:44:19 - INFO - __main__ - Step 280 Global step 280 Train loss 0.59 on epoch=69
05/30/2022 18:44:21 - INFO - __main__ - Step 290 Global step 290 Train loss 0.53 on epoch=72
05/30/2022 18:44:24 - INFO - __main__ - Step 300 Global step 300 Train loss 0.50 on epoch=74
05/30/2022 18:44:25 - INFO - __main__ - Global step 300 Train loss 0.55 Classification-F1 0.639060939060939 on epoch=74
05/30/2022 18:44:27 - INFO - __main__ - Step 310 Global step 310 Train loss 0.46 on epoch=77
05/30/2022 18:44:30 - INFO - __main__ - Step 320 Global step 320 Train loss 0.55 on epoch=79
05/30/2022 18:44:32 - INFO - __main__ - Step 330 Global step 330 Train loss 0.46 on epoch=82
05/30/2022 18:44:34 - INFO - __main__ - Step 340 Global step 340 Train loss 0.46 on epoch=84
05/30/2022 18:44:37 - INFO - __main__ - Step 350 Global step 350 Train loss 0.43 on epoch=87
05/30/2022 18:44:38 - INFO - __main__ - Global step 350 Train loss 0.47 Classification-F1 0.6726084373143196 on epoch=87
05/30/2022 18:44:38 - INFO - __main__ - Saving model with best Classification-F1: 0.6566715350335167 -> 0.6726084373143196 on epoch=87, global_step=350
05/30/2022 18:44:40 - INFO - __main__ - Step 360 Global step 360 Train loss 0.42 on epoch=89
05/30/2022 18:44:43 - INFO - __main__ - Step 370 Global step 370 Train loss 0.52 on epoch=92
05/30/2022 18:44:45 - INFO - __main__ - Step 380 Global step 380 Train loss 0.41 on epoch=94
05/30/2022 18:44:48 - INFO - __main__ - Step 390 Global step 390 Train loss 0.33 on epoch=97
05/30/2022 18:44:50 - INFO - __main__ - Step 400 Global step 400 Train loss 0.41 on epoch=99
05/30/2022 18:44:51 - INFO - __main__ - Global step 400 Train loss 0.42 Classification-F1 0.6444767690596389 on epoch=99
05/30/2022 18:44:53 - INFO - __main__ - Step 410 Global step 410 Train loss 0.44 on epoch=102
05/30/2022 18:44:56 - INFO - __main__ - Step 420 Global step 420 Train loss 0.35 on epoch=104
05/30/2022 18:44:58 - INFO - __main__ - Step 430 Global step 430 Train loss 0.42 on epoch=107
05/30/2022 18:45:01 - INFO - __main__ - Step 440 Global step 440 Train loss 0.36 on epoch=109
05/30/2022 18:45:03 - INFO - __main__ - Step 450 Global step 450 Train loss 0.44 on epoch=112
05/30/2022 18:45:04 - INFO - __main__ - Global step 450 Train loss 0.40 Classification-F1 0.7138323627560035 on epoch=112
05/30/2022 18:45:04 - INFO - __main__ - Saving model with best Classification-F1: 0.6726084373143196 -> 0.7138323627560035 on epoch=112, global_step=450
05/30/2022 18:45:06 - INFO - __main__ - Step 460 Global step 460 Train loss 0.33 on epoch=114
05/30/2022 18:45:09 - INFO - __main__ - Step 470 Global step 470 Train loss 0.42 on epoch=117
05/30/2022 18:45:11 - INFO - __main__ - Step 480 Global step 480 Train loss 0.40 on epoch=119
05/30/2022 18:45:14 - INFO - __main__ - Step 490 Global step 490 Train loss 0.31 on epoch=122
05/30/2022 18:45:16 - INFO - __main__ - Step 500 Global step 500 Train loss 0.31 on epoch=124
05/30/2022 18:45:17 - INFO - __main__ - Global step 500 Train loss 0.35 Classification-F1 0.6894293815346447 on epoch=124
05/30/2022 18:45:20 - INFO - __main__ - Step 510 Global step 510 Train loss 0.32 on epoch=127
05/30/2022 18:45:22 - INFO - __main__ - Step 520 Global step 520 Train loss 0.24 on epoch=129
05/30/2022 18:45:25 - INFO - __main__ - Step 530 Global step 530 Train loss 0.27 on epoch=132
05/30/2022 18:45:27 - INFO - __main__ - Step 540 Global step 540 Train loss 0.28 on epoch=134
05/30/2022 18:45:29 - INFO - __main__ - Step 550 Global step 550 Train loss 0.28 on epoch=137
05/30/2022 18:45:30 - INFO - __main__ - Global step 550 Train loss 0.28 Classification-F1 0.5768289898561596 on epoch=137
05/30/2022 18:45:33 - INFO - __main__ - Step 560 Global step 560 Train loss 0.24 on epoch=139
05/30/2022 18:45:35 - INFO - __main__ - Step 570 Global step 570 Train loss 0.26 on epoch=142
05/30/2022 18:45:38 - INFO - __main__ - Step 580 Global step 580 Train loss 0.29 on epoch=144
05/30/2022 18:45:40 - INFO - __main__ - Step 590 Global step 590 Train loss 0.23 on epoch=147
05/30/2022 18:45:43 - INFO - __main__ - Step 600 Global step 600 Train loss 0.20 on epoch=149
05/30/2022 18:45:43 - INFO - __main__ - Global step 600 Train loss 0.24 Classification-F1 0.6504926446102917 on epoch=149
05/30/2022 18:45:46 - INFO - __main__ - Step 610 Global step 610 Train loss 0.17 on epoch=152
05/30/2022 18:45:48 - INFO - __main__ - Step 620 Global step 620 Train loss 0.22 on epoch=154
05/30/2022 18:45:51 - INFO - __main__ - Step 630 Global step 630 Train loss 0.20 on epoch=157
05/30/2022 18:45:53 - INFO - __main__ - Step 640 Global step 640 Train loss 0.31 on epoch=159
05/30/2022 18:45:56 - INFO - __main__ - Step 650 Global step 650 Train loss 0.22 on epoch=162
05/30/2022 18:45:56 - INFO - __main__ - Global step 650 Train loss 0.23 Classification-F1 0.7018803014936381 on epoch=162
05/30/2022 18:45:59 - INFO - __main__ - Step 660 Global step 660 Train loss 0.21 on epoch=164
05/30/2022 18:46:01 - INFO - __main__ - Step 670 Global step 670 Train loss 0.28 on epoch=167
05/30/2022 18:46:04 - INFO - __main__ - Step 680 Global step 680 Train loss 0.11 on epoch=169
05/30/2022 18:46:06 - INFO - __main__ - Step 690 Global step 690 Train loss 0.23 on epoch=172
05/30/2022 18:46:09 - INFO - __main__ - Step 700 Global step 700 Train loss 0.14 on epoch=174
05/30/2022 18:46:10 - INFO - __main__ - Global step 700 Train loss 0.20 Classification-F1 0.7101008093655152 on epoch=174
05/30/2022 18:46:12 - INFO - __main__ - Step 710 Global step 710 Train loss 0.12 on epoch=177
05/30/2022 18:46:15 - INFO - __main__ - Step 720 Global step 720 Train loss 0.18 on epoch=179
05/30/2022 18:46:17 - INFO - __main__ - Step 730 Global step 730 Train loss 0.22 on epoch=182
05/30/2022 18:46:19 - INFO - __main__ - Step 740 Global step 740 Train loss 0.16 on epoch=184
05/30/2022 18:46:22 - INFO - __main__ - Step 750 Global step 750 Train loss 0.09 on epoch=187
05/30/2022 18:46:23 - INFO - __main__ - Global step 750 Train loss 0.15 Classification-F1 0.6984953703703705 on epoch=187
05/30/2022 18:46:25 - INFO - __main__ - Step 760 Global step 760 Train loss 0.11 on epoch=189
05/30/2022 18:46:28 - INFO - __main__ - Step 770 Global step 770 Train loss 0.24 on epoch=192
05/30/2022 18:46:30 - INFO - __main__ - Step 780 Global step 780 Train loss 0.11 on epoch=194
05/30/2022 18:46:33 - INFO - __main__ - Step 790 Global step 790 Train loss 0.15 on epoch=197
05/30/2022 18:46:35 - INFO - __main__ - Step 800 Global step 800 Train loss 0.23 on epoch=199
05/30/2022 18:46:36 - INFO - __main__ - Global step 800 Train loss 0.17 Classification-F1 0.5624009491466389 on epoch=199
05/30/2022 18:46:38 - INFO - __main__ - Step 810 Global step 810 Train loss 0.17 on epoch=202
05/30/2022 18:46:41 - INFO - __main__ - Step 820 Global step 820 Train loss 0.12 on epoch=204
05/30/2022 18:46:43 - INFO - __main__ - Step 830 Global step 830 Train loss 0.10 on epoch=207
05/30/2022 18:46:46 - INFO - __main__ - Step 840 Global step 840 Train loss 0.07 on epoch=209
05/30/2022 18:46:48 - INFO - __main__ - Step 850 Global step 850 Train loss 0.09 on epoch=212
05/30/2022 18:46:49 - INFO - __main__ - Global step 850 Train loss 0.11 Classification-F1 0.6583102918586791 on epoch=212
05/30/2022 18:46:51 - INFO - __main__ - Step 860 Global step 860 Train loss 0.11 on epoch=214
05/30/2022 18:46:54 - INFO - __main__ - Step 870 Global step 870 Train loss 0.08 on epoch=217
05/30/2022 18:46:56 - INFO - __main__ - Step 880 Global step 880 Train loss 0.10 on epoch=219
05/30/2022 18:46:59 - INFO - __main__ - Step 890 Global step 890 Train loss 0.10 on epoch=222
05/30/2022 18:47:01 - INFO - __main__ - Step 900 Global step 900 Train loss 0.13 on epoch=224
05/30/2022 18:47:02 - INFO - __main__ - Global step 900 Train loss 0.10 Classification-F1 0.6254574278767827 on epoch=224
05/30/2022 18:47:05 - INFO - __main__ - Step 910 Global step 910 Train loss 0.06 on epoch=227
05/30/2022 18:47:07 - INFO - __main__ - Step 920 Global step 920 Train loss 0.07 on epoch=229
05/30/2022 18:47:09 - INFO - __main__ - Step 930 Global step 930 Train loss 0.14 on epoch=232
05/30/2022 18:47:12 - INFO - __main__ - Step 940 Global step 940 Train loss 0.06 on epoch=234
05/30/2022 18:47:14 - INFO - __main__ - Step 950 Global step 950 Train loss 0.11 on epoch=237
05/30/2022 18:47:15 - INFO - __main__ - Global step 950 Train loss 0.09 Classification-F1 0.5552087286527515 on epoch=237
05/30/2022 18:47:18 - INFO - __main__ - Step 960 Global step 960 Train loss 0.14 on epoch=239
05/30/2022 18:47:20 - INFO - __main__ - Step 970 Global step 970 Train loss 0.08 on epoch=242
05/30/2022 18:47:23 - INFO - __main__ - Step 980 Global step 980 Train loss 0.17 on epoch=244
05/30/2022 18:47:25 - INFO - __main__ - Step 990 Global step 990 Train loss 0.09 on epoch=247
05/30/2022 18:47:28 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.11 on epoch=249
05/30/2022 18:47:28 - INFO - __main__ - Global step 1000 Train loss 0.12 Classification-F1 0.5681105990783409 on epoch=249
05/30/2022 18:47:31 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.07 on epoch=252
05/30/2022 18:47:34 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.09 on epoch=254
05/30/2022 18:47:36 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.06 on epoch=257
05/30/2022 18:47:39 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.07 on epoch=259
05/30/2022 18:47:41 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.06 on epoch=262
05/30/2022 18:47:42 - INFO - __main__ - Global step 1050 Train loss 0.07 Classification-F1 0.6042443985380582 on epoch=262
05/30/2022 18:47:45 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.15 on epoch=264
05/30/2022 18:47:47 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.04 on epoch=267
05/30/2022 18:47:50 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.03 on epoch=269
05/30/2022 18:47:52 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.08 on epoch=272
05/30/2022 18:47:55 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.04 on epoch=274
05/30/2022 18:47:56 - INFO - __main__ - Global step 1100 Train loss 0.07 Classification-F1 0.6438026378515812 on epoch=274
05/30/2022 18:47:58 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.13 on epoch=277
05/30/2022 18:48:01 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.11 on epoch=279
05/30/2022 18:48:03 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.04 on epoch=282
05/30/2022 18:48:06 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.06 on epoch=284
05/30/2022 18:48:09 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.27 on epoch=287
05/30/2022 18:48:09 - INFO - __main__ - Global step 1150 Train loss 0.12 Classification-F1 0.6756482198142415 on epoch=287
05/30/2022 18:48:12 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.02 on epoch=289
05/30/2022 18:48:14 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.12 on epoch=292
05/30/2022 18:48:17 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.06 on epoch=294
05/30/2022 18:48:19 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.10 on epoch=297
05/30/2022 18:48:22 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.04 on epoch=299
05/30/2022 18:48:23 - INFO - __main__ - Global step 1200 Train loss 0.07 Classification-F1 0.6046310292409647 on epoch=299
05/30/2022 18:48:25 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.03 on epoch=302
05/30/2022 18:48:28 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.04 on epoch=304
05/30/2022 18:48:31 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.04 on epoch=307
05/30/2022 18:48:33 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.14 on epoch=309
05/30/2022 18:48:36 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.06 on epoch=312
05/30/2022 18:48:36 - INFO - __main__ - Global step 1250 Train loss 0.06 Classification-F1 0.579107505070994 on epoch=312
05/30/2022 18:48:39 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.05 on epoch=314
05/30/2022 18:48:41 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.06 on epoch=317
05/30/2022 18:48:44 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.07 on epoch=319
05/30/2022 18:48:47 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.07 on epoch=322
05/30/2022 18:48:49 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.04 on epoch=324
05/30/2022 18:48:50 - INFO - __main__ - Global step 1300 Train loss 0.06 Classification-F1 0.6647783588960059 on epoch=324
05/30/2022 18:48:53 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.07 on epoch=327
05/30/2022 18:48:55 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.05 on epoch=329
05/30/2022 18:48:58 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.09 on epoch=332
05/30/2022 18:49:00 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.03 on epoch=334
05/30/2022 18:49:03 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.04 on epoch=337
05/30/2022 18:49:04 - INFO - __main__ - Global step 1350 Train loss 0.05 Classification-F1 0.642137394255361 on epoch=337
05/30/2022 18:49:06 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=339
05/30/2022 18:49:09 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.08 on epoch=342
05/30/2022 18:49:11 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.03 on epoch=344
05/30/2022 18:49:14 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.04 on epoch=347
05/30/2022 18:49:16 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.05 on epoch=349
05/30/2022 18:49:17 - INFO - __main__ - Global step 1400 Train loss 0.04 Classification-F1 0.6795815170008718 on epoch=349
05/30/2022 18:49:20 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.04 on epoch=352
05/30/2022 18:49:23 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.08 on epoch=354
05/30/2022 18:49:25 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.06 on epoch=357
05/30/2022 18:49:28 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.04 on epoch=359
05/30/2022 18:49:30 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.05 on epoch=362
05/30/2022 18:49:31 - INFO - __main__ - Global step 1450 Train loss 0.05 Classification-F1 0.6340612076095947 on epoch=362
05/30/2022 18:49:34 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.03 on epoch=364
05/30/2022 18:49:36 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.03 on epoch=367
05/30/2022 18:49:39 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.08 on epoch=369
05/30/2022 18:49:41 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.03 on epoch=372
05/30/2022 18:49:44 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.02 on epoch=374
05/30/2022 18:49:45 - INFO - __main__ - Global step 1500 Train loss 0.04 Classification-F1 0.6479137121741736 on epoch=374
05/30/2022 18:49:47 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.05 on epoch=377
05/30/2022 18:49:50 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.03 on epoch=379
05/30/2022 18:49:52 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.02 on epoch=382
05/30/2022 18:49:55 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.05 on epoch=384
05/30/2022 18:49:58 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=387
05/30/2022 18:49:59 - INFO - __main__ - Global step 1550 Train loss 0.04 Classification-F1 0.6362608182533438 on epoch=387
05/30/2022 18:50:01 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.02 on epoch=389
05/30/2022 18:50:04 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=392
05/30/2022 18:50:06 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=394
05/30/2022 18:50:09 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=397
05/30/2022 18:50:11 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.04 on epoch=399
05/30/2022 18:50:12 - INFO - __main__ - Global step 1600 Train loss 0.02 Classification-F1 0.6848337901468832 on epoch=399
05/30/2022 18:50:15 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=402
05/30/2022 18:50:17 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.04 on epoch=404
05/30/2022 18:50:20 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.02 on epoch=407
05/30/2022 18:50:22 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.03 on epoch=409
05/30/2022 18:50:24 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.03 on epoch=412
05/30/2022 18:50:25 - INFO - __main__ - Global step 1650 Train loss 0.03 Classification-F1 0.6817207285957285 on epoch=412
05/30/2022 18:50:28 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=414
05/30/2022 18:50:30 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.07 on epoch=417
05/30/2022 18:50:33 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.06 on epoch=419
05/30/2022 18:50:35 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.05 on epoch=422
05/30/2022 18:50:38 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=424
05/30/2022 18:50:39 - INFO - __main__ - Global step 1700 Train loss 0.04 Classification-F1 0.6846491912414834 on epoch=424
05/30/2022 18:50:41 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=427
05/30/2022 18:50:44 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=429
05/30/2022 18:50:46 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=432
05/30/2022 18:50:49 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.04 on epoch=434
05/30/2022 18:50:51 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=437
05/30/2022 18:50:52 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.6529843626617821 on epoch=437
05/30/2022 18:50:55 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=439
05/30/2022 18:50:57 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=442
05/30/2022 18:51:00 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.03 on epoch=444
05/30/2022 18:51:02 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.05 on epoch=447
05/30/2022 18:51:05 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=449
05/30/2022 18:51:06 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.6618909489633173 on epoch=449
05/30/2022 18:51:08 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.03 on epoch=452
05/30/2022 18:51:10 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.07 on epoch=454
05/30/2022 18:51:13 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.11 on epoch=457
05/30/2022 18:51:15 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=459
05/30/2022 18:51:18 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=462
05/30/2022 18:51:19 - INFO - __main__ - Global step 1850 Train loss 0.05 Classification-F1 0.6302211302211302 on epoch=462
05/30/2022 18:51:21 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=464
05/30/2022 18:51:24 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=467
05/30/2022 18:51:26 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.03 on epoch=469
05/30/2022 18:51:29 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=472
05/30/2022 18:51:31 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=474
05/30/2022 18:51:32 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.712959072517896 on epoch=474
05/30/2022 18:51:35 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=477
05/30/2022 18:51:37 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.07 on epoch=479
05/30/2022 18:51:40 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=482
05/30/2022 18:51:42 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=484
05/30/2022 18:51:45 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=487
05/30/2022 18:51:46 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.7497556207233627 on epoch=487
05/30/2022 18:51:46 - INFO - __main__ - Saving model with best Classification-F1: 0.7138323627560035 -> 0.7497556207233627 on epoch=487, global_step=1950
05/30/2022 18:51:48 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=489
05/30/2022 18:51:51 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=492
05/30/2022 18:51:53 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.05 on epoch=494
05/30/2022 18:51:56 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=497
05/30/2022 18:51:58 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=499
05/30/2022 18:51:59 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.7645405669599218 on epoch=499
05/30/2022 18:51:59 - INFO - __main__ - Saving model with best Classification-F1: 0.7497556207233627 -> 0.7645405669599218 on epoch=499, global_step=2000
05/30/2022 18:52:02 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.07 on epoch=502
05/30/2022 18:52:04 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.06 on epoch=504
05/30/2022 18:52:07 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.17 on epoch=507
05/30/2022 18:52:09 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.05 on epoch=509
05/30/2022 18:52:11 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.03 on epoch=512
05/30/2022 18:52:12 - INFO - __main__ - Global step 2050 Train loss 0.08 Classification-F1 0.6727095516569201 on epoch=512
05/30/2022 18:52:15 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=514
05/30/2022 18:52:17 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.04 on epoch=517
05/30/2022 18:52:20 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.04 on epoch=519
05/30/2022 18:52:22 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.03 on epoch=522
05/30/2022 18:52:25 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=524
05/30/2022 18:52:26 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.6753472222222222 on epoch=524
05/30/2022 18:52:28 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=527
05/30/2022 18:52:31 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=529
05/30/2022 18:52:33 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=532
05/30/2022 18:52:36 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=534
05/30/2022 18:52:38 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.04 on epoch=537
05/30/2022 18:52:39 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.7135161135161134 on epoch=537
05/30/2022 18:52:42 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=539
05/30/2022 18:52:44 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=542
05/30/2022 18:52:47 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=544
05/30/2022 18:52:49 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=547
05/30/2022 18:52:52 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=549
05/30/2022 18:52:52 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.6997579966329965 on epoch=549
05/30/2022 18:52:55 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=552
05/30/2022 18:52:57 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=554
05/30/2022 18:53:00 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.06 on epoch=557
05/30/2022 18:53:02 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=559
05/30/2022 18:53:05 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
05/30/2022 18:53:06 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.6745087266826397 on epoch=562
05/30/2022 18:53:08 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=564
05/30/2022 18:53:11 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
05/30/2022 18:53:13 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=569
05/30/2022 18:53:16 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=572
05/30/2022 18:53:18 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=574
05/30/2022 18:53:19 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.6862544030404152 on epoch=574
05/30/2022 18:53:22 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=577
05/30/2022 18:53:24 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=579
05/30/2022 18:53:27 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
05/30/2022 18:53:29 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=584
05/30/2022 18:53:32 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=587
05/30/2022 18:53:33 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.6532674501424501 on epoch=587
05/30/2022 18:53:35 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=589
05/30/2022 18:53:38 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=592
05/30/2022 18:53:40 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
05/30/2022 18:53:43 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.05 on epoch=597
05/30/2022 18:53:45 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=599
05/30/2022 18:53:46 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.6511667917917918 on epoch=599
05/30/2022 18:53:49 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.06 on epoch=602
05/30/2022 18:53:51 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=604
05/30/2022 18:53:54 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=607
05/30/2022 18:53:56 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
05/30/2022 18:53:59 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=612
05/30/2022 18:54:00 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.6790948702713409 on epoch=612
05/30/2022 18:54:02 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=614
05/30/2022 18:54:05 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
05/30/2022 18:54:07 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
05/30/2022 18:54:10 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=622
05/30/2022 18:54:12 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=624
05/30/2022 18:54:13 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.7108962639109698 on epoch=624
05/30/2022 18:54:16 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.07 on epoch=627
05/30/2022 18:54:18 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.05 on epoch=629
05/30/2022 18:54:21 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=632
05/30/2022 18:54:23 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=634
05/30/2022 18:54:26 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=637
05/30/2022 18:54:27 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.6756482198142415 on epoch=637
05/30/2022 18:54:29 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=639
05/30/2022 18:54:32 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
05/30/2022 18:54:34 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
05/30/2022 18:54:37 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=647
05/30/2022 18:54:39 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
05/30/2022 18:54:40 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.6541629945162553 on epoch=649
05/30/2022 18:54:43 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=652
05/30/2022 18:54:45 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
05/30/2022 18:54:48 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=657
05/30/2022 18:54:50 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=659
05/30/2022 18:54:53 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
05/30/2022 18:54:54 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.6985612426788897 on epoch=662
05/30/2022 18:54:56 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
05/30/2022 18:54:59 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
05/30/2022 18:55:01 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=669
05/30/2022 18:55:04 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.03 on epoch=672
05/30/2022 18:55:06 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
05/30/2022 18:55:07 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.6659479069405541 on epoch=674
05/30/2022 18:55:10 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
05/30/2022 18:55:12 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.05 on epoch=679
05/30/2022 18:55:15 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=682
05/30/2022 18:55:17 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=684
05/30/2022 18:55:20 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
05/30/2022 18:55:21 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.6693233082706767 on epoch=687
05/30/2022 18:55:23 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
05/30/2022 18:55:26 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.04 on epoch=692
05/30/2022 18:55:28 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.14 on epoch=694
05/30/2022 18:55:31 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=697
05/30/2022 18:55:33 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=699
05/30/2022 18:55:35 - INFO - __main__ - Global step 2800 Train loss 0.04 Classification-F1 0.6531212322531433 on epoch=699
05/30/2022 18:55:37 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
05/30/2022 18:55:39 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
05/30/2022 18:55:42 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
05/30/2022 18:55:44 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=709
05/30/2022 18:55:47 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.06 on epoch=712
05/30/2022 18:55:48 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.6170293522267206 on epoch=712
05/30/2022 18:55:51 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=714
05/30/2022 18:55:53 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
05/30/2022 18:55:55 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
05/30/2022 18:55:58 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.04 on epoch=722
05/30/2022 18:56:00 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
05/30/2022 18:56:02 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.7216727294591588 on epoch=724
05/30/2022 18:56:04 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=727
05/30/2022 18:56:07 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.03 on epoch=729
05/30/2022 18:56:09 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=732
05/30/2022 18:56:12 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=734
05/30/2022 18:56:14 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=737
05/30/2022 18:56:15 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.7631755800792304 on epoch=737
05/30/2022 18:56:18 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
05/30/2022 18:56:20 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.03 on epoch=742
05/30/2022 18:56:23 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=744
05/30/2022 18:56:25 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=747
05/30/2022 18:56:28 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.07 on epoch=749
05/30/2022 18:56:29 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.7485055934599546 on epoch=749
05/30/2022 18:56:29 - INFO - __main__ - save last model!
05/30/2022 18:56:29 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/30/2022 18:56:29 - INFO - __main__ - Start tokenizing ... 5509 instances
05/30/2022 18:56:29 - INFO - __main__ - Printing 3 examples
05/30/2022 18:56:29 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/30/2022 18:56:29 - INFO - __main__ - ['others']
05/30/2022 18:56:29 - INFO - __main__ -  [emo] what you like very little things ok
05/30/2022 18:56:29 - INFO - __main__ - ['others']
05/30/2022 18:56:29 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/30/2022 18:56:29 - INFO - __main__ - ['others']
05/30/2022 18:56:29 - INFO - __main__ - Tokenizing Input ...
05/30/2022 18:56:29 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 18:56:29 - INFO - __main__ - Printing 3 examples
05/30/2022 18:56:29 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
05/30/2022 18:56:29 - INFO - __main__ - ['sad']
05/30/2022 18:56:29 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
05/30/2022 18:56:29 - INFO - __main__ - ['sad']
05/30/2022 18:56:29 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
05/30/2022 18:56:29 - INFO - __main__ - ['sad']
05/30/2022 18:56:29 - INFO - __main__ - Tokenizing Input ...
05/30/2022 18:56:29 - INFO - __main__ - Tokenizing Output ...
05/30/2022 18:56:29 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 18:56:29 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 18:56:29 - INFO - __main__ - Printing 3 examples
05/30/2022 18:56:29 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
05/30/2022 18:56:29 - INFO - __main__ - ['sad']
05/30/2022 18:56:29 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
05/30/2022 18:56:29 - INFO - __main__ - ['sad']
05/30/2022 18:56:29 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
05/30/2022 18:56:29 - INFO - __main__ - ['sad']
05/30/2022 18:56:29 - INFO - __main__ - Tokenizing Input ...
05/30/2022 18:56:29 - INFO - __main__ - Tokenizing Output ...
05/30/2022 18:56:29 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 18:56:31 - INFO - __main__ - Tokenizing Output ...
05/30/2022 18:56:36 - INFO - __main__ - Loaded 5509 examples from test data
05/30/2022 18:56:48 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 18:56:48 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/30/2022 18:56:48 - INFO - __main__ - Starting training!
05/30/2022 18:58:10 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-24uptasks/singletask-emo/emo_16_13_0.2_8_predictions.txt
05/30/2022 18:58:10 - INFO - __main__ - Classification-F1 on test data: 0.2847
05/30/2022 18:58:10 - INFO - __main__ - prefix=emo_16_13, lr=0.2, bsz=8, dev_performance=0.7645405669599218, test_performance=0.28468248083534586
05/30/2022 18:58:10 - INFO - __main__ - Running ... prefix=emo_16_21, lr=0.5, bsz=8 ...
05/30/2022 18:58:11 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 18:58:11 - INFO - __main__ - Printing 3 examples
05/30/2022 18:58:11 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
05/30/2022 18:58:11 - INFO - __main__ - ['sad']
05/30/2022 18:58:11 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
05/30/2022 18:58:11 - INFO - __main__ - ['sad']
05/30/2022 18:58:11 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
05/30/2022 18:58:11 - INFO - __main__ - ['sad']
05/30/2022 18:58:11 - INFO - __main__ - Tokenizing Input ...
05/30/2022 18:58:11 - INFO - __main__ - Tokenizing Output ...
05/30/2022 18:58:11 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 18:58:11 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 18:58:11 - INFO - __main__ - Printing 3 examples
05/30/2022 18:58:11 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
05/30/2022 18:58:11 - INFO - __main__ - ['sad']
05/30/2022 18:58:11 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
05/30/2022 18:58:11 - INFO - __main__ - ['sad']
05/30/2022 18:58:11 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
05/30/2022 18:58:11 - INFO - __main__ - ['sad']
05/30/2022 18:58:11 - INFO - __main__ - Tokenizing Input ...
05/30/2022 18:58:11 - INFO - __main__ - Tokenizing Output ...
05/30/2022 18:58:11 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 18:58:26 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 18:58:27 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/30/2022 18:58:27 - INFO - __main__ - Starting training!
05/30/2022 18:58:30 - INFO - __main__ - Step 10 Global step 10 Train loss 3.77 on epoch=2
05/30/2022 18:58:32 - INFO - __main__ - Step 20 Global step 20 Train loss 1.87 on epoch=4
05/30/2022 18:58:35 - INFO - __main__ - Step 30 Global step 30 Train loss 1.27 on epoch=7
05/30/2022 18:58:37 - INFO - __main__ - Step 40 Global step 40 Train loss 0.97 on epoch=9
05/30/2022 18:58:40 - INFO - __main__ - Step 50 Global step 50 Train loss 0.99 on epoch=12
05/30/2022 18:58:41 - INFO - __main__ - Global step 50 Train loss 1.77 Classification-F1 0.28172367538564724 on epoch=12
05/30/2022 18:58:41 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.28172367538564724 on epoch=12, global_step=50
05/30/2022 18:58:43 - INFO - __main__ - Step 60 Global step 60 Train loss 0.80 on epoch=14
05/30/2022 18:58:46 - INFO - __main__ - Step 70 Global step 70 Train loss 0.77 on epoch=17
05/30/2022 18:58:48 - INFO - __main__ - Step 80 Global step 80 Train loss 0.70 on epoch=19
05/30/2022 18:58:51 - INFO - __main__ - Step 90 Global step 90 Train loss 0.57 on epoch=22
05/30/2022 18:58:53 - INFO - __main__ - Step 100 Global step 100 Train loss 0.61 on epoch=24
05/30/2022 18:58:54 - INFO - __main__ - Global step 100 Train loss 0.69 Classification-F1 0.550664657508644 on epoch=24
05/30/2022 18:58:54 - INFO - __main__ - Saving model with best Classification-F1: 0.28172367538564724 -> 0.550664657508644 on epoch=24, global_step=100
05/30/2022 18:58:57 - INFO - __main__ - Step 110 Global step 110 Train loss 0.60 on epoch=27
05/30/2022 18:58:59 - INFO - __main__ - Step 120 Global step 120 Train loss 0.65 on epoch=29
05/30/2022 18:59:02 - INFO - __main__ - Step 130 Global step 130 Train loss 0.55 on epoch=32
05/30/2022 18:59:04 - INFO - __main__ - Step 140 Global step 140 Train loss 0.54 on epoch=34
05/30/2022 18:59:07 - INFO - __main__ - Step 150 Global step 150 Train loss 0.48 on epoch=37
05/30/2022 18:59:07 - INFO - __main__ - Global step 150 Train loss 0.56 Classification-F1 0.5438508140286525 on epoch=37
05/30/2022 18:59:10 - INFO - __main__ - Step 160 Global step 160 Train loss 0.40 on epoch=39
05/30/2022 18:59:12 - INFO - __main__ - Step 170 Global step 170 Train loss 0.43 on epoch=42
05/30/2022 18:59:15 - INFO - __main__ - Step 180 Global step 180 Train loss 0.43 on epoch=44
05/30/2022 18:59:17 - INFO - __main__ - Step 190 Global step 190 Train loss 0.44 on epoch=47
05/30/2022 18:59:20 - INFO - __main__ - Step 200 Global step 200 Train loss 0.49 on epoch=49
05/30/2022 18:59:21 - INFO - __main__ - Global step 200 Train loss 0.44 Classification-F1 0.7534316134316135 on epoch=49
05/30/2022 18:59:21 - INFO - __main__ - Saving model with best Classification-F1: 0.550664657508644 -> 0.7534316134316135 on epoch=49, global_step=200
05/30/2022 18:59:23 - INFO - __main__ - Step 210 Global step 210 Train loss 0.33 on epoch=52
05/30/2022 18:59:25 - INFO - __main__ - Step 220 Global step 220 Train loss 0.31 on epoch=54
05/30/2022 18:59:28 - INFO - __main__ - Step 230 Global step 230 Train loss 0.31 on epoch=57
05/30/2022 18:59:30 - INFO - __main__ - Step 240 Global step 240 Train loss 0.39 on epoch=59
05/30/2022 18:59:33 - INFO - __main__ - Step 250 Global step 250 Train loss 0.32 on epoch=62
05/30/2022 18:59:33 - INFO - __main__ - Global step 250 Train loss 0.33 Classification-F1 0.6378068918114685 on epoch=62
05/30/2022 18:59:36 - INFO - __main__ - Step 260 Global step 260 Train loss 0.27 on epoch=64
05/30/2022 18:59:38 - INFO - __main__ - Step 270 Global step 270 Train loss 0.31 on epoch=67
05/30/2022 18:59:41 - INFO - __main__ - Step 280 Global step 280 Train loss 0.24 on epoch=69
05/30/2022 18:59:43 - INFO - __main__ - Step 290 Global step 290 Train loss 0.27 on epoch=72
05/30/2022 18:59:46 - INFO - __main__ - Step 300 Global step 300 Train loss 0.27 on epoch=74
05/30/2022 18:59:46 - INFO - __main__ - Global step 300 Train loss 0.27 Classification-F1 0.7246940559440559 on epoch=74
05/30/2022 18:59:49 - INFO - __main__ - Step 310 Global step 310 Train loss 0.16 on epoch=77
05/30/2022 18:59:51 - INFO - __main__ - Step 320 Global step 320 Train loss 0.17 on epoch=79
05/30/2022 18:59:54 - INFO - __main__ - Step 330 Global step 330 Train loss 0.18 on epoch=82
05/30/2022 18:59:56 - INFO - __main__ - Step 340 Global step 340 Train loss 0.20 on epoch=84
05/30/2022 18:59:58 - INFO - __main__ - Step 350 Global step 350 Train loss 0.09 on epoch=87
05/30/2022 18:59:59 - INFO - __main__ - Global step 350 Train loss 0.16 Classification-F1 0.7141768562821194 on epoch=87
05/30/2022 19:00:02 - INFO - __main__ - Step 360 Global step 360 Train loss 0.18 on epoch=89
05/30/2022 19:00:04 - INFO - __main__ - Step 370 Global step 370 Train loss 0.13 on epoch=92
05/30/2022 19:00:07 - INFO - __main__ - Step 380 Global step 380 Train loss 0.18 on epoch=94
05/30/2022 19:00:09 - INFO - __main__ - Step 390 Global step 390 Train loss 0.14 on epoch=97
05/30/2022 19:00:12 - INFO - __main__ - Step 400 Global step 400 Train loss 0.10 on epoch=99
05/30/2022 19:00:13 - INFO - __main__ - Global step 400 Train loss 0.15 Classification-F1 0.7123373373373373 on epoch=99
05/30/2022 19:00:15 - INFO - __main__ - Step 410 Global step 410 Train loss 0.09 on epoch=102
05/30/2022 19:00:18 - INFO - __main__ - Step 420 Global step 420 Train loss 0.12 on epoch=104
05/30/2022 19:00:20 - INFO - __main__ - Step 430 Global step 430 Train loss 0.16 on epoch=107
05/30/2022 19:00:23 - INFO - __main__ - Step 440 Global step 440 Train loss 0.13 on epoch=109
05/30/2022 19:00:25 - INFO - __main__ - Step 450 Global step 450 Train loss 0.10 on epoch=112
05/30/2022 19:00:26 - INFO - __main__ - Global step 450 Train loss 0.12 Classification-F1 0.7230153540637412 on epoch=112
05/30/2022 19:00:29 - INFO - __main__ - Step 460 Global step 460 Train loss 0.18 on epoch=114
05/30/2022 19:00:31 - INFO - __main__ - Step 470 Global step 470 Train loss 0.10 on epoch=117
05/30/2022 19:00:33 - INFO - __main__ - Step 480 Global step 480 Train loss 0.07 on epoch=119
05/30/2022 19:00:36 - INFO - __main__ - Step 490 Global step 490 Train loss 0.13 on epoch=122
05/30/2022 19:00:38 - INFO - __main__ - Step 500 Global step 500 Train loss 0.08 on epoch=124
05/30/2022 19:00:39 - INFO - __main__ - Global step 500 Train loss 0.11 Classification-F1 0.7171934162423292 on epoch=124
05/30/2022 19:00:42 - INFO - __main__ - Step 510 Global step 510 Train loss 0.06 on epoch=127
05/30/2022 19:00:44 - INFO - __main__ - Step 520 Global step 520 Train loss 0.09 on epoch=129
05/30/2022 19:00:47 - INFO - __main__ - Step 530 Global step 530 Train loss 0.04 on epoch=132
05/30/2022 19:00:49 - INFO - __main__ - Step 540 Global step 540 Train loss 0.08 on epoch=134
05/30/2022 19:00:51 - INFO - __main__ - Step 550 Global step 550 Train loss 0.06 on epoch=137
05/30/2022 19:00:52 - INFO - __main__ - Global step 550 Train loss 0.07 Classification-F1 0.682745324850588 on epoch=137
05/30/2022 19:00:55 - INFO - __main__ - Step 560 Global step 560 Train loss 0.07 on epoch=139
05/30/2022 19:00:57 - INFO - __main__ - Step 570 Global step 570 Train loss 0.08 on epoch=142
05/30/2022 19:01:00 - INFO - __main__ - Step 580 Global step 580 Train loss 0.08 on epoch=144
05/30/2022 19:01:02 - INFO - __main__ - Step 590 Global step 590 Train loss 0.06 on epoch=147
05/30/2022 19:01:05 - INFO - __main__ - Step 600 Global step 600 Train loss 0.05 on epoch=149
05/30/2022 19:01:06 - INFO - __main__ - Global step 600 Train loss 0.07 Classification-F1 0.6957368082368082 on epoch=149
05/30/2022 19:01:08 - INFO - __main__ - Step 610 Global step 610 Train loss 0.08 on epoch=152
05/30/2022 19:01:10 - INFO - __main__ - Step 620 Global step 620 Train loss 0.08 on epoch=154
05/30/2022 19:01:13 - INFO - __main__ - Step 630 Global step 630 Train loss 0.05 on epoch=157
05/30/2022 19:01:15 - INFO - __main__ - Step 640 Global step 640 Train loss 0.05 on epoch=159
05/30/2022 19:01:18 - INFO - __main__ - Step 650 Global step 650 Train loss 0.04 on epoch=162
05/30/2022 19:01:19 - INFO - __main__ - Global step 650 Train loss 0.06 Classification-F1 0.7102219198993392 on epoch=162
05/30/2022 19:01:21 - INFO - __main__ - Step 660 Global step 660 Train loss 0.02 on epoch=164
05/30/2022 19:01:24 - INFO - __main__ - Step 670 Global step 670 Train loss 0.03 on epoch=167
05/30/2022 19:01:26 - INFO - __main__ - Step 680 Global step 680 Train loss 0.13 on epoch=169
05/30/2022 19:01:29 - INFO - __main__ - Step 690 Global step 690 Train loss 0.10 on epoch=172
05/30/2022 19:01:31 - INFO - __main__ - Step 700 Global step 700 Train loss 0.02 on epoch=174
05/30/2022 19:01:32 - INFO - __main__ - Global step 700 Train loss 0.06 Classification-F1 0.6717948717948719 on epoch=174
05/30/2022 19:01:34 - INFO - __main__ - Step 710 Global step 710 Train loss 0.09 on epoch=177
05/30/2022 19:01:37 - INFO - __main__ - Step 720 Global step 720 Train loss 0.08 on epoch=179
05/30/2022 19:01:39 - INFO - __main__ - Step 730 Global step 730 Train loss 0.03 on epoch=182
05/30/2022 19:01:42 - INFO - __main__ - Step 740 Global step 740 Train loss 0.01 on epoch=184
05/30/2022 19:01:44 - INFO - __main__ - Step 750 Global step 750 Train loss 0.02 on epoch=187
05/30/2022 19:01:45 - INFO - __main__ - Global step 750 Train loss 0.04 Classification-F1 0.7534843143538796 on epoch=187
05/30/2022 19:01:45 - INFO - __main__ - Saving model with best Classification-F1: 0.7534316134316135 -> 0.7534843143538796 on epoch=187, global_step=750
05/30/2022 19:01:47 - INFO - __main__ - Step 760 Global step 760 Train loss 0.07 on epoch=189
05/30/2022 19:01:50 - INFO - __main__ - Step 770 Global step 770 Train loss 0.02 on epoch=192
05/30/2022 19:01:52 - INFO - __main__ - Step 780 Global step 780 Train loss 0.01 on epoch=194
05/30/2022 19:01:55 - INFO - __main__ - Step 790 Global step 790 Train loss 0.06 on epoch=197
05/30/2022 19:01:57 - INFO - __main__ - Step 800 Global step 800 Train loss 0.05 on epoch=199
05/30/2022 19:01:58 - INFO - __main__ - Global step 800 Train loss 0.04 Classification-F1 0.7329545454545455 on epoch=199
05/30/2022 19:02:00 - INFO - __main__ - Step 810 Global step 810 Train loss 0.03 on epoch=202
05/30/2022 19:02:03 - INFO - __main__ - Step 820 Global step 820 Train loss 0.05 on epoch=204
05/30/2022 19:02:05 - INFO - __main__ - Step 830 Global step 830 Train loss 0.04 on epoch=207
05/30/2022 19:02:08 - INFO - __main__ - Step 840 Global step 840 Train loss 0.07 on epoch=209
05/30/2022 19:02:10 - INFO - __main__ - Step 850 Global step 850 Train loss 0.01 on epoch=212
05/30/2022 19:02:11 - INFO - __main__ - Global step 850 Train loss 0.04 Classification-F1 0.7178670147420146 on epoch=212
05/30/2022 19:02:14 - INFO - __main__ - Step 860 Global step 860 Train loss 0.03 on epoch=214
05/30/2022 19:02:16 - INFO - __main__ - Step 870 Global step 870 Train loss 0.02 on epoch=217
05/30/2022 19:02:18 - INFO - __main__ - Step 880 Global step 880 Train loss 0.01 on epoch=219
05/30/2022 19:02:21 - INFO - __main__ - Step 890 Global step 890 Train loss 0.03 on epoch=222
05/30/2022 19:02:23 - INFO - __main__ - Step 900 Global step 900 Train loss 0.01 on epoch=224
05/30/2022 19:02:24 - INFO - __main__ - Global step 900 Train loss 0.02 Classification-F1 0.7524460601906254 on epoch=224
05/30/2022 19:02:27 - INFO - __main__ - Step 910 Global step 910 Train loss 0.05 on epoch=227
05/30/2022 19:02:29 - INFO - __main__ - Step 920 Global step 920 Train loss 0.05 on epoch=229
05/30/2022 19:02:32 - INFO - __main__ - Step 930 Global step 930 Train loss 0.06 on epoch=232
05/30/2022 19:02:34 - INFO - __main__ - Step 940 Global step 940 Train loss 0.06 on epoch=234
05/30/2022 19:02:36 - INFO - __main__ - Step 950 Global step 950 Train loss 0.02 on epoch=237
05/30/2022 19:02:37 - INFO - __main__ - Global step 950 Train loss 0.05 Classification-F1 0.7042547182349814 on epoch=237
05/30/2022 19:02:40 - INFO - __main__ - Step 960 Global step 960 Train loss 0.01 on epoch=239
05/30/2022 19:02:42 - INFO - __main__ - Step 970 Global step 970 Train loss 0.01 on epoch=242
05/30/2022 19:02:45 - INFO - __main__ - Step 980 Global step 980 Train loss 0.01 on epoch=244
05/30/2022 19:02:47 - INFO - __main__ - Step 990 Global step 990 Train loss 0.01 on epoch=247
05/30/2022 19:02:50 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.01 on epoch=249
05/30/2022 19:02:51 - INFO - __main__ - Global step 1000 Train loss 0.01 Classification-F1 0.7317963286713286 on epoch=249
05/30/2022 19:02:53 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.01 on epoch=252
05/30/2022 19:02:56 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.02 on epoch=254
05/30/2022 19:02:58 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.17 on epoch=257
05/30/2022 19:03:01 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.01 on epoch=259
05/30/2022 19:03:03 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.01 on epoch=262
05/30/2022 19:03:04 - INFO - __main__ - Global step 1050 Train loss 0.04 Classification-F1 0.7790467887242081 on epoch=262
05/30/2022 19:03:04 - INFO - __main__ - Saving model with best Classification-F1: 0.7534843143538796 -> 0.7790467887242081 on epoch=262, global_step=1050
05/30/2022 19:03:06 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.04 on epoch=264
05/30/2022 19:03:09 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.02 on epoch=267
05/30/2022 19:03:11 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.01 on epoch=269
05/30/2022 19:03:14 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.03 on epoch=272
05/30/2022 19:03:16 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.07 on epoch=274
05/30/2022 19:03:18 - INFO - __main__ - Global step 1100 Train loss 0.03 Classification-F1 0.7313015018607123 on epoch=274
05/30/2022 19:03:20 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.01 on epoch=277
05/30/2022 19:03:23 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=279
05/30/2022 19:03:25 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.09 on epoch=282
05/30/2022 19:03:28 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.01 on epoch=284
05/30/2022 19:03:30 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.04 on epoch=287
05/30/2022 19:03:31 - INFO - __main__ - Global step 1150 Train loss 0.03 Classification-F1 0.6846218814968814 on epoch=287
05/30/2022 19:03:34 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.05 on epoch=289
05/30/2022 19:03:36 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.01 on epoch=292
05/30/2022 19:03:38 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.01 on epoch=294
05/30/2022 19:03:41 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.01 on epoch=297
05/30/2022 19:03:43 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=299
05/30/2022 19:03:45 - INFO - __main__ - Global step 1200 Train loss 0.02 Classification-F1 0.7313015018607123 on epoch=299
05/30/2022 19:03:47 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.01 on epoch=302
05/30/2022 19:03:50 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=304
05/30/2022 19:03:52 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=307
05/30/2022 19:03:55 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.00 on epoch=309
05/30/2022 19:03:57 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.00 on epoch=312
05/30/2022 19:03:58 - INFO - __main__ - Global step 1250 Train loss 0.01 Classification-F1 0.7089247557997558 on epoch=312
05/30/2022 19:04:01 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=314
05/30/2022 19:04:03 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.00 on epoch=317
05/30/2022 19:04:06 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.00 on epoch=319
05/30/2022 19:04:08 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=322
05/30/2022 19:04:11 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.03 on epoch=324
05/30/2022 19:04:12 - INFO - __main__ - Global step 1300 Train loss 0.01 Classification-F1 0.731833384007297 on epoch=324
05/30/2022 19:04:14 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.00 on epoch=327
05/30/2022 19:04:17 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=329
05/30/2022 19:04:19 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.02 on epoch=332
05/30/2022 19:04:22 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=334
05/30/2022 19:04:24 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.07 on epoch=337
05/30/2022 19:04:25 - INFO - __main__ - Global step 1350 Train loss 0.02 Classification-F1 0.7722808105872622 on epoch=337
05/30/2022 19:04:28 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.03 on epoch=339
05/30/2022 19:04:30 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.02 on epoch=342
05/30/2022 19:04:33 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.15 on epoch=344
05/30/2022 19:04:35 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.00 on epoch=347
05/30/2022 19:04:38 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=349
05/30/2022 19:04:39 - INFO - __main__ - Global step 1400 Train loss 0.04 Classification-F1 0.7159493712192595 on epoch=349
05/30/2022 19:04:41 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=352
05/30/2022 19:04:44 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=354
05/30/2022 19:04:46 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=357
05/30/2022 19:04:49 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=359
05/30/2022 19:04:52 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.04 on epoch=362
05/30/2022 19:04:53 - INFO - __main__ - Global step 1450 Train loss 0.01 Classification-F1 0.7313015018607123 on epoch=362
05/30/2022 19:04:55 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=364
05/30/2022 19:04:58 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=367
05/30/2022 19:05:00 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=369
05/30/2022 19:05:03 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=372
05/30/2022 19:05:05 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.02 on epoch=374
05/30/2022 19:05:06 - INFO - __main__ - Global step 1500 Train loss 0.01 Classification-F1 0.7325986659602958 on epoch=374
05/30/2022 19:05:09 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=377
05/30/2022 19:05:11 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.07 on epoch=379
05/30/2022 19:05:14 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=382
05/30/2022 19:05:16 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=384
05/30/2022 19:05:19 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=387
05/30/2022 19:05:20 - INFO - __main__ - Global step 1550 Train loss 0.02 Classification-F1 0.7325986659602958 on epoch=387
05/30/2022 19:05:22 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=389
05/30/2022 19:05:25 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=392
05/30/2022 19:05:27 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=394
05/30/2022 19:05:30 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=397
05/30/2022 19:05:32 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=399
05/30/2022 19:05:34 - INFO - __main__ - Global step 1600 Train loss 0.01 Classification-F1 0.7103039857708788 on epoch=399
05/30/2022 19:05:36 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=402
05/30/2022 19:05:39 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=404
05/30/2022 19:05:41 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=407
05/30/2022 19:05:44 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.05 on epoch=409
05/30/2022 19:05:46 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=412
05/30/2022 19:05:47 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.734609250398724 on epoch=412
05/30/2022 19:05:50 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=414
05/30/2022 19:05:52 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=417
05/30/2022 19:05:55 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=419
05/30/2022 19:05:57 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=422
05/30/2022 19:06:00 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=424
05/30/2022 19:06:01 - INFO - __main__ - Global step 1700 Train loss 0.01 Classification-F1 0.7304566563467492 on epoch=424
05/30/2022 19:06:04 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=427
05/30/2022 19:06:06 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.04 on epoch=429
05/30/2022 19:06:09 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.12 on epoch=432
05/30/2022 19:06:11 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.04 on epoch=434
05/30/2022 19:06:14 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=437
05/30/2022 19:06:15 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.7313015018607123 on epoch=437
05/30/2022 19:06:17 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=439
05/30/2022 19:06:20 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=442
05/30/2022 19:06:22 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=444
05/30/2022 19:06:25 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.03 on epoch=447
05/30/2022 19:06:27 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=449
05/30/2022 19:06:28 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.7327931924706118 on epoch=449
05/30/2022 19:06:31 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=452
05/30/2022 19:06:33 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=454
05/30/2022 19:06:36 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=457
05/30/2022 19:06:38 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=459
05/30/2022 19:06:41 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.12 on epoch=462
05/30/2022 19:06:42 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.7325986659602958 on epoch=462
05/30/2022 19:06:45 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=464
05/30/2022 19:06:47 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=467
05/30/2022 19:06:50 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.03 on epoch=469
05/30/2022 19:06:52 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=472
05/30/2022 19:06:55 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=474
05/30/2022 19:06:56 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.7161185432924564 on epoch=474
05/30/2022 19:06:58 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=477
05/30/2022 19:07:01 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=479
05/30/2022 19:07:03 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=482
05/30/2022 19:07:06 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.08 on epoch=484
05/30/2022 19:07:08 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=487
05/30/2022 19:07:09 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.7306810306810306 on epoch=487
05/30/2022 19:07:12 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=489
05/30/2022 19:07:14 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=492
05/30/2022 19:07:17 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=494
05/30/2022 19:07:19 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=497
05/30/2022 19:07:22 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=499
05/30/2022 19:07:23 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.7306651069518717 on epoch=499
05/30/2022 19:07:26 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=502
05/30/2022 19:07:28 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
05/30/2022 19:07:31 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
05/30/2022 19:07:33 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=509
05/30/2022 19:07:36 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
05/30/2022 19:07:37 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.729864458325136 on epoch=512
05/30/2022 19:07:39 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=514
05/30/2022 19:07:42 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=517
05/30/2022 19:07:44 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.03 on epoch=519
05/30/2022 19:07:47 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
05/30/2022 19:07:49 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=524
05/30/2022 19:07:50 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.7453709893048129 on epoch=524
05/30/2022 19:07:53 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
05/30/2022 19:07:55 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
05/30/2022 19:07:58 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.12 on epoch=532
05/30/2022 19:08:00 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
05/30/2022 19:08:03 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
05/30/2022 19:08:04 - INFO - __main__ - Global step 2150 Train loss 0.03 Classification-F1 0.7305294795783926 on epoch=537
05/30/2022 19:08:07 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=539
05/30/2022 19:08:09 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
05/30/2022 19:08:12 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=544
05/30/2022 19:08:14 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=547
05/30/2022 19:08:17 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=549
05/30/2022 19:08:18 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.7075757575757576 on epoch=549
05/30/2022 19:08:20 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=552
05/30/2022 19:08:23 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
05/30/2022 19:08:25 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.07 on epoch=557
05/30/2022 19:08:28 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
05/30/2022 19:08:30 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
05/30/2022 19:08:31 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.688293131841519 on epoch=562
05/30/2022 19:08:34 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
05/30/2022 19:08:36 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
05/30/2022 19:08:39 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
05/30/2022 19:08:41 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=572
05/30/2022 19:08:44 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
05/30/2022 19:08:45 - INFO - __main__ - Global step 2300 Train loss 0.00 Classification-F1 0.7094438188188188 on epoch=574
05/30/2022 19:08:47 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
05/30/2022 19:08:50 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=579
05/30/2022 19:08:53 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=582
05/30/2022 19:08:55 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
05/30/2022 19:08:58 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
05/30/2022 19:08:59 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.7166424893756129 on epoch=587
05/30/2022 19:09:01 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
05/30/2022 19:09:04 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
05/30/2022 19:09:06 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
05/30/2022 19:09:09 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=597
05/30/2022 19:09:11 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
05/30/2022 19:09:12 - INFO - __main__ - Global step 2400 Train loss 0.00 Classification-F1 0.6884518620002491 on epoch=599
05/30/2022 19:09:15 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
05/30/2022 19:09:17 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
05/30/2022 19:09:20 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
05/30/2022 19:09:22 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
05/30/2022 19:09:25 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
05/30/2022 19:09:26 - INFO - __main__ - Global step 2450 Train loss 0.00 Classification-F1 0.7016310938636915 on epoch=612
05/30/2022 19:09:28 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
05/30/2022 19:09:31 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
05/30/2022 19:09:34 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.04 on epoch=619
05/30/2022 19:09:36 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.03 on epoch=622
05/30/2022 19:09:39 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
05/30/2022 19:09:40 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.6959032195874302 on epoch=624
05/30/2022 19:09:42 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=627
05/30/2022 19:09:45 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=629
05/30/2022 19:09:47 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
05/30/2022 19:09:50 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
05/30/2022 19:09:52 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
05/30/2022 19:09:53 - INFO - __main__ - Global step 2550 Train loss 0.00 Classification-F1 0.7157532051282052 on epoch=637
05/30/2022 19:09:56 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
05/30/2022 19:09:58 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
05/30/2022 19:10:01 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
05/30/2022 19:10:03 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
05/30/2022 19:10:06 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
05/30/2022 19:10:07 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.7313015018607123 on epoch=649
05/30/2022 19:10:10 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=652
05/30/2022 19:10:12 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
05/30/2022 19:10:15 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
05/30/2022 19:10:17 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
05/30/2022 19:10:20 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
05/30/2022 19:10:21 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.7087302292894397 on epoch=662
05/30/2022 19:10:23 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
05/30/2022 19:10:26 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
05/30/2022 19:10:28 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=669
05/30/2022 19:10:31 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
05/30/2022 19:10:34 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
05/30/2022 19:10:35 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.7302229020979021 on epoch=674
05/30/2022 19:10:37 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
05/30/2022 19:10:40 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
05/30/2022 19:10:42 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
05/30/2022 19:10:45 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
05/30/2022 19:10:47 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=687
05/30/2022 19:10:48 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.7445703406780773 on epoch=687
05/30/2022 19:10:51 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
05/30/2022 19:10:53 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
05/30/2022 19:10:56 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
05/30/2022 19:10:58 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
05/30/2022 19:11:01 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
05/30/2022 19:11:02 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.7446168414918415 on epoch=699
05/30/2022 19:11:05 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
05/30/2022 19:11:07 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=704
05/30/2022 19:11:10 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
05/30/2022 19:11:12 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
05/30/2022 19:11:15 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
05/30/2022 19:11:16 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.7179425837320574 on epoch=712
05/30/2022 19:11:18 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
05/30/2022 19:11:21 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
05/30/2022 19:11:23 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
05/30/2022 19:11:26 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
05/30/2022 19:11:28 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
05/30/2022 19:11:29 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.7325986659602958 on epoch=724
05/30/2022 19:11:32 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
05/30/2022 19:11:35 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
05/30/2022 19:11:37 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
05/30/2022 19:11:40 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
05/30/2022 19:11:42 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
05/30/2022 19:11:43 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.7309546928060251 on epoch=737
05/30/2022 19:11:46 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=739
05/30/2022 19:11:48 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
05/30/2022 19:11:51 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
05/30/2022 19:11:53 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
05/30/2022 19:11:56 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
05/30/2022 19:11:57 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.7325986659602958 on epoch=749
05/30/2022 19:11:57 - INFO - __main__ - save last model!
05/30/2022 19:11:57 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/30/2022 19:11:57 - INFO - __main__ - Start tokenizing ... 5509 instances
05/30/2022 19:11:57 - INFO - __main__ - Printing 3 examples
05/30/2022 19:11:57 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/30/2022 19:11:57 - INFO - __main__ - ['others']
05/30/2022 19:11:57 - INFO - __main__ -  [emo] what you like very little things ok
05/30/2022 19:11:57 - INFO - __main__ - ['others']
05/30/2022 19:11:57 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/30/2022 19:11:57 - INFO - __main__ - ['others']
05/30/2022 19:11:57 - INFO - __main__ - Tokenizing Input ...
05/30/2022 19:11:57 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 19:11:57 - INFO - __main__ - Printing 3 examples
05/30/2022 19:11:57 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
05/30/2022 19:11:57 - INFO - __main__ - ['sad']
05/30/2022 19:11:57 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
05/30/2022 19:11:57 - INFO - __main__ - ['sad']
05/30/2022 19:11:57 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
05/30/2022 19:11:57 - INFO - __main__ - ['sad']
05/30/2022 19:11:57 - INFO - __main__ - Tokenizing Input ...
05/30/2022 19:11:57 - INFO - __main__ - Tokenizing Output ...
05/30/2022 19:11:57 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 19:11:57 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 19:11:57 - INFO - __main__ - Printing 3 examples
05/30/2022 19:11:57 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
05/30/2022 19:11:57 - INFO - __main__ - ['sad']
05/30/2022 19:11:57 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
05/30/2022 19:11:57 - INFO - __main__ - ['sad']
05/30/2022 19:11:57 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
05/30/2022 19:11:57 - INFO - __main__ - ['sad']
05/30/2022 19:11:57 - INFO - __main__ - Tokenizing Input ...
05/30/2022 19:11:57 - INFO - __main__ - Tokenizing Output ...
05/30/2022 19:11:57 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 19:11:59 - INFO - __main__ - Tokenizing Output ...
05/30/2022 19:12:05 - INFO - __main__ - Loaded 5509 examples from test data
05/30/2022 19:12:16 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 19:12:17 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/30/2022 19:12:17 - INFO - __main__ - Starting training!
05/30/2022 19:13:39 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-24uptasks/singletask-emo/emo_16_21_0.5_8_predictions.txt
05/30/2022 19:13:39 - INFO - __main__ - Classification-F1 on test data: 0.1694
05/30/2022 19:13:40 - INFO - __main__ - prefix=emo_16_21, lr=0.5, bsz=8, dev_performance=0.7790467887242081, test_performance=0.16937307276619962
05/30/2022 19:13:40 - INFO - __main__ - Running ... prefix=emo_16_21, lr=0.4, bsz=8 ...
05/30/2022 19:13:41 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 19:13:41 - INFO - __main__ - Printing 3 examples
05/30/2022 19:13:41 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
05/30/2022 19:13:41 - INFO - __main__ - ['sad']
05/30/2022 19:13:41 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
05/30/2022 19:13:41 - INFO - __main__ - ['sad']
05/30/2022 19:13:41 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
05/30/2022 19:13:41 - INFO - __main__ - ['sad']
05/30/2022 19:13:41 - INFO - __main__ - Tokenizing Input ...
05/30/2022 19:13:41 - INFO - __main__ - Tokenizing Output ...
05/30/2022 19:13:41 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 19:13:41 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 19:13:41 - INFO - __main__ - Printing 3 examples
05/30/2022 19:13:41 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
05/30/2022 19:13:41 - INFO - __main__ - ['sad']
05/30/2022 19:13:41 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
05/30/2022 19:13:41 - INFO - __main__ - ['sad']
05/30/2022 19:13:41 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
05/30/2022 19:13:41 - INFO - __main__ - ['sad']
05/30/2022 19:13:41 - INFO - __main__ - Tokenizing Input ...
05/30/2022 19:13:41 - INFO - __main__ - Tokenizing Output ...
05/30/2022 19:13:41 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 19:13:56 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 19:13:57 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/30/2022 19:13:57 - INFO - __main__ - Starting training!
05/30/2022 19:14:00 - INFO - __main__ - Step 10 Global step 10 Train loss 3.96 on epoch=2
05/30/2022 19:14:02 - INFO - __main__ - Step 20 Global step 20 Train loss 2.08 on epoch=4
05/30/2022 19:14:05 - INFO - __main__ - Step 30 Global step 30 Train loss 1.57 on epoch=7
05/30/2022 19:14:07 - INFO - __main__ - Step 40 Global step 40 Train loss 1.01 on epoch=9
05/30/2022 19:14:10 - INFO - __main__ - Step 50 Global step 50 Train loss 0.92 on epoch=12
05/30/2022 19:14:11 - INFO - __main__ - Global step 50 Train loss 1.91 Classification-F1 0.29327197303603836 on epoch=12
05/30/2022 19:14:11 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.29327197303603836 on epoch=12, global_step=50
05/30/2022 19:14:13 - INFO - __main__ - Step 60 Global step 60 Train loss 0.85 on epoch=14
05/30/2022 19:14:16 - INFO - __main__ - Step 70 Global step 70 Train loss 0.84 on epoch=17
05/30/2022 19:14:18 - INFO - __main__ - Step 80 Global step 80 Train loss 0.76 on epoch=19
05/30/2022 19:14:20 - INFO - __main__ - Step 90 Global step 90 Train loss 0.63 on epoch=22
05/30/2022 19:14:23 - INFO - __main__ - Step 100 Global step 100 Train loss 0.77 on epoch=24
05/30/2022 19:14:24 - INFO - __main__ - Global step 100 Train loss 0.77 Classification-F1 0.4789219015280136 on epoch=24
05/30/2022 19:14:24 - INFO - __main__ - Saving model with best Classification-F1: 0.29327197303603836 -> 0.4789219015280136 on epoch=24, global_step=100
05/30/2022 19:14:26 - INFO - __main__ - Step 110 Global step 110 Train loss 0.81 on epoch=27
05/30/2022 19:14:29 - INFO - __main__ - Step 120 Global step 120 Train loss 0.57 on epoch=29
05/30/2022 19:14:31 - INFO - __main__ - Step 130 Global step 130 Train loss 0.69 on epoch=32
05/30/2022 19:14:34 - INFO - __main__ - Step 140 Global step 140 Train loss 0.70 on epoch=34
05/30/2022 19:14:36 - INFO - __main__ - Step 150 Global step 150 Train loss 0.55 on epoch=37
05/30/2022 19:14:37 - INFO - __main__ - Global step 150 Train loss 0.66 Classification-F1 0.6821862348178138 on epoch=37
05/30/2022 19:14:37 - INFO - __main__ - Saving model with best Classification-F1: 0.4789219015280136 -> 0.6821862348178138 on epoch=37, global_step=150
05/30/2022 19:14:40 - INFO - __main__ - Step 160 Global step 160 Train loss 0.54 on epoch=39
05/30/2022 19:14:42 - INFO - __main__ - Step 170 Global step 170 Train loss 0.54 on epoch=42
05/30/2022 19:14:45 - INFO - __main__ - Step 180 Global step 180 Train loss 0.50 on epoch=44
05/30/2022 19:14:47 - INFO - __main__ - Step 190 Global step 190 Train loss 0.52 on epoch=47
05/30/2022 19:14:50 - INFO - __main__ - Step 200 Global step 200 Train loss 0.43 on epoch=49
05/30/2022 19:14:50 - INFO - __main__ - Global step 200 Train loss 0.51 Classification-F1 0.7088402825244932 on epoch=49
05/30/2022 19:14:50 - INFO - __main__ - Saving model with best Classification-F1: 0.6821862348178138 -> 0.7088402825244932 on epoch=49, global_step=200
05/30/2022 19:14:53 - INFO - __main__ - Step 210 Global step 210 Train loss 0.53 on epoch=52
05/30/2022 19:14:55 - INFO - __main__ - Step 220 Global step 220 Train loss 0.50 on epoch=54
05/30/2022 19:14:58 - INFO - __main__ - Step 230 Global step 230 Train loss 0.46 on epoch=57
05/30/2022 19:15:00 - INFO - __main__ - Step 240 Global step 240 Train loss 0.49 on epoch=59
05/30/2022 19:15:03 - INFO - __main__ - Step 250 Global step 250 Train loss 0.30 on epoch=62
05/30/2022 19:15:04 - INFO - __main__ - Global step 250 Train loss 0.46 Classification-F1 0.7103857572607573 on epoch=62
05/30/2022 19:15:04 - INFO - __main__ - Saving model with best Classification-F1: 0.7088402825244932 -> 0.7103857572607573 on epoch=62, global_step=250
05/30/2022 19:15:06 - INFO - __main__ - Step 260 Global step 260 Train loss 0.35 on epoch=64
05/30/2022 19:15:09 - INFO - __main__ - Step 270 Global step 270 Train loss 0.42 on epoch=67
05/30/2022 19:15:11 - INFO - __main__ - Step 280 Global step 280 Train loss 0.27 on epoch=69
05/30/2022 19:15:14 - INFO - __main__ - Step 290 Global step 290 Train loss 0.22 on epoch=72
05/30/2022 19:15:16 - INFO - __main__ - Step 300 Global step 300 Train loss 0.22 on epoch=74
05/30/2022 19:15:17 - INFO - __main__ - Global step 300 Train loss 0.30 Classification-F1 0.7149184149184149 on epoch=74
05/30/2022 19:15:17 - INFO - __main__ - Saving model with best Classification-F1: 0.7103857572607573 -> 0.7149184149184149 on epoch=74, global_step=300
05/30/2022 19:15:19 - INFO - __main__ - Step 310 Global step 310 Train loss 0.24 on epoch=77
05/30/2022 19:15:22 - INFO - __main__ - Step 320 Global step 320 Train loss 0.23 on epoch=79
05/30/2022 19:15:24 - INFO - __main__ - Step 330 Global step 330 Train loss 0.19 on epoch=82
05/30/2022 19:15:27 - INFO - __main__ - Step 340 Global step 340 Train loss 0.26 on epoch=84
05/30/2022 19:15:29 - INFO - __main__ - Step 350 Global step 350 Train loss 0.18 on epoch=87
05/30/2022 19:15:30 - INFO - __main__ - Global step 350 Train loss 0.22 Classification-F1 0.6740339073082201 on epoch=87
05/30/2022 19:15:33 - INFO - __main__ - Step 360 Global step 360 Train loss 0.17 on epoch=89
05/30/2022 19:15:35 - INFO - __main__ - Step 370 Global step 370 Train loss 0.18 on epoch=92
05/30/2022 19:15:38 - INFO - __main__ - Step 380 Global step 380 Train loss 0.19 on epoch=94
05/30/2022 19:15:40 - INFO - __main__ - Step 390 Global step 390 Train loss 0.20 on epoch=97
05/30/2022 19:15:43 - INFO - __main__ - Step 400 Global step 400 Train loss 0.16 on epoch=99
05/30/2022 19:15:43 - INFO - __main__ - Global step 400 Train loss 0.18 Classification-F1 0.6194542847503374 on epoch=99
05/30/2022 19:15:46 - INFO - __main__ - Step 410 Global step 410 Train loss 0.16 on epoch=102
05/30/2022 19:15:48 - INFO - __main__ - Step 420 Global step 420 Train loss 0.10 on epoch=104
05/30/2022 19:15:51 - INFO - __main__ - Step 430 Global step 430 Train loss 0.15 on epoch=107
05/30/2022 19:15:53 - INFO - __main__ - Step 440 Global step 440 Train loss 0.18 on epoch=109
05/30/2022 19:15:56 - INFO - __main__ - Step 450 Global step 450 Train loss 0.12 on epoch=112
05/30/2022 19:15:57 - INFO - __main__ - Global step 450 Train loss 0.14 Classification-F1 0.6720381969294099 on epoch=112
05/30/2022 19:15:59 - INFO - __main__ - Step 460 Global step 460 Train loss 0.09 on epoch=114
05/30/2022 19:16:02 - INFO - __main__ - Step 470 Global step 470 Train loss 0.14 on epoch=117
05/30/2022 19:16:04 - INFO - __main__ - Step 480 Global step 480 Train loss 0.09 on epoch=119
05/30/2022 19:16:06 - INFO - __main__ - Step 490 Global step 490 Train loss 0.10 on epoch=122
05/30/2022 19:16:09 - INFO - __main__ - Step 500 Global step 500 Train loss 0.15 on epoch=124
05/30/2022 19:16:10 - INFO - __main__ - Global step 500 Train loss 0.11 Classification-F1 0.6600694444444444 on epoch=124
05/30/2022 19:16:12 - INFO - __main__ - Step 510 Global step 510 Train loss 0.11 on epoch=127
05/30/2022 19:16:15 - INFO - __main__ - Step 520 Global step 520 Train loss 0.08 on epoch=129
05/30/2022 19:16:17 - INFO - __main__ - Step 530 Global step 530 Train loss 0.10 on epoch=132
05/30/2022 19:16:20 - INFO - __main__ - Step 540 Global step 540 Train loss 0.07 on epoch=134
05/30/2022 19:16:22 - INFO - __main__ - Step 550 Global step 550 Train loss 0.05 on epoch=137
05/30/2022 19:16:23 - INFO - __main__ - Global step 550 Train loss 0.08 Classification-F1 0.687255833597297 on epoch=137
05/30/2022 19:16:26 - INFO - __main__ - Step 560 Global step 560 Train loss 0.04 on epoch=139
05/30/2022 19:16:28 - INFO - __main__ - Step 570 Global step 570 Train loss 0.10 on epoch=142
05/30/2022 19:16:30 - INFO - __main__ - Step 580 Global step 580 Train loss 0.13 on epoch=144
05/30/2022 19:16:33 - INFO - __main__ - Step 590 Global step 590 Train loss 0.05 on epoch=147
05/30/2022 19:16:35 - INFO - __main__ - Step 600 Global step 600 Train loss 0.06 on epoch=149
05/30/2022 19:16:36 - INFO - __main__ - Global step 600 Train loss 0.08 Classification-F1 0.7319250674606104 on epoch=149
05/30/2022 19:16:36 - INFO - __main__ - Saving model with best Classification-F1: 0.7149184149184149 -> 0.7319250674606104 on epoch=149, global_step=600
05/30/2022 19:16:39 - INFO - __main__ - Step 610 Global step 610 Train loss 0.04 on epoch=152
05/30/2022 19:16:41 - INFO - __main__ - Step 620 Global step 620 Train loss 0.05 on epoch=154
05/30/2022 19:16:44 - INFO - __main__ - Step 630 Global step 630 Train loss 0.08 on epoch=157
05/30/2022 19:16:46 - INFO - __main__ - Step 640 Global step 640 Train loss 0.05 on epoch=159
05/30/2022 19:16:49 - INFO - __main__ - Step 650 Global step 650 Train loss 0.04 on epoch=162
05/30/2022 19:16:50 - INFO - __main__ - Global step 650 Train loss 0.05 Classification-F1 0.7739065551565552 on epoch=162
05/30/2022 19:16:50 - INFO - __main__ - Saving model with best Classification-F1: 0.7319250674606104 -> 0.7739065551565552 on epoch=162, global_step=650
05/30/2022 19:16:52 - INFO - __main__ - Step 660 Global step 660 Train loss 0.02 on epoch=164
05/30/2022 19:16:55 - INFO - __main__ - Step 670 Global step 670 Train loss 0.05 on epoch=167
05/30/2022 19:16:57 - INFO - __main__ - Step 680 Global step 680 Train loss 0.11 on epoch=169
05/30/2022 19:17:00 - INFO - __main__ - Step 690 Global step 690 Train loss 0.04 on epoch=172
05/30/2022 19:17:02 - INFO - __main__ - Step 700 Global step 700 Train loss 0.05 on epoch=174
05/30/2022 19:17:03 - INFO - __main__ - Global step 700 Train loss 0.05 Classification-F1 0.7598553116379942 on epoch=174
05/30/2022 19:17:05 - INFO - __main__ - Step 710 Global step 710 Train loss 0.02 on epoch=177
05/30/2022 19:17:08 - INFO - __main__ - Step 720 Global step 720 Train loss 0.03 on epoch=179
05/30/2022 19:17:10 - INFO - __main__ - Step 730 Global step 730 Train loss 0.05 on epoch=182
05/30/2022 19:17:13 - INFO - __main__ - Step 740 Global step 740 Train loss 0.08 on epoch=184
05/30/2022 19:17:15 - INFO - __main__ - Step 750 Global step 750 Train loss 0.06 on epoch=187
05/30/2022 19:17:16 - INFO - __main__ - Global step 750 Train loss 0.05 Classification-F1 0.6717628107430739 on epoch=187
05/30/2022 19:17:19 - INFO - __main__ - Step 760 Global step 760 Train loss 0.03 on epoch=189
05/30/2022 19:17:21 - INFO - __main__ - Step 770 Global step 770 Train loss 0.12 on epoch=192
05/30/2022 19:17:24 - INFO - __main__ - Step 780 Global step 780 Train loss 0.06 on epoch=194
05/30/2022 19:17:26 - INFO - __main__ - Step 790 Global step 790 Train loss 0.02 on epoch=197
05/30/2022 19:17:29 - INFO - __main__ - Step 800 Global step 800 Train loss 0.02 on epoch=199
05/30/2022 19:17:30 - INFO - __main__ - Global step 800 Train loss 0.05 Classification-F1 0.7324198942712266 on epoch=199
05/30/2022 19:17:32 - INFO - __main__ - Step 810 Global step 810 Train loss 0.03 on epoch=202
05/30/2022 19:17:35 - INFO - __main__ - Step 820 Global step 820 Train loss 0.03 on epoch=204
05/30/2022 19:17:37 - INFO - __main__ - Step 830 Global step 830 Train loss 0.05 on epoch=207
05/30/2022 19:17:40 - INFO - __main__ - Step 840 Global step 840 Train loss 0.03 on epoch=209
05/30/2022 19:17:42 - INFO - __main__ - Step 850 Global step 850 Train loss 0.04 on epoch=212
05/30/2022 19:17:43 - INFO - __main__ - Global step 850 Train loss 0.03 Classification-F1 0.7257687165775402 on epoch=212
05/30/2022 19:17:46 - INFO - __main__ - Step 860 Global step 860 Train loss 0.07 on epoch=214
05/30/2022 19:17:48 - INFO - __main__ - Step 870 Global step 870 Train loss 0.01 on epoch=217
05/30/2022 19:17:50 - INFO - __main__ - Step 880 Global step 880 Train loss 0.02 on epoch=219
05/30/2022 19:17:53 - INFO - __main__ - Step 890 Global step 890 Train loss 0.03 on epoch=222
05/30/2022 19:17:56 - INFO - __main__ - Step 900 Global step 900 Train loss 0.03 on epoch=224
05/30/2022 19:17:56 - INFO - __main__ - Global step 900 Train loss 0.03 Classification-F1 0.7014880952380952 on epoch=224
05/30/2022 19:17:59 - INFO - __main__ - Step 910 Global step 910 Train loss 0.01 on epoch=227
05/30/2022 19:18:02 - INFO - __main__ - Step 920 Global step 920 Train loss 0.08 on epoch=229
05/30/2022 19:18:04 - INFO - __main__ - Step 930 Global step 930 Train loss 0.02 on epoch=232
05/30/2022 19:18:07 - INFO - __main__ - Step 940 Global step 940 Train loss 0.20 on epoch=234
05/30/2022 19:18:09 - INFO - __main__ - Step 950 Global step 950 Train loss 0.02 on epoch=237
05/30/2022 19:18:10 - INFO - __main__ - Global step 950 Train loss 0.07 Classification-F1 0.7786685297461159 on epoch=237
05/30/2022 19:18:10 - INFO - __main__ - Saving model with best Classification-F1: 0.7739065551565552 -> 0.7786685297461159 on epoch=237, global_step=950
05/30/2022 19:18:13 - INFO - __main__ - Step 960 Global step 960 Train loss 0.04 on epoch=239
05/30/2022 19:18:16 - INFO - __main__ - Step 970 Global step 970 Train loss 0.04 on epoch=242
05/30/2022 19:18:18 - INFO - __main__ - Step 980 Global step 980 Train loss 0.01 on epoch=244
05/30/2022 19:18:21 - INFO - __main__ - Step 990 Global step 990 Train loss 0.02 on epoch=247
05/30/2022 19:18:24 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.02 on epoch=249
05/30/2022 19:18:24 - INFO - __main__ - Global step 1000 Train loss 0.03 Classification-F1 0.7454162954162954 on epoch=249
05/30/2022 19:18:27 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.03 on epoch=252
05/30/2022 19:18:30 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.03 on epoch=254
05/30/2022 19:18:32 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.02 on epoch=257
05/30/2022 19:18:35 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.02 on epoch=259
05/30/2022 19:18:38 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.01 on epoch=262
05/30/2022 19:18:39 - INFO - __main__ - Global step 1050 Train loss 0.02 Classification-F1 0.7585951153313583 on epoch=262
05/30/2022 19:18:41 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.01 on epoch=264
05/30/2022 19:18:44 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.01 on epoch=267
05/30/2022 19:18:47 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.02 on epoch=269
05/30/2022 19:18:50 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.04 on epoch=272
05/30/2022 19:18:52 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.02 on epoch=274
05/30/2022 19:18:53 - INFO - __main__ - Global step 1100 Train loss 0.02 Classification-F1 0.7582815551565552 on epoch=274
05/30/2022 19:18:56 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.04 on epoch=277
05/30/2022 19:18:58 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=279
05/30/2022 19:19:01 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.04 on epoch=282
05/30/2022 19:19:03 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.01 on epoch=284
05/30/2022 19:19:06 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=287
05/30/2022 19:19:07 - INFO - __main__ - Global step 1150 Train loss 0.02 Classification-F1 0.6891988803530565 on epoch=287
05/30/2022 19:19:09 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.01 on epoch=289
05/30/2022 19:19:12 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.06 on epoch=292
05/30/2022 19:19:14 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.01 on epoch=294
05/30/2022 19:19:17 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.02 on epoch=297
05/30/2022 19:19:19 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=299
05/30/2022 19:19:20 - INFO - __main__ - Global step 1200 Train loss 0.02 Classification-F1 0.7729281933486468 on epoch=299
05/30/2022 19:19:23 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.01 on epoch=302
05/30/2022 19:19:25 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=304
05/30/2022 19:19:28 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.04 on epoch=307
05/30/2022 19:19:30 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=309
05/30/2022 19:19:33 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.00 on epoch=312
05/30/2022 19:19:34 - INFO - __main__ - Global step 1250 Train loss 0.01 Classification-F1 0.7099681020733651 on epoch=312
05/30/2022 19:19:36 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.00 on epoch=314
05/30/2022 19:19:39 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.04 on epoch=317
05/30/2022 19:19:41 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.06 on epoch=319
05/30/2022 19:19:44 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=322
05/30/2022 19:19:46 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=324
05/30/2022 19:19:47 - INFO - __main__ - Global step 1300 Train loss 0.03 Classification-F1 0.7331809947299077 on epoch=324
05/30/2022 19:19:50 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=327
05/30/2022 19:19:52 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.02 on epoch=329
05/30/2022 19:19:55 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.03 on epoch=332
05/30/2022 19:19:57 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=334
05/30/2022 19:20:00 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.13 on epoch=337
05/30/2022 19:20:00 - INFO - __main__ - Global step 1350 Train loss 0.04 Classification-F1 0.7739065551565552 on epoch=337
05/30/2022 19:20:03 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.09 on epoch=339
05/30/2022 19:20:05 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.00 on epoch=342
05/30/2022 19:20:08 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.00 on epoch=344
05/30/2022 19:20:11 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=347
05/30/2022 19:20:13 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=349
05/30/2022 19:20:14 - INFO - __main__ - Global step 1400 Train loss 0.03 Classification-F1 0.7582815551565552 on epoch=349
05/30/2022 19:20:17 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=352
05/30/2022 19:20:19 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.01 on epoch=354
05/30/2022 19:20:22 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=357
05/30/2022 19:20:24 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=359
05/30/2022 19:20:27 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=362
05/30/2022 19:20:28 - INFO - __main__ - Global step 1450 Train loss 0.01 Classification-F1 0.7575694444444444 on epoch=362
05/30/2022 19:20:30 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.05 on epoch=364
05/30/2022 19:20:33 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=367
05/30/2022 19:20:35 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=369
05/30/2022 19:20:38 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=372
05/30/2022 19:20:40 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.02 on epoch=374
05/30/2022 19:20:41 - INFO - __main__ - Global step 1500 Train loss 0.02 Classification-F1 0.7435873373373373 on epoch=374
05/30/2022 19:20:44 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=377
05/30/2022 19:20:46 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=379
05/30/2022 19:20:49 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.02 on epoch=382
05/30/2022 19:20:51 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=384
05/30/2022 19:20:54 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=387
05/30/2022 19:20:55 - INFO - __main__ - Global step 1550 Train loss 0.01 Classification-F1 0.7334945549047108 on epoch=387
05/30/2022 19:20:57 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=389
05/30/2022 19:21:00 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=392
05/30/2022 19:21:02 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=394
05/30/2022 19:21:05 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=397
05/30/2022 19:21:07 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=399
05/30/2022 19:21:09 - INFO - __main__ - Global step 1600 Train loss 0.01 Classification-F1 0.7472027743244128 on epoch=399
05/30/2022 19:21:11 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=402
05/30/2022 19:21:14 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=404
05/30/2022 19:21:16 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=407
05/30/2022 19:21:19 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.02 on epoch=409
05/30/2022 19:21:21 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=412
05/30/2022 19:21:22 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.7319250674606104 on epoch=412
05/30/2022 19:21:25 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.06 on epoch=414
05/30/2022 19:21:27 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=417
05/30/2022 19:21:30 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.03 on epoch=419
05/30/2022 19:21:32 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=422
05/30/2022 19:21:35 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=424
05/30/2022 19:21:35 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.7473553653042586 on epoch=424
05/30/2022 19:21:38 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=427
05/30/2022 19:21:40 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=429
05/30/2022 19:21:43 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=432
05/30/2022 19:21:45 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=434
05/30/2022 19:21:48 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=437
05/30/2022 19:21:49 - INFO - __main__ - Global step 1750 Train loss 0.00 Classification-F1 0.7676319648093842 on epoch=437
05/30/2022 19:21:52 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=439
05/30/2022 19:21:54 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=442
05/30/2022 19:21:57 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=444
05/30/2022 19:21:59 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=447
05/30/2022 19:22:02 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=449
05/30/2022 19:22:03 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.7870032051282051 on epoch=449
05/30/2022 19:22:03 - INFO - __main__ - Saving model with best Classification-F1: 0.7786685297461159 -> 0.7870032051282051 on epoch=449, global_step=1800
05/30/2022 19:22:05 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.04 on epoch=452
05/30/2022 19:22:08 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.04 on epoch=454
05/30/2022 19:22:10 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=457
05/30/2022 19:22:13 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=459
05/30/2022 19:22:15 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=462
05/30/2022 19:22:16 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.7583189885556185 on epoch=462
05/30/2022 19:22:19 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=464
05/30/2022 19:22:21 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=467
05/30/2022 19:22:24 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=469
05/30/2022 19:22:26 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=472
05/30/2022 19:22:29 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.02 on epoch=474
05/30/2022 19:22:30 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.7743044479886585 on epoch=474
05/30/2022 19:22:32 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=477
05/30/2022 19:22:35 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=479
05/30/2022 19:22:37 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=482
05/30/2022 19:22:40 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=484
05/30/2022 19:22:42 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=487
05/30/2022 19:22:43 - INFO - __main__ - Global step 1950 Train loss 0.00 Classification-F1 0.7743044479886585 on epoch=487
05/30/2022 19:22:46 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=489
05/30/2022 19:22:48 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=492
05/30/2022 19:22:51 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=494
05/30/2022 19:22:53 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=497
05/30/2022 19:22:56 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=499
05/30/2022 19:22:57 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.7598106791655179 on epoch=499
05/30/2022 19:22:59 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=502
05/30/2022 19:23:02 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
05/30/2022 19:23:04 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=507
05/30/2022 19:23:07 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=509
05/30/2022 19:23:09 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
05/30/2022 19:23:10 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.7586441336441337 on epoch=512
05/30/2022 19:23:13 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=514
05/30/2022 19:23:15 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=517
05/30/2022 19:23:18 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
05/30/2022 19:23:20 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=522
05/30/2022 19:23:23 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
05/30/2022 19:23:24 - INFO - __main__ - Global step 2100 Train loss 0.00 Classification-F1 0.7412858109632303 on epoch=524
05/30/2022 19:23:26 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=527
05/30/2022 19:23:29 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
05/30/2022 19:23:31 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
05/30/2022 19:23:34 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=534
05/30/2022 19:23:36 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
05/30/2022 19:23:37 - INFO - __main__ - Global step 2150 Train loss 0.00 Classification-F1 0.7551319648093843 on epoch=537
05/30/2022 19:23:40 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
05/30/2022 19:23:42 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
05/30/2022 19:23:45 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
05/30/2022 19:23:47 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
05/30/2022 19:23:50 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
05/30/2022 19:23:51 - INFO - __main__ - Global step 2200 Train loss 0.00 Classification-F1 0.7493383924397248 on epoch=549
05/30/2022 19:23:54 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
05/30/2022 19:23:56 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
05/30/2022 19:23:59 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
05/30/2022 19:24:01 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
05/30/2022 19:24:04 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
05/30/2022 19:24:05 - INFO - __main__ - Global step 2250 Train loss 0.00 Classification-F1 0.7009303943306813 on epoch=562
05/30/2022 19:24:07 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
05/30/2022 19:24:10 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
05/30/2022 19:24:12 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
05/30/2022 19:24:15 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
05/30/2022 19:24:17 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
05/30/2022 19:24:18 - INFO - __main__ - Global step 2300 Train loss 0.00 Classification-F1 0.7598553116379942 on epoch=574
05/30/2022 19:24:21 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
05/30/2022 19:24:23 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
05/30/2022 19:24:26 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
05/30/2022 19:24:28 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.09 on epoch=584
05/30/2022 19:24:31 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
05/30/2022 19:24:32 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.6871722774475644 on epoch=587
05/30/2022 19:24:35 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
05/30/2022 19:24:37 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
05/30/2022 19:24:40 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.03 on epoch=594
05/30/2022 19:24:42 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
05/30/2022 19:24:45 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
05/30/2022 19:24:46 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.7598553116379942 on epoch=599
05/30/2022 19:24:48 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
05/30/2022 19:24:51 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
05/30/2022 19:24:53 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=607
05/30/2022 19:24:56 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
05/30/2022 19:24:59 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
05/30/2022 19:25:00 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.7397702986118048 on epoch=612
05/30/2022 19:25:02 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
05/30/2022 19:25:05 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=617
05/30/2022 19:25:07 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=619
05/30/2022 19:25:10 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
05/30/2022 19:25:12 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
05/30/2022 19:25:13 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.7730895748987854 on epoch=624
05/30/2022 19:25:16 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
05/30/2022 19:25:18 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
05/30/2022 19:25:21 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.04 on epoch=632
05/30/2022 19:25:23 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
05/30/2022 19:25:26 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
05/30/2022 19:25:27 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.7391443863218057 on epoch=637
05/30/2022 19:25:30 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
05/30/2022 19:25:32 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=642
05/30/2022 19:25:35 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.03 on epoch=644
05/30/2022 19:25:37 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
05/30/2022 19:25:40 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=649
05/30/2022 19:25:41 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.7770337301587301 on epoch=649
05/30/2022 19:25:43 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
05/30/2022 19:25:46 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=654
05/30/2022 19:25:48 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.03 on epoch=657
05/30/2022 19:25:51 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
05/30/2022 19:25:53 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
05/30/2022 19:25:54 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.7912443693693694 on epoch=662
05/30/2022 19:25:54 - INFO - __main__ - Saving model with best Classification-F1: 0.7870032051282051 -> 0.7912443693693694 on epoch=662, global_step=2650
05/30/2022 19:25:57 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
05/30/2022 19:25:59 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
05/30/2022 19:26:02 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
05/30/2022 19:26:04 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
05/30/2022 19:26:07 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
05/30/2022 19:26:08 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.7763573232323232 on epoch=674
05/30/2022 19:26:11 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
05/30/2022 19:26:13 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
05/30/2022 19:26:16 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=682
05/30/2022 19:26:18 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=684
05/30/2022 19:26:21 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
05/30/2022 19:26:22 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.7763573232323232 on epoch=687
05/30/2022 19:26:24 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
05/30/2022 19:26:27 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
05/30/2022 19:26:29 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
05/30/2022 19:26:32 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
05/30/2022 19:26:34 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=699
05/30/2022 19:26:35 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.7582815551565552 on epoch=699
05/30/2022 19:26:38 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
05/30/2022 19:26:40 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
05/30/2022 19:26:43 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.06 on epoch=707
05/30/2022 19:26:45 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
05/30/2022 19:26:48 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
05/30/2022 19:26:49 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.7690572256067113 on epoch=712
05/30/2022 19:26:51 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
05/30/2022 19:26:54 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=717
05/30/2022 19:26:56 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
05/30/2022 19:26:59 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
05/30/2022 19:27:01 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
05/30/2022 19:27:03 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.7730895748987854 on epoch=724
05/30/2022 19:27:05 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
05/30/2022 19:27:08 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
05/30/2022 19:27:10 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
05/30/2022 19:27:13 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
05/30/2022 19:27:15 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
05/30/2022 19:27:16 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.7321927542515778 on epoch=737
05/30/2022 19:27:19 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
05/30/2022 19:27:21 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
05/30/2022 19:27:24 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=744
05/30/2022 19:27:26 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
05/30/2022 19:27:29 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
05/30/2022 19:27:30 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.7170412391000627 on epoch=749
05/30/2022 19:27:30 - INFO - __main__ - save last model!
05/30/2022 19:27:30 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/30/2022 19:27:30 - INFO - __main__ - Start tokenizing ... 5509 instances
05/30/2022 19:27:30 - INFO - __main__ - Printing 3 examples
05/30/2022 19:27:30 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/30/2022 19:27:30 - INFO - __main__ - ['others']
05/30/2022 19:27:30 - INFO - __main__ -  [emo] what you like very little things ok
05/30/2022 19:27:30 - INFO - __main__ - ['others']
05/30/2022 19:27:30 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/30/2022 19:27:30 - INFO - __main__ - ['others']
05/30/2022 19:27:30 - INFO - __main__ - Tokenizing Input ...
05/30/2022 19:27:30 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 19:27:30 - INFO - __main__ - Printing 3 examples
05/30/2022 19:27:30 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
05/30/2022 19:27:30 - INFO - __main__ - ['sad']
05/30/2022 19:27:30 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
05/30/2022 19:27:30 - INFO - __main__ - ['sad']
05/30/2022 19:27:30 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
05/30/2022 19:27:30 - INFO - __main__ - ['sad']
05/30/2022 19:27:30 - INFO - __main__ - Tokenizing Input ...
05/30/2022 19:27:30 - INFO - __main__ - Tokenizing Output ...
05/30/2022 19:27:30 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 19:27:30 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 19:27:30 - INFO - __main__ - Printing 3 examples
05/30/2022 19:27:30 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
05/30/2022 19:27:30 - INFO - __main__ - ['sad']
05/30/2022 19:27:30 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
05/30/2022 19:27:30 - INFO - __main__ - ['sad']
05/30/2022 19:27:30 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
05/30/2022 19:27:30 - INFO - __main__ - ['sad']
05/30/2022 19:27:30 - INFO - __main__ - Tokenizing Input ...
05/30/2022 19:27:30 - INFO - __main__ - Tokenizing Output ...
05/30/2022 19:27:30 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 19:27:32 - INFO - __main__ - Tokenizing Output ...
05/30/2022 19:27:37 - INFO - __main__ - Loaded 5509 examples from test data
05/30/2022 19:27:49 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 19:27:49 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/30/2022 19:27:49 - INFO - __main__ - Starting training!
05/30/2022 19:29:11 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-24uptasks/singletask-emo/emo_16_21_0.4_8_predictions.txt
05/30/2022 19:29:11 - INFO - __main__ - Classification-F1 on test data: 0.1647
05/30/2022 19:29:11 - INFO - __main__ - prefix=emo_16_21, lr=0.4, bsz=8, dev_performance=0.7912443693693694, test_performance=0.16473534739260354
05/30/2022 19:29:11 - INFO - __main__ - Running ... prefix=emo_16_21, lr=0.3, bsz=8 ...
05/30/2022 19:29:12 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 19:29:12 - INFO - __main__ - Printing 3 examples
05/30/2022 19:29:12 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
05/30/2022 19:29:12 - INFO - __main__ - ['sad']
05/30/2022 19:29:12 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
05/30/2022 19:29:12 - INFO - __main__ - ['sad']
05/30/2022 19:29:12 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
05/30/2022 19:29:12 - INFO - __main__ - ['sad']
05/30/2022 19:29:12 - INFO - __main__ - Tokenizing Input ...
05/30/2022 19:29:12 - INFO - __main__ - Tokenizing Output ...
05/30/2022 19:29:12 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 19:29:12 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 19:29:12 - INFO - __main__ - Printing 3 examples
05/30/2022 19:29:12 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
05/30/2022 19:29:12 - INFO - __main__ - ['sad']
05/30/2022 19:29:12 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
05/30/2022 19:29:12 - INFO - __main__ - ['sad']
05/30/2022 19:29:12 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
05/30/2022 19:29:12 - INFO - __main__ - ['sad']
05/30/2022 19:29:12 - INFO - __main__ - Tokenizing Input ...
05/30/2022 19:29:12 - INFO - __main__ - Tokenizing Output ...
05/30/2022 19:29:12 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 19:29:27 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 19:29:28 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/30/2022 19:29:28 - INFO - __main__ - Starting training!
05/30/2022 19:29:31 - INFO - __main__ - Step 10 Global step 10 Train loss 4.23 on epoch=2
05/30/2022 19:29:33 - INFO - __main__ - Step 20 Global step 20 Train loss 2.39 on epoch=4
05/30/2022 19:29:36 - INFO - __main__ - Step 30 Global step 30 Train loss 1.79 on epoch=7
05/30/2022 19:29:38 - INFO - __main__ - Step 40 Global step 40 Train loss 1.29 on epoch=9
05/30/2022 19:29:41 - INFO - __main__ - Step 50 Global step 50 Train loss 0.92 on epoch=12
05/30/2022 19:29:42 - INFO - __main__ - Global step 50 Train loss 2.13 Classification-F1 0.2753644421654091 on epoch=12
05/30/2022 19:29:42 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.2753644421654091 on epoch=12, global_step=50
05/30/2022 19:29:44 - INFO - __main__ - Step 60 Global step 60 Train loss 0.84 on epoch=14
05/30/2022 19:29:47 - INFO - __main__ - Step 70 Global step 70 Train loss 1.02 on epoch=17
05/30/2022 19:29:49 - INFO - __main__ - Step 80 Global step 80 Train loss 0.84 on epoch=19
05/30/2022 19:29:52 - INFO - __main__ - Step 90 Global step 90 Train loss 0.77 on epoch=22
05/30/2022 19:29:54 - INFO - __main__ - Step 100 Global step 100 Train loss 0.74 on epoch=24
05/30/2022 19:29:55 - INFO - __main__ - Global step 100 Train loss 0.84 Classification-F1 0.5519438571764154 on epoch=24
05/30/2022 19:29:55 - INFO - __main__ - Saving model with best Classification-F1: 0.2753644421654091 -> 0.5519438571764154 on epoch=24, global_step=100
05/30/2022 19:29:58 - INFO - __main__ - Step 110 Global step 110 Train loss 0.83 on epoch=27
05/30/2022 19:30:00 - INFO - __main__ - Step 120 Global step 120 Train loss 0.69 on epoch=29
05/30/2022 19:30:03 - INFO - __main__ - Step 130 Global step 130 Train loss 0.73 on epoch=32
05/30/2022 19:30:05 - INFO - __main__ - Step 140 Global step 140 Train loss 0.57 on epoch=34
05/30/2022 19:30:08 - INFO - __main__ - Step 150 Global step 150 Train loss 0.65 on epoch=37
05/30/2022 19:30:08 - INFO - __main__ - Global step 150 Train loss 0.69 Classification-F1 0.5891437415630963 on epoch=37
05/30/2022 19:30:09 - INFO - __main__ - Saving model with best Classification-F1: 0.5519438571764154 -> 0.5891437415630963 on epoch=37, global_step=150
05/30/2022 19:30:11 - INFO - __main__ - Step 160 Global step 160 Train loss 0.53 on epoch=39
05/30/2022 19:30:14 - INFO - __main__ - Step 170 Global step 170 Train loss 0.52 on epoch=42
05/30/2022 19:30:16 - INFO - __main__ - Step 180 Global step 180 Train loss 0.59 on epoch=44
05/30/2022 19:30:18 - INFO - __main__ - Step 190 Global step 190 Train loss 0.57 on epoch=47
05/30/2022 19:30:21 - INFO - __main__ - Step 200 Global step 200 Train loss 0.44 on epoch=49
05/30/2022 19:30:22 - INFO - __main__ - Global step 200 Train loss 0.53 Classification-F1 0.6813218390804598 on epoch=49
05/30/2022 19:30:22 - INFO - __main__ - Saving model with best Classification-F1: 0.5891437415630963 -> 0.6813218390804598 on epoch=49, global_step=200
05/30/2022 19:30:24 - INFO - __main__ - Step 210 Global step 210 Train loss 0.52 on epoch=52
05/30/2022 19:30:27 - INFO - __main__ - Step 220 Global step 220 Train loss 0.56 on epoch=54
05/30/2022 19:30:29 - INFO - __main__ - Step 230 Global step 230 Train loss 0.49 on epoch=57
05/30/2022 19:30:32 - INFO - __main__ - Step 240 Global step 240 Train loss 0.40 on epoch=59
05/30/2022 19:30:34 - INFO - __main__ - Step 250 Global step 250 Train loss 0.42 on epoch=62
05/30/2022 19:30:35 - INFO - __main__ - Global step 250 Train loss 0.48 Classification-F1 0.644768478609942 on epoch=62
05/30/2022 19:30:38 - INFO - __main__ - Step 260 Global step 260 Train loss 0.38 on epoch=64
05/30/2022 19:30:40 - INFO - __main__ - Step 270 Global step 270 Train loss 0.36 on epoch=67
05/30/2022 19:30:43 - INFO - __main__ - Step 280 Global step 280 Train loss 0.38 on epoch=69
05/30/2022 19:30:45 - INFO - __main__ - Step 290 Global step 290 Train loss 0.36 on epoch=72
05/30/2022 19:30:47 - INFO - __main__ - Step 300 Global step 300 Train loss 0.29 on epoch=74
05/30/2022 19:30:48 - INFO - __main__ - Global step 300 Train loss 0.35 Classification-F1 0.6704268292682927 on epoch=74
05/30/2022 19:30:51 - INFO - __main__ - Step 310 Global step 310 Train loss 0.38 on epoch=77
05/30/2022 19:30:53 - INFO - __main__ - Step 320 Global step 320 Train loss 0.33 on epoch=79
05/30/2022 19:30:56 - INFO - __main__ - Step 330 Global step 330 Train loss 0.29 on epoch=82
05/30/2022 19:30:58 - INFO - __main__ - Step 340 Global step 340 Train loss 0.24 on epoch=84
05/30/2022 19:31:01 - INFO - __main__ - Step 350 Global step 350 Train loss 0.37 on epoch=87
05/30/2022 19:31:02 - INFO - __main__ - Global step 350 Train loss 0.32 Classification-F1 0.6654900332225915 on epoch=87
05/30/2022 19:31:04 - INFO - __main__ - Step 360 Global step 360 Train loss 0.34 on epoch=89
05/30/2022 19:31:07 - INFO - __main__ - Step 370 Global step 370 Train loss 0.29 on epoch=92
05/30/2022 19:31:09 - INFO - __main__ - Step 380 Global step 380 Train loss 0.36 on epoch=94
05/30/2022 19:31:12 - INFO - __main__ - Step 390 Global step 390 Train loss 0.23 on epoch=97
05/30/2022 19:31:14 - INFO - __main__ - Step 400 Global step 400 Train loss 0.26 on epoch=99
05/30/2022 19:31:15 - INFO - __main__ - Global step 400 Train loss 0.29 Classification-F1 0.6702375762859634 on epoch=99
05/30/2022 19:31:17 - INFO - __main__ - Step 410 Global step 410 Train loss 0.26 on epoch=102
05/30/2022 19:31:20 - INFO - __main__ - Step 420 Global step 420 Train loss 0.25 on epoch=104
05/30/2022 19:31:22 - INFO - __main__ - Step 430 Global step 430 Train loss 0.20 on epoch=107
05/30/2022 19:31:25 - INFO - __main__ - Step 440 Global step 440 Train loss 0.18 on epoch=109
05/30/2022 19:31:27 - INFO - __main__ - Step 450 Global step 450 Train loss 0.27 on epoch=112
05/30/2022 19:31:28 - INFO - __main__ - Global step 450 Train loss 0.23 Classification-F1 0.6688377679231339 on epoch=112
05/30/2022 19:31:31 - INFO - __main__ - Step 460 Global step 460 Train loss 0.20 on epoch=114
05/30/2022 19:31:33 - INFO - __main__ - Step 470 Global step 470 Train loss 0.22 on epoch=117
05/30/2022 19:31:36 - INFO - __main__ - Step 480 Global step 480 Train loss 0.18 on epoch=119
05/30/2022 19:31:38 - INFO - __main__ - Step 490 Global step 490 Train loss 0.17 on epoch=122
05/30/2022 19:31:41 - INFO - __main__ - Step 500 Global step 500 Train loss 0.17 on epoch=124
05/30/2022 19:31:41 - INFO - __main__ - Global step 500 Train loss 0.19 Classification-F1 0.6413867741453949 on epoch=124
05/30/2022 19:31:44 - INFO - __main__ - Step 510 Global step 510 Train loss 0.19 on epoch=127
05/30/2022 19:31:46 - INFO - __main__ - Step 520 Global step 520 Train loss 0.09 on epoch=129
05/30/2022 19:31:49 - INFO - __main__ - Step 530 Global step 530 Train loss 0.19 on epoch=132
05/30/2022 19:31:51 - INFO - __main__ - Step 540 Global step 540 Train loss 0.10 on epoch=134
05/30/2022 19:31:54 - INFO - __main__ - Step 550 Global step 550 Train loss 0.15 on epoch=137
05/30/2022 19:31:55 - INFO - __main__ - Global step 550 Train loss 0.14 Classification-F1 0.6394360959055356 on epoch=137
05/30/2022 19:31:57 - INFO - __main__ - Step 560 Global step 560 Train loss 0.22 on epoch=139
05/30/2022 19:32:00 - INFO - __main__ - Step 570 Global step 570 Train loss 0.09 on epoch=142
05/30/2022 19:32:02 - INFO - __main__ - Step 580 Global step 580 Train loss 0.10 on epoch=144
05/30/2022 19:32:04 - INFO - __main__ - Step 590 Global step 590 Train loss 0.10 on epoch=147
05/30/2022 19:32:07 - INFO - __main__ - Step 600 Global step 600 Train loss 0.09 on epoch=149
05/30/2022 19:32:08 - INFO - __main__ - Global step 600 Train loss 0.12 Classification-F1 0.609384948858633 on epoch=149
05/30/2022 19:32:11 - INFO - __main__ - Step 610 Global step 610 Train loss 0.09 on epoch=152
05/30/2022 19:32:13 - INFO - __main__ - Step 620 Global step 620 Train loss 0.12 on epoch=154
05/30/2022 19:32:15 - INFO - __main__ - Step 630 Global step 630 Train loss 0.09 on epoch=157
05/30/2022 19:32:18 - INFO - __main__ - Step 640 Global step 640 Train loss 0.13 on epoch=159
05/30/2022 19:32:20 - INFO - __main__ - Step 650 Global step 650 Train loss 0.09 on epoch=162
05/30/2022 19:32:21 - INFO - __main__ - Global step 650 Train loss 0.10 Classification-F1 0.6574582027168234 on epoch=162
05/30/2022 19:32:24 - INFO - __main__ - Step 660 Global step 660 Train loss 0.06 on epoch=164
05/30/2022 19:32:26 - INFO - __main__ - Step 670 Global step 670 Train loss 0.06 on epoch=167
05/30/2022 19:32:29 - INFO - __main__ - Step 680 Global step 680 Train loss 0.11 on epoch=169
05/30/2022 19:32:31 - INFO - __main__ - Step 690 Global step 690 Train loss 0.04 on epoch=172
05/30/2022 19:32:34 - INFO - __main__ - Step 700 Global step 700 Train loss 0.09 on epoch=174
05/30/2022 19:32:35 - INFO - __main__ - Global step 700 Train loss 0.07 Classification-F1 0.6700823566677225 on epoch=174
05/30/2022 19:32:37 - INFO - __main__ - Step 710 Global step 710 Train loss 0.05 on epoch=177
05/30/2022 19:32:40 - INFO - __main__ - Step 720 Global step 720 Train loss 0.06 on epoch=179
05/30/2022 19:32:42 - INFO - __main__ - Step 730 Global step 730 Train loss 0.13 on epoch=182
05/30/2022 19:32:45 - INFO - __main__ - Step 740 Global step 740 Train loss 0.04 on epoch=184
05/30/2022 19:32:47 - INFO - __main__ - Step 750 Global step 750 Train loss 0.09 on epoch=187
05/30/2022 19:32:48 - INFO - __main__ - Global step 750 Train loss 0.07 Classification-F1 0.6938047296294464 on epoch=187
05/30/2022 19:32:48 - INFO - __main__ - Saving model with best Classification-F1: 0.6813218390804598 -> 0.6938047296294464 on epoch=187, global_step=750
05/30/2022 19:32:50 - INFO - __main__ - Step 760 Global step 760 Train loss 0.12 on epoch=189
05/30/2022 19:32:53 - INFO - __main__ - Step 770 Global step 770 Train loss 0.07 on epoch=192
05/30/2022 19:32:55 - INFO - __main__ - Step 780 Global step 780 Train loss 0.07 on epoch=194
05/30/2022 19:32:58 - INFO - __main__ - Step 790 Global step 790 Train loss 0.04 on epoch=197
05/30/2022 19:33:00 - INFO - __main__ - Step 800 Global step 800 Train loss 0.05 on epoch=199
05/30/2022 19:33:01 - INFO - __main__ - Global step 800 Train loss 0.07 Classification-F1 0.6822584396597555 on epoch=199
05/30/2022 19:33:04 - INFO - __main__ - Step 810 Global step 810 Train loss 0.10 on epoch=202
05/30/2022 19:33:06 - INFO - __main__ - Step 820 Global step 820 Train loss 0.12 on epoch=204
05/30/2022 19:33:09 - INFO - __main__ - Step 830 Global step 830 Train loss 0.08 on epoch=207
05/30/2022 19:33:11 - INFO - __main__ - Step 840 Global step 840 Train loss 0.05 on epoch=209
05/30/2022 19:33:14 - INFO - __main__ - Step 850 Global step 850 Train loss 0.06 on epoch=212
05/30/2022 19:33:14 - INFO - __main__ - Global step 850 Train loss 0.08 Classification-F1 0.7048782838348794 on epoch=212
05/30/2022 19:33:15 - INFO - __main__ - Saving model with best Classification-F1: 0.6938047296294464 -> 0.7048782838348794 on epoch=212, global_step=850
05/30/2022 19:33:17 - INFO - __main__ - Step 860 Global step 860 Train loss 0.09 on epoch=214
05/30/2022 19:33:19 - INFO - __main__ - Step 870 Global step 870 Train loss 0.09 on epoch=217
05/30/2022 19:33:22 - INFO - __main__ - Step 880 Global step 880 Train loss 0.03 on epoch=219
05/30/2022 19:33:24 - INFO - __main__ - Step 890 Global step 890 Train loss 0.05 on epoch=222
05/30/2022 19:33:27 - INFO - __main__ - Step 900 Global step 900 Train loss 0.04 on epoch=224
05/30/2022 19:33:28 - INFO - __main__ - Global step 900 Train loss 0.06 Classification-F1 0.6917914899257689 on epoch=224
05/30/2022 19:33:30 - INFO - __main__ - Step 910 Global step 910 Train loss 0.03 on epoch=227
05/30/2022 19:33:33 - INFO - __main__ - Step 920 Global step 920 Train loss 0.07 on epoch=229
05/30/2022 19:33:35 - INFO - __main__ - Step 930 Global step 930 Train loss 0.03 on epoch=232
05/30/2022 19:33:38 - INFO - __main__ - Step 940 Global step 940 Train loss 0.05 on epoch=234
05/30/2022 19:33:40 - INFO - __main__ - Step 950 Global step 950 Train loss 0.05 on epoch=237
05/30/2022 19:33:41 - INFO - __main__ - Global step 950 Train loss 0.05 Classification-F1 0.6725397381954183 on epoch=237
05/30/2022 19:33:44 - INFO - __main__ - Step 960 Global step 960 Train loss 0.09 on epoch=239
05/30/2022 19:33:46 - INFO - __main__ - Step 970 Global step 970 Train loss 0.04 on epoch=242
05/30/2022 19:33:49 - INFO - __main__ - Step 980 Global step 980 Train loss 0.05 on epoch=244
05/30/2022 19:33:51 - INFO - __main__ - Step 990 Global step 990 Train loss 0.04 on epoch=247
05/30/2022 19:33:54 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.03 on epoch=249
05/30/2022 19:33:55 - INFO - __main__ - Global step 1000 Train loss 0.05 Classification-F1 0.6587278387127872 on epoch=249
05/30/2022 19:33:57 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.06 on epoch=252
05/30/2022 19:34:00 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.03 on epoch=254
05/30/2022 19:34:02 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.04 on epoch=257
05/30/2022 19:34:05 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.02 on epoch=259
05/30/2022 19:34:07 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.01 on epoch=262
05/30/2022 19:34:08 - INFO - __main__ - Global step 1050 Train loss 0.03 Classification-F1 0.6717986314760508 on epoch=262
05/30/2022 19:34:10 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.07 on epoch=264
05/30/2022 19:34:13 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.05 on epoch=267
05/30/2022 19:34:15 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.06 on epoch=269
05/30/2022 19:34:18 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.05 on epoch=272
05/30/2022 19:34:21 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.01 on epoch=274
05/30/2022 19:34:22 - INFO - __main__ - Global step 1100 Train loss 0.05 Classification-F1 0.6577154923929118 on epoch=274
05/30/2022 19:34:24 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.07 on epoch=277
05/30/2022 19:34:27 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.03 on epoch=279
05/30/2022 19:34:29 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.12 on epoch=282
05/30/2022 19:34:32 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.05 on epoch=284
05/30/2022 19:34:34 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.08 on epoch=287
05/30/2022 19:34:35 - INFO - __main__ - Global step 1150 Train loss 0.07 Classification-F1 0.691969696969697 on epoch=287
05/30/2022 19:34:37 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.03 on epoch=289
05/30/2022 19:34:40 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.04 on epoch=292
05/30/2022 19:34:42 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.02 on epoch=294
05/30/2022 19:34:45 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.02 on epoch=297
05/30/2022 19:34:47 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.03 on epoch=299
05/30/2022 19:34:48 - INFO - __main__ - Global step 1200 Train loss 0.03 Classification-F1 0.6899920255183414 on epoch=299
05/30/2022 19:34:51 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.01 on epoch=302
05/30/2022 19:34:53 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.07 on epoch=304
05/30/2022 19:34:56 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.03 on epoch=307
05/30/2022 19:34:58 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.02 on epoch=309
05/30/2022 19:35:01 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.02 on epoch=312
05/30/2022 19:35:02 - INFO - __main__ - Global step 1250 Train loss 0.03 Classification-F1 0.6719303700422515 on epoch=312
05/30/2022 19:35:04 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.02 on epoch=314
05/30/2022 19:35:07 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.09 on epoch=317
05/30/2022 19:35:09 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.03 on epoch=319
05/30/2022 19:35:12 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.03 on epoch=322
05/30/2022 19:35:14 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.03 on epoch=324
05/30/2022 19:35:15 - INFO - __main__ - Global step 1300 Train loss 0.04 Classification-F1 0.6966525722339676 on epoch=324
05/30/2022 19:35:18 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=327
05/30/2022 19:35:20 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.02 on epoch=329
05/30/2022 19:35:23 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=332
05/30/2022 19:35:25 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.03 on epoch=334
05/30/2022 19:35:28 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.02 on epoch=337
05/30/2022 19:35:29 - INFO - __main__ - Global step 1350 Train loss 0.02 Classification-F1 0.6763003250812704 on epoch=337
05/30/2022 19:35:32 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.02 on epoch=339
05/30/2022 19:35:34 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.07 on epoch=342
05/30/2022 19:35:36 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.02 on epoch=344
05/30/2022 19:35:39 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.07 on epoch=347
05/30/2022 19:35:41 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=349
05/30/2022 19:35:42 - INFO - __main__ - Global step 1400 Train loss 0.04 Classification-F1 0.6913516009852216 on epoch=349
05/30/2022 19:35:45 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=352
05/30/2022 19:35:47 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.01 on epoch=354
05/30/2022 19:35:50 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.03 on epoch=357
05/30/2022 19:35:52 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.06 on epoch=359
05/30/2022 19:35:55 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=362
05/30/2022 19:35:56 - INFO - __main__ - Global step 1450 Train loss 0.03 Classification-F1 0.6834280303030303 on epoch=362
05/30/2022 19:35:58 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.02 on epoch=364
05/30/2022 19:36:00 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=367
05/30/2022 19:36:03 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.02 on epoch=369
05/30/2022 19:36:05 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=372
05/30/2022 19:36:08 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.02 on epoch=374
05/30/2022 19:36:09 - INFO - __main__ - Global step 1500 Train loss 0.02 Classification-F1 0.6862392568250758 on epoch=374
05/30/2022 19:36:11 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.03 on epoch=377
05/30/2022 19:36:14 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.02 on epoch=379
05/30/2022 19:36:16 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.02 on epoch=382
05/30/2022 19:36:19 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=384
05/30/2022 19:36:21 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=387
05/30/2022 19:36:22 - INFO - __main__ - Global step 1550 Train loss 0.02 Classification-F1 0.7060518292682927 on epoch=387
05/30/2022 19:36:22 - INFO - __main__ - Saving model with best Classification-F1: 0.7048782838348794 -> 0.7060518292682927 on epoch=387, global_step=1550
05/30/2022 19:36:25 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.11 on epoch=389
05/30/2022 19:36:27 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=392
05/30/2022 19:36:29 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.05 on epoch=394
05/30/2022 19:36:32 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=397
05/30/2022 19:36:34 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=399
05/30/2022 19:36:35 - INFO - __main__ - Global step 1600 Train loss 0.04 Classification-F1 0.6911473285486445 on epoch=399
05/30/2022 19:36:38 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=402
05/30/2022 19:36:40 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=404
05/30/2022 19:36:43 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=407
05/30/2022 19:36:45 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=409
05/30/2022 19:36:48 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=412
05/30/2022 19:36:49 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.7060518292682927 on epoch=412
05/30/2022 19:36:51 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=414
05/30/2022 19:36:54 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=417
05/30/2022 19:36:56 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=419
05/30/2022 19:36:58 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=422
05/30/2022 19:37:01 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=424
05/30/2022 19:37:02 - INFO - __main__ - Global step 1700 Train loss 0.01 Classification-F1 0.7807017543859648 on epoch=424
05/30/2022 19:37:02 - INFO - __main__ - Saving model with best Classification-F1: 0.7060518292682927 -> 0.7807017543859648 on epoch=424, global_step=1700
05/30/2022 19:37:05 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=427
05/30/2022 19:37:07 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=429
05/30/2022 19:37:09 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=432
05/30/2022 19:37:12 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=434
05/30/2022 19:37:14 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=437
05/30/2022 19:37:15 - INFO - __main__ - Global step 1750 Train loss 0.01 Classification-F1 0.7008573876423652 on epoch=437
05/30/2022 19:37:18 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=439
05/30/2022 19:37:20 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=442
05/30/2022 19:37:23 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.03 on epoch=444
05/30/2022 19:37:25 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=447
05/30/2022 19:37:27 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=449
05/30/2022 19:37:29 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.7066471163245358 on epoch=449
05/30/2022 19:37:31 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=452
05/30/2022 19:37:34 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=454
05/30/2022 19:37:36 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=457
05/30/2022 19:37:38 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=459
05/30/2022 19:37:41 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.06 on epoch=462
05/30/2022 19:37:42 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.7195993814507138 on epoch=462
05/30/2022 19:37:44 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=464
05/30/2022 19:37:47 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=467
05/30/2022 19:37:49 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=469
05/30/2022 19:37:52 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=472
05/30/2022 19:37:54 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.02 on epoch=474
05/30/2022 19:37:55 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.7061104218362284 on epoch=474
05/30/2022 19:37:58 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=477
05/30/2022 19:38:00 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=479
05/30/2022 19:38:03 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=482
05/30/2022 19:38:05 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=484
05/30/2022 19:38:08 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=487
05/30/2022 19:38:09 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.7247700216450217 on epoch=487
05/30/2022 19:38:11 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=489
05/30/2022 19:38:14 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=492
05/30/2022 19:38:16 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=494
05/30/2022 19:38:18 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=497
05/30/2022 19:38:21 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=499
05/30/2022 19:38:22 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.7046002163650669 on epoch=499
05/30/2022 19:38:24 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=502
05/30/2022 19:38:27 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
05/30/2022 19:38:29 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=507
05/30/2022 19:38:31 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=509
05/30/2022 19:38:34 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
05/30/2022 19:38:35 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.7046002163650669 on epoch=512
05/30/2022 19:38:37 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=514
05/30/2022 19:38:40 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=517
05/30/2022 19:38:42 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
05/30/2022 19:38:45 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.04 on epoch=522
05/30/2022 19:38:47 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=524
05/30/2022 19:38:48 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.7061526357199056 on epoch=524
05/30/2022 19:38:51 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
05/30/2022 19:38:53 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.08 on epoch=529
05/30/2022 19:38:55 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
05/30/2022 19:38:58 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=534
05/30/2022 19:39:00 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
05/30/2022 19:39:01 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.7055294795783926 on epoch=537
05/30/2022 19:39:04 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=539
05/30/2022 19:39:06 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=542
05/30/2022 19:39:08 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=544
05/30/2022 19:39:11 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
05/30/2022 19:39:13 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=549
05/30/2022 19:39:14 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.7046002163650669 on epoch=549
05/30/2022 19:39:17 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.03 on epoch=552
05/30/2022 19:39:19 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=554
05/30/2022 19:39:22 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=557
05/30/2022 19:39:24 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=559
05/30/2022 19:39:27 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.05 on epoch=562
05/30/2022 19:39:28 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.7177703089244851 on epoch=562
05/30/2022 19:39:30 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
05/30/2022 19:39:33 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
05/30/2022 19:39:35 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=569
05/30/2022 19:39:38 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.07 on epoch=572
05/30/2022 19:39:40 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=574
05/30/2022 19:39:41 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.7061526357199056 on epoch=574
05/30/2022 19:39:44 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=577
05/30/2022 19:39:47 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
05/30/2022 19:39:49 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=582
05/30/2022 19:39:52 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=584
05/30/2022 19:39:54 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
05/30/2022 19:39:55 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.7196116118769883 on epoch=587
05/30/2022 19:39:58 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=589
05/30/2022 19:40:00 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
05/30/2022 19:40:03 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=594
05/30/2022 19:40:05 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.05 on epoch=597
05/30/2022 19:40:08 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=599
05/30/2022 19:40:09 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.733541055718475 on epoch=599
05/30/2022 19:40:11 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=602
05/30/2022 19:40:14 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
05/30/2022 19:40:16 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=607
05/30/2022 19:40:19 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
05/30/2022 19:40:21 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
05/30/2022 19:40:22 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.7046002163650669 on epoch=612
05/30/2022 19:40:25 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
05/30/2022 19:40:28 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=617
05/30/2022 19:40:30 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=619
05/30/2022 19:40:33 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.08 on epoch=622
05/30/2022 19:40:35 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
05/30/2022 19:40:36 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.7196062942366026 on epoch=624
05/30/2022 19:40:39 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=627
05/30/2022 19:40:41 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=629
05/30/2022 19:40:44 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.03 on epoch=632
05/30/2022 19:40:46 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.04 on epoch=634
05/30/2022 19:40:49 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
05/30/2022 19:40:50 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.720734126984127 on epoch=637
05/30/2022 19:40:53 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
05/30/2022 19:40:55 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=642
05/30/2022 19:40:58 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=644
05/30/2022 19:41:00 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=647
05/30/2022 19:41:03 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=649
05/30/2022 19:41:04 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.7250644162588635 on epoch=649
05/30/2022 19:41:06 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=652
05/30/2022 19:41:09 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=654
05/30/2022 19:41:11 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
05/30/2022 19:41:14 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
05/30/2022 19:41:16 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=662
05/30/2022 19:41:17 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.7175843601816603 on epoch=662
05/30/2022 19:41:20 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=664
05/30/2022 19:41:23 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
05/30/2022 19:41:25 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
05/30/2022 19:41:28 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=672
05/30/2022 19:41:30 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=674
05/30/2022 19:41:31 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.7451863868889731 on epoch=674
05/30/2022 19:41:34 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.03 on epoch=677
05/30/2022 19:41:36 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.04 on epoch=679
05/30/2022 19:41:39 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
05/30/2022 19:41:41 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
05/30/2022 19:41:44 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.03 on epoch=687
05/30/2022 19:41:45 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.7180883924397248 on epoch=687
05/30/2022 19:41:47 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=689
05/30/2022 19:41:50 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
05/30/2022 19:41:52 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=694
05/30/2022 19:41:55 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
05/30/2022 19:41:57 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.03 on epoch=699
05/30/2022 19:41:59 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.7094373219373219 on epoch=699
05/30/2022 19:42:01 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
05/30/2022 19:42:04 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=704
05/30/2022 19:42:06 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
05/30/2022 19:42:09 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
05/30/2022 19:42:11 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=712
05/30/2022 19:42:12 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.720144355575003 on epoch=712
05/30/2022 19:42:15 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
05/30/2022 19:42:17 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=717
05/30/2022 19:42:20 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
05/30/2022 19:42:22 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.07 on epoch=722
05/30/2022 19:42:25 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=724
05/30/2022 19:42:26 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.704612414187643 on epoch=724
05/30/2022 19:42:28 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.04 on epoch=727
05/30/2022 19:42:31 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
05/30/2022 19:42:34 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
05/30/2022 19:42:36 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
05/30/2022 19:42:39 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
05/30/2022 19:42:40 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.7060518292682927 on epoch=737
05/30/2022 19:42:42 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.04 on epoch=739
05/30/2022 19:42:45 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
05/30/2022 19:42:47 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
05/30/2022 19:42:50 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
05/30/2022 19:42:52 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
05/30/2022 19:42:53 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.7315802845528455 on epoch=749
05/30/2022 19:42:53 - INFO - __main__ - save last model!
05/30/2022 19:42:53 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/30/2022 19:42:54 - INFO - __main__ - Start tokenizing ... 5509 instances
05/30/2022 19:42:54 - INFO - __main__ - Printing 3 examples
05/30/2022 19:42:54 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/30/2022 19:42:54 - INFO - __main__ - ['others']
05/30/2022 19:42:54 - INFO - __main__ -  [emo] what you like very little things ok
05/30/2022 19:42:54 - INFO - __main__ - ['others']
05/30/2022 19:42:54 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/30/2022 19:42:54 - INFO - __main__ - ['others']
05/30/2022 19:42:54 - INFO - __main__ - Tokenizing Input ...
05/30/2022 19:42:54 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 19:42:54 - INFO - __main__ - Printing 3 examples
05/30/2022 19:42:54 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
05/30/2022 19:42:54 - INFO - __main__ - ['sad']
05/30/2022 19:42:54 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
05/30/2022 19:42:54 - INFO - __main__ - ['sad']
05/30/2022 19:42:54 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
05/30/2022 19:42:54 - INFO - __main__ - ['sad']
05/30/2022 19:42:54 - INFO - __main__ - Tokenizing Input ...
05/30/2022 19:42:54 - INFO - __main__ - Tokenizing Output ...
05/30/2022 19:42:54 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 19:42:54 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 19:42:54 - INFO - __main__ - Printing 3 examples
05/30/2022 19:42:54 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
05/30/2022 19:42:54 - INFO - __main__ - ['sad']
05/30/2022 19:42:54 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
05/30/2022 19:42:54 - INFO - __main__ - ['sad']
05/30/2022 19:42:54 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
05/30/2022 19:42:54 - INFO - __main__ - ['sad']
05/30/2022 19:42:54 - INFO - __main__ - Tokenizing Input ...
05/30/2022 19:42:54 - INFO - __main__ - Tokenizing Output ...
05/30/2022 19:42:54 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 19:42:56 - INFO - __main__ - Tokenizing Output ...
05/30/2022 19:43:01 - INFO - __main__ - Loaded 5509 examples from test data
05/30/2022 19:43:12 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 19:43:13 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/30/2022 19:43:13 - INFO - __main__ - Starting training!
05/30/2022 19:44:35 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-24uptasks/singletask-emo/emo_16_21_0.3_8_predictions.txt
05/30/2022 19:44:35 - INFO - __main__ - Classification-F1 on test data: 0.1697
05/30/2022 19:44:35 - INFO - __main__ - prefix=emo_16_21, lr=0.3, bsz=8, dev_performance=0.7807017543859648, test_performance=0.16973329611963006
05/30/2022 19:44:35 - INFO - __main__ - Running ... prefix=emo_16_21, lr=0.2, bsz=8 ...
05/30/2022 19:44:36 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 19:44:36 - INFO - __main__ - Printing 3 examples
05/30/2022 19:44:36 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
05/30/2022 19:44:36 - INFO - __main__ - ['sad']
05/30/2022 19:44:36 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
05/30/2022 19:44:36 - INFO - __main__ - ['sad']
05/30/2022 19:44:36 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
05/30/2022 19:44:36 - INFO - __main__ - ['sad']
05/30/2022 19:44:36 - INFO - __main__ - Tokenizing Input ...
05/30/2022 19:44:36 - INFO - __main__ - Tokenizing Output ...
05/30/2022 19:44:36 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 19:44:36 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 19:44:36 - INFO - __main__ - Printing 3 examples
05/30/2022 19:44:36 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
05/30/2022 19:44:36 - INFO - __main__ - ['sad']
05/30/2022 19:44:36 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
05/30/2022 19:44:36 - INFO - __main__ - ['sad']
05/30/2022 19:44:36 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
05/30/2022 19:44:36 - INFO - __main__ - ['sad']
05/30/2022 19:44:36 - INFO - __main__ - Tokenizing Input ...
05/30/2022 19:44:36 - INFO - __main__ - Tokenizing Output ...
05/30/2022 19:44:36 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 19:44:55 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 19:44:56 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/30/2022 19:44:56 - INFO - __main__ - Starting training!
05/30/2022 19:44:59 - INFO - __main__ - Step 10 Global step 10 Train loss 4.66 on epoch=2
05/30/2022 19:45:01 - INFO - __main__ - Step 20 Global step 20 Train loss 2.97 on epoch=4
05/30/2022 19:45:04 - INFO - __main__ - Step 30 Global step 30 Train loss 2.26 on epoch=7
05/30/2022 19:45:06 - INFO - __main__ - Step 40 Global step 40 Train loss 1.74 on epoch=9
05/30/2022 19:45:09 - INFO - __main__ - Step 50 Global step 50 Train loss 1.63 on epoch=12
05/30/2022 19:45:10 - INFO - __main__ - Global step 50 Train loss 2.65 Classification-F1 0.2565674918616095 on epoch=12
05/30/2022 19:45:10 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.2565674918616095 on epoch=12, global_step=50
05/30/2022 19:45:12 - INFO - __main__ - Step 60 Global step 60 Train loss 1.23 on epoch=14
05/30/2022 19:45:15 - INFO - __main__ - Step 70 Global step 70 Train loss 0.99 on epoch=17
05/30/2022 19:45:17 - INFO - __main__ - Step 80 Global step 80 Train loss 0.93 on epoch=19
05/30/2022 19:45:20 - INFO - __main__ - Step 90 Global step 90 Train loss 0.94 on epoch=22
05/30/2022 19:45:22 - INFO - __main__ - Step 100 Global step 100 Train loss 0.83 on epoch=24
05/30/2022 19:45:23 - INFO - __main__ - Global step 100 Train loss 0.98 Classification-F1 0.5726356976356977 on epoch=24
05/30/2022 19:45:23 - INFO - __main__ - Saving model with best Classification-F1: 0.2565674918616095 -> 0.5726356976356977 on epoch=24, global_step=100
05/30/2022 19:45:26 - INFO - __main__ - Step 110 Global step 110 Train loss 0.86 on epoch=27
05/30/2022 19:45:28 - INFO - __main__ - Step 120 Global step 120 Train loss 0.87 on epoch=29
05/30/2022 19:45:31 - INFO - __main__ - Step 130 Global step 130 Train loss 0.76 on epoch=32
05/30/2022 19:45:33 - INFO - __main__ - Step 140 Global step 140 Train loss 0.81 on epoch=34
05/30/2022 19:45:36 - INFO - __main__ - Step 150 Global step 150 Train loss 0.72 on epoch=37
05/30/2022 19:45:36 - INFO - __main__ - Global step 150 Train loss 0.80 Classification-F1 0.5240377123266324 on epoch=37
05/30/2022 19:45:39 - INFO - __main__ - Step 160 Global step 160 Train loss 0.78 on epoch=39
05/30/2022 19:45:41 - INFO - __main__ - Step 170 Global step 170 Train loss 0.69 on epoch=42
05/30/2022 19:45:44 - INFO - __main__ - Step 180 Global step 180 Train loss 0.67 on epoch=44
05/30/2022 19:45:46 - INFO - __main__ - Step 190 Global step 190 Train loss 0.62 on epoch=47
05/30/2022 19:45:49 - INFO - __main__ - Step 200 Global step 200 Train loss 0.69 on epoch=49
05/30/2022 19:45:50 - INFO - __main__ - Global step 200 Train loss 0.69 Classification-F1 0.6317240627724499 on epoch=49
05/30/2022 19:45:50 - INFO - __main__ - Saving model with best Classification-F1: 0.5726356976356977 -> 0.6317240627724499 on epoch=49, global_step=200
05/30/2022 19:45:52 - INFO - __main__ - Step 210 Global step 210 Train loss 0.59 on epoch=52
05/30/2022 19:45:55 - INFO - __main__ - Step 220 Global step 220 Train loss 0.58 on epoch=54
05/30/2022 19:45:57 - INFO - __main__ - Step 230 Global step 230 Train loss 0.61 on epoch=57
05/30/2022 19:46:00 - INFO - __main__ - Step 240 Global step 240 Train loss 0.49 on epoch=59
05/30/2022 19:46:02 - INFO - __main__ - Step 250 Global step 250 Train loss 0.51 on epoch=62
05/30/2022 19:46:03 - INFO - __main__ - Global step 250 Train loss 0.56 Classification-F1 0.6554270291112396 on epoch=62
05/30/2022 19:46:03 - INFO - __main__ - Saving model with best Classification-F1: 0.6317240627724499 -> 0.6554270291112396 on epoch=62, global_step=250
05/30/2022 19:46:06 - INFO - __main__ - Step 260 Global step 260 Train loss 0.59 on epoch=64
05/30/2022 19:46:08 - INFO - __main__ - Step 270 Global step 270 Train loss 0.46 on epoch=67
05/30/2022 19:46:11 - INFO - __main__ - Step 280 Global step 280 Train loss 0.63 on epoch=69
05/30/2022 19:46:13 - INFO - __main__ - Step 290 Global step 290 Train loss 0.60 on epoch=72
05/30/2022 19:46:16 - INFO - __main__ - Step 300 Global step 300 Train loss 0.58 on epoch=74
05/30/2022 19:46:16 - INFO - __main__ - Global step 300 Train loss 0.57 Classification-F1 0.6594696969696969 on epoch=74
05/30/2022 19:46:16 - INFO - __main__ - Saving model with best Classification-F1: 0.6554270291112396 -> 0.6594696969696969 on epoch=74, global_step=300
05/30/2022 19:46:19 - INFO - __main__ - Step 310 Global step 310 Train loss 0.53 on epoch=77
05/30/2022 19:46:21 - INFO - __main__ - Step 320 Global step 320 Train loss 0.45 on epoch=79
05/30/2022 19:46:24 - INFO - __main__ - Step 330 Global step 330 Train loss 0.45 on epoch=82
05/30/2022 19:46:26 - INFO - __main__ - Step 340 Global step 340 Train loss 0.36 on epoch=84
05/30/2022 19:46:29 - INFO - __main__ - Step 350 Global step 350 Train loss 0.38 on epoch=87
05/30/2022 19:46:30 - INFO - __main__ - Global step 350 Train loss 0.44 Classification-F1 0.7638440860215053 on epoch=87
05/30/2022 19:46:30 - INFO - __main__ - Saving model with best Classification-F1: 0.6594696969696969 -> 0.7638440860215053 on epoch=87, global_step=350
05/30/2022 19:46:32 - INFO - __main__ - Step 360 Global step 360 Train loss 0.44 on epoch=89
05/30/2022 19:46:35 - INFO - __main__ - Step 370 Global step 370 Train loss 0.45 on epoch=92
05/30/2022 19:46:37 - INFO - __main__ - Step 380 Global step 380 Train loss 0.40 on epoch=94
05/30/2022 19:46:40 - INFO - __main__ - Step 390 Global step 390 Train loss 0.41 on epoch=97
05/30/2022 19:46:42 - INFO - __main__ - Step 400 Global step 400 Train loss 0.33 on epoch=99
05/30/2022 19:46:43 - INFO - __main__ - Global step 400 Train loss 0.40 Classification-F1 0.7397702986118047 on epoch=99
05/30/2022 19:46:46 - INFO - __main__ - Step 410 Global step 410 Train loss 0.40 on epoch=102
05/30/2022 19:46:48 - INFO - __main__ - Step 420 Global step 420 Train loss 0.33 on epoch=104
05/30/2022 19:46:51 - INFO - __main__ - Step 430 Global step 430 Train loss 0.30 on epoch=107
05/30/2022 19:46:53 - INFO - __main__ - Step 440 Global step 440 Train loss 0.30 on epoch=109
05/30/2022 19:46:56 - INFO - __main__ - Step 450 Global step 450 Train loss 0.38 on epoch=112
05/30/2022 19:46:57 - INFO - __main__ - Global step 450 Train loss 0.34 Classification-F1 0.7776544873319067 on epoch=112
05/30/2022 19:46:57 - INFO - __main__ - Saving model with best Classification-F1: 0.7638440860215053 -> 0.7776544873319067 on epoch=112, global_step=450
05/30/2022 19:46:59 - INFO - __main__ - Step 460 Global step 460 Train loss 0.32 on epoch=114
05/30/2022 19:47:02 - INFO - __main__ - Step 470 Global step 470 Train loss 0.36 on epoch=117
05/30/2022 19:47:04 - INFO - __main__ - Step 480 Global step 480 Train loss 0.25 on epoch=119
05/30/2022 19:47:07 - INFO - __main__ - Step 490 Global step 490 Train loss 0.31 on epoch=122
05/30/2022 19:47:09 - INFO - __main__ - Step 500 Global step 500 Train loss 0.20 on epoch=124
05/30/2022 19:47:10 - INFO - __main__ - Global step 500 Train loss 0.29 Classification-F1 0.7239476210064446 on epoch=124
05/30/2022 19:47:12 - INFO - __main__ - Step 510 Global step 510 Train loss 0.31 on epoch=127
05/30/2022 19:47:15 - INFO - __main__ - Step 520 Global step 520 Train loss 0.25 on epoch=129
05/30/2022 19:47:17 - INFO - __main__ - Step 530 Global step 530 Train loss 0.29 on epoch=132
05/30/2022 19:47:20 - INFO - __main__ - Step 540 Global step 540 Train loss 0.27 on epoch=134
05/30/2022 19:47:22 - INFO - __main__ - Step 550 Global step 550 Train loss 0.22 on epoch=137
05/30/2022 19:47:23 - INFO - __main__ - Global step 550 Train loss 0.27 Classification-F1 0.7288461538461538 on epoch=137
05/30/2022 19:47:26 - INFO - __main__ - Step 560 Global step 560 Train loss 0.17 on epoch=139
05/30/2022 19:47:28 - INFO - __main__ - Step 570 Global step 570 Train loss 0.29 on epoch=142
05/30/2022 19:47:31 - INFO - __main__ - Step 580 Global step 580 Train loss 0.19 on epoch=144
05/30/2022 19:47:33 - INFO - __main__ - Step 590 Global step 590 Train loss 0.25 on epoch=147
05/30/2022 19:47:36 - INFO - __main__ - Step 600 Global step 600 Train loss 0.21 on epoch=149
05/30/2022 19:47:37 - INFO - __main__ - Global step 600 Train loss 0.22 Classification-F1 0.7102272727272728 on epoch=149
05/30/2022 19:47:39 - INFO - __main__ - Step 610 Global step 610 Train loss 0.20 on epoch=152
05/30/2022 19:47:42 - INFO - __main__ - Step 620 Global step 620 Train loss 0.16 on epoch=154
05/30/2022 19:47:44 - INFO - __main__ - Step 630 Global step 630 Train loss 0.26 on epoch=157
05/30/2022 19:47:47 - INFO - __main__ - Step 640 Global step 640 Train loss 0.19 on epoch=159
05/30/2022 19:47:49 - INFO - __main__ - Step 650 Global step 650 Train loss 0.19 on epoch=162
05/30/2022 19:47:50 - INFO - __main__ - Global step 650 Train loss 0.20 Classification-F1 0.6775058275058274 on epoch=162
05/30/2022 19:47:52 - INFO - __main__ - Step 660 Global step 660 Train loss 0.18 on epoch=164
05/30/2022 19:47:55 - INFO - __main__ - Step 670 Global step 670 Train loss 0.24 on epoch=167
05/30/2022 19:47:57 - INFO - __main__ - Step 680 Global step 680 Train loss 0.19 on epoch=169
05/30/2022 19:48:00 - INFO - __main__ - Step 690 Global step 690 Train loss 0.18 on epoch=172
05/30/2022 19:48:02 - INFO - __main__ - Step 700 Global step 700 Train loss 0.12 on epoch=174
05/30/2022 19:48:03 - INFO - __main__ - Global step 700 Train loss 0.18 Classification-F1 0.7099681020733651 on epoch=174
05/30/2022 19:48:06 - INFO - __main__ - Step 710 Global step 710 Train loss 0.22 on epoch=177
05/30/2022 19:48:08 - INFO - __main__ - Step 720 Global step 720 Train loss 0.18 on epoch=179
05/30/2022 19:48:11 - INFO - __main__ - Step 730 Global step 730 Train loss 0.12 on epoch=182
05/30/2022 19:48:13 - INFO - __main__ - Step 740 Global step 740 Train loss 0.16 on epoch=184
05/30/2022 19:48:16 - INFO - __main__ - Step 750 Global step 750 Train loss 0.14 on epoch=187
05/30/2022 19:48:17 - INFO - __main__ - Global step 750 Train loss 0.17 Classification-F1 0.7039733583851231 on epoch=187
05/30/2022 19:48:19 - INFO - __main__ - Step 760 Global step 760 Train loss 0.09 on epoch=189
05/30/2022 19:48:22 - INFO - __main__ - Step 770 Global step 770 Train loss 0.15 on epoch=192
05/30/2022 19:48:24 - INFO - __main__ - Step 780 Global step 780 Train loss 0.13 on epoch=194
05/30/2022 19:48:27 - INFO - __main__ - Step 790 Global step 790 Train loss 0.20 on epoch=197
05/30/2022 19:48:29 - INFO - __main__ - Step 800 Global step 800 Train loss 0.14 on epoch=199
05/30/2022 19:48:30 - INFO - __main__ - Global step 800 Train loss 0.14 Classification-F1 0.6833565180339374 on epoch=199
05/30/2022 19:48:33 - INFO - __main__ - Step 810 Global step 810 Train loss 0.11 on epoch=202
05/30/2022 19:48:35 - INFO - __main__ - Step 820 Global step 820 Train loss 0.14 on epoch=204
05/30/2022 19:48:38 - INFO - __main__ - Step 830 Global step 830 Train loss 0.08 on epoch=207
05/30/2022 19:48:40 - INFO - __main__ - Step 840 Global step 840 Train loss 0.16 on epoch=209
05/30/2022 19:48:43 - INFO - __main__ - Step 850 Global step 850 Train loss 0.16 on epoch=212
05/30/2022 19:48:43 - INFO - __main__ - Global step 850 Train loss 0.13 Classification-F1 0.6972920806601921 on epoch=212
05/30/2022 19:48:46 - INFO - __main__ - Step 860 Global step 860 Train loss 0.12 on epoch=214
05/30/2022 19:48:48 - INFO - __main__ - Step 870 Global step 870 Train loss 0.07 on epoch=217
05/30/2022 19:48:51 - INFO - __main__ - Step 880 Global step 880 Train loss 0.06 on epoch=219
05/30/2022 19:48:53 - INFO - __main__ - Step 890 Global step 890 Train loss 0.13 on epoch=222
05/30/2022 19:48:56 - INFO - __main__ - Step 900 Global step 900 Train loss 0.11 on epoch=224
05/30/2022 19:48:57 - INFO - __main__ - Global step 900 Train loss 0.10 Classification-F1 0.7110628342245989 on epoch=224
05/30/2022 19:48:59 - INFO - __main__ - Step 910 Global step 910 Train loss 0.16 on epoch=227
05/30/2022 19:49:02 - INFO - __main__ - Step 920 Global step 920 Train loss 0.10 on epoch=229
05/30/2022 19:49:04 - INFO - __main__ - Step 930 Global step 930 Train loss 0.10 on epoch=232
05/30/2022 19:49:07 - INFO - __main__ - Step 940 Global step 940 Train loss 0.07 on epoch=234
05/30/2022 19:49:09 - INFO - __main__ - Step 950 Global step 950 Train loss 0.08 on epoch=237
05/30/2022 19:49:10 - INFO - __main__ - Global step 950 Train loss 0.10 Classification-F1 0.692106846181549 on epoch=237
05/30/2022 19:49:13 - INFO - __main__ - Step 960 Global step 960 Train loss 0.06 on epoch=239
05/30/2022 19:49:15 - INFO - __main__ - Step 970 Global step 970 Train loss 0.08 on epoch=242
05/30/2022 19:49:18 - INFO - __main__ - Step 980 Global step 980 Train loss 0.07 on epoch=244
05/30/2022 19:49:20 - INFO - __main__ - Step 990 Global step 990 Train loss 0.06 on epoch=247
05/30/2022 19:49:23 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.07 on epoch=249
05/30/2022 19:49:24 - INFO - __main__ - Global step 1000 Train loss 0.07 Classification-F1 0.7102272727272728 on epoch=249
05/30/2022 19:49:26 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.04 on epoch=252
05/30/2022 19:49:29 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.08 on epoch=254
05/30/2022 19:49:31 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.13 on epoch=257
05/30/2022 19:49:34 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.06 on epoch=259
05/30/2022 19:49:36 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.08 on epoch=262
05/30/2022 19:49:37 - INFO - __main__ - Global step 1050 Train loss 0.08 Classification-F1 0.7048782838348794 on epoch=262
05/30/2022 19:49:39 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.06 on epoch=264
05/30/2022 19:49:42 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.05 on epoch=267
05/30/2022 19:49:44 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.07 on epoch=269
05/30/2022 19:49:47 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.12 on epoch=272
05/30/2022 19:49:49 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.08 on epoch=274
05/30/2022 19:49:50 - INFO - __main__ - Global step 1100 Train loss 0.08 Classification-F1 0.7191095946387709 on epoch=274
05/30/2022 19:49:53 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.15 on epoch=277
05/30/2022 19:49:55 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.05 on epoch=279
05/30/2022 19:49:58 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.09 on epoch=282
05/30/2022 19:50:00 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.09 on epoch=284
05/30/2022 19:50:03 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.10 on epoch=287
05/30/2022 19:50:04 - INFO - __main__ - Global step 1150 Train loss 0.10 Classification-F1 0.7379772915256787 on epoch=287
05/30/2022 19:50:06 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.04 on epoch=289
05/30/2022 19:50:09 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.10 on epoch=292
05/30/2022 19:50:11 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.05 on epoch=294
05/30/2022 19:50:14 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.10 on epoch=297
05/30/2022 19:50:16 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.04 on epoch=299
05/30/2022 19:50:17 - INFO - __main__ - Global step 1200 Train loss 0.07 Classification-F1 0.6834034198963868 on epoch=299
05/30/2022 19:50:20 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.05 on epoch=302
05/30/2022 19:50:22 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.06 on epoch=304
05/30/2022 19:50:24 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.09 on epoch=307
05/30/2022 19:50:27 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.02 on epoch=309
05/30/2022 19:50:30 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.09 on epoch=312
05/30/2022 19:50:30 - INFO - __main__ - Global step 1250 Train loss 0.06 Classification-F1 0.7064649877149877 on epoch=312
05/30/2022 19:50:33 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.03 on epoch=314
05/30/2022 19:50:35 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.03 on epoch=317
05/30/2022 19:50:38 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.03 on epoch=319
05/30/2022 19:50:40 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.06 on epoch=322
05/30/2022 19:50:43 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.04 on epoch=324
05/30/2022 19:50:44 - INFO - __main__ - Global step 1300 Train loss 0.04 Classification-F1 0.6845259263022421 on epoch=324
05/30/2022 19:50:46 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.07 on epoch=327
05/30/2022 19:50:49 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.06 on epoch=329
05/30/2022 19:50:51 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.04 on epoch=332
05/30/2022 19:50:54 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.05 on epoch=334
05/30/2022 19:50:56 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.06 on epoch=337
05/30/2022 19:50:57 - INFO - __main__ - Global step 1350 Train loss 0.05 Classification-F1 0.7060837907612102 on epoch=337
05/30/2022 19:51:00 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.06 on epoch=339
05/30/2022 19:51:02 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.09 on epoch=342
05/30/2022 19:51:05 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.14 on epoch=344
05/30/2022 19:51:07 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.02 on epoch=347
05/30/2022 19:51:10 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.03 on epoch=349
05/30/2022 19:51:11 - INFO - __main__ - Global step 1400 Train loss 0.07 Classification-F1 0.6927693629730982 on epoch=349
05/30/2022 19:51:13 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.05 on epoch=352
05/30/2022 19:51:16 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.05 on epoch=354
05/30/2022 19:51:18 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.09 on epoch=357
05/30/2022 19:51:21 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.03 on epoch=359
05/30/2022 19:51:23 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.05 on epoch=362
05/30/2022 19:51:24 - INFO - __main__ - Global step 1450 Train loss 0.05 Classification-F1 0.6909722222222222 on epoch=362
05/30/2022 19:51:27 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.05 on epoch=364
05/30/2022 19:51:29 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.06 on epoch=367
05/30/2022 19:51:32 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.06 on epoch=369
05/30/2022 19:51:34 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.03 on epoch=372
05/30/2022 19:51:37 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.05 on epoch=374
05/30/2022 19:51:38 - INFO - __main__ - Global step 1500 Train loss 0.05 Classification-F1 0.7054160138399268 on epoch=374
05/30/2022 19:51:40 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.06 on epoch=377
05/30/2022 19:51:43 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.05 on epoch=379
05/30/2022 19:51:45 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.02 on epoch=382
05/30/2022 19:51:48 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=384
05/30/2022 19:51:50 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=387
05/30/2022 19:51:51 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.6895149613899614 on epoch=387
05/30/2022 19:51:54 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.07 on epoch=389
05/30/2022 19:51:56 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.04 on epoch=392
05/30/2022 19:51:59 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.06 on epoch=394
05/30/2022 19:52:01 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.03 on epoch=397
05/30/2022 19:52:04 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=399
05/30/2022 19:52:04 - INFO - __main__ - Global step 1600 Train loss 0.04 Classification-F1 0.6914635533148856 on epoch=399
05/30/2022 19:52:07 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=402
05/30/2022 19:52:09 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=404
05/30/2022 19:52:12 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.04 on epoch=407
05/30/2022 19:52:14 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.02 on epoch=409
05/30/2022 19:52:17 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.05 on epoch=412
05/30/2022 19:52:18 - INFO - __main__ - Global step 1650 Train loss 0.03 Classification-F1 0.7331809947299077 on epoch=412
05/30/2022 19:52:20 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=414
05/30/2022 19:52:23 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=417
05/30/2022 19:52:25 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.05 on epoch=419
05/30/2022 19:52:28 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.05 on epoch=422
05/30/2022 19:52:30 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.04 on epoch=424
05/30/2022 19:52:31 - INFO - __main__ - Global step 1700 Train loss 0.04 Classification-F1 0.6863899613899613 on epoch=424
05/30/2022 19:52:34 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.07 on epoch=427
05/30/2022 19:52:36 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=429
05/30/2022 19:52:39 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.03 on epoch=432
05/30/2022 19:52:41 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.04 on epoch=434
05/30/2022 19:52:44 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=437
05/30/2022 19:52:45 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.7190128711867843 on epoch=437
05/30/2022 19:52:47 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.03 on epoch=439
05/30/2022 19:52:50 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.05 on epoch=442
05/30/2022 19:52:52 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.04 on epoch=444
05/30/2022 19:52:55 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=447
05/30/2022 19:52:57 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=449
05/30/2022 19:52:58 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.7342986314760509 on epoch=449
05/30/2022 19:53:01 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=452
05/30/2022 19:53:03 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.07 on epoch=454
05/30/2022 19:53:06 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=457
05/30/2022 19:53:08 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=459
05/30/2022 19:53:11 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.05 on epoch=462
05/30/2022 19:53:11 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.7191471163245358 on epoch=462
05/30/2022 19:53:14 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=464
05/30/2022 19:53:16 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.07 on epoch=467
05/30/2022 19:53:19 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.03 on epoch=469
05/30/2022 19:53:21 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.09 on epoch=472
05/30/2022 19:53:24 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.02 on epoch=474
05/30/2022 19:53:25 - INFO - __main__ - Global step 1900 Train loss 0.05 Classification-F1 0.7541063237837432 on epoch=474
05/30/2022 19:53:27 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=477
05/30/2022 19:53:30 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=479
05/30/2022 19:53:32 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=482
05/30/2022 19:53:35 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.04 on epoch=484
05/30/2022 19:53:37 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=487
05/30/2022 19:53:38 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.7389548086322281 on epoch=487
05/30/2022 19:53:40 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=489
05/30/2022 19:53:43 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=492
05/30/2022 19:53:45 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=494
05/30/2022 19:53:48 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=497
05/30/2022 19:53:50 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=499
05/30/2022 19:53:51 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.7342986314760509 on epoch=499
05/30/2022 19:53:54 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=502
05/30/2022 19:53:56 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=504
05/30/2022 19:53:59 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.03 on epoch=507
05/30/2022 19:54:01 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=509
05/30/2022 19:54:04 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.02 on epoch=512
05/30/2022 19:54:04 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.7541063237837432 on epoch=512
05/30/2022 19:54:07 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=514
05/30/2022 19:54:09 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=517
05/30/2022 19:54:12 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=519
05/30/2022 19:54:14 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=522
05/30/2022 19:54:17 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=524
05/30/2022 19:54:18 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.7342986314760509 on epoch=524
05/30/2022 19:54:20 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=527
05/30/2022 19:54:23 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=529
05/30/2022 19:54:25 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=532
05/30/2022 19:54:28 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=534
05/30/2022 19:54:30 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.10 on epoch=537
05/30/2022 19:54:31 - INFO - __main__ - Global step 2150 Train loss 0.03 Classification-F1 0.7341826923076923 on epoch=537
05/30/2022 19:54:34 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=539
05/30/2022 19:54:36 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=542
05/30/2022 19:54:39 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=544
05/30/2022 19:54:41 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=547
05/30/2022 19:54:44 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=549
05/30/2022 19:54:45 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.7342986314760509 on epoch=549
05/30/2022 19:54:47 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
05/30/2022 19:54:50 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=554
05/30/2022 19:54:52 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=557
05/30/2022 19:54:55 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.08 on epoch=559
05/30/2022 19:54:57 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=562
05/30/2022 19:54:58 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.6895021645021645 on epoch=562
05/30/2022 19:55:01 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=564
05/30/2022 19:55:03 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=567
05/30/2022 19:55:06 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=569
05/30/2022 19:55:08 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.06 on epoch=572
05/30/2022 19:55:11 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.09 on epoch=574
05/30/2022 19:55:12 - INFO - __main__ - Global step 2300 Train loss 0.04 Classification-F1 0.7196212121212121 on epoch=574
05/30/2022 19:55:14 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=577
05/30/2022 19:55:17 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=579
05/30/2022 19:55:19 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=582
05/30/2022 19:55:22 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=584
05/30/2022 19:55:24 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=587
05/30/2022 19:55:25 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.7051435406698565 on epoch=587
05/30/2022 19:55:28 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=589
05/30/2022 19:55:30 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.03 on epoch=592
05/30/2022 19:55:33 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
05/30/2022 19:55:35 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=597
05/30/2022 19:55:38 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=599
05/30/2022 19:55:39 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.7394567384370017 on epoch=599
05/30/2022 19:55:41 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=602
05/30/2022 19:55:44 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=604
05/30/2022 19:55:46 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=607
05/30/2022 19:55:49 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=609
05/30/2022 19:55:51 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=612
05/30/2022 19:55:52 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.6895021645021645 on epoch=612
05/30/2022 19:55:55 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
05/30/2022 19:55:57 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=617
05/30/2022 19:56:00 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
05/30/2022 19:56:02 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.03 on epoch=622
05/30/2022 19:56:05 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.04 on epoch=624
05/30/2022 19:56:06 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.7389548086322281 on epoch=624
05/30/2022 19:56:08 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=627
05/30/2022 19:56:11 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=629
05/30/2022 19:56:13 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.08 on epoch=632
05/30/2022 19:56:15 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=634
05/30/2022 19:56:18 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=637
05/30/2022 19:56:19 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.7202068764568765 on epoch=637
05/30/2022 19:56:21 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.03 on epoch=639
05/30/2022 19:56:24 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=642
05/30/2022 19:56:26 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
05/30/2022 19:56:29 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=647
05/30/2022 19:56:31 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.04 on epoch=649
05/30/2022 19:56:32 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.6973661533850362 on epoch=649
05/30/2022 19:56:35 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.05 on epoch=652
05/30/2022 19:56:37 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=654
05/30/2022 19:56:40 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=657
05/30/2022 19:56:42 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.05 on epoch=659
05/30/2022 19:56:45 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=662
05/30/2022 19:56:46 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.739044289044289 on epoch=662
05/30/2022 19:56:48 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
05/30/2022 19:56:51 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.03 on epoch=667
05/30/2022 19:56:53 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.04 on epoch=669
05/30/2022 19:56:56 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=672
05/30/2022 19:56:58 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=674
05/30/2022 19:56:59 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.7197333916083917 on epoch=674
05/30/2022 19:57:02 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.03 on epoch=677
05/30/2022 19:57:04 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=679
05/30/2022 19:57:07 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.03 on epoch=682
05/30/2022 19:57:09 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=684
05/30/2022 19:57:12 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
05/30/2022 19:57:13 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.7035119969040248 on epoch=687
05/30/2022 19:57:15 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
05/30/2022 19:57:18 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=692
05/30/2022 19:57:20 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
05/30/2022 19:57:23 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=697
05/30/2022 19:57:25 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.03 on epoch=699
05/30/2022 19:57:26 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.7342986314760509 on epoch=699
05/30/2022 19:57:29 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=702
05/30/2022 19:57:31 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
05/30/2022 19:57:34 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=707
05/30/2022 19:57:36 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=709
05/30/2022 19:57:39 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=712
05/30/2022 19:57:40 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.7183014354066986 on epoch=712
05/30/2022 19:57:42 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
05/30/2022 19:57:45 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=717
05/30/2022 19:57:47 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
05/30/2022 19:57:50 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=722
05/30/2022 19:57:52 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=724
05/30/2022 19:57:53 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.683574536730217 on epoch=724
05/30/2022 19:57:56 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
05/30/2022 19:57:58 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=729
05/30/2022 19:58:01 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=732
05/30/2022 19:58:03 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
05/30/2022 19:58:06 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.03 on epoch=737
05/30/2022 19:58:07 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.7181341799855123 on epoch=737
05/30/2022 19:58:09 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.03 on epoch=739
05/30/2022 19:58:12 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
05/30/2022 19:58:14 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
05/30/2022 19:58:17 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=747
05/30/2022 19:58:19 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
05/30/2022 19:58:21 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.687255833597297 on epoch=749
05/30/2022 19:58:21 - INFO - __main__ - save last model!
05/30/2022 19:58:21 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/30/2022 19:58:21 - INFO - __main__ - Start tokenizing ... 5509 instances
05/30/2022 19:58:21 - INFO - __main__ - Printing 3 examples
05/30/2022 19:58:21 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/30/2022 19:58:21 - INFO - __main__ - ['others']
05/30/2022 19:58:21 - INFO - __main__ -  [emo] what you like very little things ok
05/30/2022 19:58:21 - INFO - __main__ - ['others']
05/30/2022 19:58:21 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/30/2022 19:58:21 - INFO - __main__ - ['others']
05/30/2022 19:58:21 - INFO - __main__ - Tokenizing Input ...
05/30/2022 19:58:21 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 19:58:21 - INFO - __main__ - Printing 3 examples
05/30/2022 19:58:21 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
05/30/2022 19:58:21 - INFO - __main__ - ['happy']
05/30/2022 19:58:21 - INFO - __main__ -  [emo] your right i'm always right i am impressed
05/30/2022 19:58:21 - INFO - __main__ - ['happy']
05/30/2022 19:58:21 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
05/30/2022 19:58:21 - INFO - __main__ - ['happy']
05/30/2022 19:58:21 - INFO - __main__ - Tokenizing Input ...
05/30/2022 19:58:21 - INFO - __main__ - Tokenizing Output ...
05/30/2022 19:58:21 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 19:58:21 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 19:58:21 - INFO - __main__ - Printing 3 examples
05/30/2022 19:58:21 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
05/30/2022 19:58:21 - INFO - __main__ - ['happy']
05/30/2022 19:58:21 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
05/30/2022 19:58:21 - INFO - __main__ - ['happy']
05/30/2022 19:58:21 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
05/30/2022 19:58:21 - INFO - __main__ - ['happy']
05/30/2022 19:58:21 - INFO - __main__ - Tokenizing Input ...
05/30/2022 19:58:21 - INFO - __main__ - Tokenizing Output ...
05/30/2022 19:58:21 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 19:58:23 - INFO - __main__ - Tokenizing Output ...
05/30/2022 19:58:28 - INFO - __main__ - Loaded 5509 examples from test data
05/30/2022 19:58:36 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 19:58:37 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/30/2022 19:58:37 - INFO - __main__ - Starting training!
05/30/2022 20:00:02 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-24uptasks/singletask-emo/emo_16_21_0.2_8_predictions.txt
05/30/2022 20:00:02 - INFO - __main__ - Classification-F1 on test data: 0.1628
05/30/2022 20:00:02 - INFO - __main__ - prefix=emo_16_21, lr=0.2, bsz=8, dev_performance=0.7776544873319067, test_performance=0.1627870971717635
05/30/2022 20:00:02 - INFO - __main__ - Running ... prefix=emo_16_42, lr=0.5, bsz=8 ...
05/30/2022 20:00:03 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 20:00:03 - INFO - __main__ - Printing 3 examples
05/30/2022 20:00:03 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
05/30/2022 20:00:03 - INFO - __main__ - ['happy']
05/30/2022 20:00:03 - INFO - __main__ -  [emo] your right i'm always right i am impressed
05/30/2022 20:00:03 - INFO - __main__ - ['happy']
05/30/2022 20:00:03 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
05/30/2022 20:00:03 - INFO - __main__ - ['happy']
05/30/2022 20:00:03 - INFO - __main__ - Tokenizing Input ...
05/30/2022 20:00:03 - INFO - __main__ - Tokenizing Output ...
05/30/2022 20:00:03 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 20:00:03 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 20:00:03 - INFO - __main__ - Printing 3 examples
05/30/2022 20:00:03 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
05/30/2022 20:00:03 - INFO - __main__ - ['happy']
05/30/2022 20:00:03 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
05/30/2022 20:00:03 - INFO - __main__ - ['happy']
05/30/2022 20:00:03 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
05/30/2022 20:00:03 - INFO - __main__ - ['happy']
05/30/2022 20:00:03 - INFO - __main__ - Tokenizing Input ...
05/30/2022 20:00:03 - INFO - __main__ - Tokenizing Output ...
05/30/2022 20:00:03 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 20:00:19 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 20:00:20 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/30/2022 20:00:20 - INFO - __main__ - Starting training!
05/30/2022 20:00:23 - INFO - __main__ - Step 10 Global step 10 Train loss 3.45 on epoch=2
05/30/2022 20:00:25 - INFO - __main__ - Step 20 Global step 20 Train loss 1.88 on epoch=4
05/30/2022 20:00:28 - INFO - __main__ - Step 30 Global step 30 Train loss 1.17 on epoch=7
05/30/2022 20:00:30 - INFO - __main__ - Step 40 Global step 40 Train loss 1.01 on epoch=9
05/30/2022 20:00:33 - INFO - __main__ - Step 50 Global step 50 Train loss 0.88 on epoch=12
05/30/2022 20:00:33 - INFO - __main__ - Global step 50 Train loss 1.68 Classification-F1 0.41937735585648467 on epoch=12
05/30/2022 20:00:33 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.41937735585648467 on epoch=12, global_step=50
05/30/2022 20:00:36 - INFO - __main__ - Step 60 Global step 60 Train loss 0.78 on epoch=14
05/30/2022 20:00:38 - INFO - __main__ - Step 70 Global step 70 Train loss 0.81 on epoch=17
05/30/2022 20:00:41 - INFO - __main__ - Step 80 Global step 80 Train loss 0.81 on epoch=19
05/30/2022 20:00:43 - INFO - __main__ - Step 90 Global step 90 Train loss 0.74 on epoch=22
05/30/2022 20:00:46 - INFO - __main__ - Step 100 Global step 100 Train loss 0.70 on epoch=24
05/30/2022 20:00:46 - INFO - __main__ - Global step 100 Train loss 0.77 Classification-F1 0.5012041598248496 on epoch=24
05/30/2022 20:00:46 - INFO - __main__ - Saving model with best Classification-F1: 0.41937735585648467 -> 0.5012041598248496 on epoch=24, global_step=100
05/30/2022 20:00:49 - INFO - __main__ - Step 110 Global step 110 Train loss 0.77 on epoch=27
05/30/2022 20:00:51 - INFO - __main__ - Step 120 Global step 120 Train loss 0.63 on epoch=29
05/30/2022 20:00:54 - INFO - __main__ - Step 130 Global step 130 Train loss 0.64 on epoch=32
05/30/2022 20:00:56 - INFO - __main__ - Step 140 Global step 140 Train loss 0.57 on epoch=34
05/30/2022 20:00:58 - INFO - __main__ - Step 150 Global step 150 Train loss 0.61 on epoch=37
05/30/2022 20:00:59 - INFO - __main__ - Global step 150 Train loss 0.64 Classification-F1 0.5370790064156773 on epoch=37
05/30/2022 20:00:59 - INFO - __main__ - Saving model with best Classification-F1: 0.5012041598248496 -> 0.5370790064156773 on epoch=37, global_step=150
05/30/2022 20:01:02 - INFO - __main__ - Step 160 Global step 160 Train loss 0.59 on epoch=39
05/30/2022 20:01:04 - INFO - __main__ - Step 170 Global step 170 Train loss 0.55 on epoch=42
05/30/2022 20:01:07 - INFO - __main__ - Step 180 Global step 180 Train loss 0.51 on epoch=44
05/30/2022 20:01:09 - INFO - __main__ - Step 190 Global step 190 Train loss 0.51 on epoch=47
05/30/2022 20:01:12 - INFO - __main__ - Step 200 Global step 200 Train loss 0.54 on epoch=49
05/30/2022 20:01:12 - INFO - __main__ - Global step 200 Train loss 0.54 Classification-F1 0.6481780167264038 on epoch=49
05/30/2022 20:01:12 - INFO - __main__ - Saving model with best Classification-F1: 0.5370790064156773 -> 0.6481780167264038 on epoch=49, global_step=200
05/30/2022 20:01:15 - INFO - __main__ - Step 210 Global step 210 Train loss 0.42 on epoch=52
05/30/2022 20:01:17 - INFO - __main__ - Step 220 Global step 220 Train loss 0.45 on epoch=54
05/30/2022 20:01:20 - INFO - __main__ - Step 230 Global step 230 Train loss 0.35 on epoch=57
05/30/2022 20:01:22 - INFO - __main__ - Step 240 Global step 240 Train loss 0.47 on epoch=59
05/30/2022 20:01:25 - INFO - __main__ - Step 250 Global step 250 Train loss 0.38 on epoch=62
05/30/2022 20:01:25 - INFO - __main__ - Global step 250 Train loss 0.41 Classification-F1 0.4882102874884318 on epoch=62
05/30/2022 20:01:28 - INFO - __main__ - Step 260 Global step 260 Train loss 0.36 on epoch=64
05/30/2022 20:01:30 - INFO - __main__ - Step 270 Global step 270 Train loss 0.38 on epoch=67
05/30/2022 20:01:33 - INFO - __main__ - Step 280 Global step 280 Train loss 0.37 on epoch=69
05/30/2022 20:01:35 - INFO - __main__ - Step 290 Global step 290 Train loss 0.28 on epoch=72
05/30/2022 20:01:37 - INFO - __main__ - Step 300 Global step 300 Train loss 0.22 on epoch=74
05/30/2022 20:01:38 - INFO - __main__ - Global step 300 Train loss 0.32 Classification-F1 0.7194975147561354 on epoch=74
05/30/2022 20:01:38 - INFO - __main__ - Saving model with best Classification-F1: 0.6481780167264038 -> 0.7194975147561354 on epoch=74, global_step=300
05/30/2022 20:01:41 - INFO - __main__ - Step 310 Global step 310 Train loss 0.28 on epoch=77
05/30/2022 20:01:43 - INFO - __main__ - Step 320 Global step 320 Train loss 0.39 on epoch=79
05/30/2022 20:01:46 - INFO - __main__ - Step 330 Global step 330 Train loss 0.26 on epoch=82
05/30/2022 20:01:48 - INFO - __main__ - Step 340 Global step 340 Train loss 0.36 on epoch=84
05/30/2022 20:01:50 - INFO - __main__ - Step 350 Global step 350 Train loss 0.34 on epoch=87
05/30/2022 20:01:51 - INFO - __main__ - Global step 350 Train loss 0.32 Classification-F1 0.653219696969697 on epoch=87
05/30/2022 20:01:54 - INFO - __main__ - Step 360 Global step 360 Train loss 0.26 on epoch=89
05/30/2022 20:01:56 - INFO - __main__ - Step 370 Global step 370 Train loss 0.28 on epoch=92
05/30/2022 20:01:58 - INFO - __main__ - Step 380 Global step 380 Train loss 0.21 on epoch=94
05/30/2022 20:02:01 - INFO - __main__ - Step 390 Global step 390 Train loss 0.16 on epoch=97
05/30/2022 20:02:03 - INFO - __main__ - Step 400 Global step 400 Train loss 0.26 on epoch=99
05/30/2022 20:02:04 - INFO - __main__ - Global step 400 Train loss 0.23 Classification-F1 0.7067329712752732 on epoch=99
05/30/2022 20:02:07 - INFO - __main__ - Step 410 Global step 410 Train loss 0.22 on epoch=102
05/30/2022 20:02:09 - INFO - __main__ - Step 420 Global step 420 Train loss 0.20 on epoch=104
05/30/2022 20:02:11 - INFO - __main__ - Step 430 Global step 430 Train loss 0.28 on epoch=107
05/30/2022 20:02:14 - INFO - __main__ - Step 440 Global step 440 Train loss 0.24 on epoch=109
05/30/2022 20:02:16 - INFO - __main__ - Step 450 Global step 450 Train loss 0.10 on epoch=112
05/30/2022 20:02:17 - INFO - __main__ - Global step 450 Train loss 0.21 Classification-F1 0.6165995564892623 on epoch=112
05/30/2022 20:02:20 - INFO - __main__ - Step 460 Global step 460 Train loss 0.15 on epoch=114
05/30/2022 20:02:22 - INFO - __main__ - Step 470 Global step 470 Train loss 0.11 on epoch=117
05/30/2022 20:02:25 - INFO - __main__ - Step 480 Global step 480 Train loss 0.10 on epoch=119
05/30/2022 20:02:27 - INFO - __main__ - Step 490 Global step 490 Train loss 0.11 on epoch=122
05/30/2022 20:02:30 - INFO - __main__ - Step 500 Global step 500 Train loss 0.12 on epoch=124
05/30/2022 20:02:31 - INFO - __main__ - Global step 500 Train loss 0.12 Classification-F1 0.7536916920676654 on epoch=124
05/30/2022 20:02:31 - INFO - __main__ - Saving model with best Classification-F1: 0.7194975147561354 -> 0.7536916920676654 on epoch=124, global_step=500
05/30/2022 20:02:33 - INFO - __main__ - Step 510 Global step 510 Train loss 0.09 on epoch=127
05/30/2022 20:02:36 - INFO - __main__ - Step 520 Global step 520 Train loss 0.13 on epoch=129
05/30/2022 20:02:38 - INFO - __main__ - Step 530 Global step 530 Train loss 0.13 on epoch=132
05/30/2022 20:02:41 - INFO - __main__ - Step 540 Global step 540 Train loss 0.16 on epoch=134
05/30/2022 20:02:43 - INFO - __main__ - Step 550 Global step 550 Train loss 0.19 on epoch=137
05/30/2022 20:02:44 - INFO - __main__ - Global step 550 Train loss 0.14 Classification-F1 0.6480886999179682 on epoch=137
05/30/2022 20:02:47 - INFO - __main__ - Step 560 Global step 560 Train loss 0.13 on epoch=139
05/30/2022 20:02:49 - INFO - __main__ - Step 570 Global step 570 Train loss 0.11 on epoch=142
05/30/2022 20:02:52 - INFO - __main__ - Step 580 Global step 580 Train loss 0.05 on epoch=144
05/30/2022 20:02:54 - INFO - __main__ - Step 590 Global step 590 Train loss 0.09 on epoch=147
05/30/2022 20:02:57 - INFO - __main__ - Step 600 Global step 600 Train loss 0.08 on epoch=149
05/30/2022 20:02:58 - INFO - __main__ - Global step 600 Train loss 0.09 Classification-F1 0.7026514053897421 on epoch=149
05/30/2022 20:03:00 - INFO - __main__ - Step 610 Global step 610 Train loss 0.17 on epoch=152
05/30/2022 20:03:03 - INFO - __main__ - Step 620 Global step 620 Train loss 0.07 on epoch=154
05/30/2022 20:03:05 - INFO - __main__ - Step 630 Global step 630 Train loss 0.03 on epoch=157
05/30/2022 20:03:08 - INFO - __main__ - Step 640 Global step 640 Train loss 0.06 on epoch=159
05/30/2022 20:03:11 - INFO - __main__ - Step 650 Global step 650 Train loss 0.04 on epoch=162
05/30/2022 20:03:11 - INFO - __main__ - Global step 650 Train loss 0.07 Classification-F1 0.7024147590070511 on epoch=162
05/30/2022 20:03:14 - INFO - __main__ - Step 660 Global step 660 Train loss 0.13 on epoch=164
05/30/2022 20:03:16 - INFO - __main__ - Step 670 Global step 670 Train loss 0.04 on epoch=167
05/30/2022 20:03:19 - INFO - __main__ - Step 680 Global step 680 Train loss 0.09 on epoch=169
05/30/2022 20:03:21 - INFO - __main__ - Step 690 Global step 690 Train loss 0.05 on epoch=172
05/30/2022 20:03:24 - INFO - __main__ - Step 700 Global step 700 Train loss 0.03 on epoch=174
05/30/2022 20:03:25 - INFO - __main__ - Global step 700 Train loss 0.07 Classification-F1 0.73209642279851 on epoch=174
05/30/2022 20:03:27 - INFO - __main__ - Step 710 Global step 710 Train loss 0.05 on epoch=177
05/30/2022 20:03:30 - INFO - __main__ - Step 720 Global step 720 Train loss 0.11 on epoch=179
05/30/2022 20:03:32 - INFO - __main__ - Step 730 Global step 730 Train loss 0.05 on epoch=182
05/30/2022 20:03:35 - INFO - __main__ - Step 740 Global step 740 Train loss 0.03 on epoch=184
05/30/2022 20:03:38 - INFO - __main__ - Step 750 Global step 750 Train loss 0.04 on epoch=187
05/30/2022 20:03:39 - INFO - __main__ - Global step 750 Train loss 0.05 Classification-F1 0.7457310251427898 on epoch=187
05/30/2022 20:03:41 - INFO - __main__ - Step 760 Global step 760 Train loss 0.02 on epoch=189
05/30/2022 20:03:44 - INFO - __main__ - Step 770 Global step 770 Train loss 0.05 on epoch=192
05/30/2022 20:03:46 - INFO - __main__ - Step 780 Global step 780 Train loss 0.04 on epoch=194
05/30/2022 20:03:49 - INFO - __main__ - Step 790 Global step 790 Train loss 0.03 on epoch=197
05/30/2022 20:03:51 - INFO - __main__ - Step 800 Global step 800 Train loss 0.06 on epoch=199
05/30/2022 20:03:52 - INFO - __main__ - Global step 800 Train loss 0.04 Classification-F1 0.6657560688346529 on epoch=199
05/30/2022 20:03:55 - INFO - __main__ - Step 810 Global step 810 Train loss 0.06 on epoch=202
05/30/2022 20:03:57 - INFO - __main__ - Step 820 Global step 820 Train loss 0.03 on epoch=204
05/30/2022 20:04:00 - INFO - __main__ - Step 830 Global step 830 Train loss 0.06 on epoch=207
05/30/2022 20:04:02 - INFO - __main__ - Step 840 Global step 840 Train loss 0.04 on epoch=209
05/30/2022 20:04:05 - INFO - __main__ - Step 850 Global step 850 Train loss 0.04 on epoch=212
05/30/2022 20:04:06 - INFO - __main__ - Global step 850 Train loss 0.05 Classification-F1 0.6107962213225371 on epoch=212
05/30/2022 20:04:08 - INFO - __main__ - Step 860 Global step 860 Train loss 0.06 on epoch=214
05/30/2022 20:04:11 - INFO - __main__ - Step 870 Global step 870 Train loss 0.02 on epoch=217
05/30/2022 20:04:13 - INFO - __main__ - Step 880 Global step 880 Train loss 0.01 on epoch=219
05/30/2022 20:04:16 - INFO - __main__ - Step 890 Global step 890 Train loss 0.01 on epoch=222
05/30/2022 20:04:19 - INFO - __main__ - Step 900 Global step 900 Train loss 0.14 on epoch=224
05/30/2022 20:04:20 - INFO - __main__ - Global step 900 Train loss 0.05 Classification-F1 0.7501313187492274 on epoch=224
05/30/2022 20:04:22 - INFO - __main__ - Step 910 Global step 910 Train loss 0.04 on epoch=227
05/30/2022 20:04:25 - INFO - __main__ - Step 920 Global step 920 Train loss 0.03 on epoch=229
05/30/2022 20:04:27 - INFO - __main__ - Step 930 Global step 930 Train loss 0.12 on epoch=232
05/30/2022 20:04:29 - INFO - __main__ - Step 940 Global step 940 Train loss 0.04 on epoch=234
05/30/2022 20:04:32 - INFO - __main__ - Step 950 Global step 950 Train loss 0.03 on epoch=237
05/30/2022 20:04:33 - INFO - __main__ - Global step 950 Train loss 0.05 Classification-F1 0.7114296562572424 on epoch=237
05/30/2022 20:04:35 - INFO - __main__ - Step 960 Global step 960 Train loss 0.02 on epoch=239
05/30/2022 20:04:38 - INFO - __main__ - Step 970 Global step 970 Train loss 0.09 on epoch=242
05/30/2022 20:04:40 - INFO - __main__ - Step 980 Global step 980 Train loss 0.06 on epoch=244
05/30/2022 20:04:43 - INFO - __main__ - Step 990 Global step 990 Train loss 0.07 on epoch=247
05/30/2022 20:04:45 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.09 on epoch=249
05/30/2022 20:04:46 - INFO - __main__ - Global step 1000 Train loss 0.07 Classification-F1 0.7211580086580086 on epoch=249
05/30/2022 20:04:49 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.03 on epoch=252
05/30/2022 20:04:51 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.04 on epoch=254
05/30/2022 20:04:54 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.01 on epoch=257
05/30/2022 20:04:56 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.01 on epoch=259
05/30/2022 20:04:59 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.02 on epoch=262
05/30/2022 20:04:59 - INFO - __main__ - Global step 1050 Train loss 0.02 Classification-F1 0.6657467532467533 on epoch=262
05/30/2022 20:05:02 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.04 on epoch=264
05/30/2022 20:05:04 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.03 on epoch=267
05/30/2022 20:05:07 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.10 on epoch=269
05/30/2022 20:05:09 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.03 on epoch=272
05/30/2022 20:05:12 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.04 on epoch=274
05/30/2022 20:05:13 - INFO - __main__ - Global step 1100 Train loss 0.05 Classification-F1 0.6693681318681319 on epoch=274
05/30/2022 20:05:15 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.02 on epoch=277
05/30/2022 20:05:18 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.00 on epoch=279
05/30/2022 20:05:20 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=282
05/30/2022 20:05:22 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.02 on epoch=284
05/30/2022 20:05:25 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.04 on epoch=287
05/30/2022 20:05:26 - INFO - __main__ - Global step 1150 Train loss 0.02 Classification-F1 0.7011904761904761 on epoch=287
05/30/2022 20:05:28 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.01 on epoch=289
05/30/2022 20:05:31 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.04 on epoch=292
05/30/2022 20:05:33 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.06 on epoch=294
05/30/2022 20:05:36 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.07 on epoch=297
05/30/2022 20:05:38 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.08 on epoch=299
05/30/2022 20:05:39 - INFO - __main__ - Global step 1200 Train loss 0.05 Classification-F1 0.6539462849946722 on epoch=299
05/30/2022 20:05:41 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.01 on epoch=302
05/30/2022 20:05:44 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=304
05/30/2022 20:05:46 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=307
05/30/2022 20:05:49 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=309
05/30/2022 20:05:51 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.09 on epoch=312
05/30/2022 20:05:52 - INFO - __main__ - Global step 1250 Train loss 0.03 Classification-F1 0.7344640313390313 on epoch=312
05/30/2022 20:05:55 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=314
05/30/2022 20:05:57 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.08 on epoch=317
05/30/2022 20:06:00 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=319
05/30/2022 20:06:02 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.00 on epoch=322
05/30/2022 20:06:05 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.00 on epoch=324
05/30/2022 20:06:06 - INFO - __main__ - Global step 1300 Train loss 0.02 Classification-F1 0.717652329749104 on epoch=324
05/30/2022 20:06:08 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=327
05/30/2022 20:06:11 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.00 on epoch=329
05/30/2022 20:06:13 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=332
05/30/2022 20:06:16 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.00 on epoch=334
05/30/2022 20:06:18 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=337
05/30/2022 20:06:19 - INFO - __main__ - Global step 1350 Train loss 0.01 Classification-F1 0.7160173160173161 on epoch=337
05/30/2022 20:06:22 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.04 on epoch=339
05/30/2022 20:06:24 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=342
05/30/2022 20:06:26 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=344
05/30/2022 20:06:29 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.00 on epoch=347
05/30/2022 20:06:31 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.03 on epoch=349
05/30/2022 20:06:32 - INFO - __main__ - Global step 1400 Train loss 0.02 Classification-F1 0.7165596123506874 on epoch=349
05/30/2022 20:06:35 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=352
05/30/2022 20:06:37 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=354
05/30/2022 20:06:40 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.00 on epoch=357
05/30/2022 20:06:42 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=359
05/30/2022 20:06:45 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=362
05/30/2022 20:06:46 - INFO - __main__ - Global step 1450 Train loss 0.01 Classification-F1 0.7192652329749104 on epoch=362
05/30/2022 20:06:48 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=364
05/30/2022 20:06:51 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=367
05/30/2022 20:06:53 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=369
05/30/2022 20:06:55 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=372
05/30/2022 20:06:58 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=374
05/30/2022 20:06:59 - INFO - __main__ - Global step 1500 Train loss 0.01 Classification-F1 0.601167574107683 on epoch=374
05/30/2022 20:07:02 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=377
05/30/2022 20:07:04 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.05 on epoch=379
05/30/2022 20:07:06 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=382
05/30/2022 20:07:09 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=384
05/30/2022 20:07:11 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.04 on epoch=387
05/30/2022 20:07:12 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.7226506679092886 on epoch=387
05/30/2022 20:07:15 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=389
05/30/2022 20:07:17 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.07 on epoch=392
05/30/2022 20:07:19 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=394
05/30/2022 20:07:22 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=397
05/30/2022 20:07:24 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=399
05/30/2022 20:07:25 - INFO - __main__ - Global step 1600 Train loss 0.02 Classification-F1 0.6436770659680877 on epoch=399
05/30/2022 20:07:28 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=402
05/30/2022 20:07:30 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=404
05/30/2022 20:07:33 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=407
05/30/2022 20:07:35 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.03 on epoch=409
05/30/2022 20:07:38 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=412
05/30/2022 20:07:39 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.7376631591052843 on epoch=412
05/30/2022 20:07:41 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=414
05/30/2022 20:07:44 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.08 on epoch=417
05/30/2022 20:07:46 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=419
05/30/2022 20:07:49 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=422
05/30/2022 20:07:51 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=424
05/30/2022 20:07:52 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.6881756756756756 on epoch=424
05/30/2022 20:07:55 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=427
05/30/2022 20:07:57 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.02 on epoch=429
05/30/2022 20:08:00 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=432
05/30/2022 20:08:02 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=434
05/30/2022 20:08:05 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=437
05/30/2022 20:08:06 - INFO - __main__ - Global step 1750 Train loss 0.01 Classification-F1 0.7053763440860215 on epoch=437
05/30/2022 20:08:08 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=439
05/30/2022 20:08:11 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.08 on epoch=442
05/30/2022 20:08:13 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.03 on epoch=444
05/30/2022 20:08:15 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=447
05/30/2022 20:08:18 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=449
05/30/2022 20:08:19 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.6433451417004048 on epoch=449
05/30/2022 20:08:21 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=452
05/30/2022 20:08:24 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.07 on epoch=454
05/30/2022 20:08:26 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=457
05/30/2022 20:08:29 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=459
05/30/2022 20:08:31 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=462
05/30/2022 20:08:32 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.708935384000799 on epoch=462
05/30/2022 20:08:35 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=464
05/30/2022 20:08:37 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=467
05/30/2022 20:08:39 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=469
05/30/2022 20:08:42 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.06 on epoch=472
05/30/2022 20:08:44 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=474
05/30/2022 20:08:45 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.7179723502304147 on epoch=474
05/30/2022 20:08:48 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=477
05/30/2022 20:08:50 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=479
05/30/2022 20:08:53 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=482
05/30/2022 20:08:55 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=484
05/30/2022 20:08:58 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=487
05/30/2022 20:08:59 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.6621533557017427 on epoch=487
05/30/2022 20:09:01 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=489
05/30/2022 20:09:04 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=492
05/30/2022 20:09:06 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.05 on epoch=494
05/30/2022 20:09:08 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=497
05/30/2022 20:09:11 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=499
05/30/2022 20:09:12 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.7011067101584343 on epoch=499
05/30/2022 20:09:14 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=502
05/30/2022 20:09:17 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.03 on epoch=504
05/30/2022 20:09:19 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=507
05/30/2022 20:09:22 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=509
05/30/2022 20:09:24 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.03 on epoch=512
05/30/2022 20:09:26 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.7505952380952381 on epoch=512
05/30/2022 20:09:28 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=514
05/30/2022 20:09:30 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=517
05/30/2022 20:09:33 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
05/30/2022 20:09:35 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
05/30/2022 20:09:38 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=524
05/30/2022 20:09:39 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.6552712639109698 on epoch=524
05/30/2022 20:09:41 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
05/30/2022 20:09:44 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
05/30/2022 20:09:46 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=532
05/30/2022 20:09:49 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=534
05/30/2022 20:09:51 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
05/30/2022 20:09:52 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.6411257606490872 on epoch=537
05/30/2022 20:09:55 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
05/30/2022 20:09:57 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
05/30/2022 20:09:59 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
05/30/2022 20:10:02 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=547
05/30/2022 20:10:04 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
05/30/2022 20:10:06 - INFO - __main__ - Global step 2200 Train loss 0.00 Classification-F1 0.6618038158785188 on epoch=549
05/30/2022 20:10:08 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
05/30/2022 20:10:11 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
05/30/2022 20:10:13 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
05/30/2022 20:10:15 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
05/30/2022 20:10:18 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
05/30/2022 20:10:19 - INFO - __main__ - Global step 2250 Train loss 0.00 Classification-F1 0.6938235491366421 on epoch=562
05/30/2022 20:10:21 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
05/30/2022 20:10:24 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=567
05/30/2022 20:10:26 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
05/30/2022 20:10:29 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=572
05/30/2022 20:10:31 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
05/30/2022 20:10:32 - INFO - __main__ - Global step 2300 Train loss 0.00 Classification-F1 0.6527504105090312 on epoch=574
05/30/2022 20:10:35 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
05/30/2022 20:10:37 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
05/30/2022 20:10:40 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
05/30/2022 20:10:42 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
05/30/2022 20:10:45 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
05/30/2022 20:10:46 - INFO - __main__ - Global step 2350 Train loss 0.00 Classification-F1 0.6536728214859145 on epoch=587
05/30/2022 20:10:48 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=589
05/30/2022 20:10:51 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.05 on epoch=592
05/30/2022 20:10:53 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
05/30/2022 20:10:55 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=597
05/30/2022 20:10:58 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
05/30/2022 20:10:59 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.7007002801120448 on epoch=599
05/30/2022 20:11:01 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
05/30/2022 20:11:04 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=604
05/30/2022 20:11:06 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
05/30/2022 20:11:09 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
05/30/2022 20:11:11 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
05/30/2022 20:11:12 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.6809221244705116 on epoch=612
05/30/2022 20:11:15 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
05/30/2022 20:11:17 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
05/30/2022 20:11:20 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.05 on epoch=619
05/30/2022 20:11:22 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
05/30/2022 20:11:25 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.05 on epoch=624
05/30/2022 20:11:26 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.6465102707749767 on epoch=624
05/30/2022 20:11:28 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
05/30/2022 20:11:31 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.03 on epoch=629
05/30/2022 20:11:33 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
05/30/2022 20:11:35 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=634
05/30/2022 20:11:38 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=637
05/30/2022 20:11:39 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.6995349771350885 on epoch=637
05/30/2022 20:11:41 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
05/30/2022 20:11:44 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
05/30/2022 20:11:46 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.16 on epoch=644
05/30/2022 20:11:49 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
05/30/2022 20:11:51 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
05/30/2022 20:11:52 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.6844400434917677 on epoch=649
05/30/2022 20:11:55 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=652
05/30/2022 20:11:57 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
05/30/2022 20:12:00 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
05/30/2022 20:12:02 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=659
05/30/2022 20:12:05 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
05/30/2022 20:12:06 - INFO - __main__ - Global step 2650 Train loss 0.00 Classification-F1 0.6621533557017427 on epoch=662
05/30/2022 20:12:08 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
05/30/2022 20:12:11 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=667
05/30/2022 20:12:13 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.04 on epoch=669
05/30/2022 20:12:16 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=672
05/30/2022 20:12:18 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
05/30/2022 20:12:19 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.6766899766899767 on epoch=674
05/30/2022 20:12:22 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
05/30/2022 20:12:24 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=679
05/30/2022 20:12:27 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
05/30/2022 20:12:29 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=684
05/30/2022 20:12:32 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=687
05/30/2022 20:12:33 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.6559958133971291 on epoch=687
05/30/2022 20:12:35 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
05/30/2022 20:12:38 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
05/30/2022 20:12:40 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
05/30/2022 20:12:42 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
05/30/2022 20:12:45 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
05/30/2022 20:12:46 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.6691436251920124 on epoch=699
05/30/2022 20:12:48 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.04 on epoch=702
05/30/2022 20:12:51 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=704
05/30/2022 20:12:53 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
05/30/2022 20:12:56 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
05/30/2022 20:12:58 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.03 on epoch=712
05/30/2022 20:12:59 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.6614473980759877 on epoch=712
05/30/2022 20:13:02 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
05/30/2022 20:13:04 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
05/30/2022 20:13:07 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.04 on epoch=719
05/30/2022 20:13:09 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
05/30/2022 20:13:12 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
05/30/2022 20:13:13 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.6931238113313485 on epoch=724
05/30/2022 20:13:15 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
05/30/2022 20:13:18 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
05/30/2022 20:13:20 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=732
05/30/2022 20:13:22 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
05/30/2022 20:13:25 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
05/30/2022 20:13:26 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.6789802789802789 on epoch=737
05/30/2022 20:13:28 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
05/30/2022 20:13:31 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
05/30/2022 20:13:33 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
05/30/2022 20:13:36 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=747
05/30/2022 20:13:38 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
05/30/2022 20:13:39 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.6803149498382763 on epoch=749
05/30/2022 20:13:39 - INFO - __main__ - save last model!
05/30/2022 20:13:39 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/30/2022 20:13:39 - INFO - __main__ - Start tokenizing ... 5509 instances
05/30/2022 20:13:39 - INFO - __main__ - Printing 3 examples
05/30/2022 20:13:39 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/30/2022 20:13:39 - INFO - __main__ - ['others']
05/30/2022 20:13:39 - INFO - __main__ -  [emo] what you like very little things ok
05/30/2022 20:13:39 - INFO - __main__ - ['others']
05/30/2022 20:13:39 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/30/2022 20:13:39 - INFO - __main__ - ['others']
05/30/2022 20:13:39 - INFO - __main__ - Tokenizing Input ...
05/30/2022 20:13:39 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 20:13:39 - INFO - __main__ - Printing 3 examples
05/30/2022 20:13:39 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
05/30/2022 20:13:39 - INFO - __main__ - ['happy']
05/30/2022 20:13:39 - INFO - __main__ -  [emo] your right i'm always right i am impressed
05/30/2022 20:13:39 - INFO - __main__ - ['happy']
05/30/2022 20:13:39 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
05/30/2022 20:13:39 - INFO - __main__ - ['happy']
05/30/2022 20:13:39 - INFO - __main__ - Tokenizing Input ...
05/30/2022 20:13:39 - INFO - __main__ - Tokenizing Output ...
05/30/2022 20:13:39 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 20:13:39 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 20:13:39 - INFO - __main__ - Printing 3 examples
05/30/2022 20:13:39 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
05/30/2022 20:13:39 - INFO - __main__ - ['happy']
05/30/2022 20:13:39 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
05/30/2022 20:13:39 - INFO - __main__ - ['happy']
05/30/2022 20:13:39 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
05/30/2022 20:13:39 - INFO - __main__ - ['happy']
05/30/2022 20:13:39 - INFO - __main__ - Tokenizing Input ...
05/30/2022 20:13:39 - INFO - __main__ - Tokenizing Output ...
05/30/2022 20:13:40 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 20:13:41 - INFO - __main__ - Tokenizing Output ...
05/30/2022 20:13:47 - INFO - __main__ - Loaded 5509 examples from test data
05/30/2022 20:13:55 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 20:13:55 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/30/2022 20:13:55 - INFO - __main__ - Starting training!
05/30/2022 20:15:22 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-24uptasks/singletask-emo/emo_16_42_0.5_8_predictions.txt
05/30/2022 20:15:22 - INFO - __main__ - Classification-F1 on test data: 0.2377
05/30/2022 20:15:22 - INFO - __main__ - prefix=emo_16_42, lr=0.5, bsz=8, dev_performance=0.7536916920676654, test_performance=0.23772980786405315
05/30/2022 20:15:22 - INFO - __main__ - Running ... prefix=emo_16_42, lr=0.4, bsz=8 ...
05/30/2022 20:15:23 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 20:15:23 - INFO - __main__ - Printing 3 examples
05/30/2022 20:15:23 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
05/30/2022 20:15:23 - INFO - __main__ - ['happy']
05/30/2022 20:15:23 - INFO - __main__ -  [emo] your right i'm always right i am impressed
05/30/2022 20:15:23 - INFO - __main__ - ['happy']
05/30/2022 20:15:23 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
05/30/2022 20:15:23 - INFO - __main__ - ['happy']
05/30/2022 20:15:23 - INFO - __main__ - Tokenizing Input ...
05/30/2022 20:15:23 - INFO - __main__ - Tokenizing Output ...
05/30/2022 20:15:23 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 20:15:23 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 20:15:23 - INFO - __main__ - Printing 3 examples
05/30/2022 20:15:23 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
05/30/2022 20:15:23 - INFO - __main__ - ['happy']
05/30/2022 20:15:23 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
05/30/2022 20:15:23 - INFO - __main__ - ['happy']
05/30/2022 20:15:23 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
05/30/2022 20:15:23 - INFO - __main__ - ['happy']
05/30/2022 20:15:23 - INFO - __main__ - Tokenizing Input ...
05/30/2022 20:15:23 - INFO - __main__ - Tokenizing Output ...
05/30/2022 20:15:23 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 20:15:38 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 20:15:39 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/30/2022 20:15:39 - INFO - __main__ - Starting training!
05/30/2022 20:15:42 - INFO - __main__ - Step 10 Global step 10 Train loss 3.53 on epoch=2
05/30/2022 20:15:44 - INFO - __main__ - Step 20 Global step 20 Train loss 1.96 on epoch=4
05/30/2022 20:15:47 - INFO - __main__ - Step 30 Global step 30 Train loss 1.37 on epoch=7
05/30/2022 20:15:49 - INFO - __main__ - Step 40 Global step 40 Train loss 1.10 on epoch=9
05/30/2022 20:15:52 - INFO - __main__ - Step 50 Global step 50 Train loss 0.97 on epoch=12
05/30/2022 20:15:53 - INFO - __main__ - Global step 50 Train loss 1.79 Classification-F1 0.3987994293251501 on epoch=12
05/30/2022 20:15:53 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.3987994293251501 on epoch=12, global_step=50
05/30/2022 20:15:55 - INFO - __main__ - Step 60 Global step 60 Train loss 0.95 on epoch=14
05/30/2022 20:15:57 - INFO - __main__ - Step 70 Global step 70 Train loss 0.84 on epoch=17
05/30/2022 20:16:00 - INFO - __main__ - Step 80 Global step 80 Train loss 0.93 on epoch=19
05/30/2022 20:16:02 - INFO - __main__ - Step 90 Global step 90 Train loss 0.78 on epoch=22
05/30/2022 20:16:05 - INFO - __main__ - Step 100 Global step 100 Train loss 0.79 on epoch=24
05/30/2022 20:16:06 - INFO - __main__ - Global step 100 Train loss 0.86 Classification-F1 0.40746333045729083 on epoch=24
05/30/2022 20:16:06 - INFO - __main__ - Saving model with best Classification-F1: 0.3987994293251501 -> 0.40746333045729083 on epoch=24, global_step=100
05/30/2022 20:16:08 - INFO - __main__ - Step 110 Global step 110 Train loss 0.71 on epoch=27
05/30/2022 20:16:10 - INFO - __main__ - Step 120 Global step 120 Train loss 0.74 on epoch=29
05/30/2022 20:16:13 - INFO - __main__ - Step 130 Global step 130 Train loss 0.68 on epoch=32
05/30/2022 20:16:15 - INFO - __main__ - Step 140 Global step 140 Train loss 0.63 on epoch=34
05/30/2022 20:16:18 - INFO - __main__ - Step 150 Global step 150 Train loss 0.59 on epoch=37
05/30/2022 20:16:19 - INFO - __main__ - Global step 150 Train loss 0.67 Classification-F1 0.5671356914858967 on epoch=37
05/30/2022 20:16:19 - INFO - __main__ - Saving model with best Classification-F1: 0.40746333045729083 -> 0.5671356914858967 on epoch=37, global_step=150
05/30/2022 20:16:21 - INFO - __main__ - Step 160 Global step 160 Train loss 0.65 on epoch=39
05/30/2022 20:16:23 - INFO - __main__ - Step 170 Global step 170 Train loss 0.61 on epoch=42
05/30/2022 20:16:26 - INFO - __main__ - Step 180 Global step 180 Train loss 0.64 on epoch=44
05/30/2022 20:16:28 - INFO - __main__ - Step 190 Global step 190 Train loss 0.55 on epoch=47
05/30/2022 20:16:31 - INFO - __main__ - Step 200 Global step 200 Train loss 0.62 on epoch=49
05/30/2022 20:16:31 - INFO - __main__ - Global step 200 Train loss 0.61 Classification-F1 0.6924563860047731 on epoch=49
05/30/2022 20:16:32 - INFO - __main__ - Saving model with best Classification-F1: 0.5671356914858967 -> 0.6924563860047731 on epoch=49, global_step=200
05/30/2022 20:16:34 - INFO - __main__ - Step 210 Global step 210 Train loss 0.54 on epoch=52
05/30/2022 20:16:36 - INFO - __main__ - Step 220 Global step 220 Train loss 0.48 on epoch=54
05/30/2022 20:16:39 - INFO - __main__ - Step 230 Global step 230 Train loss 0.46 on epoch=57
05/30/2022 20:16:41 - INFO - __main__ - Step 240 Global step 240 Train loss 0.70 on epoch=59
05/30/2022 20:16:44 - INFO - __main__ - Step 250 Global step 250 Train loss 0.48 on epoch=62
05/30/2022 20:16:44 - INFO - __main__ - Global step 250 Train loss 0.53 Classification-F1 0.6367595216700075 on epoch=62
05/30/2022 20:16:47 - INFO - __main__ - Step 260 Global step 260 Train loss 0.47 on epoch=64
05/30/2022 20:16:49 - INFO - __main__ - Step 270 Global step 270 Train loss 0.35 on epoch=67
05/30/2022 20:16:52 - INFO - __main__ - Step 280 Global step 280 Train loss 0.42 on epoch=69
05/30/2022 20:16:54 - INFO - __main__ - Step 290 Global step 290 Train loss 0.41 on epoch=72
05/30/2022 20:16:57 - INFO - __main__ - Step 300 Global step 300 Train loss 0.36 on epoch=74
05/30/2022 20:16:57 - INFO - __main__ - Global step 300 Train loss 0.40 Classification-F1 0.6895833333333333 on epoch=74
05/30/2022 20:17:00 - INFO - __main__ - Step 310 Global step 310 Train loss 0.35 on epoch=77
05/30/2022 20:17:02 - INFO - __main__ - Step 320 Global step 320 Train loss 0.37 on epoch=79
05/30/2022 20:17:05 - INFO - __main__ - Step 330 Global step 330 Train loss 0.40 on epoch=82
05/30/2022 20:17:07 - INFO - __main__ - Step 340 Global step 340 Train loss 0.37 on epoch=84
05/30/2022 20:17:10 - INFO - __main__ - Step 350 Global step 350 Train loss 0.25 on epoch=87
05/30/2022 20:17:10 - INFO - __main__ - Global step 350 Train loss 0.35 Classification-F1 0.6155513686763687 on epoch=87
05/30/2022 20:17:13 - INFO - __main__ - Step 360 Global step 360 Train loss 0.32 on epoch=89
05/30/2022 20:17:15 - INFO - __main__ - Step 370 Global step 370 Train loss 0.33 on epoch=92
05/30/2022 20:17:18 - INFO - __main__ - Step 380 Global step 380 Train loss 0.20 on epoch=94
05/30/2022 20:17:20 - INFO - __main__ - Step 390 Global step 390 Train loss 0.22 on epoch=97
05/30/2022 20:17:22 - INFO - __main__ - Step 400 Global step 400 Train loss 0.31 on epoch=99
05/30/2022 20:17:23 - INFO - __main__ - Global step 400 Train loss 0.27 Classification-F1 0.6320036614154261 on epoch=99
05/30/2022 20:17:26 - INFO - __main__ - Step 410 Global step 410 Train loss 0.22 on epoch=102
05/30/2022 20:17:28 - INFO - __main__ - Step 420 Global step 420 Train loss 0.17 on epoch=104
05/30/2022 20:17:30 - INFO - __main__ - Step 430 Global step 430 Train loss 0.24 on epoch=107
05/30/2022 20:17:33 - INFO - __main__ - Step 440 Global step 440 Train loss 0.15 on epoch=109
05/30/2022 20:17:35 - INFO - __main__ - Step 450 Global step 450 Train loss 0.29 on epoch=112
05/30/2022 20:17:36 - INFO - __main__ - Global step 450 Train loss 0.22 Classification-F1 0.6182748538011696 on epoch=112
05/30/2022 20:17:39 - INFO - __main__ - Step 460 Global step 460 Train loss 0.18 on epoch=114
05/30/2022 20:17:41 - INFO - __main__ - Step 470 Global step 470 Train loss 0.22 on epoch=117
05/30/2022 20:17:43 - INFO - __main__ - Step 480 Global step 480 Train loss 0.21 on epoch=119
05/30/2022 20:17:46 - INFO - __main__ - Step 490 Global step 490 Train loss 0.19 on epoch=122
05/30/2022 20:17:48 - INFO - __main__ - Step 500 Global step 500 Train loss 0.13 on epoch=124
05/30/2022 20:17:49 - INFO - __main__ - Global step 500 Train loss 0.19 Classification-F1 0.5737373737373738 on epoch=124
05/30/2022 20:17:52 - INFO - __main__ - Step 510 Global step 510 Train loss 0.13 on epoch=127
05/30/2022 20:17:54 - INFO - __main__ - Step 520 Global step 520 Train loss 0.14 on epoch=129
05/30/2022 20:17:56 - INFO - __main__ - Step 530 Global step 530 Train loss 0.18 on epoch=132
05/30/2022 20:17:59 - INFO - __main__ - Step 540 Global step 540 Train loss 0.10 on epoch=134
05/30/2022 20:18:01 - INFO - __main__ - Step 550 Global step 550 Train loss 0.16 on epoch=137
05/30/2022 20:18:02 - INFO - __main__ - Global step 550 Train loss 0.14 Classification-F1 0.6463954002653693 on epoch=137
05/30/2022 20:18:05 - INFO - __main__ - Step 560 Global step 560 Train loss 0.08 on epoch=139
05/30/2022 20:18:07 - INFO - __main__ - Step 570 Global step 570 Train loss 0.09 on epoch=142
05/30/2022 20:18:09 - INFO - __main__ - Step 580 Global step 580 Train loss 0.13 on epoch=144
05/30/2022 20:18:12 - INFO - __main__ - Step 590 Global step 590 Train loss 0.17 on epoch=147
05/30/2022 20:18:14 - INFO - __main__ - Step 600 Global step 600 Train loss 0.15 on epoch=149
05/30/2022 20:18:15 - INFO - __main__ - Global step 600 Train loss 0.13 Classification-F1 0.6384035678153325 on epoch=149
05/30/2022 20:18:18 - INFO - __main__ - Step 610 Global step 610 Train loss 0.21 on epoch=152
05/30/2022 20:18:20 - INFO - __main__ - Step 620 Global step 620 Train loss 0.11 on epoch=154
05/30/2022 20:18:22 - INFO - __main__ - Step 630 Global step 630 Train loss 0.10 on epoch=157
05/30/2022 20:18:25 - INFO - __main__ - Step 640 Global step 640 Train loss 0.09 on epoch=159
05/30/2022 20:18:27 - INFO - __main__ - Step 650 Global step 650 Train loss 0.10 on epoch=162
05/30/2022 20:18:28 - INFO - __main__ - Global step 650 Train loss 0.12 Classification-F1 0.612781954887218 on epoch=162
05/30/2022 20:18:31 - INFO - __main__ - Step 660 Global step 660 Train loss 0.12 on epoch=164
05/30/2022 20:18:33 - INFO - __main__ - Step 670 Global step 670 Train loss 0.07 on epoch=167
05/30/2022 20:18:35 - INFO - __main__ - Step 680 Global step 680 Train loss 0.08 on epoch=169
05/30/2022 20:18:38 - INFO - __main__ - Step 690 Global step 690 Train loss 0.15 on epoch=172
05/30/2022 20:18:40 - INFO - __main__ - Step 700 Global step 700 Train loss 0.14 on epoch=174
05/30/2022 20:18:41 - INFO - __main__ - Global step 700 Train loss 0.11 Classification-F1 0.638375350140056 on epoch=174
05/30/2022 20:18:44 - INFO - __main__ - Step 710 Global step 710 Train loss 0.05 on epoch=177
05/30/2022 20:18:46 - INFO - __main__ - Step 720 Global step 720 Train loss 0.10 on epoch=179
05/30/2022 20:18:48 - INFO - __main__ - Step 730 Global step 730 Train loss 0.14 on epoch=182
05/30/2022 20:18:51 - INFO - __main__ - Step 740 Global step 740 Train loss 0.09 on epoch=184
05/30/2022 20:18:53 - INFO - __main__ - Step 750 Global step 750 Train loss 0.06 on epoch=187
05/30/2022 20:18:54 - INFO - __main__ - Global step 750 Train loss 0.09 Classification-F1 0.6595645645645646 on epoch=187
05/30/2022 20:18:56 - INFO - __main__ - Step 760 Global step 760 Train loss 0.12 on epoch=189
05/30/2022 20:18:59 - INFO - __main__ - Step 770 Global step 770 Train loss 0.07 on epoch=192
05/30/2022 20:19:01 - INFO - __main__ - Step 780 Global step 780 Train loss 0.05 on epoch=194
05/30/2022 20:19:04 - INFO - __main__ - Step 790 Global step 790 Train loss 0.12 on epoch=197
05/30/2022 20:19:06 - INFO - __main__ - Step 800 Global step 800 Train loss 0.09 on epoch=199
05/30/2022 20:19:07 - INFO - __main__ - Global step 800 Train loss 0.09 Classification-F1 0.6379689754689755 on epoch=199
05/30/2022 20:19:09 - INFO - __main__ - Step 810 Global step 810 Train loss 0.04 on epoch=202
05/30/2022 20:19:12 - INFO - __main__ - Step 820 Global step 820 Train loss 0.11 on epoch=204
05/30/2022 20:19:14 - INFO - __main__ - Step 830 Global step 830 Train loss 0.13 on epoch=207
05/30/2022 20:19:17 - INFO - __main__ - Step 840 Global step 840 Train loss 0.04 on epoch=209
05/30/2022 20:19:19 - INFO - __main__ - Step 850 Global step 850 Train loss 0.07 on epoch=212
05/30/2022 20:19:20 - INFO - __main__ - Global step 850 Train loss 0.08 Classification-F1 0.6671089041355521 on epoch=212
05/30/2022 20:19:23 - INFO - __main__ - Step 860 Global step 860 Train loss 0.13 on epoch=214
05/30/2022 20:19:25 - INFO - __main__ - Step 870 Global step 870 Train loss 0.12 on epoch=217
05/30/2022 20:19:27 - INFO - __main__ - Step 880 Global step 880 Train loss 0.08 on epoch=219
05/30/2022 20:19:30 - INFO - __main__ - Step 890 Global step 890 Train loss 0.05 on epoch=222
05/30/2022 20:19:32 - INFO - __main__ - Step 900 Global step 900 Train loss 0.02 on epoch=224
05/30/2022 20:19:33 - INFO - __main__ - Global step 900 Train loss 0.08 Classification-F1 0.6378172527366075 on epoch=224
05/30/2022 20:19:36 - INFO - __main__ - Step 910 Global step 910 Train loss 0.13 on epoch=227
05/30/2022 20:19:38 - INFO - __main__ - Step 920 Global step 920 Train loss 0.04 on epoch=229
05/30/2022 20:19:40 - INFO - __main__ - Step 930 Global step 930 Train loss 0.02 on epoch=232
05/30/2022 20:19:43 - INFO - __main__ - Step 940 Global step 940 Train loss 0.05 on epoch=234
05/30/2022 20:19:45 - INFO - __main__ - Step 950 Global step 950 Train loss 0.03 on epoch=237
05/30/2022 20:19:46 - INFO - __main__ - Global step 950 Train loss 0.05 Classification-F1 0.6213731443994602 on epoch=237
05/30/2022 20:19:48 - INFO - __main__ - Step 960 Global step 960 Train loss 0.06 on epoch=239
05/30/2022 20:19:51 - INFO - __main__ - Step 970 Global step 970 Train loss 0.07 on epoch=242
05/30/2022 20:19:53 - INFO - __main__ - Step 980 Global step 980 Train loss 0.02 on epoch=244
05/30/2022 20:19:56 - INFO - __main__ - Step 990 Global step 990 Train loss 0.02 on epoch=247
05/30/2022 20:19:58 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.04 on epoch=249
05/30/2022 20:19:59 - INFO - __main__ - Global step 1000 Train loss 0.04 Classification-F1 0.6407570207570208 on epoch=249
05/30/2022 20:20:02 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.04 on epoch=252
05/30/2022 20:20:04 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.01 on epoch=254
05/30/2022 20:20:07 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.02 on epoch=257
05/30/2022 20:20:09 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.02 on epoch=259
05/30/2022 20:20:12 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.03 on epoch=262
05/30/2022 20:20:13 - INFO - __main__ - Global step 1050 Train loss 0.02 Classification-F1 0.6217697018333285 on epoch=262
05/30/2022 20:20:15 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.01 on epoch=264
05/30/2022 20:20:18 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.01 on epoch=267
05/30/2022 20:20:20 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.04 on epoch=269
05/30/2022 20:20:23 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.02 on epoch=272
05/30/2022 20:20:25 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.08 on epoch=274
05/30/2022 20:20:26 - INFO - __main__ - Global step 1100 Train loss 0.03 Classification-F1 0.6217697018333285 on epoch=274
05/30/2022 20:20:28 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.04 on epoch=277
05/30/2022 20:20:31 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.02 on epoch=279
05/30/2022 20:20:33 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=282
05/30/2022 20:20:36 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.09 on epoch=284
05/30/2022 20:20:38 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.05 on epoch=287
05/30/2022 20:20:39 - INFO - __main__ - Global step 1150 Train loss 0.04 Classification-F1 0.6497947454844006 on epoch=287
05/30/2022 20:20:42 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.02 on epoch=289
05/30/2022 20:20:44 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.05 on epoch=292
05/30/2022 20:20:47 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.04 on epoch=294
05/30/2022 20:20:49 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.01 on epoch=297
05/30/2022 20:20:52 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.06 on epoch=299
05/30/2022 20:20:53 - INFO - __main__ - Global step 1200 Train loss 0.04 Classification-F1 0.6301079632732858 on epoch=299
05/30/2022 20:20:55 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.03 on epoch=302
05/30/2022 20:20:58 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.08 on epoch=304
05/30/2022 20:21:00 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.09 on epoch=307
05/30/2022 20:21:03 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.02 on epoch=309
05/30/2022 20:21:05 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.05 on epoch=312
05/30/2022 20:21:06 - INFO - __main__ - Global step 1250 Train loss 0.05 Classification-F1 0.6980196945714187 on epoch=312
05/30/2022 20:21:06 - INFO - __main__ - Saving model with best Classification-F1: 0.6924563860047731 -> 0.6980196945714187 on epoch=312, global_step=1250
05/30/2022 20:21:09 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.07 on epoch=314
05/30/2022 20:21:11 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.02 on epoch=317
05/30/2022 20:21:14 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.07 on epoch=319
05/30/2022 20:21:16 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.06 on epoch=322
05/30/2022 20:21:19 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=324
05/30/2022 20:21:20 - INFO - __main__ - Global step 1300 Train loss 0.05 Classification-F1 0.7142827892827893 on epoch=324
05/30/2022 20:21:20 - INFO - __main__ - Saving model with best Classification-F1: 0.6980196945714187 -> 0.7142827892827893 on epoch=324, global_step=1300
05/30/2022 20:21:22 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.05 on epoch=327
05/30/2022 20:21:25 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.02 on epoch=329
05/30/2022 20:21:27 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=332
05/30/2022 20:21:30 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.02 on epoch=334
05/30/2022 20:21:32 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=337
05/30/2022 20:21:33 - INFO - __main__ - Global step 1350 Train loss 0.02 Classification-F1 0.688523950694336 on epoch=337
05/30/2022 20:21:36 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.02 on epoch=339
05/30/2022 20:21:38 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.05 on epoch=342
05/30/2022 20:21:41 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.05 on epoch=344
05/30/2022 20:21:43 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=347
05/30/2022 20:21:46 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.11 on epoch=349
05/30/2022 20:21:47 - INFO - __main__ - Global step 1400 Train loss 0.05 Classification-F1 0.6651590183316012 on epoch=349
05/30/2022 20:21:49 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.02 on epoch=352
05/30/2022 20:21:52 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.01 on epoch=354
05/30/2022 20:21:54 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.00 on epoch=357
05/30/2022 20:21:56 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=359
05/30/2022 20:21:59 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=362
05/30/2022 20:22:00 - INFO - __main__ - Global step 1450 Train loss 0.01 Classification-F1 0.6646687282722936 on epoch=362
05/30/2022 20:22:02 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.07 on epoch=364
05/30/2022 20:22:05 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=367
05/30/2022 20:22:07 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=369
05/30/2022 20:22:10 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.05 on epoch=372
05/30/2022 20:22:12 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.11 on epoch=374
05/30/2022 20:22:13 - INFO - __main__ - Global step 1500 Train loss 0.05 Classification-F1 0.7422332326566199 on epoch=374
05/30/2022 20:22:13 - INFO - __main__ - Saving model with best Classification-F1: 0.7142827892827893 -> 0.7422332326566199 on epoch=374, global_step=1500
05/30/2022 20:22:16 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=377
05/30/2022 20:22:18 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.09 on epoch=379
05/30/2022 20:22:21 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=382
05/30/2022 20:22:23 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=384
05/30/2022 20:22:26 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=387
05/30/2022 20:22:27 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.7307351179055033 on epoch=387
05/30/2022 20:22:29 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.02 on epoch=389
05/30/2022 20:22:32 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=392
05/30/2022 20:22:34 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=394
05/30/2022 20:22:37 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=397
05/30/2022 20:22:39 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=399
05/30/2022 20:22:40 - INFO - __main__ - Global step 1600 Train loss 0.01 Classification-F1 0.6806790770205404 on epoch=399
05/30/2022 20:22:43 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=402
05/30/2022 20:22:45 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=404
05/30/2022 20:22:48 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=407
05/30/2022 20:22:50 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=409
05/30/2022 20:22:53 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=412
05/30/2022 20:22:54 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.659291101055807 on epoch=412
05/30/2022 20:22:56 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.03 on epoch=414
05/30/2022 20:22:59 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.04 on epoch=417
05/30/2022 20:23:01 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=419
05/30/2022 20:23:04 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.04 on epoch=422
05/30/2022 20:23:06 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=424
05/30/2022 20:23:07 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.6756482198142415 on epoch=424
05/30/2022 20:23:10 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.09 on epoch=427
05/30/2022 20:23:12 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=429
05/30/2022 20:23:15 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=432
05/30/2022 20:23:17 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=434
05/30/2022 20:23:20 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=437
05/30/2022 20:23:21 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.7082951346021423 on epoch=437
05/30/2022 20:23:23 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.03 on epoch=439
05/30/2022 20:23:26 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.03 on epoch=442
05/30/2022 20:23:28 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=444
05/30/2022 20:23:31 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=447
05/30/2022 20:23:33 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=449
05/30/2022 20:23:34 - INFO - __main__ - Global step 1800 Train loss 0.02 Classification-F1 0.6545313601127555 on epoch=449
05/30/2022 20:23:37 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.03 on epoch=452
05/30/2022 20:23:39 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.09 on epoch=454
05/30/2022 20:23:42 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=457
05/30/2022 20:23:44 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=459
05/30/2022 20:23:47 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=462
05/30/2022 20:23:48 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.6579688460750155 on epoch=462
05/30/2022 20:23:50 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=464
05/30/2022 20:23:53 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=467
05/30/2022 20:23:55 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=469
05/30/2022 20:23:58 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=472
05/30/2022 20:24:00 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=474
05/30/2022 20:24:01 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.645673323092678 on epoch=474
05/30/2022 20:24:04 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=477
05/30/2022 20:24:06 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=479
05/30/2022 20:24:09 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=482
05/30/2022 20:24:11 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=484
05/30/2022 20:24:14 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=487
05/30/2022 20:24:15 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.655713539334229 on epoch=487
05/30/2022 20:24:17 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=489
05/30/2022 20:24:20 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=492
05/30/2022 20:24:22 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=494
05/30/2022 20:24:25 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=497
05/30/2022 20:24:27 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=499
05/30/2022 20:24:28 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.6942848020434227 on epoch=499
05/30/2022 20:24:31 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=502
05/30/2022 20:24:33 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
05/30/2022 20:24:36 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
05/30/2022 20:24:38 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.03 on epoch=509
05/30/2022 20:24:41 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=512
05/30/2022 20:24:42 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.706574364332985 on epoch=512
05/30/2022 20:24:44 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=514
05/30/2022 20:24:47 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=517
05/30/2022 20:24:49 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.06 on epoch=519
05/30/2022 20:24:52 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=522
05/30/2022 20:24:54 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
05/30/2022 20:24:55 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.7321848837890053 on epoch=524
05/30/2022 20:24:58 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
05/30/2022 20:25:00 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.03 on epoch=529
05/30/2022 20:25:03 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=532
05/30/2022 20:25:05 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=534
05/30/2022 20:25:07 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
05/30/2022 20:25:09 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.6725569580058745 on epoch=537
05/30/2022 20:25:11 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
05/30/2022 20:25:13 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
05/30/2022 20:25:16 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
05/30/2022 20:25:19 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
05/30/2022 20:25:21 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.03 on epoch=549
05/30/2022 20:25:22 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.6689814814814815 on epoch=549
05/30/2022 20:25:24 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
05/30/2022 20:25:27 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.06 on epoch=554
05/30/2022 20:25:29 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=557
05/30/2022 20:25:32 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=559
05/30/2022 20:25:34 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=562
05/30/2022 20:25:35 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.6720086918281295 on epoch=562
05/30/2022 20:25:38 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=564
05/30/2022 20:25:41 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=567
05/30/2022 20:25:43 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=569
05/30/2022 20:25:46 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
05/30/2022 20:25:48 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=574
05/30/2022 20:25:49 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.69922604277443 on epoch=574
05/30/2022 20:25:52 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=577
05/30/2022 20:25:54 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.10 on epoch=579
05/30/2022 20:25:57 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
05/30/2022 20:25:59 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=584
05/30/2022 20:26:02 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
05/30/2022 20:26:03 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.6785186390981448 on epoch=587
05/30/2022 20:26:05 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.05 on epoch=589
05/30/2022 20:26:07 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
05/30/2022 20:26:10 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=594
05/30/2022 20:26:13 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
05/30/2022 20:26:15 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
05/30/2022 20:26:16 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.6940113500597372 on epoch=599
05/30/2022 20:26:18 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
05/30/2022 20:26:21 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
05/30/2022 20:26:23 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
05/30/2022 20:26:26 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.06 on epoch=609
05/30/2022 20:26:28 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=612
05/30/2022 20:26:29 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.6979037877936383 on epoch=612
05/30/2022 20:26:32 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.04 on epoch=614
05/30/2022 20:26:34 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.06 on epoch=617
05/30/2022 20:26:37 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.03 on epoch=619
05/30/2022 20:26:39 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
05/30/2022 20:26:42 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=624
05/30/2022 20:26:43 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.6587010550425184 on epoch=624
05/30/2022 20:26:45 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
05/30/2022 20:26:48 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=629
05/30/2022 20:26:50 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.10 on epoch=632
05/30/2022 20:26:53 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
05/30/2022 20:26:55 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=637
05/30/2022 20:26:56 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.6214130434782609 on epoch=637
05/30/2022 20:26:59 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
05/30/2022 20:27:01 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
05/30/2022 20:27:04 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.09 on epoch=644
05/30/2022 20:27:06 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
05/30/2022 20:27:09 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
05/30/2022 20:27:10 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.6737179487179488 on epoch=649
05/30/2022 20:27:12 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=652
05/30/2022 20:27:15 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
05/30/2022 20:27:17 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=657
05/30/2022 20:27:20 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=659
05/30/2022 20:27:22 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
05/30/2022 20:27:23 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.6810729175144922 on epoch=662
05/30/2022 20:27:26 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=664
05/30/2022 20:27:28 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
05/30/2022 20:27:31 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
05/30/2022 20:27:33 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=672
05/30/2022 20:27:36 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
05/30/2022 20:27:37 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.6585249042145593 on epoch=674
05/30/2022 20:27:39 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
05/30/2022 20:27:42 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
05/30/2022 20:27:44 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
05/30/2022 20:27:47 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
05/30/2022 20:27:49 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
05/30/2022 20:27:50 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.6857754049804365 on epoch=687
05/30/2022 20:27:53 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
05/30/2022 20:27:55 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
05/30/2022 20:27:58 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
05/30/2022 20:28:00 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
05/30/2022 20:28:03 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
05/30/2022 20:28:04 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.703406954887218 on epoch=699
05/30/2022 20:28:06 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=702
05/30/2022 20:28:09 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
05/30/2022 20:28:11 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
05/30/2022 20:28:14 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
05/30/2022 20:28:16 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=712
05/30/2022 20:28:17 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.6448168948168947 on epoch=712
05/30/2022 20:28:20 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
05/30/2022 20:28:22 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
05/30/2022 20:28:25 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
05/30/2022 20:28:27 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
05/30/2022 20:28:30 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
05/30/2022 20:28:31 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.6724193548387096 on epoch=724
05/30/2022 20:28:33 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
05/30/2022 20:28:36 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
05/30/2022 20:28:38 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
05/30/2022 20:28:41 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
05/30/2022 20:28:43 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
05/30/2022 20:28:44 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.6962009069906734 on epoch=737
05/30/2022 20:28:47 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
05/30/2022 20:28:49 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
05/30/2022 20:28:52 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
05/30/2022 20:28:54 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=747
05/30/2022 20:28:57 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
05/30/2022 20:28:58 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 20:28:58 - INFO - __main__ - Printing 3 examples
05/30/2022 20:28:58 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
05/30/2022 20:28:58 - INFO - __main__ - ['happy']
05/30/2022 20:28:58 - INFO - __main__ -  [emo] your right i'm always right i am impressed
05/30/2022 20:28:58 - INFO - __main__ - ['happy']
05/30/2022 20:28:58 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
05/30/2022 20:28:58 - INFO - __main__ - ['happy']
05/30/2022 20:28:58 - INFO - __main__ - Tokenizing Input ...
05/30/2022 20:28:58 - INFO - __main__ - Tokenizing Output ...
05/30/2022 20:28:58 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 20:28:58 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 20:28:58 - INFO - __main__ - Printing 3 examples
05/30/2022 20:28:58 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
05/30/2022 20:28:58 - INFO - __main__ - ['happy']
05/30/2022 20:28:58 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
05/30/2022 20:28:58 - INFO - __main__ - ['happy']
05/30/2022 20:28:58 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
05/30/2022 20:28:58 - INFO - __main__ - ['happy']
05/30/2022 20:28:58 - INFO - __main__ - Tokenizing Input ...
05/30/2022 20:28:58 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.6932680394657117 on epoch=749
05/30/2022 20:28:58 - INFO - __main__ - save last model!
05/30/2022 20:28:58 - INFO - __main__ - Tokenizing Output ...
05/30/2022 20:28:58 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/30/2022 20:28:58 - INFO - __main__ - Start tokenizing ... 5509 instances
05/30/2022 20:28:58 - INFO - __main__ - Printing 3 examples
05/30/2022 20:28:58 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/30/2022 20:28:58 - INFO - __main__ - ['others']
05/30/2022 20:28:58 - INFO - __main__ -  [emo] what you like very little things ok
05/30/2022 20:28:58 - INFO - __main__ - ['others']
05/30/2022 20:28:58 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/30/2022 20:28:58 - INFO - __main__ - ['others']
05/30/2022 20:28:58 - INFO - __main__ - Tokenizing Input ...
05/30/2022 20:28:58 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 20:29:00 - INFO - __main__ - Tokenizing Output ...
05/30/2022 20:29:06 - INFO - __main__ - Loaded 5509 examples from test data
05/30/2022 20:29:14 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 20:29:14 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/30/2022 20:29:14 - INFO - __main__ - Starting training!
05/30/2022 20:30:46 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-24uptasks/singletask-emo/emo_16_42_0.4_8_predictions.txt
05/30/2022 20:30:46 - INFO - __main__ - Classification-F1 on test data: 0.2083
05/30/2022 20:30:47 - INFO - __main__ - prefix=emo_16_42, lr=0.4, bsz=8, dev_performance=0.7422332326566199, test_performance=0.20825965786007378
05/30/2022 20:30:47 - INFO - __main__ - Running ... prefix=emo_16_42, lr=0.3, bsz=8 ...
05/30/2022 20:30:48 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 20:30:48 - INFO - __main__ - Printing 3 examples
05/30/2022 20:30:48 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
05/30/2022 20:30:48 - INFO - __main__ - ['happy']
05/30/2022 20:30:48 - INFO - __main__ -  [emo] your right i'm always right i am impressed
05/30/2022 20:30:48 - INFO - __main__ - ['happy']
05/30/2022 20:30:48 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
05/30/2022 20:30:48 - INFO - __main__ - ['happy']
05/30/2022 20:30:48 - INFO - __main__ - Tokenizing Input ...
05/30/2022 20:30:48 - INFO - __main__ - Tokenizing Output ...
05/30/2022 20:30:48 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 20:30:48 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 20:30:48 - INFO - __main__ - Printing 3 examples
05/30/2022 20:30:48 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
05/30/2022 20:30:48 - INFO - __main__ - ['happy']
05/30/2022 20:30:48 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
05/30/2022 20:30:48 - INFO - __main__ - ['happy']
05/30/2022 20:30:48 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
05/30/2022 20:30:48 - INFO - __main__ - ['happy']
05/30/2022 20:30:48 - INFO - __main__ - Tokenizing Input ...
05/30/2022 20:30:48 - INFO - __main__ - Tokenizing Output ...
05/30/2022 20:30:48 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 20:31:03 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 20:31:04 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/30/2022 20:31:04 - INFO - __main__ - Starting training!
05/30/2022 20:31:07 - INFO - __main__ - Step 10 Global step 10 Train loss 3.92 on epoch=2
05/30/2022 20:31:10 - INFO - __main__ - Step 20 Global step 20 Train loss 2.36 on epoch=4
05/30/2022 20:31:12 - INFO - __main__ - Step 30 Global step 30 Train loss 1.50 on epoch=7
05/30/2022 20:31:15 - INFO - __main__ - Step 40 Global step 40 Train loss 1.27 on epoch=9
05/30/2022 20:31:17 - INFO - __main__ - Step 50 Global step 50 Train loss 1.06 on epoch=12
05/30/2022 20:31:18 - INFO - __main__ - Global step 50 Train loss 2.02 Classification-F1 0.4120838562043257 on epoch=12
05/30/2022 20:31:18 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.4120838562043257 on epoch=12, global_step=50
05/30/2022 20:31:21 - INFO - __main__ - Step 60 Global step 60 Train loss 0.89 on epoch=14
05/30/2022 20:31:23 - INFO - __main__ - Step 70 Global step 70 Train loss 0.91 on epoch=17
05/30/2022 20:31:26 - INFO - __main__ - Step 80 Global step 80 Train loss 0.90 on epoch=19
05/30/2022 20:31:28 - INFO - __main__ - Step 90 Global step 90 Train loss 0.78 on epoch=22
05/30/2022 20:31:31 - INFO - __main__ - Step 100 Global step 100 Train loss 0.80 on epoch=24
05/30/2022 20:31:31 - INFO - __main__ - Global step 100 Train loss 0.86 Classification-F1 0.473864258347017 on epoch=24
05/30/2022 20:31:31 - INFO - __main__ - Saving model with best Classification-F1: 0.4120838562043257 -> 0.473864258347017 on epoch=24, global_step=100
05/30/2022 20:31:34 - INFO - __main__ - Step 110 Global step 110 Train loss 0.75 on epoch=27
05/30/2022 20:31:36 - INFO - __main__ - Step 120 Global step 120 Train loss 0.75 on epoch=29
05/30/2022 20:31:39 - INFO - __main__ - Step 130 Global step 130 Train loss 0.85 on epoch=32
05/30/2022 20:31:41 - INFO - __main__ - Step 140 Global step 140 Train loss 0.73 on epoch=34
05/30/2022 20:31:44 - INFO - __main__ - Step 150 Global step 150 Train loss 0.67 on epoch=37
05/30/2022 20:31:45 - INFO - __main__ - Global step 150 Train loss 0.75 Classification-F1 0.5112412637284267 on epoch=37
05/30/2022 20:31:45 - INFO - __main__ - Saving model with best Classification-F1: 0.473864258347017 -> 0.5112412637284267 on epoch=37, global_step=150
05/30/2022 20:31:47 - INFO - __main__ - Step 160 Global step 160 Train loss 0.69 on epoch=39
05/30/2022 20:31:50 - INFO - __main__ - Step 170 Global step 170 Train loss 0.66 on epoch=42
05/30/2022 20:31:52 - INFO - __main__ - Step 180 Global step 180 Train loss 0.60 on epoch=44
05/30/2022 20:31:55 - INFO - __main__ - Step 190 Global step 190 Train loss 0.64 on epoch=47
05/30/2022 20:31:57 - INFO - __main__ - Step 200 Global step 200 Train loss 0.67 on epoch=49
05/30/2022 20:31:58 - INFO - __main__ - Global step 200 Train loss 0.65 Classification-F1 0.6109564777327936 on epoch=49
05/30/2022 20:31:58 - INFO - __main__ - Saving model with best Classification-F1: 0.5112412637284267 -> 0.6109564777327936 on epoch=49, global_step=200
05/30/2022 20:32:01 - INFO - __main__ - Step 210 Global step 210 Train loss 0.63 on epoch=52
05/30/2022 20:32:03 - INFO - __main__ - Step 220 Global step 220 Train loss 0.60 on epoch=54
05/30/2022 20:32:06 - INFO - __main__ - Step 230 Global step 230 Train loss 0.58 on epoch=57
05/30/2022 20:32:08 - INFO - __main__ - Step 240 Global step 240 Train loss 0.49 on epoch=59
05/30/2022 20:32:11 - INFO - __main__ - Step 250 Global step 250 Train loss 0.64 on epoch=62
05/30/2022 20:32:12 - INFO - __main__ - Global step 250 Train loss 0.59 Classification-F1 0.5627321474397936 on epoch=62
05/30/2022 20:32:14 - INFO - __main__ - Step 260 Global step 260 Train loss 0.52 on epoch=64
05/30/2022 20:32:17 - INFO - __main__ - Step 270 Global step 270 Train loss 0.54 on epoch=67
05/30/2022 20:32:19 - INFO - __main__ - Step 280 Global step 280 Train loss 0.47 on epoch=69
05/30/2022 20:32:22 - INFO - __main__ - Step 290 Global step 290 Train loss 0.45 on epoch=72
05/30/2022 20:32:24 - INFO - __main__ - Step 300 Global step 300 Train loss 0.38 on epoch=74
05/30/2022 20:32:25 - INFO - __main__ - Global step 300 Train loss 0.47 Classification-F1 0.702680265654649 on epoch=74
05/30/2022 20:32:25 - INFO - __main__ - Saving model with best Classification-F1: 0.6109564777327936 -> 0.702680265654649 on epoch=74, global_step=300
05/30/2022 20:32:27 - INFO - __main__ - Step 310 Global step 310 Train loss 0.43 on epoch=77
05/30/2022 20:32:30 - INFO - __main__ - Step 320 Global step 320 Train loss 0.43 on epoch=79
05/30/2022 20:32:32 - INFO - __main__ - Step 330 Global step 330 Train loss 0.37 on epoch=82
05/30/2022 20:32:35 - INFO - __main__ - Step 340 Global step 340 Train loss 0.48 on epoch=84
05/30/2022 20:32:37 - INFO - __main__ - Step 350 Global step 350 Train loss 0.34 on epoch=87
05/30/2022 20:32:38 - INFO - __main__ - Global step 350 Train loss 0.41 Classification-F1 0.6318562601872559 on epoch=87
05/30/2022 20:32:41 - INFO - __main__ - Step 360 Global step 360 Train loss 0.43 on epoch=89
05/30/2022 20:32:43 - INFO - __main__ - Step 370 Global step 370 Train loss 0.26 on epoch=92
05/30/2022 20:32:46 - INFO - __main__ - Step 380 Global step 380 Train loss 0.37 on epoch=94
05/30/2022 20:32:48 - INFO - __main__ - Step 390 Global step 390 Train loss 0.25 on epoch=97
05/30/2022 20:32:51 - INFO - __main__ - Step 400 Global step 400 Train loss 0.37 on epoch=99
05/30/2022 20:32:51 - INFO - __main__ - Global step 400 Train loss 0.34 Classification-F1 0.673076923076923 on epoch=99
05/30/2022 20:32:54 - INFO - __main__ - Step 410 Global step 410 Train loss 0.25 on epoch=102
05/30/2022 20:32:56 - INFO - __main__ - Step 420 Global step 420 Train loss 0.34 on epoch=104
05/30/2022 20:32:59 - INFO - __main__ - Step 430 Global step 430 Train loss 0.24 on epoch=107
05/30/2022 20:33:01 - INFO - __main__ - Step 440 Global step 440 Train loss 0.26 on epoch=109
05/30/2022 20:33:04 - INFO - __main__ - Step 450 Global step 450 Train loss 0.33 on epoch=112
05/30/2022 20:33:05 - INFO - __main__ - Global step 450 Train loss 0.28 Classification-F1 0.6038602675902447 on epoch=112
05/30/2022 20:33:07 - INFO - __main__ - Step 460 Global step 460 Train loss 0.27 on epoch=114
05/30/2022 20:33:10 - INFO - __main__ - Step 470 Global step 470 Train loss 0.22 on epoch=117
05/30/2022 20:33:12 - INFO - __main__ - Step 480 Global step 480 Train loss 0.27 on epoch=119
05/30/2022 20:33:15 - INFO - __main__ - Step 490 Global step 490 Train loss 0.19 on epoch=122
05/30/2022 20:33:17 - INFO - __main__ - Step 500 Global step 500 Train loss 0.32 on epoch=124
05/30/2022 20:33:18 - INFO - __main__ - Global step 500 Train loss 0.25 Classification-F1 0.6663967258794845 on epoch=124
05/30/2022 20:33:21 - INFO - __main__ - Step 510 Global step 510 Train loss 0.23 on epoch=127
05/30/2022 20:33:23 - INFO - __main__ - Step 520 Global step 520 Train loss 0.23 on epoch=129
05/30/2022 20:33:25 - INFO - __main__ - Step 530 Global step 530 Train loss 0.28 on epoch=132
05/30/2022 20:33:28 - INFO - __main__ - Step 540 Global step 540 Train loss 0.29 on epoch=134
05/30/2022 20:33:30 - INFO - __main__ - Step 550 Global step 550 Train loss 0.21 on epoch=137
05/30/2022 20:33:31 - INFO - __main__ - Global step 550 Train loss 0.25 Classification-F1 0.6881720430107526 on epoch=137
05/30/2022 20:33:34 - INFO - __main__ - Step 560 Global step 560 Train loss 0.20 on epoch=139
05/30/2022 20:33:36 - INFO - __main__ - Step 570 Global step 570 Train loss 0.18 on epoch=142
05/30/2022 20:33:39 - INFO - __main__ - Step 580 Global step 580 Train loss 0.12 on epoch=144
05/30/2022 20:33:41 - INFO - __main__ - Step 590 Global step 590 Train loss 0.17 on epoch=147
05/30/2022 20:33:44 - INFO - __main__ - Step 600 Global step 600 Train loss 0.14 on epoch=149
05/30/2022 20:33:45 - INFO - __main__ - Global step 600 Train loss 0.16 Classification-F1 0.6913194444444445 on epoch=149
05/30/2022 20:33:47 - INFO - __main__ - Step 610 Global step 610 Train loss 0.14 on epoch=152
05/30/2022 20:33:50 - INFO - __main__ - Step 620 Global step 620 Train loss 0.16 on epoch=154
05/30/2022 20:33:52 - INFO - __main__ - Step 630 Global step 630 Train loss 0.27 on epoch=157
05/30/2022 20:33:55 - INFO - __main__ - Step 640 Global step 640 Train loss 0.10 on epoch=159
05/30/2022 20:33:57 - INFO - __main__ - Step 650 Global step 650 Train loss 0.09 on epoch=162
05/30/2022 20:33:58 - INFO - __main__ - Global step 650 Train loss 0.15 Classification-F1 0.6809250136836345 on epoch=162
05/30/2022 20:34:00 - INFO - __main__ - Step 660 Global step 660 Train loss 0.17 on epoch=164
05/30/2022 20:34:03 - INFO - __main__ - Step 670 Global step 670 Train loss 0.05 on epoch=167
05/30/2022 20:34:05 - INFO - __main__ - Step 680 Global step 680 Train loss 0.10 on epoch=169
05/30/2022 20:34:08 - INFO - __main__ - Step 690 Global step 690 Train loss 0.07 on epoch=172
05/30/2022 20:34:10 - INFO - __main__ - Step 700 Global step 700 Train loss 0.10 on epoch=174
05/30/2022 20:34:11 - INFO - __main__ - Global step 700 Train loss 0.10 Classification-F1 0.7026515151515151 on epoch=174
05/30/2022 20:34:14 - INFO - __main__ - Step 710 Global step 710 Train loss 0.18 on epoch=177
05/30/2022 20:34:16 - INFO - __main__ - Step 720 Global step 720 Train loss 0.10 on epoch=179
05/30/2022 20:34:19 - INFO - __main__ - Step 730 Global step 730 Train loss 0.11 on epoch=182
05/30/2022 20:34:21 - INFO - __main__ - Step 740 Global step 740 Train loss 0.15 on epoch=184
05/30/2022 20:34:24 - INFO - __main__ - Step 750 Global step 750 Train loss 0.10 on epoch=187
05/30/2022 20:34:25 - INFO - __main__ - Global step 750 Train loss 0.13 Classification-F1 0.6390756302521008 on epoch=187
05/30/2022 20:34:27 - INFO - __main__ - Step 760 Global step 760 Train loss 0.10 on epoch=189
05/30/2022 20:34:30 - INFO - __main__ - Step 770 Global step 770 Train loss 0.17 on epoch=192
05/30/2022 20:34:32 - INFO - __main__ - Step 780 Global step 780 Train loss 0.09 on epoch=194
05/30/2022 20:34:35 - INFO - __main__ - Step 790 Global step 790 Train loss 0.04 on epoch=197
05/30/2022 20:34:37 - INFO - __main__ - Step 800 Global step 800 Train loss 0.06 on epoch=199
05/30/2022 20:34:38 - INFO - __main__ - Global step 800 Train loss 0.09 Classification-F1 0.6751758428328887 on epoch=199
05/30/2022 20:34:40 - INFO - __main__ - Step 810 Global step 810 Train loss 0.09 on epoch=202
05/30/2022 20:34:43 - INFO - __main__ - Step 820 Global step 820 Train loss 0.05 on epoch=204
05/30/2022 20:34:45 - INFO - __main__ - Step 830 Global step 830 Train loss 0.11 on epoch=207
05/30/2022 20:34:48 - INFO - __main__ - Step 840 Global step 840 Train loss 0.10 on epoch=209
05/30/2022 20:34:51 - INFO - __main__ - Step 850 Global step 850 Train loss 0.07 on epoch=212
05/30/2022 20:34:51 - INFO - __main__ - Global step 850 Train loss 0.09 Classification-F1 0.6231657108186586 on epoch=212
05/30/2022 20:34:54 - INFO - __main__ - Step 860 Global step 860 Train loss 0.07 on epoch=214
05/30/2022 20:34:56 - INFO - __main__ - Step 870 Global step 870 Train loss 0.09 on epoch=217
05/30/2022 20:34:59 - INFO - __main__ - Step 880 Global step 880 Train loss 0.03 on epoch=219
05/30/2022 20:35:01 - INFO - __main__ - Step 890 Global step 890 Train loss 0.04 on epoch=222
05/30/2022 20:35:04 - INFO - __main__ - Step 900 Global step 900 Train loss 0.12 on epoch=224
05/30/2022 20:35:05 - INFO - __main__ - Global step 900 Train loss 0.07 Classification-F1 0.6888135386119257 on epoch=224
05/30/2022 20:35:07 - INFO - __main__ - Step 910 Global step 910 Train loss 0.03 on epoch=227
05/30/2022 20:35:10 - INFO - __main__ - Step 920 Global step 920 Train loss 0.11 on epoch=229
05/30/2022 20:35:12 - INFO - __main__ - Step 930 Global step 930 Train loss 0.06 on epoch=232
05/30/2022 20:35:15 - INFO - __main__ - Step 940 Global step 940 Train loss 0.08 on epoch=234
05/30/2022 20:35:17 - INFO - __main__ - Step 950 Global step 950 Train loss 0.07 on epoch=237
05/30/2022 20:35:18 - INFO - __main__ - Global step 950 Train loss 0.07 Classification-F1 0.7071428571428571 on epoch=237
05/30/2022 20:35:18 - INFO - __main__ - Saving model with best Classification-F1: 0.702680265654649 -> 0.7071428571428571 on epoch=237, global_step=950
05/30/2022 20:35:21 - INFO - __main__ - Step 960 Global step 960 Train loss 0.14 on epoch=239
05/30/2022 20:35:23 - INFO - __main__ - Step 970 Global step 970 Train loss 0.04 on epoch=242
05/30/2022 20:35:25 - INFO - __main__ - Step 980 Global step 980 Train loss 0.04 on epoch=244
05/30/2022 20:35:28 - INFO - __main__ - Step 990 Global step 990 Train loss 0.03 on epoch=247
05/30/2022 20:35:30 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.02 on epoch=249
05/30/2022 20:35:31 - INFO - __main__ - Global step 1000 Train loss 0.05 Classification-F1 0.6349211542236473 on epoch=249
05/30/2022 20:35:34 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.04 on epoch=252
05/30/2022 20:35:36 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.02 on epoch=254
05/30/2022 20:35:39 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.04 on epoch=257
05/30/2022 20:35:41 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.08 on epoch=259
05/30/2022 20:35:44 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.04 on epoch=262
05/30/2022 20:35:45 - INFO - __main__ - Global step 1050 Train loss 0.04 Classification-F1 0.6666666666666666 on epoch=262
05/30/2022 20:35:47 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.08 on epoch=264
05/30/2022 20:35:50 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.02 on epoch=267
05/30/2022 20:35:52 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.06 on epoch=269
05/30/2022 20:35:55 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.04 on epoch=272
05/30/2022 20:35:57 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.03 on epoch=274
05/30/2022 20:35:58 - INFO - __main__ - Global step 1100 Train loss 0.04 Classification-F1 0.6695170559881348 on epoch=274
05/30/2022 20:36:01 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.06 on epoch=277
05/30/2022 20:36:03 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=279
05/30/2022 20:36:06 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.03 on epoch=282
05/30/2022 20:36:08 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.09 on epoch=284
05/30/2022 20:36:11 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.02 on epoch=287
05/30/2022 20:36:12 - INFO - __main__ - Global step 1150 Train loss 0.04 Classification-F1 0.6716374675565443 on epoch=287
05/30/2022 20:36:14 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.02 on epoch=289
05/30/2022 20:36:17 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.02 on epoch=292
05/30/2022 20:36:19 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.02 on epoch=294
05/30/2022 20:36:22 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.05 on epoch=297
05/30/2022 20:36:24 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.04 on epoch=299
05/30/2022 20:36:25 - INFO - __main__ - Global step 1200 Train loss 0.03 Classification-F1 0.6585556021039892 on epoch=299
05/30/2022 20:36:28 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.02 on epoch=302
05/30/2022 20:36:30 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.02 on epoch=304
05/30/2022 20:36:33 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.03 on epoch=307
05/30/2022 20:36:35 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.02 on epoch=309
05/30/2022 20:36:38 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.04 on epoch=312
05/30/2022 20:36:39 - INFO - __main__ - Global step 1250 Train loss 0.03 Classification-F1 0.6591027216027217 on epoch=312
05/30/2022 20:36:41 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.04 on epoch=314
05/30/2022 20:36:44 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.02 on epoch=317
05/30/2022 20:36:46 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=319
05/30/2022 20:36:49 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.04 on epoch=322
05/30/2022 20:36:51 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.03 on epoch=324
05/30/2022 20:36:53 - INFO - __main__ - Global step 1300 Train loss 0.03 Classification-F1 0.6358360389610389 on epoch=324
05/30/2022 20:36:55 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.02 on epoch=327
05/30/2022 20:36:57 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.04 on epoch=329
05/30/2022 20:37:00 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.03 on epoch=332
05/30/2022 20:37:02 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.04 on epoch=334
05/30/2022 20:37:05 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.09 on epoch=337
05/30/2022 20:37:06 - INFO - __main__ - Global step 1350 Train loss 0.04 Classification-F1 0.6328197945845004 on epoch=337
05/30/2022 20:37:08 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.03 on epoch=339
05/30/2022 20:37:11 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.03 on epoch=342
05/30/2022 20:37:13 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.02 on epoch=344
05/30/2022 20:37:16 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=347
05/30/2022 20:37:18 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=349
05/30/2022 20:37:19 - INFO - __main__ - Global step 1400 Train loss 0.02 Classification-F1 0.6875931966449208 on epoch=349
05/30/2022 20:37:22 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.02 on epoch=352
05/30/2022 20:37:25 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=354
05/30/2022 20:37:27 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.06 on epoch=357
05/30/2022 20:37:30 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.05 on epoch=359
05/30/2022 20:37:32 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=362
05/30/2022 20:37:33 - INFO - __main__ - Global step 1450 Train loss 0.03 Classification-F1 0.6785714285714285 on epoch=362
05/30/2022 20:37:36 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.02 on epoch=364
05/30/2022 20:37:38 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.02 on epoch=367
05/30/2022 20:37:41 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=369
05/30/2022 20:37:43 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=372
05/30/2022 20:37:46 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=374
05/30/2022 20:37:47 - INFO - __main__ - Global step 1500 Train loss 0.02 Classification-F1 0.7078369905956112 on epoch=374
05/30/2022 20:37:47 - INFO - __main__ - Saving model with best Classification-F1: 0.7071428571428571 -> 0.7078369905956112 on epoch=374, global_step=1500
05/30/2022 20:37:49 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=377
05/30/2022 20:37:52 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=379
05/30/2022 20:37:54 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=382
05/30/2022 20:37:57 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=384
05/30/2022 20:37:59 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=387
05/30/2022 20:38:00 - INFO - __main__ - Global step 1550 Train loss 0.01 Classification-F1 0.675993329883273 on epoch=387
05/30/2022 20:38:03 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.08 on epoch=389
05/30/2022 20:38:05 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.03 on epoch=392
05/30/2022 20:38:08 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.02 on epoch=394
05/30/2022 20:38:10 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=397
05/30/2022 20:38:13 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=399
05/30/2022 20:38:14 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.6758462958652712 on epoch=399
05/30/2022 20:38:16 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=402
05/30/2022 20:38:19 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=404
05/30/2022 20:38:21 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.02 on epoch=407
05/30/2022 20:38:24 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=409
05/30/2022 20:38:26 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=412
05/30/2022 20:38:27 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.7237425513287582 on epoch=412
05/30/2022 20:38:27 - INFO - __main__ - Saving model with best Classification-F1: 0.7078369905956112 -> 0.7237425513287582 on epoch=412, global_step=1650
05/30/2022 20:38:30 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=414
05/30/2022 20:38:32 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=417
05/30/2022 20:38:35 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=419
05/30/2022 20:38:37 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=422
05/30/2022 20:38:40 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.04 on epoch=424
05/30/2022 20:38:41 - INFO - __main__ - Global step 1700 Train loss 0.01 Classification-F1 0.6150694893341953 on epoch=424
05/30/2022 20:38:43 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=427
05/30/2022 20:38:46 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.02 on epoch=429
05/30/2022 20:38:48 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=432
05/30/2022 20:38:51 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=434
05/30/2022 20:38:53 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=437
05/30/2022 20:38:55 - INFO - __main__ - Global step 1750 Train loss 0.01 Classification-F1 0.6732856326849653 on epoch=437
05/30/2022 20:38:57 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=439
05/30/2022 20:38:59 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=442
05/30/2022 20:39:02 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.05 on epoch=444
05/30/2022 20:39:04 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=447
05/30/2022 20:39:07 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=449
05/30/2022 20:39:08 - INFO - __main__ - Global step 1800 Train loss 0.02 Classification-F1 0.6726748349732221 on epoch=449
05/30/2022 20:39:11 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=452
05/30/2022 20:39:13 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=454
05/30/2022 20:39:16 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.08 on epoch=457
05/30/2022 20:39:18 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=459
05/30/2022 20:39:21 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=462
05/30/2022 20:39:22 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.7062499999999999 on epoch=462
05/30/2022 20:39:24 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.03 on epoch=464
05/30/2022 20:39:27 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=467
05/30/2022 20:39:29 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.04 on epoch=469
05/30/2022 20:39:32 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.03 on epoch=472
05/30/2022 20:39:34 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.02 on epoch=474
05/30/2022 20:39:35 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.7081425673717763 on epoch=474
05/30/2022 20:39:38 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.07 on epoch=477
05/30/2022 20:39:40 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=479
05/30/2022 20:39:43 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=482
05/30/2022 20:39:45 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=484
05/30/2022 20:39:48 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=487
05/30/2022 20:39:49 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.673945677977936 on epoch=487
05/30/2022 20:39:51 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=489
05/30/2022 20:39:54 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=492
05/30/2022 20:39:56 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=494
05/30/2022 20:39:59 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=497
05/30/2022 20:40:01 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=499
05/30/2022 20:40:02 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.6758462958652712 on epoch=499
05/30/2022 20:40:05 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.03 on epoch=502
05/30/2022 20:40:07 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=504
05/30/2022 20:40:10 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.03 on epoch=507
05/30/2022 20:40:12 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.07 on epoch=509
05/30/2022 20:40:15 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=512
05/30/2022 20:40:16 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.6585019474682912 on epoch=512
05/30/2022 20:40:18 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=514
05/30/2022 20:40:21 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=517
05/30/2022 20:40:23 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=519
05/30/2022 20:40:26 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=522
05/30/2022 20:40:28 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
05/30/2022 20:40:30 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.6591027216027217 on epoch=524
05/30/2022 20:40:32 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.05 on epoch=527
05/30/2022 20:40:34 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
05/30/2022 20:40:37 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=532
05/30/2022 20:40:40 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=534
05/30/2022 20:40:42 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=537
05/30/2022 20:40:43 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.6242245657568238 on epoch=537
05/30/2022 20:40:46 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
05/30/2022 20:40:48 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=542
05/30/2022 20:40:51 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=544
05/30/2022 20:40:53 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
05/30/2022 20:40:56 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
05/30/2022 20:40:57 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.6396792687115268 on epoch=549
05/30/2022 20:40:59 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
05/30/2022 20:41:02 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=554
05/30/2022 20:41:04 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=557
05/30/2022 20:41:07 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=559
05/30/2022 20:41:09 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.04 on epoch=562
05/30/2022 20:41:10 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.6375171065493646 on epoch=562
05/30/2022 20:41:13 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=564
05/30/2022 20:41:15 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
05/30/2022 20:41:18 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=569
05/30/2022 20:41:20 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=572
05/30/2022 20:41:23 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
05/30/2022 20:41:24 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.6396792687115268 on epoch=574
05/30/2022 20:41:26 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=577
05/30/2022 20:41:29 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.04 on epoch=579
05/30/2022 20:41:31 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=582
05/30/2022 20:41:34 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
05/30/2022 20:41:36 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=587
05/30/2022 20:41:37 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.632051282051282 on epoch=587
05/30/2022 20:41:40 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.07 on epoch=589
05/30/2022 20:41:42 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=592
05/30/2022 20:41:45 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=594
05/30/2022 20:41:47 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.05 on epoch=597
05/30/2022 20:41:50 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=599
05/30/2022 20:41:51 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.6883337375697307 on epoch=599
05/30/2022 20:41:53 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
05/30/2022 20:41:56 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=604
05/30/2022 20:41:58 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=607
05/30/2022 20:42:01 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=609
05/30/2022 20:42:03 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
05/30/2022 20:42:04 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.692410885959273 on epoch=612
05/30/2022 20:42:07 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=614
05/30/2022 20:42:09 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
05/30/2022 20:42:12 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
05/30/2022 20:42:14 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
05/30/2022 20:42:17 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=624
05/30/2022 20:42:18 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.7392395058837304 on epoch=624
05/30/2022 20:42:18 - INFO - __main__ - Saving model with best Classification-F1: 0.7237425513287582 -> 0.7392395058837304 on epoch=624, global_step=2500
05/30/2022 20:42:21 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
05/30/2022 20:42:23 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
05/30/2022 20:42:26 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=632
05/30/2022 20:42:28 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=634
05/30/2022 20:42:31 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=637
05/30/2022 20:42:32 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.6541666666666666 on epoch=637
05/30/2022 20:42:34 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
05/30/2022 20:42:37 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
05/30/2022 20:42:39 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=644
05/30/2022 20:42:42 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
05/30/2022 20:42:44 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=649
05/30/2022 20:42:45 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.6560885351207931 on epoch=649
05/30/2022 20:42:48 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=652
05/30/2022 20:42:50 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=654
05/30/2022 20:42:53 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=657
05/30/2022 20:42:55 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=659
05/30/2022 20:42:57 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=662
05/30/2022 20:42:59 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.6542515563101301 on epoch=662
05/30/2022 20:43:01 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
05/30/2022 20:43:04 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
05/30/2022 20:43:06 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
05/30/2022 20:43:09 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
05/30/2022 20:43:11 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=674
05/30/2022 20:43:12 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.6542515563101301 on epoch=674
05/30/2022 20:43:15 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
05/30/2022 20:43:17 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
05/30/2022 20:43:20 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
05/30/2022 20:43:22 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.08 on epoch=684
05/30/2022 20:43:25 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
05/30/2022 20:43:26 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.6542515563101301 on epoch=687
05/30/2022 20:43:28 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
05/30/2022 20:43:31 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
05/30/2022 20:43:33 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
05/30/2022 20:43:36 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=697
05/30/2022 20:43:38 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
05/30/2022 20:43:39 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.6719341837250625 on epoch=699
05/30/2022 20:43:42 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.04 on epoch=702
05/30/2022 20:43:44 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
05/30/2022 20:43:47 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
05/30/2022 20:43:49 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
05/30/2022 20:43:52 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
05/30/2022 20:43:53 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.6516560798548094 on epoch=712
05/30/2022 20:43:55 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
05/30/2022 20:43:58 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=717
05/30/2022 20:44:00 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
05/30/2022 20:44:03 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
05/30/2022 20:44:05 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
05/30/2022 20:44:06 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.6879114932507591 on epoch=724
05/30/2022 20:44:09 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=727
05/30/2022 20:44:11 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=729
05/30/2022 20:44:14 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.05 on epoch=732
05/30/2022 20:44:16 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
05/30/2022 20:44:19 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=737
05/30/2022 20:44:20 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.6690963606286188 on epoch=737
05/30/2022 20:44:23 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=739
05/30/2022 20:44:25 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.03 on epoch=742
05/30/2022 20:44:28 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=744
05/30/2022 20:44:30 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
05/30/2022 20:44:32 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
05/30/2022 20:44:34 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.7040792540792541 on epoch=749
05/30/2022 20:44:34 - INFO - __main__ - save last model!
05/30/2022 20:44:34 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/30/2022 20:44:34 - INFO - __main__ - Start tokenizing ... 5509 instances
05/30/2022 20:44:34 - INFO - __main__ - Printing 3 examples
05/30/2022 20:44:34 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/30/2022 20:44:34 - INFO - __main__ - ['others']
05/30/2022 20:44:34 - INFO - __main__ -  [emo] what you like very little things ok
05/30/2022 20:44:34 - INFO - __main__ - ['others']
05/30/2022 20:44:34 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/30/2022 20:44:34 - INFO - __main__ - ['others']
05/30/2022 20:44:34 - INFO - __main__ - Tokenizing Input ...
05/30/2022 20:44:34 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 20:44:34 - INFO - __main__ - Printing 3 examples
05/30/2022 20:44:34 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
05/30/2022 20:44:34 - INFO - __main__ - ['happy']
05/30/2022 20:44:34 - INFO - __main__ -  [emo] your right i'm always right i am impressed
05/30/2022 20:44:34 - INFO - __main__ - ['happy']
05/30/2022 20:44:34 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
05/30/2022 20:44:34 - INFO - __main__ - ['happy']
05/30/2022 20:44:34 - INFO - __main__ - Tokenizing Input ...
05/30/2022 20:44:34 - INFO - __main__ - Tokenizing Output ...
05/30/2022 20:44:34 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 20:44:34 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 20:44:34 - INFO - __main__ - Printing 3 examples
05/30/2022 20:44:34 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
05/30/2022 20:44:34 - INFO - __main__ - ['happy']
05/30/2022 20:44:34 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
05/30/2022 20:44:34 - INFO - __main__ - ['happy']
05/30/2022 20:44:34 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
05/30/2022 20:44:34 - INFO - __main__ - ['happy']
05/30/2022 20:44:34 - INFO - __main__ - Tokenizing Input ...
05/30/2022 20:44:34 - INFO - __main__ - Tokenizing Output ...
05/30/2022 20:44:34 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 20:44:36 - INFO - __main__ - Tokenizing Output ...
05/30/2022 20:44:41 - INFO - __main__ - Loaded 5509 examples from test data
05/30/2022 20:44:53 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 20:44:54 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/30/2022 20:44:54 - INFO - __main__ - Starting training!
05/30/2022 20:46:16 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-24uptasks/singletask-emo/emo_16_42_0.3_8_predictions.txt
05/30/2022 20:46:16 - INFO - __main__ - Classification-F1 on test data: 0.2541
05/30/2022 20:46:17 - INFO - __main__ - prefix=emo_16_42, lr=0.3, bsz=8, dev_performance=0.7392395058837304, test_performance=0.25410966609678864
05/30/2022 20:46:17 - INFO - __main__ - Running ... prefix=emo_16_42, lr=0.2, bsz=8 ...
05/30/2022 20:46:18 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 20:46:18 - INFO - __main__ - Printing 3 examples
05/30/2022 20:46:18 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
05/30/2022 20:46:18 - INFO - __main__ - ['happy']
05/30/2022 20:46:18 - INFO - __main__ -  [emo] your right i'm always right i am impressed
05/30/2022 20:46:18 - INFO - __main__ - ['happy']
05/30/2022 20:46:18 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
05/30/2022 20:46:18 - INFO - __main__ - ['happy']
05/30/2022 20:46:18 - INFO - __main__ - Tokenizing Input ...
05/30/2022 20:46:18 - INFO - __main__ - Tokenizing Output ...
05/30/2022 20:46:18 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 20:46:18 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 20:46:18 - INFO - __main__ - Printing 3 examples
05/30/2022 20:46:18 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
05/30/2022 20:46:18 - INFO - __main__ - ['happy']
05/30/2022 20:46:18 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
05/30/2022 20:46:18 - INFO - __main__ - ['happy']
05/30/2022 20:46:18 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
05/30/2022 20:46:18 - INFO - __main__ - ['happy']
05/30/2022 20:46:18 - INFO - __main__ - Tokenizing Input ...
05/30/2022 20:46:18 - INFO - __main__ - Tokenizing Output ...
05/30/2022 20:46:18 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 20:46:36 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 20:46:37 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/30/2022 20:46:37 - INFO - __main__ - Starting training!
05/30/2022 20:46:40 - INFO - __main__ - Step 10 Global step 10 Train loss 4.41 on epoch=2
05/30/2022 20:46:43 - INFO - __main__ - Step 20 Global step 20 Train loss 2.84 on epoch=4
05/30/2022 20:46:45 - INFO - __main__ - Step 30 Global step 30 Train loss 1.92 on epoch=7
05/30/2022 20:46:47 - INFO - __main__ - Step 40 Global step 40 Train loss 1.63 on epoch=9
05/30/2022 20:46:50 - INFO - __main__ - Step 50 Global step 50 Train loss 1.30 on epoch=12
05/30/2022 20:46:51 - INFO - __main__ - Global step 50 Train loss 2.42 Classification-F1 0.3454022988505747 on epoch=12
05/30/2022 20:46:51 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.3454022988505747 on epoch=12, global_step=50
05/30/2022 20:46:53 - INFO - __main__ - Step 60 Global step 60 Train loss 1.05 on epoch=14
05/30/2022 20:46:56 - INFO - __main__ - Step 70 Global step 70 Train loss 0.90 on epoch=17
05/30/2022 20:46:58 - INFO - __main__ - Step 80 Global step 80 Train loss 0.96 on epoch=19
05/30/2022 20:47:00 - INFO - __main__ - Step 90 Global step 90 Train loss 0.91 on epoch=22
05/30/2022 20:47:03 - INFO - __main__ - Step 100 Global step 100 Train loss 0.95 on epoch=24
05/30/2022 20:47:04 - INFO - __main__ - Global step 100 Train loss 0.95 Classification-F1 0.38468286099865046 on epoch=24
05/30/2022 20:47:04 - INFO - __main__ - Saving model with best Classification-F1: 0.3454022988505747 -> 0.38468286099865046 on epoch=24, global_step=100
05/30/2022 20:47:06 - INFO - __main__ - Step 110 Global step 110 Train loss 0.84 on epoch=27
05/30/2022 20:47:09 - INFO - __main__ - Step 120 Global step 120 Train loss 0.83 on epoch=29
05/30/2022 20:47:11 - INFO - __main__ - Step 130 Global step 130 Train loss 0.81 on epoch=32
05/30/2022 20:47:13 - INFO - __main__ - Step 140 Global step 140 Train loss 0.80 on epoch=34
05/30/2022 20:47:16 - INFO - __main__ - Step 150 Global step 150 Train loss 0.82 on epoch=37
05/30/2022 20:47:17 - INFO - __main__ - Global step 150 Train loss 0.82 Classification-F1 0.4758610000815727 on epoch=37
05/30/2022 20:47:17 - INFO - __main__ - Saving model with best Classification-F1: 0.38468286099865046 -> 0.4758610000815727 on epoch=37, global_step=150
05/30/2022 20:47:19 - INFO - __main__ - Step 160 Global step 160 Train loss 0.81 on epoch=39
05/30/2022 20:47:22 - INFO - __main__ - Step 170 Global step 170 Train loss 0.80 on epoch=42
05/30/2022 20:47:24 - INFO - __main__ - Step 180 Global step 180 Train loss 0.73 on epoch=44
05/30/2022 20:47:27 - INFO - __main__ - Step 190 Global step 190 Train loss 0.66 on epoch=47
05/30/2022 20:47:29 - INFO - __main__ - Step 200 Global step 200 Train loss 0.73 on epoch=49
05/30/2022 20:47:30 - INFO - __main__ - Global step 200 Train loss 0.75 Classification-F1 0.5788288288288288 on epoch=49
05/30/2022 20:47:30 - INFO - __main__ - Saving model with best Classification-F1: 0.4758610000815727 -> 0.5788288288288288 on epoch=49, global_step=200
05/30/2022 20:47:32 - INFO - __main__ - Step 210 Global step 210 Train loss 0.70 on epoch=52
05/30/2022 20:47:35 - INFO - __main__ - Step 220 Global step 220 Train loss 0.75 on epoch=54
05/30/2022 20:47:37 - INFO - __main__ - Step 230 Global step 230 Train loss 0.70 on epoch=57
05/30/2022 20:47:40 - INFO - __main__ - Step 240 Global step 240 Train loss 0.61 on epoch=59
05/30/2022 20:47:42 - INFO - __main__ - Step 250 Global step 250 Train loss 0.55 on epoch=62
05/30/2022 20:47:43 - INFO - __main__ - Global step 250 Train loss 0.66 Classification-F1 0.6325439266615737 on epoch=62
05/30/2022 20:47:43 - INFO - __main__ - Saving model with best Classification-F1: 0.5788288288288288 -> 0.6325439266615737 on epoch=62, global_step=250
05/30/2022 20:47:45 - INFO - __main__ - Step 260 Global step 260 Train loss 0.70 on epoch=64
05/30/2022 20:47:48 - INFO - __main__ - Step 270 Global step 270 Train loss 0.58 on epoch=67
05/30/2022 20:47:50 - INFO - __main__ - Step 280 Global step 280 Train loss 0.59 on epoch=69
05/30/2022 20:47:53 - INFO - __main__ - Step 290 Global step 290 Train loss 0.53 on epoch=72
05/30/2022 20:47:55 - INFO - __main__ - Step 300 Global step 300 Train loss 0.52 on epoch=74
05/30/2022 20:47:56 - INFO - __main__ - Global step 300 Train loss 0.58 Classification-F1 0.5659590409590409 on epoch=74
05/30/2022 20:47:58 - INFO - __main__ - Step 310 Global step 310 Train loss 0.56 on epoch=77
05/30/2022 20:48:01 - INFO - __main__ - Step 320 Global step 320 Train loss 0.54 on epoch=79
05/30/2022 20:48:03 - INFO - __main__ - Step 330 Global step 330 Train loss 0.51 on epoch=82
05/30/2022 20:48:06 - INFO - __main__ - Step 340 Global step 340 Train loss 0.49 on epoch=84
05/30/2022 20:48:08 - INFO - __main__ - Step 350 Global step 350 Train loss 0.51 on epoch=87
05/30/2022 20:48:09 - INFO - __main__ - Global step 350 Train loss 0.52 Classification-F1 0.6304651027077498 on epoch=87
05/30/2022 20:48:12 - INFO - __main__ - Step 360 Global step 360 Train loss 0.50 on epoch=89
05/30/2022 20:48:14 - INFO - __main__ - Step 370 Global step 370 Train loss 0.40 on epoch=92
05/30/2022 20:48:16 - INFO - __main__ - Step 380 Global step 380 Train loss 0.53 on epoch=94
05/30/2022 20:48:19 - INFO - __main__ - Step 390 Global step 390 Train loss 0.47 on epoch=97
05/30/2022 20:48:21 - INFO - __main__ - Step 400 Global step 400 Train loss 0.37 on epoch=99
05/30/2022 20:48:22 - INFO - __main__ - Global step 400 Train loss 0.45 Classification-F1 0.7215341268472198 on epoch=99
05/30/2022 20:48:22 - INFO - __main__ - Saving model with best Classification-F1: 0.6325439266615737 -> 0.7215341268472198 on epoch=99, global_step=400
05/30/2022 20:48:25 - INFO - __main__ - Step 410 Global step 410 Train loss 0.51 on epoch=102
05/30/2022 20:48:27 - INFO - __main__ - Step 420 Global step 420 Train loss 0.38 on epoch=104
05/30/2022 20:48:29 - INFO - __main__ - Step 430 Global step 430 Train loss 0.42 on epoch=107
05/30/2022 20:48:32 - INFO - __main__ - Step 440 Global step 440 Train loss 0.44 on epoch=109
05/30/2022 20:48:34 - INFO - __main__ - Step 450 Global step 450 Train loss 0.37 on epoch=112
05/30/2022 20:48:35 - INFO - __main__ - Global step 450 Train loss 0.42 Classification-F1 0.6223039215686275 on epoch=112
05/30/2022 20:48:37 - INFO - __main__ - Step 460 Global step 460 Train loss 0.38 on epoch=114
05/30/2022 20:48:40 - INFO - __main__ - Step 470 Global step 470 Train loss 0.36 on epoch=117
05/30/2022 20:48:42 - INFO - __main__ - Step 480 Global step 480 Train loss 0.39 on epoch=119
05/30/2022 20:48:45 - INFO - __main__ - Step 490 Global step 490 Train loss 0.31 on epoch=122
05/30/2022 20:48:47 - INFO - __main__ - Step 500 Global step 500 Train loss 0.41 on epoch=124
05/30/2022 20:48:48 - INFO - __main__ - Global step 500 Train loss 0.37 Classification-F1 0.6671182266009852 on epoch=124
05/30/2022 20:48:51 - INFO - __main__ - Step 510 Global step 510 Train loss 0.42 on epoch=127
05/30/2022 20:48:53 - INFO - __main__ - Step 520 Global step 520 Train loss 0.34 on epoch=129
05/30/2022 20:48:55 - INFO - __main__ - Step 530 Global step 530 Train loss 0.28 on epoch=132
05/30/2022 20:48:58 - INFO - __main__ - Step 540 Global step 540 Train loss 0.33 on epoch=134
05/30/2022 20:49:00 - INFO - __main__ - Step 550 Global step 550 Train loss 0.32 on epoch=137
05/30/2022 20:49:01 - INFO - __main__ - Global step 550 Train loss 0.34 Classification-F1 0.6465907083554143 on epoch=137
05/30/2022 20:49:04 - INFO - __main__ - Step 560 Global step 560 Train loss 0.40 on epoch=139
05/30/2022 20:49:06 - INFO - __main__ - Step 570 Global step 570 Train loss 0.35 on epoch=142
05/30/2022 20:49:09 - INFO - __main__ - Step 580 Global step 580 Train loss 0.25 on epoch=144
05/30/2022 20:49:11 - INFO - __main__ - Step 590 Global step 590 Train loss 0.29 on epoch=147
05/30/2022 20:49:13 - INFO - __main__ - Step 600 Global step 600 Train loss 0.27 on epoch=149
05/30/2022 20:49:14 - INFO - __main__ - Global step 600 Train loss 0.31 Classification-F1 0.638285801666794 on epoch=149
05/30/2022 20:49:17 - INFO - __main__ - Step 610 Global step 610 Train loss 0.25 on epoch=152
05/30/2022 20:49:19 - INFO - __main__ - Step 620 Global step 620 Train loss 0.24 on epoch=154
05/30/2022 20:49:22 - INFO - __main__ - Step 630 Global step 630 Train loss 0.28 on epoch=157
05/30/2022 20:49:24 - INFO - __main__ - Step 640 Global step 640 Train loss 0.27 on epoch=159
05/30/2022 20:49:27 - INFO - __main__ - Step 650 Global step 650 Train loss 0.33 on epoch=162
05/30/2022 20:49:28 - INFO - __main__ - Global step 650 Train loss 0.28 Classification-F1 0.6507352941176471 on epoch=162
05/30/2022 20:49:30 - INFO - __main__ - Step 660 Global step 660 Train loss 0.25 on epoch=164
05/30/2022 20:49:32 - INFO - __main__ - Step 670 Global step 670 Train loss 0.19 on epoch=167
05/30/2022 20:49:35 - INFO - __main__ - Step 680 Global step 680 Train loss 0.21 on epoch=169
05/30/2022 20:49:37 - INFO - __main__ - Step 690 Global step 690 Train loss 0.24 on epoch=172
05/30/2022 20:49:40 - INFO - __main__ - Step 700 Global step 700 Train loss 0.26 on epoch=174
05/30/2022 20:49:41 - INFO - __main__ - Global step 700 Train loss 0.23 Classification-F1 0.6690139221832933 on epoch=174
05/30/2022 20:49:43 - INFO - __main__ - Step 710 Global step 710 Train loss 0.15 on epoch=177
05/30/2022 20:49:46 - INFO - __main__ - Step 720 Global step 720 Train loss 0.24 on epoch=179
05/30/2022 20:49:48 - INFO - __main__ - Step 730 Global step 730 Train loss 0.22 on epoch=182
05/30/2022 20:49:50 - INFO - __main__ - Step 740 Global step 740 Train loss 0.21 on epoch=184
05/30/2022 20:49:53 - INFO - __main__ - Step 750 Global step 750 Train loss 0.19 on epoch=187
05/30/2022 20:49:54 - INFO - __main__ - Global step 750 Train loss 0.20 Classification-F1 0.6738614800759014 on epoch=187
05/30/2022 20:49:56 - INFO - __main__ - Step 760 Global step 760 Train loss 0.23 on epoch=189
05/30/2022 20:49:59 - INFO - __main__ - Step 770 Global step 770 Train loss 0.23 on epoch=192
05/30/2022 20:50:01 - INFO - __main__ - Step 780 Global step 780 Train loss 0.22 on epoch=194
05/30/2022 20:50:04 - INFO - __main__ - Step 790 Global step 790 Train loss 0.33 on epoch=197
05/30/2022 20:50:06 - INFO - __main__ - Step 800 Global step 800 Train loss 0.18 on epoch=199
05/30/2022 20:50:07 - INFO - __main__ - Global step 800 Train loss 0.24 Classification-F1 0.7110982323964068 on epoch=199
05/30/2022 20:50:09 - INFO - __main__ - Step 810 Global step 810 Train loss 0.15 on epoch=202
05/30/2022 20:50:12 - INFO - __main__ - Step 820 Global step 820 Train loss 0.17 on epoch=204
05/30/2022 20:50:14 - INFO - __main__ - Step 830 Global step 830 Train loss 0.14 on epoch=207
05/30/2022 20:50:17 - INFO - __main__ - Step 840 Global step 840 Train loss 0.15 on epoch=209
05/30/2022 20:50:19 - INFO - __main__ - Step 850 Global step 850 Train loss 0.16 on epoch=212
05/30/2022 20:50:20 - INFO - __main__ - Global step 850 Train loss 0.15 Classification-F1 0.6876872119815668 on epoch=212
05/30/2022 20:50:22 - INFO - __main__ - Step 860 Global step 860 Train loss 0.22 on epoch=214
05/30/2022 20:50:25 - INFO - __main__ - Step 870 Global step 870 Train loss 0.22 on epoch=217
05/30/2022 20:50:27 - INFO - __main__ - Step 880 Global step 880 Train loss 0.08 on epoch=219
05/30/2022 20:50:30 - INFO - __main__ - Step 890 Global step 890 Train loss 0.16 on epoch=222
05/30/2022 20:50:32 - INFO - __main__ - Step 900 Global step 900 Train loss 0.15 on epoch=224
05/30/2022 20:50:33 - INFO - __main__ - Global step 900 Train loss 0.16 Classification-F1 0.6531885689578516 on epoch=224
05/30/2022 20:50:36 - INFO - __main__ - Step 910 Global step 910 Train loss 0.18 on epoch=227
05/30/2022 20:50:38 - INFO - __main__ - Step 920 Global step 920 Train loss 0.16 on epoch=229
05/30/2022 20:50:40 - INFO - __main__ - Step 930 Global step 930 Train loss 0.13 on epoch=232
05/30/2022 20:50:43 - INFO - __main__ - Step 940 Global step 940 Train loss 0.18 on epoch=234
05/30/2022 20:50:45 - INFO - __main__ - Step 950 Global step 950 Train loss 0.16 on epoch=237
05/30/2022 20:50:46 - INFO - __main__ - Global step 950 Train loss 0.16 Classification-F1 0.6089285714285715 on epoch=237
05/30/2022 20:50:49 - INFO - __main__ - Step 960 Global step 960 Train loss 0.15 on epoch=239
05/30/2022 20:50:51 - INFO - __main__ - Step 970 Global step 970 Train loss 0.12 on epoch=242
05/30/2022 20:50:53 - INFO - __main__ - Step 980 Global step 980 Train loss 0.12 on epoch=244
05/30/2022 20:50:56 - INFO - __main__ - Step 990 Global step 990 Train loss 0.13 on epoch=247
05/30/2022 20:50:58 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.13 on epoch=249
05/30/2022 20:50:59 - INFO - __main__ - Global step 1000 Train loss 0.13 Classification-F1 0.63662319481285 on epoch=249
05/30/2022 20:51:02 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.10 on epoch=252
05/30/2022 20:51:04 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.07 on epoch=254
05/30/2022 20:51:07 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.10 on epoch=257
05/30/2022 20:51:09 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.11 on epoch=259
05/30/2022 20:51:12 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.11 on epoch=262
05/30/2022 20:51:12 - INFO - __main__ - Global step 1050 Train loss 0.10 Classification-F1 0.6467664653148524 on epoch=262
05/30/2022 20:51:15 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.10 on epoch=264
05/30/2022 20:51:17 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.10 on epoch=267
05/30/2022 20:51:20 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.07 on epoch=269
05/30/2022 20:51:22 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.17 on epoch=272
05/30/2022 20:51:25 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.10 on epoch=274
05/30/2022 20:51:25 - INFO - __main__ - Global step 1100 Train loss 0.11 Classification-F1 0.7025573961057832 on epoch=274
05/30/2022 20:51:28 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.14 on epoch=277
05/30/2022 20:51:30 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.12 on epoch=279
05/30/2022 20:51:33 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.08 on epoch=282
05/30/2022 20:51:35 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.05 on epoch=284
05/30/2022 20:51:38 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.12 on epoch=287
05/30/2022 20:51:39 - INFO - __main__ - Global step 1150 Train loss 0.10 Classification-F1 0.644133459835547 on epoch=287
05/30/2022 20:51:41 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.10 on epoch=289
05/30/2022 20:51:44 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.09 on epoch=292
05/30/2022 20:51:46 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.05 on epoch=294
05/30/2022 20:51:48 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.08 on epoch=297
05/30/2022 20:51:51 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.04 on epoch=299
05/30/2022 20:51:52 - INFO - __main__ - Global step 1200 Train loss 0.07 Classification-F1 0.6658005307386112 on epoch=299
05/30/2022 20:51:54 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.10 on epoch=302
05/30/2022 20:51:57 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.08 on epoch=304
05/30/2022 20:51:59 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.03 on epoch=307
05/30/2022 20:52:02 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.18 on epoch=309
05/30/2022 20:52:04 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.10 on epoch=312
05/30/2022 20:52:05 - INFO - __main__ - Global step 1250 Train loss 0.10 Classification-F1 0.7236193986193986 on epoch=312
05/30/2022 20:52:05 - INFO - __main__ - Saving model with best Classification-F1: 0.7215341268472198 -> 0.7236193986193986 on epoch=312, global_step=1250
05/30/2022 20:52:07 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.09 on epoch=314
05/30/2022 20:52:10 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.09 on epoch=317
05/30/2022 20:52:12 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.14 on epoch=319
05/30/2022 20:52:15 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.02 on epoch=322
05/30/2022 20:52:17 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.12 on epoch=324
05/30/2022 20:52:18 - INFO - __main__ - Global step 1300 Train loss 0.09 Classification-F1 0.7411440852617323 on epoch=324
05/30/2022 20:52:18 - INFO - __main__ - Saving model with best Classification-F1: 0.7236193986193986 -> 0.7411440852617323 on epoch=324, global_step=1300
05/30/2022 20:52:21 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.07 on epoch=327
05/30/2022 20:52:23 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.05 on epoch=329
05/30/2022 20:52:25 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.05 on epoch=332
05/30/2022 20:52:28 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.10 on epoch=334
05/30/2022 20:52:30 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.06 on epoch=337
05/30/2022 20:52:31 - INFO - __main__ - Global step 1350 Train loss 0.06 Classification-F1 0.6512468852986095 on epoch=337
05/30/2022 20:52:34 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.13 on epoch=339
05/30/2022 20:52:36 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.06 on epoch=342
05/30/2022 20:52:39 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.08 on epoch=344
05/30/2022 20:52:41 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.02 on epoch=347
05/30/2022 20:52:44 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.07 on epoch=349
05/30/2022 20:52:45 - INFO - __main__ - Global step 1400 Train loss 0.07 Classification-F1 0.6749230295566503 on epoch=349
05/30/2022 20:52:47 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.03 on epoch=352
05/30/2022 20:52:50 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.06 on epoch=354
05/30/2022 20:52:52 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.11 on epoch=357
05/30/2022 20:52:55 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.03 on epoch=359
05/30/2022 20:52:57 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.04 on epoch=362
05/30/2022 20:52:58 - INFO - __main__ - Global step 1450 Train loss 0.06 Classification-F1 0.6504088504088503 on epoch=362
05/30/2022 20:53:00 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.05 on epoch=364
05/30/2022 20:53:03 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.04 on epoch=367
05/30/2022 20:53:05 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.04 on epoch=369
05/30/2022 20:53:08 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.09 on epoch=372
05/30/2022 20:53:10 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.03 on epoch=374
05/30/2022 20:53:11 - INFO - __main__ - Global step 1500 Train loss 0.05 Classification-F1 0.7068817204301077 on epoch=374
05/30/2022 20:53:13 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=377
05/30/2022 20:53:16 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.03 on epoch=379
05/30/2022 20:53:18 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.05 on epoch=382
05/30/2022 20:53:21 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.06 on epoch=384
05/30/2022 20:53:23 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.10 on epoch=387
05/30/2022 20:53:24 - INFO - __main__ - Global step 1550 Train loss 0.05 Classification-F1 0.6900677830940989 on epoch=387
05/30/2022 20:53:27 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.02 on epoch=389
05/30/2022 20:53:29 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.09 on epoch=392
05/30/2022 20:53:32 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.05 on epoch=394
05/30/2022 20:53:34 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.03 on epoch=397
05/30/2022 20:53:36 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.06 on epoch=399
05/30/2022 20:53:37 - INFO - __main__ - Global step 1600 Train loss 0.05 Classification-F1 0.7386826953003424 on epoch=399
05/30/2022 20:53:40 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.12 on epoch=402
05/30/2022 20:53:42 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=404
05/30/2022 20:53:45 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.03 on epoch=407
05/30/2022 20:53:47 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.02 on epoch=409
05/30/2022 20:53:50 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.08 on epoch=412
05/30/2022 20:53:51 - INFO - __main__ - Global step 1650 Train loss 0.05 Classification-F1 0.6457936507936508 on epoch=412
05/30/2022 20:53:53 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.03 on epoch=414
05/30/2022 20:53:56 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.09 on epoch=417
05/30/2022 20:53:58 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.06 on epoch=419
05/30/2022 20:54:00 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.09 on epoch=422
05/30/2022 20:54:03 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.05 on epoch=424
05/30/2022 20:54:04 - INFO - __main__ - Global step 1700 Train loss 0.06 Classification-F1 0.7056019585253457 on epoch=424
05/30/2022 20:54:06 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=427
05/30/2022 20:54:09 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.05 on epoch=429
05/30/2022 20:54:11 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.03 on epoch=432
05/30/2022 20:54:14 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=434
05/30/2022 20:54:16 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=437
05/30/2022 20:54:17 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.7395723522383865 on epoch=437
05/30/2022 20:54:20 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.04 on epoch=439
05/30/2022 20:54:22 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=442
05/30/2022 20:54:25 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.03 on epoch=444
05/30/2022 20:54:27 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.12 on epoch=447
05/30/2022 20:54:30 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.03 on epoch=449
05/30/2022 20:54:31 - INFO - __main__ - Global step 1800 Train loss 0.05 Classification-F1 0.6704573934837093 on epoch=449
05/30/2022 20:54:33 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.04 on epoch=452
05/30/2022 20:54:36 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.08 on epoch=454
05/30/2022 20:54:38 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=457
05/30/2022 20:54:41 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=459
05/30/2022 20:54:43 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=462
05/30/2022 20:54:44 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.687834566866825 on epoch=462
05/30/2022 20:54:47 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=464
05/30/2022 20:54:49 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.03 on epoch=467
05/30/2022 20:54:51 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=469
05/30/2022 20:54:54 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=472
05/30/2022 20:54:56 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.06 on epoch=474
05/30/2022 20:54:57 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.6553396898224484 on epoch=474
05/30/2022 20:55:00 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.11 on epoch=477
05/30/2022 20:55:02 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.08 on epoch=479
05/30/2022 20:55:05 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=482
05/30/2022 20:55:07 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=484
05/30/2022 20:55:10 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=487
05/30/2022 20:55:11 - INFO - __main__ - Global step 1950 Train loss 0.05 Classification-F1 0.6713893319156476 on epoch=487
05/30/2022 20:55:13 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=489
05/30/2022 20:55:16 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=492
05/30/2022 20:55:18 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=494
05/30/2022 20:55:20 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=497
05/30/2022 20:55:23 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=499
05/30/2022 20:55:24 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.7395723522383865 on epoch=499
05/30/2022 20:55:27 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.05 on epoch=502
05/30/2022 20:55:29 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.07 on epoch=504
05/30/2022 20:55:31 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=507
05/30/2022 20:55:34 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.05 on epoch=509
05/30/2022 20:55:36 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=512
05/30/2022 20:55:37 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.6685328185328185 on epoch=512
05/30/2022 20:55:40 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=514
05/30/2022 20:55:42 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.03 on epoch=517
05/30/2022 20:55:45 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=519
05/30/2022 20:55:47 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.11 on epoch=522
05/30/2022 20:55:50 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=524
05/30/2022 20:55:51 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.6687088588089701 on epoch=524
05/30/2022 20:55:53 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.03 on epoch=527
05/30/2022 20:55:56 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=529
05/30/2022 20:55:58 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=532
05/30/2022 20:56:00 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.05 on epoch=534
05/30/2022 20:56:03 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=537
05/30/2022 20:56:04 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.6724048800661704 on epoch=537
05/30/2022 20:56:06 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.05 on epoch=539
05/30/2022 20:56:09 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=542
05/30/2022 20:56:11 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=544
05/30/2022 20:56:14 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=547
05/30/2022 20:56:16 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=549
05/30/2022 20:56:17 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.6678386850800644 on epoch=549
05/30/2022 20:56:20 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=552
05/30/2022 20:56:22 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=554
05/30/2022 20:56:25 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=557
05/30/2022 20:56:27 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
05/30/2022 20:56:30 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.10 on epoch=562
05/30/2022 20:56:31 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.6861388384754992 on epoch=562
05/30/2022 20:56:33 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=564
05/30/2022 20:56:36 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=567
05/30/2022 20:56:38 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.06 on epoch=569
05/30/2022 20:56:40 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.03 on epoch=572
05/30/2022 20:56:43 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=574
05/30/2022 20:56:44 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.6861388384754992 on epoch=574
05/30/2022 20:56:46 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=577
05/30/2022 20:56:49 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=579
05/30/2022 20:56:51 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=582
05/30/2022 20:56:54 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=584
05/30/2022 20:56:56 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=587
05/30/2022 20:56:57 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.6238843813387425 on epoch=587
05/30/2022 20:57:00 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.04 on epoch=589
05/30/2022 20:57:02 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=592
05/30/2022 20:57:05 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.03 on epoch=594
05/30/2022 20:57:07 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=597
05/30/2022 20:57:09 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=599
05/30/2022 20:57:10 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.6171217167587404 on epoch=599
05/30/2022 20:57:13 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=602
05/30/2022 20:57:15 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=604
05/30/2022 20:57:18 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=607
05/30/2022 20:57:20 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.07 on epoch=609
05/30/2022 20:57:23 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.05 on epoch=612
05/30/2022 20:57:24 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.6330470604664152 on epoch=612
05/30/2022 20:57:26 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=614
05/30/2022 20:57:29 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=617
05/30/2022 20:57:31 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=619
05/30/2022 20:57:34 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=622
05/30/2022 20:57:36 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.05 on epoch=624
05/30/2022 20:57:37 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.6238843813387425 on epoch=624
05/30/2022 20:57:40 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.04 on epoch=627
05/30/2022 20:57:42 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=629
05/30/2022 20:57:45 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=632
05/30/2022 20:57:47 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
05/30/2022 20:57:50 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=637
05/30/2022 20:57:51 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.6404846022493081 on epoch=637
05/30/2022 20:57:53 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.03 on epoch=639
05/30/2022 20:57:56 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.06 on epoch=642
05/30/2022 20:57:58 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.03 on epoch=644
05/30/2022 20:58:01 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.07 on epoch=647
05/30/2022 20:58:03 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=649
05/30/2022 20:58:04 - INFO - __main__ - Global step 2600 Train loss 0.04 Classification-F1 0.5466183574879226 on epoch=649
05/30/2022 20:58:07 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.04 on epoch=652
05/30/2022 20:58:09 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
05/30/2022 20:58:11 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
05/30/2022 20:58:14 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=659
05/30/2022 20:58:16 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=662
05/30/2022 20:58:17 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.6861641814228021 on epoch=662
05/30/2022 20:58:20 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.04 on epoch=664
05/30/2022 20:58:22 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
05/30/2022 20:58:25 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
05/30/2022 20:58:27 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=672
05/30/2022 20:58:30 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=674
05/30/2022 20:58:31 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.7256834633494975 on epoch=674
05/30/2022 20:58:33 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=677
05/30/2022 20:58:36 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.05 on epoch=679
05/30/2022 20:58:38 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=682
05/30/2022 20:58:41 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.03 on epoch=684
05/30/2022 20:58:43 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
05/30/2022 20:58:44 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.6872557622557622 on epoch=687
05/30/2022 20:58:47 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
05/30/2022 20:58:49 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=692
05/30/2022 20:58:52 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=694
05/30/2022 20:58:54 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=697
05/30/2022 20:58:57 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=699
05/30/2022 20:58:58 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.7047655374268277 on epoch=699
05/30/2022 20:59:00 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=702
05/30/2022 20:59:03 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=704
05/30/2022 20:59:05 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.03 on epoch=707
05/30/2022 20:59:07 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=709
05/30/2022 20:59:10 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=712
05/30/2022 20:59:11 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.7232744107744108 on epoch=712
05/30/2022 20:59:13 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=714
05/30/2022 20:59:16 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=717
05/30/2022 20:59:18 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=719
05/30/2022 20:59:21 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=722
05/30/2022 20:59:23 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.04 on epoch=724
05/30/2022 20:59:24 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.6624812030075189 on epoch=724
05/30/2022 20:59:27 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
05/30/2022 20:59:29 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.04 on epoch=729
05/30/2022 20:59:32 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=732
05/30/2022 20:59:34 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=734
05/30/2022 20:59:37 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=737
05/30/2022 20:59:38 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.7025573961057832 on epoch=737
05/30/2022 20:59:40 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=739
05/30/2022 20:59:43 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.05 on epoch=742
05/30/2022 20:59:45 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.03 on epoch=744
05/30/2022 20:59:48 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=747
05/30/2022 20:59:50 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=749
05/30/2022 20:59:51 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.64894429346762 on epoch=749
05/30/2022 20:59:51 - INFO - __main__ - save last model!
05/30/2022 20:59:51 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/30/2022 20:59:51 - INFO - __main__ - Start tokenizing ... 5509 instances
05/30/2022 20:59:51 - INFO - __main__ - Printing 3 examples
05/30/2022 20:59:51 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/30/2022 20:59:51 - INFO - __main__ - ['others']
05/30/2022 20:59:51 - INFO - __main__ -  [emo] what you like very little things ok
05/30/2022 20:59:51 - INFO - __main__ - ['others']
05/30/2022 20:59:51 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/30/2022 20:59:51 - INFO - __main__ - ['others']
05/30/2022 20:59:51 - INFO - __main__ - Tokenizing Input ...
05/30/2022 20:59:51 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 20:59:51 - INFO - __main__ - Printing 3 examples
05/30/2022 20:59:51 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
05/30/2022 20:59:51 - INFO - __main__ - ['others']
05/30/2022 20:59:51 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
05/30/2022 20:59:51 - INFO - __main__ - ['others']
05/30/2022 20:59:51 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
05/30/2022 20:59:51 - INFO - __main__ - ['others']
05/30/2022 20:59:51 - INFO - __main__ - Tokenizing Input ...
05/30/2022 20:59:51 - INFO - __main__ - Tokenizing Output ...
05/30/2022 20:59:51 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 20:59:51 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 20:59:51 - INFO - __main__ - Printing 3 examples
05/30/2022 20:59:51 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
05/30/2022 20:59:51 - INFO - __main__ - ['others']
05/30/2022 20:59:51 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
05/30/2022 20:59:51 - INFO - __main__ - ['others']
05/30/2022 20:59:51 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
05/30/2022 20:59:51 - INFO - __main__ - ['others']
05/30/2022 20:59:51 - INFO - __main__ - Tokenizing Input ...
05/30/2022 20:59:51 - INFO - __main__ - Tokenizing Output ...
05/30/2022 20:59:52 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 20:59:53 - INFO - __main__ - Tokenizing Output ...
05/30/2022 20:59:59 - INFO - __main__ - Loaded 5509 examples from test data
05/30/2022 21:00:10 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 21:00:11 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/30/2022 21:00:11 - INFO - __main__ - Starting training!
05/30/2022 21:01:34 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-24uptasks/singletask-emo/emo_16_42_0.2_8_predictions.txt
05/30/2022 21:01:34 - INFO - __main__ - Classification-F1 on test data: 0.2647
05/30/2022 21:01:34 - INFO - __main__ - prefix=emo_16_42, lr=0.2, bsz=8, dev_performance=0.7411440852617323, test_performance=0.2647335777501037
05/30/2022 21:01:34 - INFO - __main__ - Running ... prefix=emo_16_87, lr=0.5, bsz=8 ...
05/30/2022 21:01:35 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 21:01:35 - INFO - __main__ - Printing 3 examples
05/30/2022 21:01:35 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
05/30/2022 21:01:35 - INFO - __main__ - ['others']
05/30/2022 21:01:35 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
05/30/2022 21:01:35 - INFO - __main__ - ['others']
05/30/2022 21:01:35 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
05/30/2022 21:01:35 - INFO - __main__ - ['others']
05/30/2022 21:01:35 - INFO - __main__ - Tokenizing Input ...
05/30/2022 21:01:35 - INFO - __main__ - Tokenizing Output ...
05/30/2022 21:01:35 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 21:01:35 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 21:01:35 - INFO - __main__ - Printing 3 examples
05/30/2022 21:01:35 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
05/30/2022 21:01:35 - INFO - __main__ - ['others']
05/30/2022 21:01:35 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
05/30/2022 21:01:35 - INFO - __main__ - ['others']
05/30/2022 21:01:35 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
05/30/2022 21:01:35 - INFO - __main__ - ['others']
05/30/2022 21:01:35 - INFO - __main__ - Tokenizing Input ...
05/30/2022 21:01:35 - INFO - __main__ - Tokenizing Output ...
05/30/2022 21:01:35 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 21:01:54 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 21:01:55 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/30/2022 21:01:55 - INFO - __main__ - Starting training!
05/30/2022 21:01:58 - INFO - __main__ - Step 10 Global step 10 Train loss 3.33 on epoch=2
05/30/2022 21:02:00 - INFO - __main__ - Step 20 Global step 20 Train loss 1.42 on epoch=4
05/30/2022 21:02:03 - INFO - __main__ - Step 30 Global step 30 Train loss 1.11 on epoch=7
05/30/2022 21:02:05 - INFO - __main__ - Step 40 Global step 40 Train loss 0.95 on epoch=9
05/30/2022 21:02:08 - INFO - __main__ - Step 50 Global step 50 Train loss 1.00 on epoch=12
05/30/2022 21:02:09 - INFO - __main__ - Global step 50 Train loss 1.56 Classification-F1 0.4720211238720262 on epoch=12
05/30/2022 21:02:09 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.4720211238720262 on epoch=12, global_step=50
05/30/2022 21:02:11 - INFO - __main__ - Step 60 Global step 60 Train loss 0.87 on epoch=14
05/30/2022 21:02:14 - INFO - __main__ - Step 70 Global step 70 Train loss 0.77 on epoch=17
05/30/2022 21:02:16 - INFO - __main__ - Step 80 Global step 80 Train loss 0.76 on epoch=19
05/30/2022 21:02:19 - INFO - __main__ - Step 90 Global step 90 Train loss 0.77 on epoch=22
05/30/2022 21:02:21 - INFO - __main__ - Step 100 Global step 100 Train loss 0.68 on epoch=24
05/30/2022 21:02:22 - INFO - __main__ - Global step 100 Train loss 0.77 Classification-F1 0.33002152674283824 on epoch=24
05/30/2022 21:02:24 - INFO - __main__ - Step 110 Global step 110 Train loss 0.63 on epoch=27
05/30/2022 21:02:27 - INFO - __main__ - Step 120 Global step 120 Train loss 0.67 on epoch=29
05/30/2022 21:02:29 - INFO - __main__ - Step 130 Global step 130 Train loss 0.58 on epoch=32
05/30/2022 21:02:32 - INFO - __main__ - Step 140 Global step 140 Train loss 0.55 on epoch=34
05/30/2022 21:02:34 - INFO - __main__ - Step 150 Global step 150 Train loss 0.55 on epoch=37
05/30/2022 21:02:35 - INFO - __main__ - Global step 150 Train loss 0.60 Classification-F1 0.7482819264069265 on epoch=37
05/30/2022 21:02:35 - INFO - __main__ - Saving model with best Classification-F1: 0.4720211238720262 -> 0.7482819264069265 on epoch=37, global_step=150
05/30/2022 21:02:37 - INFO - __main__ - Step 160 Global step 160 Train loss 0.46 on epoch=39
05/30/2022 21:02:40 - INFO - __main__ - Step 170 Global step 170 Train loss 0.46 on epoch=42
05/30/2022 21:02:42 - INFO - __main__ - Step 180 Global step 180 Train loss 0.49 on epoch=44
05/30/2022 21:02:45 - INFO - __main__ - Step 190 Global step 190 Train loss 0.38 on epoch=47
05/30/2022 21:02:47 - INFO - __main__ - Step 200 Global step 200 Train loss 0.40 on epoch=49
05/30/2022 21:02:48 - INFO - __main__ - Global step 200 Train loss 0.44 Classification-F1 0.6557498057498057 on epoch=49
05/30/2022 21:02:50 - INFO - __main__ - Step 210 Global step 210 Train loss 0.42 on epoch=52
05/30/2022 21:02:53 - INFO - __main__ - Step 220 Global step 220 Train loss 0.37 on epoch=54
05/30/2022 21:02:55 - INFO - __main__ - Step 230 Global step 230 Train loss 0.32 on epoch=57
05/30/2022 21:02:58 - INFO - __main__ - Step 240 Global step 240 Train loss 0.40 on epoch=59
05/30/2022 21:03:00 - INFO - __main__ - Step 250 Global step 250 Train loss 0.24 on epoch=62
05/30/2022 21:03:01 - INFO - __main__ - Global step 250 Train loss 0.35 Classification-F1 0.5827379534809876 on epoch=62
05/30/2022 21:03:03 - INFO - __main__ - Step 260 Global step 260 Train loss 0.25 on epoch=64
05/30/2022 21:03:06 - INFO - __main__ - Step 270 Global step 270 Train loss 0.39 on epoch=67
05/30/2022 21:03:08 - INFO - __main__ - Step 280 Global step 280 Train loss 0.33 on epoch=69
05/30/2022 21:03:11 - INFO - __main__ - Step 290 Global step 290 Train loss 0.32 on epoch=72
05/30/2022 21:03:13 - INFO - __main__ - Step 300 Global step 300 Train loss 0.26 on epoch=74
05/30/2022 21:03:14 - INFO - __main__ - Global step 300 Train loss 0.31 Classification-F1 0.7032037815126051 on epoch=74
05/30/2022 21:03:16 - INFO - __main__ - Step 310 Global step 310 Train loss 0.35 on epoch=77
05/30/2022 21:03:19 - INFO - __main__ - Step 320 Global step 320 Train loss 0.25 on epoch=79
05/30/2022 21:03:21 - INFO - __main__ - Step 330 Global step 330 Train loss 0.29 on epoch=82
05/30/2022 21:03:24 - INFO - __main__ - Step 340 Global step 340 Train loss 0.26 on epoch=84
05/30/2022 21:03:26 - INFO - __main__ - Step 350 Global step 350 Train loss 0.34 on epoch=87
05/30/2022 21:03:27 - INFO - __main__ - Global step 350 Train loss 0.30 Classification-F1 0.7394088669950739 on epoch=87
05/30/2022 21:03:29 - INFO - __main__ - Step 360 Global step 360 Train loss 0.20 on epoch=89
05/30/2022 21:03:32 - INFO - __main__ - Step 370 Global step 370 Train loss 0.15 on epoch=92
05/30/2022 21:03:34 - INFO - __main__ - Step 380 Global step 380 Train loss 0.18 on epoch=94
05/30/2022 21:03:37 - INFO - __main__ - Step 390 Global step 390 Train loss 0.16 on epoch=97
05/30/2022 21:03:39 - INFO - __main__ - Step 400 Global step 400 Train loss 0.17 on epoch=99
05/30/2022 21:03:40 - INFO - __main__ - Global step 400 Train loss 0.17 Classification-F1 0.5735347985347986 on epoch=99
05/30/2022 21:03:42 - INFO - __main__ - Step 410 Global step 410 Train loss 0.20 on epoch=102
05/30/2022 21:03:45 - INFO - __main__ - Step 420 Global step 420 Train loss 0.16 on epoch=104
05/30/2022 21:03:47 - INFO - __main__ - Step 430 Global step 430 Train loss 0.14 on epoch=107
05/30/2022 21:03:50 - INFO - __main__ - Step 440 Global step 440 Train loss 0.13 on epoch=109
05/30/2022 21:03:52 - INFO - __main__ - Step 450 Global step 450 Train loss 0.10 on epoch=112
05/30/2022 21:03:53 - INFO - __main__ - Global step 450 Train loss 0.15 Classification-F1 0.6307212785540959 on epoch=112
05/30/2022 21:03:55 - INFO - __main__ - Step 460 Global step 460 Train loss 0.19 on epoch=114
05/30/2022 21:03:58 - INFO - __main__ - Step 470 Global step 470 Train loss 0.17 on epoch=117
05/30/2022 21:04:00 - INFO - __main__ - Step 480 Global step 480 Train loss 0.10 on epoch=119
05/30/2022 21:04:03 - INFO - __main__ - Step 490 Global step 490 Train loss 0.08 on epoch=122
05/30/2022 21:04:05 - INFO - __main__ - Step 500 Global step 500 Train loss 0.15 on epoch=124
05/30/2022 21:04:06 - INFO - __main__ - Global step 500 Train loss 0.14 Classification-F1 0.7026839826839828 on epoch=124
05/30/2022 21:04:08 - INFO - __main__ - Step 510 Global step 510 Train loss 0.10 on epoch=127
05/30/2022 21:04:11 - INFO - __main__ - Step 520 Global step 520 Train loss 0.10 on epoch=129
05/30/2022 21:04:13 - INFO - __main__ - Step 530 Global step 530 Train loss 0.05 on epoch=132
05/30/2022 21:04:16 - INFO - __main__ - Step 540 Global step 540 Train loss 0.09 on epoch=134
05/30/2022 21:04:18 - INFO - __main__ - Step 550 Global step 550 Train loss 0.06 on epoch=137
05/30/2022 21:04:19 - INFO - __main__ - Global step 550 Train loss 0.08 Classification-F1 0.7115841073271414 on epoch=137
05/30/2022 21:04:21 - INFO - __main__ - Step 560 Global step 560 Train loss 0.08 on epoch=139
05/30/2022 21:04:24 - INFO - __main__ - Step 570 Global step 570 Train loss 0.09 on epoch=142
05/30/2022 21:04:26 - INFO - __main__ - Step 580 Global step 580 Train loss 0.07 on epoch=144
05/30/2022 21:04:29 - INFO - __main__ - Step 590 Global step 590 Train loss 0.06 on epoch=147
05/30/2022 21:04:31 - INFO - __main__ - Step 600 Global step 600 Train loss 0.06 on epoch=149
05/30/2022 21:04:32 - INFO - __main__ - Global step 600 Train loss 0.07 Classification-F1 0.7426872895622896 on epoch=149
05/30/2022 21:04:35 - INFO - __main__ - Step 610 Global step 610 Train loss 0.05 on epoch=152
05/30/2022 21:04:37 - INFO - __main__ - Step 620 Global step 620 Train loss 0.07 on epoch=154
05/30/2022 21:04:39 - INFO - __main__ - Step 630 Global step 630 Train loss 0.09 on epoch=157
05/30/2022 21:04:42 - INFO - __main__ - Step 640 Global step 640 Train loss 0.14 on epoch=159
05/30/2022 21:04:44 - INFO - __main__ - Step 650 Global step 650 Train loss 0.05 on epoch=162
05/30/2022 21:04:45 - INFO - __main__ - Global step 650 Train loss 0.08 Classification-F1 0.7664069264069264 on epoch=162
05/30/2022 21:04:45 - INFO - __main__ - Saving model with best Classification-F1: 0.7482819264069265 -> 0.7664069264069264 on epoch=162, global_step=650
05/30/2022 21:04:48 - INFO - __main__ - Step 660 Global step 660 Train loss 0.05 on epoch=164
05/30/2022 21:04:50 - INFO - __main__ - Step 670 Global step 670 Train loss 0.03 on epoch=167
05/30/2022 21:04:52 - INFO - __main__ - Step 680 Global step 680 Train loss 0.07 on epoch=169
05/30/2022 21:04:55 - INFO - __main__ - Step 690 Global step 690 Train loss 0.04 on epoch=172
05/30/2022 21:04:57 - INFO - __main__ - Step 700 Global step 700 Train loss 0.08 on epoch=174
05/30/2022 21:04:58 - INFO - __main__ - Global step 700 Train loss 0.06 Classification-F1 0.7274496336996337 on epoch=174
05/30/2022 21:05:01 - INFO - __main__ - Step 710 Global step 710 Train loss 0.04 on epoch=177
05/30/2022 21:05:03 - INFO - __main__ - Step 720 Global step 720 Train loss 0.03 on epoch=179
05/30/2022 21:05:06 - INFO - __main__ - Step 730 Global step 730 Train loss 0.06 on epoch=182
05/30/2022 21:05:08 - INFO - __main__ - Step 740 Global step 740 Train loss 0.09 on epoch=184
05/30/2022 21:05:10 - INFO - __main__ - Step 750 Global step 750 Train loss 0.03 on epoch=187
05/30/2022 21:05:11 - INFO - __main__ - Global step 750 Train loss 0.05 Classification-F1 0.6988038277511962 on epoch=187
05/30/2022 21:05:14 - INFO - __main__ - Step 760 Global step 760 Train loss 0.02 on epoch=189
05/30/2022 21:05:16 - INFO - __main__ - Step 770 Global step 770 Train loss 0.02 on epoch=192
05/30/2022 21:05:19 - INFO - __main__ - Step 780 Global step 780 Train loss 0.02 on epoch=194
05/30/2022 21:05:21 - INFO - __main__ - Step 790 Global step 790 Train loss 0.04 on epoch=197
05/30/2022 21:05:24 - INFO - __main__ - Step 800 Global step 800 Train loss 0.06 on epoch=199
05/30/2022 21:05:25 - INFO - __main__ - Global step 800 Train loss 0.03 Classification-F1 0.6719771241830066 on epoch=199
05/30/2022 21:05:27 - INFO - __main__ - Step 810 Global step 810 Train loss 0.04 on epoch=202
05/30/2022 21:05:29 - INFO - __main__ - Step 820 Global step 820 Train loss 0.07 on epoch=204
05/30/2022 21:05:32 - INFO - __main__ - Step 830 Global step 830 Train loss 0.02 on epoch=207
05/30/2022 21:05:34 - INFO - __main__ - Step 840 Global step 840 Train loss 0.03 on epoch=209
05/30/2022 21:05:37 - INFO - __main__ - Step 850 Global step 850 Train loss 0.04 on epoch=212
05/30/2022 21:05:38 - INFO - __main__ - Global step 850 Train loss 0.04 Classification-F1 0.7961219336219336 on epoch=212
05/30/2022 21:05:38 - INFO - __main__ - Saving model with best Classification-F1: 0.7664069264069264 -> 0.7961219336219336 on epoch=212, global_step=850
05/30/2022 21:05:40 - INFO - __main__ - Step 860 Global step 860 Train loss 0.05 on epoch=214
05/30/2022 21:05:43 - INFO - __main__ - Step 870 Global step 870 Train loss 0.04 on epoch=217
05/30/2022 21:05:45 - INFO - __main__ - Step 880 Global step 880 Train loss 0.04 on epoch=219
05/30/2022 21:05:47 - INFO - __main__ - Step 890 Global step 890 Train loss 0.01 on epoch=222
05/30/2022 21:05:50 - INFO - __main__ - Step 900 Global step 900 Train loss 0.01 on epoch=224
05/30/2022 21:05:51 - INFO - __main__ - Global step 900 Train loss 0.03 Classification-F1 0.796396998602881 on epoch=224
05/30/2022 21:05:51 - INFO - __main__ - Saving model with best Classification-F1: 0.7961219336219336 -> 0.796396998602881 on epoch=224, global_step=900
05/30/2022 21:05:53 - INFO - __main__ - Step 910 Global step 910 Train loss 0.02 on epoch=227
05/30/2022 21:05:56 - INFO - __main__ - Step 920 Global step 920 Train loss 0.05 on epoch=229
05/30/2022 21:05:58 - INFO - __main__ - Step 930 Global step 930 Train loss 0.08 on epoch=232
05/30/2022 21:06:01 - INFO - __main__ - Step 940 Global step 940 Train loss 0.01 on epoch=234
05/30/2022 21:06:03 - INFO - __main__ - Step 950 Global step 950 Train loss 0.01 on epoch=237
05/30/2022 21:06:04 - INFO - __main__ - Global step 950 Train loss 0.03 Classification-F1 0.7718569065343259 on epoch=237
05/30/2022 21:06:07 - INFO - __main__ - Step 960 Global step 960 Train loss 0.06 on epoch=239
05/30/2022 21:06:09 - INFO - __main__ - Step 970 Global step 970 Train loss 0.09 on epoch=242
05/30/2022 21:06:11 - INFO - __main__ - Step 980 Global step 980 Train loss 0.04 on epoch=244
05/30/2022 21:06:14 - INFO - __main__ - Step 990 Global step 990 Train loss 0.01 on epoch=247
05/30/2022 21:06:16 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.03 on epoch=249
05/30/2022 21:06:17 - INFO - __main__ - Global step 1000 Train loss 0.05 Classification-F1 0.7131947515848445 on epoch=249
05/30/2022 21:06:20 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.02 on epoch=252
05/30/2022 21:06:22 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.04 on epoch=254
05/30/2022 21:06:25 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.03 on epoch=257
05/30/2022 21:06:27 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.02 on epoch=259
05/30/2022 21:06:30 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.05 on epoch=262
05/30/2022 21:06:31 - INFO - __main__ - Global step 1050 Train loss 0.03 Classification-F1 0.7459150326797386 on epoch=262
05/30/2022 21:06:33 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.04 on epoch=264
05/30/2022 21:06:36 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.02 on epoch=267
05/30/2022 21:06:38 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.00 on epoch=269
05/30/2022 21:06:40 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.01 on epoch=272
05/30/2022 21:06:43 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.05 on epoch=274
05/30/2022 21:06:44 - INFO - __main__ - Global step 1100 Train loss 0.02 Classification-F1 0.7571555010893246 on epoch=274
05/30/2022 21:06:46 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.08 on epoch=277
05/30/2022 21:06:49 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=279
05/30/2022 21:06:51 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.02 on epoch=282
05/30/2022 21:06:54 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.10 on epoch=284
05/30/2022 21:06:56 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.02 on epoch=287
05/30/2022 21:06:57 - INFO - __main__ - Global step 1150 Train loss 0.04 Classification-F1 0.7952046297634533 on epoch=287
05/30/2022 21:07:00 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.06 on epoch=289
05/30/2022 21:07:02 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.00 on epoch=292
05/30/2022 21:07:05 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.09 on epoch=294
05/30/2022 21:07:07 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.02 on epoch=297
05/30/2022 21:07:10 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.02 on epoch=299
05/30/2022 21:07:11 - INFO - __main__ - Global step 1200 Train loss 0.04 Classification-F1 0.7584169151531581 on epoch=299
05/30/2022 21:07:13 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.02 on epoch=302
05/30/2022 21:07:16 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.05 on epoch=304
05/30/2022 21:07:18 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.03 on epoch=307
05/30/2022 21:07:20 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.00 on epoch=309
05/30/2022 21:07:23 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.00 on epoch=312
05/30/2022 21:07:24 - INFO - __main__ - Global step 1250 Train loss 0.02 Classification-F1 0.7165936687675817 on epoch=312
05/30/2022 21:07:26 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.06 on epoch=314
05/30/2022 21:07:29 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.01 on epoch=317
05/30/2022 21:07:31 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.02 on epoch=319
05/30/2022 21:07:34 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.05 on epoch=322
05/30/2022 21:07:36 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.02 on epoch=324
05/30/2022 21:07:37 - INFO - __main__ - Global step 1300 Train loss 0.03 Classification-F1 0.6835617129734777 on epoch=324
05/30/2022 21:07:40 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.02 on epoch=327
05/30/2022 21:07:42 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=329
05/30/2022 21:07:44 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=332
05/30/2022 21:07:47 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.02 on epoch=334
05/30/2022 21:07:49 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=337
05/30/2022 21:07:50 - INFO - __main__ - Global step 1350 Train loss 0.01 Classification-F1 0.7450472942800308 on epoch=337
05/30/2022 21:07:53 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=339
05/30/2022 21:07:55 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=342
05/30/2022 21:07:58 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=344
05/30/2022 21:08:00 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=347
05/30/2022 21:08:03 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.04 on epoch=349
05/30/2022 21:08:04 - INFO - __main__ - Global step 1400 Train loss 0.02 Classification-F1 0.7448940417690417 on epoch=349
05/30/2022 21:08:06 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.03 on epoch=352
05/30/2022 21:08:08 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.05 on epoch=354
05/30/2022 21:08:11 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=357
05/30/2022 21:08:13 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=359
05/30/2022 21:08:16 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=362
05/30/2022 21:08:17 - INFO - __main__ - Global step 1450 Train loss 0.02 Classification-F1 0.6128320150268066 on epoch=362
05/30/2022 21:08:19 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=364
05/30/2022 21:08:22 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=367
05/30/2022 21:08:24 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=369
05/30/2022 21:08:27 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.04 on epoch=372
05/30/2022 21:08:29 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.03 on epoch=374
05/30/2022 21:08:30 - INFO - __main__ - Global step 1500 Train loss 0.02 Classification-F1 0.758982683982684 on epoch=374
05/30/2022 21:08:32 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=377
05/30/2022 21:08:35 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=379
05/30/2022 21:08:37 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.02 on epoch=382
05/30/2022 21:08:40 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.07 on epoch=384
05/30/2022 21:08:42 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.03 on epoch=387
05/30/2022 21:08:43 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.7360360360360361 on epoch=387
05/30/2022 21:08:45 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.04 on epoch=389
05/30/2022 21:08:48 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=392
05/30/2022 21:08:50 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.09 on epoch=394
05/30/2022 21:08:53 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.02 on epoch=397
05/30/2022 21:08:55 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=399
05/30/2022 21:08:56 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.7513052825552826 on epoch=399
05/30/2022 21:08:59 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=402
05/30/2022 21:09:01 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=404
05/30/2022 21:09:04 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=407
05/30/2022 21:09:06 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=409
05/30/2022 21:09:09 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=412
05/30/2022 21:09:10 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.7312091503267975 on epoch=412
05/30/2022 21:09:12 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=414
05/30/2022 21:09:15 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=417
05/30/2022 21:09:17 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.06 on epoch=419
05/30/2022 21:09:20 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=422
05/30/2022 21:09:22 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=424
05/30/2022 21:09:23 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.736969696969697 on epoch=424
05/30/2022 21:09:26 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=427
05/30/2022 21:09:28 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=429
05/30/2022 21:09:31 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=432
05/30/2022 21:09:33 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.06 on epoch=434
05/30/2022 21:09:36 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=437
05/30/2022 21:09:37 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.7299445865302643 on epoch=437
05/30/2022 21:09:39 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=439
05/30/2022 21:09:42 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=442
05/30/2022 21:09:44 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.03 on epoch=444
05/30/2022 21:09:47 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=447
05/30/2022 21:09:49 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.03 on epoch=449
05/30/2022 21:09:50 - INFO - __main__ - Global step 1800 Train loss 0.02 Classification-F1 0.6945542380324988 on epoch=449
05/30/2022 21:09:53 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=452
05/30/2022 21:09:55 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=454
05/30/2022 21:09:58 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=457
05/30/2022 21:10:00 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=459
05/30/2022 21:10:03 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=462
05/30/2022 21:10:04 - INFO - __main__ - Global step 1850 Train loss 0.00 Classification-F1 0.7379719679633867 on epoch=462
05/30/2022 21:10:06 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=464
05/30/2022 21:10:09 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=467
05/30/2022 21:10:11 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=469
05/30/2022 21:10:14 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=472
05/30/2022 21:10:16 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=474
05/30/2022 21:10:17 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.7663913731276161 on epoch=474
05/30/2022 21:10:20 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=477
05/30/2022 21:10:22 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=479
05/30/2022 21:10:25 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=482
05/30/2022 21:10:27 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=484
05/30/2022 21:10:30 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=487
05/30/2022 21:10:31 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.7225225225225225 on epoch=487
05/30/2022 21:10:33 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=489
05/30/2022 21:10:36 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=492
05/30/2022 21:10:38 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=494
05/30/2022 21:10:41 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=497
05/30/2022 21:10:43 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=499
05/30/2022 21:10:44 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.7315656565656565 on epoch=499
05/30/2022 21:10:47 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=502
05/30/2022 21:10:49 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=504
05/30/2022 21:10:51 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=507
05/30/2022 21:10:54 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=509
05/30/2022 21:10:56 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=512
05/30/2022 21:10:57 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.7096495472454551 on epoch=512
05/30/2022 21:11:00 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=514
05/30/2022 21:11:02 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=517
05/30/2022 21:11:05 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
05/30/2022 21:11:07 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
05/30/2022 21:11:10 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
05/30/2022 21:11:11 - INFO - __main__ - Global step 2100 Train loss 0.00 Classification-F1 0.7451903907496013 on epoch=524
05/30/2022 21:11:13 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=527
05/30/2022 21:11:16 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=529
05/30/2022 21:11:18 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=532
05/30/2022 21:11:21 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
05/30/2022 21:11:23 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=537
05/30/2022 21:11:24 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.7873801220575415 on epoch=537
05/30/2022 21:11:27 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=539
05/30/2022 21:11:29 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=542
05/30/2022 21:11:32 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
05/30/2022 21:11:34 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
05/30/2022 21:11:37 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=549
05/30/2022 21:11:38 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.7659694312507612 on epoch=549
05/30/2022 21:11:40 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
05/30/2022 21:11:43 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=554
05/30/2022 21:11:46 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=557
05/30/2022 21:11:48 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=559
05/30/2022 21:11:50 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=562
05/30/2022 21:11:52 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.7663913731276161 on epoch=562
05/30/2022 21:11:54 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.03 on epoch=564
05/30/2022 21:11:57 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
05/30/2022 21:11:59 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=569
05/30/2022 21:12:01 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
05/30/2022 21:12:04 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
05/30/2022 21:12:05 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.7214285714285714 on epoch=574
05/30/2022 21:12:08 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
05/30/2022 21:12:10 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
05/30/2022 21:12:13 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
05/30/2022 21:12:15 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
05/30/2022 21:12:18 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.12 on epoch=587
05/30/2022 21:12:19 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.7118082368082368 on epoch=587
05/30/2022 21:12:21 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.05 on epoch=589
05/30/2022 21:12:24 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=592
05/30/2022 21:12:26 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
05/30/2022 21:12:29 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
05/30/2022 21:12:31 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
05/30/2022 21:12:32 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.7714932126696833 on epoch=599
05/30/2022 21:12:35 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
05/30/2022 21:12:37 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
05/30/2022 21:12:40 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
05/30/2022 21:12:42 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
05/30/2022 21:12:45 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=612
05/30/2022 21:12:46 - INFO - __main__ - Global step 2450 Train loss 0.00 Classification-F1 0.7520021645021645 on epoch=612
05/30/2022 21:12:48 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
05/30/2022 21:12:51 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
05/30/2022 21:12:53 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=619
05/30/2022 21:12:56 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=622
05/30/2022 21:12:58 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
05/30/2022 21:12:59 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.7361111111111112 on epoch=624
05/30/2022 21:13:02 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
05/30/2022 21:13:04 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=629
05/30/2022 21:13:07 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=632
05/30/2022 21:13:09 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
05/30/2022 21:13:12 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
05/30/2022 21:13:13 - INFO - __main__ - Global step 2550 Train loss 0.00 Classification-F1 0.7807453416149068 on epoch=637
05/30/2022 21:13:15 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
05/30/2022 21:13:18 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
05/30/2022 21:13:20 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=644
05/30/2022 21:13:23 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
05/30/2022 21:13:25 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
05/30/2022 21:13:26 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.7718497189085425 on epoch=649
05/30/2022 21:13:29 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
05/30/2022 21:13:31 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
05/30/2022 21:13:34 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
05/30/2022 21:13:36 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
05/30/2022 21:13:38 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
05/30/2022 21:13:40 - INFO - __main__ - Global step 2650 Train loss 0.00 Classification-F1 0.7665396010984247 on epoch=662
05/30/2022 21:13:42 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
05/30/2022 21:13:44 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
05/30/2022 21:13:47 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
05/30/2022 21:13:49 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=672
05/30/2022 21:13:52 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.07 on epoch=674
05/30/2022 21:13:53 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.7367936117936118 on epoch=674
05/30/2022 21:13:55 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
05/30/2022 21:13:58 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
05/30/2022 21:14:00 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=682
05/30/2022 21:14:03 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
05/30/2022 21:14:05 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=687
05/30/2022 21:14:06 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.7525642994392995 on epoch=687
05/30/2022 21:14:09 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=689
05/30/2022 21:14:11 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=692
05/30/2022 21:14:14 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
05/30/2022 21:14:16 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=697
05/30/2022 21:14:19 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
05/30/2022 21:14:20 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.7860504201680674 on epoch=699
05/30/2022 21:14:22 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
05/30/2022 21:14:25 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.04 on epoch=704
05/30/2022 21:14:27 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.05 on epoch=707
05/30/2022 21:14:29 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=709
05/30/2022 21:14:32 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=712
05/30/2022 21:14:33 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.7361111111111112 on epoch=712
05/30/2022 21:14:35 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
05/30/2022 21:14:38 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
05/30/2022 21:14:40 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=719
05/30/2022 21:14:43 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=722
05/30/2022 21:14:45 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
05/30/2022 21:14:46 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.7807453416149068 on epoch=724
05/30/2022 21:14:49 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
05/30/2022 21:14:51 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
05/30/2022 21:14:54 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=732
05/30/2022 21:14:56 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
05/30/2022 21:14:59 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
05/30/2022 21:15:00 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.7118082368082368 on epoch=737
05/30/2022 21:15:02 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
05/30/2022 21:15:05 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.08 on epoch=742
05/30/2022 21:15:07 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
05/30/2022 21:15:10 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
05/30/2022 21:15:12 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
05/30/2022 21:15:13 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.7114328614328614 on epoch=749
05/30/2022 21:15:13 - INFO - __main__ - save last model!
05/30/2022 21:15:13 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/30/2022 21:15:13 - INFO - __main__ - Start tokenizing ... 5509 instances
05/30/2022 21:15:13 - INFO - __main__ - Printing 3 examples
05/30/2022 21:15:13 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/30/2022 21:15:13 - INFO - __main__ - ['others']
05/30/2022 21:15:13 - INFO - __main__ -  [emo] what you like very little things ok
05/30/2022 21:15:13 - INFO - __main__ - ['others']
05/30/2022 21:15:13 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/30/2022 21:15:13 - INFO - __main__ - ['others']
05/30/2022 21:15:13 - INFO - __main__ - Tokenizing Input ...
05/30/2022 21:15:13 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 21:15:13 - INFO - __main__ - Printing 3 examples
05/30/2022 21:15:13 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
05/30/2022 21:15:13 - INFO - __main__ - ['others']
05/30/2022 21:15:13 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
05/30/2022 21:15:13 - INFO - __main__ - ['others']
05/30/2022 21:15:13 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
05/30/2022 21:15:13 - INFO - __main__ - ['others']
05/30/2022 21:15:13 - INFO - __main__ - Tokenizing Input ...
05/30/2022 21:15:13 - INFO - __main__ - Tokenizing Output ...
05/30/2022 21:15:14 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 21:15:14 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 21:15:14 - INFO - __main__ - Printing 3 examples
05/30/2022 21:15:14 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
05/30/2022 21:15:14 - INFO - __main__ - ['others']
05/30/2022 21:15:14 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
05/30/2022 21:15:14 - INFO - __main__ - ['others']
05/30/2022 21:15:14 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
05/30/2022 21:15:14 - INFO - __main__ - ['others']
05/30/2022 21:15:14 - INFO - __main__ - Tokenizing Input ...
05/30/2022 21:15:14 - INFO - __main__ - Tokenizing Output ...
05/30/2022 21:15:14 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 21:15:15 - INFO - __main__ - Tokenizing Output ...
05/30/2022 21:15:21 - INFO - __main__ - Loaded 5509 examples from test data
05/30/2022 21:15:32 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 21:15:33 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/30/2022 21:15:33 - INFO - __main__ - Starting training!
05/30/2022 21:16:54 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-24uptasks/singletask-emo/emo_16_87_0.5_8_predictions.txt
05/30/2022 21:16:54 - INFO - __main__ - Classification-F1 on test data: 0.2927
05/30/2022 21:16:55 - INFO - __main__ - prefix=emo_16_87, lr=0.5, bsz=8, dev_performance=0.796396998602881, test_performance=0.2927341291332122
05/30/2022 21:16:55 - INFO - __main__ - Running ... prefix=emo_16_87, lr=0.4, bsz=8 ...
05/30/2022 21:16:56 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 21:16:56 - INFO - __main__ - Printing 3 examples
05/30/2022 21:16:56 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
05/30/2022 21:16:56 - INFO - __main__ - ['others']
05/30/2022 21:16:56 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
05/30/2022 21:16:56 - INFO - __main__ - ['others']
05/30/2022 21:16:56 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
05/30/2022 21:16:56 - INFO - __main__ - ['others']
05/30/2022 21:16:56 - INFO - __main__ - Tokenizing Input ...
05/30/2022 21:16:56 - INFO - __main__ - Tokenizing Output ...
05/30/2022 21:16:56 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 21:16:56 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 21:16:56 - INFO - __main__ - Printing 3 examples
05/30/2022 21:16:56 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
05/30/2022 21:16:56 - INFO - __main__ - ['others']
05/30/2022 21:16:56 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
05/30/2022 21:16:56 - INFO - __main__ - ['others']
05/30/2022 21:16:56 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
05/30/2022 21:16:56 - INFO - __main__ - ['others']
05/30/2022 21:16:56 - INFO - __main__ - Tokenizing Input ...
05/30/2022 21:16:56 - INFO - __main__ - Tokenizing Output ...
05/30/2022 21:16:56 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 21:17:15 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 21:17:15 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/30/2022 21:17:15 - INFO - __main__ - Starting training!
05/30/2022 21:17:18 - INFO - __main__ - Step 10 Global step 10 Train loss 3.54 on epoch=2
05/30/2022 21:17:21 - INFO - __main__ - Step 20 Global step 20 Train loss 1.65 on epoch=4
05/30/2022 21:17:23 - INFO - __main__ - Step 30 Global step 30 Train loss 1.25 on epoch=7
05/30/2022 21:17:26 - INFO - __main__ - Step 40 Global step 40 Train loss 1.13 on epoch=9
05/30/2022 21:17:28 - INFO - __main__ - Step 50 Global step 50 Train loss 0.96 on epoch=12
05/30/2022 21:17:29 - INFO - __main__ - Global step 50 Train loss 1.71 Classification-F1 0.13067758749069247 on epoch=12
05/30/2022 21:17:29 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.13067758749069247 on epoch=12, global_step=50
05/30/2022 21:17:31 - INFO - __main__ - Step 60 Global step 60 Train loss 0.96 on epoch=14
05/30/2022 21:17:34 - INFO - __main__ - Step 70 Global step 70 Train loss 0.87 on epoch=17
05/30/2022 21:17:36 - INFO - __main__ - Step 80 Global step 80 Train loss 0.91 on epoch=19
05/30/2022 21:17:39 - INFO - __main__ - Step 90 Global step 90 Train loss 0.75 on epoch=22
05/30/2022 21:17:41 - INFO - __main__ - Step 100 Global step 100 Train loss 0.78 on epoch=24
05/30/2022 21:17:42 - INFO - __main__ - Global step 100 Train loss 0.86 Classification-F1 0.44209770114942526 on epoch=24
05/30/2022 21:17:42 - INFO - __main__ - Saving model with best Classification-F1: 0.13067758749069247 -> 0.44209770114942526 on epoch=24, global_step=100
05/30/2022 21:17:44 - INFO - __main__ - Step 110 Global step 110 Train loss 0.69 on epoch=27
05/30/2022 21:17:47 - INFO - __main__ - Step 120 Global step 120 Train loss 0.64 on epoch=29
05/30/2022 21:17:49 - INFO - __main__ - Step 130 Global step 130 Train loss 0.72 on epoch=32
05/30/2022 21:17:52 - INFO - __main__ - Step 140 Global step 140 Train loss 0.58 on epoch=34
05/30/2022 21:17:54 - INFO - __main__ - Step 150 Global step 150 Train loss 0.61 on epoch=37
05/30/2022 21:17:55 - INFO - __main__ - Global step 150 Train loss 0.65 Classification-F1 0.628834182229768 on epoch=37
05/30/2022 21:17:55 - INFO - __main__ - Saving model with best Classification-F1: 0.44209770114942526 -> 0.628834182229768 on epoch=37, global_step=150
05/30/2022 21:17:57 - INFO - __main__ - Step 160 Global step 160 Train loss 0.59 on epoch=39
05/30/2022 21:18:00 - INFO - __main__ - Step 170 Global step 170 Train loss 0.62 on epoch=42
05/30/2022 21:18:02 - INFO - __main__ - Step 180 Global step 180 Train loss 0.59 on epoch=44
05/30/2022 21:18:05 - INFO - __main__ - Step 190 Global step 190 Train loss 0.52 on epoch=47
05/30/2022 21:18:07 - INFO - __main__ - Step 200 Global step 200 Train loss 0.57 on epoch=49
05/30/2022 21:18:08 - INFO - __main__ - Global step 200 Train loss 0.58 Classification-F1 0.5920600025863184 on epoch=49
05/30/2022 21:18:11 - INFO - __main__ - Step 210 Global step 210 Train loss 0.50 on epoch=52
05/30/2022 21:18:13 - INFO - __main__ - Step 220 Global step 220 Train loss 0.47 on epoch=54
05/30/2022 21:18:16 - INFO - __main__ - Step 230 Global step 230 Train loss 0.45 on epoch=57
05/30/2022 21:18:18 - INFO - __main__ - Step 240 Global step 240 Train loss 0.42 on epoch=59
05/30/2022 21:18:21 - INFO - __main__ - Step 250 Global step 250 Train loss 0.39 on epoch=62
05/30/2022 21:18:21 - INFO - __main__ - Global step 250 Train loss 0.44 Classification-F1 0.7079365079365079 on epoch=62
05/30/2022 21:18:21 - INFO - __main__ - Saving model with best Classification-F1: 0.628834182229768 -> 0.7079365079365079 on epoch=62, global_step=250
05/30/2022 21:18:24 - INFO - __main__ - Step 260 Global step 260 Train loss 0.37 on epoch=64
05/30/2022 21:18:26 - INFO - __main__ - Step 270 Global step 270 Train loss 0.43 on epoch=67
05/30/2022 21:18:29 - INFO - __main__ - Step 280 Global step 280 Train loss 0.39 on epoch=69
05/30/2022 21:18:31 - INFO - __main__ - Step 290 Global step 290 Train loss 0.43 on epoch=72
05/30/2022 21:18:34 - INFO - __main__ - Step 300 Global step 300 Train loss 0.34 on epoch=74
05/30/2022 21:18:35 - INFO - __main__ - Global step 300 Train loss 0.39 Classification-F1 0.662680456798104 on epoch=74
05/30/2022 21:18:37 - INFO - __main__ - Step 310 Global step 310 Train loss 0.35 on epoch=77
05/30/2022 21:18:40 - INFO - __main__ - Step 320 Global step 320 Train loss 0.36 on epoch=79
05/30/2022 21:18:42 - INFO - __main__ - Step 330 Global step 330 Train loss 0.28 on epoch=82
05/30/2022 21:18:45 - INFO - __main__ - Step 340 Global step 340 Train loss 0.30 on epoch=84
05/30/2022 21:18:47 - INFO - __main__ - Step 350 Global step 350 Train loss 0.30 on epoch=87
05/30/2022 21:18:48 - INFO - __main__ - Global step 350 Train loss 0.32 Classification-F1 0.7758467023172906 on epoch=87
05/30/2022 21:18:48 - INFO - __main__ - Saving model with best Classification-F1: 0.7079365079365079 -> 0.7758467023172906 on epoch=87, global_step=350
05/30/2022 21:18:50 - INFO - __main__ - Step 360 Global step 360 Train loss 0.30 on epoch=89
05/30/2022 21:18:53 - INFO - __main__ - Step 370 Global step 370 Train loss 0.26 on epoch=92
05/30/2022 21:18:55 - INFO - __main__ - Step 380 Global step 380 Train loss 0.38 on epoch=94
05/30/2022 21:18:58 - INFO - __main__ - Step 390 Global step 390 Train loss 0.31 on epoch=97
05/30/2022 21:19:00 - INFO - __main__ - Step 400 Global step 400 Train loss 0.23 on epoch=99
05/30/2022 21:19:01 - INFO - __main__ - Global step 400 Train loss 0.30 Classification-F1 0.6013998138014895 on epoch=99
05/30/2022 21:19:04 - INFO - __main__ - Step 410 Global step 410 Train loss 0.37 on epoch=102
05/30/2022 21:19:06 - INFO - __main__ - Step 420 Global step 420 Train loss 0.22 on epoch=104
05/30/2022 21:19:09 - INFO - __main__ - Step 430 Global step 430 Train loss 0.29 on epoch=107
05/30/2022 21:19:11 - INFO - __main__ - Step 440 Global step 440 Train loss 0.27 on epoch=109
05/30/2022 21:19:14 - INFO - __main__ - Step 450 Global step 450 Train loss 0.23 on epoch=112
05/30/2022 21:19:15 - INFO - __main__ - Global step 450 Train loss 0.28 Classification-F1 0.7160556976413752 on epoch=112
05/30/2022 21:19:17 - INFO - __main__ - Step 460 Global step 460 Train loss 0.22 on epoch=114
05/30/2022 21:19:19 - INFO - __main__ - Step 470 Global step 470 Train loss 0.25 on epoch=117
05/30/2022 21:19:22 - INFO - __main__ - Step 480 Global step 480 Train loss 0.19 on epoch=119
05/30/2022 21:19:24 - INFO - __main__ - Step 490 Global step 490 Train loss 0.25 on epoch=122
05/30/2022 21:19:27 - INFO - __main__ - Step 500 Global step 500 Train loss 0.16 on epoch=124
05/30/2022 21:19:28 - INFO - __main__ - Global step 500 Train loss 0.21 Classification-F1 0.6717484817813766 on epoch=124
05/30/2022 21:19:30 - INFO - __main__ - Step 510 Global step 510 Train loss 0.25 on epoch=127
05/30/2022 21:19:33 - INFO - __main__ - Step 520 Global step 520 Train loss 0.21 on epoch=129
05/30/2022 21:19:35 - INFO - __main__ - Step 530 Global step 530 Train loss 0.19 on epoch=132
05/30/2022 21:19:38 - INFO - __main__ - Step 540 Global step 540 Train loss 0.21 on epoch=134
05/30/2022 21:19:40 - INFO - __main__ - Step 550 Global step 550 Train loss 0.19 on epoch=137
05/30/2022 21:19:41 - INFO - __main__ - Global step 550 Train loss 0.21 Classification-F1 0.7358993308698693 on epoch=137
05/30/2022 21:19:43 - INFO - __main__ - Step 560 Global step 560 Train loss 0.17 on epoch=139
05/30/2022 21:19:46 - INFO - __main__ - Step 570 Global step 570 Train loss 0.12 on epoch=142
05/30/2022 21:19:48 - INFO - __main__ - Step 580 Global step 580 Train loss 0.20 on epoch=144
05/30/2022 21:19:51 - INFO - __main__ - Step 590 Global step 590 Train loss 0.16 on epoch=147
05/30/2022 21:19:53 - INFO - __main__ - Step 600 Global step 600 Train loss 0.10 on epoch=149
05/30/2022 21:19:54 - INFO - __main__ - Global step 600 Train loss 0.15 Classification-F1 0.6589369302783937 on epoch=149
05/30/2022 21:19:57 - INFO - __main__ - Step 610 Global step 610 Train loss 0.16 on epoch=152
05/30/2022 21:19:59 - INFO - __main__ - Step 620 Global step 620 Train loss 0.16 on epoch=154
05/30/2022 21:20:02 - INFO - __main__ - Step 630 Global step 630 Train loss 0.24 on epoch=157
05/30/2022 21:20:04 - INFO - __main__ - Step 640 Global step 640 Train loss 0.07 on epoch=159
05/30/2022 21:20:07 - INFO - __main__ - Step 650 Global step 650 Train loss 0.09 on epoch=162
05/30/2022 21:20:08 - INFO - __main__ - Global step 650 Train loss 0.14 Classification-F1 0.6742543197468868 on epoch=162
05/30/2022 21:20:10 - INFO - __main__ - Step 660 Global step 660 Train loss 0.17 on epoch=164
05/30/2022 21:20:13 - INFO - __main__ - Step 670 Global step 670 Train loss 0.08 on epoch=167
05/30/2022 21:20:15 - INFO - __main__ - Step 680 Global step 680 Train loss 0.11 on epoch=169
05/30/2022 21:20:18 - INFO - __main__ - Step 690 Global step 690 Train loss 0.12 on epoch=172
05/30/2022 21:20:20 - INFO - __main__ - Step 700 Global step 700 Train loss 0.11 on epoch=174
05/30/2022 21:20:21 - INFO - __main__ - Global step 700 Train loss 0.12 Classification-F1 0.7250213346987541 on epoch=174
05/30/2022 21:20:23 - INFO - __main__ - Step 710 Global step 710 Train loss 0.11 on epoch=177
05/30/2022 21:20:26 - INFO - __main__ - Step 720 Global step 720 Train loss 0.10 on epoch=179
05/30/2022 21:20:28 - INFO - __main__ - Step 730 Global step 730 Train loss 0.06 on epoch=182
05/30/2022 21:20:31 - INFO - __main__ - Step 740 Global step 740 Train loss 0.07 on epoch=184
05/30/2022 21:20:33 - INFO - __main__ - Step 750 Global step 750 Train loss 0.11 on epoch=187
05/30/2022 21:20:34 - INFO - __main__ - Global step 750 Train loss 0.09 Classification-F1 0.6722750711237554 on epoch=187
05/30/2022 21:20:37 - INFO - __main__ - Step 760 Global step 760 Train loss 0.05 on epoch=189
05/30/2022 21:20:39 - INFO - __main__ - Step 770 Global step 770 Train loss 0.13 on epoch=192
05/30/2022 21:20:42 - INFO - __main__ - Step 780 Global step 780 Train loss 0.05 on epoch=194
05/30/2022 21:20:44 - INFO - __main__ - Step 790 Global step 790 Train loss 0.08 on epoch=197
05/30/2022 21:20:47 - INFO - __main__ - Step 800 Global step 800 Train loss 0.09 on epoch=199
05/30/2022 21:20:47 - INFO - __main__ - Global step 800 Train loss 0.08 Classification-F1 0.6107909379968204 on epoch=199
05/30/2022 21:20:50 - INFO - __main__ - Step 810 Global step 810 Train loss 0.07 on epoch=202
05/30/2022 21:20:52 - INFO - __main__ - Step 820 Global step 820 Train loss 0.12 on epoch=204
05/30/2022 21:20:55 - INFO - __main__ - Step 830 Global step 830 Train loss 0.10 on epoch=207
05/30/2022 21:20:57 - INFO - __main__ - Step 840 Global step 840 Train loss 0.07 on epoch=209
05/30/2022 21:21:00 - INFO - __main__ - Step 850 Global step 850 Train loss 0.06 on epoch=212
05/30/2022 21:21:01 - INFO - __main__ - Global step 850 Train loss 0.09 Classification-F1 0.7578375925150119 on epoch=212
05/30/2022 21:21:03 - INFO - __main__ - Step 860 Global step 860 Train loss 0.10 on epoch=214
05/30/2022 21:21:06 - INFO - __main__ - Step 870 Global step 870 Train loss 0.08 on epoch=217
05/30/2022 21:21:08 - INFO - __main__ - Step 880 Global step 880 Train loss 0.07 on epoch=219
05/30/2022 21:21:11 - INFO - __main__ - Step 890 Global step 890 Train loss 0.08 on epoch=222
05/30/2022 21:21:13 - INFO - __main__ - Step 900 Global step 900 Train loss 0.06 on epoch=224
05/30/2022 21:21:14 - INFO - __main__ - Global step 900 Train loss 0.08 Classification-F1 0.6990041208791209 on epoch=224
05/30/2022 21:21:16 - INFO - __main__ - Step 910 Global step 910 Train loss 0.06 on epoch=227
05/30/2022 21:21:19 - INFO - __main__ - Step 920 Global step 920 Train loss 0.03 on epoch=229
05/30/2022 21:21:21 - INFO - __main__ - Step 930 Global step 930 Train loss 0.07 on epoch=232
05/30/2022 21:21:24 - INFO - __main__ - Step 940 Global step 940 Train loss 0.04 on epoch=234
05/30/2022 21:21:26 - INFO - __main__ - Step 950 Global step 950 Train loss 0.07 on epoch=237
05/30/2022 21:21:27 - INFO - __main__ - Global step 950 Train loss 0.05 Classification-F1 0.5966229319170496 on epoch=237
05/30/2022 21:21:30 - INFO - __main__ - Step 960 Global step 960 Train loss 0.05 on epoch=239
05/30/2022 21:21:32 - INFO - __main__ - Step 970 Global step 970 Train loss 0.01 on epoch=242
05/30/2022 21:21:35 - INFO - __main__ - Step 980 Global step 980 Train loss 0.07 on epoch=244
05/30/2022 21:21:37 - INFO - __main__ - Step 990 Global step 990 Train loss 0.03 on epoch=247
05/30/2022 21:21:40 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.02 on epoch=249
05/30/2022 21:21:41 - INFO - __main__ - Global step 1000 Train loss 0.04 Classification-F1 0.7102219198993392 on epoch=249
05/30/2022 21:21:43 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.05 on epoch=252
05/30/2022 21:21:46 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.08 on epoch=254
05/30/2022 21:21:48 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.03 on epoch=257
05/30/2022 21:21:50 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.07 on epoch=259
05/30/2022 21:21:53 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.02 on epoch=262
05/30/2022 21:21:54 - INFO - __main__ - Global step 1050 Train loss 0.05 Classification-F1 0.6731353950103951 on epoch=262
05/30/2022 21:21:56 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.02 on epoch=264
05/30/2022 21:21:59 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.04 on epoch=267
05/30/2022 21:22:01 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.04 on epoch=269
05/30/2022 21:22:04 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.01 on epoch=272
05/30/2022 21:22:06 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.04 on epoch=274
05/30/2022 21:22:07 - INFO - __main__ - Global step 1100 Train loss 0.03 Classification-F1 0.731375773993808 on epoch=274
05/30/2022 21:22:10 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.06 on epoch=277
05/30/2022 21:22:12 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.03 on epoch=279
05/30/2022 21:22:15 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.02 on epoch=282
05/30/2022 21:22:17 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.03 on epoch=284
05/30/2022 21:22:20 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.03 on epoch=287
05/30/2022 21:22:21 - INFO - __main__ - Global step 1150 Train loss 0.03 Classification-F1 0.6413409650251756 on epoch=287
05/30/2022 21:22:23 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.02 on epoch=289
05/30/2022 21:22:25 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.04 on epoch=292
05/30/2022 21:22:28 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.02 on epoch=294
05/30/2022 21:22:30 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.04 on epoch=297
05/30/2022 21:22:33 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.04 on epoch=299
05/30/2022 21:22:34 - INFO - __main__ - Global step 1200 Train loss 0.03 Classification-F1 0.7669530483818241 on epoch=299
05/30/2022 21:22:36 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.02 on epoch=302
05/30/2022 21:22:39 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.05 on epoch=304
05/30/2022 21:22:41 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=307
05/30/2022 21:22:44 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.03 on epoch=309
05/30/2022 21:22:47 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.07 on epoch=312
05/30/2022 21:22:48 - INFO - __main__ - Global step 1250 Train loss 0.04 Classification-F1 0.7584169151531581 on epoch=312
05/30/2022 21:22:50 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.12 on epoch=314
05/30/2022 21:22:52 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.01 on epoch=317
05/30/2022 21:22:55 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=319
05/30/2022 21:22:57 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.05 on epoch=322
05/30/2022 21:23:00 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.06 on epoch=324
05/30/2022 21:23:01 - INFO - __main__ - Global step 1300 Train loss 0.05 Classification-F1 0.6970408207250313 on epoch=324
05/30/2022 21:23:03 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.02 on epoch=327
05/30/2022 21:23:06 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.03 on epoch=329
05/30/2022 21:23:08 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.04 on epoch=332
05/30/2022 21:23:11 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.05 on epoch=334
05/30/2022 21:23:13 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.06 on epoch=337
05/30/2022 21:23:14 - INFO - __main__ - Global step 1350 Train loss 0.04 Classification-F1 0.6701949627646222 on epoch=337
05/30/2022 21:23:17 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.02 on epoch=339
05/30/2022 21:23:19 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.04 on epoch=342
05/30/2022 21:23:22 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.03 on epoch=344
05/30/2022 21:23:24 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.02 on epoch=347
05/30/2022 21:23:27 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=349
05/30/2022 21:23:28 - INFO - __main__ - Global step 1400 Train loss 0.02 Classification-F1 0.6722750711237554 on epoch=349
05/30/2022 21:23:30 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.02 on epoch=352
05/30/2022 21:23:33 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.06 on epoch=354
05/30/2022 21:23:35 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=357
05/30/2022 21:23:37 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=359
05/30/2022 21:23:40 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.08 on epoch=362
05/30/2022 21:23:41 - INFO - __main__ - Global step 1450 Train loss 0.03 Classification-F1 0.6100384440167722 on epoch=362
05/30/2022 21:23:43 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=364
05/30/2022 21:23:46 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.02 on epoch=367
05/30/2022 21:23:48 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=369
05/30/2022 21:23:51 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=372
05/30/2022 21:23:53 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.03 on epoch=374
05/30/2022 21:23:54 - INFO - __main__ - Global step 1500 Train loss 0.01 Classification-F1 0.6834841628959275 on epoch=374
05/30/2022 21:23:57 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=377
05/30/2022 21:23:59 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.03 on epoch=379
05/30/2022 21:24:02 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=382
05/30/2022 21:24:04 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=384
05/30/2022 21:24:07 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=387
05/30/2022 21:24:08 - INFO - __main__ - Global step 1550 Train loss 0.02 Classification-F1 0.7283350840336135 on epoch=387
05/30/2022 21:24:10 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.03 on epoch=389
05/30/2022 21:24:13 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=392
05/30/2022 21:24:15 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.08 on epoch=394
05/30/2022 21:24:18 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.02 on epoch=397
05/30/2022 21:24:20 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=399
05/30/2022 21:24:21 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.7365196078431373 on epoch=399
05/30/2022 21:24:24 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=402
05/30/2022 21:24:26 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.02 on epoch=404
05/30/2022 21:24:29 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=407
05/30/2022 21:24:31 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=409
05/30/2022 21:24:34 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.03 on epoch=412
05/30/2022 21:24:35 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.7214795008912656 on epoch=412
05/30/2022 21:24:37 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=414
05/30/2022 21:24:39 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=417
05/30/2022 21:24:42 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=419
05/30/2022 21:24:44 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=422
05/30/2022 21:24:47 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=424
05/30/2022 21:24:48 - INFO - __main__ - Global step 1700 Train loss 0.01 Classification-F1 0.7458139563494992 on epoch=424
05/30/2022 21:24:50 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=427
05/30/2022 21:24:53 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=429
05/30/2022 21:24:55 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=432
05/30/2022 21:24:58 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=434
05/30/2022 21:25:00 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=437
05/30/2022 21:25:01 - INFO - __main__ - Global step 1750 Train loss 0.01 Classification-F1 0.7299445865302643 on epoch=437
05/30/2022 21:25:04 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=439
05/30/2022 21:25:06 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=442
05/30/2022 21:25:09 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.08 on epoch=444
05/30/2022 21:25:11 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.06 on epoch=447
05/30/2022 21:25:14 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=449
05/30/2022 21:25:15 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.7056175902950096 on epoch=449
05/30/2022 21:25:17 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=452
05/30/2022 21:25:20 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=454
05/30/2022 21:25:22 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=457
05/30/2022 21:25:25 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=459
05/30/2022 21:25:27 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=462
05/30/2022 21:25:28 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.6632488479262673 on epoch=462
05/30/2022 21:25:31 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=464
05/30/2022 21:25:33 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=467
05/30/2022 21:25:36 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=469
05/30/2022 21:25:38 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.07 on epoch=472
05/30/2022 21:25:41 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.02 on epoch=474
05/30/2022 21:25:42 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.7723801220575415 on epoch=474
05/30/2022 21:25:44 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=477
05/30/2022 21:25:47 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=479
05/30/2022 21:25:49 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=482
05/30/2022 21:25:52 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=484
05/30/2022 21:25:54 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.05 on epoch=487
05/30/2022 21:25:55 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.6141330891330892 on epoch=487
05/30/2022 21:25:57 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=489
05/30/2022 21:26:00 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=492
05/30/2022 21:26:03 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.08 on epoch=494
05/30/2022 21:26:05 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=497
05/30/2022 21:26:07 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=499
05/30/2022 21:26:08 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.7445958186447317 on epoch=499
05/30/2022 21:26:11 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=502
05/30/2022 21:26:13 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=504
05/30/2022 21:26:16 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.02 on epoch=507
05/30/2022 21:26:18 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=509
05/30/2022 21:26:21 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.03 on epoch=512
05/30/2022 21:26:22 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.641468868249054 on epoch=512
05/30/2022 21:26:24 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=514
05/30/2022 21:26:27 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=517
05/30/2022 21:26:29 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
05/30/2022 21:26:32 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
05/30/2022 21:26:34 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=524
05/30/2022 21:26:35 - INFO - __main__ - Global step 2100 Train loss 0.00 Classification-F1 0.7166698916408669 on epoch=524
05/30/2022 21:26:38 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.13 on epoch=527
05/30/2022 21:26:40 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=529
05/30/2022 21:26:43 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=532
05/30/2022 21:26:45 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=534
05/30/2022 21:26:48 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=537
05/30/2022 21:26:49 - INFO - __main__ - Global step 2150 Train loss 0.03 Classification-F1 0.7526189496777732 on epoch=537
05/30/2022 21:26:52 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
05/30/2022 21:26:54 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
05/30/2022 21:26:56 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.04 on epoch=544
05/30/2022 21:26:59 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=547
05/30/2022 21:27:01 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
05/30/2022 21:27:02 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.7718569065343259 on epoch=549
05/30/2022 21:27:05 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
05/30/2022 21:27:07 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
05/30/2022 21:27:10 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
05/30/2022 21:27:12 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
05/30/2022 21:27:15 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=562
05/30/2022 21:27:16 - INFO - __main__ - Global step 2250 Train loss 0.00 Classification-F1 0.7430409663865547 on epoch=562
05/30/2022 21:27:18 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
05/30/2022 21:27:21 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
05/30/2022 21:27:23 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=569
05/30/2022 21:27:26 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
05/30/2022 21:27:28 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=574
05/30/2022 21:27:29 - INFO - __main__ - Global step 2300 Train loss 0.00 Classification-F1 0.7231134878193702 on epoch=574
05/30/2022 21:27:32 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=577
05/30/2022 21:27:34 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=579
05/30/2022 21:27:37 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=582
05/30/2022 21:27:39 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
05/30/2022 21:27:42 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.05 on epoch=587
05/30/2022 21:27:43 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.7429518398268399 on epoch=587
05/30/2022 21:27:45 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
05/30/2022 21:27:48 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=592
05/30/2022 21:27:50 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
05/30/2022 21:27:53 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
05/30/2022 21:27:55 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.09 on epoch=599
05/30/2022 21:27:56 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.7858912655971481 on epoch=599
05/30/2022 21:27:56 - INFO - __main__ - Saving model with best Classification-F1: 0.7758467023172906 -> 0.7858912655971481 on epoch=599, global_step=2400
05/30/2022 21:27:59 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
05/30/2022 21:28:01 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
05/30/2022 21:28:04 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
05/30/2022 21:28:06 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=609
05/30/2022 21:28:09 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=612
05/30/2022 21:28:10 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.7515331890331891 on epoch=612
05/30/2022 21:28:12 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
05/30/2022 21:28:15 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
05/30/2022 21:28:17 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=619
05/30/2022 21:28:20 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
05/30/2022 21:28:22 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=624
05/30/2022 21:28:23 - INFO - __main__ - Global step 2500 Train loss 0.00 Classification-F1 0.7712568681318681 on epoch=624
05/30/2022 21:28:26 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=627
05/30/2022 21:28:28 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
05/30/2022 21:28:31 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=632
05/30/2022 21:28:33 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.05 on epoch=634
05/30/2022 21:28:36 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=637
05/30/2022 21:28:37 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.7452586974326105 on epoch=637
05/30/2022 21:28:39 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
05/30/2022 21:28:42 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.04 on epoch=642
05/30/2022 21:28:44 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=644
05/30/2022 21:28:47 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
05/30/2022 21:28:49 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=649
05/30/2022 21:28:50 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.7431245225362874 on epoch=649
05/30/2022 21:28:53 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
05/30/2022 21:28:55 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
05/30/2022 21:28:58 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
05/30/2022 21:29:00 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=659
05/30/2022 21:29:02 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
05/30/2022 21:29:03 - INFO - __main__ - Global step 2650 Train loss 0.00 Classification-F1 0.7236581501287385 on epoch=662
05/30/2022 21:29:06 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
05/30/2022 21:29:08 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=667
05/30/2022 21:29:11 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=669
05/30/2022 21:29:13 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
05/30/2022 21:29:16 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
05/30/2022 21:29:17 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.7712568681318681 on epoch=674
05/30/2022 21:29:19 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
05/30/2022 21:29:21 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
05/30/2022 21:29:24 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=682
05/30/2022 21:29:26 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
05/30/2022 21:29:29 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
05/30/2022 21:29:30 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.7443693693693694 on epoch=687
05/30/2022 21:29:32 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
05/30/2022 21:29:35 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
05/30/2022 21:29:37 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
05/30/2022 21:29:40 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
05/30/2022 21:29:42 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
05/30/2022 21:29:43 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.7217503217503217 on epoch=699
05/30/2022 21:29:45 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=702
05/30/2022 21:29:48 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
05/30/2022 21:29:50 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.04 on epoch=707
05/30/2022 21:29:53 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=709
05/30/2022 21:29:55 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
05/30/2022 21:29:56 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.6837218337218337 on epoch=712
05/30/2022 21:29:59 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
05/30/2022 21:30:01 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
05/30/2022 21:30:03 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
05/30/2022 21:30:06 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
05/30/2022 21:30:08 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
05/30/2022 21:30:09 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.7453688600747425 on epoch=724
05/30/2022 21:30:12 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=727
05/30/2022 21:30:14 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
05/30/2022 21:30:17 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=732
05/30/2022 21:30:19 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=734
05/30/2022 21:30:22 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
05/30/2022 21:30:23 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.7712568681318681 on epoch=737
05/30/2022 21:30:25 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
05/30/2022 21:30:28 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
05/30/2022 21:30:30 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=744
05/30/2022 21:30:33 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=747
05/30/2022 21:30:35 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=749
05/30/2022 21:30:36 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.7236581501287385 on epoch=749
05/30/2022 21:30:36 - INFO - __main__ - save last model!
05/30/2022 21:30:36 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/30/2022 21:30:36 - INFO - __main__ - Start tokenizing ... 5509 instances
05/30/2022 21:30:36 - INFO - __main__ - Printing 3 examples
05/30/2022 21:30:36 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/30/2022 21:30:36 - INFO - __main__ - ['others']
05/30/2022 21:30:36 - INFO - __main__ -  [emo] what you like very little things ok
05/30/2022 21:30:36 - INFO - __main__ - ['others']
05/30/2022 21:30:36 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/30/2022 21:30:36 - INFO - __main__ - ['others']
05/30/2022 21:30:36 - INFO - __main__ - Tokenizing Input ...
05/30/2022 21:30:36 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 21:30:36 - INFO - __main__ - Printing 3 examples
05/30/2022 21:30:36 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
05/30/2022 21:30:36 - INFO - __main__ - ['others']
05/30/2022 21:30:36 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
05/30/2022 21:30:36 - INFO - __main__ - ['others']
05/30/2022 21:30:36 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
05/30/2022 21:30:36 - INFO - __main__ - ['others']
05/30/2022 21:30:36 - INFO - __main__ - Tokenizing Input ...
05/30/2022 21:30:37 - INFO - __main__ - Tokenizing Output ...
05/30/2022 21:30:37 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 21:30:37 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 21:30:37 - INFO - __main__ - Printing 3 examples
05/30/2022 21:30:37 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
05/30/2022 21:30:37 - INFO - __main__ - ['others']
05/30/2022 21:30:37 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
05/30/2022 21:30:37 - INFO - __main__ - ['others']
05/30/2022 21:30:37 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
05/30/2022 21:30:37 - INFO - __main__ - ['others']
05/30/2022 21:30:37 - INFO - __main__ - Tokenizing Input ...
05/30/2022 21:30:37 - INFO - __main__ - Tokenizing Output ...
05/30/2022 21:30:37 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 21:30:38 - INFO - __main__ - Tokenizing Output ...
05/30/2022 21:30:43 - INFO - __main__ - Loaded 5509 examples from test data
05/30/2022 21:30:52 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 21:30:53 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/30/2022 21:30:53 - INFO - __main__ - Starting training!
05/30/2022 21:31:59 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-24uptasks/singletask-emo/emo_16_87_0.4_8_predictions.txt
05/30/2022 21:31:59 - INFO - __main__ - Classification-F1 on test data: 0.4468
05/30/2022 21:31:59 - INFO - __main__ - prefix=emo_16_87, lr=0.4, bsz=8, dev_performance=0.7858912655971481, test_performance=0.4467992468080339
05/30/2022 21:31:59 - INFO - __main__ - Running ... prefix=emo_16_87, lr=0.3, bsz=8 ...
05/30/2022 21:32:00 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 21:32:00 - INFO - __main__ - Printing 3 examples
05/30/2022 21:32:00 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
05/30/2022 21:32:00 - INFO - __main__ - ['others']
05/30/2022 21:32:00 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
05/30/2022 21:32:00 - INFO - __main__ - ['others']
05/30/2022 21:32:00 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
05/30/2022 21:32:00 - INFO - __main__ - ['others']
05/30/2022 21:32:00 - INFO - __main__ - Tokenizing Input ...
05/30/2022 21:32:00 - INFO - __main__ - Tokenizing Output ...
05/30/2022 21:32:01 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 21:32:01 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 21:32:01 - INFO - __main__ - Printing 3 examples
05/30/2022 21:32:01 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
05/30/2022 21:32:01 - INFO - __main__ - ['others']
05/30/2022 21:32:01 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
05/30/2022 21:32:01 - INFO - __main__ - ['others']
05/30/2022 21:32:01 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
05/30/2022 21:32:01 - INFO - __main__ - ['others']
05/30/2022 21:32:01 - INFO - __main__ - Tokenizing Input ...
05/30/2022 21:32:01 - INFO - __main__ - Tokenizing Output ...
05/30/2022 21:32:01 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 21:32:16 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 21:32:17 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/30/2022 21:32:17 - INFO - __main__ - Starting training!
05/30/2022 21:32:20 - INFO - __main__ - Step 10 Global step 10 Train loss 3.79 on epoch=2
05/30/2022 21:32:23 - INFO - __main__ - Step 20 Global step 20 Train loss 2.05 on epoch=4
05/30/2022 21:32:25 - INFO - __main__ - Step 30 Global step 30 Train loss 1.54 on epoch=7
05/30/2022 21:32:28 - INFO - __main__ - Step 40 Global step 40 Train loss 1.19 on epoch=9
05/30/2022 21:32:31 - INFO - __main__ - Step 50 Global step 50 Train loss 0.91 on epoch=12
05/30/2022 21:32:31 - INFO - __main__ - Global step 50 Train loss 1.90 Classification-F1 0.19886677722498616 on epoch=12
05/30/2022 21:32:31 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.19886677722498616 on epoch=12, global_step=50
05/30/2022 21:32:34 - INFO - __main__ - Step 60 Global step 60 Train loss 0.95 on epoch=14
05/30/2022 21:32:36 - INFO - __main__ - Step 70 Global step 70 Train loss 0.92 on epoch=17
05/30/2022 21:32:39 - INFO - __main__ - Step 80 Global step 80 Train loss 0.88 on epoch=19
05/30/2022 21:32:41 - INFO - __main__ - Step 90 Global step 90 Train loss 0.88 on epoch=22
05/30/2022 21:32:44 - INFO - __main__ - Step 100 Global step 100 Train loss 0.72 on epoch=24
05/30/2022 21:32:45 - INFO - __main__ - Global step 100 Train loss 0.87 Classification-F1 0.31757797970136564 on epoch=24
05/30/2022 21:32:45 - INFO - __main__ - Saving model with best Classification-F1: 0.19886677722498616 -> 0.31757797970136564 on epoch=24, global_step=100
05/30/2022 21:32:47 - INFO - __main__ - Step 110 Global step 110 Train loss 0.80 on epoch=27
05/30/2022 21:32:50 - INFO - __main__ - Step 120 Global step 120 Train loss 0.79 on epoch=29
05/30/2022 21:32:52 - INFO - __main__ - Step 130 Global step 130 Train loss 0.84 on epoch=32
05/30/2022 21:32:55 - INFO - __main__ - Step 140 Global step 140 Train loss 0.75 on epoch=34
05/30/2022 21:32:57 - INFO - __main__ - Step 150 Global step 150 Train loss 0.71 on epoch=37
05/30/2022 21:32:58 - INFO - __main__ - Global step 150 Train loss 0.78 Classification-F1 0.6370490620490621 on epoch=37
05/30/2022 21:32:58 - INFO - __main__ - Saving model with best Classification-F1: 0.31757797970136564 -> 0.6370490620490621 on epoch=37, global_step=150
05/30/2022 21:33:00 - INFO - __main__ - Step 160 Global step 160 Train loss 0.71 on epoch=39
05/30/2022 21:33:03 - INFO - __main__ - Step 170 Global step 170 Train loss 0.57 on epoch=42
05/30/2022 21:33:05 - INFO - __main__ - Step 180 Global step 180 Train loss 0.58 on epoch=44
05/30/2022 21:33:08 - INFO - __main__ - Step 190 Global step 190 Train loss 0.62 on epoch=47
05/30/2022 21:33:10 - INFO - __main__ - Step 200 Global step 200 Train loss 0.55 on epoch=49
05/30/2022 21:33:11 - INFO - __main__ - Global step 200 Train loss 0.61 Classification-F1 0.5530777701830333 on epoch=49
05/30/2022 21:33:14 - INFO - __main__ - Step 210 Global step 210 Train loss 0.55 on epoch=52
05/30/2022 21:33:16 - INFO - __main__ - Step 220 Global step 220 Train loss 0.51 on epoch=54
05/30/2022 21:33:19 - INFO - __main__ - Step 230 Global step 230 Train loss 0.50 on epoch=57
05/30/2022 21:33:21 - INFO - __main__ - Step 240 Global step 240 Train loss 0.51 on epoch=59
05/30/2022 21:33:24 - INFO - __main__ - Step 250 Global step 250 Train loss 0.42 on epoch=62
05/30/2022 21:33:24 - INFO - __main__ - Global step 250 Train loss 0.50 Classification-F1 0.713458022097728 on epoch=62
05/30/2022 21:33:24 - INFO - __main__ - Saving model with best Classification-F1: 0.6370490620490621 -> 0.713458022097728 on epoch=62, global_step=250
05/30/2022 21:33:27 - INFO - __main__ - Step 260 Global step 260 Train loss 0.52 on epoch=64
05/30/2022 21:33:29 - INFO - __main__ - Step 270 Global step 270 Train loss 0.51 on epoch=67
05/30/2022 21:33:32 - INFO - __main__ - Step 280 Global step 280 Train loss 0.52 on epoch=69
05/30/2022 21:33:34 - INFO - __main__ - Step 290 Global step 290 Train loss 0.35 on epoch=72
05/30/2022 21:33:37 - INFO - __main__ - Step 300 Global step 300 Train loss 0.36 on epoch=74
05/30/2022 21:33:38 - INFO - __main__ - Global step 300 Train loss 0.45 Classification-F1 0.6018508215570639 on epoch=74
05/30/2022 21:33:40 - INFO - __main__ - Step 310 Global step 310 Train loss 0.42 on epoch=77
05/30/2022 21:33:43 - INFO - __main__ - Step 320 Global step 320 Train loss 0.37 on epoch=79
05/30/2022 21:33:45 - INFO - __main__ - Step 330 Global step 330 Train loss 0.37 on epoch=82
05/30/2022 21:33:48 - INFO - __main__ - Step 340 Global step 340 Train loss 0.42 on epoch=84
05/30/2022 21:33:50 - INFO - __main__ - Step 350 Global step 350 Train loss 0.41 on epoch=87
05/30/2022 21:33:51 - INFO - __main__ - Global step 350 Train loss 0.40 Classification-F1 0.642893217893218 on epoch=87
05/30/2022 21:33:53 - INFO - __main__ - Step 360 Global step 360 Train loss 0.41 on epoch=89
05/30/2022 21:33:56 - INFO - __main__ - Step 370 Global step 370 Train loss 0.30 on epoch=92
05/30/2022 21:33:58 - INFO - __main__ - Step 380 Global step 380 Train loss 0.32 on epoch=94
05/30/2022 21:34:01 - INFO - __main__ - Step 390 Global step 390 Train loss 0.37 on epoch=97
05/30/2022 21:34:03 - INFO - __main__ - Step 400 Global step 400 Train loss 0.34 on epoch=99
05/30/2022 21:34:04 - INFO - __main__ - Global step 400 Train loss 0.35 Classification-F1 0.5634398496240601 on epoch=99
05/30/2022 21:34:06 - INFO - __main__ - Step 410 Global step 410 Train loss 0.34 on epoch=102
05/30/2022 21:34:09 - INFO - __main__ - Step 420 Global step 420 Train loss 0.30 on epoch=104
05/30/2022 21:34:11 - INFO - __main__ - Step 430 Global step 430 Train loss 0.31 on epoch=107
05/30/2022 21:34:14 - INFO - __main__ - Step 440 Global step 440 Train loss 0.28 on epoch=109
05/30/2022 21:34:16 - INFO - __main__ - Step 450 Global step 450 Train loss 0.24 on epoch=112
05/30/2022 21:34:17 - INFO - __main__ - Global step 450 Train loss 0.29 Classification-F1 0.6714071919664024 on epoch=112
05/30/2022 21:34:20 - INFO - __main__ - Step 460 Global step 460 Train loss 0.31 on epoch=114
05/30/2022 21:34:22 - INFO - __main__ - Step 470 Global step 470 Train loss 0.22 on epoch=117
05/30/2022 21:34:25 - INFO - __main__ - Step 480 Global step 480 Train loss 0.20 on epoch=119
05/30/2022 21:34:27 - INFO - __main__ - Step 490 Global step 490 Train loss 0.26 on epoch=122
05/30/2022 21:34:30 - INFO - __main__ - Step 500 Global step 500 Train loss 0.21 on epoch=124
05/30/2022 21:34:30 - INFO - __main__ - Global step 500 Train loss 0.24 Classification-F1 0.6164453927611824 on epoch=124
05/30/2022 21:34:33 - INFO - __main__ - Step 510 Global step 510 Train loss 0.23 on epoch=127
05/30/2022 21:34:35 - INFO - __main__ - Step 520 Global step 520 Train loss 0.18 on epoch=129
05/30/2022 21:34:38 - INFO - __main__ - Step 530 Global step 530 Train loss 0.24 on epoch=132
05/30/2022 21:34:40 - INFO - __main__ - Step 540 Global step 540 Train loss 0.24 on epoch=134
05/30/2022 21:34:43 - INFO - __main__ - Step 550 Global step 550 Train loss 0.24 on epoch=137
05/30/2022 21:34:44 - INFO - __main__ - Global step 550 Train loss 0.22 Classification-F1 0.6425653594771242 on epoch=137
05/30/2022 21:34:46 - INFO - __main__ - Step 560 Global step 560 Train loss 0.22 on epoch=139
05/30/2022 21:34:48 - INFO - __main__ - Step 570 Global step 570 Train loss 0.21 on epoch=142
05/30/2022 21:34:51 - INFO - __main__ - Step 580 Global step 580 Train loss 0.21 on epoch=144
05/30/2022 21:34:53 - INFO - __main__ - Step 590 Global step 590 Train loss 0.20 on epoch=147
05/30/2022 21:34:56 - INFO - __main__ - Step 600 Global step 600 Train loss 0.18 on epoch=149
05/30/2022 21:34:57 - INFO - __main__ - Global step 600 Train loss 0.20 Classification-F1 0.6011441305558953 on epoch=149
05/30/2022 21:34:59 - INFO - __main__ - Step 610 Global step 610 Train loss 0.17 on epoch=152
05/30/2022 21:35:01 - INFO - __main__ - Step 620 Global step 620 Train loss 0.19 on epoch=154
05/30/2022 21:35:04 - INFO - __main__ - Step 630 Global step 630 Train loss 0.12 on epoch=157
05/30/2022 21:35:06 - INFO - __main__ - Step 640 Global step 640 Train loss 0.13 on epoch=159
05/30/2022 21:35:09 - INFO - __main__ - Step 650 Global step 650 Train loss 0.12 on epoch=162
05/30/2022 21:35:10 - INFO - __main__ - Global step 650 Train loss 0.15 Classification-F1 0.6837829868789621 on epoch=162
05/30/2022 21:35:12 - INFO - __main__ - Step 660 Global step 660 Train loss 0.19 on epoch=164
05/30/2022 21:35:15 - INFO - __main__ - Step 670 Global step 670 Train loss 0.08 on epoch=167
05/30/2022 21:35:17 - INFO - __main__ - Step 680 Global step 680 Train loss 0.14 on epoch=169
05/30/2022 21:35:19 - INFO - __main__ - Step 690 Global step 690 Train loss 0.18 on epoch=172
05/30/2022 21:35:22 - INFO - __main__ - Step 700 Global step 700 Train loss 0.13 on epoch=174
05/30/2022 21:35:23 - INFO - __main__ - Global step 700 Train loss 0.15 Classification-F1 0.6303656597774245 on epoch=174
05/30/2022 21:35:25 - INFO - __main__ - Step 710 Global step 710 Train loss 0.14 on epoch=177
05/30/2022 21:35:28 - INFO - __main__ - Step 720 Global step 720 Train loss 0.14 on epoch=179
05/30/2022 21:35:30 - INFO - __main__ - Step 730 Global step 730 Train loss 0.08 on epoch=182
05/30/2022 21:35:33 - INFO - __main__ - Step 740 Global step 740 Train loss 0.11 on epoch=184
05/30/2022 21:35:35 - INFO - __main__ - Step 750 Global step 750 Train loss 0.10 on epoch=187
05/30/2022 21:35:36 - INFO - __main__ - Global step 750 Train loss 0.11 Classification-F1 0.7660504201680672 on epoch=187
05/30/2022 21:35:36 - INFO - __main__ - Saving model with best Classification-F1: 0.713458022097728 -> 0.7660504201680672 on epoch=187, global_step=750
05/30/2022 21:35:38 - INFO - __main__ - Step 760 Global step 760 Train loss 0.11 on epoch=189
05/30/2022 21:35:41 - INFO - __main__ - Step 770 Global step 770 Train loss 0.20 on epoch=192
05/30/2022 21:35:43 - INFO - __main__ - Step 780 Global step 780 Train loss 0.07 on epoch=194
05/30/2022 21:35:46 - INFO - __main__ - Step 790 Global step 790 Train loss 0.07 on epoch=197
05/30/2022 21:35:48 - INFO - __main__ - Step 800 Global step 800 Train loss 0.06 on epoch=199
05/30/2022 21:35:49 - INFO - __main__ - Global step 800 Train loss 0.10 Classification-F1 0.7378547378547379 on epoch=199
05/30/2022 21:35:52 - INFO - __main__ - Step 810 Global step 810 Train loss 0.10 on epoch=202
05/30/2022 21:35:54 - INFO - __main__ - Step 820 Global step 820 Train loss 0.05 on epoch=204
05/30/2022 21:35:57 - INFO - __main__ - Step 830 Global step 830 Train loss 0.10 on epoch=207
05/30/2022 21:35:59 - INFO - __main__ - Step 840 Global step 840 Train loss 0.06 on epoch=209
05/30/2022 21:36:02 - INFO - __main__ - Step 850 Global step 850 Train loss 0.18 on epoch=212
05/30/2022 21:36:02 - INFO - __main__ - Global step 850 Train loss 0.10 Classification-F1 0.7715247715247716 on epoch=212
05/30/2022 21:36:02 - INFO - __main__ - Saving model with best Classification-F1: 0.7660504201680672 -> 0.7715247715247716 on epoch=212, global_step=850
05/30/2022 21:36:05 - INFO - __main__ - Step 860 Global step 860 Train loss 0.19 on epoch=214
05/30/2022 21:36:07 - INFO - __main__ - Step 870 Global step 870 Train loss 0.08 on epoch=217
05/30/2022 21:36:10 - INFO - __main__ - Step 880 Global step 880 Train loss 0.04 on epoch=219
05/30/2022 21:36:12 - INFO - __main__ - Step 890 Global step 890 Train loss 0.08 on epoch=222
05/30/2022 21:36:15 - INFO - __main__ - Step 900 Global step 900 Train loss 0.10 on epoch=224
05/30/2022 21:36:16 - INFO - __main__ - Global step 900 Train loss 0.10 Classification-F1 0.7229813664596273 on epoch=224
05/30/2022 21:36:18 - INFO - __main__ - Step 910 Global step 910 Train loss 0.10 on epoch=227
05/30/2022 21:36:20 - INFO - __main__ - Step 920 Global step 920 Train loss 0.07 on epoch=229
05/30/2022 21:36:23 - INFO - __main__ - Step 930 Global step 930 Train loss 0.10 on epoch=232
05/30/2022 21:36:25 - INFO - __main__ - Step 940 Global step 940 Train loss 0.10 on epoch=234
05/30/2022 21:36:28 - INFO - __main__ - Step 950 Global step 950 Train loss 0.08 on epoch=237
05/30/2022 21:36:29 - INFO - __main__ - Global step 950 Train loss 0.09 Classification-F1 0.7100490196078432 on epoch=237
05/30/2022 21:36:31 - INFO - __main__ - Step 960 Global step 960 Train loss 0.05 on epoch=239
05/30/2022 21:36:34 - INFO - __main__ - Step 970 Global step 970 Train loss 0.04 on epoch=242
05/30/2022 21:36:36 - INFO - __main__ - Step 980 Global step 980 Train loss 0.02 on epoch=244
05/30/2022 21:36:38 - INFO - __main__ - Step 990 Global step 990 Train loss 0.06 on epoch=247
05/30/2022 21:36:41 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.10 on epoch=249
05/30/2022 21:36:42 - INFO - __main__ - Global step 1000 Train loss 0.05 Classification-F1 0.6716269841269842 on epoch=249
05/30/2022 21:36:44 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.05 on epoch=252
05/30/2022 21:36:47 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.05 on epoch=254
05/30/2022 21:36:49 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.15 on epoch=257
05/30/2022 21:36:52 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.04 on epoch=259
05/30/2022 21:36:54 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.06 on epoch=262
05/30/2022 21:36:55 - INFO - __main__ - Global step 1050 Train loss 0.07 Classification-F1 0.7122265122265122 on epoch=262
05/30/2022 21:36:57 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.06 on epoch=264
05/30/2022 21:37:00 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.06 on epoch=267
05/30/2022 21:37:02 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.04 on epoch=269
05/30/2022 21:37:05 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.03 on epoch=272
05/30/2022 21:37:07 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.02 on epoch=274
05/30/2022 21:37:08 - INFO - __main__ - Global step 1100 Train loss 0.04 Classification-F1 0.722296494355318 on epoch=274
05/30/2022 21:37:11 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.01 on epoch=277
05/30/2022 21:37:13 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.05 on epoch=279
05/30/2022 21:37:15 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.04 on epoch=282
05/30/2022 21:37:18 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.02 on epoch=284
05/30/2022 21:37:20 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.11 on epoch=287
05/30/2022 21:37:21 - INFO - __main__ - Global step 1150 Train loss 0.05 Classification-F1 0.6711541858600683 on epoch=287
05/30/2022 21:37:24 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.02 on epoch=289
05/30/2022 21:37:26 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.03 on epoch=292
05/30/2022 21:37:29 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.07 on epoch=294
05/30/2022 21:37:31 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.05 on epoch=297
05/30/2022 21:37:34 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.04 on epoch=299
05/30/2022 21:37:35 - INFO - __main__ - Global step 1200 Train loss 0.04 Classification-F1 0.68495670995671 on epoch=299
05/30/2022 21:37:37 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.03 on epoch=302
05/30/2022 21:37:40 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.03 on epoch=304
05/30/2022 21:37:42 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.03 on epoch=307
05/30/2022 21:37:44 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.04 on epoch=309
05/30/2022 21:37:47 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.01 on epoch=312
05/30/2022 21:37:48 - INFO - __main__ - Global step 1250 Train loss 0.03 Classification-F1 0.6445234708392603 on epoch=312
05/30/2022 21:37:50 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.12 on epoch=314
05/30/2022 21:37:53 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.02 on epoch=317
05/30/2022 21:37:55 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.06 on epoch=319
05/30/2022 21:37:58 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.05 on epoch=322
05/30/2022 21:38:00 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.06 on epoch=324
05/30/2022 21:38:01 - INFO - __main__ - Global step 1300 Train loss 0.06 Classification-F1 0.6580683624801271 on epoch=324
05/30/2022 21:38:03 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=327
05/30/2022 21:38:06 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.11 on epoch=329
05/30/2022 21:38:08 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=332
05/30/2022 21:38:11 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.03 on epoch=334
05/30/2022 21:38:13 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.07 on epoch=337
05/30/2022 21:38:14 - INFO - __main__ - Global step 1350 Train loss 0.05 Classification-F1 0.6734262125902993 on epoch=337
05/30/2022 21:38:16 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.02 on epoch=339
05/30/2022 21:38:19 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=342
05/30/2022 21:38:21 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=344
05/30/2022 21:38:24 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=347
05/30/2022 21:38:26 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=349
05/30/2022 21:38:27 - INFO - __main__ - Global step 1400 Train loss 0.01 Classification-F1 0.6311802232854864 on epoch=349
05/30/2022 21:38:29 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=352
05/30/2022 21:38:32 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=354
05/30/2022 21:38:34 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=357
05/30/2022 21:38:37 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.08 on epoch=359
05/30/2022 21:38:39 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=362
05/30/2022 21:38:40 - INFO - __main__ - Global step 1450 Train loss 0.03 Classification-F1 0.684863339275104 on epoch=362
05/30/2022 21:38:43 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.02 on epoch=364
05/30/2022 21:38:45 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.03 on epoch=367
05/30/2022 21:38:47 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.02 on epoch=369
05/30/2022 21:38:50 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.02 on epoch=372
05/30/2022 21:38:52 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.02 on epoch=374
05/30/2022 21:38:53 - INFO - __main__ - Global step 1500 Train loss 0.02 Classification-F1 0.6854013104013104 on epoch=374
05/30/2022 21:38:56 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=377
05/30/2022 21:38:58 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.02 on epoch=379
05/30/2022 21:39:01 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.02 on epoch=382
05/30/2022 21:39:03 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=384
05/30/2022 21:39:06 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=387
05/30/2022 21:39:06 - INFO - __main__ - Global step 1550 Train loss 0.01 Classification-F1 0.7229813664596274 on epoch=387
05/30/2022 21:39:09 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.11 on epoch=389
05/30/2022 21:39:11 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=392
05/30/2022 21:39:14 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.02 on epoch=394
05/30/2022 21:39:16 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.02 on epoch=397
05/30/2022 21:39:19 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=399
05/30/2022 21:39:20 - INFO - __main__ - Global step 1600 Train loss 0.04 Classification-F1 0.6482947232947233 on epoch=399
05/30/2022 21:39:22 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=402
05/30/2022 21:39:24 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.02 on epoch=404
05/30/2022 21:39:27 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=407
05/30/2022 21:39:29 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=409
05/30/2022 21:39:32 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.08 on epoch=412
05/30/2022 21:39:33 - INFO - __main__ - Global step 1650 Train loss 0.03 Classification-F1 0.6741312741312742 on epoch=412
05/30/2022 21:39:35 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.06 on epoch=414
05/30/2022 21:39:38 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=417
05/30/2022 21:39:40 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.08 on epoch=419
05/30/2022 21:39:43 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.06 on epoch=422
05/30/2022 21:39:45 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=424
05/30/2022 21:39:46 - INFO - __main__ - Global step 1700 Train loss 0.04 Classification-F1 0.7303921568627452 on epoch=424
05/30/2022 21:39:48 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=427
05/30/2022 21:39:51 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=429
05/30/2022 21:39:53 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.07 on epoch=432
05/30/2022 21:39:56 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=434
05/30/2022 21:39:58 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=437
05/30/2022 21:39:59 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.6940823375605985 on epoch=437
05/30/2022 21:40:01 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=439
05/30/2022 21:40:04 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.04 on epoch=442
05/30/2022 21:40:06 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=444
05/30/2022 21:40:09 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=447
05/30/2022 21:40:11 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=449
05/30/2022 21:40:12 - INFO - __main__ - Global step 1800 Train loss 0.02 Classification-F1 0.6705025499143147 on epoch=449
05/30/2022 21:40:14 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=452
05/30/2022 21:40:17 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=454
05/30/2022 21:40:19 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=457
05/30/2022 21:40:22 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.04 on epoch=459
05/30/2022 21:40:24 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=462
05/30/2022 21:40:25 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.6966386554621848 on epoch=462
05/30/2022 21:40:28 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=464
05/30/2022 21:40:30 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=467
05/30/2022 21:40:33 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=469
05/30/2022 21:40:35 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=472
05/30/2022 21:40:37 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=474
05/30/2022 21:40:38 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.6711370461370463 on epoch=474
05/30/2022 21:40:41 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=477
05/30/2022 21:40:43 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=479
05/30/2022 21:40:46 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.05 on epoch=482
05/30/2022 21:40:48 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=484
05/30/2022 21:40:51 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=487
05/30/2022 21:40:51 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.715848870260635 on epoch=487
05/30/2022 21:40:54 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=489
05/30/2022 21:40:56 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.04 on epoch=492
05/30/2022 21:40:59 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=494
05/30/2022 21:41:01 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=497
05/30/2022 21:41:04 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=499
05/30/2022 21:41:05 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.715848870260635 on epoch=499
05/30/2022 21:41:07 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.04 on epoch=502
05/30/2022 21:41:10 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=504
05/30/2022 21:41:12 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.04 on epoch=507
05/30/2022 21:41:14 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.03 on epoch=509
05/30/2022 21:41:17 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=512
05/30/2022 21:41:18 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.715848870260635 on epoch=512
05/30/2022 21:41:20 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.04 on epoch=514
05/30/2022 21:41:23 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=517
05/30/2022 21:41:25 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=519
05/30/2022 21:41:28 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=522
05/30/2022 21:41:30 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=524
05/30/2022 21:41:31 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.7086256241627087 on epoch=524
05/30/2022 21:41:33 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=527
05/30/2022 21:41:36 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=529
05/30/2022 21:41:38 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=532
05/30/2022 21:41:41 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=534
05/30/2022 21:41:43 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
05/30/2022 21:41:44 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.715848870260635 on epoch=537
05/30/2022 21:41:47 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=539
05/30/2022 21:41:49 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
05/30/2022 21:41:52 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=544
05/30/2022 21:41:54 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=547
05/30/2022 21:41:57 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=549
05/30/2022 21:41:58 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.7311688311688312 on epoch=549
05/30/2022 21:42:00 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=552
05/30/2022 21:42:03 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=554
05/30/2022 21:42:05 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.03 on epoch=557
05/30/2022 21:42:08 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=559
05/30/2022 21:42:10 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
05/30/2022 21:42:11 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.7303921568627452 on epoch=562
05/30/2022 21:42:14 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.05 on epoch=564
05/30/2022 21:42:16 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
05/30/2022 21:42:18 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=569
05/30/2022 21:42:21 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
05/30/2022 21:42:23 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=574
05/30/2022 21:42:24 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.6711370461370463 on epoch=574
05/30/2022 21:42:27 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=577
05/30/2022 21:42:29 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
05/30/2022 21:42:32 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
05/30/2022 21:42:34 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=584
05/30/2022 21:42:37 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=587
05/30/2022 21:42:38 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.6870393120393121 on epoch=587
05/30/2022 21:42:40 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=589
05/30/2022 21:42:42 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
05/30/2022 21:42:45 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=594
05/30/2022 21:42:47 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
05/30/2022 21:42:50 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=599
05/30/2022 21:42:51 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.6970588235294117 on epoch=599
05/30/2022 21:42:53 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
05/30/2022 21:42:56 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=604
05/30/2022 21:42:59 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=607
05/30/2022 21:43:01 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
05/30/2022 21:43:04 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
05/30/2022 21:43:05 - INFO - __main__ - Global step 2450 Train loss 0.00 Classification-F1 0.6937512960530864 on epoch=612
05/30/2022 21:43:07 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=614
05/30/2022 21:43:10 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
05/30/2022 21:43:12 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=619
05/30/2022 21:43:15 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.03 on epoch=622
05/30/2022 21:43:17 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.09 on epoch=624
05/30/2022 21:43:18 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.7180194193061841 on epoch=624
05/30/2022 21:43:21 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
05/30/2022 21:43:23 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
05/30/2022 21:43:26 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=632
05/30/2022 21:43:28 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
05/30/2022 21:43:31 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.07 on epoch=637
05/30/2022 21:43:32 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.6451754385964912 on epoch=637
05/30/2022 21:43:35 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.03 on epoch=639
05/30/2022 21:43:37 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=642
05/30/2022 21:43:40 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=644
05/30/2022 21:43:42 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
05/30/2022 21:43:45 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=649
05/30/2022 21:43:46 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.701379173290938 on epoch=649
05/30/2022 21:43:48 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.05 on epoch=652
05/30/2022 21:43:51 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=654
05/30/2022 21:43:53 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=657
05/30/2022 21:43:56 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=659
05/30/2022 21:43:59 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=662
05/30/2022 21:44:00 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.6603174603174603 on epoch=662
05/30/2022 21:44:02 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
05/30/2022 21:44:05 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=667
05/30/2022 21:44:07 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
05/30/2022 21:44:10 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=672
05/30/2022 21:44:12 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=674
05/30/2022 21:44:13 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.5602208699571782 on epoch=674
05/30/2022 21:44:16 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
05/30/2022 21:44:18 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
05/30/2022 21:44:21 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
05/30/2022 21:44:24 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
05/30/2022 21:44:26 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
05/30/2022 21:44:27 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.6370535714285714 on epoch=687
05/30/2022 21:44:30 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.04 on epoch=689
05/30/2022 21:44:32 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
05/30/2022 21:44:35 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=694
05/30/2022 21:44:37 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
05/30/2022 21:44:40 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
05/30/2022 21:44:41 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.6964869281045752 on epoch=699
05/30/2022 21:44:43 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=702
05/30/2022 21:44:46 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=704
05/30/2022 21:44:48 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
05/30/2022 21:44:51 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=709
05/30/2022 21:44:54 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=712
05/30/2022 21:44:55 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.7170588235294117 on epoch=712
05/30/2022 21:44:57 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=714
05/30/2022 21:45:00 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
05/30/2022 21:45:02 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
05/30/2022 21:45:05 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
05/30/2022 21:45:07 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=724
05/30/2022 21:45:08 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.6853535353535353 on epoch=724
05/30/2022 21:45:11 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=727
05/30/2022 21:45:13 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=729
05/30/2022 21:45:16 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=732
05/30/2022 21:45:19 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=734
05/30/2022 21:45:21 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=737
05/30/2022 21:45:22 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.5556431340112555 on epoch=737
05/30/2022 21:45:25 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=739
05/30/2022 21:45:27 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=742
05/30/2022 21:45:30 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=744
05/30/2022 21:45:32 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
05/30/2022 21:45:35 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.08 on epoch=749
05/30/2022 21:45:36 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.6705025499143147 on epoch=749
05/30/2022 21:45:36 - INFO - __main__ - save last model!
05/30/2022 21:45:36 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/30/2022 21:45:36 - INFO - __main__ - Start tokenizing ... 5509 instances
05/30/2022 21:45:36 - INFO - __main__ - Printing 3 examples
05/30/2022 21:45:36 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/30/2022 21:45:36 - INFO - __main__ - ['others']
05/30/2022 21:45:36 - INFO - __main__ -  [emo] what you like very little things ok
05/30/2022 21:45:36 - INFO - __main__ - ['others']
05/30/2022 21:45:36 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/30/2022 21:45:36 - INFO - __main__ - ['others']
05/30/2022 21:45:36 - INFO - __main__ - Tokenizing Input ...
05/30/2022 21:45:36 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 21:45:36 - INFO - __main__ - Printing 3 examples
05/30/2022 21:45:36 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
05/30/2022 21:45:36 - INFO - __main__ - ['others']
05/30/2022 21:45:36 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
05/30/2022 21:45:36 - INFO - __main__ - ['others']
05/30/2022 21:45:36 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
05/30/2022 21:45:36 - INFO - __main__ - ['others']
05/30/2022 21:45:36 - INFO - __main__ - Tokenizing Input ...
05/30/2022 21:45:36 - INFO - __main__ - Tokenizing Output ...
05/30/2022 21:45:36 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 21:45:36 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 21:45:36 - INFO - __main__ - Printing 3 examples
05/30/2022 21:45:36 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
05/30/2022 21:45:36 - INFO - __main__ - ['others']
05/30/2022 21:45:36 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
05/30/2022 21:45:36 - INFO - __main__ - ['others']
05/30/2022 21:45:36 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
05/30/2022 21:45:36 - INFO - __main__ - ['others']
05/30/2022 21:45:36 - INFO - __main__ - Tokenizing Input ...
05/30/2022 21:45:36 - INFO - __main__ - Tokenizing Output ...
05/30/2022 21:45:36 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 21:45:38 - INFO - __main__ - Tokenizing Output ...
05/30/2022 21:45:43 - INFO - __main__ - Loaded 5509 examples from test data
05/30/2022 21:45:55 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 21:45:56 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/30/2022 21:45:56 - INFO - __main__ - Starting training!
05/30/2022 21:47:08 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-24uptasks/singletask-emo/emo_16_87_0.3_8_predictions.txt
05/30/2022 21:47:08 - INFO - __main__ - Classification-F1 on test data: 0.2177
05/30/2022 21:47:08 - INFO - __main__ - prefix=emo_16_87, lr=0.3, bsz=8, dev_performance=0.7715247715247716, test_performance=0.21774457135844183
05/30/2022 21:47:08 - INFO - __main__ - Running ... prefix=emo_16_87, lr=0.2, bsz=8 ...
05/30/2022 21:47:09 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 21:47:09 - INFO - __main__ - Printing 3 examples
05/30/2022 21:47:09 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
05/30/2022 21:47:09 - INFO - __main__ - ['others']
05/30/2022 21:47:09 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
05/30/2022 21:47:09 - INFO - __main__ - ['others']
05/30/2022 21:47:09 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
05/30/2022 21:47:09 - INFO - __main__ - ['others']
05/30/2022 21:47:09 - INFO - __main__ - Tokenizing Input ...
05/30/2022 21:47:09 - INFO - __main__ - Tokenizing Output ...
05/30/2022 21:47:09 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 21:47:09 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 21:47:09 - INFO - __main__ - Printing 3 examples
05/30/2022 21:47:09 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
05/30/2022 21:47:09 - INFO - __main__ - ['others']
05/30/2022 21:47:09 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
05/30/2022 21:47:09 - INFO - __main__ - ['others']
05/30/2022 21:47:09 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
05/30/2022 21:47:09 - INFO - __main__ - ['others']
05/30/2022 21:47:09 - INFO - __main__ - Tokenizing Input ...
05/30/2022 21:47:09 - INFO - __main__ - Tokenizing Output ...
05/30/2022 21:47:09 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 21:47:25 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 21:47:25 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/30/2022 21:47:25 - INFO - __main__ - Starting training!
05/30/2022 21:47:29 - INFO - __main__ - Step 10 Global step 10 Train loss 4.30 on epoch=2
05/30/2022 21:47:31 - INFO - __main__ - Step 20 Global step 20 Train loss 2.53 on epoch=4
05/30/2022 21:47:34 - INFO - __main__ - Step 30 Global step 30 Train loss 1.81 on epoch=7
05/30/2022 21:47:36 - INFO - __main__ - Step 40 Global step 40 Train loss 1.43 on epoch=9
05/30/2022 21:47:39 - INFO - __main__ - Step 50 Global step 50 Train loss 1.29 on epoch=12
05/30/2022 21:47:40 - INFO - __main__ - Global step 50 Train loss 2.27 Classification-F1 0.15531756180733164 on epoch=12
05/30/2022 21:47:40 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.15531756180733164 on epoch=12, global_step=50
05/30/2022 21:47:42 - INFO - __main__ - Step 60 Global step 60 Train loss 1.15 on epoch=14
05/30/2022 21:47:45 - INFO - __main__ - Step 70 Global step 70 Train loss 0.94 on epoch=17
05/30/2022 21:47:47 - INFO - __main__ - Step 80 Global step 80 Train loss 0.95 on epoch=19
05/30/2022 21:47:50 - INFO - __main__ - Step 90 Global step 90 Train loss 0.92 on epoch=22
05/30/2022 21:47:52 - INFO - __main__ - Step 100 Global step 100 Train loss 1.02 on epoch=24
05/30/2022 21:47:53 - INFO - __main__ - Global step 100 Train loss 0.99 Classification-F1 0.3324650664589317 on epoch=24
05/30/2022 21:47:53 - INFO - __main__ - Saving model with best Classification-F1: 0.15531756180733164 -> 0.3324650664589317 on epoch=24, global_step=100
05/30/2022 21:47:56 - INFO - __main__ - Step 110 Global step 110 Train loss 0.72 on epoch=27
05/30/2022 21:47:58 - INFO - __main__ - Step 120 Global step 120 Train loss 0.77 on epoch=29
05/30/2022 21:48:01 - INFO - __main__ - Step 130 Global step 130 Train loss 0.83 on epoch=32
05/30/2022 21:48:03 - INFO - __main__ - Step 140 Global step 140 Train loss 0.72 on epoch=34
05/30/2022 21:48:06 - INFO - __main__ - Step 150 Global step 150 Train loss 0.78 on epoch=37
05/30/2022 21:48:06 - INFO - __main__ - Global step 150 Train loss 0.76 Classification-F1 0.5755516084903579 on epoch=37
05/30/2022 21:48:06 - INFO - __main__ - Saving model with best Classification-F1: 0.3324650664589317 -> 0.5755516084903579 on epoch=37, global_step=150
05/30/2022 21:48:09 - INFO - __main__ - Step 160 Global step 160 Train loss 0.67 on epoch=39
05/30/2022 21:48:11 - INFO - __main__ - Step 170 Global step 170 Train loss 0.71 on epoch=42
05/30/2022 21:48:14 - INFO - __main__ - Step 180 Global step 180 Train loss 0.74 on epoch=44
05/30/2022 21:48:16 - INFO - __main__ - Step 190 Global step 190 Train loss 0.77 on epoch=47
05/30/2022 21:48:19 - INFO - __main__ - Step 200 Global step 200 Train loss 0.67 on epoch=49
05/30/2022 21:48:20 - INFO - __main__ - Global step 200 Train loss 0.71 Classification-F1 0.47500000000000003 on epoch=49
05/30/2022 21:48:22 - INFO - __main__ - Step 210 Global step 210 Train loss 0.70 on epoch=52
05/30/2022 21:48:25 - INFO - __main__ - Step 220 Global step 220 Train loss 0.60 on epoch=54
05/30/2022 21:48:27 - INFO - __main__ - Step 230 Global step 230 Train loss 0.62 on epoch=57
05/30/2022 21:48:30 - INFO - __main__ - Step 240 Global step 240 Train loss 0.59 on epoch=59
05/30/2022 21:48:32 - INFO - __main__ - Step 250 Global step 250 Train loss 0.65 on epoch=62
05/30/2022 21:48:33 - INFO - __main__ - Global step 250 Train loss 0.63 Classification-F1 0.6000000000000001 on epoch=62
05/30/2022 21:48:33 - INFO - __main__ - Saving model with best Classification-F1: 0.5755516084903579 -> 0.6000000000000001 on epoch=62, global_step=250
05/30/2022 21:48:35 - INFO - __main__ - Step 260 Global step 260 Train loss 0.57 on epoch=64
05/30/2022 21:48:38 - INFO - __main__ - Step 270 Global step 270 Train loss 0.52 on epoch=67
05/30/2022 21:48:40 - INFO - __main__ - Step 280 Global step 280 Train loss 0.53 on epoch=69
05/30/2022 21:48:43 - INFO - __main__ - Step 290 Global step 290 Train loss 0.56 on epoch=72
05/30/2022 21:48:46 - INFO - __main__ - Step 300 Global step 300 Train loss 0.53 on epoch=74
05/30/2022 21:48:46 - INFO - __main__ - Global step 300 Train loss 0.54 Classification-F1 0.6132535640175708 on epoch=74
05/30/2022 21:48:46 - INFO - __main__ - Saving model with best Classification-F1: 0.6000000000000001 -> 0.6132535640175708 on epoch=74, global_step=300
05/30/2022 21:48:49 - INFO - __main__ - Step 310 Global step 310 Train loss 0.50 on epoch=77
05/30/2022 21:48:51 - INFO - __main__ - Step 320 Global step 320 Train loss 0.56 on epoch=79
05/30/2022 21:48:54 - INFO - __main__ - Step 330 Global step 330 Train loss 0.46 on epoch=82
05/30/2022 21:48:56 - INFO - __main__ - Step 340 Global step 340 Train loss 0.49 on epoch=84
05/30/2022 21:48:59 - INFO - __main__ - Step 350 Global step 350 Train loss 0.51 on epoch=87
05/30/2022 21:49:00 - INFO - __main__ - Global step 350 Train loss 0.50 Classification-F1 0.714885752688172 on epoch=87
05/30/2022 21:49:00 - INFO - __main__ - Saving model with best Classification-F1: 0.6132535640175708 -> 0.714885752688172 on epoch=87, global_step=350
05/30/2022 21:49:02 - INFO - __main__ - Step 360 Global step 360 Train loss 0.51 on epoch=89
05/30/2022 21:49:05 - INFO - __main__ - Step 370 Global step 370 Train loss 0.55 on epoch=92
05/30/2022 21:49:07 - INFO - __main__ - Step 380 Global step 380 Train loss 0.46 on epoch=94
05/30/2022 21:49:10 - INFO - __main__ - Step 390 Global step 390 Train loss 0.48 on epoch=97
05/30/2022 21:49:12 - INFO - __main__ - Step 400 Global step 400 Train loss 0.50 on epoch=99
05/30/2022 21:49:13 - INFO - __main__ - Global step 400 Train loss 0.50 Classification-F1 0.6431365576102418 on epoch=99
05/30/2022 21:49:16 - INFO - __main__ - Step 410 Global step 410 Train loss 0.45 on epoch=102
05/30/2022 21:49:18 - INFO - __main__ - Step 420 Global step 420 Train loss 0.48 on epoch=104
05/30/2022 21:49:21 - INFO - __main__ - Step 430 Global step 430 Train loss 0.40 on epoch=107
05/30/2022 21:49:23 - INFO - __main__ - Step 440 Global step 440 Train loss 0.36 on epoch=109
05/30/2022 21:49:26 - INFO - __main__ - Step 450 Global step 450 Train loss 0.40 on epoch=112
05/30/2022 21:49:26 - INFO - __main__ - Global step 450 Train loss 0.42 Classification-F1 0.6806653491436101 on epoch=112
05/30/2022 21:49:29 - INFO - __main__ - Step 460 Global step 460 Train loss 0.42 on epoch=114
05/30/2022 21:49:31 - INFO - __main__ - Step 470 Global step 470 Train loss 0.42 on epoch=117
05/30/2022 21:49:34 - INFO - __main__ - Step 480 Global step 480 Train loss 0.37 on epoch=119
05/30/2022 21:49:36 - INFO - __main__ - Step 490 Global step 490 Train loss 0.39 on epoch=122
05/30/2022 21:49:39 - INFO - __main__ - Step 500 Global step 500 Train loss 0.40 on epoch=124
05/30/2022 21:49:40 - INFO - __main__ - Global step 500 Train loss 0.40 Classification-F1 0.6044934640522877 on epoch=124
05/30/2022 21:49:42 - INFO - __main__ - Step 510 Global step 510 Train loss 0.37 on epoch=127
05/30/2022 21:49:45 - INFO - __main__ - Step 520 Global step 520 Train loss 0.26 on epoch=129
05/30/2022 21:49:47 - INFO - __main__ - Step 530 Global step 530 Train loss 0.29 on epoch=132
05/30/2022 21:49:50 - INFO - __main__ - Step 540 Global step 540 Train loss 0.37 on epoch=134
05/30/2022 21:49:52 - INFO - __main__ - Step 550 Global step 550 Train loss 0.25 on epoch=137
05/30/2022 21:49:53 - INFO - __main__ - Global step 550 Train loss 0.31 Classification-F1 0.6319017240069871 on epoch=137
05/30/2022 21:49:56 - INFO - __main__ - Step 560 Global step 560 Train loss 0.26 on epoch=139
05/30/2022 21:49:58 - INFO - __main__ - Step 570 Global step 570 Train loss 0.28 on epoch=142
05/30/2022 21:50:01 - INFO - __main__ - Step 580 Global step 580 Train loss 0.21 on epoch=144
05/30/2022 21:50:03 - INFO - __main__ - Step 590 Global step 590 Train loss 0.36 on epoch=147
05/30/2022 21:50:06 - INFO - __main__ - Step 600 Global step 600 Train loss 0.25 on epoch=149
05/30/2022 21:50:07 - INFO - __main__ - Global step 600 Train loss 0.27 Classification-F1 0.7149556671295801 on epoch=149
05/30/2022 21:50:07 - INFO - __main__ - Saving model with best Classification-F1: 0.714885752688172 -> 0.7149556671295801 on epoch=149, global_step=600
05/30/2022 21:50:09 - INFO - __main__ - Step 610 Global step 610 Train loss 0.19 on epoch=152
05/30/2022 21:50:12 - INFO - __main__ - Step 620 Global step 620 Train loss 0.25 on epoch=154
05/30/2022 21:50:14 - INFO - __main__ - Step 630 Global step 630 Train loss 0.30 on epoch=157
05/30/2022 21:50:17 - INFO - __main__ - Step 640 Global step 640 Train loss 0.23 on epoch=159
05/30/2022 21:50:19 - INFO - __main__ - Step 650 Global step 650 Train loss 0.22 on epoch=162
05/30/2022 21:50:20 - INFO - __main__ - Global step 650 Train loss 0.24 Classification-F1 0.7575694444444444 on epoch=162
05/30/2022 21:50:20 - INFO - __main__ - Saving model with best Classification-F1: 0.7149556671295801 -> 0.7575694444444444 on epoch=162, global_step=650
05/30/2022 21:50:22 - INFO - __main__ - Step 660 Global step 660 Train loss 0.23 on epoch=164
05/30/2022 21:50:25 - INFO - __main__ - Step 670 Global step 670 Train loss 0.19 on epoch=167
05/30/2022 21:50:27 - INFO - __main__ - Step 680 Global step 680 Train loss 0.22 on epoch=169
05/30/2022 21:50:30 - INFO - __main__ - Step 690 Global step 690 Train loss 0.22 on epoch=172
05/30/2022 21:50:32 - INFO - __main__ - Step 700 Global step 700 Train loss 0.27 on epoch=174
05/30/2022 21:50:33 - INFO - __main__ - Global step 700 Train loss 0.23 Classification-F1 0.7068376068376068 on epoch=174
05/30/2022 21:50:36 - INFO - __main__ - Step 710 Global step 710 Train loss 0.19 on epoch=177
05/30/2022 21:50:38 - INFO - __main__ - Step 720 Global step 720 Train loss 0.24 on epoch=179
05/30/2022 21:50:41 - INFO - __main__ - Step 730 Global step 730 Train loss 0.18 on epoch=182
05/30/2022 21:50:43 - INFO - __main__ - Step 740 Global step 740 Train loss 0.14 on epoch=184
05/30/2022 21:50:46 - INFO - __main__ - Step 750 Global step 750 Train loss 0.25 on epoch=187
05/30/2022 21:50:46 - INFO - __main__ - Global step 750 Train loss 0.20 Classification-F1 0.7301822573561705 on epoch=187
05/30/2022 21:50:49 - INFO - __main__ - Step 760 Global step 760 Train loss 0.17 on epoch=189
05/30/2022 21:50:51 - INFO - __main__ - Step 770 Global step 770 Train loss 0.18 on epoch=192
05/30/2022 21:50:54 - INFO - __main__ - Step 780 Global step 780 Train loss 0.25 on epoch=194
05/30/2022 21:50:56 - INFO - __main__ - Step 790 Global step 790 Train loss 0.15 on epoch=197
05/30/2022 21:50:59 - INFO - __main__ - Step 800 Global step 800 Train loss 0.25 on epoch=199
05/30/2022 21:51:00 - INFO - __main__ - Global step 800 Train loss 0.20 Classification-F1 0.7164141414141414 on epoch=199
05/30/2022 21:51:02 - INFO - __main__ - Step 810 Global step 810 Train loss 0.20 on epoch=202
05/30/2022 21:51:05 - INFO - __main__ - Step 820 Global step 820 Train loss 0.17 on epoch=204
05/30/2022 21:51:07 - INFO - __main__ - Step 830 Global step 830 Train loss 0.15 on epoch=207
05/30/2022 21:51:10 - INFO - __main__ - Step 840 Global step 840 Train loss 0.16 on epoch=209
05/30/2022 21:51:12 - INFO - __main__ - Step 850 Global step 850 Train loss 0.17 on epoch=212
05/30/2022 21:51:13 - INFO - __main__ - Global step 850 Train loss 0.17 Classification-F1 0.7231817202405438 on epoch=212
05/30/2022 21:51:16 - INFO - __main__ - Step 860 Global step 860 Train loss 0.14 on epoch=214
05/30/2022 21:51:18 - INFO - __main__ - Step 870 Global step 870 Train loss 0.10 on epoch=217
05/30/2022 21:51:21 - INFO - __main__ - Step 880 Global step 880 Train loss 0.13 on epoch=219
05/30/2022 21:51:23 - INFO - __main__ - Step 890 Global step 890 Train loss 0.21 on epoch=222
05/30/2022 21:51:26 - INFO - __main__ - Step 900 Global step 900 Train loss 0.11 on epoch=224
05/30/2022 21:51:26 - INFO - __main__ - Global step 900 Train loss 0.14 Classification-F1 0.6441984486102134 on epoch=224
05/30/2022 21:51:29 - INFO - __main__ - Step 910 Global step 910 Train loss 0.14 on epoch=227
05/30/2022 21:51:32 - INFO - __main__ - Step 920 Global step 920 Train loss 0.14 on epoch=229
05/30/2022 21:51:34 - INFO - __main__ - Step 930 Global step 930 Train loss 0.11 on epoch=232
05/30/2022 21:51:37 - INFO - __main__ - Step 940 Global step 940 Train loss 0.17 on epoch=234
05/30/2022 21:51:39 - INFO - __main__ - Step 950 Global step 950 Train loss 0.09 on epoch=237
05/30/2022 21:51:40 - INFO - __main__ - Global step 950 Train loss 0.13 Classification-F1 0.6945542380324988 on epoch=237
05/30/2022 21:51:42 - INFO - __main__ - Step 960 Global step 960 Train loss 0.11 on epoch=239
05/30/2022 21:51:45 - INFO - __main__ - Step 970 Global step 970 Train loss 0.12 on epoch=242
05/30/2022 21:51:47 - INFO - __main__ - Step 980 Global step 980 Train loss 0.11 on epoch=244
05/30/2022 21:51:50 - INFO - __main__ - Step 990 Global step 990 Train loss 0.11 on epoch=247
05/30/2022 21:51:52 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.09 on epoch=249
05/30/2022 21:51:53 - INFO - __main__ - Global step 1000 Train loss 0.11 Classification-F1 0.7077532077532078 on epoch=249
05/30/2022 21:51:56 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.16 on epoch=252
05/30/2022 21:51:59 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.20 on epoch=254
05/30/2022 21:52:01 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.14 on epoch=257
05/30/2022 21:52:04 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.06 on epoch=259
05/30/2022 21:52:06 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.14 on epoch=262
05/30/2022 21:52:07 - INFO - __main__ - Global step 1050 Train loss 0.14 Classification-F1 0.6731900452488688 on epoch=262
05/30/2022 21:52:10 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.05 on epoch=264
05/30/2022 21:52:12 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.06 on epoch=267
05/30/2022 21:52:15 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.10 on epoch=269
05/30/2022 21:52:17 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.08 on epoch=272
05/30/2022 21:52:20 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.08 on epoch=274
05/30/2022 21:52:21 - INFO - __main__ - Global step 1100 Train loss 0.07 Classification-F1 0.684920705479916 on epoch=274
05/30/2022 21:52:23 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.10 on epoch=277
05/30/2022 21:52:26 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.15 on epoch=279
05/30/2022 21:52:28 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.04 on epoch=282
05/30/2022 21:52:31 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.11 on epoch=284
05/30/2022 21:52:33 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.04 on epoch=287
05/30/2022 21:52:34 - INFO - __main__ - Global step 1150 Train loss 0.09 Classification-F1 0.707830181514392 on epoch=287
05/30/2022 21:52:37 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.08 on epoch=289
05/30/2022 21:52:39 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.09 on epoch=292
05/30/2022 21:52:42 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.09 on epoch=294
05/30/2022 21:52:44 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.07 on epoch=297
05/30/2022 21:52:47 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.07 on epoch=299
05/30/2022 21:52:48 - INFO - __main__ - Global step 1200 Train loss 0.08 Classification-F1 0.6286764705882353 on epoch=299
05/30/2022 21:52:50 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.10 on epoch=302
05/30/2022 21:52:53 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.08 on epoch=304
05/30/2022 21:52:55 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.09 on epoch=307
05/30/2022 21:52:58 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.08 on epoch=309
05/30/2022 21:53:00 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.09 on epoch=312
05/30/2022 21:53:01 - INFO - __main__ - Global step 1250 Train loss 0.09 Classification-F1 0.6973684210526315 on epoch=312
05/30/2022 21:53:04 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.09 on epoch=314
05/30/2022 21:53:06 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.04 on epoch=317
05/30/2022 21:53:09 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.10 on epoch=319
05/30/2022 21:53:11 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.03 on epoch=322
05/30/2022 21:53:14 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.07 on epoch=324
05/30/2022 21:53:15 - INFO - __main__ - Global step 1300 Train loss 0.06 Classification-F1 0.7448940417690417 on epoch=324
05/30/2022 21:53:17 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.06 on epoch=327
05/30/2022 21:53:20 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.05 on epoch=329
05/30/2022 21:53:22 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.06 on epoch=332
05/30/2022 21:53:25 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.03 on epoch=334
05/30/2022 21:53:27 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.05 on epoch=337
05/30/2022 21:53:28 - INFO - __main__ - Global step 1350 Train loss 0.05 Classification-F1 0.7663349490795144 on epoch=337
05/30/2022 21:53:28 - INFO - __main__ - Saving model with best Classification-F1: 0.7575694444444444 -> 0.7663349490795144 on epoch=337, global_step=1350
05/30/2022 21:53:30 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.07 on epoch=339
05/30/2022 21:53:33 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.03 on epoch=342
05/30/2022 21:53:36 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.04 on epoch=344
05/30/2022 21:53:38 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.09 on epoch=347
05/30/2022 21:53:41 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.04 on epoch=349
05/30/2022 21:53:41 - INFO - __main__ - Global step 1400 Train loss 0.05 Classification-F1 0.7382800982800983 on epoch=349
05/30/2022 21:53:44 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.06 on epoch=352
05/30/2022 21:53:46 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.13 on epoch=354
05/30/2022 21:53:49 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.07 on epoch=357
05/30/2022 21:53:52 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.10 on epoch=359
05/30/2022 21:53:54 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.09 on epoch=362
05/30/2022 21:53:55 - INFO - __main__ - Global step 1450 Train loss 0.09 Classification-F1 0.7377403846153846 on epoch=362
05/30/2022 21:53:57 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.04 on epoch=364
05/30/2022 21:54:00 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.07 on epoch=367
05/30/2022 21:54:02 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.07 on epoch=369
05/30/2022 21:54:05 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.09 on epoch=372
05/30/2022 21:54:07 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.09 on epoch=374
05/30/2022 21:54:08 - INFO - __main__ - Global step 1500 Train loss 0.07 Classification-F1 0.7308277027027027 on epoch=374
05/30/2022 21:54:11 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.04 on epoch=377
05/30/2022 21:54:13 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.03 on epoch=379
05/30/2022 21:54:16 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.06 on epoch=382
05/30/2022 21:54:18 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.07 on epoch=384
05/30/2022 21:54:21 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=387
05/30/2022 21:54:22 - INFO - __main__ - Global step 1550 Train loss 0.04 Classification-F1 0.7514583333333333 on epoch=387
05/30/2022 21:54:24 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.02 on epoch=389
05/30/2022 21:54:27 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=392
05/30/2022 21:54:29 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.05 on epoch=394
05/30/2022 21:54:32 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.06 on epoch=397
05/30/2022 21:54:34 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.03 on epoch=399
05/30/2022 21:54:35 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.6433381247235737 on epoch=399
05/30/2022 21:54:38 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=402
05/30/2022 21:54:40 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.05 on epoch=404
05/30/2022 21:54:43 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.08 on epoch=407
05/30/2022 21:54:45 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.02 on epoch=409
05/30/2022 21:54:48 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=412
05/30/2022 21:54:48 - INFO - __main__ - Global step 1650 Train loss 0.04 Classification-F1 0.7517361111111112 on epoch=412
05/30/2022 21:54:51 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.06 on epoch=414
05/30/2022 21:54:53 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=417
05/30/2022 21:54:56 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.14 on epoch=419
05/30/2022 21:54:59 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.03 on epoch=422
05/30/2022 21:55:01 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=424
05/30/2022 21:55:02 - INFO - __main__ - Global step 1700 Train loss 0.06 Classification-F1 0.7387372484146677 on epoch=424
05/30/2022 21:55:04 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.04 on epoch=427
05/30/2022 21:55:07 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.02 on epoch=429
05/30/2022 21:55:09 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=432
05/30/2022 21:55:12 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=434
05/30/2022 21:55:14 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.06 on epoch=437
05/30/2022 21:55:15 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.6835617129734777 on epoch=437
05/30/2022 21:55:18 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.04 on epoch=439
05/30/2022 21:55:20 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=442
05/30/2022 21:55:23 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.03 on epoch=444
05/30/2022 21:55:25 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.06 on epoch=447
05/30/2022 21:55:28 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.03 on epoch=449
05/30/2022 21:55:29 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.7571555010893246 on epoch=449
05/30/2022 21:55:31 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=452
05/30/2022 21:55:34 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.04 on epoch=454
05/30/2022 21:55:36 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.06 on epoch=457
05/30/2022 21:55:39 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=459
05/30/2022 21:55:42 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=462
05/30/2022 21:55:43 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.716969696969697 on epoch=462
05/30/2022 21:55:45 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=464
05/30/2022 21:55:48 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=467
05/30/2022 21:55:50 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.05 on epoch=469
05/30/2022 21:55:53 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.09 on epoch=472
05/30/2022 21:55:55 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.02 on epoch=474
05/30/2022 21:55:56 - INFO - __main__ - Global step 1900 Train loss 0.04 Classification-F1 0.7377403846153846 on epoch=474
05/30/2022 21:55:59 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.14 on epoch=477
05/30/2022 21:56:01 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.04 on epoch=479
05/30/2022 21:56:04 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=482
05/30/2022 21:56:06 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.08 on epoch=484
05/30/2022 21:56:09 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=487
05/30/2022 21:56:10 - INFO - __main__ - Global step 1950 Train loss 0.06 Classification-F1 0.7514583333333333 on epoch=487
05/30/2022 21:56:12 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.03 on epoch=489
05/30/2022 21:56:15 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=492
05/30/2022 21:56:18 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.04 on epoch=494
05/30/2022 21:56:20 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=497
05/30/2022 21:56:23 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=499
05/30/2022 21:56:24 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.7081285831285832 on epoch=499
05/30/2022 21:56:26 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=502
05/30/2022 21:56:29 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=504
05/30/2022 21:56:31 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=507
05/30/2022 21:56:34 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.08 on epoch=509
05/30/2022 21:56:36 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.06 on epoch=512
05/30/2022 21:56:37 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.7523801220575415 on epoch=512
05/30/2022 21:56:40 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=514
05/30/2022 21:56:42 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=517
05/30/2022 21:56:45 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.05 on epoch=519
05/30/2022 21:56:47 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=522
05/30/2022 21:56:50 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.04 on epoch=524
05/30/2022 21:56:51 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.7303030303030303 on epoch=524
05/30/2022 21:56:53 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=527
05/30/2022 21:56:56 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.04 on epoch=529
05/30/2022 21:56:59 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=532
05/30/2022 21:57:01 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.07 on epoch=534
05/30/2022 21:57:04 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.03 on epoch=537
05/30/2022 21:57:05 - INFO - __main__ - Global step 2150 Train loss 0.03 Classification-F1 0.716969696969697 on epoch=537
05/30/2022 21:57:07 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=539
05/30/2022 21:57:10 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=542
05/30/2022 21:57:12 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=544
05/30/2022 21:57:15 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=547
05/30/2022 21:57:17 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=549
05/30/2022 21:57:18 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.6716949187537423 on epoch=549
05/30/2022 21:57:21 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=552
05/30/2022 21:57:23 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=554
05/30/2022 21:57:26 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=557
05/30/2022 21:57:28 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=559
05/30/2022 21:57:31 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=562
05/30/2022 21:57:32 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.6961805555555556 on epoch=562
05/30/2022 21:57:35 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=564
05/30/2022 21:57:37 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=567
05/30/2022 21:57:40 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=569
05/30/2022 21:57:42 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=572
05/30/2022 21:57:45 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=574
05/30/2022 21:57:46 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.695580808080808 on epoch=574
05/30/2022 21:57:48 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=577
05/30/2022 21:57:51 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=579
05/30/2022 21:57:53 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=582
05/30/2022 21:57:56 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=584
05/30/2022 21:57:58 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=587
05/30/2022 21:58:00 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.716969696969697 on epoch=587
05/30/2022 21:58:02 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=589
05/30/2022 21:58:05 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.10 on epoch=592
05/30/2022 21:58:07 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.05 on epoch=594
05/30/2022 21:58:10 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=597
05/30/2022 21:58:12 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=599
05/30/2022 21:58:13 - INFO - __main__ - Global step 2400 Train loss 0.04 Classification-F1 0.6324457681365576 on epoch=599
05/30/2022 21:58:16 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.03 on epoch=602
05/30/2022 21:58:18 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=604
05/30/2022 21:58:21 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=607
05/30/2022 21:58:23 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=609
05/30/2022 21:58:26 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.05 on epoch=612
05/30/2022 21:58:27 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.6702297702297703 on epoch=612
05/30/2022 21:58:30 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=614
05/30/2022 21:58:32 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
05/30/2022 21:58:35 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=619
05/30/2022 21:58:37 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=622
05/30/2022 21:58:40 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.03 on epoch=624
05/30/2022 21:58:41 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.7091890732265447 on epoch=624
05/30/2022 21:58:43 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.04 on epoch=627
05/30/2022 21:58:46 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=629
05/30/2022 21:58:48 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.14 on epoch=632
05/30/2022 21:58:51 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=634
05/30/2022 21:58:53 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.05 on epoch=637
05/30/2022 21:58:54 - INFO - __main__ - Global step 2550 Train loss 0.05 Classification-F1 0.7175694444444444 on epoch=637
05/30/2022 21:58:57 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=639
05/30/2022 21:58:59 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=642
05/30/2022 21:59:02 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.03 on epoch=644
05/30/2022 21:59:04 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
05/30/2022 21:59:07 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=649
05/30/2022 21:59:08 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.7170588235294117 on epoch=649
05/30/2022 21:59:10 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.11 on epoch=652
05/30/2022 21:59:13 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=654
05/30/2022 21:59:15 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=657
05/30/2022 21:59:18 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=659
05/30/2022 21:59:20 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=662
05/30/2022 21:59:21 - INFO - __main__ - Global step 2650 Train loss 0.04 Classification-F1 0.7091890732265447 on epoch=662
05/30/2022 21:59:24 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=664
05/30/2022 21:59:26 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.03 on epoch=667
05/30/2022 21:59:29 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=669
05/30/2022 21:59:31 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=672
05/30/2022 21:59:34 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=674
05/30/2022 21:59:35 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.7308277027027027 on epoch=674
05/30/2022 21:59:37 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.03 on epoch=677
05/30/2022 21:59:40 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=679
05/30/2022 21:59:42 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=682
05/30/2022 21:59:45 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=684
05/30/2022 21:59:47 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=687
05/30/2022 21:59:48 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.7301963088408101 on epoch=687
05/30/2022 21:59:51 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=689
05/30/2022 21:59:53 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=692
05/30/2022 21:59:56 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=694
05/30/2022 21:59:58 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=697
05/30/2022 22:00:01 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=699
05/30/2022 22:00:02 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.721969696969697 on epoch=699
05/30/2022 22:00:04 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=702
05/30/2022 22:00:07 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.03 on epoch=704
05/30/2022 22:00:09 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.04 on epoch=707
05/30/2022 22:00:12 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=709
05/30/2022 22:00:14 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=712
05/30/2022 22:00:15 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.7523801220575415 on epoch=712
05/30/2022 22:00:18 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=714
05/30/2022 22:00:20 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=717
05/30/2022 22:00:23 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=719
05/30/2022 22:00:25 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=722
05/30/2022 22:00:28 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=724
05/30/2022 22:00:29 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.7711868401206636 on epoch=724
05/30/2022 22:00:29 - INFO - __main__ - Saving model with best Classification-F1: 0.7663349490795144 -> 0.7711868401206636 on epoch=724, global_step=2900
05/30/2022 22:00:32 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
05/30/2022 22:00:34 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=729
05/30/2022 22:00:37 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=732
05/30/2022 22:00:39 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=734
05/30/2022 22:00:41 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=737
05/30/2022 22:00:43 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.6957633053221288 on epoch=737
05/30/2022 22:00:45 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
05/30/2022 22:00:48 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=742
05/30/2022 22:00:50 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.03 on epoch=744
05/30/2022 22:00:53 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=747
05/30/2022 22:00:55 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
05/30/2022 22:00:56 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.7377403846153846 on epoch=749
05/30/2022 22:00:56 - INFO - __main__ - save last model!
05/30/2022 22:00:56 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/30/2022 22:00:56 - INFO - __main__ - Start tokenizing ... 5509 instances
05/30/2022 22:00:56 - INFO - __main__ - Printing 3 examples
05/30/2022 22:00:56 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/30/2022 22:00:56 - INFO - __main__ - ['others']
05/30/2022 22:00:56 - INFO - __main__ -  [emo] what you like very little things ok
05/30/2022 22:00:56 - INFO - __main__ - ['others']
05/30/2022 22:00:56 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/30/2022 22:00:56 - INFO - __main__ - ['others']
05/30/2022 22:00:56 - INFO - __main__ - Tokenizing Input ...
05/30/2022 22:00:58 - INFO - __main__ - Tokenizing Output ...
05/30/2022 22:01:04 - INFO - __main__ - Loaded 5509 examples from test data
05/30/2022 22:02:38 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-24uptasks/singletask-emo/emo_16_87_0.2_8_predictions.txt
05/30/2022 22:02:38 - INFO - __main__ - Classification-F1 on test data: 0.2836
05/30/2022 22:02:38 - INFO - __main__ - prefix=emo_16_87, lr=0.2, bsz=8, dev_performance=0.7711868401206636, test_performance=0.28361962630179005
