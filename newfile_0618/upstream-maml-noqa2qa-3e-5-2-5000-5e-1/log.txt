04/12/2022 15:05:21 - INFO - __main__ - Namespace(train_dir='data', predict_dir='data', identifier='large', output_dir='models/upstream-maml-noqa2qa-3e-5-2-5000-5e-1', do_train=True, do_predict=False, inner_bsz=2, inner_lr=3e-05, checkpoint=None, do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=64, num_beams=4, append_another_bos=False, train_batch_size=1, predict_batch_size=1, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=2, num_train_epochs=120.0, warmup_steps=360, total_steps=5000, wait_step=10000000000, verbose=False, eval_period=10, prefix='', debug=False, seed=42, custom_tasks_splits='./dataloader/custom_tasks_splits/train_non_qa_test_qa.json', cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=-1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='0')
04/12/2022 15:05:21 - INFO - __main__ - models/upstream-maml-noqa2qa-3e-5-2-5000-5e-1
04/12/2022 15:05:22 - INFO - __main__ - args.device: cuda
04/12/2022 15:05:22 - INFO - __main__ - Using 1 gpus
04/12/2022 15:05:24 - INFO - __main__ - Training on the following tasks: ['hate_speech_offensive', 'google_wellformed_query', 'circa', 'glue-sst2', 'scitail', 'emo', 'ag_news', 'art', 'paws', 'kilt_ay2', 'glue-qnli', 'ade_corpus_v2-classification', 'hatexplain', 'emotion', 'glue-qqp', 'kilt_fever', 'dbpedia_14', 'glue-mnli', 'discovery', 'gigaword', 'amazon_polarity', 'tab_fact', 'tweet_eval-emoji', 'tweet_eval-offensive', 'tweet_eval-sentiment', 'imdb', 'liar', 'anli', 'wikisql', 'xsum', 'yahoo_answers_topics', 'yelp_polarity', 'yelp_review_full']
04/12/2022 15:05:25 - INFO - __main__ - Start tokenizing ... 165 instances
04/12/2022 15:05:25 - INFO - __main__ - Printing 3 examples
04/12/2022 15:05:25 - INFO - __main__ -  [ade_corpus_v2-classification] The treatment of FMF attacks in patients who cannot use colchicine is an important problem.
04/12/2022 15:05:25 - INFO - __main__ -  Not Related
04/12/2022 15:05:25 - INFO - __main__ -  [ade_corpus_v2-classification] The origin of NIS is outlined briefly and some fundamental clinical and experimental facts are presented, all of which stress the importance of the acute blockade of postsynaptic DA-ergic receptors.
04/12/2022 15:05:25 - INFO - __main__ -  Not Related
04/12/2022 15:05:25 - INFO - __main__ -  [ade_corpus_v2-classification] His AFP was initially 9828 microg/L and rapidly dropped to 5597 microg/L in ten days after oral sorafenib treatment.
04/12/2022 15:05:25 - INFO - __main__ -  Not Related
04/12/2022 15:05:25 - INFO - __main__ - Tokenizing Train Input ...
04/12/2022 15:05:38 - INFO - __main__ - Tokenizing Train Output ...
04/12/2022 15:05:46 - INFO - __main__ - Tokenizing Dev Input ...
04/12/2022 15:05:59 - INFO - __main__ - Tokenizing Dev Output ...
04/12/2022 15:06:35 - INFO - __main__ - Loaded 165 examples from train data
04/12/2022 15:06:53 - INFO - __main__ - try to initialize prompt embeddings
04/12/2022 15:06:58 - INFO - __main__ - Starting training!
04/12/2022 15:07:22 - INFO - __main__ - global step: 10; train loss: 7.207366943359375; dev loss: 6.947964668273926
04/12/2022 15:07:43 - INFO - __main__ - global step: 20; train loss: 6.128995418548584; dev loss: 6.143568515777588
04/12/2022 15:08:04 - INFO - __main__ - global step: 30; train loss: 6.510130405426025; dev loss: 6.303126335144043
04/12/2022 15:08:25 - INFO - __main__ - global step: 40; train loss: 5.322949409484863; dev loss: 5.3657755851745605
04/12/2022 15:08:46 - INFO - __main__ - global step: 50; train loss: 5.32211971282959; dev loss: 5.246204853057861
04/12/2022 15:09:07 - INFO - __main__ - global step: 60; train loss: 5.921999454498291; dev loss: 5.486644744873047
04/12/2022 15:09:28 - INFO - __main__ - global step: 70; train loss: 4.65130090713501; dev loss: 5.116118431091309
04/12/2022 15:09:49 - INFO - __main__ - global step: 80; train loss: 5.145827293395996; dev loss: 5.3141045570373535
04/12/2022 15:10:10 - INFO - __main__ - global step: 90; train loss: 5.270624160766602; dev loss: 5.399756908416748
04/12/2022 15:10:31 - INFO - __main__ - global step: 100; train loss: 4.923440933227539; dev loss: 5.046135902404785
04/12/2022 15:10:53 - INFO - __main__ - global step: 110; train loss: 5.329668998718262; dev loss: 5.218357563018799
04/12/2022 15:11:15 - INFO - __main__ - global step: 120; train loss: 4.900158882141113; dev loss: 5.153865814208984
04/12/2022 15:11:38 - INFO - __main__ - global step: 130; train loss: 5.167405128479004; dev loss: 5.067916393280029
04/12/2022 15:12:01 - INFO - __main__ - global step: 140; train loss: 5.098344802856445; dev loss: 4.868041038513184
04/12/2022 15:12:24 - INFO - __main__ - global step: 150; train loss: 5.144120693206787; dev loss: 5.194594860076904
04/12/2022 15:12:47 - INFO - __main__ - global step: 160; train loss: 5.533023834228516; dev loss: 5.718014717102051
04/12/2022 15:13:11 - INFO - __main__ - global step: 170; train loss: 5.8638715744018555; dev loss: 5.483349323272705
04/12/2022 15:13:36 - INFO - __main__ - global step: 180; train loss: 5.685743808746338; dev loss: 5.970029830932617
04/12/2022 15:14:01 - INFO - __main__ - global step: 190; train loss: 5.267232418060303; dev loss: 5.3729119300842285
04/12/2022 15:14:26 - INFO - __main__ - global step: 200; train loss: 5.366044521331787; dev loss: 5.249728202819824
04/12/2022 15:14:51 - INFO - __main__ - global step: 210; train loss: 6.117816925048828; dev loss: 5.72528600692749
04/12/2022 15:15:15 - INFO - __main__ - global step: 220; train loss: 5.390089988708496; dev loss: 5.467865943908691
04/12/2022 15:15:40 - INFO - __main__ - global step: 230; train loss: 6.206952095031738; dev loss: 5.816956520080566
04/12/2022 15:16:05 - INFO - __main__ - global step: 240; train loss: 5.724435329437256; dev loss: 5.83317232131958
04/12/2022 15:16:30 - INFO - __main__ - global step: 250; train loss: 6.0667243003845215; dev loss: 5.779890060424805
04/12/2022 15:16:55 - INFO - __main__ - global step: 260; train loss: 6.157843589782715; dev loss: 6.691219329833984
04/12/2022 15:17:19 - INFO - __main__ - global step: 270; train loss: 6.36870813369751; dev loss: 6.023305892944336
04/12/2022 15:17:45 - INFO - __main__ - global step: 280; train loss: 6.405147552490234; dev loss: 6.3375959396362305
04/12/2022 15:18:09 - INFO - __main__ - global step: 290; train loss: 7.2571611404418945; dev loss: 6.659824371337891
04/12/2022 15:18:33 - INFO - __main__ - global step: 300; train loss: 6.139765739440918; dev loss: 6.180720806121826
04/12/2022 15:18:58 - INFO - __main__ - global step: 310; train loss: 6.199387550354004; dev loss: 5.951632499694824
04/12/2022 15:19:23 - INFO - __main__ - global step: 320; train loss: 5.825247287750244; dev loss: 6.297077178955078
04/12/2022 15:19:47 - INFO - __main__ - global step: 330; train loss: 5.99216890335083; dev loss: 5.926208019256592
04/12/2022 15:20:11 - INFO - __main__ - global step: 340; train loss: 5.504031658172607; dev loss: 5.659743309020996
04/12/2022 15:20:35 - INFO - __main__ - global step: 350; train loss: 5.813719749450684; dev loss: 5.41420841217041
04/12/2022 15:20:59 - INFO - __main__ - global step: 360; train loss: 5.70797872543335; dev loss: 5.663620948791504
04/12/2022 15:21:23 - INFO - __main__ - global step: 370; train loss: 6.308177471160889; dev loss: 6.012706756591797
04/12/2022 15:21:47 - INFO - __main__ - global step: 380; train loss: 5.747880935668945; dev loss: 5.703639507293701
04/12/2022 15:22:12 - INFO - __main__ - global step: 390; train loss: 5.276669025421143; dev loss: 5.189380645751953
04/12/2022 15:22:35 - INFO - __main__ - global step: 400; train loss: 5.819643974304199; dev loss: 6.191071510314941
04/12/2022 15:23:00 - INFO - __main__ - global step: 410; train loss: 5.8042683601379395; dev loss: 5.8792595863342285
04/12/2022 15:23:24 - INFO - __main__ - global step: 420; train loss: 5.588380336761475; dev loss: 5.7819061279296875
04/12/2022 15:23:50 - INFO - __main__ - global step: 430; train loss: 5.527115821838379; dev loss: 5.546597480773926
04/12/2022 15:24:15 - INFO - __main__ - global step: 440; train loss: 5.740845680236816; dev loss: 5.8587822914123535
04/12/2022 15:24:39 - INFO - __main__ - global step: 450; train loss: 5.9077839851379395; dev loss: 5.976607322692871
04/12/2022 15:25:03 - INFO - __main__ - global step: 460; train loss: 5.803023338317871; dev loss: 5.915369987487793
04/12/2022 15:25:27 - INFO - __main__ - global step: 470; train loss: 5.689932346343994; dev loss: 5.404587268829346
04/12/2022 15:25:54 - INFO - __main__ - global step: 480; train loss: 5.727533340454102; dev loss: 5.6106462478637695
04/12/2022 15:26:19 - INFO - __main__ - global step: 490; train loss: 6.151064872741699; dev loss: 5.955431938171387
04/12/2022 15:26:44 - INFO - __main__ - global step: 500; train loss: 5.842757225036621; dev loss: 6.100814342498779
04/12/2022 15:27:08 - INFO - __main__ - global step: 510; train loss: 6.079512596130371; dev loss: 6.0749335289001465
04/12/2022 15:27:33 - INFO - __main__ - global step: 520; train loss: 5.7948198318481445; dev loss: 5.695395469665527
04/12/2022 15:27:58 - INFO - __main__ - global step: 530; train loss: 5.735899925231934; dev loss: 5.6974873542785645
04/12/2022 15:28:22 - INFO - __main__ - global step: 540; train loss: 6.205303192138672; dev loss: 5.730138301849365
04/12/2022 15:28:48 - INFO - __main__ - global step: 550; train loss: 5.597574710845947; dev loss: 5.488852500915527
04/12/2022 15:29:12 - INFO - __main__ - global step: 560; train loss: 6.476613521575928; dev loss: 6.073387622833252
04/12/2022 15:29:37 - INFO - __main__ - global step: 570; train loss: 5.319599628448486; dev loss: 5.590338706970215
04/12/2022 15:30:02 - INFO - __main__ - global step: 580; train loss: 6.167407989501953; dev loss: 5.902441501617432
04/12/2022 15:30:26 - INFO - __main__ - global step: 590; train loss: 5.948649883270264; dev loss: 5.669439792633057
04/12/2022 15:30:51 - INFO - __main__ - global step: 600; train loss: 6.000680446624756; dev loss: 6.122851371765137
04/12/2022 15:31:15 - INFO - __main__ - global step: 610; train loss: 5.899270534515381; dev loss: 6.095195770263672
04/12/2022 15:31:40 - INFO - __main__ - global step: 620; train loss: 5.687539577484131; dev loss: 5.773627281188965
04/12/2022 15:32:06 - INFO - __main__ - global step: 630; train loss: 5.489747047424316; dev loss: 5.409945011138916
04/12/2022 15:32:31 - INFO - __main__ - global step: 640; train loss: 5.728107929229736; dev loss: 5.611904144287109
04/12/2022 15:32:55 - INFO - __main__ - global step: 650; train loss: 5.658390998840332; dev loss: 5.841598987579346
04/12/2022 15:33:20 - INFO - __main__ - global step: 660; train loss: 5.379857063293457; dev loss: 5.049817085266113
04/12/2022 15:33:45 - INFO - __main__ - global step: 670; train loss: 5.142349720001221; dev loss: 5.410309791564941
04/12/2022 15:34:09 - INFO - __main__ - global step: 680; train loss: 4.989593505859375; dev loss: 5.607791423797607
04/12/2022 15:34:34 - INFO - __main__ - global step: 690; train loss: 5.598021507263184; dev loss: 5.488069534301758
04/12/2022 15:34:58 - INFO - __main__ - global step: 700; train loss: 5.451406955718994; dev loss: 5.43458890914917
04/12/2022 15:35:22 - INFO - __main__ - global step: 710; train loss: 5.462302207946777; dev loss: 5.07645320892334
04/12/2022 15:35:46 - INFO - __main__ - global step: 720; train loss: 5.595932483673096; dev loss: 5.823217868804932
04/12/2022 15:36:11 - INFO - __main__ - global step: 730; train loss: 5.56962776184082; dev loss: 5.389779567718506
04/12/2022 15:36:36 - INFO - __main__ - global step: 740; train loss: 5.402095794677734; dev loss: 5.487802505493164
04/12/2022 15:37:01 - INFO - __main__ - global step: 750; train loss: 5.350189685821533; dev loss: 5.323465824127197
04/12/2022 15:37:27 - INFO - __main__ - global step: 760; train loss: 5.487961292266846; dev loss: 5.306920051574707
04/12/2022 15:37:52 - INFO - __main__ - global step: 770; train loss: 4.9869771003723145; dev loss: 4.991295337677002
04/12/2022 15:38:17 - INFO - __main__ - global step: 780; train loss: 5.585700988769531; dev loss: 5.468379020690918
04/12/2022 15:38:43 - INFO - __main__ - global step: 790; train loss: 5.421191215515137; dev loss: 5.445808410644531
04/12/2022 15:39:08 - INFO - __main__ - global step: 800; train loss: 5.314435005187988; dev loss: 5.138842582702637
04/12/2022 15:39:34 - INFO - __main__ - global step: 810; train loss: 5.348772048950195; dev loss: 5.337109565734863
04/12/2022 15:39:58 - INFO - __main__ - global step: 820; train loss: 5.038346290588379; dev loss: 4.854722023010254
04/12/2022 15:40:23 - INFO - __main__ - global step: 830; train loss: 5.418383598327637; dev loss: 5.163897514343262
04/12/2022 15:40:48 - INFO - __main__ - global step: 840; train loss: 5.19498872756958; dev loss: 5.101454734802246
04/12/2022 15:41:14 - INFO - __main__ - global step: 850; train loss: 5.228339672088623; dev loss: 5.380120277404785
04/12/2022 15:41:39 - INFO - __main__ - global step: 860; train loss: 4.630599021911621; dev loss: 4.4215288162231445
04/12/2022 15:42:03 - INFO - __main__ - global step: 870; train loss: 5.024523735046387; dev loss: 4.910418510437012
04/12/2022 15:42:26 - INFO - __main__ - global step: 880; train loss: 5.475272178649902; dev loss: 5.572530746459961
04/12/2022 15:42:51 - INFO - __main__ - global step: 890; train loss: 5.236599922180176; dev loss: 5.062678813934326
04/12/2022 15:43:15 - INFO - __main__ - global step: 900; train loss: 5.276495456695557; dev loss: 5.355164527893066
04/12/2022 15:43:39 - INFO - __main__ - global step: 910; train loss: 4.99738073348999; dev loss: 4.961977481842041
04/12/2022 15:44:04 - INFO - __main__ - global step: 920; train loss: 5.084484577178955; dev loss: 5.3360371589660645
04/12/2022 15:44:28 - INFO - __main__ - global step: 930; train loss: 4.973176956176758; dev loss: 4.729029655456543
04/12/2022 15:44:54 - INFO - __main__ - global step: 940; train loss: 4.937602519989014; dev loss: 4.65291690826416
04/12/2022 15:45:19 - INFO - __main__ - global step: 950; train loss: 4.8447113037109375; dev loss: 4.811478614807129
04/12/2022 15:45:44 - INFO - __main__ - global step: 960; train loss: 5.201995372772217; dev loss: 5.076629161834717
04/12/2022 15:46:10 - INFO - __main__ - global step: 970; train loss: 5.086386203765869; dev loss: 5.281924724578857
04/12/2022 15:46:34 - INFO - __main__ - global step: 980; train loss: 5.0497145652771; dev loss: 5.198398113250732
04/12/2022 15:46:58 - INFO - __main__ - global step: 990; train loss: 4.695635795593262; dev loss: 4.72135066986084
04/12/2022 15:47:22 - INFO - __main__ - global step: 1000; train loss: 4.729822635650635; dev loss: 4.859949111938477
04/12/2022 15:47:46 - INFO - __main__ - global step: 1010; train loss: 4.901583671569824; dev loss: 4.840784549713135
04/12/2022 15:48:11 - INFO - __main__ - global step: 1020; train loss: 5.390364646911621; dev loss: 5.145674228668213
04/12/2022 15:48:35 - INFO - __main__ - global step: 1030; train loss: 4.834124565124512; dev loss: 5.079800128936768
04/12/2022 15:48:59 - INFO - __main__ - global step: 1040; train loss: 5.155241966247559; dev loss: 4.633481025695801
04/12/2022 15:49:24 - INFO - __main__ - global step: 1050; train loss: 4.771388530731201; dev loss: 4.55794620513916
04/12/2022 15:49:49 - INFO - __main__ - global step: 1060; train loss: 4.543025016784668; dev loss: 4.51646614074707
04/12/2022 15:50:14 - INFO - __main__ - global step: 1070; train loss: 5.111557960510254; dev loss: 4.870277404785156
04/12/2022 15:50:38 - INFO - __main__ - global step: 1080; train loss: 4.69632625579834; dev loss: 4.973475456237793
04/12/2022 15:51:04 - INFO - __main__ - global step: 1090; train loss: 4.996718406677246; dev loss: 4.911154747009277
04/12/2022 15:51:28 - INFO - __main__ - global step: 1100; train loss: 4.794761657714844; dev loss: 4.575363636016846
04/12/2022 15:51:51 - INFO - __main__ - global step: 1110; train loss: 4.517178535461426; dev loss: 4.35541296005249
04/12/2022 15:52:17 - INFO - __main__ - global step: 1120; train loss: 5.240653038024902; dev loss: 5.227671146392822
04/12/2022 15:52:40 - INFO - __main__ - global step: 1130; train loss: 4.716071605682373; dev loss: 4.783541679382324
04/12/2022 15:53:05 - INFO - __main__ - global step: 1140; train loss: 4.882576942443848; dev loss: 4.821959018707275
04/12/2022 15:53:29 - INFO - __main__ - global step: 1150; train loss: 4.773375988006592; dev loss: 4.840140342712402
04/12/2022 15:53:54 - INFO - __main__ - global step: 1160; train loss: 4.662966251373291; dev loss: 4.67978048324585
04/12/2022 15:54:18 - INFO - __main__ - global step: 1170; train loss: 4.993584156036377; dev loss: 4.82843017578125
04/12/2022 15:54:41 - INFO - __main__ - global step: 1180; train loss: 4.91693639755249; dev loss: 4.803666114807129
04/12/2022 15:55:06 - INFO - __main__ - global step: 1190; train loss: 4.623877048492432; dev loss: 4.74852180480957
04/12/2022 15:55:30 - INFO - __main__ - global step: 1200; train loss: 4.426059246063232; dev loss: 4.514697074890137
04/12/2022 15:55:53 - INFO - __main__ - global step: 1210; train loss: 4.384761810302734; dev loss: 4.749957084655762
04/12/2022 15:56:18 - INFO - __main__ - global step: 1220; train loss: 4.318758487701416; dev loss: 4.295274257659912
04/12/2022 15:56:42 - INFO - __main__ - global step: 1230; train loss: 4.519094467163086; dev loss: 4.373710632324219
04/12/2022 15:57:07 - INFO - __main__ - global step: 1240; train loss: 4.841628551483154; dev loss: 4.8828582763671875
04/12/2022 15:57:31 - INFO - __main__ - global step: 1250; train loss: 4.430175304412842; dev loss: 4.372983455657959
04/12/2022 15:57:55 - INFO - __main__ - global step: 1260; train loss: 4.773975849151611; dev loss: 4.496705055236816
04/12/2022 15:58:19 - INFO - __main__ - global step: 1270; train loss: 4.583954334259033; dev loss: 4.570348739624023
04/12/2022 15:58:43 - INFO - __main__ - global step: 1280; train loss: 4.652831554412842; dev loss: 4.770788192749023
04/12/2022 15:59:07 - INFO - __main__ - global step: 1290; train loss: 4.734508991241455; dev loss: 4.525667190551758
04/12/2022 15:59:33 - INFO - __main__ - global step: 1300; train loss: 4.53147554397583; dev loss: 4.467018127441406
04/12/2022 15:59:57 - INFO - __main__ - global step: 1310; train loss: 4.7491631507873535; dev loss: 4.804924011230469
04/12/2022 16:00:22 - INFO - __main__ - global step: 1320; train loss: 4.006726264953613; dev loss: 4.22036600112915
04/12/2022 16:00:48 - INFO - __main__ - global step: 1330; train loss: 4.45270299911499; dev loss: 4.455098628997803
04/12/2022 16:01:12 - INFO - __main__ - global step: 1340; train loss: 4.516012191772461; dev loss: 4.615043640136719
04/12/2022 16:01:38 - INFO - __main__ - global step: 1350; train loss: 4.126829147338867; dev loss: 4.471431255340576
04/12/2022 16:02:03 - INFO - __main__ - global step: 1360; train loss: 4.571397304534912; dev loss: 4.559266090393066
04/12/2022 16:02:28 - INFO - __main__ - global step: 1370; train loss: 4.163710117340088; dev loss: 4.230588436126709
04/12/2022 16:02:53 - INFO - __main__ - global step: 1380; train loss: 4.56137752532959; dev loss: 4.669617652893066
04/12/2022 16:03:19 - INFO - __main__ - global step: 1390; train loss: 4.3637895584106445; dev loss: 4.190913200378418
04/12/2022 16:03:45 - INFO - __main__ - global step: 1400; train loss: 4.707938194274902; dev loss: 4.899569511413574
04/12/2022 16:04:10 - INFO - __main__ - global step: 1410; train loss: 4.725403785705566; dev loss: 4.743705749511719
04/12/2022 16:04:35 - INFO - __main__ - global step: 1420; train loss: 4.289525508880615; dev loss: 4.0873212814331055
04/12/2022 16:05:00 - INFO - __main__ - global step: 1430; train loss: 4.37393045425415; dev loss: 4.244967460632324
04/12/2022 16:05:25 - INFO - __main__ - global step: 1440; train loss: 4.146815299987793; dev loss: 4.184027671813965
04/12/2022 16:05:50 - INFO - __main__ - global step: 1450; train loss: 4.21839714050293; dev loss: 4.016895771026611
04/12/2022 16:06:15 - INFO - __main__ - global step: 1460; train loss: 4.702647686004639; dev loss: 4.7491536140441895
04/12/2022 16:06:41 - INFO - __main__ - global step: 1470; train loss: 4.217308521270752; dev loss: 4.356010913848877
04/12/2022 16:07:04 - INFO - __main__ - global step: 1480; train loss: 4.6947712898254395; dev loss: 4.415665626525879
04/12/2022 16:07:29 - INFO - __main__ - global step: 1490; train loss: 4.418385028839111; dev loss: 4.062516212463379
04/12/2022 16:07:54 - INFO - __main__ - global step: 1500; train loss: 4.314754962921143; dev loss: 4.143753528594971
04/12/2022 16:08:18 - INFO - __main__ - global step: 1510; train loss: 4.276885032653809; dev loss: 4.381474494934082
04/12/2022 16:08:42 - INFO - __main__ - global step: 1520; train loss: 4.163967132568359; dev loss: 4.173083305358887
04/12/2022 16:09:06 - INFO - __main__ - global step: 1530; train loss: 4.283751487731934; dev loss: 4.627409934997559
04/12/2022 16:09:31 - INFO - __main__ - global step: 1540; train loss: 4.438630104064941; dev loss: 4.538889408111572
04/12/2022 16:09:56 - INFO - __main__ - global step: 1550; train loss: 3.6123859882354736; dev loss: 3.5574417114257812
04/12/2022 16:10:21 - INFO - __main__ - global step: 1560; train loss: 4.012600421905518; dev loss: 4.012049674987793
04/12/2022 16:10:46 - INFO - __main__ - global step: 1570; train loss: 4.359288215637207; dev loss: 4.1866559982299805
04/12/2022 16:11:09 - INFO - __main__ - global step: 1580; train loss: 4.100253105163574; dev loss: 3.7951786518096924
04/12/2022 16:11:35 - INFO - __main__ - global step: 1590; train loss: 4.224244594573975; dev loss: 4.2129387855529785
04/12/2022 16:11:59 - INFO - __main__ - global step: 1600; train loss: 4.2772536277771; dev loss: 4.279540061950684
04/12/2022 16:12:24 - INFO - __main__ - global step: 1610; train loss: 3.9258675575256348; dev loss: 4.183806419372559
04/12/2022 16:12:50 - INFO - __main__ - global step: 1620; train loss: 4.633298397064209; dev loss: 4.80780029296875
04/12/2022 16:13:15 - INFO - __main__ - global step: 1630; train loss: 3.827892780303955; dev loss: 3.9539687633514404
04/12/2022 16:13:40 - INFO - __main__ - global step: 1640; train loss: 3.928699493408203; dev loss: 4.138870716094971
04/12/2022 16:14:04 - INFO - __main__ - global step: 1650; train loss: 4.675279140472412; dev loss: 4.351122856140137
04/12/2022 16:14:28 - INFO - __main__ - global step: 1660; train loss: 4.427277565002441; dev loss: 4.396020889282227
04/12/2022 16:14:54 - INFO - __main__ - global step: 1670; train loss: 4.871509075164795; dev loss: 4.555610179901123
04/12/2022 16:15:18 - INFO - __main__ - global step: 1680; train loss: 4.426902770996094; dev loss: 5.358248710632324
04/12/2022 16:15:42 - INFO - __main__ - global step: 1690; train loss: 5.326327323913574; dev loss: 5.081548690795898
04/12/2022 16:16:07 - INFO - __main__ - global step: 1700; train loss: 4.782105445861816; dev loss: 4.827193737030029
04/12/2022 16:16:32 - INFO - __main__ - global step: 1710; train loss: 4.65878963470459; dev loss: 4.68001651763916
04/12/2022 16:16:56 - INFO - __main__ - global step: 1720; train loss: 4.6633172035217285; dev loss: 4.413834095001221
04/12/2022 16:17:21 - INFO - __main__ - global step: 1730; train loss: 4.634058952331543; dev loss: 4.447747707366943
04/12/2022 16:17:45 - INFO - __main__ - global step: 1740; train loss: 4.828570365905762; dev loss: 4.733697891235352
04/12/2022 16:18:10 - INFO - __main__ - global step: 1750; train loss: 4.712249279022217; dev loss: 4.98380184173584
04/12/2022 16:18:34 - INFO - __main__ - global step: 1760; train loss: 4.764695167541504; dev loss: 4.827605724334717
04/12/2022 16:18:58 - INFO - __main__ - global step: 1770; train loss: 4.417990684509277; dev loss: 4.423644065856934
04/12/2022 16:19:23 - INFO - __main__ - global step: 1780; train loss: 4.242251396179199; dev loss: 4.222886085510254
04/12/2022 16:19:48 - INFO - __main__ - global step: 1790; train loss: 4.3380937576293945; dev loss: 4.557521820068359
04/12/2022 16:20:14 - INFO - __main__ - global step: 1800; train loss: 4.850888252258301; dev loss: 4.3829569816589355
04/12/2022 16:20:39 - INFO - __main__ - global step: 1810; train loss: 4.95034646987915; dev loss: 5.111897945404053
04/12/2022 16:21:04 - INFO - __main__ - global step: 1820; train loss: 4.777393341064453; dev loss: 4.360255241394043
04/12/2022 16:21:28 - INFO - __main__ - global step: 1830; train loss: 4.530644416809082; dev loss: 4.820288181304932
04/12/2022 16:21:51 - INFO - __main__ - global step: 1840; train loss: 4.6085100173950195; dev loss: 5.027667045593262
04/12/2022 16:22:16 - INFO - __main__ - global step: 1850; train loss: 4.25301456451416; dev loss: 4.860617160797119
04/12/2022 16:22:40 - INFO - __main__ - global step: 1860; train loss: 4.558125019073486; dev loss: 4.432106018066406
04/12/2022 16:23:05 - INFO - __main__ - global step: 1870; train loss: 4.075357437133789; dev loss: 4.293922424316406
04/12/2022 16:23:29 - INFO - __main__ - global step: 1880; train loss: 4.462491035461426; dev loss: 4.3326334953308105
04/12/2022 16:23:53 - INFO - __main__ - global step: 1890; train loss: 4.710870742797852; dev loss: 4.857873439788818
04/12/2022 16:24:19 - INFO - __main__ - global step: 1900; train loss: 4.019955635070801; dev loss: 3.8638179302215576
04/12/2022 16:24:43 - INFO - __main__ - global step: 1910; train loss: 4.343380928039551; dev loss: 4.293440818786621
04/12/2022 16:25:09 - INFO - __main__ - global step: 1920; train loss: 4.145020484924316; dev loss: 4.4382405281066895
04/12/2022 16:25:33 - INFO - __main__ - global step: 1930; train loss: 4.253983020782471; dev loss: 4.6259846687316895
04/12/2022 16:25:57 - INFO - __main__ - global step: 1940; train loss: 4.096282005310059; dev loss: 3.8690478801727295
04/12/2022 16:26:23 - INFO - __main__ - global step: 1950; train loss: 3.8950419425964355; dev loss: 4.078762054443359
04/12/2022 16:26:49 - INFO - __main__ - global step: 1960; train loss: 4.835325241088867; dev loss: 4.69996452331543
04/12/2022 16:27:14 - INFO - __main__ - global step: 1970; train loss: 4.057403564453125; dev loss: 4.427359580993652
04/12/2022 16:27:40 - INFO - __main__ - global step: 1980; train loss: 4.05947732925415; dev loss: 4.085087299346924
04/12/2022 16:28:05 - INFO - __main__ - global step: 1990; train loss: 5.051714897155762; dev loss: 4.600027084350586
04/12/2022 16:28:29 - INFO - __main__ - global step: 2000; train loss: 4.285943031311035; dev loss: 4.430731296539307
04/12/2022 16:28:54 - INFO - __main__ - global step: 2010; train loss: 4.051939964294434; dev loss: 4.1110734939575195
04/12/2022 16:29:18 - INFO - __main__ - global step: 2020; train loss: 4.53053092956543; dev loss: 4.5766282081604
04/12/2022 16:29:43 - INFO - __main__ - global step: 2030; train loss: 4.232123374938965; dev loss: 4.3329997062683105
04/12/2022 16:30:07 - INFO - __main__ - global step: 2040; train loss: 4.423801898956299; dev loss: 4.611880302429199
04/12/2022 16:30:33 - INFO - __main__ - global step: 2050; train loss: 3.9081883430480957; dev loss: 3.945798873901367
04/12/2022 16:30:58 - INFO - __main__ - global step: 2060; train loss: 4.03485107421875; dev loss: 4.000107765197754
04/12/2022 16:31:23 - INFO - __main__ - global step: 2070; train loss: 4.1751556396484375; dev loss: 4.123064994812012
04/12/2022 16:31:47 - INFO - __main__ - global step: 2080; train loss: 4.7140398025512695; dev loss: 4.427099704742432
04/12/2022 16:32:11 - INFO - __main__ - global step: 2090; train loss: 4.090851783752441; dev loss: 3.8760910034179688
04/12/2022 16:32:36 - INFO - __main__ - global step: 2100; train loss: 3.784383773803711; dev loss: 3.8415985107421875
04/12/2022 16:33:01 - INFO - __main__ - global step: 2110; train loss: 4.271368980407715; dev loss: 4.350008964538574
04/12/2022 16:33:26 - INFO - __main__ - global step: 2120; train loss: 4.171854496002197; dev loss: 3.966226100921631
04/12/2022 16:33:51 - INFO - __main__ - global step: 2130; train loss: 4.381482124328613; dev loss: 4.619124412536621
04/12/2022 16:34:16 - INFO - __main__ - global step: 2140; train loss: 4.244376182556152; dev loss: 4.102740287780762
04/12/2022 16:34:39 - INFO - __main__ - global step: 2150; train loss: 4.248306751251221; dev loss: 3.919053554534912
04/12/2022 16:35:03 - INFO - __main__ - global step: 2160; train loss: 4.41365909576416; dev loss: 4.511396884918213
04/12/2022 16:35:28 - INFO - __main__ - global step: 2170; train loss: 4.546515941619873; dev loss: 4.437050819396973
04/12/2022 16:35:53 - INFO - __main__ - global step: 2180; train loss: 3.8199374675750732; dev loss: 3.883941173553467
04/12/2022 16:36:19 - INFO - __main__ - global step: 2190; train loss: 3.8616700172424316; dev loss: 4.065890312194824
04/12/2022 16:36:43 - INFO - __main__ - global step: 2200; train loss: 4.039275169372559; dev loss: 3.954484224319458
04/12/2022 16:37:07 - INFO - __main__ - global step: 2210; train loss: 3.9088051319122314; dev loss: 3.669286012649536
04/12/2022 16:37:32 - INFO - __main__ - global step: 2220; train loss: 3.787142276763916; dev loss: 3.668029308319092
04/12/2022 16:37:57 - INFO - __main__ - global step: 2230; train loss: 4.027848243713379; dev loss: 3.966285228729248
04/12/2022 16:38:22 - INFO - __main__ - global step: 2240; train loss: 4.226980209350586; dev loss: 4.13466739654541
04/12/2022 16:38:46 - INFO - __main__ - global step: 2250; train loss: 3.529557466506958; dev loss: 3.5136656761169434
04/12/2022 16:39:10 - INFO - __main__ - global step: 2260; train loss: 4.46591854095459; dev loss: 4.138882637023926
04/12/2022 16:39:35 - INFO - __main__ - global step: 2270; train loss: 4.414709091186523; dev loss: 4.398175239562988
04/12/2022 16:40:00 - INFO - __main__ - global step: 2280; train loss: 4.087594509124756; dev loss: 4.15964937210083
04/12/2022 16:40:24 - INFO - __main__ - global step: 2290; train loss: 4.005638599395752; dev loss: 3.993718385696411
04/12/2022 16:40:49 - INFO - __main__ - global step: 2300; train loss: 3.785888671875; dev loss: 3.723588228225708
04/12/2022 16:41:14 - INFO - __main__ - global step: 2310; train loss: 3.663156032562256; dev loss: 3.7238526344299316
04/12/2022 16:41:38 - INFO - __main__ - global step: 2320; train loss: 3.917931079864502; dev loss: 4.047835350036621
04/12/2022 16:42:02 - INFO - __main__ - global step: 2330; train loss: 3.912336826324463; dev loss: 3.8588993549346924
04/12/2022 16:42:26 - INFO - __main__ - global step: 2340; train loss: 3.924750566482544; dev loss: 3.744345188140869
04/12/2022 16:42:51 - INFO - __main__ - global step: 2350; train loss: 3.815751314163208; dev loss: 3.8339037895202637
04/12/2022 16:43:16 - INFO - __main__ - global step: 2360; train loss: 3.9066944122314453; dev loss: 3.760558605194092
04/12/2022 16:43:40 - INFO - __main__ - global step: 2370; train loss: 4.320466041564941; dev loss: 4.291226863861084
04/12/2022 16:44:06 - INFO - __main__ - global step: 2380; train loss: 4.092354774475098; dev loss: 4.020185470581055
04/12/2022 16:44:30 - INFO - __main__ - global step: 2390; train loss: 4.026581764221191; dev loss: 3.8379967212677
04/12/2022 16:44:54 - INFO - __main__ - global step: 2400; train loss: 3.533641815185547; dev loss: 3.6219277381896973
04/12/2022 16:45:18 - INFO - __main__ - global step: 2410; train loss: 3.795407772064209; dev loss: 3.5410995483398438
04/12/2022 16:45:43 - INFO - __main__ - global step: 2420; train loss: 4.273907661437988; dev loss: 4.413426399230957
04/12/2022 16:46:08 - INFO - __main__ - global step: 2430; train loss: 3.5142321586608887; dev loss: 3.659182071685791
04/12/2022 16:46:32 - INFO - __main__ - global step: 2440; train loss: 3.523533344268799; dev loss: 3.540764331817627
04/12/2022 16:46:57 - INFO - __main__ - global step: 2450; train loss: 4.1553497314453125; dev loss: 4.213774681091309
04/12/2022 16:47:22 - INFO - __main__ - global step: 2460; train loss: 3.9209933280944824; dev loss: 3.9914937019348145
04/12/2022 16:47:48 - INFO - __main__ - global step: 2470; train loss: 4.28811502456665; dev loss: 4.138533115386963
04/12/2022 16:48:12 - INFO - __main__ - global step: 2480; train loss: 3.6238808631896973; dev loss: 3.695735216140747
04/12/2022 16:48:37 - INFO - __main__ - global step: 2490; train loss: 4.15533447265625; dev loss: 3.9271016120910645
04/12/2022 16:49:01 - INFO - __main__ - global step: 2500; train loss: 3.5493855476379395; dev loss: 3.692951202392578
04/12/2022 16:49:26 - INFO - __main__ - global step: 2510; train loss: 3.6106643676757812; dev loss: 3.737488269805908
04/12/2022 16:49:50 - INFO - __main__ - global step: 2520; train loss: 3.870272397994995; dev loss: 3.8792672157287598
04/12/2022 16:50:15 - INFO - __main__ - global step: 2530; train loss: 3.9974617958068848; dev loss: 4.012087345123291
04/12/2022 16:50:39 - INFO - __main__ - global step: 2540; train loss: 3.6954169273376465; dev loss: 3.8848633766174316
04/12/2022 16:51:03 - INFO - __main__ - global step: 2550; train loss: 3.969768524169922; dev loss: 3.659618854522705
04/12/2022 16:51:26 - INFO - __main__ - global step: 2560; train loss: 3.9953293800354004; dev loss: 3.875896453857422
04/12/2022 16:51:51 - INFO - __main__ - global step: 2570; train loss: 3.569453001022339; dev loss: 3.401885986328125
04/12/2022 16:52:15 - INFO - __main__ - global step: 2580; train loss: 3.459256649017334; dev loss: 3.5694918632507324
04/12/2022 16:52:39 - INFO - __main__ - global step: 2590; train loss: 4.112772464752197; dev loss: 4.026894569396973
04/12/2022 16:53:03 - INFO - __main__ - global step: 2600; train loss: 4.039858818054199; dev loss: 4.090721130371094
04/12/2022 16:53:27 - INFO - __main__ - global step: 2610; train loss: 3.9386684894561768; dev loss: 4.116463661193848
04/12/2022 16:53:52 - INFO - __main__ - global step: 2620; train loss: 3.4791812896728516; dev loss: 3.633530378341675
04/12/2022 16:54:17 - INFO - __main__ - global step: 2630; train loss: 4.122011184692383; dev loss: 4.049620151519775
04/12/2022 16:54:42 - INFO - __main__ - global step: 2640; train loss: 3.939171552658081; dev loss: 3.5274949073791504
04/12/2022 16:55:08 - INFO - __main__ - global step: 2650; train loss: 3.827943801879883; dev loss: 3.8974571228027344
04/12/2022 16:55:33 - INFO - __main__ - global step: 2660; train loss: 3.6301796436309814; dev loss: 3.6005282402038574
04/12/2022 16:55:57 - INFO - __main__ - global step: 2670; train loss: 3.689927577972412; dev loss: 3.640705108642578
04/12/2022 16:56:21 - INFO - __main__ - global step: 2680; train loss: 3.7720866203308105; dev loss: 3.767855167388916
04/12/2022 16:56:46 - INFO - __main__ - global step: 2690; train loss: 4.11458683013916; dev loss: 4.110173225402832
04/12/2022 16:57:10 - INFO - __main__ - global step: 2700; train loss: 4.085466384887695; dev loss: 4.173831462860107
04/12/2022 16:57:35 - INFO - __main__ - global step: 2710; train loss: 3.7064616680145264; dev loss: 3.565967082977295
04/12/2022 16:58:00 - INFO - __main__ - global step: 2720; train loss: 3.658198833465576; dev loss: 3.5670266151428223
04/12/2022 16:58:25 - INFO - __main__ - global step: 2730; train loss: 3.292731761932373; dev loss: 3.2720847129821777
04/12/2022 16:58:50 - INFO - __main__ - global step: 2740; train loss: 3.3131377696990967; dev loss: 3.457822799682617
04/12/2022 16:59:14 - INFO - __main__ - global step: 2750; train loss: 3.4623634815216064; dev loss: 3.772749662399292
04/12/2022 16:59:40 - INFO - __main__ - global step: 2760; train loss: 3.461449146270752; dev loss: 3.1322622299194336
04/12/2022 17:00:04 - INFO - __main__ - global step: 2770; train loss: 3.590062379837036; dev loss: 3.5069007873535156
04/12/2022 17:00:30 - INFO - __main__ - global step: 2780; train loss: 3.8948230743408203; dev loss: 3.7127737998962402
04/12/2022 17:00:55 - INFO - __main__ - global step: 2790; train loss: 4.143710613250732; dev loss: 4.009903907775879
04/12/2022 17:01:19 - INFO - __main__ - global step: 2800; train loss: 3.9367051124572754; dev loss: 3.9013171195983887
04/12/2022 17:01:44 - INFO - __main__ - global step: 2810; train loss: 3.8046791553497314; dev loss: 3.82848858833313
04/12/2022 17:02:08 - INFO - __main__ - global step: 2820; train loss: 3.6995773315429688; dev loss: 3.572676181793213
04/12/2022 17:02:33 - INFO - __main__ - global step: 2830; train loss: 3.6465487480163574; dev loss: 3.7572436332702637
04/12/2022 17:02:57 - INFO - __main__ - global step: 2840; train loss: 3.6985275745391846; dev loss: 3.6702942848205566
04/12/2022 17:03:21 - INFO - __main__ - global step: 2850; train loss: 4.082211494445801; dev loss: 4.06143856048584
04/12/2022 17:03:46 - INFO - __main__ - global step: 2860; train loss: 3.4145138263702393; dev loss: 3.661151170730591
04/12/2022 17:04:11 - INFO - __main__ - global step: 2870; train loss: 3.388542652130127; dev loss: 3.342186450958252
04/12/2022 17:04:35 - INFO - __main__ - global step: 2880; train loss: 3.465918779373169; dev loss: 3.617511034011841
04/12/2022 17:05:00 - INFO - __main__ - global step: 2890; train loss: 3.7554657459259033; dev loss: 3.9502570629119873
04/12/2022 17:05:25 - INFO - __main__ - global step: 2900; train loss: 3.7481350898742676; dev loss: 3.6257541179656982
04/12/2022 17:05:49 - INFO - __main__ - global step: 2910; train loss: 3.486798048019409; dev loss: 3.3869800567626953
04/12/2022 17:06:14 - INFO - __main__ - global step: 2920; train loss: 3.515723466873169; dev loss: 3.630192518234253
04/12/2022 17:06:38 - INFO - __main__ - global step: 2930; train loss: 4.179659366607666; dev loss: 4.026178359985352
04/12/2022 17:07:04 - INFO - __main__ - global step: 2940; train loss: 3.293569564819336; dev loss: 3.3496131896972656
04/12/2022 17:07:28 - INFO - __main__ - global step: 2950; train loss: 3.5038254261016846; dev loss: 3.2931675910949707
04/12/2022 17:07:53 - INFO - __main__ - global step: 2960; train loss: 3.5993552207946777; dev loss: 3.845487117767334
04/12/2022 17:08:19 - INFO - __main__ - global step: 2970; train loss: 3.468174695968628; dev loss: 3.4817230701446533
04/12/2022 17:08:45 - INFO - __main__ - global step: 2980; train loss: 3.5404582023620605; dev loss: 3.700275421142578
04/12/2022 17:09:09 - INFO - __main__ - global step: 2990; train loss: 3.6042094230651855; dev loss: 4.272071361541748
04/12/2022 17:09:33 - INFO - __main__ - global step: 3000; train loss: 3.436065196990967; dev loss: 3.4221980571746826
04/12/2022 17:09:59 - INFO - __main__ - global step: 3010; train loss: 3.8884811401367188; dev loss: 3.6567904949188232
04/12/2022 17:10:23 - INFO - __main__ - global step: 3020; train loss: 3.490877866744995; dev loss: 3.7351748943328857
04/12/2022 17:10:47 - INFO - __main__ - global step: 3030; train loss: 2.8873066902160645; dev loss: 2.979957103729248
04/12/2022 17:11:12 - INFO - __main__ - global step: 3040; train loss: 3.2071499824523926; dev loss: 3.4342052936553955
04/12/2022 17:11:36 - INFO - __main__ - global step: 3050; train loss: 3.4139881134033203; dev loss: 3.2436447143554688
04/12/2022 17:12:00 - INFO - __main__ - global step: 3060; train loss: 3.3685812950134277; dev loss: 3.6488099098205566
04/12/2022 17:12:23 - INFO - __main__ - global step: 3070; train loss: 3.752593517303467; dev loss: 3.569467067718506
04/12/2022 17:12:48 - INFO - __main__ - global step: 3080; train loss: 3.3753485679626465; dev loss: 3.6390652656555176
04/12/2022 17:13:11 - INFO - __main__ - global step: 3090; train loss: 3.3563320636749268; dev loss: 3.210498094558716
04/12/2022 17:13:35 - INFO - __main__ - global step: 3100; train loss: 4.130290985107422; dev loss: 4.337599277496338
04/12/2022 17:14:00 - INFO - __main__ - global step: 3110; train loss: 3.7781848907470703; dev loss: 3.9558403491973877
04/12/2022 17:14:26 - INFO - __main__ - global step: 3120; train loss: 2.8811697959899902; dev loss: 3.0335984230041504
04/12/2022 17:14:50 - INFO - __main__ - global step: 3130; train loss: 3.5491943359375; dev loss: 3.293363571166992
04/12/2022 17:15:15 - INFO - __main__ - global step: 3140; train loss: 3.7020370960235596; dev loss: 3.6397101879119873
04/12/2022 17:15:39 - INFO - __main__ - global step: 3150; train loss: 3.6585071086883545; dev loss: 3.484541654586792
04/12/2022 17:16:05 - INFO - __main__ - global step: 3160; train loss: 3.1554155349731445; dev loss: 3.157270908355713
04/12/2022 17:16:29 - INFO - __main__ - global step: 3170; train loss: 3.3144309520721436; dev loss: 3.1922531127929688
04/12/2022 17:16:54 - INFO - __main__ - global step: 3180; train loss: 3.354944944381714; dev loss: 3.2524890899658203
04/12/2022 17:17:18 - INFO - __main__ - global step: 3190; train loss: 4.125210762023926; dev loss: 4.261069297790527
04/12/2022 17:17:43 - INFO - __main__ - global step: 3200; train loss: 3.3745529651641846; dev loss: 3.554513454437256
04/12/2022 17:18:07 - INFO - __main__ - global step: 3210; train loss: 3.4134204387664795; dev loss: 3.219481945037842
04/12/2022 17:18:31 - INFO - __main__ - global step: 3220; train loss: 3.411432981491089; dev loss: 3.42271089553833
04/12/2022 17:18:56 - INFO - __main__ - global step: 3230; train loss: 3.1104912757873535; dev loss: 2.906255006790161
04/12/2022 17:19:20 - INFO - __main__ - global step: 3240; train loss: 3.1265735626220703; dev loss: 2.8632354736328125
04/12/2022 17:19:45 - INFO - __main__ - global step: 3250; train loss: 3.547644853591919; dev loss: 3.5626094341278076
04/12/2022 17:20:10 - INFO - __main__ - global step: 3260; train loss: 3.393200397491455; dev loss: 3.051717519760132
04/12/2022 17:20:34 - INFO - __main__ - global step: 3270; train loss: 2.8761115074157715; dev loss: 3.052049160003662
04/12/2022 17:20:59 - INFO - __main__ - global step: 3280; train loss: 3.4426021575927734; dev loss: 3.7002780437469482
04/12/2022 17:21:23 - INFO - __main__ - global step: 3290; train loss: 3.8690648078918457; dev loss: 3.620643138885498
04/12/2022 17:21:48 - INFO - __main__ - global step: 3300; train loss: 4.075364112854004; dev loss: 3.9856555461883545
04/12/2022 17:22:12 - INFO - __main__ - global step: 3310; train loss: 2.9861271381378174; dev loss: 3.0096921920776367
04/12/2022 17:22:36 - INFO - __main__ - global step: 3320; train loss: 3.359675168991089; dev loss: 3.173762083053589
04/12/2022 17:23:01 - INFO - __main__ - global step: 3330; train loss: 3.98698353767395; dev loss: 3.5306332111358643
04/12/2022 17:23:26 - INFO - __main__ - global step: 3340; train loss: 3.438474655151367; dev loss: 3.345374584197998
04/12/2022 17:23:50 - INFO - __main__ - global step: 3350; train loss: 3.2294445037841797; dev loss: 3.242009401321411
04/12/2022 17:24:14 - INFO - __main__ - global step: 3360; train loss: 3.761817216873169; dev loss: 3.901124954223633
04/12/2022 17:24:38 - INFO - __main__ - global step: 3370; train loss: 3.3864612579345703; dev loss: 3.451026439666748
04/12/2022 17:25:03 - INFO - __main__ - global step: 3380; train loss: 3.8244805335998535; dev loss: 3.771331310272217
04/12/2022 17:25:26 - INFO - __main__ - global step: 3390; train loss: 3.1612436771392822; dev loss: 3.16318941116333
04/12/2022 17:25:51 - INFO - __main__ - global step: 3400; train loss: 3.5031466484069824; dev loss: 3.2797751426696777
04/12/2022 17:26:15 - INFO - __main__ - global step: 3410; train loss: 3.4558911323547363; dev loss: 3.7762703895568848
04/12/2022 17:26:39 - INFO - __main__ - global step: 3420; train loss: 3.334925413131714; dev loss: 3.1558754444122314
04/12/2022 17:27:04 - INFO - __main__ - global step: 3430; train loss: 3.2813611030578613; dev loss: 3.2473835945129395
04/12/2022 17:27:29 - INFO - __main__ - global step: 3440; train loss: 3.1959948539733887; dev loss: 3.7529587745666504
04/12/2022 17:27:53 - INFO - __main__ - global step: 3450; train loss: 2.9134521484375; dev loss: 3.052619695663452
04/12/2022 17:28:17 - INFO - __main__ - global step: 3460; train loss: 3.349574327468872; dev loss: 3.3749663829803467
04/12/2022 17:28:42 - INFO - __main__ - global step: 3470; train loss: 3.7449562549591064; dev loss: 3.6222622394561768
04/12/2022 17:29:07 - INFO - __main__ - global step: 3480; train loss: 3.41369366645813; dev loss: 3.306119203567505
04/12/2022 17:29:32 - INFO - __main__ - global step: 3490; train loss: 2.9369194507598877; dev loss: 2.9556562900543213
04/12/2022 17:29:56 - INFO - __main__ - global step: 3500; train loss: 3.976914882659912; dev loss: 3.775942325592041
04/12/2022 17:30:20 - INFO - __main__ - global step: 3510; train loss: 3.135913133621216; dev loss: 3.2039895057678223
04/12/2022 17:30:45 - INFO - __main__ - global step: 3520; train loss: 3.163342237472534; dev loss: 3.407472610473633
04/12/2022 17:31:09 - INFO - __main__ - global step: 3530; train loss: 3.3027095794677734; dev loss: 2.940812587738037
04/12/2022 17:31:34 - INFO - __main__ - global step: 3540; train loss: 3.3588433265686035; dev loss: 3.459024429321289
04/12/2022 17:31:59 - INFO - __main__ - global step: 3550; train loss: 3.4422450065612793; dev loss: 3.4156088829040527
04/12/2022 17:32:24 - INFO - __main__ - global step: 3560; train loss: 3.202972412109375; dev loss: 2.9965667724609375
04/12/2022 17:32:47 - INFO - __main__ - global step: 3570; train loss: 3.72688627243042; dev loss: 3.5974884033203125
04/12/2022 17:33:12 - INFO - __main__ - global step: 3580; train loss: 3.1562929153442383; dev loss: 3.4910340309143066
04/12/2022 17:33:37 - INFO - __main__ - global step: 3590; train loss: 3.463770627975464; dev loss: 3.7036571502685547
04/12/2022 17:34:01 - INFO - __main__ - global step: 3600; train loss: 3.06185245513916; dev loss: 3.2834179401397705
04/12/2022 17:34:25 - INFO - __main__ - global step: 3610; train loss: 2.922234058380127; dev loss: 3.118061065673828
04/12/2022 17:34:50 - INFO - __main__ - global step: 3620; train loss: 2.8520922660827637; dev loss: 2.9582810401916504
04/12/2022 17:35:14 - INFO - __main__ - global step: 3630; train loss: 3.0061097145080566; dev loss: 3.073204755783081
04/12/2022 17:35:37 - INFO - __main__ - global step: 3640; train loss: 3.427579164505005; dev loss: 3.4241249561309814
04/12/2022 17:36:02 - INFO - __main__ - global step: 3650; train loss: 3.2323508262634277; dev loss: 3.225226879119873
04/12/2022 17:36:26 - INFO - __main__ - global step: 3660; train loss: 3.5423481464385986; dev loss: 3.6708807945251465
04/12/2022 17:36:50 - INFO - __main__ - global step: 3670; train loss: 2.981419086456299; dev loss: 3.061372995376587
04/12/2022 17:37:14 - INFO - __main__ - global step: 3680; train loss: 3.1327712535858154; dev loss: 3.2057433128356934
04/12/2022 17:37:38 - INFO - __main__ - global step: 3690; train loss: 3.4135119915008545; dev loss: 3.433633804321289
04/12/2022 17:38:03 - INFO - __main__ - global step: 3700; train loss: 3.148573398590088; dev loss: 3.1115365028381348
04/12/2022 17:38:26 - INFO - __main__ - global step: 3710; train loss: 2.92472767829895; dev loss: 3.1920597553253174
04/12/2022 17:38:49 - INFO - __main__ - global step: 3720; train loss: 2.9815216064453125; dev loss: 3.297145366668701
04/12/2022 17:39:14 - INFO - __main__ - global step: 3730; train loss: 3.075819253921509; dev loss: 2.982490062713623
04/12/2022 17:39:38 - INFO - __main__ - global step: 3740; train loss: 3.1056737899780273; dev loss: 3.0879392623901367
04/12/2022 17:40:02 - INFO - __main__ - global step: 3750; train loss: 3.070882558822632; dev loss: 3.15651535987854
04/12/2022 17:40:25 - INFO - __main__ - global step: 3760; train loss: 3.3238632678985596; dev loss: 3.485234022140503
04/12/2022 17:40:49 - INFO - __main__ - global step: 3770; train loss: 3.0002753734588623; dev loss: 3.1004257202148438
04/12/2022 17:41:12 - INFO - __main__ - global step: 3780; train loss: 3.3414719104766846; dev loss: 3.1050689220428467
04/12/2022 17:41:36 - INFO - __main__ - global step: 3790; train loss: 3.2385668754577637; dev loss: 3.178558826446533
04/12/2022 17:42:00 - INFO - __main__ - global step: 3800; train loss: 2.9446287155151367; dev loss: 2.9041574001312256
04/12/2022 17:42:23 - INFO - __main__ - global step: 3810; train loss: 2.9661240577697754; dev loss: 3.0155067443847656
04/12/2022 17:42:47 - INFO - __main__ - global step: 3820; train loss: 3.1141746044158936; dev loss: 3.1715290546417236
04/12/2022 17:43:11 - INFO - __main__ - global step: 3830; train loss: 3.393524646759033; dev loss: 3.3954696655273438
04/12/2022 17:43:35 - INFO - __main__ - global step: 3840; train loss: 3.32517671585083; dev loss: 3.5148234367370605
04/12/2022 17:43:59 - INFO - __main__ - global step: 3850; train loss: 3.074345588684082; dev loss: 3.127138137817383
04/12/2022 17:44:21 - INFO - __main__ - global step: 3860; train loss: 3.5775818824768066; dev loss: 3.5909552574157715
04/12/2022 17:44:45 - INFO - __main__ - global step: 3870; train loss: 3.2705295085906982; dev loss: 3.0285327434539795
04/12/2022 17:45:08 - INFO - __main__ - global step: 3880; train loss: 3.3487555980682373; dev loss: 3.2550950050354004
04/12/2022 17:45:32 - INFO - __main__ - global step: 3890; train loss: 3.2606940269470215; dev loss: 2.997335910797119
04/12/2022 17:45:55 - INFO - __main__ - global step: 3900; train loss: 3.13511323928833; dev loss: 3.0512912273406982
04/12/2022 17:46:19 - INFO - __main__ - global step: 3910; train loss: 3.619652509689331; dev loss: 3.676926374435425
04/12/2022 17:46:42 - INFO - __main__ - global step: 3920; train loss: 2.949714422225952; dev loss: 3.1684539318084717
04/12/2022 17:47:05 - INFO - __main__ - global step: 3930; train loss: 2.7984070777893066; dev loss: 2.7898707389831543
04/12/2022 17:47:29 - INFO - __main__ - global step: 3940; train loss: 3.1892144680023193; dev loss: 2.99538516998291
04/12/2022 17:47:53 - INFO - __main__ - global step: 3950; train loss: 3.727874755859375; dev loss: 3.1829140186309814
04/12/2022 17:48:16 - INFO - __main__ - global step: 3960; train loss: 3.074835777282715; dev loss: 2.891808271408081
04/12/2022 17:48:39 - INFO - __main__ - global step: 3970; train loss: 2.7971110343933105; dev loss: 3.1546053886413574
04/12/2022 17:49:03 - INFO - __main__ - global step: 3980; train loss: 2.810777187347412; dev loss: 2.8097968101501465
04/12/2022 17:49:26 - INFO - __main__ - global step: 3990; train loss: 3.482818603515625; dev loss: 3.0736801624298096
04/12/2022 17:49:50 - INFO - __main__ - global step: 4000; train loss: 3.6247997283935547; dev loss: 3.3840668201446533
04/12/2022 17:50:14 - INFO - __main__ - global step: 4010; train loss: 2.741811752319336; dev loss: 2.649272918701172
04/12/2022 17:50:38 - INFO - __main__ - global step: 4020; train loss: 3.086583375930786; dev loss: 3.1308634281158447
04/12/2022 17:51:02 - INFO - __main__ - global step: 4030; train loss: 2.9683408737182617; dev loss: 2.8787808418273926
04/12/2022 17:51:27 - INFO - __main__ - global step: 4040; train loss: 3.429300308227539; dev loss: 3.363459825515747
04/12/2022 17:51:52 - INFO - __main__ - global step: 4050; train loss: 3.0341131687164307; dev loss: 2.8784990310668945
04/12/2022 17:52:17 - INFO - __main__ - global step: 4060; train loss: 3.549861192703247; dev loss: 3.280681610107422
04/12/2022 17:52:40 - INFO - __main__ - global step: 4070; train loss: 2.6575493812561035; dev loss: 2.7233166694641113
04/12/2022 17:53:02 - INFO - __main__ - global step: 4080; train loss: 2.7738230228424072; dev loss: 2.7238717079162598
04/12/2022 17:53:26 - INFO - __main__ - global step: 4090; train loss: 3.0683791637420654; dev loss: 3.0742437839508057
04/12/2022 17:53:50 - INFO - __main__ - global step: 4100; train loss: 3.2962918281555176; dev loss: 3.306849718093872
04/12/2022 17:54:14 - INFO - __main__ - global step: 4110; train loss: 3.2774932384490967; dev loss: 3.437648057937622
04/12/2022 17:54:37 - INFO - __main__ - global step: 4120; train loss: 2.838733196258545; dev loss: 2.870434284210205
04/12/2022 17:55:01 - INFO - __main__ - global step: 4130; train loss: 3.656799793243408; dev loss: 3.708826780319214
04/12/2022 17:55:25 - INFO - __main__ - global step: 4140; train loss: 3.0713882446289062; dev loss: 3.243056535720825
04/12/2022 17:55:48 - INFO - __main__ - global step: 4150; train loss: 3.122584819793701; dev loss: 2.984868049621582
04/12/2022 17:56:12 - INFO - __main__ - global step: 4160; train loss: 2.9861176013946533; dev loss: 3.133340358734131
04/12/2022 17:56:35 - INFO - __main__ - global step: 4170; train loss: 3.1662087440490723; dev loss: 3.244563341140747
04/12/2022 17:56:59 - INFO - __main__ - global step: 4180; train loss: 2.675191879272461; dev loss: 2.50502347946167
04/12/2022 17:57:22 - INFO - __main__ - global step: 4190; train loss: 3.3584492206573486; dev loss: 3.116807460784912
04/12/2022 17:57:46 - INFO - __main__ - global step: 4200; train loss: 3.4726366996765137; dev loss: 3.306239604949951
04/12/2022 17:58:09 - INFO - __main__ - global step: 4210; train loss: 2.777179002761841; dev loss: 2.8132987022399902
04/12/2022 17:58:33 - INFO - __main__ - global step: 4220; train loss: 2.7323644161224365; dev loss: 3.3329460620880127
04/12/2022 17:58:56 - INFO - __main__ - global step: 4230; train loss: 2.718121290206909; dev loss: 2.6173155307769775
04/12/2022 17:59:20 - INFO - __main__ - global step: 4240; train loss: 3.0577054023742676; dev loss: 3.1910243034362793
04/12/2022 17:59:43 - INFO - __main__ - global step: 4250; train loss: 2.893373489379883; dev loss: 2.610135555267334
04/12/2022 18:00:06 - INFO - __main__ - global step: 4260; train loss: 3.3196167945861816; dev loss: 3.2255072593688965
04/12/2022 18:00:29 - INFO - __main__ - global step: 4270; train loss: 3.245924472808838; dev loss: 3.2068190574645996
04/12/2022 18:00:53 - INFO - __main__ - global step: 4280; train loss: 2.9011528491973877; dev loss: 2.8805949687957764
04/12/2022 18:01:15 - INFO - __main__ - global step: 4290; train loss: 2.9890999794006348; dev loss: 3.279144287109375
04/12/2022 18:01:39 - INFO - __main__ - global step: 4300; train loss: 3.7420754432678223; dev loss: 3.5389010906219482
04/12/2022 18:02:02 - INFO - __main__ - global step: 4310; train loss: 2.8805184364318848; dev loss: 2.9498257637023926
04/12/2022 18:02:25 - INFO - __main__ - global step: 4320; train loss: 3.076354503631592; dev loss: 3.3687281608581543
04/12/2022 18:02:48 - INFO - __main__ - global step: 4330; train loss: 2.7327044010162354; dev loss: 2.6852355003356934
04/12/2022 18:03:12 - INFO - __main__ - global step: 4340; train loss: 3.0065078735351562; dev loss: 3.04833722114563
04/12/2022 18:03:35 - INFO - __main__ - global step: 4350; train loss: 2.9749045372009277; dev loss: 2.9867563247680664
04/12/2022 18:03:59 - INFO - __main__ - global step: 4360; train loss: 2.6798408031463623; dev loss: 2.7498748302459717
04/12/2022 18:04:22 - INFO - __main__ - global step: 4370; train loss: 2.4352755546569824; dev loss: 2.614332437515259
04/12/2022 18:04:47 - INFO - __main__ - global step: 4380; train loss: 3.0202574729919434; dev loss: 3.028684377670288
04/12/2022 18:05:11 - INFO - __main__ - global step: 4390; train loss: 3.00984525680542; dev loss: 3.18377423286438
04/12/2022 18:05:35 - INFO - __main__ - global step: 4400; train loss: 2.689506769180298; dev loss: 2.9029908180236816
04/12/2022 18:05:58 - INFO - __main__ - global step: 4410; train loss: 2.4658780097961426; dev loss: 2.498919725418091
04/12/2022 18:06:22 - INFO - __main__ - global step: 4420; train loss: 2.823702573776245; dev loss: 3.0262792110443115
04/12/2022 18:06:46 - INFO - __main__ - global step: 4430; train loss: 3.172163963317871; dev loss: 3.199331521987915
04/12/2022 18:07:11 - INFO - __main__ - global step: 4440; train loss: 3.2800822257995605; dev loss: 3.339442014694214
04/12/2022 18:07:35 - INFO - __main__ - global step: 4450; train loss: 3.2448368072509766; dev loss: 3.2595877647399902
04/12/2022 18:07:58 - INFO - __main__ - global step: 4460; train loss: 3.16569185256958; dev loss: 3.0550618171691895
04/12/2022 18:08:21 - INFO - __main__ - global step: 4470; train loss: 2.490874767303467; dev loss: 2.469658613204956
04/12/2022 18:08:45 - INFO - __main__ - global step: 4480; train loss: 3.200371265411377; dev loss: 2.887535572052002
04/12/2022 18:09:08 - INFO - __main__ - global step: 4490; train loss: 2.6903436183929443; dev loss: 2.618924856185913
04/12/2022 18:09:32 - INFO - __main__ - global step: 4500; train loss: 3.011199712753296; dev loss: 3.0270638465881348
04/12/2022 18:09:55 - INFO - __main__ - global step: 4510; train loss: 3.167691707611084; dev loss: 3.1444952487945557
04/12/2022 18:10:18 - INFO - __main__ - global step: 4520; train loss: 3.3184173107147217; dev loss: 3.4339489936828613
04/12/2022 18:10:43 - INFO - __main__ - global step: 4530; train loss: 2.7598910331726074; dev loss: 2.8612260818481445
04/12/2022 18:11:07 - INFO - __main__ - global step: 4540; train loss: 2.7519071102142334; dev loss: 2.620439291000366
04/12/2022 18:11:30 - INFO - __main__ - global step: 4550; train loss: 2.6845126152038574; dev loss: 2.6033411026000977
04/12/2022 18:11:53 - INFO - __main__ - global step: 4560; train loss: 3.427149534225464; dev loss: 2.9920623302459717
04/12/2022 18:12:17 - INFO - __main__ - global step: 4570; train loss: 2.6667988300323486; dev loss: 2.815838575363159
04/12/2022 18:12:41 - INFO - __main__ - global step: 4580; train loss: 2.879490375518799; dev loss: 2.7335164546966553
04/12/2022 18:13:05 - INFO - __main__ - global step: 4590; train loss: 2.8339860439300537; dev loss: 2.573650598526001
04/12/2022 18:13:29 - INFO - __main__ - global step: 4600; train loss: 2.7426767349243164; dev loss: 3.0560312271118164
04/12/2022 18:13:53 - INFO - __main__ - global step: 4610; train loss: 3.2922749519348145; dev loss: 3.1115219593048096
04/12/2022 18:14:17 - INFO - __main__ - global step: 4620; train loss: 3.0968968868255615; dev loss: 2.971540689468384
04/12/2022 18:14:42 - INFO - __main__ - global step: 4630; train loss: 2.6134889125823975; dev loss: 2.731724262237549
04/12/2022 18:15:05 - INFO - __main__ - global step: 4640; train loss: 3.415119171142578; dev loss: 3.399829387664795
04/12/2022 18:15:28 - INFO - __main__ - global step: 4650; train loss: 3.160301923751831; dev loss: 3.054121732711792
04/12/2022 18:15:51 - INFO - __main__ - global step: 4660; train loss: 2.8264060020446777; dev loss: 2.8815057277679443
04/12/2022 18:16:15 - INFO - __main__ - global step: 4670; train loss: 2.48897647857666; dev loss: 2.49177885055542
04/12/2022 18:16:39 - INFO - __main__ - global step: 4680; train loss: 2.778557300567627; dev loss: 2.574209451675415
04/12/2022 18:17:03 - INFO - __main__ - global step: 4690; train loss: 2.920854091644287; dev loss: 3.065054416656494
04/12/2022 18:17:27 - INFO - __main__ - global step: 4700; train loss: 3.2485873699188232; dev loss: 2.9505224227905273
04/12/2022 18:17:50 - INFO - __main__ - global step: 4710; train loss: 2.7907214164733887; dev loss: 2.88765549659729
04/12/2022 18:18:14 - INFO - __main__ - global step: 4720; train loss: 2.4901528358459473; dev loss: 2.344045639038086
04/12/2022 18:18:38 - INFO - __main__ - global step: 4730; train loss: 3.2750027179718018; dev loss: 3.1021788120269775
04/12/2022 18:19:01 - INFO - __main__ - global step: 4740; train loss: 3.0550031661987305; dev loss: 3.0345921516418457
04/12/2022 18:19:24 - INFO - __main__ - global step: 4750; train loss: 2.7674264907836914; dev loss: 2.611185073852539
04/12/2022 18:19:48 - INFO - __main__ - global step: 4760; train loss: 2.5587992668151855; dev loss: 2.574769973754883
04/12/2022 18:20:12 - INFO - __main__ - global step: 4770; train loss: 3.2365126609802246; dev loss: 3.157210111618042
04/12/2022 18:20:37 - INFO - __main__ - global step: 4780; train loss: 2.9440648555755615; dev loss: 3.1160807609558105
04/12/2022 18:21:00 - INFO - __main__ - global step: 4790; train loss: 2.787360191345215; dev loss: 2.7156176567077637
04/12/2022 18:21:23 - INFO - __main__ - global step: 4800; train loss: 2.8310961723327637; dev loss: 2.856478214263916
04/12/2022 18:21:47 - INFO - __main__ - global step: 4810; train loss: 3.5004730224609375; dev loss: 3.3645012378692627
04/12/2022 18:22:11 - INFO - __main__ - global step: 4820; train loss: 2.9568512439727783; dev loss: 3.081829071044922
04/12/2022 18:22:34 - INFO - __main__ - global step: 4830; train loss: 3.256118059158325; dev loss: 3.4609973430633545
04/12/2022 18:22:58 - INFO - __main__ - global step: 4840; train loss: 2.945098400115967; dev loss: 2.9646975994110107
04/12/2022 18:23:22 - INFO - __main__ - global step: 4850; train loss: 2.8307909965515137; dev loss: 2.644369125366211
04/12/2022 18:23:46 - INFO - __main__ - global step: 4860; train loss: 3.0022618770599365; dev loss: 2.7711915969848633
04/12/2022 18:24:10 - INFO - __main__ - global step: 4870; train loss: 2.8748998641967773; dev loss: 2.6316730976104736
04/12/2022 18:24:34 - INFO - __main__ - global step: 4880; train loss: 3.0750882625579834; dev loss: 2.958265542984009
04/12/2022 18:24:59 - INFO - __main__ - global step: 4890; train loss: 3.24292254447937; dev loss: 3.0224716663360596
04/12/2022 18:25:23 - INFO - __main__ - global step: 4900; train loss: 2.6605117321014404; dev loss: 3.0098156929016113
04/12/2022 18:25:46 - INFO - __main__ - global step: 4910; train loss: 2.468832015991211; dev loss: 2.4156811237335205
04/12/2022 18:26:09 - INFO - __main__ - global step: 4920; train loss: 3.20184588432312; dev loss: 3.008767604827881
04/12/2022 18:26:33 - INFO - __main__ - global step: 4930; train loss: 2.826289415359497; dev loss: 2.9785091876983643
04/12/2022 18:26:58 - INFO - __main__ - global step: 4940; train loss: 2.5162696838378906; dev loss: 3.087334156036377
04/12/2022 18:27:23 - INFO - __main__ - global step: 4950; train loss: 2.823303699493408; dev loss: 2.93670654296875
04/12/2022 18:27:47 - INFO - __main__ - global step: 4960; train loss: 2.6599512100219727; dev loss: 2.774324893951416
04/12/2022 18:28:11 - INFO - __main__ - global step: 4970; train loss: 2.9805245399475098; dev loss: 2.7802798748016357
04/12/2022 18:28:35 - INFO - __main__ - global step: 4980; train loss: 2.857288360595703; dev loss: 2.870917558670044
04/12/2022 18:28:59 - INFO - __main__ - global step: 4990; train loss: 2.990795850753784; dev loss: 3.183971643447876
04/12/2022 18:29:22 - INFO - __main__ - global step: 5000; train loss: 3.182985782623291; dev loss: 3.056398391723633
04/12/2022 18:29:22 - INFO - __main__ - save model!
