04/06/2022 14:10:51 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=False, bsz_list=[4], cache_dir='/data/qin/cache/', checkpoint='None', cuda='4', dataset='nlp_forest_single', debug=False, dev_file='data', do_lowercase=False, do_predict=True, do_train=True, eval_period=50, freeze_embeds=False, gradient_accumulation_steps=2, identifier='T5-large-maml-noqa2qa-3e-5-2-5000-5e-1', learning_rate=0.5, learning_rate_list=[0.5], lm_adapted_path='/data/qin/lm_adapted_t5model/torch_ckpt/large/pytorch_model.bin', local_rank=0, log_step=10, max_grad_norm=1.0, max_input_length=512, max_output_length=128, model='google/t5-v1_1-large', num_beams=4, num_train_epochs=1000.0, output_dir='models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-wino_grande', predict_batch_size=16, predict_checkpoint='best-model.pt', prefix='', prompt_number=100, quiet=False, seed=42, task_dir='data/wino_grande/', task_name='wino_grande', test_file='data', total_steps=3000, train_batch_size=4, train_file='data', wait_step=10000000000, warmup_steps=50, weight_decay=1e-05)
04/06/2022 14:10:51 - INFO - __main__ - models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-wino_grande
04/28/2022 05:13:00 - INFO - __main__ - Namespace(task_dir='data/wino_grande/', task_name='wino_grande', identifier='T5-large-maml-noqa2qa-3e-5-2-5000-5e-1', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-wino_grande', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-maml-noqa2qa-3e-5-2-5000-5e-1/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='0,1')
04/28/2022 05:13:00 - INFO - __main__ - models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-wino_grande
04/28/2022 05:13:00 - INFO - __main__ - Namespace(task_dir='data/wino_grande/', task_name='wino_grande', identifier='T5-large-maml-noqa2qa-3e-5-2-5000-5e-1', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-wino_grande', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-maml-noqa2qa-3e-5-2-5000-5e-1/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='0,1')
04/28/2022 05:13:00 - INFO - __main__ - models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-wino_grande
04/28/2022 05:13:02 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
04/28/2022 05:13:02 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
04/28/2022 05:13:02 - INFO - __main__ - args.device: cuda:0
04/28/2022 05:13:02 - INFO - __main__ - args.device: cuda:1
04/28/2022 05:13:02 - INFO - __main__ - Using 2 gpus
04/28/2022 05:13:02 - INFO - __main__ - Using 2 gpus
04/28/2022 05:13:02 - INFO - __main__ - Fine-tuning the following samples: ['wino_grande_32_100', 'wino_grande_32_13', 'wino_grande_32_21', 'wino_grande_32_42', 'wino_grande_32_87']
04/28/2022 05:13:02 - INFO - __main__ - Fine-tuning the following samples: ['wino_grande_32_100', 'wino_grande_32_13', 'wino_grande_32_21', 'wino_grande_32_42', 'wino_grande_32_87']
04/28/2022 05:13:07 - INFO - __main__ - Running ... prefix=wino_grande_32_100, lr=0.5, bsz=8 ...
04/28/2022 05:13:08 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 05:13:08 - INFO - __main__ - Printing 3 examples
04/28/2022 05:13:08 - INFO - __main__ -  [wino_grande] Craig volunteered to help the dyslexic students at the school while Joel avoided them, since _ struggled with reading. (A) Craig (B) Joel
04/28/2022 05:13:08 - INFO - __main__ - ['Joel']
04/28/2022 05:13:08 - INFO - __main__ -  [wino_grande] Betty projects much more happiness than Amy, _ because/although she smiles a lot more often. (A) Betty (B) Amy
04/28/2022 05:13:08 - INFO - __main__ - ['Betty']
04/28/2022 05:13:08 - INFO - __main__ -  [wino_grande] Kevin confidently told Jason that his engraving business was going to make him rich.  _ was skeptical. (A) Kevin (B) Jason
04/28/2022 05:13:08 - INFO - __main__ - ['Jason']
04/28/2022 05:13:08 - INFO - __main__ - Tokenizing Input ...
04/28/2022 05:13:08 - INFO - __main__ - Tokenizing Output ...
04/28/2022 05:13:08 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 05:13:08 - INFO - __main__ - Printing 3 examples
04/28/2022 05:13:08 - INFO - __main__ -  [wino_grande] Craig volunteered to help the dyslexic students at the school while Joel avoided them, since _ struggled with reading. (A) Craig (B) Joel
04/28/2022 05:13:08 - INFO - __main__ - ['Joel']
04/28/2022 05:13:08 - INFO - __main__ -  [wino_grande] Betty projects much more happiness than Amy, _ because/although she smiles a lot more often. (A) Betty (B) Amy
04/28/2022 05:13:08 - INFO - __main__ - ['Betty']
04/28/2022 05:13:08 - INFO - __main__ -  [wino_grande] Kevin confidently told Jason that his engraving business was going to make him rich.  _ was skeptical. (A) Kevin (B) Jason
04/28/2022 05:13:08 - INFO - __main__ - ['Jason']
04/28/2022 05:13:08 - INFO - __main__ - Tokenizing Input ...
04/28/2022 05:13:08 - INFO - __main__ - Tokenizing Output ...
04/28/2022 05:13:08 - INFO - __main__ - Loaded 32 examples from train data
04/28/2022 05:13:08 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 05:13:08 - INFO - __main__ - Printing 3 examples
04/28/2022 05:13:08 - INFO - __main__ -  [wino_grande] Lindsey was more excited than Laura about having a gender reveal party for the baby. _ thought they were adorable. (A) Lindsey (B) Laura
04/28/2022 05:13:08 - INFO - __main__ - ['Lindsey']
04/28/2022 05:13:08 - INFO - __main__ -  [wino_grande] She liked the style of the shoes far more than the pants, because the _ looked gaudy. (A) pants (B) shoes
04/28/2022 05:13:08 - INFO - __main__ - ['pants']
04/28/2022 05:13:08 - INFO - __main__ -  [wino_grande] Julie's foot would not fit into her new pair of cowboy boots she just bought, the _ was too narrow. (A) boot (B) foot
04/28/2022 05:13:08 - INFO - __main__ - ['boot']
04/28/2022 05:13:08 - INFO - __main__ - Tokenizing Input ...
04/28/2022 05:13:08 - INFO - __main__ - Loaded 32 examples from train data
04/28/2022 05:13:08 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 05:13:08 - INFO - __main__ - Printing 3 examples
04/28/2022 05:13:08 - INFO - __main__ -  [wino_grande] Lindsey was more excited than Laura about having a gender reveal party for the baby. _ thought they were adorable. (A) Lindsey (B) Laura
04/28/2022 05:13:08 - INFO - __main__ - ['Lindsey']
04/28/2022 05:13:08 - INFO - __main__ -  [wino_grande] She liked the style of the shoes far more than the pants, because the _ looked gaudy. (A) pants (B) shoes
04/28/2022 05:13:08 - INFO - __main__ - ['pants']
04/28/2022 05:13:08 - INFO - __main__ - Tokenizing Output ...
04/28/2022 05:13:08 - INFO - __main__ -  [wino_grande] Julie's foot would not fit into her new pair of cowboy boots she just bought, the _ was too narrow. (A) boot (B) foot
04/28/2022 05:13:08 - INFO - __main__ - ['boot']
04/28/2022 05:13:08 - INFO - __main__ - Tokenizing Input ...
04/28/2022 05:13:08 - INFO - __main__ - Tokenizing Output ...
04/28/2022 05:13:08 - INFO - __main__ - Loaded 32 examples from dev data
04/28/2022 05:13:08 - INFO - __main__ - Loaded 32 examples from dev data
04/28/2022 05:13:25 - INFO - __main__ - load prompt embedding from ckpt
04/28/2022 05:13:25 - INFO - __main__ - load prompt embedding from ckpt
04/28/2022 05:13:26 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/28/2022 05:13:26 - INFO - __main__ - Starting training!
04/28/2022 05:13:31 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/28/2022 05:13:31 - INFO - __main__ - Starting training!
04/28/2022 05:13:34 - INFO - __main__ - Step 10 Global step 10 Train loss 3.19 on epoch=4
04/28/2022 05:13:37 - INFO - __main__ - Step 20 Global step 20 Train loss 1.03 on epoch=9
04/28/2022 05:13:39 - INFO - __main__ - Step 30 Global step 30 Train loss 1.03 on epoch=14
04/28/2022 05:13:42 - INFO - __main__ - Step 40 Global step 40 Train loss 0.92 on epoch=19
04/28/2022 05:13:44 - INFO - __main__ - Step 50 Global step 50 Train loss 0.42 on epoch=24
04/28/2022 05:13:45 - INFO - __main__ - Global step 50 Train loss 1.31 ACC 0.4375 on epoch=24
04/28/2022 05:13:45 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.4375 on epoch=24, global_step=50
04/28/2022 05:13:47 - INFO - __main__ - Step 60 Global step 60 Train loss 0.43 on epoch=29
04/28/2022 05:13:50 - INFO - __main__ - Step 70 Global step 70 Train loss 0.48 on epoch=34
04/28/2022 05:13:52 - INFO - __main__ - Step 80 Global step 80 Train loss 0.35 on epoch=39
04/28/2022 05:13:55 - INFO - __main__ - Step 90 Global step 90 Train loss 0.26 on epoch=44
04/28/2022 05:13:57 - INFO - __main__ - Step 100 Global step 100 Train loss 0.15 on epoch=49
04/28/2022 05:13:58 - INFO - __main__ - Global step 100 Train loss 0.33 ACC 0.46875 on epoch=49
04/28/2022 05:13:58 - INFO - __main__ - Saving model with best ACC: 0.4375 -> 0.46875 on epoch=49, global_step=100
04/28/2022 05:14:00 - INFO - __main__ - Step 110 Global step 110 Train loss 0.20 on epoch=54
04/28/2022 05:14:03 - INFO - __main__ - Step 120 Global step 120 Train loss 0.14 on epoch=59
04/28/2022 05:14:05 - INFO - __main__ - Step 130 Global step 130 Train loss 0.06 on epoch=64
04/28/2022 05:14:08 - INFO - __main__ - Step 140 Global step 140 Train loss 0.17 on epoch=69
04/28/2022 05:14:10 - INFO - __main__ - Step 150 Global step 150 Train loss 0.13 on epoch=74
04/28/2022 05:14:11 - INFO - __main__ - Global step 150 Train loss 0.14 ACC 0.4375 on epoch=74
04/28/2022 05:14:13 - INFO - __main__ - Step 160 Global step 160 Train loss 0.08 on epoch=79
04/28/2022 05:14:16 - INFO - __main__ - Step 170 Global step 170 Train loss 0.08 on epoch=84
04/28/2022 05:14:18 - INFO - __main__ - Step 180 Global step 180 Train loss 0.09 on epoch=89
04/28/2022 05:14:21 - INFO - __main__ - Step 190 Global step 190 Train loss 0.03 on epoch=94
04/28/2022 05:14:23 - INFO - __main__ - Step 200 Global step 200 Train loss 0.03 on epoch=99
04/28/2022 05:14:24 - INFO - __main__ - Global step 200 Train loss 0.06 ACC 0.5 on epoch=99
04/28/2022 05:14:24 - INFO - __main__ - Saving model with best ACC: 0.46875 -> 0.5 on epoch=99, global_step=200
04/28/2022 05:14:26 - INFO - __main__ - Step 210 Global step 210 Train loss 0.05 on epoch=104
04/28/2022 05:14:29 - INFO - __main__ - Step 220 Global step 220 Train loss 0.07 on epoch=109
04/28/2022 05:14:31 - INFO - __main__ - Step 230 Global step 230 Train loss 0.45 on epoch=114
04/28/2022 05:14:34 - INFO - __main__ - Step 240 Global step 240 Train loss 1.22 on epoch=119
04/28/2022 05:14:36 - INFO - __main__ - Step 250 Global step 250 Train loss 0.43 on epoch=124
04/28/2022 05:14:37 - INFO - __main__ - Global step 250 Train loss 0.44 ACC 0.40625 on epoch=124
04/28/2022 05:14:39 - INFO - __main__ - Step 260 Global step 260 Train loss 0.15 on epoch=129
04/28/2022 05:14:42 - INFO - __main__ - Step 270 Global step 270 Train loss 0.07 on epoch=134
04/28/2022 05:14:44 - INFO - __main__ - Step 280 Global step 280 Train loss 0.05 on epoch=139
04/28/2022 05:14:47 - INFO - __main__ - Step 290 Global step 290 Train loss 0.09 on epoch=144
04/28/2022 05:14:49 - INFO - __main__ - Step 300 Global step 300 Train loss 0.11 on epoch=149
04/28/2022 05:14:50 - INFO - __main__ - Global step 300 Train loss 0.09 ACC 0.46875 on epoch=149
04/28/2022 05:14:52 - INFO - __main__ - Step 310 Global step 310 Train loss 0.05 on epoch=154
04/28/2022 05:14:55 - INFO - __main__ - Step 320 Global step 320 Train loss 0.04 on epoch=159
04/28/2022 05:14:57 - INFO - __main__ - Step 330 Global step 330 Train loss 0.02 on epoch=164
04/28/2022 05:15:00 - INFO - __main__ - Step 340 Global step 340 Train loss 0.03 on epoch=169
04/28/2022 05:15:02 - INFO - __main__ - Step 350 Global step 350 Train loss 0.08 on epoch=174
04/28/2022 05:15:03 - INFO - __main__ - Global step 350 Train loss 0.04 ACC 0.5 on epoch=174
04/28/2022 05:15:05 - INFO - __main__ - Step 360 Global step 360 Train loss 0.03 on epoch=179
04/28/2022 05:15:08 - INFO - __main__ - Step 370 Global step 370 Train loss 0.05 on epoch=184
04/28/2022 05:15:10 - INFO - __main__ - Step 380 Global step 380 Train loss 0.07 on epoch=189
04/28/2022 05:15:13 - INFO - __main__ - Step 390 Global step 390 Train loss 0.04 on epoch=194
04/28/2022 05:15:15 - INFO - __main__ - Step 400 Global step 400 Train loss 0.15 on epoch=199
04/28/2022 05:15:16 - INFO - __main__ - Global step 400 Train loss 0.07 ACC 0.5 on epoch=199
04/28/2022 05:15:19 - INFO - __main__ - Step 410 Global step 410 Train loss 0.03 on epoch=204
04/28/2022 05:15:21 - INFO - __main__ - Step 420 Global step 420 Train loss 0.02 on epoch=209
04/28/2022 05:15:23 - INFO - __main__ - Step 430 Global step 430 Train loss 0.01 on epoch=214
04/28/2022 05:15:26 - INFO - __main__ - Step 440 Global step 440 Train loss 0.04 on epoch=219
04/28/2022 05:15:28 - INFO - __main__ - Step 450 Global step 450 Train loss 0.03 on epoch=224
04/28/2022 05:15:29 - INFO - __main__ - Global step 450 Train loss 0.03 ACC 0.5 on epoch=224
04/28/2022 05:15:31 - INFO - __main__ - Step 460 Global step 460 Train loss 0.02 on epoch=229
04/28/2022 05:15:34 - INFO - __main__ - Step 470 Global step 470 Train loss 0.03 on epoch=234
04/28/2022 05:15:36 - INFO - __main__ - Step 480 Global step 480 Train loss 0.12 on epoch=239
04/28/2022 05:15:39 - INFO - __main__ - Step 490 Global step 490 Train loss 0.04 on epoch=244
04/28/2022 05:15:41 - INFO - __main__ - Step 500 Global step 500 Train loss 0.04 on epoch=249
04/28/2022 05:15:42 - INFO - __main__ - Global step 500 Train loss 0.05 ACC 0.5 on epoch=249
04/28/2022 05:15:45 - INFO - __main__ - Step 510 Global step 510 Train loss 0.01 on epoch=254
04/28/2022 05:15:47 - INFO - __main__ - Step 520 Global step 520 Train loss 0.02 on epoch=259
04/28/2022 05:15:50 - INFO - __main__ - Step 530 Global step 530 Train loss 0.01 on epoch=264
04/28/2022 05:15:52 - INFO - __main__ - Step 540 Global step 540 Train loss 0.03 on epoch=269
04/28/2022 05:15:54 - INFO - __main__ - Step 550 Global step 550 Train loss 0.01 on epoch=274
04/28/2022 05:15:55 - INFO - __main__ - Global step 550 Train loss 0.02 ACC 0.4375 on epoch=274
04/28/2022 05:15:58 - INFO - __main__ - Step 560 Global step 560 Train loss 0.02 on epoch=279
04/28/2022 05:16:00 - INFO - __main__ - Step 570 Global step 570 Train loss 0.02 on epoch=284
04/28/2022 05:16:02 - INFO - __main__ - Step 580 Global step 580 Train loss 0.02 on epoch=289
04/28/2022 05:16:05 - INFO - __main__ - Step 590 Global step 590 Train loss 0.03 on epoch=294
04/28/2022 05:16:07 - INFO - __main__ - Step 600 Global step 600 Train loss 0.01 on epoch=299
04/28/2022 05:16:08 - INFO - __main__ - Global step 600 Train loss 0.02 ACC 0.46875 on epoch=299
04/28/2022 05:16:11 - INFO - __main__ - Step 610 Global step 610 Train loss 0.03 on epoch=304
04/28/2022 05:16:13 - INFO - __main__ - Step 620 Global step 620 Train loss 0.01 on epoch=309
04/28/2022 05:16:15 - INFO - __main__ - Step 630 Global step 630 Train loss 0.01 on epoch=314
04/28/2022 05:16:18 - INFO - __main__ - Step 640 Global step 640 Train loss 0.00 on epoch=319
04/28/2022 05:16:20 - INFO - __main__ - Step 650 Global step 650 Train loss 0.00 on epoch=324
04/28/2022 05:16:21 - INFO - __main__ - Global step 650 Train loss 0.01 ACC 0.4375 on epoch=324
04/28/2022 05:16:24 - INFO - __main__ - Step 660 Global step 660 Train loss 0.01 on epoch=329
04/28/2022 05:16:26 - INFO - __main__ - Step 670 Global step 670 Train loss 0.01 on epoch=334
04/28/2022 05:16:28 - INFO - __main__ - Step 680 Global step 680 Train loss 0.00 on epoch=339
04/28/2022 05:16:31 - INFO - __main__ - Step 690 Global step 690 Train loss 0.02 on epoch=344
04/28/2022 05:16:33 - INFO - __main__ - Step 700 Global step 700 Train loss 0.00 on epoch=349
04/28/2022 05:16:34 - INFO - __main__ - Global step 700 Train loss 0.01 ACC 0.4375 on epoch=349
04/28/2022 05:16:37 - INFO - __main__ - Step 710 Global step 710 Train loss 0.02 on epoch=354
04/28/2022 05:16:39 - INFO - __main__ - Step 720 Global step 720 Train loss 0.01 on epoch=359
04/28/2022 05:16:42 - INFO - __main__ - Step 730 Global step 730 Train loss 0.00 on epoch=364
04/28/2022 05:16:44 - INFO - __main__ - Step 740 Global step 740 Train loss 0.03 on epoch=369
04/28/2022 05:16:47 - INFO - __main__ - Step 750 Global step 750 Train loss 0.09 on epoch=374
04/28/2022 05:16:47 - INFO - __main__ - Global step 750 Train loss 0.03 ACC 0.4375 on epoch=374
04/28/2022 05:16:50 - INFO - __main__ - Step 760 Global step 760 Train loss 0.09 on epoch=379
04/28/2022 05:16:52 - INFO - __main__ - Step 770 Global step 770 Train loss 0.04 on epoch=384
04/28/2022 05:16:55 - INFO - __main__ - Step 780 Global step 780 Train loss 0.00 on epoch=389
04/28/2022 05:16:57 - INFO - __main__ - Step 790 Global step 790 Train loss 0.08 on epoch=394
04/28/2022 05:17:00 - INFO - __main__ - Step 800 Global step 800 Train loss 0.03 on epoch=399
04/28/2022 05:17:00 - INFO - __main__ - Global step 800 Train loss 0.05 ACC 0.4375 on epoch=399
04/28/2022 05:17:03 - INFO - __main__ - Step 810 Global step 810 Train loss 0.01 on epoch=404
04/28/2022 05:17:05 - INFO - __main__ - Step 820 Global step 820 Train loss 0.00 on epoch=409
04/28/2022 05:17:08 - INFO - __main__ - Step 830 Global step 830 Train loss 0.01 on epoch=414
04/28/2022 05:17:10 - INFO - __main__ - Step 840 Global step 840 Train loss 0.01 on epoch=419
04/28/2022 05:17:13 - INFO - __main__ - Step 850 Global step 850 Train loss 0.06 on epoch=424
04/28/2022 05:17:13 - INFO - __main__ - Global step 850 Train loss 0.02 ACC 0.4375 on epoch=424
04/28/2022 05:17:16 - INFO - __main__ - Step 860 Global step 860 Train loss 0.02 on epoch=429
04/28/2022 05:17:18 - INFO - __main__ - Step 870 Global step 870 Train loss 0.01 on epoch=434
04/28/2022 05:17:21 - INFO - __main__ - Step 880 Global step 880 Train loss 0.01 on epoch=439
04/28/2022 05:17:23 - INFO - __main__ - Step 890 Global step 890 Train loss 0.00 on epoch=444
04/28/2022 05:17:26 - INFO - __main__ - Step 900 Global step 900 Train loss 0.01 on epoch=449
04/28/2022 05:17:27 - INFO - __main__ - Global step 900 Train loss 0.01 ACC 0.5 on epoch=449
04/28/2022 05:17:29 - INFO - __main__ - Step 910 Global step 910 Train loss 0.00 on epoch=454
04/28/2022 05:17:31 - INFO - __main__ - Step 920 Global step 920 Train loss 0.02 on epoch=459
04/28/2022 05:17:34 - INFO - __main__ - Step 930 Global step 930 Train loss 0.02 on epoch=464
04/28/2022 05:17:36 - INFO - __main__ - Step 940 Global step 940 Train loss 0.03 on epoch=469
04/28/2022 05:17:39 - INFO - __main__ - Step 950 Global step 950 Train loss 0.00 on epoch=474
04/28/2022 05:17:40 - INFO - __main__ - Global step 950 Train loss 0.01 ACC 0.4375 on epoch=474
04/28/2022 05:17:42 - INFO - __main__ - Step 960 Global step 960 Train loss 0.00 on epoch=479
04/28/2022 05:17:44 - INFO - __main__ - Step 970 Global step 970 Train loss 0.00 on epoch=484
04/28/2022 05:17:47 - INFO - __main__ - Step 980 Global step 980 Train loss 0.03 on epoch=489
04/28/2022 05:17:50 - INFO - __main__ - Step 990 Global step 990 Train loss 0.01 on epoch=494
04/28/2022 05:17:52 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.00 on epoch=499
04/28/2022 05:17:53 - INFO - __main__ - Global step 1000 Train loss 0.01 ACC 0.4375 on epoch=499
04/28/2022 05:17:55 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.01 on epoch=504
04/28/2022 05:17:58 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.00 on epoch=509
04/28/2022 05:18:00 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.03 on epoch=514
04/28/2022 05:18:03 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.01 on epoch=519
04/28/2022 05:18:05 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.00 on epoch=524
04/28/2022 05:18:06 - INFO - __main__ - Global step 1050 Train loss 0.01 ACC 0.46875 on epoch=524
04/28/2022 05:18:08 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.00 on epoch=529
04/28/2022 05:18:11 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.00 on epoch=534
04/28/2022 05:18:13 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.02 on epoch=539
04/28/2022 05:18:16 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.00 on epoch=544
04/28/2022 05:18:18 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.00 on epoch=549
04/28/2022 05:18:19 - INFO - __main__ - Global step 1100 Train loss 0.01 ACC 0.46875 on epoch=549
04/28/2022 05:18:21 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.00 on epoch=554
04/28/2022 05:18:24 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=559
04/28/2022 05:18:26 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=564
04/28/2022 05:18:29 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.01 on epoch=569
04/28/2022 05:18:31 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.00 on epoch=574
04/28/2022 05:18:32 - INFO - __main__ - Global step 1150 Train loss 0.00 ACC 0.4375 on epoch=574
04/28/2022 05:18:34 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.00 on epoch=579
04/28/2022 05:18:37 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.00 on epoch=584
04/28/2022 05:18:39 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.01 on epoch=589
04/28/2022 05:18:42 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.00 on epoch=594
04/28/2022 05:18:44 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.00 on epoch=599
04/28/2022 05:18:45 - INFO - __main__ - Global step 1200 Train loss 0.00 ACC 0.46875 on epoch=599
04/28/2022 05:18:48 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.00 on epoch=604
04/28/2022 05:18:50 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.00 on epoch=609
04/28/2022 05:18:53 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.00 on epoch=614
04/28/2022 05:18:55 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.00 on epoch=619
04/28/2022 05:18:58 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.07 on epoch=624
04/28/2022 05:18:58 - INFO - __main__ - Global step 1250 Train loss 0.02 ACC 0.46875 on epoch=624
04/28/2022 05:19:01 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=629
04/28/2022 05:19:03 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.00 on epoch=634
04/28/2022 05:19:06 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=639
04/28/2022 05:19:08 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.00 on epoch=644
04/28/2022 05:19:11 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=649
04/28/2022 05:19:11 - INFO - __main__ - Global step 1300 Train loss 0.01 ACC 0.46875 on epoch=649
04/28/2022 05:19:14 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.00 on epoch=654
04/28/2022 05:19:16 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.02 on epoch=659
04/28/2022 05:19:19 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.00 on epoch=664
04/28/2022 05:19:21 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.05 on epoch=669
04/28/2022 05:19:24 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.00 on epoch=674
04/28/2022 05:19:25 - INFO - __main__ - Global step 1350 Train loss 0.01 ACC 0.46875 on epoch=674
04/28/2022 05:19:27 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.00 on epoch=679
04/28/2022 05:19:30 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.00 on epoch=684
04/28/2022 05:19:32 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=689
04/28/2022 05:19:34 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.02 on epoch=694
04/28/2022 05:19:37 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.00 on epoch=699
04/28/2022 05:19:38 - INFO - __main__ - Global step 1400 Train loss 0.01 ACC 0.46875 on epoch=699
04/28/2022 05:19:40 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=704
04/28/2022 05:19:43 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=709
04/28/2022 05:19:45 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.00 on epoch=714
04/28/2022 05:19:47 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=719
04/28/2022 05:19:50 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=724
04/28/2022 05:19:51 - INFO - __main__ - Global step 1450 Train loss 0.00 ACC 0.46875 on epoch=724
04/28/2022 05:19:53 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=729
04/28/2022 05:19:56 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=734
04/28/2022 05:19:58 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=739
04/28/2022 05:20:01 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=744
04/28/2022 05:20:03 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=749
04/28/2022 05:20:04 - INFO - __main__ - Global step 1500 Train loss 0.00 ACC 0.46875 on epoch=749
04/28/2022 05:20:07 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=754
04/28/2022 05:20:09 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=759
04/28/2022 05:20:12 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.02 on epoch=764
04/28/2022 05:20:14 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=769
04/28/2022 05:20:17 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=774
04/28/2022 05:20:17 - INFO - __main__ - Global step 1550 Train loss 0.00 ACC 0.46875 on epoch=774
04/28/2022 05:20:20 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=779
04/28/2022 05:20:22 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=784
04/28/2022 05:20:25 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=789
04/28/2022 05:20:27 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=794
04/28/2022 05:20:30 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=799
04/28/2022 05:20:30 - INFO - __main__ - Global step 1600 Train loss 0.00 ACC 0.46875 on epoch=799
04/28/2022 05:20:33 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=804
04/28/2022 05:20:35 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=809
04/28/2022 05:20:38 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=814
04/28/2022 05:20:40 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.04 on epoch=819
04/28/2022 05:20:43 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=824
04/28/2022 05:20:44 - INFO - __main__ - Global step 1650 Train loss 0.01 ACC 0.5 on epoch=824
04/28/2022 05:20:46 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=829
04/28/2022 05:20:49 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=834
04/28/2022 05:20:51 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=839
04/28/2022 05:20:54 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=844
04/28/2022 05:20:56 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=849
04/28/2022 05:20:57 - INFO - __main__ - Global step 1700 Train loss 0.00 ACC 0.5 on epoch=849
04/28/2022 05:20:59 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=854
04/28/2022 05:21:02 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=859
04/28/2022 05:21:04 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=864
04/28/2022 05:21:07 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=869
04/28/2022 05:21:09 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=874
04/28/2022 05:21:10 - INFO - __main__ - Global step 1750 Train loss 0.01 ACC 0.46875 on epoch=874
04/28/2022 05:21:12 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=879
04/28/2022 05:21:15 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=884
04/28/2022 05:21:17 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=889
04/28/2022 05:21:20 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=894
04/28/2022 05:21:22 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=899
04/28/2022 05:21:23 - INFO - __main__ - Global step 1800 Train loss 0.00 ACC 0.53125 on epoch=899
04/28/2022 05:21:23 - INFO - __main__ - Saving model with best ACC: 0.5 -> 0.53125 on epoch=899, global_step=1800
04/28/2022 05:21:26 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=904
04/28/2022 05:21:28 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=909
04/28/2022 05:21:31 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=914
04/28/2022 05:21:33 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=919
04/28/2022 05:21:35 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=924
04/28/2022 05:21:36 - INFO - __main__ - Global step 1850 Train loss 0.00 ACC 0.46875 on epoch=924
04/28/2022 05:21:39 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=929
04/28/2022 05:21:41 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=934
04/28/2022 05:21:44 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=939
04/28/2022 05:21:46 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=944
04/28/2022 05:21:49 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=949
04/28/2022 05:21:49 - INFO - __main__ - Global step 1900 Train loss 0.00 ACC 0.46875 on epoch=949
04/28/2022 05:21:52 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=954
04/28/2022 05:21:54 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=959
04/28/2022 05:21:57 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=964
04/28/2022 05:21:59 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=969
04/28/2022 05:22:02 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=974
04/28/2022 05:22:03 - INFO - __main__ - Global step 1950 Train loss 0.00 ACC 0.46875 on epoch=974
04/28/2022 05:22:05 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=979
04/28/2022 05:22:08 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=984
04/28/2022 05:22:10 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=989
04/28/2022 05:22:13 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=994
04/28/2022 05:22:15 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=999
04/28/2022 05:22:16 - INFO - __main__ - Global step 2000 Train loss 0.00 ACC 0.5 on epoch=999
04/28/2022 05:22:16 - INFO - __main__ - save last model!
04/28/2022 05:22:16 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
04/28/2022 05:22:16 - INFO - __main__ - Start tokenizing ... 1000 instances
04/28/2022 05:22:16 - INFO - __main__ - Printing 3 examples
04/28/2022 05:22:16 - INFO - __main__ -  [wino_grande] Sarah was a much better surgeon than Maria so _ always got the easier cases. (A) Sarah (B) Maria
04/28/2022 05:22:16 - INFO - __main__ - ['Maria']
04/28/2022 05:22:16 - INFO - __main__ -  [wino_grande] Sarah was a much better surgeon than Maria so _ always got the harder cases. (A) Sarah (B) Maria
04/28/2022 05:22:16 - INFO - __main__ - ['Sarah']
04/28/2022 05:22:16 - INFO - __main__ -  [wino_grande] They were worried the wine would ruin the bed and the blanket, but the _ was't ruined. (A) blanket (B) bed
04/28/2022 05:22:16 - INFO - __main__ - ['bed']
04/28/2022 05:22:16 - INFO - __main__ - Tokenizing Input ...
04/28/2022 05:22:17 - INFO - __main__ - Tokenizing Output ...
04/28/2022 05:22:18 - INFO - __main__ - Loaded 1000 examples from test data
04/28/2022 05:22:18 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 05:22:18 - INFO - __main__ - Printing 3 examples
04/28/2022 05:22:18 - INFO - __main__ -  [wino_grande] Craig volunteered to help the dyslexic students at the school while Joel avoided them, since _ struggled with reading. (A) Craig (B) Joel
04/28/2022 05:22:18 - INFO - __main__ - ['Joel']
04/28/2022 05:22:18 - INFO - __main__ -  [wino_grande] Betty projects much more happiness than Amy, _ because/although she smiles a lot more often. (A) Betty (B) Amy
04/28/2022 05:22:18 - INFO - __main__ - ['Betty']
04/28/2022 05:22:18 - INFO - __main__ -  [wino_grande] Kevin confidently told Jason that his engraving business was going to make him rich.  _ was skeptical. (A) Kevin (B) Jason
04/28/2022 05:22:18 - INFO - __main__ - ['Jason']
04/28/2022 05:22:18 - INFO - __main__ - Tokenizing Input ...
04/28/2022 05:22:18 - INFO - __main__ - Tokenizing Output ...
04/28/2022 05:22:18 - INFO - __main__ - Loaded 32 examples from train data
04/28/2022 05:22:18 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 05:22:18 - INFO - __main__ - Printing 3 examples
04/28/2022 05:22:18 - INFO - __main__ -  [wino_grande] Lindsey was more excited than Laura about having a gender reveal party for the baby. _ thought they were adorable. (A) Lindsey (B) Laura
04/28/2022 05:22:18 - INFO - __main__ - ['Lindsey']
04/28/2022 05:22:18 - INFO - __main__ -  [wino_grande] She liked the style of the shoes far more than the pants, because the _ looked gaudy. (A) pants (B) shoes
04/28/2022 05:22:18 - INFO - __main__ - ['pants']
04/28/2022 05:22:18 - INFO - __main__ -  [wino_grande] Julie's foot would not fit into her new pair of cowboy boots she just bought, the _ was too narrow. (A) boot (B) foot
04/28/2022 05:22:18 - INFO - __main__ - ['boot']
04/28/2022 05:22:18 - INFO - __main__ - Tokenizing Input ...
04/28/2022 05:22:18 - INFO - __main__ - Tokenizing Output ...
04/28/2022 05:22:18 - INFO - __main__ - Loaded 32 examples from dev data
04/28/2022 05:22:33 - INFO - __main__ - load prompt embedding from ckpt
04/28/2022 05:22:33 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/28/2022 05:22:33 - INFO - __main__ - Starting training!
04/28/2022 05:22:42 - INFO - __main__ - Saved prediction in models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-wino_grande/wino_grande_32_100_0.5_8_predictions.txt
04/28/2022 05:22:42 - INFO - __main__ - ACC on test data: 0.5020
04/28/2022 05:22:42 - INFO - __main__ - prefix=wino_grande_32_100, lr=0.5, bsz=8, dev_performance=0.53125, test_performance=0.502
04/28/2022 05:22:42 - INFO - __main__ - Running ... prefix=wino_grande_32_100, lr=0.4, bsz=8 ...
04/28/2022 05:22:43 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 05:22:43 - INFO - __main__ - Printing 3 examples
04/28/2022 05:22:43 - INFO - __main__ -  [wino_grande] Craig volunteered to help the dyslexic students at the school while Joel avoided them, since _ struggled with reading. (A) Craig (B) Joel
04/28/2022 05:22:43 - INFO - __main__ - ['Joel']
04/28/2022 05:22:43 - INFO - __main__ -  [wino_grande] Betty projects much more happiness than Amy, _ because/although she smiles a lot more often. (A) Betty (B) Amy
04/28/2022 05:22:43 - INFO - __main__ - ['Betty']
04/28/2022 05:22:43 - INFO - __main__ -  [wino_grande] Kevin confidently told Jason that his engraving business was going to make him rich.  _ was skeptical. (A) Kevin (B) Jason
04/28/2022 05:22:43 - INFO - __main__ - ['Jason']
04/28/2022 05:22:43 - INFO - __main__ - Tokenizing Input ...
04/28/2022 05:22:43 - INFO - __main__ - Tokenizing Output ...
04/28/2022 05:22:43 - INFO - __main__ - Loaded 32 examples from train data
04/28/2022 05:22:43 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 05:22:43 - INFO - __main__ - Printing 3 examples
04/28/2022 05:22:43 - INFO - __main__ -  [wino_grande] Lindsey was more excited than Laura about having a gender reveal party for the baby. _ thought they were adorable. (A) Lindsey (B) Laura
04/28/2022 05:22:43 - INFO - __main__ - ['Lindsey']
04/28/2022 05:22:43 - INFO - __main__ -  [wino_grande] She liked the style of the shoes far more than the pants, because the _ looked gaudy. (A) pants (B) shoes
04/28/2022 05:22:43 - INFO - __main__ - ['pants']
04/28/2022 05:22:43 - INFO - __main__ -  [wino_grande] Julie's foot would not fit into her new pair of cowboy boots she just bought, the _ was too narrow. (A) boot (B) foot
04/28/2022 05:22:43 - INFO - __main__ - ['boot']
04/28/2022 05:22:43 - INFO - __main__ - Tokenizing Input ...
04/28/2022 05:22:43 - INFO - __main__ - Tokenizing Output ...
04/28/2022 05:22:43 - INFO - __main__ - Loaded 32 examples from dev data
04/28/2022 05:23:02 - INFO - __main__ - load prompt embedding from ckpt
04/28/2022 05:23:03 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/28/2022 05:23:03 - INFO - __main__ - Starting training!
04/28/2022 05:23:06 - INFO - __main__ - Step 10 Global step 10 Train loss 3.48 on epoch=4
04/28/2022 05:23:08 - INFO - __main__ - Step 20 Global step 20 Train loss 1.17 on epoch=9
04/28/2022 05:23:11 - INFO - __main__ - Step 30 Global step 30 Train loss 0.69 on epoch=14
04/28/2022 05:23:13 - INFO - __main__ - Step 40 Global step 40 Train loss 0.74 on epoch=19
04/28/2022 05:23:16 - INFO - __main__ - Step 50 Global step 50 Train loss 0.48 on epoch=24
04/28/2022 05:23:17 - INFO - __main__ - Global step 50 Train loss 1.31 ACC 0.53125 on epoch=24
04/28/2022 05:23:17 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.53125 on epoch=24, global_step=50
04/28/2022 05:23:19 - INFO - __main__ - Step 60 Global step 60 Train loss 0.51 on epoch=29
04/28/2022 05:23:22 - INFO - __main__ - Step 70 Global step 70 Train loss 0.50 on epoch=34
04/28/2022 05:23:24 - INFO - __main__ - Step 80 Global step 80 Train loss 0.36 on epoch=39
04/28/2022 05:23:27 - INFO - __main__ - Step 90 Global step 90 Train loss 0.30 on epoch=44
04/28/2022 05:23:29 - INFO - __main__ - Step 100 Global step 100 Train loss 0.28 on epoch=49
04/28/2022 05:23:30 - INFO - __main__ - Global step 100 Train loss 0.39 ACC 0.46875 on epoch=49
04/28/2022 05:23:32 - INFO - __main__ - Step 110 Global step 110 Train loss 0.21 on epoch=54
04/28/2022 05:23:35 - INFO - __main__ - Step 120 Global step 120 Train loss 0.20 on epoch=59
04/28/2022 05:23:37 - INFO - __main__ - Step 130 Global step 130 Train loss 0.15 on epoch=64
04/28/2022 05:23:40 - INFO - __main__ - Step 140 Global step 140 Train loss 0.13 on epoch=69
04/28/2022 05:23:42 - INFO - __main__ - Step 150 Global step 150 Train loss 0.05 on epoch=74
04/28/2022 05:23:43 - INFO - __main__ - Global step 150 Train loss 0.15 ACC 0.46875 on epoch=74
04/28/2022 05:23:45 - INFO - __main__ - Step 160 Global step 160 Train loss 0.13 on epoch=79
04/28/2022 05:23:48 - INFO - __main__ - Step 170 Global step 170 Train loss 0.08 on epoch=84
04/28/2022 05:23:50 - INFO - __main__ - Step 180 Global step 180 Train loss 0.08 on epoch=89
04/28/2022 05:23:53 - INFO - __main__ - Step 190 Global step 190 Train loss 0.04 on epoch=94
04/28/2022 05:23:55 - INFO - __main__ - Step 200 Global step 200 Train loss 0.04 on epoch=99
04/28/2022 05:23:56 - INFO - __main__ - Global step 200 Train loss 0.08 ACC 0.46875 on epoch=99
04/28/2022 05:23:58 - INFO - __main__ - Step 210 Global step 210 Train loss 0.12 on epoch=104
04/28/2022 05:24:01 - INFO - __main__ - Step 220 Global step 220 Train loss 0.09 on epoch=109
04/28/2022 05:24:03 - INFO - __main__ - Step 230 Global step 230 Train loss 0.02 on epoch=114
04/28/2022 05:24:05 - INFO - __main__ - Step 240 Global step 240 Train loss 0.08 on epoch=119
04/28/2022 05:24:08 - INFO - __main__ - Step 250 Global step 250 Train loss 0.05 on epoch=124
04/28/2022 05:24:09 - INFO - __main__ - Global step 250 Train loss 0.07 ACC 0.375 on epoch=124
04/28/2022 05:24:11 - INFO - __main__ - Step 260 Global step 260 Train loss 0.03 on epoch=129
04/28/2022 05:24:14 - INFO - __main__ - Step 270 Global step 270 Train loss 0.02 on epoch=134
04/28/2022 05:24:16 - INFO - __main__ - Step 280 Global step 280 Train loss 0.01 on epoch=139
04/28/2022 05:24:18 - INFO - __main__ - Step 290 Global step 290 Train loss 0.02 on epoch=144
04/28/2022 05:24:21 - INFO - __main__ - Step 300 Global step 300 Train loss 0.01 on epoch=149
04/28/2022 05:24:22 - INFO - __main__ - Global step 300 Train loss 0.02 ACC 0.375 on epoch=149
04/28/2022 05:24:24 - INFO - __main__ - Step 310 Global step 310 Train loss 0.00 on epoch=154
04/28/2022 05:24:27 - INFO - __main__ - Step 320 Global step 320 Train loss 0.05 on epoch=159
04/28/2022 05:24:29 - INFO - __main__ - Step 330 Global step 330 Train loss 0.06 on epoch=164
04/28/2022 05:24:31 - INFO - __main__ - Step 340 Global step 340 Train loss 0.05 on epoch=169
04/28/2022 05:24:34 - INFO - __main__ - Step 350 Global step 350 Train loss 0.03 on epoch=174
04/28/2022 05:24:35 - INFO - __main__ - Global step 350 Train loss 0.04 ACC 0.40625 on epoch=174
04/28/2022 05:24:37 - INFO - __main__ - Step 360 Global step 360 Train loss 0.01 on epoch=179
04/28/2022 05:24:40 - INFO - __main__ - Step 370 Global step 370 Train loss 0.01 on epoch=184
04/28/2022 05:24:42 - INFO - __main__ - Step 380 Global step 380 Train loss 0.01 on epoch=189
04/28/2022 05:24:44 - INFO - __main__ - Step 390 Global step 390 Train loss 0.01 on epoch=194
04/28/2022 05:24:47 - INFO - __main__ - Step 400 Global step 400 Train loss 0.05 on epoch=199
04/28/2022 05:24:48 - INFO - __main__ - Global step 400 Train loss 0.02 ACC 0.40625 on epoch=199
04/28/2022 05:24:50 - INFO - __main__ - Step 410 Global step 410 Train loss 0.05 on epoch=204
04/28/2022 05:24:53 - INFO - __main__ - Step 420 Global step 420 Train loss 0.02 on epoch=209
04/28/2022 05:24:55 - INFO - __main__ - Step 430 Global step 430 Train loss 0.02 on epoch=214
04/28/2022 05:24:57 - INFO - __main__ - Step 440 Global step 440 Train loss 0.01 on epoch=219
04/28/2022 05:25:00 - INFO - __main__ - Step 450 Global step 450 Train loss 0.02 on epoch=224
04/28/2022 05:25:01 - INFO - __main__ - Global step 450 Train loss 0.02 ACC 0.4375 on epoch=224
04/28/2022 05:25:03 - INFO - __main__ - Step 460 Global step 460 Train loss 0.03 on epoch=229
04/28/2022 05:25:05 - INFO - __main__ - Step 470 Global step 470 Train loss 0.04 on epoch=234
04/28/2022 05:25:08 - INFO - __main__ - Step 480 Global step 480 Train loss 0.09 on epoch=239
04/28/2022 05:25:10 - INFO - __main__ - Step 490 Global step 490 Train loss 0.04 on epoch=244
04/28/2022 05:25:13 - INFO - __main__ - Step 500 Global step 500 Train loss 0.00 on epoch=249
04/28/2022 05:25:14 - INFO - __main__ - Global step 500 Train loss 0.04 ACC 0.40625 on epoch=249
04/28/2022 05:25:16 - INFO - __main__ - Step 510 Global step 510 Train loss 0.01 on epoch=254
04/28/2022 05:25:18 - INFO - __main__ - Step 520 Global step 520 Train loss 0.04 on epoch=259
04/28/2022 05:25:21 - INFO - __main__ - Step 530 Global step 530 Train loss 0.00 on epoch=264
04/28/2022 05:25:23 - INFO - __main__ - Step 540 Global step 540 Train loss 0.00 on epoch=269
04/28/2022 05:25:26 - INFO - __main__ - Step 550 Global step 550 Train loss 0.01 on epoch=274
04/28/2022 05:25:26 - INFO - __main__ - Global step 550 Train loss 0.01 ACC 0.46875 on epoch=274
04/28/2022 05:25:29 - INFO - __main__ - Step 560 Global step 560 Train loss 0.03 on epoch=279
04/28/2022 05:25:31 - INFO - __main__ - Step 570 Global step 570 Train loss 0.06 on epoch=284
04/28/2022 05:25:34 - INFO - __main__ - Step 580 Global step 580 Train loss 0.01 on epoch=289
04/28/2022 05:25:36 - INFO - __main__ - Step 590 Global step 590 Train loss 0.01 on epoch=294
04/28/2022 05:25:39 - INFO - __main__ - Step 600 Global step 600 Train loss 0.01 on epoch=299
04/28/2022 05:25:39 - INFO - __main__ - Global step 600 Train loss 0.02 ACC 0.4375 on epoch=299
04/28/2022 05:25:42 - INFO - __main__ - Step 610 Global step 610 Train loss 0.00 on epoch=304
04/28/2022 05:25:44 - INFO - __main__ - Step 620 Global step 620 Train loss 0.02 on epoch=309
04/28/2022 05:25:47 - INFO - __main__ - Step 630 Global step 630 Train loss 0.00 on epoch=314
04/28/2022 05:25:49 - INFO - __main__ - Step 640 Global step 640 Train loss 0.04 on epoch=319
04/28/2022 05:25:52 - INFO - __main__ - Step 650 Global step 650 Train loss 0.00 on epoch=324
04/28/2022 05:25:53 - INFO - __main__ - Global step 650 Train loss 0.01 ACC 0.375 on epoch=324
04/28/2022 05:25:55 - INFO - __main__ - Step 660 Global step 660 Train loss 0.00 on epoch=329
04/28/2022 05:25:58 - INFO - __main__ - Step 670 Global step 670 Train loss 0.00 on epoch=334
04/28/2022 05:26:00 - INFO - __main__ - Step 680 Global step 680 Train loss 0.01 on epoch=339
04/28/2022 05:26:03 - INFO - __main__ - Step 690 Global step 690 Train loss 0.00 on epoch=344
04/28/2022 05:26:05 - INFO - __main__ - Step 700 Global step 700 Train loss 0.01 on epoch=349
04/28/2022 05:26:06 - INFO - __main__ - Global step 700 Train loss 0.00 ACC 0.40625 on epoch=349
04/28/2022 05:26:09 - INFO - __main__ - Step 710 Global step 710 Train loss 0.00 on epoch=354
04/28/2022 05:26:11 - INFO - __main__ - Step 720 Global step 720 Train loss 0.00 on epoch=359
04/28/2022 05:26:14 - INFO - __main__ - Step 730 Global step 730 Train loss 0.00 on epoch=364
04/28/2022 05:26:16 - INFO - __main__ - Step 740 Global step 740 Train loss 0.00 on epoch=369
04/28/2022 05:26:19 - INFO - __main__ - Step 750 Global step 750 Train loss 0.01 on epoch=374
04/28/2022 05:26:19 - INFO - __main__ - Global step 750 Train loss 0.01 ACC 0.40625 on epoch=374
04/28/2022 05:26:22 - INFO - __main__ - Step 760 Global step 760 Train loss 0.01 on epoch=379
04/28/2022 05:26:24 - INFO - __main__ - Step 770 Global step 770 Train loss 0.00 on epoch=384
04/28/2022 05:26:27 - INFO - __main__ - Step 780 Global step 780 Train loss 0.00 on epoch=389
04/28/2022 05:26:29 - INFO - __main__ - Step 790 Global step 790 Train loss 0.00 on epoch=394
04/28/2022 05:26:32 - INFO - __main__ - Step 800 Global step 800 Train loss 0.02 on epoch=399
04/28/2022 05:26:33 - INFO - __main__ - Global step 800 Train loss 0.01 ACC 0.4375 on epoch=399
04/28/2022 05:26:35 - INFO - __main__ - Step 810 Global step 810 Train loss 0.00 on epoch=404
04/28/2022 05:26:38 - INFO - __main__ - Step 820 Global step 820 Train loss 0.03 on epoch=409
04/28/2022 05:26:40 - INFO - __main__ - Step 830 Global step 830 Train loss 0.00 on epoch=414
04/28/2022 05:26:43 - INFO - __main__ - Step 840 Global step 840 Train loss 0.00 on epoch=419
04/28/2022 05:26:45 - INFO - __main__ - Step 850 Global step 850 Train loss 0.01 on epoch=424
04/28/2022 05:26:46 - INFO - __main__ - Global step 850 Train loss 0.01 ACC 0.4375 on epoch=424
04/28/2022 05:26:48 - INFO - __main__ - Step 860 Global step 860 Train loss 0.00 on epoch=429
04/28/2022 05:26:51 - INFO - __main__ - Step 870 Global step 870 Train loss 0.00 on epoch=434
04/28/2022 05:26:53 - INFO - __main__ - Step 880 Global step 880 Train loss 0.01 on epoch=439
04/28/2022 05:26:56 - INFO - __main__ - Step 890 Global step 890 Train loss 0.01 on epoch=444
04/28/2022 05:26:58 - INFO - __main__ - Step 900 Global step 900 Train loss 0.00 on epoch=449
04/28/2022 05:26:59 - INFO - __main__ - Global step 900 Train loss 0.00 ACC 0.46875 on epoch=449
04/28/2022 05:27:02 - INFO - __main__ - Step 910 Global step 910 Train loss 0.00 on epoch=454
04/28/2022 05:27:04 - INFO - __main__ - Step 920 Global step 920 Train loss 0.01 on epoch=459
04/28/2022 05:27:07 - INFO - __main__ - Step 930 Global step 930 Train loss 0.00 on epoch=464
04/28/2022 05:27:09 - INFO - __main__ - Step 940 Global step 940 Train loss 0.00 on epoch=469
04/28/2022 05:27:12 - INFO - __main__ - Step 950 Global step 950 Train loss 0.00 on epoch=474
04/28/2022 05:27:12 - INFO - __main__ - Global step 950 Train loss 0.00 ACC 0.4375 on epoch=474
04/28/2022 05:27:15 - INFO - __main__ - Step 960 Global step 960 Train loss 0.01 on epoch=479
04/28/2022 05:27:17 - INFO - __main__ - Step 970 Global step 970 Train loss 0.01 on epoch=484
04/28/2022 05:27:20 - INFO - __main__ - Step 980 Global step 980 Train loss 0.00 on epoch=489
04/28/2022 05:27:22 - INFO - __main__ - Step 990 Global step 990 Train loss 0.00 on epoch=494
04/28/2022 05:27:25 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.01 on epoch=499
04/28/2022 05:27:25 - INFO - __main__ - Global step 1000 Train loss 0.01 ACC 0.4375 on epoch=499
04/28/2022 05:27:28 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.00 on epoch=504
04/28/2022 05:27:30 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.01 on epoch=509
04/28/2022 05:27:33 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.05 on epoch=514
04/28/2022 05:27:35 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.00 on epoch=519
04/28/2022 05:27:38 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.01 on epoch=524
04/28/2022 05:27:39 - INFO - __main__ - Global step 1050 Train loss 0.02 ACC 0.5 on epoch=524
04/28/2022 05:27:41 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.01 on epoch=529
04/28/2022 05:27:44 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.01 on epoch=534
04/28/2022 05:27:46 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.00 on epoch=539
04/28/2022 05:27:49 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.01 on epoch=544
04/28/2022 05:27:51 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.00 on epoch=549
04/28/2022 05:27:52 - INFO - __main__ - Global step 1100 Train loss 0.01 ACC 0.46875 on epoch=549
04/28/2022 05:27:54 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.00 on epoch=554
04/28/2022 05:27:57 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.00 on epoch=559
04/28/2022 05:27:59 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.00 on epoch=564
04/28/2022 05:28:02 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.00 on epoch=569
04/28/2022 05:28:04 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.00 on epoch=574
04/28/2022 05:28:05 - INFO - __main__ - Global step 1150 Train loss 0.00 ACC 0.5 on epoch=574
04/28/2022 05:28:08 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.00 on epoch=579
04/28/2022 05:28:10 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.00 on epoch=584
04/28/2022 05:28:13 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.00 on epoch=589
04/28/2022 05:28:15 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.00 on epoch=594
04/28/2022 05:28:18 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.00 on epoch=599
04/28/2022 05:28:18 - INFO - __main__ - Global step 1200 Train loss 0.00 ACC 0.5 on epoch=599
04/28/2022 05:28:21 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.00 on epoch=604
04/28/2022 05:28:23 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=609
04/28/2022 05:28:26 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.02 on epoch=614
04/28/2022 05:28:28 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.00 on epoch=619
04/28/2022 05:28:31 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.00 on epoch=624
04/28/2022 05:28:31 - INFO - __main__ - Global step 1250 Train loss 0.01 ACC 0.53125 on epoch=624
04/28/2022 05:28:34 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=629
04/28/2022 05:28:37 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.00 on epoch=634
04/28/2022 05:28:39 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.00 on epoch=639
04/28/2022 05:28:42 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=644
04/28/2022 05:28:44 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.00 on epoch=649
04/28/2022 05:28:45 - INFO - __main__ - Global step 1300 Train loss 0.00 ACC 0.53125 on epoch=649
04/28/2022 05:28:47 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.00 on epoch=654
04/28/2022 05:28:50 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.00 on epoch=659
04/28/2022 05:28:52 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.00 on epoch=664
04/28/2022 05:28:55 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.00 on epoch=669
04/28/2022 05:28:57 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.00 on epoch=674
04/28/2022 05:28:58 - INFO - __main__ - Global step 1350 Train loss 0.00 ACC 0.53125 on epoch=674
04/28/2022 05:29:01 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.02 on epoch=679
04/28/2022 05:29:03 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.00 on epoch=684
04/28/2022 05:29:06 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.00 on epoch=689
04/28/2022 05:29:08 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.00 on epoch=694
04/28/2022 05:29:11 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.00 on epoch=699
04/28/2022 05:29:11 - INFO - __main__ - Global step 1400 Train loss 0.01 ACC 0.46875 on epoch=699
04/28/2022 05:29:14 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=704
04/28/2022 05:29:16 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=709
04/28/2022 05:29:19 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=714
04/28/2022 05:29:21 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=719
04/28/2022 05:29:24 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=724
04/28/2022 05:29:25 - INFO - __main__ - Global step 1450 Train loss 0.00 ACC 0.5 on epoch=724
04/28/2022 05:29:27 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=729
04/28/2022 05:29:30 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=734
04/28/2022 05:29:32 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=739
04/28/2022 05:29:35 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=744
04/28/2022 05:29:37 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=749
04/28/2022 05:29:38 - INFO - __main__ - Global step 1500 Train loss 0.00 ACC 0.46875 on epoch=749
04/28/2022 05:29:40 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=754
04/28/2022 05:29:43 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=759
04/28/2022 05:29:45 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=764
04/28/2022 05:29:48 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=769
04/28/2022 05:29:50 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=774
04/28/2022 05:29:51 - INFO - __main__ - Global step 1550 Train loss 0.00 ACC 0.5 on epoch=774
04/28/2022 05:29:54 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=779
04/28/2022 05:29:56 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=784
04/28/2022 05:29:58 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=789
04/28/2022 05:30:01 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=794
04/28/2022 05:30:03 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=799
04/28/2022 05:30:04 - INFO - __main__ - Global step 1600 Train loss 0.00 ACC 0.5 on epoch=799
04/28/2022 05:30:06 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=804
04/28/2022 05:30:09 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=809
04/28/2022 05:30:11 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=814
04/28/2022 05:30:14 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=819
04/28/2022 05:30:16 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=824
04/28/2022 05:30:17 - INFO - __main__ - Global step 1650 Train loss 0.00 ACC 0.46875 on epoch=824
04/28/2022 05:30:19 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=829
04/28/2022 05:30:22 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=834
04/28/2022 05:30:24 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=839
04/28/2022 05:30:27 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=844
04/28/2022 05:30:29 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=849
04/28/2022 05:30:30 - INFO - __main__ - Global step 1700 Train loss 0.00 ACC 0.46875 on epoch=849
04/28/2022 05:30:32 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=854
04/28/2022 05:30:34 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=859
04/28/2022 05:30:37 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.03 on epoch=864
04/28/2022 05:30:39 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=869
04/28/2022 05:30:42 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=874
04/28/2022 05:30:42 - INFO - __main__ - Global step 1750 Train loss 0.01 ACC 0.5 on epoch=874
04/28/2022 05:30:45 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=879
04/28/2022 05:30:47 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=884
04/28/2022 05:30:50 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=889
04/28/2022 05:30:52 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=894
04/28/2022 05:30:55 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=899
04/28/2022 05:30:55 - INFO - __main__ - Global step 1800 Train loss 0.00 ACC 0.5 on epoch=899
04/28/2022 05:30:58 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=904
04/28/2022 05:31:00 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=909
04/28/2022 05:31:03 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=914
04/28/2022 05:31:05 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=919
04/28/2022 05:31:07 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=924
04/28/2022 05:31:08 - INFO - __main__ - Global step 1850 Train loss 0.01 ACC 0.46875 on epoch=924
04/28/2022 05:31:11 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=929
04/28/2022 05:31:13 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=934
04/28/2022 05:31:16 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=939
04/28/2022 05:31:18 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=944
04/28/2022 05:31:21 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=949
04/28/2022 05:31:21 - INFO - __main__ - Global step 1900 Train loss 0.00 ACC 0.46875 on epoch=949
04/28/2022 05:31:24 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=954
04/28/2022 05:31:26 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=959
04/28/2022 05:31:29 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=964
04/28/2022 05:31:31 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=969
04/28/2022 05:31:34 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=974
04/28/2022 05:31:34 - INFO - __main__ - Global step 1950 Train loss 0.00 ACC 0.4375 on epoch=974
04/28/2022 05:31:37 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=979
04/28/2022 05:31:39 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=984
04/28/2022 05:31:42 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=989
04/28/2022 05:31:44 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=994
04/28/2022 05:31:47 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=999
04/28/2022 05:31:47 - INFO - __main__ - Global step 2000 Train loss 0.01 ACC 0.40625 on epoch=999
04/28/2022 05:31:47 - INFO - __main__ - save last model!
04/28/2022 05:31:47 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
04/28/2022 05:31:47 - INFO - __main__ - Start tokenizing ... 1000 instances
04/28/2022 05:31:47 - INFO - __main__ - Printing 3 examples
04/28/2022 05:31:47 - INFO - __main__ -  [wino_grande] Sarah was a much better surgeon than Maria so _ always got the easier cases. (A) Sarah (B) Maria
04/28/2022 05:31:47 - INFO - __main__ - ['Maria']
04/28/2022 05:31:47 - INFO - __main__ -  [wino_grande] Sarah was a much better surgeon than Maria so _ always got the harder cases. (A) Sarah (B) Maria
04/28/2022 05:31:47 - INFO - __main__ - ['Sarah']
04/28/2022 05:31:47 - INFO - __main__ -  [wino_grande] They were worried the wine would ruin the bed and the blanket, but the _ was't ruined. (A) blanket (B) bed
04/28/2022 05:31:47 - INFO - __main__ - ['bed']
04/28/2022 05:31:47 - INFO - __main__ - Tokenizing Input ...
04/28/2022 05:31:48 - INFO - __main__ - Tokenizing Output ...
04/28/2022 05:31:49 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 05:31:49 - INFO - __main__ - Printing 3 examples
04/28/2022 05:31:49 - INFO - __main__ -  [wino_grande] Craig volunteered to help the dyslexic students at the school while Joel avoided them, since _ struggled with reading. (A) Craig (B) Joel
04/28/2022 05:31:49 - INFO - __main__ - ['Joel']
04/28/2022 05:31:49 - INFO - __main__ -  [wino_grande] Betty projects much more happiness than Amy, _ because/although she smiles a lot more often. (A) Betty (B) Amy
04/28/2022 05:31:49 - INFO - __main__ - ['Betty']
04/28/2022 05:31:49 - INFO - __main__ -  [wino_grande] Kevin confidently told Jason that his engraving business was going to make him rich.  _ was skeptical. (A) Kevin (B) Jason
04/28/2022 05:31:49 - INFO - __main__ - ['Jason']
04/28/2022 05:31:49 - INFO - __main__ - Tokenizing Input ...
04/28/2022 05:31:49 - INFO - __main__ - Tokenizing Output ...
04/28/2022 05:31:49 - INFO - __main__ - Loaded 1000 examples from test data
04/28/2022 05:31:49 - INFO - __main__ - Loaded 32 examples from train data
04/28/2022 05:31:49 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 05:31:49 - INFO - __main__ - Printing 3 examples
04/28/2022 05:31:49 - INFO - __main__ -  [wino_grande] Lindsey was more excited than Laura about having a gender reveal party for the baby. _ thought they were adorable. (A) Lindsey (B) Laura
04/28/2022 05:31:49 - INFO - __main__ - ['Lindsey']
04/28/2022 05:31:49 - INFO - __main__ -  [wino_grande] She liked the style of the shoes far more than the pants, because the _ looked gaudy. (A) pants (B) shoes
04/28/2022 05:31:49 - INFO - __main__ - ['pants']
04/28/2022 05:31:49 - INFO - __main__ -  [wino_grande] Julie's foot would not fit into her new pair of cowboy boots she just bought, the _ was too narrow. (A) boot (B) foot
04/28/2022 05:31:49 - INFO - __main__ - ['boot']
04/28/2022 05:31:49 - INFO - __main__ - Tokenizing Input ...
04/28/2022 05:31:49 - INFO - __main__ - Tokenizing Output ...
04/28/2022 05:31:49 - INFO - __main__ - Loaded 32 examples from dev data
04/28/2022 05:32:08 - INFO - __main__ - load prompt embedding from ckpt
04/28/2022 05:32:08 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/28/2022 05:32:08 - INFO - __main__ - Starting training!
04/28/2022 05:32:11 - INFO - __main__ - Saved prediction in models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-wino_grande/wino_grande_32_100_0.4_8_predictions.txt
04/28/2022 05:32:11 - INFO - __main__ - ACC on test data: 0.5000
04/28/2022 05:32:11 - INFO - __main__ - prefix=wino_grande_32_100, lr=0.4, bsz=8, dev_performance=0.53125, test_performance=0.5
04/28/2022 05:32:11 - INFO - __main__ - Running ... prefix=wino_grande_32_100, lr=0.3, bsz=8 ...
04/28/2022 05:32:12 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 05:32:12 - INFO - __main__ - Printing 3 examples
04/28/2022 05:32:12 - INFO - __main__ -  [wino_grande] Craig volunteered to help the dyslexic students at the school while Joel avoided them, since _ struggled with reading. (A) Craig (B) Joel
04/28/2022 05:32:12 - INFO - __main__ - ['Joel']
04/28/2022 05:32:12 - INFO - __main__ -  [wino_grande] Betty projects much more happiness than Amy, _ because/although she smiles a lot more often. (A) Betty (B) Amy
04/28/2022 05:32:12 - INFO - __main__ - ['Betty']
04/28/2022 05:32:12 - INFO - __main__ -  [wino_grande] Kevin confidently told Jason that his engraving business was going to make him rich.  _ was skeptical. (A) Kevin (B) Jason
04/28/2022 05:32:12 - INFO - __main__ - ['Jason']
04/28/2022 05:32:12 - INFO - __main__ - Tokenizing Input ...
04/28/2022 05:32:12 - INFO - __main__ - Tokenizing Output ...
04/28/2022 05:32:12 - INFO - __main__ - Loaded 32 examples from train data
04/28/2022 05:32:12 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 05:32:12 - INFO - __main__ - Printing 3 examples
04/28/2022 05:32:12 - INFO - __main__ -  [wino_grande] Lindsey was more excited than Laura about having a gender reveal party for the baby. _ thought they were adorable. (A) Lindsey (B) Laura
04/28/2022 05:32:12 - INFO - __main__ - ['Lindsey']
04/28/2022 05:32:12 - INFO - __main__ -  [wino_grande] She liked the style of the shoes far more than the pants, because the _ looked gaudy. (A) pants (B) shoes
04/28/2022 05:32:12 - INFO - __main__ - ['pants']
04/28/2022 05:32:12 - INFO - __main__ -  [wino_grande] Julie's foot would not fit into her new pair of cowboy boots she just bought, the _ was too narrow. (A) boot (B) foot
04/28/2022 05:32:12 - INFO - __main__ - ['boot']
04/28/2022 05:32:12 - INFO - __main__ - Tokenizing Input ...
04/28/2022 05:32:12 - INFO - __main__ - Tokenizing Output ...
04/28/2022 05:32:13 - INFO - __main__ - Loaded 32 examples from dev data
04/28/2022 05:32:27 - INFO - __main__ - load prompt embedding from ckpt
04/28/2022 05:32:28 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/28/2022 05:32:28 - INFO - __main__ - Starting training!
04/28/2022 05:32:31 - INFO - __main__ - Step 10 Global step 10 Train loss 3.78 on epoch=4
04/28/2022 05:32:34 - INFO - __main__ - Step 20 Global step 20 Train loss 1.49 on epoch=9
04/28/2022 05:32:36 - INFO - __main__ - Step 30 Global step 30 Train loss 0.77 on epoch=14
04/28/2022 05:32:39 - INFO - __main__ - Step 40 Global step 40 Train loss 0.65 on epoch=19
04/28/2022 05:32:41 - INFO - __main__ - Step 50 Global step 50 Train loss 0.38 on epoch=24
04/28/2022 05:32:42 - INFO - __main__ - Global step 50 Train loss 1.41 ACC 0.40625 on epoch=24
04/28/2022 05:32:42 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.40625 on epoch=24, global_step=50
04/28/2022 05:32:45 - INFO - __main__ - Step 60 Global step 60 Train loss 0.53 on epoch=29
04/28/2022 05:32:47 - INFO - __main__ - Step 70 Global step 70 Train loss 0.44 on epoch=34
04/28/2022 05:32:50 - INFO - __main__ - Step 80 Global step 80 Train loss 0.40 on epoch=39
04/28/2022 05:32:52 - INFO - __main__ - Step 90 Global step 90 Train loss 0.30 on epoch=44
04/28/2022 05:32:55 - INFO - __main__ - Step 100 Global step 100 Train loss 0.27 on epoch=49
04/28/2022 05:32:55 - INFO - __main__ - Global step 100 Train loss 0.39 ACC 0.5 on epoch=49
04/28/2022 05:32:55 - INFO - __main__ - Saving model with best ACC: 0.40625 -> 0.5 on epoch=49, global_step=100
04/28/2022 05:32:58 - INFO - __main__ - Step 110 Global step 110 Train loss 0.28 on epoch=54
04/28/2022 05:33:00 - INFO - __main__ - Step 120 Global step 120 Train loss 0.22 on epoch=59
04/28/2022 05:33:03 - INFO - __main__ - Step 130 Global step 130 Train loss 0.19 on epoch=64
04/28/2022 05:33:05 - INFO - __main__ - Step 140 Global step 140 Train loss 0.14 on epoch=69
04/28/2022 05:33:08 - INFO - __main__ - Step 150 Global step 150 Train loss 0.13 on epoch=74
04/28/2022 05:33:08 - INFO - __main__ - Global step 150 Train loss 0.19 ACC 0.5 on epoch=74
04/28/2022 05:33:11 - INFO - __main__ - Step 160 Global step 160 Train loss 0.14 on epoch=79
04/28/2022 05:33:13 - INFO - __main__ - Step 170 Global step 170 Train loss 0.17 on epoch=84
04/28/2022 05:33:16 - INFO - __main__ - Step 180 Global step 180 Train loss 0.12 on epoch=89
04/28/2022 05:33:18 - INFO - __main__ - Step 190 Global step 190 Train loss 0.17 on epoch=94
04/28/2022 05:33:21 - INFO - __main__ - Step 200 Global step 200 Train loss 0.09 on epoch=99
04/28/2022 05:33:21 - INFO - __main__ - Global step 200 Train loss 0.14 ACC 0.5 on epoch=99
04/28/2022 05:33:24 - INFO - __main__ - Step 210 Global step 210 Train loss 0.06 on epoch=104
04/28/2022 05:33:26 - INFO - __main__ - Step 220 Global step 220 Train loss 0.08 on epoch=109
04/28/2022 05:33:29 - INFO - __main__ - Step 230 Global step 230 Train loss 0.16 on epoch=114
04/28/2022 05:33:31 - INFO - __main__ - Step 240 Global step 240 Train loss 0.04 on epoch=119
04/28/2022 05:33:34 - INFO - __main__ - Step 250 Global step 250 Train loss 0.08 on epoch=124
04/28/2022 05:33:35 - INFO - __main__ - Global step 250 Train loss 0.08 ACC 0.5 on epoch=124
04/28/2022 05:33:37 - INFO - __main__ - Step 260 Global step 260 Train loss 0.03 on epoch=129
04/28/2022 05:33:40 - INFO - __main__ - Step 270 Global step 270 Train loss 0.07 on epoch=134
04/28/2022 05:33:42 - INFO - __main__ - Step 280 Global step 280 Train loss 0.05 on epoch=139
04/28/2022 05:33:44 - INFO - __main__ - Step 290 Global step 290 Train loss 0.05 on epoch=144
04/28/2022 05:33:47 - INFO - __main__ - Step 300 Global step 300 Train loss 0.03 on epoch=149
04/28/2022 05:33:48 - INFO - __main__ - Global step 300 Train loss 0.05 ACC 0.53125 on epoch=149
04/28/2022 05:33:48 - INFO - __main__ - Saving model with best ACC: 0.5 -> 0.53125 on epoch=149, global_step=300
04/28/2022 05:33:50 - INFO - __main__ - Step 310 Global step 310 Train loss 0.14 on epoch=154
04/28/2022 05:33:53 - INFO - __main__ - Step 320 Global step 320 Train loss 0.04 on epoch=159
04/28/2022 05:33:55 - INFO - __main__ - Step 330 Global step 330 Train loss 0.04 on epoch=164
04/28/2022 05:33:58 - INFO - __main__ - Step 340 Global step 340 Train loss 0.05 on epoch=169
04/28/2022 05:34:00 - INFO - __main__ - Step 350 Global step 350 Train loss 0.04 on epoch=174
04/28/2022 05:34:01 - INFO - __main__ - Global step 350 Train loss 0.06 ACC 0.53125 on epoch=174
04/28/2022 05:34:03 - INFO - __main__ - Step 360 Global step 360 Train loss 0.03 on epoch=179
04/28/2022 05:34:06 - INFO - __main__ - Step 370 Global step 370 Train loss 0.01 on epoch=184
04/28/2022 05:34:08 - INFO - __main__ - Step 380 Global step 380 Train loss 0.02 on epoch=189
04/28/2022 05:34:11 - INFO - __main__ - Step 390 Global step 390 Train loss 0.05 on epoch=194
04/28/2022 05:34:13 - INFO - __main__ - Step 400 Global step 400 Train loss 0.05 on epoch=199
04/28/2022 05:34:14 - INFO - __main__ - Global step 400 Train loss 0.03 ACC 0.53125 on epoch=199
04/28/2022 05:34:16 - INFO - __main__ - Step 410 Global step 410 Train loss 0.01 on epoch=204
04/28/2022 05:34:19 - INFO - __main__ - Step 420 Global step 420 Train loss 0.08 on epoch=209
04/28/2022 05:34:21 - INFO - __main__ - Step 430 Global step 430 Train loss 0.03 on epoch=214
04/28/2022 05:34:24 - INFO - __main__ - Step 440 Global step 440 Train loss 0.05 on epoch=219
04/28/2022 05:34:26 - INFO - __main__ - Step 450 Global step 450 Train loss 0.03 on epoch=224
04/28/2022 05:34:27 - INFO - __main__ - Global step 450 Train loss 0.04 ACC 0.59375 on epoch=224
04/28/2022 05:34:27 - INFO - __main__ - Saving model with best ACC: 0.53125 -> 0.59375 on epoch=224, global_step=450
04/28/2022 05:34:30 - INFO - __main__ - Step 460 Global step 460 Train loss 0.04 on epoch=229
04/28/2022 05:34:32 - INFO - __main__ - Step 470 Global step 470 Train loss 0.01 on epoch=234
04/28/2022 05:34:35 - INFO - __main__ - Step 480 Global step 480 Train loss 0.01 on epoch=239
04/28/2022 05:34:37 - INFO - __main__ - Step 490 Global step 490 Train loss 0.05 on epoch=244
04/28/2022 05:34:40 - INFO - __main__ - Step 500 Global step 500 Train loss 0.01 on epoch=249
04/28/2022 05:34:40 - INFO - __main__ - Global step 500 Train loss 0.03 ACC 0.53125 on epoch=249
04/28/2022 05:34:43 - INFO - __main__ - Step 510 Global step 510 Train loss 0.01 on epoch=254
04/28/2022 05:34:45 - INFO - __main__ - Step 520 Global step 520 Train loss 0.01 on epoch=259
04/28/2022 05:34:48 - INFO - __main__ - Step 530 Global step 530 Train loss 0.01 on epoch=264
04/28/2022 05:34:50 - INFO - __main__ - Step 540 Global step 540 Train loss 0.03 on epoch=269
04/28/2022 05:34:53 - INFO - __main__ - Step 550 Global step 550 Train loss 0.01 on epoch=274
04/28/2022 05:34:53 - INFO - __main__ - Global step 550 Train loss 0.01 ACC 0.53125 on epoch=274
04/28/2022 05:34:56 - INFO - __main__ - Step 560 Global step 560 Train loss 0.03 on epoch=279
04/28/2022 05:34:58 - INFO - __main__ - Step 570 Global step 570 Train loss 0.08 on epoch=284
04/28/2022 05:35:01 - INFO - __main__ - Step 580 Global step 580 Train loss 0.04 on epoch=289
04/28/2022 05:35:03 - INFO - __main__ - Step 590 Global step 590 Train loss 0.01 on epoch=294
04/28/2022 05:35:06 - INFO - __main__ - Step 600 Global step 600 Train loss 0.02 on epoch=299
04/28/2022 05:35:07 - INFO - __main__ - Global step 600 Train loss 0.03 ACC 0.5 on epoch=299
04/28/2022 05:35:09 - INFO - __main__ - Step 610 Global step 610 Train loss 0.01 on epoch=304
04/28/2022 05:35:12 - INFO - __main__ - Step 620 Global step 620 Train loss 0.05 on epoch=309
04/28/2022 05:35:14 - INFO - __main__ - Step 630 Global step 630 Train loss 0.00 on epoch=314
04/28/2022 05:35:17 - INFO - __main__ - Step 640 Global step 640 Train loss 0.02 on epoch=319
04/28/2022 05:35:19 - INFO - __main__ - Step 650 Global step 650 Train loss 0.01 on epoch=324
04/28/2022 05:35:20 - INFO - __main__ - Global step 650 Train loss 0.02 ACC 0.53125 on epoch=324
04/28/2022 05:35:22 - INFO - __main__ - Step 660 Global step 660 Train loss 0.02 on epoch=329
04/28/2022 05:35:25 - INFO - __main__ - Step 670 Global step 670 Train loss 0.01 on epoch=334
04/28/2022 05:35:27 - INFO - __main__ - Step 680 Global step 680 Train loss 0.02 on epoch=339
04/28/2022 05:35:30 - INFO - __main__ - Step 690 Global step 690 Train loss 0.01 on epoch=344
04/28/2022 05:35:32 - INFO - __main__ - Step 700 Global step 700 Train loss 0.00 on epoch=349
04/28/2022 05:35:33 - INFO - __main__ - Global step 700 Train loss 0.01 ACC 0.5 on epoch=349
04/28/2022 05:35:36 - INFO - __main__ - Step 710 Global step 710 Train loss 0.01 on epoch=354
04/28/2022 05:35:38 - INFO - __main__ - Step 720 Global step 720 Train loss 0.01 on epoch=359
04/28/2022 05:35:41 - INFO - __main__ - Step 730 Global step 730 Train loss 0.01 on epoch=364
04/28/2022 05:35:43 - INFO - __main__ - Step 740 Global step 740 Train loss 0.01 on epoch=369
04/28/2022 05:35:46 - INFO - __main__ - Step 750 Global step 750 Train loss 0.00 on epoch=374
04/28/2022 05:35:46 - INFO - __main__ - Global step 750 Train loss 0.01 ACC 0.5625 on epoch=374
04/28/2022 05:35:49 - INFO - __main__ - Step 760 Global step 760 Train loss 0.02 on epoch=379
04/28/2022 05:35:51 - INFO - __main__ - Step 770 Global step 770 Train loss 0.01 on epoch=384
04/28/2022 05:35:54 - INFO - __main__ - Step 780 Global step 780 Train loss 0.01 on epoch=389
04/28/2022 05:35:56 - INFO - __main__ - Step 790 Global step 790 Train loss 0.00 on epoch=394
04/28/2022 05:35:59 - INFO - __main__ - Step 800 Global step 800 Train loss 0.01 on epoch=399
04/28/2022 05:36:00 - INFO - __main__ - Global step 800 Train loss 0.01 ACC 0.59375 on epoch=399
04/28/2022 05:36:02 - INFO - __main__ - Step 810 Global step 810 Train loss 0.00 on epoch=404
04/28/2022 05:36:05 - INFO - __main__ - Step 820 Global step 820 Train loss 0.05 on epoch=409
04/28/2022 05:36:07 - INFO - __main__ - Step 830 Global step 830 Train loss 0.00 on epoch=414
04/28/2022 05:36:10 - INFO - __main__ - Step 840 Global step 840 Train loss 0.00 on epoch=419
04/28/2022 05:36:12 - INFO - __main__ - Step 850 Global step 850 Train loss 0.00 on epoch=424
04/28/2022 05:36:13 - INFO - __main__ - Global step 850 Train loss 0.01 ACC 0.5625 on epoch=424
04/28/2022 05:36:15 - INFO - __main__ - Step 860 Global step 860 Train loss 0.01 on epoch=429
04/28/2022 05:36:18 - INFO - __main__ - Step 870 Global step 870 Train loss 0.00 on epoch=434
04/28/2022 05:36:20 - INFO - __main__ - Step 880 Global step 880 Train loss 0.00 on epoch=439
04/28/2022 05:36:23 - INFO - __main__ - Step 890 Global step 890 Train loss 0.00 on epoch=444
04/28/2022 05:36:25 - INFO - __main__ - Step 900 Global step 900 Train loss 0.00 on epoch=449
04/28/2022 05:36:26 - INFO - __main__ - Global step 900 Train loss 0.00 ACC 0.5 on epoch=449
04/28/2022 05:36:28 - INFO - __main__ - Step 910 Global step 910 Train loss 0.04 on epoch=454
04/28/2022 05:36:31 - INFO - __main__ - Step 920 Global step 920 Train loss 0.00 on epoch=459
04/28/2022 05:36:33 - INFO - __main__ - Step 930 Global step 930 Train loss 0.00 on epoch=464
04/28/2022 05:36:36 - INFO - __main__ - Step 940 Global step 940 Train loss 0.03 on epoch=469
04/28/2022 05:36:38 - INFO - __main__ - Step 950 Global step 950 Train loss 0.00 on epoch=474
04/28/2022 05:36:39 - INFO - __main__ - Global step 950 Train loss 0.02 ACC 0.5625 on epoch=474
04/28/2022 05:36:41 - INFO - __main__ - Step 960 Global step 960 Train loss 0.00 on epoch=479
04/28/2022 05:36:44 - INFO - __main__ - Step 970 Global step 970 Train loss 0.02 on epoch=484
04/28/2022 05:36:46 - INFO - __main__ - Step 980 Global step 980 Train loss 0.00 on epoch=489
04/28/2022 05:36:49 - INFO - __main__ - Step 990 Global step 990 Train loss 0.00 on epoch=494
04/28/2022 05:36:51 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.00 on epoch=499
04/28/2022 05:36:53 - INFO - __main__ - Global step 1000 Train loss 0.01 ACC 0.53125 on epoch=499
04/28/2022 05:36:55 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.01 on epoch=504
04/28/2022 05:36:58 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.02 on epoch=509
04/28/2022 05:37:00 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.02 on epoch=514
04/28/2022 05:37:03 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.03 on epoch=519
04/28/2022 05:37:05 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.00 on epoch=524
04/28/2022 05:37:06 - INFO - __main__ - Global step 1050 Train loss 0.02 ACC 0.53125 on epoch=524
04/28/2022 05:37:09 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.00 on epoch=529
04/28/2022 05:37:11 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.00 on epoch=534
04/28/2022 05:37:14 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.00 on epoch=539
04/28/2022 05:37:16 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.01 on epoch=544
04/28/2022 05:37:19 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.01 on epoch=549
04/28/2022 05:37:19 - INFO - __main__ - Global step 1100 Train loss 0.01 ACC 0.53125 on epoch=549
04/28/2022 05:37:22 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.00 on epoch=554
04/28/2022 05:37:24 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.00 on epoch=559
04/28/2022 05:37:27 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.00 on epoch=564
04/28/2022 05:37:29 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.00 on epoch=569
04/28/2022 05:37:32 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.00 on epoch=574
04/28/2022 05:37:32 - INFO - __main__ - Global step 1150 Train loss 0.00 ACC 0.5625 on epoch=574
04/28/2022 05:37:35 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.03 on epoch=579
04/28/2022 05:37:37 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.00 on epoch=584
04/28/2022 05:37:40 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.00 on epoch=589
04/28/2022 05:37:42 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.00 on epoch=594
04/28/2022 05:37:45 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.00 on epoch=599
04/28/2022 05:37:46 - INFO - __main__ - Global step 1200 Train loss 0.01 ACC 0.53125 on epoch=599
04/28/2022 05:37:48 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.00 on epoch=604
04/28/2022 05:37:50 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=609
04/28/2022 05:37:53 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.00 on epoch=614
04/28/2022 05:37:55 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=619
04/28/2022 05:37:58 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.01 on epoch=624
04/28/2022 05:37:59 - INFO - __main__ - Global step 1250 Train loss 0.01 ACC 0.5 on epoch=624
04/28/2022 05:38:01 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.00 on epoch=629
04/28/2022 05:38:04 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.00 on epoch=634
04/28/2022 05:38:06 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.00 on epoch=639
04/28/2022 05:38:09 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=644
04/28/2022 05:38:11 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.00 on epoch=649
04/28/2022 05:38:12 - INFO - __main__ - Global step 1300 Train loss 0.00 ACC 0.53125 on epoch=649
04/28/2022 05:38:14 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.00 on epoch=654
04/28/2022 05:38:17 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.00 on epoch=659
04/28/2022 05:38:19 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.00 on epoch=664
04/28/2022 05:38:22 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.00 on epoch=669
04/28/2022 05:38:24 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.00 on epoch=674
04/28/2022 05:38:25 - INFO - __main__ - Global step 1350 Train loss 0.00 ACC 0.5 on epoch=674
04/28/2022 05:38:27 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.00 on epoch=679
04/28/2022 05:38:30 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.00 on epoch=684
04/28/2022 05:38:32 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=689
04/28/2022 05:38:35 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.00 on epoch=694
04/28/2022 05:38:37 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.00 on epoch=699
04/28/2022 05:38:38 - INFO - __main__ - Global step 1400 Train loss 0.00 ACC 0.53125 on epoch=699
04/28/2022 05:38:40 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=704
04/28/2022 05:38:43 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=709
04/28/2022 05:38:45 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.00 on epoch=714
04/28/2022 05:38:48 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=719
04/28/2022 05:38:50 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=724
04/28/2022 05:38:51 - INFO - __main__ - Global step 1450 Train loss 0.01 ACC 0.59375 on epoch=724
04/28/2022 05:38:54 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=729
04/28/2022 05:38:56 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=734
04/28/2022 05:38:59 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=739
04/28/2022 05:39:01 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.05 on epoch=744
04/28/2022 05:39:04 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=749
04/28/2022 05:39:04 - INFO - __main__ - Global step 1500 Train loss 0.01 ACC 0.5625 on epoch=749
04/28/2022 05:39:07 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=754
04/28/2022 05:39:09 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=759
04/28/2022 05:39:12 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=764
04/28/2022 05:39:14 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=769
04/28/2022 05:39:17 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=774
04/28/2022 05:39:17 - INFO - __main__ - Global step 1550 Train loss 0.00 ACC 0.53125 on epoch=774
04/28/2022 05:39:20 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=779
04/28/2022 05:39:22 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=784
04/28/2022 05:39:25 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=789
04/28/2022 05:39:27 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=794
04/28/2022 05:39:30 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=799
04/28/2022 05:39:31 - INFO - __main__ - Global step 1600 Train loss 0.00 ACC 0.5625 on epoch=799
04/28/2022 05:39:33 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=804
04/28/2022 05:39:36 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=809
04/28/2022 05:39:38 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=814
04/28/2022 05:39:41 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=819
04/28/2022 05:39:43 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=824
04/28/2022 05:39:44 - INFO - __main__ - Global step 1650 Train loss 0.00 ACC 0.5625 on epoch=824
04/28/2022 05:39:46 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=829
04/28/2022 05:39:49 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=834
04/28/2022 05:39:52 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.05 on epoch=839
04/28/2022 05:39:54 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=844
04/28/2022 05:39:57 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=849
04/28/2022 05:39:57 - INFO - __main__ - Global step 1700 Train loss 0.01 ACC 0.53125 on epoch=849
04/28/2022 05:40:00 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=854
04/28/2022 05:40:02 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=859
04/28/2022 05:40:05 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=864
04/28/2022 05:40:07 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=869
04/28/2022 05:40:10 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=874
04/28/2022 05:40:11 - INFO - __main__ - Global step 1750 Train loss 0.00 ACC 0.5625 on epoch=874
04/28/2022 05:40:13 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=879
04/28/2022 05:40:16 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=884
04/28/2022 05:40:18 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=889
04/28/2022 05:40:21 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=894
04/28/2022 05:40:23 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=899
04/28/2022 05:40:24 - INFO - __main__ - Global step 1800 Train loss 0.00 ACC 0.5625 on epoch=899
04/28/2022 05:40:26 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=904
04/28/2022 05:40:29 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=909
04/28/2022 05:40:32 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=914
04/28/2022 05:40:34 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=919
04/28/2022 05:40:37 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=924
04/28/2022 05:40:37 - INFO - __main__ - Global step 1850 Train loss 0.00 ACC 0.5625 on epoch=924
04/28/2022 05:40:40 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=929
04/28/2022 05:40:42 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=934
04/28/2022 05:40:45 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=939
04/28/2022 05:40:47 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=944
04/28/2022 05:40:50 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=949
04/28/2022 05:40:50 - INFO - __main__ - Global step 1900 Train loss 0.00 ACC 0.53125 on epoch=949
04/28/2022 05:40:53 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=954
04/28/2022 05:40:55 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=959
04/28/2022 05:40:58 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=964
04/28/2022 05:41:00 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=969
04/28/2022 05:41:03 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=974
04/28/2022 05:41:04 - INFO - __main__ - Global step 1950 Train loss 0.00 ACC 0.65625 on epoch=974
04/28/2022 05:41:04 - INFO - __main__ - Saving model with best ACC: 0.59375 -> 0.65625 on epoch=974, global_step=1950
04/28/2022 05:41:06 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=979
04/28/2022 05:41:09 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=984
04/28/2022 05:41:11 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=989
04/28/2022 05:41:14 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=994
04/28/2022 05:41:16 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=999
04/28/2022 05:41:17 - INFO - __main__ - Global step 2000 Train loss 0.00 ACC 0.625 on epoch=999
04/28/2022 05:41:17 - INFO - __main__ - save last model!
04/28/2022 05:41:17 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
04/28/2022 05:41:17 - INFO - __main__ - Start tokenizing ... 1000 instances
04/28/2022 05:41:17 - INFO - __main__ - Printing 3 examples
04/28/2022 05:41:17 - INFO - __main__ -  [wino_grande] Sarah was a much better surgeon than Maria so _ always got the easier cases. (A) Sarah (B) Maria
04/28/2022 05:41:17 - INFO - __main__ - ['Maria']
04/28/2022 05:41:17 - INFO - __main__ -  [wino_grande] Sarah was a much better surgeon than Maria so _ always got the harder cases. (A) Sarah (B) Maria
04/28/2022 05:41:17 - INFO - __main__ - ['Sarah']
04/28/2022 05:41:17 - INFO - __main__ -  [wino_grande] They were worried the wine would ruin the bed and the blanket, but the _ was't ruined. (A) blanket (B) bed
04/28/2022 05:41:17 - INFO - __main__ - ['bed']
04/28/2022 05:41:17 - INFO - __main__ - Tokenizing Input ...
04/28/2022 05:41:17 - INFO - __main__ - Tokenizing Output ...
04/28/2022 05:41:18 - INFO - __main__ - Loaded 1000 examples from test data
04/28/2022 05:41:19 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 05:41:19 - INFO - __main__ - Printing 3 examples
04/28/2022 05:41:19 - INFO - __main__ -  [wino_grande] Craig volunteered to help the dyslexic students at the school while Joel avoided them, since _ struggled with reading. (A) Craig (B) Joel
04/28/2022 05:41:19 - INFO - __main__ - ['Joel']
04/28/2022 05:41:19 - INFO - __main__ -  [wino_grande] Betty projects much more happiness than Amy, _ because/although she smiles a lot more often. (A) Betty (B) Amy
04/28/2022 05:41:19 - INFO - __main__ - ['Betty']
04/28/2022 05:41:19 - INFO - __main__ -  [wino_grande] Kevin confidently told Jason that his engraving business was going to make him rich.  _ was skeptical. (A) Kevin (B) Jason
04/28/2022 05:41:19 - INFO - __main__ - ['Jason']
04/28/2022 05:41:19 - INFO - __main__ - Tokenizing Input ...
04/28/2022 05:41:19 - INFO - __main__ - Tokenizing Output ...
04/28/2022 05:41:19 - INFO - __main__ - Loaded 32 examples from train data
04/28/2022 05:41:19 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 05:41:19 - INFO - __main__ - Printing 3 examples
04/28/2022 05:41:19 - INFO - __main__ -  [wino_grande] Lindsey was more excited than Laura about having a gender reveal party for the baby. _ thought they were adorable. (A) Lindsey (B) Laura
04/28/2022 05:41:19 - INFO - __main__ - ['Lindsey']
04/28/2022 05:41:19 - INFO - __main__ -  [wino_grande] She liked the style of the shoes far more than the pants, because the _ looked gaudy. (A) pants (B) shoes
04/28/2022 05:41:19 - INFO - __main__ - ['pants']
04/28/2022 05:41:19 - INFO - __main__ -  [wino_grande] Julie's foot would not fit into her new pair of cowboy boots she just bought, the _ was too narrow. (A) boot (B) foot
04/28/2022 05:41:19 - INFO - __main__ - ['boot']
04/28/2022 05:41:19 - INFO - __main__ - Tokenizing Input ...
04/28/2022 05:41:19 - INFO - __main__ - Tokenizing Output ...
04/28/2022 05:41:19 - INFO - __main__ - Loaded 32 examples from dev data
04/28/2022 05:41:34 - INFO - __main__ - load prompt embedding from ckpt
04/28/2022 05:41:35 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/28/2022 05:41:35 - INFO - __main__ - Starting training!
04/28/2022 05:41:42 - INFO - __main__ - Saved prediction in models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-wino_grande/wino_grande_32_100_0.3_8_predictions.txt
04/28/2022 05:41:42 - INFO - __main__ - ACC on test data: 0.5110
04/28/2022 05:41:42 - INFO - __main__ - prefix=wino_grande_32_100, lr=0.3, bsz=8, dev_performance=0.65625, test_performance=0.511
04/28/2022 05:41:42 - INFO - __main__ - Running ... prefix=wino_grande_32_100, lr=0.2, bsz=8 ...
04/28/2022 05:41:43 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 05:41:43 - INFO - __main__ - Printing 3 examples
04/28/2022 05:41:43 - INFO - __main__ -  [wino_grande] Craig volunteered to help the dyslexic students at the school while Joel avoided them, since _ struggled with reading. (A) Craig (B) Joel
04/28/2022 05:41:43 - INFO - __main__ - ['Joel']
04/28/2022 05:41:43 - INFO - __main__ -  [wino_grande] Betty projects much more happiness than Amy, _ because/although she smiles a lot more often. (A) Betty (B) Amy
04/28/2022 05:41:43 - INFO - __main__ - ['Betty']
04/28/2022 05:41:43 - INFO - __main__ -  [wino_grande] Kevin confidently told Jason that his engraving business was going to make him rich.  _ was skeptical. (A) Kevin (B) Jason
04/28/2022 05:41:43 - INFO - __main__ - ['Jason']
04/28/2022 05:41:43 - INFO - __main__ - Tokenizing Input ...
04/28/2022 05:41:43 - INFO - __main__ - Tokenizing Output ...
04/28/2022 05:41:43 - INFO - __main__ - Loaded 32 examples from train data
04/28/2022 05:41:43 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 05:41:43 - INFO - __main__ - Printing 3 examples
04/28/2022 05:41:43 - INFO - __main__ -  [wino_grande] Lindsey was more excited than Laura about having a gender reveal party for the baby. _ thought they were adorable. (A) Lindsey (B) Laura
04/28/2022 05:41:43 - INFO - __main__ - ['Lindsey']
04/28/2022 05:41:43 - INFO - __main__ -  [wino_grande] She liked the style of the shoes far more than the pants, because the _ looked gaudy. (A) pants (B) shoes
04/28/2022 05:41:43 - INFO - __main__ - ['pants']
04/28/2022 05:41:43 - INFO - __main__ -  [wino_grande] Julie's foot would not fit into her new pair of cowboy boots she just bought, the _ was too narrow. (A) boot (B) foot
04/28/2022 05:41:43 - INFO - __main__ - ['boot']
04/28/2022 05:41:43 - INFO - __main__ - Tokenizing Input ...
04/28/2022 05:41:43 - INFO - __main__ - Tokenizing Output ...
04/28/2022 05:41:43 - INFO - __main__ - Loaded 32 examples from dev data
04/28/2022 05:41:59 - INFO - __main__ - load prompt embedding from ckpt
04/28/2022 05:41:59 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/28/2022 05:41:59 - INFO - __main__ - Starting training!
04/28/2022 05:42:02 - INFO - __main__ - Step 10 Global step 10 Train loss 4.21 on epoch=4
04/28/2022 05:42:05 - INFO - __main__ - Step 20 Global step 20 Train loss 2.21 on epoch=9
04/28/2022 05:42:07 - INFO - __main__ - Step 30 Global step 30 Train loss 1.18 on epoch=14
04/28/2022 05:42:10 - INFO - __main__ - Step 40 Global step 40 Train loss 1.05 on epoch=19
04/28/2022 05:42:12 - INFO - __main__ - Step 50 Global step 50 Train loss 0.73 on epoch=24
04/28/2022 05:42:13 - INFO - __main__ - Global step 50 Train loss 1.88 ACC 0.4375 on epoch=24
04/28/2022 05:42:13 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.4375 on epoch=24, global_step=50
04/28/2022 05:42:16 - INFO - __main__ - Step 60 Global step 60 Train loss 0.51 on epoch=29
04/28/2022 05:42:18 - INFO - __main__ - Step 70 Global step 70 Train loss 0.54 on epoch=34
04/28/2022 05:42:21 - INFO - __main__ - Step 80 Global step 80 Train loss 0.40 on epoch=39
04/28/2022 05:42:23 - INFO - __main__ - Step 90 Global step 90 Train loss 0.43 on epoch=44
04/28/2022 05:42:26 - INFO - __main__ - Step 100 Global step 100 Train loss 0.45 on epoch=49
04/28/2022 05:42:26 - INFO - __main__ - Global step 100 Train loss 0.47 ACC 0.53125 on epoch=49
04/28/2022 05:42:26 - INFO - __main__ - Saving model with best ACC: 0.4375 -> 0.53125 on epoch=49, global_step=100
04/28/2022 05:42:29 - INFO - __main__ - Step 110 Global step 110 Train loss 0.39 on epoch=54
04/28/2022 05:42:32 - INFO - __main__ - Step 120 Global step 120 Train loss 0.34 on epoch=59
04/28/2022 05:42:34 - INFO - __main__ - Step 130 Global step 130 Train loss 0.29 on epoch=64
04/28/2022 05:42:37 - INFO - __main__ - Step 140 Global step 140 Train loss 0.26 on epoch=69
04/28/2022 05:42:39 - INFO - __main__ - Step 150 Global step 150 Train loss 0.21 on epoch=74
04/28/2022 05:42:40 - INFO - __main__ - Global step 150 Train loss 0.30 ACC 0.5 on epoch=74
04/28/2022 05:42:42 - INFO - __main__ - Step 160 Global step 160 Train loss 0.24 on epoch=79
04/28/2022 05:42:45 - INFO - __main__ - Step 170 Global step 170 Train loss 0.21 on epoch=84
04/28/2022 05:42:47 - INFO - __main__ - Step 180 Global step 180 Train loss 0.21 on epoch=89
04/28/2022 05:42:50 - INFO - __main__ - Step 190 Global step 190 Train loss 0.23 on epoch=94
04/28/2022 05:42:52 - INFO - __main__ - Step 200 Global step 200 Train loss 0.28 on epoch=99
04/28/2022 05:42:53 - INFO - __main__ - Global step 200 Train loss 0.23 ACC 0.53125 on epoch=99
04/28/2022 05:42:56 - INFO - __main__ - Step 210 Global step 210 Train loss 0.15 on epoch=104
04/28/2022 05:42:58 - INFO - __main__ - Step 220 Global step 220 Train loss 0.18 on epoch=109
04/28/2022 05:43:00 - INFO - __main__ - Step 230 Global step 230 Train loss 0.15 on epoch=114
04/28/2022 05:43:03 - INFO - __main__ - Step 240 Global step 240 Train loss 0.12 on epoch=119
04/28/2022 05:43:05 - INFO - __main__ - Step 250 Global step 250 Train loss 0.13 on epoch=124
04/28/2022 05:43:06 - INFO - __main__ - Global step 250 Train loss 0.15 ACC 0.46875 on epoch=124
04/28/2022 05:43:09 - INFO - __main__ - Step 260 Global step 260 Train loss 0.14 on epoch=129
04/28/2022 05:43:11 - INFO - __main__ - Step 270 Global step 270 Train loss 0.17 on epoch=134
04/28/2022 05:43:14 - INFO - __main__ - Step 280 Global step 280 Train loss 0.15 on epoch=139
04/28/2022 05:43:16 - INFO - __main__ - Step 290 Global step 290 Train loss 0.14 on epoch=144
04/28/2022 05:43:19 - INFO - __main__ - Step 300 Global step 300 Train loss 0.08 on epoch=149
04/28/2022 05:43:19 - INFO - __main__ - Global step 300 Train loss 0.13 ACC 0.53125 on epoch=149
04/28/2022 05:43:22 - INFO - __main__ - Step 310 Global step 310 Train loss 0.07 on epoch=154
04/28/2022 05:43:24 - INFO - __main__ - Step 320 Global step 320 Train loss 0.17 on epoch=159
04/28/2022 05:43:27 - INFO - __main__ - Step 330 Global step 330 Train loss 0.06 on epoch=164
04/28/2022 05:43:29 - INFO - __main__ - Step 340 Global step 340 Train loss 0.14 on epoch=169
04/28/2022 05:43:32 - INFO - __main__ - Step 350 Global step 350 Train loss 0.12 on epoch=174
04/28/2022 05:43:32 - INFO - __main__ - Global step 350 Train loss 0.11 ACC 0.46875 on epoch=174
04/28/2022 05:43:35 - INFO - __main__ - Step 360 Global step 360 Train loss 0.05 on epoch=179
04/28/2022 05:43:37 - INFO - __main__ - Step 370 Global step 370 Train loss 0.06 on epoch=184
04/28/2022 05:43:40 - INFO - __main__ - Step 380 Global step 380 Train loss 0.10 on epoch=189
04/28/2022 05:43:42 - INFO - __main__ - Step 390 Global step 390 Train loss 0.12 on epoch=194
04/28/2022 05:43:45 - INFO - __main__ - Step 400 Global step 400 Train loss 0.10 on epoch=199
04/28/2022 05:43:46 - INFO - __main__ - Global step 400 Train loss 0.09 ACC 0.53125 on epoch=199
04/28/2022 05:43:48 - INFO - __main__ - Step 410 Global step 410 Train loss 0.07 on epoch=204
04/28/2022 05:43:51 - INFO - __main__ - Step 420 Global step 420 Train loss 0.16 on epoch=209
04/28/2022 05:43:53 - INFO - __main__ - Step 430 Global step 430 Train loss 0.07 on epoch=214
04/28/2022 05:43:56 - INFO - __main__ - Step 440 Global step 440 Train loss 0.04 on epoch=219
04/28/2022 05:43:58 - INFO - __main__ - Step 450 Global step 450 Train loss 0.03 on epoch=224
04/28/2022 05:43:59 - INFO - __main__ - Global step 450 Train loss 0.07 ACC 0.46875 on epoch=224
04/28/2022 05:44:01 - INFO - __main__ - Step 460 Global step 460 Train loss 0.06 on epoch=229
04/28/2022 05:44:04 - INFO - __main__ - Step 470 Global step 470 Train loss 0.02 on epoch=234
04/28/2022 05:44:06 - INFO - __main__ - Step 480 Global step 480 Train loss 0.04 on epoch=239
04/28/2022 05:44:09 - INFO - __main__ - Step 490 Global step 490 Train loss 0.05 on epoch=244
04/28/2022 05:44:11 - INFO - __main__ - Step 500 Global step 500 Train loss 0.04 on epoch=249
04/28/2022 05:44:12 - INFO - __main__ - Global step 500 Train loss 0.04 ACC 0.4375 on epoch=249
04/28/2022 05:44:15 - INFO - __main__ - Step 510 Global step 510 Train loss 0.04 on epoch=254
04/28/2022 05:44:17 - INFO - __main__ - Step 520 Global step 520 Train loss 0.04 on epoch=259
04/28/2022 05:44:20 - INFO - __main__ - Step 530 Global step 530 Train loss 0.03 on epoch=264
04/28/2022 05:44:22 - INFO - __main__ - Step 540 Global step 540 Train loss 0.10 on epoch=269
04/28/2022 05:44:25 - INFO - __main__ - Step 550 Global step 550 Train loss 0.02 on epoch=274
04/28/2022 05:44:25 - INFO - __main__ - Global step 550 Train loss 0.05 ACC 0.4375 on epoch=274
04/28/2022 05:44:28 - INFO - __main__ - Step 560 Global step 560 Train loss 0.04 on epoch=279
04/28/2022 05:44:30 - INFO - __main__ - Step 570 Global step 570 Train loss 0.01 on epoch=284
04/28/2022 05:44:33 - INFO - __main__ - Step 580 Global step 580 Train loss 0.05 on epoch=289
04/28/2022 05:44:35 - INFO - __main__ - Step 590 Global step 590 Train loss 0.01 on epoch=294
04/28/2022 05:44:38 - INFO - __main__ - Step 600 Global step 600 Train loss 0.08 on epoch=299
04/28/2022 05:44:39 - INFO - __main__ - Global step 600 Train loss 0.04 ACC 0.46875 on epoch=299
04/28/2022 05:44:41 - INFO - __main__ - Step 610 Global step 610 Train loss 0.03 on epoch=304
04/28/2022 05:44:44 - INFO - __main__ - Step 620 Global step 620 Train loss 0.01 on epoch=309
04/28/2022 05:44:46 - INFO - __main__ - Step 630 Global step 630 Train loss 0.03 on epoch=314
04/28/2022 05:44:49 - INFO - __main__ - Step 640 Global step 640 Train loss 0.01 on epoch=319
04/28/2022 05:44:51 - INFO - __main__ - Step 650 Global step 650 Train loss 0.01 on epoch=324
04/28/2022 05:44:52 - INFO - __main__ - Global step 650 Train loss 0.02 ACC 0.53125 on epoch=324
04/28/2022 05:44:54 - INFO - __main__ - Step 660 Global step 660 Train loss 0.04 on epoch=329
04/28/2022 05:44:57 - INFO - __main__ - Step 670 Global step 670 Train loss 0.02 on epoch=334
04/28/2022 05:44:59 - INFO - __main__ - Step 680 Global step 680 Train loss 0.01 on epoch=339
04/28/2022 05:45:02 - INFO - __main__ - Step 690 Global step 690 Train loss 0.05 on epoch=344
04/28/2022 05:45:04 - INFO - __main__ - Step 700 Global step 700 Train loss 0.00 on epoch=349
04/28/2022 05:45:05 - INFO - __main__ - Global step 700 Train loss 0.03 ACC 0.46875 on epoch=349
04/28/2022 05:45:08 - INFO - __main__ - Step 710 Global step 710 Train loss 0.03 on epoch=354
04/28/2022 05:45:10 - INFO - __main__ - Step 720 Global step 720 Train loss 0.03 on epoch=359
04/28/2022 05:45:13 - INFO - __main__ - Step 730 Global step 730 Train loss 0.02 on epoch=364
04/28/2022 05:45:15 - INFO - __main__ - Step 740 Global step 740 Train loss 0.01 on epoch=369
04/28/2022 05:45:18 - INFO - __main__ - Step 750 Global step 750 Train loss 0.03 on epoch=374
04/28/2022 05:45:18 - INFO - __main__ - Global step 750 Train loss 0.02 ACC 0.46875 on epoch=374
04/28/2022 05:45:21 - INFO - __main__ - Step 760 Global step 760 Train loss 0.00 on epoch=379
04/28/2022 05:45:23 - INFO - __main__ - Step 770 Global step 770 Train loss 0.03 on epoch=384
04/28/2022 05:45:26 - INFO - __main__ - Step 780 Global step 780 Train loss 0.01 on epoch=389
04/28/2022 05:45:28 - INFO - __main__ - Step 790 Global step 790 Train loss 0.03 on epoch=394
04/28/2022 05:45:31 - INFO - __main__ - Step 800 Global step 800 Train loss 0.02 on epoch=399
04/28/2022 05:45:32 - INFO - __main__ - Global step 800 Train loss 0.02 ACC 0.5 on epoch=399
04/28/2022 05:45:34 - INFO - __main__ - Step 810 Global step 810 Train loss 0.00 on epoch=404
04/28/2022 05:45:37 - INFO - __main__ - Step 820 Global step 820 Train loss 0.01 on epoch=409
04/28/2022 05:45:39 - INFO - __main__ - Step 830 Global step 830 Train loss 0.03 on epoch=414
04/28/2022 05:45:42 - INFO - __main__ - Step 840 Global step 840 Train loss 0.01 on epoch=419
04/28/2022 05:45:44 - INFO - __main__ - Step 850 Global step 850 Train loss 0.02 on epoch=424
04/28/2022 05:45:45 - INFO - __main__ - Global step 850 Train loss 0.01 ACC 0.5 on epoch=424
04/28/2022 05:45:47 - INFO - __main__ - Step 860 Global step 860 Train loss 0.02 on epoch=429
04/28/2022 05:45:50 - INFO - __main__ - Step 870 Global step 870 Train loss 0.00 on epoch=434
04/28/2022 05:45:52 - INFO - __main__ - Step 880 Global step 880 Train loss 0.01 on epoch=439
04/28/2022 05:45:55 - INFO - __main__ - Step 890 Global step 890 Train loss 0.01 on epoch=444
04/28/2022 05:45:57 - INFO - __main__ - Step 900 Global step 900 Train loss 0.01 on epoch=449
04/28/2022 05:45:58 - INFO - __main__ - Global step 900 Train loss 0.01 ACC 0.53125 on epoch=449
04/28/2022 05:46:01 - INFO - __main__ - Step 910 Global step 910 Train loss 0.00 on epoch=454
04/28/2022 05:46:03 - INFO - __main__ - Step 920 Global step 920 Train loss 0.01 on epoch=459
04/28/2022 05:46:06 - INFO - __main__ - Step 930 Global step 930 Train loss 0.03 on epoch=464
04/28/2022 05:46:08 - INFO - __main__ - Step 940 Global step 940 Train loss 0.01 on epoch=469
04/28/2022 05:46:11 - INFO - __main__ - Step 950 Global step 950 Train loss 0.02 on epoch=474
04/28/2022 05:46:11 - INFO - __main__ - Global step 950 Train loss 0.02 ACC 0.53125 on epoch=474
04/28/2022 05:46:14 - INFO - __main__ - Step 960 Global step 960 Train loss 0.02 on epoch=479
04/28/2022 05:46:16 - INFO - __main__ - Step 970 Global step 970 Train loss 0.04 on epoch=484
04/28/2022 05:46:19 - INFO - __main__ - Step 980 Global step 980 Train loss 0.01 on epoch=489
04/28/2022 05:46:21 - INFO - __main__ - Step 990 Global step 990 Train loss 0.01 on epoch=494
04/28/2022 05:46:24 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.02 on epoch=499
04/28/2022 05:46:25 - INFO - __main__ - Global step 1000 Train loss 0.02 ACC 0.5 on epoch=499
04/28/2022 05:46:27 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.00 on epoch=504
04/28/2022 05:46:30 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.01 on epoch=509
04/28/2022 05:46:32 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.02 on epoch=514
04/28/2022 05:46:35 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.01 on epoch=519
04/28/2022 05:46:37 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.01 on epoch=524
04/28/2022 05:46:38 - INFO - __main__ - Global step 1050 Train loss 0.01 ACC 0.5 on epoch=524
04/28/2022 05:46:40 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.02 on epoch=529
04/28/2022 05:46:43 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.01 on epoch=534
04/28/2022 05:46:45 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.01 on epoch=539
04/28/2022 05:46:48 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.00 on epoch=544
04/28/2022 05:46:50 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.02 on epoch=549
04/28/2022 05:46:51 - INFO - __main__ - Global step 1100 Train loss 0.01 ACC 0.5 on epoch=549
04/28/2022 05:46:53 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.01 on epoch=554
04/28/2022 05:46:56 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=559
04/28/2022 05:46:58 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.09 on epoch=564
04/28/2022 05:47:01 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.01 on epoch=569
04/28/2022 05:47:03 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=574
04/28/2022 05:47:04 - INFO - __main__ - Global step 1150 Train loss 0.02 ACC 0.5 on epoch=574
04/28/2022 05:47:07 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.00 on epoch=579
04/28/2022 05:47:09 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.01 on epoch=584
04/28/2022 05:47:12 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.00 on epoch=589
04/28/2022 05:47:14 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.01 on epoch=594
04/28/2022 05:47:17 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.00 on epoch=599
04/28/2022 05:47:17 - INFO - __main__ - Global step 1200 Train loss 0.01 ACC 0.46875 on epoch=599
04/28/2022 05:47:20 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.01 on epoch=604
04/28/2022 05:47:22 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=609
04/28/2022 05:47:25 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=614
04/28/2022 05:47:27 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.00 on epoch=619
04/28/2022 05:47:30 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.00 on epoch=624
04/28/2022 05:47:31 - INFO - __main__ - Global step 1250 Train loss 0.01 ACC 0.53125 on epoch=624
04/28/2022 05:47:33 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=629
04/28/2022 05:47:35 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.00 on epoch=634
04/28/2022 05:47:38 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.00 on epoch=639
04/28/2022 05:47:41 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=644
04/28/2022 05:47:43 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.00 on epoch=649
04/28/2022 05:47:44 - INFO - __main__ - Global step 1300 Train loss 0.01 ACC 0.46875 on epoch=649
04/28/2022 05:47:46 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.00 on epoch=654
04/28/2022 05:47:49 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.00 on epoch=659
04/28/2022 05:47:51 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=664
04/28/2022 05:47:54 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.00 on epoch=669
04/28/2022 05:47:56 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=674
04/28/2022 05:47:57 - INFO - __main__ - Global step 1350 Train loss 0.01 ACC 0.5 on epoch=674
04/28/2022 05:47:59 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.02 on epoch=679
04/28/2022 05:48:02 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.03 on epoch=684
04/28/2022 05:48:04 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.00 on epoch=689
04/28/2022 05:48:07 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.00 on epoch=694
04/28/2022 05:48:09 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.00 on epoch=699
04/28/2022 05:48:10 - INFO - __main__ - Global step 1400 Train loss 0.01 ACC 0.46875 on epoch=699
04/28/2022 05:48:12 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=704
04/28/2022 05:48:15 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=709
04/28/2022 05:48:17 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.02 on epoch=714
04/28/2022 05:48:20 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=719
04/28/2022 05:48:22 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.10 on epoch=724
04/28/2022 05:48:23 - INFO - __main__ - Global step 1450 Train loss 0.03 ACC 0.46875 on epoch=724
04/28/2022 05:48:26 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=729
04/28/2022 05:48:28 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=734
04/28/2022 05:48:31 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=739
04/28/2022 05:48:33 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=744
04/28/2022 05:48:36 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=749
04/28/2022 05:48:36 - INFO - __main__ - Global step 1500 Train loss 0.00 ACC 0.4375 on epoch=749
04/28/2022 05:48:39 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=754
04/28/2022 05:48:41 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=759
04/28/2022 05:48:44 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=764
04/28/2022 05:48:46 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=769
04/28/2022 05:48:49 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=774
04/28/2022 05:48:49 - INFO - __main__ - Global step 1550 Train loss 0.00 ACC 0.4375 on epoch=774
04/28/2022 05:48:52 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=779
04/28/2022 05:48:54 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=784
04/28/2022 05:48:57 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=789
04/28/2022 05:48:59 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=794
04/28/2022 05:49:02 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=799
04/28/2022 05:49:02 - INFO - __main__ - Global step 1600 Train loss 0.00 ACC 0.4375 on epoch=799
04/28/2022 05:49:05 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=804
04/28/2022 05:49:07 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=809
04/28/2022 05:49:10 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=814
04/28/2022 05:49:12 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=819
04/28/2022 05:49:15 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=824
04/28/2022 05:49:16 - INFO - __main__ - Global step 1650 Train loss 0.00 ACC 0.4375 on epoch=824
04/28/2022 05:49:18 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.03 on epoch=829
04/28/2022 05:49:21 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=834
04/28/2022 05:49:23 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=839
04/28/2022 05:49:26 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=844
04/28/2022 05:49:28 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=849
04/28/2022 05:49:29 - INFO - __main__ - Global step 1700 Train loss 0.01 ACC 0.4375 on epoch=849
04/28/2022 05:49:31 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=854
04/28/2022 05:49:34 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=859
04/28/2022 05:49:36 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.04 on epoch=864
04/28/2022 05:49:39 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.05 on epoch=869
04/28/2022 05:49:41 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=874
04/28/2022 05:49:42 - INFO - __main__ - Global step 1750 Train loss 0.02 ACC 0.4375 on epoch=874
04/28/2022 05:49:44 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=879
04/28/2022 05:49:47 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=884
04/28/2022 05:49:49 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=889
04/28/2022 05:49:52 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=894
04/28/2022 05:49:54 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=899
04/28/2022 05:49:55 - INFO - __main__ - Global step 1800 Train loss 0.01 ACC 0.40625 on epoch=899
04/28/2022 05:49:57 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=904
04/28/2022 05:50:00 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=909
04/28/2022 05:50:02 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=914
04/28/2022 05:50:05 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=919
04/28/2022 05:50:07 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=924
04/28/2022 05:50:08 - INFO - __main__ - Global step 1850 Train loss 0.01 ACC 0.4375 on epoch=924
04/28/2022 05:50:11 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=929
04/28/2022 05:50:13 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=934
04/28/2022 05:50:16 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=939
04/28/2022 05:50:18 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=944
04/28/2022 05:50:20 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.04 on epoch=949
04/28/2022 05:50:21 - INFO - __main__ - Global step 1900 Train loss 0.01 ACC 0.46875 on epoch=949
04/28/2022 05:50:24 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=954
04/28/2022 05:50:26 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=959
04/28/2022 05:50:29 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=964
04/28/2022 05:50:31 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.06 on epoch=969
04/28/2022 05:50:34 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=974
04/28/2022 05:50:34 - INFO - __main__ - Global step 1950 Train loss 0.02 ACC 0.46875 on epoch=974
04/28/2022 05:50:37 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=979
04/28/2022 05:50:39 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=984
04/28/2022 05:50:42 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=989
04/28/2022 05:50:44 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=994
04/28/2022 05:50:47 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=999
04/28/2022 05:50:47 - INFO - __main__ - Global step 2000 Train loss 0.01 ACC 0.46875 on epoch=999
04/28/2022 05:50:47 - INFO - __main__ - save last model!
04/28/2022 05:50:47 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
04/28/2022 05:50:47 - INFO - __main__ - Start tokenizing ... 1000 instances
04/28/2022 05:50:47 - INFO - __main__ - Printing 3 examples
04/28/2022 05:50:47 - INFO - __main__ -  [wino_grande] Sarah was a much better surgeon than Maria so _ always got the easier cases. (A) Sarah (B) Maria
04/28/2022 05:50:47 - INFO - __main__ - ['Maria']
04/28/2022 05:50:47 - INFO - __main__ -  [wino_grande] Sarah was a much better surgeon than Maria so _ always got the harder cases. (A) Sarah (B) Maria
04/28/2022 05:50:47 - INFO - __main__ - ['Sarah']
04/28/2022 05:50:48 - INFO - __main__ -  [wino_grande] They were worried the wine would ruin the bed and the blanket, but the _ was't ruined. (A) blanket (B) bed
04/28/2022 05:50:48 - INFO - __main__ - ['bed']
04/28/2022 05:50:48 - INFO - __main__ - Tokenizing Input ...
04/28/2022 05:50:48 - INFO - __main__ - Tokenizing Output ...
04/28/2022 05:50:48 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 05:50:48 - INFO - __main__ - Printing 3 examples
04/28/2022 05:50:48 - INFO - __main__ -  [wino_grande] Brett wasn't sure what color of dress to buy unlike Derrick because _ was indecisive. (A) Brett (B) Derrick
04/28/2022 05:50:48 - INFO - __main__ - ['Brett']
04/28/2022 05:50:48 - INFO - __main__ -  [wino_grande] Jennifer felt love for others but Angela did not because _ had a cold feeling. (A) Jennifer (B) Angela
04/28/2022 05:50:48 - INFO - __main__ - ['Angela']
04/28/2022 05:50:48 - INFO - __main__ -  [wino_grande] The toddler was hurling his peas at the couches, as the _ made a very convenient missile. (A) peas (B) couches
04/28/2022 05:50:48 - INFO - __main__ - ['peas']
04/28/2022 05:50:48 - INFO - __main__ - Tokenizing Input ...
04/28/2022 05:50:48 - INFO - __main__ - Tokenizing Output ...
04/28/2022 05:50:48 - INFO - __main__ - Loaded 32 examples from train data
04/28/2022 05:50:48 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 05:50:48 - INFO - __main__ - Printing 3 examples
04/28/2022 05:50:48 - INFO - __main__ -  [wino_grande] They went on a safari and saw a panda eating bamboo, which Megan loved but Elena didn't care about. _ 's favorite animal was the panda. (A) Megan (B) Elena
04/28/2022 05:50:48 - INFO - __main__ - ['Megan']
04/28/2022 05:50:48 - INFO - __main__ -  [wino_grande] People liked being around Jeffrey more than around Neil because _ was a nice person. (A) Jeffrey (B) Neil
04/28/2022 05:50:48 - INFO - __main__ - ['Jeffrey']
04/28/2022 05:50:48 - INFO - __main__ -  [wino_grande] Steven worked all summer long to create a statue for Ian because _ hired him to. (A) Steven (B) Ian
04/28/2022 05:50:48 - INFO - __main__ - ['Ian']
04/28/2022 05:50:48 - INFO - __main__ - Tokenizing Input ...
04/28/2022 05:50:48 - INFO - __main__ - Tokenizing Output ...
04/28/2022 05:50:48 - INFO - __main__ - Loaded 32 examples from dev data
04/28/2022 05:50:49 - INFO - __main__ - Loaded 1000 examples from test data
04/28/2022 05:51:03 - INFO - __main__ - load prompt embedding from ckpt
04/28/2022 05:51:04 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/28/2022 05:51:04 - INFO - __main__ - Starting training!
04/28/2022 05:51:11 - INFO - __main__ - Saved prediction in models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-wino_grande/wino_grande_32_100_0.2_8_predictions.txt
04/28/2022 05:51:11 - INFO - __main__ - ACC on test data: 0.4950
04/28/2022 05:51:12 - INFO - __main__ - prefix=wino_grande_32_100, lr=0.2, bsz=8, dev_performance=0.53125, test_performance=0.495
04/28/2022 05:51:12 - INFO - __main__ - Running ... prefix=wino_grande_32_13, lr=0.5, bsz=8 ...
04/28/2022 05:51:13 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 05:51:13 - INFO - __main__ - Printing 3 examples
04/28/2022 05:51:13 - INFO - __main__ -  [wino_grande] Brett wasn't sure what color of dress to buy unlike Derrick because _ was indecisive. (A) Brett (B) Derrick
04/28/2022 05:51:13 - INFO - __main__ - ['Brett']
04/28/2022 05:51:13 - INFO - __main__ -  [wino_grande] Jennifer felt love for others but Angela did not because _ had a cold feeling. (A) Jennifer (B) Angela
04/28/2022 05:51:13 - INFO - __main__ - ['Angela']
04/28/2022 05:51:13 - INFO - __main__ -  [wino_grande] The toddler was hurling his peas at the couches, as the _ made a very convenient missile. (A) peas (B) couches
04/28/2022 05:51:13 - INFO - __main__ - ['peas']
04/28/2022 05:51:13 - INFO - __main__ - Tokenizing Input ...
04/28/2022 05:51:13 - INFO - __main__ - Tokenizing Output ...
04/28/2022 05:51:13 - INFO - __main__ - Loaded 32 examples from train data
04/28/2022 05:51:13 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 05:51:13 - INFO - __main__ - Printing 3 examples
04/28/2022 05:51:13 - INFO - __main__ -  [wino_grande] They went on a safari and saw a panda eating bamboo, which Megan loved but Elena didn't care about. _ 's favorite animal was the panda. (A) Megan (B) Elena
04/28/2022 05:51:13 - INFO - __main__ - ['Megan']
04/28/2022 05:51:13 - INFO - __main__ -  [wino_grande] People liked being around Jeffrey more than around Neil because _ was a nice person. (A) Jeffrey (B) Neil
04/28/2022 05:51:13 - INFO - __main__ - ['Jeffrey']
04/28/2022 05:51:13 - INFO - __main__ -  [wino_grande] Steven worked all summer long to create a statue for Ian because _ hired him to. (A) Steven (B) Ian
04/28/2022 05:51:13 - INFO - __main__ - ['Ian']
04/28/2022 05:51:13 - INFO - __main__ - Tokenizing Input ...
04/28/2022 05:51:13 - INFO - __main__ - Tokenizing Output ...
04/28/2022 05:51:13 - INFO - __main__ - Loaded 32 examples from dev data
04/28/2022 05:51:32 - INFO - __main__ - load prompt embedding from ckpt
04/28/2022 05:51:32 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/28/2022 05:51:32 - INFO - __main__ - Starting training!
04/28/2022 05:51:35 - INFO - __main__ - Step 10 Global step 10 Train loss 3.19 on epoch=4
04/28/2022 05:51:38 - INFO - __main__ - Step 20 Global step 20 Train loss 1.28 on epoch=9
04/28/2022 05:51:40 - INFO - __main__ - Step 30 Global step 30 Train loss 2.20 on epoch=14
04/28/2022 05:51:43 - INFO - __main__ - Step 40 Global step 40 Train loss 1.76 on epoch=19
04/28/2022 05:51:45 - INFO - __main__ - Step 50 Global step 50 Train loss 1.30 on epoch=24
04/28/2022 05:51:47 - INFO - __main__ - Global step 50 Train loss 1.95 ACC 0.5625 on epoch=24
04/28/2022 05:51:47 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.5625 on epoch=24, global_step=50
04/28/2022 05:51:49 - INFO - __main__ - Step 60 Global step 60 Train loss 0.97 on epoch=29
04/28/2022 05:51:52 - INFO - __main__ - Step 70 Global step 70 Train loss 1.03 on epoch=34
04/28/2022 05:51:54 - INFO - __main__ - Step 80 Global step 80 Train loss 0.99 on epoch=39
04/28/2022 05:51:57 - INFO - __main__ - Step 90 Global step 90 Train loss 0.96 on epoch=44
04/28/2022 05:51:59 - INFO - __main__ - Step 100 Global step 100 Train loss 0.76 on epoch=49
04/28/2022 05:52:00 - INFO - __main__ - Global step 100 Train loss 0.94 ACC 0.59375 on epoch=49
04/28/2022 05:52:00 - INFO - __main__ - Saving model with best ACC: 0.5625 -> 0.59375 on epoch=49, global_step=100
04/28/2022 05:52:02 - INFO - __main__ - Step 110 Global step 110 Train loss 0.68 on epoch=54
04/28/2022 05:52:05 - INFO - __main__ - Step 120 Global step 120 Train loss 0.65 on epoch=59
04/28/2022 05:52:07 - INFO - __main__ - Step 130 Global step 130 Train loss 0.66 on epoch=64
04/28/2022 05:52:10 - INFO - __main__ - Step 140 Global step 140 Train loss 0.62 on epoch=69
04/28/2022 05:52:12 - INFO - __main__ - Step 150 Global step 150 Train loss 0.60 on epoch=74
04/28/2022 05:52:13 - INFO - __main__ - Global step 150 Train loss 0.64 ACC 0.59375 on epoch=74
04/28/2022 05:52:16 - INFO - __main__ - Step 160 Global step 160 Train loss 0.68 on epoch=79
04/28/2022 05:52:18 - INFO - __main__ - Step 170 Global step 170 Train loss 0.70 on epoch=84
04/28/2022 05:52:21 - INFO - __main__ - Step 180 Global step 180 Train loss 0.61 on epoch=89
04/28/2022 05:52:23 - INFO - __main__ - Step 190 Global step 190 Train loss 0.46 on epoch=94
04/28/2022 05:52:25 - INFO - __main__ - Step 200 Global step 200 Train loss 0.48 on epoch=99
04/28/2022 05:52:26 - INFO - __main__ - Global step 200 Train loss 0.59 ACC 0.59375 on epoch=99
04/28/2022 05:52:29 - INFO - __main__ - Step 210 Global step 210 Train loss 0.41 on epoch=104
04/28/2022 05:52:31 - INFO - __main__ - Step 220 Global step 220 Train loss 0.45 on epoch=109
04/28/2022 05:52:34 - INFO - __main__ - Step 230 Global step 230 Train loss 0.39 on epoch=114
04/28/2022 05:52:36 - INFO - __main__ - Step 240 Global step 240 Train loss 0.33 on epoch=119
04/28/2022 05:52:39 - INFO - __main__ - Step 250 Global step 250 Train loss 0.44 on epoch=124
04/28/2022 05:52:40 - INFO - __main__ - Global step 250 Train loss 0.40 ACC 0.625 on epoch=124
04/28/2022 05:52:40 - INFO - __main__ - Saving model with best ACC: 0.59375 -> 0.625 on epoch=124, global_step=250
04/28/2022 05:52:42 - INFO - __main__ - Step 260 Global step 260 Train loss 0.39 on epoch=129
04/28/2022 05:52:45 - INFO - __main__ - Step 270 Global step 270 Train loss 0.27 on epoch=134
04/28/2022 05:52:47 - INFO - __main__ - Step 280 Global step 280 Train loss 0.30 on epoch=139
04/28/2022 05:52:50 - INFO - __main__ - Step 290 Global step 290 Train loss 0.29 on epoch=144
04/28/2022 05:52:52 - INFO - __main__ - Step 300 Global step 300 Train loss 0.29 on epoch=149
04/28/2022 05:52:53 - INFO - __main__ - Global step 300 Train loss 0.31 ACC 0.53125 on epoch=149
04/28/2022 05:52:56 - INFO - __main__ - Step 310 Global step 310 Train loss 0.26 on epoch=154
04/28/2022 05:52:58 - INFO - __main__ - Step 320 Global step 320 Train loss 0.21 on epoch=159
04/28/2022 05:53:01 - INFO - __main__ - Step 330 Global step 330 Train loss 0.25 on epoch=164
04/28/2022 05:53:03 - INFO - __main__ - Step 340 Global step 340 Train loss 0.16 on epoch=169
04/28/2022 05:53:06 - INFO - __main__ - Step 350 Global step 350 Train loss 0.18 on epoch=174
04/28/2022 05:53:07 - INFO - __main__ - Global step 350 Train loss 0.21 ACC 0.53125 on epoch=174
04/28/2022 05:53:09 - INFO - __main__ - Step 360 Global step 360 Train loss 0.22 on epoch=179
04/28/2022 05:53:12 - INFO - __main__ - Step 370 Global step 370 Train loss 0.16 on epoch=184
04/28/2022 05:53:14 - INFO - __main__ - Step 380 Global step 380 Train loss 0.15 on epoch=189
04/28/2022 05:53:16 - INFO - __main__ - Step 390 Global step 390 Train loss 0.18 on epoch=194
04/28/2022 05:53:19 - INFO - __main__ - Step 400 Global step 400 Train loss 0.18 on epoch=199
04/28/2022 05:53:20 - INFO - __main__ - Global step 400 Train loss 0.18 ACC 0.4375 on epoch=199
04/28/2022 05:53:22 - INFO - __main__ - Step 410 Global step 410 Train loss 0.18 on epoch=204
04/28/2022 05:53:25 - INFO - __main__ - Step 420 Global step 420 Train loss 0.19 on epoch=209
04/28/2022 05:53:27 - INFO - __main__ - Step 430 Global step 430 Train loss 0.22 on epoch=214
04/28/2022 05:53:30 - INFO - __main__ - Step 440 Global step 440 Train loss 0.24 on epoch=219
04/28/2022 05:53:32 - INFO - __main__ - Step 450 Global step 450 Train loss 0.13 on epoch=224
04/28/2022 05:53:33 - INFO - __main__ - Global step 450 Train loss 0.19 ACC 0.53125 on epoch=224
04/28/2022 05:53:36 - INFO - __main__ - Step 460 Global step 460 Train loss 0.15 on epoch=229
04/28/2022 05:53:38 - INFO - __main__ - Step 470 Global step 470 Train loss 0.10 on epoch=234
04/28/2022 05:53:41 - INFO - __main__ - Step 480 Global step 480 Train loss 0.15 on epoch=239
04/28/2022 05:53:43 - INFO - __main__ - Step 490 Global step 490 Train loss 0.12 on epoch=244
04/28/2022 05:53:46 - INFO - __main__ - Step 500 Global step 500 Train loss 0.09 on epoch=249
04/28/2022 05:53:47 - INFO - __main__ - Global step 500 Train loss 0.12 ACC 0.5625 on epoch=249
04/28/2022 05:53:49 - INFO - __main__ - Step 510 Global step 510 Train loss 0.05 on epoch=254
04/28/2022 05:53:52 - INFO - __main__ - Step 520 Global step 520 Train loss 0.11 on epoch=259
04/28/2022 05:53:54 - INFO - __main__ - Step 530 Global step 530 Train loss 0.13 on epoch=264
04/28/2022 05:53:57 - INFO - __main__ - Step 540 Global step 540 Train loss 0.10 on epoch=269
04/28/2022 05:53:59 - INFO - __main__ - Step 550 Global step 550 Train loss 0.09 on epoch=274
04/28/2022 05:54:00 - INFO - __main__ - Global step 550 Train loss 0.10 ACC 0.5625 on epoch=274
04/28/2022 05:54:02 - INFO - __main__ - Step 560 Global step 560 Train loss 0.07 on epoch=279
04/28/2022 05:54:05 - INFO - __main__ - Step 570 Global step 570 Train loss 0.11 on epoch=284
04/28/2022 05:54:07 - INFO - __main__ - Step 580 Global step 580 Train loss 0.10 on epoch=289
04/28/2022 05:54:10 - INFO - __main__ - Step 590 Global step 590 Train loss 0.08 on epoch=294
04/28/2022 05:54:12 - INFO - __main__ - Step 600 Global step 600 Train loss 0.09 on epoch=299
04/28/2022 05:54:13 - INFO - __main__ - Global step 600 Train loss 0.09 ACC 0.53125 on epoch=299
04/28/2022 05:54:16 - INFO - __main__ - Step 610 Global step 610 Train loss 0.09 on epoch=304
04/28/2022 05:54:18 - INFO - __main__ - Step 620 Global step 620 Train loss 0.11 on epoch=309
04/28/2022 05:54:21 - INFO - __main__ - Step 630 Global step 630 Train loss 0.07 on epoch=314
04/28/2022 05:54:23 - INFO - __main__ - Step 640 Global step 640 Train loss 0.08 on epoch=319
04/28/2022 05:54:26 - INFO - __main__ - Step 650 Global step 650 Train loss 0.05 on epoch=324
04/28/2022 05:54:27 - INFO - __main__ - Global step 650 Train loss 0.08 ACC 0.59375 on epoch=324
04/28/2022 05:54:29 - INFO - __main__ - Step 660 Global step 660 Train loss 0.12 on epoch=329
04/28/2022 05:54:32 - INFO - __main__ - Step 670 Global step 670 Train loss 0.10 on epoch=334
04/28/2022 05:54:34 - INFO - __main__ - Step 680 Global step 680 Train loss 0.11 on epoch=339
04/28/2022 05:54:37 - INFO - __main__ - Step 690 Global step 690 Train loss 0.03 on epoch=344
04/28/2022 05:54:39 - INFO - __main__ - Step 700 Global step 700 Train loss 0.06 on epoch=349
04/28/2022 05:54:40 - INFO - __main__ - Global step 700 Train loss 0.08 ACC 0.53125 on epoch=349
04/28/2022 05:54:43 - INFO - __main__ - Step 710 Global step 710 Train loss 0.08 on epoch=354
04/28/2022 05:54:45 - INFO - __main__ - Step 720 Global step 720 Train loss 0.05 on epoch=359
04/28/2022 05:54:48 - INFO - __main__ - Step 730 Global step 730 Train loss 0.08 on epoch=364
04/28/2022 05:54:50 - INFO - __main__ - Step 740 Global step 740 Train loss 0.04 on epoch=369
04/28/2022 05:54:53 - INFO - __main__ - Step 750 Global step 750 Train loss 0.06 on epoch=374
04/28/2022 05:54:53 - INFO - __main__ - Global step 750 Train loss 0.06 ACC 0.53125 on epoch=374
04/28/2022 05:54:56 - INFO - __main__ - Step 760 Global step 760 Train loss 0.07 on epoch=379
04/28/2022 05:54:58 - INFO - __main__ - Step 770 Global step 770 Train loss 0.01 on epoch=384
04/28/2022 05:55:01 - INFO - __main__ - Step 780 Global step 780 Train loss 0.06 on epoch=389
04/28/2022 05:55:03 - INFO - __main__ - Step 790 Global step 790 Train loss 0.05 on epoch=394
04/28/2022 05:55:06 - INFO - __main__ - Step 800 Global step 800 Train loss 0.07 on epoch=399
04/28/2022 05:55:07 - INFO - __main__ - Global step 800 Train loss 0.05 ACC 0.5 on epoch=399
04/28/2022 05:55:09 - INFO - __main__ - Step 810 Global step 810 Train loss 0.07 on epoch=404
04/28/2022 05:55:12 - INFO - __main__ - Step 820 Global step 820 Train loss 0.05 on epoch=409
04/28/2022 05:55:14 - INFO - __main__ - Step 830 Global step 830 Train loss 0.02 on epoch=414
04/28/2022 05:55:17 - INFO - __main__ - Step 840 Global step 840 Train loss 0.04 on epoch=419
04/28/2022 05:55:19 - INFO - __main__ - Step 850 Global step 850 Train loss 0.02 on epoch=424
04/28/2022 05:55:20 - INFO - __main__ - Global step 850 Train loss 0.04 ACC 0.5625 on epoch=424
04/28/2022 05:55:23 - INFO - __main__ - Step 860 Global step 860 Train loss 0.01 on epoch=429
04/28/2022 05:55:25 - INFO - __main__ - Step 870 Global step 870 Train loss 0.08 on epoch=434
04/28/2022 05:55:28 - INFO - __main__ - Step 880 Global step 880 Train loss 0.04 on epoch=439
04/28/2022 05:55:30 - INFO - __main__ - Step 890 Global step 890 Train loss 0.08 on epoch=444
04/28/2022 05:55:33 - INFO - __main__ - Step 900 Global step 900 Train loss 0.02 on epoch=449
04/28/2022 05:55:34 - INFO - __main__ - Global step 900 Train loss 0.05 ACC 0.53125 on epoch=449
04/28/2022 05:55:36 - INFO - __main__ - Step 910 Global step 910 Train loss 0.06 on epoch=454
04/28/2022 05:55:39 - INFO - __main__ - Step 920 Global step 920 Train loss 0.04 on epoch=459
04/28/2022 05:55:41 - INFO - __main__ - Step 930 Global step 930 Train loss 0.06 on epoch=464
04/28/2022 05:55:44 - INFO - __main__ - Step 940 Global step 940 Train loss 0.02 on epoch=469
04/28/2022 05:55:46 - INFO - __main__ - Step 950 Global step 950 Train loss 0.01 on epoch=474
04/28/2022 05:55:47 - INFO - __main__ - Global step 950 Train loss 0.04 ACC 0.5625 on epoch=474
04/28/2022 05:55:50 - INFO - __main__ - Step 960 Global step 960 Train loss 0.05 on epoch=479
04/28/2022 05:55:52 - INFO - __main__ - Step 970 Global step 970 Train loss 0.05 on epoch=484
04/28/2022 05:55:55 - INFO - __main__ - Step 980 Global step 980 Train loss 0.05 on epoch=489
04/28/2022 05:55:57 - INFO - __main__ - Step 990 Global step 990 Train loss 0.13 on epoch=494
04/28/2022 05:56:00 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.05 on epoch=499
04/28/2022 05:56:01 - INFO - __main__ - Global step 1000 Train loss 0.06 ACC 0.5 on epoch=499
04/28/2022 05:56:03 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.02 on epoch=504
04/28/2022 05:56:06 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.05 on epoch=509
04/28/2022 05:56:08 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.02 on epoch=514
04/28/2022 05:56:11 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.09 on epoch=519
04/28/2022 05:56:13 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.02 on epoch=524
04/28/2022 05:56:14 - INFO - __main__ - Global step 1050 Train loss 0.04 ACC 0.5625 on epoch=524
04/28/2022 05:56:17 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.03 on epoch=529
04/28/2022 05:56:19 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.01 on epoch=534
04/28/2022 05:56:22 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.03 on epoch=539
04/28/2022 05:56:24 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.06 on epoch=544
04/28/2022 05:56:26 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.01 on epoch=549
04/28/2022 05:56:28 - INFO - __main__ - Global step 1100 Train loss 0.03 ACC 0.46875 on epoch=549
04/28/2022 05:56:31 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.09 on epoch=554
04/28/2022 05:56:33 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.04 on epoch=559
04/28/2022 05:56:36 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.03 on epoch=564
04/28/2022 05:56:38 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.01 on epoch=569
04/28/2022 05:56:41 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.02 on epoch=574
04/28/2022 05:56:41 - INFO - __main__ - Global step 1150 Train loss 0.04 ACC 0.46875 on epoch=574
04/28/2022 05:56:44 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.00 on epoch=579
04/28/2022 05:56:46 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.01 on epoch=584
04/28/2022 05:56:49 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.04 on epoch=589
04/28/2022 05:56:51 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.01 on epoch=594
04/28/2022 05:56:54 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.02 on epoch=599
04/28/2022 05:56:55 - INFO - __main__ - Global step 1200 Train loss 0.02 ACC 0.4375 on epoch=599
04/28/2022 05:56:57 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.02 on epoch=604
04/28/2022 05:57:00 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.02 on epoch=609
04/28/2022 05:57:02 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.07 on epoch=614
04/28/2022 05:57:05 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.02 on epoch=619
04/28/2022 05:57:07 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.02 on epoch=624
04/28/2022 05:57:09 - INFO - __main__ - Global step 1250 Train loss 0.03 ACC 0.46875 on epoch=624
04/28/2022 05:57:11 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=629
04/28/2022 05:57:14 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.02 on epoch=634
04/28/2022 05:57:16 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.02 on epoch=639
04/28/2022 05:57:19 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=644
04/28/2022 05:57:21 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.02 on epoch=649
04/28/2022 05:57:22 - INFO - __main__ - Global step 1300 Train loss 0.02 ACC 0.4375 on epoch=649
04/28/2022 05:57:25 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=654
04/28/2022 05:57:27 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.00 on epoch=659
04/28/2022 05:57:30 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.11 on epoch=664
04/28/2022 05:57:32 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=669
04/28/2022 05:57:35 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=674
04/28/2022 05:57:36 - INFO - __main__ - Global step 1350 Train loss 0.03 ACC 0.46875 on epoch=674
04/28/2022 05:57:38 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.02 on epoch=679
04/28/2022 05:57:41 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.03 on epoch=684
04/28/2022 05:57:43 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=689
04/28/2022 05:57:46 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.00 on epoch=694
04/28/2022 05:57:48 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=699
04/28/2022 05:57:49 - INFO - __main__ - Global step 1400 Train loss 0.01 ACC 0.5 on epoch=699
04/28/2022 05:57:51 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=704
04/28/2022 05:57:54 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=709
04/28/2022 05:57:56 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.04 on epoch=714
04/28/2022 05:57:59 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=719
04/28/2022 05:58:01 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=724
04/28/2022 05:58:02 - INFO - __main__ - Global step 1450 Train loss 0.01 ACC 0.53125 on epoch=724
04/28/2022 05:58:05 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=729
04/28/2022 05:58:07 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.02 on epoch=734
04/28/2022 05:58:10 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=739
04/28/2022 05:58:12 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=744
04/28/2022 05:58:15 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=749
04/28/2022 05:58:16 - INFO - __main__ - Global step 1500 Train loss 0.01 ACC 0.46875 on epoch=749
04/28/2022 05:58:18 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=754
04/28/2022 05:58:21 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=759
04/28/2022 05:58:23 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=764
04/28/2022 05:58:26 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=769
04/28/2022 05:58:28 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=774
04/28/2022 05:58:29 - INFO - __main__ - Global step 1550 Train loss 0.00 ACC 0.46875 on epoch=774
04/28/2022 05:58:32 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=779
04/28/2022 05:58:34 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.03 on epoch=784
04/28/2022 05:58:37 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=789
04/28/2022 05:58:39 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.02 on epoch=794
04/28/2022 05:58:42 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.06 on epoch=799
04/28/2022 05:58:43 - INFO - __main__ - Global step 1600 Train loss 0.02 ACC 0.5625 on epoch=799
04/28/2022 05:58:45 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=804
04/28/2022 05:58:48 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.02 on epoch=809
04/28/2022 05:58:50 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=814
04/28/2022 05:58:53 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=819
04/28/2022 05:58:55 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=824
04/28/2022 05:58:56 - INFO - __main__ - Global step 1650 Train loss 0.01 ACC 0.5625 on epoch=824
04/28/2022 05:58:58 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=829
04/28/2022 05:59:01 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=834
04/28/2022 05:59:03 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=839
04/28/2022 05:59:06 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.02 on epoch=844
04/28/2022 05:59:08 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=849
04/28/2022 05:59:10 - INFO - __main__ - Global step 1700 Train loss 0.01 ACC 0.5625 on epoch=849
04/28/2022 05:59:12 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=854
04/28/2022 05:59:15 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=859
04/28/2022 05:59:17 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=864
04/28/2022 05:59:20 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=869
04/28/2022 05:59:22 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=874
04/28/2022 05:59:23 - INFO - __main__ - Global step 1750 Train loss 0.01 ACC 0.53125 on epoch=874
04/28/2022 05:59:26 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=879
04/28/2022 05:59:28 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=884
04/28/2022 05:59:31 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=889
04/28/2022 05:59:33 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=894
04/28/2022 05:59:36 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=899
04/28/2022 05:59:37 - INFO - __main__ - Global step 1800 Train loss 0.01 ACC 0.5625 on epoch=899
04/28/2022 05:59:39 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=904
04/28/2022 05:59:42 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=909
04/28/2022 05:59:44 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=914
04/28/2022 05:59:47 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=919
04/28/2022 05:59:49 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=924
04/28/2022 05:59:50 - INFO - __main__ - Global step 1850 Train loss 0.00 ACC 0.5 on epoch=924
04/28/2022 05:59:53 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=929
04/28/2022 05:59:55 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=934
04/28/2022 05:59:58 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=939
04/28/2022 06:00:00 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=944
04/28/2022 06:00:03 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=949
04/28/2022 06:00:03 - INFO - __main__ - Global step 1900 Train loss 0.00 ACC 0.46875 on epoch=949
04/28/2022 06:00:06 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=954
04/28/2022 06:00:08 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=959
04/28/2022 06:00:11 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=964
04/28/2022 06:00:13 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=969
04/28/2022 06:00:16 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=974
04/28/2022 06:00:17 - INFO - __main__ - Global step 1950 Train loss 0.01 ACC 0.5 on epoch=974
04/28/2022 06:00:19 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=979
04/28/2022 06:00:22 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=984
04/28/2022 06:00:24 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=989
04/28/2022 06:00:27 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=994
04/28/2022 06:00:29 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=999
04/28/2022 06:00:30 - INFO - __main__ - Global step 2000 Train loss 0.01 ACC 0.53125 on epoch=999
04/28/2022 06:00:30 - INFO - __main__ - save last model!
04/28/2022 06:00:30 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
04/28/2022 06:00:30 - INFO - __main__ - Start tokenizing ... 1000 instances
04/28/2022 06:00:30 - INFO - __main__ - Printing 3 examples
04/28/2022 06:00:30 - INFO - __main__ -  [wino_grande] Sarah was a much better surgeon than Maria so _ always got the easier cases. (A) Sarah (B) Maria
04/28/2022 06:00:30 - INFO - __main__ - ['Maria']
04/28/2022 06:00:30 - INFO - __main__ -  [wino_grande] Sarah was a much better surgeon than Maria so _ always got the harder cases. (A) Sarah (B) Maria
04/28/2022 06:00:30 - INFO - __main__ - ['Sarah']
04/28/2022 06:00:30 - INFO - __main__ -  [wino_grande] They were worried the wine would ruin the bed and the blanket, but the _ was't ruined. (A) blanket (B) bed
04/28/2022 06:00:30 - INFO - __main__ - ['bed']
04/28/2022 06:00:30 - INFO - __main__ - Tokenizing Input ...
04/28/2022 06:00:31 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 06:00:31 - INFO - __main__ - Printing 3 examples
04/28/2022 06:00:31 - INFO - __main__ -  [wino_grande] Brett wasn't sure what color of dress to buy unlike Derrick because _ was indecisive. (A) Brett (B) Derrick
04/28/2022 06:00:31 - INFO - __main__ - ['Brett']
04/28/2022 06:00:31 - INFO - __main__ -  [wino_grande] Jennifer felt love for others but Angela did not because _ had a cold feeling. (A) Jennifer (B) Angela
04/28/2022 06:00:31 - INFO - __main__ - ['Angela']
04/28/2022 06:00:31 - INFO - __main__ -  [wino_grande] The toddler was hurling his peas at the couches, as the _ made a very convenient missile. (A) peas (B) couches
04/28/2022 06:00:31 - INFO - __main__ - ['peas']
04/28/2022 06:00:31 - INFO - __main__ - Tokenizing Input ...
04/28/2022 06:00:31 - INFO - __main__ - Tokenizing Output ...
04/28/2022 06:00:31 - INFO - __main__ - Loaded 32 examples from train data
04/28/2022 06:00:31 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 06:00:31 - INFO - __main__ - Printing 3 examples
04/28/2022 06:00:31 - INFO - __main__ -  [wino_grande] They went on a safari and saw a panda eating bamboo, which Megan loved but Elena didn't care about. _ 's favorite animal was the panda. (A) Megan (B) Elena
04/28/2022 06:00:31 - INFO - __main__ - ['Megan']
04/28/2022 06:00:31 - INFO - __main__ -  [wino_grande] People liked being around Jeffrey more than around Neil because _ was a nice person. (A) Jeffrey (B) Neil
04/28/2022 06:00:31 - INFO - __main__ - ['Jeffrey']
04/28/2022 06:00:31 - INFO - __main__ -  [wino_grande] Steven worked all summer long to create a statue for Ian because _ hired him to. (A) Steven (B) Ian
04/28/2022 06:00:31 - INFO - __main__ - ['Ian']
04/28/2022 06:00:31 - INFO - __main__ - Tokenizing Input ...
04/28/2022 06:00:31 - INFO - __main__ - Tokenizing Output ...
04/28/2022 06:00:31 - INFO - __main__ - Loaded 32 examples from dev data
04/28/2022 06:00:31 - INFO - __main__ - Tokenizing Output ...
04/28/2022 06:00:32 - INFO - __main__ - Loaded 1000 examples from test data
04/28/2022 06:00:46 - INFO - __main__ - load prompt embedding from ckpt
04/28/2022 06:00:47 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/28/2022 06:00:47 - INFO - __main__ - Starting training!
04/28/2022 06:01:02 - INFO - __main__ - Saved prediction in models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-wino_grande/wino_grande_32_13_0.5_8_predictions.txt
04/28/2022 06:01:02 - INFO - __main__ - ACC on test data: 0.5030
04/28/2022 06:01:02 - INFO - __main__ - prefix=wino_grande_32_13, lr=0.5, bsz=8, dev_performance=0.625, test_performance=0.503
04/28/2022 06:01:02 - INFO - __main__ - Running ... prefix=wino_grande_32_13, lr=0.4, bsz=8 ...
04/28/2022 06:01:03 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 06:01:03 - INFO - __main__ - Printing 3 examples
04/28/2022 06:01:03 - INFO - __main__ -  [wino_grande] Brett wasn't sure what color of dress to buy unlike Derrick because _ was indecisive. (A) Brett (B) Derrick
04/28/2022 06:01:03 - INFO - __main__ - ['Brett']
04/28/2022 06:01:03 - INFO - __main__ -  [wino_grande] Jennifer felt love for others but Angela did not because _ had a cold feeling. (A) Jennifer (B) Angela
04/28/2022 06:01:03 - INFO - __main__ - ['Angela']
04/28/2022 06:01:03 - INFO - __main__ -  [wino_grande] The toddler was hurling his peas at the couches, as the _ made a very convenient missile. (A) peas (B) couches
04/28/2022 06:01:03 - INFO - __main__ - ['peas']
04/28/2022 06:01:03 - INFO - __main__ - Tokenizing Input ...
04/28/2022 06:01:03 - INFO - __main__ - Tokenizing Output ...
04/28/2022 06:01:03 - INFO - __main__ - Loaded 32 examples from train data
04/28/2022 06:01:03 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 06:01:03 - INFO - __main__ - Printing 3 examples
04/28/2022 06:01:03 - INFO - __main__ -  [wino_grande] They went on a safari and saw a panda eating bamboo, which Megan loved but Elena didn't care about. _ 's favorite animal was the panda. (A) Megan (B) Elena
04/28/2022 06:01:03 - INFO - __main__ - ['Megan']
04/28/2022 06:01:03 - INFO - __main__ -  [wino_grande] People liked being around Jeffrey more than around Neil because _ was a nice person. (A) Jeffrey (B) Neil
04/28/2022 06:01:03 - INFO - __main__ - ['Jeffrey']
04/28/2022 06:01:03 - INFO - __main__ -  [wino_grande] Steven worked all summer long to create a statue for Ian because _ hired him to. (A) Steven (B) Ian
04/28/2022 06:01:03 - INFO - __main__ - ['Ian']
04/28/2022 06:01:03 - INFO - __main__ - Tokenizing Input ...
04/28/2022 06:01:03 - INFO - __main__ - Tokenizing Output ...
04/28/2022 06:01:03 - INFO - __main__ - Loaded 32 examples from dev data
04/28/2022 06:01:22 - INFO - __main__ - load prompt embedding from ckpt
04/28/2022 06:01:23 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/28/2022 06:01:23 - INFO - __main__ - Starting training!
04/28/2022 06:01:26 - INFO - __main__ - Step 10 Global step 10 Train loss 3.12 on epoch=4
04/28/2022 06:01:29 - INFO - __main__ - Step 20 Global step 20 Train loss 1.06 on epoch=9
04/28/2022 06:01:31 - INFO - __main__ - Step 30 Global step 30 Train loss 0.83 on epoch=14
04/28/2022 06:01:34 - INFO - __main__ - Step 40 Global step 40 Train loss 0.68 on epoch=19
04/28/2022 06:01:36 - INFO - __main__ - Step 50 Global step 50 Train loss 0.48 on epoch=24
04/28/2022 06:01:37 - INFO - __main__ - Global step 50 Train loss 1.23 ACC 0.5625 on epoch=24
04/28/2022 06:01:37 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.5625 on epoch=24, global_step=50
04/28/2022 06:01:39 - INFO - __main__ - Step 60 Global step 60 Train loss 0.50 on epoch=29
04/28/2022 06:01:42 - INFO - __main__ - Step 70 Global step 70 Train loss 0.38 on epoch=34
04/28/2022 06:01:44 - INFO - __main__ - Step 80 Global step 80 Train loss 0.41 on epoch=39
04/28/2022 06:01:47 - INFO - __main__ - Step 90 Global step 90 Train loss 0.32 on epoch=44
04/28/2022 06:01:49 - INFO - __main__ - Step 100 Global step 100 Train loss 0.23 on epoch=49
04/28/2022 06:01:50 - INFO - __main__ - Global step 100 Train loss 0.37 ACC 0.5625 on epoch=49
04/28/2022 06:01:53 - INFO - __main__ - Step 110 Global step 110 Train loss 0.37 on epoch=54
04/28/2022 06:01:55 - INFO - __main__ - Step 120 Global step 120 Train loss 0.31 on epoch=59
04/28/2022 06:01:58 - INFO - __main__ - Step 130 Global step 130 Train loss 0.28 on epoch=64
04/28/2022 06:02:00 - INFO - __main__ - Step 140 Global step 140 Train loss 0.24 on epoch=69
04/28/2022 06:02:03 - INFO - __main__ - Step 150 Global step 150 Train loss 0.19 on epoch=74
04/28/2022 06:02:04 - INFO - __main__ - Global step 150 Train loss 0.28 ACC 0.59375 on epoch=74
04/28/2022 06:02:04 - INFO - __main__ - Saving model with best ACC: 0.5625 -> 0.59375 on epoch=74, global_step=150
04/28/2022 06:02:06 - INFO - __main__ - Step 160 Global step 160 Train loss 0.15 on epoch=79
04/28/2022 06:02:09 - INFO - __main__ - Step 170 Global step 170 Train loss 0.14 on epoch=84
04/28/2022 06:02:11 - INFO - __main__ - Step 180 Global step 180 Train loss 0.16 on epoch=89
04/28/2022 06:02:14 - INFO - __main__ - Step 190 Global step 190 Train loss 0.09 on epoch=94
04/28/2022 06:02:16 - INFO - __main__ - Step 200 Global step 200 Train loss 0.10 on epoch=99
04/28/2022 06:02:17 - INFO - __main__ - Global step 200 Train loss 0.13 ACC 0.625 on epoch=99
04/28/2022 06:02:17 - INFO - __main__ - Saving model with best ACC: 0.59375 -> 0.625 on epoch=99, global_step=200
04/28/2022 06:02:20 - INFO - __main__ - Step 210 Global step 210 Train loss 0.13 on epoch=104
04/28/2022 06:02:22 - INFO - __main__ - Step 220 Global step 220 Train loss 0.11 on epoch=109
04/28/2022 06:02:25 - INFO - __main__ - Step 230 Global step 230 Train loss 0.27 on epoch=114
04/28/2022 06:02:27 - INFO - __main__ - Step 240 Global step 240 Train loss 0.25 on epoch=119
04/28/2022 06:02:30 - INFO - __main__ - Step 250 Global step 250 Train loss 0.12 on epoch=124
04/28/2022 06:02:31 - INFO - __main__ - Global step 250 Train loss 0.17 ACC 0.65625 on epoch=124
04/28/2022 06:02:31 - INFO - __main__ - Saving model with best ACC: 0.625 -> 0.65625 on epoch=124, global_step=250
04/28/2022 06:02:33 - INFO - __main__ - Step 260 Global step 260 Train loss 0.09 on epoch=129
04/28/2022 06:02:36 - INFO - __main__ - Step 270 Global step 270 Train loss 0.10 on epoch=134
04/28/2022 06:02:38 - INFO - __main__ - Step 280 Global step 280 Train loss 0.06 on epoch=139
04/28/2022 06:02:41 - INFO - __main__ - Step 290 Global step 290 Train loss 0.10 on epoch=144
04/28/2022 06:02:43 - INFO - __main__ - Step 300 Global step 300 Train loss 0.14 on epoch=149
04/28/2022 06:02:44 - INFO - __main__ - Global step 300 Train loss 0.10 ACC 0.625 on epoch=149
04/28/2022 06:02:47 - INFO - __main__ - Step 310 Global step 310 Train loss 0.13 on epoch=154
04/28/2022 06:02:49 - INFO - __main__ - Step 320 Global step 320 Train loss 0.09 on epoch=159
04/28/2022 06:02:52 - INFO - __main__ - Step 330 Global step 330 Train loss 0.12 on epoch=164
04/28/2022 06:02:54 - INFO - __main__ - Step 340 Global step 340 Train loss 0.11 on epoch=169
04/28/2022 06:02:57 - INFO - __main__ - Step 350 Global step 350 Train loss 0.05 on epoch=174
04/28/2022 06:02:59 - INFO - __main__ - Global step 350 Train loss 0.10 ACC 0.5625 on epoch=174
04/28/2022 06:03:02 - INFO - __main__ - Step 360 Global step 360 Train loss 0.08 on epoch=179
04/28/2022 06:03:04 - INFO - __main__ - Step 370 Global step 370 Train loss 0.07 on epoch=184
04/28/2022 06:03:07 - INFO - __main__ - Step 380 Global step 380 Train loss 0.07 on epoch=189
04/28/2022 06:03:09 - INFO - __main__ - Step 390 Global step 390 Train loss 0.02 on epoch=194
04/28/2022 06:03:11 - INFO - __main__ - Step 400 Global step 400 Train loss 0.09 on epoch=199
04/28/2022 06:03:12 - INFO - __main__ - Global step 400 Train loss 0.07 ACC 0.59375 on epoch=199
04/28/2022 06:03:15 - INFO - __main__ - Step 410 Global step 410 Train loss 0.08 on epoch=204
04/28/2022 06:03:17 - INFO - __main__ - Step 420 Global step 420 Train loss 0.10 on epoch=209
04/28/2022 06:03:20 - INFO - __main__ - Step 430 Global step 430 Train loss 0.08 on epoch=214
04/28/2022 06:03:22 - INFO - __main__ - Step 440 Global step 440 Train loss 0.03 on epoch=219
04/28/2022 06:03:25 - INFO - __main__ - Step 450 Global step 450 Train loss 0.04 on epoch=224
04/28/2022 06:03:26 - INFO - __main__ - Global step 450 Train loss 0.07 ACC 0.53125 on epoch=224
04/28/2022 06:03:28 - INFO - __main__ - Step 460 Global step 460 Train loss 0.03 on epoch=229
04/28/2022 06:03:31 - INFO - __main__ - Step 470 Global step 470 Train loss 0.04 on epoch=234
04/28/2022 06:03:33 - INFO - __main__ - Step 480 Global step 480 Train loss 0.06 on epoch=239
04/28/2022 06:03:36 - INFO - __main__ - Step 490 Global step 490 Train loss 0.09 on epoch=244
04/28/2022 06:03:38 - INFO - __main__ - Step 500 Global step 500 Train loss 0.07 on epoch=249
04/28/2022 06:03:39 - INFO - __main__ - Global step 500 Train loss 0.06 ACC 0.5625 on epoch=249
04/28/2022 06:03:42 - INFO - __main__ - Step 510 Global step 510 Train loss 0.04 on epoch=254
04/28/2022 06:03:44 - INFO - __main__ - Step 520 Global step 520 Train loss 0.07 on epoch=259
04/28/2022 06:03:47 - INFO - __main__ - Step 530 Global step 530 Train loss 0.07 on epoch=264
04/28/2022 06:03:49 - INFO - __main__ - Step 540 Global step 540 Train loss 0.05 on epoch=269
04/28/2022 06:03:52 - INFO - __main__ - Step 550 Global step 550 Train loss 0.03 on epoch=274
04/28/2022 06:03:53 - INFO - __main__ - Global step 550 Train loss 0.05 ACC 0.5 on epoch=274
04/28/2022 06:03:55 - INFO - __main__ - Step 560 Global step 560 Train loss 0.03 on epoch=279
04/28/2022 06:03:58 - INFO - __main__ - Step 570 Global step 570 Train loss 0.02 on epoch=284
04/28/2022 06:04:00 - INFO - __main__ - Step 580 Global step 580 Train loss 0.01 on epoch=289
04/28/2022 06:04:03 - INFO - __main__ - Step 590 Global step 590 Train loss 0.08 on epoch=294
04/28/2022 06:04:05 - INFO - __main__ - Step 600 Global step 600 Train loss 0.05 on epoch=299
04/28/2022 06:04:06 - INFO - __main__ - Global step 600 Train loss 0.04 ACC 0.5 on epoch=299
04/28/2022 06:04:09 - INFO - __main__ - Step 610 Global step 610 Train loss 0.05 on epoch=304
04/28/2022 06:04:11 - INFO - __main__ - Step 620 Global step 620 Train loss 0.03 on epoch=309
04/28/2022 06:04:14 - INFO - __main__ - Step 630 Global step 630 Train loss 0.02 on epoch=314
04/28/2022 06:04:16 - INFO - __main__ - Step 640 Global step 640 Train loss 0.06 on epoch=319
04/28/2022 06:04:19 - INFO - __main__ - Step 650 Global step 650 Train loss 0.01 on epoch=324
04/28/2022 06:04:21 - INFO - __main__ - Global step 650 Train loss 0.03 ACC 0.46875 on epoch=324
04/28/2022 06:04:23 - INFO - __main__ - Step 660 Global step 660 Train loss 0.01 on epoch=329
04/28/2022 06:04:26 - INFO - __main__ - Step 670 Global step 670 Train loss 0.06 on epoch=334
04/28/2022 06:04:28 - INFO - __main__ - Step 680 Global step 680 Train loss 0.02 on epoch=339
04/28/2022 06:04:31 - INFO - __main__ - Step 690 Global step 690 Train loss 0.01 on epoch=344
04/28/2022 06:04:33 - INFO - __main__ - Step 700 Global step 700 Train loss 0.04 on epoch=349
04/28/2022 06:04:36 - INFO - __main__ - Global step 700 Train loss 0.03 ACC 0.5625 on epoch=349
04/28/2022 06:04:39 - INFO - __main__ - Step 710 Global step 710 Train loss 0.03 on epoch=354
04/28/2022 06:04:41 - INFO - __main__ - Step 720 Global step 720 Train loss 0.01 on epoch=359
04/28/2022 06:04:44 - INFO - __main__ - Step 730 Global step 730 Train loss 0.02 on epoch=364
04/28/2022 06:04:46 - INFO - __main__ - Step 740 Global step 740 Train loss 0.01 on epoch=369
04/28/2022 06:04:49 - INFO - __main__ - Step 750 Global step 750 Train loss 0.05 on epoch=374
04/28/2022 06:04:51 - INFO - __main__ - Global step 750 Train loss 0.02 ACC 0.53125 on epoch=374
04/28/2022 06:04:53 - INFO - __main__ - Step 760 Global step 760 Train loss 0.02 on epoch=379
04/28/2022 06:04:55 - INFO - __main__ - Step 770 Global step 770 Train loss 0.01 on epoch=384
04/28/2022 06:04:58 - INFO - __main__ - Step 780 Global step 780 Train loss 0.05 on epoch=389
04/28/2022 06:05:00 - INFO - __main__ - Step 790 Global step 790 Train loss 0.01 on epoch=394
04/28/2022 06:05:03 - INFO - __main__ - Step 800 Global step 800 Train loss 0.02 on epoch=399
04/28/2022 06:05:05 - INFO - __main__ - Global step 800 Train loss 0.02 ACC 0.625 on epoch=399
04/28/2022 06:05:08 - INFO - __main__ - Step 810 Global step 810 Train loss 0.02 on epoch=404
04/28/2022 06:05:10 - INFO - __main__ - Step 820 Global step 820 Train loss 0.01 on epoch=409
04/28/2022 06:05:13 - INFO - __main__ - Step 830 Global step 830 Train loss 0.01 on epoch=414
04/28/2022 06:05:15 - INFO - __main__ - Step 840 Global step 840 Train loss 0.01 on epoch=419
04/28/2022 06:05:18 - INFO - __main__ - Step 850 Global step 850 Train loss 0.09 on epoch=424
04/28/2022 06:05:19 - INFO - __main__ - Global step 850 Train loss 0.03 ACC 0.625 on epoch=424
04/28/2022 06:05:21 - INFO - __main__ - Step 860 Global step 860 Train loss 0.01 on epoch=429
04/28/2022 06:05:24 - INFO - __main__ - Step 870 Global step 870 Train loss 0.03 on epoch=434
04/28/2022 06:05:26 - INFO - __main__ - Step 880 Global step 880 Train loss 0.01 on epoch=439
04/28/2022 06:05:29 - INFO - __main__ - Step 890 Global step 890 Train loss 0.01 on epoch=444
04/28/2022 06:05:31 - INFO - __main__ - Step 900 Global step 900 Train loss 0.01 on epoch=449
04/28/2022 06:05:32 - INFO - __main__ - Global step 900 Train loss 0.02 ACC 0.5625 on epoch=449
04/28/2022 06:05:35 - INFO - __main__ - Step 910 Global step 910 Train loss 0.11 on epoch=454
04/28/2022 06:05:38 - INFO - __main__ - Step 920 Global step 920 Train loss 0.01 on epoch=459
04/28/2022 06:05:40 - INFO - __main__ - Step 930 Global step 930 Train loss 0.01 on epoch=464
04/28/2022 06:05:42 - INFO - __main__ - Step 940 Global step 940 Train loss 0.00 on epoch=469
04/28/2022 06:05:45 - INFO - __main__ - Step 950 Global step 950 Train loss 0.04 on epoch=474
04/28/2022 06:05:46 - INFO - __main__ - Global step 950 Train loss 0.03 ACC 0.53125 on epoch=474
04/28/2022 06:05:49 - INFO - __main__ - Step 960 Global step 960 Train loss 0.02 on epoch=479
04/28/2022 06:05:51 - INFO - __main__ - Step 970 Global step 970 Train loss 0.02 on epoch=484
04/28/2022 06:05:54 - INFO - __main__ - Step 980 Global step 980 Train loss 0.03 on epoch=489
04/28/2022 06:05:56 - INFO - __main__ - Step 990 Global step 990 Train loss 0.01 on epoch=494
04/28/2022 06:05:59 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.15 on epoch=499
04/28/2022 06:06:01 - INFO - __main__ - Global step 1000 Train loss 0.05 ACC 0.625 on epoch=499
04/28/2022 06:06:04 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.01 on epoch=504
04/28/2022 06:06:06 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.04 on epoch=509
04/28/2022 06:06:09 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.04 on epoch=514
04/28/2022 06:06:11 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.08 on epoch=519
04/28/2022 06:06:13 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.01 on epoch=524
04/28/2022 06:06:15 - INFO - __main__ - Global step 1050 Train loss 0.04 ACC 0.625 on epoch=524
04/28/2022 06:06:17 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.02 on epoch=529
04/28/2022 06:06:20 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.01 on epoch=534
04/28/2022 06:06:22 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.01 on epoch=539
04/28/2022 06:06:25 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.00 on epoch=544
04/28/2022 06:06:27 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.00 on epoch=549
04/28/2022 06:06:29 - INFO - __main__ - Global step 1100 Train loss 0.01 ACC 0.5625 on epoch=549
04/28/2022 06:06:32 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.01 on epoch=554
04/28/2022 06:06:34 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=559
04/28/2022 06:06:37 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.00 on epoch=564
04/28/2022 06:06:39 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.01 on epoch=569
04/28/2022 06:06:42 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=574
04/28/2022 06:06:44 - INFO - __main__ - Global step 1150 Train loss 0.01 ACC 0.5625 on epoch=574
04/28/2022 06:06:46 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.02 on epoch=579
04/28/2022 06:06:49 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.00 on epoch=584
04/28/2022 06:06:51 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.01 on epoch=589
04/28/2022 06:06:54 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.01 on epoch=594
04/28/2022 06:06:56 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=599
04/28/2022 06:06:59 - INFO - __main__ - Global step 1200 Train loss 0.01 ACC 0.53125 on epoch=599
04/28/2022 06:07:01 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.00 on epoch=604
04/28/2022 06:07:04 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.02 on epoch=609
04/28/2022 06:07:06 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=614
04/28/2022 06:07:09 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=619
04/28/2022 06:07:11 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.01 on epoch=624
04/28/2022 06:07:15 - INFO - __main__ - Global step 1250 Train loss 0.01 ACC 0.53125 on epoch=624
04/28/2022 06:07:17 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=629
04/28/2022 06:07:20 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.00 on epoch=634
04/28/2022 06:07:22 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.00 on epoch=639
04/28/2022 06:07:25 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.00 on epoch=644
04/28/2022 06:07:27 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.00 on epoch=649
04/28/2022 06:07:30 - INFO - __main__ - Global step 1300 Train loss 0.00 ACC 0.5625 on epoch=649
04/28/2022 06:07:33 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.05 on epoch=654
04/28/2022 06:07:35 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.00 on epoch=659
04/28/2022 06:07:38 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=664
04/28/2022 06:07:40 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=669
04/28/2022 06:07:43 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.00 on epoch=674
04/28/2022 06:07:44 - INFO - __main__ - Global step 1350 Train loss 0.02 ACC 0.59375 on epoch=674
04/28/2022 06:07:46 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.03 on epoch=679
04/28/2022 06:07:49 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.00 on epoch=684
04/28/2022 06:07:51 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.00 on epoch=689
04/28/2022 06:07:54 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.00 on epoch=694
04/28/2022 06:07:56 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.00 on epoch=699
04/28/2022 06:07:59 - INFO - __main__ - Global step 1400 Train loss 0.01 ACC 0.5625 on epoch=699
04/28/2022 06:08:01 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=704
04/28/2022 06:08:04 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=709
04/28/2022 06:08:06 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=714
04/28/2022 06:08:09 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=719
04/28/2022 06:08:11 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=724
04/28/2022 06:08:13 - INFO - __main__ - Global step 1450 Train loss 0.00 ACC 0.59375 on epoch=724
04/28/2022 06:08:15 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=729
04/28/2022 06:08:18 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=734
04/28/2022 06:08:20 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=739
04/28/2022 06:08:23 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=744
04/28/2022 06:08:25 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=749
04/28/2022 06:08:27 - INFO - __main__ - Global step 1500 Train loss 0.00 ACC 0.59375 on epoch=749
04/28/2022 06:08:29 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.03 on epoch=754
04/28/2022 06:08:32 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=759
04/28/2022 06:08:34 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=764
04/28/2022 06:08:37 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=769
04/28/2022 06:08:39 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=774
04/28/2022 06:08:44 - INFO - __main__ - Global step 1550 Train loss 0.01 ACC 0.5625 on epoch=774
04/28/2022 06:08:47 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=779
04/28/2022 06:08:49 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=784
04/28/2022 06:08:52 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=789
04/28/2022 06:08:54 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=794
04/28/2022 06:08:57 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=799
04/28/2022 06:08:58 - INFO - __main__ - Global step 1600 Train loss 0.00 ACC 0.5625 on epoch=799
04/28/2022 06:09:00 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=804
04/28/2022 06:09:03 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.04 on epoch=809
04/28/2022 06:09:05 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=814
04/28/2022 06:09:08 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=819
04/28/2022 06:09:10 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=824
04/28/2022 06:09:13 - INFO - __main__ - Global step 1650 Train loss 0.01 ACC 0.5625 on epoch=824
04/28/2022 06:09:15 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=829
04/28/2022 06:09:18 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=834
04/28/2022 06:09:20 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=839
04/28/2022 06:09:23 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=844
04/28/2022 06:09:25 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=849
04/28/2022 06:09:27 - INFO - __main__ - Global step 1700 Train loss 0.01 ACC 0.59375 on epoch=849
04/28/2022 06:09:30 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=854
04/28/2022 06:09:32 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=859
04/28/2022 06:09:35 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=864
04/28/2022 06:09:38 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=869
04/28/2022 06:09:40 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=874
04/28/2022 06:09:41 - INFO - __main__ - Global step 1750 Train loss 0.00 ACC 0.625 on epoch=874
04/28/2022 06:09:43 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=879
04/28/2022 06:09:46 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=884
04/28/2022 06:09:49 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=889
04/28/2022 06:09:51 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=894
04/28/2022 06:09:53 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=899
04/28/2022 06:09:55 - INFO - __main__ - Global step 1800 Train loss 0.00 ACC 0.5625 on epoch=899
04/28/2022 06:09:57 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=904
04/28/2022 06:10:00 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=909
04/28/2022 06:10:02 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=914
04/28/2022 06:10:05 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=919
04/28/2022 06:10:07 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=924
04/28/2022 06:10:08 - INFO - __main__ - Global step 1850 Train loss 0.00 ACC 0.53125 on epoch=924
04/28/2022 06:10:11 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=929
04/28/2022 06:10:13 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=934
04/28/2022 06:10:16 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=939
04/28/2022 06:10:18 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=944
04/28/2022 06:10:21 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=949
04/28/2022 06:10:22 - INFO - __main__ - Global step 1900 Train loss 0.00 ACC 0.53125 on epoch=949
04/28/2022 06:10:24 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=954
04/28/2022 06:10:27 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=959
04/28/2022 06:10:29 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=964
04/28/2022 06:10:32 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=969
04/28/2022 06:10:34 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=974
04/28/2022 06:10:35 - INFO - __main__ - Global step 1950 Train loss 0.00 ACC 0.5625 on epoch=974
04/28/2022 06:10:38 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=979
04/28/2022 06:10:40 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=984
04/28/2022 06:10:42 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=989
04/28/2022 06:10:45 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=994
04/28/2022 06:10:47 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=999
04/28/2022 06:10:48 - INFO - __main__ - Global step 2000 Train loss 0.00 ACC 0.59375 on epoch=999
04/28/2022 06:10:48 - INFO - __main__ - save last model!
04/28/2022 06:10:48 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
04/28/2022 06:10:48 - INFO - __main__ - Start tokenizing ... 1000 instances
04/28/2022 06:10:48 - INFO - __main__ - Printing 3 examples
04/28/2022 06:10:48 - INFO - __main__ -  [wino_grande] Sarah was a much better surgeon than Maria so _ always got the easier cases. (A) Sarah (B) Maria
04/28/2022 06:10:48 - INFO - __main__ - ['Maria']
04/28/2022 06:10:48 - INFO - __main__ -  [wino_grande] Sarah was a much better surgeon than Maria so _ always got the harder cases. (A) Sarah (B) Maria
04/28/2022 06:10:48 - INFO - __main__ - ['Sarah']
04/28/2022 06:10:48 - INFO - __main__ -  [wino_grande] They were worried the wine would ruin the bed and the blanket, but the _ was't ruined. (A) blanket (B) bed
04/28/2022 06:10:48 - INFO - __main__ - ['bed']
04/28/2022 06:10:48 - INFO - __main__ - Tokenizing Input ...
04/28/2022 06:10:49 - INFO - __main__ - Tokenizing Output ...
04/28/2022 06:10:50 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 06:10:50 - INFO - __main__ - Printing 3 examples
04/28/2022 06:10:50 - INFO - __main__ -  [wino_grande] Brett wasn't sure what color of dress to buy unlike Derrick because _ was indecisive. (A) Brett (B) Derrick
04/28/2022 06:10:50 - INFO - __main__ - ['Brett']
04/28/2022 06:10:50 - INFO - __main__ -  [wino_grande] Jennifer felt love for others but Angela did not because _ had a cold feeling. (A) Jennifer (B) Angela
04/28/2022 06:10:50 - INFO - __main__ - ['Angela']
04/28/2022 06:10:50 - INFO - __main__ -  [wino_grande] The toddler was hurling his peas at the couches, as the _ made a very convenient missile. (A) peas (B) couches
04/28/2022 06:10:50 - INFO - __main__ - ['peas']
04/28/2022 06:10:50 - INFO - __main__ - Tokenizing Input ...
04/28/2022 06:10:50 - INFO - __main__ - Tokenizing Output ...
04/28/2022 06:10:50 - INFO - __main__ - Loaded 32 examples from train data
04/28/2022 06:10:50 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 06:10:50 - INFO - __main__ - Printing 3 examples
04/28/2022 06:10:50 - INFO - __main__ -  [wino_grande] They went on a safari and saw a panda eating bamboo, which Megan loved but Elena didn't care about. _ 's favorite animal was the panda. (A) Megan (B) Elena
04/28/2022 06:10:50 - INFO - __main__ - ['Megan']
04/28/2022 06:10:50 - INFO - __main__ -  [wino_grande] People liked being around Jeffrey more than around Neil because _ was a nice person. (A) Jeffrey (B) Neil
04/28/2022 06:10:50 - INFO - __main__ - ['Jeffrey']
04/28/2022 06:10:50 - INFO - __main__ -  [wino_grande] Steven worked all summer long to create a statue for Ian because _ hired him to. (A) Steven (B) Ian
04/28/2022 06:10:50 - INFO - __main__ - ['Ian']
04/28/2022 06:10:50 - INFO - __main__ - Tokenizing Input ...
04/28/2022 06:10:50 - INFO - __main__ - Tokenizing Output ...
04/28/2022 06:10:50 - INFO - __main__ - Loaded 32 examples from dev data
04/28/2022 06:10:50 - INFO - __main__ - Loaded 1000 examples from test data
04/28/2022 06:11:05 - INFO - __main__ - load prompt embedding from ckpt
04/28/2022 06:11:06 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/28/2022 06:11:06 - INFO - __main__ - Starting training!
04/28/2022 06:11:16 - INFO - __main__ - Saved prediction in models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-wino_grande/wino_grande_32_13_0.4_8_predictions.txt
04/28/2022 06:11:16 - INFO - __main__ - ACC on test data: 0.4890
04/28/2022 06:11:17 - INFO - __main__ - prefix=wino_grande_32_13, lr=0.4, bsz=8, dev_performance=0.65625, test_performance=0.489
04/28/2022 06:11:17 - INFO - __main__ - Running ... prefix=wino_grande_32_13, lr=0.3, bsz=8 ...
04/28/2022 06:11:18 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 06:11:18 - INFO - __main__ - Printing 3 examples
04/28/2022 06:11:18 - INFO - __main__ -  [wino_grande] Brett wasn't sure what color of dress to buy unlike Derrick because _ was indecisive. (A) Brett (B) Derrick
04/28/2022 06:11:18 - INFO - __main__ - ['Brett']
04/28/2022 06:11:18 - INFO - __main__ -  [wino_grande] Jennifer felt love for others but Angela did not because _ had a cold feeling. (A) Jennifer (B) Angela
04/28/2022 06:11:18 - INFO - __main__ - ['Angela']
04/28/2022 06:11:18 - INFO - __main__ -  [wino_grande] The toddler was hurling his peas at the couches, as the _ made a very convenient missile. (A) peas (B) couches
04/28/2022 06:11:18 - INFO - __main__ - ['peas']
04/28/2022 06:11:18 - INFO - __main__ - Tokenizing Input ...
04/28/2022 06:11:18 - INFO - __main__ - Tokenizing Output ...
04/28/2022 06:11:18 - INFO - __main__ - Loaded 32 examples from train data
04/28/2022 06:11:18 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 06:11:18 - INFO - __main__ - Printing 3 examples
04/28/2022 06:11:18 - INFO - __main__ -  [wino_grande] They went on a safari and saw a panda eating bamboo, which Megan loved but Elena didn't care about. _ 's favorite animal was the panda. (A) Megan (B) Elena
04/28/2022 06:11:18 - INFO - __main__ - ['Megan']
04/28/2022 06:11:18 - INFO - __main__ -  [wino_grande] People liked being around Jeffrey more than around Neil because _ was a nice person. (A) Jeffrey (B) Neil
04/28/2022 06:11:18 - INFO - __main__ - ['Jeffrey']
04/28/2022 06:11:18 - INFO - __main__ -  [wino_grande] Steven worked all summer long to create a statue for Ian because _ hired him to. (A) Steven (B) Ian
04/28/2022 06:11:18 - INFO - __main__ - ['Ian']
04/28/2022 06:11:18 - INFO - __main__ - Tokenizing Input ...
04/28/2022 06:11:18 - INFO - __main__ - Tokenizing Output ...
04/28/2022 06:11:18 - INFO - __main__ - Loaded 32 examples from dev data
04/28/2022 06:11:33 - INFO - __main__ - load prompt embedding from ckpt
04/28/2022 06:11:34 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/28/2022 06:11:34 - INFO - __main__ - Starting training!
04/28/2022 06:11:37 - INFO - __main__ - Step 10 Global step 10 Train loss 3.45 on epoch=4
04/28/2022 06:11:39 - INFO - __main__ - Step 20 Global step 20 Train loss 1.54 on epoch=9
04/28/2022 06:11:42 - INFO - __main__ - Step 30 Global step 30 Train loss 0.99 on epoch=14
04/28/2022 06:11:44 - INFO - __main__ - Step 40 Global step 40 Train loss 0.79 on epoch=19
04/28/2022 06:11:47 - INFO - __main__ - Step 50 Global step 50 Train loss 0.59 on epoch=24
04/28/2022 06:11:48 - INFO - __main__ - Global step 50 Train loss 1.47 ACC 0.59375 on epoch=24
04/28/2022 06:11:48 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.59375 on epoch=24, global_step=50
04/28/2022 06:11:51 - INFO - __main__ - Step 60 Global step 60 Train loss 0.53 on epoch=29
04/28/2022 06:11:53 - INFO - __main__ - Step 70 Global step 70 Train loss 0.57 on epoch=34
04/28/2022 06:11:56 - INFO - __main__ - Step 80 Global step 80 Train loss 0.38 on epoch=39
04/28/2022 06:11:58 - INFO - __main__ - Step 90 Global step 90 Train loss 0.25 on epoch=44
04/28/2022 06:12:01 - INFO - __main__ - Step 100 Global step 100 Train loss 0.30 on epoch=49
04/28/2022 06:12:02 - INFO - __main__ - Global step 100 Train loss 0.41 ACC 0.6875 on epoch=49
04/28/2022 06:12:02 - INFO - __main__ - Saving model with best ACC: 0.59375 -> 0.6875 on epoch=49, global_step=100
04/28/2022 06:12:04 - INFO - __main__ - Step 110 Global step 110 Train loss 0.32 on epoch=54
04/28/2022 06:12:07 - INFO - __main__ - Step 120 Global step 120 Train loss 0.33 on epoch=59
04/28/2022 06:12:09 - INFO - __main__ - Step 130 Global step 130 Train loss 0.21 on epoch=64
04/28/2022 06:12:12 - INFO - __main__ - Step 140 Global step 140 Train loss 0.28 on epoch=69
04/28/2022 06:12:14 - INFO - __main__ - Step 150 Global step 150 Train loss 0.25 on epoch=74
04/28/2022 06:12:15 - INFO - __main__ - Global step 150 Train loss 0.28 ACC 0.46875 on epoch=74
04/28/2022 06:12:18 - INFO - __main__ - Step 160 Global step 160 Train loss 0.13 on epoch=79
04/28/2022 06:12:20 - INFO - __main__ - Step 170 Global step 170 Train loss 0.17 on epoch=84
04/28/2022 06:12:23 - INFO - __main__ - Step 180 Global step 180 Train loss 0.16 on epoch=89
04/28/2022 06:12:25 - INFO - __main__ - Step 190 Global step 190 Train loss 0.23 on epoch=94
04/28/2022 06:12:28 - INFO - __main__ - Step 200 Global step 200 Train loss 0.20 on epoch=99
04/28/2022 06:12:28 - INFO - __main__ - Global step 200 Train loss 0.18 ACC 0.5625 on epoch=99
04/28/2022 06:12:31 - INFO - __main__ - Step 210 Global step 210 Train loss 0.11 on epoch=104
04/28/2022 06:12:33 - INFO - __main__ - Step 220 Global step 220 Train loss 0.20 on epoch=109
04/28/2022 06:12:36 - INFO - __main__ - Step 230 Global step 230 Train loss 0.11 on epoch=114
04/28/2022 06:12:38 - INFO - __main__ - Step 240 Global step 240 Train loss 0.16 on epoch=119
04/28/2022 06:12:41 - INFO - __main__ - Step 250 Global step 250 Train loss 0.12 on epoch=124
04/28/2022 06:12:42 - INFO - __main__ - Global step 250 Train loss 0.14 ACC 0.59375 on epoch=124
04/28/2022 06:12:44 - INFO - __main__ - Step 260 Global step 260 Train loss 0.15 on epoch=129
04/28/2022 06:12:47 - INFO - __main__ - Step 270 Global step 270 Train loss 0.07 on epoch=134
04/28/2022 06:12:49 - INFO - __main__ - Step 280 Global step 280 Train loss 0.14 on epoch=139
04/28/2022 06:12:52 - INFO - __main__ - Step 290 Global step 290 Train loss 0.11 on epoch=144
04/28/2022 06:12:54 - INFO - __main__ - Step 300 Global step 300 Train loss 0.13 on epoch=149
04/28/2022 06:12:55 - INFO - __main__ - Global step 300 Train loss 0.12 ACC 0.59375 on epoch=149
04/28/2022 06:12:58 - INFO - __main__ - Step 310 Global step 310 Train loss 0.20 on epoch=154
04/28/2022 06:13:00 - INFO - __main__ - Step 320 Global step 320 Train loss 0.15 on epoch=159
04/28/2022 06:13:03 - INFO - __main__ - Step 330 Global step 330 Train loss 0.12 on epoch=164
04/28/2022 06:13:05 - INFO - __main__ - Step 340 Global step 340 Train loss 0.11 on epoch=169
04/28/2022 06:13:07 - INFO - __main__ - Step 350 Global step 350 Train loss 0.06 on epoch=174
04/28/2022 06:13:08 - INFO - __main__ - Global step 350 Train loss 0.13 ACC 0.625 on epoch=174
04/28/2022 06:13:11 - INFO - __main__ - Step 360 Global step 360 Train loss 0.07 on epoch=179
04/28/2022 06:13:13 - INFO - __main__ - Step 370 Global step 370 Train loss 0.08 on epoch=184
04/28/2022 06:13:16 - INFO - __main__ - Step 380 Global step 380 Train loss 0.08 on epoch=189
04/28/2022 06:13:18 - INFO - __main__ - Step 390 Global step 390 Train loss 0.07 on epoch=194
04/28/2022 06:13:21 - INFO - __main__ - Step 400 Global step 400 Train loss 0.12 on epoch=199
04/28/2022 06:13:22 - INFO - __main__ - Global step 400 Train loss 0.08 ACC 0.5 on epoch=199
04/28/2022 06:13:24 - INFO - __main__ - Step 410 Global step 410 Train loss 0.10 on epoch=204
04/28/2022 06:13:27 - INFO - __main__ - Step 420 Global step 420 Train loss 0.04 on epoch=209
04/28/2022 06:13:29 - INFO - __main__ - Step 430 Global step 430 Train loss 0.11 on epoch=214
04/28/2022 06:13:32 - INFO - __main__ - Step 440 Global step 440 Train loss 0.14 on epoch=219
04/28/2022 06:13:34 - INFO - __main__ - Step 450 Global step 450 Train loss 0.04 on epoch=224
04/28/2022 06:13:35 - INFO - __main__ - Global step 450 Train loss 0.09 ACC 0.5625 on epoch=224
04/28/2022 06:13:38 - INFO - __main__ - Step 460 Global step 460 Train loss 0.07 on epoch=229
04/28/2022 06:13:40 - INFO - __main__ - Step 470 Global step 470 Train loss 0.07 on epoch=234
04/28/2022 06:13:43 - INFO - __main__ - Step 480 Global step 480 Train loss 0.04 on epoch=239
04/28/2022 06:13:45 - INFO - __main__ - Step 490 Global step 490 Train loss 0.07 on epoch=244
04/28/2022 06:13:47 - INFO - __main__ - Step 500 Global step 500 Train loss 0.07 on epoch=249
04/28/2022 06:13:48 - INFO - __main__ - Global step 500 Train loss 0.06 ACC 0.53125 on epoch=249
04/28/2022 06:13:51 - INFO - __main__ - Step 510 Global step 510 Train loss 0.05 on epoch=254
04/28/2022 06:13:53 - INFO - __main__ - Step 520 Global step 520 Train loss 0.08 on epoch=259
04/28/2022 06:13:56 - INFO - __main__ - Step 530 Global step 530 Train loss 0.08 on epoch=264
04/28/2022 06:13:58 - INFO - __main__ - Step 540 Global step 540 Train loss 0.09 on epoch=269
04/28/2022 06:14:01 - INFO - __main__ - Step 550 Global step 550 Train loss 0.06 on epoch=274
04/28/2022 06:14:02 - INFO - __main__ - Global step 550 Train loss 0.07 ACC 0.59375 on epoch=274
04/28/2022 06:14:04 - INFO - __main__ - Step 560 Global step 560 Train loss 0.02 on epoch=279
04/28/2022 06:14:07 - INFO - __main__ - Step 570 Global step 570 Train loss 0.08 on epoch=284
04/28/2022 06:14:09 - INFO - __main__ - Step 580 Global step 580 Train loss 0.07 on epoch=289
04/28/2022 06:14:12 - INFO - __main__ - Step 590 Global step 590 Train loss 0.04 on epoch=294
04/28/2022 06:14:14 - INFO - __main__ - Step 600 Global step 600 Train loss 0.05 on epoch=299
04/28/2022 06:14:15 - INFO - __main__ - Global step 600 Train loss 0.05 ACC 0.59375 on epoch=299
04/28/2022 06:14:17 - INFO - __main__ - Step 610 Global step 610 Train loss 0.03 on epoch=304
04/28/2022 06:14:20 - INFO - __main__ - Step 620 Global step 620 Train loss 0.04 on epoch=309
04/28/2022 06:14:22 - INFO - __main__ - Step 630 Global step 630 Train loss 0.08 on epoch=314
04/28/2022 06:14:25 - INFO - __main__ - Step 640 Global step 640 Train loss 0.06 on epoch=319
04/28/2022 06:14:27 - INFO - __main__ - Step 650 Global step 650 Train loss 0.02 on epoch=324
04/28/2022 06:14:28 - INFO - __main__ - Global step 650 Train loss 0.04 ACC 0.5625 on epoch=324
04/28/2022 06:14:31 - INFO - __main__ - Step 660 Global step 660 Train loss 0.02 on epoch=329
04/28/2022 06:14:33 - INFO - __main__ - Step 670 Global step 670 Train loss 0.03 on epoch=334
04/28/2022 06:14:36 - INFO - __main__ - Step 680 Global step 680 Train loss 0.06 on epoch=339
04/28/2022 06:14:38 - INFO - __main__ - Step 690 Global step 690 Train loss 0.01 on epoch=344
04/28/2022 06:14:41 - INFO - __main__ - Step 700 Global step 700 Train loss 0.01 on epoch=349
04/28/2022 06:14:41 - INFO - __main__ - Global step 700 Train loss 0.03 ACC 0.59375 on epoch=349
04/28/2022 06:14:44 - INFO - __main__ - Step 710 Global step 710 Train loss 0.03 on epoch=354
04/28/2022 06:14:46 - INFO - __main__ - Step 720 Global step 720 Train loss 0.06 on epoch=359
04/28/2022 06:14:49 - INFO - __main__ - Step 730 Global step 730 Train loss 0.05 on epoch=364
04/28/2022 06:14:51 - INFO - __main__ - Step 740 Global step 740 Train loss 0.03 on epoch=369
04/28/2022 06:14:54 - INFO - __main__ - Step 750 Global step 750 Train loss 0.02 on epoch=374
04/28/2022 06:14:55 - INFO - __main__ - Global step 750 Train loss 0.04 ACC 0.5625 on epoch=374
04/28/2022 06:14:57 - INFO - __main__ - Step 760 Global step 760 Train loss 0.02 on epoch=379
04/28/2022 06:15:00 - INFO - __main__ - Step 770 Global step 770 Train loss 0.07 on epoch=384
04/28/2022 06:15:02 - INFO - __main__ - Step 780 Global step 780 Train loss 0.01 on epoch=389
04/28/2022 06:15:05 - INFO - __main__ - Step 790 Global step 790 Train loss 0.03 on epoch=394
04/28/2022 06:15:07 - INFO - __main__ - Step 800 Global step 800 Train loss 0.00 on epoch=399
04/28/2022 06:15:08 - INFO - __main__ - Global step 800 Train loss 0.03 ACC 0.53125 on epoch=399
04/28/2022 06:15:10 - INFO - __main__ - Step 810 Global step 810 Train loss 0.01 on epoch=404
04/28/2022 06:15:13 - INFO - __main__ - Step 820 Global step 820 Train loss 0.03 on epoch=409
04/28/2022 06:15:15 - INFO - __main__ - Step 830 Global step 830 Train loss 0.01 on epoch=414
04/28/2022 06:15:18 - INFO - __main__ - Step 840 Global step 840 Train loss 0.01 on epoch=419
04/28/2022 06:15:20 - INFO - __main__ - Step 850 Global step 850 Train loss 0.00 on epoch=424
04/28/2022 06:15:21 - INFO - __main__ - Global step 850 Train loss 0.01 ACC 0.53125 on epoch=424
04/28/2022 06:15:24 - INFO - __main__ - Step 860 Global step 860 Train loss 0.01 on epoch=429
04/28/2022 06:15:26 - INFO - __main__ - Step 870 Global step 870 Train loss 0.02 on epoch=434
04/28/2022 06:15:29 - INFO - __main__ - Step 880 Global step 880 Train loss 0.01 on epoch=439
04/28/2022 06:15:31 - INFO - __main__ - Step 890 Global step 890 Train loss 0.03 on epoch=444
04/28/2022 06:15:34 - INFO - __main__ - Step 900 Global step 900 Train loss 0.01 on epoch=449
04/28/2022 06:15:34 - INFO - __main__ - Global step 900 Train loss 0.02 ACC 0.53125 on epoch=449
04/28/2022 06:15:37 - INFO - __main__ - Step 910 Global step 910 Train loss 0.04 on epoch=454
04/28/2022 06:15:39 - INFO - __main__ - Step 920 Global step 920 Train loss 0.03 on epoch=459
04/28/2022 06:15:42 - INFO - __main__ - Step 930 Global step 930 Train loss 0.02 on epoch=464
04/28/2022 06:15:44 - INFO - __main__ - Step 940 Global step 940 Train loss 0.03 on epoch=469
04/28/2022 06:15:47 - INFO - __main__ - Step 950 Global step 950 Train loss 0.03 on epoch=474
04/28/2022 06:15:48 - INFO - __main__ - Global step 950 Train loss 0.03 ACC 0.5 on epoch=474
04/28/2022 06:15:50 - INFO - __main__ - Step 960 Global step 960 Train loss 0.04 on epoch=479
04/28/2022 06:15:53 - INFO - __main__ - Step 970 Global step 970 Train loss 0.01 on epoch=484
04/28/2022 06:15:55 - INFO - __main__ - Step 980 Global step 980 Train loss 0.04 on epoch=489
04/28/2022 06:15:58 - INFO - __main__ - Step 990 Global step 990 Train loss 0.00 on epoch=494
04/28/2022 06:16:00 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.01 on epoch=499
04/28/2022 06:16:01 - INFO - __main__ - Global step 1000 Train loss 0.02 ACC 0.5625 on epoch=499
04/28/2022 06:16:03 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.03 on epoch=504
04/28/2022 06:16:06 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.00 on epoch=509
04/28/2022 06:16:08 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.03 on epoch=514
04/28/2022 06:16:11 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.01 on epoch=519
04/28/2022 06:16:13 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.05 on epoch=524
04/28/2022 06:16:14 - INFO - __main__ - Global step 1050 Train loss 0.02 ACC 0.53125 on epoch=524
04/28/2022 06:16:17 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.04 on epoch=529
04/28/2022 06:16:20 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.00 on epoch=534
04/28/2022 06:16:22 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.01 on epoch=539
04/28/2022 06:16:25 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.05 on epoch=544
04/28/2022 06:16:27 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.00 on epoch=549
04/28/2022 06:16:28 - INFO - __main__ - Global step 1100 Train loss 0.02 ACC 0.5625 on epoch=549
04/28/2022 06:16:31 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.00 on epoch=554
04/28/2022 06:16:33 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.00 on epoch=559
04/28/2022 06:16:36 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=564
04/28/2022 06:16:38 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.00 on epoch=569
04/28/2022 06:16:41 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.06 on epoch=574
04/28/2022 06:16:42 - INFO - __main__ - Global step 1150 Train loss 0.02 ACC 0.53125 on epoch=574
04/28/2022 06:16:45 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.01 on epoch=579
04/28/2022 06:16:47 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.00 on epoch=584
04/28/2022 06:16:50 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.00 on epoch=589
04/28/2022 06:16:52 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.05 on epoch=594
04/28/2022 06:16:55 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.02 on epoch=599
04/28/2022 06:16:56 - INFO - __main__ - Global step 1200 Train loss 0.02 ACC 0.53125 on epoch=599
04/28/2022 06:16:58 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.00 on epoch=604
04/28/2022 06:17:01 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=609
04/28/2022 06:17:03 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=614
04/28/2022 06:17:06 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.00 on epoch=619
04/28/2022 06:17:08 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.07 on epoch=624
04/28/2022 06:17:09 - INFO - __main__ - Global step 1250 Train loss 0.02 ACC 0.5 on epoch=624
04/28/2022 06:17:12 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.04 on epoch=629
04/28/2022 06:17:14 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.00 on epoch=634
04/28/2022 06:17:17 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.00 on epoch=639
04/28/2022 06:17:19 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.00 on epoch=644
04/28/2022 06:17:22 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=649
04/28/2022 06:17:23 - INFO - __main__ - Global step 1300 Train loss 0.01 ACC 0.53125 on epoch=649
04/28/2022 06:17:25 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.00 on epoch=654
04/28/2022 06:17:28 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.00 on epoch=659
04/28/2022 06:17:30 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.00 on epoch=664
04/28/2022 06:17:33 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.00 on epoch=669
04/28/2022 06:17:35 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.00 on epoch=674
04/28/2022 06:17:36 - INFO - __main__ - Global step 1350 Train loss 0.00 ACC 0.5625 on epoch=674
04/28/2022 06:17:38 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.00 on epoch=679
04/28/2022 06:17:41 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.00 on epoch=684
04/28/2022 06:17:43 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.04 on epoch=689
04/28/2022 06:17:46 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=694
04/28/2022 06:17:48 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=699
04/28/2022 06:17:49 - INFO - __main__ - Global step 1400 Train loss 0.01 ACC 0.5 on epoch=699
04/28/2022 06:17:52 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=704
04/28/2022 06:17:54 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=709
04/28/2022 06:17:57 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.00 on epoch=714
04/28/2022 06:17:59 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=719
04/28/2022 06:18:01 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=724
04/28/2022 06:18:02 - INFO - __main__ - Global step 1450 Train loss 0.00 ACC 0.4375 on epoch=724
04/28/2022 06:18:05 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=729
04/28/2022 06:18:07 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=734
04/28/2022 06:18:10 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=739
04/28/2022 06:18:12 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=744
04/28/2022 06:18:15 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=749
04/28/2022 06:18:16 - INFO - __main__ - Global step 1500 Train loss 0.01 ACC 0.53125 on epoch=749
04/28/2022 06:18:18 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=754
04/28/2022 06:18:20 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=759
04/28/2022 06:18:23 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=764
04/28/2022 06:18:25 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=769
04/28/2022 06:18:28 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=774
04/28/2022 06:18:29 - INFO - __main__ - Global step 1550 Train loss 0.00 ACC 0.53125 on epoch=774
04/28/2022 06:18:31 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=779
04/28/2022 06:18:34 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=784
04/28/2022 06:18:36 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=789
04/28/2022 06:18:39 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=794
04/28/2022 06:18:41 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=799
04/28/2022 06:18:42 - INFO - __main__ - Global step 1600 Train loss 0.00 ACC 0.5625 on epoch=799
04/28/2022 06:18:45 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.07 on epoch=804
04/28/2022 06:18:47 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=809
04/28/2022 06:18:50 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=814
04/28/2022 06:18:52 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=819
04/28/2022 06:18:54 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=824
04/28/2022 06:18:55 - INFO - __main__ - Global step 1650 Train loss 0.02 ACC 0.5625 on epoch=824
04/28/2022 06:18:58 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=829
04/28/2022 06:19:00 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=834
04/28/2022 06:19:03 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=839
04/28/2022 06:19:05 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=844
04/28/2022 06:19:08 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=849
04/28/2022 06:19:09 - INFO - __main__ - Global step 1700 Train loss 0.01 ACC 0.59375 on epoch=849
04/28/2022 06:19:11 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=854
04/28/2022 06:19:13 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=859
04/28/2022 06:19:16 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=864
04/28/2022 06:19:18 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=869
04/28/2022 06:19:21 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=874
04/28/2022 06:19:22 - INFO - __main__ - Global step 1750 Train loss 0.00 ACC 0.53125 on epoch=874
04/28/2022 06:19:24 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.04 on epoch=879
04/28/2022 06:19:27 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=884
04/28/2022 06:19:29 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=889
04/28/2022 06:19:32 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=894
04/28/2022 06:19:34 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=899
04/28/2022 06:19:35 - INFO - __main__ - Global step 1800 Train loss 0.01 ACC 0.5625 on epoch=899
04/28/2022 06:19:37 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=904
04/28/2022 06:19:40 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=909
04/28/2022 06:19:42 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=914
04/28/2022 06:19:45 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=919
04/28/2022 06:19:47 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=924
04/28/2022 06:19:48 - INFO - __main__ - Global step 1850 Train loss 0.00 ACC 0.625 on epoch=924
04/28/2022 06:19:51 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=929
04/28/2022 06:19:53 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=934
04/28/2022 06:19:56 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=939
04/28/2022 06:19:58 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=944
04/28/2022 06:20:01 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=949
04/28/2022 06:20:01 - INFO - __main__ - Global step 1900 Train loss 0.01 ACC 0.5625 on epoch=949
04/28/2022 06:20:04 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=954
04/28/2022 06:20:07 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=959
04/28/2022 06:20:09 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=964
04/28/2022 06:20:12 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=969
04/28/2022 06:20:14 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=974
04/28/2022 06:20:15 - INFO - __main__ - Global step 1950 Train loss 0.00 ACC 0.5625 on epoch=974
04/28/2022 06:20:18 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=979
04/28/2022 06:20:20 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.04 on epoch=984
04/28/2022 06:20:23 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=989
04/28/2022 06:20:25 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=994
04/28/2022 06:20:28 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=999
04/28/2022 06:20:29 - INFO - __main__ - Global step 2000 Train loss 0.01 ACC 0.5 on epoch=999
04/28/2022 06:20:29 - INFO - __main__ - save last model!
04/28/2022 06:20:29 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
04/28/2022 06:20:29 - INFO - __main__ - Start tokenizing ... 1000 instances
04/28/2022 06:20:29 - INFO - __main__ - Printing 3 examples
04/28/2022 06:20:29 - INFO - __main__ -  [wino_grande] Sarah was a much better surgeon than Maria so _ always got the easier cases. (A) Sarah (B) Maria
04/28/2022 06:20:29 - INFO - __main__ - ['Maria']
04/28/2022 06:20:29 - INFO - __main__ -  [wino_grande] Sarah was a much better surgeon than Maria so _ always got the harder cases. (A) Sarah (B) Maria
04/28/2022 06:20:29 - INFO - __main__ - ['Sarah']
04/28/2022 06:20:29 - INFO - __main__ -  [wino_grande] They were worried the wine would ruin the bed and the blanket, but the _ was't ruined. (A) blanket (B) bed
04/28/2022 06:20:29 - INFO - __main__ - ['bed']
04/28/2022 06:20:29 - INFO - __main__ - Tokenizing Input ...
04/28/2022 06:20:29 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 06:20:29 - INFO - __main__ - Printing 3 examples
04/28/2022 06:20:29 - INFO - __main__ -  [wino_grande] Brett wasn't sure what color of dress to buy unlike Derrick because _ was indecisive. (A) Brett (B) Derrick
04/28/2022 06:20:29 - INFO - __main__ - ['Brett']
04/28/2022 06:20:29 - INFO - __main__ -  [wino_grande] Jennifer felt love for others but Angela did not because _ had a cold feeling. (A) Jennifer (B) Angela
04/28/2022 06:20:29 - INFO - __main__ - ['Angela']
04/28/2022 06:20:29 - INFO - __main__ -  [wino_grande] The toddler was hurling his peas at the couches, as the _ made a very convenient missile. (A) peas (B) couches
04/28/2022 06:20:29 - INFO - __main__ - ['peas']
04/28/2022 06:20:29 - INFO - __main__ - Tokenizing Input ...
04/28/2022 06:20:29 - INFO - __main__ - Tokenizing Output ...
04/28/2022 06:20:29 - INFO - __main__ - Loaded 32 examples from train data
04/28/2022 06:20:29 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 06:20:29 - INFO - __main__ - Printing 3 examples
04/28/2022 06:20:29 - INFO - __main__ -  [wino_grande] They went on a safari and saw a panda eating bamboo, which Megan loved but Elena didn't care about. _ 's favorite animal was the panda. (A) Megan (B) Elena
04/28/2022 06:20:29 - INFO - __main__ - ['Megan']
04/28/2022 06:20:29 - INFO - __main__ -  [wino_grande] People liked being around Jeffrey more than around Neil because _ was a nice person. (A) Jeffrey (B) Neil
04/28/2022 06:20:29 - INFO - __main__ - ['Jeffrey']
04/28/2022 06:20:29 - INFO - __main__ -  [wino_grande] Steven worked all summer long to create a statue for Ian because _ hired him to. (A) Steven (B) Ian
04/28/2022 06:20:29 - INFO - __main__ - ['Ian']
04/28/2022 06:20:29 - INFO - __main__ - Tokenizing Input ...
04/28/2022 06:20:29 - INFO - __main__ - Tokenizing Output ...
04/28/2022 06:20:29 - INFO - __main__ - Tokenizing Output ...
04/28/2022 06:20:29 - INFO - __main__ - Loaded 32 examples from dev data
04/28/2022 06:20:30 - INFO - __main__ - Loaded 1000 examples from test data
04/28/2022 06:20:48 - INFO - __main__ - load prompt embedding from ckpt
04/28/2022 06:20:48 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/28/2022 06:20:48 - INFO - __main__ - Starting training!
04/28/2022 06:20:54 - INFO - __main__ - Saved prediction in models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-wino_grande/wino_grande_32_13_0.3_8_predictions.txt
04/28/2022 06:20:54 - INFO - __main__ - ACC on test data: 0.4910
04/28/2022 06:20:54 - INFO - __main__ - prefix=wino_grande_32_13, lr=0.3, bsz=8, dev_performance=0.6875, test_performance=0.491
04/28/2022 06:20:54 - INFO - __main__ - Running ... prefix=wino_grande_32_13, lr=0.2, bsz=8 ...
04/28/2022 06:20:55 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 06:20:55 - INFO - __main__ - Printing 3 examples
04/28/2022 06:20:55 - INFO - __main__ -  [wino_grande] Brett wasn't sure what color of dress to buy unlike Derrick because _ was indecisive. (A) Brett (B) Derrick
04/28/2022 06:20:55 - INFO - __main__ - ['Brett']
04/28/2022 06:20:55 - INFO - __main__ -  [wino_grande] Jennifer felt love for others but Angela did not because _ had a cold feeling. (A) Jennifer (B) Angela
04/28/2022 06:20:55 - INFO - __main__ - ['Angela']
04/28/2022 06:20:55 - INFO - __main__ -  [wino_grande] The toddler was hurling his peas at the couches, as the _ made a very convenient missile. (A) peas (B) couches
04/28/2022 06:20:55 - INFO - __main__ - ['peas']
04/28/2022 06:20:55 - INFO - __main__ - Tokenizing Input ...
04/28/2022 06:20:55 - INFO - __main__ - Tokenizing Output ...
04/28/2022 06:20:55 - INFO - __main__ - Loaded 32 examples from train data
04/28/2022 06:20:55 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 06:20:55 - INFO - __main__ - Printing 3 examples
04/28/2022 06:20:55 - INFO - __main__ -  [wino_grande] They went on a safari and saw a panda eating bamboo, which Megan loved but Elena didn't care about. _ 's favorite animal was the panda. (A) Megan (B) Elena
04/28/2022 06:20:55 - INFO - __main__ - ['Megan']
04/28/2022 06:20:55 - INFO - __main__ -  [wino_grande] People liked being around Jeffrey more than around Neil because _ was a nice person. (A) Jeffrey (B) Neil
04/28/2022 06:20:55 - INFO - __main__ - ['Jeffrey']
04/28/2022 06:20:55 - INFO - __main__ -  [wino_grande] Steven worked all summer long to create a statue for Ian because _ hired him to. (A) Steven (B) Ian
04/28/2022 06:20:55 - INFO - __main__ - ['Ian']
04/28/2022 06:20:55 - INFO - __main__ - Tokenizing Input ...
04/28/2022 06:20:55 - INFO - __main__ - Tokenizing Output ...
04/28/2022 06:20:55 - INFO - __main__ - Loaded 32 examples from dev data
04/28/2022 06:21:10 - INFO - __main__ - load prompt embedding from ckpt
04/28/2022 06:21:11 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/28/2022 06:21:11 - INFO - __main__ - Starting training!
04/28/2022 06:21:14 - INFO - __main__ - Step 10 Global step 10 Train loss 3.79 on epoch=4
04/28/2022 06:21:16 - INFO - __main__ - Step 20 Global step 20 Train loss 2.17 on epoch=9
04/28/2022 06:21:19 - INFO - __main__ - Step 30 Global step 30 Train loss 1.25 on epoch=14
04/28/2022 06:21:21 - INFO - __main__ - Step 40 Global step 40 Train loss 0.82 on epoch=19
04/28/2022 06:21:24 - INFO - __main__ - Step 50 Global step 50 Train loss 0.65 on epoch=24
04/28/2022 06:21:25 - INFO - __main__ - Global step 50 Train loss 1.74 ACC 0.625 on epoch=24
04/28/2022 06:21:25 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.625 on epoch=24, global_step=50
04/28/2022 06:21:27 - INFO - __main__ - Step 60 Global step 60 Train loss 0.65 on epoch=29
04/28/2022 06:21:30 - INFO - __main__ - Step 70 Global step 70 Train loss 0.68 on epoch=34
04/28/2022 06:21:32 - INFO - __main__ - Step 80 Global step 80 Train loss 0.40 on epoch=39
04/28/2022 06:21:35 - INFO - __main__ - Step 90 Global step 90 Train loss 0.42 on epoch=44
04/28/2022 06:21:37 - INFO - __main__ - Step 100 Global step 100 Train loss 0.51 on epoch=49
04/28/2022 06:21:38 - INFO - __main__ - Global step 100 Train loss 0.53 ACC 0.5625 on epoch=49
04/28/2022 06:21:40 - INFO - __main__ - Step 110 Global step 110 Train loss 0.33 on epoch=54
04/28/2022 06:21:43 - INFO - __main__ - Step 120 Global step 120 Train loss 0.51 on epoch=59
04/28/2022 06:21:45 - INFO - __main__ - Step 130 Global step 130 Train loss 0.32 on epoch=64
04/28/2022 06:21:48 - INFO - __main__ - Step 140 Global step 140 Train loss 0.40 on epoch=69
04/28/2022 06:21:50 - INFO - __main__ - Step 150 Global step 150 Train loss 0.26 on epoch=74
04/28/2022 06:21:51 - INFO - __main__ - Global step 150 Train loss 0.36 ACC 0.5625 on epoch=74
04/28/2022 06:21:54 - INFO - __main__ - Step 160 Global step 160 Train loss 0.36 on epoch=79
04/28/2022 06:21:56 - INFO - __main__ - Step 170 Global step 170 Train loss 0.27 on epoch=84
04/28/2022 06:21:58 - INFO - __main__ - Step 180 Global step 180 Train loss 0.32 on epoch=89
04/28/2022 06:22:01 - INFO - __main__ - Step 190 Global step 190 Train loss 0.32 on epoch=94
04/28/2022 06:22:03 - INFO - __main__ - Step 200 Global step 200 Train loss 0.21 on epoch=99
04/28/2022 06:22:04 - INFO - __main__ - Global step 200 Train loss 0.29 ACC 0.625 on epoch=99
04/28/2022 06:22:07 - INFO - __main__ - Step 210 Global step 210 Train loss 0.22 on epoch=104
04/28/2022 06:22:09 - INFO - __main__ - Step 220 Global step 220 Train loss 0.19 on epoch=109
04/28/2022 06:22:12 - INFO - __main__ - Step 230 Global step 230 Train loss 0.19 on epoch=114
04/28/2022 06:22:14 - INFO - __main__ - Step 240 Global step 240 Train loss 0.17 on epoch=119
04/28/2022 06:22:17 - INFO - __main__ - Step 250 Global step 250 Train loss 0.23 on epoch=124
04/28/2022 06:22:17 - INFO - __main__ - Global step 250 Train loss 0.20 ACC 0.5625 on epoch=124
04/28/2022 06:22:20 - INFO - __main__ - Step 260 Global step 260 Train loss 0.17 on epoch=129
04/28/2022 06:22:22 - INFO - __main__ - Step 270 Global step 270 Train loss 0.18 on epoch=134
04/28/2022 06:22:25 - INFO - __main__ - Step 280 Global step 280 Train loss 0.12 on epoch=139
04/28/2022 06:22:27 - INFO - __main__ - Step 290 Global step 290 Train loss 0.19 on epoch=144
04/28/2022 06:22:30 - INFO - __main__ - Step 300 Global step 300 Train loss 0.24 on epoch=149
04/28/2022 06:22:31 - INFO - __main__ - Global step 300 Train loss 0.18 ACC 0.53125 on epoch=149
04/28/2022 06:22:33 - INFO - __main__ - Step 310 Global step 310 Train loss 0.19 on epoch=154
04/28/2022 06:22:36 - INFO - __main__ - Step 320 Global step 320 Train loss 0.15 on epoch=159
04/28/2022 06:22:38 - INFO - __main__ - Step 330 Global step 330 Train loss 0.12 on epoch=164
04/28/2022 06:22:41 - INFO - __main__ - Step 340 Global step 340 Train loss 0.15 on epoch=169
04/28/2022 06:22:43 - INFO - __main__ - Step 350 Global step 350 Train loss 0.20 on epoch=174
04/28/2022 06:22:44 - INFO - __main__ - Global step 350 Train loss 0.16 ACC 0.46875 on epoch=174
04/28/2022 06:22:46 - INFO - __main__ - Step 360 Global step 360 Train loss 0.15 on epoch=179
04/28/2022 06:22:49 - INFO - __main__ - Step 370 Global step 370 Train loss 0.19 on epoch=184
04/28/2022 06:22:51 - INFO - __main__ - Step 380 Global step 380 Train loss 0.07 on epoch=189
04/28/2022 06:22:54 - INFO - __main__ - Step 390 Global step 390 Train loss 0.15 on epoch=194
04/28/2022 06:22:56 - INFO - __main__ - Step 400 Global step 400 Train loss 0.08 on epoch=199
04/28/2022 06:22:57 - INFO - __main__ - Global step 400 Train loss 0.13 ACC 0.625 on epoch=199
04/28/2022 06:23:00 - INFO - __main__ - Step 410 Global step 410 Train loss 0.15 on epoch=204
04/28/2022 06:23:02 - INFO - __main__ - Step 420 Global step 420 Train loss 0.09 on epoch=209
04/28/2022 06:23:05 - INFO - __main__ - Step 430 Global step 430 Train loss 0.07 on epoch=214
04/28/2022 06:23:07 - INFO - __main__ - Step 440 Global step 440 Train loss 0.05 on epoch=219
04/28/2022 06:23:09 - INFO - __main__ - Step 450 Global step 450 Train loss 0.15 on epoch=224
04/28/2022 06:23:10 - INFO - __main__ - Global step 450 Train loss 0.10 ACC 0.53125 on epoch=224
04/28/2022 06:23:13 - INFO - __main__ - Step 460 Global step 460 Train loss 0.13 on epoch=229
04/28/2022 06:23:15 - INFO - __main__ - Step 470 Global step 470 Train loss 0.14 on epoch=234
04/28/2022 06:23:18 - INFO - __main__ - Step 480 Global step 480 Train loss 0.12 on epoch=239
04/28/2022 06:23:20 - INFO - __main__ - Step 490 Global step 490 Train loss 0.11 on epoch=244
04/28/2022 06:23:23 - INFO - __main__ - Step 500 Global step 500 Train loss 0.09 on epoch=249
04/28/2022 06:23:24 - INFO - __main__ - Global step 500 Train loss 0.12 ACC 0.53125 on epoch=249
04/28/2022 06:23:26 - INFO - __main__ - Step 510 Global step 510 Train loss 0.12 on epoch=254
04/28/2022 06:23:29 - INFO - __main__ - Step 520 Global step 520 Train loss 0.06 on epoch=259
04/28/2022 06:23:31 - INFO - __main__ - Step 530 Global step 530 Train loss 0.07 on epoch=264
04/28/2022 06:23:33 - INFO - __main__ - Step 540 Global step 540 Train loss 0.09 on epoch=269
04/28/2022 06:23:36 - INFO - __main__ - Step 550 Global step 550 Train loss 0.07 on epoch=274
04/28/2022 06:23:37 - INFO - __main__ - Global step 550 Train loss 0.08 ACC 0.53125 on epoch=274
04/28/2022 06:23:39 - INFO - __main__ - Step 560 Global step 560 Train loss 0.08 on epoch=279
04/28/2022 06:23:42 - INFO - __main__ - Step 570 Global step 570 Train loss 0.07 on epoch=284
04/28/2022 06:23:44 - INFO - __main__ - Step 580 Global step 580 Train loss 0.09 on epoch=289
04/28/2022 06:23:47 - INFO - __main__ - Step 590 Global step 590 Train loss 0.11 on epoch=294
04/28/2022 06:23:49 - INFO - __main__ - Step 600 Global step 600 Train loss 0.06 on epoch=299
04/28/2022 06:23:50 - INFO - __main__ - Global step 600 Train loss 0.08 ACC 0.5 on epoch=299
04/28/2022 06:23:53 - INFO - __main__ - Step 610 Global step 610 Train loss 0.03 on epoch=304
04/28/2022 06:23:55 - INFO - __main__ - Step 620 Global step 620 Train loss 0.04 on epoch=309
04/28/2022 06:23:58 - INFO - __main__ - Step 630 Global step 630 Train loss 0.05 on epoch=314
04/28/2022 06:24:00 - INFO - __main__ - Step 640 Global step 640 Train loss 0.05 on epoch=319
04/28/2022 06:24:02 - INFO - __main__ - Step 650 Global step 650 Train loss 0.09 on epoch=324
04/28/2022 06:24:03 - INFO - __main__ - Global step 650 Train loss 0.05 ACC 0.46875 on epoch=324
04/28/2022 06:24:06 - INFO - __main__ - Step 660 Global step 660 Train loss 0.09 on epoch=329
04/28/2022 06:24:08 - INFO - __main__ - Step 670 Global step 670 Train loss 0.08 on epoch=334
04/28/2022 06:24:11 - INFO - __main__ - Step 680 Global step 680 Train loss 0.08 on epoch=339
04/28/2022 06:24:13 - INFO - __main__ - Step 690 Global step 690 Train loss 0.09 on epoch=344
04/28/2022 06:24:16 - INFO - __main__ - Step 700 Global step 700 Train loss 0.02 on epoch=349
04/28/2022 06:24:16 - INFO - __main__ - Global step 700 Train loss 0.07 ACC 0.5 on epoch=349
04/28/2022 06:24:19 - INFO - __main__ - Step 710 Global step 710 Train loss 0.10 on epoch=354
04/28/2022 06:24:21 - INFO - __main__ - Step 720 Global step 720 Train loss 0.11 on epoch=359
04/28/2022 06:24:24 - INFO - __main__ - Step 730 Global step 730 Train loss 0.12 on epoch=364
04/28/2022 06:24:26 - INFO - __main__ - Step 740 Global step 740 Train loss 0.03 on epoch=369
04/28/2022 06:24:29 - INFO - __main__ - Step 750 Global step 750 Train loss 0.06 on epoch=374
04/28/2022 06:24:30 - INFO - __main__ - Global step 750 Train loss 0.08 ACC 0.5625 on epoch=374
04/28/2022 06:24:32 - INFO - __main__ - Step 760 Global step 760 Train loss 0.04 on epoch=379
04/28/2022 06:24:35 - INFO - __main__ - Step 770 Global step 770 Train loss 0.03 on epoch=384
04/28/2022 06:24:37 - INFO - __main__ - Step 780 Global step 780 Train loss 0.07 on epoch=389
04/28/2022 06:24:39 - INFO - __main__ - Step 790 Global step 790 Train loss 0.03 on epoch=394
04/28/2022 06:24:42 - INFO - __main__ - Step 800 Global step 800 Train loss 0.02 on epoch=399
04/28/2022 06:24:43 - INFO - __main__ - Global step 800 Train loss 0.04 ACC 0.5625 on epoch=399
04/28/2022 06:24:45 - INFO - __main__ - Step 810 Global step 810 Train loss 0.13 on epoch=404
04/28/2022 06:24:48 - INFO - __main__ - Step 820 Global step 820 Train loss 0.03 on epoch=409
04/28/2022 06:24:50 - INFO - __main__ - Step 830 Global step 830 Train loss 0.05 on epoch=414
04/28/2022 06:24:53 - INFO - __main__ - Step 840 Global step 840 Train loss 0.02 on epoch=419
04/28/2022 06:24:55 - INFO - __main__ - Step 850 Global step 850 Train loss 0.06 on epoch=424
04/28/2022 06:24:56 - INFO - __main__ - Global step 850 Train loss 0.06 ACC 0.46875 on epoch=424
04/28/2022 06:24:59 - INFO - __main__ - Step 860 Global step 860 Train loss 0.03 on epoch=429
04/28/2022 06:25:01 - INFO - __main__ - Step 870 Global step 870 Train loss 0.04 on epoch=434
04/28/2022 06:25:04 - INFO - __main__ - Step 880 Global step 880 Train loss 0.04 on epoch=439
04/28/2022 06:25:06 - INFO - __main__ - Step 890 Global step 890 Train loss 0.13 on epoch=444
04/28/2022 06:25:08 - INFO - __main__ - Step 900 Global step 900 Train loss 0.04 on epoch=449
04/28/2022 06:25:09 - INFO - __main__ - Global step 900 Train loss 0.06 ACC 0.46875 on epoch=449
04/28/2022 06:25:12 - INFO - __main__ - Step 910 Global step 910 Train loss 0.07 on epoch=454
04/28/2022 06:25:14 - INFO - __main__ - Step 920 Global step 920 Train loss 0.01 on epoch=459
04/28/2022 06:25:17 - INFO - __main__ - Step 930 Global step 930 Train loss 0.09 on epoch=464
04/28/2022 06:25:19 - INFO - __main__ - Step 940 Global step 940 Train loss 0.04 on epoch=469
04/28/2022 06:25:22 - INFO - __main__ - Step 950 Global step 950 Train loss 0.04 on epoch=474
04/28/2022 06:25:22 - INFO - __main__ - Global step 950 Train loss 0.05 ACC 0.5 on epoch=474
04/28/2022 06:25:25 - INFO - __main__ - Step 960 Global step 960 Train loss 0.04 on epoch=479
04/28/2022 06:25:27 - INFO - __main__ - Step 970 Global step 970 Train loss 0.02 on epoch=484
04/28/2022 06:25:30 - INFO - __main__ - Step 980 Global step 980 Train loss 0.01 on epoch=489
04/28/2022 06:25:32 - INFO - __main__ - Step 990 Global step 990 Train loss 0.01 on epoch=494
04/28/2022 06:25:35 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.02 on epoch=499
04/28/2022 06:25:36 - INFO - __main__ - Global step 1000 Train loss 0.02 ACC 0.5 on epoch=499
04/28/2022 06:25:38 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.04 on epoch=504
04/28/2022 06:25:41 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.04 on epoch=509
04/28/2022 06:25:43 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.03 on epoch=514
04/28/2022 06:25:46 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.01 on epoch=519
04/28/2022 06:25:48 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.02 on epoch=524
04/28/2022 06:25:49 - INFO - __main__ - Global step 1050 Train loss 0.03 ACC 0.46875 on epoch=524
04/28/2022 06:25:52 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.02 on epoch=529
04/28/2022 06:25:54 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.03 on epoch=534
04/28/2022 06:25:56 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.03 on epoch=539
04/28/2022 06:25:59 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.05 on epoch=544
04/28/2022 06:26:01 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.09 on epoch=549
04/28/2022 06:26:02 - INFO - __main__ - Global step 1100 Train loss 0.04 ACC 0.5 on epoch=549
04/28/2022 06:26:05 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.04 on epoch=554
04/28/2022 06:26:07 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=559
04/28/2022 06:26:10 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.00 on epoch=564
04/28/2022 06:26:12 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.06 on epoch=569
04/28/2022 06:26:15 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=574
04/28/2022 06:26:16 - INFO - __main__ - Global step 1150 Train loss 0.02 ACC 0.5 on epoch=574
04/28/2022 06:26:18 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.01 on epoch=579
04/28/2022 06:26:20 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.02 on epoch=584
04/28/2022 06:26:23 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.03 on epoch=589
04/28/2022 06:26:25 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.02 on epoch=594
04/28/2022 06:26:28 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.02 on epoch=599
04/28/2022 06:26:29 - INFO - __main__ - Global step 1200 Train loss 0.02 ACC 0.5 on epoch=599
04/28/2022 06:26:31 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.02 on epoch=604
04/28/2022 06:26:34 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=609
04/28/2022 06:26:36 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.03 on epoch=614
04/28/2022 06:26:39 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.02 on epoch=619
04/28/2022 06:26:41 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.01 on epoch=624
04/28/2022 06:26:42 - INFO - __main__ - Global step 1250 Train loss 0.02 ACC 0.46875 on epoch=624
04/28/2022 06:26:45 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.08 on epoch=629
04/28/2022 06:26:47 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.02 on epoch=634
04/28/2022 06:26:49 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=639
04/28/2022 06:26:52 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.02 on epoch=644
04/28/2022 06:26:54 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=649
04/28/2022 06:26:55 - INFO - __main__ - Global step 1300 Train loss 0.03 ACC 0.4375 on epoch=649
04/28/2022 06:26:58 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.04 on epoch=654
04/28/2022 06:27:00 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.00 on epoch=659
04/28/2022 06:27:03 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=664
04/28/2022 06:27:05 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=669
04/28/2022 06:27:08 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.04 on epoch=674
04/28/2022 06:27:09 - INFO - __main__ - Global step 1350 Train loss 0.02 ACC 0.5 on epoch=674
04/28/2022 06:27:11 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=679
04/28/2022 06:27:13 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.02 on epoch=684
04/28/2022 06:27:16 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.04 on epoch=689
04/28/2022 06:27:18 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.02 on epoch=694
04/28/2022 06:27:21 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=699
04/28/2022 06:27:22 - INFO - __main__ - Global step 1400 Train loss 0.02 ACC 0.5 on epoch=699
04/28/2022 06:27:24 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.02 on epoch=704
04/28/2022 06:27:27 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=709
04/28/2022 06:27:29 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=714
04/28/2022 06:27:32 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=719
04/28/2022 06:27:34 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=724
04/28/2022 06:27:35 - INFO - __main__ - Global step 1450 Train loss 0.01 ACC 0.53125 on epoch=724
04/28/2022 06:27:38 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=729
04/28/2022 06:27:40 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=734
04/28/2022 06:27:43 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=739
04/28/2022 06:27:45 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=744
04/28/2022 06:27:48 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=749
04/28/2022 06:27:49 - INFO - __main__ - Global step 1500 Train loss 0.01 ACC 0.5 on epoch=749
04/28/2022 06:27:51 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=754
04/28/2022 06:27:54 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=759
04/28/2022 06:27:56 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=764
04/28/2022 06:27:59 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=769
04/28/2022 06:28:01 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=774
04/28/2022 06:28:02 - INFO - __main__ - Global step 1550 Train loss 0.01 ACC 0.46875 on epoch=774
04/28/2022 06:28:05 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=779
04/28/2022 06:28:07 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=784
04/28/2022 06:28:09 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=789
04/28/2022 06:28:12 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=794
04/28/2022 06:28:14 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=799
04/28/2022 06:28:15 - INFO - __main__ - Global step 1600 Train loss 0.00 ACC 0.53125 on epoch=799
04/28/2022 06:28:18 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=804
04/28/2022 06:28:20 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.08 on epoch=809
04/28/2022 06:28:23 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=814
04/28/2022 06:28:25 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=819
04/28/2022 06:28:28 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.05 on epoch=824
04/28/2022 06:28:29 - INFO - __main__ - Global step 1650 Train loss 0.03 ACC 0.53125 on epoch=824
04/28/2022 06:28:31 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.03 on epoch=829
04/28/2022 06:28:34 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=834
04/28/2022 06:28:36 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=839
04/28/2022 06:28:38 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=844
04/28/2022 06:28:41 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.04 on epoch=849
04/28/2022 06:28:42 - INFO - __main__ - Global step 1700 Train loss 0.02 ACC 0.5 on epoch=849
04/28/2022 06:28:44 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.03 on epoch=854
04/28/2022 06:28:47 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=859
04/28/2022 06:28:49 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=864
04/28/2022 06:28:52 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=869
04/28/2022 06:28:54 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=874
04/28/2022 06:28:55 - INFO - __main__ - Global step 1750 Train loss 0.01 ACC 0.46875 on epoch=874
04/28/2022 06:28:58 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=879
04/28/2022 06:29:00 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=884
04/28/2022 06:29:03 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=889
04/28/2022 06:29:05 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=894
04/28/2022 06:29:07 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=899
04/28/2022 06:29:08 - INFO - __main__ - Global step 1800 Train loss 0.01 ACC 0.5 on epoch=899
04/28/2022 06:29:11 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=904
04/28/2022 06:29:13 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=909
04/28/2022 06:29:16 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=914
04/28/2022 06:29:18 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=919
04/28/2022 06:29:21 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.04 on epoch=924
04/28/2022 06:29:22 - INFO - __main__ - Global step 1850 Train loss 0.01 ACC 0.5625 on epoch=924
04/28/2022 06:29:24 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=929
04/28/2022 06:29:27 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.11 on epoch=934
04/28/2022 06:29:29 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=939
04/28/2022 06:29:32 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=944
04/28/2022 06:29:34 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=949
04/28/2022 06:29:35 - INFO - __main__ - Global step 1900 Train loss 0.02 ACC 0.5 on epoch=949
04/28/2022 06:29:37 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=954
04/28/2022 06:29:40 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=959
04/28/2022 06:29:42 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=964
04/28/2022 06:29:45 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=969
04/28/2022 06:29:47 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=974
04/28/2022 06:29:48 - INFO - __main__ - Global step 1950 Train loss 0.00 ACC 0.53125 on epoch=974
04/28/2022 06:29:51 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=979
04/28/2022 06:29:53 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=984
04/28/2022 06:29:56 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=989
04/28/2022 06:29:58 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=994
04/28/2022 06:30:01 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=999
04/28/2022 06:30:02 - INFO - __main__ - Global step 2000 Train loss 0.01 ACC 0.53125 on epoch=999
04/28/2022 06:30:02 - INFO - __main__ - save last model!
04/28/2022 06:30:02 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
04/28/2022 06:30:02 - INFO - __main__ - Start tokenizing ... 1000 instances
04/28/2022 06:30:02 - INFO - __main__ - Printing 3 examples
04/28/2022 06:30:02 - INFO - __main__ -  [wino_grande] Sarah was a much better surgeon than Maria so _ always got the easier cases. (A) Sarah (B) Maria
04/28/2022 06:30:02 - INFO - __main__ - ['Maria']
04/28/2022 06:30:02 - INFO - __main__ -  [wino_grande] Sarah was a much better surgeon than Maria so _ always got the harder cases. (A) Sarah (B) Maria
04/28/2022 06:30:02 - INFO - __main__ - ['Sarah']
04/28/2022 06:30:02 - INFO - __main__ -  [wino_grande] They were worried the wine would ruin the bed and the blanket, but the _ was't ruined. (A) blanket (B) bed
04/28/2022 06:30:02 - INFO - __main__ - ['bed']
04/28/2022 06:30:02 - INFO - __main__ - Tokenizing Input ...
04/28/2022 06:30:02 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 06:30:02 - INFO - __main__ - Printing 3 examples
04/28/2022 06:30:02 - INFO - __main__ -  [wino_grande] Adam appointed Neil as the head guard, because _ trained so hard that he became the best of the best. (A) Adam (B) Neil
04/28/2022 06:30:02 - INFO - __main__ - ['Neil']
04/28/2022 06:30:02 - INFO - __main__ -  [wino_grande] Victoria was a more freaked out individual than Natalie, so _ became paranoid more easily. (A) Victoria (B) Natalie
04/28/2022 06:30:02 - INFO - __main__ - ['Victoria']
04/28/2022 06:30:02 - INFO - __main__ -  [wino_grande] Joseph thought Craig was turning into a homebody because _ would not get out of the house. (A) Joseph (B) Craig
04/28/2022 06:30:02 - INFO - __main__ - ['Craig']
04/28/2022 06:30:02 - INFO - __main__ - Tokenizing Input ...
04/28/2022 06:30:02 - INFO - __main__ - Tokenizing Output ...
04/28/2022 06:30:02 - INFO - __main__ - Loaded 32 examples from train data
04/28/2022 06:30:02 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 06:30:02 - INFO - __main__ - Printing 3 examples
04/28/2022 06:30:02 - INFO - __main__ -  [wino_grande] Donald ran as fast as a snail unlike Kevin who ran faster, because _ had an injury. (A) Donald (B) Kevin
04/28/2022 06:30:02 - INFO - __main__ - ['Donald']
04/28/2022 06:30:02 - INFO - __main__ -  [wino_grande] He tried to put the pacifier into their baby's mouth, but struggled because the _ was too tiny. (A) pacifier (B) mouth
04/28/2022 06:30:02 - INFO - __main__ - ['mouth']
04/28/2022 06:30:02 - INFO - __main__ -  [wino_grande] Meg was in a hurry so while parking and getting out of her car she accidentally left her phone inside as the _ was more pressing. (A) phone (B) car
04/28/2022 06:30:02 - INFO - __main__ - ['car']
04/28/2022 06:30:02 - INFO - __main__ - Tokenizing Input ...
04/28/2022 06:30:02 - INFO - __main__ - Tokenizing Output ...
04/28/2022 06:30:02 - INFO - __main__ - Loaded 32 examples from dev data
04/28/2022 06:30:02 - INFO - __main__ - Tokenizing Output ...
04/28/2022 06:30:03 - INFO - __main__ - Loaded 1000 examples from test data
04/28/2022 06:30:21 - INFO - __main__ - load prompt embedding from ckpt
04/28/2022 06:30:21 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/28/2022 06:30:21 - INFO - __main__ - Starting training!
04/28/2022 06:30:26 - INFO - __main__ - Saved prediction in models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-wino_grande/wino_grande_32_13_0.2_8_predictions.txt
04/28/2022 06:30:26 - INFO - __main__ - ACC on test data: 0.5100
04/28/2022 06:30:26 - INFO - __main__ - prefix=wino_grande_32_13, lr=0.2, bsz=8, dev_performance=0.625, test_performance=0.51
04/28/2022 06:30:26 - INFO - __main__ - Running ... prefix=wino_grande_32_21, lr=0.5, bsz=8 ...
04/28/2022 06:30:27 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 06:30:27 - INFO - __main__ - Printing 3 examples
04/28/2022 06:30:27 - INFO - __main__ -  [wino_grande] Adam appointed Neil as the head guard, because _ trained so hard that he became the best of the best. (A) Adam (B) Neil
04/28/2022 06:30:27 - INFO - __main__ - ['Neil']
04/28/2022 06:30:27 - INFO - __main__ -  [wino_grande] Victoria was a more freaked out individual than Natalie, so _ became paranoid more easily. (A) Victoria (B) Natalie
04/28/2022 06:30:27 - INFO - __main__ - ['Victoria']
04/28/2022 06:30:27 - INFO - __main__ -  [wino_grande] Joseph thought Craig was turning into a homebody because _ would not get out of the house. (A) Joseph (B) Craig
04/28/2022 06:30:27 - INFO - __main__ - ['Craig']
04/28/2022 06:30:27 - INFO - __main__ - Tokenizing Input ...
04/28/2022 06:30:27 - INFO - __main__ - Tokenizing Output ...
04/28/2022 06:30:27 - INFO - __main__ - Loaded 32 examples from train data
04/28/2022 06:30:27 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 06:30:27 - INFO - __main__ - Printing 3 examples
04/28/2022 06:30:27 - INFO - __main__ -  [wino_grande] Donald ran as fast as a snail unlike Kevin who ran faster, because _ had an injury. (A) Donald (B) Kevin
04/28/2022 06:30:27 - INFO - __main__ - ['Donald']
04/28/2022 06:30:27 - INFO - __main__ -  [wino_grande] He tried to put the pacifier into their baby's mouth, but struggled because the _ was too tiny. (A) pacifier (B) mouth
04/28/2022 06:30:27 - INFO - __main__ - ['mouth']
04/28/2022 06:30:27 - INFO - __main__ -  [wino_grande] Meg was in a hurry so while parking and getting out of her car she accidentally left her phone inside as the _ was more pressing. (A) phone (B) car
04/28/2022 06:30:27 - INFO - __main__ - ['car']
04/28/2022 06:30:27 - INFO - __main__ - Tokenizing Input ...
04/28/2022 06:30:27 - INFO - __main__ - Tokenizing Output ...
04/28/2022 06:30:27 - INFO - __main__ - Loaded 32 examples from dev data
04/28/2022 06:30:42 - INFO - __main__ - load prompt embedding from ckpt
04/28/2022 06:30:43 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/28/2022 06:30:43 - INFO - __main__ - Starting training!
04/28/2022 06:30:46 - INFO - __main__ - Step 10 Global step 10 Train loss 3.27 on epoch=4
04/28/2022 06:30:48 - INFO - __main__ - Step 20 Global step 20 Train loss 1.09 on epoch=9
04/28/2022 06:30:51 - INFO - __main__ - Step 30 Global step 30 Train loss 0.68 on epoch=14
04/28/2022 06:30:53 - INFO - __main__ - Step 40 Global step 40 Train loss 0.54 on epoch=19
04/28/2022 06:30:55 - INFO - __main__ - Step 50 Global step 50 Train loss 0.46 on epoch=24
04/28/2022 06:30:56 - INFO - __main__ - Global step 50 Train loss 1.21 ACC 0.59375 on epoch=24
04/28/2022 06:30:56 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.59375 on epoch=24, global_step=50
04/28/2022 06:30:59 - INFO - __main__ - Step 60 Global step 60 Train loss 0.22 on epoch=29
04/28/2022 06:31:01 - INFO - __main__ - Step 70 Global step 70 Train loss 0.16 on epoch=34
04/28/2022 06:31:04 - INFO - __main__ - Step 80 Global step 80 Train loss 0.15 on epoch=39
04/28/2022 06:31:06 - INFO - __main__ - Step 90 Global step 90 Train loss 0.22 on epoch=44
04/28/2022 06:31:09 - INFO - __main__ - Step 100 Global step 100 Train loss 0.24 on epoch=49
04/28/2022 06:31:09 - INFO - __main__ - Global step 100 Train loss 0.20 ACC 0.59375 on epoch=49
04/28/2022 06:31:12 - INFO - __main__ - Step 110 Global step 110 Train loss 0.15 on epoch=54
04/28/2022 06:31:14 - INFO - __main__ - Step 120 Global step 120 Train loss 0.18 on epoch=59
04/28/2022 06:31:17 - INFO - __main__ - Step 130 Global step 130 Train loss 0.12 on epoch=64
04/28/2022 06:31:19 - INFO - __main__ - Step 140 Global step 140 Train loss 0.11 on epoch=69
04/28/2022 06:31:21 - INFO - __main__ - Step 150 Global step 150 Train loss 0.12 on epoch=74
04/28/2022 06:31:22 - INFO - __main__ - Global step 150 Train loss 0.14 ACC 0.53125 on epoch=74
04/28/2022 06:31:25 - INFO - __main__ - Step 160 Global step 160 Train loss 0.07 on epoch=79
04/28/2022 06:31:27 - INFO - __main__ - Step 170 Global step 170 Train loss 0.11 on epoch=84
04/28/2022 06:31:29 - INFO - __main__ - Step 180 Global step 180 Train loss 0.07 on epoch=89
04/28/2022 06:31:32 - INFO - __main__ - Step 190 Global step 190 Train loss 0.13 on epoch=94
04/28/2022 06:31:34 - INFO - __main__ - Step 200 Global step 200 Train loss 0.03 on epoch=99
04/28/2022 06:31:35 - INFO - __main__ - Global step 200 Train loss 0.09 ACC 0.53125 on epoch=99
04/28/2022 06:31:37 - INFO - __main__ - Step 210 Global step 210 Train loss 0.11 on epoch=104
04/28/2022 06:31:40 - INFO - __main__ - Step 220 Global step 220 Train loss 0.09 on epoch=109
04/28/2022 06:31:42 - INFO - __main__ - Step 230 Global step 230 Train loss 0.12 on epoch=114
04/28/2022 06:31:45 - INFO - __main__ - Step 240 Global step 240 Train loss 0.13 on epoch=119
04/28/2022 06:31:47 - INFO - __main__ - Step 250 Global step 250 Train loss 0.04 on epoch=124
04/28/2022 06:31:48 - INFO - __main__ - Global step 250 Train loss 0.10 ACC 0.53125 on epoch=124
04/28/2022 06:31:50 - INFO - __main__ - Step 260 Global step 260 Train loss 0.07 on epoch=129
04/28/2022 06:31:53 - INFO - __main__ - Step 270 Global step 270 Train loss 0.03 on epoch=134
04/28/2022 06:31:55 - INFO - __main__ - Step 280 Global step 280 Train loss 0.01 on epoch=139
04/28/2022 06:31:58 - INFO - __main__ - Step 290 Global step 290 Train loss 0.05 on epoch=144
04/28/2022 06:32:00 - INFO - __main__ - Step 300 Global step 300 Train loss 0.05 on epoch=149
04/28/2022 06:32:01 - INFO - __main__ - Global step 300 Train loss 0.04 ACC 0.4375 on epoch=149
04/28/2022 06:32:03 - INFO - __main__ - Step 310 Global step 310 Train loss 0.06 on epoch=154
04/28/2022 06:32:06 - INFO - __main__ - Step 320 Global step 320 Train loss 0.03 on epoch=159
04/28/2022 06:32:08 - INFO - __main__ - Step 330 Global step 330 Train loss 0.01 on epoch=164
04/28/2022 06:32:11 - INFO - __main__ - Step 340 Global step 340 Train loss 0.02 on epoch=169
04/28/2022 06:32:13 - INFO - __main__ - Step 350 Global step 350 Train loss 0.01 on epoch=174
04/28/2022 06:32:14 - INFO - __main__ - Global step 350 Train loss 0.03 ACC 0.625 on epoch=174
04/28/2022 06:32:14 - INFO - __main__ - Saving model with best ACC: 0.59375 -> 0.625 on epoch=174, global_step=350
04/28/2022 06:32:16 - INFO - __main__ - Step 360 Global step 360 Train loss 0.01 on epoch=179
04/28/2022 06:32:19 - INFO - __main__ - Step 370 Global step 370 Train loss 0.01 on epoch=184
04/28/2022 06:32:21 - INFO - __main__ - Step 380 Global step 380 Train loss 0.01 on epoch=189
04/28/2022 06:32:24 - INFO - __main__ - Step 390 Global step 390 Train loss 0.05 on epoch=194
04/28/2022 06:32:26 - INFO - __main__ - Step 400 Global step 400 Train loss 0.01 on epoch=199
04/28/2022 06:32:27 - INFO - __main__ - Global step 400 Train loss 0.02 ACC 0.53125 on epoch=199
04/28/2022 06:32:30 - INFO - __main__ - Step 410 Global step 410 Train loss 0.01 on epoch=204
04/28/2022 06:32:32 - INFO - __main__ - Step 420 Global step 420 Train loss 0.02 on epoch=209
04/28/2022 06:32:35 - INFO - __main__ - Step 430 Global step 430 Train loss 0.01 on epoch=214
04/28/2022 06:32:37 - INFO - __main__ - Step 440 Global step 440 Train loss 0.02 on epoch=219
04/28/2022 06:32:39 - INFO - __main__ - Step 450 Global step 450 Train loss 0.00 on epoch=224
04/28/2022 06:32:42 - INFO - __main__ - Global step 450 Train loss 0.01 ACC 0.5625 on epoch=224
04/28/2022 06:32:44 - INFO - __main__ - Step 460 Global step 460 Train loss 0.04 on epoch=229
04/28/2022 06:32:47 - INFO - __main__ - Step 470 Global step 470 Train loss 0.11 on epoch=234
04/28/2022 06:32:49 - INFO - __main__ - Step 480 Global step 480 Train loss 0.01 on epoch=239
04/28/2022 06:32:52 - INFO - __main__ - Step 490 Global step 490 Train loss 0.03 on epoch=244
04/28/2022 06:32:54 - INFO - __main__ - Step 500 Global step 500 Train loss 0.00 on epoch=249
04/28/2022 06:32:55 - INFO - __main__ - Global step 500 Train loss 0.04 ACC 0.5625 on epoch=249
04/28/2022 06:32:58 - INFO - __main__ - Step 510 Global step 510 Train loss 0.01 on epoch=254
04/28/2022 06:33:00 - INFO - __main__ - Step 520 Global step 520 Train loss 0.01 on epoch=259
04/28/2022 06:33:03 - INFO - __main__ - Step 530 Global step 530 Train loss 0.04 on epoch=264
04/28/2022 06:33:05 - INFO - __main__ - Step 540 Global step 540 Train loss 0.06 on epoch=269
04/28/2022 06:33:07 - INFO - __main__ - Step 550 Global step 550 Train loss 0.01 on epoch=274
04/28/2022 06:33:10 - INFO - __main__ - Global step 550 Train loss 0.03 ACC 0.5625 on epoch=274
04/28/2022 06:33:12 - INFO - __main__ - Step 560 Global step 560 Train loss 0.01 on epoch=279
04/28/2022 06:33:15 - INFO - __main__ - Step 570 Global step 570 Train loss 0.03 on epoch=284
04/28/2022 06:33:17 - INFO - __main__ - Step 580 Global step 580 Train loss 0.01 on epoch=289
04/28/2022 06:33:20 - INFO - __main__ - Step 590 Global step 590 Train loss 0.02 on epoch=294
04/28/2022 06:33:22 - INFO - __main__ - Step 600 Global step 600 Train loss 0.02 on epoch=299
04/28/2022 06:33:24 - INFO - __main__ - Global step 600 Train loss 0.02 ACC 0.5 on epoch=299
04/28/2022 06:33:27 - INFO - __main__ - Step 610 Global step 610 Train loss 0.00 on epoch=304
04/28/2022 06:33:29 - INFO - __main__ - Step 620 Global step 620 Train loss 0.01 on epoch=309
04/28/2022 06:33:31 - INFO - __main__ - Step 630 Global step 630 Train loss 0.02 on epoch=314
04/28/2022 06:33:34 - INFO - __main__ - Step 640 Global step 640 Train loss 0.01 on epoch=319
04/28/2022 06:33:36 - INFO - __main__ - Step 650 Global step 650 Train loss 0.03 on epoch=324
04/28/2022 06:33:38 - INFO - __main__ - Global step 650 Train loss 0.01 ACC 0.5 on epoch=324
04/28/2022 06:33:40 - INFO - __main__ - Step 660 Global step 660 Train loss 0.03 on epoch=329
04/28/2022 06:33:42 - INFO - __main__ - Step 670 Global step 670 Train loss 0.01 on epoch=334
04/28/2022 06:33:45 - INFO - __main__ - Step 680 Global step 680 Train loss 0.00 on epoch=339
04/28/2022 06:33:47 - INFO - __main__ - Step 690 Global step 690 Train loss 0.00 on epoch=344
04/28/2022 06:33:50 - INFO - __main__ - Step 700 Global step 700 Train loss 0.00 on epoch=349
04/28/2022 06:33:51 - INFO - __main__ - Global step 700 Train loss 0.01 ACC 0.4375 on epoch=349
04/28/2022 06:33:54 - INFO - __main__ - Step 710 Global step 710 Train loss 0.02 on epoch=354
04/28/2022 06:33:56 - INFO - __main__ - Step 720 Global step 720 Train loss 0.00 on epoch=359
04/28/2022 06:33:59 - INFO - __main__ - Step 730 Global step 730 Train loss 0.02 on epoch=364
04/28/2022 06:34:01 - INFO - __main__ - Step 740 Global step 740 Train loss 0.00 on epoch=369
04/28/2022 06:34:04 - INFO - __main__ - Step 750 Global step 750 Train loss 0.00 on epoch=374
04/28/2022 06:34:05 - INFO - __main__ - Global step 750 Train loss 0.01 ACC 0.5 on epoch=374
04/28/2022 06:34:08 - INFO - __main__ - Step 760 Global step 760 Train loss 0.01 on epoch=379
04/28/2022 06:34:10 - INFO - __main__ - Step 770 Global step 770 Train loss 0.00 on epoch=384
04/28/2022 06:34:13 - INFO - __main__ - Step 780 Global step 780 Train loss 0.00 on epoch=389
04/28/2022 06:34:15 - INFO - __main__ - Step 790 Global step 790 Train loss 0.00 on epoch=394
04/28/2022 06:34:18 - INFO - __main__ - Step 800 Global step 800 Train loss 0.00 on epoch=399
04/28/2022 06:34:19 - INFO - __main__ - Global step 800 Train loss 0.00 ACC 0.5625 on epoch=399
04/28/2022 06:34:22 - INFO - __main__ - Step 810 Global step 810 Train loss 0.02 on epoch=404
04/28/2022 06:34:24 - INFO - __main__ - Step 820 Global step 820 Train loss 0.00 on epoch=409
04/28/2022 06:34:27 - INFO - __main__ - Step 830 Global step 830 Train loss 0.00 on epoch=414
04/28/2022 06:34:29 - INFO - __main__ - Step 840 Global step 840 Train loss 0.04 on epoch=419
04/28/2022 06:34:32 - INFO - __main__ - Step 850 Global step 850 Train loss 0.00 on epoch=424
04/28/2022 06:34:35 - INFO - __main__ - Global step 850 Train loss 0.01 ACC 0.5 on epoch=424
04/28/2022 06:34:37 - INFO - __main__ - Step 860 Global step 860 Train loss 0.01 on epoch=429
04/28/2022 06:34:39 - INFO - __main__ - Step 870 Global step 870 Train loss 0.00 on epoch=434
04/28/2022 06:34:42 - INFO - __main__ - Step 880 Global step 880 Train loss 0.00 on epoch=439
04/28/2022 06:34:44 - INFO - __main__ - Step 890 Global step 890 Train loss 0.00 on epoch=444
04/28/2022 06:34:47 - INFO - __main__ - Step 900 Global step 900 Train loss 0.00 on epoch=449
04/28/2022 06:34:49 - INFO - __main__ - Global step 900 Train loss 0.00 ACC 0.5625 on epoch=449
04/28/2022 06:34:52 - INFO - __main__ - Step 910 Global step 910 Train loss 0.00 on epoch=454
04/28/2022 06:34:54 - INFO - __main__ - Step 920 Global step 920 Train loss 0.00 on epoch=459
04/28/2022 06:34:57 - INFO - __main__ - Step 930 Global step 930 Train loss 0.01 on epoch=464
04/28/2022 06:34:59 - INFO - __main__ - Step 940 Global step 940 Train loss 0.00 on epoch=469
04/28/2022 06:35:02 - INFO - __main__ - Step 950 Global step 950 Train loss 0.00 on epoch=474
04/28/2022 06:35:04 - INFO - __main__ - Global step 950 Train loss 0.00 ACC 0.46875 on epoch=474
04/28/2022 06:35:07 - INFO - __main__ - Step 960 Global step 960 Train loss 0.01 on epoch=479
04/28/2022 06:35:09 - INFO - __main__ - Step 970 Global step 970 Train loss 0.00 on epoch=484
04/28/2022 06:35:12 - INFO - __main__ - Step 980 Global step 980 Train loss 0.01 on epoch=489
04/28/2022 06:35:14 - INFO - __main__ - Step 990 Global step 990 Train loss 0.00 on epoch=494
04/28/2022 06:35:17 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.00 on epoch=499
04/28/2022 06:35:19 - INFO - __main__ - Global step 1000 Train loss 0.00 ACC 0.46875 on epoch=499
04/28/2022 06:35:22 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.04 on epoch=504
04/28/2022 06:35:24 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.00 on epoch=509
04/28/2022 06:35:27 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.01 on epoch=514
04/28/2022 06:35:29 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.02 on epoch=519
04/28/2022 06:35:32 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.00 on epoch=524
04/28/2022 06:35:34 - INFO - __main__ - Global step 1050 Train loss 0.01 ACC 0.46875 on epoch=524
04/28/2022 06:35:36 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.00 on epoch=529
04/28/2022 06:35:39 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.00 on epoch=534
04/28/2022 06:35:41 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.01 on epoch=539
04/28/2022 06:35:44 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.00 on epoch=544
04/28/2022 06:35:46 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.01 on epoch=549
04/28/2022 06:35:48 - INFO - __main__ - Global step 1100 Train loss 0.01 ACC 0.4375 on epoch=549
04/28/2022 06:35:51 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.00 on epoch=554
04/28/2022 06:35:53 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.07 on epoch=559
04/28/2022 06:35:56 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.00 on epoch=564
04/28/2022 06:35:58 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.02 on epoch=569
04/28/2022 06:36:01 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=574
04/28/2022 06:36:02 - INFO - __main__ - Global step 1150 Train loss 0.02 ACC 0.625 on epoch=574
04/28/2022 06:36:05 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.00 on epoch=579
04/28/2022 06:36:07 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.00 on epoch=584
04/28/2022 06:36:10 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.00 on epoch=589
04/28/2022 06:36:12 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.00 on epoch=594
04/28/2022 06:36:14 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.00 on epoch=599
04/28/2022 06:36:17 - INFO - __main__ - Global step 1200 Train loss 0.00 ACC 0.5625 on epoch=599
04/28/2022 06:36:19 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.00 on epoch=604
04/28/2022 06:36:22 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=609
04/28/2022 06:36:24 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.00 on epoch=614
04/28/2022 06:36:27 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.00 on epoch=619
04/28/2022 06:36:29 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.06 on epoch=624
04/28/2022 06:36:31 - INFO - __main__ - Global step 1250 Train loss 0.01 ACC 0.5625 on epoch=624
04/28/2022 06:36:33 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.00 on epoch=629
04/28/2022 06:36:35 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.00 on epoch=634
04/28/2022 06:36:38 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.00 on epoch=639
04/28/2022 06:36:40 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.00 on epoch=644
04/28/2022 06:36:43 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.00 on epoch=649
04/28/2022 06:36:44 - INFO - __main__ - Global step 1300 Train loss 0.00 ACC 0.53125 on epoch=649
04/28/2022 06:36:47 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.00 on epoch=654
04/28/2022 06:36:49 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.00 on epoch=659
04/28/2022 06:36:52 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.00 on epoch=664
04/28/2022 06:36:54 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=669
04/28/2022 06:36:56 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=674
04/28/2022 06:36:59 - INFO - __main__ - Global step 1350 Train loss 0.00 ACC 0.5625 on epoch=674
04/28/2022 06:37:01 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.00 on epoch=679
04/28/2022 06:37:04 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.00 on epoch=684
04/28/2022 06:37:06 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=689
04/28/2022 06:37:09 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.00 on epoch=694
04/28/2022 06:37:11 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.00 on epoch=699
04/28/2022 06:37:13 - INFO - __main__ - Global step 1400 Train loss 0.00 ACC 0.59375 on epoch=699
04/28/2022 06:37:16 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=704
04/28/2022 06:37:18 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=709
04/28/2022 06:37:21 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.00 on epoch=714
04/28/2022 06:37:23 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=719
04/28/2022 06:37:26 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=724
04/28/2022 06:37:28 - INFO - __main__ - Global step 1450 Train loss 0.00 ACC 0.59375 on epoch=724
04/28/2022 06:37:30 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=729
04/28/2022 06:37:33 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=734
04/28/2022 06:37:35 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=739
04/28/2022 06:37:38 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=744
04/28/2022 06:37:40 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=749
04/28/2022 06:37:42 - INFO - __main__ - Global step 1500 Train loss 0.00 ACC 0.5625 on epoch=749
04/28/2022 06:37:45 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=754
04/28/2022 06:37:47 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=759
04/28/2022 06:37:50 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=764
04/28/2022 06:37:52 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=769
04/28/2022 06:37:55 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=774
04/28/2022 06:37:57 - INFO - __main__ - Global step 1550 Train loss 0.01 ACC 0.5625 on epoch=774
04/28/2022 06:38:00 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=779
04/28/2022 06:38:02 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.06 on epoch=784
04/28/2022 06:38:05 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=789
04/28/2022 06:38:07 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=794
04/28/2022 06:38:09 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=799
04/28/2022 06:38:11 - INFO - __main__ - Global step 1600 Train loss 0.02 ACC 0.53125 on epoch=799
04/28/2022 06:38:13 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=804
04/28/2022 06:38:16 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.02 on epoch=809
04/28/2022 06:38:18 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=814
04/28/2022 06:38:21 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=819
04/28/2022 06:38:23 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=824
04/28/2022 06:38:25 - INFO - __main__ - Global step 1650 Train loss 0.01 ACC 0.53125 on epoch=824
04/28/2022 06:38:27 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=829
04/28/2022 06:38:30 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=834
04/28/2022 06:38:32 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=839
04/28/2022 06:38:35 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=844
04/28/2022 06:38:38 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=849
04/28/2022 06:38:40 - INFO - __main__ - Global step 1700 Train loss 0.00 ACC 0.5625 on epoch=849
04/28/2022 06:38:42 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=854
04/28/2022 06:38:45 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=859
04/28/2022 06:38:48 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=864
04/28/2022 06:38:50 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=869
04/28/2022 06:38:53 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=874
04/28/2022 06:38:55 - INFO - __main__ - Global step 1750 Train loss 0.00 ACC 0.5625 on epoch=874
04/28/2022 06:38:57 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=879
04/28/2022 06:39:00 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=884
04/28/2022 06:39:02 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=889
04/28/2022 06:39:05 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=894
04/28/2022 06:39:07 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=899
04/28/2022 06:39:08 - INFO - __main__ - Global step 1800 Train loss 0.00 ACC 0.5625 on epoch=899
04/28/2022 06:39:11 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=904
04/28/2022 06:39:13 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=909
04/28/2022 06:39:16 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=914
04/28/2022 06:39:18 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=919
04/28/2022 06:39:21 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=924
04/28/2022 06:39:22 - INFO - __main__ - Global step 1850 Train loss 0.00 ACC 0.625 on epoch=924
04/28/2022 06:39:24 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=929
04/28/2022 06:39:27 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=934
04/28/2022 06:39:29 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=939
04/28/2022 06:39:32 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=944
04/28/2022 06:39:34 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=949
04/28/2022 06:39:35 - INFO - __main__ - Global step 1900 Train loss 0.00 ACC 0.625 on epoch=949
04/28/2022 06:39:38 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=954
04/28/2022 06:39:40 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=959
04/28/2022 06:39:42 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=964
04/28/2022 06:39:45 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=969
04/28/2022 06:39:47 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=974
04/28/2022 06:39:49 - INFO - __main__ - Global step 1950 Train loss 0.01 ACC 0.625 on epoch=974
04/28/2022 06:39:51 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=979
04/28/2022 06:39:54 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=984
04/28/2022 06:39:56 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=989
04/28/2022 06:39:59 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=994
04/28/2022 06:40:01 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=999
04/28/2022 06:40:02 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 06:40:02 - INFO - __main__ - Printing 3 examples
04/28/2022 06:40:02 - INFO - __main__ -  [wino_grande] Adam appointed Neil as the head guard, because _ trained so hard that he became the best of the best. (A) Adam (B) Neil
04/28/2022 06:40:02 - INFO - __main__ - ['Neil']
04/28/2022 06:40:02 - INFO - __main__ -  [wino_grande] Victoria was a more freaked out individual than Natalie, so _ became paranoid more easily. (A) Victoria (B) Natalie
04/28/2022 06:40:02 - INFO - __main__ - ['Victoria']
04/28/2022 06:40:02 - INFO - __main__ -  [wino_grande] Joseph thought Craig was turning into a homebody because _ would not get out of the house. (A) Joseph (B) Craig
04/28/2022 06:40:02 - INFO - __main__ - ['Craig']
04/28/2022 06:40:02 - INFO - __main__ - Tokenizing Input ...
04/28/2022 06:40:02 - INFO - __main__ - Tokenizing Output ...
04/28/2022 06:40:03 - INFO - __main__ - Loaded 32 examples from train data
04/28/2022 06:40:03 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 06:40:03 - INFO - __main__ - Printing 3 examples
04/28/2022 06:40:03 - INFO - __main__ -  [wino_grande] Donald ran as fast as a snail unlike Kevin who ran faster, because _ had an injury. (A) Donald (B) Kevin
04/28/2022 06:40:03 - INFO - __main__ - ['Donald']
04/28/2022 06:40:03 - INFO - __main__ -  [wino_grande] He tried to put the pacifier into their baby's mouth, but struggled because the _ was too tiny. (A) pacifier (B) mouth
04/28/2022 06:40:03 - INFO - __main__ - ['mouth']
04/28/2022 06:40:03 - INFO - __main__ -  [wino_grande] Meg was in a hurry so while parking and getting out of her car she accidentally left her phone inside as the _ was more pressing. (A) phone (B) car
04/28/2022 06:40:03 - INFO - __main__ - ['car']
04/28/2022 06:40:03 - INFO - __main__ - Tokenizing Input ...
04/28/2022 06:40:03 - INFO - __main__ - Tokenizing Output ...
04/28/2022 06:40:03 - INFO - __main__ - Loaded 32 examples from dev data
04/28/2022 06:40:03 - INFO - __main__ - Global step 2000 Train loss 0.00 ACC 0.59375 on epoch=999
04/28/2022 06:40:03 - INFO - __main__ - save last model!
04/28/2022 06:40:03 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
04/28/2022 06:40:03 - INFO - __main__ - Start tokenizing ... 1000 instances
04/28/2022 06:40:03 - INFO - __main__ - Printing 3 examples
04/28/2022 06:40:03 - INFO - __main__ -  [wino_grande] Sarah was a much better surgeon than Maria so _ always got the easier cases. (A) Sarah (B) Maria
04/28/2022 06:40:03 - INFO - __main__ - ['Maria']
04/28/2022 06:40:03 - INFO - __main__ -  [wino_grande] Sarah was a much better surgeon than Maria so _ always got the harder cases. (A) Sarah (B) Maria
04/28/2022 06:40:03 - INFO - __main__ - ['Sarah']
04/28/2022 06:40:03 - INFO - __main__ -  [wino_grande] They were worried the wine would ruin the bed and the blanket, but the _ was't ruined. (A) blanket (B) bed
04/28/2022 06:40:03 - INFO - __main__ - ['bed']
04/28/2022 06:40:03 - INFO - __main__ - Tokenizing Input ...
04/28/2022 06:40:03 - INFO - __main__ - Tokenizing Output ...
04/28/2022 06:40:04 - INFO - __main__ - Loaded 1000 examples from test data
04/28/2022 06:40:21 - INFO - __main__ - load prompt embedding from ckpt
04/28/2022 06:40:22 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/28/2022 06:40:22 - INFO - __main__ - Starting training!
04/28/2022 06:40:44 - INFO - __main__ - Saved prediction in models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-wino_grande/wino_grande_32_21_0.5_8_predictions.txt
04/28/2022 06:40:44 - INFO - __main__ - ACC on test data: 0.4940
04/28/2022 06:40:44 - INFO - __main__ - prefix=wino_grande_32_21, lr=0.5, bsz=8, dev_performance=0.625, test_performance=0.494
04/28/2022 06:40:44 - INFO - __main__ - Running ... prefix=wino_grande_32_21, lr=0.4, bsz=8 ...
04/28/2022 06:40:45 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 06:40:45 - INFO - __main__ - Printing 3 examples
04/28/2022 06:40:45 - INFO - __main__ -  [wino_grande] Adam appointed Neil as the head guard, because _ trained so hard that he became the best of the best. (A) Adam (B) Neil
04/28/2022 06:40:45 - INFO - __main__ - ['Neil']
04/28/2022 06:40:45 - INFO - __main__ -  [wino_grande] Victoria was a more freaked out individual than Natalie, so _ became paranoid more easily. (A) Victoria (B) Natalie
04/28/2022 06:40:45 - INFO - __main__ - ['Victoria']
04/28/2022 06:40:45 - INFO - __main__ -  [wino_grande] Joseph thought Craig was turning into a homebody because _ would not get out of the house. (A) Joseph (B) Craig
04/28/2022 06:40:45 - INFO - __main__ - ['Craig']
04/28/2022 06:40:45 - INFO - __main__ - Tokenizing Input ...
04/28/2022 06:40:45 - INFO - __main__ - Tokenizing Output ...
04/28/2022 06:40:45 - INFO - __main__ - Loaded 32 examples from train data
04/28/2022 06:40:45 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 06:40:45 - INFO - __main__ - Printing 3 examples
04/28/2022 06:40:45 - INFO - __main__ -  [wino_grande] Donald ran as fast as a snail unlike Kevin who ran faster, because _ had an injury. (A) Donald (B) Kevin
04/28/2022 06:40:45 - INFO - __main__ - ['Donald']
04/28/2022 06:40:45 - INFO - __main__ -  [wino_grande] He tried to put the pacifier into their baby's mouth, but struggled because the _ was too tiny. (A) pacifier (B) mouth
04/28/2022 06:40:45 - INFO - __main__ - ['mouth']
04/28/2022 06:40:45 - INFO - __main__ -  [wino_grande] Meg was in a hurry so while parking and getting out of her car she accidentally left her phone inside as the _ was more pressing. (A) phone (B) car
04/28/2022 06:40:45 - INFO - __main__ - ['car']
04/28/2022 06:40:45 - INFO - __main__ - Tokenizing Input ...
04/28/2022 06:40:45 - INFO - __main__ - Tokenizing Output ...
04/28/2022 06:40:45 - INFO - __main__ - Loaded 32 examples from dev data
04/28/2022 06:41:04 - INFO - __main__ - load prompt embedding from ckpt
04/28/2022 06:41:04 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/28/2022 06:41:04 - INFO - __main__ - Starting training!
04/28/2022 06:41:07 - INFO - __main__ - Step 10 Global step 10 Train loss 3.63 on epoch=4
04/28/2022 06:41:10 - INFO - __main__ - Step 20 Global step 20 Train loss 1.07 on epoch=9
04/28/2022 06:41:12 - INFO - __main__ - Step 30 Global step 30 Train loss 0.54 on epoch=14
04/28/2022 06:41:15 - INFO - __main__ - Step 40 Global step 40 Train loss 0.44 on epoch=19
04/28/2022 06:41:17 - INFO - __main__ - Step 50 Global step 50 Train loss 0.38 on epoch=24
04/28/2022 06:41:18 - INFO - __main__ - Global step 50 Train loss 1.21 ACC 0.625 on epoch=24
04/28/2022 06:41:18 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.625 on epoch=24, global_step=50
04/28/2022 06:41:20 - INFO - __main__ - Step 60 Global step 60 Train loss 0.27 on epoch=29
04/28/2022 06:41:23 - INFO - __main__ - Step 70 Global step 70 Train loss 0.38 on epoch=34
04/28/2022 06:41:25 - INFO - __main__ - Step 80 Global step 80 Train loss 0.29 on epoch=39
04/28/2022 06:41:28 - INFO - __main__ - Step 90 Global step 90 Train loss 0.29 on epoch=44
04/28/2022 06:41:30 - INFO - __main__ - Step 100 Global step 100 Train loss 0.24 on epoch=49
04/28/2022 06:41:31 - INFO - __main__ - Global step 100 Train loss 0.29 ACC 0.5 on epoch=49
04/28/2022 06:41:34 - INFO - __main__ - Step 110 Global step 110 Train loss 0.21 on epoch=54
04/28/2022 06:41:36 - INFO - __main__ - Step 120 Global step 120 Train loss 0.27 on epoch=59
04/28/2022 06:41:38 - INFO - __main__ - Step 130 Global step 130 Train loss 0.17 on epoch=64
04/28/2022 06:41:41 - INFO - __main__ - Step 140 Global step 140 Train loss 0.16 on epoch=69
04/28/2022 06:41:43 - INFO - __main__ - Step 150 Global step 150 Train loss 0.12 on epoch=74
04/28/2022 06:41:44 - INFO - __main__ - Global step 150 Train loss 0.19 ACC 0.46875 on epoch=74
04/28/2022 06:41:46 - INFO - __main__ - Step 160 Global step 160 Train loss 0.11 on epoch=79
04/28/2022 06:41:49 - INFO - __main__ - Step 170 Global step 170 Train loss 0.11 on epoch=84
04/28/2022 06:41:51 - INFO - __main__ - Step 180 Global step 180 Train loss 0.13 on epoch=89
04/28/2022 06:41:54 - INFO - __main__ - Step 190 Global step 190 Train loss 0.14 on epoch=94
04/28/2022 06:41:56 - INFO - __main__ - Step 200 Global step 200 Train loss 0.12 on epoch=99
04/28/2022 06:41:57 - INFO - __main__ - Global step 200 Train loss 0.12 ACC 0.53125 on epoch=99
04/28/2022 06:42:00 - INFO - __main__ - Step 210 Global step 210 Train loss 0.02 on epoch=104
04/28/2022 06:42:02 - INFO - __main__ - Step 220 Global step 220 Train loss 0.20 on epoch=109
04/28/2022 06:42:05 - INFO - __main__ - Step 230 Global step 230 Train loss 0.09 on epoch=114
04/28/2022 06:42:07 - INFO - __main__ - Step 240 Global step 240 Train loss 0.04 on epoch=119
04/28/2022 06:42:10 - INFO - __main__ - Step 250 Global step 250 Train loss 0.09 on epoch=124
04/28/2022 06:42:10 - INFO - __main__ - Global step 250 Train loss 0.09 ACC 0.53125 on epoch=124
04/28/2022 06:42:13 - INFO - __main__ - Step 260 Global step 260 Train loss 0.05 on epoch=129
04/28/2022 06:42:15 - INFO - __main__ - Step 270 Global step 270 Train loss 0.06 on epoch=134
04/28/2022 06:42:18 - INFO - __main__ - Step 280 Global step 280 Train loss 0.04 on epoch=139
04/28/2022 06:42:20 - INFO - __main__ - Step 290 Global step 290 Train loss 0.06 on epoch=144
04/28/2022 06:42:23 - INFO - __main__ - Step 300 Global step 300 Train loss 0.02 on epoch=149
04/28/2022 06:42:24 - INFO - __main__ - Global step 300 Train loss 0.05 ACC 0.53125 on epoch=149
04/28/2022 06:42:26 - INFO - __main__ - Step 310 Global step 310 Train loss 0.04 on epoch=154
04/28/2022 06:42:28 - INFO - __main__ - Step 320 Global step 320 Train loss 0.08 on epoch=159
04/28/2022 06:42:31 - INFO - __main__ - Step 330 Global step 330 Train loss 0.03 on epoch=164
04/28/2022 06:42:33 - INFO - __main__ - Step 340 Global step 340 Train loss 0.02 on epoch=169
04/28/2022 06:42:36 - INFO - __main__ - Step 350 Global step 350 Train loss 0.11 on epoch=174
04/28/2022 06:42:37 - INFO - __main__ - Global step 350 Train loss 0.06 ACC 0.5 on epoch=174
04/28/2022 06:42:39 - INFO - __main__ - Step 360 Global step 360 Train loss 0.03 on epoch=179
04/28/2022 06:42:42 - INFO - __main__ - Step 370 Global step 370 Train loss 0.05 on epoch=184
04/28/2022 06:42:44 - INFO - __main__ - Step 380 Global step 380 Train loss 0.01 on epoch=189
04/28/2022 06:42:47 - INFO - __main__ - Step 390 Global step 390 Train loss 0.04 on epoch=194
04/28/2022 06:42:49 - INFO - __main__ - Step 400 Global step 400 Train loss 0.01 on epoch=199
04/28/2022 06:42:50 - INFO - __main__ - Global step 400 Train loss 0.03 ACC 0.4375 on epoch=199
04/28/2022 06:42:52 - INFO - __main__ - Step 410 Global step 410 Train loss 0.02 on epoch=204
04/28/2022 06:42:55 - INFO - __main__ - Step 420 Global step 420 Train loss 0.01 on epoch=209
04/28/2022 06:42:57 - INFO - __main__ - Step 430 Global step 430 Train loss 0.08 on epoch=214
04/28/2022 06:43:00 - INFO - __main__ - Step 440 Global step 440 Train loss 0.02 on epoch=219
04/28/2022 06:43:02 - INFO - __main__ - Step 450 Global step 450 Train loss 0.02 on epoch=224
04/28/2022 06:43:03 - INFO - __main__ - Global step 450 Train loss 0.03 ACC 0.53125 on epoch=224
04/28/2022 06:43:06 - INFO - __main__ - Step 460 Global step 460 Train loss 0.06 on epoch=229
04/28/2022 06:43:08 - INFO - __main__ - Step 470 Global step 470 Train loss 0.02 on epoch=234
04/28/2022 06:43:11 - INFO - __main__ - Step 480 Global step 480 Train loss 0.01 on epoch=239
04/28/2022 06:43:13 - INFO - __main__ - Step 490 Global step 490 Train loss 0.01 on epoch=244
04/28/2022 06:43:16 - INFO - __main__ - Step 500 Global step 500 Train loss 0.02 on epoch=249
04/28/2022 06:43:16 - INFO - __main__ - Global step 500 Train loss 0.02 ACC 0.5 on epoch=249
04/28/2022 06:43:19 - INFO - __main__ - Step 510 Global step 510 Train loss 0.01 on epoch=254
04/28/2022 06:43:21 - INFO - __main__ - Step 520 Global step 520 Train loss 0.01 on epoch=259
04/28/2022 06:43:24 - INFO - __main__ - Step 530 Global step 530 Train loss 0.02 on epoch=264
04/28/2022 06:43:26 - INFO - __main__ - Step 540 Global step 540 Train loss 0.03 on epoch=269
04/28/2022 06:43:29 - INFO - __main__ - Step 550 Global step 550 Train loss 0.07 on epoch=274
04/28/2022 06:43:29 - INFO - __main__ - Global step 550 Train loss 0.03 ACC 0.46875 on epoch=274
04/28/2022 06:43:32 - INFO - __main__ - Step 560 Global step 560 Train loss 0.01 on epoch=279
04/28/2022 06:43:34 - INFO - __main__ - Step 570 Global step 570 Train loss 0.02 on epoch=284
04/28/2022 06:43:37 - INFO - __main__ - Step 580 Global step 580 Train loss 0.00 on epoch=289
04/28/2022 06:43:39 - INFO - __main__ - Step 590 Global step 590 Train loss 0.01 on epoch=294
04/28/2022 06:43:42 - INFO - __main__ - Step 600 Global step 600 Train loss 0.00 on epoch=299
04/28/2022 06:43:43 - INFO - __main__ - Global step 600 Train loss 0.01 ACC 0.5 on epoch=299
04/28/2022 06:43:45 - INFO - __main__ - Step 610 Global step 610 Train loss 0.02 on epoch=304
04/28/2022 06:43:48 - INFO - __main__ - Step 620 Global step 620 Train loss 0.00 on epoch=309
04/28/2022 06:43:50 - INFO - __main__ - Step 630 Global step 630 Train loss 0.05 on epoch=314
04/28/2022 06:43:53 - INFO - __main__ - Step 640 Global step 640 Train loss 0.01 on epoch=319
04/28/2022 06:43:55 - INFO - __main__ - Step 650 Global step 650 Train loss 0.03 on epoch=324
04/28/2022 06:43:56 - INFO - __main__ - Global step 650 Train loss 0.02 ACC 0.5 on epoch=324
04/28/2022 06:43:59 - INFO - __main__ - Step 660 Global step 660 Train loss 0.03 on epoch=329
04/28/2022 06:44:01 - INFO - __main__ - Step 670 Global step 670 Train loss 0.01 on epoch=334
04/28/2022 06:44:04 - INFO - __main__ - Step 680 Global step 680 Train loss 0.01 on epoch=339
04/28/2022 06:44:06 - INFO - __main__ - Step 690 Global step 690 Train loss 0.00 on epoch=344
04/28/2022 06:44:09 - INFO - __main__ - Step 700 Global step 700 Train loss 0.01 on epoch=349
04/28/2022 06:44:10 - INFO - __main__ - Global step 700 Train loss 0.01 ACC 0.53125 on epoch=349
04/28/2022 06:44:12 - INFO - __main__ - Step 710 Global step 710 Train loss 0.02 on epoch=354
04/28/2022 06:44:15 - INFO - __main__ - Step 720 Global step 720 Train loss 0.00 on epoch=359
04/28/2022 06:44:17 - INFO - __main__ - Step 730 Global step 730 Train loss 0.03 on epoch=364
04/28/2022 06:44:20 - INFO - __main__ - Step 740 Global step 740 Train loss 0.01 on epoch=369
04/28/2022 06:44:22 - INFO - __main__ - Step 750 Global step 750 Train loss 0.01 on epoch=374
04/28/2022 06:44:23 - INFO - __main__ - Global step 750 Train loss 0.02 ACC 0.53125 on epoch=374
04/28/2022 06:44:26 - INFO - __main__ - Step 760 Global step 760 Train loss 0.00 on epoch=379
04/28/2022 06:44:28 - INFO - __main__ - Step 770 Global step 770 Train loss 0.01 on epoch=384
04/28/2022 06:44:30 - INFO - __main__ - Step 780 Global step 780 Train loss 0.01 on epoch=389
04/28/2022 06:44:33 - INFO - __main__ - Step 790 Global step 790 Train loss 0.01 on epoch=394
04/28/2022 06:44:35 - INFO - __main__ - Step 800 Global step 800 Train loss 0.01 on epoch=399
04/28/2022 06:44:37 - INFO - __main__ - Global step 800 Train loss 0.01 ACC 0.53125 on epoch=399
04/28/2022 06:44:39 - INFO - __main__ - Step 810 Global step 810 Train loss 0.00 on epoch=404
04/28/2022 06:44:41 - INFO - __main__ - Step 820 Global step 820 Train loss 0.00 on epoch=409
04/28/2022 06:44:44 - INFO - __main__ - Step 830 Global step 830 Train loss 0.07 on epoch=414
04/28/2022 06:44:46 - INFO - __main__ - Step 840 Global step 840 Train loss 0.02 on epoch=419
04/28/2022 06:44:49 - INFO - __main__ - Step 850 Global step 850 Train loss 0.00 on epoch=424
04/28/2022 06:44:50 - INFO - __main__ - Global step 850 Train loss 0.02 ACC 0.5 on epoch=424
04/28/2022 06:44:53 - INFO - __main__ - Step 860 Global step 860 Train loss 0.00 on epoch=429
04/28/2022 06:44:55 - INFO - __main__ - Step 870 Global step 870 Train loss 0.00 on epoch=434
04/28/2022 06:44:57 - INFO - __main__ - Step 880 Global step 880 Train loss 0.01 on epoch=439
04/28/2022 06:45:00 - INFO - __main__ - Step 890 Global step 890 Train loss 0.00 on epoch=444
04/28/2022 06:45:02 - INFO - __main__ - Step 900 Global step 900 Train loss 0.02 on epoch=449
04/28/2022 06:45:03 - INFO - __main__ - Global step 900 Train loss 0.01 ACC 0.5 on epoch=449
04/28/2022 06:45:06 - INFO - __main__ - Step 910 Global step 910 Train loss 0.00 on epoch=454
04/28/2022 06:45:08 - INFO - __main__ - Step 920 Global step 920 Train loss 0.00 on epoch=459
04/28/2022 06:45:11 - INFO - __main__ - Step 930 Global step 930 Train loss 0.00 on epoch=464
04/28/2022 06:45:13 - INFO - __main__ - Step 940 Global step 940 Train loss 0.00 on epoch=469
04/28/2022 06:45:16 - INFO - __main__ - Step 950 Global step 950 Train loss 0.01 on epoch=474
04/28/2022 06:45:17 - INFO - __main__ - Global step 950 Train loss 0.00 ACC 0.5 on epoch=474
04/28/2022 06:45:20 - INFO - __main__ - Step 960 Global step 960 Train loss 0.00 on epoch=479
04/28/2022 06:45:22 - INFO - __main__ - Step 970 Global step 970 Train loss 0.00 on epoch=484
04/28/2022 06:45:25 - INFO - __main__ - Step 980 Global step 980 Train loss 0.00 on epoch=489
04/28/2022 06:45:27 - INFO - __main__ - Step 990 Global step 990 Train loss 0.01 on epoch=494
04/28/2022 06:45:29 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.00 on epoch=499
04/28/2022 06:45:31 - INFO - __main__ - Global step 1000 Train loss 0.00 ACC 0.53125 on epoch=499
04/28/2022 06:45:33 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.06 on epoch=504
04/28/2022 06:45:36 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.00 on epoch=509
04/28/2022 06:45:38 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.00 on epoch=514
04/28/2022 06:45:40 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.00 on epoch=519
04/28/2022 06:45:43 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.02 on epoch=524
04/28/2022 06:45:44 - INFO - __main__ - Global step 1050 Train loss 0.02 ACC 0.5 on epoch=524
04/28/2022 06:45:47 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.00 on epoch=529
04/28/2022 06:45:49 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.00 on epoch=534
04/28/2022 06:45:52 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.00 on epoch=539
04/28/2022 06:45:54 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.00 on epoch=544
04/28/2022 06:45:57 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.00 on epoch=549
04/28/2022 06:45:58 - INFO - __main__ - Global step 1100 Train loss 0.00 ACC 0.5 on epoch=549
04/28/2022 06:46:00 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.00 on epoch=554
04/28/2022 06:46:03 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.00 on epoch=559
04/28/2022 06:46:05 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=564
04/28/2022 06:46:08 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.01 on epoch=569
04/28/2022 06:46:10 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.04 on epoch=574
04/28/2022 06:46:11 - INFO - __main__ - Global step 1150 Train loss 0.01 ACC 0.5625 on epoch=574
04/28/2022 06:46:13 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.04 on epoch=579
04/28/2022 06:46:16 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.00 on epoch=584
04/28/2022 06:46:18 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.00 on epoch=589
04/28/2022 06:46:21 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.00 on epoch=594
04/28/2022 06:46:23 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.00 on epoch=599
04/28/2022 06:46:25 - INFO - __main__ - Global step 1200 Train loss 0.01 ACC 0.53125 on epoch=599
04/28/2022 06:46:28 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.00 on epoch=604
04/28/2022 06:46:30 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.00 on epoch=609
04/28/2022 06:46:33 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.00 on epoch=614
04/28/2022 06:46:35 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=619
04/28/2022 06:46:38 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.01 on epoch=624
04/28/2022 06:46:39 - INFO - __main__ - Global step 1250 Train loss 0.00 ACC 0.53125 on epoch=624
04/28/2022 06:46:41 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.00 on epoch=629
04/28/2022 06:46:44 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.00 on epoch=634
04/28/2022 06:46:46 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.00 on epoch=639
04/28/2022 06:46:49 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.00 on epoch=644
04/28/2022 06:46:51 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.00 on epoch=649
04/28/2022 06:46:52 - INFO - __main__ - Global step 1300 Train loss 0.00 ACC 0.5625 on epoch=649
04/28/2022 06:46:55 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.00 on epoch=654
04/28/2022 06:46:57 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.00 on epoch=659
04/28/2022 06:47:00 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.05 on epoch=664
04/28/2022 06:47:02 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.03 on epoch=669
04/28/2022 06:47:05 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.00 on epoch=674
04/28/2022 06:47:06 - INFO - __main__ - Global step 1350 Train loss 0.01 ACC 0.5 on epoch=674
04/28/2022 06:47:08 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.00 on epoch=679
04/28/2022 06:47:11 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.00 on epoch=684
04/28/2022 06:47:13 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.00 on epoch=689
04/28/2022 06:47:16 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=694
04/28/2022 06:47:18 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.00 on epoch=699
04/28/2022 06:47:21 - INFO - __main__ - Global step 1400 Train loss 0.00 ACC 0.53125 on epoch=699
04/28/2022 06:47:23 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=704
04/28/2022 06:47:26 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=709
04/28/2022 06:47:28 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.00 on epoch=714
04/28/2022 06:47:31 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=719
04/28/2022 06:47:33 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=724
04/28/2022 06:47:35 - INFO - __main__ - Global step 1450 Train loss 0.00 ACC 0.53125 on epoch=724
04/28/2022 06:47:37 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=729
04/28/2022 06:47:40 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=734
04/28/2022 06:47:42 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=739
04/28/2022 06:47:45 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=744
04/28/2022 06:47:47 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=749
04/28/2022 06:47:49 - INFO - __main__ - Global step 1500 Train loss 0.00 ACC 0.53125 on epoch=749
04/28/2022 06:47:52 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.04 on epoch=754
04/28/2022 06:47:54 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=759
04/28/2022 06:47:56 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=764
04/28/2022 06:47:59 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=769
04/28/2022 06:48:01 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=774
04/28/2022 06:48:04 - INFO - __main__ - Global step 1550 Train loss 0.01 ACC 0.53125 on epoch=774
04/28/2022 06:48:07 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=779
04/28/2022 06:48:09 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=784
04/28/2022 06:48:12 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.03 on epoch=789
04/28/2022 06:48:14 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=794
04/28/2022 06:48:17 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=799
04/28/2022 06:48:19 - INFO - __main__ - Global step 1600 Train loss 0.01 ACC 0.5 on epoch=799
04/28/2022 06:48:22 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=804
04/28/2022 06:48:24 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=809
04/28/2022 06:48:27 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=814
04/28/2022 06:48:29 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=819
04/28/2022 06:48:32 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=824
04/28/2022 06:48:35 - INFO - __main__ - Global step 1650 Train loss 0.00 ACC 0.5625 on epoch=824
04/28/2022 06:48:37 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=829
04/28/2022 06:48:40 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=834
04/28/2022 06:48:42 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=839
04/28/2022 06:48:45 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=844
04/28/2022 06:48:47 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=849
04/28/2022 06:48:51 - INFO - __main__ - Global step 1700 Train loss 0.00 ACC 0.59375 on epoch=849
04/28/2022 06:48:53 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=854
04/28/2022 06:48:56 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=859
04/28/2022 06:48:58 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=864
04/28/2022 06:49:01 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=869
04/28/2022 06:49:04 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=874
04/28/2022 06:49:07 - INFO - __main__ - Global step 1750 Train loss 0.00 ACC 0.5625 on epoch=874
04/28/2022 06:49:10 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=879
04/28/2022 06:49:13 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=884
04/28/2022 06:49:15 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=889
04/28/2022 06:49:18 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=894
04/28/2022 06:49:20 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=899
04/28/2022 06:49:22 - INFO - __main__ - Global step 1800 Train loss 0.00 ACC 0.59375 on epoch=899
04/28/2022 06:49:25 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=904
04/28/2022 06:49:27 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=909
04/28/2022 06:49:30 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=914
04/28/2022 06:49:32 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=919
04/28/2022 06:49:35 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.07 on epoch=924
04/28/2022 06:49:36 - INFO - __main__ - Global step 1850 Train loss 0.01 ACC 0.53125 on epoch=924
04/28/2022 06:49:39 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=929
04/28/2022 06:49:41 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=934
04/28/2022 06:49:44 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=939
04/28/2022 06:49:46 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=944
04/28/2022 06:49:49 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=949
04/28/2022 06:49:52 - INFO - __main__ - Global step 1900 Train loss 0.00 ACC 0.53125 on epoch=949
04/28/2022 06:49:54 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=954
04/28/2022 06:49:57 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=959
04/28/2022 06:49:59 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=964
04/28/2022 06:50:02 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=969
04/28/2022 06:50:04 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=974
04/28/2022 06:50:07 - INFO - __main__ - Global step 1950 Train loss 0.00 ACC 0.46875 on epoch=974
04/28/2022 06:50:09 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=979
04/28/2022 06:50:12 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=984
04/28/2022 06:50:14 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=989
04/28/2022 06:50:17 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=994
04/28/2022 06:50:19 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=999
04/28/2022 06:50:21 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 06:50:21 - INFO - __main__ - Printing 3 examples
04/28/2022 06:50:21 - INFO - __main__ -  [wino_grande] Adam appointed Neil as the head guard, because _ trained so hard that he became the best of the best. (A) Adam (B) Neil
04/28/2022 06:50:21 - INFO - __main__ - ['Neil']
04/28/2022 06:50:21 - INFO - __main__ -  [wino_grande] Victoria was a more freaked out individual than Natalie, so _ became paranoid more easily. (A) Victoria (B) Natalie
04/28/2022 06:50:21 - INFO - __main__ - ['Victoria']
04/28/2022 06:50:21 - INFO - __main__ -  [wino_grande] Joseph thought Craig was turning into a homebody because _ would not get out of the house. (A) Joseph (B) Craig
04/28/2022 06:50:21 - INFO - __main__ - ['Craig']
04/28/2022 06:50:21 - INFO - __main__ - Tokenizing Input ...
04/28/2022 06:50:21 - INFO - __main__ - Tokenizing Output ...
04/28/2022 06:50:21 - INFO - __main__ - Loaded 32 examples from train data
04/28/2022 06:50:21 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 06:50:21 - INFO - __main__ - Printing 3 examples
04/28/2022 06:50:21 - INFO - __main__ -  [wino_grande] Donald ran as fast as a snail unlike Kevin who ran faster, because _ had an injury. (A) Donald (B) Kevin
04/28/2022 06:50:21 - INFO - __main__ - ['Donald']
04/28/2022 06:50:21 - INFO - __main__ -  [wino_grande] He tried to put the pacifier into their baby's mouth, but struggled because the _ was too tiny. (A) pacifier (B) mouth
04/28/2022 06:50:21 - INFO - __main__ - ['mouth']
04/28/2022 06:50:21 - INFO - __main__ -  [wino_grande] Meg was in a hurry so while parking and getting out of her car she accidentally left her phone inside as the _ was more pressing. (A) phone (B) car
04/28/2022 06:50:21 - INFO - __main__ - ['car']
04/28/2022 06:50:21 - INFO - __main__ - Tokenizing Input ...
04/28/2022 06:50:22 - INFO - __main__ - Tokenizing Output ...
04/28/2022 06:50:22 - INFO - __main__ - Loaded 32 examples from dev data
04/28/2022 06:50:22 - INFO - __main__ - Global step 2000 Train loss 0.00 ACC 0.53125 on epoch=999
04/28/2022 06:50:22 - INFO - __main__ - save last model!
04/28/2022 06:50:22 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
04/28/2022 06:50:22 - INFO - __main__ - Start tokenizing ... 1000 instances
04/28/2022 06:50:22 - INFO - __main__ - Printing 3 examples
04/28/2022 06:50:22 - INFO - __main__ -  [wino_grande] Sarah was a much better surgeon than Maria so _ always got the easier cases. (A) Sarah (B) Maria
04/28/2022 06:50:22 - INFO - __main__ - ['Maria']
04/28/2022 06:50:22 - INFO - __main__ -  [wino_grande] Sarah was a much better surgeon than Maria so _ always got the harder cases. (A) Sarah (B) Maria
04/28/2022 06:50:22 - INFO - __main__ - ['Sarah']
04/28/2022 06:50:22 - INFO - __main__ -  [wino_grande] They were worried the wine would ruin the bed and the blanket, but the _ was't ruined. (A) blanket (B) bed
04/28/2022 06:50:22 - INFO - __main__ - ['bed']
04/28/2022 06:50:22 - INFO - __main__ - Tokenizing Input ...
04/28/2022 06:50:22 - INFO - __main__ - Tokenizing Output ...
04/28/2022 06:50:23 - INFO - __main__ - Loaded 1000 examples from test data
04/28/2022 06:50:37 - INFO - __main__ - load prompt embedding from ckpt
04/28/2022 06:50:38 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/28/2022 06:50:38 - INFO - __main__ - Starting training!
04/28/2022 06:51:31 - INFO - __main__ - Saved prediction in models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-wino_grande/wino_grande_32_21_0.4_8_predictions.txt
04/28/2022 06:51:31 - INFO - __main__ - ACC on test data: 0.4900
04/28/2022 06:51:32 - INFO - __main__ - prefix=wino_grande_32_21, lr=0.4, bsz=8, dev_performance=0.625, test_performance=0.49
04/28/2022 06:51:32 - INFO - __main__ - Running ... prefix=wino_grande_32_21, lr=0.3, bsz=8 ...
04/28/2022 06:51:33 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 06:51:33 - INFO - __main__ - Printing 3 examples
04/28/2022 06:51:33 - INFO - __main__ -  [wino_grande] Adam appointed Neil as the head guard, because _ trained so hard that he became the best of the best. (A) Adam (B) Neil
04/28/2022 06:51:33 - INFO - __main__ - ['Neil']
04/28/2022 06:51:33 - INFO - __main__ -  [wino_grande] Victoria was a more freaked out individual than Natalie, so _ became paranoid more easily. (A) Victoria (B) Natalie
04/28/2022 06:51:33 - INFO - __main__ - ['Victoria']
04/28/2022 06:51:33 - INFO - __main__ -  [wino_grande] Joseph thought Craig was turning into a homebody because _ would not get out of the house. (A) Joseph (B) Craig
04/28/2022 06:51:33 - INFO - __main__ - ['Craig']
04/28/2022 06:51:33 - INFO - __main__ - Tokenizing Input ...
04/28/2022 06:51:33 - INFO - __main__ - Tokenizing Output ...
04/28/2022 06:51:33 - INFO - __main__ - Loaded 32 examples from train data
04/28/2022 06:51:33 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 06:51:33 - INFO - __main__ - Printing 3 examples
04/28/2022 06:51:33 - INFO - __main__ -  [wino_grande] Donald ran as fast as a snail unlike Kevin who ran faster, because _ had an injury. (A) Donald (B) Kevin
04/28/2022 06:51:33 - INFO - __main__ - ['Donald']
04/28/2022 06:51:33 - INFO - __main__ -  [wino_grande] He tried to put the pacifier into their baby's mouth, but struggled because the _ was too tiny. (A) pacifier (B) mouth
04/28/2022 06:51:33 - INFO - __main__ - ['mouth']
04/28/2022 06:51:33 - INFO - __main__ -  [wino_grande] Meg was in a hurry so while parking and getting out of her car she accidentally left her phone inside as the _ was more pressing. (A) phone (B) car
04/28/2022 06:51:33 - INFO - __main__ - ['car']
04/28/2022 06:51:33 - INFO - __main__ - Tokenizing Input ...
04/28/2022 06:51:33 - INFO - __main__ - Tokenizing Output ...
04/28/2022 06:51:33 - INFO - __main__ - Loaded 32 examples from dev data
04/28/2022 06:51:51 - INFO - __main__ - load prompt embedding from ckpt
04/28/2022 06:51:52 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/28/2022 06:51:52 - INFO - __main__ - Starting training!
04/28/2022 06:51:55 - INFO - __main__ - Step 10 Global step 10 Train loss 4.26 on epoch=4
04/28/2022 06:51:58 - INFO - __main__ - Step 20 Global step 20 Train loss 1.74 on epoch=9
04/28/2022 06:52:00 - INFO - __main__ - Step 30 Global step 30 Train loss 1.04 on epoch=14
04/28/2022 06:52:03 - INFO - __main__ - Step 40 Global step 40 Train loss 0.67 on epoch=19
04/28/2022 06:52:05 - INFO - __main__ - Step 50 Global step 50 Train loss 0.66 on epoch=24
04/28/2022 06:52:06 - INFO - __main__ - Global step 50 Train loss 1.68 ACC 0.6875 on epoch=24
04/28/2022 06:52:06 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.6875 on epoch=24, global_step=50
04/28/2022 06:52:08 - INFO - __main__ - Step 60 Global step 60 Train loss 0.41 on epoch=29
04/28/2022 06:52:11 - INFO - __main__ - Step 70 Global step 70 Train loss 0.47 on epoch=34
04/28/2022 06:52:13 - INFO - __main__ - Step 80 Global step 80 Train loss 0.33 on epoch=39
04/28/2022 06:52:16 - INFO - __main__ - Step 90 Global step 90 Train loss 0.27 on epoch=44
04/28/2022 06:52:18 - INFO - __main__ - Step 100 Global step 100 Train loss 0.26 on epoch=49
04/28/2022 06:52:19 - INFO - __main__ - Global step 100 Train loss 0.35 ACC 0.5625 on epoch=49
04/28/2022 06:52:22 - INFO - __main__ - Step 110 Global step 110 Train loss 0.31 on epoch=54
04/28/2022 06:52:24 - INFO - __main__ - Step 120 Global step 120 Train loss 0.19 on epoch=59
04/28/2022 06:52:27 - INFO - __main__ - Step 130 Global step 130 Train loss 0.17 on epoch=64
04/28/2022 06:52:29 - INFO - __main__ - Step 140 Global step 140 Train loss 0.20 on epoch=69
04/28/2022 06:52:32 - INFO - __main__ - Step 150 Global step 150 Train loss 0.18 on epoch=74
04/28/2022 06:52:32 - INFO - __main__ - Global step 150 Train loss 0.21 ACC 0.53125 on epoch=74
04/28/2022 06:52:35 - INFO - __main__ - Step 160 Global step 160 Train loss 0.14 on epoch=79
04/28/2022 06:52:37 - INFO - __main__ - Step 170 Global step 170 Train loss 0.11 on epoch=84
04/28/2022 06:52:40 - INFO - __main__ - Step 180 Global step 180 Train loss 0.20 on epoch=89
04/28/2022 06:52:42 - INFO - __main__ - Step 190 Global step 190 Train loss 0.06 on epoch=94
04/28/2022 06:52:45 - INFO - __main__ - Step 200 Global step 200 Train loss 0.10 on epoch=99
04/28/2022 06:52:46 - INFO - __main__ - Global step 200 Train loss 0.12 ACC 0.59375 on epoch=99
04/28/2022 06:52:48 - INFO - __main__ - Step 210 Global step 210 Train loss 0.13 on epoch=104
04/28/2022 06:52:51 - INFO - __main__ - Step 220 Global step 220 Train loss 0.14 on epoch=109
04/28/2022 06:52:53 - INFO - __main__ - Step 230 Global step 230 Train loss 0.05 on epoch=114
04/28/2022 06:52:56 - INFO - __main__ - Step 240 Global step 240 Train loss 0.10 on epoch=119
04/28/2022 06:52:58 - INFO - __main__ - Step 250 Global step 250 Train loss 0.08 on epoch=124
04/28/2022 06:52:59 - INFO - __main__ - Global step 250 Train loss 0.10 ACC 0.625 on epoch=124
04/28/2022 06:53:01 - INFO - __main__ - Step 260 Global step 260 Train loss 0.04 on epoch=129
04/28/2022 06:53:04 - INFO - __main__ - Step 270 Global step 270 Train loss 0.07 on epoch=134
04/28/2022 06:53:06 - INFO - __main__ - Step 280 Global step 280 Train loss 0.13 on epoch=139
04/28/2022 06:53:09 - INFO - __main__ - Step 290 Global step 290 Train loss 0.04 on epoch=144
04/28/2022 06:53:11 - INFO - __main__ - Step 300 Global step 300 Train loss 0.05 on epoch=149
04/28/2022 06:53:12 - INFO - __main__ - Global step 300 Train loss 0.06 ACC 0.5625 on epoch=149
04/28/2022 06:53:15 - INFO - __main__ - Step 310 Global step 310 Train loss 0.04 on epoch=154
04/28/2022 06:53:17 - INFO - __main__ - Step 320 Global step 320 Train loss 0.03 on epoch=159
04/28/2022 06:53:20 - INFO - __main__ - Step 330 Global step 330 Train loss 0.06 on epoch=164
04/28/2022 06:53:22 - INFO - __main__ - Step 340 Global step 340 Train loss 0.04 on epoch=169
04/28/2022 06:53:25 - INFO - __main__ - Step 350 Global step 350 Train loss 0.07 on epoch=174
04/28/2022 06:53:25 - INFO - __main__ - Global step 350 Train loss 0.05 ACC 0.5 on epoch=174
04/28/2022 06:53:28 - INFO - __main__ - Step 360 Global step 360 Train loss 0.13 on epoch=179
04/28/2022 06:53:30 - INFO - __main__ - Step 370 Global step 370 Train loss 0.04 on epoch=184
04/28/2022 06:53:33 - INFO - __main__ - Step 380 Global step 380 Train loss 0.03 on epoch=189
04/28/2022 06:53:35 - INFO - __main__ - Step 390 Global step 390 Train loss 0.01 on epoch=194
04/28/2022 06:53:38 - INFO - __main__ - Step 400 Global step 400 Train loss 0.01 on epoch=199
04/28/2022 06:53:39 - INFO - __main__ - Global step 400 Train loss 0.04 ACC 0.625 on epoch=199
04/28/2022 06:53:41 - INFO - __main__ - Step 410 Global step 410 Train loss 0.03 on epoch=204
04/28/2022 06:53:44 - INFO - __main__ - Step 420 Global step 420 Train loss 0.02 on epoch=209
04/28/2022 06:53:46 - INFO - __main__ - Step 430 Global step 430 Train loss 0.03 on epoch=214
04/28/2022 06:53:49 - INFO - __main__ - Step 440 Global step 440 Train loss 0.07 on epoch=219
04/28/2022 06:53:51 - INFO - __main__ - Step 450 Global step 450 Train loss 0.01 on epoch=224
04/28/2022 06:53:52 - INFO - __main__ - Global step 450 Train loss 0.03 ACC 0.5 on epoch=224
04/28/2022 06:53:54 - INFO - __main__ - Step 460 Global step 460 Train loss 0.08 on epoch=229
04/28/2022 06:53:57 - INFO - __main__ - Step 470 Global step 470 Train loss 0.02 on epoch=234
04/28/2022 06:53:59 - INFO - __main__ - Step 480 Global step 480 Train loss 0.07 on epoch=239
04/28/2022 06:54:02 - INFO - __main__ - Step 490 Global step 490 Train loss 0.03 on epoch=244
04/28/2022 06:54:04 - INFO - __main__ - Step 500 Global step 500 Train loss 0.03 on epoch=249
04/28/2022 06:54:05 - INFO - __main__ - Global step 500 Train loss 0.05 ACC 0.5625 on epoch=249
04/28/2022 06:54:08 - INFO - __main__ - Step 510 Global step 510 Train loss 0.01 on epoch=254
04/28/2022 06:54:10 - INFO - __main__ - Step 520 Global step 520 Train loss 0.01 on epoch=259
04/28/2022 06:54:13 - INFO - __main__ - Step 530 Global step 530 Train loss 0.01 on epoch=264
04/28/2022 06:54:15 - INFO - __main__ - Step 540 Global step 540 Train loss 0.06 on epoch=269
04/28/2022 06:54:18 - INFO - __main__ - Step 550 Global step 550 Train loss 0.04 on epoch=274
04/28/2022 06:54:18 - INFO - __main__ - Global step 550 Train loss 0.02 ACC 0.5 on epoch=274
04/28/2022 06:54:21 - INFO - __main__ - Step 560 Global step 560 Train loss 0.01 on epoch=279
04/28/2022 06:54:23 - INFO - __main__ - Step 570 Global step 570 Train loss 0.01 on epoch=284
04/28/2022 06:54:26 - INFO - __main__ - Step 580 Global step 580 Train loss 0.01 on epoch=289
04/28/2022 06:54:28 - INFO - __main__ - Step 590 Global step 590 Train loss 0.02 on epoch=294
04/28/2022 06:54:31 - INFO - __main__ - Step 600 Global step 600 Train loss 0.01 on epoch=299
04/28/2022 06:54:32 - INFO - __main__ - Global step 600 Train loss 0.01 ACC 0.53125 on epoch=299
04/28/2022 06:54:34 - INFO - __main__ - Step 610 Global step 610 Train loss 0.02 on epoch=304
04/28/2022 06:54:37 - INFO - __main__ - Step 620 Global step 620 Train loss 0.03 on epoch=309
04/28/2022 06:54:39 - INFO - __main__ - Step 630 Global step 630 Train loss 0.03 on epoch=314
04/28/2022 06:54:42 - INFO - __main__ - Step 640 Global step 640 Train loss 0.02 on epoch=319
04/28/2022 06:54:44 - INFO - __main__ - Step 650 Global step 650 Train loss 0.04 on epoch=324
04/28/2022 06:54:45 - INFO - __main__ - Global step 650 Train loss 0.03 ACC 0.5625 on epoch=324
04/28/2022 06:54:47 - INFO - __main__ - Step 660 Global step 660 Train loss 0.01 on epoch=329
04/28/2022 06:54:50 - INFO - __main__ - Step 670 Global step 670 Train loss 0.00 on epoch=334
04/28/2022 06:54:52 - INFO - __main__ - Step 680 Global step 680 Train loss 0.00 on epoch=339
04/28/2022 06:54:55 - INFO - __main__ - Step 690 Global step 690 Train loss 0.00 on epoch=344
04/28/2022 06:54:57 - INFO - __main__ - Step 700 Global step 700 Train loss 0.02 on epoch=349
04/28/2022 06:54:58 - INFO - __main__ - Global step 700 Train loss 0.01 ACC 0.5 on epoch=349
04/28/2022 06:55:01 - INFO - __main__ - Step 710 Global step 710 Train loss 0.04 on epoch=354
04/28/2022 06:55:03 - INFO - __main__ - Step 720 Global step 720 Train loss 0.00 on epoch=359
04/28/2022 06:55:06 - INFO - __main__ - Step 730 Global step 730 Train loss 0.01 on epoch=364
04/28/2022 06:55:08 - INFO - __main__ - Step 740 Global step 740 Train loss 0.00 on epoch=369
04/28/2022 06:55:11 - INFO - __main__ - Step 750 Global step 750 Train loss 0.00 on epoch=374
04/28/2022 06:55:11 - INFO - __main__ - Global step 750 Train loss 0.01 ACC 0.53125 on epoch=374
04/28/2022 06:55:14 - INFO - __main__ - Step 760 Global step 760 Train loss 0.01 on epoch=379
04/28/2022 06:55:16 - INFO - __main__ - Step 770 Global step 770 Train loss 0.00 on epoch=384
04/28/2022 06:55:19 - INFO - __main__ - Step 780 Global step 780 Train loss 0.00 on epoch=389
04/28/2022 06:55:21 - INFO - __main__ - Step 790 Global step 790 Train loss 0.00 on epoch=394
04/28/2022 06:55:24 - INFO - __main__ - Step 800 Global step 800 Train loss 0.04 on epoch=399
04/28/2022 06:55:26 - INFO - __main__ - Global step 800 Train loss 0.01 ACC 0.53125 on epoch=399
04/28/2022 06:55:28 - INFO - __main__ - Step 810 Global step 810 Train loss 0.01 on epoch=404
04/28/2022 06:55:31 - INFO - __main__ - Step 820 Global step 820 Train loss 0.03 on epoch=409
04/28/2022 06:55:33 - INFO - __main__ - Step 830 Global step 830 Train loss 0.01 on epoch=414
04/28/2022 06:55:36 - INFO - __main__ - Step 840 Global step 840 Train loss 0.01 on epoch=419
04/28/2022 06:55:38 - INFO - __main__ - Step 850 Global step 850 Train loss 0.03 on epoch=424
04/28/2022 06:55:39 - INFO - __main__ - Global step 850 Train loss 0.02 ACC 0.59375 on epoch=424
04/28/2022 06:55:41 - INFO - __main__ - Step 860 Global step 860 Train loss 0.00 on epoch=429
04/28/2022 06:55:44 - INFO - __main__ - Step 870 Global step 870 Train loss 0.02 on epoch=434
04/28/2022 06:55:46 - INFO - __main__ - Step 880 Global step 880 Train loss 0.01 on epoch=439
04/28/2022 06:55:49 - INFO - __main__ - Step 890 Global step 890 Train loss 0.01 on epoch=444
04/28/2022 06:55:51 - INFO - __main__ - Step 900 Global step 900 Train loss 0.03 on epoch=449
04/28/2022 06:55:52 - INFO - __main__ - Global step 900 Train loss 0.01 ACC 0.5625 on epoch=449
04/28/2022 06:55:54 - INFO - __main__ - Step 910 Global step 910 Train loss 0.00 on epoch=454
04/28/2022 06:55:57 - INFO - __main__ - Step 920 Global step 920 Train loss 0.02 on epoch=459
04/28/2022 06:55:59 - INFO - __main__ - Step 930 Global step 930 Train loss 0.00 on epoch=464
04/28/2022 06:56:02 - INFO - __main__ - Step 940 Global step 940 Train loss 0.03 on epoch=469
04/28/2022 06:56:04 - INFO - __main__ - Step 950 Global step 950 Train loss 0.01 on epoch=474
04/28/2022 06:56:05 - INFO - __main__ - Global step 950 Train loss 0.01 ACC 0.5625 on epoch=474
04/28/2022 06:56:08 - INFO - __main__ - Step 960 Global step 960 Train loss 0.01 on epoch=479
04/28/2022 06:56:10 - INFO - __main__ - Step 970 Global step 970 Train loss 0.02 on epoch=484
04/28/2022 06:56:13 - INFO - __main__ - Step 980 Global step 980 Train loss 0.00 on epoch=489
04/28/2022 06:56:15 - INFO - __main__ - Step 990 Global step 990 Train loss 0.01 on epoch=494
04/28/2022 06:56:18 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.00 on epoch=499
04/28/2022 06:56:18 - INFO - __main__ - Global step 1000 Train loss 0.01 ACC 0.625 on epoch=499
04/28/2022 06:56:21 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.01 on epoch=504
04/28/2022 06:56:24 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.00 on epoch=509
04/28/2022 06:56:26 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.02 on epoch=514
04/28/2022 06:56:29 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.00 on epoch=519
04/28/2022 06:56:31 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.01 on epoch=524
04/28/2022 06:56:32 - INFO - __main__ - Global step 1050 Train loss 0.01 ACC 0.5625 on epoch=524
04/28/2022 06:56:34 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.00 on epoch=529
04/28/2022 06:56:37 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.06 on epoch=534
04/28/2022 06:56:39 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.04 on epoch=539
04/28/2022 06:56:42 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.00 on epoch=544
04/28/2022 06:56:44 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.01 on epoch=549
04/28/2022 06:56:45 - INFO - __main__ - Global step 1100 Train loss 0.02 ACC 0.53125 on epoch=549
04/28/2022 06:56:48 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.00 on epoch=554
04/28/2022 06:56:50 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.03 on epoch=559
04/28/2022 06:56:53 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.00 on epoch=564
04/28/2022 06:56:55 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.00 on epoch=569
04/28/2022 06:56:58 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=574
04/28/2022 06:56:59 - INFO - __main__ - Global step 1150 Train loss 0.01 ACC 0.5625 on epoch=574
04/28/2022 06:57:01 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.00 on epoch=579
04/28/2022 06:57:04 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.00 on epoch=584
04/28/2022 06:57:06 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.00 on epoch=589
04/28/2022 06:57:08 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.00 on epoch=594
04/28/2022 06:57:11 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.00 on epoch=599
04/28/2022 06:57:12 - INFO - __main__ - Global step 1200 Train loss 0.00 ACC 0.53125 on epoch=599
04/28/2022 06:57:14 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.00 on epoch=604
04/28/2022 06:57:17 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.02 on epoch=609
04/28/2022 06:57:19 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.00 on epoch=614
04/28/2022 06:57:22 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.00 on epoch=619
04/28/2022 06:57:24 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.02 on epoch=624
04/28/2022 06:57:25 - INFO - __main__ - Global step 1250 Train loss 0.01 ACC 0.5 on epoch=624
04/28/2022 06:57:28 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.00 on epoch=629
04/28/2022 06:57:30 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.00 on epoch=634
04/28/2022 06:57:33 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.04 on epoch=639
04/28/2022 06:57:35 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.00 on epoch=644
04/28/2022 06:57:38 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.00 on epoch=649
04/28/2022 06:57:39 - INFO - __main__ - Global step 1300 Train loss 0.01 ACC 0.59375 on epoch=649
04/28/2022 06:57:41 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.00 on epoch=654
04/28/2022 06:57:44 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.00 on epoch=659
04/28/2022 06:57:46 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.00 on epoch=664
04/28/2022 06:57:49 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.00 on epoch=669
04/28/2022 06:57:51 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.00 on epoch=674
04/28/2022 06:57:52 - INFO - __main__ - Global step 1350 Train loss 0.00 ACC 0.5 on epoch=674
04/28/2022 06:57:55 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.00 on epoch=679
04/28/2022 06:57:57 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.00 on epoch=684
04/28/2022 06:58:00 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.00 on epoch=689
04/28/2022 06:58:02 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=694
04/28/2022 06:58:05 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.00 on epoch=699
04/28/2022 06:58:06 - INFO - __main__ - Global step 1400 Train loss 0.00 ACC 0.5 on epoch=699
04/28/2022 06:58:08 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=704
04/28/2022 06:58:11 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=709
04/28/2022 06:58:13 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.00 on epoch=714
04/28/2022 06:58:16 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=719
04/28/2022 06:58:18 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=724
04/28/2022 06:58:19 - INFO - __main__ - Global step 1450 Train loss 0.01 ACC 0.5625 on epoch=724
04/28/2022 06:58:22 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=729
04/28/2022 06:58:24 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=734
04/28/2022 06:58:27 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=739
04/28/2022 06:58:29 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=744
04/28/2022 06:58:32 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=749
04/28/2022 06:58:33 - INFO - __main__ - Global step 1500 Train loss 0.00 ACC 0.53125 on epoch=749
04/28/2022 06:58:35 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=754
04/28/2022 06:58:38 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=759
04/28/2022 06:58:40 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=764
04/28/2022 06:58:43 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=769
04/28/2022 06:58:45 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=774
04/28/2022 06:58:46 - INFO - __main__ - Global step 1550 Train loss 0.00 ACC 0.5625 on epoch=774
04/28/2022 06:58:49 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=779
04/28/2022 06:58:51 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=784
04/28/2022 06:58:54 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=789
04/28/2022 06:58:56 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=794
04/28/2022 06:58:59 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.04 on epoch=799
04/28/2022 06:59:00 - INFO - __main__ - Global step 1600 Train loss 0.01 ACC 0.5 on epoch=799
04/28/2022 06:59:02 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=804
04/28/2022 06:59:05 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=809
04/28/2022 06:59:07 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=814
04/28/2022 06:59:10 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=819
04/28/2022 06:59:12 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=824
04/28/2022 06:59:13 - INFO - __main__ - Global step 1650 Train loss 0.00 ACC 0.46875 on epoch=824
04/28/2022 06:59:15 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=829
04/28/2022 06:59:18 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=834
04/28/2022 06:59:20 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=839
04/28/2022 06:59:23 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=844
04/28/2022 06:59:26 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=849
04/28/2022 06:59:26 - INFO - __main__ - Global step 1700 Train loss 0.00 ACC 0.5 on epoch=849
04/28/2022 06:59:29 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.09 on epoch=854
04/28/2022 06:59:31 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=859
04/28/2022 06:59:34 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=864
04/28/2022 06:59:36 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=869
04/28/2022 06:59:39 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=874
04/28/2022 06:59:40 - INFO - __main__ - Global step 1750 Train loss 0.02 ACC 0.59375 on epoch=874
04/28/2022 06:59:42 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=879
04/28/2022 06:59:45 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=884
04/28/2022 06:59:47 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=889
04/28/2022 06:59:50 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=894
04/28/2022 06:59:52 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=899
04/28/2022 06:59:53 - INFO - __main__ - Global step 1800 Train loss 0.00 ACC 0.5625 on epoch=899
04/28/2022 06:59:56 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=904
04/28/2022 06:59:58 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=909
04/28/2022 07:00:01 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=914
04/28/2022 07:00:03 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=919
04/28/2022 07:00:06 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=924
04/28/2022 07:00:06 - INFO - __main__ - Global step 1850 Train loss 0.00 ACC 0.59375 on epoch=924
04/28/2022 07:00:09 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=929
04/28/2022 07:00:11 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=934
04/28/2022 07:00:14 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=939
04/28/2022 07:00:16 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=944
04/28/2022 07:00:19 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=949
04/28/2022 07:00:20 - INFO - __main__ - Global step 1900 Train loss 0.00 ACC 0.53125 on epoch=949
04/28/2022 07:00:22 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=954
04/28/2022 07:00:25 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=959
04/28/2022 07:00:27 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=964
04/28/2022 07:00:30 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=969
04/28/2022 07:00:32 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=974
04/28/2022 07:00:33 - INFO - __main__ - Global step 1950 Train loss 0.00 ACC 0.59375 on epoch=974
04/28/2022 07:00:35 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=979
04/28/2022 07:00:38 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=984
04/28/2022 07:00:40 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=989
04/28/2022 07:00:43 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=994
04/28/2022 07:00:45 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=999
04/28/2022 07:00:46 - INFO - __main__ - Global step 2000 Train loss 0.00 ACC 0.53125 on epoch=999
04/28/2022 07:00:46 - INFO - __main__ - save last model!
04/28/2022 07:00:46 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
04/28/2022 07:00:46 - INFO - __main__ - Start tokenizing ... 1000 instances
04/28/2022 07:00:46 - INFO - __main__ - Printing 3 examples
04/28/2022 07:00:46 - INFO - __main__ -  [wino_grande] Sarah was a much better surgeon than Maria so _ always got the easier cases. (A) Sarah (B) Maria
04/28/2022 07:00:46 - INFO - __main__ - ['Maria']
04/28/2022 07:00:46 - INFO - __main__ -  [wino_grande] Sarah was a much better surgeon than Maria so _ always got the harder cases. (A) Sarah (B) Maria
04/28/2022 07:00:46 - INFO - __main__ - ['Sarah']
04/28/2022 07:00:46 - INFO - __main__ -  [wino_grande] They were worried the wine would ruin the bed and the blanket, but the _ was't ruined. (A) blanket (B) bed
04/28/2022 07:00:46 - INFO - __main__ - ['bed']
04/28/2022 07:00:46 - INFO - __main__ - Tokenizing Input ...
04/28/2022 07:00:47 - INFO - __main__ - Tokenizing Output ...
04/28/2022 07:00:47 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 07:00:47 - INFO - __main__ - Printing 3 examples
04/28/2022 07:00:47 - INFO - __main__ -  [wino_grande] Adam appointed Neil as the head guard, because _ trained so hard that he became the best of the best. (A) Adam (B) Neil
04/28/2022 07:00:47 - INFO - __main__ - ['Neil']
04/28/2022 07:00:47 - INFO - __main__ -  [wino_grande] Victoria was a more freaked out individual than Natalie, so _ became paranoid more easily. (A) Victoria (B) Natalie
04/28/2022 07:00:47 - INFO - __main__ - ['Victoria']
04/28/2022 07:00:47 - INFO - __main__ -  [wino_grande] Joseph thought Craig was turning into a homebody because _ would not get out of the house. (A) Joseph (B) Craig
04/28/2022 07:00:47 - INFO - __main__ - ['Craig']
04/28/2022 07:00:47 - INFO - __main__ - Tokenizing Input ...
04/28/2022 07:00:47 - INFO - __main__ - Tokenizing Output ...
04/28/2022 07:00:47 - INFO - __main__ - Loaded 32 examples from train data
04/28/2022 07:00:47 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 07:00:47 - INFO - __main__ - Printing 3 examples
04/28/2022 07:00:47 - INFO - __main__ -  [wino_grande] Donald ran as fast as a snail unlike Kevin who ran faster, because _ had an injury. (A) Donald (B) Kevin
04/28/2022 07:00:47 - INFO - __main__ - ['Donald']
04/28/2022 07:00:47 - INFO - __main__ -  [wino_grande] He tried to put the pacifier into their baby's mouth, but struggled because the _ was too tiny. (A) pacifier (B) mouth
04/28/2022 07:00:47 - INFO - __main__ - ['mouth']
04/28/2022 07:00:47 - INFO - __main__ -  [wino_grande] Meg was in a hurry so while parking and getting out of her car she accidentally left her phone inside as the _ was more pressing. (A) phone (B) car
04/28/2022 07:00:47 - INFO - __main__ - ['car']
04/28/2022 07:00:47 - INFO - __main__ - Tokenizing Input ...
04/28/2022 07:00:47 - INFO - __main__ - Tokenizing Output ...
04/28/2022 07:00:47 - INFO - __main__ - Loaded 32 examples from dev data
04/28/2022 07:00:48 - INFO - __main__ - Loaded 1000 examples from test data
04/28/2022 07:01:02 - INFO - __main__ - load prompt embedding from ckpt
04/28/2022 07:01:03 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/28/2022 07:01:03 - INFO - __main__ - Starting training!
04/28/2022 07:01:10 - INFO - __main__ - Saved prediction in models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-wino_grande/wino_grande_32_21_0.3_8_predictions.txt
04/28/2022 07:01:10 - INFO - __main__ - ACC on test data: 0.4990
04/28/2022 07:01:11 - INFO - __main__ - prefix=wino_grande_32_21, lr=0.3, bsz=8, dev_performance=0.6875, test_performance=0.499
04/28/2022 07:01:11 - INFO - __main__ - Running ... prefix=wino_grande_32_21, lr=0.2, bsz=8 ...
04/28/2022 07:01:11 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 07:01:11 - INFO - __main__ - Printing 3 examples
04/28/2022 07:01:11 - INFO - __main__ -  [wino_grande] Adam appointed Neil as the head guard, because _ trained so hard that he became the best of the best. (A) Adam (B) Neil
04/28/2022 07:01:11 - INFO - __main__ - ['Neil']
04/28/2022 07:01:11 - INFO - __main__ -  [wino_grande] Victoria was a more freaked out individual than Natalie, so _ became paranoid more easily. (A) Victoria (B) Natalie
04/28/2022 07:01:11 - INFO - __main__ - ['Victoria']
04/28/2022 07:01:11 - INFO - __main__ -  [wino_grande] Joseph thought Craig was turning into a homebody because _ would not get out of the house. (A) Joseph (B) Craig
04/28/2022 07:01:11 - INFO - __main__ - ['Craig']
04/28/2022 07:01:11 - INFO - __main__ - Tokenizing Input ...
04/28/2022 07:01:11 - INFO - __main__ - Tokenizing Output ...
04/28/2022 07:01:11 - INFO - __main__ - Loaded 32 examples from train data
04/28/2022 07:01:11 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 07:01:11 - INFO - __main__ - Printing 3 examples
04/28/2022 07:01:11 - INFO - __main__ -  [wino_grande] Donald ran as fast as a snail unlike Kevin who ran faster, because _ had an injury. (A) Donald (B) Kevin
04/28/2022 07:01:11 - INFO - __main__ - ['Donald']
04/28/2022 07:01:11 - INFO - __main__ -  [wino_grande] He tried to put the pacifier into their baby's mouth, but struggled because the _ was too tiny. (A) pacifier (B) mouth
04/28/2022 07:01:11 - INFO - __main__ - ['mouth']
04/28/2022 07:01:11 - INFO - __main__ -  [wino_grande] Meg was in a hurry so while parking and getting out of her car she accidentally left her phone inside as the _ was more pressing. (A) phone (B) car
04/28/2022 07:01:12 - INFO - __main__ - ['car']
04/28/2022 07:01:12 - INFO - __main__ - Tokenizing Input ...
04/28/2022 07:01:12 - INFO - __main__ - Tokenizing Output ...
04/28/2022 07:01:12 - INFO - __main__ - Loaded 32 examples from dev data
04/28/2022 07:01:27 - INFO - __main__ - load prompt embedding from ckpt
04/28/2022 07:01:28 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/28/2022 07:01:28 - INFO - __main__ - Starting training!
04/28/2022 07:01:31 - INFO - __main__ - Step 10 Global step 10 Train loss 4.50 on epoch=4
04/28/2022 07:01:33 - INFO - __main__ - Step 20 Global step 20 Train loss 2.69 on epoch=9
04/28/2022 07:01:36 - INFO - __main__ - Step 30 Global step 30 Train loss 1.50 on epoch=14
04/28/2022 07:01:38 - INFO - __main__ - Step 40 Global step 40 Train loss 0.96 on epoch=19
04/28/2022 07:01:40 - INFO - __main__ - Step 50 Global step 50 Train loss 0.70 on epoch=24
04/28/2022 07:01:41 - INFO - __main__ - Global step 50 Train loss 2.07 ACC 0.65625 on epoch=24
04/28/2022 07:01:41 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.65625 on epoch=24, global_step=50
04/28/2022 07:01:44 - INFO - __main__ - Step 60 Global step 60 Train loss 0.80 on epoch=29
04/28/2022 07:01:46 - INFO - __main__ - Step 70 Global step 70 Train loss 0.62 on epoch=34
04/28/2022 07:01:49 - INFO - __main__ - Step 80 Global step 80 Train loss 0.41 on epoch=39
04/28/2022 07:01:51 - INFO - __main__ - Step 90 Global step 90 Train loss 0.43 on epoch=44
04/28/2022 07:01:54 - INFO - __main__ - Step 100 Global step 100 Train loss 0.37 on epoch=49
04/28/2022 07:01:54 - INFO - __main__ - Global step 100 Train loss 0.53 ACC 0.59375 on epoch=49
04/28/2022 07:01:57 - INFO - __main__ - Step 110 Global step 110 Train loss 0.29 on epoch=54
04/28/2022 07:01:59 - INFO - __main__ - Step 120 Global step 120 Train loss 0.37 on epoch=59
04/28/2022 07:02:02 - INFO - __main__ - Step 130 Global step 130 Train loss 0.31 on epoch=64
04/28/2022 07:02:04 - INFO - __main__ - Step 140 Global step 140 Train loss 0.18 on epoch=69
04/28/2022 07:02:07 - INFO - __main__ - Step 150 Global step 150 Train loss 0.16 on epoch=74
04/28/2022 07:02:07 - INFO - __main__ - Global step 150 Train loss 0.26 ACC 0.6875 on epoch=74
04/28/2022 07:02:07 - INFO - __main__ - Saving model with best ACC: 0.65625 -> 0.6875 on epoch=74, global_step=150
04/28/2022 07:02:10 - INFO - __main__ - Step 160 Global step 160 Train loss 0.24 on epoch=79
04/28/2022 07:02:12 - INFO - __main__ - Step 170 Global step 170 Train loss 0.10 on epoch=84
04/28/2022 07:02:15 - INFO - __main__ - Step 180 Global step 180 Train loss 0.24 on epoch=89
04/28/2022 07:02:17 - INFO - __main__ - Step 190 Global step 190 Train loss 0.19 on epoch=94
04/28/2022 07:02:20 - INFO - __main__ - Step 200 Global step 200 Train loss 0.13 on epoch=99
04/28/2022 07:02:21 - INFO - __main__ - Global step 200 Train loss 0.18 ACC 0.625 on epoch=99
04/28/2022 07:02:23 - INFO - __main__ - Step 210 Global step 210 Train loss 0.10 on epoch=104
04/28/2022 07:02:26 - INFO - __main__ - Step 220 Global step 220 Train loss 0.09 on epoch=109
04/28/2022 07:02:28 - INFO - __main__ - Step 230 Global step 230 Train loss 0.13 on epoch=114
04/28/2022 07:02:31 - INFO - __main__ - Step 240 Global step 240 Train loss 0.16 on epoch=119
04/28/2022 07:02:33 - INFO - __main__ - Step 250 Global step 250 Train loss 0.09 on epoch=124
04/28/2022 07:02:34 - INFO - __main__ - Global step 250 Train loss 0.11 ACC 0.625 on epoch=124
04/28/2022 07:02:36 - INFO - __main__ - Step 260 Global step 260 Train loss 0.11 on epoch=129
04/28/2022 07:02:39 - INFO - __main__ - Step 270 Global step 270 Train loss 0.11 on epoch=134
04/28/2022 07:02:41 - INFO - __main__ - Step 280 Global step 280 Train loss 0.11 on epoch=139
04/28/2022 07:02:44 - INFO - __main__ - Step 290 Global step 290 Train loss 0.05 on epoch=144
04/28/2022 07:02:46 - INFO - __main__ - Step 300 Global step 300 Train loss 0.04 on epoch=149
04/28/2022 07:02:47 - INFO - __main__ - Global step 300 Train loss 0.08 ACC 0.65625 on epoch=149
04/28/2022 07:02:50 - INFO - __main__ - Step 310 Global step 310 Train loss 0.08 on epoch=154
04/28/2022 07:02:52 - INFO - __main__ - Step 320 Global step 320 Train loss 0.14 on epoch=159
04/28/2022 07:02:54 - INFO - __main__ - Step 330 Global step 330 Train loss 0.06 on epoch=164
04/28/2022 07:02:57 - INFO - __main__ - Step 340 Global step 340 Train loss 0.14 on epoch=169
04/28/2022 07:02:59 - INFO - __main__ - Step 350 Global step 350 Train loss 0.05 on epoch=174
04/28/2022 07:03:00 - INFO - __main__ - Global step 350 Train loss 0.09 ACC 0.59375 on epoch=174
04/28/2022 07:03:03 - INFO - __main__ - Step 360 Global step 360 Train loss 0.02 on epoch=179
04/28/2022 07:03:05 - INFO - __main__ - Step 370 Global step 370 Train loss 0.06 on epoch=184
04/28/2022 07:03:08 - INFO - __main__ - Step 380 Global step 380 Train loss 0.04 on epoch=189
04/28/2022 07:03:10 - INFO - __main__ - Step 390 Global step 390 Train loss 0.02 on epoch=194
04/28/2022 07:03:13 - INFO - __main__ - Step 400 Global step 400 Train loss 0.02 on epoch=199
04/28/2022 07:03:13 - INFO - __main__ - Global step 400 Train loss 0.03 ACC 0.59375 on epoch=199
04/28/2022 07:03:16 - INFO - __main__ - Step 410 Global step 410 Train loss 0.10 on epoch=204
04/28/2022 07:03:18 - INFO - __main__ - Step 420 Global step 420 Train loss 0.07 on epoch=209
04/28/2022 07:03:21 - INFO - __main__ - Step 430 Global step 430 Train loss 0.05 on epoch=214
04/28/2022 07:03:23 - INFO - __main__ - Step 440 Global step 440 Train loss 0.04 on epoch=219
04/28/2022 07:03:26 - INFO - __main__ - Step 450 Global step 450 Train loss 0.06 on epoch=224
04/28/2022 07:03:26 - INFO - __main__ - Global step 450 Train loss 0.06 ACC 0.5625 on epoch=224
04/28/2022 07:03:29 - INFO - __main__ - Step 460 Global step 460 Train loss 0.06 on epoch=229
04/28/2022 07:03:31 - INFO - __main__ - Step 470 Global step 470 Train loss 0.02 on epoch=234
04/28/2022 07:03:34 - INFO - __main__ - Step 480 Global step 480 Train loss 0.03 on epoch=239
04/28/2022 07:03:36 - INFO - __main__ - Step 490 Global step 490 Train loss 0.04 on epoch=244
04/28/2022 07:03:39 - INFO - __main__ - Step 500 Global step 500 Train loss 0.11 on epoch=249
04/28/2022 07:03:39 - INFO - __main__ - Global step 500 Train loss 0.05 ACC 0.59375 on epoch=249
04/28/2022 07:03:42 - INFO - __main__ - Step 510 Global step 510 Train loss 0.06 on epoch=254
04/28/2022 07:03:44 - INFO - __main__ - Step 520 Global step 520 Train loss 0.01 on epoch=259
04/28/2022 07:03:47 - INFO - __main__ - Step 530 Global step 530 Train loss 0.02 on epoch=264
04/28/2022 07:03:49 - INFO - __main__ - Step 540 Global step 540 Train loss 0.01 on epoch=269
04/28/2022 07:03:52 - INFO - __main__ - Step 550 Global step 550 Train loss 0.02 on epoch=274
04/28/2022 07:03:53 - INFO - __main__ - Global step 550 Train loss 0.03 ACC 0.59375 on epoch=274
04/28/2022 07:03:55 - INFO - __main__ - Step 560 Global step 560 Train loss 0.01 on epoch=279
04/28/2022 07:03:58 - INFO - __main__ - Step 570 Global step 570 Train loss 0.02 on epoch=284
04/28/2022 07:04:00 - INFO - __main__ - Step 580 Global step 580 Train loss 0.01 on epoch=289
04/28/2022 07:04:03 - INFO - __main__ - Step 590 Global step 590 Train loss 0.01 on epoch=294
04/28/2022 07:04:05 - INFO - __main__ - Step 600 Global step 600 Train loss 0.01 on epoch=299
04/28/2022 07:04:07 - INFO - __main__ - Global step 600 Train loss 0.01 ACC 0.5625 on epoch=299
04/28/2022 07:04:10 - INFO - __main__ - Step 610 Global step 610 Train loss 0.03 on epoch=304
04/28/2022 07:04:12 - INFO - __main__ - Step 620 Global step 620 Train loss 0.02 on epoch=309
04/28/2022 07:04:15 - INFO - __main__ - Step 630 Global step 630 Train loss 0.03 on epoch=314
04/28/2022 07:04:17 - INFO - __main__ - Step 640 Global step 640 Train loss 0.02 on epoch=319
04/28/2022 07:04:20 - INFO - __main__ - Step 650 Global step 650 Train loss 0.04 on epoch=324
04/28/2022 07:04:21 - INFO - __main__ - Global step 650 Train loss 0.03 ACC 0.5625 on epoch=324
04/28/2022 07:04:23 - INFO - __main__ - Step 660 Global step 660 Train loss 0.04 on epoch=329
04/28/2022 07:04:26 - INFO - __main__ - Step 670 Global step 670 Train loss 0.05 on epoch=334
04/28/2022 07:04:28 - INFO - __main__ - Step 680 Global step 680 Train loss 0.01 on epoch=339
04/28/2022 07:04:31 - INFO - __main__ - Step 690 Global step 690 Train loss 0.01 on epoch=344
04/28/2022 07:04:33 - INFO - __main__ - Step 700 Global step 700 Train loss 0.01 on epoch=349
04/28/2022 07:04:34 - INFO - __main__ - Global step 700 Train loss 0.02 ACC 0.625 on epoch=349
04/28/2022 07:04:36 - INFO - __main__ - Step 710 Global step 710 Train loss 0.01 on epoch=354
04/28/2022 07:04:39 - INFO - __main__ - Step 720 Global step 720 Train loss 0.06 on epoch=359
04/28/2022 07:04:41 - INFO - __main__ - Step 730 Global step 730 Train loss 0.01 on epoch=364
04/28/2022 07:04:44 - INFO - __main__ - Step 740 Global step 740 Train loss 0.01 on epoch=369
04/28/2022 07:04:47 - INFO - __main__ - Step 750 Global step 750 Train loss 0.09 on epoch=374
04/28/2022 07:04:47 - INFO - __main__ - Global step 750 Train loss 0.03 ACC 0.65625 on epoch=374
04/28/2022 07:04:50 - INFO - __main__ - Step 760 Global step 760 Train loss 0.01 on epoch=379
04/28/2022 07:04:52 - INFO - __main__ - Step 770 Global step 770 Train loss 0.01 on epoch=384
04/28/2022 07:04:55 - INFO - __main__ - Step 780 Global step 780 Train loss 0.02 on epoch=389
04/28/2022 07:04:57 - INFO - __main__ - Step 790 Global step 790 Train loss 0.00 on epoch=394
04/28/2022 07:05:00 - INFO - __main__ - Step 800 Global step 800 Train loss 0.01 on epoch=399
04/28/2022 07:05:01 - INFO - __main__ - Global step 800 Train loss 0.01 ACC 0.65625 on epoch=399
04/28/2022 07:05:03 - INFO - __main__ - Step 810 Global step 810 Train loss 0.04 on epoch=404
04/28/2022 07:05:06 - INFO - __main__ - Step 820 Global step 820 Train loss 0.06 on epoch=409
04/28/2022 07:05:08 - INFO - __main__ - Step 830 Global step 830 Train loss 0.01 on epoch=414
04/28/2022 07:05:11 - INFO - __main__ - Step 840 Global step 840 Train loss 0.01 on epoch=419
04/28/2022 07:05:13 - INFO - __main__ - Step 850 Global step 850 Train loss 0.02 on epoch=424
04/28/2022 07:05:14 - INFO - __main__ - Global step 850 Train loss 0.03 ACC 0.625 on epoch=424
04/28/2022 07:05:17 - INFO - __main__ - Step 860 Global step 860 Train loss 0.06 on epoch=429
04/28/2022 07:05:19 - INFO - __main__ - Step 870 Global step 870 Train loss 0.01 on epoch=434
04/28/2022 07:05:22 - INFO - __main__ - Step 880 Global step 880 Train loss 0.01 on epoch=439
04/28/2022 07:05:24 - INFO - __main__ - Step 890 Global step 890 Train loss 0.01 on epoch=444
04/28/2022 07:05:27 - INFO - __main__ - Step 900 Global step 900 Train loss 0.01 on epoch=449
04/28/2022 07:05:27 - INFO - __main__ - Global step 900 Train loss 0.02 ACC 0.59375 on epoch=449
04/28/2022 07:05:30 - INFO - __main__ - Step 910 Global step 910 Train loss 0.02 on epoch=454
04/28/2022 07:05:32 - INFO - __main__ - Step 920 Global step 920 Train loss 0.00 on epoch=459
04/28/2022 07:05:35 - INFO - __main__ - Step 930 Global step 930 Train loss 0.01 on epoch=464
04/28/2022 07:05:37 - INFO - __main__ - Step 940 Global step 940 Train loss 0.00 on epoch=469
04/28/2022 07:05:40 - INFO - __main__ - Step 950 Global step 950 Train loss 0.01 on epoch=474
04/28/2022 07:05:41 - INFO - __main__ - Global step 950 Train loss 0.01 ACC 0.65625 on epoch=474
04/28/2022 07:05:43 - INFO - __main__ - Step 960 Global step 960 Train loss 0.00 on epoch=479
04/28/2022 07:05:46 - INFO - __main__ - Step 970 Global step 970 Train loss 0.00 on epoch=484
04/28/2022 07:05:48 - INFO - __main__ - Step 980 Global step 980 Train loss 0.01 on epoch=489
04/28/2022 07:05:51 - INFO - __main__ - Step 990 Global step 990 Train loss 0.02 on epoch=494
04/28/2022 07:05:53 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.01 on epoch=499
04/28/2022 07:05:54 - INFO - __main__ - Global step 1000 Train loss 0.01 ACC 0.625 on epoch=499
04/28/2022 07:05:56 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.00 on epoch=504
04/28/2022 07:05:59 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.00 on epoch=509
04/28/2022 07:06:01 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.02 on epoch=514
04/28/2022 07:06:04 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.00 on epoch=519
04/28/2022 07:06:06 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.01 on epoch=524
04/28/2022 07:06:07 - INFO - __main__ - Global step 1050 Train loss 0.01 ACC 0.65625 on epoch=524
04/28/2022 07:06:09 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.00 on epoch=529
04/28/2022 07:06:12 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.02 on epoch=534
04/28/2022 07:06:15 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.01 on epoch=539
04/28/2022 07:06:17 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.00 on epoch=544
04/28/2022 07:06:20 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.01 on epoch=549
04/28/2022 07:06:20 - INFO - __main__ - Global step 1100 Train loss 0.01 ACC 0.625 on epoch=549
04/28/2022 07:06:23 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.00 on epoch=554
04/28/2022 07:06:25 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=559
04/28/2022 07:06:28 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.00 on epoch=564
04/28/2022 07:06:30 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.01 on epoch=569
04/28/2022 07:06:33 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=574
04/28/2022 07:06:33 - INFO - __main__ - Global step 1150 Train loss 0.01 ACC 0.59375 on epoch=574
04/28/2022 07:06:36 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.00 on epoch=579
04/28/2022 07:06:39 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.01 on epoch=584
04/28/2022 07:06:41 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.00 on epoch=589
04/28/2022 07:06:44 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.02 on epoch=594
04/28/2022 07:06:46 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.00 on epoch=599
04/28/2022 07:06:47 - INFO - __main__ - Global step 1200 Train loss 0.01 ACC 0.625 on epoch=599
04/28/2022 07:06:49 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.17 on epoch=604
04/28/2022 07:06:52 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=609
04/28/2022 07:06:54 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=614
04/28/2022 07:06:57 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.00 on epoch=619
04/28/2022 07:06:59 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.00 on epoch=624
04/28/2022 07:07:00 - INFO - __main__ - Global step 1250 Train loss 0.04 ACC 0.59375 on epoch=624
04/28/2022 07:07:02 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=629
04/28/2022 07:07:05 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.00 on epoch=634
04/28/2022 07:07:08 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.00 on epoch=639
04/28/2022 07:07:10 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.00 on epoch=644
04/28/2022 07:07:13 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.00 on epoch=649
04/28/2022 07:07:13 - INFO - __main__ - Global step 1300 Train loss 0.00 ACC 0.59375 on epoch=649
04/28/2022 07:07:16 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.00 on epoch=654
04/28/2022 07:07:18 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.02 on epoch=659
04/28/2022 07:07:21 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.00 on epoch=664
04/28/2022 07:07:23 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.00 on epoch=669
04/28/2022 07:07:26 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=674
04/28/2022 07:07:27 - INFO - __main__ - Global step 1350 Train loss 0.01 ACC 0.65625 on epoch=674
04/28/2022 07:07:29 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.02 on epoch=679
04/28/2022 07:07:31 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.00 on epoch=684
04/28/2022 07:07:34 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=689
04/28/2022 07:07:36 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.00 on epoch=694
04/28/2022 07:07:39 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.00 on epoch=699
04/28/2022 07:07:40 - INFO - __main__ - Global step 1400 Train loss 0.01 ACC 0.625 on epoch=699
04/28/2022 07:07:42 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=704
04/28/2022 07:07:44 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=709
04/28/2022 07:07:47 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.00 on epoch=714
04/28/2022 07:07:49 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=719
04/28/2022 07:07:52 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=724
04/28/2022 07:07:53 - INFO - __main__ - Global step 1450 Train loss 0.00 ACC 0.625 on epoch=724
04/28/2022 07:07:55 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=729
04/28/2022 07:07:57 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=734
04/28/2022 07:08:00 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=739
04/28/2022 07:08:02 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.03 on epoch=744
04/28/2022 07:08:05 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=749
04/28/2022 07:08:05 - INFO - __main__ - Global step 1500 Train loss 0.01 ACC 0.59375 on epoch=749
04/28/2022 07:08:08 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=754
04/28/2022 07:08:10 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=759
04/28/2022 07:08:13 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=764
04/28/2022 07:08:15 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=769
04/28/2022 07:08:18 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.04 on epoch=774
04/28/2022 07:08:19 - INFO - __main__ - Global step 1550 Train loss 0.01 ACC 0.59375 on epoch=774
04/28/2022 07:08:21 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=779
04/28/2022 07:08:23 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=784
04/28/2022 07:08:26 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=789
04/28/2022 07:08:29 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.09 on epoch=794
04/28/2022 07:08:31 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=799
04/28/2022 07:08:32 - INFO - __main__ - Global step 1600 Train loss 0.02 ACC 0.5625 on epoch=799
04/28/2022 07:08:34 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=804
04/28/2022 07:08:37 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=809
04/28/2022 07:08:39 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=814
04/28/2022 07:08:42 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=819
04/28/2022 07:08:44 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=824
04/28/2022 07:08:45 - INFO - __main__ - Global step 1650 Train loss 0.00 ACC 0.5625 on epoch=824
04/28/2022 07:08:47 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=829
04/28/2022 07:08:50 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=834
04/28/2022 07:08:53 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=839
04/28/2022 07:08:55 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=844
04/28/2022 07:08:58 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=849
04/28/2022 07:08:58 - INFO - __main__ - Global step 1700 Train loss 0.01 ACC 0.5625 on epoch=849
04/28/2022 07:09:01 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=854
04/28/2022 07:09:03 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=859
04/28/2022 07:09:06 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=864
04/28/2022 07:09:09 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=869
04/28/2022 07:09:11 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=874
04/28/2022 07:09:12 - INFO - __main__ - Global step 1750 Train loss 0.00 ACC 0.59375 on epoch=874
04/28/2022 07:09:14 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=879
04/28/2022 07:09:17 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=884
04/28/2022 07:09:20 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=889
04/28/2022 07:09:22 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=894
04/28/2022 07:09:25 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=899
04/28/2022 07:09:25 - INFO - __main__ - Global step 1800 Train loss 0.00 ACC 0.5625 on epoch=899
04/28/2022 07:09:28 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=904
04/28/2022 07:09:31 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=909
04/28/2022 07:09:33 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=914
04/28/2022 07:09:36 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=919
04/28/2022 07:09:38 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=924
04/28/2022 07:09:39 - INFO - __main__ - Global step 1850 Train loss 0.00 ACC 0.5625 on epoch=924
04/28/2022 07:09:41 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=929
04/28/2022 07:09:44 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=934
04/28/2022 07:09:46 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=939
04/28/2022 07:09:49 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=944
04/28/2022 07:09:52 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=949
04/28/2022 07:09:52 - INFO - __main__ - Global step 1900 Train loss 0.00 ACC 0.53125 on epoch=949
04/28/2022 07:09:55 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=954
04/28/2022 07:09:58 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=959
04/28/2022 07:10:00 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=964
04/28/2022 07:10:03 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.04 on epoch=969
04/28/2022 07:10:05 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=974
04/28/2022 07:10:06 - INFO - __main__ - Global step 1950 Train loss 0.01 ACC 0.53125 on epoch=974
04/28/2022 07:10:08 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=979
04/28/2022 07:10:11 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=984
04/28/2022 07:10:14 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=989
04/28/2022 07:10:16 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=994
04/28/2022 07:10:19 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=999
04/28/2022 07:10:19 - INFO - __main__ - Global step 2000 Train loss 0.00 ACC 0.53125 on epoch=999
04/28/2022 07:10:19 - INFO - __main__ - save last model!
04/28/2022 07:10:19 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
04/28/2022 07:10:19 - INFO - __main__ - Start tokenizing ... 1000 instances
04/28/2022 07:10:19 - INFO - __main__ - Printing 3 examples
04/28/2022 07:10:19 - INFO - __main__ -  [wino_grande] Sarah was a much better surgeon than Maria so _ always got the easier cases. (A) Sarah (B) Maria
04/28/2022 07:10:19 - INFO - __main__ - ['Maria']
04/28/2022 07:10:19 - INFO - __main__ -  [wino_grande] Sarah was a much better surgeon than Maria so _ always got the harder cases. (A) Sarah (B) Maria
04/28/2022 07:10:19 - INFO - __main__ - ['Sarah']
04/28/2022 07:10:19 - INFO - __main__ -  [wino_grande] They were worried the wine would ruin the bed and the blanket, but the _ was't ruined. (A) blanket (B) bed
04/28/2022 07:10:19 - INFO - __main__ - ['bed']
04/28/2022 07:10:20 - INFO - __main__ - Tokenizing Input ...
04/28/2022 07:10:20 - INFO - __main__ - Tokenizing Output ...
04/28/2022 07:10:20 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 07:10:20 - INFO - __main__ - Printing 3 examples
04/28/2022 07:10:20 - INFO - __main__ -  [wino_grande] Monica confided in Cynthia that she had prepared an Emergency Evacuation Kit for the storm.  _ was impressed. (A) Monica (B) Cynthia
04/28/2022 07:10:20 - INFO - __main__ - ['Cynthia']
04/28/2022 07:10:20 - INFO - __main__ -  [wino_grande] Rebecca had less grass in their yard than Elena because _ had more rabbits in their yard. (A) Rebecca (B) Elena
04/28/2022 07:10:20 - INFO - __main__ - ['Rebecca']
04/28/2022 07:10:20 - INFO - __main__ -  [wino_grande] Erin has a lot of dry skin on their arms and legs and Angela does not, because _ has been using lotion to keep their skin soft. (A) Erin (B) Angela
04/28/2022 07:10:20 - INFO - __main__ - ['Angela']
04/28/2022 07:10:20 - INFO - __main__ - Tokenizing Input ...
04/28/2022 07:10:20 - INFO - __main__ - Tokenizing Output ...
04/28/2022 07:10:21 - INFO - __main__ - Loaded 32 examples from train data
04/28/2022 07:10:21 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 07:10:21 - INFO - __main__ - Printing 3 examples
04/28/2022 07:10:21 - INFO - __main__ -  [wino_grande] Kyle always had ideas in the mind unlike Matthew, because _ was a horrible imaginative person. (A) Kyle (B) Matthew
04/28/2022 07:10:21 - INFO - __main__ - ['Matthew']
04/28/2022 07:10:21 - INFO - __main__ -  [wino_grande] Dennis showed endless dedication to the unappreciative Ian, so _ expended their energy for nothing. (A) Dennis (B) Ian
04/28/2022 07:10:21 - INFO - __main__ - ['Dennis']
04/28/2022 07:10:21 - INFO - __main__ -  [wino_grande] It was taking a long time for Emily to heal, so Jennifer gave her some antibiotics. _ is has a wound. (A) Emily (B) Jennifer
04/28/2022 07:10:21 - INFO - __main__ - ['Emily']
04/28/2022 07:10:21 - INFO - __main__ - Tokenizing Input ...
04/28/2022 07:10:21 - INFO - __main__ - Tokenizing Output ...
04/28/2022 07:10:21 - INFO - __main__ - Loaded 32 examples from dev data
04/28/2022 07:10:21 - INFO - __main__ - Loaded 1000 examples from test data
04/28/2022 07:10:39 - INFO - __main__ - load prompt embedding from ckpt
04/28/2022 07:10:40 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/28/2022 07:10:40 - INFO - __main__ - Starting training!
04/28/2022 07:10:43 - INFO - __main__ - Saved prediction in models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-wino_grande/wino_grande_32_21_0.2_8_predictions.txt
04/28/2022 07:10:43 - INFO - __main__ - ACC on test data: 0.4930
04/28/2022 07:10:43 - INFO - __main__ - prefix=wino_grande_32_21, lr=0.2, bsz=8, dev_performance=0.6875, test_performance=0.493
04/28/2022 07:10:43 - INFO - __main__ - Running ... prefix=wino_grande_32_42, lr=0.5, bsz=8 ...
04/28/2022 07:10:44 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 07:10:44 - INFO - __main__ - Printing 3 examples
04/28/2022 07:10:44 - INFO - __main__ -  [wino_grande] Monica confided in Cynthia that she had prepared an Emergency Evacuation Kit for the storm.  _ was impressed. (A) Monica (B) Cynthia
04/28/2022 07:10:44 - INFO - __main__ - ['Cynthia']
04/28/2022 07:10:44 - INFO - __main__ -  [wino_grande] Rebecca had less grass in their yard than Elena because _ had more rabbits in their yard. (A) Rebecca (B) Elena
04/28/2022 07:10:44 - INFO - __main__ - ['Rebecca']
04/28/2022 07:10:44 - INFO - __main__ -  [wino_grande] Erin has a lot of dry skin on their arms and legs and Angela does not, because _ has been using lotion to keep their skin soft. (A) Erin (B) Angela
04/28/2022 07:10:44 - INFO - __main__ - ['Angela']
04/28/2022 07:10:44 - INFO - __main__ - Tokenizing Input ...
04/28/2022 07:10:44 - INFO - __main__ - Tokenizing Output ...
04/28/2022 07:10:44 - INFO - __main__ - Loaded 32 examples from train data
04/28/2022 07:10:44 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 07:10:44 - INFO - __main__ - Printing 3 examples
04/28/2022 07:10:44 - INFO - __main__ -  [wino_grande] Kyle always had ideas in the mind unlike Matthew, because _ was a horrible imaginative person. (A) Kyle (B) Matthew
04/28/2022 07:10:44 - INFO - __main__ - ['Matthew']
04/28/2022 07:10:44 - INFO - __main__ -  [wino_grande] Dennis showed endless dedication to the unappreciative Ian, so _ expended their energy for nothing. (A) Dennis (B) Ian
04/28/2022 07:10:44 - INFO - __main__ - ['Dennis']
04/28/2022 07:10:44 - INFO - __main__ -  [wino_grande] It was taking a long time for Emily to heal, so Jennifer gave her some antibiotics. _ is has a wound. (A) Emily (B) Jennifer
04/28/2022 07:10:44 - INFO - __main__ - ['Emily']
04/28/2022 07:10:44 - INFO - __main__ - Tokenizing Input ...
04/28/2022 07:10:44 - INFO - __main__ - Tokenizing Output ...
04/28/2022 07:10:44 - INFO - __main__ - Loaded 32 examples from dev data
04/28/2022 07:11:02 - INFO - __main__ - load prompt embedding from ckpt
04/28/2022 07:11:03 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/28/2022 07:11:03 - INFO - __main__ - Starting training!
04/28/2022 07:11:06 - INFO - __main__ - Step 10 Global step 10 Train loss 2.99 on epoch=4
04/28/2022 07:11:09 - INFO - __main__ - Step 20 Global step 20 Train loss 0.83 on epoch=9
04/28/2022 07:11:11 - INFO - __main__ - Step 30 Global step 30 Train loss 0.52 on epoch=14
04/28/2022 07:11:14 - INFO - __main__ - Step 40 Global step 40 Train loss 0.39 on epoch=19
04/28/2022 07:11:16 - INFO - __main__ - Step 50 Global step 50 Train loss 0.37 on epoch=24
04/28/2022 07:11:17 - INFO - __main__ - Global step 50 Train loss 1.02 ACC 0.46875 on epoch=24
04/28/2022 07:11:17 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.46875 on epoch=24, global_step=50
04/28/2022 07:11:20 - INFO - __main__ - Step 60 Global step 60 Train loss 0.33 on epoch=29
04/28/2022 07:11:23 - INFO - __main__ - Step 70 Global step 70 Train loss 0.22 on epoch=34
04/28/2022 07:11:25 - INFO - __main__ - Step 80 Global step 80 Train loss 0.31 on epoch=39
04/28/2022 07:11:27 - INFO - __main__ - Step 90 Global step 90 Train loss 0.26 on epoch=44
04/28/2022 07:11:30 - INFO - __main__ - Step 100 Global step 100 Train loss 0.18 on epoch=49
04/28/2022 07:11:31 - INFO - __main__ - Global step 100 Train loss 0.26 ACC 0.5625 on epoch=49
04/28/2022 07:11:31 - INFO - __main__ - Saving model with best ACC: 0.46875 -> 0.5625 on epoch=49, global_step=100
04/28/2022 07:11:33 - INFO - __main__ - Step 110 Global step 110 Train loss 0.16 on epoch=54
04/28/2022 07:11:36 - INFO - __main__ - Step 120 Global step 120 Train loss 0.22 on epoch=59
04/28/2022 07:11:38 - INFO - __main__ - Step 130 Global step 130 Train loss 0.12 on epoch=64
04/28/2022 07:11:41 - INFO - __main__ - Step 140 Global step 140 Train loss 0.10 on epoch=69
04/28/2022 07:11:43 - INFO - __main__ - Step 150 Global step 150 Train loss 0.09 on epoch=74
04/28/2022 07:11:44 - INFO - __main__ - Global step 150 Train loss 0.14 ACC 0.59375 on epoch=74
04/28/2022 07:11:44 - INFO - __main__ - Saving model with best ACC: 0.5625 -> 0.59375 on epoch=74, global_step=150
04/28/2022 07:11:47 - INFO - __main__ - Step 160 Global step 160 Train loss 0.08 on epoch=79
04/28/2022 07:11:49 - INFO - __main__ - Step 170 Global step 170 Train loss 0.10 on epoch=84
04/28/2022 07:11:52 - INFO - __main__ - Step 180 Global step 180 Train loss 0.11 on epoch=89
04/28/2022 07:11:54 - INFO - __main__ - Step 190 Global step 190 Train loss 0.09 on epoch=94
04/28/2022 07:11:57 - INFO - __main__ - Step 200 Global step 200 Train loss 0.06 on epoch=99
04/28/2022 07:11:57 - INFO - __main__ - Global step 200 Train loss 0.09 ACC 0.6875 on epoch=99
04/28/2022 07:11:57 - INFO - __main__ - Saving model with best ACC: 0.59375 -> 0.6875 on epoch=99, global_step=200
04/28/2022 07:12:00 - INFO - __main__ - Step 210 Global step 210 Train loss 0.06 on epoch=104
04/28/2022 07:12:02 - INFO - __main__ - Step 220 Global step 220 Train loss 0.11 on epoch=109
04/28/2022 07:12:05 - INFO - __main__ - Step 230 Global step 230 Train loss 0.08 on epoch=114
04/28/2022 07:12:07 - INFO - __main__ - Step 240 Global step 240 Train loss 0.05 on epoch=119
04/28/2022 07:12:10 - INFO - __main__ - Step 250 Global step 250 Train loss 0.04 on epoch=124
04/28/2022 07:12:11 - INFO - __main__ - Global step 250 Train loss 0.07 ACC 0.6875 on epoch=124
04/28/2022 07:12:13 - INFO - __main__ - Step 260 Global step 260 Train loss 0.03 on epoch=129
04/28/2022 07:12:16 - INFO - __main__ - Step 270 Global step 270 Train loss 0.06 on epoch=134
04/28/2022 07:12:18 - INFO - __main__ - Step 280 Global step 280 Train loss 0.02 on epoch=139
04/28/2022 07:12:21 - INFO - __main__ - Step 290 Global step 290 Train loss 0.04 on epoch=144
04/28/2022 07:12:23 - INFO - __main__ - Step 300 Global step 300 Train loss 0.01 on epoch=149
04/28/2022 07:12:24 - INFO - __main__ - Global step 300 Train loss 0.03 ACC 0.71875 on epoch=149
04/28/2022 07:12:24 - INFO - __main__ - Saving model with best ACC: 0.6875 -> 0.71875 on epoch=149, global_step=300
04/28/2022 07:12:26 - INFO - __main__ - Step 310 Global step 310 Train loss 0.01 on epoch=154
04/28/2022 07:12:29 - INFO - __main__ - Step 320 Global step 320 Train loss 0.04 on epoch=159
04/28/2022 07:12:31 - INFO - __main__ - Step 330 Global step 330 Train loss 0.06 on epoch=164
04/28/2022 07:12:34 - INFO - __main__ - Step 340 Global step 340 Train loss 0.05 on epoch=169
04/28/2022 07:12:37 - INFO - __main__ - Step 350 Global step 350 Train loss 0.02 on epoch=174
04/28/2022 07:12:37 - INFO - __main__ - Global step 350 Train loss 0.03 ACC 0.6875 on epoch=174
04/28/2022 07:12:40 - INFO - __main__ - Step 360 Global step 360 Train loss 0.02 on epoch=179
04/28/2022 07:12:42 - INFO - __main__ - Step 370 Global step 370 Train loss 0.05 on epoch=184
04/28/2022 07:12:45 - INFO - __main__ - Step 380 Global step 380 Train loss 0.03 on epoch=189
04/28/2022 07:12:47 - INFO - __main__ - Step 390 Global step 390 Train loss 0.01 on epoch=194
04/28/2022 07:12:50 - INFO - __main__ - Step 400 Global step 400 Train loss 0.02 on epoch=199
04/28/2022 07:12:51 - INFO - __main__ - Global step 400 Train loss 0.02 ACC 0.71875 on epoch=199
04/28/2022 07:12:53 - INFO - __main__ - Step 410 Global step 410 Train loss 0.01 on epoch=204
04/28/2022 07:12:56 - INFO - __main__ - Step 420 Global step 420 Train loss 0.00 on epoch=209
04/28/2022 07:12:58 - INFO - __main__ - Step 430 Global step 430 Train loss 0.03 on epoch=214
04/28/2022 07:13:01 - INFO - __main__ - Step 440 Global step 440 Train loss 0.02 on epoch=219
04/28/2022 07:13:03 - INFO - __main__ - Step 450 Global step 450 Train loss 0.01 on epoch=224
04/28/2022 07:13:04 - INFO - __main__ - Global step 450 Train loss 0.01 ACC 0.71875 on epoch=224
04/28/2022 07:13:07 - INFO - __main__ - Step 460 Global step 460 Train loss 0.08 on epoch=229
04/28/2022 07:13:09 - INFO - __main__ - Step 470 Global step 470 Train loss 0.03 on epoch=234
04/28/2022 07:13:12 - INFO - __main__ - Step 480 Global step 480 Train loss 0.03 on epoch=239
04/28/2022 07:13:14 - INFO - __main__ - Step 490 Global step 490 Train loss 0.03 on epoch=244
04/28/2022 07:13:17 - INFO - __main__ - Step 500 Global step 500 Train loss 0.02 on epoch=249
04/28/2022 07:13:17 - INFO - __main__ - Global step 500 Train loss 0.04 ACC 0.65625 on epoch=249
04/28/2022 07:13:20 - INFO - __main__ - Step 510 Global step 510 Train loss 0.04 on epoch=254
04/28/2022 07:13:22 - INFO - __main__ - Step 520 Global step 520 Train loss 0.05 on epoch=259
04/28/2022 07:13:25 - INFO - __main__ - Step 530 Global step 530 Train loss 0.01 on epoch=264
04/28/2022 07:13:27 - INFO - __main__ - Step 540 Global step 540 Train loss 0.01 on epoch=269
04/28/2022 07:13:30 - INFO - __main__ - Step 550 Global step 550 Train loss 0.01 on epoch=274
04/28/2022 07:13:31 - INFO - __main__ - Global step 550 Train loss 0.02 ACC 0.71875 on epoch=274
04/28/2022 07:13:33 - INFO - __main__ - Step 560 Global step 560 Train loss 0.00 on epoch=279
04/28/2022 07:13:36 - INFO - __main__ - Step 570 Global step 570 Train loss 0.01 on epoch=284
04/28/2022 07:13:38 - INFO - __main__ - Step 580 Global step 580 Train loss 0.01 on epoch=289
04/28/2022 07:13:41 - INFO - __main__ - Step 590 Global step 590 Train loss 0.02 on epoch=294
04/28/2022 07:13:43 - INFO - __main__ - Step 600 Global step 600 Train loss 0.00 on epoch=299
04/28/2022 07:13:44 - INFO - __main__ - Global step 600 Train loss 0.01 ACC 0.71875 on epoch=299
04/28/2022 07:13:46 - INFO - __main__ - Step 610 Global step 610 Train loss 0.01 on epoch=304
04/28/2022 07:13:49 - INFO - __main__ - Step 620 Global step 620 Train loss 0.01 on epoch=309
04/28/2022 07:13:52 - INFO - __main__ - Step 630 Global step 630 Train loss 0.00 on epoch=314
04/28/2022 07:13:54 - INFO - __main__ - Step 640 Global step 640 Train loss 0.01 on epoch=319
04/28/2022 07:13:56 - INFO - __main__ - Step 650 Global step 650 Train loss 0.00 on epoch=324
04/28/2022 07:13:57 - INFO - __main__ - Global step 650 Train loss 0.01 ACC 0.75 on epoch=324
04/28/2022 07:13:57 - INFO - __main__ - Saving model with best ACC: 0.71875 -> 0.75 on epoch=324, global_step=650
04/28/2022 07:14:00 - INFO - __main__ - Step 660 Global step 660 Train loss 0.01 on epoch=329
04/28/2022 07:14:02 - INFO - __main__ - Step 670 Global step 670 Train loss 0.00 on epoch=334
04/28/2022 07:14:05 - INFO - __main__ - Step 680 Global step 680 Train loss 0.00 on epoch=339
04/28/2022 07:14:07 - INFO - __main__ - Step 690 Global step 690 Train loss 0.00 on epoch=344
04/28/2022 07:14:10 - INFO - __main__ - Step 700 Global step 700 Train loss 0.00 on epoch=349
04/28/2022 07:14:10 - INFO - __main__ - Global step 700 Train loss 0.00 ACC 0.75 on epoch=349
04/28/2022 07:14:13 - INFO - __main__ - Step 710 Global step 710 Train loss 0.05 on epoch=354
04/28/2022 07:14:15 - INFO - __main__ - Step 720 Global step 720 Train loss 0.03 on epoch=359
04/28/2022 07:14:18 - INFO - __main__ - Step 730 Global step 730 Train loss 0.01 on epoch=364
04/28/2022 07:14:20 - INFO - __main__ - Step 740 Global step 740 Train loss 0.00 on epoch=369
04/28/2022 07:14:23 - INFO - __main__ - Step 750 Global step 750 Train loss 0.01 on epoch=374
04/28/2022 07:14:24 - INFO - __main__ - Global step 750 Train loss 0.02 ACC 0.8125 on epoch=374
04/28/2022 07:14:24 - INFO - __main__ - Saving model with best ACC: 0.75 -> 0.8125 on epoch=374, global_step=750
04/28/2022 07:14:26 - INFO - __main__ - Step 760 Global step 760 Train loss 0.00 on epoch=379
04/28/2022 07:14:29 - INFO - __main__ - Step 770 Global step 770 Train loss 0.01 on epoch=384
04/28/2022 07:14:31 - INFO - __main__ - Step 780 Global step 780 Train loss 0.00 on epoch=389
04/28/2022 07:14:34 - INFO - __main__ - Step 790 Global step 790 Train loss 0.05 on epoch=394
04/28/2022 07:14:36 - INFO - __main__ - Step 800 Global step 800 Train loss 0.00 on epoch=399
04/28/2022 07:14:37 - INFO - __main__ - Global step 800 Train loss 0.01 ACC 0.8125 on epoch=399
04/28/2022 07:14:40 - INFO - __main__ - Step 810 Global step 810 Train loss 0.00 on epoch=404
04/28/2022 07:14:42 - INFO - __main__ - Step 820 Global step 820 Train loss 0.00 on epoch=409
04/28/2022 07:14:45 - INFO - __main__ - Step 830 Global step 830 Train loss 0.00 on epoch=414
04/28/2022 07:14:47 - INFO - __main__ - Step 840 Global step 840 Train loss 0.01 on epoch=419
04/28/2022 07:14:49 - INFO - __main__ - Step 850 Global step 850 Train loss 0.00 on epoch=424
04/28/2022 07:14:51 - INFO - __main__ - Global step 850 Train loss 0.00 ACC 0.71875 on epoch=424
04/28/2022 07:14:53 - INFO - __main__ - Step 860 Global step 860 Train loss 0.01 on epoch=429
04/28/2022 07:14:56 - INFO - __main__ - Step 870 Global step 870 Train loss 0.02 on epoch=434
04/28/2022 07:14:58 - INFO - __main__ - Step 880 Global step 880 Train loss 0.01 on epoch=439
04/28/2022 07:15:01 - INFO - __main__ - Step 890 Global step 890 Train loss 0.01 on epoch=444
04/28/2022 07:15:03 - INFO - __main__ - Step 900 Global step 900 Train loss 0.01 on epoch=449
04/28/2022 07:15:04 - INFO - __main__ - Global step 900 Train loss 0.01 ACC 0.78125 on epoch=449
04/28/2022 07:15:06 - INFO - __main__ - Step 910 Global step 910 Train loss 0.00 on epoch=454
04/28/2022 07:15:09 - INFO - __main__ - Step 920 Global step 920 Train loss 0.00 on epoch=459
04/28/2022 07:15:11 - INFO - __main__ - Step 930 Global step 930 Train loss 0.00 on epoch=464
04/28/2022 07:15:14 - INFO - __main__ - Step 940 Global step 940 Train loss 0.00 on epoch=469
04/28/2022 07:15:16 - INFO - __main__ - Step 950 Global step 950 Train loss 0.00 on epoch=474
04/28/2022 07:15:17 - INFO - __main__ - Global step 950 Train loss 0.00 ACC 0.78125 on epoch=474
04/28/2022 07:15:20 - INFO - __main__ - Step 960 Global step 960 Train loss 0.00 on epoch=479
04/28/2022 07:15:22 - INFO - __main__ - Step 970 Global step 970 Train loss 0.02 on epoch=484
04/28/2022 07:15:25 - INFO - __main__ - Step 980 Global step 980 Train loss 0.00 on epoch=489
04/28/2022 07:15:27 - INFO - __main__ - Step 990 Global step 990 Train loss 0.00 on epoch=494
04/28/2022 07:15:30 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.00 on epoch=499
04/28/2022 07:15:30 - INFO - __main__ - Global step 1000 Train loss 0.01 ACC 0.78125 on epoch=499
04/28/2022 07:15:33 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.00 on epoch=504
04/28/2022 07:15:35 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.00 on epoch=509
04/28/2022 07:15:38 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.00 on epoch=514
04/28/2022 07:15:40 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.00 on epoch=519
04/28/2022 07:15:43 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.00 on epoch=524
04/28/2022 07:15:44 - INFO - __main__ - Global step 1050 Train loss 0.00 ACC 0.71875 on epoch=524
04/28/2022 07:15:46 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.00 on epoch=529
04/28/2022 07:15:49 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.00 on epoch=534
04/28/2022 07:15:51 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.00 on epoch=539
04/28/2022 07:15:54 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.00 on epoch=544
04/28/2022 07:15:56 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.00 on epoch=549
04/28/2022 07:15:57 - INFO - __main__ - Global step 1100 Train loss 0.00 ACC 0.75 on epoch=549
04/28/2022 07:16:00 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.00 on epoch=554
04/28/2022 07:16:02 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=559
04/28/2022 07:16:04 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=564
04/28/2022 07:16:07 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.00 on epoch=569
04/28/2022 07:16:09 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=574
04/28/2022 07:16:10 - INFO - __main__ - Global step 1150 Train loss 0.01 ACC 0.6875 on epoch=574
04/28/2022 07:16:13 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.01 on epoch=579
04/28/2022 07:16:15 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.00 on epoch=584
04/28/2022 07:16:18 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.00 on epoch=589
04/28/2022 07:16:20 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.00 on epoch=594
04/28/2022 07:16:23 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.00 on epoch=599
04/28/2022 07:16:24 - INFO - __main__ - Global step 1200 Train loss 0.00 ACC 0.6875 on epoch=599
04/28/2022 07:16:26 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.00 on epoch=604
04/28/2022 07:16:29 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=609
04/28/2022 07:16:31 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.00 on epoch=614
04/28/2022 07:16:34 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.00 on epoch=619
04/28/2022 07:16:36 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.01 on epoch=624
04/28/2022 07:16:37 - INFO - __main__ - Global step 1250 Train loss 0.00 ACC 0.65625 on epoch=624
04/28/2022 07:16:40 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.00 on epoch=629
04/28/2022 07:16:42 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.00 on epoch=634
04/28/2022 07:16:45 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.00 on epoch=639
04/28/2022 07:16:47 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.00 on epoch=644
04/28/2022 07:16:49 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.00 on epoch=649
04/28/2022 07:16:50 - INFO - __main__ - Global step 1300 Train loss 0.00 ACC 0.6875 on epoch=649
04/28/2022 07:16:53 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.00 on epoch=654
04/28/2022 07:16:55 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.00 on epoch=659
04/28/2022 07:16:58 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.00 on epoch=664
04/28/2022 07:17:00 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.00 on epoch=669
04/28/2022 07:17:03 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.00 on epoch=674
04/28/2022 07:17:04 - INFO - __main__ - Global step 1350 Train loss 0.00 ACC 0.625 on epoch=674
04/28/2022 07:17:06 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.03 on epoch=679
04/28/2022 07:17:09 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.02 on epoch=684
04/28/2022 07:17:11 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.00 on epoch=689
04/28/2022 07:17:14 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.00 on epoch=694
04/28/2022 07:17:16 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.00 on epoch=699
04/28/2022 07:17:17 - INFO - __main__ - Global step 1400 Train loss 0.01 ACC 0.71875 on epoch=699
04/28/2022 07:17:20 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=704
04/28/2022 07:17:22 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=709
04/28/2022 07:17:24 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.00 on epoch=714
04/28/2022 07:17:27 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=719
04/28/2022 07:17:29 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=724
04/28/2022 07:17:30 - INFO - __main__ - Global step 1450 Train loss 0.01 ACC 0.71875 on epoch=724
04/28/2022 07:17:33 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=729
04/28/2022 07:17:35 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=734
04/28/2022 07:17:38 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=739
04/28/2022 07:17:40 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=744
04/28/2022 07:17:43 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=749
04/28/2022 07:17:43 - INFO - __main__ - Global step 1500 Train loss 0.00 ACC 0.71875 on epoch=749
04/28/2022 07:17:46 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=754
04/28/2022 07:17:48 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=759
04/28/2022 07:17:51 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=764
04/28/2022 07:17:53 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=769
04/28/2022 07:17:56 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=774
04/28/2022 07:17:56 - INFO - __main__ - Global step 1550 Train loss 0.00 ACC 0.71875 on epoch=774
04/28/2022 07:17:59 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=779
04/28/2022 07:18:01 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=784
04/28/2022 07:18:04 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=789
04/28/2022 07:18:06 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=794
04/28/2022 07:18:09 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=799
04/28/2022 07:18:10 - INFO - __main__ - Global step 1600 Train loss 0.00 ACC 0.65625 on epoch=799
04/28/2022 07:18:12 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=804
04/28/2022 07:18:15 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=809
04/28/2022 07:18:17 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=814
04/28/2022 07:18:20 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=819
04/28/2022 07:18:22 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=824
04/28/2022 07:18:23 - INFO - __main__ - Global step 1650 Train loss 0.00 ACC 0.65625 on epoch=824
04/28/2022 07:18:26 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=829
04/28/2022 07:18:28 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=834
04/28/2022 07:18:31 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=839
04/28/2022 07:18:33 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=844
04/28/2022 07:18:36 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=849
04/28/2022 07:18:38 - INFO - __main__ - Global step 1700 Train loss 0.00 ACC 0.65625 on epoch=849
04/28/2022 07:18:41 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=854
04/28/2022 07:18:43 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=859
04/28/2022 07:18:46 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=864
04/28/2022 07:18:48 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=869
04/28/2022 07:18:51 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=874
04/28/2022 07:18:52 - INFO - __main__ - Global step 1750 Train loss 0.01 ACC 0.6875 on epoch=874
04/28/2022 07:18:54 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=879
04/28/2022 07:18:57 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=884
04/28/2022 07:18:59 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=889
04/28/2022 07:19:02 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=894
04/28/2022 07:19:04 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=899
04/28/2022 07:19:05 - INFO - __main__ - Global step 1800 Train loss 0.00 ACC 0.71875 on epoch=899
04/28/2022 07:19:08 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=904
04/28/2022 07:19:10 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=909
04/28/2022 07:19:13 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=914
04/28/2022 07:19:15 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=919
04/28/2022 07:19:18 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=924
04/28/2022 07:19:19 - INFO - __main__ - Global step 1850 Train loss 0.00 ACC 0.71875 on epoch=924
04/28/2022 07:19:22 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=929
04/28/2022 07:19:24 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=934
04/28/2022 07:19:27 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=939
04/28/2022 07:19:29 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=944
04/28/2022 07:19:31 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=949
04/28/2022 07:19:33 - INFO - __main__ - Global step 1900 Train loss 0.00 ACC 0.71875 on epoch=949
04/28/2022 07:19:35 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=954
04/28/2022 07:19:38 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=959
04/28/2022 07:19:40 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=964
04/28/2022 07:19:43 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=969
04/28/2022 07:19:45 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=974
04/28/2022 07:19:47 - INFO - __main__ - Global step 1950 Train loss 0.01 ACC 0.75 on epoch=974
04/28/2022 07:19:50 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=979
04/28/2022 07:19:52 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=984
04/28/2022 07:19:55 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=989
04/28/2022 07:19:57 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=994
04/28/2022 07:20:00 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=999
04/28/2022 07:20:01 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 07:20:01 - INFO - __main__ - Printing 3 examples
04/28/2022 07:20:01 - INFO - __main__ -  [wino_grande] Monica confided in Cynthia that she had prepared an Emergency Evacuation Kit for the storm.  _ was impressed. (A) Monica (B) Cynthia
04/28/2022 07:20:01 - INFO - __main__ - ['Cynthia']
04/28/2022 07:20:01 - INFO - __main__ -  [wino_grande] Rebecca had less grass in their yard than Elena because _ had more rabbits in their yard. (A) Rebecca (B) Elena
04/28/2022 07:20:01 - INFO - __main__ - ['Rebecca']
04/28/2022 07:20:01 - INFO - __main__ -  [wino_grande] Erin has a lot of dry skin on their arms and legs and Angela does not, because _ has been using lotion to keep their skin soft. (A) Erin (B) Angela
04/28/2022 07:20:01 - INFO - __main__ - ['Angela']
04/28/2022 07:20:01 - INFO - __main__ - Tokenizing Input ...
04/28/2022 07:20:01 - INFO - __main__ - Tokenizing Output ...
04/28/2022 07:20:01 - INFO - __main__ - Loaded 32 examples from train data
04/28/2022 07:20:01 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 07:20:01 - INFO - __main__ - Printing 3 examples
04/28/2022 07:20:01 - INFO - __main__ -  [wino_grande] Kyle always had ideas in the mind unlike Matthew, because _ was a horrible imaginative person. (A) Kyle (B) Matthew
04/28/2022 07:20:01 - INFO - __main__ - ['Matthew']
04/28/2022 07:20:01 - INFO - __main__ -  [wino_grande] Dennis showed endless dedication to the unappreciative Ian, so _ expended their energy for nothing. (A) Dennis (B) Ian
04/28/2022 07:20:01 - INFO - __main__ - ['Dennis']
04/28/2022 07:20:01 - INFO - __main__ -  [wino_grande] It was taking a long time for Emily to heal, so Jennifer gave her some antibiotics. _ is has a wound. (A) Emily (B) Jennifer
04/28/2022 07:20:01 - INFO - __main__ - ['Emily']
04/28/2022 07:20:01 - INFO - __main__ - Tokenizing Input ...
04/28/2022 07:20:01 - INFO - __main__ - Tokenizing Output ...
04/28/2022 07:20:01 - INFO - __main__ - Loaded 32 examples from dev data
04/28/2022 07:20:01 - INFO - __main__ - Global step 2000 Train loss 0.00 ACC 0.75 on epoch=999
04/28/2022 07:20:01 - INFO - __main__ - save last model!
04/28/2022 07:20:02 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
04/28/2022 07:20:02 - INFO - __main__ - Start tokenizing ... 1000 instances
04/28/2022 07:20:02 - INFO - __main__ - Printing 3 examples
04/28/2022 07:20:02 - INFO - __main__ -  [wino_grande] Sarah was a much better surgeon than Maria so _ always got the easier cases. (A) Sarah (B) Maria
04/28/2022 07:20:02 - INFO - __main__ - ['Maria']
04/28/2022 07:20:02 - INFO - __main__ -  [wino_grande] Sarah was a much better surgeon than Maria so _ always got the harder cases. (A) Sarah (B) Maria
04/28/2022 07:20:02 - INFO - __main__ - ['Sarah']
04/28/2022 07:20:02 - INFO - __main__ -  [wino_grande] They were worried the wine would ruin the bed and the blanket, but the _ was't ruined. (A) blanket (B) bed
04/28/2022 07:20:02 - INFO - __main__ - ['bed']
04/28/2022 07:20:02 - INFO - __main__ - Tokenizing Input ...
04/28/2022 07:20:02 - INFO - __main__ - Tokenizing Output ...
04/28/2022 07:20:03 - INFO - __main__ - Loaded 1000 examples from test data
04/28/2022 07:20:17 - INFO - __main__ - load prompt embedding from ckpt
04/28/2022 07:20:17 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/28/2022 07:20:18 - INFO - __main__ - Starting training!
04/28/2022 07:20:47 - INFO - __main__ - Saved prediction in models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-wino_grande/wino_grande_32_42_0.5_8_predictions.txt
04/28/2022 07:20:47 - INFO - __main__ - ACC on test data: 0.4810
04/28/2022 07:20:48 - INFO - __main__ - prefix=wino_grande_32_42, lr=0.5, bsz=8, dev_performance=0.8125, test_performance=0.481
04/28/2022 07:20:48 - INFO - __main__ - Running ... prefix=wino_grande_32_42, lr=0.4, bsz=8 ...
04/28/2022 07:20:49 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 07:20:49 - INFO - __main__ - Printing 3 examples
04/28/2022 07:20:49 - INFO - __main__ -  [wino_grande] Monica confided in Cynthia that she had prepared an Emergency Evacuation Kit for the storm.  _ was impressed. (A) Monica (B) Cynthia
04/28/2022 07:20:49 - INFO - __main__ - ['Cynthia']
04/28/2022 07:20:49 - INFO - __main__ -  [wino_grande] Rebecca had less grass in their yard than Elena because _ had more rabbits in their yard. (A) Rebecca (B) Elena
04/28/2022 07:20:49 - INFO - __main__ - ['Rebecca']
04/28/2022 07:20:49 - INFO - __main__ -  [wino_grande] Erin has a lot of dry skin on their arms and legs and Angela does not, because _ has been using lotion to keep their skin soft. (A) Erin (B) Angela
04/28/2022 07:20:49 - INFO - __main__ - ['Angela']
04/28/2022 07:20:49 - INFO - __main__ - Tokenizing Input ...
04/28/2022 07:20:49 - INFO - __main__ - Tokenizing Output ...
04/28/2022 07:20:49 - INFO - __main__ - Loaded 32 examples from train data
04/28/2022 07:20:49 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 07:20:49 - INFO - __main__ - Printing 3 examples
04/28/2022 07:20:49 - INFO - __main__ -  [wino_grande] Kyle always had ideas in the mind unlike Matthew, because _ was a horrible imaginative person. (A) Kyle (B) Matthew
04/28/2022 07:20:49 - INFO - __main__ - ['Matthew']
04/28/2022 07:20:49 - INFO - __main__ -  [wino_grande] Dennis showed endless dedication to the unappreciative Ian, so _ expended their energy for nothing. (A) Dennis (B) Ian
04/28/2022 07:20:49 - INFO - __main__ - ['Dennis']
04/28/2022 07:20:49 - INFO - __main__ -  [wino_grande] It was taking a long time for Emily to heal, so Jennifer gave her some antibiotics. _ is has a wound. (A) Emily (B) Jennifer
04/28/2022 07:20:49 - INFO - __main__ - ['Emily']
04/28/2022 07:20:49 - INFO - __main__ - Tokenizing Input ...
04/28/2022 07:20:49 - INFO - __main__ - Tokenizing Output ...
04/28/2022 07:20:49 - INFO - __main__ - Loaded 32 examples from dev data
04/28/2022 07:21:08 - INFO - __main__ - load prompt embedding from ckpt
04/28/2022 07:21:09 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/28/2022 07:21:09 - INFO - __main__ - Starting training!
04/28/2022 07:21:13 - INFO - __main__ - Step 10 Global step 10 Train loss 3.31 on epoch=4
04/28/2022 07:21:15 - INFO - __main__ - Step 20 Global step 20 Train loss 1.00 on epoch=9
04/28/2022 07:21:18 - INFO - __main__ - Step 30 Global step 30 Train loss 0.63 on epoch=14
04/28/2022 07:21:20 - INFO - __main__ - Step 40 Global step 40 Train loss 0.53 on epoch=19
04/28/2022 07:21:23 - INFO - __main__ - Step 50 Global step 50 Train loss 0.37 on epoch=24
04/28/2022 07:21:23 - INFO - __main__ - Global step 50 Train loss 1.17 ACC 0.5 on epoch=24
04/28/2022 07:21:23 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.5 on epoch=24, global_step=50
04/28/2022 07:21:26 - INFO - __main__ - Step 60 Global step 60 Train loss 0.42 on epoch=29
04/28/2022 07:21:28 - INFO - __main__ - Step 70 Global step 70 Train loss 0.30 on epoch=34
04/28/2022 07:21:31 - INFO - __main__ - Step 80 Global step 80 Train loss 0.33 on epoch=39
04/28/2022 07:21:33 - INFO - __main__ - Step 90 Global step 90 Train loss 0.25 on epoch=44
04/28/2022 07:21:36 - INFO - __main__ - Step 100 Global step 100 Train loss 0.14 on epoch=49
04/28/2022 07:21:37 - INFO - __main__ - Global step 100 Train loss 0.29 ACC 0.5625 on epoch=49
04/28/2022 07:21:37 - INFO - __main__ - Saving model with best ACC: 0.5 -> 0.5625 on epoch=49, global_step=100
04/28/2022 07:21:39 - INFO - __main__ - Step 110 Global step 110 Train loss 0.18 on epoch=54
04/28/2022 07:21:42 - INFO - __main__ - Step 120 Global step 120 Train loss 0.20 on epoch=59
04/28/2022 07:21:44 - INFO - __main__ - Step 130 Global step 130 Train loss 0.21 on epoch=64
04/28/2022 07:21:47 - INFO - __main__ - Step 140 Global step 140 Train loss 0.12 on epoch=69
04/28/2022 07:21:49 - INFO - __main__ - Step 150 Global step 150 Train loss 0.17 on epoch=74
04/28/2022 07:21:50 - INFO - __main__ - Global step 150 Train loss 0.18 ACC 0.59375 on epoch=74
04/28/2022 07:21:50 - INFO - __main__ - Saving model with best ACC: 0.5625 -> 0.59375 on epoch=74, global_step=150
04/28/2022 07:21:53 - INFO - __main__ - Step 160 Global step 160 Train loss 0.14 on epoch=79
04/28/2022 07:21:55 - INFO - __main__ - Step 170 Global step 170 Train loss 0.15 on epoch=84
04/28/2022 07:21:58 - INFO - __main__ - Step 180 Global step 180 Train loss 0.12 on epoch=89
04/28/2022 07:22:00 - INFO - __main__ - Step 190 Global step 190 Train loss 0.04 on epoch=94
04/28/2022 07:22:03 - INFO - __main__ - Step 200 Global step 200 Train loss 0.08 on epoch=99
04/28/2022 07:22:03 - INFO - __main__ - Global step 200 Train loss 0.11 ACC 0.65625 on epoch=99
04/28/2022 07:22:03 - INFO - __main__ - Saving model with best ACC: 0.59375 -> 0.65625 on epoch=99, global_step=200
04/28/2022 07:22:06 - INFO - __main__ - Step 210 Global step 210 Train loss 0.08 on epoch=104
04/28/2022 07:22:08 - INFO - __main__ - Step 220 Global step 220 Train loss 0.08 on epoch=109
04/28/2022 07:22:11 - INFO - __main__ - Step 230 Global step 230 Train loss 0.67 on epoch=114
04/28/2022 07:22:13 - INFO - __main__ - Step 240 Global step 240 Train loss 1.44 on epoch=119
04/28/2022 07:22:16 - INFO - __main__ - Step 250 Global step 250 Train loss 0.32 on epoch=124
04/28/2022 07:22:17 - INFO - __main__ - Global step 250 Train loss 0.52 ACC 0.625 on epoch=124
04/28/2022 07:22:19 - INFO - __main__ - Step 260 Global step 260 Train loss 0.22 on epoch=129
04/28/2022 07:22:22 - INFO - __main__ - Step 270 Global step 270 Train loss 0.16 on epoch=134
04/28/2022 07:22:24 - INFO - __main__ - Step 280 Global step 280 Train loss 0.11 on epoch=139
04/28/2022 07:22:27 - INFO - __main__ - Step 290 Global step 290 Train loss 0.14 on epoch=144
04/28/2022 07:22:29 - INFO - __main__ - Step 300 Global step 300 Train loss 0.11 on epoch=149
04/28/2022 07:22:30 - INFO - __main__ - Global step 300 Train loss 0.15 ACC 0.65625 on epoch=149
04/28/2022 07:22:32 - INFO - __main__ - Step 310 Global step 310 Train loss 0.09 on epoch=154
04/28/2022 07:22:35 - INFO - __main__ - Step 320 Global step 320 Train loss 0.08 on epoch=159
04/28/2022 07:22:37 - INFO - __main__ - Step 330 Global step 330 Train loss 0.09 on epoch=164
04/28/2022 07:22:40 - INFO - __main__ - Step 340 Global step 340 Train loss 0.09 on epoch=169
04/28/2022 07:22:42 - INFO - __main__ - Step 350 Global step 350 Train loss 0.06 on epoch=174
04/28/2022 07:22:43 - INFO - __main__ - Global step 350 Train loss 0.08 ACC 0.65625 on epoch=174
04/28/2022 07:22:46 - INFO - __main__ - Step 360 Global step 360 Train loss 0.06 on epoch=179
04/28/2022 07:22:48 - INFO - __main__ - Step 370 Global step 370 Train loss 0.10 on epoch=184
04/28/2022 07:22:51 - INFO - __main__ - Step 380 Global step 380 Train loss 0.06 on epoch=189
04/28/2022 07:22:53 - INFO - __main__ - Step 390 Global step 390 Train loss 0.07 on epoch=194
04/28/2022 07:22:56 - INFO - __main__ - Step 400 Global step 400 Train loss 0.09 on epoch=199
04/28/2022 07:22:57 - INFO - __main__ - Global step 400 Train loss 0.08 ACC 0.65625 on epoch=199
04/28/2022 07:22:59 - INFO - __main__ - Step 410 Global step 410 Train loss 0.04 on epoch=204
04/28/2022 07:23:02 - INFO - __main__ - Step 420 Global step 420 Train loss 0.04 on epoch=209
04/28/2022 07:23:04 - INFO - __main__ - Step 430 Global step 430 Train loss 0.06 on epoch=214
04/28/2022 07:23:07 - INFO - __main__ - Step 440 Global step 440 Train loss 0.08 on epoch=219
04/28/2022 07:23:09 - INFO - __main__ - Step 450 Global step 450 Train loss 0.07 on epoch=224
04/28/2022 07:23:10 - INFO - __main__ - Global step 450 Train loss 0.06 ACC 0.65625 on epoch=224
04/28/2022 07:23:12 - INFO - __main__ - Step 460 Global step 460 Train loss 0.06 on epoch=229
04/28/2022 07:23:15 - INFO - __main__ - Step 470 Global step 470 Train loss 0.03 on epoch=234
04/28/2022 07:23:17 - INFO - __main__ - Step 480 Global step 480 Train loss 0.05 on epoch=239
04/28/2022 07:23:20 - INFO - __main__ - Step 490 Global step 490 Train loss 0.02 on epoch=244
04/28/2022 07:23:22 - INFO - __main__ - Step 500 Global step 500 Train loss 0.05 on epoch=249
04/28/2022 07:23:23 - INFO - __main__ - Global step 500 Train loss 0.04 ACC 0.65625 on epoch=249
04/28/2022 07:23:25 - INFO - __main__ - Step 510 Global step 510 Train loss 0.06 on epoch=254
04/28/2022 07:23:28 - INFO - __main__ - Step 520 Global step 520 Train loss 0.07 on epoch=259
04/28/2022 07:23:30 - INFO - __main__ - Step 530 Global step 530 Train loss 0.04 on epoch=264
04/28/2022 07:23:33 - INFO - __main__ - Step 540 Global step 540 Train loss 0.05 on epoch=269
04/28/2022 07:23:35 - INFO - __main__ - Step 550 Global step 550 Train loss 0.06 on epoch=274
04/28/2022 07:23:36 - INFO - __main__ - Global step 550 Train loss 0.06 ACC 0.6875 on epoch=274
04/28/2022 07:23:36 - INFO - __main__ - Saving model with best ACC: 0.65625 -> 0.6875 on epoch=274, global_step=550
04/28/2022 07:23:39 - INFO - __main__ - Step 560 Global step 560 Train loss 0.04 on epoch=279
04/28/2022 07:23:41 - INFO - __main__ - Step 570 Global step 570 Train loss 0.07 on epoch=284
04/28/2022 07:23:43 - INFO - __main__ - Step 580 Global step 580 Train loss 0.03 on epoch=289
04/28/2022 07:23:46 - INFO - __main__ - Step 590 Global step 590 Train loss 0.09 on epoch=294
04/28/2022 07:23:48 - INFO - __main__ - Step 600 Global step 600 Train loss 0.04 on epoch=299
04/28/2022 07:23:49 - INFO - __main__ - Global step 600 Train loss 0.05 ACC 0.75 on epoch=299
04/28/2022 07:23:49 - INFO - __main__ - Saving model with best ACC: 0.6875 -> 0.75 on epoch=299, global_step=600
04/28/2022 07:23:52 - INFO - __main__ - Step 610 Global step 610 Train loss 0.04 on epoch=304
04/28/2022 07:23:54 - INFO - __main__ - Step 620 Global step 620 Train loss 0.05 on epoch=309
04/28/2022 07:23:57 - INFO - __main__ - Step 630 Global step 630 Train loss 0.03 on epoch=314
04/28/2022 07:23:59 - INFO - __main__ - Step 640 Global step 640 Train loss 0.02 on epoch=319
04/28/2022 07:24:02 - INFO - __main__ - Step 650 Global step 650 Train loss 0.02 on epoch=324
04/28/2022 07:24:02 - INFO - __main__ - Global step 650 Train loss 0.03 ACC 0.75 on epoch=324
04/28/2022 07:24:05 - INFO - __main__ - Step 660 Global step 660 Train loss 0.07 on epoch=329
04/28/2022 07:24:07 - INFO - __main__ - Step 670 Global step 670 Train loss 0.04 on epoch=334
04/28/2022 07:24:10 - INFO - __main__ - Step 680 Global step 680 Train loss 0.02 on epoch=339
04/28/2022 07:24:12 - INFO - __main__ - Step 690 Global step 690 Train loss 0.02 on epoch=344
04/28/2022 07:24:15 - INFO - __main__ - Step 700 Global step 700 Train loss 0.03 on epoch=349
04/28/2022 07:24:15 - INFO - __main__ - Global step 700 Train loss 0.03 ACC 0.71875 on epoch=349
04/28/2022 07:24:18 - INFO - __main__ - Step 710 Global step 710 Train loss 0.01 on epoch=354
04/28/2022 07:24:20 - INFO - __main__ - Step 720 Global step 720 Train loss 0.01 on epoch=359
04/28/2022 07:24:23 - INFO - __main__ - Step 730 Global step 730 Train loss 0.01 on epoch=364
04/28/2022 07:24:25 - INFO - __main__ - Step 740 Global step 740 Train loss 0.04 on epoch=369
04/28/2022 07:24:28 - INFO - __main__ - Step 750 Global step 750 Train loss 0.02 on epoch=374
04/28/2022 07:24:29 - INFO - __main__ - Global step 750 Train loss 0.02 ACC 0.6875 on epoch=374
04/28/2022 07:24:31 - INFO - __main__ - Step 760 Global step 760 Train loss 0.04 on epoch=379
04/28/2022 07:24:34 - INFO - __main__ - Step 770 Global step 770 Train loss 0.02 on epoch=384
04/28/2022 07:24:36 - INFO - __main__ - Step 780 Global step 780 Train loss 0.06 on epoch=389
04/28/2022 07:24:39 - INFO - __main__ - Step 790 Global step 790 Train loss 0.06 on epoch=394
04/28/2022 07:24:41 - INFO - __main__ - Step 800 Global step 800 Train loss 0.02 on epoch=399
04/28/2022 07:24:42 - INFO - __main__ - Global step 800 Train loss 0.04 ACC 0.71875 on epoch=399
04/28/2022 07:24:44 - INFO - __main__ - Step 810 Global step 810 Train loss 0.02 on epoch=404
04/28/2022 07:24:47 - INFO - __main__ - Step 820 Global step 820 Train loss 0.01 on epoch=409
04/28/2022 07:24:49 - INFO - __main__ - Step 830 Global step 830 Train loss 0.02 on epoch=414
04/28/2022 07:24:52 - INFO - __main__ - Step 840 Global step 840 Train loss 0.01 on epoch=419
04/28/2022 07:24:54 - INFO - __main__ - Step 850 Global step 850 Train loss 0.02 on epoch=424
04/28/2022 07:24:55 - INFO - __main__ - Global step 850 Train loss 0.01 ACC 0.71875 on epoch=424
04/28/2022 07:24:58 - INFO - __main__ - Step 860 Global step 860 Train loss 0.03 on epoch=429
04/28/2022 07:25:00 - INFO - __main__ - Step 870 Global step 870 Train loss 0.03 on epoch=434
04/28/2022 07:25:02 - INFO - __main__ - Step 880 Global step 880 Train loss 0.04 on epoch=439
04/28/2022 07:25:05 - INFO - __main__ - Step 890 Global step 890 Train loss 0.02 on epoch=444
04/28/2022 07:25:07 - INFO - __main__ - Step 900 Global step 900 Train loss 0.01 on epoch=449
04/28/2022 07:25:08 - INFO - __main__ - Global step 900 Train loss 0.03 ACC 0.6875 on epoch=449
04/28/2022 07:25:11 - INFO - __main__ - Step 910 Global step 910 Train loss 0.07 on epoch=454
04/28/2022 07:25:13 - INFO - __main__ - Step 920 Global step 920 Train loss 0.05 on epoch=459
04/28/2022 07:25:16 - INFO - __main__ - Step 930 Global step 930 Train loss 0.03 on epoch=464
04/28/2022 07:25:18 - INFO - __main__ - Step 940 Global step 940 Train loss 0.01 on epoch=469
04/28/2022 07:25:21 - INFO - __main__ - Step 950 Global step 950 Train loss 0.03 on epoch=474
04/28/2022 07:25:21 - INFO - __main__ - Global step 950 Train loss 0.04 ACC 0.6875 on epoch=474
04/28/2022 07:25:24 - INFO - __main__ - Step 960 Global step 960 Train loss 0.03 on epoch=479
04/28/2022 07:25:26 - INFO - __main__ - Step 970 Global step 970 Train loss 0.01 on epoch=484
04/28/2022 07:25:29 - INFO - __main__ - Step 980 Global step 980 Train loss 0.01 on epoch=489
04/28/2022 07:25:31 - INFO - __main__ - Step 990 Global step 990 Train loss 0.02 on epoch=494
04/28/2022 07:25:34 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.03 on epoch=499
04/28/2022 07:25:36 - INFO - __main__ - Global step 1000 Train loss 0.02 ACC 0.71875 on epoch=499
04/28/2022 07:25:39 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.02 on epoch=504
04/28/2022 07:25:41 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.01 on epoch=509
04/28/2022 07:25:44 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.02 on epoch=514
04/28/2022 07:25:46 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.01 on epoch=519
04/28/2022 07:25:49 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.02 on epoch=524
04/28/2022 07:25:51 - INFO - __main__ - Global step 1050 Train loss 0.02 ACC 0.6875 on epoch=524
04/28/2022 07:25:54 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.01 on epoch=529
04/28/2022 07:25:56 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.01 on epoch=534
04/28/2022 07:25:59 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.02 on epoch=539
04/28/2022 07:26:01 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.01 on epoch=544
04/28/2022 07:26:04 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.01 on epoch=549
04/28/2022 07:26:04 - INFO - __main__ - Global step 1100 Train loss 0.01 ACC 0.71875 on epoch=549
04/28/2022 07:26:07 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.03 on epoch=554
04/28/2022 07:26:09 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.02 on epoch=559
04/28/2022 07:26:12 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=564
04/28/2022 07:26:14 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.02 on epoch=569
04/28/2022 07:26:17 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=574
04/28/2022 07:26:17 - INFO - __main__ - Global step 1150 Train loss 0.02 ACC 0.71875 on epoch=574
04/28/2022 07:26:20 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.02 on epoch=579
04/28/2022 07:26:22 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.00 on epoch=584
04/28/2022 07:26:25 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.00 on epoch=589
04/28/2022 07:26:27 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.02 on epoch=594
04/28/2022 07:26:30 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.00 on epoch=599
04/28/2022 07:26:31 - INFO - __main__ - Global step 1200 Train loss 0.01 ACC 0.71875 on epoch=599
04/28/2022 07:26:33 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.00 on epoch=604
04/28/2022 07:26:35 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.00 on epoch=609
04/28/2022 07:26:38 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=614
04/28/2022 07:26:40 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.00 on epoch=619
04/28/2022 07:26:43 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.00 on epoch=624
04/28/2022 07:26:44 - INFO - __main__ - Global step 1250 Train loss 0.01 ACC 0.71875 on epoch=624
04/28/2022 07:26:46 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.00 on epoch=629
04/28/2022 07:26:49 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.00 on epoch=634
04/28/2022 07:26:51 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.00 on epoch=639
04/28/2022 07:26:54 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.04 on epoch=644
04/28/2022 07:26:56 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=649
04/28/2022 07:26:57 - INFO - __main__ - Global step 1300 Train loss 0.01 ACC 0.75 on epoch=649
04/28/2022 07:26:59 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=654
04/28/2022 07:27:02 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.00 on epoch=659
04/28/2022 07:27:04 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.00 on epoch=664
04/28/2022 07:27:07 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=669
04/28/2022 07:27:09 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=674
04/28/2022 07:27:10 - INFO - __main__ - Global step 1350 Train loss 0.01 ACC 0.75 on epoch=674
04/28/2022 07:27:12 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.00 on epoch=679
04/28/2022 07:27:15 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=684
04/28/2022 07:27:17 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.00 on epoch=689
04/28/2022 07:27:20 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=694
04/28/2022 07:27:22 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.03 on epoch=699
04/28/2022 07:27:23 - INFO - __main__ - Global step 1400 Train loss 0.01 ACC 0.75 on epoch=699
04/28/2022 07:27:26 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=704
04/28/2022 07:27:28 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=709
04/28/2022 07:27:31 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.02 on epoch=714
04/28/2022 07:27:33 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=719
04/28/2022 07:27:36 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.05 on epoch=724
04/28/2022 07:27:36 - INFO - __main__ - Global step 1450 Train loss 0.02 ACC 0.75 on epoch=724
04/28/2022 07:27:39 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=729
04/28/2022 07:27:41 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.03 on epoch=734
04/28/2022 07:27:44 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=739
04/28/2022 07:27:46 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=744
04/28/2022 07:27:49 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.02 on epoch=749
04/28/2022 07:27:49 - INFO - __main__ - Global step 1500 Train loss 0.01 ACC 0.75 on epoch=749
04/28/2022 07:27:52 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=754
04/28/2022 07:27:54 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=759
04/28/2022 07:27:57 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=764
04/28/2022 07:27:59 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=769
04/28/2022 07:28:02 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=774
04/28/2022 07:28:03 - INFO - __main__ - Global step 1550 Train loss 0.01 ACC 0.71875 on epoch=774
04/28/2022 07:28:05 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=779
04/28/2022 07:28:08 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=784
04/28/2022 07:28:10 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=789
04/28/2022 07:28:13 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=794
04/28/2022 07:28:15 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=799
04/28/2022 07:28:16 - INFO - __main__ - Global step 1600 Train loss 0.00 ACC 0.75 on epoch=799
04/28/2022 07:28:19 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=804
04/28/2022 07:28:21 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=809
04/28/2022 07:28:24 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=814
04/28/2022 07:28:26 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=819
04/28/2022 07:28:29 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=824
04/28/2022 07:28:30 - INFO - __main__ - Global step 1650 Train loss 0.00 ACC 0.75 on epoch=824
04/28/2022 07:28:32 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=829
04/28/2022 07:28:35 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=834
04/28/2022 07:28:37 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=839
04/28/2022 07:28:40 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=844
04/28/2022 07:28:42 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=849
04/28/2022 07:28:44 - INFO - __main__ - Global step 1700 Train loss 0.01 ACC 0.71875 on epoch=849
04/28/2022 07:28:47 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=854
04/28/2022 07:28:49 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=859
04/28/2022 07:28:52 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=864
04/28/2022 07:28:54 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=869
04/28/2022 07:28:57 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=874
04/28/2022 07:28:58 - INFO - __main__ - Global step 1750 Train loss 0.00 ACC 0.75 on epoch=874
04/28/2022 07:29:00 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=879
04/28/2022 07:29:03 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=884
04/28/2022 07:29:05 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=889
04/28/2022 07:29:08 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=894
04/28/2022 07:29:10 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=899
04/28/2022 07:29:12 - INFO - __main__ - Global step 1800 Train loss 0.00 ACC 0.71875 on epoch=899
04/28/2022 07:29:15 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=904
04/28/2022 07:29:17 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=909
04/28/2022 07:29:20 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=914
04/28/2022 07:29:22 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=919
04/28/2022 07:29:24 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=924
04/28/2022 07:29:26 - INFO - __main__ - Global step 1850 Train loss 0.01 ACC 0.75 on epoch=924
04/28/2022 07:29:29 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=929
04/28/2022 07:29:31 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=934
04/28/2022 07:29:34 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=939
04/28/2022 07:29:36 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=944
04/28/2022 07:29:39 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=949
04/28/2022 07:29:41 - INFO - __main__ - Global step 1900 Train loss 0.00 ACC 0.75 on epoch=949
04/28/2022 07:29:43 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=954
04/28/2022 07:29:46 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=959
04/28/2022 07:29:48 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=964
04/28/2022 07:29:51 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=969
04/28/2022 07:29:53 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=974
04/28/2022 07:29:55 - INFO - __main__ - Global step 1950 Train loss 0.00 ACC 0.71875 on epoch=974
04/28/2022 07:29:57 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=979
04/28/2022 07:30:00 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=984
04/28/2022 07:30:02 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=989
04/28/2022 07:30:05 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=994
04/28/2022 07:30:07 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=999
04/28/2022 07:30:09 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 07:30:09 - INFO - __main__ - Printing 3 examples
04/28/2022 07:30:09 - INFO - __main__ -  [wino_grande] Monica confided in Cynthia that she had prepared an Emergency Evacuation Kit for the storm.  _ was impressed. (A) Monica (B) Cynthia
04/28/2022 07:30:09 - INFO - __main__ - ['Cynthia']
04/28/2022 07:30:09 - INFO - __main__ -  [wino_grande] Rebecca had less grass in their yard than Elena because _ had more rabbits in their yard. (A) Rebecca (B) Elena
04/28/2022 07:30:09 - INFO - __main__ - ['Rebecca']
04/28/2022 07:30:09 - INFO - __main__ -  [wino_grande] Erin has a lot of dry skin on their arms and legs and Angela does not, because _ has been using lotion to keep their skin soft. (A) Erin (B) Angela
04/28/2022 07:30:09 - INFO - __main__ - ['Angela']
04/28/2022 07:30:09 - INFO - __main__ - Tokenizing Input ...
04/28/2022 07:30:09 - INFO - __main__ - Tokenizing Output ...
04/28/2022 07:30:09 - INFO - __main__ - Loaded 32 examples from train data
04/28/2022 07:30:09 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 07:30:09 - INFO - __main__ - Printing 3 examples
04/28/2022 07:30:09 - INFO - __main__ -  [wino_grande] Kyle always had ideas in the mind unlike Matthew, because _ was a horrible imaginative person. (A) Kyle (B) Matthew
04/28/2022 07:30:09 - INFO - __main__ - ['Matthew']
04/28/2022 07:30:09 - INFO - __main__ -  [wino_grande] Dennis showed endless dedication to the unappreciative Ian, so _ expended their energy for nothing. (A) Dennis (B) Ian
04/28/2022 07:30:09 - INFO - __main__ - ['Dennis']
04/28/2022 07:30:09 - INFO - __main__ -  [wino_grande] It was taking a long time for Emily to heal, so Jennifer gave her some antibiotics. _ is has a wound. (A) Emily (B) Jennifer
04/28/2022 07:30:09 - INFO - __main__ - ['Emily']
04/28/2022 07:30:09 - INFO - __main__ - Tokenizing Input ...
04/28/2022 07:30:09 - INFO - __main__ - Tokenizing Output ...
04/28/2022 07:30:09 - INFO - __main__ - Loaded 32 examples from dev data
04/28/2022 07:30:10 - INFO - __main__ - Global step 2000 Train loss 0.00 ACC 0.71875 on epoch=999
04/28/2022 07:30:10 - INFO - __main__ - save last model!
04/28/2022 07:30:10 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
04/28/2022 07:30:10 - INFO - __main__ - Start tokenizing ... 1000 instances
04/28/2022 07:30:10 - INFO - __main__ - Printing 3 examples
04/28/2022 07:30:10 - INFO - __main__ -  [wino_grande] Sarah was a much better surgeon than Maria so _ always got the easier cases. (A) Sarah (B) Maria
04/28/2022 07:30:10 - INFO - __main__ - ['Maria']
04/28/2022 07:30:10 - INFO - __main__ -  [wino_grande] Sarah was a much better surgeon than Maria so _ always got the harder cases. (A) Sarah (B) Maria
04/28/2022 07:30:10 - INFO - __main__ - ['Sarah']
04/28/2022 07:30:10 - INFO - __main__ -  [wino_grande] They were worried the wine would ruin the bed and the blanket, but the _ was't ruined. (A) blanket (B) bed
04/28/2022 07:30:10 - INFO - __main__ - ['bed']
04/28/2022 07:30:10 - INFO - __main__ - Tokenizing Input ...
04/28/2022 07:30:10 - INFO - __main__ - Tokenizing Output ...
04/28/2022 07:30:11 - INFO - __main__ - Loaded 1000 examples from test data
04/28/2022 07:30:28 - INFO - __main__ - load prompt embedding from ckpt
04/28/2022 07:30:28 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/28/2022 07:30:28 - INFO - __main__ - Starting training!
04/28/2022 07:31:34 - INFO - __main__ - Saved prediction in models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-wino_grande/wino_grande_32_42_0.4_8_predictions.txt
04/28/2022 07:31:34 - INFO - __main__ - ACC on test data: 0.4790
04/28/2022 07:31:35 - INFO - __main__ - prefix=wino_grande_32_42, lr=0.4, bsz=8, dev_performance=0.75, test_performance=0.479
04/28/2022 07:31:35 - INFO - __main__ - Running ... prefix=wino_grande_32_42, lr=0.3, bsz=8 ...
04/28/2022 07:31:36 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 07:31:36 - INFO - __main__ - Printing 3 examples
04/28/2022 07:31:36 - INFO - __main__ -  [wino_grande] Monica confided in Cynthia that she had prepared an Emergency Evacuation Kit for the storm.  _ was impressed. (A) Monica (B) Cynthia
04/28/2022 07:31:36 - INFO - __main__ - ['Cynthia']
04/28/2022 07:31:36 - INFO - __main__ -  [wino_grande] Rebecca had less grass in their yard than Elena because _ had more rabbits in their yard. (A) Rebecca (B) Elena
04/28/2022 07:31:36 - INFO - __main__ - ['Rebecca']
04/28/2022 07:31:36 - INFO - __main__ -  [wino_grande] Erin has a lot of dry skin on their arms and legs and Angela does not, because _ has been using lotion to keep their skin soft. (A) Erin (B) Angela
04/28/2022 07:31:36 - INFO - __main__ - ['Angela']
04/28/2022 07:31:36 - INFO - __main__ - Tokenizing Input ...
04/28/2022 07:31:36 - INFO - __main__ - Tokenizing Output ...
04/28/2022 07:31:36 - INFO - __main__ - Loaded 32 examples from train data
04/28/2022 07:31:36 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 07:31:36 - INFO - __main__ - Printing 3 examples
04/28/2022 07:31:36 - INFO - __main__ -  [wino_grande] Kyle always had ideas in the mind unlike Matthew, because _ was a horrible imaginative person. (A) Kyle (B) Matthew
04/28/2022 07:31:36 - INFO - __main__ - ['Matthew']
04/28/2022 07:31:36 - INFO - __main__ -  [wino_grande] Dennis showed endless dedication to the unappreciative Ian, so _ expended their energy for nothing. (A) Dennis (B) Ian
04/28/2022 07:31:36 - INFO - __main__ - ['Dennis']
04/28/2022 07:31:36 - INFO - __main__ -  [wino_grande] It was taking a long time for Emily to heal, so Jennifer gave her some antibiotics. _ is has a wound. (A) Emily (B) Jennifer
04/28/2022 07:31:36 - INFO - __main__ - ['Emily']
04/28/2022 07:31:36 - INFO - __main__ - Tokenizing Input ...
04/28/2022 07:31:36 - INFO - __main__ - Tokenizing Output ...
04/28/2022 07:31:36 - INFO - __main__ - Loaded 32 examples from dev data
04/28/2022 07:31:55 - INFO - __main__ - load prompt embedding from ckpt
04/28/2022 07:31:55 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/28/2022 07:31:55 - INFO - __main__ - Starting training!
04/28/2022 07:31:58 - INFO - __main__ - Step 10 Global step 10 Train loss 3.46 on epoch=4
04/28/2022 07:32:01 - INFO - __main__ - Step 20 Global step 20 Train loss 1.26 on epoch=9
04/28/2022 07:32:03 - INFO - __main__ - Step 30 Global step 30 Train loss 0.61 on epoch=14
04/28/2022 07:32:06 - INFO - __main__ - Step 40 Global step 40 Train loss 0.71 on epoch=19
04/28/2022 07:32:09 - INFO - __main__ - Step 50 Global step 50 Train loss 0.52 on epoch=24
04/28/2022 07:32:09 - INFO - __main__ - Global step 50 Train loss 1.31 ACC 0.46875 on epoch=24
04/28/2022 07:32:09 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.46875 on epoch=24, global_step=50
04/28/2022 07:32:12 - INFO - __main__ - Step 60 Global step 60 Train loss 0.43 on epoch=29
04/28/2022 07:32:14 - INFO - __main__ - Step 70 Global step 70 Train loss 0.45 on epoch=34
04/28/2022 07:32:17 - INFO - __main__ - Step 80 Global step 80 Train loss 0.31 on epoch=39
04/28/2022 07:32:19 - INFO - __main__ - Step 90 Global step 90 Train loss 0.23 on epoch=44
04/28/2022 07:32:22 - INFO - __main__ - Step 100 Global step 100 Train loss 0.32 on epoch=49
04/28/2022 07:32:23 - INFO - __main__ - Global step 100 Train loss 0.35 ACC 0.46875 on epoch=49
04/28/2022 07:32:25 - INFO - __main__ - Step 110 Global step 110 Train loss 0.23 on epoch=54
04/28/2022 07:32:28 - INFO - __main__ - Step 120 Global step 120 Train loss 0.22 on epoch=59
04/28/2022 07:32:30 - INFO - __main__ - Step 130 Global step 130 Train loss 0.25 on epoch=64
04/28/2022 07:32:33 - INFO - __main__ - Step 140 Global step 140 Train loss 0.22 on epoch=69
04/28/2022 07:32:35 - INFO - __main__ - Step 150 Global step 150 Train loss 0.10 on epoch=74
04/28/2022 07:32:36 - INFO - __main__ - Global step 150 Train loss 0.20 ACC 0.5625 on epoch=74
04/28/2022 07:32:36 - INFO - __main__ - Saving model with best ACC: 0.46875 -> 0.5625 on epoch=74, global_step=150
04/28/2022 07:32:38 - INFO - __main__ - Step 160 Global step 160 Train loss 0.15 on epoch=79
04/28/2022 07:32:41 - INFO - __main__ - Step 170 Global step 170 Train loss 0.13 on epoch=84
04/28/2022 07:32:43 - INFO - __main__ - Step 180 Global step 180 Train loss 0.13 on epoch=89
04/28/2022 07:32:46 - INFO - __main__ - Step 190 Global step 190 Train loss 0.16 on epoch=94
04/28/2022 07:32:48 - INFO - __main__ - Step 200 Global step 200 Train loss 0.09 on epoch=99
04/28/2022 07:32:49 - INFO - __main__ - Global step 200 Train loss 0.13 ACC 0.65625 on epoch=99
04/28/2022 07:32:49 - INFO - __main__ - Saving model with best ACC: 0.5625 -> 0.65625 on epoch=99, global_step=200
04/28/2022 07:32:52 - INFO - __main__ - Step 210 Global step 210 Train loss 0.08 on epoch=104
04/28/2022 07:32:54 - INFO - __main__ - Step 220 Global step 220 Train loss 0.08 on epoch=109
04/28/2022 07:32:57 - INFO - __main__ - Step 230 Global step 230 Train loss 0.07 on epoch=114
04/28/2022 07:32:59 - INFO - __main__ - Step 240 Global step 240 Train loss 0.08 on epoch=119
04/28/2022 07:33:02 - INFO - __main__ - Step 250 Global step 250 Train loss 0.14 on epoch=124
04/28/2022 07:33:02 - INFO - __main__ - Global step 250 Train loss 0.09 ACC 0.59375 on epoch=124
04/28/2022 07:33:05 - INFO - __main__ - Step 260 Global step 260 Train loss 0.16 on epoch=129
04/28/2022 07:33:07 - INFO - __main__ - Step 270 Global step 270 Train loss 0.10 on epoch=134
04/28/2022 07:33:10 - INFO - __main__ - Step 280 Global step 280 Train loss 0.07 on epoch=139
04/28/2022 07:33:12 - INFO - __main__ - Step 290 Global step 290 Train loss 0.13 on epoch=144
04/28/2022 07:33:15 - INFO - __main__ - Step 300 Global step 300 Train loss 0.04 on epoch=149
04/28/2022 07:33:16 - INFO - __main__ - Global step 300 Train loss 0.10 ACC 0.65625 on epoch=149
04/28/2022 07:33:18 - INFO - __main__ - Step 310 Global step 310 Train loss 0.07 on epoch=154
04/28/2022 07:33:21 - INFO - __main__ - Step 320 Global step 320 Train loss 0.05 on epoch=159
04/28/2022 07:33:23 - INFO - __main__ - Step 330 Global step 330 Train loss 0.08 on epoch=164
04/28/2022 07:33:26 - INFO - __main__ - Step 340 Global step 340 Train loss 0.02 on epoch=169
04/28/2022 07:33:28 - INFO - __main__ - Step 350 Global step 350 Train loss 0.08 on epoch=174
04/28/2022 07:33:29 - INFO - __main__ - Global step 350 Train loss 0.06 ACC 0.65625 on epoch=174
04/28/2022 07:33:31 - INFO - __main__ - Step 360 Global step 360 Train loss 0.02 on epoch=179
04/28/2022 07:33:34 - INFO - __main__ - Step 370 Global step 370 Train loss 0.05 on epoch=184
04/28/2022 07:33:36 - INFO - __main__ - Step 380 Global step 380 Train loss 0.05 on epoch=189
04/28/2022 07:33:39 - INFO - __main__ - Step 390 Global step 390 Train loss 0.04 on epoch=194
04/28/2022 07:33:41 - INFO - __main__ - Step 400 Global step 400 Train loss 0.02 on epoch=199
04/28/2022 07:33:42 - INFO - __main__ - Global step 400 Train loss 0.04 ACC 0.65625 on epoch=199
04/28/2022 07:33:45 - INFO - __main__ - Step 410 Global step 410 Train loss 0.06 on epoch=204
04/28/2022 07:33:47 - INFO - __main__ - Step 420 Global step 420 Train loss 0.02 on epoch=209
04/28/2022 07:33:50 - INFO - __main__ - Step 430 Global step 430 Train loss 0.02 on epoch=214
04/28/2022 07:33:52 - INFO - __main__ - Step 440 Global step 440 Train loss 0.09 on epoch=219
04/28/2022 07:33:55 - INFO - __main__ - Step 450 Global step 450 Train loss 0.08 on epoch=224
04/28/2022 07:33:56 - INFO - __main__ - Global step 450 Train loss 0.05 ACC 0.6875 on epoch=224
04/28/2022 07:33:56 - INFO - __main__ - Saving model with best ACC: 0.65625 -> 0.6875 on epoch=224, global_step=450
04/28/2022 07:33:58 - INFO - __main__ - Step 460 Global step 460 Train loss 0.03 on epoch=229
04/28/2022 07:34:01 - INFO - __main__ - Step 470 Global step 470 Train loss 0.05 on epoch=234
04/28/2022 07:34:03 - INFO - __main__ - Step 480 Global step 480 Train loss 0.03 on epoch=239
04/28/2022 07:34:06 - INFO - __main__ - Step 490 Global step 490 Train loss 0.05 on epoch=244
04/28/2022 07:34:08 - INFO - __main__ - Step 500 Global step 500 Train loss 0.01 on epoch=249
04/28/2022 07:34:09 - INFO - __main__ - Global step 500 Train loss 0.03 ACC 0.6875 on epoch=249
04/28/2022 07:34:12 - INFO - __main__ - Step 510 Global step 510 Train loss 0.08 on epoch=254
04/28/2022 07:34:14 - INFO - __main__ - Step 520 Global step 520 Train loss 0.06 on epoch=259
04/28/2022 07:34:17 - INFO - __main__ - Step 530 Global step 530 Train loss 0.02 on epoch=264
04/28/2022 07:34:19 - INFO - __main__ - Step 540 Global step 540 Train loss 0.04 on epoch=269
04/28/2022 07:34:22 - INFO - __main__ - Step 550 Global step 550 Train loss 0.01 on epoch=274
04/28/2022 07:34:22 - INFO - __main__ - Global step 550 Train loss 0.04 ACC 0.6875 on epoch=274
04/28/2022 07:34:25 - INFO - __main__ - Step 560 Global step 560 Train loss 0.03 on epoch=279
04/28/2022 07:34:27 - INFO - __main__ - Step 570 Global step 570 Train loss 0.01 on epoch=284
04/28/2022 07:34:30 - INFO - __main__ - Step 580 Global step 580 Train loss 0.04 on epoch=289
04/28/2022 07:34:32 - INFO - __main__ - Step 590 Global step 590 Train loss 0.01 on epoch=294
04/28/2022 07:34:35 - INFO - __main__ - Step 600 Global step 600 Train loss 0.01 on epoch=299
04/28/2022 07:34:36 - INFO - __main__ - Global step 600 Train loss 0.02 ACC 0.6875 on epoch=299
04/28/2022 07:34:38 - INFO - __main__ - Step 610 Global step 610 Train loss 0.00 on epoch=304
04/28/2022 07:34:41 - INFO - __main__ - Step 620 Global step 620 Train loss 0.04 on epoch=309
04/28/2022 07:34:43 - INFO - __main__ - Step 630 Global step 630 Train loss 0.01 on epoch=314
04/28/2022 07:34:46 - INFO - __main__ - Step 640 Global step 640 Train loss 0.03 on epoch=319
04/28/2022 07:34:48 - INFO - __main__ - Step 650 Global step 650 Train loss 0.00 on epoch=324
04/28/2022 07:34:49 - INFO - __main__ - Global step 650 Train loss 0.02 ACC 0.71875 on epoch=324
04/28/2022 07:34:49 - INFO - __main__ - Saving model with best ACC: 0.6875 -> 0.71875 on epoch=324, global_step=650
04/28/2022 07:34:52 - INFO - __main__ - Step 660 Global step 660 Train loss 0.01 on epoch=329
04/28/2022 07:34:54 - INFO - __main__ - Step 670 Global step 670 Train loss 0.14 on epoch=334
04/28/2022 07:34:57 - INFO - __main__ - Step 680 Global step 680 Train loss 0.00 on epoch=339
04/28/2022 07:34:59 - INFO - __main__ - Step 690 Global step 690 Train loss 0.02 on epoch=344
04/28/2022 07:35:02 - INFO - __main__ - Step 700 Global step 700 Train loss 0.02 on epoch=349
04/28/2022 07:35:04 - INFO - __main__ - Global step 700 Train loss 0.04 ACC 0.6875 on epoch=349
04/28/2022 07:35:06 - INFO - __main__ - Step 710 Global step 710 Train loss 0.01 on epoch=354
04/28/2022 07:35:09 - INFO - __main__ - Step 720 Global step 720 Train loss 0.01 on epoch=359
04/28/2022 07:35:11 - INFO - __main__ - Step 730 Global step 730 Train loss 0.04 on epoch=364
04/28/2022 07:35:14 - INFO - __main__ - Step 740 Global step 740 Train loss 0.01 on epoch=369
04/28/2022 07:35:16 - INFO - __main__ - Step 750 Global step 750 Train loss 0.01 on epoch=374
04/28/2022 07:35:17 - INFO - __main__ - Global step 750 Train loss 0.02 ACC 0.625 on epoch=374
04/28/2022 07:35:20 - INFO - __main__ - Step 760 Global step 760 Train loss 0.01 on epoch=379
04/28/2022 07:35:22 - INFO - __main__ - Step 770 Global step 770 Train loss 0.02 on epoch=384
04/28/2022 07:35:25 - INFO - __main__ - Step 780 Global step 780 Train loss 0.05 on epoch=389
04/28/2022 07:35:27 - INFO - __main__ - Step 790 Global step 790 Train loss 0.02 on epoch=394
04/28/2022 07:35:30 - INFO - __main__ - Step 800 Global step 800 Train loss 0.03 on epoch=399
04/28/2022 07:35:30 - INFO - __main__ - Global step 800 Train loss 0.03 ACC 0.65625 on epoch=399
04/28/2022 07:35:33 - INFO - __main__ - Step 810 Global step 810 Train loss 0.05 on epoch=404
04/28/2022 07:35:35 - INFO - __main__ - Step 820 Global step 820 Train loss 0.00 on epoch=409
04/28/2022 07:35:38 - INFO - __main__ - Step 830 Global step 830 Train loss 0.03 on epoch=414
04/28/2022 07:35:40 - INFO - __main__ - Step 840 Global step 840 Train loss 0.01 on epoch=419
04/28/2022 07:35:43 - INFO - __main__ - Step 850 Global step 850 Train loss 0.04 on epoch=424
04/28/2022 07:35:44 - INFO - __main__ - Global step 850 Train loss 0.03 ACC 0.65625 on epoch=424
04/28/2022 07:35:46 - INFO - __main__ - Step 860 Global step 860 Train loss 0.01 on epoch=429
04/28/2022 07:35:49 - INFO - __main__ - Step 870 Global step 870 Train loss 0.02 on epoch=434
04/28/2022 07:35:51 - INFO - __main__ - Step 880 Global step 880 Train loss 0.01 on epoch=439
04/28/2022 07:35:54 - INFO - __main__ - Step 890 Global step 890 Train loss 0.02 on epoch=444
04/28/2022 07:35:56 - INFO - __main__ - Step 900 Global step 900 Train loss 0.00 on epoch=449
04/28/2022 07:35:57 - INFO - __main__ - Global step 900 Train loss 0.01 ACC 0.65625 on epoch=449
04/28/2022 07:35:59 - INFO - __main__ - Step 910 Global step 910 Train loss 0.00 on epoch=454
04/28/2022 07:36:02 - INFO - __main__ - Step 920 Global step 920 Train loss 0.00 on epoch=459
04/28/2022 07:36:04 - INFO - __main__ - Step 930 Global step 930 Train loss 0.01 on epoch=464
04/28/2022 07:36:07 - INFO - __main__ - Step 940 Global step 940 Train loss 0.07 on epoch=469
04/28/2022 07:36:09 - INFO - __main__ - Step 950 Global step 950 Train loss 0.01 on epoch=474
04/28/2022 07:36:10 - INFO - __main__ - Global step 950 Train loss 0.02 ACC 0.75 on epoch=474
04/28/2022 07:36:10 - INFO - __main__ - Saving model with best ACC: 0.71875 -> 0.75 on epoch=474, global_step=950
04/28/2022 07:36:13 - INFO - __main__ - Step 960 Global step 960 Train loss 0.02 on epoch=479
04/28/2022 07:36:15 - INFO - __main__ - Step 970 Global step 970 Train loss 0.00 on epoch=484
04/28/2022 07:36:18 - INFO - __main__ - Step 980 Global step 980 Train loss 0.02 on epoch=489
04/28/2022 07:36:20 - INFO - __main__ - Step 990 Global step 990 Train loss 0.01 on epoch=494
04/28/2022 07:36:23 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.01 on epoch=499
04/28/2022 07:36:23 - INFO - __main__ - Global step 1000 Train loss 0.01 ACC 0.6875 on epoch=499
04/28/2022 07:36:26 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.00 on epoch=504
04/28/2022 07:36:28 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.00 on epoch=509
04/28/2022 07:36:31 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.00 on epoch=514
04/28/2022 07:36:33 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.01 on epoch=519
04/28/2022 07:36:36 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.04 on epoch=524
04/28/2022 07:36:37 - INFO - __main__ - Global step 1050 Train loss 0.01 ACC 0.65625 on epoch=524
04/28/2022 07:36:39 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.01 on epoch=529
04/28/2022 07:36:42 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.00 on epoch=534
04/28/2022 07:36:44 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.00 on epoch=539
04/28/2022 07:36:47 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.00 on epoch=544
04/28/2022 07:36:49 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.00 on epoch=549
04/28/2022 07:36:50 - INFO - __main__ - Global step 1100 Train loss 0.00 ACC 0.75 on epoch=549
04/28/2022 07:36:52 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.05 on epoch=554
04/28/2022 07:36:55 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.00 on epoch=559
04/28/2022 07:36:57 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.00 on epoch=564
04/28/2022 07:37:00 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.01 on epoch=569
04/28/2022 07:37:02 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.06 on epoch=574
04/28/2022 07:37:03 - INFO - __main__ - Global step 1150 Train loss 0.03 ACC 0.71875 on epoch=574
04/28/2022 07:37:06 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.02 on epoch=579
04/28/2022 07:37:08 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.00 on epoch=584
04/28/2022 07:37:11 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.00 on epoch=589
04/28/2022 07:37:13 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.00 on epoch=594
04/28/2022 07:37:16 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.00 on epoch=599
04/28/2022 07:37:17 - INFO - __main__ - Global step 1200 Train loss 0.01 ACC 0.6875 on epoch=599
04/28/2022 07:37:19 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.01 on epoch=604
04/28/2022 07:37:22 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.00 on epoch=609
04/28/2022 07:37:24 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=614
04/28/2022 07:37:27 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.00 on epoch=619
04/28/2022 07:37:29 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.00 on epoch=624
04/28/2022 07:37:30 - INFO - __main__ - Global step 1250 Train loss 0.01 ACC 0.71875 on epoch=624
04/28/2022 07:37:33 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.02 on epoch=629
04/28/2022 07:37:35 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.00 on epoch=634
04/28/2022 07:37:38 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.00 on epoch=639
04/28/2022 07:37:40 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=644
04/28/2022 07:37:43 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.00 on epoch=649
04/28/2022 07:37:44 - INFO - __main__ - Global step 1300 Train loss 0.01 ACC 0.71875 on epoch=649
04/28/2022 07:37:47 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.00 on epoch=654
04/28/2022 07:37:49 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.00 on epoch=659
04/28/2022 07:37:52 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.00 on epoch=664
04/28/2022 07:37:54 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.00 on epoch=669
04/28/2022 07:37:57 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.00 on epoch=674
04/28/2022 07:37:58 - INFO - __main__ - Global step 1350 Train loss 0.00 ACC 0.71875 on epoch=674
04/28/2022 07:38:01 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.00 on epoch=679
04/28/2022 07:38:03 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.00 on epoch=684
04/28/2022 07:38:06 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.00 on epoch=689
04/28/2022 07:38:08 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.00 on epoch=694
04/28/2022 07:38:11 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.00 on epoch=699
04/28/2022 07:38:13 - INFO - __main__ - Global step 1400 Train loss 0.00 ACC 0.75 on epoch=699
04/28/2022 07:38:15 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=704
04/28/2022 07:38:18 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=709
04/28/2022 07:38:20 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.00 on epoch=714
04/28/2022 07:38:23 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=719
04/28/2022 07:38:25 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=724
04/28/2022 07:38:27 - INFO - __main__ - Global step 1450 Train loss 0.00 ACC 0.75 on epoch=724
04/28/2022 07:38:29 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.02 on epoch=729
04/28/2022 07:38:32 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=734
04/28/2022 07:38:34 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=739
04/28/2022 07:38:37 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=744
04/28/2022 07:38:39 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=749
04/28/2022 07:38:42 - INFO - __main__ - Global step 1500 Train loss 0.01 ACC 0.71875 on epoch=749
04/28/2022 07:38:44 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=754
04/28/2022 07:38:47 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=759
04/28/2022 07:38:49 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.02 on epoch=764
04/28/2022 07:38:52 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=769
04/28/2022 07:38:54 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=774
04/28/2022 07:38:56 - INFO - __main__ - Global step 1550 Train loss 0.01 ACC 0.65625 on epoch=774
04/28/2022 07:38:59 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=779
04/28/2022 07:39:01 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=784
04/28/2022 07:39:04 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=789
04/28/2022 07:39:06 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=794
04/28/2022 07:39:09 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=799
04/28/2022 07:39:10 - INFO - __main__ - Global step 1600 Train loss 0.00 ACC 0.6875 on epoch=799
04/28/2022 07:39:13 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=804
04/28/2022 07:39:15 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=809
04/28/2022 07:39:18 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=814
04/28/2022 07:39:20 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=819
04/28/2022 07:39:23 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=824
04/28/2022 07:39:24 - INFO - __main__ - Global step 1650 Train loss 0.00 ACC 0.71875 on epoch=824
04/28/2022 07:39:27 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=829
04/28/2022 07:39:29 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=834
04/28/2022 07:39:32 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=839
04/28/2022 07:39:34 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=844
04/28/2022 07:39:37 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.07 on epoch=849
04/28/2022 07:39:38 - INFO - __main__ - Global step 1700 Train loss 0.01 ACC 0.71875 on epoch=849
04/28/2022 07:39:40 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=854
04/28/2022 07:39:42 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=859
04/28/2022 07:39:45 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=864
04/28/2022 07:39:47 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=869
04/28/2022 07:39:50 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=874
04/28/2022 07:39:51 - INFO - __main__ - Global step 1750 Train loss 0.00 ACC 0.71875 on epoch=874
04/28/2022 07:39:54 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=879
04/28/2022 07:39:56 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=884
04/28/2022 07:39:59 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=889
04/28/2022 07:40:01 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=894
04/28/2022 07:40:04 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=899
04/28/2022 07:40:05 - INFO - __main__ - Global step 1800 Train loss 0.00 ACC 0.78125 on epoch=899
04/28/2022 07:40:05 - INFO - __main__ - Saving model with best ACC: 0.75 -> 0.78125 on epoch=899, global_step=1800
04/28/2022 07:40:08 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=904
04/28/2022 07:40:10 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=909
04/28/2022 07:40:13 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=914
04/28/2022 07:40:15 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=919
04/28/2022 07:40:18 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=924
04/28/2022 07:40:20 - INFO - __main__ - Global step 1850 Train loss 0.00 ACC 0.75 on epoch=924
04/28/2022 07:40:23 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=929
04/28/2022 07:40:25 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=934
04/28/2022 07:40:28 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=939
04/28/2022 07:40:30 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=944
04/28/2022 07:40:33 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=949
04/28/2022 07:40:35 - INFO - __main__ - Global step 1900 Train loss 0.00 ACC 0.71875 on epoch=949
04/28/2022 07:40:38 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=954
04/28/2022 07:40:40 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=959
04/28/2022 07:40:42 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=964
04/28/2022 07:40:45 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=969
04/28/2022 07:40:47 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=974
04/28/2022 07:40:49 - INFO - __main__ - Global step 1950 Train loss 0.00 ACC 0.71875 on epoch=974
04/28/2022 07:40:52 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=979
04/28/2022 07:40:54 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=984
04/28/2022 07:40:57 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=989
04/28/2022 07:40:59 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=994
04/28/2022 07:41:02 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=999
04/28/2022 07:41:03 - INFO - __main__ - Global step 2000 Train loss 0.00 ACC 0.65625 on epoch=999
04/28/2022 07:41:03 - INFO - __main__ - save last model!
04/28/2022 07:41:03 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
04/28/2022 07:41:03 - INFO - __main__ - Start tokenizing ... 1000 instances
04/28/2022 07:41:03 - INFO - __main__ - Printing 3 examples
04/28/2022 07:41:03 - INFO - __main__ -  [wino_grande] Sarah was a much better surgeon than Maria so _ always got the easier cases. (A) Sarah (B) Maria
04/28/2022 07:41:03 - INFO - __main__ - ['Maria']
04/28/2022 07:41:03 - INFO - __main__ -  [wino_grande] Sarah was a much better surgeon than Maria so _ always got the harder cases. (A) Sarah (B) Maria
04/28/2022 07:41:03 - INFO - __main__ - ['Sarah']
04/28/2022 07:41:03 - INFO - __main__ -  [wino_grande] They were worried the wine would ruin the bed and the blanket, but the _ was't ruined. (A) blanket (B) bed
04/28/2022 07:41:03 - INFO - __main__ - ['bed']
04/28/2022 07:41:03 - INFO - __main__ - Tokenizing Input ...
04/28/2022 07:41:03 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 07:41:03 - INFO - __main__ - Printing 3 examples
04/28/2022 07:41:03 - INFO - __main__ -  [wino_grande] Monica confided in Cynthia that she had prepared an Emergency Evacuation Kit for the storm.  _ was impressed. (A) Monica (B) Cynthia
04/28/2022 07:41:03 - INFO - __main__ - ['Cynthia']
04/28/2022 07:41:03 - INFO - __main__ -  [wino_grande] Rebecca had less grass in their yard than Elena because _ had more rabbits in their yard. (A) Rebecca (B) Elena
04/28/2022 07:41:03 - INFO - __main__ - ['Rebecca']
04/28/2022 07:41:03 - INFO - __main__ -  [wino_grande] Erin has a lot of dry skin on their arms and legs and Angela does not, because _ has been using lotion to keep their skin soft. (A) Erin (B) Angela
04/28/2022 07:41:03 - INFO - __main__ - ['Angela']
04/28/2022 07:41:03 - INFO - __main__ - Tokenizing Input ...
04/28/2022 07:41:03 - INFO - __main__ - Tokenizing Output ...
04/28/2022 07:41:03 - INFO - __main__ - Tokenizing Output ...
04/28/2022 07:41:03 - INFO - __main__ - Loaded 32 examples from train data
04/28/2022 07:41:03 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 07:41:03 - INFO - __main__ - Printing 3 examples
04/28/2022 07:41:03 - INFO - __main__ -  [wino_grande] Kyle always had ideas in the mind unlike Matthew, because _ was a horrible imaginative person. (A) Kyle (B) Matthew
04/28/2022 07:41:03 - INFO - __main__ - ['Matthew']
04/28/2022 07:41:03 - INFO - __main__ -  [wino_grande] Dennis showed endless dedication to the unappreciative Ian, so _ expended their energy for nothing. (A) Dennis (B) Ian
04/28/2022 07:41:03 - INFO - __main__ - ['Dennis']
04/28/2022 07:41:03 - INFO - __main__ -  [wino_grande] It was taking a long time for Emily to heal, so Jennifer gave her some antibiotics. _ is has a wound. (A) Emily (B) Jennifer
04/28/2022 07:41:03 - INFO - __main__ - ['Emily']
04/28/2022 07:41:03 - INFO - __main__ - Tokenizing Input ...
04/28/2022 07:41:03 - INFO - __main__ - Tokenizing Output ...
04/28/2022 07:41:03 - INFO - __main__ - Loaded 32 examples from dev data
04/28/2022 07:41:04 - INFO - __main__ - Loaded 1000 examples from test data
04/28/2022 07:41:19 - INFO - __main__ - load prompt embedding from ckpt
04/28/2022 07:41:20 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/28/2022 07:41:20 - INFO - __main__ - Starting training!
04/28/2022 07:41:32 - INFO - __main__ - Saved prediction in models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-wino_grande/wino_grande_32_42_0.3_8_predictions.txt
04/28/2022 07:41:32 - INFO - __main__ - ACC on test data: 0.4900
04/28/2022 07:41:33 - INFO - __main__ - prefix=wino_grande_32_42, lr=0.3, bsz=8, dev_performance=0.78125, test_performance=0.49
04/28/2022 07:41:33 - INFO - __main__ - Running ... prefix=wino_grande_32_42, lr=0.2, bsz=8 ...
04/28/2022 07:41:34 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 07:41:34 - INFO - __main__ - Printing 3 examples
04/28/2022 07:41:34 - INFO - __main__ -  [wino_grande] Monica confided in Cynthia that she had prepared an Emergency Evacuation Kit for the storm.  _ was impressed. (A) Monica (B) Cynthia
04/28/2022 07:41:34 - INFO - __main__ - ['Cynthia']
04/28/2022 07:41:34 - INFO - __main__ -  [wino_grande] Rebecca had less grass in their yard than Elena because _ had more rabbits in their yard. (A) Rebecca (B) Elena
04/28/2022 07:41:34 - INFO - __main__ - ['Rebecca']
04/28/2022 07:41:34 - INFO - __main__ -  [wino_grande] Erin has a lot of dry skin on their arms and legs and Angela does not, because _ has been using lotion to keep their skin soft. (A) Erin (B) Angela
04/28/2022 07:41:34 - INFO - __main__ - ['Angela']
04/28/2022 07:41:34 - INFO - __main__ - Tokenizing Input ...
04/28/2022 07:41:34 - INFO - __main__ - Tokenizing Output ...
04/28/2022 07:41:34 - INFO - __main__ - Loaded 32 examples from train data
04/28/2022 07:41:34 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 07:41:34 - INFO - __main__ - Printing 3 examples
04/28/2022 07:41:34 - INFO - __main__ -  [wino_grande] Kyle always had ideas in the mind unlike Matthew, because _ was a horrible imaginative person. (A) Kyle (B) Matthew
04/28/2022 07:41:34 - INFO - __main__ - ['Matthew']
04/28/2022 07:41:34 - INFO - __main__ -  [wino_grande] Dennis showed endless dedication to the unappreciative Ian, so _ expended their energy for nothing. (A) Dennis (B) Ian
04/28/2022 07:41:34 - INFO - __main__ - ['Dennis']
04/28/2022 07:41:34 - INFO - __main__ -  [wino_grande] It was taking a long time for Emily to heal, so Jennifer gave her some antibiotics. _ is has a wound. (A) Emily (B) Jennifer
04/28/2022 07:41:34 - INFO - __main__ - ['Emily']
04/28/2022 07:41:34 - INFO - __main__ - Tokenizing Input ...
04/28/2022 07:41:34 - INFO - __main__ - Tokenizing Output ...
04/28/2022 07:41:34 - INFO - __main__ - Loaded 32 examples from dev data
04/28/2022 07:41:49 - INFO - __main__ - load prompt embedding from ckpt
04/28/2022 07:41:50 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/28/2022 07:41:50 - INFO - __main__ - Starting training!
04/28/2022 07:41:53 - INFO - __main__ - Step 10 Global step 10 Train loss 3.91 on epoch=4
04/28/2022 07:41:56 - INFO - __main__ - Step 20 Global step 20 Train loss 2.03 on epoch=9
04/28/2022 07:41:58 - INFO - __main__ - Step 30 Global step 30 Train loss 0.98 on epoch=14
04/28/2022 07:42:01 - INFO - __main__ - Step 40 Global step 40 Train loss 0.70 on epoch=19
04/28/2022 07:42:03 - INFO - __main__ - Step 50 Global step 50 Train loss 0.64 on epoch=24
04/28/2022 07:42:04 - INFO - __main__ - Global step 50 Train loss 1.65 ACC 0.59375 on epoch=24
04/28/2022 07:42:04 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.59375 on epoch=24, global_step=50
04/28/2022 07:42:07 - INFO - __main__ - Step 60 Global step 60 Train loss 0.57 on epoch=29
04/28/2022 07:42:09 - INFO - __main__ - Step 70 Global step 70 Train loss 0.49 on epoch=34
04/28/2022 07:42:11 - INFO - __main__ - Step 80 Global step 80 Train loss 0.44 on epoch=39
04/28/2022 07:42:14 - INFO - __main__ - Step 90 Global step 90 Train loss 0.28 on epoch=44
04/28/2022 07:42:16 - INFO - __main__ - Step 100 Global step 100 Train loss 0.32 on epoch=49
04/28/2022 07:42:17 - INFO - __main__ - Global step 100 Train loss 0.42 ACC 0.5 on epoch=49
04/28/2022 07:42:20 - INFO - __main__ - Step 110 Global step 110 Train loss 0.27 on epoch=54
04/28/2022 07:42:22 - INFO - __main__ - Step 120 Global step 120 Train loss 0.35 on epoch=59
04/28/2022 07:42:24 - INFO - __main__ - Step 130 Global step 130 Train loss 0.31 on epoch=64
04/28/2022 07:42:27 - INFO - __main__ - Step 140 Global step 140 Train loss 0.24 on epoch=69
04/28/2022 07:42:29 - INFO - __main__ - Step 150 Global step 150 Train loss 0.29 on epoch=74
04/28/2022 07:42:30 - INFO - __main__ - Global step 150 Train loss 0.29 ACC 0.53125 on epoch=74
04/28/2022 07:42:33 - INFO - __main__ - Step 160 Global step 160 Train loss 0.23 on epoch=79
04/28/2022 07:42:35 - INFO - __main__ - Step 170 Global step 170 Train loss 0.31 on epoch=84
04/28/2022 07:42:38 - INFO - __main__ - Step 180 Global step 180 Train loss 0.25 on epoch=89
04/28/2022 07:42:40 - INFO - __main__ - Step 190 Global step 190 Train loss 0.22 on epoch=94
04/28/2022 07:42:42 - INFO - __main__ - Step 200 Global step 200 Train loss 0.19 on epoch=99
04/28/2022 07:42:43 - INFO - __main__ - Global step 200 Train loss 0.24 ACC 0.59375 on epoch=99
04/28/2022 07:42:46 - INFO - __main__ - Step 210 Global step 210 Train loss 0.14 on epoch=104
04/28/2022 07:42:48 - INFO - __main__ - Step 220 Global step 220 Train loss 0.20 on epoch=109
04/28/2022 07:42:50 - INFO - __main__ - Step 230 Global step 230 Train loss 0.19 on epoch=114
04/28/2022 07:42:53 - INFO - __main__ - Step 240 Global step 240 Train loss 0.22 on epoch=119
04/28/2022 07:42:55 - INFO - __main__ - Step 250 Global step 250 Train loss 0.22 on epoch=124
04/28/2022 07:42:56 - INFO - __main__ - Global step 250 Train loss 0.19 ACC 0.625 on epoch=124
04/28/2022 07:42:56 - INFO - __main__ - Saving model with best ACC: 0.59375 -> 0.625 on epoch=124, global_step=250
04/28/2022 07:42:59 - INFO - __main__ - Step 260 Global step 260 Train loss 0.17 on epoch=129
04/28/2022 07:43:01 - INFO - __main__ - Step 270 Global step 270 Train loss 0.10 on epoch=134
04/28/2022 07:43:04 - INFO - __main__ - Step 280 Global step 280 Train loss 0.10 on epoch=139
04/28/2022 07:43:06 - INFO - __main__ - Step 290 Global step 290 Train loss 0.11 on epoch=144
04/28/2022 07:43:08 - INFO - __main__ - Step 300 Global step 300 Train loss 0.08 on epoch=149
04/28/2022 07:43:09 - INFO - __main__ - Global step 300 Train loss 0.11 ACC 0.625 on epoch=149
04/28/2022 07:43:12 - INFO - __main__ - Step 310 Global step 310 Train loss 0.13 on epoch=154
04/28/2022 07:43:14 - INFO - __main__ - Step 320 Global step 320 Train loss 0.10 on epoch=159
04/28/2022 07:43:17 - INFO - __main__ - Step 330 Global step 330 Train loss 0.10 on epoch=164
04/28/2022 07:43:19 - INFO - __main__ - Step 340 Global step 340 Train loss 0.16 on epoch=169
04/28/2022 07:43:22 - INFO - __main__ - Step 350 Global step 350 Train loss 0.11 on epoch=174
04/28/2022 07:43:22 - INFO - __main__ - Global step 350 Train loss 0.12 ACC 0.65625 on epoch=174
04/28/2022 07:43:22 - INFO - __main__ - Saving model with best ACC: 0.625 -> 0.65625 on epoch=174, global_step=350
04/28/2022 07:43:25 - INFO - __main__ - Step 360 Global step 360 Train loss 0.09 on epoch=179
04/28/2022 07:43:27 - INFO - __main__ - Step 370 Global step 370 Train loss 0.13 on epoch=184
04/28/2022 07:43:30 - INFO - __main__ - Step 380 Global step 380 Train loss 0.05 on epoch=189
04/28/2022 07:43:32 - INFO - __main__ - Step 390 Global step 390 Train loss 0.06 on epoch=194
04/28/2022 07:43:35 - INFO - __main__ - Step 400 Global step 400 Train loss 0.11 on epoch=199
04/28/2022 07:43:35 - INFO - __main__ - Global step 400 Train loss 0.09 ACC 0.65625 on epoch=199
04/28/2022 07:43:38 - INFO - __main__ - Step 410 Global step 410 Train loss 0.12 on epoch=204
04/28/2022 07:43:40 - INFO - __main__ - Step 420 Global step 420 Train loss 0.04 on epoch=209
04/28/2022 07:43:43 - INFO - __main__ - Step 430 Global step 430 Train loss 0.08 on epoch=214
04/28/2022 07:43:45 - INFO - __main__ - Step 440 Global step 440 Train loss 0.06 on epoch=219
04/28/2022 07:43:48 - INFO - __main__ - Step 450 Global step 450 Train loss 0.03 on epoch=224
04/28/2022 07:43:49 - INFO - __main__ - Global step 450 Train loss 0.07 ACC 0.65625 on epoch=224
04/28/2022 07:43:51 - INFO - __main__ - Step 460 Global step 460 Train loss 0.06 on epoch=229
04/28/2022 07:43:54 - INFO - __main__ - Step 470 Global step 470 Train loss 0.07 on epoch=234
04/28/2022 07:43:56 - INFO - __main__ - Step 480 Global step 480 Train loss 0.08 on epoch=239
04/28/2022 07:43:59 - INFO - __main__ - Step 490 Global step 490 Train loss 0.05 on epoch=244
04/28/2022 07:44:01 - INFO - __main__ - Step 500 Global step 500 Train loss 0.05 on epoch=249
04/28/2022 07:44:02 - INFO - __main__ - Global step 500 Train loss 0.06 ACC 0.6875 on epoch=249
04/28/2022 07:44:02 - INFO - __main__ - Saving model with best ACC: 0.65625 -> 0.6875 on epoch=249, global_step=500
04/28/2022 07:44:04 - INFO - __main__ - Step 510 Global step 510 Train loss 0.06 on epoch=254
04/28/2022 07:44:07 - INFO - __main__ - Step 520 Global step 520 Train loss 0.08 on epoch=259
04/28/2022 07:44:09 - INFO - __main__ - Step 530 Global step 530 Train loss 0.05 on epoch=264
04/28/2022 07:44:12 - INFO - __main__ - Step 540 Global step 540 Train loss 0.11 on epoch=269
04/28/2022 07:44:14 - INFO - __main__ - Step 550 Global step 550 Train loss 0.06 on epoch=274
04/28/2022 07:44:15 - INFO - __main__ - Global step 550 Train loss 0.07 ACC 0.625 on epoch=274
04/28/2022 07:44:18 - INFO - __main__ - Step 560 Global step 560 Train loss 0.04 on epoch=279
04/28/2022 07:44:20 - INFO - __main__ - Step 570 Global step 570 Train loss 0.10 on epoch=284
04/28/2022 07:44:23 - INFO - __main__ - Step 580 Global step 580 Train loss 0.02 on epoch=289
04/28/2022 07:44:25 - INFO - __main__ - Step 590 Global step 590 Train loss 0.10 on epoch=294
04/28/2022 07:44:28 - INFO - __main__ - Step 600 Global step 600 Train loss 0.01 on epoch=299
04/28/2022 07:44:28 - INFO - __main__ - Global step 600 Train loss 0.06 ACC 0.65625 on epoch=299
04/28/2022 07:44:31 - INFO - __main__ - Step 610 Global step 610 Train loss 0.02 on epoch=304
04/28/2022 07:44:33 - INFO - __main__ - Step 620 Global step 620 Train loss 0.05 on epoch=309
04/28/2022 07:44:36 - INFO - __main__ - Step 630 Global step 630 Train loss 0.02 on epoch=314
04/28/2022 07:44:38 - INFO - __main__ - Step 640 Global step 640 Train loss 0.06 on epoch=319
04/28/2022 07:44:41 - INFO - __main__ - Step 650 Global step 650 Train loss 0.03 on epoch=324
04/28/2022 07:44:42 - INFO - __main__ - Global step 650 Train loss 0.04 ACC 0.6875 on epoch=324
04/28/2022 07:44:44 - INFO - __main__ - Step 660 Global step 660 Train loss 0.06 on epoch=329
04/28/2022 07:44:47 - INFO - __main__ - Step 670 Global step 670 Train loss 0.06 on epoch=334
04/28/2022 07:44:49 - INFO - __main__ - Step 680 Global step 680 Train loss 0.08 on epoch=339
04/28/2022 07:44:52 - INFO - __main__ - Step 690 Global step 690 Train loss 0.01 on epoch=344
04/28/2022 07:44:54 - INFO - __main__ - Step 700 Global step 700 Train loss 0.02 on epoch=349
04/28/2022 07:44:55 - INFO - __main__ - Global step 700 Train loss 0.05 ACC 0.65625 on epoch=349
04/28/2022 07:44:57 - INFO - __main__ - Step 710 Global step 710 Train loss 0.03 on epoch=354
04/28/2022 07:45:00 - INFO - __main__ - Step 720 Global step 720 Train loss 0.03 on epoch=359
04/28/2022 07:45:03 - INFO - __main__ - Step 730 Global step 730 Train loss 0.02 on epoch=364
04/28/2022 07:45:05 - INFO - __main__ - Step 740 Global step 740 Train loss 0.01 on epoch=369
04/28/2022 07:45:08 - INFO - __main__ - Step 750 Global step 750 Train loss 0.07 on epoch=374
04/28/2022 07:45:08 - INFO - __main__ - Global step 750 Train loss 0.03 ACC 0.6875 on epoch=374
04/28/2022 07:45:11 - INFO - __main__ - Step 760 Global step 760 Train loss 0.01 on epoch=379
04/28/2022 07:45:13 - INFO - __main__ - Step 770 Global step 770 Train loss 0.02 on epoch=384
04/28/2022 07:45:16 - INFO - __main__ - Step 780 Global step 780 Train loss 0.01 on epoch=389
04/28/2022 07:45:18 - INFO - __main__ - Step 790 Global step 790 Train loss 0.05 on epoch=394
04/28/2022 07:45:21 - INFO - __main__ - Step 800 Global step 800 Train loss 0.01 on epoch=399
04/28/2022 07:45:22 - INFO - __main__ - Global step 800 Train loss 0.02 ACC 0.71875 on epoch=399
04/28/2022 07:45:22 - INFO - __main__ - Saving model with best ACC: 0.6875 -> 0.71875 on epoch=399, global_step=800
04/28/2022 07:45:24 - INFO - __main__ - Step 810 Global step 810 Train loss 0.01 on epoch=404
04/28/2022 07:45:26 - INFO - __main__ - Step 820 Global step 820 Train loss 0.03 on epoch=409
04/28/2022 07:45:29 - INFO - __main__ - Step 830 Global step 830 Train loss 0.07 on epoch=414
04/28/2022 07:45:32 - INFO - __main__ - Step 840 Global step 840 Train loss 0.01 on epoch=419
04/28/2022 07:45:34 - INFO - __main__ - Step 850 Global step 850 Train loss 0.02 on epoch=424
04/28/2022 07:45:35 - INFO - __main__ - Global step 850 Train loss 0.03 ACC 0.71875 on epoch=424
04/28/2022 07:45:37 - INFO - __main__ - Step 860 Global step 860 Train loss 0.02 on epoch=429
04/28/2022 07:45:40 - INFO - __main__ - Step 870 Global step 870 Train loss 0.01 on epoch=434
04/28/2022 07:45:42 - INFO - __main__ - Step 880 Global step 880 Train loss 0.00 on epoch=439
04/28/2022 07:45:45 - INFO - __main__ - Step 890 Global step 890 Train loss 0.01 on epoch=444
04/28/2022 07:45:47 - INFO - __main__ - Step 900 Global step 900 Train loss 0.01 on epoch=449
04/28/2022 07:45:48 - INFO - __main__ - Global step 900 Train loss 0.01 ACC 0.6875 on epoch=449
04/28/2022 07:45:50 - INFO - __main__ - Step 910 Global step 910 Train loss 0.03 on epoch=454
04/28/2022 07:45:53 - INFO - __main__ - Step 920 Global step 920 Train loss 0.04 on epoch=459
04/28/2022 07:45:55 - INFO - __main__ - Step 930 Global step 930 Train loss 0.03 on epoch=464
04/28/2022 07:45:58 - INFO - __main__ - Step 940 Global step 940 Train loss 0.01 on epoch=469
04/28/2022 07:46:00 - INFO - __main__ - Step 950 Global step 950 Train loss 0.04 on epoch=474
04/28/2022 07:46:01 - INFO - __main__ - Global step 950 Train loss 0.03 ACC 0.625 on epoch=474
04/28/2022 07:46:04 - INFO - __main__ - Step 960 Global step 960 Train loss 0.02 on epoch=479
04/28/2022 07:46:06 - INFO - __main__ - Step 970 Global step 970 Train loss 0.01 on epoch=484
04/28/2022 07:46:09 - INFO - __main__ - Step 980 Global step 980 Train loss 0.00 on epoch=489
04/28/2022 07:46:11 - INFO - __main__ - Step 990 Global step 990 Train loss 0.06 on epoch=494
04/28/2022 07:46:14 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.00 on epoch=499
04/28/2022 07:46:15 - INFO - __main__ - Global step 1000 Train loss 0.02 ACC 0.6875 on epoch=499
04/28/2022 07:46:17 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.00 on epoch=504
04/28/2022 07:46:20 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.01 on epoch=509
04/28/2022 07:46:22 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.04 on epoch=514
04/28/2022 07:46:25 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.00 on epoch=519
04/28/2022 07:46:27 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.01 on epoch=524
04/28/2022 07:46:28 - INFO - __main__ - Global step 1050 Train loss 0.01 ACC 0.65625 on epoch=524
04/28/2022 07:46:30 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.01 on epoch=529
04/28/2022 07:46:33 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.06 on epoch=534
04/28/2022 07:46:35 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.01 on epoch=539
04/28/2022 07:46:38 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.02 on epoch=544
04/28/2022 07:46:40 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.01 on epoch=549
04/28/2022 07:46:41 - INFO - __main__ - Global step 1100 Train loss 0.02 ACC 0.65625 on epoch=549
04/28/2022 07:46:44 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.00 on epoch=554
04/28/2022 07:46:46 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=559
04/28/2022 07:46:49 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.02 on epoch=564
04/28/2022 07:46:51 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.02 on epoch=569
04/28/2022 07:46:54 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.00 on epoch=574
04/28/2022 07:46:55 - INFO - __main__ - Global step 1150 Train loss 0.01 ACC 0.65625 on epoch=574
04/28/2022 07:46:57 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.01 on epoch=579
04/28/2022 07:47:00 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.01 on epoch=584
04/28/2022 07:47:02 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.00 on epoch=589
04/28/2022 07:47:05 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.02 on epoch=594
04/28/2022 07:47:07 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.03 on epoch=599
04/28/2022 07:47:08 - INFO - __main__ - Global step 1200 Train loss 0.01 ACC 0.65625 on epoch=599
04/28/2022 07:47:11 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.01 on epoch=604
04/28/2022 07:47:13 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=609
04/28/2022 07:47:16 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=614
04/28/2022 07:47:18 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.02 on epoch=619
04/28/2022 07:47:21 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.00 on epoch=624
04/28/2022 07:47:21 - INFO - __main__ - Global step 1250 Train loss 0.01 ACC 0.65625 on epoch=624
04/28/2022 07:47:24 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.00 on epoch=629
04/28/2022 07:47:26 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.00 on epoch=634
04/28/2022 07:47:29 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.00 on epoch=639
04/28/2022 07:47:31 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.00 on epoch=644
04/28/2022 07:47:34 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=649
04/28/2022 07:47:35 - INFO - __main__ - Global step 1300 Train loss 0.00 ACC 0.65625 on epoch=649
04/28/2022 07:47:37 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.00 on epoch=654
04/28/2022 07:47:40 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=659
04/28/2022 07:47:42 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.00 on epoch=664
04/28/2022 07:47:45 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=669
04/28/2022 07:47:47 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.00 on epoch=674
04/28/2022 07:47:48 - INFO - __main__ - Global step 1350 Train loss 0.00 ACC 0.65625 on epoch=674
04/28/2022 07:47:50 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.00 on epoch=679
04/28/2022 07:47:53 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=684
04/28/2022 07:47:56 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=689
04/28/2022 07:47:58 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.00 on epoch=694
04/28/2022 07:48:00 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.00 on epoch=699
04/28/2022 07:48:01 - INFO - __main__ - Global step 1400 Train loss 0.01 ACC 0.65625 on epoch=699
04/28/2022 07:48:04 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=704
04/28/2022 07:48:06 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.06 on epoch=709
04/28/2022 07:48:09 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.00 on epoch=714
04/28/2022 07:48:11 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=719
04/28/2022 07:48:14 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=724
04/28/2022 07:48:15 - INFO - __main__ - Global step 1450 Train loss 0.01 ACC 0.6875 on epoch=724
04/28/2022 07:48:17 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=729
04/28/2022 07:48:20 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=734
04/28/2022 07:48:22 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=739
04/28/2022 07:48:25 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=744
04/28/2022 07:48:27 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=749
04/28/2022 07:48:28 - INFO - __main__ - Global step 1500 Train loss 0.00 ACC 0.65625 on epoch=749
04/28/2022 07:48:30 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=754
04/28/2022 07:48:33 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.04 on epoch=759
04/28/2022 07:48:35 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=764
04/28/2022 07:48:38 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=769
04/28/2022 07:48:41 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=774
04/28/2022 07:48:41 - INFO - __main__ - Global step 1550 Train loss 0.01 ACC 0.65625 on epoch=774
04/28/2022 07:48:44 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=779
04/28/2022 07:48:46 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=784
04/28/2022 07:48:49 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.03 on epoch=789
04/28/2022 07:48:51 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=794
04/28/2022 07:48:54 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=799
04/28/2022 07:48:55 - INFO - __main__ - Global step 1600 Train loss 0.01 ACC 0.6875 on epoch=799
04/28/2022 07:48:57 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=804
04/28/2022 07:49:00 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=809
04/28/2022 07:49:02 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=814
04/28/2022 07:49:05 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=819
04/28/2022 07:49:07 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=824
04/28/2022 07:49:08 - INFO - __main__ - Global step 1650 Train loss 0.00 ACC 0.65625 on epoch=824
04/28/2022 07:49:11 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=829
04/28/2022 07:49:13 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=834
04/28/2022 07:49:16 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=839
04/28/2022 07:49:18 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=844
04/28/2022 07:49:21 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=849
04/28/2022 07:49:21 - INFO - __main__ - Global step 1700 Train loss 0.01 ACC 0.65625 on epoch=849
04/28/2022 07:49:24 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=854
04/28/2022 07:49:26 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=859
04/28/2022 07:49:29 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.03 on epoch=864
04/28/2022 07:49:31 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=869
04/28/2022 07:49:34 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=874
04/28/2022 07:49:35 - INFO - __main__ - Global step 1750 Train loss 0.01 ACC 0.65625 on epoch=874
04/28/2022 07:49:37 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=879
04/28/2022 07:49:40 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=884
04/28/2022 07:49:42 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.03 on epoch=889
04/28/2022 07:49:45 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=894
04/28/2022 07:49:47 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=899
04/28/2022 07:49:48 - INFO - __main__ - Global step 1800 Train loss 0.01 ACC 0.65625 on epoch=899
04/28/2022 07:49:50 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=904
04/28/2022 07:49:53 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=909
04/28/2022 07:49:55 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=914
04/28/2022 07:49:58 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=919
04/28/2022 07:50:00 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=924
04/28/2022 07:50:01 - INFO - __main__ - Global step 1850 Train loss 0.01 ACC 0.6875 on epoch=924
04/28/2022 07:50:04 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=929
04/28/2022 07:50:06 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=934
04/28/2022 07:50:09 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=939
04/28/2022 07:50:11 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=944
04/28/2022 07:50:14 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.05 on epoch=949
04/28/2022 07:50:15 - INFO - __main__ - Global step 1900 Train loss 0.02 ACC 0.65625 on epoch=949
04/28/2022 07:50:17 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=954
04/28/2022 07:50:20 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=959
04/28/2022 07:50:22 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=964
04/28/2022 07:50:25 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=969
04/28/2022 07:50:27 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=974
04/28/2022 07:50:28 - INFO - __main__ - Global step 1950 Train loss 0.00 ACC 0.65625 on epoch=974
04/28/2022 07:50:30 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=979
04/28/2022 07:50:33 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=984
04/28/2022 07:50:35 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=989
04/28/2022 07:50:38 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=994
04/28/2022 07:50:40 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=999
04/28/2022 07:50:41 - INFO - __main__ - Global step 2000 Train loss 0.01 ACC 0.65625 on epoch=999
04/28/2022 07:50:41 - INFO - __main__ - save last model!
04/28/2022 07:50:41 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
04/28/2022 07:50:41 - INFO - __main__ - Start tokenizing ... 1000 instances
04/28/2022 07:50:41 - INFO - __main__ - Printing 3 examples
04/28/2022 07:50:41 - INFO - __main__ -  [wino_grande] Sarah was a much better surgeon than Maria so _ always got the easier cases. (A) Sarah (B) Maria
04/28/2022 07:50:41 - INFO - __main__ - ['Maria']
04/28/2022 07:50:41 - INFO - __main__ -  [wino_grande] Sarah was a much better surgeon than Maria so _ always got the harder cases. (A) Sarah (B) Maria
04/28/2022 07:50:41 - INFO - __main__ - ['Sarah']
04/28/2022 07:50:41 - INFO - __main__ -  [wino_grande] They were worried the wine would ruin the bed and the blanket, but the _ was't ruined. (A) blanket (B) bed
04/28/2022 07:50:41 - INFO - __main__ - ['bed']
04/28/2022 07:50:41 - INFO - __main__ - Tokenizing Input ...
04/28/2022 07:50:42 - INFO - __main__ - Tokenizing Output ...
04/28/2022 07:50:42 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 07:50:42 - INFO - __main__ - Printing 3 examples
04/28/2022 07:50:42 - INFO - __main__ -  [wino_grande] Adam gave his friend an apple instead of an orange because his friend was quite fond of the _ . (A) orange (B) apple
04/28/2022 07:50:42 - INFO - __main__ - ['apple']
04/28/2022 07:50:42 - INFO - __main__ -  [wino_grande] William wants to file a lawsuit so he asks Aaron for help, because _ is a lawyer. (A) William (B) Aaron
04/28/2022 07:50:42 - INFO - __main__ - ['Aaron']
04/28/2022 07:50:42 - INFO - __main__ -  [wino_grande] Brian suffers a lot from loneliness compared to Brett because _ has lost all of his family. (A) Brian (B) Brett
04/28/2022 07:50:42 - INFO - __main__ - ['Brian']
04/28/2022 07:50:42 - INFO - __main__ - Tokenizing Input ...
04/28/2022 07:50:42 - INFO - __main__ - Tokenizing Output ...
04/28/2022 07:50:42 - INFO - __main__ - Loaded 32 examples from train data
04/28/2022 07:50:42 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 07:50:42 - INFO - __main__ - Printing 3 examples
04/28/2022 07:50:42 - INFO - __main__ -  [wino_grande] Although Elena hated sweets a whole lot more than Megan, _ was the one to own a bakery. (A) Elena (B) Megan
04/28/2022 07:50:42 - INFO - __main__ - ['Elena']
04/28/2022 07:50:42 - INFO - __main__ -  [wino_grande] The meeting took longer than the interview because there was more to cover during the _ . (A) meeting (B) interview
04/28/2022 07:50:42 - INFO - __main__ - ['meeting']
04/28/2022 07:50:42 - INFO - __main__ -  [wino_grande] Rebecca set out to walk around and recruit new members for Lindsey 's church because _ was old and disabled. (A) Rebecca (B) Lindsey
04/28/2022 07:50:42 - INFO - __main__ - ['Lindsey']
04/28/2022 07:50:42 - INFO - __main__ - Tokenizing Input ...
04/28/2022 07:50:42 - INFO - __main__ - Tokenizing Output ...
04/28/2022 07:50:42 - INFO - __main__ - Loaded 32 examples from dev data
04/28/2022 07:50:43 - INFO - __main__ - Loaded 1000 examples from test data
04/28/2022 07:50:57 - INFO - __main__ - load prompt embedding from ckpt
04/28/2022 07:50:58 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/28/2022 07:50:58 - INFO - __main__ - Starting training!
04/28/2022 07:51:12 - INFO - __main__ - Saved prediction in models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-wino_grande/wino_grande_32_42_0.2_8_predictions.txt
04/28/2022 07:51:12 - INFO - __main__ - ACC on test data: 0.4910
04/28/2022 07:51:13 - INFO - __main__ - prefix=wino_grande_32_42, lr=0.2, bsz=8, dev_performance=0.71875, test_performance=0.491
04/28/2022 07:51:13 - INFO - __main__ - Running ... prefix=wino_grande_32_87, lr=0.5, bsz=8 ...
04/28/2022 07:51:14 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 07:51:14 - INFO - __main__ - Printing 3 examples
04/28/2022 07:51:14 - INFO - __main__ -  [wino_grande] Adam gave his friend an apple instead of an orange because his friend was quite fond of the _ . (A) orange (B) apple
04/28/2022 07:51:14 - INFO - __main__ - ['apple']
04/28/2022 07:51:14 - INFO - __main__ -  [wino_grande] William wants to file a lawsuit so he asks Aaron for help, because _ is a lawyer. (A) William (B) Aaron
04/28/2022 07:51:14 - INFO - __main__ - ['Aaron']
04/28/2022 07:51:14 - INFO - __main__ -  [wino_grande] Brian suffers a lot from loneliness compared to Brett because _ has lost all of his family. (A) Brian (B) Brett
04/28/2022 07:51:14 - INFO - __main__ - ['Brian']
04/28/2022 07:51:14 - INFO - __main__ - Tokenizing Input ...
04/28/2022 07:51:14 - INFO - __main__ - Tokenizing Output ...
04/28/2022 07:51:14 - INFO - __main__ - Loaded 32 examples from train data
04/28/2022 07:51:14 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 07:51:14 - INFO - __main__ - Printing 3 examples
04/28/2022 07:51:14 - INFO - __main__ -  [wino_grande] Although Elena hated sweets a whole lot more than Megan, _ was the one to own a bakery. (A) Elena (B) Megan
04/28/2022 07:51:14 - INFO - __main__ - ['Elena']
04/28/2022 07:51:14 - INFO - __main__ -  [wino_grande] The meeting took longer than the interview because there was more to cover during the _ . (A) meeting (B) interview
04/28/2022 07:51:14 - INFO - __main__ - ['meeting']
04/28/2022 07:51:14 - INFO - __main__ -  [wino_grande] Rebecca set out to walk around and recruit new members for Lindsey 's church because _ was old and disabled. (A) Rebecca (B) Lindsey
04/28/2022 07:51:14 - INFO - __main__ - ['Lindsey']
04/28/2022 07:51:14 - INFO - __main__ - Tokenizing Input ...
04/28/2022 07:51:14 - INFO - __main__ - Tokenizing Output ...
04/28/2022 07:51:14 - INFO - __main__ - Loaded 32 examples from dev data
04/28/2022 07:51:29 - INFO - __main__ - load prompt embedding from ckpt
04/28/2022 07:51:30 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/28/2022 07:51:30 - INFO - __main__ - Starting training!
04/28/2022 07:51:33 - INFO - __main__ - Step 10 Global step 10 Train loss 3.34 on epoch=4
04/28/2022 07:51:35 - INFO - __main__ - Step 20 Global step 20 Train loss 1.11 on epoch=9
04/28/2022 07:51:38 - INFO - __main__ - Step 30 Global step 30 Train loss 0.78 on epoch=14
04/28/2022 07:51:40 - INFO - __main__ - Step 40 Global step 40 Train loss 0.76 on epoch=19
04/28/2022 07:51:43 - INFO - __main__ - Step 50 Global step 50 Train loss 0.39 on epoch=24
04/28/2022 07:51:43 - INFO - __main__ - Global step 50 Train loss 1.28 ACC 0.53125 on epoch=24
04/28/2022 07:51:43 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.53125 on epoch=24, global_step=50
04/28/2022 07:51:46 - INFO - __main__ - Step 60 Global step 60 Train loss 0.31 on epoch=29
04/28/2022 07:51:48 - INFO - __main__ - Step 70 Global step 70 Train loss 0.27 on epoch=34
04/28/2022 07:51:51 - INFO - __main__ - Step 80 Global step 80 Train loss 0.29 on epoch=39
04/28/2022 07:51:53 - INFO - __main__ - Step 90 Global step 90 Train loss 0.23 on epoch=44
04/28/2022 07:51:56 - INFO - __main__ - Step 100 Global step 100 Train loss 0.20 on epoch=49
04/28/2022 07:51:56 - INFO - __main__ - Global step 100 Train loss 0.26 ACC 0.5 on epoch=49
04/28/2022 07:51:59 - INFO - __main__ - Step 110 Global step 110 Train loss 0.21 on epoch=54
04/28/2022 07:52:01 - INFO - __main__ - Step 120 Global step 120 Train loss 0.20 on epoch=59
04/28/2022 07:52:04 - INFO - __main__ - Step 130 Global step 130 Train loss 0.20 on epoch=64
04/28/2022 07:52:06 - INFO - __main__ - Step 140 Global step 140 Train loss 0.09 on epoch=69
04/28/2022 07:52:09 - INFO - __main__ - Step 150 Global step 150 Train loss 0.12 on epoch=74
04/28/2022 07:52:09 - INFO - __main__ - Global step 150 Train loss 0.16 ACC 0.53125 on epoch=74
04/28/2022 07:52:12 - INFO - __main__ - Step 160 Global step 160 Train loss 0.08 on epoch=79
04/28/2022 07:52:14 - INFO - __main__ - Step 170 Global step 170 Train loss 0.09 on epoch=84
04/28/2022 07:52:17 - INFO - __main__ - Step 180 Global step 180 Train loss 0.23 on epoch=89
04/28/2022 07:52:19 - INFO - __main__ - Step 190 Global step 190 Train loss 0.12 on epoch=94
04/28/2022 07:52:22 - INFO - __main__ - Step 200 Global step 200 Train loss 0.08 on epoch=99
04/28/2022 07:52:22 - INFO - __main__ - Global step 200 Train loss 0.12 ACC 0.5 on epoch=99
04/28/2022 07:52:25 - INFO - __main__ - Step 210 Global step 210 Train loss 0.14 on epoch=104
04/28/2022 07:52:27 - INFO - __main__ - Step 220 Global step 220 Train loss 0.08 on epoch=109
04/28/2022 07:52:30 - INFO - __main__ - Step 230 Global step 230 Train loss 0.13 on epoch=114
04/28/2022 07:52:32 - INFO - __main__ - Step 240 Global step 240 Train loss 0.12 on epoch=119
04/28/2022 07:52:35 - INFO - __main__ - Step 250 Global step 250 Train loss 0.10 on epoch=124
04/28/2022 07:52:36 - INFO - __main__ - Global step 250 Train loss 0.12 ACC 0.46875 on epoch=124
04/28/2022 07:52:38 - INFO - __main__ - Step 260 Global step 260 Train loss 0.08 on epoch=129
04/28/2022 07:52:41 - INFO - __main__ - Step 270 Global step 270 Train loss 0.07 on epoch=134
04/28/2022 07:52:43 - INFO - __main__ - Step 280 Global step 280 Train loss 0.05 on epoch=139
04/28/2022 07:52:45 - INFO - __main__ - Step 290 Global step 290 Train loss 0.07 on epoch=144
04/28/2022 07:52:48 - INFO - __main__ - Step 300 Global step 300 Train loss 0.04 on epoch=149
04/28/2022 07:52:49 - INFO - __main__ - Global step 300 Train loss 0.06 ACC 0.59375 on epoch=149
04/28/2022 07:52:49 - INFO - __main__ - Saving model with best ACC: 0.53125 -> 0.59375 on epoch=149, global_step=300
04/28/2022 07:52:51 - INFO - __main__ - Step 310 Global step 310 Train loss 0.08 on epoch=154
04/28/2022 07:52:54 - INFO - __main__ - Step 320 Global step 320 Train loss 0.09 on epoch=159
04/28/2022 07:52:56 - INFO - __main__ - Step 330 Global step 330 Train loss 0.14 on epoch=164
04/28/2022 07:52:59 - INFO - __main__ - Step 340 Global step 340 Train loss 0.11 on epoch=169
04/28/2022 07:53:01 - INFO - __main__ - Step 350 Global step 350 Train loss 0.07 on epoch=174
04/28/2022 07:53:02 - INFO - __main__ - Global step 350 Train loss 0.10 ACC 0.53125 on epoch=174
04/28/2022 07:53:04 - INFO - __main__ - Step 360 Global step 360 Train loss 0.11 on epoch=179
04/28/2022 07:53:07 - INFO - __main__ - Step 370 Global step 370 Train loss 0.08 on epoch=184
04/28/2022 07:53:09 - INFO - __main__ - Step 380 Global step 380 Train loss 0.06 on epoch=189
04/28/2022 07:53:12 - INFO - __main__ - Step 390 Global step 390 Train loss 0.11 on epoch=194
04/28/2022 07:53:14 - INFO - __main__ - Step 400 Global step 400 Train loss 0.06 on epoch=199
04/28/2022 07:53:15 - INFO - __main__ - Global step 400 Train loss 0.08 ACC 0.53125 on epoch=199
04/28/2022 07:53:18 - INFO - __main__ - Step 410 Global step 410 Train loss 0.08 on epoch=204
04/28/2022 07:53:20 - INFO - __main__ - Step 420 Global step 420 Train loss 0.06 on epoch=209
04/28/2022 07:53:23 - INFO - __main__ - Step 430 Global step 430 Train loss 0.07 on epoch=214
04/28/2022 07:53:25 - INFO - __main__ - Step 440 Global step 440 Train loss 0.04 on epoch=219
04/28/2022 07:53:27 - INFO - __main__ - Step 450 Global step 450 Train loss 0.02 on epoch=224
04/28/2022 07:53:28 - INFO - __main__ - Global step 450 Train loss 0.05 ACC 0.5 on epoch=224
04/28/2022 07:53:31 - INFO - __main__ - Step 460 Global step 460 Train loss 0.07 on epoch=229
04/28/2022 07:53:33 - INFO - __main__ - Step 470 Global step 470 Train loss 0.06 on epoch=234
04/28/2022 07:53:36 - INFO - __main__ - Step 480 Global step 480 Train loss 0.08 on epoch=239
04/28/2022 07:53:38 - INFO - __main__ - Step 490 Global step 490 Train loss 0.05 on epoch=244
04/28/2022 07:53:40 - INFO - __main__ - Step 500 Global step 500 Train loss 0.06 on epoch=249
04/28/2022 07:53:41 - INFO - __main__ - Global step 500 Train loss 0.06 ACC 0.53125 on epoch=249
04/28/2022 07:53:44 - INFO - __main__ - Step 510 Global step 510 Train loss 0.05 on epoch=254
04/28/2022 07:53:46 - INFO - __main__ - Step 520 Global step 520 Train loss 0.16 on epoch=259
04/28/2022 07:53:49 - INFO - __main__ - Step 530 Global step 530 Train loss 0.08 on epoch=264
04/28/2022 07:53:51 - INFO - __main__ - Step 540 Global step 540 Train loss 0.05 on epoch=269
04/28/2022 07:53:54 - INFO - __main__ - Step 550 Global step 550 Train loss 0.05 on epoch=274
04/28/2022 07:53:55 - INFO - __main__ - Global step 550 Train loss 0.08 ACC 0.5 on epoch=274
04/28/2022 07:53:57 - INFO - __main__ - Step 560 Global step 560 Train loss 0.05 on epoch=279
04/28/2022 07:54:00 - INFO - __main__ - Step 570 Global step 570 Train loss 0.03 on epoch=284
04/28/2022 07:54:02 - INFO - __main__ - Step 580 Global step 580 Train loss 0.03 on epoch=289
04/28/2022 07:54:05 - INFO - __main__ - Step 590 Global step 590 Train loss 0.03 on epoch=294
04/28/2022 07:54:07 - INFO - __main__ - Step 600 Global step 600 Train loss 0.04 on epoch=299
04/28/2022 07:54:08 - INFO - __main__ - Global step 600 Train loss 0.04 ACC 0.5 on epoch=299
04/28/2022 07:54:11 - INFO - __main__ - Step 610 Global step 610 Train loss 0.02 on epoch=304
04/28/2022 07:54:13 - INFO - __main__ - Step 620 Global step 620 Train loss 0.10 on epoch=309
04/28/2022 07:54:16 - INFO - __main__ - Step 630 Global step 630 Train loss 0.08 on epoch=314
04/28/2022 07:54:18 - INFO - __main__ - Step 640 Global step 640 Train loss 0.08 on epoch=319
04/28/2022 07:54:21 - INFO - __main__ - Step 650 Global step 650 Train loss 0.07 on epoch=324
04/28/2022 07:54:21 - INFO - __main__ - Global step 650 Train loss 0.07 ACC 0.5625 on epoch=324
04/28/2022 07:54:24 - INFO - __main__ - Step 660 Global step 660 Train loss 0.02 on epoch=329
04/28/2022 07:54:26 - INFO - __main__ - Step 670 Global step 670 Train loss 0.02 on epoch=334
04/28/2022 07:54:29 - INFO - __main__ - Step 680 Global step 680 Train loss 0.02 on epoch=339
04/28/2022 07:54:31 - INFO - __main__ - Step 690 Global step 690 Train loss 0.05 on epoch=344
04/28/2022 07:54:34 - INFO - __main__ - Step 700 Global step 700 Train loss 0.04 on epoch=349
04/28/2022 07:54:35 - INFO - __main__ - Global step 700 Train loss 0.03 ACC 0.5625 on epoch=349
04/28/2022 07:54:37 - INFO - __main__ - Step 710 Global step 710 Train loss 0.02 on epoch=354
04/28/2022 07:54:40 - INFO - __main__ - Step 720 Global step 720 Train loss 0.04 on epoch=359
04/28/2022 07:54:42 - INFO - __main__ - Step 730 Global step 730 Train loss 0.05 on epoch=364
04/28/2022 07:54:45 - INFO - __main__ - Step 740 Global step 740 Train loss 0.02 on epoch=369
04/28/2022 07:54:47 - INFO - __main__ - Step 750 Global step 750 Train loss 0.08 on epoch=374
04/28/2022 07:54:48 - INFO - __main__ - Global step 750 Train loss 0.05 ACC 0.46875 on epoch=374
04/28/2022 07:54:51 - INFO - __main__ - Step 760 Global step 760 Train loss 0.05 on epoch=379
04/28/2022 07:54:53 - INFO - __main__ - Step 770 Global step 770 Train loss 0.06 on epoch=384
04/28/2022 07:54:55 - INFO - __main__ - Step 780 Global step 780 Train loss 0.06 on epoch=389
04/28/2022 07:54:58 - INFO - __main__ - Step 790 Global step 790 Train loss 0.05 on epoch=394
04/28/2022 07:55:00 - INFO - __main__ - Step 800 Global step 800 Train loss 0.06 on epoch=399
04/28/2022 07:55:01 - INFO - __main__ - Global step 800 Train loss 0.06 ACC 0.5 on epoch=399
04/28/2022 07:55:04 - INFO - __main__ - Step 810 Global step 810 Train loss 0.05 on epoch=404
04/28/2022 07:55:06 - INFO - __main__ - Step 820 Global step 820 Train loss 0.03 on epoch=409
04/28/2022 07:55:09 - INFO - __main__ - Step 830 Global step 830 Train loss 0.06 on epoch=414
04/28/2022 07:55:11 - INFO - __main__ - Step 840 Global step 840 Train loss 0.06 on epoch=419
04/28/2022 07:55:14 - INFO - __main__ - Step 850 Global step 850 Train loss 0.05 on epoch=424
04/28/2022 07:55:14 - INFO - __main__ - Global step 850 Train loss 0.05 ACC 0.53125 on epoch=424
04/28/2022 07:55:17 - INFO - __main__ - Step 860 Global step 860 Train loss 0.06 on epoch=429
04/28/2022 07:55:19 - INFO - __main__ - Step 870 Global step 870 Train loss 0.02 on epoch=434
04/28/2022 07:55:22 - INFO - __main__ - Step 880 Global step 880 Train loss 0.03 on epoch=439
04/28/2022 07:55:24 - INFO - __main__ - Step 890 Global step 890 Train loss 0.02 on epoch=444
04/28/2022 07:55:27 - INFO - __main__ - Step 900 Global step 900 Train loss 0.09 on epoch=449
04/28/2022 07:55:28 - INFO - __main__ - Global step 900 Train loss 0.05 ACC 0.46875 on epoch=449
04/28/2022 07:55:30 - INFO - __main__ - Step 910 Global step 910 Train loss 0.04 on epoch=454
04/28/2022 07:55:33 - INFO - __main__ - Step 920 Global step 920 Train loss 0.03 on epoch=459
04/28/2022 07:55:35 - INFO - __main__ - Step 930 Global step 930 Train loss 0.06 on epoch=464
04/28/2022 07:55:37 - INFO - __main__ - Step 940 Global step 940 Train loss 0.06 on epoch=469
04/28/2022 07:55:40 - INFO - __main__ - Step 950 Global step 950 Train loss 0.02 on epoch=474
04/28/2022 07:55:41 - INFO - __main__ - Global step 950 Train loss 0.04 ACC 0.53125 on epoch=474
04/28/2022 07:55:43 - INFO - __main__ - Step 960 Global step 960 Train loss 0.07 on epoch=479
04/28/2022 07:55:46 - INFO - __main__ - Step 970 Global step 970 Train loss 0.03 on epoch=484
04/28/2022 07:55:48 - INFO - __main__ - Step 980 Global step 980 Train loss 0.05 on epoch=489
04/28/2022 07:55:51 - INFO - __main__ - Step 990 Global step 990 Train loss 0.03 on epoch=494
04/28/2022 07:55:53 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.03 on epoch=499
04/28/2022 07:55:54 - INFO - __main__ - Global step 1000 Train loss 0.04 ACC 0.5625 on epoch=499
04/28/2022 07:55:56 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.04 on epoch=504
04/28/2022 07:55:59 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.02 on epoch=509
04/28/2022 07:56:02 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.03 on epoch=514
04/28/2022 07:56:04 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.02 on epoch=519
04/28/2022 07:56:06 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.02 on epoch=524
04/28/2022 07:56:07 - INFO - __main__ - Global step 1050 Train loss 0.03 ACC 0.53125 on epoch=524
04/28/2022 07:56:10 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.03 on epoch=529
04/28/2022 07:56:12 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.02 on epoch=534
04/28/2022 07:56:15 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.03 on epoch=539
04/28/2022 07:56:17 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.03 on epoch=544
04/28/2022 07:56:20 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.05 on epoch=549
04/28/2022 07:56:20 - INFO - __main__ - Global step 1100 Train loss 0.03 ACC 0.5 on epoch=549
04/28/2022 07:56:23 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.05 on epoch=554
04/28/2022 07:56:25 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.03 on epoch=559
04/28/2022 07:56:28 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.05 on epoch=564
04/28/2022 07:56:30 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.02 on epoch=569
04/28/2022 07:56:33 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=574
04/28/2022 07:56:34 - INFO - __main__ - Global step 1150 Train loss 0.03 ACC 0.53125 on epoch=574
04/28/2022 07:56:36 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.02 on epoch=579
04/28/2022 07:56:39 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.01 on epoch=584
04/28/2022 07:56:41 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.03 on epoch=589
04/28/2022 07:56:44 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.02 on epoch=594
04/28/2022 07:56:47 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.03 on epoch=599
04/28/2022 07:56:47 - INFO - __main__ - Global step 1200 Train loss 0.02 ACC 0.59375 on epoch=599
04/28/2022 07:56:50 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.02 on epoch=604
04/28/2022 07:56:53 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.03 on epoch=609
04/28/2022 07:56:55 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.09 on epoch=614
04/28/2022 07:56:58 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.04 on epoch=619
04/28/2022 07:57:00 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.01 on epoch=624
04/28/2022 07:57:01 - INFO - __main__ - Global step 1250 Train loss 0.04 ACC 0.46875 on epoch=624
04/28/2022 07:57:04 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=629
04/28/2022 07:57:06 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.04 on epoch=634
04/28/2022 07:57:09 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.02 on epoch=639
04/28/2022 07:57:11 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.02 on epoch=644
04/28/2022 07:57:14 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.08 on epoch=649
04/28/2022 07:57:15 - INFO - __main__ - Global step 1300 Train loss 0.03 ACC 0.5625 on epoch=649
04/28/2022 07:57:17 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.02 on epoch=654
04/28/2022 07:57:20 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.04 on epoch=659
04/28/2022 07:57:22 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.03 on epoch=664
04/28/2022 07:57:25 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.04 on epoch=669
04/28/2022 07:57:28 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.02 on epoch=674
04/28/2022 07:57:28 - INFO - __main__ - Global step 1350 Train loss 0.03 ACC 0.53125 on epoch=674
04/28/2022 07:57:31 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=679
04/28/2022 07:57:33 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.05 on epoch=684
04/28/2022 07:57:36 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.03 on epoch=689
04/28/2022 07:57:38 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.04 on epoch=694
04/28/2022 07:57:41 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=699
04/28/2022 07:57:42 - INFO - __main__ - Global step 1400 Train loss 0.03 ACC 0.46875 on epoch=699
04/28/2022 07:57:44 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=704
04/28/2022 07:57:47 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=709
04/28/2022 07:57:50 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.03 on epoch=714
04/28/2022 07:57:52 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.05 on epoch=719
04/28/2022 07:57:55 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=724
04/28/2022 07:57:56 - INFO - __main__ - Global step 1450 Train loss 0.03 ACC 0.53125 on epoch=724
04/28/2022 07:57:58 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.04 on epoch=729
04/28/2022 07:58:01 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=734
04/28/2022 07:58:03 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=739
04/28/2022 07:58:06 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.04 on epoch=744
04/28/2022 07:58:08 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=749
04/28/2022 07:58:09 - INFO - __main__ - Global step 1500 Train loss 0.02 ACC 0.5625 on epoch=749
04/28/2022 07:58:12 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=754
04/28/2022 07:58:14 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=759
04/28/2022 07:58:17 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=764
04/28/2022 07:58:20 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=769
04/28/2022 07:58:22 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=774
04/28/2022 07:58:23 - INFO - __main__ - Global step 1550 Train loss 0.01 ACC 0.53125 on epoch=774
04/28/2022 07:58:26 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=779
04/28/2022 07:58:28 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=784
04/28/2022 07:58:31 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.03 on epoch=789
04/28/2022 07:58:33 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=794
04/28/2022 07:58:36 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=799
04/28/2022 07:58:37 - INFO - __main__ - Global step 1600 Train loss 0.02 ACC 0.59375 on epoch=799
04/28/2022 07:58:39 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=804
04/28/2022 07:58:42 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=809
04/28/2022 07:58:44 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=814
04/28/2022 07:58:47 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=819
04/28/2022 07:58:50 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=824
04/28/2022 07:58:50 - INFO - __main__ - Global step 1650 Train loss 0.01 ACC 0.59375 on epoch=824
04/28/2022 07:58:53 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=829
04/28/2022 07:58:56 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=834
04/28/2022 07:58:58 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=839
04/28/2022 07:59:01 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=844
04/28/2022 07:59:03 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=849
04/28/2022 07:59:04 - INFO - __main__ - Global step 1700 Train loss 0.00 ACC 0.53125 on epoch=849
04/28/2022 07:59:07 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=854
04/28/2022 07:59:09 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=859
04/28/2022 07:59:12 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=864
04/28/2022 07:59:14 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=869
04/28/2022 07:59:17 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=874
04/28/2022 07:59:18 - INFO - __main__ - Global step 1750 Train loss 0.00 ACC 0.53125 on epoch=874
04/28/2022 07:59:20 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=879
04/28/2022 07:59:23 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=884
04/28/2022 07:59:25 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=889
04/28/2022 07:59:28 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=894
04/28/2022 07:59:31 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=899
04/28/2022 07:59:31 - INFO - __main__ - Global step 1800 Train loss 0.00 ACC 0.5625 on epoch=899
04/28/2022 07:59:34 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=904
04/28/2022 07:59:37 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=909
04/28/2022 07:59:39 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=914
04/28/2022 07:59:42 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.04 on epoch=919
04/28/2022 07:59:44 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=924
04/28/2022 07:59:45 - INFO - __main__ - Global step 1850 Train loss 0.01 ACC 0.5625 on epoch=924
04/28/2022 07:59:48 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=929
04/28/2022 07:59:50 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.03 on epoch=934
04/28/2022 07:59:53 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=939
04/28/2022 07:59:55 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=944
04/28/2022 07:59:58 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=949
04/28/2022 07:59:59 - INFO - __main__ - Global step 1900 Train loss 0.01 ACC 0.5625 on epoch=949
04/28/2022 08:00:01 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=954
04/28/2022 08:00:04 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=959
04/28/2022 08:00:06 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=964
04/28/2022 08:00:09 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=969
04/28/2022 08:00:11 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=974
04/28/2022 08:00:12 - INFO - __main__ - Global step 1950 Train loss 0.01 ACC 0.5625 on epoch=974
04/28/2022 08:00:14 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=979
04/28/2022 08:00:17 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=984
04/28/2022 08:00:19 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=989
04/28/2022 08:00:22 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=994
04/28/2022 08:00:24 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=999
04/28/2022 08:00:25 - INFO - __main__ - Global step 2000 Train loss 0.00 ACC 0.59375 on epoch=999
04/28/2022 08:00:25 - INFO - __main__ - save last model!
04/28/2022 08:00:25 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
04/28/2022 08:00:25 - INFO - __main__ - Start tokenizing ... 1000 instances
04/28/2022 08:00:25 - INFO - __main__ - Printing 3 examples
04/28/2022 08:00:25 - INFO - __main__ -  [wino_grande] Sarah was a much better surgeon than Maria so _ always got the easier cases. (A) Sarah (B) Maria
04/28/2022 08:00:25 - INFO - __main__ - ['Maria']
04/28/2022 08:00:25 - INFO - __main__ -  [wino_grande] Sarah was a much better surgeon than Maria so _ always got the harder cases. (A) Sarah (B) Maria
04/28/2022 08:00:25 - INFO - __main__ - ['Sarah']
04/28/2022 08:00:25 - INFO - __main__ -  [wino_grande] They were worried the wine would ruin the bed and the blanket, but the _ was't ruined. (A) blanket (B) bed
04/28/2022 08:00:25 - INFO - __main__ - ['bed']
04/28/2022 08:00:25 - INFO - __main__ - Tokenizing Input ...
04/28/2022 08:00:26 - INFO - __main__ - Tokenizing Output ...
04/28/2022 08:00:26 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 08:00:26 - INFO - __main__ - Printing 3 examples
04/28/2022 08:00:26 - INFO - __main__ -  [wino_grande] Adam gave his friend an apple instead of an orange because his friend was quite fond of the _ . (A) orange (B) apple
04/28/2022 08:00:26 - INFO - __main__ - ['apple']
04/28/2022 08:00:26 - INFO - __main__ -  [wino_grande] William wants to file a lawsuit so he asks Aaron for help, because _ is a lawyer. (A) William (B) Aaron
04/28/2022 08:00:26 - INFO - __main__ - ['Aaron']
04/28/2022 08:00:26 - INFO - __main__ -  [wino_grande] Brian suffers a lot from loneliness compared to Brett because _ has lost all of his family. (A) Brian (B) Brett
04/28/2022 08:00:26 - INFO - __main__ - ['Brian']
04/28/2022 08:00:26 - INFO - __main__ - Tokenizing Input ...
04/28/2022 08:00:26 - INFO - __main__ - Tokenizing Output ...
04/28/2022 08:00:26 - INFO - __main__ - Loaded 32 examples from train data
04/28/2022 08:00:26 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 08:00:26 - INFO - __main__ - Printing 3 examples
04/28/2022 08:00:26 - INFO - __main__ -  [wino_grande] Although Elena hated sweets a whole lot more than Megan, _ was the one to own a bakery. (A) Elena (B) Megan
04/28/2022 08:00:26 - INFO - __main__ - ['Elena']
04/28/2022 08:00:26 - INFO - __main__ -  [wino_grande] The meeting took longer than the interview because there was more to cover during the _ . (A) meeting (B) interview
04/28/2022 08:00:26 - INFO - __main__ - ['meeting']
04/28/2022 08:00:26 - INFO - __main__ -  [wino_grande] Rebecca set out to walk around and recruit new members for Lindsey 's church because _ was old and disabled. (A) Rebecca (B) Lindsey
04/28/2022 08:00:26 - INFO - __main__ - ['Lindsey']
04/28/2022 08:00:26 - INFO - __main__ - Tokenizing Input ...
04/28/2022 08:00:26 - INFO - __main__ - Tokenizing Output ...
04/28/2022 08:00:26 - INFO - __main__ - Loaded 32 examples from dev data
04/28/2022 08:00:27 - INFO - __main__ - Loaded 1000 examples from test data
04/28/2022 08:00:45 - INFO - __main__ - load prompt embedding from ckpt
04/28/2022 08:00:45 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/28/2022 08:00:45 - INFO - __main__ - Starting training!
04/28/2022 08:00:48 - INFO - __main__ - Saved prediction in models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-wino_grande/wino_grande_32_87_0.5_8_predictions.txt
04/28/2022 08:00:48 - INFO - __main__ - ACC on test data: 0.5010
04/28/2022 08:00:49 - INFO - __main__ - prefix=wino_grande_32_87, lr=0.5, bsz=8, dev_performance=0.59375, test_performance=0.501
04/28/2022 08:00:49 - INFO - __main__ - Running ... prefix=wino_grande_32_87, lr=0.4, bsz=8 ...
04/28/2022 08:00:50 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 08:00:50 - INFO - __main__ - Printing 3 examples
04/28/2022 08:00:50 - INFO - __main__ -  [wino_grande] Adam gave his friend an apple instead of an orange because his friend was quite fond of the _ . (A) orange (B) apple
04/28/2022 08:00:50 - INFO - __main__ - ['apple']
04/28/2022 08:00:50 - INFO - __main__ -  [wino_grande] William wants to file a lawsuit so he asks Aaron for help, because _ is a lawyer. (A) William (B) Aaron
04/28/2022 08:00:50 - INFO - __main__ - ['Aaron']
04/28/2022 08:00:50 - INFO - __main__ -  [wino_grande] Brian suffers a lot from loneliness compared to Brett because _ has lost all of his family. (A) Brian (B) Brett
04/28/2022 08:00:50 - INFO - __main__ - ['Brian']
04/28/2022 08:00:50 - INFO - __main__ - Tokenizing Input ...
04/28/2022 08:00:50 - INFO - __main__ - Tokenizing Output ...
04/28/2022 08:00:50 - INFO - __main__ - Loaded 32 examples from train data
04/28/2022 08:00:50 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 08:00:50 - INFO - __main__ - Printing 3 examples
04/28/2022 08:00:50 - INFO - __main__ -  [wino_grande] Although Elena hated sweets a whole lot more than Megan, _ was the one to own a bakery. (A) Elena (B) Megan
04/28/2022 08:00:50 - INFO - __main__ - ['Elena']
04/28/2022 08:00:50 - INFO - __main__ -  [wino_grande] The meeting took longer than the interview because there was more to cover during the _ . (A) meeting (B) interview
04/28/2022 08:00:50 - INFO - __main__ - ['meeting']
04/28/2022 08:00:50 - INFO - __main__ -  [wino_grande] Rebecca set out to walk around and recruit new members for Lindsey 's church because _ was old and disabled. (A) Rebecca (B) Lindsey
04/28/2022 08:00:50 - INFO - __main__ - ['Lindsey']
04/28/2022 08:00:50 - INFO - __main__ - Tokenizing Input ...
04/28/2022 08:00:50 - INFO - __main__ - Tokenizing Output ...
04/28/2022 08:00:50 - INFO - __main__ - Loaded 32 examples from dev data
04/28/2022 08:01:08 - INFO - __main__ - load prompt embedding from ckpt
04/28/2022 08:01:09 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/28/2022 08:01:09 - INFO - __main__ - Starting training!
04/28/2022 08:01:12 - INFO - __main__ - Step 10 Global step 10 Train loss 3.57 on epoch=4
04/28/2022 08:01:15 - INFO - __main__ - Step 20 Global step 20 Train loss 1.50 on epoch=9
04/28/2022 08:01:17 - INFO - __main__ - Step 30 Global step 30 Train loss 0.70 on epoch=14
04/28/2022 08:01:20 - INFO - __main__ - Step 40 Global step 40 Train loss 0.63 on epoch=19
04/28/2022 08:01:22 - INFO - __main__ - Step 50 Global step 50 Train loss 0.59 on epoch=24
04/28/2022 08:01:23 - INFO - __main__ - Global step 50 Train loss 1.40 ACC 0.53125 on epoch=24
04/28/2022 08:01:23 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.53125 on epoch=24, global_step=50
04/28/2022 08:01:26 - INFO - __main__ - Step 60 Global step 60 Train loss 0.35 on epoch=29
04/28/2022 08:01:28 - INFO - __main__ - Step 70 Global step 70 Train loss 0.33 on epoch=34
04/28/2022 08:01:31 - INFO - __main__ - Step 80 Global step 80 Train loss 0.43 on epoch=39
04/28/2022 08:01:33 - INFO - __main__ - Step 90 Global step 90 Train loss 0.23 on epoch=44
04/28/2022 08:01:36 - INFO - __main__ - Step 100 Global step 100 Train loss 0.19 on epoch=49
04/28/2022 08:01:36 - INFO - __main__ - Global step 100 Train loss 0.31 ACC 0.5625 on epoch=49
04/28/2022 08:01:37 - INFO - __main__ - Saving model with best ACC: 0.53125 -> 0.5625 on epoch=49, global_step=100
04/28/2022 08:01:39 - INFO - __main__ - Step 110 Global step 110 Train loss 0.10 on epoch=54
04/28/2022 08:01:41 - INFO - __main__ - Step 120 Global step 120 Train loss 0.24 on epoch=59
04/28/2022 08:01:44 - INFO - __main__ - Step 130 Global step 130 Train loss 0.17 on epoch=64
04/28/2022 08:01:46 - INFO - __main__ - Step 140 Global step 140 Train loss 0.14 on epoch=69
04/28/2022 08:01:49 - INFO - __main__ - Step 150 Global step 150 Train loss 0.25 on epoch=74
04/28/2022 08:01:50 - INFO - __main__ - Global step 150 Train loss 0.18 ACC 0.4375 on epoch=74
04/28/2022 08:01:52 - INFO - __main__ - Step 160 Global step 160 Train loss 0.14 on epoch=79
04/28/2022 08:01:55 - INFO - __main__ - Step 170 Global step 170 Train loss 0.13 on epoch=84
04/28/2022 08:01:57 - INFO - __main__ - Step 180 Global step 180 Train loss 0.10 on epoch=89
04/28/2022 08:02:00 - INFO - __main__ - Step 190 Global step 190 Train loss 0.10 on epoch=94
04/28/2022 08:02:02 - INFO - __main__ - Step 200 Global step 200 Train loss 0.08 on epoch=99
04/28/2022 08:02:03 - INFO - __main__ - Global step 200 Train loss 0.11 ACC 0.46875 on epoch=99
04/28/2022 08:02:06 - INFO - __main__ - Step 210 Global step 210 Train loss 0.10 on epoch=104
04/28/2022 08:02:08 - INFO - __main__ - Step 220 Global step 220 Train loss 0.03 on epoch=109
04/28/2022 08:02:11 - INFO - __main__ - Step 230 Global step 230 Train loss 0.06 on epoch=114
04/28/2022 08:02:13 - INFO - __main__ - Step 240 Global step 240 Train loss 0.10 on epoch=119
04/28/2022 08:02:16 - INFO - __main__ - Step 250 Global step 250 Train loss 0.12 on epoch=124
04/28/2022 08:02:16 - INFO - __main__ - Global step 250 Train loss 0.08 ACC 0.40625 on epoch=124
04/28/2022 08:02:19 - INFO - __main__ - Step 260 Global step 260 Train loss 0.06 on epoch=129
04/28/2022 08:02:21 - INFO - __main__ - Step 270 Global step 270 Train loss 0.08 on epoch=134
04/28/2022 08:02:24 - INFO - __main__ - Step 280 Global step 280 Train loss 0.10 on epoch=139
04/28/2022 08:02:26 - INFO - __main__ - Step 290 Global step 290 Train loss 0.04 on epoch=144
04/28/2022 08:02:29 - INFO - __main__ - Step 300 Global step 300 Train loss 0.07 on epoch=149
04/28/2022 08:02:30 - INFO - __main__ - Global step 300 Train loss 0.07 ACC 0.46875 on epoch=149
04/28/2022 08:02:32 - INFO - __main__ - Step 310 Global step 310 Train loss 0.12 on epoch=154
04/28/2022 08:02:35 - INFO - __main__ - Step 320 Global step 320 Train loss 0.05 on epoch=159
04/28/2022 08:02:37 - INFO - __main__ - Step 330 Global step 330 Train loss 0.09 on epoch=164
04/28/2022 08:02:40 - INFO - __main__ - Step 340 Global step 340 Train loss 0.08 on epoch=169
04/28/2022 08:02:42 - INFO - __main__ - Step 350 Global step 350 Train loss 0.05 on epoch=174
04/28/2022 08:02:43 - INFO - __main__ - Global step 350 Train loss 0.08 ACC 0.5 on epoch=174
04/28/2022 08:02:45 - INFO - __main__ - Step 360 Global step 360 Train loss 0.17 on epoch=179
04/28/2022 08:02:48 - INFO - __main__ - Step 370 Global step 370 Train loss 0.06 on epoch=184
04/28/2022 08:02:50 - INFO - __main__ - Step 380 Global step 380 Train loss 0.13 on epoch=189
04/28/2022 08:02:53 - INFO - __main__ - Step 390 Global step 390 Train loss 0.07 on epoch=194
04/28/2022 08:02:55 - INFO - __main__ - Step 400 Global step 400 Train loss 0.03 on epoch=199
04/28/2022 08:02:56 - INFO - __main__ - Global step 400 Train loss 0.09 ACC 0.4375 on epoch=199
04/28/2022 08:02:59 - INFO - __main__ - Step 410 Global step 410 Train loss 0.06 on epoch=204
04/28/2022 08:03:01 - INFO - __main__ - Step 420 Global step 420 Train loss 0.07 on epoch=209
04/28/2022 08:03:04 - INFO - __main__ - Step 430 Global step 430 Train loss 0.03 on epoch=214
04/28/2022 08:03:06 - INFO - __main__ - Step 440 Global step 440 Train loss 0.09 on epoch=219
04/28/2022 08:03:09 - INFO - __main__ - Step 450 Global step 450 Train loss 0.07 on epoch=224
04/28/2022 08:03:10 - INFO - __main__ - Global step 450 Train loss 0.06 ACC 0.53125 on epoch=224
04/28/2022 08:03:12 - INFO - __main__ - Step 460 Global step 460 Train loss 0.04 on epoch=229
04/28/2022 08:03:15 - INFO - __main__ - Step 470 Global step 470 Train loss 0.06 on epoch=234
04/28/2022 08:03:17 - INFO - __main__ - Step 480 Global step 480 Train loss 0.06 on epoch=239
04/28/2022 08:03:20 - INFO - __main__ - Step 490 Global step 490 Train loss 0.06 on epoch=244
04/28/2022 08:03:22 - INFO - __main__ - Step 500 Global step 500 Train loss 0.05 on epoch=249
04/28/2022 08:03:23 - INFO - __main__ - Global step 500 Train loss 0.05 ACC 0.53125 on epoch=249
04/28/2022 08:03:25 - INFO - __main__ - Step 510 Global step 510 Train loss 0.07 on epoch=254
04/28/2022 08:03:28 - INFO - __main__ - Step 520 Global step 520 Train loss 0.05 on epoch=259
04/28/2022 08:03:30 - INFO - __main__ - Step 530 Global step 530 Train loss 0.03 on epoch=264
04/28/2022 08:03:33 - INFO - __main__ - Step 540 Global step 540 Train loss 0.05 on epoch=269
04/28/2022 08:03:35 - INFO - __main__ - Step 550 Global step 550 Train loss 0.20 on epoch=274
04/28/2022 08:03:36 - INFO - __main__ - Global step 550 Train loss 0.08 ACC 0.5 on epoch=274
04/28/2022 08:03:39 - INFO - __main__ - Step 560 Global step 560 Train loss 0.06 on epoch=279
04/28/2022 08:03:41 - INFO - __main__ - Step 570 Global step 570 Train loss 0.06 on epoch=284
04/28/2022 08:03:44 - INFO - __main__ - Step 580 Global step 580 Train loss 0.07 on epoch=289
04/28/2022 08:03:46 - INFO - __main__ - Step 590 Global step 590 Train loss 0.04 on epoch=294
04/28/2022 08:03:48 - INFO - __main__ - Step 600 Global step 600 Train loss 0.08 on epoch=299
04/28/2022 08:03:49 - INFO - __main__ - Global step 600 Train loss 0.06 ACC 0.53125 on epoch=299
04/28/2022 08:03:52 - INFO - __main__ - Step 610 Global step 610 Train loss 0.09 on epoch=304
04/28/2022 08:03:54 - INFO - __main__ - Step 620 Global step 620 Train loss 0.05 on epoch=309
04/28/2022 08:03:57 - INFO - __main__ - Step 630 Global step 630 Train loss 0.03 on epoch=314
04/28/2022 08:03:59 - INFO - __main__ - Step 640 Global step 640 Train loss 0.07 on epoch=319
04/28/2022 08:04:02 - INFO - __main__ - Step 650 Global step 650 Train loss 0.04 on epoch=324
04/28/2022 08:04:03 - INFO - __main__ - Global step 650 Train loss 0.06 ACC 0.59375 on epoch=324
04/28/2022 08:04:03 - INFO - __main__ - Saving model with best ACC: 0.5625 -> 0.59375 on epoch=324, global_step=650
04/28/2022 08:04:05 - INFO - __main__ - Step 660 Global step 660 Train loss 0.10 on epoch=329
04/28/2022 08:04:08 - INFO - __main__ - Step 670 Global step 670 Train loss 0.05 on epoch=334
04/28/2022 08:04:10 - INFO - __main__ - Step 680 Global step 680 Train loss 0.03 on epoch=339
04/28/2022 08:04:13 - INFO - __main__ - Step 690 Global step 690 Train loss 0.04 on epoch=344
04/28/2022 08:04:15 - INFO - __main__ - Step 700 Global step 700 Train loss 0.04 on epoch=349
04/28/2022 08:04:16 - INFO - __main__ - Global step 700 Train loss 0.05 ACC 0.53125 on epoch=349
04/28/2022 08:04:19 - INFO - __main__ - Step 710 Global step 710 Train loss 0.06 on epoch=354
04/28/2022 08:04:21 - INFO - __main__ - Step 720 Global step 720 Train loss 0.06 on epoch=359
04/28/2022 08:04:24 - INFO - __main__ - Step 730 Global step 730 Train loss 0.02 on epoch=364
04/28/2022 08:04:26 - INFO - __main__ - Step 740 Global step 740 Train loss 0.04 on epoch=369
04/28/2022 08:04:29 - INFO - __main__ - Step 750 Global step 750 Train loss 0.04 on epoch=374
04/28/2022 08:04:29 - INFO - __main__ - Global step 750 Train loss 0.04 ACC 0.53125 on epoch=374
04/28/2022 08:04:32 - INFO - __main__ - Step 760 Global step 760 Train loss 0.03 on epoch=379
04/28/2022 08:04:35 - INFO - __main__ - Step 770 Global step 770 Train loss 0.02 on epoch=384
04/28/2022 08:04:37 - INFO - __main__ - Step 780 Global step 780 Train loss 0.02 on epoch=389
04/28/2022 08:04:40 - INFO - __main__ - Step 790 Global step 790 Train loss 0.01 on epoch=394
04/28/2022 08:04:42 - INFO - __main__ - Step 800 Global step 800 Train loss 0.09 on epoch=399
04/28/2022 08:04:43 - INFO - __main__ - Global step 800 Train loss 0.03 ACC 0.46875 on epoch=399
04/28/2022 08:04:46 - INFO - __main__ - Step 810 Global step 810 Train loss 0.08 on epoch=404
04/28/2022 08:04:48 - INFO - __main__ - Step 820 Global step 820 Train loss 0.10 on epoch=409
04/28/2022 08:04:51 - INFO - __main__ - Step 830 Global step 830 Train loss 0.04 on epoch=414
04/28/2022 08:04:53 - INFO - __main__ - Step 840 Global step 840 Train loss 0.03 on epoch=419
04/28/2022 08:04:56 - INFO - __main__ - Step 850 Global step 850 Train loss 0.03 on epoch=424
04/28/2022 08:04:56 - INFO - __main__ - Global step 850 Train loss 0.06 ACC 0.46875 on epoch=424
04/28/2022 08:04:59 - INFO - __main__ - Step 860 Global step 860 Train loss 0.07 on epoch=429
04/28/2022 08:05:01 - INFO - __main__ - Step 870 Global step 870 Train loss 0.03 on epoch=434
04/28/2022 08:05:04 - INFO - __main__ - Step 880 Global step 880 Train loss 0.06 on epoch=439
04/28/2022 08:05:06 - INFO - __main__ - Step 890 Global step 890 Train loss 0.10 on epoch=444
04/28/2022 08:05:09 - INFO - __main__ - Step 900 Global step 900 Train loss 0.08 on epoch=449
04/28/2022 08:05:10 - INFO - __main__ - Global step 900 Train loss 0.07 ACC 0.5 on epoch=449
04/28/2022 08:05:12 - INFO - __main__ - Step 910 Global step 910 Train loss 0.02 on epoch=454
04/28/2022 08:05:15 - INFO - __main__ - Step 920 Global step 920 Train loss 0.09 on epoch=459
04/28/2022 08:05:17 - INFO - __main__ - Step 930 Global step 930 Train loss 0.04 on epoch=464
04/28/2022 08:05:20 - INFO - __main__ - Step 940 Global step 940 Train loss 0.02 on epoch=469
04/28/2022 08:05:22 - INFO - __main__ - Step 950 Global step 950 Train loss 0.03 on epoch=474
04/28/2022 08:05:23 - INFO - __main__ - Global step 950 Train loss 0.04 ACC 0.46875 on epoch=474
04/28/2022 08:05:26 - INFO - __main__ - Step 960 Global step 960 Train loss 0.07 on epoch=479
04/28/2022 08:05:28 - INFO - __main__ - Step 970 Global step 970 Train loss 0.05 on epoch=484
04/28/2022 08:05:31 - INFO - __main__ - Step 980 Global step 980 Train loss 0.05 on epoch=489
04/28/2022 08:05:33 - INFO - __main__ - Step 990 Global step 990 Train loss 0.01 on epoch=494
04/28/2022 08:05:36 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.04 on epoch=499
04/28/2022 08:05:37 - INFO - __main__ - Global step 1000 Train loss 0.04 ACC 0.53125 on epoch=499
04/28/2022 08:05:39 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.03 on epoch=504
04/28/2022 08:05:42 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.02 on epoch=509
04/28/2022 08:05:44 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.03 on epoch=514
04/28/2022 08:05:47 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.01 on epoch=519
04/28/2022 08:05:49 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.06 on epoch=524
04/28/2022 08:05:50 - INFO - __main__ - Global step 1050 Train loss 0.03 ACC 0.5 on epoch=524
04/28/2022 08:05:52 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.04 on epoch=529
04/28/2022 08:05:55 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.03 on epoch=534
04/28/2022 08:05:57 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.04 on epoch=539
04/28/2022 08:06:00 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.02 on epoch=544
04/28/2022 08:06:02 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.06 on epoch=549
04/28/2022 08:06:03 - INFO - __main__ - Global step 1100 Train loss 0.04 ACC 0.5 on epoch=549
04/28/2022 08:06:06 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.03 on epoch=554
04/28/2022 08:06:08 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.05 on epoch=559
04/28/2022 08:06:11 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.02 on epoch=564
04/28/2022 08:06:13 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.01 on epoch=569
04/28/2022 08:06:16 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.03 on epoch=574
04/28/2022 08:06:17 - INFO - __main__ - Global step 1150 Train loss 0.03 ACC 0.5 on epoch=574
04/28/2022 08:06:19 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.06 on epoch=579
04/28/2022 08:06:22 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.01 on epoch=584
04/28/2022 08:06:24 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.03 on epoch=589
04/28/2022 08:06:27 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.03 on epoch=594
04/28/2022 08:06:29 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.06 on epoch=599
04/28/2022 08:06:30 - INFO - __main__ - Global step 1200 Train loss 0.04 ACC 0.53125 on epoch=599
04/28/2022 08:06:33 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.02 on epoch=604
04/28/2022 08:06:36 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.06 on epoch=609
04/28/2022 08:06:38 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.03 on epoch=614
04/28/2022 08:06:41 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.05 on epoch=619
04/28/2022 08:06:43 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.09 on epoch=624
04/28/2022 08:06:44 - INFO - __main__ - Global step 1250 Train loss 0.05 ACC 0.53125 on epoch=624
04/28/2022 08:06:46 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.02 on epoch=629
04/28/2022 08:06:49 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.03 on epoch=634
04/28/2022 08:06:52 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.02 on epoch=639
04/28/2022 08:06:54 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=644
04/28/2022 08:06:57 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.10 on epoch=649
04/28/2022 08:06:57 - INFO - __main__ - Global step 1300 Train loss 0.04 ACC 0.46875 on epoch=649
04/28/2022 08:07:00 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.02 on epoch=654
04/28/2022 08:07:03 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=659
04/28/2022 08:07:05 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=664
04/28/2022 08:07:08 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=669
04/28/2022 08:07:10 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.03 on epoch=674
04/28/2022 08:07:11 - INFO - __main__ - Global step 1350 Train loss 0.02 ACC 0.4375 on epoch=674
04/28/2022 08:07:13 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.02 on epoch=679
04/28/2022 08:07:16 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.02 on epoch=684
04/28/2022 08:07:19 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.02 on epoch=689
04/28/2022 08:07:21 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.04 on epoch=694
04/28/2022 08:07:24 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=699
04/28/2022 08:07:24 - INFO - __main__ - Global step 1400 Train loss 0.02 ACC 0.53125 on epoch=699
04/28/2022 08:07:27 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.02 on epoch=704
04/28/2022 08:07:30 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.01 on epoch=709
04/28/2022 08:07:32 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=714
04/28/2022 08:07:35 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=719
04/28/2022 08:07:37 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=724
04/28/2022 08:07:38 - INFO - __main__ - Global step 1450 Train loss 0.01 ACC 0.53125 on epoch=724
04/28/2022 08:07:41 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=729
04/28/2022 08:07:43 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=734
04/28/2022 08:07:46 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.02 on epoch=739
04/28/2022 08:07:48 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=744
04/28/2022 08:07:51 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.02 on epoch=749
04/28/2022 08:07:52 - INFO - __main__ - Global step 1500 Train loss 0.01 ACC 0.46875 on epoch=749
04/28/2022 08:07:54 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=754
04/28/2022 08:07:57 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=759
04/28/2022 08:07:59 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=764
04/28/2022 08:08:02 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=769
04/28/2022 08:08:04 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=774
04/28/2022 08:08:05 - INFO - __main__ - Global step 1550 Train loss 0.01 ACC 0.53125 on epoch=774
04/28/2022 08:08:07 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.04 on epoch=779
04/28/2022 08:08:10 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=784
04/28/2022 08:08:13 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=789
04/28/2022 08:08:15 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=794
04/28/2022 08:08:18 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=799
04/28/2022 08:08:18 - INFO - __main__ - Global step 1600 Train loss 0.01 ACC 0.5625 on epoch=799
04/28/2022 08:08:21 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=804
04/28/2022 08:08:23 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=809
04/28/2022 08:08:26 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=814
04/28/2022 08:08:28 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.07 on epoch=819
04/28/2022 08:08:31 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=824
04/28/2022 08:08:32 - INFO - __main__ - Global step 1650 Train loss 0.02 ACC 0.46875 on epoch=824
04/28/2022 08:08:34 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=829
04/28/2022 08:08:37 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=834
04/28/2022 08:08:39 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=839
04/28/2022 08:08:42 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=844
04/28/2022 08:08:44 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=849
04/28/2022 08:08:45 - INFO - __main__ - Global step 1700 Train loss 0.01 ACC 0.46875 on epoch=849
04/28/2022 08:08:48 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=854
04/28/2022 08:08:50 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=859
04/28/2022 08:08:53 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=864
04/28/2022 08:08:55 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=869
04/28/2022 08:08:58 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=874
04/28/2022 08:08:59 - INFO - __main__ - Global step 1750 Train loss 0.01 ACC 0.46875 on epoch=874
04/28/2022 08:09:01 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=879
04/28/2022 08:09:04 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=884
04/28/2022 08:09:06 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=889
04/28/2022 08:09:09 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=894
04/28/2022 08:09:11 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=899
04/28/2022 08:09:12 - INFO - __main__ - Global step 1800 Train loss 0.00 ACC 0.5 on epoch=899
04/28/2022 08:09:15 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=904
04/28/2022 08:09:17 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=909
04/28/2022 08:09:20 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=914
04/28/2022 08:09:22 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=919
04/28/2022 08:09:25 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=924
04/28/2022 08:09:25 - INFO - __main__ - Global step 1850 Train loss 0.01 ACC 0.46875 on epoch=924
04/28/2022 08:09:28 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=929
04/28/2022 08:09:30 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=934
04/28/2022 08:09:33 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=939
04/28/2022 08:09:35 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=944
04/28/2022 08:09:38 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=949
04/28/2022 08:09:39 - INFO - __main__ - Global step 1900 Train loss 0.00 ACC 0.46875 on epoch=949
04/28/2022 08:09:41 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=954
04/28/2022 08:09:44 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=959
04/28/2022 08:09:46 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=964
04/28/2022 08:09:49 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=969
04/28/2022 08:09:51 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=974
04/28/2022 08:09:52 - INFO - __main__ - Global step 1950 Train loss 0.00 ACC 0.5 on epoch=974
04/28/2022 08:09:54 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=979
04/28/2022 08:09:57 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=984
04/28/2022 08:09:59 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.05 on epoch=989
04/28/2022 08:10:02 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=994
04/28/2022 08:10:04 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=999
04/28/2022 08:10:05 - INFO - __main__ - Global step 2000 Train loss 0.02 ACC 0.46875 on epoch=999
04/28/2022 08:10:05 - INFO - __main__ - save last model!
04/28/2022 08:10:05 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
04/28/2022 08:10:05 - INFO - __main__ - Start tokenizing ... 1000 instances
04/28/2022 08:10:05 - INFO - __main__ - Printing 3 examples
04/28/2022 08:10:05 - INFO - __main__ -  [wino_grande] Sarah was a much better surgeon than Maria so _ always got the easier cases. (A) Sarah (B) Maria
04/28/2022 08:10:05 - INFO - __main__ - ['Maria']
04/28/2022 08:10:05 - INFO - __main__ -  [wino_grande] Sarah was a much better surgeon than Maria so _ always got the harder cases. (A) Sarah (B) Maria
04/28/2022 08:10:05 - INFO - __main__ - ['Sarah']
04/28/2022 08:10:05 - INFO - __main__ -  [wino_grande] They were worried the wine would ruin the bed and the blanket, but the _ was't ruined. (A) blanket (B) bed
04/28/2022 08:10:05 - INFO - __main__ - ['bed']
04/28/2022 08:10:05 - INFO - __main__ - Tokenizing Input ...
04/28/2022 08:10:05 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 08:10:05 - INFO - __main__ - Printing 3 examples
04/28/2022 08:10:05 - INFO - __main__ -  [wino_grande] Adam gave his friend an apple instead of an orange because his friend was quite fond of the _ . (A) orange (B) apple
04/28/2022 08:10:05 - INFO - __main__ - ['apple']
04/28/2022 08:10:05 - INFO - __main__ -  [wino_grande] William wants to file a lawsuit so he asks Aaron for help, because _ is a lawyer. (A) William (B) Aaron
04/28/2022 08:10:05 - INFO - __main__ - ['Aaron']
04/28/2022 08:10:05 - INFO - __main__ -  [wino_grande] Brian suffers a lot from loneliness compared to Brett because _ has lost all of his family. (A) Brian (B) Brett
04/28/2022 08:10:05 - INFO - __main__ - ['Brian']
04/28/2022 08:10:05 - INFO - __main__ - Tokenizing Input ...
04/28/2022 08:10:05 - INFO - __main__ - Tokenizing Output ...
04/28/2022 08:10:06 - INFO - __main__ - Loaded 32 examples from train data
04/28/2022 08:10:06 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 08:10:06 - INFO - __main__ - Printing 3 examples
04/28/2022 08:10:06 - INFO - __main__ -  [wino_grande] Although Elena hated sweets a whole lot more than Megan, _ was the one to own a bakery. (A) Elena (B) Megan
04/28/2022 08:10:06 - INFO - __main__ - ['Elena']
04/28/2022 08:10:06 - INFO - __main__ -  [wino_grande] The meeting took longer than the interview because there was more to cover during the _ . (A) meeting (B) interview
04/28/2022 08:10:06 - INFO - __main__ - Tokenizing Output ...
04/28/2022 08:10:06 - INFO - __main__ - ['meeting']
04/28/2022 08:10:06 - INFO - __main__ -  [wino_grande] Rebecca set out to walk around and recruit new members for Lindsey 's church because _ was old and disabled. (A) Rebecca (B) Lindsey
04/28/2022 08:10:06 - INFO - __main__ - ['Lindsey']
04/28/2022 08:10:06 - INFO - __main__ - Tokenizing Input ...
04/28/2022 08:10:06 - INFO - __main__ - Tokenizing Output ...
04/28/2022 08:10:06 - INFO - __main__ - Loaded 32 examples from dev data
04/28/2022 08:10:07 - INFO - __main__ - Loaded 1000 examples from test data
04/28/2022 08:10:21 - INFO - __main__ - load prompt embedding from ckpt
04/28/2022 08:10:22 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/28/2022 08:10:22 - INFO - __main__ - Starting training!
04/28/2022 08:10:30 - INFO - __main__ - Saved prediction in models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-wino_grande/wino_grande_32_87_0.4_8_predictions.txt
04/28/2022 08:10:30 - INFO - __main__ - ACC on test data: 0.4850
04/28/2022 08:10:30 - INFO - __main__ - prefix=wino_grande_32_87, lr=0.4, bsz=8, dev_performance=0.59375, test_performance=0.485
04/28/2022 08:10:30 - INFO - __main__ - Running ... prefix=wino_grande_32_87, lr=0.3, bsz=8 ...
04/28/2022 08:10:31 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 08:10:31 - INFO - __main__ - Printing 3 examples
04/28/2022 08:10:31 - INFO - __main__ -  [wino_grande] Adam gave his friend an apple instead of an orange because his friend was quite fond of the _ . (A) orange (B) apple
04/28/2022 08:10:31 - INFO - __main__ - ['apple']
04/28/2022 08:10:31 - INFO - __main__ -  [wino_grande] William wants to file a lawsuit so he asks Aaron for help, because _ is a lawyer. (A) William (B) Aaron
04/28/2022 08:10:31 - INFO - __main__ - ['Aaron']
04/28/2022 08:10:31 - INFO - __main__ -  [wino_grande] Brian suffers a lot from loneliness compared to Brett because _ has lost all of his family. (A) Brian (B) Brett
04/28/2022 08:10:31 - INFO - __main__ - ['Brian']
04/28/2022 08:10:31 - INFO - __main__ - Tokenizing Input ...
04/28/2022 08:10:31 - INFO - __main__ - Tokenizing Output ...
04/28/2022 08:10:31 - INFO - __main__ - Loaded 32 examples from train data
04/28/2022 08:10:31 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 08:10:31 - INFO - __main__ - Printing 3 examples
04/28/2022 08:10:31 - INFO - __main__ -  [wino_grande] Although Elena hated sweets a whole lot more than Megan, _ was the one to own a bakery. (A) Elena (B) Megan
04/28/2022 08:10:31 - INFO - __main__ - ['Elena']
04/28/2022 08:10:31 - INFO - __main__ -  [wino_grande] The meeting took longer than the interview because there was more to cover during the _ . (A) meeting (B) interview
04/28/2022 08:10:31 - INFO - __main__ - ['meeting']
04/28/2022 08:10:31 - INFO - __main__ -  [wino_grande] Rebecca set out to walk around and recruit new members for Lindsey 's church because _ was old and disabled. (A) Rebecca (B) Lindsey
04/28/2022 08:10:31 - INFO - __main__ - ['Lindsey']
04/28/2022 08:10:31 - INFO - __main__ - Tokenizing Input ...
04/28/2022 08:10:31 - INFO - __main__ - Tokenizing Output ...
04/28/2022 08:10:31 - INFO - __main__ - Loaded 32 examples from dev data
04/28/2022 08:10:50 - INFO - __main__ - load prompt embedding from ckpt
04/28/2022 08:10:50 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/28/2022 08:10:50 - INFO - __main__ - Starting training!
04/28/2022 08:10:53 - INFO - __main__ - Step 10 Global step 10 Train loss 3.83 on epoch=4
04/28/2022 08:10:56 - INFO - __main__ - Step 20 Global step 20 Train loss 1.59 on epoch=9
04/28/2022 08:10:58 - INFO - __main__ - Step 30 Global step 30 Train loss 0.75 on epoch=14
04/28/2022 08:11:01 - INFO - __main__ - Step 40 Global step 40 Train loss 0.77 on epoch=19
04/28/2022 08:11:03 - INFO - __main__ - Step 50 Global step 50 Train loss 0.69 on epoch=24
04/28/2022 08:11:04 - INFO - __main__ - Global step 50 Train loss 1.53 ACC 0.5 on epoch=24
04/28/2022 08:11:04 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.5 on epoch=24, global_step=50
04/28/2022 08:11:07 - INFO - __main__ - Step 60 Global step 60 Train loss 0.55 on epoch=29
04/28/2022 08:11:09 - INFO - __main__ - Step 70 Global step 70 Train loss 0.44 on epoch=34
04/28/2022 08:11:12 - INFO - __main__ - Step 80 Global step 80 Train loss 0.38 on epoch=39
04/28/2022 08:11:14 - INFO - __main__ - Step 90 Global step 90 Train loss 0.39 on epoch=44
04/28/2022 08:11:17 - INFO - __main__ - Step 100 Global step 100 Train loss 0.26 on epoch=49
04/28/2022 08:11:18 - INFO - __main__ - Global step 100 Train loss 0.40 ACC 0.4375 on epoch=49
04/28/2022 08:11:20 - INFO - __main__ - Step 110 Global step 110 Train loss 0.31 on epoch=54
04/28/2022 08:11:23 - INFO - __main__ - Step 120 Global step 120 Train loss 0.20 on epoch=59
04/28/2022 08:11:25 - INFO - __main__ - Step 130 Global step 130 Train loss 0.20 on epoch=64
04/28/2022 08:11:28 - INFO - __main__ - Step 140 Global step 140 Train loss 0.29 on epoch=69
04/28/2022 08:11:30 - INFO - __main__ - Step 150 Global step 150 Train loss 0.15 on epoch=74
04/28/2022 08:11:31 - INFO - __main__ - Global step 150 Train loss 0.23 ACC 0.34375 on epoch=74
04/28/2022 08:11:33 - INFO - __main__ - Step 160 Global step 160 Train loss 0.14 on epoch=79
04/28/2022 08:11:36 - INFO - __main__ - Step 170 Global step 170 Train loss 0.19 on epoch=84
04/28/2022 08:11:38 - INFO - __main__ - Step 180 Global step 180 Train loss 0.13 on epoch=89
04/28/2022 08:11:41 - INFO - __main__ - Step 190 Global step 190 Train loss 0.17 on epoch=94
04/28/2022 08:11:43 - INFO - __main__ - Step 200 Global step 200 Train loss 0.14 on epoch=99
04/28/2022 08:11:44 - INFO - __main__ - Global step 200 Train loss 0.15 ACC 0.40625 on epoch=99
04/28/2022 08:11:47 - INFO - __main__ - Step 210 Global step 210 Train loss 0.14 on epoch=104
04/28/2022 08:11:49 - INFO - __main__ - Step 220 Global step 220 Train loss 0.11 on epoch=109
04/28/2022 08:11:52 - INFO - __main__ - Step 230 Global step 230 Train loss 0.10 on epoch=114
04/28/2022 08:11:54 - INFO - __main__ - Step 240 Global step 240 Train loss 0.09 on epoch=119
04/28/2022 08:11:57 - INFO - __main__ - Step 250 Global step 250 Train loss 0.14 on epoch=124
04/28/2022 08:11:58 - INFO - __main__ - Global step 250 Train loss 0.12 ACC 0.5 on epoch=124
04/28/2022 08:12:00 - INFO - __main__ - Step 260 Global step 260 Train loss 0.12 on epoch=129
04/28/2022 08:12:03 - INFO - __main__ - Step 270 Global step 270 Train loss 0.08 on epoch=134
04/28/2022 08:12:05 - INFO - __main__ - Step 280 Global step 280 Train loss 0.13 on epoch=139
04/28/2022 08:12:08 - INFO - __main__ - Step 290 Global step 290 Train loss 0.12 on epoch=144
04/28/2022 08:12:10 - INFO - __main__ - Step 300 Global step 300 Train loss 0.17 on epoch=149
04/28/2022 08:12:11 - INFO - __main__ - Global step 300 Train loss 0.12 ACC 0.5 on epoch=149
04/28/2022 08:12:13 - INFO - __main__ - Step 310 Global step 310 Train loss 0.08 on epoch=154
04/28/2022 08:12:16 - INFO - __main__ - Step 320 Global step 320 Train loss 0.12 on epoch=159
04/28/2022 08:12:18 - INFO - __main__ - Step 330 Global step 330 Train loss 0.08 on epoch=164
04/28/2022 08:12:21 - INFO - __main__ - Step 340 Global step 340 Train loss 0.18 on epoch=169
04/28/2022 08:12:23 - INFO - __main__ - Step 350 Global step 350 Train loss 0.11 on epoch=174
04/28/2022 08:12:24 - INFO - __main__ - Global step 350 Train loss 0.12 ACC 0.46875 on epoch=174
04/28/2022 08:12:27 - INFO - __main__ - Step 360 Global step 360 Train loss 0.16 on epoch=179
04/28/2022 08:12:29 - INFO - __main__ - Step 370 Global step 370 Train loss 0.04 on epoch=184
04/28/2022 08:12:32 - INFO - __main__ - Step 380 Global step 380 Train loss 0.13 on epoch=189
04/28/2022 08:12:34 - INFO - __main__ - Step 390 Global step 390 Train loss 0.10 on epoch=194
04/28/2022 08:12:37 - INFO - __main__ - Step 400 Global step 400 Train loss 0.06 on epoch=199
04/28/2022 08:12:38 - INFO - __main__ - Global step 400 Train loss 0.10 ACC 0.5 on epoch=199
04/28/2022 08:12:40 - INFO - __main__ - Step 410 Global step 410 Train loss 0.15 on epoch=204
04/28/2022 08:12:43 - INFO - __main__ - Step 420 Global step 420 Train loss 0.05 on epoch=209
04/28/2022 08:12:45 - INFO - __main__ - Step 430 Global step 430 Train loss 0.07 on epoch=214
04/28/2022 08:12:48 - INFO - __main__ - Step 440 Global step 440 Train loss 0.09 on epoch=219
04/28/2022 08:12:50 - INFO - __main__ - Step 450 Global step 450 Train loss 0.03 on epoch=224
04/28/2022 08:12:51 - INFO - __main__ - Global step 450 Train loss 0.08 ACC 0.53125 on epoch=224
04/28/2022 08:12:51 - INFO - __main__ - Saving model with best ACC: 0.5 -> 0.53125 on epoch=224, global_step=450
04/28/2022 08:12:53 - INFO - __main__ - Step 460 Global step 460 Train loss 0.05 on epoch=229
04/28/2022 08:12:56 - INFO - __main__ - Step 470 Global step 470 Train loss 0.10 on epoch=234
04/28/2022 08:12:58 - INFO - __main__ - Step 480 Global step 480 Train loss 0.09 on epoch=239
04/28/2022 08:13:01 - INFO - __main__ - Step 490 Global step 490 Train loss 0.08 on epoch=244
04/28/2022 08:13:03 - INFO - __main__ - Step 500 Global step 500 Train loss 0.13 on epoch=249
04/28/2022 08:13:04 - INFO - __main__ - Global step 500 Train loss 0.09 ACC 0.46875 on epoch=249
04/28/2022 08:13:07 - INFO - __main__ - Step 510 Global step 510 Train loss 0.04 on epoch=254
04/28/2022 08:13:09 - INFO - __main__ - Step 520 Global step 520 Train loss 0.05 on epoch=259
04/28/2022 08:13:12 - INFO - __main__ - Step 530 Global step 530 Train loss 0.10 on epoch=264
04/28/2022 08:13:14 - INFO - __main__ - Step 540 Global step 540 Train loss 0.07 on epoch=269
04/28/2022 08:13:17 - INFO - __main__ - Step 550 Global step 550 Train loss 0.04 on epoch=274
04/28/2022 08:13:18 - INFO - __main__ - Global step 550 Train loss 0.06 ACC 0.53125 on epoch=274
04/28/2022 08:13:20 - INFO - __main__ - Step 560 Global step 560 Train loss 0.04 on epoch=279
04/28/2022 08:13:22 - INFO - __main__ - Step 570 Global step 570 Train loss 0.02 on epoch=284
04/28/2022 08:13:25 - INFO - __main__ - Step 580 Global step 580 Train loss 0.04 on epoch=289
04/28/2022 08:13:27 - INFO - __main__ - Step 590 Global step 590 Train loss 0.15 on epoch=294
04/28/2022 08:13:30 - INFO - __main__ - Step 600 Global step 600 Train loss 0.07 on epoch=299
04/28/2022 08:13:31 - INFO - __main__ - Global step 600 Train loss 0.06 ACC 0.5 on epoch=299
04/28/2022 08:13:33 - INFO - __main__ - Step 610 Global step 610 Train loss 0.07 on epoch=304
04/28/2022 08:13:36 - INFO - __main__ - Step 620 Global step 620 Train loss 0.08 on epoch=309
04/28/2022 08:13:38 - INFO - __main__ - Step 630 Global step 630 Train loss 0.04 on epoch=314
04/28/2022 08:13:41 - INFO - __main__ - Step 640 Global step 640 Train loss 0.13 on epoch=319
04/28/2022 08:13:43 - INFO - __main__ - Step 650 Global step 650 Train loss 0.06 on epoch=324
04/28/2022 08:13:44 - INFO - __main__ - Global step 650 Train loss 0.08 ACC 0.46875 on epoch=324
04/28/2022 08:13:47 - INFO - __main__ - Step 660 Global step 660 Train loss 0.08 on epoch=329
04/28/2022 08:13:49 - INFO - __main__ - Step 670 Global step 670 Train loss 0.03 on epoch=334
04/28/2022 08:13:52 - INFO - __main__ - Step 680 Global step 680 Train loss 0.04 on epoch=339
04/28/2022 08:13:54 - INFO - __main__ - Step 690 Global step 690 Train loss 0.08 on epoch=344
04/28/2022 08:13:56 - INFO - __main__ - Step 700 Global step 700 Train loss 0.08 on epoch=349
04/28/2022 08:13:57 - INFO - __main__ - Global step 700 Train loss 0.06 ACC 0.5 on epoch=349
04/28/2022 08:14:00 - INFO - __main__ - Step 710 Global step 710 Train loss 0.05 on epoch=354
04/28/2022 08:14:02 - INFO - __main__ - Step 720 Global step 720 Train loss 0.07 on epoch=359
04/28/2022 08:14:05 - INFO - __main__ - Step 730 Global step 730 Train loss 0.09 on epoch=364
04/28/2022 08:14:07 - INFO - __main__ - Step 740 Global step 740 Train loss 0.09 on epoch=369
04/28/2022 08:14:10 - INFO - __main__ - Step 750 Global step 750 Train loss 0.04 on epoch=374
04/28/2022 08:14:10 - INFO - __main__ - Global step 750 Train loss 0.07 ACC 0.5 on epoch=374
04/28/2022 08:14:13 - INFO - __main__ - Step 760 Global step 760 Train loss 0.09 on epoch=379
04/28/2022 08:14:15 - INFO - __main__ - Step 770 Global step 770 Train loss 0.04 on epoch=384
04/28/2022 08:14:18 - INFO - __main__ - Step 780 Global step 780 Train loss 0.04 on epoch=389
04/28/2022 08:14:20 - INFO - __main__ - Step 790 Global step 790 Train loss 0.04 on epoch=394
04/28/2022 08:14:23 - INFO - __main__ - Step 800 Global step 800 Train loss 0.08 on epoch=399
04/28/2022 08:14:24 - INFO - __main__ - Global step 800 Train loss 0.06 ACC 0.40625 on epoch=399
04/28/2022 08:14:26 - INFO - __main__ - Step 810 Global step 810 Train loss 0.03 on epoch=404
04/28/2022 08:14:29 - INFO - __main__ - Step 820 Global step 820 Train loss 0.07 on epoch=409
04/28/2022 08:14:31 - INFO - __main__ - Step 830 Global step 830 Train loss 0.06 on epoch=414
04/28/2022 08:14:34 - INFO - __main__ - Step 840 Global step 840 Train loss 0.04 on epoch=419
04/28/2022 08:14:36 - INFO - __main__ - Step 850 Global step 850 Train loss 0.02 on epoch=424
04/28/2022 08:14:37 - INFO - __main__ - Global step 850 Train loss 0.04 ACC 0.5 on epoch=424
04/28/2022 08:14:39 - INFO - __main__ - Step 860 Global step 860 Train loss 0.04 on epoch=429
04/28/2022 08:14:42 - INFO - __main__ - Step 870 Global step 870 Train loss 0.05 on epoch=434
04/28/2022 08:14:44 - INFO - __main__ - Step 880 Global step 880 Train loss 0.07 on epoch=439
04/28/2022 08:14:47 - INFO - __main__ - Step 890 Global step 890 Train loss 0.06 on epoch=444
04/28/2022 08:14:49 - INFO - __main__ - Step 900 Global step 900 Train loss 0.06 on epoch=449
04/28/2022 08:14:50 - INFO - __main__ - Global step 900 Train loss 0.06 ACC 0.53125 on epoch=449
04/28/2022 08:14:53 - INFO - __main__ - Step 910 Global step 910 Train loss 0.05 on epoch=454
04/28/2022 08:14:55 - INFO - __main__ - Step 920 Global step 920 Train loss 0.04 on epoch=459
04/28/2022 08:14:58 - INFO - __main__ - Step 930 Global step 930 Train loss 0.01 on epoch=464
04/28/2022 08:15:00 - INFO - __main__ - Step 940 Global step 940 Train loss 0.10 on epoch=469
04/28/2022 08:15:03 - INFO - __main__ - Step 950 Global step 950 Train loss 0.04 on epoch=474
04/28/2022 08:15:04 - INFO - __main__ - Global step 950 Train loss 0.05 ACC 0.46875 on epoch=474
04/28/2022 08:15:06 - INFO - __main__ - Step 960 Global step 960 Train loss 0.03 on epoch=479
04/28/2022 08:15:09 - INFO - __main__ - Step 970 Global step 970 Train loss 0.09 on epoch=484
04/28/2022 08:15:11 - INFO - __main__ - Step 980 Global step 980 Train loss 0.04 on epoch=489
04/28/2022 08:15:14 - INFO - __main__ - Step 990 Global step 990 Train loss 0.05 on epoch=494
04/28/2022 08:15:16 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.02 on epoch=499
04/28/2022 08:15:17 - INFO - __main__ - Global step 1000 Train loss 0.05 ACC 0.5 on epoch=499
04/28/2022 08:15:19 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.04 on epoch=504
04/28/2022 08:15:22 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.14 on epoch=509
04/28/2022 08:15:24 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.03 on epoch=514
04/28/2022 08:15:27 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.03 on epoch=519
04/28/2022 08:15:29 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.04 on epoch=524
04/28/2022 08:15:30 - INFO - __main__ - Global step 1050 Train loss 0.06 ACC 0.53125 on epoch=524
04/28/2022 08:15:33 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.04 on epoch=529
04/28/2022 08:15:35 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.04 on epoch=534
04/28/2022 08:15:38 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.02 on epoch=539
04/28/2022 08:15:40 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.06 on epoch=544
04/28/2022 08:15:43 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.04 on epoch=549
04/28/2022 08:15:44 - INFO - __main__ - Global step 1100 Train loss 0.04 ACC 0.46875 on epoch=549
04/28/2022 08:15:46 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.02 on epoch=554
04/28/2022 08:15:49 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.03 on epoch=559
04/28/2022 08:15:51 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.02 on epoch=564
04/28/2022 08:15:54 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.03 on epoch=569
04/28/2022 08:15:56 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.05 on epoch=574
04/28/2022 08:15:57 - INFO - __main__ - Global step 1150 Train loss 0.03 ACC 0.53125 on epoch=574
04/28/2022 08:15:59 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.04 on epoch=579
04/28/2022 08:16:02 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.03 on epoch=584
04/28/2022 08:16:05 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.05 on epoch=589
04/28/2022 08:16:07 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.05 on epoch=594
04/28/2022 08:16:10 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=599
04/28/2022 08:16:10 - INFO - __main__ - Global step 1200 Train loss 0.04 ACC 0.53125 on epoch=599
04/28/2022 08:16:13 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.02 on epoch=604
04/28/2022 08:16:15 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.06 on epoch=609
04/28/2022 08:16:18 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=614
04/28/2022 08:16:20 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.02 on epoch=619
04/28/2022 08:16:23 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.02 on epoch=624
04/28/2022 08:16:24 - INFO - __main__ - Global step 1250 Train loss 0.03 ACC 0.5 on epoch=624
04/28/2022 08:16:26 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.07 on epoch=629
04/28/2022 08:16:29 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.08 on epoch=634
04/28/2022 08:16:31 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.02 on epoch=639
04/28/2022 08:16:34 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.03 on epoch=644
04/28/2022 08:16:36 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.02 on epoch=649
04/28/2022 08:16:37 - INFO - __main__ - Global step 1300 Train loss 0.04 ACC 0.59375 on epoch=649
04/28/2022 08:16:37 - INFO - __main__ - Saving model with best ACC: 0.53125 -> 0.59375 on epoch=649, global_step=1300
04/28/2022 08:16:39 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=654
04/28/2022 08:16:42 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.03 on epoch=659
04/28/2022 08:16:44 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.04 on epoch=664
04/28/2022 08:16:47 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=669
04/28/2022 08:16:50 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.05 on epoch=674
04/28/2022 08:16:50 - INFO - __main__ - Global step 1350 Train loss 0.03 ACC 0.53125 on epoch=674
04/28/2022 08:16:53 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.02 on epoch=679
04/28/2022 08:16:55 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.02 on epoch=684
04/28/2022 08:16:58 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.05 on epoch=689
04/28/2022 08:17:00 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.00 on epoch=694
04/28/2022 08:17:03 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.08 on epoch=699
04/28/2022 08:17:04 - INFO - __main__ - Global step 1400 Train loss 0.03 ACC 0.5625 on epoch=699
04/28/2022 08:17:06 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=704
04/28/2022 08:17:09 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=709
04/28/2022 08:17:11 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.02 on epoch=714
04/28/2022 08:17:14 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=719
04/28/2022 08:17:16 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=724
04/28/2022 08:17:17 - INFO - __main__ - Global step 1450 Train loss 0.01 ACC 0.59375 on epoch=724
04/28/2022 08:17:20 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.06 on epoch=729
04/28/2022 08:17:22 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=734
04/28/2022 08:17:25 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=739
04/28/2022 08:17:27 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=744
04/28/2022 08:17:30 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.08 on epoch=749
04/28/2022 08:17:30 - INFO - __main__ - Global step 1500 Train loss 0.03 ACC 0.53125 on epoch=749
04/28/2022 08:17:33 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=754
04/28/2022 08:17:35 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=759
04/28/2022 08:17:38 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=764
04/28/2022 08:17:40 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=769
04/28/2022 08:17:43 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=774
04/28/2022 08:17:44 - INFO - __main__ - Global step 1550 Train loss 0.01 ACC 0.5 on epoch=774
04/28/2022 08:17:46 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=779
04/28/2022 08:17:49 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.03 on epoch=784
04/28/2022 08:17:51 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=789
04/28/2022 08:17:54 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.03 on epoch=794
04/28/2022 08:17:56 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=799
04/28/2022 08:17:57 - INFO - __main__ - Global step 1600 Train loss 0.01 ACC 0.5 on epoch=799
04/28/2022 08:18:00 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=804
04/28/2022 08:18:02 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=809
04/28/2022 08:18:05 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=814
04/28/2022 08:18:07 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=819
04/28/2022 08:18:10 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=824
04/28/2022 08:18:11 - INFO - __main__ - Global step 1650 Train loss 0.00 ACC 0.46875 on epoch=824
04/28/2022 08:18:13 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=829
04/28/2022 08:18:16 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=834
04/28/2022 08:18:18 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=839
04/28/2022 08:18:21 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=844
04/28/2022 08:18:24 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.04 on epoch=849
04/28/2022 08:18:24 - INFO - __main__ - Global step 1700 Train loss 0.01 ACC 0.53125 on epoch=849
04/28/2022 08:18:27 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=854
04/28/2022 08:18:29 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=859
04/28/2022 08:18:32 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.04 on epoch=864
04/28/2022 08:18:35 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=869
04/28/2022 08:18:37 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=874
04/28/2022 08:18:38 - INFO - __main__ - Global step 1750 Train loss 0.01 ACC 0.53125 on epoch=874
04/28/2022 08:18:40 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=879
04/28/2022 08:18:43 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=884
04/28/2022 08:18:45 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=889
04/28/2022 08:18:48 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=894
04/28/2022 08:18:50 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=899
04/28/2022 08:18:51 - INFO - __main__ - Global step 1800 Train loss 0.01 ACC 0.53125 on epoch=899
04/28/2022 08:18:54 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=904
04/28/2022 08:18:56 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=909
04/28/2022 08:18:59 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=914
04/28/2022 08:19:01 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=919
04/28/2022 08:19:04 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=924
04/28/2022 08:19:05 - INFO - __main__ - Global step 1850 Train loss 0.01 ACC 0.53125 on epoch=924
04/28/2022 08:19:07 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=929
04/28/2022 08:19:10 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=934
04/28/2022 08:19:12 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.05 on epoch=939
04/28/2022 08:19:15 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.04 on epoch=944
04/28/2022 08:19:17 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=949
04/28/2022 08:19:18 - INFO - __main__ - Global step 1900 Train loss 0.02 ACC 0.53125 on epoch=949
04/28/2022 08:19:20 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=954
04/28/2022 08:19:23 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=959
04/28/2022 08:19:25 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=964
04/28/2022 08:19:28 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=969
04/28/2022 08:19:31 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=974
04/28/2022 08:19:32 - INFO - __main__ - Global step 1950 Train loss 0.01 ACC 0.5 on epoch=974
04/28/2022 08:19:34 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=979
04/28/2022 08:19:37 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=984
04/28/2022 08:19:39 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=989
04/28/2022 08:19:42 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=994
04/28/2022 08:19:44 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=999
04/28/2022 08:19:45 - INFO - __main__ - Global step 2000 Train loss 0.00 ACC 0.53125 on epoch=999
04/28/2022 08:19:45 - INFO - __main__ - save last model!
04/28/2022 08:19:45 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
04/28/2022 08:19:45 - INFO - __main__ - Start tokenizing ... 1000 instances
04/28/2022 08:19:45 - INFO - __main__ - Printing 3 examples
04/28/2022 08:19:45 - INFO - __main__ -  [wino_grande] Sarah was a much better surgeon than Maria so _ always got the easier cases. (A) Sarah (B) Maria
04/28/2022 08:19:45 - INFO - __main__ - ['Maria']
04/28/2022 08:19:45 - INFO - __main__ -  [wino_grande] Sarah was a much better surgeon than Maria so _ always got the harder cases. (A) Sarah (B) Maria
04/28/2022 08:19:45 - INFO - __main__ - ['Sarah']
04/28/2022 08:19:45 - INFO - __main__ -  [wino_grande] They were worried the wine would ruin the bed and the blanket, but the _ was't ruined. (A) blanket (B) bed
04/28/2022 08:19:45 - INFO - __main__ - ['bed']
04/28/2022 08:19:45 - INFO - __main__ - Tokenizing Input ...
04/28/2022 08:19:46 - INFO - __main__ - Tokenizing Output ...
04/28/2022 08:19:47 - INFO - __main__ - Loaded 1000 examples from test data
04/28/2022 08:19:47 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 08:19:47 - INFO - __main__ - Printing 3 examples
04/28/2022 08:19:47 - INFO - __main__ -  [wino_grande] Adam gave his friend an apple instead of an orange because his friend was quite fond of the _ . (A) orange (B) apple
04/28/2022 08:19:47 - INFO - __main__ - ['apple']
04/28/2022 08:19:47 - INFO - __main__ -  [wino_grande] William wants to file a lawsuit so he asks Aaron for help, because _ is a lawyer. (A) William (B) Aaron
04/28/2022 08:19:47 - INFO - __main__ - ['Aaron']
04/28/2022 08:19:47 - INFO - __main__ -  [wino_grande] Brian suffers a lot from loneliness compared to Brett because _ has lost all of his family. (A) Brian (B) Brett
04/28/2022 08:19:47 - INFO - __main__ - ['Brian']
04/28/2022 08:19:47 - INFO - __main__ - Tokenizing Input ...
04/28/2022 08:19:47 - INFO - __main__ - Tokenizing Output ...
04/28/2022 08:19:48 - INFO - __main__ - Loaded 32 examples from train data
04/28/2022 08:19:48 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 08:19:48 - INFO - __main__ - Printing 3 examples
04/28/2022 08:19:48 - INFO - __main__ -  [wino_grande] Although Elena hated sweets a whole lot more than Megan, _ was the one to own a bakery. (A) Elena (B) Megan
04/28/2022 08:19:48 - INFO - __main__ - ['Elena']
04/28/2022 08:19:48 - INFO - __main__ -  [wino_grande] The meeting took longer than the interview because there was more to cover during the _ . (A) meeting (B) interview
04/28/2022 08:19:48 - INFO - __main__ - ['meeting']
04/28/2022 08:19:48 - INFO - __main__ -  [wino_grande] Rebecca set out to walk around and recruit new members for Lindsey 's church because _ was old and disabled. (A) Rebecca (B) Lindsey
04/28/2022 08:19:48 - INFO - __main__ - ['Lindsey']
04/28/2022 08:19:48 - INFO - __main__ - Tokenizing Input ...
04/28/2022 08:19:48 - INFO - __main__ - Tokenizing Output ...
04/28/2022 08:19:48 - INFO - __main__ - Loaded 32 examples from dev data
04/28/2022 08:20:06 - INFO - __main__ - load prompt embedding from ckpt
04/28/2022 08:20:07 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/28/2022 08:20:07 - INFO - __main__ - Starting training!
04/28/2022 08:20:08 - INFO - __main__ - Saved prediction in models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-wino_grande/wino_grande_32_87_0.3_8_predictions.txt
04/28/2022 08:20:08 - INFO - __main__ - ACC on test data: 0.4940
04/28/2022 08:20:09 - INFO - __main__ - prefix=wino_grande_32_87, lr=0.3, bsz=8, dev_performance=0.59375, test_performance=0.494
04/28/2022 08:20:09 - INFO - __main__ - Running ... prefix=wino_grande_32_87, lr=0.2, bsz=8 ...
04/28/2022 08:20:09 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 08:20:09 - INFO - __main__ - Printing 3 examples
04/28/2022 08:20:09 - INFO - __main__ -  [wino_grande] Adam gave his friend an apple instead of an orange because his friend was quite fond of the _ . (A) orange (B) apple
04/28/2022 08:20:09 - INFO - __main__ - ['apple']
04/28/2022 08:20:09 - INFO - __main__ -  [wino_grande] William wants to file a lawsuit so he asks Aaron for help, because _ is a lawyer. (A) William (B) Aaron
04/28/2022 08:20:09 - INFO - __main__ - ['Aaron']
04/28/2022 08:20:09 - INFO - __main__ -  [wino_grande] Brian suffers a lot from loneliness compared to Brett because _ has lost all of his family. (A) Brian (B) Brett
04/28/2022 08:20:09 - INFO - __main__ - ['Brian']
04/28/2022 08:20:09 - INFO - __main__ - Tokenizing Input ...
04/28/2022 08:20:09 - INFO - __main__ - Tokenizing Output ...
04/28/2022 08:20:09 - INFO - __main__ - Loaded 32 examples from train data
04/28/2022 08:20:10 - INFO - __main__ - Start tokenizing ... 32 instances
04/28/2022 08:20:10 - INFO - __main__ - Printing 3 examples
04/28/2022 08:20:10 - INFO - __main__ -  [wino_grande] Although Elena hated sweets a whole lot more than Megan, _ was the one to own a bakery. (A) Elena (B) Megan
04/28/2022 08:20:10 - INFO - __main__ - ['Elena']
04/28/2022 08:20:10 - INFO - __main__ -  [wino_grande] The meeting took longer than the interview because there was more to cover during the _ . (A) meeting (B) interview
04/28/2022 08:20:10 - INFO - __main__ - ['meeting']
04/28/2022 08:20:10 - INFO - __main__ -  [wino_grande] Rebecca set out to walk around and recruit new members for Lindsey 's church because _ was old and disabled. (A) Rebecca (B) Lindsey
04/28/2022 08:20:10 - INFO - __main__ - ['Lindsey']
04/28/2022 08:20:10 - INFO - __main__ - Tokenizing Input ...
04/28/2022 08:20:10 - INFO - __main__ - Tokenizing Output ...
04/28/2022 08:20:10 - INFO - __main__ - Loaded 32 examples from dev data
04/28/2022 08:20:25 - INFO - __main__ - load prompt embedding from ckpt
04/28/2022 08:20:26 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/28/2022 08:20:26 - INFO - __main__ - Starting training!
04/28/2022 08:20:29 - INFO - __main__ - Step 10 Global step 10 Train loss 4.36 on epoch=4
04/28/2022 08:20:31 - INFO - __main__ - Step 20 Global step 20 Train loss 2.38 on epoch=9
04/28/2022 08:20:34 - INFO - __main__ - Step 30 Global step 30 Train loss 1.36 on epoch=14
04/28/2022 08:20:36 - INFO - __main__ - Step 40 Global step 40 Train loss 1.01 on epoch=19
04/28/2022 08:20:39 - INFO - __main__ - Step 50 Global step 50 Train loss 0.93 on epoch=24
04/28/2022 08:20:40 - INFO - __main__ - Global step 50 Train loss 2.01 ACC 0.5625 on epoch=24
04/28/2022 08:20:40 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.5625 on epoch=24, global_step=50
04/28/2022 08:20:42 - INFO - __main__ - Step 60 Global step 60 Train loss 0.82 on epoch=29
04/28/2022 08:20:45 - INFO - __main__ - Step 70 Global step 70 Train loss 0.73 on epoch=34
04/28/2022 08:20:47 - INFO - __main__ - Step 80 Global step 80 Train loss 0.56 on epoch=39
04/28/2022 08:20:50 - INFO - __main__ - Step 90 Global step 90 Train loss 0.56 on epoch=44
04/28/2022 08:20:53 - INFO - __main__ - Step 100 Global step 100 Train loss 0.48 on epoch=49
04/28/2022 08:20:53 - INFO - __main__ - Global step 100 Train loss 0.63 ACC 0.5625 on epoch=49
04/28/2022 08:20:56 - INFO - __main__ - Step 110 Global step 110 Train loss 0.51 on epoch=54
04/28/2022 08:20:58 - INFO - __main__ - Step 120 Global step 120 Train loss 0.45 on epoch=59
04/28/2022 08:21:01 - INFO - __main__ - Step 130 Global step 130 Train loss 0.28 on epoch=64
04/28/2022 08:21:04 - INFO - __main__ - Step 140 Global step 140 Train loss 0.35 on epoch=69
04/28/2022 08:21:06 - INFO - __main__ - Step 150 Global step 150 Train loss 0.23 on epoch=74
04/28/2022 08:21:07 - INFO - __main__ - Global step 150 Train loss 0.36 ACC 0.40625 on epoch=74
04/28/2022 08:21:10 - INFO - __main__ - Step 160 Global step 160 Train loss 0.33 on epoch=79
04/28/2022 08:21:12 - INFO - __main__ - Step 170 Global step 170 Train loss 0.29 on epoch=84
04/28/2022 08:21:15 - INFO - __main__ - Step 180 Global step 180 Train loss 0.12 on epoch=89
04/28/2022 08:21:17 - INFO - __main__ - Step 190 Global step 190 Train loss 0.16 on epoch=94
04/28/2022 08:21:20 - INFO - __main__ - Step 200 Global step 200 Train loss 0.21 on epoch=99
04/28/2022 08:21:21 - INFO - __main__ - Global step 200 Train loss 0.22 ACC 0.46875 on epoch=99
04/28/2022 08:21:23 - INFO - __main__ - Step 210 Global step 210 Train loss 0.13 on epoch=104
04/28/2022 08:21:26 - INFO - __main__ - Step 220 Global step 220 Train loss 0.18 on epoch=109
04/28/2022 08:21:28 - INFO - __main__ - Step 230 Global step 230 Train loss 0.11 on epoch=114
04/28/2022 08:21:31 - INFO - __main__ - Step 240 Global step 240 Train loss 0.17 on epoch=119
04/28/2022 08:21:34 - INFO - __main__ - Step 250 Global step 250 Train loss 0.11 on epoch=124
04/28/2022 08:21:34 - INFO - __main__ - Global step 250 Train loss 0.14 ACC 0.40625 on epoch=124
04/28/2022 08:21:37 - INFO - __main__ - Step 260 Global step 260 Train loss 0.14 on epoch=129
04/28/2022 08:21:40 - INFO - __main__ - Step 270 Global step 270 Train loss 0.07 on epoch=134
04/28/2022 08:21:42 - INFO - __main__ - Step 280 Global step 280 Train loss 0.12 on epoch=139
04/28/2022 08:21:45 - INFO - __main__ - Step 290 Global step 290 Train loss 0.06 on epoch=144
04/28/2022 08:21:47 - INFO - __main__ - Step 300 Global step 300 Train loss 0.10 on epoch=149
04/28/2022 08:21:48 - INFO - __main__ - Global step 300 Train loss 0.10 ACC 0.40625 on epoch=149
04/28/2022 08:21:51 - INFO - __main__ - Step 310 Global step 310 Train loss 0.13 on epoch=154
04/28/2022 08:21:53 - INFO - __main__ - Step 320 Global step 320 Train loss 0.12 on epoch=159
04/28/2022 08:21:56 - INFO - __main__ - Step 330 Global step 330 Train loss 0.06 on epoch=164
04/28/2022 08:21:58 - INFO - __main__ - Step 340 Global step 340 Train loss 0.12 on epoch=169
04/28/2022 08:22:01 - INFO - __main__ - Step 350 Global step 350 Train loss 0.06 on epoch=174
04/28/2022 08:22:02 - INFO - __main__ - Global step 350 Train loss 0.10 ACC 0.46875 on epoch=174
04/28/2022 08:22:04 - INFO - __main__ - Step 360 Global step 360 Train loss 0.11 on epoch=179
04/28/2022 08:22:07 - INFO - __main__ - Step 370 Global step 370 Train loss 0.09 on epoch=184
04/28/2022 08:22:10 - INFO - __main__ - Step 380 Global step 380 Train loss 0.10 on epoch=189
04/28/2022 08:22:12 - INFO - __main__ - Step 390 Global step 390 Train loss 0.11 on epoch=194
04/28/2022 08:22:15 - INFO - __main__ - Step 400 Global step 400 Train loss 0.20 on epoch=199
04/28/2022 08:22:16 - INFO - __main__ - Global step 400 Train loss 0.12 ACC 0.46875 on epoch=199
04/28/2022 08:22:18 - INFO - __main__ - Step 410 Global step 410 Train loss 0.08 on epoch=204
04/28/2022 08:22:21 - INFO - __main__ - Step 420 Global step 420 Train loss 0.16 on epoch=209
04/28/2022 08:22:23 - INFO - __main__ - Step 430 Global step 430 Train loss 0.07 on epoch=214
04/28/2022 08:22:26 - INFO - __main__ - Step 440 Global step 440 Train loss 0.05 on epoch=219
04/28/2022 08:22:28 - INFO - __main__ - Step 450 Global step 450 Train loss 0.13 on epoch=224
04/28/2022 08:22:29 - INFO - __main__ - Global step 450 Train loss 0.10 ACC 0.5 on epoch=224
04/28/2022 08:22:32 - INFO - __main__ - Step 460 Global step 460 Train loss 0.12 on epoch=229
04/28/2022 08:22:34 - INFO - __main__ - Step 470 Global step 470 Train loss 0.11 on epoch=234
04/28/2022 08:22:37 - INFO - __main__ - Step 480 Global step 480 Train loss 0.04 on epoch=239
04/28/2022 08:22:40 - INFO - __main__ - Step 490 Global step 490 Train loss 0.10 on epoch=244
04/28/2022 08:22:42 - INFO - __main__ - Step 500 Global step 500 Train loss 0.06 on epoch=249
04/28/2022 08:22:43 - INFO - __main__ - Global step 500 Train loss 0.08 ACC 0.46875 on epoch=249
04/28/2022 08:22:46 - INFO - __main__ - Step 510 Global step 510 Train loss 0.12 on epoch=254
04/28/2022 08:22:48 - INFO - __main__ - Step 520 Global step 520 Train loss 0.08 on epoch=259
04/28/2022 08:22:51 - INFO - __main__ - Step 530 Global step 530 Train loss 0.08 on epoch=264
04/28/2022 08:22:53 - INFO - __main__ - Step 540 Global step 540 Train loss 0.11 on epoch=269
04/28/2022 08:22:56 - INFO - __main__ - Step 550 Global step 550 Train loss 0.08 on epoch=274
04/28/2022 08:22:57 - INFO - __main__ - Global step 550 Train loss 0.10 ACC 0.5 on epoch=274
04/28/2022 08:22:59 - INFO - __main__ - Step 560 Global step 560 Train loss 0.05 on epoch=279
04/28/2022 08:23:02 - INFO - __main__ - Step 570 Global step 570 Train loss 0.10 on epoch=284
04/28/2022 08:23:04 - INFO - __main__ - Step 580 Global step 580 Train loss 0.11 on epoch=289
04/28/2022 08:23:07 - INFO - __main__ - Step 590 Global step 590 Train loss 0.05 on epoch=294
04/28/2022 08:23:10 - INFO - __main__ - Step 600 Global step 600 Train loss 0.05 on epoch=299
04/28/2022 08:23:10 - INFO - __main__ - Global step 600 Train loss 0.07 ACC 0.4375 on epoch=299
04/28/2022 08:23:13 - INFO - __main__ - Step 610 Global step 610 Train loss 0.08 on epoch=304
04/28/2022 08:23:15 - INFO - __main__ - Step 620 Global step 620 Train loss 0.06 on epoch=309
04/28/2022 08:23:18 - INFO - __main__ - Step 630 Global step 630 Train loss 0.06 on epoch=314
04/28/2022 08:23:21 - INFO - __main__ - Step 640 Global step 640 Train loss 0.11 on epoch=319
04/28/2022 08:23:23 - INFO - __main__ - Step 650 Global step 650 Train loss 0.07 on epoch=324
04/28/2022 08:23:24 - INFO - __main__ - Global step 650 Train loss 0.07 ACC 0.46875 on epoch=324
04/28/2022 08:23:27 - INFO - __main__ - Step 660 Global step 660 Train loss 0.05 on epoch=329
04/28/2022 08:23:29 - INFO - __main__ - Step 670 Global step 670 Train loss 0.03 on epoch=334
04/28/2022 08:23:32 - INFO - __main__ - Step 680 Global step 680 Train loss 0.03 on epoch=339
04/28/2022 08:23:34 - INFO - __main__ - Step 690 Global step 690 Train loss 0.13 on epoch=344
04/28/2022 08:23:37 - INFO - __main__ - Step 700 Global step 700 Train loss 0.07 on epoch=349
04/28/2022 08:23:38 - INFO - __main__ - Global step 700 Train loss 0.06 ACC 0.5625 on epoch=349
04/28/2022 08:23:40 - INFO - __main__ - Step 710 Global step 710 Train loss 0.05 on epoch=354
04/28/2022 08:23:43 - INFO - __main__ - Step 720 Global step 720 Train loss 0.04 on epoch=359
04/28/2022 08:23:46 - INFO - __main__ - Step 730 Global step 730 Train loss 0.03 on epoch=364
04/28/2022 08:23:48 - INFO - __main__ - Step 740 Global step 740 Train loss 0.10 on epoch=369
04/28/2022 08:23:51 - INFO - __main__ - Step 750 Global step 750 Train loss 0.10 on epoch=374
04/28/2022 08:23:52 - INFO - __main__ - Global step 750 Train loss 0.06 ACC 0.5 on epoch=374
04/28/2022 08:23:54 - INFO - __main__ - Step 760 Global step 760 Train loss 0.06 on epoch=379
04/28/2022 08:23:57 - INFO - __main__ - Step 770 Global step 770 Train loss 0.07 on epoch=384
04/28/2022 08:23:59 - INFO - __main__ - Step 780 Global step 780 Train loss 0.09 on epoch=389
04/28/2022 08:24:02 - INFO - __main__ - Step 790 Global step 790 Train loss 0.05 on epoch=394
04/28/2022 08:24:04 - INFO - __main__ - Step 800 Global step 800 Train loss 0.07 on epoch=399
04/28/2022 08:24:05 - INFO - __main__ - Global step 800 Train loss 0.07 ACC 0.5625 on epoch=399
04/28/2022 08:24:08 - INFO - __main__ - Step 810 Global step 810 Train loss 0.03 on epoch=404
04/28/2022 08:24:10 - INFO - __main__ - Step 820 Global step 820 Train loss 0.07 on epoch=409
04/28/2022 08:24:13 - INFO - __main__ - Step 830 Global step 830 Train loss 0.06 on epoch=414
04/28/2022 08:24:16 - INFO - __main__ - Step 840 Global step 840 Train loss 0.04 on epoch=419
04/28/2022 08:24:18 - INFO - __main__ - Step 850 Global step 850 Train loss 0.02 on epoch=424
04/28/2022 08:24:19 - INFO - __main__ - Global step 850 Train loss 0.04 ACC 0.5 on epoch=424
04/28/2022 08:24:21 - INFO - __main__ - Step 860 Global step 860 Train loss 0.06 on epoch=429
04/28/2022 08:24:24 - INFO - __main__ - Step 870 Global step 870 Train loss 0.07 on epoch=434
04/28/2022 08:24:27 - INFO - __main__ - Step 880 Global step 880 Train loss 0.03 on epoch=439
04/28/2022 08:24:29 - INFO - __main__ - Step 890 Global step 890 Train loss 0.03 on epoch=444
04/28/2022 08:24:32 - INFO - __main__ - Step 900 Global step 900 Train loss 0.03 on epoch=449
04/28/2022 08:24:33 - INFO - __main__ - Global step 900 Train loss 0.04 ACC 0.5 on epoch=449
04/28/2022 08:24:35 - INFO - __main__ - Step 910 Global step 910 Train loss 0.06 on epoch=454
04/28/2022 08:24:38 - INFO - __main__ - Step 920 Global step 920 Train loss 0.04 on epoch=459
04/28/2022 08:24:41 - INFO - __main__ - Step 930 Global step 930 Train loss 0.08 on epoch=464
04/28/2022 08:24:43 - INFO - __main__ - Step 940 Global step 940 Train loss 0.04 on epoch=469
04/28/2022 08:24:46 - INFO - __main__ - Step 950 Global step 950 Train loss 0.02 on epoch=474
04/28/2022 08:24:47 - INFO - __main__ - Global step 950 Train loss 0.05 ACC 0.53125 on epoch=474
04/28/2022 08:24:49 - INFO - __main__ - Step 960 Global step 960 Train loss 0.05 on epoch=479
04/28/2022 08:24:52 - INFO - __main__ - Step 970 Global step 970 Train loss 0.10 on epoch=484
04/28/2022 08:24:54 - INFO - __main__ - Step 980 Global step 980 Train loss 0.07 on epoch=489
04/28/2022 08:24:57 - INFO - __main__ - Step 990 Global step 990 Train loss 0.02 on epoch=494
04/28/2022 08:24:59 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.06 on epoch=499
04/28/2022 08:25:00 - INFO - __main__ - Global step 1000 Train loss 0.06 ACC 0.5625 on epoch=499
04/28/2022 08:25:03 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.05 on epoch=504
04/28/2022 08:25:05 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.04 on epoch=509
04/28/2022 08:25:08 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.08 on epoch=514
04/28/2022 08:25:10 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.04 on epoch=519
04/28/2022 08:25:13 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.02 on epoch=524
04/28/2022 08:25:14 - INFO - __main__ - Global step 1050 Train loss 0.05 ACC 0.5 on epoch=524
04/28/2022 08:25:16 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.07 on epoch=529
04/28/2022 08:25:19 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.07 on epoch=534
04/28/2022 08:25:22 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.02 on epoch=539
04/28/2022 08:25:24 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.08 on epoch=544
04/28/2022 08:25:27 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.06 on epoch=549
04/28/2022 08:25:28 - INFO - __main__ - Global step 1100 Train loss 0.06 ACC 0.53125 on epoch=549
04/28/2022 08:25:30 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.03 on epoch=554
04/28/2022 08:25:33 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.03 on epoch=559
04/28/2022 08:25:35 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.03 on epoch=564
04/28/2022 08:25:38 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.04 on epoch=569
04/28/2022 08:25:41 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.06 on epoch=574
04/28/2022 08:25:41 - INFO - __main__ - Global step 1150 Train loss 0.04 ACC 0.59375 on epoch=574
04/28/2022 08:25:41 - INFO - __main__ - Saving model with best ACC: 0.5625 -> 0.59375 on epoch=574, global_step=1150
04/28/2022 08:25:44 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.04 on epoch=579
04/28/2022 08:25:47 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.07 on epoch=584
04/28/2022 08:25:49 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.03 on epoch=589
04/28/2022 08:25:52 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.05 on epoch=594
04/28/2022 08:25:55 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.06 on epoch=599
04/28/2022 08:25:55 - INFO - __main__ - Global step 1200 Train loss 0.05 ACC 0.59375 on epoch=599
04/28/2022 08:25:58 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.03 on epoch=604
04/28/2022 08:26:00 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.04 on epoch=609
04/28/2022 08:26:03 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.06 on epoch=614
04/28/2022 08:26:06 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.03 on epoch=619
04/28/2022 08:26:08 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.07 on epoch=624
04/28/2022 08:26:09 - INFO - __main__ - Global step 1250 Train loss 0.05 ACC 0.59375 on epoch=624
04/28/2022 08:26:12 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.05 on epoch=629
04/28/2022 08:26:14 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.06 on epoch=634
04/28/2022 08:26:17 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.04 on epoch=639
04/28/2022 08:26:19 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.04 on epoch=644
04/28/2022 08:26:22 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.03 on epoch=649
04/28/2022 08:26:23 - INFO - __main__ - Global step 1300 Train loss 0.04 ACC 0.59375 on epoch=649
04/28/2022 08:26:25 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.07 on epoch=654
04/28/2022 08:26:28 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.02 on epoch=659
04/28/2022 08:26:31 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.03 on epoch=664
04/28/2022 08:26:33 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.10 on epoch=669
04/28/2022 08:26:36 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.03 on epoch=674
04/28/2022 08:26:37 - INFO - __main__ - Global step 1350 Train loss 0.05 ACC 0.5625 on epoch=674
04/28/2022 08:26:39 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.04 on epoch=679
04/28/2022 08:26:42 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.05 on epoch=684
04/28/2022 08:26:44 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.06 on epoch=689
04/28/2022 08:26:47 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.04 on epoch=694
04/28/2022 08:26:49 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=699
04/28/2022 08:26:50 - INFO - __main__ - Global step 1400 Train loss 0.04 ACC 0.5625 on epoch=699
04/28/2022 08:26:53 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.03 on epoch=704
04/28/2022 08:26:55 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=709
04/28/2022 08:26:58 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.04 on epoch=714
04/28/2022 08:27:01 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=719
04/28/2022 08:27:03 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=724
04/28/2022 08:27:04 - INFO - __main__ - Global step 1450 Train loss 0.02 ACC 0.5625 on epoch=724
04/28/2022 08:27:07 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.05 on epoch=729
04/28/2022 08:27:09 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.02 on epoch=734
04/28/2022 08:27:12 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.06 on epoch=739
04/28/2022 08:27:14 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.04 on epoch=744
04/28/2022 08:27:17 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.03 on epoch=749
04/28/2022 08:27:18 - INFO - __main__ - Global step 1500 Train loss 0.04 ACC 0.625 on epoch=749
04/28/2022 08:27:18 - INFO - __main__ - Saving model with best ACC: 0.59375 -> 0.625 on epoch=749, global_step=1500
04/28/2022 08:27:20 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=754
04/28/2022 08:27:23 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.02 on epoch=759
04/28/2022 08:27:26 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.02 on epoch=764
04/28/2022 08:27:28 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=769
04/28/2022 08:27:31 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=774
04/28/2022 08:27:31 - INFO - __main__ - Global step 1550 Train loss 0.02 ACC 0.5625 on epoch=774
04/28/2022 08:27:34 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.03 on epoch=779
04/28/2022 08:27:37 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.08 on epoch=784
04/28/2022 08:27:39 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.02 on epoch=789
04/28/2022 08:27:42 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.02 on epoch=794
04/28/2022 08:27:45 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.06 on epoch=799
04/28/2022 08:27:45 - INFO - __main__ - Global step 1600 Train loss 0.04 ACC 0.5625 on epoch=799
04/28/2022 08:27:48 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=804
04/28/2022 08:27:51 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=809
04/28/2022 08:27:53 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.09 on epoch=814
04/28/2022 08:27:56 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.11 on epoch=819
04/28/2022 08:27:58 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.05 on epoch=824
04/28/2022 08:27:59 - INFO - __main__ - Global step 1650 Train loss 0.06 ACC 0.5625 on epoch=824
04/28/2022 08:28:02 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.03 on epoch=829
04/28/2022 08:28:04 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=834
04/28/2022 08:28:07 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.04 on epoch=839
04/28/2022 08:28:09 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=844
04/28/2022 08:28:12 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=849
04/28/2022 08:28:13 - INFO - __main__ - Global step 1700 Train loss 0.02 ACC 0.59375 on epoch=849
04/28/2022 08:28:15 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.04 on epoch=854
04/28/2022 08:28:18 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.09 on epoch=859
04/28/2022 08:28:21 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.03 on epoch=864
04/28/2022 08:28:23 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=869
04/28/2022 08:28:26 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=874
04/28/2022 08:28:27 - INFO - __main__ - Global step 1750 Train loss 0.04 ACC 0.5625 on epoch=874
04/28/2022 08:28:29 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.06 on epoch=879
04/28/2022 08:28:32 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=884
04/28/2022 08:28:34 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.04 on epoch=889
04/28/2022 08:28:37 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.03 on epoch=894
04/28/2022 08:28:40 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=899
04/28/2022 08:28:40 - INFO - __main__ - Global step 1800 Train loss 0.03 ACC 0.5625 on epoch=899
04/28/2022 08:28:43 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=904
04/28/2022 08:28:46 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=909
04/28/2022 08:28:48 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=914
04/28/2022 08:28:51 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.07 on epoch=919
04/28/2022 08:28:53 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=924
04/28/2022 08:28:54 - INFO - __main__ - Global step 1850 Train loss 0.02 ACC 0.46875 on epoch=924
04/28/2022 08:28:57 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.03 on epoch=929
04/28/2022 08:28:59 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=934
04/28/2022 08:29:02 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=939
04/28/2022 08:29:05 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=944
04/28/2022 08:29:07 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.11 on epoch=949
04/28/2022 08:29:08 - INFO - __main__ - Global step 1900 Train loss 0.03 ACC 0.5 on epoch=949
04/28/2022 08:29:11 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=954
04/28/2022 08:29:13 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=959
04/28/2022 08:29:16 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.08 on epoch=964
04/28/2022 08:29:18 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.04 on epoch=969
04/28/2022 08:29:21 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=974
04/28/2022 08:29:22 - INFO - __main__ - Global step 1950 Train loss 0.03 ACC 0.53125 on epoch=974
04/28/2022 08:29:24 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=979
04/28/2022 08:29:27 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=984
04/28/2022 08:29:29 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=989
04/28/2022 08:29:32 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=994
04/28/2022 08:29:34 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=999
04/28/2022 08:29:35 - INFO - __main__ - Global step 2000 Train loss 0.01 ACC 0.5 on epoch=999
04/28/2022 08:29:35 - INFO - __main__ - save last model!
04/28/2022 08:29:35 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
04/28/2022 08:29:35 - INFO - __main__ - Start tokenizing ... 1000 instances
04/28/2022 08:29:35 - INFO - __main__ - Printing 3 examples
04/28/2022 08:29:35 - INFO - __main__ -  [wino_grande] Sarah was a much better surgeon than Maria so _ always got the easier cases. (A) Sarah (B) Maria
04/28/2022 08:29:35 - INFO - __main__ - ['Maria']
04/28/2022 08:29:35 - INFO - __main__ -  [wino_grande] Sarah was a much better surgeon than Maria so _ always got the harder cases. (A) Sarah (B) Maria
04/28/2022 08:29:35 - INFO - __main__ - ['Sarah']
04/28/2022 08:29:35 - INFO - __main__ -  [wino_grande] They were worried the wine would ruin the bed and the blanket, but the _ was't ruined. (A) blanket (B) bed
04/28/2022 08:29:35 - INFO - __main__ - ['bed']
04/28/2022 08:29:35 - INFO - __main__ - Tokenizing Input ...
04/28/2022 08:29:36 - INFO - __main__ - Tokenizing Output ...
04/28/2022 08:29:37 - INFO - __main__ - Loaded 1000 examples from test data
04/28/2022 08:29:59 - INFO - __main__ - Saved prediction in models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-wino_grande/wino_grande_32_87_0.2_8_predictions.txt
04/28/2022 08:29:59 - INFO - __main__ - ACC on test data: 0.5100
04/28/2022 08:29:59 - INFO - __main__ - prefix=wino_grande_32_87, lr=0.2, bsz=8, dev_performance=0.625, test_performance=0.51
