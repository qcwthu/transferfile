04/06/2022 14:10:30 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=False, bsz_list=[4], cache_dir='/data/qin/cache/', checkpoint='None', cuda='4', dataset='nlp_forest_single', debug=False, dev_file='data', do_lowercase=False, do_predict=True, do_train=True, eval_period=50, freeze_embeds=False, gradient_accumulation_steps=2, identifier='T5-large-maml-noqa2qa-3e-5-2-5000-5e-1', learning_rate=0.5, learning_rate_list=[0.5], lm_adapted_path='/data/qin/lm_adapted_t5model/torch_ckpt/large/pytorch_model.bin', local_rank=0, log_step=10, max_grad_norm=1.0, max_input_length=512, max_output_length=128, model='google/t5-v1_1-large', num_beams=4, num_train_epochs=1000.0, output_dir='models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-openbookqa', predict_batch_size=16, predict_checkpoint='best-model.pt', prefix='', prompt_number=100, quiet=False, seed=42, task_dir='data/openbookqa/', task_name='openbookqa', test_file='data', total_steps=3000, train_batch_size=4, train_file='data', wait_step=10000000000, warmup_steps=50, weight_decay=1e-05)
04/06/2022 14:10:30 - INFO - __main__ - models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-openbookqa
04/25/2022 16:18:54 - INFO - __main__ - Namespace(task_dir='data/openbookqa/', task_name='openbookqa', identifier='T5-large-maml-noqa2qa-3e-5-2-5000-5e-1', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-openbookqa', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-maml-noqa2qa-3e-5-2-5000-5e-1/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='0,1')
04/25/2022 16:18:54 - INFO - __main__ - models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-openbookqa
04/25/2022 16:18:54 - INFO - __main__ - Namespace(task_dir='data/openbookqa/', task_name='openbookqa', identifier='T5-large-maml-noqa2qa-3e-5-2-5000-5e-1', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-openbookqa', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-maml-noqa2qa-3e-5-2-5000-5e-1/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='0,1')
04/25/2022 16:18:54 - INFO - __main__ - models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-openbookqa
04/25/2022 16:18:56 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
04/25/2022 16:18:56 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
04/25/2022 16:18:56 - INFO - __main__ - args.device: cuda:0
04/25/2022 16:18:56 - INFO - __main__ - Using 2 gpus
04/25/2022 16:18:56 - INFO - __main__ - args.device: cuda:1
04/25/2022 16:18:56 - INFO - __main__ - Using 2 gpus
04/25/2022 16:18:56 - INFO - __main__ - Fine-tuning the following samples: ['openbookqa_32_100', 'openbookqa_32_13', 'openbookqa_32_21', 'openbookqa_32_42', 'openbookqa_32_87']
04/25/2022 16:18:56 - INFO - __main__ - Fine-tuning the following samples: ['openbookqa_32_100', 'openbookqa_32_13', 'openbookqa_32_21', 'openbookqa_32_42', 'openbookqa_32_87']
04/25/2022 16:19:00 - INFO - __main__ - Running ... prefix=openbookqa_32_100, lr=0.5, bsz=8 ...
04/25/2022 16:19:01 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 16:19:01 - INFO - __main__ - Printing 3 examples
04/25/2022 16:19:01 - INFO - __main__ -  [openbookqa] Plant population would fail to maintain it's size if (A) fertilizer is applied (B) gets more sun (C) H2O depletes (D) grows
04/25/2022 16:19:01 - INFO - __main__ - ['H2O depletes']
04/25/2022 16:19:01 - INFO - __main__ -  [openbookqa] if members of a species are born then the species what increases? (A) water (B) community (C) understanding (D) food
04/25/2022 16:19:01 - INFO - __main__ - ['community']
04/25/2022 16:19:01 - INFO - __main__ -  [openbookqa] An example of adaption is (A) Eating tacos (B) wearing sunblock (C) Reading a book (D) Drinking water
04/25/2022 16:19:01 - INFO - __main__ - ['wearing sunblock']
04/25/2022 16:19:01 - INFO - __main__ - Tokenizing Input ...
04/25/2022 16:19:01 - INFO - __main__ - Tokenizing Output ...
04/25/2022 16:19:01 - INFO - __main__ - Loaded 32 examples from train data
04/25/2022 16:19:01 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 16:19:01 - INFO - __main__ - Printing 3 examples
04/25/2022 16:19:01 - INFO - __main__ -  [openbookqa] If you desired to keep your house cooler in the summer months (A) plant trees that tower above the ground (B) plant ivy around the trees (C) plant shrubs around the foundation (D) plant trees that stay smaller than dogwoods
04/25/2022 16:19:01 - INFO - __main__ - ['plant trees that tower above the ground']
04/25/2022 16:19:01 - INFO - __main__ -  [openbookqa] A person knows that a place always has blue skies, warm weather and a light breeze because (A) that is the beach (B) that is the meaning (C) that is the religion (D) climate is fairly reliable
04/25/2022 16:19:01 - INFO - __main__ - ['climate is fairly reliable']
04/25/2022 16:19:01 - INFO - __main__ -  [openbookqa] Microscopes (A) make tiny atoms look smaller (B) enhance the size of amoebas for easier viewing (C) make magnifying things much more difficult (D) make huge samples look minuscule
04/25/2022 16:19:01 - INFO - __main__ - ['enhance the size of amoebas for easier viewing']
04/25/2022 16:19:01 - INFO - __main__ - Tokenizing Input ...
04/25/2022 16:19:01 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 16:19:01 - INFO - __main__ - Printing 3 examples
04/25/2022 16:19:01 - INFO - __main__ -  [openbookqa] Plant population would fail to maintain it's size if (A) fertilizer is applied (B) gets more sun (C) H2O depletes (D) grows
04/25/2022 16:19:01 - INFO - __main__ - ['H2O depletes']
04/25/2022 16:19:01 - INFO - __main__ -  [openbookqa] if members of a species are born then the species what increases? (A) water (B) community (C) understanding (D) food
04/25/2022 16:19:01 - INFO - __main__ - ['community']
04/25/2022 16:19:01 - INFO - __main__ -  [openbookqa] An example of adaption is (A) Eating tacos (B) wearing sunblock (C) Reading a book (D) Drinking water
04/25/2022 16:19:01 - INFO - __main__ - ['wearing sunblock']
04/25/2022 16:19:01 - INFO - __main__ - Tokenizing Input ...
04/25/2022 16:19:01 - INFO - __main__ - Tokenizing Output ...
04/25/2022 16:19:01 - INFO - __main__ - Tokenizing Output ...
04/25/2022 16:19:01 - INFO - __main__ - Loaded 32 examples from dev data
04/25/2022 16:19:01 - INFO - __main__ - Loaded 32 examples from train data
04/25/2022 16:19:01 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 16:19:01 - INFO - __main__ - Printing 3 examples
04/25/2022 16:19:01 - INFO - __main__ -  [openbookqa] If you desired to keep your house cooler in the summer months (A) plant trees that tower above the ground (B) plant ivy around the trees (C) plant shrubs around the foundation (D) plant trees that stay smaller than dogwoods
04/25/2022 16:19:01 - INFO - __main__ - ['plant trees that tower above the ground']
04/25/2022 16:19:01 - INFO - __main__ -  [openbookqa] A person knows that a place always has blue skies, warm weather and a light breeze because (A) that is the beach (B) that is the meaning (C) that is the religion (D) climate is fairly reliable
04/25/2022 16:19:01 - INFO - __main__ - ['climate is fairly reliable']
04/25/2022 16:19:01 - INFO - __main__ -  [openbookqa] Microscopes (A) make tiny atoms look smaller (B) enhance the size of amoebas for easier viewing (C) make magnifying things much more difficult (D) make huge samples look minuscule
04/25/2022 16:19:01 - INFO - __main__ - ['enhance the size of amoebas for easier viewing']
04/25/2022 16:19:01 - INFO - __main__ - Tokenizing Input ...
04/25/2022 16:19:01 - INFO - __main__ - Tokenizing Output ...
04/25/2022 16:19:01 - INFO - __main__ - Loaded 32 examples from dev data
04/25/2022 16:19:19 - INFO - __main__ - load prompt embedding from ckpt
04/25/2022 16:19:20 - INFO - __main__ - load prompt embedding from ckpt
04/25/2022 16:19:20 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/25/2022 16:19:20 - INFO - __main__ - Starting training!
04/25/2022 16:19:25 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/25/2022 16:19:25 - INFO - __main__ - Starting training!
04/25/2022 16:19:29 - INFO - __main__ - Step 10 Global step 10 Train loss 1.80 on epoch=4
04/25/2022 16:19:32 - INFO - __main__ - Step 20 Global step 20 Train loss 1.17 on epoch=9
04/25/2022 16:19:34 - INFO - __main__ - Step 30 Global step 30 Train loss 0.82 on epoch=14
04/25/2022 16:19:37 - INFO - __main__ - Step 40 Global step 40 Train loss 0.68 on epoch=19
04/25/2022 16:19:39 - INFO - __main__ - Step 50 Global step 50 Train loss 0.55 on epoch=24
04/25/2022 16:19:41 - INFO - __main__ - Global step 50 Train loss 1.00 ACC 0.28125 on epoch=24
04/25/2022 16:19:41 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.28125 on epoch=24, global_step=50
04/25/2022 16:19:43 - INFO - __main__ - Step 60 Global step 60 Train loss 0.48 on epoch=29
04/25/2022 16:19:46 - INFO - __main__ - Step 70 Global step 70 Train loss 0.34 on epoch=34
04/25/2022 16:19:48 - INFO - __main__ - Step 80 Global step 80 Train loss 0.37 on epoch=39
04/25/2022 16:19:51 - INFO - __main__ - Step 90 Global step 90 Train loss 0.32 on epoch=44
04/25/2022 16:19:53 - INFO - __main__ - Step 100 Global step 100 Train loss 0.32 on epoch=49
04/25/2022 16:19:55 - INFO - __main__ - Global step 100 Train loss 0.37 ACC 0.28125 on epoch=49
04/25/2022 16:19:57 - INFO - __main__ - Step 110 Global step 110 Train loss 0.28 on epoch=54
04/25/2022 16:20:00 - INFO - __main__ - Step 120 Global step 120 Train loss 0.22 on epoch=59
04/25/2022 16:20:02 - INFO - __main__ - Step 130 Global step 130 Train loss 0.25 on epoch=64
04/25/2022 16:20:05 - INFO - __main__ - Step 140 Global step 140 Train loss 0.18 on epoch=69
04/25/2022 16:20:07 - INFO - __main__ - Step 150 Global step 150 Train loss 0.17 on epoch=74
04/25/2022 16:20:09 - INFO - __main__ - Global step 150 Train loss 0.22 ACC 0.25 on epoch=74
04/25/2022 16:20:12 - INFO - __main__ - Step 160 Global step 160 Train loss 0.16 on epoch=79
04/25/2022 16:20:14 - INFO - __main__ - Step 170 Global step 170 Train loss 0.18 on epoch=84
04/25/2022 16:20:17 - INFO - __main__ - Step 180 Global step 180 Train loss 0.12 on epoch=89
04/25/2022 16:20:19 - INFO - __main__ - Step 190 Global step 190 Train loss 0.14 on epoch=94
04/25/2022 16:20:22 - INFO - __main__ - Step 200 Global step 200 Train loss 0.13 on epoch=99
04/25/2022 16:20:24 - INFO - __main__ - Global step 200 Train loss 0.14 ACC 0.25 on epoch=99
04/25/2022 16:20:26 - INFO - __main__ - Step 210 Global step 210 Train loss 0.10 on epoch=104
04/25/2022 16:20:29 - INFO - __main__ - Step 220 Global step 220 Train loss 0.09 on epoch=109
04/25/2022 16:20:31 - INFO - __main__ - Step 230 Global step 230 Train loss 0.12 on epoch=114
04/25/2022 16:20:34 - INFO - __main__ - Step 240 Global step 240 Train loss 0.07 on epoch=119
04/25/2022 16:20:36 - INFO - __main__ - Step 250 Global step 250 Train loss 0.09 on epoch=124
04/25/2022 16:20:38 - INFO - __main__ - Global step 250 Train loss 0.09 ACC 0.15625 on epoch=124
04/25/2022 16:20:41 - INFO - __main__ - Step 260 Global step 260 Train loss 0.12 on epoch=129
04/25/2022 16:20:43 - INFO - __main__ - Step 270 Global step 270 Train loss 0.06 on epoch=134
04/25/2022 16:20:46 - INFO - __main__ - Step 280 Global step 280 Train loss 0.10 on epoch=139
04/25/2022 16:20:48 - INFO - __main__ - Step 290 Global step 290 Train loss 0.07 on epoch=144
04/25/2022 16:20:51 - INFO - __main__ - Step 300 Global step 300 Train loss 0.09 on epoch=149
04/25/2022 16:20:53 - INFO - __main__ - Global step 300 Train loss 0.09 ACC 0.25 on epoch=149
04/25/2022 16:20:55 - INFO - __main__ - Step 310 Global step 310 Train loss 0.10 on epoch=154
04/25/2022 16:20:58 - INFO - __main__ - Step 320 Global step 320 Train loss 0.09 on epoch=159
04/25/2022 16:21:00 - INFO - __main__ - Step 330 Global step 330 Train loss 0.08 on epoch=164
04/25/2022 16:21:02 - INFO - __main__ - Step 340 Global step 340 Train loss 0.05 on epoch=169
04/25/2022 16:21:05 - INFO - __main__ - Step 350 Global step 350 Train loss 0.07 on epoch=174
04/25/2022 16:21:07 - INFO - __main__ - Global step 350 Train loss 0.08 ACC 0.15625 on epoch=174
04/25/2022 16:21:10 - INFO - __main__ - Step 360 Global step 360 Train loss 0.08 on epoch=179
04/25/2022 16:21:12 - INFO - __main__ - Step 370 Global step 370 Train loss 0.03 on epoch=184
04/25/2022 16:21:14 - INFO - __main__ - Step 380 Global step 380 Train loss 0.04 on epoch=189
04/25/2022 16:21:17 - INFO - __main__ - Step 390 Global step 390 Train loss 0.06 on epoch=194
04/25/2022 16:21:19 - INFO - __main__ - Step 400 Global step 400 Train loss 0.03 on epoch=199
04/25/2022 16:21:21 - INFO - __main__ - Global step 400 Train loss 0.05 ACC 0.25 on epoch=199
04/25/2022 16:21:24 - INFO - __main__ - Step 410 Global step 410 Train loss 0.06 on epoch=204
04/25/2022 16:21:26 - INFO - __main__ - Step 420 Global step 420 Train loss 0.07 on epoch=209
04/25/2022 16:21:28 - INFO - __main__ - Step 430 Global step 430 Train loss 0.12 on epoch=214
04/25/2022 16:21:31 - INFO - __main__ - Step 440 Global step 440 Train loss 0.04 on epoch=219
04/25/2022 16:21:33 - INFO - __main__ - Step 450 Global step 450 Train loss 0.03 on epoch=224
04/25/2022 16:21:35 - INFO - __main__ - Global step 450 Train loss 0.06 ACC 0.3125 on epoch=224
04/25/2022 16:21:35 - INFO - __main__ - Saving model with best ACC: 0.28125 -> 0.3125 on epoch=224, global_step=450
04/25/2022 16:21:38 - INFO - __main__ - Step 460 Global step 460 Train loss 0.04 on epoch=229
04/25/2022 16:21:40 - INFO - __main__ - Step 470 Global step 470 Train loss 0.06 on epoch=234
04/25/2022 16:21:43 - INFO - __main__ - Step 480 Global step 480 Train loss 0.07 on epoch=239
04/25/2022 16:21:45 - INFO - __main__ - Step 490 Global step 490 Train loss 0.04 on epoch=244
04/25/2022 16:21:47 - INFO - __main__ - Step 500 Global step 500 Train loss 0.07 on epoch=249
04/25/2022 16:21:49 - INFO - __main__ - Global step 500 Train loss 0.05 ACC 0.375 on epoch=249
04/25/2022 16:21:49 - INFO - __main__ - Saving model with best ACC: 0.3125 -> 0.375 on epoch=249, global_step=500
04/25/2022 16:21:52 - INFO - __main__ - Step 510 Global step 510 Train loss 0.02 on epoch=254
04/25/2022 16:21:54 - INFO - __main__ - Step 520 Global step 520 Train loss 0.01 on epoch=259
04/25/2022 16:21:56 - INFO - __main__ - Step 530 Global step 530 Train loss 0.01 on epoch=264
04/25/2022 16:21:59 - INFO - __main__ - Step 540 Global step 540 Train loss 0.02 on epoch=269
04/25/2022 16:22:01 - INFO - __main__ - Step 550 Global step 550 Train loss 0.02 on epoch=274
04/25/2022 16:22:03 - INFO - __main__ - Global step 550 Train loss 0.02 ACC 0.3125 on epoch=274
04/25/2022 16:22:05 - INFO - __main__ - Step 560 Global step 560 Train loss 0.02 on epoch=279
04/25/2022 16:22:08 - INFO - __main__ - Step 570 Global step 570 Train loss 0.04 on epoch=284
04/25/2022 16:22:10 - INFO - __main__ - Step 580 Global step 580 Train loss 0.03 on epoch=289
04/25/2022 16:22:13 - INFO - __main__ - Step 590 Global step 590 Train loss 0.02 on epoch=294
04/25/2022 16:22:15 - INFO - __main__ - Step 600 Global step 600 Train loss 0.03 on epoch=299
04/25/2022 16:22:17 - INFO - __main__ - Global step 600 Train loss 0.03 ACC 0.3125 on epoch=299
04/25/2022 16:22:19 - INFO - __main__ - Step 610 Global step 610 Train loss 0.03 on epoch=304
04/25/2022 16:22:22 - INFO - __main__ - Step 620 Global step 620 Train loss 0.02 on epoch=309
04/25/2022 16:22:24 - INFO - __main__ - Step 630 Global step 630 Train loss 0.02 on epoch=314
04/25/2022 16:22:27 - INFO - __main__ - Step 640 Global step 640 Train loss 0.02 on epoch=319
04/25/2022 16:22:29 - INFO - __main__ - Step 650 Global step 650 Train loss 0.03 on epoch=324
04/25/2022 16:22:31 - INFO - __main__ - Global step 650 Train loss 0.02 ACC 0.34375 on epoch=324
04/25/2022 16:22:33 - INFO - __main__ - Step 660 Global step 660 Train loss 0.02 on epoch=329
04/25/2022 16:22:36 - INFO - __main__ - Step 670 Global step 670 Train loss 0.02 on epoch=334
04/25/2022 16:22:38 - INFO - __main__ - Step 680 Global step 680 Train loss 0.02 on epoch=339
04/25/2022 16:22:41 - INFO - __main__ - Step 690 Global step 690 Train loss 0.01 on epoch=344
04/25/2022 16:22:43 - INFO - __main__ - Step 700 Global step 700 Train loss 0.01 on epoch=349
04/25/2022 16:22:45 - INFO - __main__ - Global step 700 Train loss 0.02 ACC 0.21875 on epoch=349
04/25/2022 16:22:47 - INFO - __main__ - Step 710 Global step 710 Train loss 0.02 on epoch=354
04/25/2022 16:22:50 - INFO - __main__ - Step 720 Global step 720 Train loss 0.04 on epoch=359
04/25/2022 16:22:52 - INFO - __main__ - Step 730 Global step 730 Train loss 0.03 on epoch=364
04/25/2022 16:22:55 - INFO - __main__ - Step 740 Global step 740 Train loss 0.01 on epoch=369
04/25/2022 16:22:57 - INFO - __main__ - Step 750 Global step 750 Train loss 0.02 on epoch=374
04/25/2022 16:22:59 - INFO - __main__ - Global step 750 Train loss 0.02 ACC 0.34375 on epoch=374
04/25/2022 16:23:01 - INFO - __main__ - Step 760 Global step 760 Train loss 0.02 on epoch=379
04/25/2022 16:23:04 - INFO - __main__ - Step 770 Global step 770 Train loss 0.02 on epoch=384
04/25/2022 16:23:06 - INFO - __main__ - Step 780 Global step 780 Train loss 0.02 on epoch=389
04/25/2022 16:23:09 - INFO - __main__ - Step 790 Global step 790 Train loss 0.01 on epoch=394
04/25/2022 16:23:11 - INFO - __main__ - Step 800 Global step 800 Train loss 0.01 on epoch=399
04/25/2022 16:23:13 - INFO - __main__ - Global step 800 Train loss 0.02 ACC 0.28125 on epoch=399
04/25/2022 16:23:15 - INFO - __main__ - Step 810 Global step 810 Train loss 0.01 on epoch=404
04/25/2022 16:23:18 - INFO - __main__ - Step 820 Global step 820 Train loss 0.01 on epoch=409
04/25/2022 16:23:20 - INFO - __main__ - Step 830 Global step 830 Train loss 0.02 on epoch=414
04/25/2022 16:23:23 - INFO - __main__ - Step 840 Global step 840 Train loss 0.01 on epoch=419
04/25/2022 16:23:25 - INFO - __main__ - Step 850 Global step 850 Train loss 0.01 on epoch=424
04/25/2022 16:23:27 - INFO - __main__ - Global step 850 Train loss 0.01 ACC 0.25 on epoch=424
04/25/2022 16:23:29 - INFO - __main__ - Step 860 Global step 860 Train loss 0.01 on epoch=429
04/25/2022 16:23:31 - INFO - __main__ - Step 870 Global step 870 Train loss 0.02 on epoch=434
04/25/2022 16:23:34 - INFO - __main__ - Step 880 Global step 880 Train loss 0.01 on epoch=439
04/25/2022 16:23:36 - INFO - __main__ - Step 890 Global step 890 Train loss 0.01 on epoch=444
04/25/2022 16:23:39 - INFO - __main__ - Step 900 Global step 900 Train loss 0.03 on epoch=449
04/25/2022 16:23:40 - INFO - __main__ - Global step 900 Train loss 0.02 ACC 0.25 on epoch=449
04/25/2022 16:23:43 - INFO - __main__ - Step 910 Global step 910 Train loss 0.02 on epoch=454
04/25/2022 16:23:45 - INFO - __main__ - Step 920 Global step 920 Train loss 0.02 on epoch=459
04/25/2022 16:23:48 - INFO - __main__ - Step 930 Global step 930 Train loss 0.01 on epoch=464
04/25/2022 16:23:50 - INFO - __main__ - Step 940 Global step 940 Train loss 0.02 on epoch=469
04/25/2022 16:23:53 - INFO - __main__ - Step 950 Global step 950 Train loss 0.03 on epoch=474
04/25/2022 16:23:54 - INFO - __main__ - Global step 950 Train loss 0.02 ACC 0.28125 on epoch=474
04/25/2022 16:23:57 - INFO - __main__ - Step 960 Global step 960 Train loss 0.01 on epoch=479
04/25/2022 16:23:59 - INFO - __main__ - Step 970 Global step 970 Train loss 0.01 on epoch=484
04/25/2022 16:24:02 - INFO - __main__ - Step 980 Global step 980 Train loss 0.01 on epoch=489
04/25/2022 16:24:04 - INFO - __main__ - Step 990 Global step 990 Train loss 0.01 on epoch=494
04/25/2022 16:24:07 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.01 on epoch=499
04/25/2022 16:24:08 - INFO - __main__ - Global step 1000 Train loss 0.01 ACC 0.28125 on epoch=499
04/25/2022 16:24:11 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.01 on epoch=504
04/25/2022 16:24:13 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.01 on epoch=509
04/25/2022 16:24:16 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.01 on epoch=514
04/25/2022 16:24:18 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.03 on epoch=519
04/25/2022 16:24:21 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.01 on epoch=524
04/25/2022 16:24:22 - INFO - __main__ - Global step 1050 Train loss 0.01 ACC 0.3125 on epoch=524
04/25/2022 16:24:25 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.01 on epoch=529
04/25/2022 16:24:27 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.01 on epoch=534
04/25/2022 16:24:30 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.01 on epoch=539
04/25/2022 16:24:32 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.00 on epoch=544
04/25/2022 16:24:34 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.01 on epoch=549
04/25/2022 16:24:36 - INFO - __main__ - Global step 1100 Train loss 0.01 ACC 0.3125 on epoch=549
04/25/2022 16:24:39 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.00 on epoch=554
04/25/2022 16:24:41 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=559
04/25/2022 16:24:44 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=564
04/25/2022 16:24:46 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.00 on epoch=569
04/25/2022 16:24:48 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.02 on epoch=574
04/25/2022 16:24:50 - INFO - __main__ - Global step 1150 Train loss 0.01 ACC 0.25 on epoch=574
04/25/2022 16:24:53 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.00 on epoch=579
04/25/2022 16:24:55 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.00 on epoch=584
04/25/2022 16:24:58 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.02 on epoch=589
04/25/2022 16:25:00 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.01 on epoch=594
04/25/2022 16:25:03 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=599
04/25/2022 16:25:04 - INFO - __main__ - Global step 1200 Train loss 0.01 ACC 0.28125 on epoch=599
04/25/2022 16:25:07 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.03 on epoch=604
04/25/2022 16:25:09 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=609
04/25/2022 16:25:12 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.00 on epoch=614
04/25/2022 16:25:14 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.00 on epoch=619
04/25/2022 16:25:17 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.04 on epoch=624
04/25/2022 16:25:18 - INFO - __main__ - Global step 1250 Train loss 0.02 ACC 0.28125 on epoch=624
04/25/2022 16:25:21 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.02 on epoch=629
04/25/2022 16:25:23 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.01 on epoch=634
04/25/2022 16:25:26 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=639
04/25/2022 16:25:28 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.02 on epoch=644
04/25/2022 16:25:30 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=649
04/25/2022 16:25:32 - INFO - __main__ - Global step 1300 Train loss 0.01 ACC 0.25 on epoch=649
04/25/2022 16:25:35 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.00 on epoch=654
04/25/2022 16:25:37 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=659
04/25/2022 16:25:40 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.02 on epoch=664
04/25/2022 16:25:42 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.03 on epoch=669
04/25/2022 16:25:44 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=674
04/25/2022 16:25:47 - INFO - __main__ - Global step 1350 Train loss 0.01 ACC 0.1875 on epoch=674
04/25/2022 16:25:49 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=679
04/25/2022 16:25:51 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.00 on epoch=684
04/25/2022 16:25:54 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=689
04/25/2022 16:25:56 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.05 on epoch=694
04/25/2022 16:25:59 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.00 on epoch=699
04/25/2022 16:26:00 - INFO - __main__ - Global step 1400 Train loss 0.01 ACC 0.3125 on epoch=699
04/25/2022 16:26:03 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=704
04/25/2022 16:26:05 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=709
04/25/2022 16:26:08 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=714
04/25/2022 16:26:10 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=719
04/25/2022 16:26:13 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=724
04/25/2022 16:26:14 - INFO - __main__ - Global step 1450 Train loss 0.01 ACC 0.34375 on epoch=724
04/25/2022 16:26:17 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.03 on epoch=729
04/25/2022 16:26:19 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=734
04/25/2022 16:26:21 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=739
04/25/2022 16:26:24 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.02 on epoch=744
04/25/2022 16:26:26 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=749
04/25/2022 16:26:28 - INFO - __main__ - Global step 1500 Train loss 0.01 ACC 0.34375 on epoch=749
04/25/2022 16:26:31 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=754
04/25/2022 16:26:33 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=759
04/25/2022 16:26:36 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=764
04/25/2022 16:26:38 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=769
04/25/2022 16:26:41 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=774
04/25/2022 16:26:42 - INFO - __main__ - Global step 1550 Train loss 0.01 ACC 0.34375 on epoch=774
04/25/2022 16:26:45 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=779
04/25/2022 16:26:47 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=784
04/25/2022 16:26:50 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=789
04/25/2022 16:26:52 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=794
04/25/2022 16:26:55 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=799
04/25/2022 16:26:56 - INFO - __main__ - Global step 1600 Train loss 0.01 ACC 0.3125 on epoch=799
04/25/2022 16:26:59 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.47 on epoch=804
04/25/2022 16:27:01 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.33 on epoch=809
04/25/2022 16:27:03 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.05 on epoch=814
04/25/2022 16:27:06 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=819
04/25/2022 16:27:08 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=824
04/25/2022 16:27:10 - INFO - __main__ - Global step 1650 Train loss 0.17 ACC 0.3125 on epoch=824
04/25/2022 16:27:12 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=829
04/25/2022 16:27:15 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=834
04/25/2022 16:27:17 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=839
04/25/2022 16:27:20 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=844
04/25/2022 16:27:22 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=849
04/25/2022 16:27:24 - INFO - __main__ - Global step 1700 Train loss 0.01 ACC 0.375 on epoch=849
04/25/2022 16:27:27 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=854
04/25/2022 16:27:29 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.04 on epoch=859
04/25/2022 16:27:32 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=864
04/25/2022 16:27:34 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=869
04/25/2022 16:27:36 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=874
04/25/2022 16:27:38 - INFO - __main__ - Global step 1750 Train loss 0.01 ACC 0.28125 on epoch=874
04/25/2022 16:27:41 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=879
04/25/2022 16:27:43 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=884
04/25/2022 16:27:45 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=889
04/25/2022 16:27:48 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=894
04/25/2022 16:27:50 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=899
04/25/2022 16:27:52 - INFO - __main__ - Global step 1800 Train loss 0.01 ACC 0.28125 on epoch=899
04/25/2022 16:27:55 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=904
04/25/2022 16:27:57 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=909
04/25/2022 16:27:59 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=914
04/25/2022 16:28:02 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=919
04/25/2022 16:28:04 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=924
04/25/2022 16:28:06 - INFO - __main__ - Global step 1850 Train loss 0.01 ACC 0.21875 on epoch=924
04/25/2022 16:28:09 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=929
04/25/2022 16:28:11 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=934
04/25/2022 16:28:14 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=939
04/25/2022 16:28:16 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=944
04/25/2022 16:28:19 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=949
04/25/2022 16:28:20 - INFO - __main__ - Global step 1900 Train loss 0.00 ACC 0.28125 on epoch=949
04/25/2022 16:28:23 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=954
04/25/2022 16:28:25 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=959
04/25/2022 16:28:28 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=964
04/25/2022 16:28:30 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=969
04/25/2022 16:28:33 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=974
04/25/2022 16:28:34 - INFO - __main__ - Global step 1950 Train loss 0.01 ACC 0.3125 on epoch=974
04/25/2022 16:28:37 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=979
04/25/2022 16:28:39 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=984
04/25/2022 16:28:42 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=989
04/25/2022 16:28:44 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=994
04/25/2022 16:28:47 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=999
04/25/2022 16:28:49 - INFO - __main__ - Global step 2000 Train loss 0.01 ACC 0.25 on epoch=999
04/25/2022 16:28:49 - INFO - __main__ - save last model!
04/25/2022 16:28:49 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
04/25/2022 16:28:49 - INFO - __main__ - Start tokenizing ... 500 instances
04/25/2022 16:28:49 - INFO - __main__ - Printing 3 examples
04/25/2022 16:28:49 - INFO - __main__ -  [openbookqa] Frilled sharks and angler fish live far beneath the surface of the ocean, which is why they are known as (A) Deep sea animals (B) fish (C) Long Sea Fish (D) Far Sea Animals
04/25/2022 16:28:49 - INFO - __main__ - ['Deep sea animals']
04/25/2022 16:28:49 - INFO - __main__ -  [openbookqa] Gas can fill any container it is given, and liquid (A) is standard weight and size (B) is the opposite of variable (C) only needs a few (D) uses what it needs
04/25/2022 16:28:49 - INFO - __main__ - ['uses what it needs']
04/25/2022 16:28:49 - INFO - __main__ -  [openbookqa] When birds migrate south for the winter, they do it because (A) they are genetically called to (B) their children ask for them to (C) it is important to their happiness (D) they decide to each year
04/25/2022 16:28:49 - INFO - __main__ - ['they are genetically called to']
04/25/2022 16:28:49 - INFO - __main__ - Tokenizing Input ...
04/25/2022 16:28:49 - INFO - __main__ - Tokenizing Output ...
04/25/2022 16:28:49 - INFO - __main__ - Loaded 500 examples from test data
04/25/2022 16:28:49 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 16:28:49 - INFO - __main__ - Printing 3 examples
04/25/2022 16:28:49 - INFO - __main__ -  [openbookqa] Plant population would fail to maintain it's size if (A) fertilizer is applied (B) gets more sun (C) H2O depletes (D) grows
04/25/2022 16:28:49 - INFO - __main__ - ['H2O depletes']
04/25/2022 16:28:49 - INFO - __main__ -  [openbookqa] if members of a species are born then the species what increases? (A) water (B) community (C) understanding (D) food
04/25/2022 16:28:49 - INFO - __main__ - ['community']
04/25/2022 16:28:49 - INFO - __main__ -  [openbookqa] An example of adaption is (A) Eating tacos (B) wearing sunblock (C) Reading a book (D) Drinking water
04/25/2022 16:28:49 - INFO - __main__ - ['wearing sunblock']
04/25/2022 16:28:49 - INFO - __main__ - Tokenizing Input ...
04/25/2022 16:28:49 - INFO - __main__ - Tokenizing Output ...
04/25/2022 16:28:49 - INFO - __main__ - Loaded 32 examples from train data
04/25/2022 16:28:49 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 16:28:49 - INFO - __main__ - Printing 3 examples
04/25/2022 16:28:49 - INFO - __main__ -  [openbookqa] If you desired to keep your house cooler in the summer months (A) plant trees that tower above the ground (B) plant ivy around the trees (C) plant shrubs around the foundation (D) plant trees that stay smaller than dogwoods
04/25/2022 16:28:49 - INFO - __main__ - ['plant trees that tower above the ground']
04/25/2022 16:28:49 - INFO - __main__ -  [openbookqa] A person knows that a place always has blue skies, warm weather and a light breeze because (A) that is the beach (B) that is the meaning (C) that is the religion (D) climate is fairly reliable
04/25/2022 16:28:49 - INFO - __main__ - ['climate is fairly reliable']
04/25/2022 16:28:49 - INFO - __main__ -  [openbookqa] Microscopes (A) make tiny atoms look smaller (B) enhance the size of amoebas for easier viewing (C) make magnifying things much more difficult (D) make huge samples look minuscule
04/25/2022 16:28:49 - INFO - __main__ - ['enhance the size of amoebas for easier viewing']
04/25/2022 16:28:49 - INFO - __main__ - Tokenizing Input ...
04/25/2022 16:28:49 - INFO - __main__ - Tokenizing Output ...
04/25/2022 16:28:49 - INFO - __main__ - Loaded 32 examples from dev data
04/25/2022 16:29:08 - INFO - __main__ - load prompt embedding from ckpt
04/25/2022 16:29:09 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/25/2022 16:29:09 - INFO - __main__ - Starting training!
04/25/2022 16:29:20 - INFO - __main__ - Saved prediction in models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-openbookqa/openbookqa_32_100_0.5_8_predictions.txt
04/25/2022 16:29:20 - INFO - __main__ - ACC on test data: 0.3000
04/25/2022 16:29:20 - INFO - __main__ - prefix=openbookqa_32_100, lr=0.5, bsz=8, dev_performance=0.375, test_performance=0.3
04/25/2022 16:29:20 - INFO - __main__ - Running ... prefix=openbookqa_32_100, lr=0.4, bsz=8 ...
04/25/2022 16:29:21 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 16:29:21 - INFO - __main__ - Printing 3 examples
04/25/2022 16:29:21 - INFO - __main__ -  [openbookqa] Plant population would fail to maintain it's size if (A) fertilizer is applied (B) gets more sun (C) H2O depletes (D) grows
04/25/2022 16:29:21 - INFO - __main__ - ['H2O depletes']
04/25/2022 16:29:21 - INFO - __main__ -  [openbookqa] if members of a species are born then the species what increases? (A) water (B) community (C) understanding (D) food
04/25/2022 16:29:21 - INFO - __main__ - ['community']
04/25/2022 16:29:21 - INFO - __main__ -  [openbookqa] An example of adaption is (A) Eating tacos (B) wearing sunblock (C) Reading a book (D) Drinking water
04/25/2022 16:29:21 - INFO - __main__ - ['wearing sunblock']
04/25/2022 16:29:21 - INFO - __main__ - Tokenizing Input ...
04/25/2022 16:29:21 - INFO - __main__ - Tokenizing Output ...
04/25/2022 16:29:21 - INFO - __main__ - Loaded 32 examples from train data
04/25/2022 16:29:21 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 16:29:21 - INFO - __main__ - Printing 3 examples
04/25/2022 16:29:21 - INFO - __main__ -  [openbookqa] If you desired to keep your house cooler in the summer months (A) plant trees that tower above the ground (B) plant ivy around the trees (C) plant shrubs around the foundation (D) plant trees that stay smaller than dogwoods
04/25/2022 16:29:21 - INFO - __main__ - ['plant trees that tower above the ground']
04/25/2022 16:29:21 - INFO - __main__ -  [openbookqa] A person knows that a place always has blue skies, warm weather and a light breeze because (A) that is the beach (B) that is the meaning (C) that is the religion (D) climate is fairly reliable
04/25/2022 16:29:21 - INFO - __main__ - ['climate is fairly reliable']
04/25/2022 16:29:21 - INFO - __main__ -  [openbookqa] Microscopes (A) make tiny atoms look smaller (B) enhance the size of amoebas for easier viewing (C) make magnifying things much more difficult (D) make huge samples look minuscule
04/25/2022 16:29:21 - INFO - __main__ - ['enhance the size of amoebas for easier viewing']
04/25/2022 16:29:21 - INFO - __main__ - Tokenizing Input ...
04/25/2022 16:29:21 - INFO - __main__ - Tokenizing Output ...
04/25/2022 16:29:21 - INFO - __main__ - Loaded 32 examples from dev data
04/25/2022 16:29:36 - INFO - __main__ - load prompt embedding from ckpt
04/25/2022 16:29:37 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/25/2022 16:29:37 - INFO - __main__ - Starting training!
04/25/2022 16:29:40 - INFO - __main__ - Step 10 Global step 10 Train loss 1.75 on epoch=4
04/25/2022 16:29:42 - INFO - __main__ - Step 20 Global step 20 Train loss 1.27 on epoch=9
04/25/2022 16:29:45 - INFO - __main__ - Step 30 Global step 30 Train loss 0.87 on epoch=14
04/25/2022 16:29:47 - INFO - __main__ - Step 40 Global step 40 Train loss 0.73 on epoch=19
04/25/2022 16:29:50 - INFO - __main__ - Step 50 Global step 50 Train loss 0.69 on epoch=24
04/25/2022 16:29:52 - INFO - __main__ - Global step 50 Train loss 1.06 ACC 0.3125 on epoch=24
04/25/2022 16:29:52 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.3125 on epoch=24, global_step=50
04/25/2022 16:29:54 - INFO - __main__ - Step 60 Global step 60 Train loss 0.62 on epoch=29
04/25/2022 16:29:57 - INFO - __main__ - Step 70 Global step 70 Train loss 0.49 on epoch=34
04/25/2022 16:30:00 - INFO - __main__ - Step 80 Global step 80 Train loss 0.51 on epoch=39
04/25/2022 16:30:02 - INFO - __main__ - Step 90 Global step 90 Train loss 0.40 on epoch=44
04/25/2022 16:30:05 - INFO - __main__ - Step 100 Global step 100 Train loss 0.37 on epoch=49
04/25/2022 16:30:06 - INFO - __main__ - Global step 100 Train loss 0.48 ACC 0.28125 on epoch=49
04/25/2022 16:30:09 - INFO - __main__ - Step 110 Global step 110 Train loss 0.33 on epoch=54
04/25/2022 16:30:12 - INFO - __main__ - Step 120 Global step 120 Train loss 0.27 on epoch=59
04/25/2022 16:30:14 - INFO - __main__ - Step 130 Global step 130 Train loss 0.30 on epoch=64
04/25/2022 16:30:17 - INFO - __main__ - Step 140 Global step 140 Train loss 0.21 on epoch=69
04/25/2022 16:30:19 - INFO - __main__ - Step 150 Global step 150 Train loss 0.29 on epoch=74
04/25/2022 16:30:21 - INFO - __main__ - Global step 150 Train loss 0.28 ACC 0.3125 on epoch=74
04/25/2022 16:30:24 - INFO - __main__ - Step 160 Global step 160 Train loss 0.24 on epoch=79
04/25/2022 16:30:26 - INFO - __main__ - Step 170 Global step 170 Train loss 0.20 on epoch=84
04/25/2022 16:30:29 - INFO - __main__ - Step 180 Global step 180 Train loss 0.24 on epoch=89
04/25/2022 16:30:31 - INFO - __main__ - Step 190 Global step 190 Train loss 0.14 on epoch=94
04/25/2022 16:30:34 - INFO - __main__ - Step 200 Global step 200 Train loss 0.15 on epoch=99
04/25/2022 16:30:36 - INFO - __main__ - Global step 200 Train loss 0.19 ACC 0.28125 on epoch=99
04/25/2022 16:30:38 - INFO - __main__ - Step 210 Global step 210 Train loss 0.16 on epoch=104
04/25/2022 16:30:41 - INFO - __main__ - Step 220 Global step 220 Train loss 0.15 on epoch=109
04/25/2022 16:30:43 - INFO - __main__ - Step 230 Global step 230 Train loss 0.10 on epoch=114
04/25/2022 16:30:46 - INFO - __main__ - Step 240 Global step 240 Train loss 0.12 on epoch=119
04/25/2022 16:30:48 - INFO - __main__ - Step 250 Global step 250 Train loss 0.10 on epoch=124
04/25/2022 16:30:50 - INFO - __main__ - Global step 250 Train loss 0.13 ACC 0.21875 on epoch=124
04/25/2022 16:30:53 - INFO - __main__ - Step 260 Global step 260 Train loss 0.11 on epoch=129
04/25/2022 16:30:56 - INFO - __main__ - Step 270 Global step 270 Train loss 0.16 on epoch=134
04/25/2022 16:30:58 - INFO - __main__ - Step 280 Global step 280 Train loss 0.09 on epoch=139
04/25/2022 16:31:01 - INFO - __main__ - Step 290 Global step 290 Train loss 0.10 on epoch=144
04/25/2022 16:31:03 - INFO - __main__ - Step 300 Global step 300 Train loss 0.10 on epoch=149
04/25/2022 16:31:05 - INFO - __main__ - Global step 300 Train loss 0.11 ACC 0.15625 on epoch=149
04/25/2022 16:31:08 - INFO - __main__ - Step 310 Global step 310 Train loss 0.10 on epoch=154
04/25/2022 16:31:10 - INFO - __main__ - Step 320 Global step 320 Train loss 0.07 on epoch=159
04/25/2022 16:31:13 - INFO - __main__ - Step 330 Global step 330 Train loss 0.06 on epoch=164
04/25/2022 16:31:16 - INFO - __main__ - Step 340 Global step 340 Train loss 0.03 on epoch=169
04/25/2022 16:31:18 - INFO - __main__ - Step 350 Global step 350 Train loss 0.05 on epoch=174
04/25/2022 16:31:20 - INFO - __main__ - Global step 350 Train loss 0.06 ACC 0.1875 on epoch=174
04/25/2022 16:31:23 - INFO - __main__ - Step 360 Global step 360 Train loss 0.06 on epoch=179
04/25/2022 16:31:25 - INFO - __main__ - Step 370 Global step 370 Train loss 0.09 on epoch=184
04/25/2022 16:31:28 - INFO - __main__ - Step 380 Global step 380 Train loss 0.04 on epoch=189
04/25/2022 16:31:30 - INFO - __main__ - Step 390 Global step 390 Train loss 0.05 on epoch=194
04/25/2022 16:31:33 - INFO - __main__ - Step 400 Global step 400 Train loss 0.09 on epoch=199
04/25/2022 16:31:35 - INFO - __main__ - Global step 400 Train loss 0.06 ACC 0.25 on epoch=199
04/25/2022 16:31:37 - INFO - __main__ - Step 410 Global step 410 Train loss 0.05 on epoch=204
04/25/2022 16:31:40 - INFO - __main__ - Step 420 Global step 420 Train loss 0.04 on epoch=209
04/25/2022 16:31:42 - INFO - __main__ - Step 430 Global step 430 Train loss 0.04 on epoch=214
04/25/2022 16:31:45 - INFO - __main__ - Step 440 Global step 440 Train loss 0.04 on epoch=219
04/25/2022 16:31:48 - INFO - __main__ - Step 450 Global step 450 Train loss 0.03 on epoch=224
04/25/2022 16:31:50 - INFO - __main__ - Global step 450 Train loss 0.04 ACC 0.21875 on epoch=224
04/25/2022 16:31:52 - INFO - __main__ - Step 460 Global step 460 Train loss 0.04 on epoch=229
04/25/2022 16:31:55 - INFO - __main__ - Step 470 Global step 470 Train loss 0.04 on epoch=234
04/25/2022 16:31:58 - INFO - __main__ - Step 480 Global step 480 Train loss 0.04 on epoch=239
04/25/2022 16:32:00 - INFO - __main__ - Step 490 Global step 490 Train loss 0.04 on epoch=244
04/25/2022 16:32:03 - INFO - __main__ - Step 500 Global step 500 Train loss 0.04 on epoch=249
04/25/2022 16:32:05 - INFO - __main__ - Global step 500 Train loss 0.04 ACC 0.1875 on epoch=249
04/25/2022 16:32:07 - INFO - __main__ - Step 510 Global step 510 Train loss 0.05 on epoch=254
04/25/2022 16:32:10 - INFO - __main__ - Step 520 Global step 520 Train loss 0.09 on epoch=259
04/25/2022 16:32:12 - INFO - __main__ - Step 530 Global step 530 Train loss 0.03 on epoch=264
04/25/2022 16:32:15 - INFO - __main__ - Step 540 Global step 540 Train loss 0.03 on epoch=269
04/25/2022 16:32:18 - INFO - __main__ - Step 550 Global step 550 Train loss 0.04 on epoch=274
04/25/2022 16:32:19 - INFO - __main__ - Global step 550 Train loss 0.05 ACC 0.25 on epoch=274
04/25/2022 16:32:22 - INFO - __main__ - Step 560 Global step 560 Train loss 0.04 on epoch=279
04/25/2022 16:32:24 - INFO - __main__ - Step 570 Global step 570 Train loss 0.01 on epoch=284
04/25/2022 16:32:27 - INFO - __main__ - Step 580 Global step 580 Train loss 0.03 on epoch=289
04/25/2022 16:32:30 - INFO - __main__ - Step 590 Global step 590 Train loss 0.03 on epoch=294
04/25/2022 16:32:32 - INFO - __main__ - Step 600 Global step 600 Train loss 0.04 on epoch=299
04/25/2022 16:32:35 - INFO - __main__ - Global step 600 Train loss 0.03 ACC 0.21875 on epoch=299
04/25/2022 16:32:37 - INFO - __main__ - Step 610 Global step 610 Train loss 0.03 on epoch=304
04/25/2022 16:32:40 - INFO - __main__ - Step 620 Global step 620 Train loss 0.03 on epoch=309
04/25/2022 16:32:42 - INFO - __main__ - Step 630 Global step 630 Train loss 0.03 on epoch=314
04/25/2022 16:32:45 - INFO - __main__ - Step 640 Global step 640 Train loss 0.03 on epoch=319
04/25/2022 16:32:47 - INFO - __main__ - Step 650 Global step 650 Train loss 0.03 on epoch=324
04/25/2022 16:32:49 - INFO - __main__ - Global step 650 Train loss 0.03 ACC 0.21875 on epoch=324
04/25/2022 16:32:52 - INFO - __main__ - Step 660 Global step 660 Train loss 0.03 on epoch=329
04/25/2022 16:32:54 - INFO - __main__ - Step 670 Global step 670 Train loss 0.02 on epoch=334
04/25/2022 16:32:57 - INFO - __main__ - Step 680 Global step 680 Train loss 0.04 on epoch=339
04/25/2022 16:32:59 - INFO - __main__ - Step 690 Global step 690 Train loss 0.02 on epoch=344
04/25/2022 16:33:02 - INFO - __main__ - Step 700 Global step 700 Train loss 0.02 on epoch=349
04/25/2022 16:33:04 - INFO - __main__ - Global step 700 Train loss 0.03 ACC 0.28125 on epoch=349
04/25/2022 16:33:06 - INFO - __main__ - Step 710 Global step 710 Train loss 0.04 on epoch=354
04/25/2022 16:33:09 - INFO - __main__ - Step 720 Global step 720 Train loss 0.04 on epoch=359
04/25/2022 16:33:11 - INFO - __main__ - Step 730 Global step 730 Train loss 0.01 on epoch=364
04/25/2022 16:33:14 - INFO - __main__ - Step 740 Global step 740 Train loss 0.03 on epoch=369
04/25/2022 16:33:17 - INFO - __main__ - Step 750 Global step 750 Train loss 0.04 on epoch=374
04/25/2022 16:33:19 - INFO - __main__ - Global step 750 Train loss 0.03 ACC 0.25 on epoch=374
04/25/2022 16:33:22 - INFO - __main__ - Step 760 Global step 760 Train loss 0.03 on epoch=379
04/25/2022 16:33:24 - INFO - __main__ - Step 770 Global step 770 Train loss 0.03 on epoch=384
04/25/2022 16:33:27 - INFO - __main__ - Step 780 Global step 780 Train loss 0.02 on epoch=389
04/25/2022 16:33:29 - INFO - __main__ - Step 790 Global step 790 Train loss 0.01 on epoch=394
04/25/2022 16:33:32 - INFO - __main__ - Step 800 Global step 800 Train loss 0.01 on epoch=399
04/25/2022 16:33:34 - INFO - __main__ - Global step 800 Train loss 0.02 ACC 0.25 on epoch=399
04/25/2022 16:33:37 - INFO - __main__ - Step 810 Global step 810 Train loss 0.01 on epoch=404
04/25/2022 16:33:39 - INFO - __main__ - Step 820 Global step 820 Train loss 0.01 on epoch=409
04/25/2022 16:33:42 - INFO - __main__ - Step 830 Global step 830 Train loss 0.02 on epoch=414
04/25/2022 16:33:44 - INFO - __main__ - Step 840 Global step 840 Train loss 0.02 on epoch=419
04/25/2022 16:33:47 - INFO - __main__ - Step 850 Global step 850 Train loss 0.02 on epoch=424
04/25/2022 16:33:49 - INFO - __main__ - Global step 850 Train loss 0.02 ACC 0.25 on epoch=424
04/25/2022 16:33:51 - INFO - __main__ - Step 860 Global step 860 Train loss 0.01 on epoch=429
04/25/2022 16:33:54 - INFO - __main__ - Step 870 Global step 870 Train loss 0.03 on epoch=434
04/25/2022 16:33:56 - INFO - __main__ - Step 880 Global step 880 Train loss 0.01 on epoch=439
04/25/2022 16:33:59 - INFO - __main__ - Step 890 Global step 890 Train loss 0.02 on epoch=444
04/25/2022 16:34:02 - INFO - __main__ - Step 900 Global step 900 Train loss 0.04 on epoch=449
04/25/2022 16:34:04 - INFO - __main__ - Global step 900 Train loss 0.02 ACC 0.25 on epoch=449
04/25/2022 16:34:06 - INFO - __main__ - Step 910 Global step 910 Train loss 0.01 on epoch=454
04/25/2022 16:34:09 - INFO - __main__ - Step 920 Global step 920 Train loss 0.01 on epoch=459
04/25/2022 16:34:11 - INFO - __main__ - Step 930 Global step 930 Train loss 0.02 on epoch=464
04/25/2022 16:34:14 - INFO - __main__ - Step 940 Global step 940 Train loss 0.04 on epoch=469
04/25/2022 16:34:16 - INFO - __main__ - Step 950 Global step 950 Train loss 0.01 on epoch=474
04/25/2022 16:34:18 - INFO - __main__ - Global step 950 Train loss 0.02 ACC 0.21875 on epoch=474
04/25/2022 16:34:21 - INFO - __main__ - Step 960 Global step 960 Train loss 0.02 on epoch=479
04/25/2022 16:34:24 - INFO - __main__ - Step 970 Global step 970 Train loss 0.04 on epoch=484
04/25/2022 16:34:26 - INFO - __main__ - Step 980 Global step 980 Train loss 0.01 on epoch=489
04/25/2022 16:34:29 - INFO - __main__ - Step 990 Global step 990 Train loss 0.01 on epoch=494
04/25/2022 16:34:32 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.01 on epoch=499
04/25/2022 16:34:34 - INFO - __main__ - Global step 1000 Train loss 0.02 ACC 0.25 on epoch=499
04/25/2022 16:34:36 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.01 on epoch=504
04/25/2022 16:34:39 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.01 on epoch=509
04/25/2022 16:34:41 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.01 on epoch=514
04/25/2022 16:34:44 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.01 on epoch=519
04/25/2022 16:34:46 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.01 on epoch=524
04/25/2022 16:34:49 - INFO - __main__ - Global step 1050 Train loss 0.01 ACC 0.15625 on epoch=524
04/25/2022 16:34:51 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.02 on epoch=529
04/25/2022 16:34:54 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.01 on epoch=534
04/25/2022 16:34:56 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.04 on epoch=539
04/25/2022 16:34:59 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.01 on epoch=544
04/25/2022 16:35:01 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.00 on epoch=549
04/25/2022 16:35:04 - INFO - __main__ - Global step 1100 Train loss 0.02 ACC 0.25 on epoch=549
04/25/2022 16:35:06 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.00 on epoch=554
04/25/2022 16:35:09 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.02 on epoch=559
04/25/2022 16:35:11 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=564
04/25/2022 16:35:14 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.01 on epoch=569
04/25/2022 16:35:16 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=574
04/25/2022 16:35:18 - INFO - __main__ - Global step 1150 Train loss 0.01 ACC 0.3125 on epoch=574
04/25/2022 16:35:21 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.01 on epoch=579
04/25/2022 16:35:24 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.02 on epoch=584
04/25/2022 16:35:26 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.01 on epoch=589
04/25/2022 16:35:29 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.03 on epoch=594
04/25/2022 16:35:31 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.02 on epoch=599
04/25/2022 16:35:34 - INFO - __main__ - Global step 1200 Train loss 0.02 ACC 0.21875 on epoch=599
04/25/2022 16:35:36 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.01 on epoch=604
04/25/2022 16:35:39 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.00 on epoch=609
04/25/2022 16:35:41 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=614
04/25/2022 16:35:44 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=619
04/25/2022 16:35:46 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.01 on epoch=624
04/25/2022 16:35:49 - INFO - __main__ - Global step 1250 Train loss 0.01 ACC 0.21875 on epoch=624
04/25/2022 16:35:51 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.00 on epoch=629
04/25/2022 16:35:54 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.00 on epoch=634
04/25/2022 16:35:56 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.03 on epoch=639
04/25/2022 16:35:59 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.04 on epoch=644
04/25/2022 16:36:02 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=649
04/25/2022 16:36:04 - INFO - __main__ - Global step 1300 Train loss 0.02 ACC 0.25 on epoch=649
04/25/2022 16:36:06 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.00 on epoch=654
04/25/2022 16:36:09 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.05 on epoch=659
04/25/2022 16:36:12 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.02 on epoch=664
04/25/2022 16:36:14 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.00 on epoch=669
04/25/2022 16:36:17 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=674
04/25/2022 16:36:19 - INFO - __main__ - Global step 1350 Train loss 0.02 ACC 0.1875 on epoch=674
04/25/2022 16:36:21 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=679
04/25/2022 16:36:24 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=684
04/25/2022 16:36:26 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=689
04/25/2022 16:36:29 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=694
04/25/2022 16:36:31 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=699
04/25/2022 16:36:34 - INFO - __main__ - Global step 1400 Train loss 0.01 ACC 0.21875 on epoch=699
04/25/2022 16:36:36 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.02 on epoch=704
04/25/2022 16:36:39 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.01 on epoch=709
04/25/2022 16:36:41 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=714
04/25/2022 16:36:44 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=719
04/25/2022 16:36:47 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=724
04/25/2022 16:36:49 - INFO - __main__ - Global step 1450 Train loss 0.01 ACC 0.25 on epoch=724
04/25/2022 16:36:52 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=729
04/25/2022 16:36:54 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=734
04/25/2022 16:36:57 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=739
04/25/2022 16:36:59 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=744
04/25/2022 16:37:02 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=749
04/25/2022 16:37:04 - INFO - __main__ - Global step 1500 Train loss 0.01 ACC 0.28125 on epoch=749
04/25/2022 16:37:07 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=754
04/25/2022 16:37:09 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=759
04/25/2022 16:37:12 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=764
04/25/2022 16:37:14 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=769
04/25/2022 16:37:17 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=774
04/25/2022 16:37:19 - INFO - __main__ - Global step 1550 Train loss 0.01 ACC 0.28125 on epoch=774
04/25/2022 16:37:22 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=779
04/25/2022 16:37:24 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=784
04/25/2022 16:37:27 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.02 on epoch=789
04/25/2022 16:37:29 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=794
04/25/2022 16:37:32 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=799
04/25/2022 16:37:34 - INFO - __main__ - Global step 1600 Train loss 0.01 ACC 0.34375 on epoch=799
04/25/2022 16:37:34 - INFO - __main__ - Saving model with best ACC: 0.3125 -> 0.34375 on epoch=799, global_step=1600
04/25/2022 16:37:36 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=804
04/25/2022 16:37:39 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=809
04/25/2022 16:37:41 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=814
04/25/2022 16:37:44 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.02 on epoch=819
04/25/2022 16:37:46 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=824
04/25/2022 16:37:49 - INFO - __main__ - Global step 1650 Train loss 0.01 ACC 0.3125 on epoch=824
04/25/2022 16:37:51 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=829
04/25/2022 16:37:54 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=834
04/25/2022 16:37:56 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=839
04/25/2022 16:37:59 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=844
04/25/2022 16:38:01 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=849
04/25/2022 16:38:03 - INFO - __main__ - Global step 1700 Train loss 0.00 ACC 0.34375 on epoch=849
04/25/2022 16:38:06 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=854
04/25/2022 16:38:08 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=859
04/25/2022 16:38:11 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=864
04/25/2022 16:38:13 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=869
04/25/2022 16:38:16 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=874
04/25/2022 16:38:18 - INFO - __main__ - Global step 1750 Train loss 0.01 ACC 0.3125 on epoch=874
04/25/2022 16:38:21 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=879
04/25/2022 16:38:23 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=884
04/25/2022 16:38:25 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=889
04/25/2022 16:38:28 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=894
04/25/2022 16:38:31 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=899
04/25/2022 16:38:33 - INFO - __main__ - Global step 1800 Train loss 0.01 ACC 0.34375 on epoch=899
04/25/2022 16:38:35 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=904
04/25/2022 16:38:38 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=909
04/25/2022 16:38:40 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=914
04/25/2022 16:38:43 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=919
04/25/2022 16:38:45 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=924
04/25/2022 16:38:47 - INFO - __main__ - Global step 1850 Train loss 0.00 ACC 0.28125 on epoch=924
04/25/2022 16:38:50 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=929
04/25/2022 16:38:52 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=934
04/25/2022 16:38:55 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=939
04/25/2022 16:38:57 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=944
04/25/2022 16:39:00 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=949
04/25/2022 16:39:02 - INFO - __main__ - Global step 1900 Train loss 0.01 ACC 0.25 on epoch=949
04/25/2022 16:39:05 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=954
04/25/2022 16:39:07 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=959
04/25/2022 16:39:10 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=964
04/25/2022 16:39:12 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=969
04/25/2022 16:39:15 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=974
04/25/2022 16:39:17 - INFO - __main__ - Global step 1950 Train loss 0.01 ACC 0.25 on epoch=974
04/25/2022 16:39:19 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.03 on epoch=979
04/25/2022 16:39:22 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=984
04/25/2022 16:39:24 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=989
04/25/2022 16:39:27 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=994
04/25/2022 16:39:29 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=999
04/25/2022 16:39:30 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 16:39:30 - INFO - __main__ - Printing 3 examples
04/25/2022 16:39:30 - INFO - __main__ -  [openbookqa] Plant population would fail to maintain it's size if (A) fertilizer is applied (B) gets more sun (C) H2O depletes (D) grows
04/25/2022 16:39:30 - INFO - __main__ - ['H2O depletes']
04/25/2022 16:39:30 - INFO - __main__ -  [openbookqa] if members of a species are born then the species what increases? (A) water (B) community (C) understanding (D) food
04/25/2022 16:39:30 - INFO - __main__ - ['community']
04/25/2022 16:39:30 - INFO - __main__ -  [openbookqa] An example of adaption is (A) Eating tacos (B) wearing sunblock (C) Reading a book (D) Drinking water
04/25/2022 16:39:30 - INFO - __main__ - ['wearing sunblock']
04/25/2022 16:39:30 - INFO - __main__ - Tokenizing Input ...
04/25/2022 16:39:30 - INFO - __main__ - Tokenizing Output ...
04/25/2022 16:39:30 - INFO - __main__ - Loaded 32 examples from train data
04/25/2022 16:39:30 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 16:39:30 - INFO - __main__ - Printing 3 examples
04/25/2022 16:39:30 - INFO - __main__ -  [openbookqa] If you desired to keep your house cooler in the summer months (A) plant trees that tower above the ground (B) plant ivy around the trees (C) plant shrubs around the foundation (D) plant trees that stay smaller than dogwoods
04/25/2022 16:39:30 - INFO - __main__ - ['plant trees that tower above the ground']
04/25/2022 16:39:30 - INFO - __main__ -  [openbookqa] A person knows that a place always has blue skies, warm weather and a light breeze because (A) that is the beach (B) that is the meaning (C) that is the religion (D) climate is fairly reliable
04/25/2022 16:39:30 - INFO - __main__ - ['climate is fairly reliable']
04/25/2022 16:39:30 - INFO - __main__ -  [openbookqa] Microscopes (A) make tiny atoms look smaller (B) enhance the size of amoebas for easier viewing (C) make magnifying things much more difficult (D) make huge samples look minuscule
04/25/2022 16:39:30 - INFO - __main__ - ['enhance the size of amoebas for easier viewing']
04/25/2022 16:39:30 - INFO - __main__ - Tokenizing Input ...
04/25/2022 16:39:30 - INFO - __main__ - Tokenizing Output ...
04/25/2022 16:39:31 - INFO - __main__ - Loaded 32 examples from dev data
04/25/2022 16:39:31 - INFO - __main__ - Global step 2000 Train loss 0.01 ACC 0.34375 on epoch=999
04/25/2022 16:39:32 - INFO - __main__ - save last model!
04/25/2022 16:39:32 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
04/25/2022 16:39:32 - INFO - __main__ - Start tokenizing ... 500 instances
04/25/2022 16:39:32 - INFO - __main__ - Printing 3 examples
04/25/2022 16:39:32 - INFO - __main__ -  [openbookqa] Frilled sharks and angler fish live far beneath the surface of the ocean, which is why they are known as (A) Deep sea animals (B) fish (C) Long Sea Fish (D) Far Sea Animals
04/25/2022 16:39:32 - INFO - __main__ - ['Deep sea animals']
04/25/2022 16:39:32 - INFO - __main__ -  [openbookqa] Gas can fill any container it is given, and liquid (A) is standard weight and size (B) is the opposite of variable (C) only needs a few (D) uses what it needs
04/25/2022 16:39:32 - INFO - __main__ - ['uses what it needs']
04/25/2022 16:39:32 - INFO - __main__ -  [openbookqa] When birds migrate south for the winter, they do it because (A) they are genetically called to (B) their children ask for them to (C) it is important to their happiness (D) they decide to each year
04/25/2022 16:39:32 - INFO - __main__ - ['they are genetically called to']
04/25/2022 16:39:32 - INFO - __main__ - Tokenizing Input ...
04/25/2022 16:39:32 - INFO - __main__ - Tokenizing Output ...
04/25/2022 16:39:32 - INFO - __main__ - Loaded 500 examples from test data
04/25/2022 16:39:46 - INFO - __main__ - load prompt embedding from ckpt
04/25/2022 16:39:47 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/25/2022 16:39:47 - INFO - __main__ - Starting training!
04/25/2022 16:40:06 - INFO - __main__ - Saved prediction in models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-openbookqa/openbookqa_32_100_0.4_8_predictions.txt
04/25/2022 16:40:06 - INFO - __main__ - ACC on test data: 0.2620
04/25/2022 16:40:06 - INFO - __main__ - prefix=openbookqa_32_100, lr=0.4, bsz=8, dev_performance=0.34375, test_performance=0.262
04/25/2022 16:40:06 - INFO - __main__ - Running ... prefix=openbookqa_32_100, lr=0.3, bsz=8 ...
04/25/2022 16:40:07 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 16:40:07 - INFO - __main__ - Printing 3 examples
04/25/2022 16:40:07 - INFO - __main__ -  [openbookqa] Plant population would fail to maintain it's size if (A) fertilizer is applied (B) gets more sun (C) H2O depletes (D) grows
04/25/2022 16:40:07 - INFO - __main__ - ['H2O depletes']
04/25/2022 16:40:07 - INFO - __main__ -  [openbookqa] if members of a species are born then the species what increases? (A) water (B) community (C) understanding (D) food
04/25/2022 16:40:07 - INFO - __main__ - ['community']
04/25/2022 16:40:07 - INFO - __main__ -  [openbookqa] An example of adaption is (A) Eating tacos (B) wearing sunblock (C) Reading a book (D) Drinking water
04/25/2022 16:40:07 - INFO - __main__ - ['wearing sunblock']
04/25/2022 16:40:07 - INFO - __main__ - Tokenizing Input ...
04/25/2022 16:40:07 - INFO - __main__ - Tokenizing Output ...
04/25/2022 16:40:08 - INFO - __main__ - Loaded 32 examples from train data
04/25/2022 16:40:08 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 16:40:08 - INFO - __main__ - Printing 3 examples
04/25/2022 16:40:08 - INFO - __main__ -  [openbookqa] If you desired to keep your house cooler in the summer months (A) plant trees that tower above the ground (B) plant ivy around the trees (C) plant shrubs around the foundation (D) plant trees that stay smaller than dogwoods
04/25/2022 16:40:08 - INFO - __main__ - ['plant trees that tower above the ground']
04/25/2022 16:40:08 - INFO - __main__ -  [openbookqa] A person knows that a place always has blue skies, warm weather and a light breeze because (A) that is the beach (B) that is the meaning (C) that is the religion (D) climate is fairly reliable
04/25/2022 16:40:08 - INFO - __main__ - ['climate is fairly reliable']
04/25/2022 16:40:08 - INFO - __main__ -  [openbookqa] Microscopes (A) make tiny atoms look smaller (B) enhance the size of amoebas for easier viewing (C) make magnifying things much more difficult (D) make huge samples look minuscule
04/25/2022 16:40:08 - INFO - __main__ - ['enhance the size of amoebas for easier viewing']
04/25/2022 16:40:08 - INFO - __main__ - Tokenizing Input ...
04/25/2022 16:40:08 - INFO - __main__ - Tokenizing Output ...
04/25/2022 16:40:08 - INFO - __main__ - Loaded 32 examples from dev data
04/25/2022 16:40:22 - INFO - __main__ - load prompt embedding from ckpt
04/25/2022 16:40:23 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/25/2022 16:40:23 - INFO - __main__ - Starting training!
04/25/2022 16:40:26 - INFO - __main__ - Step 10 Global step 10 Train loss 1.88 on epoch=4
04/25/2022 16:40:29 - INFO - __main__ - Step 20 Global step 20 Train loss 1.34 on epoch=9
04/25/2022 16:40:31 - INFO - __main__ - Step 30 Global step 30 Train loss 0.97 on epoch=14
04/25/2022 16:40:34 - INFO - __main__ - Step 40 Global step 40 Train loss 0.85 on epoch=19
04/25/2022 16:40:36 - INFO - __main__ - Step 50 Global step 50 Train loss 0.72 on epoch=24
04/25/2022 16:40:38 - INFO - __main__ - Global step 50 Train loss 1.15 ACC 0.21875 on epoch=24
04/25/2022 16:40:38 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.21875 on epoch=24, global_step=50
04/25/2022 16:40:41 - INFO - __main__ - Step 60 Global step 60 Train loss 0.64 on epoch=29
04/25/2022 16:40:43 - INFO - __main__ - Step 70 Global step 70 Train loss 0.59 on epoch=34
04/25/2022 16:40:45 - INFO - __main__ - Step 80 Global step 80 Train loss 0.52 on epoch=39
04/25/2022 16:40:48 - INFO - __main__ - Step 90 Global step 90 Train loss 0.47 on epoch=44
04/25/2022 16:40:50 - INFO - __main__ - Step 100 Global step 100 Train loss 0.40 on epoch=49
04/25/2022 16:40:52 - INFO - __main__ - Global step 100 Train loss 0.52 ACC 0.3125 on epoch=49
04/25/2022 16:40:52 - INFO - __main__ - Saving model with best ACC: 0.21875 -> 0.3125 on epoch=49, global_step=100
04/25/2022 16:40:55 - INFO - __main__ - Step 110 Global step 110 Train loss 0.36 on epoch=54
04/25/2022 16:40:57 - INFO - __main__ - Step 120 Global step 120 Train loss 0.32 on epoch=59
04/25/2022 16:41:00 - INFO - __main__ - Step 130 Global step 130 Train loss 0.25 on epoch=64
04/25/2022 16:41:02 - INFO - __main__ - Step 140 Global step 140 Train loss 0.36 on epoch=69
04/25/2022 16:41:05 - INFO - __main__ - Step 150 Global step 150 Train loss 0.23 on epoch=74
04/25/2022 16:41:06 - INFO - __main__ - Global step 150 Train loss 0.31 ACC 0.3125 on epoch=74
04/25/2022 16:41:09 - INFO - __main__ - Step 160 Global step 160 Train loss 0.31 on epoch=79
04/25/2022 16:41:11 - INFO - __main__ - Step 170 Global step 170 Train loss 0.23 on epoch=84
04/25/2022 16:41:14 - INFO - __main__ - Step 180 Global step 180 Train loss 0.26 on epoch=89
04/25/2022 16:41:16 - INFO - __main__ - Step 190 Global step 190 Train loss 0.21 on epoch=94
04/25/2022 16:41:19 - INFO - __main__ - Step 200 Global step 200 Train loss 0.18 on epoch=99
04/25/2022 16:41:20 - INFO - __main__ - Global step 200 Train loss 0.24 ACC 0.21875 on epoch=99
04/25/2022 16:41:23 - INFO - __main__ - Step 210 Global step 210 Train loss 0.21 on epoch=104
04/25/2022 16:41:25 - INFO - __main__ - Step 220 Global step 220 Train loss 0.21 on epoch=109
04/25/2022 16:41:28 - INFO - __main__ - Step 230 Global step 230 Train loss 0.18 on epoch=114
04/25/2022 16:41:30 - INFO - __main__ - Step 240 Global step 240 Train loss 0.10 on epoch=119
04/25/2022 16:41:33 - INFO - __main__ - Step 250 Global step 250 Train loss 0.13 on epoch=124
04/25/2022 16:41:34 - INFO - __main__ - Global step 250 Train loss 0.17 ACC 0.25 on epoch=124
04/25/2022 16:41:37 - INFO - __main__ - Step 260 Global step 260 Train loss 0.11 on epoch=129
04/25/2022 16:41:39 - INFO - __main__ - Step 270 Global step 270 Train loss 0.15 on epoch=134
04/25/2022 16:41:42 - INFO - __main__ - Step 280 Global step 280 Train loss 0.09 on epoch=139
04/25/2022 16:41:44 - INFO - __main__ - Step 290 Global step 290 Train loss 0.13 on epoch=144
04/25/2022 16:41:47 - INFO - __main__ - Step 300 Global step 300 Train loss 0.15 on epoch=149
04/25/2022 16:41:48 - INFO - __main__ - Global step 300 Train loss 0.12 ACC 0.1875 on epoch=149
04/25/2022 16:41:51 - INFO - __main__ - Step 310 Global step 310 Train loss 0.14 on epoch=154
04/25/2022 16:41:53 - INFO - __main__ - Step 320 Global step 320 Train loss 0.11 on epoch=159
04/25/2022 16:41:56 - INFO - __main__ - Step 330 Global step 330 Train loss 0.08 on epoch=164
04/25/2022 16:41:58 - INFO - __main__ - Step 340 Global step 340 Train loss 0.13 on epoch=169
04/25/2022 16:42:01 - INFO - __main__ - Step 350 Global step 350 Train loss 0.11 on epoch=174
04/25/2022 16:42:02 - INFO - __main__ - Global step 350 Train loss 0.11 ACC 0.3125 on epoch=174
04/25/2022 16:42:05 - INFO - __main__ - Step 360 Global step 360 Train loss 0.08 on epoch=179
04/25/2022 16:42:07 - INFO - __main__ - Step 370 Global step 370 Train loss 0.09 on epoch=184
04/25/2022 16:42:10 - INFO - __main__ - Step 380 Global step 380 Train loss 0.06 on epoch=189
04/25/2022 16:42:13 - INFO - __main__ - Step 390 Global step 390 Train loss 0.07 on epoch=194
04/25/2022 16:42:15 - INFO - __main__ - Step 400 Global step 400 Train loss 0.06 on epoch=199
04/25/2022 16:42:17 - INFO - __main__ - Global step 400 Train loss 0.07 ACC 0.28125 on epoch=199
04/25/2022 16:42:19 - INFO - __main__ - Step 410 Global step 410 Train loss 0.06 on epoch=204
04/25/2022 16:42:22 - INFO - __main__ - Step 420 Global step 420 Train loss 0.04 on epoch=209
04/25/2022 16:42:24 - INFO - __main__ - Step 430 Global step 430 Train loss 0.05 on epoch=214
04/25/2022 16:42:27 - INFO - __main__ - Step 440 Global step 440 Train loss 0.08 on epoch=219
04/25/2022 16:42:30 - INFO - __main__ - Step 450 Global step 450 Train loss 0.03 on epoch=224
04/25/2022 16:42:32 - INFO - __main__ - Global step 450 Train loss 0.05 ACC 0.1875 on epoch=224
04/25/2022 16:42:34 - INFO - __main__ - Step 460 Global step 460 Train loss 0.07 on epoch=229
04/25/2022 16:42:37 - INFO - __main__ - Step 470 Global step 470 Train loss 0.05 on epoch=234
04/25/2022 16:42:39 - INFO - __main__ - Step 480 Global step 480 Train loss 0.07 on epoch=239
04/25/2022 16:42:42 - INFO - __main__ - Step 490 Global step 490 Train loss 0.07 on epoch=244
04/25/2022 16:42:44 - INFO - __main__ - Step 500 Global step 500 Train loss 0.11 on epoch=249
04/25/2022 16:42:46 - INFO - __main__ - Global step 500 Train loss 0.07 ACC 0.21875 on epoch=249
04/25/2022 16:42:49 - INFO - __main__ - Step 510 Global step 510 Train loss 0.05 on epoch=254
04/25/2022 16:42:51 - INFO - __main__ - Step 520 Global step 520 Train loss 0.07 on epoch=259
04/25/2022 16:42:54 - INFO - __main__ - Step 530 Global step 530 Train loss 0.04 on epoch=264
04/25/2022 16:42:56 - INFO - __main__ - Step 540 Global step 540 Train loss 0.05 on epoch=269
04/25/2022 16:42:59 - INFO - __main__ - Step 550 Global step 550 Train loss 0.06 on epoch=274
04/25/2022 16:43:01 - INFO - __main__ - Global step 550 Train loss 0.06 ACC 0.09375 on epoch=274
04/25/2022 16:43:04 - INFO - __main__ - Step 560 Global step 560 Train loss 0.03 on epoch=279
04/25/2022 16:43:06 - INFO - __main__ - Step 570 Global step 570 Train loss 0.05 on epoch=284
04/25/2022 16:43:09 - INFO - __main__ - Step 580 Global step 580 Train loss 0.02 on epoch=289
04/25/2022 16:43:12 - INFO - __main__ - Step 590 Global step 590 Train loss 0.03 on epoch=294
04/25/2022 16:43:14 - INFO - __main__ - Step 600 Global step 600 Train loss 0.04 on epoch=299
04/25/2022 16:43:16 - INFO - __main__ - Global step 600 Train loss 0.04 ACC 0.21875 on epoch=299
04/25/2022 16:43:18 - INFO - __main__ - Step 610 Global step 610 Train loss 0.02 on epoch=304
04/25/2022 16:43:21 - INFO - __main__ - Step 620 Global step 620 Train loss 0.03 on epoch=309
04/25/2022 16:43:24 - INFO - __main__ - Step 630 Global step 630 Train loss 0.03 on epoch=314
04/25/2022 16:43:26 - INFO - __main__ - Step 640 Global step 640 Train loss 0.04 on epoch=319
04/25/2022 16:43:29 - INFO - __main__ - Step 650 Global step 650 Train loss 0.07 on epoch=324
04/25/2022 16:43:31 - INFO - __main__ - Global step 650 Train loss 0.04 ACC 0.3125 on epoch=324
04/25/2022 16:43:33 - INFO - __main__ - Step 660 Global step 660 Train loss 0.02 on epoch=329
04/25/2022 16:43:36 - INFO - __main__ - Step 670 Global step 670 Train loss 0.03 on epoch=334
04/25/2022 16:43:39 - INFO - __main__ - Step 680 Global step 680 Train loss 0.04 on epoch=339
04/25/2022 16:43:41 - INFO - __main__ - Step 690 Global step 690 Train loss 0.03 on epoch=344
04/25/2022 16:43:44 - INFO - __main__ - Step 700 Global step 700 Train loss 0.03 on epoch=349
04/25/2022 16:43:45 - INFO - __main__ - Global step 700 Train loss 0.03 ACC 0.28125 on epoch=349
04/25/2022 16:43:48 - INFO - __main__ - Step 710 Global step 710 Train loss 0.03 on epoch=354
04/25/2022 16:43:51 - INFO - __main__ - Step 720 Global step 720 Train loss 0.01 on epoch=359
04/25/2022 16:43:53 - INFO - __main__ - Step 730 Global step 730 Train loss 0.03 on epoch=364
04/25/2022 16:43:56 - INFO - __main__ - Step 740 Global step 740 Train loss 0.02 on epoch=369
04/25/2022 16:43:58 - INFO - __main__ - Step 750 Global step 750 Train loss 0.03 on epoch=374
04/25/2022 16:44:00 - INFO - __main__ - Global step 750 Train loss 0.02 ACC 0.34375 on epoch=374
04/25/2022 16:44:00 - INFO - __main__ - Saving model with best ACC: 0.3125 -> 0.34375 on epoch=374, global_step=750
04/25/2022 16:44:03 - INFO - __main__ - Step 760 Global step 760 Train loss 0.02 on epoch=379
04/25/2022 16:44:06 - INFO - __main__ - Step 770 Global step 770 Train loss 0.03 on epoch=384
04/25/2022 16:44:08 - INFO - __main__ - Step 780 Global step 780 Train loss 0.03 on epoch=389
04/25/2022 16:44:11 - INFO - __main__ - Step 790 Global step 790 Train loss 0.02 on epoch=394
04/25/2022 16:44:13 - INFO - __main__ - Step 800 Global step 800 Train loss 0.03 on epoch=399
04/25/2022 16:44:16 - INFO - __main__ - Global step 800 Train loss 0.02 ACC 0.21875 on epoch=399
04/25/2022 16:44:19 - INFO - __main__ - Step 810 Global step 810 Train loss 0.01 on epoch=404
04/25/2022 16:44:21 - INFO - __main__ - Step 820 Global step 820 Train loss 0.03 on epoch=409
04/25/2022 16:44:24 - INFO - __main__ - Step 830 Global step 830 Train loss 0.01 on epoch=414
04/25/2022 16:44:26 - INFO - __main__ - Step 840 Global step 840 Train loss 0.03 on epoch=419
04/25/2022 16:44:29 - INFO - __main__ - Step 850 Global step 850 Train loss 0.02 on epoch=424
04/25/2022 16:44:31 - INFO - __main__ - Global step 850 Train loss 0.02 ACC 0.15625 on epoch=424
04/25/2022 16:44:34 - INFO - __main__ - Step 860 Global step 860 Train loss 0.01 on epoch=429
04/25/2022 16:44:36 - INFO - __main__ - Step 870 Global step 870 Train loss 0.06 on epoch=434
04/25/2022 16:44:39 - INFO - __main__ - Step 880 Global step 880 Train loss 0.01 on epoch=439
04/25/2022 16:44:42 - INFO - __main__ - Step 890 Global step 890 Train loss 0.02 on epoch=444
04/25/2022 16:44:44 - INFO - __main__ - Step 900 Global step 900 Train loss 0.04 on epoch=449
04/25/2022 16:44:47 - INFO - __main__ - Global step 900 Train loss 0.03 ACC 0.15625 on epoch=449
04/25/2022 16:44:49 - INFO - __main__ - Step 910 Global step 910 Train loss 0.01 on epoch=454
04/25/2022 16:44:52 - INFO - __main__ - Step 920 Global step 920 Train loss 0.03 on epoch=459
04/25/2022 16:44:54 - INFO - __main__ - Step 930 Global step 930 Train loss 0.01 on epoch=464
04/25/2022 16:44:57 - INFO - __main__ - Step 940 Global step 940 Train loss 0.01 on epoch=469
04/25/2022 16:45:00 - INFO - __main__ - Step 950 Global step 950 Train loss 0.02 on epoch=474
04/25/2022 16:45:01 - INFO - __main__ - Global step 950 Train loss 0.02 ACC 0.1875 on epoch=474
04/25/2022 16:45:04 - INFO - __main__ - Step 960 Global step 960 Train loss 0.02 on epoch=479
04/25/2022 16:45:06 - INFO - __main__ - Step 970 Global step 970 Train loss 0.01 on epoch=484
04/25/2022 16:45:09 - INFO - __main__ - Step 980 Global step 980 Train loss 0.03 on epoch=489
04/25/2022 16:45:12 - INFO - __main__ - Step 990 Global step 990 Train loss 0.01 on epoch=494
04/25/2022 16:45:14 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.01 on epoch=499
04/25/2022 16:45:16 - INFO - __main__ - Global step 1000 Train loss 0.01 ACC 0.1875 on epoch=499
04/25/2022 16:45:18 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.02 on epoch=504
04/25/2022 16:45:21 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.01 on epoch=509
04/25/2022 16:45:24 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.02 on epoch=514
04/25/2022 16:45:26 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.01 on epoch=519
04/25/2022 16:45:29 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.02 on epoch=524
04/25/2022 16:45:30 - INFO - __main__ - Global step 1050 Train loss 0.02 ACC 0.25 on epoch=524
04/25/2022 16:45:33 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.01 on epoch=529
04/25/2022 16:45:36 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.01 on epoch=534
04/25/2022 16:45:38 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.01 on epoch=539
04/25/2022 16:45:41 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.01 on epoch=544
04/25/2022 16:45:43 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.03 on epoch=549
04/25/2022 16:45:45 - INFO - __main__ - Global step 1100 Train loss 0.01 ACC 0.21875 on epoch=549
04/25/2022 16:45:48 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.04 on epoch=554
04/25/2022 16:45:50 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=559
04/25/2022 16:45:53 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=564
04/25/2022 16:45:55 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.02 on epoch=569
04/25/2022 16:45:58 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=574
04/25/2022 16:46:00 - INFO - __main__ - Global step 1150 Train loss 0.02 ACC 0.25 on epoch=574
04/25/2022 16:46:02 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.01 on epoch=579
04/25/2022 16:46:05 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.01 on epoch=584
04/25/2022 16:46:08 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.05 on epoch=589
04/25/2022 16:46:10 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.02 on epoch=594
04/25/2022 16:46:13 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=599
04/25/2022 16:46:14 - INFO - __main__ - Global step 1200 Train loss 0.02 ACC 0.28125 on epoch=599
04/25/2022 16:46:17 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.01 on epoch=604
04/25/2022 16:46:19 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=609
04/25/2022 16:46:22 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=614
04/25/2022 16:46:25 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.03 on epoch=619
04/25/2022 16:46:27 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.01 on epoch=624
04/25/2022 16:46:29 - INFO - __main__ - Global step 1250 Train loss 0.01 ACC 0.1875 on epoch=624
04/25/2022 16:46:31 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=629
04/25/2022 16:46:34 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.04 on epoch=634
04/25/2022 16:46:37 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=639
04/25/2022 16:46:39 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.00 on epoch=644
04/25/2022 16:46:42 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.02 on epoch=649
04/25/2022 16:46:43 - INFO - __main__ - Global step 1300 Train loss 0.02 ACC 0.1875 on epoch=649
04/25/2022 16:46:46 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.02 on epoch=654
04/25/2022 16:46:48 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=659
04/25/2022 16:46:51 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.00 on epoch=664
04/25/2022 16:46:53 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.00 on epoch=669
04/25/2022 16:46:56 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.00 on epoch=674
04/25/2022 16:46:58 - INFO - __main__ - Global step 1350 Train loss 0.01 ACC 0.15625 on epoch=674
04/25/2022 16:47:00 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=679
04/25/2022 16:47:03 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.02 on epoch=684
04/25/2022 16:47:05 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.00 on epoch=689
04/25/2022 16:47:08 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=694
04/25/2022 16:47:11 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.03 on epoch=699
04/25/2022 16:47:13 - INFO - __main__ - Global step 1400 Train loss 0.01 ACC 0.28125 on epoch=699
04/25/2022 16:47:15 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=704
04/25/2022 16:47:18 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=709
04/25/2022 16:47:20 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=714
04/25/2022 16:47:23 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=719
04/25/2022 16:47:25 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=724
04/25/2022 16:47:27 - INFO - __main__ - Global step 1450 Train loss 0.01 ACC 0.28125 on epoch=724
04/25/2022 16:47:30 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=729
04/25/2022 16:47:32 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=734
04/25/2022 16:47:35 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=739
04/25/2022 16:47:37 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=744
04/25/2022 16:47:40 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.02 on epoch=749
04/25/2022 16:47:42 - INFO - __main__ - Global step 1500 Train loss 0.01 ACC 0.21875 on epoch=749
04/25/2022 16:47:44 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=754
04/25/2022 16:47:47 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.02 on epoch=759
04/25/2022 16:47:50 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=764
04/25/2022 16:47:52 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=769
04/25/2022 16:47:55 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=774
04/25/2022 16:47:56 - INFO - __main__ - Global step 1550 Train loss 0.01 ACC 0.28125 on epoch=774
04/25/2022 16:47:59 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.02 on epoch=779
04/25/2022 16:48:02 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=784
04/25/2022 16:48:04 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=789
04/25/2022 16:48:07 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=794
04/25/2022 16:48:09 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.03 on epoch=799
04/25/2022 16:48:12 - INFO - __main__ - Global step 1600 Train loss 0.01 ACC 0.28125 on epoch=799
04/25/2022 16:48:14 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=804
04/25/2022 16:48:17 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=809
04/25/2022 16:48:19 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=814
04/25/2022 16:48:22 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=819
04/25/2022 16:48:24 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.03 on epoch=824
04/25/2022 16:48:26 - INFO - __main__ - Global step 1650 Train loss 0.01 ACC 0.21875 on epoch=824
04/25/2022 16:48:29 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=829
04/25/2022 16:48:31 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.03 on epoch=834
04/25/2022 16:48:34 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=839
04/25/2022 16:48:37 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=844
04/25/2022 16:48:39 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=849
04/25/2022 16:48:41 - INFO - __main__ - Global step 1700 Train loss 0.02 ACC 0.3125 on epoch=849
04/25/2022 16:48:44 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=854
04/25/2022 16:48:46 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=859
04/25/2022 16:48:49 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=864
04/25/2022 16:48:51 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=869
04/25/2022 16:48:54 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=874
04/25/2022 16:48:56 - INFO - __main__ - Global step 1750 Train loss 0.01 ACC 0.34375 on epoch=874
04/25/2022 16:48:59 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=879
04/25/2022 16:49:01 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=884
04/25/2022 16:49:04 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=889
04/25/2022 16:49:06 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=894
04/25/2022 16:49:09 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=899
04/25/2022 16:49:11 - INFO - __main__ - Global step 1800 Train loss 0.01 ACC 0.34375 on epoch=899
04/25/2022 16:49:13 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=904
04/25/2022 16:49:16 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=909
04/25/2022 16:49:19 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=914
04/25/2022 16:49:21 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=919
04/25/2022 16:49:24 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=924
04/25/2022 16:49:26 - INFO - __main__ - Global step 1850 Train loss 0.01 ACC 0.34375 on epoch=924
04/25/2022 16:49:28 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=929
04/25/2022 16:49:31 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=934
04/25/2022 16:49:33 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=939
04/25/2022 16:49:36 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=944
04/25/2022 16:49:39 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=949
04/25/2022 16:49:41 - INFO - __main__ - Global step 1900 Train loss 0.00 ACC 0.34375 on epoch=949
04/25/2022 16:49:43 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=954
04/25/2022 16:49:46 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=959
04/25/2022 16:49:48 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=964
04/25/2022 16:49:51 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=969
04/25/2022 16:49:54 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=974
04/25/2022 16:49:56 - INFO - __main__ - Global step 1950 Train loss 0.01 ACC 0.34375 on epoch=974
04/25/2022 16:49:58 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=979
04/25/2022 16:50:01 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=984
04/25/2022 16:50:03 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=989
04/25/2022 16:50:06 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=994
04/25/2022 16:50:08 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=999
04/25/2022 16:50:10 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 16:50:10 - INFO - __main__ - Printing 3 examples
04/25/2022 16:50:10 - INFO - __main__ -  [openbookqa] Plant population would fail to maintain it's size if (A) fertilizer is applied (B) gets more sun (C) H2O depletes (D) grows
04/25/2022 16:50:10 - INFO - __main__ - ['H2O depletes']
04/25/2022 16:50:10 - INFO - __main__ -  [openbookqa] if members of a species are born then the species what increases? (A) water (B) community (C) understanding (D) food
04/25/2022 16:50:10 - INFO - __main__ - ['community']
04/25/2022 16:50:10 - INFO - __main__ -  [openbookqa] An example of adaption is (A) Eating tacos (B) wearing sunblock (C) Reading a book (D) Drinking water
04/25/2022 16:50:10 - INFO - __main__ - ['wearing sunblock']
04/25/2022 16:50:10 - INFO - __main__ - Tokenizing Input ...
04/25/2022 16:50:10 - INFO - __main__ - Tokenizing Output ...
04/25/2022 16:50:10 - INFO - __main__ - Loaded 32 examples from train data
04/25/2022 16:50:10 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 16:50:10 - INFO - __main__ - Printing 3 examples
04/25/2022 16:50:10 - INFO - __main__ -  [openbookqa] If you desired to keep your house cooler in the summer months (A) plant trees that tower above the ground (B) plant ivy around the trees (C) plant shrubs around the foundation (D) plant trees that stay smaller than dogwoods
04/25/2022 16:50:10 - INFO - __main__ - ['plant trees that tower above the ground']
04/25/2022 16:50:10 - INFO - __main__ -  [openbookqa] A person knows that a place always has blue skies, warm weather and a light breeze because (A) that is the beach (B) that is the meaning (C) that is the religion (D) climate is fairly reliable
04/25/2022 16:50:10 - INFO - __main__ - ['climate is fairly reliable']
04/25/2022 16:50:10 - INFO - __main__ -  [openbookqa] Microscopes (A) make tiny atoms look smaller (B) enhance the size of amoebas for easier viewing (C) make magnifying things much more difficult (D) make huge samples look minuscule
04/25/2022 16:50:10 - INFO - __main__ - ['enhance the size of amoebas for easier viewing']
04/25/2022 16:50:10 - INFO - __main__ - Tokenizing Input ...
04/25/2022 16:50:10 - INFO - __main__ - Tokenizing Output ...
04/25/2022 16:50:10 - INFO - __main__ - Loaded 32 examples from dev data
04/25/2022 16:50:10 - INFO - __main__ - Global step 2000 Train loss 0.01 ACC 0.28125 on epoch=999
04/25/2022 16:50:10 - INFO - __main__ - save last model!
04/25/2022 16:50:10 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
04/25/2022 16:50:10 - INFO - __main__ - Start tokenizing ... 500 instances
04/25/2022 16:50:10 - INFO - __main__ - Printing 3 examples
04/25/2022 16:50:10 - INFO - __main__ -  [openbookqa] Frilled sharks and angler fish live far beneath the surface of the ocean, which is why they are known as (A) Deep sea animals (B) fish (C) Long Sea Fish (D) Far Sea Animals
04/25/2022 16:50:10 - INFO - __main__ - ['Deep sea animals']
04/25/2022 16:50:10 - INFO - __main__ -  [openbookqa] Gas can fill any container it is given, and liquid (A) is standard weight and size (B) is the opposite of variable (C) only needs a few (D) uses what it needs
04/25/2022 16:50:10 - INFO - __main__ - ['uses what it needs']
04/25/2022 16:50:10 - INFO - __main__ -  [openbookqa] When birds migrate south for the winter, they do it because (A) they are genetically called to (B) their children ask for them to (C) it is important to their happiness (D) they decide to each year
04/25/2022 16:50:10 - INFO - __main__ - ['they are genetically called to']
04/25/2022 16:50:10 - INFO - __main__ - Tokenizing Input ...
04/25/2022 16:50:11 - INFO - __main__ - Tokenizing Output ...
04/25/2022 16:50:11 - INFO - __main__ - Loaded 500 examples from test data
04/25/2022 16:50:28 - INFO - __main__ - load prompt embedding from ckpt
04/25/2022 16:50:29 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/25/2022 16:50:29 - INFO - __main__ - Starting training!
04/25/2022 16:50:43 - INFO - __main__ - Saved prediction in models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-openbookqa/openbookqa_32_100_0.3_8_predictions.txt
04/25/2022 16:50:43 - INFO - __main__ - ACC on test data: 0.2620
04/25/2022 16:50:44 - INFO - __main__ - prefix=openbookqa_32_100, lr=0.3, bsz=8, dev_performance=0.34375, test_performance=0.262
04/25/2022 16:50:44 - INFO - __main__ - Running ... prefix=openbookqa_32_100, lr=0.2, bsz=8 ...
04/25/2022 16:50:45 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 16:50:45 - INFO - __main__ - Printing 3 examples
04/25/2022 16:50:45 - INFO - __main__ -  [openbookqa] Plant population would fail to maintain it's size if (A) fertilizer is applied (B) gets more sun (C) H2O depletes (D) grows
04/25/2022 16:50:45 - INFO - __main__ - ['H2O depletes']
04/25/2022 16:50:45 - INFO - __main__ -  [openbookqa] if members of a species are born then the species what increases? (A) water (B) community (C) understanding (D) food
04/25/2022 16:50:45 - INFO - __main__ - ['community']
04/25/2022 16:50:45 - INFO - __main__ -  [openbookqa] An example of adaption is (A) Eating tacos (B) wearing sunblock (C) Reading a book (D) Drinking water
04/25/2022 16:50:45 - INFO - __main__ - ['wearing sunblock']
04/25/2022 16:50:45 - INFO - __main__ - Tokenizing Input ...
04/25/2022 16:50:45 - INFO - __main__ - Tokenizing Output ...
04/25/2022 16:50:45 - INFO - __main__ - Loaded 32 examples from train data
04/25/2022 16:50:45 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 16:50:45 - INFO - __main__ - Printing 3 examples
04/25/2022 16:50:45 - INFO - __main__ -  [openbookqa] If you desired to keep your house cooler in the summer months (A) plant trees that tower above the ground (B) plant ivy around the trees (C) plant shrubs around the foundation (D) plant trees that stay smaller than dogwoods
04/25/2022 16:50:45 - INFO - __main__ - ['plant trees that tower above the ground']
04/25/2022 16:50:45 - INFO - __main__ -  [openbookqa] A person knows that a place always has blue skies, warm weather and a light breeze because (A) that is the beach (B) that is the meaning (C) that is the religion (D) climate is fairly reliable
04/25/2022 16:50:45 - INFO - __main__ - ['climate is fairly reliable']
04/25/2022 16:50:45 - INFO - __main__ -  [openbookqa] Microscopes (A) make tiny atoms look smaller (B) enhance the size of amoebas for easier viewing (C) make magnifying things much more difficult (D) make huge samples look minuscule
04/25/2022 16:50:45 - INFO - __main__ - ['enhance the size of amoebas for easier viewing']
04/25/2022 16:50:45 - INFO - __main__ - Tokenizing Input ...
04/25/2022 16:50:45 - INFO - __main__ - Tokenizing Output ...
04/25/2022 16:50:45 - INFO - __main__ - Loaded 32 examples from dev data
04/25/2022 16:50:59 - INFO - __main__ - load prompt embedding from ckpt
04/25/2022 16:51:00 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/25/2022 16:51:00 - INFO - __main__ - Starting training!
04/25/2022 16:51:03 - INFO - __main__ - Step 10 Global step 10 Train loss 1.97 on epoch=4
04/25/2022 16:51:06 - INFO - __main__ - Step 20 Global step 20 Train loss 1.53 on epoch=9
04/25/2022 16:51:08 - INFO - __main__ - Step 30 Global step 30 Train loss 1.18 on epoch=14
04/25/2022 16:51:11 - INFO - __main__ - Step 40 Global step 40 Train loss 1.04 on epoch=19
04/25/2022 16:51:13 - INFO - __main__ - Step 50 Global step 50 Train loss 0.84 on epoch=24
04/25/2022 16:51:15 - INFO - __main__ - Global step 50 Train loss 1.31 ACC 0.21875 on epoch=24
04/25/2022 16:51:15 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.21875 on epoch=24, global_step=50
04/25/2022 16:51:17 - INFO - __main__ - Step 60 Global step 60 Train loss 0.73 on epoch=29
04/25/2022 16:51:20 - INFO - __main__ - Step 70 Global step 70 Train loss 0.65 on epoch=34
04/25/2022 16:51:22 - INFO - __main__ - Step 80 Global step 80 Train loss 0.68 on epoch=39
04/25/2022 16:51:25 - INFO - __main__ - Step 90 Global step 90 Train loss 0.61 on epoch=44
04/25/2022 16:51:27 - INFO - __main__ - Step 100 Global step 100 Train loss 0.59 on epoch=49
04/25/2022 16:51:29 - INFO - __main__ - Global step 100 Train loss 0.65 ACC 0.3125 on epoch=49
04/25/2022 16:51:29 - INFO - __main__ - Saving model with best ACC: 0.21875 -> 0.3125 on epoch=49, global_step=100
04/25/2022 16:51:31 - INFO - __main__ - Step 110 Global step 110 Train loss 0.49 on epoch=54
04/25/2022 16:51:34 - INFO - __main__ - Step 120 Global step 120 Train loss 0.42 on epoch=59
04/25/2022 16:51:36 - INFO - __main__ - Step 130 Global step 130 Train loss 0.44 on epoch=64
04/25/2022 16:51:39 - INFO - __main__ - Step 140 Global step 140 Train loss 0.43 on epoch=69
04/25/2022 16:51:41 - INFO - __main__ - Step 150 Global step 150 Train loss 0.43 on epoch=74
04/25/2022 16:51:43 - INFO - __main__ - Global step 150 Train loss 0.44 ACC 0.28125 on epoch=74
04/25/2022 16:51:46 - INFO - __main__ - Step 160 Global step 160 Train loss 0.35 on epoch=79
04/25/2022 16:51:48 - INFO - __main__ - Step 170 Global step 170 Train loss 0.39 on epoch=84
04/25/2022 16:51:50 - INFO - __main__ - Step 180 Global step 180 Train loss 0.33 on epoch=89
04/25/2022 16:51:53 - INFO - __main__ - Step 190 Global step 190 Train loss 0.26 on epoch=94
04/25/2022 16:51:55 - INFO - __main__ - Step 200 Global step 200 Train loss 0.31 on epoch=99
04/25/2022 16:51:57 - INFO - __main__ - Global step 200 Train loss 0.33 ACC 0.25 on epoch=99
04/25/2022 16:52:00 - INFO - __main__ - Step 210 Global step 210 Train loss 0.26 on epoch=104
04/25/2022 16:52:02 - INFO - __main__ - Step 220 Global step 220 Train loss 0.25 on epoch=109
04/25/2022 16:52:04 - INFO - __main__ - Step 230 Global step 230 Train loss 0.20 on epoch=114
04/25/2022 16:52:07 - INFO - __main__ - Step 240 Global step 240 Train loss 0.21 on epoch=119
04/25/2022 16:52:09 - INFO - __main__ - Step 250 Global step 250 Train loss 0.26 on epoch=124
04/25/2022 16:52:11 - INFO - __main__ - Global step 250 Train loss 0.24 ACC 0.3125 on epoch=124
04/25/2022 16:52:13 - INFO - __main__ - Step 260 Global step 260 Train loss 0.17 on epoch=129
04/25/2022 16:52:16 - INFO - __main__ - Step 270 Global step 270 Train loss 0.19 on epoch=134
04/25/2022 16:52:18 - INFO - __main__ - Step 280 Global step 280 Train loss 0.18 on epoch=139
04/25/2022 16:52:20 - INFO - __main__ - Step 290 Global step 290 Train loss 0.13 on epoch=144
04/25/2022 16:52:23 - INFO - __main__ - Step 300 Global step 300 Train loss 0.18 on epoch=149
04/25/2022 16:52:25 - INFO - __main__ - Global step 300 Train loss 0.17 ACC 0.25 on epoch=149
04/25/2022 16:52:27 - INFO - __main__ - Step 310 Global step 310 Train loss 0.16 on epoch=154
04/25/2022 16:52:30 - INFO - __main__ - Step 320 Global step 320 Train loss 0.14 on epoch=159
04/25/2022 16:52:32 - INFO - __main__ - Step 330 Global step 330 Train loss 0.12 on epoch=164
04/25/2022 16:52:34 - INFO - __main__ - Step 340 Global step 340 Train loss 0.10 on epoch=169
04/25/2022 16:52:37 - INFO - __main__ - Step 350 Global step 350 Train loss 0.12 on epoch=174
04/25/2022 16:52:39 - INFO - __main__ - Global step 350 Train loss 0.13 ACC 0.3125 on epoch=174
04/25/2022 16:52:41 - INFO - __main__ - Step 360 Global step 360 Train loss 0.12 on epoch=179
04/25/2022 16:52:43 - INFO - __main__ - Step 370 Global step 370 Train loss 0.12 on epoch=184
04/25/2022 16:52:46 - INFO - __main__ - Step 380 Global step 380 Train loss 0.09 on epoch=189
04/25/2022 16:52:48 - INFO - __main__ - Step 390 Global step 390 Train loss 0.08 on epoch=194
04/25/2022 16:52:51 - INFO - __main__ - Step 400 Global step 400 Train loss 0.11 on epoch=199
04/25/2022 16:52:52 - INFO - __main__ - Global step 400 Train loss 0.10 ACC 0.34375 on epoch=199
04/25/2022 16:52:52 - INFO - __main__ - Saving model with best ACC: 0.3125 -> 0.34375 on epoch=199, global_step=400
04/25/2022 16:52:55 - INFO - __main__ - Step 410 Global step 410 Train loss 0.11 on epoch=204
04/25/2022 16:52:57 - INFO - __main__ - Step 420 Global step 420 Train loss 0.13 on epoch=209
04/25/2022 16:53:00 - INFO - __main__ - Step 430 Global step 430 Train loss 0.08 on epoch=214
04/25/2022 16:53:02 - INFO - __main__ - Step 440 Global step 440 Train loss 0.09 on epoch=219
04/25/2022 16:53:05 - INFO - __main__ - Step 450 Global step 450 Train loss 0.08 on epoch=224
04/25/2022 16:53:06 - INFO - __main__ - Global step 450 Train loss 0.10 ACC 0.25 on epoch=224
04/25/2022 16:53:09 - INFO - __main__ - Step 460 Global step 460 Train loss 0.06 on epoch=229
04/25/2022 16:53:11 - INFO - __main__ - Step 470 Global step 470 Train loss 0.06 on epoch=234
04/25/2022 16:53:14 - INFO - __main__ - Step 480 Global step 480 Train loss 0.08 on epoch=239
04/25/2022 16:53:16 - INFO - __main__ - Step 490 Global step 490 Train loss 0.11 on epoch=244
04/25/2022 16:53:19 - INFO - __main__ - Step 500 Global step 500 Train loss 0.06 on epoch=249
04/25/2022 16:53:20 - INFO - __main__ - Global step 500 Train loss 0.07 ACC 0.21875 on epoch=249
04/25/2022 16:53:23 - INFO - __main__ - Step 510 Global step 510 Train loss 0.07 on epoch=254
04/25/2022 16:53:25 - INFO - __main__ - Step 520 Global step 520 Train loss 0.07 on epoch=259
04/25/2022 16:53:28 - INFO - __main__ - Step 530 Global step 530 Train loss 0.12 on epoch=264
04/25/2022 16:53:30 - INFO - __main__ - Step 540 Global step 540 Train loss 0.06 on epoch=269
04/25/2022 16:53:33 - INFO - __main__ - Step 550 Global step 550 Train loss 0.09 on epoch=274
04/25/2022 16:53:34 - INFO - __main__ - Global step 550 Train loss 0.08 ACC 0.25 on epoch=274
04/25/2022 16:53:37 - INFO - __main__ - Step 560 Global step 560 Train loss 0.05 on epoch=279
04/25/2022 16:53:39 - INFO - __main__ - Step 570 Global step 570 Train loss 0.07 on epoch=284
04/25/2022 16:53:42 - INFO - __main__ - Step 580 Global step 580 Train loss 0.06 on epoch=289
04/25/2022 16:53:44 - INFO - __main__ - Step 590 Global step 590 Train loss 0.06 on epoch=294
04/25/2022 16:53:47 - INFO - __main__ - Step 600 Global step 600 Train loss 0.05 on epoch=299
04/25/2022 16:53:48 - INFO - __main__ - Global step 600 Train loss 0.06 ACC 0.28125 on epoch=299
04/25/2022 16:53:51 - INFO - __main__ - Step 610 Global step 610 Train loss 0.05 on epoch=304
04/25/2022 16:53:53 - INFO - __main__ - Step 620 Global step 620 Train loss 0.06 on epoch=309
04/25/2022 16:53:56 - INFO - __main__ - Step 630 Global step 630 Train loss 0.06 on epoch=314
04/25/2022 16:53:58 - INFO - __main__ - Step 640 Global step 640 Train loss 0.06 on epoch=319
04/25/2022 16:54:00 - INFO - __main__ - Step 650 Global step 650 Train loss 0.03 on epoch=324
04/25/2022 16:54:02 - INFO - __main__ - Global step 650 Train loss 0.05 ACC 0.3125 on epoch=324
04/25/2022 16:54:05 - INFO - __main__ - Step 660 Global step 660 Train loss 0.07 on epoch=329
04/25/2022 16:54:07 - INFO - __main__ - Step 670 Global step 670 Train loss 0.05 on epoch=334
04/25/2022 16:54:09 - INFO - __main__ - Step 680 Global step 680 Train loss 0.05 on epoch=339
04/25/2022 16:54:12 - INFO - __main__ - Step 690 Global step 690 Train loss 0.05 on epoch=344
04/25/2022 16:54:14 - INFO - __main__ - Step 700 Global step 700 Train loss 0.04 on epoch=349
04/25/2022 16:54:16 - INFO - __main__ - Global step 700 Train loss 0.05 ACC 0.3125 on epoch=349
04/25/2022 16:54:18 - INFO - __main__ - Step 710 Global step 710 Train loss 0.05 on epoch=354
04/25/2022 16:54:21 - INFO - __main__ - Step 720 Global step 720 Train loss 0.04 on epoch=359
04/25/2022 16:54:23 - INFO - __main__ - Step 730 Global step 730 Train loss 0.04 on epoch=364
04/25/2022 16:54:26 - INFO - __main__ - Step 740 Global step 740 Train loss 0.05 on epoch=369
04/25/2022 16:54:28 - INFO - __main__ - Step 750 Global step 750 Train loss 0.04 on epoch=374
04/25/2022 16:54:30 - INFO - __main__ - Global step 750 Train loss 0.05 ACC 0.3125 on epoch=374
04/25/2022 16:54:32 - INFO - __main__ - Step 760 Global step 760 Train loss 0.05 on epoch=379
04/25/2022 16:54:35 - INFO - __main__ - Step 770 Global step 770 Train loss 0.05 on epoch=384
04/25/2022 16:54:37 - INFO - __main__ - Step 780 Global step 780 Train loss 0.04 on epoch=389
04/25/2022 16:54:40 - INFO - __main__ - Step 790 Global step 790 Train loss 0.03 on epoch=394
04/25/2022 16:54:42 - INFO - __main__ - Step 800 Global step 800 Train loss 0.04 on epoch=399
04/25/2022 16:54:44 - INFO - __main__ - Global step 800 Train loss 0.04 ACC 0.25 on epoch=399
04/25/2022 16:54:46 - INFO - __main__ - Step 810 Global step 810 Train loss 0.03 on epoch=404
04/25/2022 16:54:49 - INFO - __main__ - Step 820 Global step 820 Train loss 0.03 on epoch=409
04/25/2022 16:54:51 - INFO - __main__ - Step 830 Global step 830 Train loss 0.03 on epoch=414
04/25/2022 16:54:54 - INFO - __main__ - Step 840 Global step 840 Train loss 0.04 on epoch=419
04/25/2022 16:54:56 - INFO - __main__ - Step 850 Global step 850 Train loss 0.04 on epoch=424
04/25/2022 16:54:58 - INFO - __main__ - Global step 850 Train loss 0.03 ACC 0.21875 on epoch=424
04/25/2022 16:55:00 - INFO - __main__ - Step 860 Global step 860 Train loss 0.04 on epoch=429
04/25/2022 16:55:03 - INFO - __main__ - Step 870 Global step 870 Train loss 0.05 on epoch=434
04/25/2022 16:55:05 - INFO - __main__ - Step 880 Global step 880 Train loss 0.03 on epoch=439
04/25/2022 16:55:07 - INFO - __main__ - Step 890 Global step 890 Train loss 0.03 on epoch=444
04/25/2022 16:55:10 - INFO - __main__ - Step 900 Global step 900 Train loss 0.04 on epoch=449
04/25/2022 16:55:12 - INFO - __main__ - Global step 900 Train loss 0.04 ACC 0.21875 on epoch=449
04/25/2022 16:55:14 - INFO - __main__ - Step 910 Global step 910 Train loss 0.05 on epoch=454
04/25/2022 16:55:16 - INFO - __main__ - Step 920 Global step 920 Train loss 0.03 on epoch=459
04/25/2022 16:55:19 - INFO - __main__ - Step 930 Global step 930 Train loss 0.02 on epoch=464
04/25/2022 16:55:21 - INFO - __main__ - Step 940 Global step 940 Train loss 0.03 on epoch=469
04/25/2022 16:55:24 - INFO - __main__ - Step 950 Global step 950 Train loss 0.03 on epoch=474
04/25/2022 16:55:25 - INFO - __main__ - Global step 950 Train loss 0.03 ACC 0.28125 on epoch=474
04/25/2022 16:55:28 - INFO - __main__ - Step 960 Global step 960 Train loss 0.03 on epoch=479
04/25/2022 16:55:30 - INFO - __main__ - Step 970 Global step 970 Train loss 0.04 on epoch=484
04/25/2022 16:55:33 - INFO - __main__ - Step 980 Global step 980 Train loss 0.03 on epoch=489
04/25/2022 16:55:35 - INFO - __main__ - Step 990 Global step 990 Train loss 0.02 on epoch=494
04/25/2022 16:55:38 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.02 on epoch=499
04/25/2022 16:55:39 - INFO - __main__ - Global step 1000 Train loss 0.03 ACC 0.25 on epoch=499
04/25/2022 16:55:42 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.02 on epoch=504
04/25/2022 16:55:44 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.02 on epoch=509
04/25/2022 16:55:47 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.02 on epoch=514
04/25/2022 16:55:49 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.03 on epoch=519
04/25/2022 16:55:52 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.03 on epoch=524
04/25/2022 16:55:53 - INFO - __main__ - Global step 1050 Train loss 0.02 ACC 0.21875 on epoch=524
04/25/2022 16:55:56 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.01 on epoch=529
04/25/2022 16:55:58 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.03 on epoch=534
04/25/2022 16:56:01 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.01 on epoch=539
04/25/2022 16:56:03 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.02 on epoch=544
04/25/2022 16:56:06 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.02 on epoch=549
04/25/2022 16:56:07 - INFO - __main__ - Global step 1100 Train loss 0.02 ACC 0.15625 on epoch=549
04/25/2022 16:56:10 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.02 on epoch=554
04/25/2022 16:56:12 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.03 on epoch=559
04/25/2022 16:56:15 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.05 on epoch=564
04/25/2022 16:56:17 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.03 on epoch=569
04/25/2022 16:56:19 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=574
04/25/2022 16:56:21 - INFO - __main__ - Global step 1150 Train loss 0.03 ACC 0.15625 on epoch=574
04/25/2022 16:56:24 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.02 on epoch=579
04/25/2022 16:56:26 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.02 on epoch=584
04/25/2022 16:56:29 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.02 on epoch=589
04/25/2022 16:56:31 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.02 on epoch=594
04/25/2022 16:56:34 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.04 on epoch=599
04/25/2022 16:56:35 - INFO - __main__ - Global step 1200 Train loss 0.02 ACC 0.21875 on epoch=599
04/25/2022 16:56:38 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.02 on epoch=604
04/25/2022 16:56:40 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.03 on epoch=609
04/25/2022 16:56:43 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=614
04/25/2022 16:56:45 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=619
04/25/2022 16:56:48 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.02 on epoch=624
04/25/2022 16:56:49 - INFO - __main__ - Global step 1250 Train loss 0.02 ACC 0.25 on epoch=624
04/25/2022 16:56:52 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=629
04/25/2022 16:56:54 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.01 on epoch=634
04/25/2022 16:56:57 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.02 on epoch=639
04/25/2022 16:56:59 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.06 on epoch=644
04/25/2022 16:57:02 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.02 on epoch=649
04/25/2022 16:57:04 - INFO - __main__ - Global step 1300 Train loss 0.03 ACC 0.15625 on epoch=649
04/25/2022 16:57:06 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=654
04/25/2022 16:57:08 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.02 on epoch=659
04/25/2022 16:57:11 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.03 on epoch=664
04/25/2022 16:57:13 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.03 on epoch=669
04/25/2022 16:57:16 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=674
04/25/2022 16:57:17 - INFO - __main__ - Global step 1350 Train loss 0.02 ACC 0.28125 on epoch=674
04/25/2022 16:57:20 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=679
04/25/2022 16:57:22 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=684
04/25/2022 16:57:25 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=689
04/25/2022 16:57:27 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.02 on epoch=694
04/25/2022 16:57:30 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=699
04/25/2022 16:57:31 - INFO - __main__ - Global step 1400 Train loss 0.01 ACC 0.21875 on epoch=699
04/25/2022 16:57:34 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.02 on epoch=704
04/25/2022 16:57:36 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.01 on epoch=709
04/25/2022 16:57:39 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=714
04/25/2022 16:57:41 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=719
04/25/2022 16:57:43 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=724
04/25/2022 16:57:45 - INFO - __main__ - Global step 1450 Train loss 0.01 ACC 0.21875 on epoch=724
04/25/2022 16:57:48 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=729
04/25/2022 16:57:50 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=734
04/25/2022 16:57:52 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=739
04/25/2022 16:57:55 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.03 on epoch=744
04/25/2022 16:57:57 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=749
04/25/2022 16:57:59 - INFO - __main__ - Global step 1500 Train loss 0.01 ACC 0.28125 on epoch=749
04/25/2022 16:58:01 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=754
04/25/2022 16:58:04 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=759
04/25/2022 16:58:06 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=764
04/25/2022 16:58:09 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=769
04/25/2022 16:58:11 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.03 on epoch=774
04/25/2022 16:58:13 - INFO - __main__ - Global step 1550 Train loss 0.02 ACC 0.1875 on epoch=774
04/25/2022 16:58:15 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.03 on epoch=779
04/25/2022 16:58:18 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=784
04/25/2022 16:58:20 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=789
04/25/2022 16:58:23 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=794
04/25/2022 16:58:25 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=799
04/25/2022 16:58:27 - INFO - __main__ - Global step 1600 Train loss 0.01 ACC 0.25 on epoch=799
04/25/2022 16:58:29 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=804
04/25/2022 16:58:32 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=809
04/25/2022 16:58:34 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=814
04/25/2022 16:58:37 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=819
04/25/2022 16:58:39 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=824
04/25/2022 16:58:41 - INFO - __main__ - Global step 1650 Train loss 0.01 ACC 0.25 on epoch=824
04/25/2022 16:58:43 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=829
04/25/2022 16:58:46 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=834
04/25/2022 16:58:48 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=839
04/25/2022 16:58:51 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=844
04/25/2022 16:58:53 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=849
04/25/2022 16:58:55 - INFO - __main__ - Global step 1700 Train loss 0.01 ACC 0.25 on epoch=849
04/25/2022 16:58:57 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=854
04/25/2022 16:59:00 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=859
04/25/2022 16:59:02 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=864
04/25/2022 16:59:05 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=869
04/25/2022 16:59:07 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=874
04/25/2022 16:59:09 - INFO - __main__ - Global step 1750 Train loss 0.01 ACC 0.21875 on epoch=874
04/25/2022 16:59:12 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=879
04/25/2022 16:59:14 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=884
04/25/2022 16:59:16 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=889
04/25/2022 16:59:19 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.03 on epoch=894
04/25/2022 16:59:21 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.03 on epoch=899
04/25/2022 16:59:23 - INFO - __main__ - Global step 1800 Train loss 0.02 ACC 0.25 on epoch=899
04/25/2022 16:59:26 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.03 on epoch=904
04/25/2022 16:59:28 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=909
04/25/2022 16:59:30 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=914
04/25/2022 16:59:33 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=919
04/25/2022 16:59:35 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=924
04/25/2022 16:59:37 - INFO - __main__ - Global step 1850 Train loss 0.02 ACC 0.21875 on epoch=924
04/25/2022 16:59:40 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=929
04/25/2022 16:59:42 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=934
04/25/2022 16:59:45 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=939
04/25/2022 16:59:47 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=944
04/25/2022 16:59:50 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=949
04/25/2022 16:59:52 - INFO - __main__ - Global step 1900 Train loss 0.01 ACC 0.25 on epoch=949
04/25/2022 16:59:54 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=954
04/25/2022 16:59:56 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=959
04/25/2022 16:59:59 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=964
04/25/2022 17:00:01 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=969
04/25/2022 17:00:04 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=974
04/25/2022 17:00:06 - INFO - __main__ - Global step 1950 Train loss 0.01 ACC 0.21875 on epoch=974
04/25/2022 17:00:08 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=979
04/25/2022 17:00:11 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=984
04/25/2022 17:00:13 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=989
04/25/2022 17:00:16 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=994
04/25/2022 17:00:18 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=999
04/25/2022 17:00:20 - INFO - __main__ - Global step 2000 Train loss 0.01 ACC 0.28125 on epoch=999
04/25/2022 17:00:20 - INFO - __main__ - save last model!
04/25/2022 17:00:20 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
04/25/2022 17:00:20 - INFO - __main__ - Start tokenizing ... 500 instances
04/25/2022 17:00:20 - INFO - __main__ - Printing 3 examples
04/25/2022 17:00:20 - INFO - __main__ -  [openbookqa] Frilled sharks and angler fish live far beneath the surface of the ocean, which is why they are known as (A) Deep sea animals (B) fish (C) Long Sea Fish (D) Far Sea Animals
04/25/2022 17:00:20 - INFO - __main__ - ['Deep sea animals']
04/25/2022 17:00:20 - INFO - __main__ -  [openbookqa] Gas can fill any container it is given, and liquid (A) is standard weight and size (B) is the opposite of variable (C) only needs a few (D) uses what it needs
04/25/2022 17:00:20 - INFO - __main__ - ['uses what it needs']
04/25/2022 17:00:20 - INFO - __main__ -  [openbookqa] When birds migrate south for the winter, they do it because (A) they are genetically called to (B) their children ask for them to (C) it is important to their happiness (D) they decide to each year
04/25/2022 17:00:20 - INFO - __main__ - ['they are genetically called to']
04/25/2022 17:00:20 - INFO - __main__ - Tokenizing Input ...
04/25/2022 17:00:20 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 17:00:20 - INFO - __main__ - Printing 3 examples
04/25/2022 17:00:20 - INFO - __main__ -  [openbookqa] we only have diamonds because of the existence of (A) machines (B) large pressure (C) work force (D) carbonite
04/25/2022 17:00:20 - INFO - __main__ - ['large pressure']
04/25/2022 17:00:20 - INFO - __main__ -  [openbookqa] A thing which may be found at a special location for reusing materials is a (A) fresh cat litter (B) new brick house (C) rusted aluminum tray (D) old used wax
04/25/2022 17:00:20 - INFO - __main__ - ['rusted aluminum tray']
04/25/2022 17:00:20 - INFO - __main__ -  [openbookqa] If a raptor loses weight, then it will have an easier time (A) eating a goldfish cracker (B) building a small house (C) circling way up there (D) leaving home at night
04/25/2022 17:00:20 - INFO - __main__ - ['circling way up there']
04/25/2022 17:00:20 - INFO - __main__ - Tokenizing Input ...
04/25/2022 17:00:20 - INFO - __main__ - Tokenizing Output ...
04/25/2022 17:00:20 - INFO - __main__ - Tokenizing Output ...
04/25/2022 17:00:20 - INFO - __main__ - Loaded 32 examples from train data
04/25/2022 17:00:20 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 17:00:20 - INFO - __main__ - Printing 3 examples
04/25/2022 17:00:20 - INFO - __main__ -  [openbookqa] A tuna would prefer to consume (A) An Apple (B) beef (C) Nemo (D) dogs
04/25/2022 17:00:20 - INFO - __main__ - ['Nemo']
04/25/2022 17:00:20 - INFO - __main__ -  [openbookqa] Overeating (A) causes massive weight loss (B) causes the number on the scale to go up (C) boosts the immune system (D) causes the number on the scale to go down
04/25/2022 17:00:20 - INFO - __main__ - ['causes the number on the scale to go up']
04/25/2022 17:00:20 - INFO - __main__ -  [openbookqa] The more active an animal is (A) their water level will stay steady (B) the less H2O they need to stay hydrated (C) the more H20 they should take in (D) the less likely they are to sweat or pant
04/25/2022 17:00:20 - INFO - __main__ - ['the more H20 they should take in']
04/25/2022 17:00:20 - INFO - __main__ - Tokenizing Input ...
04/25/2022 17:00:20 - INFO - __main__ - Tokenizing Output ...
04/25/2022 17:00:20 - INFO - __main__ - Loaded 32 examples from dev data
04/25/2022 17:00:21 - INFO - __main__ - Loaded 500 examples from test data
04/25/2022 17:00:39 - INFO - __main__ - load prompt embedding from ckpt
04/25/2022 17:00:39 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/25/2022 17:00:39 - INFO - __main__ - Starting training!
04/25/2022 17:00:55 - INFO - __main__ - Saved prediction in models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-openbookqa/openbookqa_32_100_0.2_8_predictions.txt
04/25/2022 17:00:55 - INFO - __main__ - ACC on test data: 0.2720
04/25/2022 17:00:56 - INFO - __main__ - prefix=openbookqa_32_100, lr=0.2, bsz=8, dev_performance=0.34375, test_performance=0.272
04/25/2022 17:00:56 - INFO - __main__ - Running ... prefix=openbookqa_32_13, lr=0.5, bsz=8 ...
04/25/2022 17:00:57 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 17:00:57 - INFO - __main__ - Printing 3 examples
04/25/2022 17:00:57 - INFO - __main__ -  [openbookqa] we only have diamonds because of the existence of (A) machines (B) large pressure (C) work force (D) carbonite
04/25/2022 17:00:57 - INFO - __main__ - ['large pressure']
04/25/2022 17:00:57 - INFO - __main__ -  [openbookqa] A thing which may be found at a special location for reusing materials is a (A) fresh cat litter (B) new brick house (C) rusted aluminum tray (D) old used wax
04/25/2022 17:00:57 - INFO - __main__ - ['rusted aluminum tray']
04/25/2022 17:00:57 - INFO - __main__ -  [openbookqa] If a raptor loses weight, then it will have an easier time (A) eating a goldfish cracker (B) building a small house (C) circling way up there (D) leaving home at night
04/25/2022 17:00:57 - INFO - __main__ - ['circling way up there']
04/25/2022 17:00:57 - INFO - __main__ - Tokenizing Input ...
04/25/2022 17:00:57 - INFO - __main__ - Tokenizing Output ...
04/25/2022 17:00:57 - INFO - __main__ - Loaded 32 examples from train data
04/25/2022 17:00:57 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 17:00:57 - INFO - __main__ - Printing 3 examples
04/25/2022 17:00:57 - INFO - __main__ -  [openbookqa] A tuna would prefer to consume (A) An Apple (B) beef (C) Nemo (D) dogs
04/25/2022 17:00:57 - INFO - __main__ - ['Nemo']
04/25/2022 17:00:57 - INFO - __main__ -  [openbookqa] Overeating (A) causes massive weight loss (B) causes the number on the scale to go up (C) boosts the immune system (D) causes the number on the scale to go down
04/25/2022 17:00:57 - INFO - __main__ - ['causes the number on the scale to go up']
04/25/2022 17:00:57 - INFO - __main__ -  [openbookqa] The more active an animal is (A) their water level will stay steady (B) the less H2O they need to stay hydrated (C) the more H20 they should take in (D) the less likely they are to sweat or pant
04/25/2022 17:00:57 - INFO - __main__ - ['the more H20 they should take in']
04/25/2022 17:00:57 - INFO - __main__ - Tokenizing Input ...
04/25/2022 17:00:57 - INFO - __main__ - Tokenizing Output ...
04/25/2022 17:00:57 - INFO - __main__ - Loaded 32 examples from dev data
04/25/2022 17:01:15 - INFO - __main__ - load prompt embedding from ckpt
04/25/2022 17:01:16 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/25/2022 17:01:16 - INFO - __main__ - Starting training!
04/25/2022 17:01:21 - INFO - __main__ - Step 10 Global step 10 Train loss 2.35 on epoch=4
04/25/2022 17:01:24 - INFO - __main__ - Step 20 Global step 20 Train loss 1.73 on epoch=9
04/25/2022 17:01:26 - INFO - __main__ - Step 30 Global step 30 Train loss 1.07 on epoch=14
04/25/2022 17:01:28 - INFO - __main__ - Step 40 Global step 40 Train loss 0.73 on epoch=19
04/25/2022 17:01:31 - INFO - __main__ - Step 50 Global step 50 Train loss 0.61 on epoch=24
04/25/2022 17:01:33 - INFO - __main__ - Global step 50 Train loss 1.30 ACC 0.21875 on epoch=24
04/25/2022 17:01:33 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.21875 on epoch=24, global_step=50
04/25/2022 17:01:35 - INFO - __main__ - Step 60 Global step 60 Train loss 0.61 on epoch=29
04/25/2022 17:01:38 - INFO - __main__ - Step 70 Global step 70 Train loss 0.45 on epoch=34
04/25/2022 17:01:40 - INFO - __main__ - Step 80 Global step 80 Train loss 0.40 on epoch=39
04/25/2022 17:01:43 - INFO - __main__ - Step 90 Global step 90 Train loss 0.38 on epoch=44
04/25/2022 17:01:45 - INFO - __main__ - Step 100 Global step 100 Train loss 0.25 on epoch=49
04/25/2022 17:01:47 - INFO - __main__ - Global step 100 Train loss 0.42 ACC 0.34375 on epoch=49
04/25/2022 17:01:47 - INFO - __main__ - Saving model with best ACC: 0.21875 -> 0.34375 on epoch=49, global_step=100
04/25/2022 17:01:49 - INFO - __main__ - Step 110 Global step 110 Train loss 0.25 on epoch=54
04/25/2022 17:01:52 - INFO - __main__ - Step 120 Global step 120 Train loss 0.21 on epoch=59
04/25/2022 17:01:54 - INFO - __main__ - Step 130 Global step 130 Train loss 0.23 on epoch=64
04/25/2022 17:01:57 - INFO - __main__ - Step 140 Global step 140 Train loss 0.21 on epoch=69
04/25/2022 17:01:59 - INFO - __main__ - Step 150 Global step 150 Train loss 0.13 on epoch=74
04/25/2022 17:02:01 - INFO - __main__ - Global step 150 Train loss 0.21 ACC 0.375 on epoch=74
04/25/2022 17:02:01 - INFO - __main__ - Saving model with best ACC: 0.34375 -> 0.375 on epoch=74, global_step=150
04/25/2022 17:02:03 - INFO - __main__ - Step 160 Global step 160 Train loss 0.15 on epoch=79
04/25/2022 17:02:06 - INFO - __main__ - Step 170 Global step 170 Train loss 0.15 on epoch=84
04/25/2022 17:02:08 - INFO - __main__ - Step 180 Global step 180 Train loss 0.15 on epoch=89
04/25/2022 17:02:11 - INFO - __main__ - Step 190 Global step 190 Train loss 0.15 on epoch=94
04/25/2022 17:02:13 - INFO - __main__ - Step 200 Global step 200 Train loss 0.22 on epoch=99
04/25/2022 17:02:15 - INFO - __main__ - Global step 200 Train loss 0.16 ACC 0.34375 on epoch=99
04/25/2022 17:02:17 - INFO - __main__ - Step 210 Global step 210 Train loss 0.10 on epoch=104
04/25/2022 17:02:20 - INFO - __main__ - Step 220 Global step 220 Train loss 0.16 on epoch=109
04/25/2022 17:02:22 - INFO - __main__ - Step 230 Global step 230 Train loss 0.08 on epoch=114
04/25/2022 17:02:25 - INFO - __main__ - Step 240 Global step 240 Train loss 0.06 on epoch=119
04/25/2022 17:02:27 - INFO - __main__ - Step 250 Global step 250 Train loss 0.07 on epoch=124
04/25/2022 17:02:29 - INFO - __main__ - Global step 250 Train loss 0.09 ACC 0.375 on epoch=124
04/25/2022 17:02:31 - INFO - __main__ - Step 260 Global step 260 Train loss 0.05 on epoch=129
04/25/2022 17:02:34 - INFO - __main__ - Step 270 Global step 270 Train loss 0.14 on epoch=134
04/25/2022 17:02:36 - INFO - __main__ - Step 280 Global step 280 Train loss 0.04 on epoch=139
04/25/2022 17:02:39 - INFO - __main__ - Step 290 Global step 290 Train loss 0.06 on epoch=144
04/25/2022 17:02:41 - INFO - __main__ - Step 300 Global step 300 Train loss 0.10 on epoch=149
04/25/2022 17:02:43 - INFO - __main__ - Global step 300 Train loss 0.08 ACC 0.40625 on epoch=149
04/25/2022 17:02:43 - INFO - __main__ - Saving model with best ACC: 0.375 -> 0.40625 on epoch=149, global_step=300
04/25/2022 17:02:45 - INFO - __main__ - Step 310 Global step 310 Train loss 0.04 on epoch=154
04/25/2022 17:02:48 - INFO - __main__ - Step 320 Global step 320 Train loss 0.07 on epoch=159
04/25/2022 17:02:50 - INFO - __main__ - Step 330 Global step 330 Train loss 0.09 on epoch=164
04/25/2022 17:02:53 - INFO - __main__ - Step 340 Global step 340 Train loss 0.05 on epoch=169
04/25/2022 17:02:55 - INFO - __main__ - Step 350 Global step 350 Train loss 0.06 on epoch=174
04/25/2022 17:02:57 - INFO - __main__ - Global step 350 Train loss 0.06 ACC 0.28125 on epoch=174
04/25/2022 17:02:59 - INFO - __main__ - Step 360 Global step 360 Train loss 0.03 on epoch=179
04/25/2022 17:03:02 - INFO - __main__ - Step 370 Global step 370 Train loss 0.03 on epoch=184
04/25/2022 17:03:04 - INFO - __main__ - Step 380 Global step 380 Train loss 0.06 on epoch=189
04/25/2022 17:03:07 - INFO - __main__ - Step 390 Global step 390 Train loss 0.05 on epoch=194
04/25/2022 17:03:09 - INFO - __main__ - Step 400 Global step 400 Train loss 0.03 on epoch=199
04/25/2022 17:03:11 - INFO - __main__ - Global step 400 Train loss 0.04 ACC 0.3125 on epoch=199
04/25/2022 17:03:13 - INFO - __main__ - Step 410 Global step 410 Train loss 0.03 on epoch=204
04/25/2022 17:03:16 - INFO - __main__ - Step 420 Global step 420 Train loss 0.03 on epoch=209
04/25/2022 17:03:18 - INFO - __main__ - Step 430 Global step 430 Train loss 0.06 on epoch=214
04/25/2022 17:03:21 - INFO - __main__ - Step 440 Global step 440 Train loss 0.03 on epoch=219
04/25/2022 17:03:23 - INFO - __main__ - Step 450 Global step 450 Train loss 0.20 on epoch=224
04/25/2022 17:03:25 - INFO - __main__ - Global step 450 Train loss 0.07 ACC 0.3125 on epoch=224
04/25/2022 17:03:27 - INFO - __main__ - Step 460 Global step 460 Train loss 0.06 on epoch=229
04/25/2022 17:03:30 - INFO - __main__ - Step 470 Global step 470 Train loss 0.04 on epoch=234
04/25/2022 17:03:32 - INFO - __main__ - Step 480 Global step 480 Train loss 0.05 on epoch=239
04/25/2022 17:03:35 - INFO - __main__ - Step 490 Global step 490 Train loss 0.04 on epoch=244
04/25/2022 17:03:37 - INFO - __main__ - Step 500 Global step 500 Train loss 0.06 on epoch=249
04/25/2022 17:03:39 - INFO - __main__ - Global step 500 Train loss 0.05 ACC 0.3125 on epoch=249
04/25/2022 17:03:42 - INFO - __main__ - Step 510 Global step 510 Train loss 0.02 on epoch=254
04/25/2022 17:03:44 - INFO - __main__ - Step 520 Global step 520 Train loss 0.02 on epoch=259
04/25/2022 17:03:46 - INFO - __main__ - Step 530 Global step 530 Train loss 0.02 on epoch=264
04/25/2022 17:03:49 - INFO - __main__ - Step 540 Global step 540 Train loss 0.02 on epoch=269
04/25/2022 17:03:51 - INFO - __main__ - Step 550 Global step 550 Train loss 0.05 on epoch=274
04/25/2022 17:03:53 - INFO - __main__ - Global step 550 Train loss 0.03 ACC 0.34375 on epoch=274
04/25/2022 17:03:55 - INFO - __main__ - Step 560 Global step 560 Train loss 0.03 on epoch=279
04/25/2022 17:03:58 - INFO - __main__ - Step 570 Global step 570 Train loss 0.06 on epoch=284
04/25/2022 17:04:00 - INFO - __main__ - Step 580 Global step 580 Train loss 0.07 on epoch=289
04/25/2022 17:04:03 - INFO - __main__ - Step 590 Global step 590 Train loss 0.03 on epoch=294
04/25/2022 17:04:05 - INFO - __main__ - Step 600 Global step 600 Train loss 0.03 on epoch=299
04/25/2022 17:04:07 - INFO - __main__ - Global step 600 Train loss 0.04 ACC 0.3125 on epoch=299
04/25/2022 17:04:10 - INFO - __main__ - Step 610 Global step 610 Train loss 0.03 on epoch=304
04/25/2022 17:04:12 - INFO - __main__ - Step 620 Global step 620 Train loss 0.02 on epoch=309
04/25/2022 17:04:14 - INFO - __main__ - Step 630 Global step 630 Train loss 0.06 on epoch=314
04/25/2022 17:04:17 - INFO - __main__ - Step 640 Global step 640 Train loss 0.07 on epoch=319
04/25/2022 17:04:19 - INFO - __main__ - Step 650 Global step 650 Train loss 0.02 on epoch=324
04/25/2022 17:04:21 - INFO - __main__ - Global step 650 Train loss 0.04 ACC 0.28125 on epoch=324
04/25/2022 17:04:24 - INFO - __main__ - Step 660 Global step 660 Train loss 0.02 on epoch=329
04/25/2022 17:04:26 - INFO - __main__ - Step 670 Global step 670 Train loss 0.02 on epoch=334
04/25/2022 17:04:29 - INFO - __main__ - Step 680 Global step 680 Train loss 0.01 on epoch=339
04/25/2022 17:04:31 - INFO - __main__ - Step 690 Global step 690 Train loss 0.02 on epoch=344
04/25/2022 17:04:34 - INFO - __main__ - Step 700 Global step 700 Train loss 0.06 on epoch=349
04/25/2022 17:04:36 - INFO - __main__ - Global step 700 Train loss 0.02 ACC 0.375 on epoch=349
04/25/2022 17:04:38 - INFO - __main__ - Step 710 Global step 710 Train loss 0.03 on epoch=354
04/25/2022 17:04:40 - INFO - __main__ - Step 720 Global step 720 Train loss 0.06 on epoch=359
04/25/2022 17:04:43 - INFO - __main__ - Step 730 Global step 730 Train loss 0.09 on epoch=364
04/25/2022 17:04:45 - INFO - __main__ - Step 740 Global step 740 Train loss 0.05 on epoch=369
04/25/2022 17:04:48 - INFO - __main__ - Step 750 Global step 750 Train loss 0.05 on epoch=374
04/25/2022 17:04:50 - INFO - __main__ - Global step 750 Train loss 0.06 ACC 0.46875 on epoch=374
04/25/2022 17:04:50 - INFO - __main__ - Saving model with best ACC: 0.40625 -> 0.46875 on epoch=374, global_step=750
04/25/2022 17:04:52 - INFO - __main__ - Step 760 Global step 760 Train loss 0.01 on epoch=379
04/25/2022 17:04:54 - INFO - __main__ - Step 770 Global step 770 Train loss 0.02 on epoch=384
04/25/2022 17:04:57 - INFO - __main__ - Step 780 Global step 780 Train loss 0.01 on epoch=389
04/25/2022 17:04:59 - INFO - __main__ - Step 790 Global step 790 Train loss 0.02 on epoch=394
04/25/2022 17:05:02 - INFO - __main__ - Step 800 Global step 800 Train loss 0.01 on epoch=399
04/25/2022 17:05:04 - INFO - __main__ - Global step 800 Train loss 0.02 ACC 0.375 on epoch=399
04/25/2022 17:05:06 - INFO - __main__ - Step 810 Global step 810 Train loss 0.01 on epoch=404
04/25/2022 17:05:09 - INFO - __main__ - Step 820 Global step 820 Train loss 0.01 on epoch=409
04/25/2022 17:05:11 - INFO - __main__ - Step 830 Global step 830 Train loss 0.01 on epoch=414
04/25/2022 17:05:13 - INFO - __main__ - Step 840 Global step 840 Train loss 0.04 on epoch=419
04/25/2022 17:05:16 - INFO - __main__ - Step 850 Global step 850 Train loss 0.01 on epoch=424
04/25/2022 17:05:18 - INFO - __main__ - Global step 850 Train loss 0.02 ACC 0.25 on epoch=424
04/25/2022 17:05:20 - INFO - __main__ - Step 860 Global step 860 Train loss 0.01 on epoch=429
04/25/2022 17:05:23 - INFO - __main__ - Step 870 Global step 870 Train loss 0.05 on epoch=434
04/25/2022 17:05:25 - INFO - __main__ - Step 880 Global step 880 Train loss 0.00 on epoch=439
04/25/2022 17:05:28 - INFO - __main__ - Step 890 Global step 890 Train loss 0.04 on epoch=444
04/25/2022 17:05:30 - INFO - __main__ - Step 900 Global step 900 Train loss 0.06 on epoch=449
04/25/2022 17:05:32 - INFO - __main__ - Global step 900 Train loss 0.03 ACC 0.3125 on epoch=449
04/25/2022 17:05:34 - INFO - __main__ - Step 910 Global step 910 Train loss 0.02 on epoch=454
04/25/2022 17:05:37 - INFO - __main__ - Step 920 Global step 920 Train loss 0.02 on epoch=459
04/25/2022 17:05:39 - INFO - __main__ - Step 930 Global step 930 Train loss 0.02 on epoch=464
04/25/2022 17:05:42 - INFO - __main__ - Step 940 Global step 940 Train loss 0.01 on epoch=469
04/25/2022 17:05:44 - INFO - __main__ - Step 950 Global step 950 Train loss 0.02 on epoch=474
04/25/2022 17:05:46 - INFO - __main__ - Global step 950 Train loss 0.02 ACC 0.28125 on epoch=474
04/25/2022 17:05:49 - INFO - __main__ - Step 960 Global step 960 Train loss 0.04 on epoch=479
04/25/2022 17:05:51 - INFO - __main__ - Step 970 Global step 970 Train loss 0.01 on epoch=484
04/25/2022 17:05:53 - INFO - __main__ - Step 980 Global step 980 Train loss 0.01 on epoch=489
04/25/2022 17:05:56 - INFO - __main__ - Step 990 Global step 990 Train loss 0.02 on epoch=494
04/25/2022 17:05:58 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.01 on epoch=499
04/25/2022 17:06:00 - INFO - __main__ - Global step 1000 Train loss 0.02 ACC 0.40625 on epoch=499
04/25/2022 17:06:03 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.01 on epoch=504
04/25/2022 17:06:05 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.02 on epoch=509
04/25/2022 17:06:08 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.02 on epoch=514
04/25/2022 17:06:10 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.02 on epoch=519
04/25/2022 17:06:12 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.01 on epoch=524
04/25/2022 17:06:14 - INFO - __main__ - Global step 1050 Train loss 0.01 ACC 0.40625 on epoch=524
04/25/2022 17:06:17 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.01 on epoch=529
04/25/2022 17:06:20 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.01 on epoch=534
04/25/2022 17:06:22 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.03 on epoch=539
04/25/2022 17:06:24 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.04 on epoch=544
04/25/2022 17:06:27 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.01 on epoch=549
04/25/2022 17:06:29 - INFO - __main__ - Global step 1100 Train loss 0.02 ACC 0.40625 on epoch=549
04/25/2022 17:06:31 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.02 on epoch=554
04/25/2022 17:06:34 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=559
04/25/2022 17:06:36 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=564
04/25/2022 17:06:39 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.02 on epoch=569
04/25/2022 17:06:41 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=574
04/25/2022 17:06:43 - INFO - __main__ - Global step 1150 Train loss 0.01 ACC 0.3125 on epoch=574
04/25/2022 17:06:46 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.02 on epoch=579
04/25/2022 17:06:48 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.01 on epoch=584
04/25/2022 17:06:51 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.01 on epoch=589
04/25/2022 17:06:53 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.04 on epoch=594
04/25/2022 17:06:55 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=599
04/25/2022 17:06:57 - INFO - __main__ - Global step 1200 Train loss 0.02 ACC 0.34375 on epoch=599
04/25/2022 17:07:00 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.01 on epoch=604
04/25/2022 17:07:02 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=609
04/25/2022 17:07:05 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.04 on epoch=614
04/25/2022 17:07:07 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=619
04/25/2022 17:07:10 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.02 on epoch=624
04/25/2022 17:07:12 - INFO - __main__ - Global step 1250 Train loss 0.02 ACC 0.40625 on epoch=624
04/25/2022 17:07:14 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=629
04/25/2022 17:07:17 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.06 on epoch=634
04/25/2022 17:07:19 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.02 on epoch=639
04/25/2022 17:07:21 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=644
04/25/2022 17:07:24 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.04 on epoch=649
04/25/2022 17:07:26 - INFO - __main__ - Global step 1300 Train loss 0.03 ACC 0.28125 on epoch=649
04/25/2022 17:07:28 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=654
04/25/2022 17:07:31 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=659
04/25/2022 17:07:33 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=664
04/25/2022 17:07:36 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=669
04/25/2022 17:07:38 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=674
04/25/2022 17:07:40 - INFO - __main__ - Global step 1350 Train loss 0.01 ACC 0.34375 on epoch=674
04/25/2022 17:07:42 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=679
04/25/2022 17:07:45 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=684
04/25/2022 17:07:47 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.02 on epoch=689
04/25/2022 17:07:50 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=694
04/25/2022 17:07:52 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.04 on epoch=699
04/25/2022 17:07:54 - INFO - __main__ - Global step 1400 Train loss 0.02 ACC 0.34375 on epoch=699
04/25/2022 17:07:57 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=704
04/25/2022 17:07:59 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.01 on epoch=709
04/25/2022 17:08:01 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=714
04/25/2022 17:08:04 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=719
04/25/2022 17:08:06 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=724
04/25/2022 17:08:08 - INFO - __main__ - Global step 1450 Train loss 0.01 ACC 0.21875 on epoch=724
04/25/2022 17:08:11 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.02 on epoch=729
04/25/2022 17:08:13 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=734
04/25/2022 17:08:16 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=739
04/25/2022 17:08:18 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=744
04/25/2022 17:08:21 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=749
04/25/2022 17:08:22 - INFO - __main__ - Global step 1500 Train loss 0.01 ACC 0.28125 on epoch=749
04/25/2022 17:08:25 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=754
04/25/2022 17:08:27 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=759
04/25/2022 17:08:30 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=764
04/25/2022 17:08:32 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=769
04/25/2022 17:08:35 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=774
04/25/2022 17:08:37 - INFO - __main__ - Global step 1550 Train loss 0.01 ACC 0.34375 on epoch=774
04/25/2022 17:08:39 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=779
04/25/2022 17:08:42 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=784
04/25/2022 17:08:44 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=789
04/25/2022 17:08:46 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=794
04/25/2022 17:08:49 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=799
04/25/2022 17:08:51 - INFO - __main__ - Global step 1600 Train loss 0.01 ACC 0.25 on epoch=799
04/25/2022 17:08:53 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.04 on epoch=804
04/25/2022 17:08:56 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=809
04/25/2022 17:08:58 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=814
04/25/2022 17:09:01 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.02 on epoch=819
04/25/2022 17:09:03 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.03 on epoch=824
04/25/2022 17:09:05 - INFO - __main__ - Global step 1650 Train loss 0.02 ACC 0.3125 on epoch=824
04/25/2022 17:09:08 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=829
04/25/2022 17:09:10 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=834
04/25/2022 17:09:13 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=839
04/25/2022 17:09:15 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=844
04/25/2022 17:09:17 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=849
04/25/2022 17:09:19 - INFO - __main__ - Global step 1700 Train loss 0.01 ACC 0.34375 on epoch=849
04/25/2022 17:09:22 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=854
04/25/2022 17:09:24 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.02 on epoch=859
04/25/2022 17:09:27 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=864
04/25/2022 17:09:29 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=869
04/25/2022 17:09:32 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=874
04/25/2022 17:09:34 - INFO - __main__ - Global step 1750 Train loss 0.01 ACC 0.375 on epoch=874
04/25/2022 17:09:36 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=879
04/25/2022 17:09:39 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=884
04/25/2022 17:09:41 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=889
04/25/2022 17:09:44 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=894
04/25/2022 17:09:46 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=899
04/25/2022 17:09:48 - INFO - __main__ - Global step 1800 Train loss 0.01 ACC 0.125 on epoch=899
04/25/2022 17:09:50 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=904
04/25/2022 17:09:53 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.04 on epoch=909
04/25/2022 17:09:55 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=914
04/25/2022 17:09:58 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=919
04/25/2022 17:10:00 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.08 on epoch=924
04/25/2022 17:10:02 - INFO - __main__ - Global step 1850 Train loss 0.03 ACC 0.28125 on epoch=924
04/25/2022 17:10:05 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=929
04/25/2022 17:10:07 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=934
04/25/2022 17:10:10 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=939
04/25/2022 17:10:12 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=944
04/25/2022 17:10:15 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=949
04/25/2022 17:10:17 - INFO - __main__ - Global step 1900 Train loss 0.01 ACC 0.3125 on epoch=949
04/25/2022 17:10:19 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=954
04/25/2022 17:10:22 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=959
04/25/2022 17:10:24 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=964
04/25/2022 17:10:27 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=969
04/25/2022 17:10:29 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=974
04/25/2022 17:10:31 - INFO - __main__ - Global step 1950 Train loss 0.01 ACC 0.1875 on epoch=974
04/25/2022 17:10:33 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=979
04/25/2022 17:10:36 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=984
04/25/2022 17:10:38 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=989
04/25/2022 17:10:41 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=994
04/25/2022 17:10:43 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=999
04/25/2022 17:10:45 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 17:10:45 - INFO - __main__ - Printing 3 examples
04/25/2022 17:10:45 - INFO - __main__ -  [openbookqa] we only have diamonds because of the existence of (A) machines (B) large pressure (C) work force (D) carbonite
04/25/2022 17:10:45 - INFO - __main__ - ['large pressure']
04/25/2022 17:10:45 - INFO - __main__ -  [openbookqa] A thing which may be found at a special location for reusing materials is a (A) fresh cat litter (B) new brick house (C) rusted aluminum tray (D) old used wax
04/25/2022 17:10:45 - INFO - __main__ - ['rusted aluminum tray']
04/25/2022 17:10:45 - INFO - __main__ -  [openbookqa] If a raptor loses weight, then it will have an easier time (A) eating a goldfish cracker (B) building a small house (C) circling way up there (D) leaving home at night
04/25/2022 17:10:45 - INFO - __main__ - ['circling way up there']
04/25/2022 17:10:45 - INFO - __main__ - Tokenizing Input ...
04/25/2022 17:10:45 - INFO - __main__ - Tokenizing Output ...
04/25/2022 17:10:45 - INFO - __main__ - Loaded 32 examples from train data
04/25/2022 17:10:45 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 17:10:45 - INFO - __main__ - Printing 3 examples
04/25/2022 17:10:45 - INFO - __main__ -  [openbookqa] A tuna would prefer to consume (A) An Apple (B) beef (C) Nemo (D) dogs
04/25/2022 17:10:45 - INFO - __main__ - ['Nemo']
04/25/2022 17:10:45 - INFO - __main__ -  [openbookqa] Overeating (A) causes massive weight loss (B) causes the number on the scale to go up (C) boosts the immune system (D) causes the number on the scale to go down
04/25/2022 17:10:45 - INFO - __main__ - ['causes the number on the scale to go up']
04/25/2022 17:10:45 - INFO - __main__ -  [openbookqa] The more active an animal is (A) their water level will stay steady (B) the less H2O they need to stay hydrated (C) the more H20 they should take in (D) the less likely they are to sweat or pant
04/25/2022 17:10:45 - INFO - __main__ - ['the more H20 they should take in']
04/25/2022 17:10:45 - INFO - __main__ - Tokenizing Input ...
04/25/2022 17:10:45 - INFO - __main__ - Tokenizing Output ...
04/25/2022 17:10:45 - INFO - __main__ - Loaded 32 examples from dev data
04/25/2022 17:10:45 - INFO - __main__ - Global step 2000 Train loss 0.01 ACC 0.25 on epoch=999
04/25/2022 17:10:45 - INFO - __main__ - save last model!
04/25/2022 17:10:45 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
04/25/2022 17:10:45 - INFO - __main__ - Start tokenizing ... 500 instances
04/25/2022 17:10:45 - INFO - __main__ - Printing 3 examples
04/25/2022 17:10:45 - INFO - __main__ -  [openbookqa] Frilled sharks and angler fish live far beneath the surface of the ocean, which is why they are known as (A) Deep sea animals (B) fish (C) Long Sea Fish (D) Far Sea Animals
04/25/2022 17:10:45 - INFO - __main__ - ['Deep sea animals']
04/25/2022 17:10:45 - INFO - __main__ -  [openbookqa] Gas can fill any container it is given, and liquid (A) is standard weight and size (B) is the opposite of variable (C) only needs a few (D) uses what it needs
04/25/2022 17:10:45 - INFO - __main__ - ['uses what it needs']
04/25/2022 17:10:45 - INFO - __main__ -  [openbookqa] When birds migrate south for the winter, they do it because (A) they are genetically called to (B) their children ask for them to (C) it is important to their happiness (D) they decide to each year
04/25/2022 17:10:45 - INFO - __main__ - ['they are genetically called to']
04/25/2022 17:10:45 - INFO - __main__ - Tokenizing Input ...
04/25/2022 17:10:46 - INFO - __main__ - Tokenizing Output ...
04/25/2022 17:10:46 - INFO - __main__ - Loaded 500 examples from test data
04/25/2022 17:11:01 - INFO - __main__ - load prompt embedding from ckpt
04/25/2022 17:11:01 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/25/2022 17:11:01 - INFO - __main__ - Starting training!
04/25/2022 17:11:17 - INFO - __main__ - Saved prediction in models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-openbookqa/openbookqa_32_13_0.5_8_predictions.txt
04/25/2022 17:11:17 - INFO - __main__ - ACC on test data: 0.2540
04/25/2022 17:11:17 - INFO - __main__ - prefix=openbookqa_32_13, lr=0.5, bsz=8, dev_performance=0.46875, test_performance=0.254
04/25/2022 17:11:17 - INFO - __main__ - Running ... prefix=openbookqa_32_13, lr=0.4, bsz=8 ...
04/25/2022 17:11:18 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 17:11:18 - INFO - __main__ - Printing 3 examples
04/25/2022 17:11:18 - INFO - __main__ -  [openbookqa] we only have diamonds because of the existence of (A) machines (B) large pressure (C) work force (D) carbonite
04/25/2022 17:11:18 - INFO - __main__ - ['large pressure']
04/25/2022 17:11:18 - INFO - __main__ -  [openbookqa] A thing which may be found at a special location for reusing materials is a (A) fresh cat litter (B) new brick house (C) rusted aluminum tray (D) old used wax
04/25/2022 17:11:18 - INFO - __main__ - ['rusted aluminum tray']
04/25/2022 17:11:18 - INFO - __main__ -  [openbookqa] If a raptor loses weight, then it will have an easier time (A) eating a goldfish cracker (B) building a small house (C) circling way up there (D) leaving home at night
04/25/2022 17:11:18 - INFO - __main__ - ['circling way up there']
04/25/2022 17:11:18 - INFO - __main__ - Tokenizing Input ...
04/25/2022 17:11:18 - INFO - __main__ - Tokenizing Output ...
04/25/2022 17:11:18 - INFO - __main__ - Loaded 32 examples from train data
04/25/2022 17:11:18 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 17:11:18 - INFO - __main__ - Printing 3 examples
04/25/2022 17:11:18 - INFO - __main__ -  [openbookqa] A tuna would prefer to consume (A) An Apple (B) beef (C) Nemo (D) dogs
04/25/2022 17:11:18 - INFO - __main__ - ['Nemo']
04/25/2022 17:11:18 - INFO - __main__ -  [openbookqa] Overeating (A) causes massive weight loss (B) causes the number on the scale to go up (C) boosts the immune system (D) causes the number on the scale to go down
04/25/2022 17:11:18 - INFO - __main__ - ['causes the number on the scale to go up']
04/25/2022 17:11:18 - INFO - __main__ -  [openbookqa] The more active an animal is (A) their water level will stay steady (B) the less H2O they need to stay hydrated (C) the more H20 they should take in (D) the less likely they are to sweat or pant
04/25/2022 17:11:18 - INFO - __main__ - ['the more H20 they should take in']
04/25/2022 17:11:18 - INFO - __main__ - Tokenizing Input ...
04/25/2022 17:11:18 - INFO - __main__ - Tokenizing Output ...
04/25/2022 17:11:18 - INFO - __main__ - Loaded 32 examples from dev data
04/25/2022 17:11:34 - INFO - __main__ - load prompt embedding from ckpt
04/25/2022 17:11:34 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/25/2022 17:11:34 - INFO - __main__ - Starting training!
04/25/2022 17:11:38 - INFO - __main__ - Step 10 Global step 10 Train loss 2.17 on epoch=4
04/25/2022 17:11:40 - INFO - __main__ - Step 20 Global step 20 Train loss 1.27 on epoch=9
04/25/2022 17:11:42 - INFO - __main__ - Step 30 Global step 30 Train loss 0.89 on epoch=14
04/25/2022 17:11:45 - INFO - __main__ - Step 40 Global step 40 Train loss 0.71 on epoch=19
04/25/2022 17:11:47 - INFO - __main__ - Step 50 Global step 50 Train loss 0.62 on epoch=24
04/25/2022 17:11:50 - INFO - __main__ - Global step 50 Train loss 1.13 ACC 0.1875 on epoch=24
04/25/2022 17:11:50 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.1875 on epoch=24, global_step=50
04/25/2022 17:11:52 - INFO - __main__ - Step 60 Global step 60 Train loss 0.59 on epoch=29
04/25/2022 17:11:55 - INFO - __main__ - Step 70 Global step 70 Train loss 0.48 on epoch=34
04/25/2022 17:11:57 - INFO - __main__ - Step 80 Global step 80 Train loss 0.42 on epoch=39
04/25/2022 17:12:00 - INFO - __main__ - Step 90 Global step 90 Train loss 0.35 on epoch=44
04/25/2022 17:12:02 - INFO - __main__ - Step 100 Global step 100 Train loss 0.36 on epoch=49
04/25/2022 17:12:04 - INFO - __main__ - Global step 100 Train loss 0.44 ACC 0.3125 on epoch=49
04/25/2022 17:12:04 - INFO - __main__ - Saving model with best ACC: 0.1875 -> 0.3125 on epoch=49, global_step=100
04/25/2022 17:12:07 - INFO - __main__ - Step 110 Global step 110 Train loss 0.25 on epoch=54
04/25/2022 17:12:10 - INFO - __main__ - Step 120 Global step 120 Train loss 0.24 on epoch=59
04/25/2022 17:12:12 - INFO - __main__ - Step 130 Global step 130 Train loss 0.28 on epoch=64
04/25/2022 17:12:15 - INFO - __main__ - Step 140 Global step 140 Train loss 0.21 on epoch=69
04/25/2022 17:12:17 - INFO - __main__ - Step 150 Global step 150 Train loss 0.20 on epoch=74
04/25/2022 17:12:19 - INFO - __main__ - Global step 150 Train loss 0.24 ACC 0.40625 on epoch=74
04/25/2022 17:12:19 - INFO - __main__ - Saving model with best ACC: 0.3125 -> 0.40625 on epoch=74, global_step=150
04/25/2022 17:12:22 - INFO - __main__ - Step 160 Global step 160 Train loss 0.19 on epoch=79
04/25/2022 17:12:24 - INFO - __main__ - Step 170 Global step 170 Train loss 0.20 on epoch=84
04/25/2022 17:12:27 - INFO - __main__ - Step 180 Global step 180 Train loss 0.17 on epoch=89
04/25/2022 17:12:29 - INFO - __main__ - Step 190 Global step 190 Train loss 0.12 on epoch=94
04/25/2022 17:12:32 - INFO - __main__ - Step 200 Global step 200 Train loss 0.15 on epoch=99
04/25/2022 17:12:34 - INFO - __main__ - Global step 200 Train loss 0.16 ACC 0.28125 on epoch=99
04/25/2022 17:12:36 - INFO - __main__ - Step 210 Global step 210 Train loss 0.14 on epoch=104
04/25/2022 17:12:39 - INFO - __main__ - Step 220 Global step 220 Train loss 0.13 on epoch=109
04/25/2022 17:12:41 - INFO - __main__ - Step 230 Global step 230 Train loss 0.11 on epoch=114
04/25/2022 17:12:44 - INFO - __main__ - Step 240 Global step 240 Train loss 0.10 on epoch=119
04/25/2022 17:12:46 - INFO - __main__ - Step 250 Global step 250 Train loss 0.15 on epoch=124
04/25/2022 17:12:48 - INFO - __main__ - Global step 250 Train loss 0.13 ACC 0.375 on epoch=124
04/25/2022 17:12:51 - INFO - __main__ - Step 260 Global step 260 Train loss 0.10 on epoch=129
04/25/2022 17:12:53 - INFO - __main__ - Step 270 Global step 270 Train loss 0.07 on epoch=134
04/25/2022 17:12:56 - INFO - __main__ - Step 280 Global step 280 Train loss 0.07 on epoch=139
04/25/2022 17:12:58 - INFO - __main__ - Step 290 Global step 290 Train loss 0.06 on epoch=144
04/25/2022 17:13:01 - INFO - __main__ - Step 300 Global step 300 Train loss 0.05 on epoch=149
04/25/2022 17:13:03 - INFO - __main__ - Global step 300 Train loss 0.07 ACC 0.34375 on epoch=149
04/25/2022 17:13:05 - INFO - __main__ - Step 310 Global step 310 Train loss 0.08 on epoch=154
04/25/2022 17:13:08 - INFO - __main__ - Step 320 Global step 320 Train loss 0.07 on epoch=159
04/25/2022 17:13:10 - INFO - __main__ - Step 330 Global step 330 Train loss 0.08 on epoch=164
04/25/2022 17:13:13 - INFO - __main__ - Step 340 Global step 340 Train loss 0.07 on epoch=169
04/25/2022 17:13:15 - INFO - __main__ - Step 350 Global step 350 Train loss 0.07 on epoch=174
04/25/2022 17:13:17 - INFO - __main__ - Global step 350 Train loss 0.07 ACC 0.3125 on epoch=174
04/25/2022 17:13:20 - INFO - __main__ - Step 360 Global step 360 Train loss 0.06 on epoch=179
04/25/2022 17:13:22 - INFO - __main__ - Step 370 Global step 370 Train loss 0.06 on epoch=184
04/25/2022 17:13:25 - INFO - __main__ - Step 380 Global step 380 Train loss 0.06 on epoch=189
04/25/2022 17:13:27 - INFO - __main__ - Step 390 Global step 390 Train loss 0.05 on epoch=194
04/25/2022 17:13:30 - INFO - __main__ - Step 400 Global step 400 Train loss 0.05 on epoch=199
04/25/2022 17:13:32 - INFO - __main__ - Global step 400 Train loss 0.06 ACC 0.34375 on epoch=199
04/25/2022 17:13:34 - INFO - __main__ - Step 410 Global step 410 Train loss 0.09 on epoch=204
04/25/2022 17:13:37 - INFO - __main__ - Step 420 Global step 420 Train loss 0.08 on epoch=209
04/25/2022 17:13:39 - INFO - __main__ - Step 430 Global step 430 Train loss 0.04 on epoch=214
04/25/2022 17:13:41 - INFO - __main__ - Step 440 Global step 440 Train loss 0.06 on epoch=219
04/25/2022 17:13:44 - INFO - __main__ - Step 450 Global step 450 Train loss 0.07 on epoch=224
04/25/2022 17:13:46 - INFO - __main__ - Global step 450 Train loss 0.07 ACC 0.40625 on epoch=224
04/25/2022 17:13:48 - INFO - __main__ - Step 460 Global step 460 Train loss 0.04 on epoch=229
04/25/2022 17:13:51 - INFO - __main__ - Step 470 Global step 470 Train loss 0.04 on epoch=234
04/25/2022 17:13:53 - INFO - __main__ - Step 480 Global step 480 Train loss 0.05 on epoch=239
04/25/2022 17:13:56 - INFO - __main__ - Step 490 Global step 490 Train loss 0.05 on epoch=244
04/25/2022 17:13:58 - INFO - __main__ - Step 500 Global step 500 Train loss 0.05 on epoch=249
04/25/2022 17:14:00 - INFO - __main__ - Global step 500 Train loss 0.05 ACC 0.375 on epoch=249
04/25/2022 17:14:03 - INFO - __main__ - Step 510 Global step 510 Train loss 0.02 on epoch=254
04/25/2022 17:14:05 - INFO - __main__ - Step 520 Global step 520 Train loss 0.02 on epoch=259
04/25/2022 17:14:08 - INFO - __main__ - Step 530 Global step 530 Train loss 0.04 on epoch=264
04/25/2022 17:14:10 - INFO - __main__ - Step 540 Global step 540 Train loss 0.03 on epoch=269
04/25/2022 17:14:13 - INFO - __main__ - Step 550 Global step 550 Train loss 0.03 on epoch=274
04/25/2022 17:14:15 - INFO - __main__ - Global step 550 Train loss 0.03 ACC 0.375 on epoch=274
04/25/2022 17:14:17 - INFO - __main__ - Step 560 Global step 560 Train loss 0.03 on epoch=279
04/25/2022 17:14:20 - INFO - __main__ - Step 570 Global step 570 Train loss 0.03 on epoch=284
04/25/2022 17:14:22 - INFO - __main__ - Step 580 Global step 580 Train loss 0.02 on epoch=289
04/25/2022 17:14:25 - INFO - __main__ - Step 590 Global step 590 Train loss 0.03 on epoch=294
04/25/2022 17:14:27 - INFO - __main__ - Step 600 Global step 600 Train loss 0.05 on epoch=299
04/25/2022 17:14:29 - INFO - __main__ - Global step 600 Train loss 0.03 ACC 0.375 on epoch=299
04/25/2022 17:14:32 - INFO - __main__ - Step 610 Global step 610 Train loss 0.04 on epoch=304
04/25/2022 17:14:34 - INFO - __main__ - Step 620 Global step 620 Train loss 0.04 on epoch=309
04/25/2022 17:14:37 - INFO - __main__ - Step 630 Global step 630 Train loss 0.02 on epoch=314
04/25/2022 17:14:39 - INFO - __main__ - Step 640 Global step 640 Train loss 0.03 on epoch=319
04/25/2022 17:14:42 - INFO - __main__ - Step 650 Global step 650 Train loss 0.06 on epoch=324
04/25/2022 17:14:44 - INFO - __main__ - Global step 650 Train loss 0.04 ACC 0.21875 on epoch=324
04/25/2022 17:14:46 - INFO - __main__ - Step 660 Global step 660 Train loss 0.04 on epoch=329
04/25/2022 17:14:49 - INFO - __main__ - Step 670 Global step 670 Train loss 0.01 on epoch=334
04/25/2022 17:14:51 - INFO - __main__ - Step 680 Global step 680 Train loss 0.03 on epoch=339
04/25/2022 17:14:54 - INFO - __main__ - Step 690 Global step 690 Train loss 0.02 on epoch=344
04/25/2022 17:14:56 - INFO - __main__ - Step 700 Global step 700 Train loss 0.01 on epoch=349
04/25/2022 17:14:58 - INFO - __main__ - Global step 700 Train loss 0.03 ACC 0.3125 on epoch=349
04/25/2022 17:15:01 - INFO - __main__ - Step 710 Global step 710 Train loss 0.03 on epoch=354
04/25/2022 17:15:03 - INFO - __main__ - Step 720 Global step 720 Train loss 0.01 on epoch=359
04/25/2022 17:15:06 - INFO - __main__ - Step 730 Global step 730 Train loss 0.02 on epoch=364
04/25/2022 17:15:08 - INFO - __main__ - Step 740 Global step 740 Train loss 0.01 on epoch=369
04/25/2022 17:15:11 - INFO - __main__ - Step 750 Global step 750 Train loss 0.03 on epoch=374
04/25/2022 17:15:13 - INFO - __main__ - Global step 750 Train loss 0.02 ACC 0.28125 on epoch=374
04/25/2022 17:15:15 - INFO - __main__ - Step 760 Global step 760 Train loss 0.02 on epoch=379
04/25/2022 17:15:18 - INFO - __main__ - Step 770 Global step 770 Train loss 0.01 on epoch=384
04/25/2022 17:15:20 - INFO - __main__ - Step 780 Global step 780 Train loss 0.03 on epoch=389
04/25/2022 17:15:23 - INFO - __main__ - Step 790 Global step 790 Train loss 0.01 on epoch=394
04/25/2022 17:15:25 - INFO - __main__ - Step 800 Global step 800 Train loss 0.05 on epoch=399
04/25/2022 17:15:28 - INFO - __main__ - Global step 800 Train loss 0.02 ACC 0.34375 on epoch=399
04/25/2022 17:15:30 - INFO - __main__ - Step 810 Global step 810 Train loss 0.01 on epoch=404
04/25/2022 17:15:33 - INFO - __main__ - Step 820 Global step 820 Train loss 0.02 on epoch=409
04/25/2022 17:15:35 - INFO - __main__ - Step 830 Global step 830 Train loss 0.01 on epoch=414
04/25/2022 17:15:38 - INFO - __main__ - Step 840 Global step 840 Train loss 0.02 on epoch=419
04/25/2022 17:15:40 - INFO - __main__ - Step 850 Global step 850 Train loss 0.02 on epoch=424
04/25/2022 17:15:42 - INFO - __main__ - Global step 850 Train loss 0.02 ACC 0.28125 on epoch=424
04/25/2022 17:15:45 - INFO - __main__ - Step 860 Global step 860 Train loss 0.01 on epoch=429
04/25/2022 17:15:47 - INFO - __main__ - Step 870 Global step 870 Train loss 0.02 on epoch=434
04/25/2022 17:15:50 - INFO - __main__ - Step 880 Global step 880 Train loss 0.02 on epoch=439
04/25/2022 17:15:52 - INFO - __main__ - Step 890 Global step 890 Train loss 0.02 on epoch=444
04/25/2022 17:15:55 - INFO - __main__ - Step 900 Global step 900 Train loss 0.01 on epoch=449
04/25/2022 17:15:56 - INFO - __main__ - Global step 900 Train loss 0.02 ACC 0.28125 on epoch=449
04/25/2022 17:15:59 - INFO - __main__ - Step 910 Global step 910 Train loss 0.02 on epoch=454
04/25/2022 17:16:01 - INFO - __main__ - Step 920 Global step 920 Train loss 0.01 on epoch=459
04/25/2022 17:16:04 - INFO - __main__ - Step 930 Global step 930 Train loss 0.02 on epoch=464
04/25/2022 17:16:06 - INFO - __main__ - Step 940 Global step 940 Train loss 0.01 on epoch=469
04/25/2022 17:16:09 - INFO - __main__ - Step 950 Global step 950 Train loss 0.01 on epoch=474
04/25/2022 17:16:11 - INFO - __main__ - Global step 950 Train loss 0.01 ACC 0.28125 on epoch=474
04/25/2022 17:16:13 - INFO - __main__ - Step 960 Global step 960 Train loss 0.06 on epoch=479
04/25/2022 17:16:16 - INFO - __main__ - Step 970 Global step 970 Train loss 0.01 on epoch=484
04/25/2022 17:16:18 - INFO - __main__ - Step 980 Global step 980 Train loss 0.03 on epoch=489
04/25/2022 17:16:21 - INFO - __main__ - Step 990 Global step 990 Train loss 0.02 on epoch=494
04/25/2022 17:16:23 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.01 on epoch=499
04/25/2022 17:16:25 - INFO - __main__ - Global step 1000 Train loss 0.03 ACC 0.375 on epoch=499
04/25/2022 17:16:28 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.01 on epoch=504
04/25/2022 17:16:30 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.01 on epoch=509
04/25/2022 17:16:32 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.01 on epoch=514
04/25/2022 17:16:35 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.01 on epoch=519
04/25/2022 17:16:38 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.00 on epoch=524
04/25/2022 17:16:39 - INFO - __main__ - Global step 1050 Train loss 0.01 ACC 0.3125 on epoch=524
04/25/2022 17:16:42 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.02 on epoch=529
04/25/2022 17:16:44 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.01 on epoch=534
04/25/2022 17:16:47 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.02 on epoch=539
04/25/2022 17:16:49 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.02 on epoch=544
04/25/2022 17:16:52 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.03 on epoch=549
04/25/2022 17:16:54 - INFO - __main__ - Global step 1100 Train loss 0.02 ACC 0.5 on epoch=549
04/25/2022 17:16:54 - INFO - __main__ - Saving model with best ACC: 0.40625 -> 0.5 on epoch=549, global_step=1100
04/25/2022 17:16:56 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.02 on epoch=554
04/25/2022 17:16:59 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=559
04/25/2022 17:17:01 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=564
04/25/2022 17:17:04 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.01 on epoch=569
04/25/2022 17:17:06 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=574
04/25/2022 17:17:08 - INFO - __main__ - Global step 1150 Train loss 0.01 ACC 0.375 on epoch=574
04/25/2022 17:17:11 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.01 on epoch=579
04/25/2022 17:17:13 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.01 on epoch=584
04/25/2022 17:17:16 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.02 on epoch=589
04/25/2022 17:17:18 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.01 on epoch=594
04/25/2022 17:17:21 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=599
04/25/2022 17:17:22 - INFO - __main__ - Global step 1200 Train loss 0.01 ACC 0.4375 on epoch=599
04/25/2022 17:17:25 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.01 on epoch=604
04/25/2022 17:17:27 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.04 on epoch=609
04/25/2022 17:17:30 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=614
04/25/2022 17:17:32 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.00 on epoch=619
04/25/2022 17:17:35 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.02 on epoch=624
04/25/2022 17:17:37 - INFO - __main__ - Global step 1250 Train loss 0.02 ACC 0.34375 on epoch=624
04/25/2022 17:17:39 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=629
04/25/2022 17:17:42 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.01 on epoch=634
04/25/2022 17:17:44 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=639
04/25/2022 17:17:47 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.04 on epoch=644
04/25/2022 17:17:49 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=649
04/25/2022 17:17:51 - INFO - __main__ - Global step 1300 Train loss 0.01 ACC 0.3125 on epoch=649
04/25/2022 17:17:53 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=654
04/25/2022 17:17:56 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=659
04/25/2022 17:17:58 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.02 on epoch=664
04/25/2022 17:18:01 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=669
04/25/2022 17:18:03 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=674
04/25/2022 17:18:05 - INFO - __main__ - Global step 1350 Train loss 0.01 ACC 0.34375 on epoch=674
04/25/2022 17:18:08 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=679
04/25/2022 17:18:10 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=684
04/25/2022 17:18:13 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=689
04/25/2022 17:18:15 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.02 on epoch=694
04/25/2022 17:18:18 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=699
04/25/2022 17:18:20 - INFO - __main__ - Global step 1400 Train loss 0.01 ACC 0.40625 on epoch=699
04/25/2022 17:18:22 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=704
04/25/2022 17:18:25 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=709
04/25/2022 17:18:27 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.00 on epoch=714
04/25/2022 17:18:30 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=719
04/25/2022 17:18:32 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=724
04/25/2022 17:18:34 - INFO - __main__ - Global step 1450 Train loss 0.01 ACC 0.4375 on epoch=724
04/25/2022 17:18:37 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=729
04/25/2022 17:18:39 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=734
04/25/2022 17:18:42 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=739
04/25/2022 17:18:44 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=744
04/25/2022 17:18:47 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=749
04/25/2022 17:18:49 - INFO - __main__ - Global step 1500 Train loss 0.01 ACC 0.3125 on epoch=749
04/25/2022 17:18:51 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=754
04/25/2022 17:18:54 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=759
04/25/2022 17:18:56 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=764
04/25/2022 17:18:59 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=769
04/25/2022 17:19:01 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=774
04/25/2022 17:19:03 - INFO - __main__ - Global step 1550 Train loss 0.01 ACC 0.34375 on epoch=774
04/25/2022 17:19:06 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=779
04/25/2022 17:19:08 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=784
04/25/2022 17:19:11 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=789
04/25/2022 17:19:13 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=794
04/25/2022 17:19:16 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.06 on epoch=799
04/25/2022 17:19:17 - INFO - __main__ - Global step 1600 Train loss 0.02 ACC 0.40625 on epoch=799
04/25/2022 17:19:20 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=804
04/25/2022 17:19:23 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=809
04/25/2022 17:19:25 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=814
04/25/2022 17:19:28 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.03 on epoch=819
04/25/2022 17:19:30 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=824
04/25/2022 17:19:32 - INFO - __main__ - Global step 1650 Train loss 0.01 ACC 0.25 on epoch=824
04/25/2022 17:19:35 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=829
04/25/2022 17:19:37 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=834
04/25/2022 17:19:40 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=839
04/25/2022 17:19:42 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=844
04/25/2022 17:19:45 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=849
04/25/2022 17:19:47 - INFO - __main__ - Global step 1700 Train loss 0.01 ACC 0.3125 on epoch=849
04/25/2022 17:19:49 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=854
04/25/2022 17:19:52 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=859
04/25/2022 17:19:54 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.03 on epoch=864
04/25/2022 17:19:57 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=869
04/25/2022 17:19:59 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=874
04/25/2022 17:20:02 - INFO - __main__ - Global step 1750 Train loss 0.01 ACC 0.28125 on epoch=874
04/25/2022 17:20:04 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=879
04/25/2022 17:20:07 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=884
04/25/2022 17:20:09 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=889
04/25/2022 17:20:12 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=894
04/25/2022 17:20:14 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=899
04/25/2022 17:20:16 - INFO - __main__ - Global step 1800 Train loss 0.01 ACC 0.25 on epoch=899
04/25/2022 17:20:19 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=904
04/25/2022 17:20:21 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=909
04/25/2022 17:20:24 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=914
04/25/2022 17:20:26 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=919
04/25/2022 17:20:29 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=924
04/25/2022 17:20:31 - INFO - __main__ - Global step 1850 Train loss 0.01 ACC 0.25 on epoch=924
04/25/2022 17:20:34 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=929
04/25/2022 17:20:36 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=934
04/25/2022 17:20:39 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=939
04/25/2022 17:20:41 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=944
04/25/2022 17:20:44 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=949
04/25/2022 17:20:46 - INFO - __main__ - Global step 1900 Train loss 0.00 ACC 0.3125 on epoch=949
04/25/2022 17:20:48 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=954
04/25/2022 17:20:51 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.04 on epoch=959
04/25/2022 17:20:53 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=964
04/25/2022 17:20:56 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=969
04/25/2022 17:20:58 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=974
04/25/2022 17:21:00 - INFO - __main__ - Global step 1950 Train loss 0.01 ACC 0.3125 on epoch=974
04/25/2022 17:21:03 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=979
04/25/2022 17:21:05 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=984
04/25/2022 17:21:08 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=989
04/25/2022 17:21:10 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=994
04/25/2022 17:21:13 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=999
04/25/2022 17:21:14 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 17:21:14 - INFO - __main__ - Printing 3 examples
04/25/2022 17:21:14 - INFO - __main__ -  [openbookqa] we only have diamonds because of the existence of (A) machines (B) large pressure (C) work force (D) carbonite
04/25/2022 17:21:14 - INFO - __main__ - ['large pressure']
04/25/2022 17:21:14 - INFO - __main__ -  [openbookqa] A thing which may be found at a special location for reusing materials is a (A) fresh cat litter (B) new brick house (C) rusted aluminum tray (D) old used wax
04/25/2022 17:21:14 - INFO - __main__ - ['rusted aluminum tray']
04/25/2022 17:21:14 - INFO - __main__ -  [openbookqa] If a raptor loses weight, then it will have an easier time (A) eating a goldfish cracker (B) building a small house (C) circling way up there (D) leaving home at night
04/25/2022 17:21:14 - INFO - __main__ - ['circling way up there']
04/25/2022 17:21:14 - INFO - __main__ - Tokenizing Input ...
04/25/2022 17:21:14 - INFO - __main__ - Tokenizing Output ...
04/25/2022 17:21:14 - INFO - __main__ - Loaded 32 examples from train data
04/25/2022 17:21:14 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 17:21:14 - INFO - __main__ - Printing 3 examples
04/25/2022 17:21:14 - INFO - __main__ -  [openbookqa] A tuna would prefer to consume (A) An Apple (B) beef (C) Nemo (D) dogs
04/25/2022 17:21:14 - INFO - __main__ - ['Nemo']
04/25/2022 17:21:14 - INFO - __main__ -  [openbookqa] Overeating (A) causes massive weight loss (B) causes the number on the scale to go up (C) boosts the immune system (D) causes the number on the scale to go down
04/25/2022 17:21:14 - INFO - __main__ - ['causes the number on the scale to go up']
04/25/2022 17:21:14 - INFO - __main__ -  [openbookqa] The more active an animal is (A) their water level will stay steady (B) the less H2O they need to stay hydrated (C) the more H20 they should take in (D) the less likely they are to sweat or pant
04/25/2022 17:21:14 - INFO - __main__ - ['the more H20 they should take in']
04/25/2022 17:21:14 - INFO - __main__ - Tokenizing Input ...
04/25/2022 17:21:14 - INFO - __main__ - Tokenizing Output ...
04/25/2022 17:21:14 - INFO - __main__ - Loaded 32 examples from dev data
04/25/2022 17:21:15 - INFO - __main__ - Global step 2000 Train loss 0.01 ACC 0.34375 on epoch=999
04/25/2022 17:21:15 - INFO - __main__ - save last model!
04/25/2022 17:21:15 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
04/25/2022 17:21:15 - INFO - __main__ - Start tokenizing ... 500 instances
04/25/2022 17:21:15 - INFO - __main__ - Printing 3 examples
04/25/2022 17:21:15 - INFO - __main__ -  [openbookqa] Frilled sharks and angler fish live far beneath the surface of the ocean, which is why they are known as (A) Deep sea animals (B) fish (C) Long Sea Fish (D) Far Sea Animals
04/25/2022 17:21:15 - INFO - __main__ - ['Deep sea animals']
04/25/2022 17:21:15 - INFO - __main__ -  [openbookqa] Gas can fill any container it is given, and liquid (A) is standard weight and size (B) is the opposite of variable (C) only needs a few (D) uses what it needs
04/25/2022 17:21:15 - INFO - __main__ - ['uses what it needs']
04/25/2022 17:21:15 - INFO - __main__ -  [openbookqa] When birds migrate south for the winter, they do it because (A) they are genetically called to (B) their children ask for them to (C) it is important to their happiness (D) they decide to each year
04/25/2022 17:21:15 - INFO - __main__ - ['they are genetically called to']
04/25/2022 17:21:15 - INFO - __main__ - Tokenizing Input ...
04/25/2022 17:21:15 - INFO - __main__ - Tokenizing Output ...
04/25/2022 17:21:16 - INFO - __main__ - Loaded 500 examples from test data
04/25/2022 17:21:30 - INFO - __main__ - load prompt embedding from ckpt
04/25/2022 17:21:31 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/25/2022 17:21:31 - INFO - __main__ - Starting training!
04/25/2022 17:21:47 - INFO - __main__ - Saved prediction in models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-openbookqa/openbookqa_32_13_0.4_8_predictions.txt
04/25/2022 17:21:47 - INFO - __main__ - ACC on test data: 0.2620
04/25/2022 17:21:48 - INFO - __main__ - prefix=openbookqa_32_13, lr=0.4, bsz=8, dev_performance=0.5, test_performance=0.262
04/25/2022 17:21:48 - INFO - __main__ - Running ... prefix=openbookqa_32_13, lr=0.3, bsz=8 ...
04/25/2022 17:21:49 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 17:21:49 - INFO - __main__ - Printing 3 examples
04/25/2022 17:21:49 - INFO - __main__ -  [openbookqa] we only have diamonds because of the existence of (A) machines (B) large pressure (C) work force (D) carbonite
04/25/2022 17:21:49 - INFO - __main__ - ['large pressure']
04/25/2022 17:21:49 - INFO - __main__ -  [openbookqa] A thing which may be found at a special location for reusing materials is a (A) fresh cat litter (B) new brick house (C) rusted aluminum tray (D) old used wax
04/25/2022 17:21:49 - INFO - __main__ - ['rusted aluminum tray']
04/25/2022 17:21:49 - INFO - __main__ -  [openbookqa] If a raptor loses weight, then it will have an easier time (A) eating a goldfish cracker (B) building a small house (C) circling way up there (D) leaving home at night
04/25/2022 17:21:49 - INFO - __main__ - ['circling way up there']
04/25/2022 17:21:49 - INFO - __main__ - Tokenizing Input ...
04/25/2022 17:21:49 - INFO - __main__ - Tokenizing Output ...
04/25/2022 17:21:49 - INFO - __main__ - Loaded 32 examples from train data
04/25/2022 17:21:49 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 17:21:49 - INFO - __main__ - Printing 3 examples
04/25/2022 17:21:49 - INFO - __main__ -  [openbookqa] A tuna would prefer to consume (A) An Apple (B) beef (C) Nemo (D) dogs
04/25/2022 17:21:49 - INFO - __main__ - ['Nemo']
04/25/2022 17:21:49 - INFO - __main__ -  [openbookqa] Overeating (A) causes massive weight loss (B) causes the number on the scale to go up (C) boosts the immune system (D) causes the number on the scale to go down
04/25/2022 17:21:49 - INFO - __main__ - ['causes the number on the scale to go up']
04/25/2022 17:21:49 - INFO - __main__ -  [openbookqa] The more active an animal is (A) their water level will stay steady (B) the less H2O they need to stay hydrated (C) the more H20 they should take in (D) the less likely they are to sweat or pant
04/25/2022 17:21:49 - INFO - __main__ - ['the more H20 they should take in']
04/25/2022 17:21:49 - INFO - __main__ - Tokenizing Input ...
04/25/2022 17:21:49 - INFO - __main__ - Tokenizing Output ...
04/25/2022 17:21:49 - INFO - __main__ - Loaded 32 examples from dev data
04/25/2022 17:22:04 - INFO - __main__ - load prompt embedding from ckpt
04/25/2022 17:22:05 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/25/2022 17:22:05 - INFO - __main__ - Starting training!
04/25/2022 17:22:08 - INFO - __main__ - Step 10 Global step 10 Train loss 2.23 on epoch=4
04/25/2022 17:22:11 - INFO - __main__ - Step 20 Global step 20 Train loss 1.58 on epoch=9
04/25/2022 17:22:14 - INFO - __main__ - Step 30 Global step 30 Train loss 1.17 on epoch=14
04/25/2022 17:22:16 - INFO - __main__ - Step 40 Global step 40 Train loss 0.95 on epoch=19
04/25/2022 17:22:18 - INFO - __main__ - Step 50 Global step 50 Train loss 0.69 on epoch=24
04/25/2022 17:22:21 - INFO - __main__ - Global step 50 Train loss 1.32 ACC 0.1875 on epoch=24
04/25/2022 17:22:21 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.1875 on epoch=24, global_step=50
04/25/2022 17:22:23 - INFO - __main__ - Step 60 Global step 60 Train loss 0.63 on epoch=29
04/25/2022 17:22:26 - INFO - __main__ - Step 70 Global step 70 Train loss 0.59 on epoch=34
04/25/2022 17:22:28 - INFO - __main__ - Step 80 Global step 80 Train loss 0.48 on epoch=39
04/25/2022 17:22:31 - INFO - __main__ - Step 90 Global step 90 Train loss 0.45 on epoch=44
04/25/2022 17:22:33 - INFO - __main__ - Step 100 Global step 100 Train loss 0.36 on epoch=49
04/25/2022 17:22:35 - INFO - __main__ - Global step 100 Train loss 0.50 ACC 0.1875 on epoch=49
04/25/2022 17:22:38 - INFO - __main__ - Step 110 Global step 110 Train loss 0.41 on epoch=54
04/25/2022 17:22:40 - INFO - __main__ - Step 120 Global step 120 Train loss 0.33 on epoch=59
04/25/2022 17:22:43 - INFO - __main__ - Step 130 Global step 130 Train loss 0.30 on epoch=64
04/25/2022 17:22:45 - INFO - __main__ - Step 140 Global step 140 Train loss 0.28 on epoch=69
04/25/2022 17:22:48 - INFO - __main__ - Step 150 Global step 150 Train loss 0.24 on epoch=74
04/25/2022 17:22:50 - INFO - __main__ - Global step 150 Train loss 0.31 ACC 0.25 on epoch=74
04/25/2022 17:22:50 - INFO - __main__ - Saving model with best ACC: 0.1875 -> 0.25 on epoch=74, global_step=150
04/25/2022 17:22:52 - INFO - __main__ - Step 160 Global step 160 Train loss 0.22 on epoch=79
04/25/2022 17:22:55 - INFO - __main__ - Step 170 Global step 170 Train loss 0.23 on epoch=84
04/25/2022 17:22:57 - INFO - __main__ - Step 180 Global step 180 Train loss 0.21 on epoch=89
04/25/2022 17:22:59 - INFO - __main__ - Step 190 Global step 190 Train loss 0.19 on epoch=94
04/25/2022 17:23:02 - INFO - __main__ - Step 200 Global step 200 Train loss 0.16 on epoch=99
04/25/2022 17:23:04 - INFO - __main__ - Global step 200 Train loss 0.20 ACC 0.375 on epoch=99
04/25/2022 17:23:04 - INFO - __main__ - Saving model with best ACC: 0.25 -> 0.375 on epoch=99, global_step=200
04/25/2022 17:23:06 - INFO - __main__ - Step 210 Global step 210 Train loss 0.16 on epoch=104
04/25/2022 17:23:09 - INFO - __main__ - Step 220 Global step 220 Train loss 0.14 on epoch=109
04/25/2022 17:23:11 - INFO - __main__ - Step 230 Global step 230 Train loss 0.14 on epoch=114
04/25/2022 17:23:13 - INFO - __main__ - Step 240 Global step 240 Train loss 0.09 on epoch=119
04/25/2022 17:23:16 - INFO - __main__ - Step 250 Global step 250 Train loss 0.13 on epoch=124
04/25/2022 17:23:18 - INFO - __main__ - Global step 250 Train loss 0.13 ACC 0.375 on epoch=124
04/25/2022 17:23:20 - INFO - __main__ - Step 260 Global step 260 Train loss 0.12 on epoch=129
04/25/2022 17:23:23 - INFO - __main__ - Step 270 Global step 270 Train loss 0.08 on epoch=134
04/25/2022 17:23:25 - INFO - __main__ - Step 280 Global step 280 Train loss 0.13 on epoch=139
04/25/2022 17:23:28 - INFO - __main__ - Step 290 Global step 290 Train loss 0.10 on epoch=144
04/25/2022 17:23:30 - INFO - __main__ - Step 300 Global step 300 Train loss 0.10 on epoch=149
04/25/2022 17:23:32 - INFO - __main__ - Global step 300 Train loss 0.11 ACC 0.40625 on epoch=149
04/25/2022 17:23:32 - INFO - __main__ - Saving model with best ACC: 0.375 -> 0.40625 on epoch=149, global_step=300
04/25/2022 17:23:34 - INFO - __main__ - Step 310 Global step 310 Train loss 0.12 on epoch=154
04/25/2022 17:23:37 - INFO - __main__ - Step 320 Global step 320 Train loss 0.06 on epoch=159
04/25/2022 17:23:39 - INFO - __main__ - Step 330 Global step 330 Train loss 0.06 on epoch=164
04/25/2022 17:23:42 - INFO - __main__ - Step 340 Global step 340 Train loss 0.06 on epoch=169
04/25/2022 17:23:44 - INFO - __main__ - Step 350 Global step 350 Train loss 0.05 on epoch=174
04/25/2022 17:23:46 - INFO - __main__ - Global step 350 Train loss 0.07 ACC 0.375 on epoch=174
04/25/2022 17:23:49 - INFO - __main__ - Step 360 Global step 360 Train loss 0.05 on epoch=179
04/25/2022 17:23:51 - INFO - __main__ - Step 370 Global step 370 Train loss 0.06 on epoch=184
04/25/2022 17:23:54 - INFO - __main__ - Step 380 Global step 380 Train loss 0.06 on epoch=189
04/25/2022 17:23:56 - INFO - __main__ - Step 390 Global step 390 Train loss 0.06 on epoch=194
04/25/2022 17:23:59 - INFO - __main__ - Step 400 Global step 400 Train loss 0.06 on epoch=199
04/25/2022 17:24:01 - INFO - __main__ - Global step 400 Train loss 0.06 ACC 0.3125 on epoch=199
04/25/2022 17:24:03 - INFO - __main__ - Step 410 Global step 410 Train loss 0.06 on epoch=204
04/25/2022 17:24:05 - INFO - __main__ - Step 420 Global step 420 Train loss 0.07 on epoch=209
04/25/2022 17:24:08 - INFO - __main__ - Step 430 Global step 430 Train loss 0.07 on epoch=214
04/25/2022 17:24:10 - INFO - __main__ - Step 440 Global step 440 Train loss 0.06 on epoch=219
04/25/2022 17:24:13 - INFO - __main__ - Step 450 Global step 450 Train loss 0.05 on epoch=224
04/25/2022 17:24:15 - INFO - __main__ - Global step 450 Train loss 0.06 ACC 0.34375 on epoch=224
04/25/2022 17:24:17 - INFO - __main__ - Step 460 Global step 460 Train loss 0.03 on epoch=229
04/25/2022 17:24:20 - INFO - __main__ - Step 470 Global step 470 Train loss 0.05 on epoch=234
04/25/2022 17:24:23 - INFO - __main__ - Step 480 Global step 480 Train loss 0.04 on epoch=239
04/25/2022 17:24:25 - INFO - __main__ - Step 490 Global step 490 Train loss 0.03 on epoch=244
04/25/2022 17:24:28 - INFO - __main__ - Step 500 Global step 500 Train loss 0.06 on epoch=249
04/25/2022 17:24:30 - INFO - __main__ - Global step 500 Train loss 0.04 ACC 0.4375 on epoch=249
04/25/2022 17:24:30 - INFO - __main__ - Saving model with best ACC: 0.40625 -> 0.4375 on epoch=249, global_step=500
04/25/2022 17:24:32 - INFO - __main__ - Step 510 Global step 510 Train loss 0.04 on epoch=254
04/25/2022 17:24:35 - INFO - __main__ - Step 520 Global step 520 Train loss 0.04 on epoch=259
04/25/2022 17:24:37 - INFO - __main__ - Step 530 Global step 530 Train loss 0.04 on epoch=264
04/25/2022 17:24:40 - INFO - __main__ - Step 540 Global step 540 Train loss 0.05 on epoch=269
04/25/2022 17:24:42 - INFO - __main__ - Step 550 Global step 550 Train loss 0.03 on epoch=274
04/25/2022 17:24:44 - INFO - __main__ - Global step 550 Train loss 0.04 ACC 0.40625 on epoch=274
04/25/2022 17:24:46 - INFO - __main__ - Step 560 Global step 560 Train loss 0.02 on epoch=279
04/25/2022 17:24:49 - INFO - __main__ - Step 570 Global step 570 Train loss 0.05 on epoch=284
04/25/2022 17:24:51 - INFO - __main__ - Step 580 Global step 580 Train loss 0.03 on epoch=289
04/25/2022 17:24:54 - INFO - __main__ - Step 590 Global step 590 Train loss 0.02 on epoch=294
04/25/2022 17:24:56 - INFO - __main__ - Step 600 Global step 600 Train loss 0.04 on epoch=299
04/25/2022 17:24:58 - INFO - __main__ - Global step 600 Train loss 0.03 ACC 0.4375 on epoch=299
04/25/2022 17:25:01 - INFO - __main__ - Step 610 Global step 610 Train loss 0.09 on epoch=304
04/25/2022 17:25:03 - INFO - __main__ - Step 620 Global step 620 Train loss 0.17 on epoch=309
04/25/2022 17:25:06 - INFO - __main__ - Step 630 Global step 630 Train loss 0.16 on epoch=314
04/25/2022 17:25:08 - INFO - __main__ - Step 640 Global step 640 Train loss 0.17 on epoch=319
04/25/2022 17:25:11 - INFO - __main__ - Step 650 Global step 650 Train loss 0.11 on epoch=324
04/25/2022 17:25:12 - INFO - __main__ - Global step 650 Train loss 0.14 ACC 0.40625 on epoch=324
04/25/2022 17:25:15 - INFO - __main__ - Step 660 Global step 660 Train loss 0.07 on epoch=329
04/25/2022 17:25:17 - INFO - __main__ - Step 670 Global step 670 Train loss 0.13 on epoch=334
04/25/2022 17:25:20 - INFO - __main__ - Step 680 Global step 680 Train loss 0.05 on epoch=339
04/25/2022 17:25:22 - INFO - __main__ - Step 690 Global step 690 Train loss 0.02 on epoch=344
04/25/2022 17:25:25 - INFO - __main__ - Step 700 Global step 700 Train loss 0.02 on epoch=349
04/25/2022 17:25:27 - INFO - __main__ - Global step 700 Train loss 0.06 ACC 0.34375 on epoch=349
04/25/2022 17:25:29 - INFO - __main__ - Step 710 Global step 710 Train loss 0.05 on epoch=354
04/25/2022 17:25:31 - INFO - __main__ - Step 720 Global step 720 Train loss 0.04 on epoch=359
04/25/2022 17:25:34 - INFO - __main__ - Step 730 Global step 730 Train loss 0.03 on epoch=364
04/25/2022 17:25:36 - INFO - __main__ - Step 740 Global step 740 Train loss 0.04 on epoch=369
04/25/2022 17:25:39 - INFO - __main__ - Step 750 Global step 750 Train loss 0.03 on epoch=374
04/25/2022 17:25:41 - INFO - __main__ - Global step 750 Train loss 0.04 ACC 0.375 on epoch=374
04/25/2022 17:25:43 - INFO - __main__ - Step 760 Global step 760 Train loss 0.01 on epoch=379
04/25/2022 17:25:46 - INFO - __main__ - Step 770 Global step 770 Train loss 0.02 on epoch=384
04/25/2022 17:25:48 - INFO - __main__ - Step 780 Global step 780 Train loss 0.03 on epoch=389
04/25/2022 17:25:51 - INFO - __main__ - Step 790 Global step 790 Train loss 0.03 on epoch=394
04/25/2022 17:25:53 - INFO - __main__ - Step 800 Global step 800 Train loss 0.02 on epoch=399
04/25/2022 17:25:55 - INFO - __main__ - Global step 800 Train loss 0.02 ACC 0.25 on epoch=399
04/25/2022 17:25:57 - INFO - __main__ - Step 810 Global step 810 Train loss 0.02 on epoch=404
04/25/2022 17:26:00 - INFO - __main__ - Step 820 Global step 820 Train loss 0.04 on epoch=409
04/25/2022 17:26:02 - INFO - __main__ - Step 830 Global step 830 Train loss 0.05 on epoch=414
04/25/2022 17:26:05 - INFO - __main__ - Step 840 Global step 840 Train loss 0.03 on epoch=419
04/25/2022 17:26:07 - INFO - __main__ - Step 850 Global step 850 Train loss 0.05 on epoch=424
04/25/2022 17:26:09 - INFO - __main__ - Global step 850 Train loss 0.04 ACC 0.40625 on epoch=424
04/25/2022 17:26:12 - INFO - __main__ - Step 860 Global step 860 Train loss 0.03 on epoch=429
04/25/2022 17:26:14 - INFO - __main__ - Step 870 Global step 870 Train loss 0.02 on epoch=434
04/25/2022 17:26:16 - INFO - __main__ - Step 880 Global step 880 Train loss 0.02 on epoch=439
04/25/2022 17:26:19 - INFO - __main__ - Step 890 Global step 890 Train loss 0.03 on epoch=444
04/25/2022 17:26:21 - INFO - __main__ - Step 900 Global step 900 Train loss 0.04 on epoch=449
04/25/2022 17:26:23 - INFO - __main__ - Global step 900 Train loss 0.03 ACC 0.34375 on epoch=449
04/25/2022 17:26:26 - INFO - __main__ - Step 910 Global step 910 Train loss 0.03 on epoch=454
04/25/2022 17:26:28 - INFO - __main__ - Step 920 Global step 920 Train loss 0.01 on epoch=459
04/25/2022 17:26:31 - INFO - __main__ - Step 930 Global step 930 Train loss 0.02 on epoch=464
04/25/2022 17:26:33 - INFO - __main__ - Step 940 Global step 940 Train loss 0.01 on epoch=469
04/25/2022 17:26:35 - INFO - __main__ - Step 950 Global step 950 Train loss 0.01 on epoch=474
04/25/2022 17:26:37 - INFO - __main__ - Global step 950 Train loss 0.02 ACC 0.46875 on epoch=474
04/25/2022 17:26:37 - INFO - __main__ - Saving model with best ACC: 0.4375 -> 0.46875 on epoch=474, global_step=950
04/25/2022 17:26:40 - INFO - __main__ - Step 960 Global step 960 Train loss 0.01 on epoch=479
04/25/2022 17:26:42 - INFO - __main__ - Step 970 Global step 970 Train loss 0.01 on epoch=484
04/25/2022 17:26:45 - INFO - __main__ - Step 980 Global step 980 Train loss 0.02 on epoch=489
04/25/2022 17:26:47 - INFO - __main__ - Step 990 Global step 990 Train loss 0.02 on epoch=494
04/25/2022 17:26:49 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.02 on epoch=499
04/25/2022 17:26:51 - INFO - __main__ - Global step 1000 Train loss 0.02 ACC 0.375 on epoch=499
04/25/2022 17:26:53 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.02 on epoch=504
04/25/2022 17:26:56 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.02 on epoch=509
04/25/2022 17:26:58 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.04 on epoch=514
04/25/2022 17:27:00 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.02 on epoch=519
04/25/2022 17:27:03 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.01 on epoch=524
04/25/2022 17:27:05 - INFO - __main__ - Global step 1050 Train loss 0.02 ACC 0.40625 on epoch=524
04/25/2022 17:27:07 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.06 on epoch=529
04/25/2022 17:27:09 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.01 on epoch=534
04/25/2022 17:27:11 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.01 on epoch=539
04/25/2022 17:27:14 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.03 on epoch=544
04/25/2022 17:27:16 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.02 on epoch=549
04/25/2022 17:27:18 - INFO - __main__ - Global step 1100 Train loss 0.03 ACC 0.4375 on epoch=549
04/25/2022 17:27:20 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.01 on epoch=554
04/25/2022 17:27:23 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=559
04/25/2022 17:27:25 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.03 on epoch=564
04/25/2022 17:27:27 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.04 on epoch=569
04/25/2022 17:27:30 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=574
04/25/2022 17:27:32 - INFO - __main__ - Global step 1150 Train loss 0.02 ACC 0.46875 on epoch=574
04/25/2022 17:27:34 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.01 on epoch=579
04/25/2022 17:27:36 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.02 on epoch=584
04/25/2022 17:27:38 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.01 on epoch=589
04/25/2022 17:27:41 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.02 on epoch=594
04/25/2022 17:27:43 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=599
04/25/2022 17:27:45 - INFO - __main__ - Global step 1200 Train loss 0.02 ACC 0.40625 on epoch=599
04/25/2022 17:27:47 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.02 on epoch=604
04/25/2022 17:27:50 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.00 on epoch=609
04/25/2022 17:27:52 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=614
04/25/2022 17:27:54 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.02 on epoch=619
04/25/2022 17:27:56 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.02 on epoch=624
04/25/2022 17:27:58 - INFO - __main__ - Global step 1250 Train loss 0.01 ACC 0.40625 on epoch=624
04/25/2022 17:28:01 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.02 on epoch=629
04/25/2022 17:28:03 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.01 on epoch=634
04/25/2022 17:28:05 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=639
04/25/2022 17:28:08 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.02 on epoch=644
04/25/2022 17:28:10 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=649
04/25/2022 17:28:12 - INFO - __main__ - Global step 1300 Train loss 0.01 ACC 0.40625 on epoch=649
04/25/2022 17:28:14 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=654
04/25/2022 17:28:16 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.03 on epoch=659
04/25/2022 17:28:19 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.00 on epoch=664
04/25/2022 17:28:21 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=669
04/25/2022 17:28:23 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=674
04/25/2022 17:28:25 - INFO - __main__ - Global step 1350 Train loss 0.01 ACC 0.4375 on epoch=674
04/25/2022 17:28:27 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.02 on epoch=679
04/25/2022 17:28:30 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.02 on epoch=684
04/25/2022 17:28:32 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.02 on epoch=689
04/25/2022 17:28:34 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=694
04/25/2022 17:28:37 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=699
04/25/2022 17:28:39 - INFO - __main__ - Global step 1400 Train loss 0.02 ACC 0.28125 on epoch=699
04/25/2022 17:28:41 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=704
04/25/2022 17:28:43 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.01 on epoch=709
04/25/2022 17:28:45 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.00 on epoch=714
04/25/2022 17:28:48 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=719
04/25/2022 17:28:50 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=724
04/25/2022 17:28:52 - INFO - __main__ - Global step 1450 Train loss 0.01 ACC 0.375 on epoch=724
04/25/2022 17:28:54 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=729
04/25/2022 17:28:57 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=734
04/25/2022 17:28:59 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=739
04/25/2022 17:29:01 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=744
04/25/2022 17:29:03 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=749
04/25/2022 17:29:05 - INFO - __main__ - Global step 1500 Train loss 0.01 ACC 0.40625 on epoch=749
04/25/2022 17:29:08 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=754
04/25/2022 17:29:10 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.02 on epoch=759
04/25/2022 17:29:13 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=764
04/25/2022 17:29:15 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=769
04/25/2022 17:29:18 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=774
04/25/2022 17:29:20 - INFO - __main__ - Global step 1550 Train loss 0.02 ACC 0.375 on epoch=774
04/25/2022 17:29:22 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=779
04/25/2022 17:29:25 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=784
04/25/2022 17:29:27 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=789
04/25/2022 17:29:30 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=794
04/25/2022 17:29:32 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=799
04/25/2022 17:29:35 - INFO - __main__ - Global step 1600 Train loss 0.01 ACC 0.375 on epoch=799
04/25/2022 17:29:37 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=804
04/25/2022 17:29:40 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=809
04/25/2022 17:29:42 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=814
04/25/2022 17:29:45 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.03 on epoch=819
04/25/2022 17:29:47 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=824
04/25/2022 17:29:49 - INFO - __main__ - Global step 1650 Train loss 0.01 ACC 0.34375 on epoch=824
04/25/2022 17:29:52 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=829
04/25/2022 17:29:54 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=834
04/25/2022 17:29:57 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=839
04/25/2022 17:29:59 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=844
04/25/2022 17:30:02 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=849
04/25/2022 17:30:04 - INFO - __main__ - Global step 1700 Train loss 0.01 ACC 0.34375 on epoch=849
04/25/2022 17:30:06 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=854
04/25/2022 17:30:09 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=859
04/25/2022 17:30:11 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=864
04/25/2022 17:30:13 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=869
04/25/2022 17:30:16 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=874
04/25/2022 17:30:18 - INFO - __main__ - Global step 1750 Train loss 0.01 ACC 0.25 on epoch=874
04/25/2022 17:30:20 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=879
04/25/2022 17:30:23 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=884
04/25/2022 17:30:25 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=889
04/25/2022 17:30:28 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=894
04/25/2022 17:30:30 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=899
04/25/2022 17:30:33 - INFO - __main__ - Global step 1800 Train loss 0.01 ACC 0.28125 on epoch=899
04/25/2022 17:30:35 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=904
04/25/2022 17:30:38 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=909
04/25/2022 17:30:40 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=914
04/25/2022 17:30:43 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=919
04/25/2022 17:30:45 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=924
04/25/2022 17:30:48 - INFO - __main__ - Global step 1850 Train loss 0.01 ACC 0.3125 on epoch=924
04/25/2022 17:30:50 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=929
04/25/2022 17:30:52 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=934
04/25/2022 17:30:55 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=939
04/25/2022 17:30:57 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=944
04/25/2022 17:31:00 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=949
04/25/2022 17:31:02 - INFO - __main__ - Global step 1900 Train loss 0.01 ACC 0.34375 on epoch=949
04/25/2022 17:31:04 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=954
04/25/2022 17:31:07 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=959
04/25/2022 17:31:09 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=964
04/25/2022 17:31:12 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=969
04/25/2022 17:31:14 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=974
04/25/2022 17:31:16 - INFO - __main__ - Global step 1950 Train loss 0.01 ACC 0.3125 on epoch=974
04/25/2022 17:31:19 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.03 on epoch=979
04/25/2022 17:31:21 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.06 on epoch=984
04/25/2022 17:31:24 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=989
04/25/2022 17:31:26 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=994
04/25/2022 17:31:29 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.03 on epoch=999
04/25/2022 17:31:30 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 17:31:30 - INFO - __main__ - Printing 3 examples
04/25/2022 17:31:30 - INFO - __main__ -  [openbookqa] we only have diamonds because of the existence of (A) machines (B) large pressure (C) work force (D) carbonite
04/25/2022 17:31:30 - INFO - __main__ - ['large pressure']
04/25/2022 17:31:30 - INFO - __main__ -  [openbookqa] A thing which may be found at a special location for reusing materials is a (A) fresh cat litter (B) new brick house (C) rusted aluminum tray (D) old used wax
04/25/2022 17:31:30 - INFO - __main__ - ['rusted aluminum tray']
04/25/2022 17:31:30 - INFO - __main__ -  [openbookqa] If a raptor loses weight, then it will have an easier time (A) eating a goldfish cracker (B) building a small house (C) circling way up there (D) leaving home at night
04/25/2022 17:31:30 - INFO - __main__ - ['circling way up there']
04/25/2022 17:31:30 - INFO - __main__ - Tokenizing Input ...
04/25/2022 17:31:30 - INFO - __main__ - Tokenizing Output ...
04/25/2022 17:31:30 - INFO - __main__ - Loaded 32 examples from train data
04/25/2022 17:31:30 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 17:31:30 - INFO - __main__ - Printing 3 examples
04/25/2022 17:31:30 - INFO - __main__ -  [openbookqa] A tuna would prefer to consume (A) An Apple (B) beef (C) Nemo (D) dogs
04/25/2022 17:31:30 - INFO - __main__ - ['Nemo']
04/25/2022 17:31:30 - INFO - __main__ -  [openbookqa] Overeating (A) causes massive weight loss (B) causes the number on the scale to go up (C) boosts the immune system (D) causes the number on the scale to go down
04/25/2022 17:31:30 - INFO - __main__ - ['causes the number on the scale to go up']
04/25/2022 17:31:30 - INFO - __main__ -  [openbookqa] The more active an animal is (A) their water level will stay steady (B) the less H2O they need to stay hydrated (C) the more H20 they should take in (D) the less likely they are to sweat or pant
04/25/2022 17:31:30 - INFO - __main__ - ['the more H20 they should take in']
04/25/2022 17:31:30 - INFO - __main__ - Tokenizing Input ...
04/25/2022 17:31:30 - INFO - __main__ - Tokenizing Output ...
04/25/2022 17:31:30 - INFO - __main__ - Loaded 32 examples from dev data
04/25/2022 17:31:31 - INFO - __main__ - Global step 2000 Train loss 0.02 ACC 0.28125 on epoch=999
04/25/2022 17:31:31 - INFO - __main__ - save last model!
04/25/2022 17:31:31 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
04/25/2022 17:31:31 - INFO - __main__ - Start tokenizing ... 500 instances
04/25/2022 17:31:31 - INFO - __main__ - Printing 3 examples
04/25/2022 17:31:31 - INFO - __main__ -  [openbookqa] Frilled sharks and angler fish live far beneath the surface of the ocean, which is why they are known as (A) Deep sea animals (B) fish (C) Long Sea Fish (D) Far Sea Animals
04/25/2022 17:31:31 - INFO - __main__ - ['Deep sea animals']
04/25/2022 17:31:31 - INFO - __main__ -  [openbookqa] Gas can fill any container it is given, and liquid (A) is standard weight and size (B) is the opposite of variable (C) only needs a few (D) uses what it needs
04/25/2022 17:31:31 - INFO - __main__ - ['uses what it needs']
04/25/2022 17:31:31 - INFO - __main__ -  [openbookqa] When birds migrate south for the winter, they do it because (A) they are genetically called to (B) their children ask for them to (C) it is important to their happiness (D) they decide to each year
04/25/2022 17:31:31 - INFO - __main__ - ['they are genetically called to']
04/25/2022 17:31:31 - INFO - __main__ - Tokenizing Input ...
04/25/2022 17:31:31 - INFO - __main__ - Tokenizing Output ...
04/25/2022 17:31:31 - INFO - __main__ - Loaded 500 examples from test data
04/25/2022 17:31:48 - INFO - __main__ - load prompt embedding from ckpt
04/25/2022 17:31:49 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/25/2022 17:31:49 - INFO - __main__ - Starting training!
04/25/2022 17:32:03 - INFO - __main__ - Saved prediction in models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-openbookqa/openbookqa_32_13_0.3_8_predictions.txt
04/25/2022 17:32:03 - INFO - __main__ - ACC on test data: 0.2940
04/25/2022 17:32:03 - INFO - __main__ - prefix=openbookqa_32_13, lr=0.3, bsz=8, dev_performance=0.46875, test_performance=0.294
04/25/2022 17:32:03 - INFO - __main__ - Running ... prefix=openbookqa_32_13, lr=0.2, bsz=8 ...
04/25/2022 17:32:04 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 17:32:04 - INFO - __main__ - Printing 3 examples
04/25/2022 17:32:04 - INFO - __main__ -  [openbookqa] we only have diamonds because of the existence of (A) machines (B) large pressure (C) work force (D) carbonite
04/25/2022 17:32:04 - INFO - __main__ - ['large pressure']
04/25/2022 17:32:04 - INFO - __main__ -  [openbookqa] A thing which may be found at a special location for reusing materials is a (A) fresh cat litter (B) new brick house (C) rusted aluminum tray (D) old used wax
04/25/2022 17:32:04 - INFO - __main__ - ['rusted aluminum tray']
04/25/2022 17:32:04 - INFO - __main__ -  [openbookqa] If a raptor loses weight, then it will have an easier time (A) eating a goldfish cracker (B) building a small house (C) circling way up there (D) leaving home at night
04/25/2022 17:32:04 - INFO - __main__ - ['circling way up there']
04/25/2022 17:32:04 - INFO - __main__ - Tokenizing Input ...
04/25/2022 17:32:04 - INFO - __main__ - Tokenizing Output ...
04/25/2022 17:32:04 - INFO - __main__ - Loaded 32 examples from train data
04/25/2022 17:32:04 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 17:32:04 - INFO - __main__ - Printing 3 examples
04/25/2022 17:32:04 - INFO - __main__ -  [openbookqa] A tuna would prefer to consume (A) An Apple (B) beef (C) Nemo (D) dogs
04/25/2022 17:32:04 - INFO - __main__ - ['Nemo']
04/25/2022 17:32:04 - INFO - __main__ -  [openbookqa] Overeating (A) causes massive weight loss (B) causes the number on the scale to go up (C) boosts the immune system (D) causes the number on the scale to go down
04/25/2022 17:32:04 - INFO - __main__ - ['causes the number on the scale to go up']
04/25/2022 17:32:04 - INFO - __main__ -  [openbookqa] The more active an animal is (A) their water level will stay steady (B) the less H2O they need to stay hydrated (C) the more H20 they should take in (D) the less likely they are to sweat or pant
04/25/2022 17:32:04 - INFO - __main__ - ['the more H20 they should take in']
04/25/2022 17:32:04 - INFO - __main__ - Tokenizing Input ...
04/25/2022 17:32:04 - INFO - __main__ - Tokenizing Output ...
04/25/2022 17:32:04 - INFO - __main__ - Loaded 32 examples from dev data
04/25/2022 17:32:19 - INFO - __main__ - load prompt embedding from ckpt
04/25/2022 17:32:20 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/25/2022 17:32:20 - INFO - __main__ - Starting training!
04/25/2022 17:32:23 - INFO - __main__ - Step 10 Global step 10 Train loss 2.38 on epoch=4
04/25/2022 17:32:26 - INFO - __main__ - Step 20 Global step 20 Train loss 1.87 on epoch=9
04/25/2022 17:32:28 - INFO - __main__ - Step 30 Global step 30 Train loss 1.35 on epoch=14
04/25/2022 17:32:31 - INFO - __main__ - Step 40 Global step 40 Train loss 1.01 on epoch=19
04/25/2022 17:32:33 - INFO - __main__ - Step 50 Global step 50 Train loss 0.76 on epoch=24
04/25/2022 17:32:35 - INFO - __main__ - Global step 50 Train loss 1.48 ACC 0.1875 on epoch=24
04/25/2022 17:32:35 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.1875 on epoch=24, global_step=50
04/25/2022 17:32:38 - INFO - __main__ - Step 60 Global step 60 Train loss 0.79 on epoch=29
04/25/2022 17:32:40 - INFO - __main__ - Step 70 Global step 70 Train loss 0.64 on epoch=34
04/25/2022 17:32:42 - INFO - __main__ - Step 80 Global step 80 Train loss 0.56 on epoch=39
04/25/2022 17:32:45 - INFO - __main__ - Step 90 Global step 90 Train loss 0.51 on epoch=44
04/25/2022 17:32:47 - INFO - __main__ - Step 100 Global step 100 Train loss 0.48 on epoch=49
04/25/2022 17:32:49 - INFO - __main__ - Global step 100 Train loss 0.60 ACC 0.375 on epoch=49
04/25/2022 17:32:49 - INFO - __main__ - Saving model with best ACC: 0.1875 -> 0.375 on epoch=49, global_step=100
04/25/2022 17:32:51 - INFO - __main__ - Step 110 Global step 110 Train loss 0.39 on epoch=54
04/25/2022 17:32:54 - INFO - __main__ - Step 120 Global step 120 Train loss 0.42 on epoch=59
04/25/2022 17:32:56 - INFO - __main__ - Step 130 Global step 130 Train loss 0.36 on epoch=64
04/25/2022 17:32:59 - INFO - __main__ - Step 140 Global step 140 Train loss 0.36 on epoch=69
04/25/2022 17:33:01 - INFO - __main__ - Step 150 Global step 150 Train loss 0.26 on epoch=74
04/25/2022 17:33:03 - INFO - __main__ - Global step 150 Train loss 0.36 ACC 0.4375 on epoch=74
04/25/2022 17:33:03 - INFO - __main__ - Saving model with best ACC: 0.375 -> 0.4375 on epoch=74, global_step=150
04/25/2022 17:33:05 - INFO - __main__ - Step 160 Global step 160 Train loss 0.33 on epoch=79
04/25/2022 17:33:08 - INFO - __main__ - Step 170 Global step 170 Train loss 0.26 on epoch=84
04/25/2022 17:33:10 - INFO - __main__ - Step 180 Global step 180 Train loss 0.29 on epoch=89
04/25/2022 17:33:12 - INFO - __main__ - Step 190 Global step 190 Train loss 0.22 on epoch=94
04/25/2022 17:33:15 - INFO - __main__ - Step 200 Global step 200 Train loss 0.27 on epoch=99
04/25/2022 17:33:17 - INFO - __main__ - Global step 200 Train loss 0.27 ACC 0.40625 on epoch=99
04/25/2022 17:33:19 - INFO - __main__ - Step 210 Global step 210 Train loss 0.25 on epoch=104
04/25/2022 17:33:22 - INFO - __main__ - Step 220 Global step 220 Train loss 0.13 on epoch=109
04/25/2022 17:33:24 - INFO - __main__ - Step 230 Global step 230 Train loss 0.16 on epoch=114
04/25/2022 17:33:26 - INFO - __main__ - Step 240 Global step 240 Train loss 0.16 on epoch=119
04/25/2022 17:33:29 - INFO - __main__ - Step 250 Global step 250 Train loss 0.15 on epoch=124
04/25/2022 17:33:31 - INFO - __main__ - Global step 250 Train loss 0.17 ACC 0.4375 on epoch=124
04/25/2022 17:33:33 - INFO - __main__ - Step 260 Global step 260 Train loss 0.15 on epoch=129
04/25/2022 17:33:36 - INFO - __main__ - Step 270 Global step 270 Train loss 0.17 on epoch=134
04/25/2022 17:33:38 - INFO - __main__ - Step 280 Global step 280 Train loss 0.15 on epoch=139
04/25/2022 17:33:41 - INFO - __main__ - Step 290 Global step 290 Train loss 0.16 on epoch=144
04/25/2022 17:33:43 - INFO - __main__ - Step 300 Global step 300 Train loss 0.15 on epoch=149
04/25/2022 17:33:45 - INFO - __main__ - Global step 300 Train loss 0.16 ACC 0.4375 on epoch=149
04/25/2022 17:33:47 - INFO - __main__ - Step 310 Global step 310 Train loss 0.16 on epoch=154
04/25/2022 17:33:50 - INFO - __main__ - Step 320 Global step 320 Train loss 0.12 on epoch=159
04/25/2022 17:33:52 - INFO - __main__ - Step 330 Global step 330 Train loss 0.14 on epoch=164
04/25/2022 17:33:55 - INFO - __main__ - Step 340 Global step 340 Train loss 0.12 on epoch=169
04/25/2022 17:33:57 - INFO - __main__ - Step 350 Global step 350 Train loss 0.12 on epoch=174
04/25/2022 17:33:59 - INFO - __main__ - Global step 350 Train loss 0.13 ACC 0.40625 on epoch=174
04/25/2022 17:34:02 - INFO - __main__ - Step 360 Global step 360 Train loss 0.08 on epoch=179
04/25/2022 17:34:04 - INFO - __main__ - Step 370 Global step 370 Train loss 0.11 on epoch=184
04/25/2022 17:34:06 - INFO - __main__ - Step 380 Global step 380 Train loss 0.13 on epoch=189
04/25/2022 17:34:09 - INFO - __main__ - Step 390 Global step 390 Train loss 0.05 on epoch=194
04/25/2022 17:34:11 - INFO - __main__ - Step 400 Global step 400 Train loss 0.10 on epoch=199
04/25/2022 17:34:13 - INFO - __main__ - Global step 400 Train loss 0.09 ACC 0.4375 on epoch=199
04/25/2022 17:34:16 - INFO - __main__ - Step 410 Global step 410 Train loss 0.05 on epoch=204
04/25/2022 17:34:18 - INFO - __main__ - Step 420 Global step 420 Train loss 0.07 on epoch=209
04/25/2022 17:34:21 - INFO - __main__ - Step 430 Global step 430 Train loss 0.07 on epoch=214
04/25/2022 17:34:23 - INFO - __main__ - Step 440 Global step 440 Train loss 0.08 on epoch=219
04/25/2022 17:34:25 - INFO - __main__ - Step 450 Global step 450 Train loss 0.05 on epoch=224
04/25/2022 17:34:27 - INFO - __main__ - Global step 450 Train loss 0.07 ACC 0.4375 on epoch=224
04/25/2022 17:34:30 - INFO - __main__ - Step 460 Global step 460 Train loss 0.06 on epoch=229
04/25/2022 17:34:32 - INFO - __main__ - Step 470 Global step 470 Train loss 0.09 on epoch=234
04/25/2022 17:34:35 - INFO - __main__ - Step 480 Global step 480 Train loss 0.05 on epoch=239
04/25/2022 17:34:37 - INFO - __main__ - Step 490 Global step 490 Train loss 0.06 on epoch=244
04/25/2022 17:34:40 - INFO - __main__ - Step 500 Global step 500 Train loss 0.12 on epoch=249
04/25/2022 17:34:42 - INFO - __main__ - Global step 500 Train loss 0.08 ACC 0.40625 on epoch=249
04/25/2022 17:34:44 - INFO - __main__ - Step 510 Global step 510 Train loss 0.04 on epoch=254
04/25/2022 17:34:46 - INFO - __main__ - Step 520 Global step 520 Train loss 0.04 on epoch=259
04/25/2022 17:34:49 - INFO - __main__ - Step 530 Global step 530 Train loss 0.10 on epoch=264
04/25/2022 17:34:51 - INFO - __main__ - Step 540 Global step 540 Train loss 0.09 on epoch=269
04/25/2022 17:34:54 - INFO - __main__ - Step 550 Global step 550 Train loss 0.11 on epoch=274
04/25/2022 17:34:56 - INFO - __main__ - Global step 550 Train loss 0.08 ACC 0.34375 on epoch=274
04/25/2022 17:34:58 - INFO - __main__ - Step 560 Global step 560 Train loss 0.07 on epoch=279
04/25/2022 17:35:00 - INFO - __main__ - Step 570 Global step 570 Train loss 0.06 on epoch=284
04/25/2022 17:35:03 - INFO - __main__ - Step 580 Global step 580 Train loss 0.05 on epoch=289
04/25/2022 17:35:05 - INFO - __main__ - Step 590 Global step 590 Train loss 0.04 on epoch=294
04/25/2022 17:35:08 - INFO - __main__ - Step 600 Global step 600 Train loss 0.07 on epoch=299
04/25/2022 17:35:10 - INFO - __main__ - Global step 600 Train loss 0.06 ACC 0.34375 on epoch=299
04/25/2022 17:35:12 - INFO - __main__ - Step 610 Global step 610 Train loss 0.07 on epoch=304
04/25/2022 17:35:15 - INFO - __main__ - Step 620 Global step 620 Train loss 0.05 on epoch=309
04/25/2022 17:35:17 - INFO - __main__ - Step 630 Global step 630 Train loss 0.09 on epoch=314
04/25/2022 17:35:19 - INFO - __main__ - Step 640 Global step 640 Train loss 0.08 on epoch=319
04/25/2022 17:35:22 - INFO - __main__ - Step 650 Global step 650 Train loss 0.05 on epoch=324
04/25/2022 17:35:24 - INFO - __main__ - Global step 650 Train loss 0.07 ACC 0.3125 on epoch=324
04/25/2022 17:35:26 - INFO - __main__ - Step 660 Global step 660 Train loss 0.04 on epoch=329
04/25/2022 17:35:29 - INFO - __main__ - Step 670 Global step 670 Train loss 0.07 on epoch=334
04/25/2022 17:35:31 - INFO - __main__ - Step 680 Global step 680 Train loss 0.06 on epoch=339
04/25/2022 17:35:34 - INFO - __main__ - Step 690 Global step 690 Train loss 0.04 on epoch=344
04/25/2022 17:35:36 - INFO - __main__ - Step 700 Global step 700 Train loss 0.03 on epoch=349
04/25/2022 17:35:38 - INFO - __main__ - Global step 700 Train loss 0.05 ACC 0.375 on epoch=349
04/25/2022 17:35:40 - INFO - __main__ - Step 710 Global step 710 Train loss 0.06 on epoch=354
04/25/2022 17:35:43 - INFO - __main__ - Step 720 Global step 720 Train loss 0.03 on epoch=359
04/25/2022 17:35:45 - INFO - __main__ - Step 730 Global step 730 Train loss 0.02 on epoch=364
04/25/2022 17:35:48 - INFO - __main__ - Step 740 Global step 740 Train loss 0.03 on epoch=369
04/25/2022 17:35:50 - INFO - __main__ - Step 750 Global step 750 Train loss 0.02 on epoch=374
04/25/2022 17:35:52 - INFO - __main__ - Global step 750 Train loss 0.03 ACC 0.34375 on epoch=374
04/25/2022 17:35:54 - INFO - __main__ - Step 760 Global step 760 Train loss 0.05 on epoch=379
04/25/2022 17:35:57 - INFO - __main__ - Step 770 Global step 770 Train loss 0.04 on epoch=384
04/25/2022 17:35:59 - INFO - __main__ - Step 780 Global step 780 Train loss 0.04 on epoch=389
04/25/2022 17:36:02 - INFO - __main__ - Step 790 Global step 790 Train loss 0.05 on epoch=394
04/25/2022 17:36:04 - INFO - __main__ - Step 800 Global step 800 Train loss 0.04 on epoch=399
04/25/2022 17:36:06 - INFO - __main__ - Global step 800 Train loss 0.05 ACC 0.375 on epoch=399
04/25/2022 17:36:09 - INFO - __main__ - Step 810 Global step 810 Train loss 0.02 on epoch=404
04/25/2022 17:36:11 - INFO - __main__ - Step 820 Global step 820 Train loss 0.03 on epoch=409
04/25/2022 17:36:13 - INFO - __main__ - Step 830 Global step 830 Train loss 0.03 on epoch=414
04/25/2022 17:36:16 - INFO - __main__ - Step 840 Global step 840 Train loss 0.04 on epoch=419
04/25/2022 17:36:18 - INFO - __main__ - Step 850 Global step 850 Train loss 0.06 on epoch=424
04/25/2022 17:36:20 - INFO - __main__ - Global step 850 Train loss 0.03 ACC 0.34375 on epoch=424
04/25/2022 17:36:23 - INFO - __main__ - Step 860 Global step 860 Train loss 0.02 on epoch=429
04/25/2022 17:36:25 - INFO - __main__ - Step 870 Global step 870 Train loss 0.02 on epoch=434
04/25/2022 17:36:27 - INFO - __main__ - Step 880 Global step 880 Train loss 0.01 on epoch=439
04/25/2022 17:36:30 - INFO - __main__ - Step 890 Global step 890 Train loss 0.06 on epoch=444
04/25/2022 17:36:32 - INFO - __main__ - Step 900 Global step 900 Train loss 0.04 on epoch=449
04/25/2022 17:36:34 - INFO - __main__ - Global step 900 Train loss 0.03 ACC 0.40625 on epoch=449
04/25/2022 17:36:37 - INFO - __main__ - Step 910 Global step 910 Train loss 0.04 on epoch=454
04/25/2022 17:36:39 - INFO - __main__ - Step 920 Global step 920 Train loss 0.04 on epoch=459
04/25/2022 17:36:42 - INFO - __main__ - Step 930 Global step 930 Train loss 0.02 on epoch=464
04/25/2022 17:36:44 - INFO - __main__ - Step 940 Global step 940 Train loss 0.02 on epoch=469
04/25/2022 17:36:46 - INFO - __main__ - Step 950 Global step 950 Train loss 0.02 on epoch=474
04/25/2022 17:36:48 - INFO - __main__ - Global step 950 Train loss 0.03 ACC 0.4375 on epoch=474
04/25/2022 17:36:51 - INFO - __main__ - Step 960 Global step 960 Train loss 0.02 on epoch=479
04/25/2022 17:36:53 - INFO - __main__ - Step 970 Global step 970 Train loss 0.03 on epoch=484
04/25/2022 17:36:56 - INFO - __main__ - Step 980 Global step 980 Train loss 0.01 on epoch=489
04/25/2022 17:36:58 - INFO - __main__ - Step 990 Global step 990 Train loss 0.02 on epoch=494
04/25/2022 17:37:00 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.02 on epoch=499
04/25/2022 17:37:02 - INFO - __main__ - Global step 1000 Train loss 0.02 ACC 0.34375 on epoch=499
04/25/2022 17:37:04 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.02 on epoch=504
04/25/2022 17:37:07 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.01 on epoch=509
04/25/2022 17:37:09 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.01 on epoch=514
04/25/2022 17:37:12 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.01 on epoch=519
04/25/2022 17:37:14 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.03 on epoch=524
04/25/2022 17:37:16 - INFO - __main__ - Global step 1050 Train loss 0.02 ACC 0.3125 on epoch=524
04/25/2022 17:37:18 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.03 on epoch=529
04/25/2022 17:37:21 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.02 on epoch=534
04/25/2022 17:37:23 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.01 on epoch=539
04/25/2022 17:37:26 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.03 on epoch=544
04/25/2022 17:37:28 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.01 on epoch=549
04/25/2022 17:37:30 - INFO - __main__ - Global step 1100 Train loss 0.02 ACC 0.375 on epoch=549
04/25/2022 17:37:33 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.02 on epoch=554
04/25/2022 17:37:35 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.04 on epoch=559
04/25/2022 17:37:38 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.02 on epoch=564
04/25/2022 17:37:40 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.07 on epoch=569
04/25/2022 17:37:43 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.02 on epoch=574
04/25/2022 17:37:44 - INFO - __main__ - Global step 1150 Train loss 0.03 ACC 0.25 on epoch=574
04/25/2022 17:37:47 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.02 on epoch=579
04/25/2022 17:37:49 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.02 on epoch=584
04/25/2022 17:37:52 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.01 on epoch=589
04/25/2022 17:37:54 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.01 on epoch=594
04/25/2022 17:37:57 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.02 on epoch=599
04/25/2022 17:37:59 - INFO - __main__ - Global step 1200 Train loss 0.02 ACC 0.1875 on epoch=599
04/25/2022 17:38:01 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.03 on epoch=604
04/25/2022 17:38:03 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.05 on epoch=609
04/25/2022 17:38:06 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=614
04/25/2022 17:38:08 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.03 on epoch=619
04/25/2022 17:38:11 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.01 on epoch=624
04/25/2022 17:38:12 - INFO - __main__ - Global step 1250 Train loss 0.03 ACC 0.34375 on epoch=624
04/25/2022 17:38:15 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=629
04/25/2022 17:38:17 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.01 on epoch=634
04/25/2022 17:38:20 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.04 on epoch=639
04/25/2022 17:38:22 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.03 on epoch=644
04/25/2022 17:38:25 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=649
04/25/2022 17:38:27 - INFO - __main__ - Global step 1300 Train loss 0.02 ACC 0.21875 on epoch=649
04/25/2022 17:38:29 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=654
04/25/2022 17:38:31 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=659
04/25/2022 17:38:34 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=664
04/25/2022 17:38:36 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.02 on epoch=669
04/25/2022 17:38:39 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.02 on epoch=674
04/25/2022 17:38:41 - INFO - __main__ - Global step 1350 Train loss 0.01 ACC 0.34375 on epoch=674
04/25/2022 17:38:43 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=679
04/25/2022 17:38:46 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.02 on epoch=684
04/25/2022 17:38:48 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.04 on epoch=689
04/25/2022 17:38:50 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=694
04/25/2022 17:38:53 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=699
04/25/2022 17:38:55 - INFO - __main__ - Global step 1400 Train loss 0.02 ACC 0.34375 on epoch=699
04/25/2022 17:38:57 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=704
04/25/2022 17:39:00 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.01 on epoch=709
04/25/2022 17:39:02 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=714
04/25/2022 17:39:04 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=719
04/25/2022 17:39:07 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=724
04/25/2022 17:39:09 - INFO - __main__ - Global step 1450 Train loss 0.01 ACC 0.34375 on epoch=724
04/25/2022 17:39:11 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.02 on epoch=729
04/25/2022 17:39:14 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=734
04/25/2022 17:39:16 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=739
04/25/2022 17:39:19 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.02 on epoch=744
04/25/2022 17:39:21 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=749
04/25/2022 17:39:23 - INFO - __main__ - Global step 1500 Train loss 0.01 ACC 0.25 on epoch=749
04/25/2022 17:39:25 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=754
04/25/2022 17:39:28 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.04 on epoch=759
04/25/2022 17:39:30 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.02 on epoch=764
04/25/2022 17:39:33 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=769
04/25/2022 17:39:35 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=774
04/25/2022 17:39:37 - INFO - __main__ - Global step 1550 Train loss 0.02 ACC 0.3125 on epoch=774
04/25/2022 17:39:39 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=779
04/25/2022 17:39:42 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.04 on epoch=784
04/25/2022 17:39:44 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.02 on epoch=789
04/25/2022 17:39:47 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.02 on epoch=794
04/25/2022 17:39:49 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=799
04/25/2022 17:39:51 - INFO - __main__ - Global step 1600 Train loss 0.02 ACC 0.28125 on epoch=799
04/25/2022 17:39:54 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=804
04/25/2022 17:39:56 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=809
04/25/2022 17:39:58 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.02 on epoch=814
04/25/2022 17:40:01 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.04 on epoch=819
04/25/2022 17:40:03 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.04 on epoch=824
04/25/2022 17:40:05 - INFO - __main__ - Global step 1650 Train loss 0.02 ACC 0.1875 on epoch=824
04/25/2022 17:40:08 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=829
04/25/2022 17:40:10 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=834
04/25/2022 17:40:13 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=839
04/25/2022 17:40:15 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=844
04/25/2022 17:40:17 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=849
04/25/2022 17:40:19 - INFO - __main__ - Global step 1700 Train loss 0.01 ACC 0.21875 on epoch=849
04/25/2022 17:40:22 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.03 on epoch=854
04/25/2022 17:40:24 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=859
04/25/2022 17:40:27 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.03 on epoch=864
04/25/2022 17:40:29 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=869
04/25/2022 17:40:31 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=874
04/25/2022 17:40:33 - INFO - __main__ - Global step 1750 Train loss 0.02 ACC 0.34375 on epoch=874
04/25/2022 17:40:36 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=879
04/25/2022 17:40:38 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=884
04/25/2022 17:40:41 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=889
04/25/2022 17:40:43 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=894
04/25/2022 17:40:46 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=899
04/25/2022 17:40:47 - INFO - __main__ - Global step 1800 Train loss 0.01 ACC 0.3125 on epoch=899
04/25/2022 17:40:50 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=904
04/25/2022 17:40:52 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=909
04/25/2022 17:40:55 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=914
04/25/2022 17:40:57 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.06 on epoch=919
04/25/2022 17:41:00 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=924
04/25/2022 17:41:02 - INFO - __main__ - Global step 1850 Train loss 0.02 ACC 0.25 on epoch=924
04/25/2022 17:41:04 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=929
04/25/2022 17:41:07 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=934
04/25/2022 17:41:09 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=939
04/25/2022 17:41:12 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=944
04/25/2022 17:41:14 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=949
04/25/2022 17:41:16 - INFO - __main__ - Global step 1900 Train loss 0.01 ACC 0.15625 on epoch=949
04/25/2022 17:41:18 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=954
04/25/2022 17:41:21 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=959
04/25/2022 17:41:23 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=964
04/25/2022 17:41:26 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=969
04/25/2022 17:41:28 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=974
04/25/2022 17:41:30 - INFO - __main__ - Global step 1950 Train loss 0.01 ACC 0.21875 on epoch=974
04/25/2022 17:41:32 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=979
04/25/2022 17:41:35 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=984
04/25/2022 17:41:37 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=989
04/25/2022 17:41:40 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=994
04/25/2022 17:41:42 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=999
04/25/2022 17:41:44 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 17:41:44 - INFO - __main__ - Printing 3 examples
04/25/2022 17:41:44 - INFO - __main__ -  [openbookqa] a lack of illumination would result in which of these? (A) the restroom overflowing with water (B) a principal's door being locked (C) a student unable to view what he is writing (D) a teacher being unable to transport to school
04/25/2022 17:41:44 - INFO - __main__ - ['a student unable to view what he is writing']
04/25/2022 17:41:44 - INFO - __main__ -  [openbookqa] The quickness of this animal is a key change that allows it to escape attacks from feasting animals: (A) the praying mantis (B) the potato bug (C) antelope (D) the eagle
04/25/2022 17:41:44 - INFO - __main__ - ['antelope']
04/25/2022 17:41:44 - INFO - __main__ -  [openbookqa] Vegetables provide a lot of nutrients for (A) cats (B) dogs (C) humans (D) snakes
04/25/2022 17:41:44 - INFO - __main__ - ['humans']
04/25/2022 17:41:44 - INFO - __main__ - Tokenizing Input ...
04/25/2022 17:41:44 - INFO - __main__ - Tokenizing Output ...
04/25/2022 17:41:44 - INFO - __main__ - Loaded 32 examples from train data
04/25/2022 17:41:44 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 17:41:44 - INFO - __main__ - Printing 3 examples
04/25/2022 17:41:44 - INFO - __main__ -  [openbookqa] A bird eating a lizard is an example of what type of relationship? (A) symbiotic (B) producer (C) parasitic (D) predatory
04/25/2022 17:41:44 - INFO - __main__ - ['predatory']
04/25/2022 17:41:44 - INFO - __main__ -  [openbookqa] Where would you find the most sunlight? (A) England (B) Morocco (C) Sweden (D) Norway
04/25/2022 17:41:44 - INFO - __main__ - ['Morocco']
04/25/2022 17:41:44 - INFO - __main__ -  [openbookqa] Microscopes (A) make tiny atoms look smaller (B) enhance the size of amoebas for easier viewing (C) make magnifying things much more difficult (D) make huge samples look minuscule
04/25/2022 17:41:44 - INFO - __main__ - ['enhance the size of amoebas for easier viewing']
04/25/2022 17:41:44 - INFO - __main__ - Tokenizing Input ...
04/25/2022 17:41:44 - INFO - __main__ - Tokenizing Output ...
04/25/2022 17:41:44 - INFO - __main__ - Loaded 32 examples from dev data
04/25/2022 17:41:44 - INFO - __main__ - Global step 2000 Train loss 0.01 ACC 0.15625 on epoch=999
04/25/2022 17:41:44 - INFO - __main__ - save last model!
04/25/2022 17:41:44 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
04/25/2022 17:41:44 - INFO - __main__ - Start tokenizing ... 500 instances
04/25/2022 17:41:44 - INFO - __main__ - Printing 3 examples
04/25/2022 17:41:44 - INFO - __main__ -  [openbookqa] Frilled sharks and angler fish live far beneath the surface of the ocean, which is why they are known as (A) Deep sea animals (B) fish (C) Long Sea Fish (D) Far Sea Animals
04/25/2022 17:41:44 - INFO - __main__ - ['Deep sea animals']
04/25/2022 17:41:44 - INFO - __main__ -  [openbookqa] Gas can fill any container it is given, and liquid (A) is standard weight and size (B) is the opposite of variable (C) only needs a few (D) uses what it needs
04/25/2022 17:41:44 - INFO - __main__ - ['uses what it needs']
04/25/2022 17:41:44 - INFO - __main__ -  [openbookqa] When birds migrate south for the winter, they do it because (A) they are genetically called to (B) their children ask for them to (C) it is important to their happiness (D) they decide to each year
04/25/2022 17:41:44 - INFO - __main__ - ['they are genetically called to']
04/25/2022 17:41:44 - INFO - __main__ - Tokenizing Input ...
04/25/2022 17:41:44 - INFO - __main__ - Tokenizing Output ...
04/25/2022 17:41:45 - INFO - __main__ - Loaded 500 examples from test data
04/25/2022 17:41:59 - INFO - __main__ - load prompt embedding from ckpt
04/25/2022 17:42:00 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/25/2022 17:42:00 - INFO - __main__ - Starting training!
04/25/2022 17:42:17 - INFO - __main__ - Saved prediction in models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-openbookqa/openbookqa_32_13_0.2_8_predictions.txt
04/25/2022 17:42:17 - INFO - __main__ - ACC on test data: 0.2540
04/25/2022 17:42:19 - INFO - __main__ - prefix=openbookqa_32_13, lr=0.2, bsz=8, dev_performance=0.4375, test_performance=0.254
04/25/2022 17:42:19 - INFO - __main__ - Running ... prefix=openbookqa_32_21, lr=0.5, bsz=8 ...
04/25/2022 17:42:19 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 17:42:19 - INFO - __main__ - Printing 3 examples
04/25/2022 17:42:19 - INFO - __main__ -  [openbookqa] a lack of illumination would result in which of these? (A) the restroom overflowing with water (B) a principal's door being locked (C) a student unable to view what he is writing (D) a teacher being unable to transport to school
04/25/2022 17:42:19 - INFO - __main__ - ['a student unable to view what he is writing']
04/25/2022 17:42:19 - INFO - __main__ -  [openbookqa] The quickness of this animal is a key change that allows it to escape attacks from feasting animals: (A) the praying mantis (B) the potato bug (C) antelope (D) the eagle
04/25/2022 17:42:19 - INFO - __main__ - ['antelope']
04/25/2022 17:42:19 - INFO - __main__ -  [openbookqa] Vegetables provide a lot of nutrients for (A) cats (B) dogs (C) humans (D) snakes
04/25/2022 17:42:19 - INFO - __main__ - ['humans']
04/25/2022 17:42:19 - INFO - __main__ - Tokenizing Input ...
04/25/2022 17:42:20 - INFO - __main__ - Tokenizing Output ...
04/25/2022 17:42:20 - INFO - __main__ - Loaded 32 examples from train data
04/25/2022 17:42:20 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 17:42:20 - INFO - __main__ - Printing 3 examples
04/25/2022 17:42:20 - INFO - __main__ -  [openbookqa] A bird eating a lizard is an example of what type of relationship? (A) symbiotic (B) producer (C) parasitic (D) predatory
04/25/2022 17:42:20 - INFO - __main__ - ['predatory']
04/25/2022 17:42:20 - INFO - __main__ -  [openbookqa] Where would you find the most sunlight? (A) England (B) Morocco (C) Sweden (D) Norway
04/25/2022 17:42:20 - INFO - __main__ - ['Morocco']
04/25/2022 17:42:20 - INFO - __main__ -  [openbookqa] Microscopes (A) make tiny atoms look smaller (B) enhance the size of amoebas for easier viewing (C) make magnifying things much more difficult (D) make huge samples look minuscule
04/25/2022 17:42:20 - INFO - __main__ - ['enhance the size of amoebas for easier viewing']
04/25/2022 17:42:20 - INFO - __main__ - Tokenizing Input ...
04/25/2022 17:42:20 - INFO - __main__ - Tokenizing Output ...
04/25/2022 17:42:20 - INFO - __main__ - Loaded 32 examples from dev data
04/25/2022 17:42:35 - INFO - __main__ - load prompt embedding from ckpt
04/25/2022 17:42:35 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/25/2022 17:42:35 - INFO - __main__ - Starting training!
04/25/2022 17:42:39 - INFO - __main__ - Step 10 Global step 10 Train loss 1.72 on epoch=4
04/25/2022 17:42:41 - INFO - __main__ - Step 20 Global step 20 Train loss 1.19 on epoch=9
04/25/2022 17:42:43 - INFO - __main__ - Step 30 Global step 30 Train loss 0.68 on epoch=14
04/25/2022 17:42:46 - INFO - __main__ - Step 40 Global step 40 Train loss 0.53 on epoch=19
04/25/2022 17:42:48 - INFO - __main__ - Step 50 Global step 50 Train loss 0.72 on epoch=24
04/25/2022 17:42:50 - INFO - __main__ - Global step 50 Train loss 0.97 ACC 0.21875 on epoch=24
04/25/2022 17:42:51 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.21875 on epoch=24, global_step=50
04/25/2022 17:42:53 - INFO - __main__ - Step 60 Global step 60 Train loss 1.30 on epoch=29
04/25/2022 17:42:55 - INFO - __main__ - Step 70 Global step 70 Train loss 4.13 on epoch=34
04/25/2022 17:42:58 - INFO - __main__ - Step 80 Global step 80 Train loss 3.12 on epoch=39
04/25/2022 17:43:00 - INFO - __main__ - Step 90 Global step 90 Train loss 2.15 on epoch=44
04/25/2022 17:43:03 - INFO - __main__ - Step 100 Global step 100 Train loss 1.73 on epoch=49
04/25/2022 17:43:05 - INFO - __main__ - Global step 100 Train loss 2.49 ACC 0.09375 on epoch=49
04/25/2022 17:43:08 - INFO - __main__ - Step 110 Global step 110 Train loss 0.98 on epoch=54
04/25/2022 17:43:10 - INFO - __main__ - Step 120 Global step 120 Train loss 0.93 on epoch=59
04/25/2022 17:43:13 - INFO - __main__ - Step 130 Global step 130 Train loss 0.77 on epoch=64
04/25/2022 17:43:15 - INFO - __main__ - Step 140 Global step 140 Train loss 0.75 on epoch=69
04/25/2022 17:43:18 - INFO - __main__ - Step 150 Global step 150 Train loss 0.78 on epoch=74
04/25/2022 17:43:20 - INFO - __main__ - Global step 150 Train loss 0.84 ACC 0.28125 on epoch=74
04/25/2022 17:43:20 - INFO - __main__ - Saving model with best ACC: 0.21875 -> 0.28125 on epoch=74, global_step=150
04/25/2022 17:43:23 - INFO - __main__ - Step 160 Global step 160 Train loss 0.62 on epoch=79
04/25/2022 17:43:25 - INFO - __main__ - Step 170 Global step 170 Train loss 0.58 on epoch=84
04/25/2022 17:43:28 - INFO - __main__ - Step 180 Global step 180 Train loss 0.64 on epoch=89
04/25/2022 17:43:30 - INFO - __main__ - Step 190 Global step 190 Train loss 0.50 on epoch=94
04/25/2022 17:43:32 - INFO - __main__ - Step 200 Global step 200 Train loss 0.47 on epoch=99
04/25/2022 17:43:35 - INFO - __main__ - Global step 200 Train loss 0.56 ACC 0.09375 on epoch=99
04/25/2022 17:43:37 - INFO - __main__ - Step 210 Global step 210 Train loss 0.47 on epoch=104
04/25/2022 17:43:40 - INFO - __main__ - Step 220 Global step 220 Train loss 0.55 on epoch=109
04/25/2022 17:43:42 - INFO - __main__ - Step 230 Global step 230 Train loss 0.47 on epoch=114
04/25/2022 17:43:44 - INFO - __main__ - Step 240 Global step 240 Train loss 0.48 on epoch=119
04/25/2022 17:43:47 - INFO - __main__ - Step 250 Global step 250 Train loss 0.45 on epoch=124
04/25/2022 17:43:49 - INFO - __main__ - Global step 250 Train loss 0.48 ACC 0.25 on epoch=124
04/25/2022 17:43:52 - INFO - __main__ - Step 260 Global step 260 Train loss 0.45 on epoch=129
04/25/2022 17:43:54 - INFO - __main__ - Step 270 Global step 270 Train loss 0.40 on epoch=134
04/25/2022 17:43:57 - INFO - __main__ - Step 280 Global step 280 Train loss 0.40 on epoch=139
04/25/2022 17:43:59 - INFO - __main__ - Step 290 Global step 290 Train loss 0.34 on epoch=144
04/25/2022 17:44:02 - INFO - __main__ - Step 300 Global step 300 Train loss 0.40 on epoch=149
04/25/2022 17:44:04 - INFO - __main__ - Global step 300 Train loss 0.40 ACC 0.21875 on epoch=149
04/25/2022 17:44:06 - INFO - __main__ - Step 310 Global step 310 Train loss 0.32 on epoch=154
04/25/2022 17:44:09 - INFO - __main__ - Step 320 Global step 320 Train loss 0.40 on epoch=159
04/25/2022 17:44:11 - INFO - __main__ - Step 330 Global step 330 Train loss 0.41 on epoch=164
04/25/2022 17:44:14 - INFO - __main__ - Step 340 Global step 340 Train loss 0.39 on epoch=169
04/25/2022 17:44:16 - INFO - __main__ - Step 350 Global step 350 Train loss 0.40 on epoch=174
04/25/2022 17:44:19 - INFO - __main__ - Global step 350 Train loss 0.38 ACC 0.25 on epoch=174
04/25/2022 17:44:21 - INFO - __main__ - Step 360 Global step 360 Train loss 0.33 on epoch=179
04/25/2022 17:44:24 - INFO - __main__ - Step 370 Global step 370 Train loss 0.29 on epoch=184
04/25/2022 17:44:26 - INFO - __main__ - Step 380 Global step 380 Train loss 0.37 on epoch=189
04/25/2022 17:44:29 - INFO - __main__ - Step 390 Global step 390 Train loss 0.41 on epoch=194
04/25/2022 17:44:31 - INFO - __main__ - Step 400 Global step 400 Train loss 0.36 on epoch=199
04/25/2022 17:44:33 - INFO - __main__ - Global step 400 Train loss 0.35 ACC 0.1875 on epoch=199
04/25/2022 17:44:35 - INFO - __main__ - Step 410 Global step 410 Train loss 0.34 on epoch=204
04/25/2022 17:44:38 - INFO - __main__ - Step 420 Global step 420 Train loss 0.41 on epoch=209
04/25/2022 17:44:40 - INFO - __main__ - Step 430 Global step 430 Train loss 1.72 on epoch=214
04/25/2022 17:44:43 - INFO - __main__ - Step 440 Global step 440 Train loss 0.48 on epoch=219
04/25/2022 17:44:45 - INFO - __main__ - Step 450 Global step 450 Train loss 0.78 on epoch=224
04/25/2022 17:44:47 - INFO - __main__ - Global step 450 Train loss 0.75 ACC 0.0625 on epoch=224
04/25/2022 17:44:49 - INFO - __main__ - Step 460 Global step 460 Train loss 0.44 on epoch=229
04/25/2022 17:44:52 - INFO - __main__ - Step 470 Global step 470 Train loss 0.43 on epoch=234
04/25/2022 17:44:54 - INFO - __main__ - Step 480 Global step 480 Train loss 2.05 on epoch=239
04/25/2022 17:44:57 - INFO - __main__ - Step 490 Global step 490 Train loss 4.24 on epoch=244
04/25/2022 17:44:59 - INFO - __main__ - Step 500 Global step 500 Train loss 0.86 on epoch=249
04/25/2022 17:45:01 - INFO - __main__ - Global step 500 Train loss 1.60 ACC 0.15625 on epoch=249
04/25/2022 17:45:03 - INFO - __main__ - Step 510 Global step 510 Train loss 0.73 on epoch=254
04/25/2022 17:45:06 - INFO - __main__ - Step 520 Global step 520 Train loss 1.27 on epoch=259
04/25/2022 17:45:08 - INFO - __main__ - Step 530 Global step 530 Train loss 0.98 on epoch=264
04/25/2022 17:45:10 - INFO - __main__ - Step 540 Global step 540 Train loss 0.81 on epoch=269
04/25/2022 17:45:13 - INFO - __main__ - Step 550 Global step 550 Train loss 0.66 on epoch=274
04/25/2022 17:45:14 - INFO - __main__ - Global step 550 Train loss 0.89 ACC 0.15625 on epoch=274
04/25/2022 17:45:17 - INFO - __main__ - Step 560 Global step 560 Train loss 0.65 on epoch=279
04/25/2022 17:45:19 - INFO - __main__ - Step 570 Global step 570 Train loss 0.62 on epoch=284
04/25/2022 17:45:22 - INFO - __main__ - Step 580 Global step 580 Train loss 0.57 on epoch=289
04/25/2022 17:45:24 - INFO - __main__ - Step 590 Global step 590 Train loss 0.53 on epoch=294
04/25/2022 17:45:27 - INFO - __main__ - Step 600 Global step 600 Train loss 0.49 on epoch=299
04/25/2022 17:45:28 - INFO - __main__ - Global step 600 Train loss 0.57 ACC 0.15625 on epoch=299
04/25/2022 17:45:31 - INFO - __main__ - Step 610 Global step 610 Train loss 0.50 on epoch=304
04/25/2022 17:45:33 - INFO - __main__ - Step 620 Global step 620 Train loss 0.43 on epoch=309
04/25/2022 17:45:36 - INFO - __main__ - Step 630 Global step 630 Train loss 0.42 on epoch=314
04/25/2022 17:45:38 - INFO - __main__ - Step 640 Global step 640 Train loss 0.36 on epoch=319
04/25/2022 17:45:41 - INFO - __main__ - Step 650 Global step 650 Train loss 0.37 on epoch=324
04/25/2022 17:45:42 - INFO - __main__ - Global step 650 Train loss 0.42 ACC 0.1875 on epoch=324
04/25/2022 17:45:45 - INFO - __main__ - Step 660 Global step 660 Train loss 0.44 on epoch=329
04/25/2022 17:45:47 - INFO - __main__ - Step 670 Global step 670 Train loss 0.41 on epoch=334
04/25/2022 17:45:50 - INFO - __main__ - Step 680 Global step 680 Train loss 0.35 on epoch=339
04/25/2022 17:45:52 - INFO - __main__ - Step 690 Global step 690 Train loss 0.34 on epoch=344
04/25/2022 17:45:55 - INFO - __main__ - Step 700 Global step 700 Train loss 0.34 on epoch=349
04/25/2022 17:45:56 - INFO - __main__ - Global step 700 Train loss 0.37 ACC 0.1875 on epoch=349
04/25/2022 17:45:59 - INFO - __main__ - Step 710 Global step 710 Train loss 0.43 on epoch=354
04/25/2022 17:46:01 - INFO - __main__ - Step 720 Global step 720 Train loss 0.38 on epoch=359
04/25/2022 17:46:04 - INFO - __main__ - Step 730 Global step 730 Train loss 0.34 on epoch=364
04/25/2022 17:46:06 - INFO - __main__ - Step 740 Global step 740 Train loss 0.33 on epoch=369
04/25/2022 17:46:09 - INFO - __main__ - Step 750 Global step 750 Train loss 0.36 on epoch=374
04/25/2022 17:46:10 - INFO - __main__ - Global step 750 Train loss 0.37 ACC 0.1875 on epoch=374
04/25/2022 17:46:13 - INFO - __main__ - Step 760 Global step 760 Train loss 0.32 on epoch=379
04/25/2022 17:46:15 - INFO - __main__ - Step 770 Global step 770 Train loss 0.37 on epoch=384
04/25/2022 17:46:18 - INFO - __main__ - Step 780 Global step 780 Train loss 0.33 on epoch=389
04/25/2022 17:46:20 - INFO - __main__ - Step 790 Global step 790 Train loss 0.34 on epoch=394
04/25/2022 17:46:23 - INFO - __main__ - Step 800 Global step 800 Train loss 0.29 on epoch=399
04/25/2022 17:46:24 - INFO - __main__ - Global step 800 Train loss 0.33 ACC 0.15625 on epoch=399
04/25/2022 17:46:27 - INFO - __main__ - Step 810 Global step 810 Train loss 0.38 on epoch=404
04/25/2022 17:46:29 - INFO - __main__ - Step 820 Global step 820 Train loss 0.32 on epoch=409
04/25/2022 17:46:32 - INFO - __main__ - Step 830 Global step 830 Train loss 0.29 on epoch=414
04/25/2022 17:46:34 - INFO - __main__ - Step 840 Global step 840 Train loss 0.25 on epoch=419
04/25/2022 17:46:36 - INFO - __main__ - Step 850 Global step 850 Train loss 0.33 on epoch=424
04/25/2022 17:46:39 - INFO - __main__ - Global step 850 Train loss 0.31 ACC 0.1875 on epoch=424
04/25/2022 17:46:41 - INFO - __main__ - Step 860 Global step 860 Train loss 0.31 on epoch=429
04/25/2022 17:46:43 - INFO - __main__ - Step 870 Global step 870 Train loss 0.35 on epoch=434
04/25/2022 17:46:46 - INFO - __main__ - Step 880 Global step 880 Train loss 0.23 on epoch=439
04/25/2022 17:46:48 - INFO - __main__ - Step 890 Global step 890 Train loss 0.33 on epoch=444
04/25/2022 17:46:51 - INFO - __main__ - Step 900 Global step 900 Train loss 0.30 on epoch=449
04/25/2022 17:46:53 - INFO - __main__ - Global step 900 Train loss 0.30 ACC 0.1875 on epoch=449
04/25/2022 17:46:55 - INFO - __main__ - Step 910 Global step 910 Train loss 0.27 on epoch=454
04/25/2022 17:46:58 - INFO - __main__ - Step 920 Global step 920 Train loss 0.30 on epoch=459
04/25/2022 17:47:00 - INFO - __main__ - Step 930 Global step 930 Train loss 0.31 on epoch=464
04/25/2022 17:47:03 - INFO - __main__ - Step 940 Global step 940 Train loss 0.41 on epoch=469
04/25/2022 17:47:05 - INFO - __main__ - Step 950 Global step 950 Train loss 0.35 on epoch=474
04/25/2022 17:47:07 - INFO - __main__ - Global step 950 Train loss 0.33 ACC 0.1875 on epoch=474
04/25/2022 17:47:09 - INFO - __main__ - Step 960 Global step 960 Train loss 0.33 on epoch=479
04/25/2022 17:47:12 - INFO - __main__ - Step 970 Global step 970 Train loss 0.28 on epoch=484
04/25/2022 17:47:14 - INFO - __main__ - Step 980 Global step 980 Train loss 0.31 on epoch=489
04/25/2022 17:47:17 - INFO - __main__ - Step 990 Global step 990 Train loss 0.35 on epoch=494
04/25/2022 17:47:19 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.27 on epoch=499
04/25/2022 17:47:21 - INFO - __main__ - Global step 1000 Train loss 0.31 ACC 0.1875 on epoch=499
04/25/2022 17:47:24 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.42 on epoch=504
04/25/2022 17:47:26 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.39 on epoch=509
04/25/2022 17:47:29 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.27 on epoch=514
04/25/2022 17:47:31 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.28 on epoch=519
04/25/2022 17:47:34 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.26 on epoch=524
04/25/2022 17:47:35 - INFO - __main__ - Global step 1050 Train loss 0.32 ACC 0.1875 on epoch=524
04/25/2022 17:47:38 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.28 on epoch=529
04/25/2022 17:47:40 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.27 on epoch=534
04/25/2022 17:47:43 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.18 on epoch=539
04/25/2022 17:47:45 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.27 on epoch=544
04/25/2022 17:47:47 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.19 on epoch=549
04/25/2022 17:47:49 - INFO - __main__ - Global step 1100 Train loss 0.24 ACC 0.15625 on epoch=549
04/25/2022 17:47:52 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.13 on epoch=554
04/25/2022 17:47:54 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.22 on epoch=559
04/25/2022 17:47:57 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.21 on epoch=564
04/25/2022 17:47:59 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.18 on epoch=569
04/25/2022 17:48:01 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.27 on epoch=574
04/25/2022 17:48:03 - INFO - __main__ - Global step 1150 Train loss 0.20 ACC 0.15625 on epoch=574
04/25/2022 17:48:06 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.22 on epoch=579
04/25/2022 17:48:08 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.21 on epoch=584
04/25/2022 17:48:11 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.22 on epoch=589
04/25/2022 17:48:13 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.26 on epoch=594
04/25/2022 17:48:16 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.21 on epoch=599
04/25/2022 17:48:17 - INFO - __main__ - Global step 1200 Train loss 0.22 ACC 0.15625 on epoch=599
04/25/2022 17:48:20 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.20 on epoch=604
04/25/2022 17:48:22 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.31 on epoch=609
04/25/2022 17:48:25 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.22 on epoch=614
04/25/2022 17:48:27 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.16 on epoch=619
04/25/2022 17:48:30 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.17 on epoch=624
04/25/2022 17:48:32 - INFO - __main__ - Global step 1250 Train loss 0.21 ACC 0.15625 on epoch=624
04/25/2022 17:48:34 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.20 on epoch=629
04/25/2022 17:48:37 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.16 on epoch=634
04/25/2022 17:48:39 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.20 on epoch=639
04/25/2022 17:48:41 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.17 on epoch=644
04/25/2022 17:48:44 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.16 on epoch=649
04/25/2022 17:48:46 - INFO - __main__ - Global step 1300 Train loss 0.18 ACC 0.15625 on epoch=649
04/25/2022 17:48:49 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.18 on epoch=654
04/25/2022 17:48:51 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.19 on epoch=659
04/25/2022 17:48:54 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.15 on epoch=664
04/25/2022 17:48:56 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.15 on epoch=669
04/25/2022 17:48:59 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.16 on epoch=674
04/25/2022 17:49:01 - INFO - __main__ - Global step 1350 Train loss 0.17 ACC 0.15625 on epoch=674
04/25/2022 17:49:03 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.21 on epoch=679
04/25/2022 17:49:06 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.17 on epoch=684
04/25/2022 17:49:08 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.15 on epoch=689
04/25/2022 17:49:11 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.20 on epoch=694
04/25/2022 17:49:13 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.14 on epoch=699
04/25/2022 17:49:15 - INFO - __main__ - Global step 1400 Train loss 0.17 ACC 0.1875 on epoch=699
04/25/2022 17:49:18 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.15 on epoch=704
04/25/2022 17:49:20 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.16 on epoch=709
04/25/2022 17:49:23 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.13 on epoch=714
04/25/2022 17:49:25 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.22 on epoch=719
04/25/2022 17:49:28 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.17 on epoch=724
04/25/2022 17:49:30 - INFO - __main__ - Global step 1450 Train loss 0.16 ACC 0.1875 on epoch=724
04/25/2022 17:49:33 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.15 on epoch=729
04/25/2022 17:49:35 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.15 on epoch=734
04/25/2022 17:49:38 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.15 on epoch=739
04/25/2022 17:49:40 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.17 on epoch=744
04/25/2022 17:49:43 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.15 on epoch=749
04/25/2022 17:49:45 - INFO - __main__ - Global step 1500 Train loss 0.15 ACC 0.1875 on epoch=749
04/25/2022 17:49:48 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.15 on epoch=754
04/25/2022 17:49:50 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.15 on epoch=759
04/25/2022 17:49:53 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.15 on epoch=764
04/25/2022 17:49:55 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.14 on epoch=769
04/25/2022 17:49:58 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.17 on epoch=774
04/25/2022 17:50:00 - INFO - __main__ - Global step 1550 Train loss 0.15 ACC 0.15625 on epoch=774
04/25/2022 17:50:02 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.11 on epoch=779
04/25/2022 17:50:05 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.15 on epoch=784
04/25/2022 17:50:07 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.16 on epoch=789
04/25/2022 17:50:10 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.12 on epoch=794
04/25/2022 17:50:12 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.10 on epoch=799
04/25/2022 17:50:14 - INFO - __main__ - Global step 1600 Train loss 0.13 ACC 0.15625 on epoch=799
04/25/2022 17:50:17 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.15 on epoch=804
04/25/2022 17:50:19 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.14 on epoch=809
04/25/2022 17:50:22 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.12 on epoch=814
04/25/2022 17:50:24 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.13 on epoch=819
04/25/2022 17:50:27 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.12 on epoch=824
04/25/2022 17:50:29 - INFO - __main__ - Global step 1650 Train loss 0.13 ACC 0.1875 on epoch=824
04/25/2022 17:50:31 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.15 on epoch=829
04/25/2022 17:50:34 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.13 on epoch=834
04/25/2022 17:50:37 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.09 on epoch=839
04/25/2022 17:50:39 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.12 on epoch=844
04/25/2022 17:50:41 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.13 on epoch=849
04/25/2022 17:50:44 - INFO - __main__ - Global step 1700 Train loss 0.13 ACC 0.1875 on epoch=849
04/25/2022 17:50:46 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.08 on epoch=854
04/25/2022 17:50:49 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.14 on epoch=859
04/25/2022 17:50:51 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.11 on epoch=864
04/25/2022 17:50:54 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.12 on epoch=869
04/25/2022 17:50:56 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.09 on epoch=874
04/25/2022 17:50:59 - INFO - __main__ - Global step 1750 Train loss 0.11 ACC 0.25 on epoch=874
04/25/2022 17:51:01 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.10 on epoch=879
04/25/2022 17:51:04 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.07 on epoch=884
04/25/2022 17:51:06 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.09 on epoch=889
04/25/2022 17:51:09 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.10 on epoch=894
04/25/2022 17:51:11 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.11 on epoch=899
04/25/2022 17:51:13 - INFO - __main__ - Global step 1800 Train loss 0.09 ACC 0.1875 on epoch=899
04/25/2022 17:51:16 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.13 on epoch=904
04/25/2022 17:51:18 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.15 on epoch=909
04/25/2022 17:51:21 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.09 on epoch=914
04/25/2022 17:51:23 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.08 on epoch=919
04/25/2022 17:51:26 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.07 on epoch=924
04/25/2022 17:51:28 - INFO - __main__ - Global step 1850 Train loss 0.10 ACC 0.25 on epoch=924
04/25/2022 17:51:30 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.12 on epoch=929
04/25/2022 17:51:33 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.11 on epoch=934
04/25/2022 17:51:35 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.10 on epoch=939
04/25/2022 17:51:38 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.08 on epoch=944
04/25/2022 17:51:40 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.09 on epoch=949
04/25/2022 17:51:43 - INFO - __main__ - Global step 1900 Train loss 0.10 ACC 0.28125 on epoch=949
04/25/2022 17:51:45 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.06 on epoch=954
04/25/2022 17:51:48 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.08 on epoch=959
04/25/2022 17:51:50 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.07 on epoch=964
04/25/2022 17:51:53 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.11 on epoch=969
04/25/2022 17:51:55 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.06 on epoch=974
04/25/2022 17:51:57 - INFO - __main__ - Global step 1950 Train loss 0.08 ACC 0.28125 on epoch=974
04/25/2022 17:51:59 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.07 on epoch=979
04/25/2022 17:52:02 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.06 on epoch=984
04/25/2022 17:52:05 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.07 on epoch=989
04/25/2022 17:52:07 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.08 on epoch=994
04/25/2022 17:52:10 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.09 on epoch=999
04/25/2022 17:52:11 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 17:52:11 - INFO - __main__ - Printing 3 examples
04/25/2022 17:52:11 - INFO - __main__ -  [openbookqa] a lack of illumination would result in which of these? (A) the restroom overflowing with water (B) a principal's door being locked (C) a student unable to view what he is writing (D) a teacher being unable to transport to school
04/25/2022 17:52:11 - INFO - __main__ - ['a student unable to view what he is writing']
04/25/2022 17:52:11 - INFO - __main__ -  [openbookqa] The quickness of this animal is a key change that allows it to escape attacks from feasting animals: (A) the praying mantis (B) the potato bug (C) antelope (D) the eagle
04/25/2022 17:52:11 - INFO - __main__ - ['antelope']
04/25/2022 17:52:11 - INFO - __main__ -  [openbookqa] Vegetables provide a lot of nutrients for (A) cats (B) dogs (C) humans (D) snakes
04/25/2022 17:52:11 - INFO - __main__ - ['humans']
04/25/2022 17:52:11 - INFO - __main__ - Tokenizing Input ...
04/25/2022 17:52:11 - INFO - __main__ - Tokenizing Output ...
04/25/2022 17:52:11 - INFO - __main__ - Loaded 32 examples from train data
04/25/2022 17:52:11 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 17:52:11 - INFO - __main__ - Printing 3 examples
04/25/2022 17:52:11 - INFO - __main__ -  [openbookqa] A bird eating a lizard is an example of what type of relationship? (A) symbiotic (B) producer (C) parasitic (D) predatory
04/25/2022 17:52:11 - INFO - __main__ - ['predatory']
04/25/2022 17:52:11 - INFO - __main__ -  [openbookqa] Where would you find the most sunlight? (A) England (B) Morocco (C) Sweden (D) Norway
04/25/2022 17:52:11 - INFO - __main__ - ['Morocco']
04/25/2022 17:52:11 - INFO - __main__ -  [openbookqa] Microscopes (A) make tiny atoms look smaller (B) enhance the size of amoebas for easier viewing (C) make magnifying things much more difficult (D) make huge samples look minuscule
04/25/2022 17:52:11 - INFO - __main__ - ['enhance the size of amoebas for easier viewing']
04/25/2022 17:52:11 - INFO - __main__ - Tokenizing Input ...
04/25/2022 17:52:11 - INFO - __main__ - Tokenizing Output ...
04/25/2022 17:52:11 - INFO - __main__ - Loaded 32 examples from dev data
04/25/2022 17:52:12 - INFO - __main__ - Global step 2000 Train loss 0.07 ACC 0.21875 on epoch=999
04/25/2022 17:52:12 - INFO - __main__ - save last model!
04/25/2022 17:52:12 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
04/25/2022 17:52:12 - INFO - __main__ - Start tokenizing ... 500 instances
04/25/2022 17:52:12 - INFO - __main__ - Printing 3 examples
04/25/2022 17:52:12 - INFO - __main__ -  [openbookqa] Frilled sharks and angler fish live far beneath the surface of the ocean, which is why they are known as (A) Deep sea animals (B) fish (C) Long Sea Fish (D) Far Sea Animals
04/25/2022 17:52:12 - INFO - __main__ - ['Deep sea animals']
04/25/2022 17:52:12 - INFO - __main__ -  [openbookqa] Gas can fill any container it is given, and liquid (A) is standard weight and size (B) is the opposite of variable (C) only needs a few (D) uses what it needs
04/25/2022 17:52:12 - INFO - __main__ - ['uses what it needs']
04/25/2022 17:52:12 - INFO - __main__ -  [openbookqa] When birds migrate south for the winter, they do it because (A) they are genetically called to (B) their children ask for them to (C) it is important to their happiness (D) they decide to each year
04/25/2022 17:52:12 - INFO - __main__ - ['they are genetically called to']
04/25/2022 17:52:12 - INFO - __main__ - Tokenizing Input ...
04/25/2022 17:52:12 - INFO - __main__ - Tokenizing Output ...
04/25/2022 17:52:13 - INFO - __main__ - Loaded 500 examples from test data
04/25/2022 17:52:26 - INFO - __main__ - load prompt embedding from ckpt
04/25/2022 17:52:27 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/25/2022 17:52:27 - INFO - __main__ - Starting training!
04/25/2022 17:52:43 - INFO - __main__ - Saved prediction in models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-openbookqa/openbookqa_32_21_0.5_8_predictions.txt
04/25/2022 17:52:43 - INFO - __main__ - ACC on test data: 0.2400
04/25/2022 17:52:44 - INFO - __main__ - prefix=openbookqa_32_21, lr=0.5, bsz=8, dev_performance=0.28125, test_performance=0.24
04/25/2022 17:52:44 - INFO - __main__ - Running ... prefix=openbookqa_32_21, lr=0.4, bsz=8 ...
04/25/2022 17:52:45 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 17:52:45 - INFO - __main__ - Printing 3 examples
04/25/2022 17:52:45 - INFO - __main__ -  [openbookqa] a lack of illumination would result in which of these? (A) the restroom overflowing with water (B) a principal's door being locked (C) a student unable to view what he is writing (D) a teacher being unable to transport to school
04/25/2022 17:52:45 - INFO - __main__ - ['a student unable to view what he is writing']
04/25/2022 17:52:45 - INFO - __main__ -  [openbookqa] The quickness of this animal is a key change that allows it to escape attacks from feasting animals: (A) the praying mantis (B) the potato bug (C) antelope (D) the eagle
04/25/2022 17:52:45 - INFO - __main__ - ['antelope']
04/25/2022 17:52:45 - INFO - __main__ -  [openbookqa] Vegetables provide a lot of nutrients for (A) cats (B) dogs (C) humans (D) snakes
04/25/2022 17:52:45 - INFO - __main__ - ['humans']
04/25/2022 17:52:45 - INFO - __main__ - Tokenizing Input ...
04/25/2022 17:52:45 - INFO - __main__ - Tokenizing Output ...
04/25/2022 17:52:45 - INFO - __main__ - Loaded 32 examples from train data
04/25/2022 17:52:45 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 17:52:45 - INFO - __main__ - Printing 3 examples
04/25/2022 17:52:45 - INFO - __main__ -  [openbookqa] A bird eating a lizard is an example of what type of relationship? (A) symbiotic (B) producer (C) parasitic (D) predatory
04/25/2022 17:52:45 - INFO - __main__ - ['predatory']
04/25/2022 17:52:45 - INFO - __main__ -  [openbookqa] Where would you find the most sunlight? (A) England (B) Morocco (C) Sweden (D) Norway
04/25/2022 17:52:45 - INFO - __main__ - ['Morocco']
04/25/2022 17:52:45 - INFO - __main__ -  [openbookqa] Microscopes (A) make tiny atoms look smaller (B) enhance the size of amoebas for easier viewing (C) make magnifying things much more difficult (D) make huge samples look minuscule
04/25/2022 17:52:45 - INFO - __main__ - ['enhance the size of amoebas for easier viewing']
04/25/2022 17:52:45 - INFO - __main__ - Tokenizing Input ...
04/25/2022 17:52:45 - INFO - __main__ - Tokenizing Output ...
04/25/2022 17:52:45 - INFO - __main__ - Loaded 32 examples from dev data
04/25/2022 17:53:00 - INFO - __main__ - load prompt embedding from ckpt
04/25/2022 17:53:01 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/25/2022 17:53:01 - INFO - __main__ - Starting training!
04/25/2022 17:53:04 - INFO - __main__ - Step 10 Global step 10 Train loss 1.81 on epoch=4
04/25/2022 17:53:07 - INFO - __main__ - Step 20 Global step 20 Train loss 1.30 on epoch=9
04/25/2022 17:53:09 - INFO - __main__ - Step 30 Global step 30 Train loss 0.87 on epoch=14
04/25/2022 17:53:12 - INFO - __main__ - Step 40 Global step 40 Train loss 0.66 on epoch=19
04/25/2022 17:53:14 - INFO - __main__ - Step 50 Global step 50 Train loss 0.54 on epoch=24
04/25/2022 17:53:16 - INFO - __main__ - Global step 50 Train loss 1.04 ACC 0.15625 on epoch=24
04/25/2022 17:53:16 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.15625 on epoch=24, global_step=50
04/25/2022 17:53:19 - INFO - __main__ - Step 60 Global step 60 Train loss 0.40 on epoch=29
04/25/2022 17:53:22 - INFO - __main__ - Step 70 Global step 70 Train loss 0.40 on epoch=34
04/25/2022 17:53:24 - INFO - __main__ - Step 80 Global step 80 Train loss 0.32 on epoch=39
04/25/2022 17:53:27 - INFO - __main__ - Step 90 Global step 90 Train loss 0.25 on epoch=44
04/25/2022 17:53:29 - INFO - __main__ - Step 100 Global step 100 Train loss 0.25 on epoch=49
04/25/2022 17:53:32 - INFO - __main__ - Global step 100 Train loss 0.32 ACC 0.25 on epoch=49
04/25/2022 17:53:32 - INFO - __main__ - Saving model with best ACC: 0.15625 -> 0.25 on epoch=49, global_step=100
04/25/2022 17:53:34 - INFO - __main__ - Step 110 Global step 110 Train loss 0.26 on epoch=54
04/25/2022 17:53:37 - INFO - __main__ - Step 120 Global step 120 Train loss 0.22 on epoch=59
04/25/2022 17:53:39 - INFO - __main__ - Step 130 Global step 130 Train loss 0.17 on epoch=64
04/25/2022 17:53:42 - INFO - __main__ - Step 140 Global step 140 Train loss 0.14 on epoch=69
04/25/2022 17:53:45 - INFO - __main__ - Step 150 Global step 150 Train loss 0.14 on epoch=74
04/25/2022 17:53:47 - INFO - __main__ - Global step 150 Train loss 0.19 ACC 0.21875 on epoch=74
04/25/2022 17:53:49 - INFO - __main__ - Step 160 Global step 160 Train loss 0.14 on epoch=79
04/25/2022 17:53:52 - INFO - __main__ - Step 170 Global step 170 Train loss 0.11 on epoch=84
04/25/2022 17:53:54 - INFO - __main__ - Step 180 Global step 180 Train loss 0.15 on epoch=89
04/25/2022 17:53:57 - INFO - __main__ - Step 190 Global step 190 Train loss 0.08 on epoch=94
04/25/2022 17:53:59 - INFO - __main__ - Step 200 Global step 200 Train loss 0.13 on epoch=99
04/25/2022 17:54:02 - INFO - __main__ - Global step 200 Train loss 0.12 ACC 0.28125 on epoch=99
04/25/2022 17:54:02 - INFO - __main__ - Saving model with best ACC: 0.25 -> 0.28125 on epoch=99, global_step=200
04/25/2022 17:54:04 - INFO - __main__ - Step 210 Global step 210 Train loss 0.06 on epoch=104
04/25/2022 17:54:07 - INFO - __main__ - Step 220 Global step 220 Train loss 0.07 on epoch=109
04/25/2022 17:54:09 - INFO - __main__ - Step 230 Global step 230 Train loss 0.08 on epoch=114
04/25/2022 17:54:12 - INFO - __main__ - Step 240 Global step 240 Train loss 0.07 on epoch=119
04/25/2022 17:54:14 - INFO - __main__ - Step 250 Global step 250 Train loss 0.08 on epoch=124
04/25/2022 17:54:16 - INFO - __main__ - Global step 250 Train loss 0.07 ACC 0.25 on epoch=124
04/25/2022 17:54:19 - INFO - __main__ - Step 260 Global step 260 Train loss 0.06 on epoch=129
04/25/2022 17:54:21 - INFO - __main__ - Step 270 Global step 270 Train loss 0.05 on epoch=134
04/25/2022 17:54:24 - INFO - __main__ - Step 280 Global step 280 Train loss 0.07 on epoch=139
04/25/2022 17:54:26 - INFO - __main__ - Step 290 Global step 290 Train loss 0.09 on epoch=144
04/25/2022 17:54:29 - INFO - __main__ - Step 300 Global step 300 Train loss 0.03 on epoch=149
04/25/2022 17:54:31 - INFO - __main__ - Global step 300 Train loss 0.06 ACC 0.21875 on epoch=149
04/25/2022 17:54:33 - INFO - __main__ - Step 310 Global step 310 Train loss 0.06 on epoch=154
04/25/2022 17:54:36 - INFO - __main__ - Step 320 Global step 320 Train loss 0.06 on epoch=159
04/25/2022 17:54:39 - INFO - __main__ - Step 330 Global step 330 Train loss 0.07 on epoch=164
04/25/2022 17:54:41 - INFO - __main__ - Step 340 Global step 340 Train loss 0.05 on epoch=169
04/25/2022 17:54:44 - INFO - __main__ - Step 350 Global step 350 Train loss 0.02 on epoch=174
04/25/2022 17:54:46 - INFO - __main__ - Global step 350 Train loss 0.06 ACC 0.21875 on epoch=174
04/25/2022 17:54:48 - INFO - __main__ - Step 360 Global step 360 Train loss 0.06 on epoch=179
04/25/2022 17:54:51 - INFO - __main__ - Step 370 Global step 370 Train loss 0.05 on epoch=184
04/25/2022 17:54:53 - INFO - __main__ - Step 380 Global step 380 Train loss 0.02 on epoch=189
04/25/2022 17:54:56 - INFO - __main__ - Step 390 Global step 390 Train loss 0.05 on epoch=194
04/25/2022 17:54:58 - INFO - __main__ - Step 400 Global step 400 Train loss 0.04 on epoch=199
04/25/2022 17:55:00 - INFO - __main__ - Global step 400 Train loss 0.04 ACC 0.25 on epoch=199
04/25/2022 17:55:03 - INFO - __main__ - Step 410 Global step 410 Train loss 0.01 on epoch=204
04/25/2022 17:55:05 - INFO - __main__ - Step 420 Global step 420 Train loss 0.03 on epoch=209
04/25/2022 17:55:08 - INFO - __main__ - Step 430 Global step 430 Train loss 0.03 on epoch=214
04/25/2022 17:55:10 - INFO - __main__ - Step 440 Global step 440 Train loss 0.07 on epoch=219
04/25/2022 17:55:13 - INFO - __main__ - Step 450 Global step 450 Train loss 0.03 on epoch=224
04/25/2022 17:55:15 - INFO - __main__ - Global step 450 Train loss 0.04 ACC 0.1875 on epoch=224
04/25/2022 17:55:18 - INFO - __main__ - Step 460 Global step 460 Train loss 0.03 on epoch=229
04/25/2022 17:55:20 - INFO - __main__ - Step 470 Global step 470 Train loss 0.02 on epoch=234
04/25/2022 17:55:23 - INFO - __main__ - Step 480 Global step 480 Train loss 0.03 on epoch=239
04/25/2022 17:55:25 - INFO - __main__ - Step 490 Global step 490 Train loss 0.01 on epoch=244
04/25/2022 17:55:28 - INFO - __main__ - Step 500 Global step 500 Train loss 0.03 on epoch=249
04/25/2022 17:55:30 - INFO - __main__ - Global step 500 Train loss 0.03 ACC 0.28125 on epoch=249
04/25/2022 17:55:32 - INFO - __main__ - Step 510 Global step 510 Train loss 0.05 on epoch=254
04/25/2022 17:55:35 - INFO - __main__ - Step 520 Global step 520 Train loss 0.02 on epoch=259
04/25/2022 17:55:37 - INFO - __main__ - Step 530 Global step 530 Train loss 0.02 on epoch=264
04/25/2022 17:55:39 - INFO - __main__ - Step 540 Global step 540 Train loss 0.02 on epoch=269
04/25/2022 17:55:42 - INFO - __main__ - Step 550 Global step 550 Train loss 0.02 on epoch=274
04/25/2022 17:55:44 - INFO - __main__ - Global step 550 Train loss 0.03 ACC 0.28125 on epoch=274
04/25/2022 17:55:47 - INFO - __main__ - Step 560 Global step 560 Train loss 0.01 on epoch=279
04/25/2022 17:55:49 - INFO - __main__ - Step 570 Global step 570 Train loss 0.03 on epoch=284
04/25/2022 17:55:52 - INFO - __main__ - Step 580 Global step 580 Train loss 0.01 on epoch=289
04/25/2022 17:55:54 - INFO - __main__ - Step 590 Global step 590 Train loss 0.02 on epoch=294
04/25/2022 17:55:57 - INFO - __main__ - Step 600 Global step 600 Train loss 0.01 on epoch=299
04/25/2022 17:55:59 - INFO - __main__ - Global step 600 Train loss 0.02 ACC 0.25 on epoch=299
04/25/2022 17:56:01 - INFO - __main__ - Step 610 Global step 610 Train loss 0.04 on epoch=304
04/25/2022 17:56:04 - INFO - __main__ - Step 620 Global step 620 Train loss 0.02 on epoch=309
04/25/2022 17:56:06 - INFO - __main__ - Step 630 Global step 630 Train loss 0.01 on epoch=314
04/25/2022 17:56:09 - INFO - __main__ - Step 640 Global step 640 Train loss 0.00 on epoch=319
04/25/2022 17:56:11 - INFO - __main__ - Step 650 Global step 650 Train loss 0.01 on epoch=324
04/25/2022 17:56:13 - INFO - __main__ - Global step 650 Train loss 0.02 ACC 0.21875 on epoch=324
04/25/2022 17:56:16 - INFO - __main__ - Step 660 Global step 660 Train loss 0.02 on epoch=329
04/25/2022 17:56:18 - INFO - __main__ - Step 670 Global step 670 Train loss 0.02 on epoch=334
04/25/2022 17:56:21 - INFO - __main__ - Step 680 Global step 680 Train loss 0.02 on epoch=339
04/25/2022 17:56:23 - INFO - __main__ - Step 690 Global step 690 Train loss 0.03 on epoch=344
04/25/2022 17:56:26 - INFO - __main__ - Step 700 Global step 700 Train loss 0.02 on epoch=349
04/25/2022 17:56:28 - INFO - __main__ - Global step 700 Train loss 0.02 ACC 0.25 on epoch=349
04/25/2022 17:56:31 - INFO - __main__ - Step 710 Global step 710 Train loss 0.02 on epoch=354
04/25/2022 17:56:33 - INFO - __main__ - Step 720 Global step 720 Train loss 0.01 on epoch=359
04/25/2022 17:56:36 - INFO - __main__ - Step 730 Global step 730 Train loss 0.01 on epoch=364
04/25/2022 17:56:38 - INFO - __main__ - Step 740 Global step 740 Train loss 0.01 on epoch=369
04/25/2022 17:56:41 - INFO - __main__ - Step 750 Global step 750 Train loss 0.03 on epoch=374
04/25/2022 17:56:43 - INFO - __main__ - Global step 750 Train loss 0.02 ACC 0.21875 on epoch=374
04/25/2022 17:56:46 - INFO - __main__ - Step 760 Global step 760 Train loss 0.02 on epoch=379
04/25/2022 17:56:48 - INFO - __main__ - Step 770 Global step 770 Train loss 0.01 on epoch=384
04/25/2022 17:56:51 - INFO - __main__ - Step 780 Global step 780 Train loss 0.02 on epoch=389
04/25/2022 17:56:53 - INFO - __main__ - Step 790 Global step 790 Train loss 0.01 on epoch=394
04/25/2022 17:56:56 - INFO - __main__ - Step 800 Global step 800 Train loss 0.01 on epoch=399
04/25/2022 17:56:58 - INFO - __main__ - Global step 800 Train loss 0.01 ACC 0.25 on epoch=399
04/25/2022 17:57:01 - INFO - __main__ - Step 810 Global step 810 Train loss 0.02 on epoch=404
04/25/2022 17:57:03 - INFO - __main__ - Step 820 Global step 820 Train loss 0.02 on epoch=409
04/25/2022 17:57:06 - INFO - __main__ - Step 830 Global step 830 Train loss 0.01 on epoch=414
04/25/2022 17:57:08 - INFO - __main__ - Step 840 Global step 840 Train loss 0.01 on epoch=419
04/25/2022 17:57:11 - INFO - __main__ - Step 850 Global step 850 Train loss 0.01 on epoch=424
04/25/2022 17:57:13 - INFO - __main__ - Global step 850 Train loss 0.01 ACC 0.25 on epoch=424
04/25/2022 17:57:16 - INFO - __main__ - Step 860 Global step 860 Train loss 0.00 on epoch=429
04/25/2022 17:57:18 - INFO - __main__ - Step 870 Global step 870 Train loss 0.02 on epoch=434
04/25/2022 17:57:21 - INFO - __main__ - Step 880 Global step 880 Train loss 0.01 on epoch=439
04/25/2022 17:57:23 - INFO - __main__ - Step 890 Global step 890 Train loss 0.03 on epoch=444
04/25/2022 17:57:26 - INFO - __main__ - Step 900 Global step 900 Train loss 0.01 on epoch=449
04/25/2022 17:57:28 - INFO - __main__ - Global step 900 Train loss 0.02 ACC 0.25 on epoch=449
04/25/2022 17:57:31 - INFO - __main__ - Step 910 Global step 910 Train loss 0.01 on epoch=454
04/25/2022 17:57:33 - INFO - __main__ - Step 920 Global step 920 Train loss 0.01 on epoch=459
04/25/2022 17:57:36 - INFO - __main__ - Step 930 Global step 930 Train loss 0.01 on epoch=464
04/25/2022 17:57:38 - INFO - __main__ - Step 940 Global step 940 Train loss 0.01 on epoch=469
04/25/2022 17:57:41 - INFO - __main__ - Step 950 Global step 950 Train loss 0.01 on epoch=474
04/25/2022 17:57:43 - INFO - __main__ - Global step 950 Train loss 0.01 ACC 0.25 on epoch=474
04/25/2022 17:57:46 - INFO - __main__ - Step 960 Global step 960 Train loss 0.00 on epoch=479
04/25/2022 17:57:48 - INFO - __main__ - Step 970 Global step 970 Train loss 0.00 on epoch=484
04/25/2022 17:57:51 - INFO - __main__ - Step 980 Global step 980 Train loss 0.01 on epoch=489
04/25/2022 17:57:53 - INFO - __main__ - Step 990 Global step 990 Train loss 0.01 on epoch=494
04/25/2022 17:57:56 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.01 on epoch=499
04/25/2022 17:57:58 - INFO - __main__ - Global step 1000 Train loss 0.01 ACC 0.28125 on epoch=499
04/25/2022 17:58:01 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.02 on epoch=504
04/25/2022 17:58:03 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.01 on epoch=509
04/25/2022 17:58:06 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.01 on epoch=514
04/25/2022 17:58:08 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.01 on epoch=519
04/25/2022 17:58:11 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.01 on epoch=524
04/25/2022 17:58:13 - INFO - __main__ - Global step 1050 Train loss 0.01 ACC 0.25 on epoch=524
04/25/2022 17:58:15 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.01 on epoch=529
04/25/2022 17:58:18 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.01 on epoch=534
04/25/2022 17:58:20 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.01 on epoch=539
04/25/2022 17:58:23 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.02 on epoch=544
04/25/2022 17:58:25 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.02 on epoch=549
04/25/2022 17:58:27 - INFO - __main__ - Global step 1100 Train loss 0.01 ACC 0.21875 on epoch=549
04/25/2022 17:58:30 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.00 on epoch=554
04/25/2022 17:58:33 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.02 on epoch=559
04/25/2022 17:58:35 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.00 on epoch=564
04/25/2022 17:58:37 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.00 on epoch=569
04/25/2022 17:58:40 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.02 on epoch=574
04/25/2022 17:58:42 - INFO - __main__ - Global step 1150 Train loss 0.01 ACC 0.25 on epoch=574
04/25/2022 17:58:44 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.01 on epoch=579
04/25/2022 17:58:47 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.00 on epoch=584
04/25/2022 17:58:49 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.00 on epoch=589
04/25/2022 17:58:52 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.00 on epoch=594
04/25/2022 17:58:54 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.00 on epoch=599
04/25/2022 17:58:57 - INFO - __main__ - Global step 1200 Train loss 0.00 ACC 0.25 on epoch=599
04/25/2022 17:58:59 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.01 on epoch=604
04/25/2022 17:59:02 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=609
04/25/2022 17:59:04 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.00 on epoch=614
04/25/2022 17:59:07 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=619
04/25/2022 17:59:09 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.01 on epoch=624
04/25/2022 17:59:11 - INFO - __main__ - Global step 1250 Train loss 0.01 ACC 0.28125 on epoch=624
04/25/2022 17:59:14 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=629
04/25/2022 17:59:16 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.01 on epoch=634
04/25/2022 17:59:19 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=639
04/25/2022 17:59:21 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.00 on epoch=644
04/25/2022 17:59:24 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.00 on epoch=649
04/25/2022 17:59:26 - INFO - __main__ - Global step 1300 Train loss 0.01 ACC 0.28125 on epoch=649
04/25/2022 17:59:28 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=654
04/25/2022 17:59:31 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=659
04/25/2022 17:59:33 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=664
04/25/2022 17:59:36 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=669
04/25/2022 17:59:38 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.00 on epoch=674
04/25/2022 17:59:40 - INFO - __main__ - Global step 1350 Train loss 0.01 ACC 0.28125 on epoch=674
04/25/2022 17:59:43 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=679
04/25/2022 17:59:45 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=684
04/25/2022 17:59:48 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.00 on epoch=689
04/25/2022 17:59:50 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.00 on epoch=694
04/25/2022 17:59:53 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.00 on epoch=699
04/25/2022 17:59:55 - INFO - __main__ - Global step 1400 Train loss 0.01 ACC 0.3125 on epoch=699
04/25/2022 17:59:55 - INFO - __main__ - Saving model with best ACC: 0.28125 -> 0.3125 on epoch=699, global_step=1400
04/25/2022 17:59:58 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=704
04/25/2022 18:00:00 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=709
04/25/2022 18:00:03 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.02 on epoch=714
04/25/2022 18:00:05 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=719
04/25/2022 18:00:08 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=724
04/25/2022 18:00:10 - INFO - __main__ - Global step 1450 Train loss 0.01 ACC 0.3125 on epoch=724
04/25/2022 18:00:12 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=729
04/25/2022 18:00:15 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=734
04/25/2022 18:00:17 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=739
04/25/2022 18:00:20 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.02 on epoch=744
04/25/2022 18:00:22 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=749
04/25/2022 18:00:25 - INFO - __main__ - Global step 1500 Train loss 0.01 ACC 0.25 on epoch=749
04/25/2022 18:00:27 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=754
04/25/2022 18:00:30 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=759
04/25/2022 18:00:32 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=764
04/25/2022 18:00:35 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=769
04/25/2022 18:00:37 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=774
04/25/2022 18:00:39 - INFO - __main__ - Global step 1550 Train loss 0.01 ACC 0.28125 on epoch=774
04/25/2022 18:00:42 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=779
04/25/2022 18:00:44 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=784
04/25/2022 18:00:47 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.03 on epoch=789
04/25/2022 18:00:49 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=794
04/25/2022 18:00:52 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=799
04/25/2022 18:00:55 - INFO - __main__ - Global step 1600 Train loss 0.01 ACC 0.21875 on epoch=799
04/25/2022 18:00:57 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=804
04/25/2022 18:01:00 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=809
04/25/2022 18:01:02 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=814
04/25/2022 18:01:05 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=819
04/25/2022 18:01:07 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=824
04/25/2022 18:01:10 - INFO - __main__ - Global step 1650 Train loss 0.01 ACC 0.1875 on epoch=824
04/25/2022 18:01:12 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=829
04/25/2022 18:01:15 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=834
04/25/2022 18:01:17 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=839
04/25/2022 18:01:20 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=844
04/25/2022 18:01:22 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=849
04/25/2022 18:01:25 - INFO - __main__ - Global step 1700 Train loss 0.01 ACC 0.25 on epoch=849
04/25/2022 18:01:27 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=854
04/25/2022 18:01:30 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=859
04/25/2022 18:01:32 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=864
04/25/2022 18:01:35 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=869
04/25/2022 18:01:37 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=874
04/25/2022 18:01:40 - INFO - __main__ - Global step 1750 Train loss 0.00 ACC 0.21875 on epoch=874
04/25/2022 18:01:43 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=879
04/25/2022 18:01:45 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.04 on epoch=884
04/25/2022 18:01:48 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=889
04/25/2022 18:01:50 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=894
04/25/2022 18:01:52 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=899
04/25/2022 18:01:55 - INFO - __main__ - Global step 1800 Train loss 0.01 ACC 0.28125 on epoch=899
04/25/2022 18:01:58 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=904
04/25/2022 18:02:00 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=909
04/25/2022 18:02:03 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=914
04/25/2022 18:02:05 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=919
04/25/2022 18:02:08 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.05 on epoch=924
04/25/2022 18:02:10 - INFO - __main__ - Global step 1850 Train loss 0.01 ACC 0.25 on epoch=924
04/25/2022 18:02:12 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=929
04/25/2022 18:02:15 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=934
04/25/2022 18:02:17 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=939
04/25/2022 18:02:20 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=944
04/25/2022 18:02:22 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=949
04/25/2022 18:02:25 - INFO - __main__ - Global step 1900 Train loss 0.00 ACC 0.21875 on epoch=949
04/25/2022 18:02:27 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=954
04/25/2022 18:02:30 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=959
04/25/2022 18:02:32 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=964
04/25/2022 18:02:35 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=969
04/25/2022 18:02:37 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=974
04/25/2022 18:02:40 - INFO - __main__ - Global step 1950 Train loss 0.00 ACC 0.21875 on epoch=974
04/25/2022 18:02:42 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=979
04/25/2022 18:02:45 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=984
04/25/2022 18:02:47 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=989
04/25/2022 18:02:50 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=994
04/25/2022 18:02:52 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=999
04/25/2022 18:02:53 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 18:02:53 - INFO - __main__ - Printing 3 examples
04/25/2022 18:02:53 - INFO - __main__ -  [openbookqa] a lack of illumination would result in which of these? (A) the restroom overflowing with water (B) a principal's door being locked (C) a student unable to view what he is writing (D) a teacher being unable to transport to school
04/25/2022 18:02:53 - INFO - __main__ - ['a student unable to view what he is writing']
04/25/2022 18:02:53 - INFO - __main__ -  [openbookqa] The quickness of this animal is a key change that allows it to escape attacks from feasting animals: (A) the praying mantis (B) the potato bug (C) antelope (D) the eagle
04/25/2022 18:02:53 - INFO - __main__ - ['antelope']
04/25/2022 18:02:53 - INFO - __main__ -  [openbookqa] Vegetables provide a lot of nutrients for (A) cats (B) dogs (C) humans (D) snakes
04/25/2022 18:02:53 - INFO - __main__ - ['humans']
04/25/2022 18:02:53 - INFO - __main__ - Tokenizing Input ...
04/25/2022 18:02:53 - INFO - __main__ - Tokenizing Output ...
04/25/2022 18:02:53 - INFO - __main__ - Loaded 32 examples from train data
04/25/2022 18:02:53 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 18:02:53 - INFO - __main__ - Printing 3 examples
04/25/2022 18:02:53 - INFO - __main__ -  [openbookqa] A bird eating a lizard is an example of what type of relationship? (A) symbiotic (B) producer (C) parasitic (D) predatory
04/25/2022 18:02:53 - INFO - __main__ - ['predatory']
04/25/2022 18:02:53 - INFO - __main__ -  [openbookqa] Where would you find the most sunlight? (A) England (B) Morocco (C) Sweden (D) Norway
04/25/2022 18:02:53 - INFO - __main__ - ['Morocco']
04/25/2022 18:02:53 - INFO - __main__ -  [openbookqa] Microscopes (A) make tiny atoms look smaller (B) enhance the size of amoebas for easier viewing (C) make magnifying things much more difficult (D) make huge samples look minuscule
04/25/2022 18:02:53 - INFO - __main__ - ['enhance the size of amoebas for easier viewing']
04/25/2022 18:02:53 - INFO - __main__ - Tokenizing Input ...
04/25/2022 18:02:53 - INFO - __main__ - Tokenizing Output ...
04/25/2022 18:02:54 - INFO - __main__ - Loaded 32 examples from dev data
04/25/2022 18:02:55 - INFO - __main__ - Global step 2000 Train loss 0.01 ACC 0.1875 on epoch=999
04/25/2022 18:02:55 - INFO - __main__ - save last model!
04/25/2022 18:02:55 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
04/25/2022 18:02:55 - INFO - __main__ - Start tokenizing ... 500 instances
04/25/2022 18:02:55 - INFO - __main__ - Printing 3 examples
04/25/2022 18:02:55 - INFO - __main__ -  [openbookqa] Frilled sharks and angler fish live far beneath the surface of the ocean, which is why they are known as (A) Deep sea animals (B) fish (C) Long Sea Fish (D) Far Sea Animals
04/25/2022 18:02:55 - INFO - __main__ - ['Deep sea animals']
04/25/2022 18:02:55 - INFO - __main__ -  [openbookqa] Gas can fill any container it is given, and liquid (A) is standard weight and size (B) is the opposite of variable (C) only needs a few (D) uses what it needs
04/25/2022 18:02:55 - INFO - __main__ - ['uses what it needs']
04/25/2022 18:02:55 - INFO - __main__ -  [openbookqa] When birds migrate south for the winter, they do it because (A) they are genetically called to (B) their children ask for them to (C) it is important to their happiness (D) they decide to each year
04/25/2022 18:02:55 - INFO - __main__ - ['they are genetically called to']
04/25/2022 18:02:55 - INFO - __main__ - Tokenizing Input ...
04/25/2022 18:02:55 - INFO - __main__ - Tokenizing Output ...
04/25/2022 18:02:55 - INFO - __main__ - Loaded 500 examples from test data
04/25/2022 18:03:09 - INFO - __main__ - load prompt embedding from ckpt
04/25/2022 18:03:10 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/25/2022 18:03:10 - INFO - __main__ - Starting training!
04/25/2022 18:03:28 - INFO - __main__ - Saved prediction in models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-openbookqa/openbookqa_32_21_0.4_8_predictions.txt
04/25/2022 18:03:28 - INFO - __main__ - ACC on test data: 0.2900
04/25/2022 18:03:28 - INFO - __main__ - prefix=openbookqa_32_21, lr=0.4, bsz=8, dev_performance=0.3125, test_performance=0.29
04/25/2022 18:03:28 - INFO - __main__ - Running ... prefix=openbookqa_32_21, lr=0.3, bsz=8 ...
04/25/2022 18:03:29 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 18:03:29 - INFO - __main__ - Printing 3 examples
04/25/2022 18:03:29 - INFO - __main__ -  [openbookqa] a lack of illumination would result in which of these? (A) the restroom overflowing with water (B) a principal's door being locked (C) a student unable to view what he is writing (D) a teacher being unable to transport to school
04/25/2022 18:03:29 - INFO - __main__ - ['a student unable to view what he is writing']
04/25/2022 18:03:29 - INFO - __main__ -  [openbookqa] The quickness of this animal is a key change that allows it to escape attacks from feasting animals: (A) the praying mantis (B) the potato bug (C) antelope (D) the eagle
04/25/2022 18:03:29 - INFO - __main__ - ['antelope']
04/25/2022 18:03:29 - INFO - __main__ -  [openbookqa] Vegetables provide a lot of nutrients for (A) cats (B) dogs (C) humans (D) snakes
04/25/2022 18:03:29 - INFO - __main__ - ['humans']
04/25/2022 18:03:29 - INFO - __main__ - Tokenizing Input ...
04/25/2022 18:03:29 - INFO - __main__ - Tokenizing Output ...
04/25/2022 18:03:29 - INFO - __main__ - Loaded 32 examples from train data
04/25/2022 18:03:29 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 18:03:29 - INFO - __main__ - Printing 3 examples
04/25/2022 18:03:29 - INFO - __main__ -  [openbookqa] A bird eating a lizard is an example of what type of relationship? (A) symbiotic (B) producer (C) parasitic (D) predatory
04/25/2022 18:03:29 - INFO - __main__ - ['predatory']
04/25/2022 18:03:29 - INFO - __main__ -  [openbookqa] Where would you find the most sunlight? (A) England (B) Morocco (C) Sweden (D) Norway
04/25/2022 18:03:29 - INFO - __main__ - ['Morocco']
04/25/2022 18:03:29 - INFO - __main__ -  [openbookqa] Microscopes (A) make tiny atoms look smaller (B) enhance the size of amoebas for easier viewing (C) make magnifying things much more difficult (D) make huge samples look minuscule
04/25/2022 18:03:29 - INFO - __main__ - ['enhance the size of amoebas for easier viewing']
04/25/2022 18:03:29 - INFO - __main__ - Tokenizing Input ...
04/25/2022 18:03:29 - INFO - __main__ - Tokenizing Output ...
04/25/2022 18:03:29 - INFO - __main__ - Loaded 32 examples from dev data
04/25/2022 18:03:50 - INFO - __main__ - load prompt embedding from ckpt
04/25/2022 18:03:50 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/25/2022 18:03:50 - INFO - __main__ - Starting training!
04/25/2022 18:03:54 - INFO - __main__ - Step 10 Global step 10 Train loss 1.80 on epoch=4
04/25/2022 18:03:56 - INFO - __main__ - Step 20 Global step 20 Train loss 1.43 on epoch=9
04/25/2022 18:03:58 - INFO - __main__ - Step 30 Global step 30 Train loss 1.00 on epoch=14
04/25/2022 18:04:01 - INFO - __main__ - Step 40 Global step 40 Train loss 0.72 on epoch=19
04/25/2022 18:04:03 - INFO - __main__ - Step 50 Global step 50 Train loss 0.65 on epoch=24
04/25/2022 18:04:06 - INFO - __main__ - Global step 50 Train loss 1.12 ACC 0.125 on epoch=24
04/25/2022 18:04:06 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.125 on epoch=24, global_step=50
04/25/2022 18:04:08 - INFO - __main__ - Step 60 Global step 60 Train loss 0.55 on epoch=29
04/25/2022 18:04:11 - INFO - __main__ - Step 70 Global step 70 Train loss 0.46 on epoch=34
04/25/2022 18:04:13 - INFO - __main__ - Step 80 Global step 80 Train loss 0.41 on epoch=39
04/25/2022 18:04:16 - INFO - __main__ - Step 90 Global step 90 Train loss 0.44 on epoch=44
04/25/2022 18:04:18 - INFO - __main__ - Step 100 Global step 100 Train loss 0.25 on epoch=49
04/25/2022 18:04:21 - INFO - __main__ - Global step 100 Train loss 0.42 ACC 0.21875 on epoch=49
04/25/2022 18:04:21 - INFO - __main__ - Saving model with best ACC: 0.125 -> 0.21875 on epoch=49, global_step=100
04/25/2022 18:04:23 - INFO - __main__ - Step 110 Global step 110 Train loss 0.27 on epoch=54
04/25/2022 18:04:26 - INFO - __main__ - Step 120 Global step 120 Train loss 0.26 on epoch=59
04/25/2022 18:04:28 - INFO - __main__ - Step 130 Global step 130 Train loss 0.28 on epoch=64
04/25/2022 18:04:31 - INFO - __main__ - Step 140 Global step 140 Train loss 0.26 on epoch=69
04/25/2022 18:04:33 - INFO - __main__ - Step 150 Global step 150 Train loss 0.17 on epoch=74
04/25/2022 18:04:35 - INFO - __main__ - Global step 150 Train loss 0.25 ACC 0.21875 on epoch=74
04/25/2022 18:04:38 - INFO - __main__ - Step 160 Global step 160 Train loss 0.22 on epoch=79
04/25/2022 18:04:40 - INFO - __main__ - Step 170 Global step 170 Train loss 0.17 on epoch=84
04/25/2022 18:04:43 - INFO - __main__ - Step 180 Global step 180 Train loss 0.20 on epoch=89
04/25/2022 18:04:45 - INFO - __main__ - Step 190 Global step 190 Train loss 0.13 on epoch=94
04/25/2022 18:04:48 - INFO - __main__ - Step 200 Global step 200 Train loss 0.15 on epoch=99
04/25/2022 18:04:50 - INFO - __main__ - Global step 200 Train loss 0.18 ACC 0.21875 on epoch=99
04/25/2022 18:04:52 - INFO - __main__ - Step 210 Global step 210 Train loss 0.13 on epoch=104
04/25/2022 18:04:55 - INFO - __main__ - Step 220 Global step 220 Train loss 0.15 on epoch=109
04/25/2022 18:04:57 - INFO - __main__ - Step 230 Global step 230 Train loss 0.11 on epoch=114
04/25/2022 18:05:00 - INFO - __main__ - Step 240 Global step 240 Train loss 0.11 on epoch=119
04/25/2022 18:05:02 - INFO - __main__ - Step 250 Global step 250 Train loss 0.09 on epoch=124
04/25/2022 18:05:05 - INFO - __main__ - Global step 250 Train loss 0.12 ACC 0.25 on epoch=124
04/25/2022 18:05:05 - INFO - __main__ - Saving model with best ACC: 0.21875 -> 0.25 on epoch=124, global_step=250
04/25/2022 18:05:08 - INFO - __main__ - Step 260 Global step 260 Train loss 0.08 on epoch=129
04/25/2022 18:05:10 - INFO - __main__ - Step 270 Global step 270 Train loss 0.09 on epoch=134
04/25/2022 18:05:13 - INFO - __main__ - Step 280 Global step 280 Train loss 0.09 on epoch=139
04/25/2022 18:05:15 - INFO - __main__ - Step 290 Global step 290 Train loss 0.11 on epoch=144
04/25/2022 18:05:18 - INFO - __main__ - Step 300 Global step 300 Train loss 0.09 on epoch=149
04/25/2022 18:05:20 - INFO - __main__ - Global step 300 Train loss 0.09 ACC 0.3125 on epoch=149
04/25/2022 18:05:20 - INFO - __main__ - Saving model with best ACC: 0.25 -> 0.3125 on epoch=149, global_step=300
04/25/2022 18:05:23 - INFO - __main__ - Step 310 Global step 310 Train loss 0.14 on epoch=154
04/25/2022 18:05:25 - INFO - __main__ - Step 320 Global step 320 Train loss 0.08 on epoch=159
04/25/2022 18:05:28 - INFO - __main__ - Step 330 Global step 330 Train loss 0.08 on epoch=164
04/25/2022 18:05:30 - INFO - __main__ - Step 340 Global step 340 Train loss 0.05 on epoch=169
04/25/2022 18:05:33 - INFO - __main__ - Step 350 Global step 350 Train loss 0.06 on epoch=174
04/25/2022 18:05:35 - INFO - __main__ - Global step 350 Train loss 0.08 ACC 0.21875 on epoch=174
04/25/2022 18:05:38 - INFO - __main__ - Step 360 Global step 360 Train loss 0.05 on epoch=179
04/25/2022 18:05:40 - INFO - __main__ - Step 370 Global step 370 Train loss 0.06 on epoch=184
04/25/2022 18:05:43 - INFO - __main__ - Step 380 Global step 380 Train loss 0.07 on epoch=189
04/25/2022 18:05:45 - INFO - __main__ - Step 390 Global step 390 Train loss 0.08 on epoch=194
04/25/2022 18:05:48 - INFO - __main__ - Step 400 Global step 400 Train loss 0.03 on epoch=199
04/25/2022 18:05:50 - INFO - __main__ - Global step 400 Train loss 0.06 ACC 0.25 on epoch=199
04/25/2022 18:05:53 - INFO - __main__ - Step 410 Global step 410 Train loss 0.05 on epoch=204
04/25/2022 18:05:55 - INFO - __main__ - Step 420 Global step 420 Train loss 0.06 on epoch=209
04/25/2022 18:05:58 - INFO - __main__ - Step 430 Global step 430 Train loss 0.07 on epoch=214
04/25/2022 18:06:00 - INFO - __main__ - Step 440 Global step 440 Train loss 0.05 on epoch=219
04/25/2022 18:06:03 - INFO - __main__ - Step 450 Global step 450 Train loss 0.05 on epoch=224
04/25/2022 18:06:06 - INFO - __main__ - Global step 450 Train loss 0.06 ACC 0.25 on epoch=224
04/25/2022 18:06:08 - INFO - __main__ - Step 460 Global step 460 Train loss 0.03 on epoch=229
04/25/2022 18:06:11 - INFO - __main__ - Step 470 Global step 470 Train loss 0.03 on epoch=234
04/25/2022 18:06:13 - INFO - __main__ - Step 480 Global step 480 Train loss 0.04 on epoch=239
04/25/2022 18:06:16 - INFO - __main__ - Step 490 Global step 490 Train loss 0.02 on epoch=244
04/25/2022 18:06:18 - INFO - __main__ - Step 500 Global step 500 Train loss 0.05 on epoch=249
04/25/2022 18:06:21 - INFO - __main__ - Global step 500 Train loss 0.03 ACC 0.25 on epoch=249
04/25/2022 18:06:23 - INFO - __main__ - Step 510 Global step 510 Train loss 0.01 on epoch=254
04/25/2022 18:06:26 - INFO - __main__ - Step 520 Global step 520 Train loss 0.04 on epoch=259
04/25/2022 18:06:28 - INFO - __main__ - Step 530 Global step 530 Train loss 0.04 on epoch=264
04/25/2022 18:06:31 - INFO - __main__ - Step 540 Global step 540 Train loss 0.03 on epoch=269
04/25/2022 18:06:33 - INFO - __main__ - Step 550 Global step 550 Train loss 0.05 on epoch=274
04/25/2022 18:06:36 - INFO - __main__ - Global step 550 Train loss 0.03 ACC 0.25 on epoch=274
04/25/2022 18:06:38 - INFO - __main__ - Step 560 Global step 560 Train loss 0.03 on epoch=279
04/25/2022 18:06:41 - INFO - __main__ - Step 570 Global step 570 Train loss 0.03 on epoch=284
04/25/2022 18:06:43 - INFO - __main__ - Step 580 Global step 580 Train loss 0.03 on epoch=289
04/25/2022 18:06:46 - INFO - __main__ - Step 590 Global step 590 Train loss 0.03 on epoch=294
04/25/2022 18:06:48 - INFO - __main__ - Step 600 Global step 600 Train loss 0.05 on epoch=299
04/25/2022 18:06:51 - INFO - __main__ - Global step 600 Train loss 0.04 ACC 0.25 on epoch=299
04/25/2022 18:06:53 - INFO - __main__ - Step 610 Global step 610 Train loss 0.02 on epoch=304
04/25/2022 18:06:56 - INFO - __main__ - Step 620 Global step 620 Train loss 0.05 on epoch=309
04/25/2022 18:06:58 - INFO - __main__ - Step 630 Global step 630 Train loss 0.02 on epoch=314
04/25/2022 18:07:01 - INFO - __main__ - Step 640 Global step 640 Train loss 0.05 on epoch=319
04/25/2022 18:07:03 - INFO - __main__ - Step 650 Global step 650 Train loss 0.03 on epoch=324
04/25/2022 18:07:06 - INFO - __main__ - Global step 650 Train loss 0.03 ACC 0.28125 on epoch=324
04/25/2022 18:07:08 - INFO - __main__ - Step 660 Global step 660 Train loss 0.03 on epoch=329
04/25/2022 18:07:11 - INFO - __main__ - Step 670 Global step 670 Train loss 0.01 on epoch=334
04/25/2022 18:07:13 - INFO - __main__ - Step 680 Global step 680 Train loss 0.02 on epoch=339
04/25/2022 18:07:16 - INFO - __main__ - Step 690 Global step 690 Train loss 0.01 on epoch=344
04/25/2022 18:07:18 - INFO - __main__ - Step 700 Global step 700 Train loss 0.01 on epoch=349
04/25/2022 18:07:21 - INFO - __main__ - Global step 700 Train loss 0.02 ACC 0.28125 on epoch=349
04/25/2022 18:07:23 - INFO - __main__ - Step 710 Global step 710 Train loss 0.03 on epoch=354
04/25/2022 18:07:26 - INFO - __main__ - Step 720 Global step 720 Train loss 0.04 on epoch=359
04/25/2022 18:07:28 - INFO - __main__ - Step 730 Global step 730 Train loss 0.03 on epoch=364
04/25/2022 18:07:31 - INFO - __main__ - Step 740 Global step 740 Train loss 0.04 on epoch=369
04/25/2022 18:07:34 - INFO - __main__ - Step 750 Global step 750 Train loss 0.01 on epoch=374
04/25/2022 18:07:36 - INFO - __main__ - Global step 750 Train loss 0.03 ACC 0.28125 on epoch=374
04/25/2022 18:07:39 - INFO - __main__ - Step 760 Global step 760 Train loss 0.01 on epoch=379
04/25/2022 18:07:41 - INFO - __main__ - Step 770 Global step 770 Train loss 0.03 on epoch=384
04/25/2022 18:07:44 - INFO - __main__ - Step 780 Global step 780 Train loss 0.02 on epoch=389
04/25/2022 18:07:46 - INFO - __main__ - Step 790 Global step 790 Train loss 0.02 on epoch=394
04/25/2022 18:07:49 - INFO - __main__ - Step 800 Global step 800 Train loss 0.01 on epoch=399
04/25/2022 18:07:51 - INFO - __main__ - Global step 800 Train loss 0.02 ACC 0.21875 on epoch=399
04/25/2022 18:07:54 - INFO - __main__ - Step 810 Global step 810 Train loss 0.01 on epoch=404
04/25/2022 18:07:56 - INFO - __main__ - Step 820 Global step 820 Train loss 0.03 on epoch=409
04/25/2022 18:07:59 - INFO - __main__ - Step 830 Global step 830 Train loss 0.03 on epoch=414
04/25/2022 18:08:01 - INFO - __main__ - Step 840 Global step 840 Train loss 0.01 on epoch=419
04/25/2022 18:08:04 - INFO - __main__ - Step 850 Global step 850 Train loss 0.01 on epoch=424
04/25/2022 18:08:06 - INFO - __main__ - Global step 850 Train loss 0.02 ACC 0.25 on epoch=424
04/25/2022 18:08:09 - INFO - __main__ - Step 860 Global step 860 Train loss 0.01 on epoch=429
04/25/2022 18:08:11 - INFO - __main__ - Step 870 Global step 870 Train loss 0.02 on epoch=434
04/25/2022 18:08:14 - INFO - __main__ - Step 880 Global step 880 Train loss 0.01 on epoch=439
04/25/2022 18:08:16 - INFO - __main__ - Step 890 Global step 890 Train loss 0.03 on epoch=444
04/25/2022 18:08:19 - INFO - __main__ - Step 900 Global step 900 Train loss 0.01 on epoch=449
04/25/2022 18:08:21 - INFO - __main__ - Global step 900 Train loss 0.01 ACC 0.21875 on epoch=449
04/25/2022 18:08:24 - INFO - __main__ - Step 910 Global step 910 Train loss 0.01 on epoch=454
04/25/2022 18:08:26 - INFO - __main__ - Step 920 Global step 920 Train loss 0.01 on epoch=459
04/25/2022 18:08:29 - INFO - __main__ - Step 930 Global step 930 Train loss 0.03 on epoch=464
04/25/2022 18:08:31 - INFO - __main__ - Step 940 Global step 940 Train loss 0.04 on epoch=469
04/25/2022 18:08:34 - INFO - __main__ - Step 950 Global step 950 Train loss 0.01 on epoch=474
04/25/2022 18:08:36 - INFO - __main__ - Global step 950 Train loss 0.02 ACC 0.21875 on epoch=474
04/25/2022 18:08:39 - INFO - __main__ - Step 960 Global step 960 Train loss 0.03 on epoch=479
04/25/2022 18:08:41 - INFO - __main__ - Step 970 Global step 970 Train loss 0.01 on epoch=484
04/25/2022 18:08:44 - INFO - __main__ - Step 980 Global step 980 Train loss 0.02 on epoch=489
04/25/2022 18:08:46 - INFO - __main__ - Step 990 Global step 990 Train loss 0.02 on epoch=494
04/25/2022 18:08:49 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.00 on epoch=499
04/25/2022 18:08:51 - INFO - __main__ - Global step 1000 Train loss 0.02 ACC 0.15625 on epoch=499
04/25/2022 18:08:54 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.01 on epoch=504
04/25/2022 18:08:56 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.00 on epoch=509
04/25/2022 18:08:58 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.01 on epoch=514
04/25/2022 18:09:01 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.00 on epoch=519
04/25/2022 18:09:03 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.03 on epoch=524
04/25/2022 18:09:06 - INFO - __main__ - Global step 1050 Train loss 0.01 ACC 0.21875 on epoch=524
04/25/2022 18:09:08 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.01 on epoch=529
04/25/2022 18:09:11 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.00 on epoch=534
04/25/2022 18:09:13 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.02 on epoch=539
04/25/2022 18:09:16 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.00 on epoch=544
04/25/2022 18:09:18 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.00 on epoch=549
04/25/2022 18:09:21 - INFO - __main__ - Global step 1100 Train loss 0.01 ACC 0.15625 on epoch=549
04/25/2022 18:09:23 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.00 on epoch=554
04/25/2022 18:09:26 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=559
04/25/2022 18:09:28 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=564
04/25/2022 18:09:31 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.04 on epoch=569
04/25/2022 18:09:33 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.02 on epoch=574
04/25/2022 18:09:36 - INFO - __main__ - Global step 1150 Train loss 0.02 ACC 0.25 on epoch=574
04/25/2022 18:09:39 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.01 on epoch=579
04/25/2022 18:09:41 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.02 on epoch=584
04/25/2022 18:09:43 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.02 on epoch=589
04/25/2022 18:09:46 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.02 on epoch=594
04/25/2022 18:09:49 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=599
04/25/2022 18:09:51 - INFO - __main__ - Global step 1200 Train loss 0.01 ACC 0.15625 on epoch=599
04/25/2022 18:09:54 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.01 on epoch=604
04/25/2022 18:09:56 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.00 on epoch=609
04/25/2022 18:09:59 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=614
04/25/2022 18:10:01 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.02 on epoch=619
04/25/2022 18:10:04 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.01 on epoch=624
04/25/2022 18:10:06 - INFO - __main__ - Global step 1250 Train loss 0.01 ACC 0.28125 on epoch=624
04/25/2022 18:10:09 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.00 on epoch=629
04/25/2022 18:10:11 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.02 on epoch=634
04/25/2022 18:10:14 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.00 on epoch=639
04/25/2022 18:10:16 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.00 on epoch=644
04/25/2022 18:10:19 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.00 on epoch=649
04/25/2022 18:10:22 - INFO - __main__ - Global step 1300 Train loss 0.01 ACC 0.25 on epoch=649
04/25/2022 18:10:24 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=654
04/25/2022 18:10:27 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=659
04/25/2022 18:10:29 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=664
04/25/2022 18:10:32 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.02 on epoch=669
04/25/2022 18:10:34 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=674
04/25/2022 18:10:37 - INFO - __main__ - Global step 1350 Train loss 0.01 ACC 0.21875 on epoch=674
04/25/2022 18:10:39 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.04 on epoch=679
04/25/2022 18:10:41 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=684
04/25/2022 18:10:44 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=689
04/25/2022 18:10:46 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=694
04/25/2022 18:10:49 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=699
04/25/2022 18:10:51 - INFO - __main__ - Global step 1400 Train loss 0.02 ACC 0.25 on epoch=699
04/25/2022 18:10:54 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=704
04/25/2022 18:10:56 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.01 on epoch=709
04/25/2022 18:10:59 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.02 on epoch=714
04/25/2022 18:11:01 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=719
04/25/2022 18:11:04 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=724
04/25/2022 18:11:06 - INFO - __main__ - Global step 1450 Train loss 0.01 ACC 0.21875 on epoch=724
04/25/2022 18:11:09 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=729
04/25/2022 18:11:11 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.02 on epoch=734
04/25/2022 18:11:14 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=739
04/25/2022 18:11:16 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=744
04/25/2022 18:11:19 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=749
04/25/2022 18:11:21 - INFO - __main__ - Global step 1500 Train loss 0.01 ACC 0.21875 on epoch=749
04/25/2022 18:11:24 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=754
04/25/2022 18:11:26 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=759
04/25/2022 18:11:29 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=764
04/25/2022 18:11:32 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=769
04/25/2022 18:11:34 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=774
04/25/2022 18:11:37 - INFO - __main__ - Global step 1550 Train loss 0.00 ACC 0.21875 on epoch=774
04/25/2022 18:11:39 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=779
04/25/2022 18:11:42 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=784
04/25/2022 18:11:44 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=789
04/25/2022 18:11:47 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=794
04/25/2022 18:11:49 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=799
04/25/2022 18:11:52 - INFO - __main__ - Global step 1600 Train loss 0.01 ACC 0.1875 on epoch=799
04/25/2022 18:11:55 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=804
04/25/2022 18:11:57 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=809
04/25/2022 18:11:59 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=814
04/25/2022 18:12:02 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=819
04/25/2022 18:12:04 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=824
04/25/2022 18:12:07 - INFO - __main__ - Global step 1650 Train loss 0.01 ACC 0.21875 on epoch=824
04/25/2022 18:12:10 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=829
04/25/2022 18:12:12 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=834
04/25/2022 18:12:15 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=839
04/25/2022 18:12:17 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=844
04/25/2022 18:12:19 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=849
04/25/2022 18:12:22 - INFO - __main__ - Global step 1700 Train loss 0.00 ACC 0.21875 on epoch=849
04/25/2022 18:12:25 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=854
04/25/2022 18:12:27 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=859
04/25/2022 18:12:30 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=864
04/25/2022 18:12:32 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=869
04/25/2022 18:12:34 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=874
04/25/2022 18:12:37 - INFO - __main__ - Global step 1750 Train loss 0.01 ACC 0.15625 on epoch=874
04/25/2022 18:12:40 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.03 on epoch=879
04/25/2022 18:12:42 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=884
04/25/2022 18:12:45 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=889
04/25/2022 18:12:47 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=894
04/25/2022 18:12:50 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=899
04/25/2022 18:12:52 - INFO - __main__ - Global step 1800 Train loss 0.01 ACC 0.125 on epoch=899
04/25/2022 18:12:55 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=904
04/25/2022 18:12:57 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=909
04/25/2022 18:13:00 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=914
04/25/2022 18:13:02 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=919
04/25/2022 18:13:05 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=924
04/25/2022 18:13:07 - INFO - __main__ - Global step 1850 Train loss 0.01 ACC 0.21875 on epoch=924
04/25/2022 18:13:10 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=929
04/25/2022 18:13:12 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=934
04/25/2022 18:13:15 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=939
04/25/2022 18:13:17 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=944
04/25/2022 18:13:20 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=949
04/25/2022 18:13:22 - INFO - __main__ - Global step 1900 Train loss 0.00 ACC 0.28125 on epoch=949
04/25/2022 18:13:25 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=954
04/25/2022 18:13:27 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=959
04/25/2022 18:13:30 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=964
04/25/2022 18:13:32 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=969
04/25/2022 18:13:35 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=974
04/25/2022 18:13:37 - INFO - __main__ - Global step 1950 Train loss 0.01 ACC 0.25 on epoch=974
04/25/2022 18:13:40 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=979
04/25/2022 18:13:42 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=984
04/25/2022 18:13:45 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=989
04/25/2022 18:13:47 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=994
04/25/2022 18:13:50 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=999
04/25/2022 18:13:51 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 18:13:51 - INFO - __main__ - Printing 3 examples
04/25/2022 18:13:51 - INFO - __main__ -  [openbookqa] a lack of illumination would result in which of these? (A) the restroom overflowing with water (B) a principal's door being locked (C) a student unable to view what he is writing (D) a teacher being unable to transport to school
04/25/2022 18:13:51 - INFO - __main__ - ['a student unable to view what he is writing']
04/25/2022 18:13:51 - INFO - __main__ -  [openbookqa] The quickness of this animal is a key change that allows it to escape attacks from feasting animals: (A) the praying mantis (B) the potato bug (C) antelope (D) the eagle
04/25/2022 18:13:51 - INFO - __main__ - ['antelope']
04/25/2022 18:13:51 - INFO - __main__ -  [openbookqa] Vegetables provide a lot of nutrients for (A) cats (B) dogs (C) humans (D) snakes
04/25/2022 18:13:51 - INFO - __main__ - ['humans']
04/25/2022 18:13:51 - INFO - __main__ - Tokenizing Input ...
04/25/2022 18:13:51 - INFO - __main__ - Tokenizing Output ...
04/25/2022 18:13:51 - INFO - __main__ - Loaded 32 examples from train data
04/25/2022 18:13:51 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 18:13:51 - INFO - __main__ - Printing 3 examples
04/25/2022 18:13:51 - INFO - __main__ -  [openbookqa] A bird eating a lizard is an example of what type of relationship? (A) symbiotic (B) producer (C) parasitic (D) predatory
04/25/2022 18:13:51 - INFO - __main__ - ['predatory']
04/25/2022 18:13:51 - INFO - __main__ -  [openbookqa] Where would you find the most sunlight? (A) England (B) Morocco (C) Sweden (D) Norway
04/25/2022 18:13:51 - INFO - __main__ - ['Morocco']
04/25/2022 18:13:51 - INFO - __main__ -  [openbookqa] Microscopes (A) make tiny atoms look smaller (B) enhance the size of amoebas for easier viewing (C) make magnifying things much more difficult (D) make huge samples look minuscule
04/25/2022 18:13:51 - INFO - __main__ - ['enhance the size of amoebas for easier viewing']
04/25/2022 18:13:51 - INFO - __main__ - Tokenizing Input ...
04/25/2022 18:13:51 - INFO - __main__ - Tokenizing Output ...
04/25/2022 18:13:51 - INFO - __main__ - Loaded 32 examples from dev data
04/25/2022 18:13:52 - INFO - __main__ - Global step 2000 Train loss 0.01 ACC 0.21875 on epoch=999
04/25/2022 18:13:52 - INFO - __main__ - save last model!
04/25/2022 18:13:52 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
04/25/2022 18:13:52 - INFO - __main__ - Start tokenizing ... 500 instances
04/25/2022 18:13:52 - INFO - __main__ - Printing 3 examples
04/25/2022 18:13:52 - INFO - __main__ -  [openbookqa] Frilled sharks and angler fish live far beneath the surface of the ocean, which is why they are known as (A) Deep sea animals (B) fish (C) Long Sea Fish (D) Far Sea Animals
04/25/2022 18:13:52 - INFO - __main__ - ['Deep sea animals']
04/25/2022 18:13:52 - INFO - __main__ -  [openbookqa] Gas can fill any container it is given, and liquid (A) is standard weight and size (B) is the opposite of variable (C) only needs a few (D) uses what it needs
04/25/2022 18:13:52 - INFO - __main__ - ['uses what it needs']
04/25/2022 18:13:52 - INFO - __main__ -  [openbookqa] When birds migrate south for the winter, they do it because (A) they are genetically called to (B) their children ask for them to (C) it is important to their happiness (D) they decide to each year
04/25/2022 18:13:52 - INFO - __main__ - ['they are genetically called to']
04/25/2022 18:13:52 - INFO - __main__ - Tokenizing Input ...
04/25/2022 18:13:53 - INFO - __main__ - Tokenizing Output ...
04/25/2022 18:13:53 - INFO - __main__ - Loaded 500 examples from test data
04/25/2022 18:14:07 - INFO - __main__ - load prompt embedding from ckpt
04/25/2022 18:14:07 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/25/2022 18:14:07 - INFO - __main__ - Starting training!
04/25/2022 18:14:24 - INFO - __main__ - Saved prediction in models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-openbookqa/openbookqa_32_21_0.3_8_predictions.txt
04/25/2022 18:14:24 - INFO - __main__ - ACC on test data: 0.2500
04/25/2022 18:14:24 - INFO - __main__ - prefix=openbookqa_32_21, lr=0.3, bsz=8, dev_performance=0.3125, test_performance=0.25
04/25/2022 18:14:24 - INFO - __main__ - Running ... prefix=openbookqa_32_21, lr=0.2, bsz=8 ...
04/25/2022 18:14:25 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 18:14:25 - INFO - __main__ - Printing 3 examples
04/25/2022 18:14:25 - INFO - __main__ -  [openbookqa] a lack of illumination would result in which of these? (A) the restroom overflowing with water (B) a principal's door being locked (C) a student unable to view what he is writing (D) a teacher being unable to transport to school
04/25/2022 18:14:25 - INFO - __main__ - ['a student unable to view what he is writing']
04/25/2022 18:14:25 - INFO - __main__ -  [openbookqa] The quickness of this animal is a key change that allows it to escape attacks from feasting animals: (A) the praying mantis (B) the potato bug (C) antelope (D) the eagle
04/25/2022 18:14:25 - INFO - __main__ - ['antelope']
04/25/2022 18:14:25 - INFO - __main__ -  [openbookqa] Vegetables provide a lot of nutrients for (A) cats (B) dogs (C) humans (D) snakes
04/25/2022 18:14:25 - INFO - __main__ - ['humans']
04/25/2022 18:14:25 - INFO - __main__ - Tokenizing Input ...
04/25/2022 18:14:25 - INFO - __main__ - Tokenizing Output ...
04/25/2022 18:14:25 - INFO - __main__ - Loaded 32 examples from train data
04/25/2022 18:14:25 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 18:14:25 - INFO - __main__ - Printing 3 examples
04/25/2022 18:14:25 - INFO - __main__ -  [openbookqa] A bird eating a lizard is an example of what type of relationship? (A) symbiotic (B) producer (C) parasitic (D) predatory
04/25/2022 18:14:25 - INFO - __main__ - ['predatory']
04/25/2022 18:14:25 - INFO - __main__ -  [openbookqa] Where would you find the most sunlight? (A) England (B) Morocco (C) Sweden (D) Norway
04/25/2022 18:14:25 - INFO - __main__ - ['Morocco']
04/25/2022 18:14:25 - INFO - __main__ -  [openbookqa] Microscopes (A) make tiny atoms look smaller (B) enhance the size of amoebas for easier viewing (C) make magnifying things much more difficult (D) make huge samples look minuscule
04/25/2022 18:14:25 - INFO - __main__ - ['enhance the size of amoebas for easier viewing']
04/25/2022 18:14:25 - INFO - __main__ - Tokenizing Input ...
04/25/2022 18:14:25 - INFO - __main__ - Tokenizing Output ...
04/25/2022 18:14:25 - INFO - __main__ - Loaded 32 examples from dev data
04/25/2022 18:14:41 - INFO - __main__ - load prompt embedding from ckpt
04/25/2022 18:14:41 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/25/2022 18:14:41 - INFO - __main__ - Starting training!
04/25/2022 18:14:44 - INFO - __main__ - Step 10 Global step 10 Train loss 1.89 on epoch=4
04/25/2022 18:14:47 - INFO - __main__ - Step 20 Global step 20 Train loss 1.64 on epoch=9
04/25/2022 18:14:49 - INFO - __main__ - Step 30 Global step 30 Train loss 1.27 on epoch=14
04/25/2022 18:14:52 - INFO - __main__ - Step 40 Global step 40 Train loss 1.01 on epoch=19
04/25/2022 18:14:54 - INFO - __main__ - Step 50 Global step 50 Train loss 0.84 on epoch=24
04/25/2022 18:14:56 - INFO - __main__ - Global step 50 Train loss 1.33 ACC 0.21875 on epoch=24
04/25/2022 18:14:56 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.21875 on epoch=24, global_step=50
04/25/2022 18:14:58 - INFO - __main__ - Step 60 Global step 60 Train loss 0.72 on epoch=29
04/25/2022 18:15:01 - INFO - __main__ - Step 70 Global step 70 Train loss 0.55 on epoch=34
04/25/2022 18:15:03 - INFO - __main__ - Step 80 Global step 80 Train loss 0.55 on epoch=39
04/25/2022 18:15:06 - INFO - __main__ - Step 90 Global step 90 Train loss 0.49 on epoch=44
04/25/2022 18:15:08 - INFO - __main__ - Step 100 Global step 100 Train loss 0.47 on epoch=49
04/25/2022 18:15:10 - INFO - __main__ - Global step 100 Train loss 0.56 ACC 0.21875 on epoch=49
04/25/2022 18:15:13 - INFO - __main__ - Step 110 Global step 110 Train loss 0.42 on epoch=54
04/25/2022 18:15:15 - INFO - __main__ - Step 120 Global step 120 Train loss 0.30 on epoch=59
04/25/2022 18:15:18 - INFO - __main__ - Step 130 Global step 130 Train loss 0.26 on epoch=64
04/25/2022 18:15:20 - INFO - __main__ - Step 140 Global step 140 Train loss 0.32 on epoch=69
04/25/2022 18:15:22 - INFO - __main__ - Step 150 Global step 150 Train loss 0.27 on epoch=74
04/25/2022 18:15:24 - INFO - __main__ - Global step 150 Train loss 0.31 ACC 0.21875 on epoch=74
04/25/2022 18:15:27 - INFO - __main__ - Step 160 Global step 160 Train loss 0.22 on epoch=79
04/25/2022 18:15:29 - INFO - __main__ - Step 170 Global step 170 Train loss 0.22 on epoch=84
04/25/2022 18:15:32 - INFO - __main__ - Step 180 Global step 180 Train loss 0.22 on epoch=89
04/25/2022 18:15:34 - INFO - __main__ - Step 190 Global step 190 Train loss 0.21 on epoch=94
04/25/2022 18:15:36 - INFO - __main__ - Step 200 Global step 200 Train loss 0.21 on epoch=99
04/25/2022 18:15:38 - INFO - __main__ - Global step 200 Train loss 0.22 ACC 0.25 on epoch=99
04/25/2022 18:15:38 - INFO - __main__ - Saving model with best ACC: 0.21875 -> 0.25 on epoch=99, global_step=200
04/25/2022 18:15:41 - INFO - __main__ - Step 210 Global step 210 Train loss 0.21 on epoch=104
04/25/2022 18:15:43 - INFO - __main__ - Step 220 Global step 220 Train loss 0.14 on epoch=109
04/25/2022 18:15:46 - INFO - __main__ - Step 230 Global step 230 Train loss 0.16 on epoch=114
04/25/2022 18:15:48 - INFO - __main__ - Step 240 Global step 240 Train loss 0.09 on epoch=119
04/25/2022 18:15:51 - INFO - __main__ - Step 250 Global step 250 Train loss 0.15 on epoch=124
04/25/2022 18:15:53 - INFO - __main__ - Global step 250 Train loss 0.15 ACC 0.3125 on epoch=124
04/25/2022 18:15:53 - INFO - __main__ - Saving model with best ACC: 0.25 -> 0.3125 on epoch=124, global_step=250
04/25/2022 18:15:55 - INFO - __main__ - Step 260 Global step 260 Train loss 0.18 on epoch=129
04/25/2022 18:15:58 - INFO - __main__ - Step 270 Global step 270 Train loss 0.12 on epoch=134
04/25/2022 18:16:00 - INFO - __main__ - Step 280 Global step 280 Train loss 0.12 on epoch=139
04/25/2022 18:16:02 - INFO - __main__ - Step 290 Global step 290 Train loss 0.11 on epoch=144
04/25/2022 18:16:05 - INFO - __main__ - Step 300 Global step 300 Train loss 0.11 on epoch=149
04/25/2022 18:16:07 - INFO - __main__ - Global step 300 Train loss 0.13 ACC 0.34375 on epoch=149
04/25/2022 18:16:07 - INFO - __main__ - Saving model with best ACC: 0.3125 -> 0.34375 on epoch=149, global_step=300
04/25/2022 18:16:09 - INFO - __main__ - Step 310 Global step 310 Train loss 0.16 on epoch=154
04/25/2022 18:16:12 - INFO - __main__ - Step 320 Global step 320 Train loss 0.11 on epoch=159
04/25/2022 18:16:14 - INFO - __main__ - Step 330 Global step 330 Train loss 0.08 on epoch=164
04/25/2022 18:16:16 - INFO - __main__ - Step 340 Global step 340 Train loss 0.07 on epoch=169
04/25/2022 18:16:19 - INFO - __main__ - Step 350 Global step 350 Train loss 0.12 on epoch=174
04/25/2022 18:16:21 - INFO - __main__ - Global step 350 Train loss 0.11 ACC 0.34375 on epoch=174
04/25/2022 18:16:24 - INFO - __main__ - Step 360 Global step 360 Train loss 0.07 on epoch=179
04/25/2022 18:16:26 - INFO - __main__ - Step 370 Global step 370 Train loss 0.09 on epoch=184
04/25/2022 18:16:28 - INFO - __main__ - Step 380 Global step 380 Train loss 0.11 on epoch=189
04/25/2022 18:16:31 - INFO - __main__ - Step 390 Global step 390 Train loss 0.07 on epoch=194
04/25/2022 18:16:33 - INFO - __main__ - Step 400 Global step 400 Train loss 0.09 on epoch=199
04/25/2022 18:16:35 - INFO - __main__ - Global step 400 Train loss 0.09 ACC 0.34375 on epoch=199
04/25/2022 18:16:38 - INFO - __main__ - Step 410 Global step 410 Train loss 0.08 on epoch=204
04/25/2022 18:16:40 - INFO - __main__ - Step 420 Global step 420 Train loss 0.06 on epoch=209
04/25/2022 18:16:43 - INFO - __main__ - Step 430 Global step 430 Train loss 0.09 on epoch=214
04/25/2022 18:16:45 - INFO - __main__ - Step 440 Global step 440 Train loss 0.04 on epoch=219
04/25/2022 18:16:47 - INFO - __main__ - Step 450 Global step 450 Train loss 0.05 on epoch=224
04/25/2022 18:16:50 - INFO - __main__ - Global step 450 Train loss 0.06 ACC 0.40625 on epoch=224
04/25/2022 18:16:50 - INFO - __main__ - Saving model with best ACC: 0.34375 -> 0.40625 on epoch=224, global_step=450
04/25/2022 18:16:52 - INFO - __main__ - Step 460 Global step 460 Train loss 0.05 on epoch=229
04/25/2022 18:16:55 - INFO - __main__ - Step 470 Global step 470 Train loss 0.06 on epoch=234
04/25/2022 18:16:57 - INFO - __main__ - Step 480 Global step 480 Train loss 0.05 on epoch=239
04/25/2022 18:17:00 - INFO - __main__ - Step 490 Global step 490 Train loss 0.07 on epoch=244
04/25/2022 18:17:02 - INFO - __main__ - Step 500 Global step 500 Train loss 0.03 on epoch=249
04/25/2022 18:17:04 - INFO - __main__ - Global step 500 Train loss 0.05 ACC 0.375 on epoch=249
04/25/2022 18:17:07 - INFO - __main__ - Step 510 Global step 510 Train loss 0.10 on epoch=254
04/25/2022 18:17:09 - INFO - __main__ - Step 520 Global step 520 Train loss 0.05 on epoch=259
04/25/2022 18:17:12 - INFO - __main__ - Step 530 Global step 530 Train loss 0.03 on epoch=264
04/25/2022 18:17:14 - INFO - __main__ - Step 540 Global step 540 Train loss 0.05 on epoch=269
04/25/2022 18:17:17 - INFO - __main__ - Step 550 Global step 550 Train loss 0.04 on epoch=274
04/25/2022 18:17:19 - INFO - __main__ - Global step 550 Train loss 0.05 ACC 0.34375 on epoch=274
04/25/2022 18:17:21 - INFO - __main__ - Step 560 Global step 560 Train loss 0.03 on epoch=279
04/25/2022 18:17:24 - INFO - __main__ - Step 570 Global step 570 Train loss 0.03 on epoch=284
04/25/2022 18:17:26 - INFO - __main__ - Step 580 Global step 580 Train loss 0.06 on epoch=289
04/25/2022 18:17:29 - INFO - __main__ - Step 590 Global step 590 Train loss 0.03 on epoch=294
04/25/2022 18:17:31 - INFO - __main__ - Step 600 Global step 600 Train loss 0.04 on epoch=299
04/25/2022 18:17:33 - INFO - __main__ - Global step 600 Train loss 0.04 ACC 0.34375 on epoch=299
04/25/2022 18:17:36 - INFO - __main__ - Step 610 Global step 610 Train loss 0.05 on epoch=304
04/25/2022 18:17:38 - INFO - __main__ - Step 620 Global step 620 Train loss 0.07 on epoch=309
04/25/2022 18:17:41 - INFO - __main__ - Step 630 Global step 630 Train loss 0.02 on epoch=314
04/25/2022 18:17:43 - INFO - __main__ - Step 640 Global step 640 Train loss 0.02 on epoch=319
04/25/2022 18:17:45 - INFO - __main__ - Step 650 Global step 650 Train loss 0.03 on epoch=324
04/25/2022 18:17:47 - INFO - __main__ - Global step 650 Train loss 0.04 ACC 0.375 on epoch=324
04/25/2022 18:17:50 - INFO - __main__ - Step 660 Global step 660 Train loss 0.02 on epoch=329
04/25/2022 18:17:52 - INFO - __main__ - Step 670 Global step 670 Train loss 0.03 on epoch=334
04/25/2022 18:17:55 - INFO - __main__ - Step 680 Global step 680 Train loss 0.05 on epoch=339
04/25/2022 18:17:57 - INFO - __main__ - Step 690 Global step 690 Train loss 0.03 on epoch=344
04/25/2022 18:18:00 - INFO - __main__ - Step 700 Global step 700 Train loss 0.02 on epoch=349
04/25/2022 18:18:02 - INFO - __main__ - Global step 700 Train loss 0.03 ACC 0.375 on epoch=349
04/25/2022 18:18:05 - INFO - __main__ - Step 710 Global step 710 Train loss 0.05 on epoch=354
04/25/2022 18:18:07 - INFO - __main__ - Step 720 Global step 720 Train loss 0.04 on epoch=359
04/25/2022 18:18:09 - INFO - __main__ - Step 730 Global step 730 Train loss 0.03 on epoch=364
04/25/2022 18:18:12 - INFO - __main__ - Step 740 Global step 740 Train loss 0.04 on epoch=369
04/25/2022 18:18:14 - INFO - __main__ - Step 750 Global step 750 Train loss 0.02 on epoch=374
04/25/2022 18:18:17 - INFO - __main__ - Global step 750 Train loss 0.03 ACC 0.375 on epoch=374
04/25/2022 18:18:19 - INFO - __main__ - Step 760 Global step 760 Train loss 0.02 on epoch=379
04/25/2022 18:18:22 - INFO - __main__ - Step 770 Global step 770 Train loss 0.01 on epoch=384
04/25/2022 18:18:24 - INFO - __main__ - Step 780 Global step 780 Train loss 0.03 on epoch=389
04/25/2022 18:18:27 - INFO - __main__ - Step 790 Global step 790 Train loss 0.04 on epoch=394
04/25/2022 18:18:29 - INFO - __main__ - Step 800 Global step 800 Train loss 0.03 on epoch=399
04/25/2022 18:18:31 - INFO - __main__ - Global step 800 Train loss 0.03 ACC 0.375 on epoch=399
04/25/2022 18:18:34 - INFO - __main__ - Step 810 Global step 810 Train loss 0.02 on epoch=404
04/25/2022 18:18:36 - INFO - __main__ - Step 820 Global step 820 Train loss 0.05 on epoch=409
04/25/2022 18:18:39 - INFO - __main__ - Step 830 Global step 830 Train loss 0.03 on epoch=414
04/25/2022 18:18:41 - INFO - __main__ - Step 840 Global step 840 Train loss 0.03 on epoch=419
04/25/2022 18:18:43 - INFO - __main__ - Step 850 Global step 850 Train loss 0.03 on epoch=424
04/25/2022 18:18:46 - INFO - __main__ - Global step 850 Train loss 0.03 ACC 0.40625 on epoch=424
04/25/2022 18:18:48 - INFO - __main__ - Step 860 Global step 860 Train loss 0.04 on epoch=429
04/25/2022 18:18:51 - INFO - __main__ - Step 870 Global step 870 Train loss 0.01 on epoch=434
04/25/2022 18:18:53 - INFO - __main__ - Step 880 Global step 880 Train loss 0.02 on epoch=439
04/25/2022 18:18:56 - INFO - __main__ - Step 890 Global step 890 Train loss 0.01 on epoch=444
04/25/2022 18:18:58 - INFO - __main__ - Step 900 Global step 900 Train loss 0.02 on epoch=449
04/25/2022 18:19:00 - INFO - __main__ - Global step 900 Train loss 0.02 ACC 0.34375 on epoch=449
04/25/2022 18:19:03 - INFO - __main__ - Step 910 Global step 910 Train loss 0.01 on epoch=454
04/25/2022 18:19:05 - INFO - __main__ - Step 920 Global step 920 Train loss 0.02 on epoch=459
04/25/2022 18:19:08 - INFO - __main__ - Step 930 Global step 930 Train loss 0.03 on epoch=464
04/25/2022 18:19:10 - INFO - __main__ - Step 940 Global step 940 Train loss 0.03 on epoch=469
04/25/2022 18:19:12 - INFO - __main__ - Step 950 Global step 950 Train loss 0.02 on epoch=474
04/25/2022 18:19:15 - INFO - __main__ - Global step 950 Train loss 0.02 ACC 0.34375 on epoch=474
04/25/2022 18:19:17 - INFO - __main__ - Step 960 Global step 960 Train loss 0.04 on epoch=479
04/25/2022 18:19:20 - INFO - __main__ - Step 970 Global step 970 Train loss 0.01 on epoch=484
04/25/2022 18:19:22 - INFO - __main__ - Step 980 Global step 980 Train loss 0.01 on epoch=489
04/25/2022 18:19:25 - INFO - __main__ - Step 990 Global step 990 Train loss 0.02 on epoch=494
04/25/2022 18:19:27 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.04 on epoch=499
04/25/2022 18:19:29 - INFO - __main__ - Global step 1000 Train loss 0.02 ACC 0.34375 on epoch=499
04/25/2022 18:19:32 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.02 on epoch=504
04/25/2022 18:19:34 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.02 on epoch=509
04/25/2022 18:19:37 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.03 on epoch=514
04/25/2022 18:19:39 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.02 on epoch=519
04/25/2022 18:19:42 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.01 on epoch=524
04/25/2022 18:19:44 - INFO - __main__ - Global step 1050 Train loss 0.02 ACC 0.28125 on epoch=524
04/25/2022 18:19:46 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.03 on epoch=529
04/25/2022 18:19:49 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.01 on epoch=534
04/25/2022 18:19:51 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.04 on epoch=539
04/25/2022 18:19:54 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.04 on epoch=544
04/25/2022 18:19:56 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.02 on epoch=549
04/25/2022 18:19:58 - INFO - __main__ - Global step 1100 Train loss 0.03 ACC 0.4375 on epoch=549
04/25/2022 18:19:59 - INFO - __main__ - Saving model with best ACC: 0.40625 -> 0.4375 on epoch=549, global_step=1100
04/25/2022 18:20:01 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.02 on epoch=554
04/25/2022 18:20:03 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=559
04/25/2022 18:20:06 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.02 on epoch=564
04/25/2022 18:20:08 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.01 on epoch=569
04/25/2022 18:20:11 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.03 on epoch=574
04/25/2022 18:20:13 - INFO - __main__ - Global step 1150 Train loss 0.02 ACC 0.34375 on epoch=574
04/25/2022 18:20:15 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.03 on epoch=579
04/25/2022 18:20:18 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.02 on epoch=584
04/25/2022 18:20:20 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.01 on epoch=589
04/25/2022 18:20:23 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.03 on epoch=594
04/25/2022 18:20:25 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.06 on epoch=599
04/25/2022 18:20:28 - INFO - __main__ - Global step 1200 Train loss 0.03 ACC 0.40625 on epoch=599
04/25/2022 18:20:30 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.04 on epoch=604
04/25/2022 18:20:33 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.03 on epoch=609
04/25/2022 18:20:35 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.04 on epoch=614
04/25/2022 18:20:37 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.02 on epoch=619
04/25/2022 18:20:40 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.01 on epoch=624
04/25/2022 18:20:42 - INFO - __main__ - Global step 1250 Train loss 0.03 ACC 0.375 on epoch=624
04/25/2022 18:20:45 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.02 on epoch=629
04/25/2022 18:20:47 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.01 on epoch=634
04/25/2022 18:20:49 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.00 on epoch=639
04/25/2022 18:20:52 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=644
04/25/2022 18:20:54 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=649
04/25/2022 18:20:57 - INFO - __main__ - Global step 1300 Train loss 0.01 ACC 0.40625 on epoch=649
04/25/2022 18:20:59 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.00 on epoch=654
04/25/2022 18:21:01 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=659
04/25/2022 18:21:04 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=664
04/25/2022 18:21:06 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.00 on epoch=669
04/25/2022 18:21:09 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=674
04/25/2022 18:21:11 - INFO - __main__ - Global step 1350 Train loss 0.01 ACC 0.34375 on epoch=674
04/25/2022 18:21:13 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=679
04/25/2022 18:21:16 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.03 on epoch=684
04/25/2022 18:21:18 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.03 on epoch=689
04/25/2022 18:21:21 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.00 on epoch=694
04/25/2022 18:21:23 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=699
04/25/2022 18:21:25 - INFO - __main__ - Global step 1400 Train loss 0.02 ACC 0.3125 on epoch=699
04/25/2022 18:21:28 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=704
04/25/2022 18:21:30 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=709
04/25/2022 18:21:33 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=714
04/25/2022 18:21:35 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=719
04/25/2022 18:21:38 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=724
04/25/2022 18:21:40 - INFO - __main__ - Global step 1450 Train loss 0.01 ACC 0.375 on epoch=724
04/25/2022 18:21:42 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.02 on epoch=729
04/25/2022 18:21:45 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.02 on epoch=734
04/25/2022 18:21:47 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=739
04/25/2022 18:21:50 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.03 on epoch=744
04/25/2022 18:21:52 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.02 on epoch=749
04/25/2022 18:21:54 - INFO - __main__ - Global step 1500 Train loss 0.02 ACC 0.375 on epoch=749
04/25/2022 18:21:57 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=754
04/25/2022 18:21:59 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=759
04/25/2022 18:22:02 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=764
04/25/2022 18:22:04 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=769
04/25/2022 18:22:07 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=774
04/25/2022 18:22:09 - INFO - __main__ - Global step 1550 Train loss 0.01 ACC 0.375 on epoch=774
04/25/2022 18:22:12 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=779
04/25/2022 18:22:14 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=784
04/25/2022 18:22:17 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=789
04/25/2022 18:22:19 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=794
04/25/2022 18:22:22 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=799
04/25/2022 18:22:24 - INFO - __main__ - Global step 1600 Train loss 0.01 ACC 0.375 on epoch=799
04/25/2022 18:22:26 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=804
04/25/2022 18:22:29 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=809
04/25/2022 18:22:31 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=814
04/25/2022 18:22:34 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=819
04/25/2022 18:22:36 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=824
04/25/2022 18:22:39 - INFO - __main__ - Global step 1650 Train loss 0.01 ACC 0.40625 on epoch=824
04/25/2022 18:22:41 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=829
04/25/2022 18:22:44 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=834
04/25/2022 18:22:46 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=839
04/25/2022 18:22:49 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=844
04/25/2022 18:22:51 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=849
04/25/2022 18:22:53 - INFO - __main__ - Global step 1700 Train loss 0.01 ACC 0.28125 on epoch=849
04/25/2022 18:22:56 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=854
04/25/2022 18:22:58 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=859
04/25/2022 18:23:01 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=864
04/25/2022 18:23:03 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=869
04/25/2022 18:23:06 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=874
04/25/2022 18:23:08 - INFO - __main__ - Global step 1750 Train loss 0.01 ACC 0.3125 on epoch=874
04/25/2022 18:23:11 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=879
04/25/2022 18:23:13 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=884
04/25/2022 18:23:16 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=889
04/25/2022 18:23:18 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=894
04/25/2022 18:23:21 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=899
04/25/2022 18:23:23 - INFO - __main__ - Global step 1800 Train loss 0.01 ACC 0.3125 on epoch=899
04/25/2022 18:23:26 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=904
04/25/2022 18:23:28 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=909
04/25/2022 18:23:31 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=914
04/25/2022 18:23:33 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=919
04/25/2022 18:23:36 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=924
04/25/2022 18:23:38 - INFO - __main__ - Global step 1850 Train loss 0.01 ACC 0.34375 on epoch=924
04/25/2022 18:23:40 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=929
04/25/2022 18:23:43 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=934
04/25/2022 18:23:45 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=939
04/25/2022 18:23:48 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=944
04/25/2022 18:23:50 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=949
04/25/2022 18:23:53 - INFO - __main__ - Global step 1900 Train loss 0.01 ACC 0.3125 on epoch=949
04/25/2022 18:23:55 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=954
04/25/2022 18:23:58 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=959
04/25/2022 18:24:00 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=964
04/25/2022 18:24:03 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=969
04/25/2022 18:24:05 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=974
04/25/2022 18:24:08 - INFO - __main__ - Global step 1950 Train loss 0.01 ACC 0.375 on epoch=974
04/25/2022 18:24:10 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.03 on epoch=979
04/25/2022 18:24:13 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=984
04/25/2022 18:24:15 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=989
04/25/2022 18:24:18 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=994
04/25/2022 18:24:20 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=999
04/25/2022 18:24:21 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 18:24:21 - INFO - __main__ - Printing 3 examples
04/25/2022 18:24:21 - INFO - __main__ -  [openbookqa] Which is likeliest to metamorphose? (A) a live insect (B) a human (C) a plant (D) a dead butterfly
04/25/2022 18:24:21 - INFO - __main__ - ['a live insect']
04/25/2022 18:24:21 - INFO - __main__ -  [openbookqa] Which animal is most likely to eat another living animal? (A) deer (B) elephant (C) worm (D) lion
04/25/2022 18:24:21 - INFO - __main__ - ['lion']
04/25/2022 18:24:21 - INFO - __main__ -  [openbookqa] If a see through thing is multifaceted, it is most likely (A) a ball (B) an apple (C) a silver globe (D) a quartz square
04/25/2022 18:24:21 - INFO - __main__ - ['a quartz square']
04/25/2022 18:24:21 - INFO - __main__ - Tokenizing Input ...
04/25/2022 18:24:21 - INFO - __main__ - Tokenizing Output ...
04/25/2022 18:24:21 - INFO - __main__ - Loaded 32 examples from train data
04/25/2022 18:24:21 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 18:24:21 - INFO - __main__ - Printing 3 examples
04/25/2022 18:24:21 - INFO - __main__ -  [openbookqa] An organism that can survive without the help of other cells is (A) Brewer's yeast (B) air (C) sand (D) sugar
04/25/2022 18:24:21 - INFO - __main__ - ["Brewer's yeast"]
04/25/2022 18:24:21 - INFO - __main__ -  [openbookqa] some animals remove their hair coverings for (A) naptime (B) lunchtime (C) mating season (D) scorching climates
04/25/2022 18:24:21 - INFO - __main__ - ['scorching climates']
04/25/2022 18:24:21 - INFO - __main__ -  [openbookqa] Which animal sometimes needs to move quickly for food? (A) coyote (B) horse (C) deer (D) buffalo
04/25/2022 18:24:21 - INFO - __main__ - ['coyote']
04/25/2022 18:24:21 - INFO - __main__ - Tokenizing Input ...
04/25/2022 18:24:21 - INFO - __main__ - Tokenizing Output ...
04/25/2022 18:24:22 - INFO - __main__ - Loaded 32 examples from dev data
04/25/2022 18:24:22 - INFO - __main__ - Global step 2000 Train loss 0.01 ACC 0.28125 on epoch=999
04/25/2022 18:24:22 - INFO - __main__ - save last model!
04/25/2022 18:24:23 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
04/25/2022 18:24:23 - INFO - __main__ - Start tokenizing ... 500 instances
04/25/2022 18:24:23 - INFO - __main__ - Printing 3 examples
04/25/2022 18:24:23 - INFO - __main__ -  [openbookqa] Frilled sharks and angler fish live far beneath the surface of the ocean, which is why they are known as (A) Deep sea animals (B) fish (C) Long Sea Fish (D) Far Sea Animals
04/25/2022 18:24:23 - INFO - __main__ - ['Deep sea animals']
04/25/2022 18:24:23 - INFO - __main__ -  [openbookqa] Gas can fill any container it is given, and liquid (A) is standard weight and size (B) is the opposite of variable (C) only needs a few (D) uses what it needs
04/25/2022 18:24:23 - INFO - __main__ - ['uses what it needs']
04/25/2022 18:24:23 - INFO - __main__ -  [openbookqa] When birds migrate south for the winter, they do it because (A) they are genetically called to (B) their children ask for them to (C) it is important to their happiness (D) they decide to each year
04/25/2022 18:24:23 - INFO - __main__ - ['they are genetically called to']
04/25/2022 18:24:23 - INFO - __main__ - Tokenizing Input ...
04/25/2022 18:24:23 - INFO - __main__ - Tokenizing Output ...
04/25/2022 18:24:23 - INFO - __main__ - Loaded 500 examples from test data
04/25/2022 18:24:38 - INFO - __main__ - load prompt embedding from ckpt
04/25/2022 18:24:39 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/25/2022 18:24:39 - INFO - __main__ - Starting training!
04/25/2022 18:24:54 - INFO - __main__ - Saved prediction in models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-openbookqa/openbookqa_32_21_0.2_8_predictions.txt
04/25/2022 18:24:54 - INFO - __main__ - ACC on test data: 0.2620
04/25/2022 18:24:54 - INFO - __main__ - prefix=openbookqa_32_21, lr=0.2, bsz=8, dev_performance=0.4375, test_performance=0.262
04/25/2022 18:24:54 - INFO - __main__ - Running ... prefix=openbookqa_32_42, lr=0.5, bsz=8 ...
04/25/2022 18:24:55 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 18:24:55 - INFO - __main__ - Printing 3 examples
04/25/2022 18:24:55 - INFO - __main__ -  [openbookqa] Which is likeliest to metamorphose? (A) a live insect (B) a human (C) a plant (D) a dead butterfly
04/25/2022 18:24:55 - INFO - __main__ - ['a live insect']
04/25/2022 18:24:55 - INFO - __main__ -  [openbookqa] Which animal is most likely to eat another living animal? (A) deer (B) elephant (C) worm (D) lion
04/25/2022 18:24:55 - INFO - __main__ - ['lion']
04/25/2022 18:24:55 - INFO - __main__ -  [openbookqa] If a see through thing is multifaceted, it is most likely (A) a ball (B) an apple (C) a silver globe (D) a quartz square
04/25/2022 18:24:55 - INFO - __main__ - ['a quartz square']
04/25/2022 18:24:55 - INFO - __main__ - Tokenizing Input ...
04/25/2022 18:24:55 - INFO - __main__ - Tokenizing Output ...
04/25/2022 18:24:55 - INFO - __main__ - Loaded 32 examples from train data
04/25/2022 18:24:55 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 18:24:55 - INFO - __main__ - Printing 3 examples
04/25/2022 18:24:55 - INFO - __main__ -  [openbookqa] An organism that can survive without the help of other cells is (A) Brewer's yeast (B) air (C) sand (D) sugar
04/25/2022 18:24:55 - INFO - __main__ - ["Brewer's yeast"]
04/25/2022 18:24:55 - INFO - __main__ -  [openbookqa] some animals remove their hair coverings for (A) naptime (B) lunchtime (C) mating season (D) scorching climates
04/25/2022 18:24:55 - INFO - __main__ - ['scorching climates']
04/25/2022 18:24:55 - INFO - __main__ -  [openbookqa] Which animal sometimes needs to move quickly for food? (A) coyote (B) horse (C) deer (D) buffalo
04/25/2022 18:24:55 - INFO - __main__ - ['coyote']
04/25/2022 18:24:55 - INFO - __main__ - Tokenizing Input ...
04/25/2022 18:24:55 - INFO - __main__ - Tokenizing Output ...
04/25/2022 18:24:55 - INFO - __main__ - Loaded 32 examples from dev data
04/25/2022 18:25:10 - INFO - __main__ - load prompt embedding from ckpt
04/25/2022 18:25:11 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/25/2022 18:25:11 - INFO - __main__ - Starting training!
04/25/2022 18:25:15 - INFO - __main__ - Step 10 Global step 10 Train loss 1.80 on epoch=4
04/25/2022 18:25:17 - INFO - __main__ - Step 20 Global step 20 Train loss 1.07 on epoch=9
04/25/2022 18:25:20 - INFO - __main__ - Step 30 Global step 30 Train loss 0.66 on epoch=14
04/25/2022 18:25:22 - INFO - __main__ - Step 40 Global step 40 Train loss 0.56 on epoch=19
04/25/2022 18:25:25 - INFO - __main__ - Step 50 Global step 50 Train loss 0.45 on epoch=24
04/25/2022 18:25:26 - INFO - __main__ - Global step 50 Train loss 0.91 ACC 0.21875 on epoch=24
04/25/2022 18:25:26 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.21875 on epoch=24, global_step=50
04/25/2022 18:25:29 - INFO - __main__ - Step 60 Global step 60 Train loss 0.32 on epoch=29
04/25/2022 18:25:31 - INFO - __main__ - Step 70 Global step 70 Train loss 0.30 on epoch=34
04/25/2022 18:25:34 - INFO - __main__ - Step 80 Global step 80 Train loss 0.37 on epoch=39
04/25/2022 18:25:37 - INFO - __main__ - Step 90 Global step 90 Train loss 0.25 on epoch=44
04/25/2022 18:25:39 - INFO - __main__ - Step 100 Global step 100 Train loss 0.22 on epoch=49
04/25/2022 18:25:41 - INFO - __main__ - Global step 100 Train loss 0.29 ACC 0.21875 on epoch=49
04/25/2022 18:25:43 - INFO - __main__ - Step 110 Global step 110 Train loss 0.17 on epoch=54
04/25/2022 18:25:46 - INFO - __main__ - Step 120 Global step 120 Train loss 0.22 on epoch=59
04/25/2022 18:25:48 - INFO - __main__ - Step 130 Global step 130 Train loss 0.23 on epoch=64
04/25/2022 18:25:51 - INFO - __main__ - Step 140 Global step 140 Train loss 0.15 on epoch=69
04/25/2022 18:25:53 - INFO - __main__ - Step 150 Global step 150 Train loss 0.16 on epoch=74
04/25/2022 18:25:55 - INFO - __main__ - Global step 150 Train loss 0.19 ACC 0.3125 on epoch=74
04/25/2022 18:25:55 - INFO - __main__ - Saving model with best ACC: 0.21875 -> 0.3125 on epoch=74, global_step=150
04/25/2022 18:25:58 - INFO - __main__ - Step 160 Global step 160 Train loss 0.09 on epoch=79
04/25/2022 18:26:00 - INFO - __main__ - Step 170 Global step 170 Train loss 0.11 on epoch=84
04/25/2022 18:26:03 - INFO - __main__ - Step 180 Global step 180 Train loss 0.15 on epoch=89
04/25/2022 18:26:05 - INFO - __main__ - Step 190 Global step 190 Train loss 0.08 on epoch=94
04/25/2022 18:26:08 - INFO - __main__ - Step 200 Global step 200 Train loss 0.07 on epoch=99
04/25/2022 18:26:09 - INFO - __main__ - Global step 200 Train loss 0.10 ACC 0.15625 on epoch=99
04/25/2022 18:26:12 - INFO - __main__ - Step 210 Global step 210 Train loss 0.06 on epoch=104
04/25/2022 18:26:14 - INFO - __main__ - Step 220 Global step 220 Train loss 0.11 on epoch=109
04/25/2022 18:26:17 - INFO - __main__ - Step 230 Global step 230 Train loss 0.06 on epoch=114
04/25/2022 18:26:19 - INFO - __main__ - Step 240 Global step 240 Train loss 0.08 on epoch=119
04/25/2022 18:26:22 - INFO - __main__ - Step 250 Global step 250 Train loss 0.08 on epoch=124
04/25/2022 18:26:24 - INFO - __main__ - Global step 250 Train loss 0.08 ACC 0.15625 on epoch=124
04/25/2022 18:26:26 - INFO - __main__ - Step 260 Global step 260 Train loss 0.07 on epoch=129
04/25/2022 18:26:29 - INFO - __main__ - Step 270 Global step 270 Train loss 0.06 on epoch=134
04/25/2022 18:26:31 - INFO - __main__ - Step 280 Global step 280 Train loss 0.08 on epoch=139
04/25/2022 18:26:34 - INFO - __main__ - Step 290 Global step 290 Train loss 0.09 on epoch=144
04/25/2022 18:26:36 - INFO - __main__ - Step 300 Global step 300 Train loss 0.05 on epoch=149
04/25/2022 18:26:38 - INFO - __main__ - Global step 300 Train loss 0.07 ACC 0.21875 on epoch=149
04/25/2022 18:26:40 - INFO - __main__ - Step 310 Global step 310 Train loss 0.13 on epoch=154
04/25/2022 18:26:42 - INFO - __main__ - Step 320 Global step 320 Train loss 0.04 on epoch=159
04/25/2022 18:26:45 - INFO - __main__ - Step 330 Global step 330 Train loss 0.03 on epoch=164
04/25/2022 18:26:47 - INFO - __main__ - Step 340 Global step 340 Train loss 0.04 on epoch=169
04/25/2022 18:26:50 - INFO - __main__ - Step 350 Global step 350 Train loss 0.02 on epoch=174
04/25/2022 18:26:52 - INFO - __main__ - Global step 350 Train loss 0.05 ACC 0.0625 on epoch=174
04/25/2022 18:26:54 - INFO - __main__ - Step 360 Global step 360 Train loss 0.03 on epoch=179
04/25/2022 18:26:56 - INFO - __main__ - Step 370 Global step 370 Train loss 0.02 on epoch=184
04/25/2022 18:26:59 - INFO - __main__ - Step 380 Global step 380 Train loss 0.02 on epoch=189
04/25/2022 18:27:01 - INFO - __main__ - Step 390 Global step 390 Train loss 0.02 on epoch=194
04/25/2022 18:27:04 - INFO - __main__ - Step 400 Global step 400 Train loss 0.02 on epoch=199
04/25/2022 18:27:05 - INFO - __main__ - Global step 400 Train loss 0.02 ACC 0.15625 on epoch=199
04/25/2022 18:27:08 - INFO - __main__ - Step 410 Global step 410 Train loss 0.03 on epoch=204
04/25/2022 18:27:10 - INFO - __main__ - Step 420 Global step 420 Train loss 0.03 on epoch=209
04/25/2022 18:27:13 - INFO - __main__ - Step 430 Global step 430 Train loss 0.03 on epoch=214
04/25/2022 18:27:15 - INFO - __main__ - Step 440 Global step 440 Train loss 0.02 on epoch=219
04/25/2022 18:27:18 - INFO - __main__ - Step 450 Global step 450 Train loss 0.03 on epoch=224
04/25/2022 18:27:19 - INFO - __main__ - Global step 450 Train loss 0.03 ACC 0.1875 on epoch=224
04/25/2022 18:27:22 - INFO - __main__ - Step 460 Global step 460 Train loss 0.04 on epoch=229
04/25/2022 18:27:24 - INFO - __main__ - Step 470 Global step 470 Train loss 0.02 on epoch=234
04/25/2022 18:27:26 - INFO - __main__ - Step 480 Global step 480 Train loss 0.01 on epoch=239
04/25/2022 18:27:29 - INFO - __main__ - Step 490 Global step 490 Train loss 0.02 on epoch=244
04/25/2022 18:27:31 - INFO - __main__ - Step 500 Global step 500 Train loss 0.03 on epoch=249
04/25/2022 18:27:33 - INFO - __main__ - Global step 500 Train loss 0.02 ACC 0.15625 on epoch=249
04/25/2022 18:27:36 - INFO - __main__ - Step 510 Global step 510 Train loss 0.01 on epoch=254
04/25/2022 18:27:38 - INFO - __main__ - Step 520 Global step 520 Train loss 0.03 on epoch=259
04/25/2022 18:27:40 - INFO - __main__ - Step 530 Global step 530 Train loss 0.07 on epoch=264
04/25/2022 18:27:43 - INFO - __main__ - Step 540 Global step 540 Train loss 0.07 on epoch=269
04/25/2022 18:27:45 - INFO - __main__ - Step 550 Global step 550 Train loss 0.01 on epoch=274
04/25/2022 18:27:47 - INFO - __main__ - Global step 550 Train loss 0.04 ACC 0.21875 on epoch=274
04/25/2022 18:27:50 - INFO - __main__ - Step 560 Global step 560 Train loss 0.04 on epoch=279
04/25/2022 18:27:52 - INFO - __main__ - Step 570 Global step 570 Train loss 0.04 on epoch=284
04/25/2022 18:27:55 - INFO - __main__ - Step 580 Global step 580 Train loss 0.01 on epoch=289
04/25/2022 18:27:57 - INFO - __main__ - Step 590 Global step 590 Train loss 0.01 on epoch=294
04/25/2022 18:28:00 - INFO - __main__ - Step 600 Global step 600 Train loss 0.01 on epoch=299
04/25/2022 18:28:01 - INFO - __main__ - Global step 600 Train loss 0.02 ACC 0.1875 on epoch=299
04/25/2022 18:28:04 - INFO - __main__ - Step 610 Global step 610 Train loss 0.03 on epoch=304
04/25/2022 18:28:06 - INFO - __main__ - Step 620 Global step 620 Train loss 0.02 on epoch=309
04/25/2022 18:28:09 - INFO - __main__ - Step 630 Global step 630 Train loss 0.02 on epoch=314
04/25/2022 18:28:11 - INFO - __main__ - Step 640 Global step 640 Train loss 0.04 on epoch=319
04/25/2022 18:28:14 - INFO - __main__ - Step 650 Global step 650 Train loss 0.01 on epoch=324
04/25/2022 18:28:15 - INFO - __main__ - Global step 650 Train loss 0.02 ACC 0.21875 on epoch=324
04/25/2022 18:28:18 - INFO - __main__ - Step 660 Global step 660 Train loss 0.01 on epoch=329
04/25/2022 18:28:20 - INFO - __main__ - Step 670 Global step 670 Train loss 0.02 on epoch=334
04/25/2022 18:28:23 - INFO - __main__ - Step 680 Global step 680 Train loss 0.00 on epoch=339
04/25/2022 18:28:25 - INFO - __main__ - Step 690 Global step 690 Train loss 0.01 on epoch=344
04/25/2022 18:28:27 - INFO - __main__ - Step 700 Global step 700 Train loss 0.02 on epoch=349
04/25/2022 18:28:29 - INFO - __main__ - Global step 700 Train loss 0.01 ACC 0.21875 on epoch=349
04/25/2022 18:28:32 - INFO - __main__ - Step 710 Global step 710 Train loss 0.01 on epoch=354
04/25/2022 18:28:34 - INFO - __main__ - Step 720 Global step 720 Train loss 0.02 on epoch=359
04/25/2022 18:28:37 - INFO - __main__ - Step 730 Global step 730 Train loss 0.02 on epoch=364
04/25/2022 18:28:39 - INFO - __main__ - Step 740 Global step 740 Train loss 0.01 on epoch=369
04/25/2022 18:28:41 - INFO - __main__ - Step 750 Global step 750 Train loss 0.01 on epoch=374
04/25/2022 18:28:43 - INFO - __main__ - Global step 750 Train loss 0.01 ACC 0.125 on epoch=374
04/25/2022 18:28:46 - INFO - __main__ - Step 760 Global step 760 Train loss 0.01 on epoch=379
04/25/2022 18:28:48 - INFO - __main__ - Step 770 Global step 770 Train loss 0.03 on epoch=384
04/25/2022 18:28:50 - INFO - __main__ - Step 780 Global step 780 Train loss 0.02 on epoch=389
04/25/2022 18:28:53 - INFO - __main__ - Step 790 Global step 790 Train loss 0.02 on epoch=394
04/25/2022 18:28:55 - INFO - __main__ - Step 800 Global step 800 Train loss 0.01 on epoch=399
04/25/2022 18:28:57 - INFO - __main__ - Global step 800 Train loss 0.02 ACC 0.1875 on epoch=399
04/25/2022 18:28:59 - INFO - __main__ - Step 810 Global step 810 Train loss 0.01 on epoch=404
04/25/2022 18:29:02 - INFO - __main__ - Step 820 Global step 820 Train loss 0.00 on epoch=409
04/25/2022 18:29:04 - INFO - __main__ - Step 830 Global step 830 Train loss 0.01 on epoch=414
04/25/2022 18:29:07 - INFO - __main__ - Step 840 Global step 840 Train loss 0.01 on epoch=419
04/25/2022 18:29:09 - INFO - __main__ - Step 850 Global step 850 Train loss 0.01 on epoch=424
04/25/2022 18:29:11 - INFO - __main__ - Global step 850 Train loss 0.01 ACC 0.15625 on epoch=424
04/25/2022 18:29:13 - INFO - __main__ - Step 860 Global step 860 Train loss 0.02 on epoch=429
04/25/2022 18:29:16 - INFO - __main__ - Step 870 Global step 870 Train loss 0.01 on epoch=434
04/25/2022 18:29:18 - INFO - __main__ - Step 880 Global step 880 Train loss 0.00 on epoch=439
04/25/2022 18:29:21 - INFO - __main__ - Step 890 Global step 890 Train loss 0.01 on epoch=444
04/25/2022 18:29:23 - INFO - __main__ - Step 900 Global step 900 Train loss 0.01 on epoch=449
04/25/2022 18:29:25 - INFO - __main__ - Global step 900 Train loss 0.01 ACC 0.1875 on epoch=449
04/25/2022 18:29:27 - INFO - __main__ - Step 910 Global step 910 Train loss 0.01 on epoch=454
04/25/2022 18:29:29 - INFO - __main__ - Step 920 Global step 920 Train loss 0.01 on epoch=459
04/25/2022 18:29:32 - INFO - __main__ - Step 930 Global step 930 Train loss 0.00 on epoch=464
04/25/2022 18:29:34 - INFO - __main__ - Step 940 Global step 940 Train loss 0.01 on epoch=469
04/25/2022 18:29:37 - INFO - __main__ - Step 950 Global step 950 Train loss 0.00 on epoch=474
04/25/2022 18:29:39 - INFO - __main__ - Global step 950 Train loss 0.01 ACC 0.25 on epoch=474
04/25/2022 18:29:41 - INFO - __main__ - Step 960 Global step 960 Train loss 0.01 on epoch=479
04/25/2022 18:29:44 - INFO - __main__ - Step 970 Global step 970 Train loss 0.03 on epoch=484
04/25/2022 18:29:46 - INFO - __main__ - Step 980 Global step 980 Train loss 0.01 on epoch=489
04/25/2022 18:29:49 - INFO - __main__ - Step 990 Global step 990 Train loss 0.02 on epoch=494
04/25/2022 18:29:51 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.01 on epoch=499
04/25/2022 18:29:53 - INFO - __main__ - Global step 1000 Train loss 0.01 ACC 0.125 on epoch=499
04/25/2022 18:29:55 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.01 on epoch=504
04/25/2022 18:29:58 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.05 on epoch=509
04/25/2022 18:30:00 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.01 on epoch=514
04/25/2022 18:30:02 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.00 on epoch=519
04/25/2022 18:30:05 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.01 on epoch=524
04/25/2022 18:30:06 - INFO - __main__ - Global step 1050 Train loss 0.01 ACC 0.09375 on epoch=524
04/25/2022 18:30:09 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.00 on epoch=529
04/25/2022 18:30:11 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.01 on epoch=534
04/25/2022 18:30:14 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.00 on epoch=539
04/25/2022 18:30:16 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.00 on epoch=544
04/25/2022 18:30:19 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.00 on epoch=549
04/25/2022 18:30:20 - INFO - __main__ - Global step 1100 Train loss 0.00 ACC 0.125 on epoch=549
04/25/2022 18:30:23 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.01 on epoch=554
04/25/2022 18:30:25 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.00 on epoch=559
04/25/2022 18:30:28 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.00 on epoch=564
04/25/2022 18:30:30 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.00 on epoch=569
04/25/2022 18:30:33 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.00 on epoch=574
04/25/2022 18:30:34 - INFO - __main__ - Global step 1150 Train loss 0.00 ACC 0.125 on epoch=574
04/25/2022 18:30:37 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.00 on epoch=579
04/25/2022 18:30:39 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.00 on epoch=584
04/25/2022 18:30:42 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.00 on epoch=589
04/25/2022 18:30:44 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.00 on epoch=594
04/25/2022 18:30:47 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.00 on epoch=599
04/25/2022 18:30:48 - INFO - __main__ - Global step 1200 Train loss 0.00 ACC 0.09375 on epoch=599
04/25/2022 18:30:51 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.01 on epoch=604
04/25/2022 18:30:53 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=609
04/25/2022 18:30:56 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=614
04/25/2022 18:30:58 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.03 on epoch=619
04/25/2022 18:31:01 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.05 on epoch=624
04/25/2022 18:31:02 - INFO - __main__ - Global step 1250 Train loss 0.02 ACC 0.125 on epoch=624
04/25/2022 18:31:05 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=629
04/25/2022 18:31:07 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.01 on epoch=634
04/25/2022 18:31:10 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=639
04/25/2022 18:31:12 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.00 on epoch=644
04/25/2022 18:31:15 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=649
04/25/2022 18:31:16 - INFO - __main__ - Global step 1300 Train loss 0.01 ACC 0.15625 on epoch=649
04/25/2022 18:31:19 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=654
04/25/2022 18:31:21 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.00 on epoch=659
04/25/2022 18:31:24 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.00 on epoch=664
04/25/2022 18:31:26 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.00 on epoch=669
04/25/2022 18:31:28 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.02 on epoch=674
04/25/2022 18:31:30 - INFO - __main__ - Global step 1350 Train loss 0.01 ACC 0.125 on epoch=674
04/25/2022 18:31:33 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.00 on epoch=679
04/25/2022 18:31:35 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=684
04/25/2022 18:31:38 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.00 on epoch=689
04/25/2022 18:31:40 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.00 on epoch=694
04/25/2022 18:31:42 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.00 on epoch=699
04/25/2022 18:31:44 - INFO - __main__ - Global step 1400 Train loss 0.00 ACC 0.09375 on epoch=699
04/25/2022 18:31:47 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=704
04/25/2022 18:31:49 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=709
04/25/2022 18:31:51 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=714
04/25/2022 18:31:54 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=719
04/25/2022 18:31:56 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=724
04/25/2022 18:31:58 - INFO - __main__ - Global step 1450 Train loss 0.01 ACC 0.21875 on epoch=724
04/25/2022 18:32:00 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=729
04/25/2022 18:32:03 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=734
04/25/2022 18:32:05 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=739
04/25/2022 18:32:08 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=744
04/25/2022 18:32:10 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=749
04/25/2022 18:32:12 - INFO - __main__ - Global step 1500 Train loss 0.00 ACC 0.1875 on epoch=749
04/25/2022 18:32:14 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=754
04/25/2022 18:32:17 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=759
04/25/2022 18:32:19 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=764
04/25/2022 18:32:22 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=769
04/25/2022 18:32:24 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=774
04/25/2022 18:32:26 - INFO - __main__ - Global step 1550 Train loss 0.01 ACC 0.1875 on epoch=774
04/25/2022 18:32:28 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=779
04/25/2022 18:32:31 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=784
04/25/2022 18:32:33 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=789
04/25/2022 18:32:36 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=794
04/25/2022 18:32:38 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=799
04/25/2022 18:32:40 - INFO - __main__ - Global step 1600 Train loss 0.00 ACC 0.125 on epoch=799
04/25/2022 18:32:42 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=804
04/25/2022 18:32:45 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=809
04/25/2022 18:32:47 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=814
04/25/2022 18:32:50 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=819
04/25/2022 18:32:52 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=824
04/25/2022 18:32:54 - INFO - __main__ - Global step 1650 Train loss 0.00 ACC 0.15625 on epoch=824
04/25/2022 18:32:57 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=829
04/25/2022 18:32:59 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=834
04/25/2022 18:33:02 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=839
04/25/2022 18:33:04 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=844
04/25/2022 18:33:07 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=849
04/25/2022 18:33:09 - INFO - __main__ - Global step 1700 Train loss 0.01 ACC 0.1875 on epoch=849
04/25/2022 18:33:11 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=854
04/25/2022 18:33:14 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=859
04/25/2022 18:33:16 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=864
04/25/2022 18:33:19 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=869
04/25/2022 18:33:21 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=874
04/25/2022 18:33:23 - INFO - __main__ - Global step 1750 Train loss 0.01 ACC 0.15625 on epoch=874
04/25/2022 18:33:25 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=879
04/25/2022 18:33:28 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=884
04/25/2022 18:33:31 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=889
04/25/2022 18:33:33 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=894
04/25/2022 18:33:36 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=899
04/25/2022 18:33:37 - INFO - __main__ - Global step 1800 Train loss 0.00 ACC 0.125 on epoch=899
04/25/2022 18:33:40 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=904
04/25/2022 18:33:43 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=909
04/25/2022 18:33:45 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=914
04/25/2022 18:33:48 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=919
04/25/2022 18:33:50 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=924
04/25/2022 18:33:52 - INFO - __main__ - Global step 1850 Train loss 0.00 ACC 0.15625 on epoch=924
04/25/2022 18:33:54 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=929
04/25/2022 18:33:57 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=934
04/25/2022 18:33:59 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=939
04/25/2022 18:34:02 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=944
04/25/2022 18:34:04 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=949
04/25/2022 18:34:06 - INFO - __main__ - Global step 1900 Train loss 0.00 ACC 0.125 on epoch=949
04/25/2022 18:34:09 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=954
04/25/2022 18:34:11 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=959
04/25/2022 18:34:14 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=964
04/25/2022 18:34:16 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=969
04/25/2022 18:34:19 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=974
04/25/2022 18:34:20 - INFO - __main__ - Global step 1950 Train loss 0.00 ACC 0.125 on epoch=974
04/25/2022 18:34:23 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=979
04/25/2022 18:34:25 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=984
04/25/2022 18:34:28 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=989
04/25/2022 18:34:31 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=994
04/25/2022 18:34:33 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=999
04/25/2022 18:34:34 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 18:34:34 - INFO - __main__ - Printing 3 examples
04/25/2022 18:34:34 - INFO - __main__ -  [openbookqa] Which is likeliest to metamorphose? (A) a live insect (B) a human (C) a plant (D) a dead butterfly
04/25/2022 18:34:34 - INFO - __main__ - ['a live insect']
04/25/2022 18:34:34 - INFO - __main__ -  [openbookqa] Which animal is most likely to eat another living animal? (A) deer (B) elephant (C) worm (D) lion
04/25/2022 18:34:34 - INFO - __main__ - ['lion']
04/25/2022 18:34:34 - INFO - __main__ -  [openbookqa] If a see through thing is multifaceted, it is most likely (A) a ball (B) an apple (C) a silver globe (D) a quartz square
04/25/2022 18:34:34 - INFO - __main__ - ['a quartz square']
04/25/2022 18:34:34 - INFO - __main__ - Tokenizing Input ...
04/25/2022 18:34:34 - INFO - __main__ - Tokenizing Output ...
04/25/2022 18:34:34 - INFO - __main__ - Loaded 32 examples from train data
04/25/2022 18:34:34 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 18:34:34 - INFO - __main__ - Printing 3 examples
04/25/2022 18:34:34 - INFO - __main__ -  [openbookqa] An organism that can survive without the help of other cells is (A) Brewer's yeast (B) air (C) sand (D) sugar
04/25/2022 18:34:34 - INFO - __main__ - ["Brewer's yeast"]
04/25/2022 18:34:34 - INFO - __main__ -  [openbookqa] some animals remove their hair coverings for (A) naptime (B) lunchtime (C) mating season (D) scorching climates
04/25/2022 18:34:34 - INFO - __main__ - ['scorching climates']
04/25/2022 18:34:34 - INFO - __main__ -  [openbookqa] Which animal sometimes needs to move quickly for food? (A) coyote (B) horse (C) deer (D) buffalo
04/25/2022 18:34:34 - INFO - __main__ - ['coyote']
04/25/2022 18:34:34 - INFO - __main__ - Tokenizing Input ...
04/25/2022 18:34:34 - INFO - __main__ - Tokenizing Output ...
04/25/2022 18:34:34 - INFO - __main__ - Loaded 32 examples from dev data
04/25/2022 18:34:35 - INFO - __main__ - Global step 2000 Train loss 0.01 ACC 0.15625 on epoch=999
04/25/2022 18:34:35 - INFO - __main__ - save last model!
04/25/2022 18:34:35 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
04/25/2022 18:34:35 - INFO - __main__ - Start tokenizing ... 500 instances
04/25/2022 18:34:35 - INFO - __main__ - Printing 3 examples
04/25/2022 18:34:35 - INFO - __main__ -  [openbookqa] Frilled sharks and angler fish live far beneath the surface of the ocean, which is why they are known as (A) Deep sea animals (B) fish (C) Long Sea Fish (D) Far Sea Animals
04/25/2022 18:34:35 - INFO - __main__ - ['Deep sea animals']
04/25/2022 18:34:35 - INFO - __main__ -  [openbookqa] Gas can fill any container it is given, and liquid (A) is standard weight and size (B) is the opposite of variable (C) only needs a few (D) uses what it needs
04/25/2022 18:34:35 - INFO - __main__ - ['uses what it needs']
04/25/2022 18:34:35 - INFO - __main__ -  [openbookqa] When birds migrate south for the winter, they do it because (A) they are genetically called to (B) their children ask for them to (C) it is important to their happiness (D) they decide to each year
04/25/2022 18:34:35 - INFO - __main__ - ['they are genetically called to']
04/25/2022 18:34:35 - INFO - __main__ - Tokenizing Input ...
04/25/2022 18:34:35 - INFO - __main__ - Tokenizing Output ...
04/25/2022 18:34:36 - INFO - __main__ - Loaded 500 examples from test data
04/25/2022 18:34:52 - INFO - __main__ - load prompt embedding from ckpt
04/25/2022 18:34:53 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/25/2022 18:34:53 - INFO - __main__ - Starting training!
04/25/2022 18:35:09 - INFO - __main__ - Saved prediction in models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-openbookqa/openbookqa_32_42_0.5_8_predictions.txt
04/25/2022 18:35:09 - INFO - __main__ - ACC on test data: 0.3100
04/25/2022 18:35:09 - INFO - __main__ - prefix=openbookqa_32_42, lr=0.5, bsz=8, dev_performance=0.3125, test_performance=0.31
04/25/2022 18:35:09 - INFO - __main__ - Running ... prefix=openbookqa_32_42, lr=0.4, bsz=8 ...
04/25/2022 18:35:10 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 18:35:10 - INFO - __main__ - Printing 3 examples
04/25/2022 18:35:10 - INFO - __main__ -  [openbookqa] Which is likeliest to metamorphose? (A) a live insect (B) a human (C) a plant (D) a dead butterfly
04/25/2022 18:35:10 - INFO - __main__ - ['a live insect']
04/25/2022 18:35:10 - INFO - __main__ -  [openbookqa] Which animal is most likely to eat another living animal? (A) deer (B) elephant (C) worm (D) lion
04/25/2022 18:35:10 - INFO - __main__ - ['lion']
04/25/2022 18:35:10 - INFO - __main__ -  [openbookqa] If a see through thing is multifaceted, it is most likely (A) a ball (B) an apple (C) a silver globe (D) a quartz square
04/25/2022 18:35:10 - INFO - __main__ - ['a quartz square']
04/25/2022 18:35:10 - INFO - __main__ - Tokenizing Input ...
04/25/2022 18:35:10 - INFO - __main__ - Tokenizing Output ...
04/25/2022 18:35:10 - INFO - __main__ - Loaded 32 examples from train data
04/25/2022 18:35:10 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 18:35:10 - INFO - __main__ - Printing 3 examples
04/25/2022 18:35:10 - INFO - __main__ -  [openbookqa] An organism that can survive without the help of other cells is (A) Brewer's yeast (B) air (C) sand (D) sugar
04/25/2022 18:35:10 - INFO - __main__ - ["Brewer's yeast"]
04/25/2022 18:35:10 - INFO - __main__ -  [openbookqa] some animals remove their hair coverings for (A) naptime (B) lunchtime (C) mating season (D) scorching climates
04/25/2022 18:35:10 - INFO - __main__ - ['scorching climates']
04/25/2022 18:35:10 - INFO - __main__ -  [openbookqa] Which animal sometimes needs to move quickly for food? (A) coyote (B) horse (C) deer (D) buffalo
04/25/2022 18:35:10 - INFO - __main__ - ['coyote']
04/25/2022 18:35:10 - INFO - __main__ - Tokenizing Input ...
04/25/2022 18:35:10 - INFO - __main__ - Tokenizing Output ...
04/25/2022 18:35:10 - INFO - __main__ - Loaded 32 examples from dev data
04/25/2022 18:35:28 - INFO - __main__ - load prompt embedding from ckpt
04/25/2022 18:35:29 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/25/2022 18:35:29 - INFO - __main__ - Starting training!
04/25/2022 18:35:32 - INFO - __main__ - Step 10 Global step 10 Train loss 1.96 on epoch=4
04/25/2022 18:35:35 - INFO - __main__ - Step 20 Global step 20 Train loss 1.27 on epoch=9
04/25/2022 18:35:37 - INFO - __main__ - Step 30 Global step 30 Train loss 0.83 on epoch=14
04/25/2022 18:35:40 - INFO - __main__ - Step 40 Global step 40 Train loss 0.67 on epoch=19
04/25/2022 18:35:42 - INFO - __main__ - Step 50 Global step 50 Train loss 0.67 on epoch=24
04/25/2022 18:35:44 - INFO - __main__ - Global step 50 Train loss 1.08 ACC 0.1875 on epoch=24
04/25/2022 18:35:44 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.1875 on epoch=24, global_step=50
04/25/2022 18:35:47 - INFO - __main__ - Step 60 Global step 60 Train loss 0.48 on epoch=29
04/25/2022 18:35:49 - INFO - __main__ - Step 70 Global step 70 Train loss 0.35 on epoch=34
04/25/2022 18:35:52 - INFO - __main__ - Step 80 Global step 80 Train loss 0.31 on epoch=39
04/25/2022 18:35:54 - INFO - __main__ - Step 90 Global step 90 Train loss 0.27 on epoch=44
04/25/2022 18:35:57 - INFO - __main__ - Step 100 Global step 100 Train loss 0.31 on epoch=49
04/25/2022 18:35:59 - INFO - __main__ - Global step 100 Train loss 0.34 ACC 0.28125 on epoch=49
04/25/2022 18:35:59 - INFO - __main__ - Saving model with best ACC: 0.1875 -> 0.28125 on epoch=49, global_step=100
04/25/2022 18:36:01 - INFO - __main__ - Step 110 Global step 110 Train loss 0.19 on epoch=54
04/25/2022 18:36:04 - INFO - __main__ - Step 120 Global step 120 Train loss 0.17 on epoch=59
04/25/2022 18:36:06 - INFO - __main__ - Step 130 Global step 130 Train loss 0.19 on epoch=64
04/25/2022 18:36:09 - INFO - __main__ - Step 140 Global step 140 Train loss 0.15 on epoch=69
04/25/2022 18:36:11 - INFO - __main__ - Step 150 Global step 150 Train loss 0.18 on epoch=74
04/25/2022 18:36:13 - INFO - __main__ - Global step 150 Train loss 0.17 ACC 0.21875 on epoch=74
04/25/2022 18:36:15 - INFO - __main__ - Step 160 Global step 160 Train loss 0.18 on epoch=79
04/25/2022 18:36:18 - INFO - __main__ - Step 170 Global step 170 Train loss 0.07 on epoch=84
04/25/2022 18:36:20 - INFO - __main__ - Step 180 Global step 180 Train loss 0.10 on epoch=89
04/25/2022 18:36:23 - INFO - __main__ - Step 190 Global step 190 Train loss 0.14 on epoch=94
04/25/2022 18:36:25 - INFO - __main__ - Step 200 Global step 200 Train loss 0.08 on epoch=99
04/25/2022 18:36:27 - INFO - __main__ - Global step 200 Train loss 0.11 ACC 0.15625 on epoch=99
04/25/2022 18:36:29 - INFO - __main__ - Step 210 Global step 210 Train loss 0.09 on epoch=104
04/25/2022 18:36:32 - INFO - __main__ - Step 220 Global step 220 Train loss 0.05 on epoch=109
04/25/2022 18:36:34 - INFO - __main__ - Step 230 Global step 230 Train loss 0.07 on epoch=114
04/25/2022 18:36:37 - INFO - __main__ - Step 240 Global step 240 Train loss 0.07 on epoch=119
04/25/2022 18:36:39 - INFO - __main__ - Step 250 Global step 250 Train loss 0.05 on epoch=124
04/25/2022 18:36:41 - INFO - __main__ - Global step 250 Train loss 0.07 ACC 0.15625 on epoch=124
04/25/2022 18:36:44 - INFO - __main__ - Step 260 Global step 260 Train loss 0.05 on epoch=129
04/25/2022 18:36:46 - INFO - __main__ - Step 270 Global step 270 Train loss 0.05 on epoch=134
04/25/2022 18:36:49 - INFO - __main__ - Step 280 Global step 280 Train loss 0.04 on epoch=139
04/25/2022 18:36:51 - INFO - __main__ - Step 290 Global step 290 Train loss 0.05 on epoch=144
04/25/2022 18:36:54 - INFO - __main__ - Step 300 Global step 300 Train loss 0.03 on epoch=149
04/25/2022 18:36:55 - INFO - __main__ - Global step 300 Train loss 0.04 ACC 0.1875 on epoch=149
04/25/2022 18:36:58 - INFO - __main__ - Step 310 Global step 310 Train loss 0.03 on epoch=154
04/25/2022 18:37:01 - INFO - __main__ - Step 320 Global step 320 Train loss 0.04 on epoch=159
04/25/2022 18:37:03 - INFO - __main__ - Step 330 Global step 330 Train loss 0.05 on epoch=164
04/25/2022 18:37:06 - INFO - __main__ - Step 340 Global step 340 Train loss 0.04 on epoch=169
04/25/2022 18:37:08 - INFO - __main__ - Step 350 Global step 350 Train loss 0.05 on epoch=174
04/25/2022 18:37:10 - INFO - __main__ - Global step 350 Train loss 0.04 ACC 0.1875 on epoch=174
04/25/2022 18:37:12 - INFO - __main__ - Step 360 Global step 360 Train loss 0.04 on epoch=179
04/25/2022 18:37:15 - INFO - __main__ - Step 370 Global step 370 Train loss 0.06 on epoch=184
04/25/2022 18:37:18 - INFO - __main__ - Step 380 Global step 380 Train loss 0.05 on epoch=189
04/25/2022 18:37:20 - INFO - __main__ - Step 390 Global step 390 Train loss 0.03 on epoch=194
04/25/2022 18:37:23 - INFO - __main__ - Step 400 Global step 400 Train loss 0.05 on epoch=199
04/25/2022 18:37:24 - INFO - __main__ - Global step 400 Train loss 0.04 ACC 0.15625 on epoch=199
04/25/2022 18:37:27 - INFO - __main__ - Step 410 Global step 410 Train loss 0.02 on epoch=204
04/25/2022 18:37:29 - INFO - __main__ - Step 420 Global step 420 Train loss 0.04 on epoch=209
04/25/2022 18:37:32 - INFO - __main__ - Step 430 Global step 430 Train loss 0.03 on epoch=214
04/25/2022 18:37:35 - INFO - __main__ - Step 440 Global step 440 Train loss 0.04 on epoch=219
04/25/2022 18:37:37 - INFO - __main__ - Step 450 Global step 450 Train loss 0.06 on epoch=224
04/25/2022 18:37:39 - INFO - __main__ - Global step 450 Train loss 0.04 ACC 0.125 on epoch=224
04/25/2022 18:37:41 - INFO - __main__ - Step 460 Global step 460 Train loss 0.04 on epoch=229
04/25/2022 18:37:44 - INFO - __main__ - Step 470 Global step 470 Train loss 0.04 on epoch=234
04/25/2022 18:37:47 - INFO - __main__ - Step 480 Global step 480 Train loss 0.02 on epoch=239
04/25/2022 18:37:49 - INFO - __main__ - Step 490 Global step 490 Train loss 0.03 on epoch=244
04/25/2022 18:37:52 - INFO - __main__ - Step 500 Global step 500 Train loss 0.02 on epoch=249
04/25/2022 18:37:53 - INFO - __main__ - Global step 500 Train loss 0.03 ACC 0.125 on epoch=249
04/25/2022 18:37:56 - INFO - __main__ - Step 510 Global step 510 Train loss 0.02 on epoch=254
04/25/2022 18:37:59 - INFO - __main__ - Step 520 Global step 520 Train loss 0.02 on epoch=259
04/25/2022 18:38:01 - INFO - __main__ - Step 530 Global step 530 Train loss 0.01 on epoch=264
04/25/2022 18:38:04 - INFO - __main__ - Step 540 Global step 540 Train loss 0.01 on epoch=269
04/25/2022 18:38:06 - INFO - __main__ - Step 550 Global step 550 Train loss 0.02 on epoch=274
04/25/2022 18:38:08 - INFO - __main__ - Global step 550 Train loss 0.02 ACC 0.21875 on epoch=274
04/25/2022 18:38:10 - INFO - __main__ - Step 560 Global step 560 Train loss 0.02 on epoch=279
04/25/2022 18:38:13 - INFO - __main__ - Step 570 Global step 570 Train loss 0.02 on epoch=284
04/25/2022 18:38:16 - INFO - __main__ - Step 580 Global step 580 Train loss 0.01 on epoch=289
04/25/2022 18:38:18 - INFO - __main__ - Step 590 Global step 590 Train loss 0.01 on epoch=294
04/25/2022 18:38:21 - INFO - __main__ - Step 600 Global step 600 Train loss 0.02 on epoch=299
04/25/2022 18:38:22 - INFO - __main__ - Global step 600 Train loss 0.02 ACC 0.15625 on epoch=299
04/25/2022 18:38:25 - INFO - __main__ - Step 610 Global step 610 Train loss 0.01 on epoch=304
04/25/2022 18:38:27 - INFO - __main__ - Step 620 Global step 620 Train loss 0.02 on epoch=309
04/25/2022 18:38:30 - INFO - __main__ - Step 630 Global step 630 Train loss 0.01 on epoch=314
04/25/2022 18:38:32 - INFO - __main__ - Step 640 Global step 640 Train loss 0.01 on epoch=319
04/25/2022 18:38:35 - INFO - __main__ - Step 650 Global step 650 Train loss 0.01 on epoch=324
04/25/2022 18:38:36 - INFO - __main__ - Global step 650 Train loss 0.01 ACC 0.1875 on epoch=324
04/25/2022 18:38:39 - INFO - __main__ - Step 660 Global step 660 Train loss 0.02 on epoch=329
04/25/2022 18:38:41 - INFO - __main__ - Step 670 Global step 670 Train loss 0.03 on epoch=334
04/25/2022 18:38:44 - INFO - __main__ - Step 680 Global step 680 Train loss 0.01 on epoch=339
04/25/2022 18:38:46 - INFO - __main__ - Step 690 Global step 690 Train loss 0.01 on epoch=344
04/25/2022 18:38:49 - INFO - __main__ - Step 700 Global step 700 Train loss 0.01 on epoch=349
04/25/2022 18:38:51 - INFO - __main__ - Global step 700 Train loss 0.01 ACC 0.21875 on epoch=349
04/25/2022 18:38:53 - INFO - __main__ - Step 710 Global step 710 Train loss 0.02 on epoch=354
04/25/2022 18:38:56 - INFO - __main__ - Step 720 Global step 720 Train loss 0.01 on epoch=359
04/25/2022 18:38:58 - INFO - __main__ - Step 730 Global step 730 Train loss 0.01 on epoch=364
04/25/2022 18:39:01 - INFO - __main__ - Step 740 Global step 740 Train loss 0.07 on epoch=369
04/25/2022 18:39:03 - INFO - __main__ - Step 750 Global step 750 Train loss 0.01 on epoch=374
04/25/2022 18:39:05 - INFO - __main__ - Global step 750 Train loss 0.02 ACC 0.125 on epoch=374
04/25/2022 18:39:07 - INFO - __main__ - Step 760 Global step 760 Train loss 0.01 on epoch=379
04/25/2022 18:39:10 - INFO - __main__ - Step 770 Global step 770 Train loss 0.03 on epoch=384
04/25/2022 18:39:12 - INFO - __main__ - Step 780 Global step 780 Train loss 0.01 on epoch=389
04/25/2022 18:39:15 - INFO - __main__ - Step 790 Global step 790 Train loss 0.01 on epoch=394
04/25/2022 18:39:17 - INFO - __main__ - Step 800 Global step 800 Train loss 0.01 on epoch=399
04/25/2022 18:39:19 - INFO - __main__ - Global step 800 Train loss 0.01 ACC 0.1875 on epoch=399
04/25/2022 18:39:22 - INFO - __main__ - Step 810 Global step 810 Train loss 0.01 on epoch=404
04/25/2022 18:39:24 - INFO - __main__ - Step 820 Global step 820 Train loss 0.01 on epoch=409
04/25/2022 18:39:27 - INFO - __main__ - Step 830 Global step 830 Train loss 0.01 on epoch=414
04/25/2022 18:39:29 - INFO - __main__ - Step 840 Global step 840 Train loss 0.02 on epoch=419
04/25/2022 18:39:32 - INFO - __main__ - Step 850 Global step 850 Train loss 0.03 on epoch=424
04/25/2022 18:39:33 - INFO - __main__ - Global step 850 Train loss 0.01 ACC 0.125 on epoch=424
04/25/2022 18:39:36 - INFO - __main__ - Step 860 Global step 860 Train loss 0.03 on epoch=429
04/25/2022 18:39:38 - INFO - __main__ - Step 870 Global step 870 Train loss 0.01 on epoch=434
04/25/2022 18:39:41 - INFO - __main__ - Step 880 Global step 880 Train loss 0.03 on epoch=439
04/25/2022 18:39:43 - INFO - __main__ - Step 890 Global step 890 Train loss 0.01 on epoch=444
04/25/2022 18:39:46 - INFO - __main__ - Step 900 Global step 900 Train loss 0.01 on epoch=449
04/25/2022 18:39:47 - INFO - __main__ - Global step 900 Train loss 0.02 ACC 0.09375 on epoch=449
04/25/2022 18:39:50 - INFO - __main__ - Step 910 Global step 910 Train loss 0.02 on epoch=454
04/25/2022 18:39:52 - INFO - __main__ - Step 920 Global step 920 Train loss 0.01 on epoch=459
04/25/2022 18:39:55 - INFO - __main__ - Step 930 Global step 930 Train loss 0.03 on epoch=464
04/25/2022 18:39:57 - INFO - __main__ - Step 940 Global step 940 Train loss 0.01 on epoch=469
04/25/2022 18:40:00 - INFO - __main__ - Step 950 Global step 950 Train loss 0.01 on epoch=474
04/25/2022 18:40:02 - INFO - __main__ - Global step 950 Train loss 0.02 ACC 0.15625 on epoch=474
04/25/2022 18:40:04 - INFO - __main__ - Step 960 Global step 960 Train loss 0.01 on epoch=479
04/25/2022 18:40:07 - INFO - __main__ - Step 970 Global step 970 Train loss 0.01 on epoch=484
04/25/2022 18:40:09 - INFO - __main__ - Step 980 Global step 980 Train loss 0.01 on epoch=489
04/25/2022 18:40:12 - INFO - __main__ - Step 990 Global step 990 Train loss 0.01 on epoch=494
04/25/2022 18:40:14 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.02 on epoch=499
04/25/2022 18:40:16 - INFO - __main__ - Global step 1000 Train loss 0.01 ACC 0.15625 on epoch=499
04/25/2022 18:40:18 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.01 on epoch=504
04/25/2022 18:40:21 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.01 on epoch=509
04/25/2022 18:40:23 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.03 on epoch=514
04/25/2022 18:40:26 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.00 on epoch=519
04/25/2022 18:40:28 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.03 on epoch=524
04/25/2022 18:40:30 - INFO - __main__ - Global step 1050 Train loss 0.02 ACC 0.21875 on epoch=524
04/25/2022 18:40:32 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.02 on epoch=529
04/25/2022 18:40:35 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.01 on epoch=534
04/25/2022 18:40:37 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.02 on epoch=539
04/25/2022 18:40:40 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.03 on epoch=544
04/25/2022 18:40:42 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.01 on epoch=549
04/25/2022 18:40:44 - INFO - __main__ - Global step 1100 Train loss 0.02 ACC 0.125 on epoch=549
04/25/2022 18:40:47 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.01 on epoch=554
04/25/2022 18:40:49 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=559
04/25/2022 18:40:52 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=564
04/25/2022 18:40:54 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.02 on epoch=569
04/25/2022 18:40:56 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=574
04/25/2022 18:40:58 - INFO - __main__ - Global step 1150 Train loss 0.01 ACC 0.15625 on epoch=574
04/25/2022 18:41:01 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.00 on epoch=579
04/25/2022 18:41:03 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.01 on epoch=584
04/25/2022 18:41:06 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.02 on epoch=589
04/25/2022 18:41:08 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.01 on epoch=594
04/25/2022 18:41:11 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=599
04/25/2022 18:41:12 - INFO - __main__ - Global step 1200 Train loss 0.01 ACC 0.15625 on epoch=599
04/25/2022 18:41:15 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.01 on epoch=604
04/25/2022 18:41:17 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=609
04/25/2022 18:41:20 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.00 on epoch=614
04/25/2022 18:41:22 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.00 on epoch=619
04/25/2022 18:41:25 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.00 on epoch=624
04/25/2022 18:41:26 - INFO - __main__ - Global step 1250 Train loss 0.00 ACC 0.09375 on epoch=624
04/25/2022 18:41:29 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=629
04/25/2022 18:41:32 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.01 on epoch=634
04/25/2022 18:41:34 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=639
04/25/2022 18:41:37 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.00 on epoch=644
04/25/2022 18:41:39 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=649
04/25/2022 18:41:41 - INFO - __main__ - Global step 1300 Train loss 0.01 ACC 0.09375 on epoch=649
04/25/2022 18:41:44 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.00 on epoch=654
04/25/2022 18:41:46 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.00 on epoch=659
04/25/2022 18:41:49 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=664
04/25/2022 18:41:51 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.00 on epoch=669
04/25/2022 18:41:54 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.00 on epoch=674
04/25/2022 18:41:55 - INFO - __main__ - Global step 1350 Train loss 0.00 ACC 0.09375 on epoch=674
04/25/2022 18:41:58 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=679
04/25/2022 18:42:00 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.00 on epoch=684
04/25/2022 18:42:03 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.00 on epoch=689
04/25/2022 18:42:05 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.00 on epoch=694
04/25/2022 18:42:08 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.00 on epoch=699
04/25/2022 18:42:09 - INFO - __main__ - Global step 1400 Train loss 0.00 ACC 0.15625 on epoch=699
04/25/2022 18:42:12 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=704
04/25/2022 18:42:14 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=709
04/25/2022 18:42:17 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=714
04/25/2022 18:42:19 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=719
04/25/2022 18:42:22 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=724
04/25/2022 18:42:24 - INFO - __main__ - Global step 1450 Train loss 0.00 ACC 0.21875 on epoch=724
04/25/2022 18:42:27 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.02 on epoch=729
04/25/2022 18:42:29 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=734
04/25/2022 18:42:32 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=739
04/25/2022 18:42:34 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=744
04/25/2022 18:42:37 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=749
04/25/2022 18:42:39 - INFO - __main__ - Global step 1500 Train loss 0.01 ACC 0.1875 on epoch=749
04/25/2022 18:42:42 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=754
04/25/2022 18:42:44 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=759
04/25/2022 18:42:47 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.02 on epoch=764
04/25/2022 18:42:49 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=769
04/25/2022 18:42:52 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=774
04/25/2022 18:42:54 - INFO - __main__ - Global step 1550 Train loss 0.01 ACC 0.25 on epoch=774
04/25/2022 18:42:56 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.02 on epoch=779
04/25/2022 18:42:59 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.03 on epoch=784
04/25/2022 18:43:01 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=789
04/25/2022 18:43:04 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=794
04/25/2022 18:43:06 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=799
04/25/2022 18:43:08 - INFO - __main__ - Global step 1600 Train loss 0.02 ACC 0.15625 on epoch=799
04/25/2022 18:43:10 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=804
04/25/2022 18:43:13 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=809
04/25/2022 18:43:15 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=814
04/25/2022 18:43:18 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=819
04/25/2022 18:43:21 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=824
04/25/2022 18:43:22 - INFO - __main__ - Global step 1650 Train loss 0.00 ACC 0.09375 on epoch=824
04/25/2022 18:43:25 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=829
04/25/2022 18:43:27 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=834
04/25/2022 18:43:30 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=839
04/25/2022 18:43:32 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=844
04/25/2022 18:43:35 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=849
04/25/2022 18:43:37 - INFO - __main__ - Global step 1700 Train loss 0.01 ACC 0.1875 on epoch=849
04/25/2022 18:43:39 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=854
04/25/2022 18:43:42 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=859
04/25/2022 18:43:44 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=864
04/25/2022 18:43:47 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=869
04/25/2022 18:43:49 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=874
04/25/2022 18:43:51 - INFO - __main__ - Global step 1750 Train loss 0.01 ACC 0.09375 on epoch=874
04/25/2022 18:43:54 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=879
04/25/2022 18:43:56 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=884
04/25/2022 18:43:59 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=889
04/25/2022 18:44:01 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=894
04/25/2022 18:44:04 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=899
04/25/2022 18:44:05 - INFO - __main__ - Global step 1800 Train loss 0.01 ACC 0.21875 on epoch=899
04/25/2022 18:44:08 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=904
04/25/2022 18:44:11 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=909
04/25/2022 18:44:13 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=914
04/25/2022 18:44:16 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=919
04/25/2022 18:44:18 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=924
04/25/2022 18:44:21 - INFO - __main__ - Global step 1850 Train loss 0.00 ACC 0.125 on epoch=924
04/25/2022 18:44:23 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=929
04/25/2022 18:44:26 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=934
04/25/2022 18:44:28 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=939
04/25/2022 18:44:31 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=944
04/25/2022 18:44:33 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=949
04/25/2022 18:44:35 - INFO - __main__ - Global step 1900 Train loss 0.01 ACC 0.09375 on epoch=949
04/25/2022 18:44:37 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=954
04/25/2022 18:44:40 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=959
04/25/2022 18:44:43 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=964
04/25/2022 18:44:45 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=969
04/25/2022 18:44:48 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=974
04/25/2022 18:44:49 - INFO - __main__ - Global step 1950 Train loss 0.00 ACC 0.125 on epoch=974
04/25/2022 18:44:52 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=979
04/25/2022 18:44:54 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=984
04/25/2022 18:44:57 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=989
04/25/2022 18:44:59 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=994
04/25/2022 18:45:02 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=999
04/25/2022 18:45:03 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 18:45:03 - INFO - __main__ - Printing 3 examples
04/25/2022 18:45:03 - INFO - __main__ -  [openbookqa] Which is likeliest to metamorphose? (A) a live insect (B) a human (C) a plant (D) a dead butterfly
04/25/2022 18:45:03 - INFO - __main__ - ['a live insect']
04/25/2022 18:45:03 - INFO - __main__ -  [openbookqa] Which animal is most likely to eat another living animal? (A) deer (B) elephant (C) worm (D) lion
04/25/2022 18:45:03 - INFO - __main__ - ['lion']
04/25/2022 18:45:03 - INFO - __main__ -  [openbookqa] If a see through thing is multifaceted, it is most likely (A) a ball (B) an apple (C) a silver globe (D) a quartz square
04/25/2022 18:45:03 - INFO - __main__ - ['a quartz square']
04/25/2022 18:45:03 - INFO - __main__ - Tokenizing Input ...
04/25/2022 18:45:03 - INFO - __main__ - Tokenizing Output ...
04/25/2022 18:45:03 - INFO - __main__ - Loaded 32 examples from train data
04/25/2022 18:45:03 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 18:45:03 - INFO - __main__ - Printing 3 examples
04/25/2022 18:45:03 - INFO - __main__ -  [openbookqa] An organism that can survive without the help of other cells is (A) Brewer's yeast (B) air (C) sand (D) sugar
04/25/2022 18:45:03 - INFO - __main__ - ["Brewer's yeast"]
04/25/2022 18:45:03 - INFO - __main__ -  [openbookqa] some animals remove their hair coverings for (A) naptime (B) lunchtime (C) mating season (D) scorching climates
04/25/2022 18:45:03 - INFO - __main__ - ['scorching climates']
04/25/2022 18:45:03 - INFO - __main__ -  [openbookqa] Which animal sometimes needs to move quickly for food? (A) coyote (B) horse (C) deer (D) buffalo
04/25/2022 18:45:03 - INFO - __main__ - ['coyote']
04/25/2022 18:45:03 - INFO - __main__ - Tokenizing Input ...
04/25/2022 18:45:03 - INFO - __main__ - Tokenizing Output ...
04/25/2022 18:45:03 - INFO - __main__ - Loaded 32 examples from dev data
04/25/2022 18:45:04 - INFO - __main__ - Global step 2000 Train loss 0.01 ACC 0.125 on epoch=999
04/25/2022 18:45:04 - INFO - __main__ - save last model!
04/25/2022 18:45:04 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
04/25/2022 18:45:04 - INFO - __main__ - Start tokenizing ... 500 instances
04/25/2022 18:45:04 - INFO - __main__ - Printing 3 examples
04/25/2022 18:45:04 - INFO - __main__ -  [openbookqa] Frilled sharks and angler fish live far beneath the surface of the ocean, which is why they are known as (A) Deep sea animals (B) fish (C) Long Sea Fish (D) Far Sea Animals
04/25/2022 18:45:04 - INFO - __main__ - ['Deep sea animals']
04/25/2022 18:45:04 - INFO - __main__ -  [openbookqa] Gas can fill any container it is given, and liquid (A) is standard weight and size (B) is the opposite of variable (C) only needs a few (D) uses what it needs
04/25/2022 18:45:04 - INFO - __main__ - ['uses what it needs']
04/25/2022 18:45:04 - INFO - __main__ -  [openbookqa] When birds migrate south for the winter, they do it because (A) they are genetically called to (B) their children ask for them to (C) it is important to their happiness (D) they decide to each year
04/25/2022 18:45:04 - INFO - __main__ - ['they are genetically called to']
04/25/2022 18:45:04 - INFO - __main__ - Tokenizing Input ...
04/25/2022 18:45:04 - INFO - __main__ - Tokenizing Output ...
04/25/2022 18:45:05 - INFO - __main__ - Loaded 500 examples from test data
04/25/2022 18:45:19 - INFO - __main__ - load prompt embedding from ckpt
04/25/2022 18:45:19 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/25/2022 18:45:19 - INFO - __main__ - Starting training!
04/25/2022 18:45:38 - INFO - __main__ - Saved prediction in models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-openbookqa/openbookqa_32_42_0.4_8_predictions.txt
04/25/2022 18:45:38 - INFO - __main__ - ACC on test data: 0.2880
04/25/2022 18:45:38 - INFO - __main__ - prefix=openbookqa_32_42, lr=0.4, bsz=8, dev_performance=0.28125, test_performance=0.288
04/25/2022 18:45:38 - INFO - __main__ - Running ... prefix=openbookqa_32_42, lr=0.3, bsz=8 ...
04/25/2022 18:45:39 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 18:45:39 - INFO - __main__ - Printing 3 examples
04/25/2022 18:45:39 - INFO - __main__ -  [openbookqa] Which is likeliest to metamorphose? (A) a live insect (B) a human (C) a plant (D) a dead butterfly
04/25/2022 18:45:39 - INFO - __main__ - ['a live insect']
04/25/2022 18:45:39 - INFO - __main__ -  [openbookqa] Which animal is most likely to eat another living animal? (A) deer (B) elephant (C) worm (D) lion
04/25/2022 18:45:39 - INFO - __main__ - ['lion']
04/25/2022 18:45:39 - INFO - __main__ -  [openbookqa] If a see through thing is multifaceted, it is most likely (A) a ball (B) an apple (C) a silver globe (D) a quartz square
04/25/2022 18:45:39 - INFO - __main__ - ['a quartz square']
04/25/2022 18:45:39 - INFO - __main__ - Tokenizing Input ...
04/25/2022 18:45:39 - INFO - __main__ - Tokenizing Output ...
04/25/2022 18:45:39 - INFO - __main__ - Loaded 32 examples from train data
04/25/2022 18:45:39 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 18:45:39 - INFO - __main__ - Printing 3 examples
04/25/2022 18:45:39 - INFO - __main__ -  [openbookqa] An organism that can survive without the help of other cells is (A) Brewer's yeast (B) air (C) sand (D) sugar
04/25/2022 18:45:39 - INFO - __main__ - ["Brewer's yeast"]
04/25/2022 18:45:39 - INFO - __main__ -  [openbookqa] some animals remove their hair coverings for (A) naptime (B) lunchtime (C) mating season (D) scorching climates
04/25/2022 18:45:39 - INFO - __main__ - ['scorching climates']
04/25/2022 18:45:39 - INFO - __main__ -  [openbookqa] Which animal sometimes needs to move quickly for food? (A) coyote (B) horse (C) deer (D) buffalo
04/25/2022 18:45:39 - INFO - __main__ - ['coyote']
04/25/2022 18:45:39 - INFO - __main__ - Tokenizing Input ...
04/25/2022 18:45:39 - INFO - __main__ - Tokenizing Output ...
04/25/2022 18:45:39 - INFO - __main__ - Loaded 32 examples from dev data
04/25/2022 18:45:56 - INFO - __main__ - load prompt embedding from ckpt
04/25/2022 18:45:56 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/25/2022 18:45:56 - INFO - __main__ - Starting training!
04/25/2022 18:46:00 - INFO - __main__ - Step 10 Global step 10 Train loss 1.97 on epoch=4
04/25/2022 18:46:02 - INFO - __main__ - Step 20 Global step 20 Train loss 1.43 on epoch=9
04/25/2022 18:46:05 - INFO - __main__ - Step 30 Global step 30 Train loss 0.99 on epoch=14
04/25/2022 18:46:07 - INFO - __main__ - Step 40 Global step 40 Train loss 0.67 on epoch=19
04/25/2022 18:46:10 - INFO - __main__ - Step 50 Global step 50 Train loss 0.59 on epoch=24
04/25/2022 18:46:11 - INFO - __main__ - Global step 50 Train loss 1.13 ACC 0.15625 on epoch=24
04/25/2022 18:46:11 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.15625 on epoch=24, global_step=50
04/25/2022 18:46:14 - INFO - __main__ - Step 60 Global step 60 Train loss 0.53 on epoch=29
04/25/2022 18:46:17 - INFO - __main__ - Step 70 Global step 70 Train loss 0.46 on epoch=34
04/25/2022 18:46:19 - INFO - __main__ - Step 80 Global step 80 Train loss 0.37 on epoch=39
04/25/2022 18:46:22 - INFO - __main__ - Step 90 Global step 90 Train loss 0.40 on epoch=44
04/25/2022 18:46:24 - INFO - __main__ - Step 100 Global step 100 Train loss 0.34 on epoch=49
04/25/2022 18:46:26 - INFO - __main__ - Global step 100 Train loss 0.42 ACC 0.375 on epoch=49
04/25/2022 18:46:26 - INFO - __main__ - Saving model with best ACC: 0.15625 -> 0.375 on epoch=49, global_step=100
04/25/2022 18:46:28 - INFO - __main__ - Step 110 Global step 110 Train loss 0.37 on epoch=54
04/25/2022 18:46:31 - INFO - __main__ - Step 120 Global step 120 Train loss 0.29 on epoch=59
04/25/2022 18:46:33 - INFO - __main__ - Step 130 Global step 130 Train loss 0.22 on epoch=64
04/25/2022 18:46:36 - INFO - __main__ - Step 140 Global step 140 Train loss 0.22 on epoch=69
04/25/2022 18:46:38 - INFO - __main__ - Step 150 Global step 150 Train loss 0.20 on epoch=74
04/25/2022 18:46:40 - INFO - __main__ - Global step 150 Train loss 0.26 ACC 0.1875 on epoch=74
04/25/2022 18:46:43 - INFO - __main__ - Step 160 Global step 160 Train loss 0.20 on epoch=79
04/25/2022 18:46:45 - INFO - __main__ - Step 170 Global step 170 Train loss 0.18 on epoch=84
04/25/2022 18:46:48 - INFO - __main__ - Step 180 Global step 180 Train loss 0.15 on epoch=89
04/25/2022 18:46:50 - INFO - __main__ - Step 190 Global step 190 Train loss 0.23 on epoch=94
04/25/2022 18:46:53 - INFO - __main__ - Step 200 Global step 200 Train loss 0.16 on epoch=99
04/25/2022 18:46:55 - INFO - __main__ - Global step 200 Train loss 0.19 ACC 0.1875 on epoch=99
04/25/2022 18:46:57 - INFO - __main__ - Step 210 Global step 210 Train loss 0.12 on epoch=104
04/25/2022 18:47:00 - INFO - __main__ - Step 220 Global step 220 Train loss 0.10 on epoch=109
04/25/2022 18:47:02 - INFO - __main__ - Step 230 Global step 230 Train loss 0.10 on epoch=114
04/25/2022 18:47:05 - INFO - __main__ - Step 240 Global step 240 Train loss 0.09 on epoch=119
04/25/2022 18:47:07 - INFO - __main__ - Step 250 Global step 250 Train loss 0.10 on epoch=124
04/25/2022 18:47:09 - INFO - __main__ - Global step 250 Train loss 0.10 ACC 0.28125 on epoch=124
04/25/2022 18:47:11 - INFO - __main__ - Step 260 Global step 260 Train loss 0.10 on epoch=129
04/25/2022 18:47:14 - INFO - __main__ - Step 270 Global step 270 Train loss 0.07 on epoch=134
04/25/2022 18:47:16 - INFO - __main__ - Step 280 Global step 280 Train loss 0.04 on epoch=139
04/25/2022 18:47:19 - INFO - __main__ - Step 290 Global step 290 Train loss 0.08 on epoch=144
04/25/2022 18:47:21 - INFO - __main__ - Step 300 Global step 300 Train loss 0.05 on epoch=149
04/25/2022 18:47:23 - INFO - __main__ - Global step 300 Train loss 0.07 ACC 0.1875 on epoch=149
04/25/2022 18:47:26 - INFO - __main__ - Step 310 Global step 310 Train loss 0.06 on epoch=154
04/25/2022 18:47:28 - INFO - __main__ - Step 320 Global step 320 Train loss 0.06 on epoch=159
04/25/2022 18:47:31 - INFO - __main__ - Step 330 Global step 330 Train loss 0.08 on epoch=164
04/25/2022 18:47:33 - INFO - __main__ - Step 340 Global step 340 Train loss 0.10 on epoch=169
04/25/2022 18:47:36 - INFO - __main__ - Step 350 Global step 350 Train loss 0.04 on epoch=174
04/25/2022 18:47:37 - INFO - __main__ - Global step 350 Train loss 0.07 ACC 0.21875 on epoch=174
04/25/2022 18:47:40 - INFO - __main__ - Step 360 Global step 360 Train loss 0.05 on epoch=179
04/25/2022 18:47:43 - INFO - __main__ - Step 370 Global step 370 Train loss 0.05 on epoch=184
04/25/2022 18:47:45 - INFO - __main__ - Step 380 Global step 380 Train loss 0.03 on epoch=189
04/25/2022 18:47:48 - INFO - __main__ - Step 390 Global step 390 Train loss 0.03 on epoch=194
04/25/2022 18:47:50 - INFO - __main__ - Step 400 Global step 400 Train loss 0.03 on epoch=199
04/25/2022 18:47:52 - INFO - __main__ - Global step 400 Train loss 0.04 ACC 0.15625 on epoch=199
04/25/2022 18:47:55 - INFO - __main__ - Step 410 Global step 410 Train loss 0.03 on epoch=204
04/25/2022 18:47:57 - INFO - __main__ - Step 420 Global step 420 Train loss 0.03 on epoch=209
04/25/2022 18:48:00 - INFO - __main__ - Step 430 Global step 430 Train loss 0.04 on epoch=214
04/25/2022 18:48:03 - INFO - __main__ - Step 440 Global step 440 Train loss 0.04 on epoch=219
04/25/2022 18:48:05 - INFO - __main__ - Step 450 Global step 450 Train loss 0.04 on epoch=224
04/25/2022 18:48:07 - INFO - __main__ - Global step 450 Train loss 0.04 ACC 0.1875 on epoch=224
04/25/2022 18:48:09 - INFO - __main__ - Step 460 Global step 460 Train loss 0.05 on epoch=229
04/25/2022 18:48:12 - INFO - __main__ - Step 470 Global step 470 Train loss 0.04 on epoch=234
04/25/2022 18:48:14 - INFO - __main__ - Step 480 Global step 480 Train loss 0.03 on epoch=239
04/25/2022 18:48:17 - INFO - __main__ - Step 490 Global step 490 Train loss 0.03 on epoch=244
04/25/2022 18:48:20 - INFO - __main__ - Step 500 Global step 500 Train loss 0.05 on epoch=249
04/25/2022 18:48:21 - INFO - __main__ - Global step 500 Train loss 0.04 ACC 0.25 on epoch=249
04/25/2022 18:48:24 - INFO - __main__ - Step 510 Global step 510 Train loss 0.05 on epoch=254
04/25/2022 18:48:26 - INFO - __main__ - Step 520 Global step 520 Train loss 0.02 on epoch=259
04/25/2022 18:48:29 - INFO - __main__ - Step 530 Global step 530 Train loss 0.05 on epoch=264
04/25/2022 18:48:31 - INFO - __main__ - Step 540 Global step 540 Train loss 0.01 on epoch=269
04/25/2022 18:48:34 - INFO - __main__ - Step 550 Global step 550 Train loss 0.02 on epoch=274
04/25/2022 18:48:35 - INFO - __main__ - Global step 550 Train loss 0.03 ACC 0.1875 on epoch=274
04/25/2022 18:48:38 - INFO - __main__ - Step 560 Global step 560 Train loss 0.02 on epoch=279
04/25/2022 18:48:40 - INFO - __main__ - Step 570 Global step 570 Train loss 0.10 on epoch=284
04/25/2022 18:48:43 - INFO - __main__ - Step 580 Global step 580 Train loss 0.04 on epoch=289
04/25/2022 18:48:46 - INFO - __main__ - Step 590 Global step 590 Train loss 0.03 on epoch=294
04/25/2022 18:48:48 - INFO - __main__ - Step 600 Global step 600 Train loss 0.01 on epoch=299
04/25/2022 18:48:50 - INFO - __main__ - Global step 600 Train loss 0.04 ACC 0.1875 on epoch=299
04/25/2022 18:48:52 - INFO - __main__ - Step 610 Global step 610 Train loss 0.06 on epoch=304
04/25/2022 18:48:55 - INFO - __main__ - Step 620 Global step 620 Train loss 0.01 on epoch=309
04/25/2022 18:48:57 - INFO - __main__ - Step 630 Global step 630 Train loss 0.01 on epoch=314
04/25/2022 18:49:00 - INFO - __main__ - Step 640 Global step 640 Train loss 0.05 on epoch=319
04/25/2022 18:49:03 - INFO - __main__ - Step 650 Global step 650 Train loss 0.01 on epoch=324
04/25/2022 18:49:04 - INFO - __main__ - Global step 650 Train loss 0.03 ACC 0.1875 on epoch=324
04/25/2022 18:49:07 - INFO - __main__ - Step 660 Global step 660 Train loss 0.04 on epoch=329
04/25/2022 18:49:09 - INFO - __main__ - Step 670 Global step 670 Train loss 0.04 on epoch=334
04/25/2022 18:49:12 - INFO - __main__ - Step 680 Global step 680 Train loss 0.02 on epoch=339
04/25/2022 18:49:14 - INFO - __main__ - Step 690 Global step 690 Train loss 0.03 on epoch=344
04/25/2022 18:49:17 - INFO - __main__ - Step 700 Global step 700 Train loss 0.04 on epoch=349
04/25/2022 18:49:19 - INFO - __main__ - Global step 700 Train loss 0.03 ACC 0.3125 on epoch=349
04/25/2022 18:49:21 - INFO - __main__ - Step 710 Global step 710 Train loss 0.02 on epoch=354
04/25/2022 18:49:24 - INFO - __main__ - Step 720 Global step 720 Train loss 0.03 on epoch=359
04/25/2022 18:49:26 - INFO - __main__ - Step 730 Global step 730 Train loss 0.03 on epoch=364
04/25/2022 18:49:29 - INFO - __main__ - Step 740 Global step 740 Train loss 0.02 on epoch=369
04/25/2022 18:49:31 - INFO - __main__ - Step 750 Global step 750 Train loss 0.03 on epoch=374
04/25/2022 18:49:33 - INFO - __main__ - Global step 750 Train loss 0.03 ACC 0.125 on epoch=374
04/25/2022 18:49:36 - INFO - __main__ - Step 760 Global step 760 Train loss 0.02 on epoch=379
04/25/2022 18:49:38 - INFO - __main__ - Step 770 Global step 770 Train loss 0.03 on epoch=384
04/25/2022 18:49:41 - INFO - __main__ - Step 780 Global step 780 Train loss 0.01 on epoch=389
04/25/2022 18:49:43 - INFO - __main__ - Step 790 Global step 790 Train loss 0.01 on epoch=394
04/25/2022 18:49:46 - INFO - __main__ - Step 800 Global step 800 Train loss 0.01 on epoch=399
04/25/2022 18:49:48 - INFO - __main__ - Global step 800 Train loss 0.02 ACC 0.125 on epoch=399
04/25/2022 18:49:50 - INFO - __main__ - Step 810 Global step 810 Train loss 0.02 on epoch=404
04/25/2022 18:49:53 - INFO - __main__ - Step 820 Global step 820 Train loss 0.01 on epoch=409
04/25/2022 18:49:55 - INFO - __main__ - Step 830 Global step 830 Train loss 0.01 on epoch=414
04/25/2022 18:49:58 - INFO - __main__ - Step 840 Global step 840 Train loss 0.04 on epoch=419
04/25/2022 18:50:00 - INFO - __main__ - Step 850 Global step 850 Train loss 0.01 on epoch=424
04/25/2022 18:50:02 - INFO - __main__ - Global step 850 Train loss 0.02 ACC 0.125 on epoch=424
04/25/2022 18:50:05 - INFO - __main__ - Step 860 Global step 860 Train loss 0.01 on epoch=429
04/25/2022 18:50:07 - INFO - __main__ - Step 870 Global step 870 Train loss 0.01 on epoch=434
04/25/2022 18:50:09 - INFO - __main__ - Step 880 Global step 880 Train loss 0.04 on epoch=439
04/25/2022 18:50:12 - INFO - __main__ - Step 890 Global step 890 Train loss 0.01 on epoch=444
04/25/2022 18:50:14 - INFO - __main__ - Step 900 Global step 900 Train loss 0.01 on epoch=449
04/25/2022 18:50:16 - INFO - __main__ - Global step 900 Train loss 0.01 ACC 0.15625 on epoch=449
04/25/2022 18:50:18 - INFO - __main__ - Step 910 Global step 910 Train loss 0.00 on epoch=454
04/25/2022 18:50:21 - INFO - __main__ - Step 920 Global step 920 Train loss 0.00 on epoch=459
04/25/2022 18:50:23 - INFO - __main__ - Step 930 Global step 930 Train loss 0.00 on epoch=464
04/25/2022 18:50:26 - INFO - __main__ - Step 940 Global step 940 Train loss 0.02 on epoch=469
04/25/2022 18:50:28 - INFO - __main__ - Step 950 Global step 950 Train loss 0.01 on epoch=474
04/25/2022 18:50:30 - INFO - __main__ - Global step 950 Train loss 0.01 ACC 0.21875 on epoch=474
04/25/2022 18:50:32 - INFO - __main__ - Step 960 Global step 960 Train loss 0.00 on epoch=479
04/25/2022 18:50:35 - INFO - __main__ - Step 970 Global step 970 Train loss 0.00 on epoch=484
04/25/2022 18:50:37 - INFO - __main__ - Step 980 Global step 980 Train loss 0.01 on epoch=489
04/25/2022 18:50:40 - INFO - __main__ - Step 990 Global step 990 Train loss 0.00 on epoch=494
04/25/2022 18:50:42 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.01 on epoch=499
04/25/2022 18:50:44 - INFO - __main__ - Global step 1000 Train loss 0.01 ACC 0.21875 on epoch=499
04/25/2022 18:50:47 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.01 on epoch=504
04/25/2022 18:50:49 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.01 on epoch=509
04/25/2022 18:50:52 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.01 on epoch=514
04/25/2022 18:50:54 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.02 on epoch=519
04/25/2022 18:50:57 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.01 on epoch=524
04/25/2022 18:50:59 - INFO - __main__ - Global step 1050 Train loss 0.01 ACC 0.21875 on epoch=524
04/25/2022 18:51:01 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.03 on epoch=529
04/25/2022 18:51:03 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.01 on epoch=534
04/25/2022 18:51:06 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.01 on epoch=539
04/25/2022 18:51:09 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.00 on epoch=544
04/25/2022 18:51:11 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.01 on epoch=549
04/25/2022 18:51:12 - INFO - __main__ - Global step 1100 Train loss 0.01 ACC 0.25 on epoch=549
04/25/2022 18:51:15 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.01 on epoch=554
04/25/2022 18:51:17 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=559
04/25/2022 18:51:20 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=564
04/25/2022 18:51:22 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.00 on epoch=569
04/25/2022 18:51:25 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=574
04/25/2022 18:51:27 - INFO - __main__ - Global step 1150 Train loss 0.01 ACC 0.15625 on epoch=574
04/25/2022 18:51:29 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.01 on epoch=579
04/25/2022 18:51:32 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.01 on epoch=584
04/25/2022 18:51:34 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.00 on epoch=589
04/25/2022 18:51:37 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.03 on epoch=594
04/25/2022 18:51:39 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.00 on epoch=599
04/25/2022 18:51:41 - INFO - __main__ - Global step 1200 Train loss 0.01 ACC 0.15625 on epoch=599
04/25/2022 18:51:43 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.01 on epoch=604
04/25/2022 18:51:46 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=609
04/25/2022 18:51:48 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.00 on epoch=614
04/25/2022 18:51:51 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.04 on epoch=619
04/25/2022 18:51:53 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.00 on epoch=624
04/25/2022 18:51:55 - INFO - __main__ - Global step 1250 Train loss 0.01 ACC 0.1875 on epoch=624
04/25/2022 18:51:58 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.00 on epoch=629
04/25/2022 18:52:00 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.01 on epoch=634
04/25/2022 18:52:03 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.00 on epoch=639
04/25/2022 18:52:05 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.00 on epoch=644
04/25/2022 18:52:08 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=649
04/25/2022 18:52:09 - INFO - __main__ - Global step 1300 Train loss 0.01 ACC 0.15625 on epoch=649
04/25/2022 18:52:12 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=654
04/25/2022 18:52:14 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.00 on epoch=659
04/25/2022 18:52:17 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=664
04/25/2022 18:52:19 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.02 on epoch=669
04/25/2022 18:52:22 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.00 on epoch=674
04/25/2022 18:52:24 - INFO - __main__ - Global step 1350 Train loss 0.01 ACC 0.125 on epoch=674
04/25/2022 18:52:26 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.00 on epoch=679
04/25/2022 18:52:29 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=684
04/25/2022 18:52:31 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=689
04/25/2022 18:52:34 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=694
04/25/2022 18:52:36 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=699
04/25/2022 18:52:38 - INFO - __main__ - Global step 1400 Train loss 0.01 ACC 0.125 on epoch=699
04/25/2022 18:52:40 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=704
04/25/2022 18:52:43 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=709
04/25/2022 18:52:45 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.00 on epoch=714
04/25/2022 18:52:48 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=719
04/25/2022 18:52:50 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=724
04/25/2022 18:52:52 - INFO - __main__ - Global step 1450 Train loss 0.01 ACC 0.125 on epoch=724
04/25/2022 18:52:54 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=729
04/25/2022 18:52:57 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=734
04/25/2022 18:52:59 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=739
04/25/2022 18:53:02 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=744
04/25/2022 18:53:04 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=749
04/25/2022 18:53:06 - INFO - __main__ - Global step 1500 Train loss 0.00 ACC 0.21875 on epoch=749
04/25/2022 18:53:08 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=754
04/25/2022 18:53:11 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=759
04/25/2022 18:53:13 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=764
04/25/2022 18:53:16 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=769
04/25/2022 18:53:19 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=774
04/25/2022 18:53:20 - INFO - __main__ - Global step 1550 Train loss 0.01 ACC 0.21875 on epoch=774
04/25/2022 18:53:23 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=779
04/25/2022 18:53:26 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.03 on epoch=784
04/25/2022 18:53:28 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=789
04/25/2022 18:53:31 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=794
04/25/2022 18:53:33 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=799
04/25/2022 18:53:35 - INFO - __main__ - Global step 1600 Train loss 0.01 ACC 0.25 on epoch=799
04/25/2022 18:53:37 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=804
04/25/2022 18:53:40 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.02 on epoch=809
04/25/2022 18:53:42 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.02 on epoch=814
04/25/2022 18:53:45 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=819
04/25/2022 18:53:47 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=824
04/25/2022 18:53:49 - INFO - __main__ - Global step 1650 Train loss 0.01 ACC 0.21875 on epoch=824
04/25/2022 18:53:52 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=829
04/25/2022 18:53:54 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=834
04/25/2022 18:53:57 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=839
04/25/2022 18:53:59 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=844
04/25/2022 18:54:02 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=849
04/25/2022 18:54:04 - INFO - __main__ - Global step 1700 Train loss 0.01 ACC 0.21875 on epoch=849
04/25/2022 18:54:06 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=854
04/25/2022 18:54:09 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=859
04/25/2022 18:54:11 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=864
04/25/2022 18:54:14 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=869
04/25/2022 18:54:16 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=874
04/25/2022 18:54:18 - INFO - __main__ - Global step 1750 Train loss 0.00 ACC 0.1875 on epoch=874
04/25/2022 18:54:20 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=879
04/25/2022 18:54:23 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=884
04/25/2022 18:54:25 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=889
04/25/2022 18:54:28 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=894
04/25/2022 18:54:30 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=899
04/25/2022 18:54:32 - INFO - __main__ - Global step 1800 Train loss 0.00 ACC 0.21875 on epoch=899
04/25/2022 18:54:35 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=904
04/25/2022 18:54:37 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=909
04/25/2022 18:54:40 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=914
04/25/2022 18:54:42 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=919
04/25/2022 18:54:45 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=924
04/25/2022 18:54:46 - INFO - __main__ - Global step 1850 Train loss 0.01 ACC 0.125 on epoch=924
04/25/2022 18:54:49 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=929
04/25/2022 18:54:51 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=934
04/25/2022 18:54:54 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=939
04/25/2022 18:54:56 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=944
04/25/2022 18:54:59 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.02 on epoch=949
04/25/2022 18:55:01 - INFO - __main__ - Global step 1900 Train loss 0.01 ACC 0.21875 on epoch=949
04/25/2022 18:55:03 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=954
04/25/2022 18:55:06 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=959
04/25/2022 18:55:08 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=964
04/25/2022 18:55:11 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=969
04/25/2022 18:55:13 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=974
04/25/2022 18:55:15 - INFO - __main__ - Global step 1950 Train loss 0.00 ACC 0.1875 on epoch=974
04/25/2022 18:55:17 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=979
04/25/2022 18:55:20 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=984
04/25/2022 18:55:22 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=989
04/25/2022 18:55:25 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=994
04/25/2022 18:55:27 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=999
04/25/2022 18:55:29 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 18:55:29 - INFO - __main__ - Printing 3 examples
04/25/2022 18:55:29 - INFO - __main__ -  [openbookqa] Which is likeliest to metamorphose? (A) a live insect (B) a human (C) a plant (D) a dead butterfly
04/25/2022 18:55:29 - INFO - __main__ - ['a live insect']
04/25/2022 18:55:29 - INFO - __main__ -  [openbookqa] Which animal is most likely to eat another living animal? (A) deer (B) elephant (C) worm (D) lion
04/25/2022 18:55:29 - INFO - __main__ - ['lion']
04/25/2022 18:55:29 - INFO - __main__ -  [openbookqa] If a see through thing is multifaceted, it is most likely (A) a ball (B) an apple (C) a silver globe (D) a quartz square
04/25/2022 18:55:29 - INFO - __main__ - ['a quartz square']
04/25/2022 18:55:29 - INFO - __main__ - Tokenizing Input ...
04/25/2022 18:55:29 - INFO - __main__ - Tokenizing Output ...
04/25/2022 18:55:29 - INFO - __main__ - Loaded 32 examples from train data
04/25/2022 18:55:29 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 18:55:29 - INFO - __main__ - Printing 3 examples
04/25/2022 18:55:29 - INFO - __main__ -  [openbookqa] An organism that can survive without the help of other cells is (A) Brewer's yeast (B) air (C) sand (D) sugar
04/25/2022 18:55:29 - INFO - __main__ - ["Brewer's yeast"]
04/25/2022 18:55:29 - INFO - __main__ -  [openbookqa] some animals remove their hair coverings for (A) naptime (B) lunchtime (C) mating season (D) scorching climates
04/25/2022 18:55:29 - INFO - __main__ - ['scorching climates']
04/25/2022 18:55:29 - INFO - __main__ -  [openbookqa] Which animal sometimes needs to move quickly for food? (A) coyote (B) horse (C) deer (D) buffalo
04/25/2022 18:55:29 - INFO - __main__ - ['coyote']
04/25/2022 18:55:29 - INFO - __main__ - Tokenizing Input ...
04/25/2022 18:55:29 - INFO - __main__ - Tokenizing Output ...
04/25/2022 18:55:29 - INFO - __main__ - Loaded 32 examples from dev data
04/25/2022 18:55:29 - INFO - __main__ - Global step 2000 Train loss 0.01 ACC 0.28125 on epoch=999
04/25/2022 18:55:29 - INFO - __main__ - save last model!
04/25/2022 18:55:29 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
04/25/2022 18:55:29 - INFO - __main__ - Start tokenizing ... 500 instances
04/25/2022 18:55:29 - INFO - __main__ - Printing 3 examples
04/25/2022 18:55:29 - INFO - __main__ -  [openbookqa] Frilled sharks and angler fish live far beneath the surface of the ocean, which is why they are known as (A) Deep sea animals (B) fish (C) Long Sea Fish (D) Far Sea Animals
04/25/2022 18:55:29 - INFO - __main__ - ['Deep sea animals']
04/25/2022 18:55:29 - INFO - __main__ -  [openbookqa] Gas can fill any container it is given, and liquid (A) is standard weight and size (B) is the opposite of variable (C) only needs a few (D) uses what it needs
04/25/2022 18:55:29 - INFO - __main__ - ['uses what it needs']
04/25/2022 18:55:29 - INFO - __main__ -  [openbookqa] When birds migrate south for the winter, they do it because (A) they are genetically called to (B) their children ask for them to (C) it is important to their happiness (D) they decide to each year
04/25/2022 18:55:29 - INFO - __main__ - ['they are genetically called to']
04/25/2022 18:55:29 - INFO - __main__ - Tokenizing Input ...
04/25/2022 18:55:29 - INFO - __main__ - Tokenizing Output ...
04/25/2022 18:55:30 - INFO - __main__ - Loaded 500 examples from test data
04/25/2022 18:55:47 - INFO - __main__ - load prompt embedding from ckpt
04/25/2022 18:55:48 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/25/2022 18:55:48 - INFO - __main__ - Starting training!
04/25/2022 18:56:02 - INFO - __main__ - Saved prediction in models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-openbookqa/openbookqa_32_42_0.3_8_predictions.txt
04/25/2022 18:56:02 - INFO - __main__ - ACC on test data: 0.2720
04/25/2022 18:56:02 - INFO - __main__ - prefix=openbookqa_32_42, lr=0.3, bsz=8, dev_performance=0.375, test_performance=0.272
04/25/2022 18:56:02 - INFO - __main__ - Running ... prefix=openbookqa_32_42, lr=0.2, bsz=8 ...
04/25/2022 18:56:03 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 18:56:03 - INFO - __main__ - Printing 3 examples
04/25/2022 18:56:03 - INFO - __main__ -  [openbookqa] Which is likeliest to metamorphose? (A) a live insect (B) a human (C) a plant (D) a dead butterfly
04/25/2022 18:56:03 - INFO - __main__ - ['a live insect']
04/25/2022 18:56:03 - INFO - __main__ -  [openbookqa] Which animal is most likely to eat another living animal? (A) deer (B) elephant (C) worm (D) lion
04/25/2022 18:56:03 - INFO - __main__ - ['lion']
04/25/2022 18:56:03 - INFO - __main__ -  [openbookqa] If a see through thing is multifaceted, it is most likely (A) a ball (B) an apple (C) a silver globe (D) a quartz square
04/25/2022 18:56:03 - INFO - __main__ - ['a quartz square']
04/25/2022 18:56:03 - INFO - __main__ - Tokenizing Input ...
04/25/2022 18:56:03 - INFO - __main__ - Tokenizing Output ...
04/25/2022 18:56:03 - INFO - __main__ - Loaded 32 examples from train data
04/25/2022 18:56:03 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 18:56:03 - INFO - __main__ - Printing 3 examples
04/25/2022 18:56:03 - INFO - __main__ -  [openbookqa] An organism that can survive without the help of other cells is (A) Brewer's yeast (B) air (C) sand (D) sugar
04/25/2022 18:56:03 - INFO - __main__ - ["Brewer's yeast"]
04/25/2022 18:56:03 - INFO - __main__ -  [openbookqa] some animals remove their hair coverings for (A) naptime (B) lunchtime (C) mating season (D) scorching climates
04/25/2022 18:56:03 - INFO - __main__ - ['scorching climates']
04/25/2022 18:56:03 - INFO - __main__ -  [openbookqa] Which animal sometimes needs to move quickly for food? (A) coyote (B) horse (C) deer (D) buffalo
04/25/2022 18:56:03 - INFO - __main__ - ['coyote']
04/25/2022 18:56:03 - INFO - __main__ - Tokenizing Input ...
04/25/2022 18:56:03 - INFO - __main__ - Tokenizing Output ...
04/25/2022 18:56:03 - INFO - __main__ - Loaded 32 examples from dev data
04/25/2022 18:56:22 - INFO - __main__ - load prompt embedding from ckpt
04/25/2022 18:56:22 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/25/2022 18:56:22 - INFO - __main__ - Starting training!
04/25/2022 18:56:25 - INFO - __main__ - Step 10 Global step 10 Train loss 2.13 on epoch=4
04/25/2022 18:56:28 - INFO - __main__ - Step 20 Global step 20 Train loss 1.53 on epoch=9
04/25/2022 18:56:31 - INFO - __main__ - Step 30 Global step 30 Train loss 1.14 on epoch=14
04/25/2022 18:56:33 - INFO - __main__ - Step 40 Global step 40 Train loss 0.91 on epoch=19
04/25/2022 18:56:35 - INFO - __main__ - Step 50 Global step 50 Train loss 0.64 on epoch=24
04/25/2022 18:56:37 - INFO - __main__ - Global step 50 Train loss 1.27 ACC 0.21875 on epoch=24
04/25/2022 18:56:37 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.21875 on epoch=24, global_step=50
04/25/2022 18:56:40 - INFO - __main__ - Step 60 Global step 60 Train loss 0.68 on epoch=29
04/25/2022 18:56:42 - INFO - __main__ - Step 70 Global step 70 Train loss 0.61 on epoch=34
04/25/2022 18:56:45 - INFO - __main__ - Step 80 Global step 80 Train loss 0.52 on epoch=39
04/25/2022 18:56:47 - INFO - __main__ - Step 90 Global step 90 Train loss 0.47 on epoch=44
04/25/2022 18:56:50 - INFO - __main__ - Step 100 Global step 100 Train loss 0.50 on epoch=49
04/25/2022 18:56:51 - INFO - __main__ - Global step 100 Train loss 0.56 ACC 0.21875 on epoch=49
04/25/2022 18:56:54 - INFO - __main__ - Step 110 Global step 110 Train loss 0.39 on epoch=54
04/25/2022 18:56:56 - INFO - __main__ - Step 120 Global step 120 Train loss 0.32 on epoch=59
04/25/2022 18:56:59 - INFO - __main__ - Step 130 Global step 130 Train loss 0.33 on epoch=64
04/25/2022 18:57:01 - INFO - __main__ - Step 140 Global step 140 Train loss 0.28 on epoch=69
04/25/2022 18:57:04 - INFO - __main__ - Step 150 Global step 150 Train loss 0.26 on epoch=74
04/25/2022 18:57:05 - INFO - __main__ - Global step 150 Train loss 0.32 ACC 0.28125 on epoch=74
04/25/2022 18:57:05 - INFO - __main__ - Saving model with best ACC: 0.21875 -> 0.28125 on epoch=74, global_step=150
04/25/2022 18:57:08 - INFO - __main__ - Step 160 Global step 160 Train loss 0.24 on epoch=79
04/25/2022 18:57:10 - INFO - __main__ - Step 170 Global step 170 Train loss 0.21 on epoch=84
04/25/2022 18:57:13 - INFO - __main__ - Step 180 Global step 180 Train loss 0.26 on epoch=89
04/25/2022 18:57:15 - INFO - __main__ - Step 190 Global step 190 Train loss 0.22 on epoch=94
04/25/2022 18:57:18 - INFO - __main__ - Step 200 Global step 200 Train loss 0.22 on epoch=99
04/25/2022 18:57:20 - INFO - __main__ - Global step 200 Train loss 0.23 ACC 0.1875 on epoch=99
04/25/2022 18:57:22 - INFO - __main__ - Step 210 Global step 210 Train loss 0.13 on epoch=104
04/25/2022 18:57:25 - INFO - __main__ - Step 220 Global step 220 Train loss 0.16 on epoch=109
04/25/2022 18:57:27 - INFO - __main__ - Step 230 Global step 230 Train loss 0.13 on epoch=114
04/25/2022 18:57:30 - INFO - __main__ - Step 240 Global step 240 Train loss 0.15 on epoch=119
04/25/2022 18:57:32 - INFO - __main__ - Step 250 Global step 250 Train loss 0.09 on epoch=124
04/25/2022 18:57:34 - INFO - __main__ - Global step 250 Train loss 0.13 ACC 0.21875 on epoch=124
04/25/2022 18:57:36 - INFO - __main__ - Step 260 Global step 260 Train loss 0.12 on epoch=129
04/25/2022 18:57:39 - INFO - __main__ - Step 270 Global step 270 Train loss 0.11 on epoch=134
04/25/2022 18:57:41 - INFO - __main__ - Step 280 Global step 280 Train loss 0.10 on epoch=139
04/25/2022 18:57:44 - INFO - __main__ - Step 290 Global step 290 Train loss 0.11 on epoch=144
04/25/2022 18:57:46 - INFO - __main__ - Step 300 Global step 300 Train loss 0.11 on epoch=149
04/25/2022 18:57:48 - INFO - __main__ - Global step 300 Train loss 0.11 ACC 0.1875 on epoch=149
04/25/2022 18:57:51 - INFO - __main__ - Step 310 Global step 310 Train loss 0.09 on epoch=154
04/25/2022 18:57:53 - INFO - __main__ - Step 320 Global step 320 Train loss 0.08 on epoch=159
04/25/2022 18:57:56 - INFO - __main__ - Step 330 Global step 330 Train loss 0.08 on epoch=164
04/25/2022 18:57:58 - INFO - __main__ - Step 340 Global step 340 Train loss 0.06 on epoch=169
04/25/2022 18:58:01 - INFO - __main__ - Step 350 Global step 350 Train loss 0.08 on epoch=174
04/25/2022 18:58:02 - INFO - __main__ - Global step 350 Train loss 0.08 ACC 0.25 on epoch=174
04/25/2022 18:58:05 - INFO - __main__ - Step 360 Global step 360 Train loss 0.08 on epoch=179
04/25/2022 18:58:07 - INFO - __main__ - Step 370 Global step 370 Train loss 0.05 on epoch=184
04/25/2022 18:58:10 - INFO - __main__ - Step 380 Global step 380 Train loss 0.06 on epoch=189
04/25/2022 18:58:12 - INFO - __main__ - Step 390 Global step 390 Train loss 0.04 on epoch=194
04/25/2022 18:58:15 - INFO - __main__ - Step 400 Global step 400 Train loss 0.06 on epoch=199
04/25/2022 18:58:17 - INFO - __main__ - Global step 400 Train loss 0.06 ACC 0.1875 on epoch=199
04/25/2022 18:58:19 - INFO - __main__ - Step 410 Global step 410 Train loss 0.05 on epoch=204
04/25/2022 18:58:22 - INFO - __main__ - Step 420 Global step 420 Train loss 0.08 on epoch=209
04/25/2022 18:58:24 - INFO - __main__ - Step 430 Global step 430 Train loss 0.10 on epoch=214
04/25/2022 18:58:27 - INFO - __main__ - Step 440 Global step 440 Train loss 0.04 on epoch=219
04/25/2022 18:58:29 - INFO - __main__ - Step 450 Global step 450 Train loss 0.05 on epoch=224
04/25/2022 18:58:31 - INFO - __main__ - Global step 450 Train loss 0.07 ACC 0.15625 on epoch=224
04/25/2022 18:58:33 - INFO - __main__ - Step 460 Global step 460 Train loss 0.03 on epoch=229
04/25/2022 18:58:36 - INFO - __main__ - Step 470 Global step 470 Train loss 0.06 on epoch=234
04/25/2022 18:58:38 - INFO - __main__ - Step 480 Global step 480 Train loss 0.04 on epoch=239
04/25/2022 18:58:41 - INFO - __main__ - Step 490 Global step 490 Train loss 0.03 on epoch=244
04/25/2022 18:58:43 - INFO - __main__ - Step 500 Global step 500 Train loss 0.02 on epoch=249
04/25/2022 18:58:45 - INFO - __main__ - Global step 500 Train loss 0.04 ACC 0.1875 on epoch=249
04/25/2022 18:58:48 - INFO - __main__ - Step 510 Global step 510 Train loss 0.02 on epoch=254
04/25/2022 18:58:50 - INFO - __main__ - Step 520 Global step 520 Train loss 0.05 on epoch=259
04/25/2022 18:58:53 - INFO - __main__ - Step 530 Global step 530 Train loss 0.03 on epoch=264
04/25/2022 18:58:55 - INFO - __main__ - Step 540 Global step 540 Train loss 0.05 on epoch=269
04/25/2022 18:58:57 - INFO - __main__ - Step 550 Global step 550 Train loss 0.05 on epoch=274
04/25/2022 18:58:59 - INFO - __main__ - Global step 550 Train loss 0.04 ACC 0.1875 on epoch=274
04/25/2022 18:59:02 - INFO - __main__ - Step 560 Global step 560 Train loss 0.03 on epoch=279
04/25/2022 18:59:04 - INFO - __main__ - Step 570 Global step 570 Train loss 0.03 on epoch=284
04/25/2022 18:59:07 - INFO - __main__ - Step 580 Global step 580 Train loss 0.02 on epoch=289
04/25/2022 18:59:09 - INFO - __main__ - Step 590 Global step 590 Train loss 0.04 on epoch=294
04/25/2022 18:59:12 - INFO - __main__ - Step 600 Global step 600 Train loss 0.03 on epoch=299
04/25/2022 18:59:13 - INFO - __main__ - Global step 600 Train loss 0.03 ACC 0.21875 on epoch=299
04/25/2022 18:59:16 - INFO - __main__ - Step 610 Global step 610 Train loss 0.06 on epoch=304
04/25/2022 18:59:18 - INFO - __main__ - Step 620 Global step 620 Train loss 0.02 on epoch=309
04/25/2022 18:59:21 - INFO - __main__ - Step 630 Global step 630 Train loss 0.04 on epoch=314
04/25/2022 18:59:23 - INFO - __main__ - Step 640 Global step 640 Train loss 0.02 on epoch=319
04/25/2022 18:59:26 - INFO - __main__ - Step 650 Global step 650 Train loss 0.04 on epoch=324
04/25/2022 18:59:28 - INFO - __main__ - Global step 650 Train loss 0.04 ACC 0.28125 on epoch=324
04/25/2022 18:59:30 - INFO - __main__ - Step 660 Global step 660 Train loss 0.04 on epoch=329
04/25/2022 18:59:33 - INFO - __main__ - Step 670 Global step 670 Train loss 0.02 on epoch=334
04/25/2022 18:59:35 - INFO - __main__ - Step 680 Global step 680 Train loss 0.03 on epoch=339
04/25/2022 18:59:38 - INFO - __main__ - Step 690 Global step 690 Train loss 0.02 on epoch=344
04/25/2022 18:59:40 - INFO - __main__ - Step 700 Global step 700 Train loss 0.03 on epoch=349
04/25/2022 18:59:42 - INFO - __main__ - Global step 700 Train loss 0.03 ACC 0.15625 on epoch=349
04/25/2022 18:59:44 - INFO - __main__ - Step 710 Global step 710 Train loss 0.03 on epoch=354
04/25/2022 18:59:47 - INFO - __main__ - Step 720 Global step 720 Train loss 0.01 on epoch=359
04/25/2022 18:59:49 - INFO - __main__ - Step 730 Global step 730 Train loss 0.02 on epoch=364
04/25/2022 18:59:52 - INFO - __main__ - Step 740 Global step 740 Train loss 0.01 on epoch=369
04/25/2022 18:59:54 - INFO - __main__ - Step 750 Global step 750 Train loss 0.03 on epoch=374
04/25/2022 18:59:56 - INFO - __main__ - Global step 750 Train loss 0.02 ACC 0.25 on epoch=374
04/25/2022 18:59:58 - INFO - __main__ - Step 760 Global step 760 Train loss 0.06 on epoch=379
04/25/2022 19:00:01 - INFO - __main__ - Step 770 Global step 770 Train loss 0.04 on epoch=384
04/25/2022 19:00:03 - INFO - __main__ - Step 780 Global step 780 Train loss 0.02 on epoch=389
04/25/2022 19:00:06 - INFO - __main__ - Step 790 Global step 790 Train loss 0.02 on epoch=394
04/25/2022 19:00:08 - INFO - __main__ - Step 800 Global step 800 Train loss 0.01 on epoch=399
04/25/2022 19:00:10 - INFO - __main__ - Global step 800 Train loss 0.03 ACC 0.1875 on epoch=399
04/25/2022 19:00:13 - INFO - __main__ - Step 810 Global step 810 Train loss 0.03 on epoch=404
04/25/2022 19:00:15 - INFO - __main__ - Step 820 Global step 820 Train loss 0.01 on epoch=409
04/25/2022 19:00:18 - INFO - __main__ - Step 830 Global step 830 Train loss 0.03 on epoch=414
04/25/2022 19:00:20 - INFO - __main__ - Step 840 Global step 840 Train loss 0.01 on epoch=419
04/25/2022 19:00:23 - INFO - __main__ - Step 850 Global step 850 Train loss 0.01 on epoch=424
04/25/2022 19:00:25 - INFO - __main__ - Global step 850 Train loss 0.02 ACC 0.1875 on epoch=424
04/25/2022 19:00:27 - INFO - __main__ - Step 860 Global step 860 Train loss 0.02 on epoch=429
04/25/2022 19:00:30 - INFO - __main__ - Step 870 Global step 870 Train loss 0.01 on epoch=434
04/25/2022 19:00:32 - INFO - __main__ - Step 880 Global step 880 Train loss 0.02 on epoch=439
04/25/2022 19:00:35 - INFO - __main__ - Step 890 Global step 890 Train loss 0.02 on epoch=444
04/25/2022 19:00:37 - INFO - __main__ - Step 900 Global step 900 Train loss 0.02 on epoch=449
04/25/2022 19:00:39 - INFO - __main__ - Global step 900 Train loss 0.02 ACC 0.21875 on epoch=449
04/25/2022 19:00:42 - INFO - __main__ - Step 910 Global step 910 Train loss 0.04 on epoch=454
04/25/2022 19:00:44 - INFO - __main__ - Step 920 Global step 920 Train loss 0.02 on epoch=459
04/25/2022 19:00:47 - INFO - __main__ - Step 930 Global step 930 Train loss 0.01 on epoch=464
04/25/2022 19:00:49 - INFO - __main__ - Step 940 Global step 940 Train loss 0.04 on epoch=469
04/25/2022 19:00:52 - INFO - __main__ - Step 950 Global step 950 Train loss 0.01 on epoch=474
04/25/2022 19:00:53 - INFO - __main__ - Global step 950 Train loss 0.02 ACC 0.21875 on epoch=474
04/25/2022 19:00:56 - INFO - __main__ - Step 960 Global step 960 Train loss 0.01 on epoch=479
04/25/2022 19:00:58 - INFO - __main__ - Step 970 Global step 970 Train loss 0.01 on epoch=484
04/25/2022 19:01:01 - INFO - __main__ - Step 980 Global step 980 Train loss 0.01 on epoch=489
04/25/2022 19:01:04 - INFO - __main__ - Step 990 Global step 990 Train loss 0.02 on epoch=494
04/25/2022 19:01:06 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.01 on epoch=499
04/25/2022 19:01:08 - INFO - __main__ - Global step 1000 Train loss 0.01 ACC 0.21875 on epoch=499
04/25/2022 19:01:10 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.01 on epoch=504
04/25/2022 19:01:13 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.01 on epoch=509
04/25/2022 19:01:15 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.02 on epoch=514
04/25/2022 19:01:18 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.01 on epoch=519
04/25/2022 19:01:20 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.01 on epoch=524
04/25/2022 19:01:22 - INFO - __main__ - Global step 1050 Train loss 0.01 ACC 0.28125 on epoch=524
04/25/2022 19:01:25 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.03 on epoch=529
04/25/2022 19:01:27 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.01 on epoch=534
04/25/2022 19:01:30 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.01 on epoch=539
04/25/2022 19:01:32 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.03 on epoch=544
04/25/2022 19:01:35 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.01 on epoch=549
04/25/2022 19:01:36 - INFO - __main__ - Global step 1100 Train loss 0.02 ACC 0.21875 on epoch=549
04/25/2022 19:01:39 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.01 on epoch=554
04/25/2022 19:01:41 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=559
04/25/2022 19:01:44 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=564
04/25/2022 19:01:46 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.02 on epoch=569
04/25/2022 19:01:49 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.00 on epoch=574
04/25/2022 19:01:51 - INFO - __main__ - Global step 1150 Train loss 0.01 ACC 0.21875 on epoch=574
04/25/2022 19:01:53 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.02 on epoch=579
04/25/2022 19:01:56 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.01 on epoch=584
04/25/2022 19:01:58 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.01 on epoch=589
04/25/2022 19:02:01 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.01 on epoch=594
04/25/2022 19:02:03 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=599
04/25/2022 19:02:05 - INFO - __main__ - Global step 1200 Train loss 0.01 ACC 0.25 on epoch=599
04/25/2022 19:02:07 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.02 on epoch=604
04/25/2022 19:02:10 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.03 on epoch=609
04/25/2022 19:02:12 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=614
04/25/2022 19:02:15 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=619
04/25/2022 19:02:17 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.01 on epoch=624
04/25/2022 19:02:19 - INFO - __main__ - Global step 1250 Train loss 0.01 ACC 0.21875 on epoch=624
04/25/2022 19:02:22 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.02 on epoch=629
04/25/2022 19:02:24 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.00 on epoch=634
04/25/2022 19:02:27 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.00 on epoch=639
04/25/2022 19:02:29 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=644
04/25/2022 19:02:32 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.00 on epoch=649
04/25/2022 19:02:33 - INFO - __main__ - Global step 1300 Train loss 0.01 ACC 0.28125 on epoch=649
04/25/2022 19:02:36 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.00 on epoch=654
04/25/2022 19:02:39 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=659
04/25/2022 19:02:41 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=664
04/25/2022 19:02:44 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=669
04/25/2022 19:02:46 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.02 on epoch=674
04/25/2022 19:02:48 - INFO - __main__ - Global step 1350 Train loss 0.01 ACC 0.1875 on epoch=674
04/25/2022 19:02:50 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.03 on epoch=679
04/25/2022 19:02:53 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=684
04/25/2022 19:02:56 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=689
04/25/2022 19:02:58 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.00 on epoch=694
04/25/2022 19:03:01 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=699
04/25/2022 19:03:02 - INFO - __main__ - Global step 1400 Train loss 0.01 ACC 0.25 on epoch=699
04/25/2022 19:03:05 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=704
04/25/2022 19:03:07 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=709
04/25/2022 19:03:10 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=714
04/25/2022 19:03:12 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=719
04/25/2022 19:03:15 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=724
04/25/2022 19:03:17 - INFO - __main__ - Global step 1450 Train loss 0.01 ACC 0.1875 on epoch=724
04/25/2022 19:03:19 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=729
04/25/2022 19:03:22 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=734
04/25/2022 19:03:24 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=739
04/25/2022 19:03:27 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=744
04/25/2022 19:03:29 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.02 on epoch=749
04/25/2022 19:03:31 - INFO - __main__ - Global step 1500 Train loss 0.01 ACC 0.15625 on epoch=749
04/25/2022 19:03:34 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=754
04/25/2022 19:03:36 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.03 on epoch=759
04/25/2022 19:03:39 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=764
04/25/2022 19:03:41 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=769
04/25/2022 19:03:44 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=774
04/25/2022 19:03:45 - INFO - __main__ - Global step 1550 Train loss 0.01 ACC 0.21875 on epoch=774
04/25/2022 19:03:48 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=779
04/25/2022 19:03:51 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=784
04/25/2022 19:03:53 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=789
04/25/2022 19:03:56 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=794
04/25/2022 19:03:58 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=799
04/25/2022 19:04:00 - INFO - __main__ - Global step 1600 Train loss 0.01 ACC 0.125 on epoch=799
04/25/2022 19:04:03 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=804
04/25/2022 19:04:05 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=809
04/25/2022 19:04:08 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=814
04/25/2022 19:04:11 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=819
04/25/2022 19:04:13 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=824
04/25/2022 19:04:15 - INFO - __main__ - Global step 1650 Train loss 0.01 ACC 0.15625 on epoch=824
04/25/2022 19:04:17 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=829
04/25/2022 19:04:20 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=834
04/25/2022 19:04:23 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=839
04/25/2022 19:04:25 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.02 on epoch=844
04/25/2022 19:04:28 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=849
04/25/2022 19:04:29 - INFO - __main__ - Global step 1700 Train loss 0.01 ACC 0.125 on epoch=849
04/25/2022 19:04:32 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=854
04/25/2022 19:04:34 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=859
04/25/2022 19:04:37 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=864
04/25/2022 19:04:39 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=869
04/25/2022 19:04:42 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=874
04/25/2022 19:04:44 - INFO - __main__ - Global step 1750 Train loss 0.01 ACC 0.1875 on epoch=874
04/25/2022 19:04:46 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=879
04/25/2022 19:04:49 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=884
04/25/2022 19:04:51 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=889
04/25/2022 19:04:54 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=894
04/25/2022 19:04:56 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=899
04/25/2022 19:04:58 - INFO - __main__ - Global step 1800 Train loss 0.00 ACC 0.15625 on epoch=899
04/25/2022 19:05:01 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=904
04/25/2022 19:05:03 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=909
04/25/2022 19:05:06 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=914
04/25/2022 19:05:08 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=919
04/25/2022 19:05:11 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=924
04/25/2022 19:05:13 - INFO - __main__ - Global step 1850 Train loss 0.01 ACC 0.1875 on epoch=924
04/25/2022 19:05:15 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=929
04/25/2022 19:05:18 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=934
04/25/2022 19:05:20 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=939
04/25/2022 19:05:23 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.04 on epoch=944
04/25/2022 19:05:25 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=949
04/25/2022 19:05:27 - INFO - __main__ - Global step 1900 Train loss 0.01 ACC 0.15625 on epoch=949
04/25/2022 19:05:30 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=954
04/25/2022 19:05:32 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=959
04/25/2022 19:05:35 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=964
04/25/2022 19:05:37 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=969
04/25/2022 19:05:40 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=974
04/25/2022 19:05:41 - INFO - __main__ - Global step 1950 Train loss 0.00 ACC 0.28125 on epoch=974
04/25/2022 19:05:44 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=979
04/25/2022 19:05:47 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=984
04/25/2022 19:05:49 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=989
04/25/2022 19:05:52 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=994
04/25/2022 19:05:54 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=999
04/25/2022 19:05:55 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 19:05:55 - INFO - __main__ - Printing 3 examples
04/25/2022 19:05:55 - INFO - __main__ -  [openbookqa] As vehicles become more efficient petro consumption (A) increases (B) stops (C) decreases (D) stay the same
04/25/2022 19:05:55 - INFO - __main__ - ['decreases']
04/25/2022 19:05:55 - INFO - __main__ -  [openbookqa] which of these could be measured in mL? (A) circumference of a head (B) the contents of a wine jar (C) the length of a pen (D) the width of a window
04/25/2022 19:05:55 - INFO - __main__ - ['the contents of a wine jar']
04/25/2022 19:05:55 - INFO - __main__ -  [openbookqa] To have a positive impact of the environment (A) use Styrofoam plates and bowls (B) use more paper towels (C) drive a car that guzzles gas (D) salvage plastic bottles instead of throwing them away
04/25/2022 19:05:55 - INFO - __main__ - ['salvage plastic bottles instead of throwing them away']
04/25/2022 19:05:55 - INFO - __main__ - Tokenizing Input ...
04/25/2022 19:05:55 - INFO - __main__ - Tokenizing Output ...
04/25/2022 19:05:56 - INFO - __main__ - Loaded 32 examples from train data
04/25/2022 19:05:56 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 19:05:56 - INFO - __main__ - Printing 3 examples
04/25/2022 19:05:56 - INFO - __main__ -  [openbookqa] Due to weathering (A) large submarines are built (B) new bikes are raced (C) holes in the pathway (D) 2nd story houses are built
04/25/2022 19:05:56 - INFO - __main__ - ['holes in the pathway']
04/25/2022 19:05:56 - INFO - __main__ -  [openbookqa] Which area would be brightest, if you woke up there? (A) rainy environments (B) underwater environments (C) forest areas (D) frozen areas
04/25/2022 19:05:56 - INFO - __main__ - ['frozen areas']
04/25/2022 19:05:56 - INFO - __main__ -  [openbookqa] Which area contains few organisms? (A) Madagascar (B) South Pole (C) Amazon Rain Forest (D) Sahara Desert
04/25/2022 19:05:56 - INFO - __main__ - ['South Pole']
04/25/2022 19:05:56 - INFO - __main__ - Tokenizing Input ...
04/25/2022 19:05:56 - INFO - __main__ - Tokenizing Output ...
04/25/2022 19:05:56 - INFO - __main__ - Loaded 32 examples from dev data
04/25/2022 19:05:56 - INFO - __main__ - Global step 2000 Train loss 0.01 ACC 0.1875 on epoch=999
04/25/2022 19:05:56 - INFO - __main__ - save last model!
04/25/2022 19:05:56 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
04/25/2022 19:05:56 - INFO - __main__ - Start tokenizing ... 500 instances
04/25/2022 19:05:56 - INFO - __main__ - Printing 3 examples
04/25/2022 19:05:56 - INFO - __main__ -  [openbookqa] Frilled sharks and angler fish live far beneath the surface of the ocean, which is why they are known as (A) Deep sea animals (B) fish (C) Long Sea Fish (D) Far Sea Animals
04/25/2022 19:05:56 - INFO - __main__ - ['Deep sea animals']
04/25/2022 19:05:56 - INFO - __main__ -  [openbookqa] Gas can fill any container it is given, and liquid (A) is standard weight and size (B) is the opposite of variable (C) only needs a few (D) uses what it needs
04/25/2022 19:05:56 - INFO - __main__ - ['uses what it needs']
04/25/2022 19:05:56 - INFO - __main__ -  [openbookqa] When birds migrate south for the winter, they do it because (A) they are genetically called to (B) their children ask for them to (C) it is important to their happiness (D) they decide to each year
04/25/2022 19:05:56 - INFO - __main__ - ['they are genetically called to']
04/25/2022 19:05:56 - INFO - __main__ - Tokenizing Input ...
04/25/2022 19:05:56 - INFO - __main__ - Tokenizing Output ...
04/25/2022 19:05:57 - INFO - __main__ - Loaded 500 examples from test data
04/25/2022 19:06:14 - INFO - __main__ - load prompt embedding from ckpt
04/25/2022 19:06:14 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/25/2022 19:06:15 - INFO - __main__ - Starting training!
04/25/2022 19:06:30 - INFO - __main__ - Saved prediction in models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-openbookqa/openbookqa_32_42_0.2_8_predictions.txt
04/25/2022 19:06:30 - INFO - __main__ - ACC on test data: 0.3180
04/25/2022 19:06:31 - INFO - __main__ - prefix=openbookqa_32_42, lr=0.2, bsz=8, dev_performance=0.28125, test_performance=0.318
04/25/2022 19:06:31 - INFO - __main__ - Running ... prefix=openbookqa_32_87, lr=0.5, bsz=8 ...
04/25/2022 19:06:32 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 19:06:32 - INFO - __main__ - Printing 3 examples
04/25/2022 19:06:32 - INFO - __main__ -  [openbookqa] As vehicles become more efficient petro consumption (A) increases (B) stops (C) decreases (D) stay the same
04/25/2022 19:06:32 - INFO - __main__ - ['decreases']
04/25/2022 19:06:32 - INFO - __main__ -  [openbookqa] which of these could be measured in mL? (A) circumference of a head (B) the contents of a wine jar (C) the length of a pen (D) the width of a window
04/25/2022 19:06:32 - INFO - __main__ - ['the contents of a wine jar']
04/25/2022 19:06:32 - INFO - __main__ -  [openbookqa] To have a positive impact of the environment (A) use Styrofoam plates and bowls (B) use more paper towels (C) drive a car that guzzles gas (D) salvage plastic bottles instead of throwing them away
04/25/2022 19:06:32 - INFO - __main__ - ['salvage plastic bottles instead of throwing them away']
04/25/2022 19:06:32 - INFO - __main__ - Tokenizing Input ...
04/25/2022 19:06:32 - INFO - __main__ - Tokenizing Output ...
04/25/2022 19:06:32 - INFO - __main__ - Loaded 32 examples from train data
04/25/2022 19:06:32 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 19:06:32 - INFO - __main__ - Printing 3 examples
04/25/2022 19:06:32 - INFO - __main__ -  [openbookqa] Due to weathering (A) large submarines are built (B) new bikes are raced (C) holes in the pathway (D) 2nd story houses are built
04/25/2022 19:06:32 - INFO - __main__ - ['holes in the pathway']
04/25/2022 19:06:32 - INFO - __main__ -  [openbookqa] Which area would be brightest, if you woke up there? (A) rainy environments (B) underwater environments (C) forest areas (D) frozen areas
04/25/2022 19:06:32 - INFO - __main__ - ['frozen areas']
04/25/2022 19:06:32 - INFO - __main__ -  [openbookqa] Which area contains few organisms? (A) Madagascar (B) South Pole (C) Amazon Rain Forest (D) Sahara Desert
04/25/2022 19:06:32 - INFO - __main__ - ['South Pole']
04/25/2022 19:06:32 - INFO - __main__ - Tokenizing Input ...
04/25/2022 19:06:32 - INFO - __main__ - Tokenizing Output ...
04/25/2022 19:06:32 - INFO - __main__ - Loaded 32 examples from dev data
04/25/2022 19:06:47 - INFO - __main__ - load prompt embedding from ckpt
04/25/2022 19:06:48 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/25/2022 19:06:48 - INFO - __main__ - Starting training!
04/25/2022 19:06:52 - INFO - __main__ - Step 10 Global step 10 Train loss 1.86 on epoch=4
04/25/2022 19:06:54 - INFO - __main__ - Step 20 Global step 20 Train loss 0.99 on epoch=9
04/25/2022 19:06:57 - INFO - __main__ - Step 30 Global step 30 Train loss 0.62 on epoch=14
04/25/2022 19:06:59 - INFO - __main__ - Step 40 Global step 40 Train loss 0.51 on epoch=19
04/25/2022 19:07:02 - INFO - __main__ - Step 50 Global step 50 Train loss 0.48 on epoch=24
04/25/2022 19:07:03 - INFO - __main__ - Global step 50 Train loss 0.89 ACC 0.21875 on epoch=24
04/25/2022 19:07:03 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.21875 on epoch=24, global_step=50
04/25/2022 19:07:06 - INFO - __main__ - Step 60 Global step 60 Train loss 0.32 on epoch=29
04/25/2022 19:07:08 - INFO - __main__ - Step 70 Global step 70 Train loss 0.29 on epoch=34
04/25/2022 19:07:11 - INFO - __main__ - Step 80 Global step 80 Train loss 0.29 on epoch=39
04/25/2022 19:07:13 - INFO - __main__ - Step 90 Global step 90 Train loss 0.22 on epoch=44
04/25/2022 19:07:16 - INFO - __main__ - Step 100 Global step 100 Train loss 0.17 on epoch=49
04/25/2022 19:07:17 - INFO - __main__ - Global step 100 Train loss 0.26 ACC 0.25 on epoch=49
04/25/2022 19:07:17 - INFO - __main__ - Saving model with best ACC: 0.21875 -> 0.25 on epoch=49, global_step=100
04/25/2022 19:07:19 - INFO - __main__ - Step 110 Global step 110 Train loss 0.16 on epoch=54
04/25/2022 19:07:22 - INFO - __main__ - Step 120 Global step 120 Train loss 0.18 on epoch=59
04/25/2022 19:07:24 - INFO - __main__ - Step 130 Global step 130 Train loss 0.15 on epoch=64
04/25/2022 19:07:27 - INFO - __main__ - Step 140 Global step 140 Train loss 0.13 on epoch=69
04/25/2022 19:07:29 - INFO - __main__ - Step 150 Global step 150 Train loss 0.14 on epoch=74
04/25/2022 19:07:31 - INFO - __main__ - Global step 150 Train loss 0.15 ACC 0.4375 on epoch=74
04/25/2022 19:07:31 - INFO - __main__ - Saving model with best ACC: 0.25 -> 0.4375 on epoch=74, global_step=150
04/25/2022 19:07:33 - INFO - __main__ - Step 160 Global step 160 Train loss 0.08 on epoch=79
04/25/2022 19:07:36 - INFO - __main__ - Step 170 Global step 170 Train loss 0.09 on epoch=84
04/25/2022 19:07:38 - INFO - __main__ - Step 180 Global step 180 Train loss 0.09 on epoch=89
04/25/2022 19:07:41 - INFO - __main__ - Step 190 Global step 190 Train loss 0.05 on epoch=94
04/25/2022 19:07:43 - INFO - __main__ - Step 200 Global step 200 Train loss 0.09 on epoch=99
04/25/2022 19:07:45 - INFO - __main__ - Global step 200 Train loss 0.08 ACC 0.4375 on epoch=99
04/25/2022 19:07:47 - INFO - __main__ - Step 210 Global step 210 Train loss 0.07 on epoch=104
04/25/2022 19:07:49 - INFO - __main__ - Step 220 Global step 220 Train loss 0.07 on epoch=109
04/25/2022 19:07:52 - INFO - __main__ - Step 230 Global step 230 Train loss 0.08 on epoch=114
04/25/2022 19:07:54 - INFO - __main__ - Step 240 Global step 240 Train loss 0.04 on epoch=119
04/25/2022 19:07:57 - INFO - __main__ - Step 250 Global step 250 Train loss 0.06 on epoch=124
04/25/2022 19:07:58 - INFO - __main__ - Global step 250 Train loss 0.06 ACC 0.40625 on epoch=124
04/25/2022 19:08:01 - INFO - __main__ - Step 260 Global step 260 Train loss 0.05 on epoch=129
04/25/2022 19:08:03 - INFO - __main__ - Step 270 Global step 270 Train loss 0.05 on epoch=134
04/25/2022 19:08:06 - INFO - __main__ - Step 280 Global step 280 Train loss 0.06 on epoch=139
04/25/2022 19:08:08 - INFO - __main__ - Step 290 Global step 290 Train loss 0.04 on epoch=144
04/25/2022 19:08:11 - INFO - __main__ - Step 300 Global step 300 Train loss 0.04 on epoch=149
04/25/2022 19:08:13 - INFO - __main__ - Global step 300 Train loss 0.05 ACC 0.3125 on epoch=149
04/25/2022 19:08:15 - INFO - __main__ - Step 310 Global step 310 Train loss 0.04 on epoch=154
04/25/2022 19:08:18 - INFO - __main__ - Step 320 Global step 320 Train loss 0.04 on epoch=159
04/25/2022 19:08:20 - INFO - __main__ - Step 330 Global step 330 Train loss 0.02 on epoch=164
04/25/2022 19:08:22 - INFO - __main__ - Step 340 Global step 340 Train loss 0.04 on epoch=169
04/25/2022 19:08:25 - INFO - __main__ - Step 350 Global step 350 Train loss 0.02 on epoch=174
04/25/2022 19:08:27 - INFO - __main__ - Global step 350 Train loss 0.03 ACC 0.21875 on epoch=174
04/25/2022 19:08:29 - INFO - __main__ - Step 360 Global step 360 Train loss 0.08 on epoch=179
04/25/2022 19:08:32 - INFO - __main__ - Step 370 Global step 370 Train loss 0.06 on epoch=184
04/25/2022 19:08:34 - INFO - __main__ - Step 380 Global step 380 Train loss 0.02 on epoch=189
04/25/2022 19:08:36 - INFO - __main__ - Step 390 Global step 390 Train loss 0.01 on epoch=194
04/25/2022 19:08:39 - INFO - __main__ - Step 400 Global step 400 Train loss 0.02 on epoch=199
04/25/2022 19:08:40 - INFO - __main__ - Global step 400 Train loss 0.04 ACC 0.21875 on epoch=199
04/25/2022 19:08:43 - INFO - __main__ - Step 410 Global step 410 Train loss 0.03 on epoch=204
04/25/2022 19:08:45 - INFO - __main__ - Step 420 Global step 420 Train loss 0.01 on epoch=209
04/25/2022 19:08:48 - INFO - __main__ - Step 430 Global step 430 Train loss 0.02 on epoch=214
04/25/2022 19:08:50 - INFO - __main__ - Step 440 Global step 440 Train loss 0.02 on epoch=219
04/25/2022 19:08:53 - INFO - __main__ - Step 450 Global step 450 Train loss 0.03 on epoch=224
04/25/2022 19:08:54 - INFO - __main__ - Global step 450 Train loss 0.02 ACC 0.3125 on epoch=224
04/25/2022 19:08:57 - INFO - __main__ - Step 460 Global step 460 Train loss 0.02 on epoch=229
04/25/2022 19:08:59 - INFO - __main__ - Step 470 Global step 470 Train loss 0.02 on epoch=234
04/25/2022 19:09:02 - INFO - __main__ - Step 480 Global step 480 Train loss 0.01 on epoch=239
04/25/2022 19:09:04 - INFO - __main__ - Step 490 Global step 490 Train loss 0.04 on epoch=244
04/25/2022 19:09:07 - INFO - __main__ - Step 500 Global step 500 Train loss 0.02 on epoch=249
04/25/2022 19:09:08 - INFO - __main__ - Global step 500 Train loss 0.02 ACC 0.3125 on epoch=249
04/25/2022 19:09:11 - INFO - __main__ - Step 510 Global step 510 Train loss 0.02 on epoch=254
04/25/2022 19:09:13 - INFO - __main__ - Step 520 Global step 520 Train loss 0.02 on epoch=259
04/25/2022 19:09:16 - INFO - __main__ - Step 530 Global step 530 Train loss 0.02 on epoch=264
04/25/2022 19:09:18 - INFO - __main__ - Step 540 Global step 540 Train loss 0.04 on epoch=269
04/25/2022 19:09:21 - INFO - __main__ - Step 550 Global step 550 Train loss 0.02 on epoch=274
04/25/2022 19:09:22 - INFO - __main__ - Global step 550 Train loss 0.02 ACC 0.34375 on epoch=274
04/25/2022 19:09:25 - INFO - __main__ - Step 560 Global step 560 Train loss 0.03 on epoch=279
04/25/2022 19:09:27 - INFO - __main__ - Step 570 Global step 570 Train loss 0.01 on epoch=284
04/25/2022 19:09:29 - INFO - __main__ - Step 580 Global step 580 Train loss 0.02 on epoch=289
04/25/2022 19:09:32 - INFO - __main__ - Step 590 Global step 590 Train loss 0.01 on epoch=294
04/25/2022 19:09:34 - INFO - __main__ - Step 600 Global step 600 Train loss 0.01 on epoch=299
04/25/2022 19:09:36 - INFO - __main__ - Global step 600 Train loss 0.02 ACC 0.375 on epoch=299
04/25/2022 19:09:38 - INFO - __main__ - Step 610 Global step 610 Train loss 0.01 on epoch=304
04/25/2022 19:09:41 - INFO - __main__ - Step 620 Global step 620 Train loss 0.01 on epoch=309
04/25/2022 19:09:43 - INFO - __main__ - Step 630 Global step 630 Train loss 0.01 on epoch=314
04/25/2022 19:09:46 - INFO - __main__ - Step 640 Global step 640 Train loss 0.01 on epoch=319
04/25/2022 19:09:48 - INFO - __main__ - Step 650 Global step 650 Train loss 0.01 on epoch=324
04/25/2022 19:09:50 - INFO - __main__ - Global step 650 Train loss 0.01 ACC 0.375 on epoch=324
04/25/2022 19:09:52 - INFO - __main__ - Step 660 Global step 660 Train loss 0.00 on epoch=329
04/25/2022 19:09:55 - INFO - __main__ - Step 670 Global step 670 Train loss 0.02 on epoch=334
04/25/2022 19:09:57 - INFO - __main__ - Step 680 Global step 680 Train loss 0.01 on epoch=339
04/25/2022 19:10:00 - INFO - __main__ - Step 690 Global step 690 Train loss 0.01 on epoch=344
04/25/2022 19:10:02 - INFO - __main__ - Step 700 Global step 700 Train loss 0.01 on epoch=349
04/25/2022 19:10:04 - INFO - __main__ - Global step 700 Train loss 0.01 ACC 0.34375 on epoch=349
04/25/2022 19:10:06 - INFO - __main__ - Step 710 Global step 710 Train loss 0.05 on epoch=354
04/25/2022 19:10:09 - INFO - __main__ - Step 720 Global step 720 Train loss 0.04 on epoch=359
04/25/2022 19:10:11 - INFO - __main__ - Step 730 Global step 730 Train loss 0.01 on epoch=364
04/25/2022 19:10:14 - INFO - __main__ - Step 740 Global step 740 Train loss 0.01 on epoch=369
04/25/2022 19:10:16 - INFO - __main__ - Step 750 Global step 750 Train loss 0.01 on epoch=374
04/25/2022 19:10:18 - INFO - __main__ - Global step 750 Train loss 0.02 ACC 0.3125 on epoch=374
04/25/2022 19:10:20 - INFO - __main__ - Step 760 Global step 760 Train loss 0.01 on epoch=379
04/25/2022 19:10:23 - INFO - __main__ - Step 770 Global step 770 Train loss 0.01 on epoch=384
04/25/2022 19:10:25 - INFO - __main__ - Step 780 Global step 780 Train loss 0.00 on epoch=389
04/25/2022 19:10:28 - INFO - __main__ - Step 790 Global step 790 Train loss 0.01 on epoch=394
04/25/2022 19:10:30 - INFO - __main__ - Step 800 Global step 800 Train loss 0.03 on epoch=399
04/25/2022 19:10:32 - INFO - __main__ - Global step 800 Train loss 0.01 ACC 0.28125 on epoch=399
04/25/2022 19:10:34 - INFO - __main__ - Step 810 Global step 810 Train loss 0.01 on epoch=404
04/25/2022 19:10:36 - INFO - __main__ - Step 820 Global step 820 Train loss 0.00 on epoch=409
04/25/2022 19:10:39 - INFO - __main__ - Step 830 Global step 830 Train loss 0.00 on epoch=414
04/25/2022 19:10:41 - INFO - __main__ - Step 840 Global step 840 Train loss 0.00 on epoch=419
04/25/2022 19:10:44 - INFO - __main__ - Step 850 Global step 850 Train loss 0.00 on epoch=424
04/25/2022 19:10:46 - INFO - __main__ - Global step 850 Train loss 0.00 ACC 0.34375 on epoch=424
04/25/2022 19:10:48 - INFO - __main__ - Step 860 Global step 860 Train loss 0.02 on epoch=429
04/25/2022 19:10:50 - INFO - __main__ - Step 870 Global step 870 Train loss 0.01 on epoch=434
04/25/2022 19:10:53 - INFO - __main__ - Step 880 Global step 880 Train loss 0.02 on epoch=439
04/25/2022 19:10:55 - INFO - __main__ - Step 890 Global step 890 Train loss 0.01 on epoch=444
04/25/2022 19:10:58 - INFO - __main__ - Step 900 Global step 900 Train loss 0.01 on epoch=449
04/25/2022 19:11:00 - INFO - __main__ - Global step 900 Train loss 0.01 ACC 0.25 on epoch=449
04/25/2022 19:11:02 - INFO - __main__ - Step 910 Global step 910 Train loss 0.01 on epoch=454
04/25/2022 19:11:04 - INFO - __main__ - Step 920 Global step 920 Train loss 0.01 on epoch=459
04/25/2022 19:11:07 - INFO - __main__ - Step 930 Global step 930 Train loss 0.00 on epoch=464
04/25/2022 19:11:09 - INFO - __main__ - Step 940 Global step 940 Train loss 0.01 on epoch=469
04/25/2022 19:11:12 - INFO - __main__ - Step 950 Global step 950 Train loss 0.01 on epoch=474
04/25/2022 19:11:13 - INFO - __main__ - Global step 950 Train loss 0.01 ACC 0.3125 on epoch=474
04/25/2022 19:11:16 - INFO - __main__ - Step 960 Global step 960 Train loss 0.02 on epoch=479
04/25/2022 19:11:18 - INFO - __main__ - Step 970 Global step 970 Train loss 0.01 on epoch=484
04/25/2022 19:11:21 - INFO - __main__ - Step 980 Global step 980 Train loss 0.03 on epoch=489
04/25/2022 19:11:23 - INFO - __main__ - Step 990 Global step 990 Train loss 0.00 on epoch=494
04/25/2022 19:11:26 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.01 on epoch=499
04/25/2022 19:11:27 - INFO - __main__ - Global step 1000 Train loss 0.01 ACC 0.25 on epoch=499
04/25/2022 19:11:30 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.01 on epoch=504
04/25/2022 19:11:32 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.00 on epoch=509
04/25/2022 19:11:35 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.01 on epoch=514
04/25/2022 19:11:37 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.01 on epoch=519
04/25/2022 19:11:40 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.02 on epoch=524
04/25/2022 19:11:42 - INFO - __main__ - Global step 1050 Train loss 0.01 ACC 0.3125 on epoch=524
04/25/2022 19:11:44 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.01 on epoch=529
04/25/2022 19:11:46 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.01 on epoch=534
04/25/2022 19:11:49 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.00 on epoch=539
04/25/2022 19:11:51 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.01 on epoch=544
04/25/2022 19:11:54 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.01 on epoch=549
04/25/2022 19:11:55 - INFO - __main__ - Global step 1100 Train loss 0.01 ACC 0.3125 on epoch=549
04/25/2022 19:11:58 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.03 on epoch=554
04/25/2022 19:12:00 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=559
04/25/2022 19:12:03 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=564
04/25/2022 19:12:05 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.01 on epoch=569
04/25/2022 19:12:08 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=574
04/25/2022 19:12:09 - INFO - __main__ - Global step 1150 Train loss 0.01 ACC 0.28125 on epoch=574
04/25/2022 19:12:12 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.02 on epoch=579
04/25/2022 19:12:14 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.01 on epoch=584
04/25/2022 19:12:17 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.01 on epoch=589
04/25/2022 19:12:19 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.01 on epoch=594
04/25/2022 19:12:21 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=599
04/25/2022 19:12:23 - INFO - __main__ - Global step 1200 Train loss 0.01 ACC 0.28125 on epoch=599
04/25/2022 19:12:25 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.00 on epoch=604
04/25/2022 19:12:28 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=609
04/25/2022 19:12:30 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.00 on epoch=614
04/25/2022 19:12:33 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.00 on epoch=619
04/25/2022 19:12:35 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.01 on epoch=624
04/25/2022 19:12:37 - INFO - __main__ - Global step 1250 Train loss 0.01 ACC 0.28125 on epoch=624
04/25/2022 19:12:39 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=629
04/25/2022 19:12:42 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.00 on epoch=634
04/25/2022 19:12:44 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=639
04/25/2022 19:12:47 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=644
04/25/2022 19:12:49 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.00 on epoch=649
04/25/2022 19:12:51 - INFO - __main__ - Global step 1300 Train loss 0.01 ACC 0.28125 on epoch=649
04/25/2022 19:12:53 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=654
04/25/2022 19:12:56 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.00 on epoch=659
04/25/2022 19:12:58 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.00 on epoch=664
04/25/2022 19:13:01 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.00 on epoch=669
04/25/2022 19:13:03 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=674
04/25/2022 19:13:05 - INFO - __main__ - Global step 1350 Train loss 0.00 ACC 0.28125 on epoch=674
04/25/2022 19:13:07 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.00 on epoch=679
04/25/2022 19:13:10 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.02 on epoch=684
04/25/2022 19:13:12 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.00 on epoch=689
04/25/2022 19:13:15 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.02 on epoch=694
04/25/2022 19:13:17 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=699
04/25/2022 19:13:19 - INFO - __main__ - Global step 1400 Train loss 0.01 ACC 0.28125 on epoch=699
04/25/2022 19:13:21 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=704
04/25/2022 19:13:24 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=709
04/25/2022 19:13:26 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=714
04/25/2022 19:13:29 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=719
04/25/2022 19:13:31 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=724
04/25/2022 19:13:33 - INFO - __main__ - Global step 1450 Train loss 0.01 ACC 0.25 on epoch=724
04/25/2022 19:13:35 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=729
04/25/2022 19:13:38 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=734
04/25/2022 19:13:40 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=739
04/25/2022 19:13:42 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=744
04/25/2022 19:13:45 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=749
04/25/2022 19:13:47 - INFO - __main__ - Global step 1500 Train loss 0.00 ACC 0.25 on epoch=749
04/25/2022 19:13:49 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.04 on epoch=754
04/25/2022 19:13:52 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.02 on epoch=759
04/25/2022 19:13:54 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.02 on epoch=764
04/25/2022 19:13:56 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=769
04/25/2022 19:13:59 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=774
04/25/2022 19:14:01 - INFO - __main__ - Global step 1550 Train loss 0.02 ACC 0.28125 on epoch=774
04/25/2022 19:14:03 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=779
04/25/2022 19:14:05 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=784
04/25/2022 19:14:08 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=789
04/25/2022 19:14:10 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=794
04/25/2022 19:14:13 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=799
04/25/2022 19:14:14 - INFO - __main__ - Global step 1600 Train loss 0.01 ACC 0.25 on epoch=799
04/25/2022 19:14:17 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=804
04/25/2022 19:14:19 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=809
04/25/2022 19:14:22 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=814
04/25/2022 19:14:24 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=819
04/25/2022 19:14:27 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.03 on epoch=824
04/25/2022 19:14:28 - INFO - __main__ - Global step 1650 Train loss 0.01 ACC 0.25 on epoch=824
04/25/2022 19:14:31 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=829
04/25/2022 19:14:33 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=834
04/25/2022 19:14:36 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=839
04/25/2022 19:14:38 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.03 on epoch=844
04/25/2022 19:14:41 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=849
04/25/2022 19:14:42 - INFO - __main__ - Global step 1700 Train loss 0.01 ACC 0.1875 on epoch=849
04/25/2022 19:14:45 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=854
04/25/2022 19:14:47 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=859
04/25/2022 19:14:50 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=864
04/25/2022 19:14:52 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=869
04/25/2022 19:14:55 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=874
04/25/2022 19:14:56 - INFO - __main__ - Global step 1750 Train loss 0.01 ACC 0.25 on epoch=874
04/25/2022 19:14:59 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=879
04/25/2022 19:15:01 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=884
04/25/2022 19:15:04 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=889
04/25/2022 19:15:06 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=894
04/25/2022 19:15:09 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=899
04/25/2022 19:15:11 - INFO - __main__ - Global step 1800 Train loss 0.00 ACC 0.25 on epoch=899
04/25/2022 19:15:13 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=904
04/25/2022 19:15:15 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=909
04/25/2022 19:15:18 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=914
04/25/2022 19:15:21 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=919
04/25/2022 19:15:23 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=924
04/25/2022 19:15:25 - INFO - __main__ - Global step 1850 Train loss 0.01 ACC 0.25 on epoch=924
04/25/2022 19:15:27 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=929
04/25/2022 19:15:30 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=934
04/25/2022 19:15:32 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=939
04/25/2022 19:15:35 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=944
04/25/2022 19:15:37 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.02 on epoch=949
04/25/2022 19:15:39 - INFO - __main__ - Global step 1900 Train loss 0.01 ACC 0.21875 on epoch=949
04/25/2022 19:15:42 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=954
04/25/2022 19:15:44 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=959
04/25/2022 19:15:47 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=964
04/25/2022 19:15:49 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=969
04/25/2022 19:15:52 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=974
04/25/2022 19:15:53 - INFO - __main__ - Global step 1950 Train loss 0.01 ACC 0.1875 on epoch=974
04/25/2022 19:15:56 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=979
04/25/2022 19:15:58 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=984
04/25/2022 19:16:01 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=989
04/25/2022 19:16:03 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=994
04/25/2022 19:16:06 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=999
04/25/2022 19:16:07 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 19:16:07 - INFO - __main__ - Printing 3 examples
04/25/2022 19:16:07 - INFO - __main__ -  [openbookqa] As vehicles become more efficient petro consumption (A) increases (B) stops (C) decreases (D) stay the same
04/25/2022 19:16:07 - INFO - __main__ - ['decreases']
04/25/2022 19:16:07 - INFO - __main__ -  [openbookqa] which of these could be measured in mL? (A) circumference of a head (B) the contents of a wine jar (C) the length of a pen (D) the width of a window
04/25/2022 19:16:07 - INFO - __main__ - ['the contents of a wine jar']
04/25/2022 19:16:07 - INFO - __main__ -  [openbookqa] To have a positive impact of the environment (A) use Styrofoam plates and bowls (B) use more paper towels (C) drive a car that guzzles gas (D) salvage plastic bottles instead of throwing them away
04/25/2022 19:16:07 - INFO - __main__ - ['salvage plastic bottles instead of throwing them away']
04/25/2022 19:16:07 - INFO - __main__ - Tokenizing Input ...
04/25/2022 19:16:07 - INFO - __main__ - Tokenizing Output ...
04/25/2022 19:16:07 - INFO - __main__ - Loaded 32 examples from train data
04/25/2022 19:16:07 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 19:16:07 - INFO - __main__ - Printing 3 examples
04/25/2022 19:16:07 - INFO - __main__ -  [openbookqa] Due to weathering (A) large submarines are built (B) new bikes are raced (C) holes in the pathway (D) 2nd story houses are built
04/25/2022 19:16:07 - INFO - __main__ - ['holes in the pathway']
04/25/2022 19:16:07 - INFO - __main__ -  [openbookqa] Which area would be brightest, if you woke up there? (A) rainy environments (B) underwater environments (C) forest areas (D) frozen areas
04/25/2022 19:16:07 - INFO - __main__ - ['frozen areas']
04/25/2022 19:16:07 - INFO - __main__ -  [openbookqa] Which area contains few organisms? (A) Madagascar (B) South Pole (C) Amazon Rain Forest (D) Sahara Desert
04/25/2022 19:16:07 - INFO - __main__ - ['South Pole']
04/25/2022 19:16:07 - INFO - __main__ - Tokenizing Input ...
04/25/2022 19:16:07 - INFO - __main__ - Tokenizing Output ...
04/25/2022 19:16:07 - INFO - __main__ - Loaded 32 examples from dev data
04/25/2022 19:16:07 - INFO - __main__ - Global step 2000 Train loss 0.01 ACC 0.21875 on epoch=999
04/25/2022 19:16:07 - INFO - __main__ - save last model!
04/25/2022 19:16:07 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
04/25/2022 19:16:07 - INFO - __main__ - Start tokenizing ... 500 instances
04/25/2022 19:16:07 - INFO - __main__ - Printing 3 examples
04/25/2022 19:16:07 - INFO - __main__ -  [openbookqa] Frilled sharks and angler fish live far beneath the surface of the ocean, which is why they are known as (A) Deep sea animals (B) fish (C) Long Sea Fish (D) Far Sea Animals
04/25/2022 19:16:07 - INFO - __main__ - ['Deep sea animals']
04/25/2022 19:16:07 - INFO - __main__ -  [openbookqa] Gas can fill any container it is given, and liquid (A) is standard weight and size (B) is the opposite of variable (C) only needs a few (D) uses what it needs
04/25/2022 19:16:07 - INFO - __main__ - ['uses what it needs']
04/25/2022 19:16:07 - INFO - __main__ -  [openbookqa] When birds migrate south for the winter, they do it because (A) they are genetically called to (B) their children ask for them to (C) it is important to their happiness (D) they decide to each year
04/25/2022 19:16:07 - INFO - __main__ - ['they are genetically called to']
04/25/2022 19:16:07 - INFO - __main__ - Tokenizing Input ...
04/25/2022 19:16:08 - INFO - __main__ - Tokenizing Output ...
04/25/2022 19:16:08 - INFO - __main__ - Loaded 500 examples from test data
04/25/2022 19:16:25 - INFO - __main__ - load prompt embedding from ckpt
04/25/2022 19:16:26 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/25/2022 19:16:26 - INFO - __main__ - Starting training!
04/25/2022 19:16:40 - INFO - __main__ - Saved prediction in models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-openbookqa/openbookqa_32_87_0.5_8_predictions.txt
04/25/2022 19:16:40 - INFO - __main__ - ACC on test data: 0.2680
04/25/2022 19:16:40 - INFO - __main__ - prefix=openbookqa_32_87, lr=0.5, bsz=8, dev_performance=0.4375, test_performance=0.268
04/25/2022 19:16:40 - INFO - __main__ - Running ... prefix=openbookqa_32_87, lr=0.4, bsz=8 ...
04/25/2022 19:16:41 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 19:16:41 - INFO - __main__ - Printing 3 examples
04/25/2022 19:16:41 - INFO - __main__ -  [openbookqa] As vehicles become more efficient petro consumption (A) increases (B) stops (C) decreases (D) stay the same
04/25/2022 19:16:41 - INFO - __main__ - ['decreases']
04/25/2022 19:16:41 - INFO - __main__ -  [openbookqa] which of these could be measured in mL? (A) circumference of a head (B) the contents of a wine jar (C) the length of a pen (D) the width of a window
04/25/2022 19:16:41 - INFO - __main__ - ['the contents of a wine jar']
04/25/2022 19:16:41 - INFO - __main__ -  [openbookqa] To have a positive impact of the environment (A) use Styrofoam plates and bowls (B) use more paper towels (C) drive a car that guzzles gas (D) salvage plastic bottles instead of throwing them away
04/25/2022 19:16:41 - INFO - __main__ - ['salvage plastic bottles instead of throwing them away']
04/25/2022 19:16:41 - INFO - __main__ - Tokenizing Input ...
04/25/2022 19:16:41 - INFO - __main__ - Tokenizing Output ...
04/25/2022 19:16:41 - INFO - __main__ - Loaded 32 examples from train data
04/25/2022 19:16:41 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 19:16:41 - INFO - __main__ - Printing 3 examples
04/25/2022 19:16:41 - INFO - __main__ -  [openbookqa] Due to weathering (A) large submarines are built (B) new bikes are raced (C) holes in the pathway (D) 2nd story houses are built
04/25/2022 19:16:41 - INFO - __main__ - ['holes in the pathway']
04/25/2022 19:16:41 - INFO - __main__ -  [openbookqa] Which area would be brightest, if you woke up there? (A) rainy environments (B) underwater environments (C) forest areas (D) frozen areas
04/25/2022 19:16:41 - INFO - __main__ - ['frozen areas']
04/25/2022 19:16:41 - INFO - __main__ -  [openbookqa] Which area contains few organisms? (A) Madagascar (B) South Pole (C) Amazon Rain Forest (D) Sahara Desert
04/25/2022 19:16:41 - INFO - __main__ - ['South Pole']
04/25/2022 19:16:41 - INFO - __main__ - Tokenizing Input ...
04/25/2022 19:16:41 - INFO - __main__ - Tokenizing Output ...
04/25/2022 19:16:41 - INFO - __main__ - Loaded 32 examples from dev data
04/25/2022 19:17:00 - INFO - __main__ - load prompt embedding from ckpt
04/25/2022 19:17:01 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/25/2022 19:17:01 - INFO - __main__ - Starting training!
04/25/2022 19:17:04 - INFO - __main__ - Step 10 Global step 10 Train loss 1.90 on epoch=4
04/25/2022 19:17:06 - INFO - __main__ - Step 20 Global step 20 Train loss 1.16 on epoch=9
04/25/2022 19:17:09 - INFO - __main__ - Step 30 Global step 30 Train loss 0.76 on epoch=14
04/25/2022 19:17:11 - INFO - __main__ - Step 40 Global step 40 Train loss 0.54 on epoch=19
04/25/2022 19:17:14 - INFO - __main__ - Step 50 Global step 50 Train loss 0.44 on epoch=24
04/25/2022 19:17:16 - INFO - __main__ - Global step 50 Train loss 0.96 ACC 0.3125 on epoch=24
04/25/2022 19:17:16 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.3125 on epoch=24, global_step=50
04/25/2022 19:17:19 - INFO - __main__ - Step 60 Global step 60 Train loss 0.45 on epoch=29
04/25/2022 19:17:21 - INFO - __main__ - Step 70 Global step 70 Train loss 0.32 on epoch=34
04/25/2022 19:17:24 - INFO - __main__ - Step 80 Global step 80 Train loss 0.38 on epoch=39
04/25/2022 19:17:26 - INFO - __main__ - Step 90 Global step 90 Train loss 0.30 on epoch=44
04/25/2022 19:17:29 - INFO - __main__ - Step 100 Global step 100 Train loss 0.28 on epoch=49
04/25/2022 19:17:30 - INFO - __main__ - Global step 100 Train loss 0.34 ACC 0.34375 on epoch=49
04/25/2022 19:17:30 - INFO - __main__ - Saving model with best ACC: 0.3125 -> 0.34375 on epoch=49, global_step=100
04/25/2022 19:17:32 - INFO - __main__ - Step 110 Global step 110 Train loss 0.21 on epoch=54
04/25/2022 19:17:35 - INFO - __main__ - Step 120 Global step 120 Train loss 0.22 on epoch=59
04/25/2022 19:17:37 - INFO - __main__ - Step 130 Global step 130 Train loss 0.12 on epoch=64
04/25/2022 19:17:40 - INFO - __main__ - Step 140 Global step 140 Train loss 0.13 on epoch=69
04/25/2022 19:17:42 - INFO - __main__ - Step 150 Global step 150 Train loss 0.17 on epoch=74
04/25/2022 19:17:44 - INFO - __main__ - Global step 150 Train loss 0.17 ACC 0.34375 on epoch=74
04/25/2022 19:17:46 - INFO - __main__ - Step 160 Global step 160 Train loss 0.12 on epoch=79
04/25/2022 19:17:49 - INFO - __main__ - Step 170 Global step 170 Train loss 0.14 on epoch=84
04/25/2022 19:17:51 - INFO - __main__ - Step 180 Global step 180 Train loss 0.14 on epoch=89
04/25/2022 19:17:54 - INFO - __main__ - Step 190 Global step 190 Train loss 0.13 on epoch=94
04/25/2022 19:17:56 - INFO - __main__ - Step 200 Global step 200 Train loss 0.10 on epoch=99
04/25/2022 19:17:58 - INFO - __main__ - Global step 200 Train loss 0.13 ACC 0.25 on epoch=99
04/25/2022 19:18:00 - INFO - __main__ - Step 210 Global step 210 Train loss 0.09 on epoch=104
04/25/2022 19:18:02 - INFO - __main__ - Step 220 Global step 220 Train loss 0.08 on epoch=109
04/25/2022 19:18:05 - INFO - __main__ - Step 230 Global step 230 Train loss 0.08 on epoch=114
04/25/2022 19:18:07 - INFO - __main__ - Step 240 Global step 240 Train loss 0.06 on epoch=119
04/25/2022 19:18:10 - INFO - __main__ - Step 250 Global step 250 Train loss 0.07 on epoch=124
04/25/2022 19:18:11 - INFO - __main__ - Global step 250 Train loss 0.08 ACC 0.28125 on epoch=124
04/25/2022 19:18:14 - INFO - __main__ - Step 260 Global step 260 Train loss 0.05 on epoch=129
04/25/2022 19:18:16 - INFO - __main__ - Step 270 Global step 270 Train loss 0.07 on epoch=134
04/25/2022 19:18:19 - INFO - __main__ - Step 280 Global step 280 Train loss 0.08 on epoch=139
04/25/2022 19:18:21 - INFO - __main__ - Step 290 Global step 290 Train loss 0.09 on epoch=144
04/25/2022 19:18:24 - INFO - __main__ - Step 300 Global step 300 Train loss 0.05 on epoch=149
04/25/2022 19:18:25 - INFO - __main__ - Global step 300 Train loss 0.07 ACC 0.34375 on epoch=149
04/25/2022 19:18:28 - INFO - __main__ - Step 310 Global step 310 Train loss 0.04 on epoch=154
04/25/2022 19:18:30 - INFO - __main__ - Step 320 Global step 320 Train loss 0.05 on epoch=159
04/25/2022 19:18:33 - INFO - __main__ - Step 330 Global step 330 Train loss 0.09 on epoch=164
04/25/2022 19:18:35 - INFO - __main__ - Step 340 Global step 340 Train loss 0.06 on epoch=169
04/25/2022 19:18:37 - INFO - __main__ - Step 350 Global step 350 Train loss 0.03 on epoch=174
04/25/2022 19:18:39 - INFO - __main__ - Global step 350 Train loss 0.05 ACC 0.34375 on epoch=174
04/25/2022 19:18:42 - INFO - __main__ - Step 360 Global step 360 Train loss 0.05 on epoch=179
04/25/2022 19:18:44 - INFO - __main__ - Step 370 Global step 370 Train loss 0.03 on epoch=184
04/25/2022 19:18:47 - INFO - __main__ - Step 380 Global step 380 Train loss 0.03 on epoch=189
04/25/2022 19:18:49 - INFO - __main__ - Step 390 Global step 390 Train loss 0.04 on epoch=194
04/25/2022 19:18:51 - INFO - __main__ - Step 400 Global step 400 Train loss 0.01 on epoch=199
04/25/2022 19:18:53 - INFO - __main__ - Global step 400 Train loss 0.03 ACC 0.28125 on epoch=199
04/25/2022 19:18:56 - INFO - __main__ - Step 410 Global step 410 Train loss 0.05 on epoch=204
04/25/2022 19:18:58 - INFO - __main__ - Step 420 Global step 420 Train loss 0.03 on epoch=209
04/25/2022 19:19:00 - INFO - __main__ - Step 430 Global step 430 Train loss 0.04 on epoch=214
04/25/2022 19:19:03 - INFO - __main__ - Step 440 Global step 440 Train loss 0.04 on epoch=219
04/25/2022 19:19:05 - INFO - __main__ - Step 450 Global step 450 Train loss 0.05 on epoch=224
04/25/2022 19:19:07 - INFO - __main__ - Global step 450 Train loss 0.04 ACC 0.25 on epoch=224
04/25/2022 19:19:09 - INFO - __main__ - Step 460 Global step 460 Train loss 0.02 on epoch=229
04/25/2022 19:19:12 - INFO - __main__ - Step 470 Global step 470 Train loss 0.04 on epoch=234
04/25/2022 19:19:14 - INFO - __main__ - Step 480 Global step 480 Train loss 0.03 on epoch=239
04/25/2022 19:19:17 - INFO - __main__ - Step 490 Global step 490 Train loss 0.06 on epoch=244
04/25/2022 19:19:19 - INFO - __main__ - Step 500 Global step 500 Train loss 0.04 on epoch=249
04/25/2022 19:19:21 - INFO - __main__ - Global step 500 Train loss 0.04 ACC 0.375 on epoch=249
04/25/2022 19:19:21 - INFO - __main__ - Saving model with best ACC: 0.34375 -> 0.375 on epoch=249, global_step=500
04/25/2022 19:19:23 - INFO - __main__ - Step 510 Global step 510 Train loss 0.07 on epoch=254
04/25/2022 19:19:26 - INFO - __main__ - Step 520 Global step 520 Train loss 0.02 on epoch=259
04/25/2022 19:19:28 - INFO - __main__ - Step 530 Global step 530 Train loss 0.03 on epoch=264
04/25/2022 19:19:30 - INFO - __main__ - Step 540 Global step 540 Train loss 0.02 on epoch=269
04/25/2022 19:19:33 - INFO - __main__ - Step 550 Global step 550 Train loss 0.05 on epoch=274
04/25/2022 19:19:35 - INFO - __main__ - Global step 550 Train loss 0.04 ACC 0.34375 on epoch=274
04/25/2022 19:19:37 - INFO - __main__ - Step 560 Global step 560 Train loss 0.05 on epoch=279
04/25/2022 19:19:39 - INFO - __main__ - Step 570 Global step 570 Train loss 0.02 on epoch=284
04/25/2022 19:19:42 - INFO - __main__ - Step 580 Global step 580 Train loss 0.01 on epoch=289
04/25/2022 19:19:44 - INFO - __main__ - Step 590 Global step 590 Train loss 0.03 on epoch=294
04/25/2022 19:19:47 - INFO - __main__ - Step 600 Global step 600 Train loss 0.03 on epoch=299
04/25/2022 19:19:48 - INFO - __main__ - Global step 600 Train loss 0.03 ACC 0.34375 on epoch=299
04/25/2022 19:19:51 - INFO - __main__ - Step 610 Global step 610 Train loss 0.02 on epoch=304
04/25/2022 19:19:53 - INFO - __main__ - Step 620 Global step 620 Train loss 0.01 on epoch=309
04/25/2022 19:19:56 - INFO - __main__ - Step 630 Global step 630 Train loss 0.01 on epoch=314
04/25/2022 19:19:58 - INFO - __main__ - Step 640 Global step 640 Train loss 0.05 on epoch=319
04/25/2022 19:20:01 - INFO - __main__ - Step 650 Global step 650 Train loss 0.05 on epoch=324
04/25/2022 19:20:02 - INFO - __main__ - Global step 650 Train loss 0.03 ACC 0.34375 on epoch=324
04/25/2022 19:20:05 - INFO - __main__ - Step 660 Global step 660 Train loss 0.02 on epoch=329
04/25/2022 19:20:07 - INFO - __main__ - Step 670 Global step 670 Train loss 0.01 on epoch=334
04/25/2022 19:20:10 - INFO - __main__ - Step 680 Global step 680 Train loss 0.02 on epoch=339
04/25/2022 19:20:12 - INFO - __main__ - Step 690 Global step 690 Train loss 0.02 on epoch=344
04/25/2022 19:20:15 - INFO - __main__ - Step 700 Global step 700 Train loss 0.03 on epoch=349
04/25/2022 19:20:16 - INFO - __main__ - Global step 700 Train loss 0.02 ACC 0.34375 on epoch=349
04/25/2022 19:20:19 - INFO - __main__ - Step 710 Global step 710 Train loss 0.02 on epoch=354
04/25/2022 19:20:21 - INFO - __main__ - Step 720 Global step 720 Train loss 0.01 on epoch=359
04/25/2022 19:20:24 - INFO - __main__ - Step 730 Global step 730 Train loss 0.01 on epoch=364
04/25/2022 19:20:26 - INFO - __main__ - Step 740 Global step 740 Train loss 0.01 on epoch=369
04/25/2022 19:20:29 - INFO - __main__ - Step 750 Global step 750 Train loss 0.01 on epoch=374
04/25/2022 19:20:30 - INFO - __main__ - Global step 750 Train loss 0.01 ACC 0.3125 on epoch=374
04/25/2022 19:20:33 - INFO - __main__ - Step 760 Global step 760 Train loss 0.01 on epoch=379
04/25/2022 19:20:35 - INFO - __main__ - Step 770 Global step 770 Train loss 0.01 on epoch=384
04/25/2022 19:20:38 - INFO - __main__ - Step 780 Global step 780 Train loss 0.02 on epoch=389
04/25/2022 19:20:40 - INFO - __main__ - Step 790 Global step 790 Train loss 0.01 on epoch=394
04/25/2022 19:20:42 - INFO - __main__ - Step 800 Global step 800 Train loss 0.01 on epoch=399
04/25/2022 19:20:44 - INFO - __main__ - Global step 800 Train loss 0.01 ACC 0.25 on epoch=399
04/25/2022 19:20:47 - INFO - __main__ - Step 810 Global step 810 Train loss 0.01 on epoch=404
04/25/2022 19:20:49 - INFO - __main__ - Step 820 Global step 820 Train loss 0.01 on epoch=409
04/25/2022 19:20:51 - INFO - __main__ - Step 830 Global step 830 Train loss 0.01 on epoch=414
04/25/2022 19:20:54 - INFO - __main__ - Step 840 Global step 840 Train loss 0.02 on epoch=419
04/25/2022 19:20:56 - INFO - __main__ - Step 850 Global step 850 Train loss 0.01 on epoch=424
04/25/2022 19:20:58 - INFO - __main__ - Global step 850 Train loss 0.01 ACC 0.25 on epoch=424
04/25/2022 19:21:01 - INFO - __main__ - Step 860 Global step 860 Train loss 0.01 on epoch=429
04/25/2022 19:21:03 - INFO - __main__ - Step 870 Global step 870 Train loss 0.00 on epoch=434
04/25/2022 19:21:05 - INFO - __main__ - Step 880 Global step 880 Train loss 0.01 on epoch=439
04/25/2022 19:21:08 - INFO - __main__ - Step 890 Global step 890 Train loss 0.01 on epoch=444
04/25/2022 19:21:10 - INFO - __main__ - Step 900 Global step 900 Train loss 0.02 on epoch=449
04/25/2022 19:21:12 - INFO - __main__ - Global step 900 Train loss 0.01 ACC 0.3125 on epoch=449
04/25/2022 19:21:14 - INFO - __main__ - Step 910 Global step 910 Train loss 0.01 on epoch=454
04/25/2022 19:21:16 - INFO - __main__ - Step 920 Global step 920 Train loss 0.02 on epoch=459
04/25/2022 19:21:19 - INFO - __main__ - Step 930 Global step 930 Train loss 0.01 on epoch=464
04/25/2022 19:21:21 - INFO - __main__ - Step 940 Global step 940 Train loss 0.01 on epoch=469
04/25/2022 19:21:24 - INFO - __main__ - Step 950 Global step 950 Train loss 0.00 on epoch=474
04/25/2022 19:21:26 - INFO - __main__ - Global step 950 Train loss 0.01 ACC 0.1875 on epoch=474
04/25/2022 19:21:28 - INFO - __main__ - Step 960 Global step 960 Train loss 0.03 on epoch=479
04/25/2022 19:21:30 - INFO - __main__ - Step 970 Global step 970 Train loss 0.02 on epoch=484
04/25/2022 19:21:33 - INFO - __main__ - Step 980 Global step 980 Train loss 0.01 on epoch=489
04/25/2022 19:21:35 - INFO - __main__ - Step 990 Global step 990 Train loss 0.02 on epoch=494
04/25/2022 19:21:38 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.01 on epoch=499
04/25/2022 19:21:39 - INFO - __main__ - Global step 1000 Train loss 0.02 ACC 0.34375 on epoch=499
04/25/2022 19:21:42 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.00 on epoch=504
04/25/2022 19:21:44 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.00 on epoch=509
04/25/2022 19:21:47 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.01 on epoch=514
04/25/2022 19:21:49 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.00 on epoch=519
04/25/2022 19:21:51 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.02 on epoch=524
04/25/2022 19:21:53 - INFO - __main__ - Global step 1050 Train loss 0.01 ACC 0.28125 on epoch=524
04/25/2022 19:21:56 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.01 on epoch=529
04/25/2022 19:21:58 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.01 on epoch=534
04/25/2022 19:22:00 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.00 on epoch=539
04/25/2022 19:22:03 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.00 on epoch=544
04/25/2022 19:22:05 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.01 on epoch=549
04/25/2022 19:22:07 - INFO - __main__ - Global step 1100 Train loss 0.01 ACC 0.25 on epoch=549
04/25/2022 19:22:09 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.00 on epoch=554
04/25/2022 19:22:12 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=559
04/25/2022 19:22:14 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=564
04/25/2022 19:22:17 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.04 on epoch=569
04/25/2022 19:22:19 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.00 on epoch=574
04/25/2022 19:22:21 - INFO - __main__ - Global step 1150 Train loss 0.01 ACC 0.28125 on epoch=574
04/25/2022 19:22:23 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.01 on epoch=579
04/25/2022 19:22:26 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.01 on epoch=584
04/25/2022 19:22:28 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.00 on epoch=589
04/25/2022 19:22:30 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.01 on epoch=594
04/25/2022 19:22:33 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=599
04/25/2022 19:22:35 - INFO - __main__ - Global step 1200 Train loss 0.01 ACC 0.3125 on epoch=599
04/25/2022 19:22:37 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.00 on epoch=604
04/25/2022 19:22:39 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.00 on epoch=609
04/25/2022 19:22:42 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.00 on epoch=614
04/25/2022 19:22:44 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.02 on epoch=619
04/25/2022 19:22:47 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.01 on epoch=624
04/25/2022 19:22:48 - INFO - __main__ - Global step 1250 Train loss 0.01 ACC 0.28125 on epoch=624
04/25/2022 19:22:51 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.02 on epoch=629
04/25/2022 19:22:53 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.01 on epoch=634
04/25/2022 19:22:56 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=639
04/25/2022 19:22:58 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=644
04/25/2022 19:23:00 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=649
04/25/2022 19:23:02 - INFO - __main__ - Global step 1300 Train loss 0.01 ACC 0.21875 on epoch=649
04/25/2022 19:23:05 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.00 on epoch=654
04/25/2022 19:23:07 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.00 on epoch=659
04/25/2022 19:23:10 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.00 on epoch=664
04/25/2022 19:23:12 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.00 on epoch=669
04/25/2022 19:23:14 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.00 on epoch=674
04/25/2022 19:23:16 - INFO - __main__ - Global step 1350 Train loss 0.00 ACC 0.3125 on epoch=674
04/25/2022 19:23:19 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=679
04/25/2022 19:23:21 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=684
04/25/2022 19:23:23 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.00 on epoch=689
04/25/2022 19:23:26 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=694
04/25/2022 19:23:28 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.00 on epoch=699
04/25/2022 19:23:30 - INFO - __main__ - Global step 1400 Train loss 0.01 ACC 0.25 on epoch=699
04/25/2022 19:23:32 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=704
04/25/2022 19:23:35 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=709
04/25/2022 19:23:37 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.00 on epoch=714
04/25/2022 19:23:40 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=719
04/25/2022 19:23:42 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=724
04/25/2022 19:23:44 - INFO - __main__ - Global step 1450 Train loss 0.01 ACC 0.25 on epoch=724
04/25/2022 19:23:46 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=729
04/25/2022 19:23:49 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=734
04/25/2022 19:23:51 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=739
04/25/2022 19:23:53 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=744
04/25/2022 19:23:56 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=749
04/25/2022 19:23:58 - INFO - __main__ - Global step 1500 Train loss 0.01 ACC 0.3125 on epoch=749
04/25/2022 19:24:00 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=754
04/25/2022 19:24:02 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=759
04/25/2022 19:24:05 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.02 on epoch=764
04/25/2022 19:24:07 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=769
04/25/2022 19:24:10 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=774
04/25/2022 19:24:11 - INFO - __main__ - Global step 1550 Train loss 0.01 ACC 0.3125 on epoch=774
04/25/2022 19:24:14 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=779
04/25/2022 19:24:16 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=784
04/25/2022 19:24:19 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.02 on epoch=789
04/25/2022 19:24:21 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=794
04/25/2022 19:24:24 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=799
04/25/2022 19:24:25 - INFO - __main__ - Global step 1600 Train loss 0.01 ACC 0.3125 on epoch=799
04/25/2022 19:24:28 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=804
04/25/2022 19:24:30 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=809
04/25/2022 19:24:33 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=814
04/25/2022 19:24:35 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=819
04/25/2022 19:24:37 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=824
04/25/2022 19:24:39 - INFO - __main__ - Global step 1650 Train loss 0.00 ACC 0.28125 on epoch=824
04/25/2022 19:24:42 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=829
04/25/2022 19:24:44 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=834
04/25/2022 19:24:46 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=839
04/25/2022 19:24:49 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=844
04/25/2022 19:24:51 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=849
04/25/2022 19:24:53 - INFO - __main__ - Global step 1700 Train loss 0.01 ACC 0.28125 on epoch=849
04/25/2022 19:24:55 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=854
04/25/2022 19:24:58 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=859
04/25/2022 19:25:00 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=864
04/25/2022 19:25:03 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=869
04/25/2022 19:25:05 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=874
04/25/2022 19:25:07 - INFO - __main__ - Global step 1750 Train loss 0.01 ACC 0.28125 on epoch=874
04/25/2022 19:25:09 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=879
04/25/2022 19:25:12 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=884
04/25/2022 19:25:14 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=889
04/25/2022 19:25:17 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=894
04/25/2022 19:25:19 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=899
04/25/2022 19:25:21 - INFO - __main__ - Global step 1800 Train loss 0.00 ACC 0.25 on epoch=899
04/25/2022 19:25:24 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=904
04/25/2022 19:25:26 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=909
04/25/2022 19:25:28 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=914
04/25/2022 19:25:31 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=919
04/25/2022 19:25:33 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=924
04/25/2022 19:25:35 - INFO - __main__ - Global step 1850 Train loss 0.01 ACC 0.21875 on epoch=924
04/25/2022 19:25:38 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=929
04/25/2022 19:25:40 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=934
04/25/2022 19:25:43 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=939
04/25/2022 19:25:45 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=944
04/25/2022 19:25:48 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=949
04/25/2022 19:25:49 - INFO - __main__ - Global step 1900 Train loss 0.00 ACC 0.25 on epoch=949
04/25/2022 19:25:52 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=954
04/25/2022 19:25:54 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=959
04/25/2022 19:25:57 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=964
04/25/2022 19:25:59 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=969
04/25/2022 19:26:02 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=974
04/25/2022 19:26:04 - INFO - __main__ - Global step 1950 Train loss 0.01 ACC 0.34375 on epoch=974
04/25/2022 19:26:06 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=979
04/25/2022 19:26:09 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=984
04/25/2022 19:26:11 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=989
04/25/2022 19:26:14 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=994
04/25/2022 19:26:16 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=999
04/25/2022 19:26:18 - INFO - __main__ - Global step 2000 Train loss 0.00 ACC 0.25 on epoch=999
04/25/2022 19:26:18 - INFO - __main__ - save last model!
04/25/2022 19:26:18 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
04/25/2022 19:26:18 - INFO - __main__ - Start tokenizing ... 500 instances
04/25/2022 19:26:18 - INFO - __main__ - Printing 3 examples
04/25/2022 19:26:18 - INFO - __main__ -  [openbookqa] Frilled sharks and angler fish live far beneath the surface of the ocean, which is why they are known as (A) Deep sea animals (B) fish (C) Long Sea Fish (D) Far Sea Animals
04/25/2022 19:26:18 - INFO - __main__ - ['Deep sea animals']
04/25/2022 19:26:18 - INFO - __main__ -  [openbookqa] Gas can fill any container it is given, and liquid (A) is standard weight and size (B) is the opposite of variable (C) only needs a few (D) uses what it needs
04/25/2022 19:26:18 - INFO - __main__ - ['uses what it needs']
04/25/2022 19:26:18 - INFO - __main__ -  [openbookqa] When birds migrate south for the winter, they do it because (A) they are genetically called to (B) their children ask for them to (C) it is important to their happiness (D) they decide to each year
04/25/2022 19:26:18 - INFO - __main__ - ['they are genetically called to']
04/25/2022 19:26:18 - INFO - __main__ - Tokenizing Input ...
04/25/2022 19:26:18 - INFO - __main__ - Tokenizing Output ...
04/25/2022 19:26:19 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 19:26:19 - INFO - __main__ - Printing 3 examples
04/25/2022 19:26:19 - INFO - __main__ -  [openbookqa] As vehicles become more efficient petro consumption (A) increases (B) stops (C) decreases (D) stay the same
04/25/2022 19:26:19 - INFO - __main__ - ['decreases']
04/25/2022 19:26:19 - INFO - __main__ -  [openbookqa] which of these could be measured in mL? (A) circumference of a head (B) the contents of a wine jar (C) the length of a pen (D) the width of a window
04/25/2022 19:26:19 - INFO - __main__ - ['the contents of a wine jar']
04/25/2022 19:26:19 - INFO - __main__ -  [openbookqa] To have a positive impact of the environment (A) use Styrofoam plates and bowls (B) use more paper towels (C) drive a car that guzzles gas (D) salvage plastic bottles instead of throwing them away
04/25/2022 19:26:19 - INFO - __main__ - ['salvage plastic bottles instead of throwing them away']
04/25/2022 19:26:19 - INFO - __main__ - Tokenizing Input ...
04/25/2022 19:26:19 - INFO - __main__ - Tokenizing Output ...
04/25/2022 19:26:19 - INFO - __main__ - Loaded 500 examples from test data
04/25/2022 19:26:19 - INFO - __main__ - Loaded 32 examples from train data
04/25/2022 19:26:19 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 19:26:19 - INFO - __main__ - Printing 3 examples
04/25/2022 19:26:19 - INFO - __main__ -  [openbookqa] Due to weathering (A) large submarines are built (B) new bikes are raced (C) holes in the pathway (D) 2nd story houses are built
04/25/2022 19:26:19 - INFO - __main__ - ['holes in the pathway']
04/25/2022 19:26:19 - INFO - __main__ -  [openbookqa] Which area would be brightest, if you woke up there? (A) rainy environments (B) underwater environments (C) forest areas (D) frozen areas
04/25/2022 19:26:19 - INFO - __main__ - ['frozen areas']
04/25/2022 19:26:19 - INFO - __main__ -  [openbookqa] Which area contains few organisms? (A) Madagascar (B) South Pole (C) Amazon Rain Forest (D) Sahara Desert
04/25/2022 19:26:19 - INFO - __main__ - ['South Pole']
04/25/2022 19:26:19 - INFO - __main__ - Tokenizing Input ...
04/25/2022 19:26:19 - INFO - __main__ - Tokenizing Output ...
04/25/2022 19:26:19 - INFO - __main__ - Loaded 32 examples from dev data
04/25/2022 19:26:38 - INFO - __main__ - load prompt embedding from ckpt
04/25/2022 19:26:38 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/25/2022 19:26:39 - INFO - __main__ - Starting training!
04/25/2022 19:26:51 - INFO - __main__ - Saved prediction in models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-openbookqa/openbookqa_32_87_0.4_8_predictions.txt
04/25/2022 19:26:51 - INFO - __main__ - ACC on test data: 0.3040
04/25/2022 19:26:52 - INFO - __main__ - prefix=openbookqa_32_87, lr=0.4, bsz=8, dev_performance=0.375, test_performance=0.304
04/25/2022 19:26:52 - INFO - __main__ - Running ... prefix=openbookqa_32_87, lr=0.3, bsz=8 ...
04/25/2022 19:26:53 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 19:26:53 - INFO - __main__ - Printing 3 examples
04/25/2022 19:26:53 - INFO - __main__ -  [openbookqa] As vehicles become more efficient petro consumption (A) increases (B) stops (C) decreases (D) stay the same
04/25/2022 19:26:53 - INFO - __main__ - ['decreases']
04/25/2022 19:26:53 - INFO - __main__ -  [openbookqa] which of these could be measured in mL? (A) circumference of a head (B) the contents of a wine jar (C) the length of a pen (D) the width of a window
04/25/2022 19:26:53 - INFO - __main__ - ['the contents of a wine jar']
04/25/2022 19:26:53 - INFO - __main__ -  [openbookqa] To have a positive impact of the environment (A) use Styrofoam plates and bowls (B) use more paper towels (C) drive a car that guzzles gas (D) salvage plastic bottles instead of throwing them away
04/25/2022 19:26:53 - INFO - __main__ - ['salvage plastic bottles instead of throwing them away']
04/25/2022 19:26:53 - INFO - __main__ - Tokenizing Input ...
04/25/2022 19:26:53 - INFO - __main__ - Tokenizing Output ...
04/25/2022 19:26:53 - INFO - __main__ - Loaded 32 examples from train data
04/25/2022 19:26:53 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 19:26:53 - INFO - __main__ - Printing 3 examples
04/25/2022 19:26:53 - INFO - __main__ -  [openbookqa] Due to weathering (A) large submarines are built (B) new bikes are raced (C) holes in the pathway (D) 2nd story houses are built
04/25/2022 19:26:53 - INFO - __main__ - ['holes in the pathway']
04/25/2022 19:26:53 - INFO - __main__ -  [openbookqa] Which area would be brightest, if you woke up there? (A) rainy environments (B) underwater environments (C) forest areas (D) frozen areas
04/25/2022 19:26:53 - INFO - __main__ - ['frozen areas']
04/25/2022 19:26:53 - INFO - __main__ -  [openbookqa] Which area contains few organisms? (A) Madagascar (B) South Pole (C) Amazon Rain Forest (D) Sahara Desert
04/25/2022 19:26:53 - INFO - __main__ - ['South Pole']
04/25/2022 19:26:53 - INFO - __main__ - Tokenizing Input ...
04/25/2022 19:26:53 - INFO - __main__ - Tokenizing Output ...
04/25/2022 19:26:53 - INFO - __main__ - Loaded 32 examples from dev data
04/25/2022 19:27:10 - INFO - __main__ - load prompt embedding from ckpt
04/25/2022 19:27:10 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/25/2022 19:27:10 - INFO - __main__ - Starting training!
04/25/2022 19:27:14 - INFO - __main__ - Step 10 Global step 10 Train loss 1.98 on epoch=4
04/25/2022 19:27:16 - INFO - __main__ - Step 20 Global step 20 Train loss 1.42 on epoch=9
04/25/2022 19:27:19 - INFO - __main__ - Step 30 Global step 30 Train loss 0.90 on epoch=14
04/25/2022 19:27:21 - INFO - __main__ - Step 40 Global step 40 Train loss 0.73 on epoch=19
04/25/2022 19:27:24 - INFO - __main__ - Step 50 Global step 50 Train loss 0.53 on epoch=24
04/25/2022 19:27:25 - INFO - __main__ - Global step 50 Train loss 1.11 ACC 0.3125 on epoch=24
04/25/2022 19:27:25 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.3125 on epoch=24, global_step=50
04/25/2022 19:27:28 - INFO - __main__ - Step 60 Global step 60 Train loss 0.50 on epoch=29
04/25/2022 19:27:30 - INFO - __main__ - Step 70 Global step 70 Train loss 0.49 on epoch=34
04/25/2022 19:27:33 - INFO - __main__ - Step 80 Global step 80 Train loss 0.39 on epoch=39
04/25/2022 19:27:35 - INFO - __main__ - Step 90 Global step 90 Train loss 0.38 on epoch=44
04/25/2022 19:27:38 - INFO - __main__ - Step 100 Global step 100 Train loss 0.33 on epoch=49
04/25/2022 19:27:39 - INFO - __main__ - Global step 100 Train loss 0.42 ACC 0.375 on epoch=49
04/25/2022 19:27:39 - INFO - __main__ - Saving model with best ACC: 0.3125 -> 0.375 on epoch=49, global_step=100
04/25/2022 19:27:41 - INFO - __main__ - Step 110 Global step 110 Train loss 0.29 on epoch=54
04/25/2022 19:27:44 - INFO - __main__ - Step 120 Global step 120 Train loss 0.26 on epoch=59
04/25/2022 19:27:46 - INFO - __main__ - Step 130 Global step 130 Train loss 0.24 on epoch=64
04/25/2022 19:27:49 - INFO - __main__ - Step 140 Global step 140 Train loss 0.24 on epoch=69
04/25/2022 19:27:51 - INFO - __main__ - Step 150 Global step 150 Train loss 0.22 on epoch=74
04/25/2022 19:27:53 - INFO - __main__ - Global step 150 Train loss 0.25 ACC 0.375 on epoch=74
04/25/2022 19:27:56 - INFO - __main__ - Step 160 Global step 160 Train loss 0.21 on epoch=79
04/25/2022 19:27:58 - INFO - __main__ - Step 170 Global step 170 Train loss 0.17 on epoch=84
04/25/2022 19:28:01 - INFO - __main__ - Step 180 Global step 180 Train loss 0.12 on epoch=89
04/25/2022 19:28:03 - INFO - __main__ - Step 190 Global step 190 Train loss 0.18 on epoch=94
04/25/2022 19:28:06 - INFO - __main__ - Step 200 Global step 200 Train loss 0.10 on epoch=99
04/25/2022 19:28:07 - INFO - __main__ - Global step 200 Train loss 0.16 ACC 0.375 on epoch=99
04/25/2022 19:28:10 - INFO - __main__ - Step 210 Global step 210 Train loss 0.12 on epoch=104
04/25/2022 19:28:12 - INFO - __main__ - Step 220 Global step 220 Train loss 0.14 on epoch=109
04/25/2022 19:28:15 - INFO - __main__ - Step 230 Global step 230 Train loss 0.09 on epoch=114
04/25/2022 19:28:17 - INFO - __main__ - Step 240 Global step 240 Train loss 0.11 on epoch=119
04/25/2022 19:28:20 - INFO - __main__ - Step 250 Global step 250 Train loss 0.11 on epoch=124
04/25/2022 19:28:21 - INFO - __main__ - Global step 250 Train loss 0.11 ACC 0.3125 on epoch=124
04/25/2022 19:28:24 - INFO - __main__ - Step 260 Global step 260 Train loss 0.07 on epoch=129
04/25/2022 19:28:26 - INFO - __main__ - Step 270 Global step 270 Train loss 0.13 on epoch=134
04/25/2022 19:28:29 - INFO - __main__ - Step 280 Global step 280 Train loss 0.08 on epoch=139
04/25/2022 19:28:31 - INFO - __main__ - Step 290 Global step 290 Train loss 0.10 on epoch=144
04/25/2022 19:28:33 - INFO - __main__ - Step 300 Global step 300 Train loss 0.04 on epoch=149
04/25/2022 19:28:35 - INFO - __main__ - Global step 300 Train loss 0.08 ACC 0.28125 on epoch=149
04/25/2022 19:28:37 - INFO - __main__ - Step 310 Global step 310 Train loss 0.10 on epoch=154
04/25/2022 19:28:40 - INFO - __main__ - Step 320 Global step 320 Train loss 0.08 on epoch=159
04/25/2022 19:28:42 - INFO - __main__ - Step 330 Global step 330 Train loss 0.05 on epoch=164
04/25/2022 19:28:45 - INFO - __main__ - Step 340 Global step 340 Train loss 0.04 on epoch=169
04/25/2022 19:28:47 - INFO - __main__ - Step 350 Global step 350 Train loss 0.05 on epoch=174
04/25/2022 19:28:49 - INFO - __main__ - Global step 350 Train loss 0.06 ACC 0.375 on epoch=174
04/25/2022 19:28:52 - INFO - __main__ - Step 360 Global step 360 Train loss 0.08 on epoch=179
04/25/2022 19:28:54 - INFO - __main__ - Step 370 Global step 370 Train loss 0.03 on epoch=184
04/25/2022 19:28:57 - INFO - __main__ - Step 380 Global step 380 Train loss 0.06 on epoch=189
04/25/2022 19:28:59 - INFO - __main__ - Step 390 Global step 390 Train loss 0.05 on epoch=194
04/25/2022 19:29:02 - INFO - __main__ - Step 400 Global step 400 Train loss 0.09 on epoch=199
04/25/2022 19:29:03 - INFO - __main__ - Global step 400 Train loss 0.06 ACC 0.3125 on epoch=199
04/25/2022 19:29:06 - INFO - __main__ - Step 410 Global step 410 Train loss 0.03 on epoch=204
04/25/2022 19:29:08 - INFO - __main__ - Step 420 Global step 420 Train loss 0.08 on epoch=209
04/25/2022 19:29:11 - INFO - __main__ - Step 430 Global step 430 Train loss 0.04 on epoch=214
04/25/2022 19:29:13 - INFO - __main__ - Step 440 Global step 440 Train loss 0.02 on epoch=219
04/25/2022 19:29:16 - INFO - __main__ - Step 450 Global step 450 Train loss 0.03 on epoch=224
04/25/2022 19:29:17 - INFO - __main__ - Global step 450 Train loss 0.04 ACC 0.40625 on epoch=224
04/25/2022 19:29:17 - INFO - __main__ - Saving model with best ACC: 0.375 -> 0.40625 on epoch=224, global_step=450
04/25/2022 19:29:20 - INFO - __main__ - Step 460 Global step 460 Train loss 0.04 on epoch=229
04/25/2022 19:29:22 - INFO - __main__ - Step 470 Global step 470 Train loss 0.01 on epoch=234
04/25/2022 19:29:25 - INFO - __main__ - Step 480 Global step 480 Train loss 0.04 on epoch=239
04/25/2022 19:29:27 - INFO - __main__ - Step 490 Global step 490 Train loss 0.03 on epoch=244
04/25/2022 19:29:30 - INFO - __main__ - Step 500 Global step 500 Train loss 0.03 on epoch=249
04/25/2022 19:29:32 - INFO - __main__ - Global step 500 Train loss 0.03 ACC 0.34375 on epoch=249
04/25/2022 19:29:34 - INFO - __main__ - Step 510 Global step 510 Train loss 0.02 on epoch=254
04/25/2022 19:29:37 - INFO - __main__ - Step 520 Global step 520 Train loss 0.02 on epoch=259
04/25/2022 19:29:39 - INFO - __main__ - Step 530 Global step 530 Train loss 0.05 on epoch=264
04/25/2022 19:29:41 - INFO - __main__ - Step 540 Global step 540 Train loss 0.02 on epoch=269
04/25/2022 19:29:44 - INFO - __main__ - Step 550 Global step 550 Train loss 0.02 on epoch=274
04/25/2022 19:29:45 - INFO - __main__ - Global step 550 Train loss 0.03 ACC 0.3125 on epoch=274
04/25/2022 19:29:48 - INFO - __main__ - Step 560 Global step 560 Train loss 0.02 on epoch=279
04/25/2022 19:29:50 - INFO - __main__ - Step 570 Global step 570 Train loss 0.01 on epoch=284
04/25/2022 19:29:53 - INFO - __main__ - Step 580 Global step 580 Train loss 0.03 on epoch=289
04/25/2022 19:29:55 - INFO - __main__ - Step 590 Global step 590 Train loss 0.04 on epoch=294
04/25/2022 19:29:58 - INFO - __main__ - Step 600 Global step 600 Train loss 0.04 on epoch=299
04/25/2022 19:29:59 - INFO - __main__ - Global step 600 Train loss 0.03 ACC 0.28125 on epoch=299
04/25/2022 19:30:02 - INFO - __main__ - Step 610 Global step 610 Train loss 0.02 on epoch=304
04/25/2022 19:30:04 - INFO - __main__ - Step 620 Global step 620 Train loss 0.02 on epoch=309
04/25/2022 19:30:07 - INFO - __main__ - Step 630 Global step 630 Train loss 0.03 on epoch=314
04/25/2022 19:30:09 - INFO - __main__ - Step 640 Global step 640 Train loss 0.02 on epoch=319
04/25/2022 19:30:12 - INFO - __main__ - Step 650 Global step 650 Train loss 0.04 on epoch=324
04/25/2022 19:30:14 - INFO - __main__ - Global step 650 Train loss 0.02 ACC 0.34375 on epoch=324
04/25/2022 19:30:16 - INFO - __main__ - Step 660 Global step 660 Train loss 0.03 on epoch=329
04/25/2022 19:30:19 - INFO - __main__ - Step 670 Global step 670 Train loss 0.04 on epoch=334
04/25/2022 19:30:21 - INFO - __main__ - Step 680 Global step 680 Train loss 0.02 on epoch=339
04/25/2022 19:30:24 - INFO - __main__ - Step 690 Global step 690 Train loss 0.03 on epoch=344
04/25/2022 19:30:26 - INFO - __main__ - Step 700 Global step 700 Train loss 0.05 on epoch=349
04/25/2022 19:30:28 - INFO - __main__ - Global step 700 Train loss 0.03 ACC 0.34375 on epoch=349
04/25/2022 19:30:30 - INFO - __main__ - Step 710 Global step 710 Train loss 0.01 on epoch=354
04/25/2022 19:30:33 - INFO - __main__ - Step 720 Global step 720 Train loss 0.01 on epoch=359
04/25/2022 19:30:35 - INFO - __main__ - Step 730 Global step 730 Train loss 0.04 on epoch=364
04/25/2022 19:30:38 - INFO - __main__ - Step 740 Global step 740 Train loss 0.01 on epoch=369
04/25/2022 19:30:40 - INFO - __main__ - Step 750 Global step 750 Train loss 0.02 on epoch=374
04/25/2022 19:30:42 - INFO - __main__ - Global step 750 Train loss 0.02 ACC 0.40625 on epoch=374
04/25/2022 19:30:44 - INFO - __main__ - Step 760 Global step 760 Train loss 0.02 on epoch=379
04/25/2022 19:30:47 - INFO - __main__ - Step 770 Global step 770 Train loss 0.03 on epoch=384
04/25/2022 19:30:49 - INFO - __main__ - Step 780 Global step 780 Train loss 0.01 on epoch=389
04/25/2022 19:30:52 - INFO - __main__ - Step 790 Global step 790 Train loss 0.02 on epoch=394
04/25/2022 19:30:54 - INFO - __main__ - Step 800 Global step 800 Train loss 0.01 on epoch=399
04/25/2022 19:30:56 - INFO - __main__ - Global step 800 Train loss 0.02 ACC 0.3125 on epoch=399
04/25/2022 19:30:58 - INFO - __main__ - Step 810 Global step 810 Train loss 0.01 on epoch=404
04/25/2022 19:31:01 - INFO - __main__ - Step 820 Global step 820 Train loss 0.01 on epoch=409
04/25/2022 19:31:03 - INFO - __main__ - Step 830 Global step 830 Train loss 0.02 on epoch=414
04/25/2022 19:31:06 - INFO - __main__ - Step 840 Global step 840 Train loss 0.01 on epoch=419
04/25/2022 19:31:08 - INFO - __main__ - Step 850 Global step 850 Train loss 0.02 on epoch=424
04/25/2022 19:31:10 - INFO - __main__ - Global step 850 Train loss 0.01 ACC 0.34375 on epoch=424
04/25/2022 19:31:13 - INFO - __main__ - Step 860 Global step 860 Train loss 0.03 on epoch=429
04/25/2022 19:31:15 - INFO - __main__ - Step 870 Global step 870 Train loss 0.02 on epoch=434
04/25/2022 19:31:18 - INFO - __main__ - Step 880 Global step 880 Train loss 0.01 on epoch=439
04/25/2022 19:31:20 - INFO - __main__ - Step 890 Global step 890 Train loss 0.01 on epoch=444
04/25/2022 19:31:23 - INFO - __main__ - Step 900 Global step 900 Train loss 0.03 on epoch=449
04/25/2022 19:31:24 - INFO - __main__ - Global step 900 Train loss 0.02 ACC 0.375 on epoch=449
04/25/2022 19:31:27 - INFO - __main__ - Step 910 Global step 910 Train loss 0.01 on epoch=454
04/25/2022 19:31:29 - INFO - __main__ - Step 920 Global step 920 Train loss 0.02 on epoch=459
04/25/2022 19:31:32 - INFO - __main__ - Step 930 Global step 930 Train loss 0.01 on epoch=464
04/25/2022 19:31:34 - INFO - __main__ - Step 940 Global step 940 Train loss 0.01 on epoch=469
04/25/2022 19:31:37 - INFO - __main__ - Step 950 Global step 950 Train loss 0.00 on epoch=474
04/25/2022 19:31:38 - INFO - __main__ - Global step 950 Train loss 0.01 ACC 0.34375 on epoch=474
04/25/2022 19:31:41 - INFO - __main__ - Step 960 Global step 960 Train loss 0.05 on epoch=479
04/25/2022 19:31:43 - INFO - __main__ - Step 970 Global step 970 Train loss 0.02 on epoch=484
04/25/2022 19:31:46 - INFO - __main__ - Step 980 Global step 980 Train loss 0.01 on epoch=489
04/25/2022 19:31:48 - INFO - __main__ - Step 990 Global step 990 Train loss 0.01 on epoch=494
04/25/2022 19:31:51 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.02 on epoch=499
04/25/2022 19:31:53 - INFO - __main__ - Global step 1000 Train loss 0.02 ACC 0.46875 on epoch=499
04/25/2022 19:31:53 - INFO - __main__ - Saving model with best ACC: 0.40625 -> 0.46875 on epoch=499, global_step=1000
04/25/2022 19:31:55 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.01 on epoch=504
04/25/2022 19:31:57 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.02 on epoch=509
04/25/2022 19:32:00 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.01 on epoch=514
04/25/2022 19:32:02 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.02 on epoch=519
04/25/2022 19:32:05 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.01 on epoch=524
04/25/2022 19:32:07 - INFO - __main__ - Global step 1050 Train loss 0.01 ACC 0.34375 on epoch=524
04/25/2022 19:32:09 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.01 on epoch=529
04/25/2022 19:32:12 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.01 on epoch=534
04/25/2022 19:32:14 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.02 on epoch=539
04/25/2022 19:32:17 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.01 on epoch=544
04/25/2022 19:32:19 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.01 on epoch=549
04/25/2022 19:32:21 - INFO - __main__ - Global step 1100 Train loss 0.01 ACC 0.3125 on epoch=549
04/25/2022 19:32:23 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.01 on epoch=554
04/25/2022 19:32:26 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=559
04/25/2022 19:32:28 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=564
04/25/2022 19:32:31 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.00 on epoch=569
04/25/2022 19:32:33 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=574
04/25/2022 19:32:35 - INFO - __main__ - Global step 1150 Train loss 0.01 ACC 0.3125 on epoch=574
04/25/2022 19:32:38 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.00 on epoch=579
04/25/2022 19:32:40 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.00 on epoch=584
04/25/2022 19:32:43 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.01 on epoch=589
04/25/2022 19:32:45 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.01 on epoch=594
04/25/2022 19:32:47 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.02 on epoch=599
04/25/2022 19:32:49 - INFO - __main__ - Global step 1200 Train loss 0.01 ACC 0.375 on epoch=599
04/25/2022 19:32:52 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.01 on epoch=604
04/25/2022 19:32:54 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=609
04/25/2022 19:32:57 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=614
04/25/2022 19:32:59 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=619
04/25/2022 19:33:02 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.02 on epoch=624
04/25/2022 19:33:03 - INFO - __main__ - Global step 1250 Train loss 0.01 ACC 0.4375 on epoch=624
04/25/2022 19:33:06 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.00 on epoch=629
04/25/2022 19:33:09 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.00 on epoch=634
04/25/2022 19:33:11 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.04 on epoch=639
04/25/2022 19:33:14 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.00 on epoch=644
04/25/2022 19:33:16 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.00 on epoch=649
04/25/2022 19:33:18 - INFO - __main__ - Global step 1300 Train loss 0.01 ACC 0.40625 on epoch=649
04/25/2022 19:33:20 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=654
04/25/2022 19:33:23 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.05 on epoch=659
04/25/2022 19:33:25 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=664
04/25/2022 19:33:28 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.00 on epoch=669
04/25/2022 19:33:31 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=674
04/25/2022 19:33:32 - INFO - __main__ - Global step 1350 Train loss 0.01 ACC 0.3125 on epoch=674
04/25/2022 19:33:35 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.03 on epoch=679
04/25/2022 19:33:37 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=684
04/25/2022 19:33:40 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=689
04/25/2022 19:33:42 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=694
04/25/2022 19:33:45 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=699
04/25/2022 19:33:47 - INFO - __main__ - Global step 1400 Train loss 0.01 ACC 0.34375 on epoch=699
04/25/2022 19:33:49 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=704
04/25/2022 19:33:52 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=709
04/25/2022 19:33:54 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=714
04/25/2022 19:33:56 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=719
04/25/2022 19:33:59 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.04 on epoch=724
04/25/2022 19:34:01 - INFO - __main__ - Global step 1450 Train loss 0.01 ACC 0.34375 on epoch=724
04/25/2022 19:34:03 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=729
04/25/2022 19:34:06 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.02 on epoch=734
04/25/2022 19:34:08 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=739
04/25/2022 19:34:11 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=744
04/25/2022 19:34:13 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=749
04/25/2022 19:34:15 - INFO - __main__ - Global step 1500 Train loss 0.01 ACC 0.34375 on epoch=749
04/25/2022 19:34:17 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=754
04/25/2022 19:34:20 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=759
04/25/2022 19:34:22 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=764
04/25/2022 19:34:25 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=769
04/25/2022 19:34:27 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=774
04/25/2022 19:34:29 - INFO - __main__ - Global step 1550 Train loss 0.01 ACC 0.375 on epoch=774
04/25/2022 19:34:32 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=779
04/25/2022 19:34:34 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=784
04/25/2022 19:34:37 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=789
04/25/2022 19:34:39 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.05 on epoch=794
04/25/2022 19:34:42 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=799
04/25/2022 19:34:43 - INFO - __main__ - Global step 1600 Train loss 0.01 ACC 0.3125 on epoch=799
04/25/2022 19:34:46 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=804
04/25/2022 19:34:48 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=809
04/25/2022 19:34:51 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=814
04/25/2022 19:34:54 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=819
04/25/2022 19:34:56 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=824
04/25/2022 19:34:58 - INFO - __main__ - Global step 1650 Train loss 0.00 ACC 0.3125 on epoch=824
04/25/2022 19:35:00 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.03 on epoch=829
04/25/2022 19:35:03 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=834
04/25/2022 19:35:05 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=839
04/25/2022 19:35:08 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=844
04/25/2022 19:35:10 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=849
04/25/2022 19:35:12 - INFO - __main__ - Global step 1700 Train loss 0.02 ACC 0.28125 on epoch=849
04/25/2022 19:35:14 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=854
04/25/2022 19:35:17 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=859
04/25/2022 19:35:20 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=864
04/25/2022 19:35:22 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=869
04/25/2022 19:35:24 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=874
04/25/2022 19:35:26 - INFO - __main__ - Global step 1750 Train loss 0.01 ACC 0.34375 on epoch=874
04/25/2022 19:35:29 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=879
04/25/2022 19:35:31 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=884
04/25/2022 19:35:34 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=889
04/25/2022 19:35:37 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=894
04/25/2022 19:35:39 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=899
04/25/2022 19:35:41 - INFO - __main__ - Global step 1800 Train loss 0.01 ACC 0.25 on epoch=899
04/25/2022 19:35:43 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=904
04/25/2022 19:35:46 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=909
04/25/2022 19:35:48 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=914
04/25/2022 19:35:51 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=919
04/25/2022 19:35:53 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=924
04/25/2022 19:35:55 - INFO - __main__ - Global step 1850 Train loss 0.01 ACC 0.28125 on epoch=924
04/25/2022 19:35:58 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=929
04/25/2022 19:36:00 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=934
04/25/2022 19:36:03 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=939
04/25/2022 19:36:05 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=944
04/25/2022 19:36:08 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=949
04/25/2022 19:36:10 - INFO - __main__ - Global step 1900 Train loss 0.00 ACC 0.40625 on epoch=949
04/25/2022 19:36:12 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=954
04/25/2022 19:36:15 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=959
04/25/2022 19:36:17 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=964
04/25/2022 19:36:20 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=969
04/25/2022 19:36:22 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=974
04/25/2022 19:36:24 - INFO - __main__ - Global step 1950 Train loss 0.01 ACC 0.34375 on epoch=974
04/25/2022 19:36:26 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=979
04/25/2022 19:36:29 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=984
04/25/2022 19:36:31 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=989
04/25/2022 19:36:34 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=994
04/25/2022 19:36:36 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=999
04/25/2022 19:36:38 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 19:36:38 - INFO - __main__ - Printing 3 examples
04/25/2022 19:36:38 - INFO - __main__ -  [openbookqa] As vehicles become more efficient petro consumption (A) increases (B) stops (C) decreases (D) stay the same
04/25/2022 19:36:38 - INFO - __main__ - ['decreases']
04/25/2022 19:36:38 - INFO - __main__ -  [openbookqa] which of these could be measured in mL? (A) circumference of a head (B) the contents of a wine jar (C) the length of a pen (D) the width of a window
04/25/2022 19:36:38 - INFO - __main__ - ['the contents of a wine jar']
04/25/2022 19:36:38 - INFO - __main__ -  [openbookqa] To have a positive impact of the environment (A) use Styrofoam plates and bowls (B) use more paper towels (C) drive a car that guzzles gas (D) salvage plastic bottles instead of throwing them away
04/25/2022 19:36:38 - INFO - __main__ - ['salvage plastic bottles instead of throwing them away']
04/25/2022 19:36:38 - INFO - __main__ - Tokenizing Input ...
04/25/2022 19:36:38 - INFO - __main__ - Tokenizing Output ...
04/25/2022 19:36:38 - INFO - __main__ - Loaded 32 examples from train data
04/25/2022 19:36:38 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 19:36:38 - INFO - __main__ - Printing 3 examples
04/25/2022 19:36:38 - INFO - __main__ -  [openbookqa] Due to weathering (A) large submarines are built (B) new bikes are raced (C) holes in the pathway (D) 2nd story houses are built
04/25/2022 19:36:38 - INFO - __main__ - ['holes in the pathway']
04/25/2022 19:36:38 - INFO - __main__ -  [openbookqa] Which area would be brightest, if you woke up there? (A) rainy environments (B) underwater environments (C) forest areas (D) frozen areas
04/25/2022 19:36:38 - INFO - __main__ - ['frozen areas']
04/25/2022 19:36:38 - INFO - __main__ -  [openbookqa] Which area contains few organisms? (A) Madagascar (B) South Pole (C) Amazon Rain Forest (D) Sahara Desert
04/25/2022 19:36:38 - INFO - __main__ - ['South Pole']
04/25/2022 19:36:38 - INFO - __main__ - Tokenizing Input ...
04/25/2022 19:36:38 - INFO - __main__ - Tokenizing Output ...
04/25/2022 19:36:38 - INFO - __main__ - Loaded 32 examples from dev data
04/25/2022 19:36:38 - INFO - __main__ - Global step 2000 Train loss 0.00 ACC 0.34375 on epoch=999
04/25/2022 19:36:38 - INFO - __main__ - save last model!
04/25/2022 19:36:38 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
04/25/2022 19:36:38 - INFO - __main__ - Start tokenizing ... 500 instances
04/25/2022 19:36:38 - INFO - __main__ - Printing 3 examples
04/25/2022 19:36:38 - INFO - __main__ -  [openbookqa] Frilled sharks and angler fish live far beneath the surface of the ocean, which is why they are known as (A) Deep sea animals (B) fish (C) Long Sea Fish (D) Far Sea Animals
04/25/2022 19:36:38 - INFO - __main__ - ['Deep sea animals']
04/25/2022 19:36:38 - INFO - __main__ -  [openbookqa] Gas can fill any container it is given, and liquid (A) is standard weight and size (B) is the opposite of variable (C) only needs a few (D) uses what it needs
04/25/2022 19:36:38 - INFO - __main__ - ['uses what it needs']
04/25/2022 19:36:38 - INFO - __main__ -  [openbookqa] When birds migrate south for the winter, they do it because (A) they are genetically called to (B) their children ask for them to (C) it is important to their happiness (D) they decide to each year
04/25/2022 19:36:38 - INFO - __main__ - ['they are genetically called to']
04/25/2022 19:36:38 - INFO - __main__ - Tokenizing Input ...
04/25/2022 19:36:38 - INFO - __main__ - Tokenizing Output ...
04/25/2022 19:36:39 - INFO - __main__ - Loaded 500 examples from test data
04/25/2022 19:36:54 - INFO - __main__ - load prompt embedding from ckpt
04/25/2022 19:36:54 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/25/2022 19:36:54 - INFO - __main__ - Starting training!
04/25/2022 19:37:12 - INFO - __main__ - Saved prediction in models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-openbookqa/openbookqa_32_87_0.3_8_predictions.txt
04/25/2022 19:37:12 - INFO - __main__ - ACC on test data: 0.2780
04/25/2022 19:37:13 - INFO - __main__ - prefix=openbookqa_32_87, lr=0.3, bsz=8, dev_performance=0.46875, test_performance=0.278
04/25/2022 19:37:13 - INFO - __main__ - Running ... prefix=openbookqa_32_87, lr=0.2, bsz=8 ...
04/25/2022 19:37:14 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 19:37:14 - INFO - __main__ - Printing 3 examples
04/25/2022 19:37:14 - INFO - __main__ -  [openbookqa] As vehicles become more efficient petro consumption (A) increases (B) stops (C) decreases (D) stay the same
04/25/2022 19:37:14 - INFO - __main__ - ['decreases']
04/25/2022 19:37:14 - INFO - __main__ -  [openbookqa] which of these could be measured in mL? (A) circumference of a head (B) the contents of a wine jar (C) the length of a pen (D) the width of a window
04/25/2022 19:37:14 - INFO - __main__ - ['the contents of a wine jar']
04/25/2022 19:37:14 - INFO - __main__ -  [openbookqa] To have a positive impact of the environment (A) use Styrofoam plates and bowls (B) use more paper towels (C) drive a car that guzzles gas (D) salvage plastic bottles instead of throwing them away
04/25/2022 19:37:14 - INFO - __main__ - ['salvage plastic bottles instead of throwing them away']
04/25/2022 19:37:14 - INFO - __main__ - Tokenizing Input ...
04/25/2022 19:37:14 - INFO - __main__ - Tokenizing Output ...
04/25/2022 19:37:14 - INFO - __main__ - Loaded 32 examples from train data
04/25/2022 19:37:14 - INFO - __main__ - Start tokenizing ... 32 instances
04/25/2022 19:37:14 - INFO - __main__ - Printing 3 examples
04/25/2022 19:37:14 - INFO - __main__ -  [openbookqa] Due to weathering (A) large submarines are built (B) new bikes are raced (C) holes in the pathway (D) 2nd story houses are built
04/25/2022 19:37:14 - INFO - __main__ - ['holes in the pathway']
04/25/2022 19:37:14 - INFO - __main__ -  [openbookqa] Which area would be brightest, if you woke up there? (A) rainy environments (B) underwater environments (C) forest areas (D) frozen areas
04/25/2022 19:37:14 - INFO - __main__ - ['frozen areas']
04/25/2022 19:37:14 - INFO - __main__ -  [openbookqa] Which area contains few organisms? (A) Madagascar (B) South Pole (C) Amazon Rain Forest (D) Sahara Desert
04/25/2022 19:37:14 - INFO - __main__ - ['South Pole']
04/25/2022 19:37:14 - INFO - __main__ - Tokenizing Input ...
04/25/2022 19:37:14 - INFO - __main__ - Tokenizing Output ...
04/25/2022 19:37:14 - INFO - __main__ - Loaded 32 examples from dev data
04/25/2022 19:37:29 - INFO - __main__ - load prompt embedding from ckpt
04/25/2022 19:37:30 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/25/2022 19:37:30 - INFO - __main__ - Starting training!
04/25/2022 19:37:33 - INFO - __main__ - Step 10 Global step 10 Train loss 2.15 on epoch=4
04/25/2022 19:37:35 - INFO - __main__ - Step 20 Global step 20 Train loss 1.64 on epoch=9
04/25/2022 19:37:38 - INFO - __main__ - Step 30 Global step 30 Train loss 1.25 on epoch=14
04/25/2022 19:37:40 - INFO - __main__ - Step 40 Global step 40 Train loss 0.96 on epoch=19
04/25/2022 19:37:43 - INFO - __main__ - Step 50 Global step 50 Train loss 0.74 on epoch=24
04/25/2022 19:37:44 - INFO - __main__ - Global step 50 Train loss 1.35 ACC 0.28125 on epoch=24
04/25/2022 19:37:44 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.28125 on epoch=24, global_step=50
04/25/2022 19:37:47 - INFO - __main__ - Step 60 Global step 60 Train loss 0.71 on epoch=29
04/25/2022 19:37:49 - INFO - __main__ - Step 70 Global step 70 Train loss 0.58 on epoch=34
04/25/2022 19:37:51 - INFO - __main__ - Step 80 Global step 80 Train loss 0.51 on epoch=39
04/25/2022 19:37:54 - INFO - __main__ - Step 90 Global step 90 Train loss 0.55 on epoch=44
04/25/2022 19:37:56 - INFO - __main__ - Step 100 Global step 100 Train loss 0.44 on epoch=49
04/25/2022 19:37:58 - INFO - __main__ - Global step 100 Train loss 0.56 ACC 0.34375 on epoch=49
04/25/2022 19:37:58 - INFO - __main__ - Saving model with best ACC: 0.28125 -> 0.34375 on epoch=49, global_step=100
04/25/2022 19:38:00 - INFO - __main__ - Step 110 Global step 110 Train loss 0.41 on epoch=54
04/25/2022 19:38:02 - INFO - __main__ - Step 120 Global step 120 Train loss 0.40 on epoch=59
04/25/2022 19:38:05 - INFO - __main__ - Step 130 Global step 130 Train loss 0.31 on epoch=64
04/25/2022 19:38:07 - INFO - __main__ - Step 140 Global step 140 Train loss 0.38 on epoch=69
04/25/2022 19:38:10 - INFO - __main__ - Step 150 Global step 150 Train loss 0.33 on epoch=74
04/25/2022 19:38:11 - INFO - __main__ - Global step 150 Train loss 0.37 ACC 0.375 on epoch=74
04/25/2022 19:38:11 - INFO - __main__ - Saving model with best ACC: 0.34375 -> 0.375 on epoch=74, global_step=150
04/25/2022 19:38:14 - INFO - __main__ - Step 160 Global step 160 Train loss 0.23 on epoch=79
04/25/2022 19:38:16 - INFO - __main__ - Step 170 Global step 170 Train loss 0.27 on epoch=84
04/25/2022 19:38:18 - INFO - __main__ - Step 180 Global step 180 Train loss 0.24 on epoch=89
04/25/2022 19:38:21 - INFO - __main__ - Step 190 Global step 190 Train loss 0.21 on epoch=94
04/25/2022 19:38:23 - INFO - __main__ - Step 200 Global step 200 Train loss 0.21 on epoch=99
04/25/2022 19:38:25 - INFO - __main__ - Global step 200 Train loss 0.23 ACC 0.40625 on epoch=99
04/25/2022 19:38:25 - INFO - __main__ - Saving model with best ACC: 0.375 -> 0.40625 on epoch=99, global_step=200
04/25/2022 19:38:27 - INFO - __main__ - Step 210 Global step 210 Train loss 0.20 on epoch=104
04/25/2022 19:38:30 - INFO - __main__ - Step 220 Global step 220 Train loss 0.25 on epoch=109
04/25/2022 19:38:32 - INFO - __main__ - Step 230 Global step 230 Train loss 0.17 on epoch=114
04/25/2022 19:38:35 - INFO - __main__ - Step 240 Global step 240 Train loss 0.23 on epoch=119
04/25/2022 19:38:37 - INFO - __main__ - Step 250 Global step 250 Train loss 0.20 on epoch=124
04/25/2022 19:38:39 - INFO - __main__ - Global step 250 Train loss 0.21 ACC 0.40625 on epoch=124
04/25/2022 19:38:41 - INFO - __main__ - Step 260 Global step 260 Train loss 0.12 on epoch=129
04/25/2022 19:38:43 - INFO - __main__ - Step 270 Global step 270 Train loss 0.13 on epoch=134
04/25/2022 19:38:46 - INFO - __main__ - Step 280 Global step 280 Train loss 0.15 on epoch=139
04/25/2022 19:38:48 - INFO - __main__ - Step 290 Global step 290 Train loss 0.15 on epoch=144
04/25/2022 19:38:51 - INFO - __main__ - Step 300 Global step 300 Train loss 0.15 on epoch=149
04/25/2022 19:38:52 - INFO - __main__ - Global step 300 Train loss 0.14 ACC 0.4375 on epoch=149
04/25/2022 19:38:53 - INFO - __main__ - Saving model with best ACC: 0.40625 -> 0.4375 on epoch=149, global_step=300
04/25/2022 19:38:55 - INFO - __main__ - Step 310 Global step 310 Train loss 0.13 on epoch=154
04/25/2022 19:38:57 - INFO - __main__ - Step 320 Global step 320 Train loss 0.16 on epoch=159
04/25/2022 19:39:00 - INFO - __main__ - Step 330 Global step 330 Train loss 0.11 on epoch=164
04/25/2022 19:39:02 - INFO - __main__ - Step 340 Global step 340 Train loss 0.10 on epoch=169
04/25/2022 19:39:05 - INFO - __main__ - Step 350 Global step 350 Train loss 0.14 on epoch=174
04/25/2022 19:39:06 - INFO - __main__ - Global step 350 Train loss 0.13 ACC 0.4375 on epoch=174
04/25/2022 19:39:09 - INFO - __main__ - Step 360 Global step 360 Train loss 0.08 on epoch=179
04/25/2022 19:39:11 - INFO - __main__ - Step 370 Global step 370 Train loss 0.10 on epoch=184
04/25/2022 19:39:13 - INFO - __main__ - Step 380 Global step 380 Train loss 0.08 on epoch=189
04/25/2022 19:39:16 - INFO - __main__ - Step 390 Global step 390 Train loss 0.09 on epoch=194
04/25/2022 19:39:18 - INFO - __main__ - Step 400 Global step 400 Train loss 0.08 on epoch=199
04/25/2022 19:39:20 - INFO - __main__ - Global step 400 Train loss 0.09 ACC 0.375 on epoch=199
04/25/2022 19:39:22 - INFO - __main__ - Step 410 Global step 410 Train loss 0.09 on epoch=204
04/25/2022 19:39:25 - INFO - __main__ - Step 420 Global step 420 Train loss 0.11 on epoch=209
04/25/2022 19:39:27 - INFO - __main__ - Step 430 Global step 430 Train loss 0.08 on epoch=214
04/25/2022 19:39:30 - INFO - __main__ - Step 440 Global step 440 Train loss 0.07 on epoch=219
04/25/2022 19:39:32 - INFO - __main__ - Step 450 Global step 450 Train loss 0.07 on epoch=224
04/25/2022 19:39:34 - INFO - __main__ - Global step 450 Train loss 0.08 ACC 0.34375 on epoch=224
04/25/2022 19:39:36 - INFO - __main__ - Step 460 Global step 460 Train loss 0.09 on epoch=229
04/25/2022 19:39:39 - INFO - __main__ - Step 470 Global step 470 Train loss 0.06 on epoch=234
04/25/2022 19:39:41 - INFO - __main__ - Step 480 Global step 480 Train loss 0.09 on epoch=239
04/25/2022 19:39:43 - INFO - __main__ - Step 490 Global step 490 Train loss 0.05 on epoch=244
04/25/2022 19:39:46 - INFO - __main__ - Step 500 Global step 500 Train loss 0.08 on epoch=249
04/25/2022 19:39:47 - INFO - __main__ - Global step 500 Train loss 0.07 ACC 0.34375 on epoch=249
04/25/2022 19:39:50 - INFO - __main__ - Step 510 Global step 510 Train loss 0.04 on epoch=254
04/25/2022 19:39:52 - INFO - __main__ - Step 520 Global step 520 Train loss 0.08 on epoch=259
04/25/2022 19:39:55 - INFO - __main__ - Step 530 Global step 530 Train loss 0.04 on epoch=264
04/25/2022 19:39:57 - INFO - __main__ - Step 540 Global step 540 Train loss 0.07 on epoch=269
04/25/2022 19:39:59 - INFO - __main__ - Step 550 Global step 550 Train loss 0.05 on epoch=274
04/25/2022 19:40:01 - INFO - __main__ - Global step 550 Train loss 0.06 ACC 0.40625 on epoch=274
04/25/2022 19:40:03 - INFO - __main__ - Step 560 Global step 560 Train loss 0.04 on epoch=279
04/25/2022 19:40:06 - INFO - __main__ - Step 570 Global step 570 Train loss 0.04 on epoch=284
04/25/2022 19:40:08 - INFO - __main__ - Step 580 Global step 580 Train loss 0.05 on epoch=289
04/25/2022 19:40:11 - INFO - __main__ - Step 590 Global step 590 Train loss 0.02 on epoch=294
04/25/2022 19:40:13 - INFO - __main__ - Step 600 Global step 600 Train loss 0.04 on epoch=299
04/25/2022 19:40:15 - INFO - __main__ - Global step 600 Train loss 0.04 ACC 0.46875 on epoch=299
04/25/2022 19:40:15 - INFO - __main__ - Saving model with best ACC: 0.4375 -> 0.46875 on epoch=299, global_step=600
04/25/2022 19:40:17 - INFO - __main__ - Step 610 Global step 610 Train loss 0.03 on epoch=304
04/25/2022 19:40:20 - INFO - __main__ - Step 620 Global step 620 Train loss 0.05 on epoch=309
04/25/2022 19:40:22 - INFO - __main__ - Step 630 Global step 630 Train loss 0.04 on epoch=314
04/25/2022 19:40:25 - INFO - __main__ - Step 640 Global step 640 Train loss 0.03 on epoch=319
04/25/2022 19:40:27 - INFO - __main__ - Step 650 Global step 650 Train loss 0.05 on epoch=324
04/25/2022 19:40:29 - INFO - __main__ - Global step 650 Train loss 0.04 ACC 0.34375 on epoch=324
04/25/2022 19:40:31 - INFO - __main__ - Step 660 Global step 660 Train loss 0.05 on epoch=329
04/25/2022 19:40:33 - INFO - __main__ - Step 670 Global step 670 Train loss 0.04 on epoch=334
04/25/2022 19:40:36 - INFO - __main__ - Step 680 Global step 680 Train loss 0.06 on epoch=339
04/25/2022 19:40:38 - INFO - __main__ - Step 690 Global step 690 Train loss 0.06 on epoch=344
04/25/2022 19:40:41 - INFO - __main__ - Step 700 Global step 700 Train loss 0.02 on epoch=349
04/25/2022 19:40:42 - INFO - __main__ - Global step 700 Train loss 0.04 ACC 0.34375 on epoch=349
04/25/2022 19:40:45 - INFO - __main__ - Step 710 Global step 710 Train loss 0.05 on epoch=354
04/25/2022 19:40:47 - INFO - __main__ - Step 720 Global step 720 Train loss 0.05 on epoch=359
04/25/2022 19:40:49 - INFO - __main__ - Step 730 Global step 730 Train loss 0.03 on epoch=364
04/25/2022 19:40:52 - INFO - __main__ - Step 740 Global step 740 Train loss 0.03 on epoch=369
04/25/2022 19:40:54 - INFO - __main__ - Step 750 Global step 750 Train loss 0.05 on epoch=374
04/25/2022 19:40:56 - INFO - __main__ - Global step 750 Train loss 0.04 ACC 0.4375 on epoch=374
04/25/2022 19:40:58 - INFO - __main__ - Step 760 Global step 760 Train loss 0.07 on epoch=379
04/25/2022 19:41:01 - INFO - __main__ - Step 770 Global step 770 Train loss 0.03 on epoch=384
04/25/2022 19:41:03 - INFO - __main__ - Step 780 Global step 780 Train loss 0.04 on epoch=389
04/25/2022 19:41:06 - INFO - __main__ - Step 790 Global step 790 Train loss 0.04 on epoch=394
04/25/2022 19:41:08 - INFO - __main__ - Step 800 Global step 800 Train loss 0.03 on epoch=399
04/25/2022 19:41:10 - INFO - __main__ - Global step 800 Train loss 0.04 ACC 0.40625 on epoch=399
04/25/2022 19:41:12 - INFO - __main__ - Step 810 Global step 810 Train loss 0.03 on epoch=404
04/25/2022 19:41:15 - INFO - __main__ - Step 820 Global step 820 Train loss 0.06 on epoch=409
04/25/2022 19:41:17 - INFO - __main__ - Step 830 Global step 830 Train loss 0.04 on epoch=414
04/25/2022 19:41:19 - INFO - __main__ - Step 840 Global step 840 Train loss 0.04 on epoch=419
04/25/2022 19:41:22 - INFO - __main__ - Step 850 Global step 850 Train loss 0.02 on epoch=424
04/25/2022 19:41:23 - INFO - __main__ - Global step 850 Train loss 0.04 ACC 0.4375 on epoch=424
04/25/2022 19:41:26 - INFO - __main__ - Step 860 Global step 860 Train loss 0.03 on epoch=429
04/25/2022 19:41:28 - INFO - __main__ - Step 870 Global step 870 Train loss 0.05 on epoch=434
04/25/2022 19:41:31 - INFO - __main__ - Step 880 Global step 880 Train loss 0.03 on epoch=439
04/25/2022 19:41:33 - INFO - __main__ - Step 890 Global step 890 Train loss 0.02 on epoch=444
04/25/2022 19:41:35 - INFO - __main__ - Step 900 Global step 900 Train loss 0.01 on epoch=449
04/25/2022 19:41:37 - INFO - __main__ - Global step 900 Train loss 0.03 ACC 0.40625 on epoch=449
04/25/2022 19:41:39 - INFO - __main__ - Step 910 Global step 910 Train loss 0.05 on epoch=454
04/25/2022 19:41:42 - INFO - __main__ - Step 920 Global step 920 Train loss 0.04 on epoch=459
04/25/2022 19:41:44 - INFO - __main__ - Step 930 Global step 930 Train loss 0.03 on epoch=464
04/25/2022 19:41:47 - INFO - __main__ - Step 940 Global step 940 Train loss 0.03 on epoch=469
04/25/2022 19:41:49 - INFO - __main__ - Step 950 Global step 950 Train loss 0.01 on epoch=474
04/25/2022 19:41:51 - INFO - __main__ - Global step 950 Train loss 0.03 ACC 0.4375 on epoch=474
04/25/2022 19:41:53 - INFO - __main__ - Step 960 Global step 960 Train loss 0.01 on epoch=479
04/25/2022 19:41:56 - INFO - __main__ - Step 970 Global step 970 Train loss 0.02 on epoch=484
04/25/2022 19:41:58 - INFO - __main__ - Step 980 Global step 980 Train loss 0.03 on epoch=489
04/25/2022 19:42:00 - INFO - __main__ - Step 990 Global step 990 Train loss 0.02 on epoch=494
04/25/2022 19:42:03 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.02 on epoch=499
04/25/2022 19:42:04 - INFO - __main__ - Global step 1000 Train loss 0.02 ACC 0.40625 on epoch=499
04/25/2022 19:42:07 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.03 on epoch=504
04/25/2022 19:42:09 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.02 on epoch=509
04/25/2022 19:42:12 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.03 on epoch=514
04/25/2022 19:42:14 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.02 on epoch=519
04/25/2022 19:42:17 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.01 on epoch=524
04/25/2022 19:42:18 - INFO - __main__ - Global step 1050 Train loss 0.02 ACC 0.375 on epoch=524
04/25/2022 19:42:21 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.02 on epoch=529
04/25/2022 19:42:23 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.02 on epoch=534
04/25/2022 19:42:26 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.02 on epoch=539
04/25/2022 19:42:28 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.01 on epoch=544
04/25/2022 19:42:30 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.02 on epoch=549
04/25/2022 19:42:32 - INFO - __main__ - Global step 1100 Train loss 0.02 ACC 0.40625 on epoch=549
04/25/2022 19:42:34 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.01 on epoch=554
04/25/2022 19:42:37 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.02 on epoch=559
04/25/2022 19:42:39 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=564
04/25/2022 19:42:42 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.01 on epoch=569
04/25/2022 19:42:44 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.04 on epoch=574
04/25/2022 19:42:46 - INFO - __main__ - Global step 1150 Train loss 0.02 ACC 0.4375 on epoch=574
04/25/2022 19:42:48 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.02 on epoch=579
04/25/2022 19:42:50 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.01 on epoch=584
04/25/2022 19:42:53 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.01 on epoch=589
04/25/2022 19:42:55 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.02 on epoch=594
04/25/2022 19:42:58 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=599
04/25/2022 19:42:59 - INFO - __main__ - Global step 1200 Train loss 0.01 ACC 0.40625 on epoch=599
04/25/2022 19:43:02 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.02 on epoch=604
04/25/2022 19:43:04 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.04 on epoch=609
04/25/2022 19:43:07 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.02 on epoch=614
04/25/2022 19:43:09 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=619
04/25/2022 19:43:11 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.01 on epoch=624
04/25/2022 19:43:13 - INFO - __main__ - Global step 1250 Train loss 0.02 ACC 0.4375 on epoch=624
04/25/2022 19:43:15 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=629
04/25/2022 19:43:18 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.01 on epoch=634
04/25/2022 19:43:20 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=639
04/25/2022 19:43:23 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=644
04/25/2022 19:43:25 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=649
04/25/2022 19:43:27 - INFO - __main__ - Global step 1300 Train loss 0.01 ACC 0.40625 on epoch=649
04/25/2022 19:43:29 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=654
04/25/2022 19:43:32 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=659
04/25/2022 19:43:34 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.02 on epoch=664
04/25/2022 19:43:36 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=669
04/25/2022 19:43:39 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.02 on epoch=674
04/25/2022 19:43:40 - INFO - __main__ - Global step 1350 Train loss 0.01 ACC 0.46875 on epoch=674
04/25/2022 19:43:43 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.00 on epoch=679
04/25/2022 19:43:45 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.02 on epoch=684
04/25/2022 19:43:48 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=689
04/25/2022 19:43:50 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=694
04/25/2022 19:43:52 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=699
04/25/2022 19:43:54 - INFO - __main__ - Global step 1400 Train loss 0.01 ACC 0.3125 on epoch=699
04/25/2022 19:43:56 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=704
04/25/2022 19:43:59 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.01 on epoch=709
04/25/2022 19:44:01 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=714
04/25/2022 19:44:04 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=719
04/25/2022 19:44:06 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=724
04/25/2022 19:44:08 - INFO - __main__ - Global step 1450 Train loss 0.01 ACC 0.40625 on epoch=724
04/25/2022 19:44:10 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=729
04/25/2022 19:44:12 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.03 on epoch=734
04/25/2022 19:44:15 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=739
04/25/2022 19:44:17 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.02 on epoch=744
04/25/2022 19:44:20 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.02 on epoch=749
04/25/2022 19:44:21 - INFO - __main__ - Global step 1500 Train loss 0.02 ACC 0.40625 on epoch=749
04/25/2022 19:44:24 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=754
04/25/2022 19:44:26 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=759
04/25/2022 19:44:29 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.02 on epoch=764
04/25/2022 19:44:31 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=769
04/25/2022 19:44:33 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=774
04/25/2022 19:44:35 - INFO - __main__ - Global step 1550 Train loss 0.01 ACC 0.375 on epoch=774
04/25/2022 19:44:37 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=779
04/25/2022 19:44:40 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=784
04/25/2022 19:44:42 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=789
04/25/2022 19:44:45 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=794
04/25/2022 19:44:47 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.03 on epoch=799
04/25/2022 19:44:49 - INFO - __main__ - Global step 1600 Train loss 0.01 ACC 0.375 on epoch=799
04/25/2022 19:44:51 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=804
04/25/2022 19:44:54 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=809
04/25/2022 19:44:56 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=814
04/25/2022 19:44:58 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=819
04/25/2022 19:45:01 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=824
04/25/2022 19:45:02 - INFO - __main__ - Global step 1650 Train loss 0.01 ACC 0.25 on epoch=824
04/25/2022 19:45:05 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=829
04/25/2022 19:45:07 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=834
04/25/2022 19:45:10 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=839
04/25/2022 19:45:12 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=844
04/25/2022 19:45:15 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=849
04/25/2022 19:45:16 - INFO - __main__ - Global step 1700 Train loss 0.01 ACC 0.34375 on epoch=849
04/25/2022 19:45:19 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=854
04/25/2022 19:45:21 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=859
04/25/2022 19:45:24 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=864
04/25/2022 19:45:26 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=869
04/25/2022 19:45:28 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=874
04/25/2022 19:45:30 - INFO - __main__ - Global step 1750 Train loss 0.01 ACC 0.3125 on epoch=874
04/25/2022 19:45:32 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=879
04/25/2022 19:45:35 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=884
04/25/2022 19:45:37 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=889
04/25/2022 19:45:40 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=894
04/25/2022 19:45:42 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=899
04/25/2022 19:45:44 - INFO - __main__ - Global step 1800 Train loss 0.01 ACC 0.34375 on epoch=899
04/25/2022 19:45:46 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=904
04/25/2022 19:45:49 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=909
04/25/2022 19:45:51 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=914
04/25/2022 19:45:54 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=919
04/25/2022 19:45:56 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=924
04/25/2022 19:45:58 - INFO - __main__ - Global step 1850 Train loss 0.01 ACC 0.34375 on epoch=924
04/25/2022 19:46:01 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=929
04/25/2022 19:46:03 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=934
04/25/2022 19:46:06 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=939
04/25/2022 19:46:08 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=944
04/25/2022 19:46:10 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=949
04/25/2022 19:46:12 - INFO - __main__ - Global step 1900 Train loss 0.01 ACC 0.375 on epoch=949
04/25/2022 19:46:14 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=954
04/25/2022 19:46:17 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=959
04/25/2022 19:46:19 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.04 on epoch=964
04/25/2022 19:46:22 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=969
04/25/2022 19:46:24 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=974
04/25/2022 19:46:26 - INFO - __main__ - Global step 1950 Train loss 0.01 ACC 0.34375 on epoch=974
04/25/2022 19:46:28 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=979
04/25/2022 19:46:31 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=984
04/25/2022 19:46:33 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=989
04/25/2022 19:46:36 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=994
04/25/2022 19:46:38 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=999
04/25/2022 19:46:40 - INFO - __main__ - Global step 2000 Train loss 0.01 ACC 0.34375 on epoch=999
04/25/2022 19:46:40 - INFO - __main__ - save last model!
04/25/2022 19:46:40 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
04/25/2022 19:46:40 - INFO - __main__ - Start tokenizing ... 500 instances
04/25/2022 19:46:40 - INFO - __main__ - Printing 3 examples
04/25/2022 19:46:40 - INFO - __main__ -  [openbookqa] Frilled sharks and angler fish live far beneath the surface of the ocean, which is why they are known as (A) Deep sea animals (B) fish (C) Long Sea Fish (D) Far Sea Animals
04/25/2022 19:46:40 - INFO - __main__ - ['Deep sea animals']
04/25/2022 19:46:40 - INFO - __main__ -  [openbookqa] Gas can fill any container it is given, and liquid (A) is standard weight and size (B) is the opposite of variable (C) only needs a few (D) uses what it needs
04/25/2022 19:46:40 - INFO - __main__ - ['uses what it needs']
04/25/2022 19:46:40 - INFO - __main__ -  [openbookqa] When birds migrate south for the winter, they do it because (A) they are genetically called to (B) their children ask for them to (C) it is important to their happiness (D) they decide to each year
04/25/2022 19:46:40 - INFO - __main__ - ['they are genetically called to']
04/25/2022 19:46:40 - INFO - __main__ - Tokenizing Input ...
04/25/2022 19:46:40 - INFO - __main__ - Tokenizing Output ...
04/25/2022 19:46:41 - INFO - __main__ - Loaded 500 examples from test data
04/25/2022 19:47:13 - INFO - __main__ - Saved prediction in models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-openbookqa/openbookqa_32_87_0.2_8_predictions.txt
04/25/2022 19:47:13 - INFO - __main__ - ACC on test data: 0.2860
04/25/2022 19:47:14 - INFO - __main__ - prefix=openbookqa_32_87, lr=0.2, bsz=8, dev_performance=0.46875, test_performance=0.286
