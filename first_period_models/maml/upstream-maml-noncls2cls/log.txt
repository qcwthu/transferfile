01/05/2022 13:29:36 - INFO - __main__ - Namespace(train_dir='data', predict_dir='data', identifier='large', output_dir='models/upstream-maml-noncls2cls', do_train=True, do_predict=False, inner_bsz=2, inner_lr=3e-05, checkpoint=None, do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=64, num_beams=4, append_another_bos=False, train_batch_size=1, predict_batch_size=1, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=4, num_train_epochs=120.0, warmup_steps=360, total_steps=4500, wait_step=10000000000, verbose=False, eval_period=10, prefix='', debug=False, seed=42, custom_tasks_splits='./dataloader/custom_tasks_splits/train_nonclassification_test_classification.json', cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=-1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='2')
01/05/2022 13:29:36 - INFO - __main__ - models/upstream-maml-noncls2cls
01/05/2022 13:29:36 - INFO - __main__ - args.device: cuda
01/05/2022 13:29:36 - INFO - __main__ - Using 1 gpus
01/05/2022 13:29:37 - INFO - __main__ - Training on the following tasks: ['ade_corpus_v2-dosage', 'art', 'biomrc', 'blimp-anaphor_number_agreement', 'blimp-ellipsis_n_bar_2', 'blimp-sentential_negation_npi_licensor_present', 'blimp-sentential_negation_npi_scope', 'break-QDMR-high-level', 'commonsense_qa', 'crows_pairs', 'dream', 'duorc', 'eli5-asks', 'eli5-eli5', 'freebase_qa', 'gigaword', 'hellaswag', 'hotpot_qa', 'kilt_ay2', 'kilt_hotpotqa', 'kilt_trex', 'kilt_zsre', 'lama-conceptnet', 'lama-google_re', 'lama-squad', 'math_qa', 'numer_sense', 'openbookqa', 'piqa', 'proto_qa', 'qa_srl', 'quarel', 'quartz-no_knowledge', 'race-high', 'reddit_tifu-title', 'reddit_tifu-tldr', 'ropes', 'sciq', 'social_i_qa', 'spider', 'superglue-multirc', 'wiki_bio', 'wikisql', 'xsum', 'yelp_review_full']
01/05/2022 13:29:42 - INFO - __main__ - Start tokenizing ... 225 instances
01/05/2022 13:29:42 - INFO - __main__ - Printing 3 examples
01/05/2022 13:29:42 - INFO - __main__ -  [ade_corpus_v2-dosage] A small initial dose of prazosin ranging from 0.5 to 1 mg has been recommended to avoid the first-dose phenomenon characterized by a sudden and severe drop in blood pressure after the administration of the first dose of prazosin. [SEP] prazosin
01/05/2022 13:29:42 - INFO - __main__ -  0.5 to 1 mg
01/05/2022 13:29:42 - INFO - __main__ -  [ade_corpus_v2-dosage] High-dose intravenous mannitol infusion in various clinical settings may result in acute renal failure (ARF). [SEP] mannitol
01/05/2022 13:29:42 - INFO - __main__ -  High-dose
01/05/2022 13:29:42 - INFO - __main__ -  [ade_corpus_v2-dosage] This paper reports on a 6.9-year-old autistic male who developed repeated episodes of acute dystonic reactions associated with pimozide administration at the doses of 0.096 mg/kg/day and 0.032 mg/kg/day and 32 hours following pimozide withdrawal, as well as during subsequent thioridazine administration. [SEP] pimozide
01/05/2022 13:29:42 - INFO - __main__ -  0.032 mg/kg/day
01/05/2022 13:29:42 - INFO - __main__ - Tokenizing Train Input ...
01/05/2022 13:29:47 - INFO - __main__ - Tokenizing Train Output ...
01/05/2022 13:29:51 - INFO - __main__ - Tokenizing Dev Input ...
01/05/2022 13:29:57 - INFO - __main__ - Tokenizing Dev Output ...
01/05/2022 13:30:10 - INFO - __main__ - Loaded 225 examples from train data
01/05/2022 13:30:25 - INFO - __main__ - try to initialize prompt embeddings
01/05/2022 13:30:30 - INFO - __main__ - Starting training!
01/05/2022 13:31:11 - INFO - __main__ - global step: 10; train loss: 4.910775184631348; dev loss: 4.965750694274902
01/05/2022 13:31:52 - INFO - __main__ - global step: 20; train loss: 5.063498497009277; dev loss: 4.841732978820801
01/05/2022 13:32:32 - INFO - __main__ - global step: 30; train loss: 4.417138576507568; dev loss: 4.610723495483398
01/05/2022 13:33:12 - INFO - __main__ - global step: 40; train loss: 4.064152717590332; dev loss: 4.034298896789551
01/05/2022 13:33:51 - INFO - __main__ - global step: 50; train loss: 3.9421298503875732; dev loss: 4.184844017028809
01/05/2022 13:34:32 - INFO - __main__ - global step: 60; train loss: 3.999763011932373; dev loss: 4.146642208099365
01/05/2022 13:35:13 - INFO - __main__ - global step: 70; train loss: 3.7722671031951904; dev loss: 3.7586421966552734
01/05/2022 13:35:56 - INFO - __main__ - global step: 80; train loss: 4.040822982788086; dev loss: 3.8404698371887207
01/05/2022 13:36:38 - INFO - __main__ - global step: 90; train loss: 3.98042368888855; dev loss: 3.513018846511841
01/05/2022 13:37:19 - INFO - __main__ - global step: 100; train loss: 3.918198823928833; dev loss: 3.9345715045928955
01/05/2022 13:38:01 - INFO - __main__ - global step: 110; train loss: 3.5073559284210205; dev loss: 3.8320674896240234
01/05/2022 13:38:43 - INFO - __main__ - global step: 120; train loss: 4.012616157531738; dev loss: 3.7708370685577393
01/05/2022 13:39:25 - INFO - __main__ - global step: 130; train loss: 3.694267749786377; dev loss: 3.942181348800659
01/05/2022 13:40:07 - INFO - __main__ - global step: 140; train loss: 3.426126003265381; dev loss: 3.434007167816162
01/05/2022 13:40:50 - INFO - __main__ - global step: 150; train loss: 3.642961025238037; dev loss: 3.3296432495117188
01/05/2022 13:41:31 - INFO - __main__ - global step: 160; train loss: 3.827524185180664; dev loss: 3.604391098022461
01/05/2022 13:42:11 - INFO - __main__ - global step: 170; train loss: 3.5254502296447754; dev loss: 3.4381027221679688
01/05/2022 13:42:51 - INFO - __main__ - global step: 180; train loss: 4.004630088806152; dev loss: 3.536163330078125
01/05/2022 13:43:33 - INFO - __main__ - global step: 190; train loss: 3.1944198608398438; dev loss: 3.088475227355957
01/05/2022 13:44:14 - INFO - __main__ - global step: 200; train loss: 3.833679676055908; dev loss: 3.9501824378967285
01/05/2022 13:44:54 - INFO - __main__ - global step: 210; train loss: 3.297443389892578; dev loss: 3.049001932144165
01/05/2022 13:45:34 - INFO - __main__ - global step: 220; train loss: 3.110896348953247; dev loss: 3.0094218254089355
01/05/2022 13:46:15 - INFO - __main__ - global step: 230; train loss: 2.616426467895508; dev loss: 2.7328975200653076
01/05/2022 13:46:58 - INFO - __main__ - global step: 240; train loss: 3.19358229637146; dev loss: 3.3732731342315674
01/05/2022 13:47:41 - INFO - __main__ - global step: 250; train loss: 3.0948400497436523; dev loss: 3.118729591369629
01/05/2022 13:48:23 - INFO - __main__ - global step: 260; train loss: 2.9562952518463135; dev loss: 2.7382500171661377
01/05/2022 13:49:03 - INFO - __main__ - global step: 270; train loss: 3.0835347175598145; dev loss: 3.230304002761841
01/05/2022 13:49:43 - INFO - __main__ - global step: 280; train loss: 3.2155678272247314; dev loss: 2.979032278060913
01/05/2022 13:50:24 - INFO - __main__ - global step: 290; train loss: 2.8962035179138184; dev loss: 2.7949910163879395
01/05/2022 13:51:07 - INFO - __main__ - global step: 300; train loss: 2.8447959423065186; dev loss: 2.7429747581481934
01/05/2022 13:51:51 - INFO - __main__ - global step: 310; train loss: 3.0803382396698; dev loss: 2.8644425868988037
01/05/2022 13:52:34 - INFO - __main__ - global step: 320; train loss: 2.96005916595459; dev loss: 2.9885575771331787
01/05/2022 13:53:17 - INFO - __main__ - global step: 330; train loss: 2.9058618545532227; dev loss: 3.171670913696289
01/05/2022 13:53:59 - INFO - __main__ - global step: 340; train loss: 2.656564474105835; dev loss: 2.3691272735595703
01/05/2022 13:54:41 - INFO - __main__ - global step: 350; train loss: 2.927635669708252; dev loss: 2.8266501426696777
01/05/2022 13:55:22 - INFO - __main__ - global step: 360; train loss: 2.8268229961395264; dev loss: 2.8026514053344727
01/05/2022 13:56:04 - INFO - __main__ - global step: 370; train loss: 2.7492640018463135; dev loss: 2.7763001918792725
01/05/2022 13:56:47 - INFO - __main__ - global step: 380; train loss: 2.8978166580200195; dev loss: 2.9347774982452393
01/05/2022 13:57:30 - INFO - __main__ - global step: 390; train loss: 2.6281468868255615; dev loss: 2.7194907665252686
01/05/2022 13:58:13 - INFO - __main__ - global step: 400; train loss: 2.559406042098999; dev loss: 2.7869648933410645
01/05/2022 13:58:57 - INFO - __main__ - global step: 410; train loss: 2.5929393768310547; dev loss: 2.583487033843994
01/05/2022 13:59:40 - INFO - __main__ - global step: 420; train loss: 2.798924207687378; dev loss: 2.9055848121643066
01/05/2022 14:00:23 - INFO - __main__ - global step: 430; train loss: 2.5294294357299805; dev loss: 2.5587053298950195
01/05/2022 14:01:06 - INFO - __main__ - global step: 440; train loss: 2.8968920707702637; dev loss: 2.688800096511841
01/05/2022 14:01:48 - INFO - __main__ - global step: 450; train loss: 2.754317045211792; dev loss: 2.5649492740631104
01/05/2022 14:02:31 - INFO - __main__ - global step: 460; train loss: 2.854604721069336; dev loss: 2.7987308502197266
01/05/2022 14:03:13 - INFO - __main__ - global step: 470; train loss: 2.6042826175689697; dev loss: 2.5809130668640137
01/05/2022 14:03:53 - INFO - __main__ - global step: 480; train loss: 2.5360004901885986; dev loss: 2.4602999687194824
01/05/2022 14:04:33 - INFO - __main__ - global step: 490; train loss: 2.6021292209625244; dev loss: 2.471601963043213
01/05/2022 14:05:13 - INFO - __main__ - global step: 500; train loss: 2.820891857147217; dev loss: 2.797091007232666
01/05/2022 14:05:54 - INFO - __main__ - global step: 510; train loss: 2.4601402282714844; dev loss: 2.401597261428833
01/05/2022 14:06:36 - INFO - __main__ - global step: 520; train loss: 2.614281415939331; dev loss: 2.5903868675231934
01/05/2022 14:07:19 - INFO - __main__ - global step: 530; train loss: 2.6863350868225098; dev loss: 2.8931710720062256
01/05/2022 14:08:02 - INFO - __main__ - global step: 540; train loss: 2.6393303871154785; dev loss: 2.4196791648864746
01/05/2022 14:08:44 - INFO - __main__ - global step: 550; train loss: 2.6959471702575684; dev loss: 2.688300132751465
01/05/2022 14:09:26 - INFO - __main__ - global step: 560; train loss: 2.633230209350586; dev loss: 2.3925955295562744
01/05/2022 14:10:09 - INFO - __main__ - global step: 570; train loss: 2.4891583919525146; dev loss: 2.5837724208831787
01/05/2022 14:10:51 - INFO - __main__ - global step: 580; train loss: 2.6455883979797363; dev loss: 2.785215139389038
01/05/2022 14:11:34 - INFO - __main__ - global step: 590; train loss: 2.81357479095459; dev loss: 2.8344602584838867
01/05/2022 14:12:16 - INFO - __main__ - global step: 600; train loss: 2.6101648807525635; dev loss: 2.741095542907715
01/05/2022 14:12:58 - INFO - __main__ - global step: 610; train loss: 2.1863677501678467; dev loss: 2.067159652709961
01/05/2022 14:13:40 - INFO - __main__ - global step: 620; train loss: 2.3908286094665527; dev loss: 2.3205864429473877
01/05/2022 14:14:22 - INFO - __main__ - global step: 630; train loss: 2.494192600250244; dev loss: 2.526874542236328
01/05/2022 14:15:06 - INFO - __main__ - global step: 640; train loss: 2.508889675140381; dev loss: 2.4078640937805176
01/05/2022 14:15:50 - INFO - __main__ - global step: 650; train loss: 2.2421669960021973; dev loss: 2.2914016246795654
01/05/2022 14:16:33 - INFO - __main__ - global step: 660; train loss: 2.390000343322754; dev loss: 2.4245972633361816
01/05/2022 14:17:17 - INFO - __main__ - global step: 670; train loss: 2.669646739959717; dev loss: 2.6888720989227295
01/05/2022 14:18:00 - INFO - __main__ - global step: 680; train loss: 2.2564101219177246; dev loss: 2.5593299865722656
01/05/2022 14:18:42 - INFO - __main__ - global step: 690; train loss: 2.2491326332092285; dev loss: 2.268263101577759
01/05/2022 14:19:25 - INFO - __main__ - global step: 700; train loss: 2.4726808071136475; dev loss: 2.517981767654419
01/05/2022 14:20:07 - INFO - __main__ - global step: 710; train loss: 2.5417587757110596; dev loss: 2.5266213417053223
01/05/2022 14:20:51 - INFO - __main__ - global step: 720; train loss: 2.373185396194458; dev loss: 2.43107271194458
01/05/2022 14:21:34 - INFO - __main__ - global step: 730; train loss: 2.356656551361084; dev loss: 2.2369723320007324
01/05/2022 14:22:17 - INFO - __main__ - global step: 740; train loss: 2.5936686992645264; dev loss: 2.510571002960205
01/05/2022 14:23:00 - INFO - __main__ - global step: 750; train loss: 2.2519054412841797; dev loss: 2.3633761405944824
01/05/2022 14:23:43 - INFO - __main__ - global step: 760; train loss: 2.233926773071289; dev loss: 2.2288269996643066
01/05/2022 14:24:26 - INFO - __main__ - global step: 770; train loss: 2.6254324913024902; dev loss: 2.5091450214385986
01/05/2022 14:25:08 - INFO - __main__ - global step: 780; train loss: 2.5751490592956543; dev loss: 2.557610273361206
01/05/2022 14:25:51 - INFO - __main__ - global step: 790; train loss: 2.1705400943756104; dev loss: 1.9720274209976196
01/05/2022 14:26:35 - INFO - __main__ - global step: 800; train loss: 2.5833282470703125; dev loss: 2.606187105178833
01/05/2022 14:27:17 - INFO - __main__ - global step: 810; train loss: 2.1682140827178955; dev loss: 2.1084952354431152
01/05/2022 14:27:59 - INFO - __main__ - global step: 820; train loss: 2.2772936820983887; dev loss: 2.553250551223755
01/05/2022 14:28:41 - INFO - __main__ - global step: 830; train loss: 2.2535338401794434; dev loss: 2.3280460834503174
01/05/2022 14:29:23 - INFO - __main__ - global step: 840; train loss: 2.0648422241210938; dev loss: 1.9092121124267578
01/05/2022 14:30:04 - INFO - __main__ - global step: 850; train loss: 2.269709587097168; dev loss: 2.255293369293213
01/05/2022 14:30:46 - INFO - __main__ - global step: 860; train loss: 2.197662591934204; dev loss: 2.3813724517822266
01/05/2022 14:31:28 - INFO - __main__ - global step: 870; train loss: 1.9877691268920898; dev loss: 1.9705982208251953
01/05/2022 14:32:09 - INFO - __main__ - global step: 880; train loss: 2.0565555095672607; dev loss: 2.051278591156006
01/05/2022 14:32:51 - INFO - __main__ - global step: 890; train loss: 2.419548749923706; dev loss: 2.754322052001953
01/05/2022 14:33:33 - INFO - __main__ - global step: 900; train loss: 2.3122119903564453; dev loss: 2.485909938812256
01/05/2022 14:34:14 - INFO - __main__ - global step: 910; train loss: 2.4032771587371826; dev loss: 2.3110320568084717
01/05/2022 14:34:55 - INFO - __main__ - global step: 920; train loss: 2.541191816329956; dev loss: 2.733290195465088
01/05/2022 14:35:37 - INFO - __main__ - global step: 930; train loss: 2.0408942699432373; dev loss: 1.9175713062286377
01/05/2022 14:36:19 - INFO - __main__ - global step: 940; train loss: 1.7786333560943604; dev loss: 2.107346773147583
01/05/2022 14:37:00 - INFO - __main__ - global step: 950; train loss: 2.1286354064941406; dev loss: 2.1862759590148926
01/05/2022 14:37:42 - INFO - __main__ - global step: 960; train loss: 2.489806652069092; dev loss: 2.225567579269409
01/05/2022 14:38:23 - INFO - __main__ - global step: 970; train loss: 2.6041393280029297; dev loss: 2.5521557331085205
01/05/2022 14:39:05 - INFO - __main__ - global step: 980; train loss: 2.4201998710632324; dev loss: 2.208501100540161
01/05/2022 14:39:47 - INFO - __main__ - global step: 990; train loss: 2.1829941272735596; dev loss: 2.2675507068634033
01/05/2022 14:40:30 - INFO - __main__ - global step: 1000; train loss: 2.3148818016052246; dev loss: 2.3109076023101807
01/05/2022 14:41:12 - INFO - __main__ - global step: 1010; train loss: 1.6766704320907593; dev loss: 1.9762604236602783
01/05/2022 14:41:55 - INFO - __main__ - global step: 1020; train loss: 1.9329925775527954; dev loss: 1.7687257528305054
01/05/2022 14:42:37 - INFO - __main__ - global step: 1030; train loss: 2.4608871936798096; dev loss: 2.280944347381592
01/05/2022 14:43:20 - INFO - __main__ - global step: 1040; train loss: 2.2551321983337402; dev loss: 2.1264772415161133
01/05/2022 14:44:02 - INFO - __main__ - global step: 1050; train loss: 1.9924730062484741; dev loss: 1.9200109243392944
01/05/2022 14:44:43 - INFO - __main__ - global step: 1060; train loss: 2.5248265266418457; dev loss: 2.397827625274658
01/05/2022 14:45:24 - INFO - __main__ - global step: 1070; train loss: 2.201395034790039; dev loss: 2.2489266395568848
01/05/2022 14:46:06 - INFO - __main__ - global step: 1080; train loss: 2.226362943649292; dev loss: 2.1827683448791504
01/05/2022 14:46:49 - INFO - __main__ - global step: 1090; train loss: 2.4101357460021973; dev loss: 2.1126034259796143
01/05/2022 14:47:31 - INFO - __main__ - global step: 1100; train loss: 2.020251512527466; dev loss: 1.893058180809021
01/05/2022 14:48:13 - INFO - __main__ - global step: 1110; train loss: 2.525331974029541; dev loss: 2.4990234375
01/05/2022 14:48:55 - INFO - __main__ - global step: 1120; train loss: 2.2542331218719482; dev loss: 2.198702812194824
01/05/2022 14:49:38 - INFO - __main__ - global step: 1130; train loss: 2.091165542602539; dev loss: 2.0323734283447266
01/05/2022 14:50:20 - INFO - __main__ - global step: 1140; train loss: 1.9886754751205444; dev loss: 1.9666340351104736
01/05/2022 14:50:59 - INFO - __main__ - global step: 1150; train loss: 2.3877310752868652; dev loss: 2.3275203704833984
01/05/2022 14:51:39 - INFO - __main__ - global step: 1160; train loss: 1.972704291343689; dev loss: 1.8695869445800781
01/05/2022 14:52:19 - INFO - __main__ - global step: 1170; train loss: 2.122551441192627; dev loss: 2.197535991668701
01/05/2022 14:53:00 - INFO - __main__ - global step: 1180; train loss: 2.2043755054473877; dev loss: 2.4851810932159424
01/05/2022 14:53:41 - INFO - __main__ - global step: 1190; train loss: 2.1353278160095215; dev loss: 2.177532911300659
01/05/2022 14:54:24 - INFO - __main__ - global step: 1200; train loss: 2.106114149093628; dev loss: 2.0688774585723877
01/05/2022 14:55:07 - INFO - __main__ - global step: 1210; train loss: 2.0578534603118896; dev loss: 2.0470166206359863
01/05/2022 14:55:49 - INFO - __main__ - global step: 1220; train loss: 1.7136121988296509; dev loss: 1.632055640220642
01/05/2022 14:56:32 - INFO - __main__ - global step: 1230; train loss: 2.1464521884918213; dev loss: 2.2871530055999756
01/05/2022 14:57:15 - INFO - __main__ - global step: 1240; train loss: 2.7787787914276123; dev loss: 2.6314361095428467
01/05/2022 14:57:57 - INFO - __main__ - global step: 1250; train loss: 2.004310369491577; dev loss: 1.960205078125
01/05/2022 14:58:40 - INFO - __main__ - global step: 1260; train loss: 1.9590038061141968; dev loss: 1.9658997058868408
01/05/2022 14:59:23 - INFO - __main__ - global step: 1270; train loss: 2.1137173175811768; dev loss: 2.087167263031006
01/05/2022 15:00:05 - INFO - __main__ - global step: 1280; train loss: 2.503903388977051; dev loss: 2.332489013671875
01/05/2022 15:00:48 - INFO - __main__ - global step: 1290; train loss: 2.0237433910369873; dev loss: 2.1397621631622314
01/05/2022 15:01:31 - INFO - __main__ - global step: 1300; train loss: 1.9144054651260376; dev loss: 1.905174970626831
01/05/2022 15:02:13 - INFO - __main__ - global step: 1310; train loss: 2.213192939758301; dev loss: 2.3539235591888428
01/05/2022 15:02:55 - INFO - __main__ - global step: 1320; train loss: 2.205501079559326; dev loss: 1.8865989446640015
01/05/2022 15:03:37 - INFO - __main__ - global step: 1330; train loss: 1.7528175115585327; dev loss: 1.8947086334228516
01/05/2022 15:04:19 - INFO - __main__ - global step: 1340; train loss: 2.1783456802368164; dev loss: 2.509775400161743
01/05/2022 15:05:00 - INFO - __main__ - global step: 1350; train loss: 2.357438802719116; dev loss: 2.2697722911834717
01/05/2022 15:05:41 - INFO - __main__ - global step: 1360; train loss: 2.2845358848571777; dev loss: 2.521165132522583
01/05/2022 15:06:23 - INFO - __main__ - global step: 1370; train loss: 1.980528473854065; dev loss: 1.9694665670394897
01/05/2022 15:07:06 - INFO - __main__ - global step: 1380; train loss: 2.1960043907165527; dev loss: 2.199564218521118
01/05/2022 15:07:47 - INFO - __main__ - global step: 1390; train loss: 1.8802716732025146; dev loss: 1.9742008447647095
01/05/2022 15:08:29 - INFO - __main__ - global step: 1400; train loss: 2.319831132888794; dev loss: 2.111659288406372
01/05/2022 15:09:11 - INFO - __main__ - global step: 1410; train loss: 2.121466636657715; dev loss: 2.195479154586792
01/05/2022 15:09:53 - INFO - __main__ - global step: 1420; train loss: 1.7489326000213623; dev loss: 1.7858211994171143
01/05/2022 15:10:35 - INFO - __main__ - global step: 1430; train loss: 2.1651268005371094; dev loss: 2.151508331298828
01/05/2022 15:11:16 - INFO - __main__ - global step: 1440; train loss: 2.0557990074157715; dev loss: 2.018059253692627
01/05/2022 15:11:58 - INFO - __main__ - global step: 1450; train loss: 2.1011171340942383; dev loss: 2.128103733062744
01/05/2022 15:12:40 - INFO - __main__ - global step: 1460; train loss: 2.1695423126220703; dev loss: 2.0285160541534424
01/05/2022 15:13:22 - INFO - __main__ - global step: 1470; train loss: 2.0681138038635254; dev loss: 2.145211696624756
01/05/2022 15:14:05 - INFO - __main__ - global step: 1480; train loss: 2.4505691528320312; dev loss: 2.2687504291534424
01/05/2022 15:14:49 - INFO - __main__ - global step: 1490; train loss: 2.2448534965515137; dev loss: 2.1268692016601562
01/05/2022 15:15:32 - INFO - __main__ - global step: 1500; train loss: 2.2546048164367676; dev loss: 2.2565956115722656
01/05/2022 15:16:16 - INFO - __main__ - global step: 1510; train loss: 1.9943950176239014; dev loss: 1.948987364768982
01/05/2022 15:16:59 - INFO - __main__ - global step: 1520; train loss: 1.974374532699585; dev loss: 2.1719253063201904
01/05/2022 15:17:41 - INFO - __main__ - global step: 1530; train loss: 2.0581352710723877; dev loss: 2.0002574920654297
01/05/2022 15:18:23 - INFO - __main__ - global step: 1540; train loss: 2.026275157928467; dev loss: 2.1763641834259033
01/05/2022 15:19:05 - INFO - __main__ - global step: 1550; train loss: 2.3661437034606934; dev loss: 2.3316264152526855
01/05/2022 15:19:48 - INFO - __main__ - global step: 1560; train loss: 2.084212303161621; dev loss: 2.1541407108306885
01/05/2022 15:20:31 - INFO - __main__ - global step: 1570; train loss: 2.264616012573242; dev loss: 2.1941869258880615
01/05/2022 15:21:14 - INFO - __main__ - global step: 1580; train loss: 1.7858253717422485; dev loss: 1.9514347314834595
01/05/2022 15:21:56 - INFO - __main__ - global step: 1590; train loss: 2.708493709564209; dev loss: 2.518782377243042
01/05/2022 15:22:39 - INFO - __main__ - global step: 1600; train loss: 2.0743045806884766; dev loss: 2.02327036857605
01/05/2022 15:23:19 - INFO - __main__ - global step: 1610; train loss: 2.264293670654297; dev loss: 2.2315425872802734
01/05/2022 15:23:59 - INFO - __main__ - global step: 1620; train loss: 1.8067200183868408; dev loss: 1.6841920614242554
01/05/2022 15:24:39 - INFO - __main__ - global step: 1630; train loss: 2.1372878551483154; dev loss: 2.0004196166992188
01/05/2022 15:25:20 - INFO - __main__ - global step: 1640; train loss: 1.7609392404556274; dev loss: 1.8303020000457764
01/05/2022 15:26:03 - INFO - __main__ - global step: 1650; train loss: 2.472918748855591; dev loss: 2.2070600986480713
01/05/2022 15:26:45 - INFO - __main__ - global step: 1660; train loss: 1.9823795557022095; dev loss: 2.315849781036377
01/05/2022 15:27:24 - INFO - __main__ - global step: 1670; train loss: 1.702514410018921; dev loss: 1.7694931030273438
01/05/2022 15:28:03 - INFO - __main__ - global step: 1680; train loss: 2.004516124725342; dev loss: 1.8575845956802368
01/05/2022 15:28:43 - INFO - __main__ - global step: 1690; train loss: 2.194362163543701; dev loss: 2.0918571949005127
01/05/2022 15:29:22 - INFO - __main__ - global step: 1700; train loss: 2.0259249210357666; dev loss: 1.9821125268936157
01/05/2022 15:30:01 - INFO - __main__ - global step: 1710; train loss: 2.4538328647613525; dev loss: 2.4417386054992676
01/05/2022 15:30:40 - INFO - __main__ - global step: 1720; train loss: 1.9072011709213257; dev loss: 1.9960559606552124
01/05/2022 15:31:20 - INFO - __main__ - global step: 1730; train loss: 1.9361652135849; dev loss: 1.9264713525772095
01/05/2022 15:31:59 - INFO - __main__ - global step: 1740; train loss: 1.7609401941299438; dev loss: 1.754256010055542
01/05/2022 15:32:38 - INFO - __main__ - global step: 1750; train loss: 1.6668075323104858; dev loss: 1.7245008945465088
01/05/2022 15:33:19 - INFO - __main__ - global step: 1760; train loss: 1.9389508962631226; dev loss: 2.1180996894836426
01/05/2022 15:33:59 - INFO - __main__ - global step: 1770; train loss: 2.0753395557403564; dev loss: 2.1709117889404297
01/05/2022 15:34:38 - INFO - __main__ - global step: 1780; train loss: 1.8299248218536377; dev loss: 1.6644366979599
01/05/2022 15:35:17 - INFO - __main__ - global step: 1790; train loss: 2.1504409313201904; dev loss: 1.9266560077667236
01/05/2022 15:35:56 - INFO - __main__ - global step: 1800; train loss: 2.146599531173706; dev loss: 2.024416446685791
01/05/2022 15:36:38 - INFO - __main__ - global step: 1810; train loss: 2.309190511703491; dev loss: 2.3814756870269775
01/05/2022 15:37:20 - INFO - __main__ - global step: 1820; train loss: 2.338177442550659; dev loss: 2.0965638160705566
01/05/2022 15:38:01 - INFO - __main__ - global step: 1830; train loss: 2.02024245262146; dev loss: 2.2064003944396973
01/05/2022 15:38:42 - INFO - __main__ - global step: 1840; train loss: 1.6348273754119873; dev loss: 1.846405029296875
01/05/2022 15:39:24 - INFO - __main__ - global step: 1850; train loss: 1.6687854528427124; dev loss: 1.6871559619903564
01/05/2022 15:40:05 - INFO - __main__ - global step: 1860; train loss: 2.09283447265625; dev loss: 2.136007785797119
01/05/2022 15:40:48 - INFO - __main__ - global step: 1870; train loss: 2.355510711669922; dev loss: 2.2057900428771973
01/05/2022 15:41:31 - INFO - __main__ - global step: 1880; train loss: 1.7488071918487549; dev loss: 1.6896584033966064
01/05/2022 15:42:11 - INFO - __main__ - global step: 1890; train loss: 2.1837451457977295; dev loss: 2.121429204940796
01/05/2022 15:42:52 - INFO - __main__ - global step: 1900; train loss: 1.9234533309936523; dev loss: 2.036475419998169
01/05/2022 15:43:32 - INFO - __main__ - global step: 1910; train loss: 1.8401710987091064; dev loss: 1.6505769491195679
01/05/2022 15:44:11 - INFO - __main__ - global step: 1920; train loss: 2.38594913482666; dev loss: 2.01330828666687
01/05/2022 15:44:48 - INFO - __main__ - global step: 1930; train loss: 1.7513649463653564; dev loss: 1.8056190013885498
01/05/2022 15:45:25 - INFO - __main__ - global step: 1940; train loss: 1.8592926263809204; dev loss: 1.7606828212738037
01/05/2022 15:46:03 - INFO - __main__ - global step: 1950; train loss: 2.0855722427368164; dev loss: 1.8660342693328857
01/05/2022 15:46:40 - INFO - __main__ - global step: 1960; train loss: 2.312849521636963; dev loss: 2.0441439151763916
01/05/2022 15:47:17 - INFO - __main__ - global step: 1970; train loss: 2.1109044551849365; dev loss: 2.1818490028381348
01/05/2022 15:47:55 - INFO - __main__ - global step: 1980; train loss: 1.7324497699737549; dev loss: 1.7039291858673096
01/05/2022 15:48:32 - INFO - __main__ - global step: 1990; train loss: 2.2516350746154785; dev loss: 1.9824116230010986
01/05/2022 15:49:10 - INFO - __main__ - global step: 2000; train loss: 1.888404130935669; dev loss: 2.082145929336548
01/05/2022 15:49:48 - INFO - __main__ - global step: 2010; train loss: 2.0351147651672363; dev loss: 2.0635364055633545
01/05/2022 15:50:26 - INFO - __main__ - global step: 2020; train loss: 1.7866764068603516; dev loss: 1.8443348407745361
01/05/2022 15:51:05 - INFO - __main__ - global step: 2030; train loss: 2.0750720500946045; dev loss: 1.9374275207519531
01/05/2022 15:51:44 - INFO - __main__ - global step: 2040; train loss: 1.7680610418319702; dev loss: 1.9367250204086304
01/05/2022 15:52:22 - INFO - __main__ - global step: 2050; train loss: 1.8668670654296875; dev loss: 1.777947187423706
01/05/2022 15:53:01 - INFO - __main__ - global step: 2060; train loss: 2.0219037532806396; dev loss: 2.0901894569396973
01/05/2022 15:53:41 - INFO - __main__ - global step: 2070; train loss: 2.086336612701416; dev loss: 1.9787395000457764
01/05/2022 15:54:20 - INFO - __main__ - global step: 2080; train loss: 2.1258907318115234; dev loss: 2.0773067474365234
01/05/2022 15:54:59 - INFO - __main__ - global step: 2090; train loss: 2.258539915084839; dev loss: 2.1247611045837402
01/05/2022 15:55:38 - INFO - __main__ - global step: 2100; train loss: 1.892761468887329; dev loss: 2.013317108154297
01/05/2022 15:56:17 - INFO - __main__ - global step: 2110; train loss: 2.020200729370117; dev loss: 1.8888689279556274
01/05/2022 15:56:55 - INFO - __main__ - global step: 2120; train loss: 1.6614269018173218; dev loss: 1.5894556045532227
01/05/2022 15:57:36 - INFO - __main__ - global step: 2130; train loss: 2.0951647758483887; dev loss: 1.8389095067977905
01/05/2022 15:58:17 - INFO - __main__ - global step: 2140; train loss: 2.172020435333252; dev loss: 1.9100955724716187
01/05/2022 15:58:59 - INFO - __main__ - global step: 2150; train loss: 2.2134222984313965; dev loss: 2.1395888328552246
01/05/2022 15:59:39 - INFO - __main__ - global step: 2160; train loss: 1.8658422231674194; dev loss: 1.966943383216858
01/05/2022 16:00:19 - INFO - __main__ - global step: 2170; train loss: 1.856591820716858; dev loss: 1.6778738498687744
01/05/2022 16:01:00 - INFO - __main__ - global step: 2180; train loss: 1.9230670928955078; dev loss: 1.8552446365356445
01/05/2022 16:01:40 - INFO - __main__ - global step: 2190; train loss: 2.0457539558410645; dev loss: 1.8437398672103882
01/05/2022 16:02:20 - INFO - __main__ - global step: 2200; train loss: 1.6979682445526123; dev loss: 1.6976630687713623
01/05/2022 16:03:00 - INFO - __main__ - global step: 2210; train loss: 1.9558738470077515; dev loss: 1.6610758304595947
01/05/2022 16:03:39 - INFO - __main__ - global step: 2220; train loss: 2.094216823577881; dev loss: 2.1971590518951416
01/05/2022 16:04:19 - INFO - __main__ - global step: 2230; train loss: 1.8969475030899048; dev loss: 2.063605308532715
01/05/2022 16:04:59 - INFO - __main__ - global step: 2240; train loss: 1.8542349338531494; dev loss: 1.829568862915039
01/05/2022 16:05:39 - INFO - __main__ - global step: 2250; train loss: 2.1341114044189453; dev loss: 2.1930127143859863
01/05/2022 16:06:19 - INFO - __main__ - global step: 2260; train loss: 1.709549903869629; dev loss: 1.8006668090820312
01/05/2022 16:06:59 - INFO - __main__ - global step: 2270; train loss: 1.8887641429901123; dev loss: 1.8496710062026978
01/05/2022 16:07:39 - INFO - __main__ - global step: 2280; train loss: 1.957066535949707; dev loss: 2.079063892364502
01/05/2022 16:08:19 - INFO - __main__ - global step: 2290; train loss: 2.58496356010437; dev loss: 2.3697071075439453
01/05/2022 16:08:59 - INFO - __main__ - global step: 2300; train loss: 2.096345901489258; dev loss: 2.09635591506958
01/05/2022 16:09:38 - INFO - __main__ - global step: 2310; train loss: 1.3127763271331787; dev loss: 1.236643671989441
01/05/2022 16:10:18 - INFO - __main__ - global step: 2320; train loss: 2.020742893218994; dev loss: 1.9632686376571655
01/05/2022 16:10:58 - INFO - __main__ - global step: 2330; train loss: 1.8090009689331055; dev loss: 1.9437777996063232
01/05/2022 16:11:38 - INFO - __main__ - global step: 2340; train loss: 2.1633293628692627; dev loss: 2.0518805980682373
01/05/2022 16:12:18 - INFO - __main__ - global step: 2350; train loss: 1.7828500270843506; dev loss: 1.9265415668487549
01/05/2022 16:12:58 - INFO - __main__ - global step: 2360; train loss: 1.7366173267364502; dev loss: 1.8102394342422485
01/05/2022 16:13:38 - INFO - __main__ - global step: 2370; train loss: 2.1500258445739746; dev loss: 2.144213914871216
01/05/2022 16:14:18 - INFO - __main__ - global step: 2380; train loss: 2.1626453399658203; dev loss: 2.0751280784606934
01/05/2022 16:14:59 - INFO - __main__ - global step: 2390; train loss: 1.7393277883529663; dev loss: 1.7314081192016602
01/05/2022 16:15:40 - INFO - __main__ - global step: 2400; train loss: 2.0809993743896484; dev loss: 1.9632022380828857
01/05/2022 16:16:20 - INFO - __main__ - global step: 2410; train loss: 1.5710569620132446; dev loss: 1.6051915884017944
01/05/2022 16:16:59 - INFO - __main__ - global step: 2420; train loss: 1.9861301183700562; dev loss: 2.056185483932495
01/05/2022 16:17:37 - INFO - __main__ - global step: 2430; train loss: 1.5926710367202759; dev loss: 1.3836649656295776
01/05/2022 16:18:15 - INFO - __main__ - global step: 2440; train loss: 2.301435947418213; dev loss: 2.797151565551758
01/05/2022 16:18:53 - INFO - __main__ - global step: 2450; train loss: 2.2350497245788574; dev loss: 2.452008008956909
01/05/2022 16:19:30 - INFO - __main__ - global step: 2460; train loss: 1.77358078956604; dev loss: 1.7891203165054321
01/05/2022 16:20:08 - INFO - __main__ - global step: 2470; train loss: 2.4969213008880615; dev loss: 2.096226692199707
01/05/2022 16:20:46 - INFO - __main__ - global step: 2480; train loss: 2.0135514736175537; dev loss: 2.0532608032226562
01/05/2022 16:21:24 - INFO - __main__ - global step: 2490; train loss: 1.9502818584442139; dev loss: 2.0974221229553223
01/05/2022 16:22:01 - INFO - __main__ - global step: 2500; train loss: 2.203280210494995; dev loss: 2.2759151458740234
01/05/2022 16:22:39 - INFO - __main__ - global step: 2510; train loss: 1.840959906578064; dev loss: 1.9448896646499634
01/05/2022 16:23:17 - INFO - __main__ - global step: 2520; train loss: 2.4236984252929688; dev loss: 2.37736177444458
01/05/2022 16:23:55 - INFO - __main__ - global step: 2530; train loss: 1.8004802465438843; dev loss: 1.6969521045684814
01/05/2022 16:24:32 - INFO - __main__ - global step: 2540; train loss: 1.7358213663101196; dev loss: 1.545305609703064
01/05/2022 16:25:10 - INFO - __main__ - global step: 2550; train loss: 1.6144027709960938; dev loss: 1.7153561115264893
01/05/2022 16:25:48 - INFO - __main__ - global step: 2560; train loss: 1.7822434902191162; dev loss: 1.6822407245635986
01/05/2022 16:26:26 - INFO - __main__ - global step: 2570; train loss: 2.1711459159851074; dev loss: 2.2143771648406982
01/05/2022 16:27:04 - INFO - __main__ - global step: 2580; train loss: 2.0019583702087402; dev loss: 1.9885841608047485
01/05/2022 16:27:43 - INFO - __main__ - global step: 2590; train loss: 1.8320480585098267; dev loss: 1.9538387060165405
01/05/2022 16:28:21 - INFO - __main__ - global step: 2600; train loss: 2.1105072498321533; dev loss: 1.904902696609497
01/05/2022 16:28:59 - INFO - __main__ - global step: 2610; train loss: 1.6533359289169312; dev loss: 1.5017927885055542
01/05/2022 16:29:37 - INFO - __main__ - global step: 2620; train loss: 1.819226861000061; dev loss: 2.0222666263580322
01/05/2022 16:30:14 - INFO - __main__ - global step: 2630; train loss: 1.6813236474990845; dev loss: 1.7042129039764404
01/05/2022 16:30:52 - INFO - __main__ - global step: 2640; train loss: 1.7533996105194092; dev loss: 1.8405345678329468
01/05/2022 16:31:30 - INFO - __main__ - global step: 2650; train loss: 1.9530693292617798; dev loss: 1.8827632665634155
01/05/2022 16:32:07 - INFO - __main__ - global step: 2660; train loss: 2.0180106163024902; dev loss: 1.9788475036621094
01/05/2022 16:32:44 - INFO - __main__ - global step: 2670; train loss: 2.2015419006347656; dev loss: 2.0967140197753906
01/05/2022 16:33:21 - INFO - __main__ - global step: 2680; train loss: 1.7786667346954346; dev loss: 1.8494617938995361
01/05/2022 16:33:59 - INFO - __main__ - global step: 2690; train loss: 1.7708053588867188; dev loss: 1.9604942798614502
01/05/2022 16:34:35 - INFO - __main__ - global step: 2700; train loss: 1.5826921463012695; dev loss: 1.808871865272522
01/05/2022 16:35:12 - INFO - __main__ - global step: 2710; train loss: 2.238168716430664; dev loss: 2.131986141204834
01/05/2022 16:35:49 - INFO - __main__ - global step: 2720; train loss: 1.7648143768310547; dev loss: 1.8666698932647705
01/05/2022 16:36:26 - INFO - __main__ - global step: 2730; train loss: 1.814568281173706; dev loss: 1.7227474451065063
01/05/2022 16:37:03 - INFO - __main__ - global step: 2740; train loss: 1.775162935256958; dev loss: 1.9190216064453125
01/05/2022 16:37:39 - INFO - __main__ - global step: 2750; train loss: 1.9484035968780518; dev loss: 1.7963616847991943
01/05/2022 16:38:16 - INFO - __main__ - global step: 2760; train loss: 1.6622222661972046; dev loss: 1.6693474054336548
01/05/2022 16:38:53 - INFO - __main__ - global step: 2770; train loss: 1.780832052230835; dev loss: 2.008690595626831
01/05/2022 16:39:30 - INFO - __main__ - global step: 2780; train loss: 1.9143375158309937; dev loss: 2.100940227508545
01/05/2022 16:40:07 - INFO - __main__ - global step: 2790; train loss: 2.034517765045166; dev loss: 1.9771608114242554
01/05/2022 16:40:45 - INFO - __main__ - global step: 2800; train loss: 1.6658744812011719; dev loss: 1.7510051727294922
01/05/2022 16:41:27 - INFO - __main__ - global step: 2810; train loss: 1.9151347875595093; dev loss: 1.7085094451904297
01/05/2022 16:42:08 - INFO - __main__ - global step: 2820; train loss: 2.038367748260498; dev loss: 2.104515552520752
01/05/2022 16:42:49 - INFO - __main__ - global step: 2830; train loss: 2.127227783203125; dev loss: 2.023066282272339
01/05/2022 16:43:29 - INFO - __main__ - global step: 2840; train loss: 1.8245456218719482; dev loss: 1.8759658336639404
01/05/2022 16:44:09 - INFO - __main__ - global step: 2850; train loss: 1.5835657119750977; dev loss: 1.5907647609710693
01/05/2022 16:44:50 - INFO - __main__ - global step: 2860; train loss: 1.704851746559143; dev loss: 1.8491626977920532
01/05/2022 16:45:30 - INFO - __main__ - global step: 2870; train loss: 2.0622479915618896; dev loss: 1.9944957494735718
01/05/2022 16:46:11 - INFO - __main__ - global step: 2880; train loss: 1.9534642696380615; dev loss: 1.8179171085357666
01/05/2022 16:46:51 - INFO - __main__ - global step: 2890; train loss: 1.7283436059951782; dev loss: 1.6222543716430664
01/05/2022 16:47:31 - INFO - __main__ - global step: 2900; train loss: 1.9354721307754517; dev loss: 1.6525501012802124
01/05/2022 16:48:11 - INFO - __main__ - global step: 2910; train loss: 1.7860755920410156; dev loss: 1.857954740524292
01/05/2022 16:48:50 - INFO - __main__ - global step: 2920; train loss: 1.932716965675354; dev loss: 1.9577586650848389
01/05/2022 16:49:30 - INFO - __main__ - global step: 2930; train loss: 1.7151925563812256; dev loss: 1.5922877788543701
01/05/2022 16:50:10 - INFO - __main__ - global step: 2940; train loss: 1.7336403131484985; dev loss: 1.7845436334609985
01/05/2022 16:50:49 - INFO - __main__ - global step: 2950; train loss: 1.9438276290893555; dev loss: 1.9576921463012695
01/05/2022 16:51:29 - INFO - __main__ - global step: 2960; train loss: 1.706266164779663; dev loss: 1.933408498764038
01/05/2022 16:52:09 - INFO - __main__ - global step: 2970; train loss: 1.9726158380508423; dev loss: 1.7587740421295166
01/05/2022 16:52:49 - INFO - __main__ - global step: 2980; train loss: 1.8322118520736694; dev loss: 1.7374610900878906
01/05/2022 16:53:28 - INFO - __main__ - global step: 2990; train loss: 1.714087724685669; dev loss: 1.8592212200164795
01/05/2022 16:54:08 - INFO - __main__ - global step: 3000; train loss: 1.5074622631072998; dev loss: 1.508305549621582
01/05/2022 16:54:48 - INFO - __main__ - global step: 3010; train loss: 1.913753867149353; dev loss: 2.09257435798645
01/05/2022 16:55:28 - INFO - __main__ - global step: 3020; train loss: 1.9076135158538818; dev loss: 1.8471025228500366
01/05/2022 16:56:08 - INFO - __main__ - global step: 3030; train loss: 1.8992688655853271; dev loss: 1.8663753271102905
01/05/2022 16:56:47 - INFO - __main__ - global step: 3040; train loss: 2.065126895904541; dev loss: 1.829176664352417
01/05/2022 16:57:27 - INFO - __main__ - global step: 3050; train loss: 2.2732958793640137; dev loss: 1.96420419216156
01/05/2022 16:58:07 - INFO - __main__ - global step: 3060; train loss: 1.2716615200042725; dev loss: 1.3060184717178345
01/05/2022 16:58:47 - INFO - __main__ - global step: 3070; train loss: 2.141714572906494; dev loss: 1.9748554229736328
01/05/2022 16:59:26 - INFO - __main__ - global step: 3080; train loss: 1.8518375158309937; dev loss: 1.7394399642944336
01/05/2022 17:00:06 - INFO - __main__ - global step: 3090; train loss: 1.8502333164215088; dev loss: 2.0800588130950928
01/05/2022 17:00:46 - INFO - __main__ - global step: 3100; train loss: 1.844262719154358; dev loss: 1.907861351966858
01/05/2022 17:01:25 - INFO - __main__ - global step: 3110; train loss: 1.626514196395874; dev loss: 1.4736143350601196
01/05/2022 17:02:05 - INFO - __main__ - global step: 3120; train loss: 2.063513994216919; dev loss: 2.074711799621582
01/05/2022 17:02:44 - INFO - __main__ - global step: 3130; train loss: 1.819350004196167; dev loss: 1.8860113620758057
01/05/2022 17:03:24 - INFO - __main__ - global step: 3140; train loss: 1.5940223932266235; dev loss: 1.788509726524353
01/05/2022 17:04:03 - INFO - __main__ - global step: 3150; train loss: 2.0600762367248535; dev loss: 1.9259074926376343
01/05/2022 17:04:42 - INFO - __main__ - global step: 3160; train loss: 2.036503314971924; dev loss: 2.1585121154785156
01/05/2022 17:05:21 - INFO - __main__ - global step: 3170; train loss: 1.7842094898223877; dev loss: 2.0910208225250244
01/05/2022 17:06:01 - INFO - __main__ - global step: 3180; train loss: 2.0443778038024902; dev loss: 1.8821513652801514
01/05/2022 17:06:40 - INFO - __main__ - global step: 3190; train loss: 1.7410976886749268; dev loss: 1.8104050159454346
01/05/2022 17:07:19 - INFO - __main__ - global step: 3200; train loss: 1.7578424215316772; dev loss: 1.574677586555481
01/05/2022 17:07:58 - INFO - __main__ - global step: 3210; train loss: 1.9936268329620361; dev loss: 1.7917146682739258
01/05/2022 17:08:37 - INFO - __main__ - global step: 3220; train loss: 1.8782742023468018; dev loss: 1.6438404321670532
01/05/2022 17:09:16 - INFO - __main__ - global step: 3230; train loss: 2.125420093536377; dev loss: 2.0551578998565674
01/05/2022 17:09:55 - INFO - __main__ - global step: 3240; train loss: 1.7851231098175049; dev loss: 1.6530815362930298
01/05/2022 17:10:34 - INFO - __main__ - global step: 3250; train loss: 1.6988452672958374; dev loss: 1.8513017892837524
01/05/2022 17:11:14 - INFO - __main__ - global step: 3260; train loss: 1.9201557636260986; dev loss: 1.9241313934326172
01/05/2022 17:11:53 - INFO - __main__ - global step: 3270; train loss: 2.0455660820007324; dev loss: 2.061380386352539
01/05/2022 17:12:32 - INFO - __main__ - global step: 3280; train loss: 1.9689083099365234; dev loss: 1.8006622791290283
01/05/2022 17:13:11 - INFO - __main__ - global step: 3290; train loss: 1.8544174432754517; dev loss: 1.8081896305084229
01/05/2022 17:13:50 - INFO - __main__ - global step: 3300; train loss: 1.8352206945419312; dev loss: 1.7990047931671143
01/05/2022 17:14:30 - INFO - __main__ - global step: 3310; train loss: 1.5604760646820068; dev loss: 1.7435743808746338
01/05/2022 17:15:08 - INFO - __main__ - global step: 3320; train loss: 1.6712239980697632; dev loss: 1.8874651193618774
01/05/2022 17:15:48 - INFO - __main__ - global step: 3330; train loss: 1.7856378555297852; dev loss: 1.7976270914077759
01/05/2022 17:16:27 - INFO - __main__ - global step: 3340; train loss: 1.8722413778305054; dev loss: 1.8025524616241455
01/05/2022 17:17:06 - INFO - __main__ - global step: 3350; train loss: 1.7430118322372437; dev loss: 1.7176777124404907
01/05/2022 17:17:45 - INFO - __main__ - global step: 3360; train loss: 1.7724453210830688; dev loss: 2.1929354667663574
01/05/2022 17:18:25 - INFO - __main__ - global step: 3370; train loss: 2.0850372314453125; dev loss: 1.976779580116272
01/05/2022 17:19:05 - INFO - __main__ - global step: 3380; train loss: 1.654650330543518; dev loss: 1.763942003250122
01/05/2022 17:19:45 - INFO - __main__ - global step: 3390; train loss: 1.7586132287979126; dev loss: 1.7211074829101562
01/05/2022 17:20:25 - INFO - __main__ - global step: 3400; train loss: 1.783172369003296; dev loss: 1.7889827489852905
01/05/2022 17:21:05 - INFO - __main__ - global step: 3410; train loss: 2.085326671600342; dev loss: 1.7803757190704346
01/05/2022 17:21:44 - INFO - __main__ - global step: 3420; train loss: 1.8124170303344727; dev loss: 1.720280408859253
01/05/2022 17:22:24 - INFO - __main__ - global step: 3430; train loss: 1.6619189977645874; dev loss: 1.6386638879776
01/05/2022 17:23:04 - INFO - __main__ - global step: 3440; train loss: 1.6680704355239868; dev loss: 1.7486016750335693
01/05/2022 17:23:44 - INFO - __main__ - global step: 3450; train loss: 1.7763283252716064; dev loss: 1.4764797687530518
01/05/2022 17:24:23 - INFO - __main__ - global step: 3460; train loss: 1.9405006170272827; dev loss: 1.8068374395370483
01/05/2022 17:25:03 - INFO - __main__ - global step: 3470; train loss: 1.802250623703003; dev loss: 1.7692569494247437
01/05/2022 17:25:43 - INFO - __main__ - global step: 3480; train loss: 2.0548579692840576; dev loss: 1.7042350769042969
01/05/2022 17:26:23 - INFO - __main__ - global step: 3490; train loss: 1.8296630382537842; dev loss: 1.7789093255996704
01/05/2022 17:27:03 - INFO - __main__ - global step: 3500; train loss: 1.6512978076934814; dev loss: 1.8152081966400146
01/05/2022 17:27:42 - INFO - __main__ - global step: 3510; train loss: 1.9608291387557983; dev loss: 1.9654842615127563
01/05/2022 17:28:22 - INFO - __main__ - global step: 3520; train loss: 1.963397741317749; dev loss: 2.0818023681640625
01/05/2022 17:29:02 - INFO - __main__ - global step: 3530; train loss: 1.6272624731063843; dev loss: 1.6860042810440063
01/05/2022 17:29:42 - INFO - __main__ - global step: 3540; train loss: 1.7197246551513672; dev loss: 1.5285484790802002
01/05/2022 17:30:22 - INFO - __main__ - global step: 3550; train loss: 2.2668545246124268; dev loss: 1.9077560901641846
01/05/2022 17:31:02 - INFO - __main__ - global step: 3560; train loss: 1.7583833932876587; dev loss: 1.6048171520233154
01/05/2022 17:31:42 - INFO - __main__ - global step: 3570; train loss: 1.6707032918930054; dev loss: 1.6596006155014038
01/05/2022 17:32:22 - INFO - __main__ - global step: 3580; train loss: 1.8429985046386719; dev loss: 1.785191297531128
01/05/2022 17:33:02 - INFO - __main__ - global step: 3590; train loss: 1.9098289012908936; dev loss: 1.7587677240371704
01/05/2022 17:33:42 - INFO - __main__ - global step: 3600; train loss: 1.6997768878936768; dev loss: 1.6814159154891968
01/05/2022 17:34:22 - INFO - __main__ - global step: 3610; train loss: 2.1327223777770996; dev loss: 2.2488744258880615
01/05/2022 17:35:01 - INFO - __main__ - global step: 3620; train loss: 1.6743993759155273; dev loss: 1.6728222370147705
01/05/2022 17:35:41 - INFO - __main__ - global step: 3630; train loss: 1.672048568725586; dev loss: 1.4527950286865234
01/05/2022 17:36:21 - INFO - __main__ - global step: 3640; train loss: 2.114638328552246; dev loss: 2.077871561050415
01/05/2022 17:37:01 - INFO - __main__ - global step: 3650; train loss: 1.759131669998169; dev loss: 1.791975975036621
01/05/2022 17:37:41 - INFO - __main__ - global step: 3660; train loss: 1.6210343837738037; dev loss: 1.4995137453079224
01/05/2022 17:38:20 - INFO - __main__ - global step: 3670; train loss: 1.8744697570800781; dev loss: 2.0979244709014893
01/05/2022 17:38:59 - INFO - __main__ - global step: 3680; train loss: 2.0974977016448975; dev loss: 1.9981609582901
01/05/2022 17:39:38 - INFO - __main__ - global step: 3690; train loss: 1.5469410419464111; dev loss: 1.5667235851287842
01/05/2022 17:40:17 - INFO - __main__ - global step: 3700; train loss: 1.5633571147918701; dev loss: 1.6242713928222656
01/05/2022 17:40:57 - INFO - __main__ - global step: 3710; train loss: 1.9030649662017822; dev loss: 1.8706344366073608
01/05/2022 17:41:36 - INFO - __main__ - global step: 3720; train loss: 1.8597873449325562; dev loss: 1.9508192539215088
01/05/2022 17:42:15 - INFO - __main__ - global step: 3730; train loss: 1.576072096824646; dev loss: 1.7794395685195923
01/05/2022 17:42:55 - INFO - __main__ - global step: 3740; train loss: 2.1087520122528076; dev loss: 1.9484431743621826
01/05/2022 17:43:34 - INFO - __main__ - global step: 3750; train loss: 1.9950851202011108; dev loss: 1.7230794429779053
01/05/2022 17:44:13 - INFO - __main__ - global step: 3760; train loss: 1.8468984365463257; dev loss: 1.8209073543548584
01/05/2022 17:44:52 - INFO - __main__ - global step: 3770; train loss: 1.5212516784667969; dev loss: 1.7962726354599
01/05/2022 17:45:32 - INFO - __main__ - global step: 3780; train loss: 1.5501823425292969; dev loss: 1.7028230428695679
01/05/2022 17:46:12 - INFO - __main__ - global step: 3790; train loss: 1.8849204778671265; dev loss: 1.8786563873291016
01/05/2022 17:46:52 - INFO - __main__ - global step: 3800; train loss: 2.0236401557922363; dev loss: 1.8511453866958618
01/05/2022 17:47:31 - INFO - __main__ - global step: 3810; train loss: 1.9101642370224; dev loss: 1.8239777088165283
01/05/2022 17:48:11 - INFO - __main__ - global step: 3820; train loss: 1.5302642583847046; dev loss: 1.6767337322235107
01/05/2022 17:48:51 - INFO - __main__ - global step: 3830; train loss: 1.3505746126174927; dev loss: 1.400865912437439
01/05/2022 17:49:31 - INFO - __main__ - global step: 3840; train loss: 2.261570453643799; dev loss: 2.1674106121063232
01/05/2022 17:50:11 - INFO - __main__ - global step: 3850; train loss: 1.711803674697876; dev loss: 1.8386017084121704
01/05/2022 17:50:51 - INFO - __main__ - global step: 3860; train loss: 1.4689093828201294; dev loss: 1.4419314861297607
01/05/2022 17:51:30 - INFO - __main__ - global step: 3870; train loss: 2.0045390129089355; dev loss: 1.9164249897003174
01/05/2022 17:52:10 - INFO - __main__ - global step: 3880; train loss: 1.7508636713027954; dev loss: 1.755357027053833
01/05/2022 17:52:49 - INFO - __main__ - global step: 3890; train loss: 1.739461898803711; dev loss: 1.770189881324768
01/05/2022 17:53:29 - INFO - __main__ - global step: 3900; train loss: 1.82991623878479; dev loss: 1.7856746912002563
01/05/2022 17:54:08 - INFO - __main__ - global step: 3910; train loss: 1.5602272748947144; dev loss: 1.592529058456421
01/05/2022 17:54:48 - INFO - __main__ - global step: 3920; train loss: 1.8938119411468506; dev loss: 1.8438667058944702
01/05/2022 17:55:27 - INFO - __main__ - global step: 3930; train loss: 2.2409274578094482; dev loss: 2.0085957050323486
01/05/2022 17:56:07 - INFO - __main__ - global step: 3940; train loss: 1.7395260334014893; dev loss: 1.6908642053604126
01/05/2022 17:56:46 - INFO - __main__ - global step: 3950; train loss: 1.9442628622055054; dev loss: 1.7368476390838623
01/05/2022 17:57:26 - INFO - __main__ - global step: 3960; train loss: 1.4853562116622925; dev loss: 1.4758161306381226
01/05/2022 17:58:05 - INFO - __main__ - global step: 3970; train loss: 1.9832165241241455; dev loss: 1.8003261089324951
01/05/2022 17:58:45 - INFO - __main__ - global step: 3980; train loss: 1.711857557296753; dev loss: 1.7548177242279053
01/05/2022 17:59:25 - INFO - __main__ - global step: 3990; train loss: 1.8616832494735718; dev loss: 1.9269145727157593
01/05/2022 18:00:04 - INFO - __main__ - global step: 4000; train loss: 1.7819797992706299; dev loss: 1.9009265899658203
01/05/2022 18:00:44 - INFO - __main__ - global step: 4010; train loss: 1.8766849040985107; dev loss: 1.826041579246521
01/05/2022 18:01:23 - INFO - __main__ - global step: 4020; train loss: 1.9178009033203125; dev loss: 1.9352623224258423
01/05/2022 18:02:03 - INFO - __main__ - global step: 4030; train loss: 1.7440769672393799; dev loss: 1.7103557586669922
01/05/2022 18:02:43 - INFO - __main__ - global step: 4040; train loss: 1.7438409328460693; dev loss: 1.6668955087661743
01/05/2022 18:03:22 - INFO - __main__ - global step: 4050; train loss: 1.7332912683486938; dev loss: 1.3997561931610107
01/05/2022 18:04:01 - INFO - __main__ - global step: 4060; train loss: 1.498766303062439; dev loss: 1.5989935398101807
01/05/2022 18:04:41 - INFO - __main__ - global step: 4070; train loss: 1.853244423866272; dev loss: 1.8304601907730103
01/05/2022 18:05:20 - INFO - __main__ - global step: 4080; train loss: 1.8111759424209595; dev loss: 1.8787431716918945
01/05/2022 18:05:59 - INFO - __main__ - global step: 4090; train loss: 2.0433809757232666; dev loss: 1.934476613998413
01/05/2022 18:06:38 - INFO - __main__ - global step: 4100; train loss: 1.9647302627563477; dev loss: 1.8458271026611328
01/05/2022 18:07:17 - INFO - __main__ - global step: 4110; train loss: 1.969655990600586; dev loss: 1.9278768301010132
01/05/2022 18:07:56 - INFO - __main__ - global step: 4120; train loss: 1.5714327096939087; dev loss: 1.5978004932403564
01/05/2022 18:08:35 - INFO - __main__ - global step: 4130; train loss: 1.9703419208526611; dev loss: 1.8846057653427124
01/05/2022 18:09:14 - INFO - __main__ - global step: 4140; train loss: 1.7023718357086182; dev loss: 1.5854222774505615
01/05/2022 18:09:54 - INFO - __main__ - global step: 4150; train loss: 1.8232759237289429; dev loss: 1.8855822086334229
01/05/2022 18:10:33 - INFO - __main__ - global step: 4160; train loss: 1.869908094406128; dev loss: 1.9198424816131592
01/05/2022 18:11:12 - INFO - __main__ - global step: 4170; train loss: 1.6485809087753296; dev loss: 1.6259944438934326
01/05/2022 18:11:51 - INFO - __main__ - global step: 4180; train loss: 1.8046796321868896; dev loss: 1.801709771156311
01/05/2022 18:12:30 - INFO - __main__ - global step: 4190; train loss: 1.8212387561798096; dev loss: 1.8162639141082764
01/05/2022 18:13:09 - INFO - __main__ - global step: 4200; train loss: 1.6912368535995483; dev loss: 1.6591243743896484
01/05/2022 18:13:48 - INFO - __main__ - global step: 4210; train loss: 1.7089958190917969; dev loss: 1.9119904041290283
01/05/2022 18:14:28 - INFO - __main__ - global step: 4220; train loss: 1.830804467201233; dev loss: 1.8742538690567017
01/05/2022 18:15:08 - INFO - __main__ - global step: 4230; train loss: 2.2493786811828613; dev loss: 2.2411932945251465
01/05/2022 18:15:47 - INFO - __main__ - global step: 4240; train loss: 1.4304487705230713; dev loss: 1.457006573677063
01/05/2022 18:16:27 - INFO - __main__ - global step: 4250; train loss: 1.6453899145126343; dev loss: 1.3502421379089355
01/05/2022 18:17:07 - INFO - __main__ - global step: 4260; train loss: 1.6447131633758545; dev loss: 1.4631154537200928
01/05/2022 18:17:47 - INFO - __main__ - global step: 4270; train loss: 1.9756171703338623; dev loss: 2.0798957347869873
01/05/2022 18:18:27 - INFO - __main__ - global step: 4280; train loss: 1.9488632678985596; dev loss: 2.0329277515411377
01/05/2022 18:19:07 - INFO - __main__ - global step: 4290; train loss: 1.6985645294189453; dev loss: 1.7942473888397217
01/05/2022 18:19:47 - INFO - __main__ - global step: 4300; train loss: 1.3789887428283691; dev loss: 1.3559497594833374
01/05/2022 18:20:25 - INFO - __main__ - global step: 4310; train loss: 2.1099965572357178; dev loss: 2.0503392219543457
01/05/2022 18:21:02 - INFO - __main__ - global step: 4320; train loss: 2.129425525665283; dev loss: 1.9372074604034424
01/05/2022 18:21:40 - INFO - __main__ - global step: 4330; train loss: 1.5724490880966187; dev loss: 1.5513511896133423
01/05/2022 18:22:18 - INFO - __main__ - global step: 4340; train loss: 1.7390190362930298; dev loss: 1.727098822593689
01/05/2022 18:22:57 - INFO - __main__ - global step: 4350; train loss: 1.8574800491333008; dev loss: 1.6742184162139893
01/05/2022 18:23:34 - INFO - __main__ - global step: 4360; train loss: 1.572584867477417; dev loss: 1.4551254510879517
01/05/2022 18:24:12 - INFO - __main__ - global step: 4370; train loss: 1.8790756464004517; dev loss: 1.8342891931533813
01/05/2022 18:24:50 - INFO - __main__ - global step: 4380; train loss: 2.1811249256134033; dev loss: 2.2325263023376465
01/05/2022 18:25:29 - INFO - __main__ - global step: 4390; train loss: 1.8885605335235596; dev loss: 1.968369483947754
01/05/2022 18:26:10 - INFO - __main__ - global step: 4400; train loss: 1.6605374813079834; dev loss: 1.5496203899383545
01/05/2022 18:26:50 - INFO - __main__ - global step: 4410; train loss: 1.9509270191192627; dev loss: 2.038973331451416
01/05/2022 18:27:30 - INFO - __main__ - global step: 4420; train loss: 1.791799783706665; dev loss: 1.7844932079315186
01/05/2022 18:28:10 - INFO - __main__ - global step: 4430; train loss: 1.663231611251831; dev loss: 1.5227218866348267
01/05/2022 18:28:50 - INFO - __main__ - global step: 4440; train loss: 1.6081619262695312; dev loss: 1.4523260593414307
01/05/2022 18:29:28 - INFO - __main__ - global step: 4450; train loss: 2.2239320278167725; dev loss: 1.8858534097671509
01/05/2022 18:30:07 - INFO - __main__ - global step: 4460; train loss: 1.525101900100708; dev loss: 1.4562839269638062
01/05/2022 18:30:46 - INFO - __main__ - global step: 4470; train loss: 1.8824207782745361; dev loss: 1.7208888530731201
01/05/2022 18:31:24 - INFO - __main__ - global step: 4480; train loss: 1.7303314208984375; dev loss: 1.5205291509628296
01/05/2022 18:32:03 - INFO - __main__ - global step: 4490; train loss: 2.3401803970336914; dev loss: 2.3191871643066406
01/05/2022 18:32:42 - INFO - __main__ - global step: 4500; train loss: 1.7373549938201904; dev loss: 1.6117740869522095
01/05/2022 18:32:42 - INFO - __main__ - save model!
