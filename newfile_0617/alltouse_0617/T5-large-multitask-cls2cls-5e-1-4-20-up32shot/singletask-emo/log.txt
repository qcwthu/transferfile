05/21/2022 21:26:59 - INFO - __main__ - Namespace(task_dir='data/emo/', task_name='emo', identifier='T5-large-multitask-cls2cls-5e-1-4-20-up32shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-multitask-cls2cls-5e-1-4-20-up32shot/singletask-emo', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-multitask-cls2cls-5e-1-4-20-32shot/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='4,5')
05/21/2022 21:26:59 - INFO - __main__ - models/T5-large-multitask-cls2cls-5e-1-4-20-up32shot/singletask-emo
05/21/2022 21:26:59 - INFO - __main__ - Namespace(task_dir='data/emo/', task_name='emo', identifier='T5-large-multitask-cls2cls-5e-1-4-20-up32shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-multitask-cls2cls-5e-1-4-20-up32shot/singletask-emo', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-multitask-cls2cls-5e-1-4-20-32shot/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='4,5')
05/21/2022 21:26:59 - INFO - __main__ - models/T5-large-multitask-cls2cls-5e-1-4-20-up32shot/singletask-emo
05/21/2022 21:27:00 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
05/21/2022 21:27:01 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
05/21/2022 21:27:01 - INFO - __main__ - args.device: cuda:0
05/21/2022 21:27:01 - INFO - __main__ - Using 2 gpus
05/21/2022 21:27:01 - INFO - __main__ - args.device: cuda:1
05/21/2022 21:27:01 - INFO - __main__ - Using 2 gpus
05/21/2022 21:27:01 - INFO - __main__ - Fine-tuning the following samples: ['emo_16_100', 'emo_16_13', 'emo_16_21', 'emo_16_42', 'emo_16_87']
05/21/2022 21:27:01 - INFO - __main__ - Fine-tuning the following samples: ['emo_16_100', 'emo_16_13', 'emo_16_21', 'emo_16_42', 'emo_16_87']
05/21/2022 21:27:06 - INFO - __main__ - Running ... prefix=emo_16_100, lr=0.5, bsz=8 ...
06/01/2022 01:16:59 - INFO - __main__ - Namespace(task_dir='data/emo/', task_name='emo', identifier='T5-large-multitask-cls2cls-5e-1-4-20-up32shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-multitask-cls2cls-5e-1-4-20-up32shot/singletask-emo', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-multitask-cls2cls-5e-1-4-20-32shot/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='4,5')
06/01/2022 01:16:59 - INFO - __main__ - models/T5-large-multitask-cls2cls-5e-1-4-20-up32shot/singletask-emo
06/01/2022 01:16:59 - INFO - __main__ - Namespace(task_dir='data/emo/', task_name='emo', identifier='T5-large-multitask-cls2cls-5e-1-4-20-up32shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-multitask-cls2cls-5e-1-4-20-up32shot/singletask-emo', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-multitask-cls2cls-5e-1-4-20-32shot/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='4,5')
06/01/2022 01:16:59 - INFO - __main__ - models/T5-large-multitask-cls2cls-5e-1-4-20-up32shot/singletask-emo
06/01/2022 01:17:00 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
06/01/2022 01:17:00 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
06/01/2022 01:17:00 - INFO - __main__ - args.device: cuda:0
06/01/2022 01:17:00 - INFO - __main__ - Using 2 gpus
06/01/2022 01:17:00 - INFO - __main__ - args.device: cuda:1
06/01/2022 01:17:00 - INFO - __main__ - Using 2 gpus
06/01/2022 01:17:00 - INFO - __main__ - Fine-tuning the following samples: ['emo_16_100', 'emo_16_13', 'emo_16_21', 'emo_16_42', 'emo_16_87']
06/01/2022 01:17:00 - INFO - __main__ - Fine-tuning the following samples: ['emo_16_100', 'emo_16_13', 'emo_16_21', 'emo_16_42', 'emo_16_87']
06/01/2022 01:17:05 - INFO - __main__ - Running ... prefix=emo_16_100, lr=0.5, bsz=8 ...
06/01/2022 01:17:06 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 01:17:06 - INFO - __main__ - Printing 3 examples
06/01/2022 01:17:06 - INFO - __main__ -  [emo] how cause yes am listening
06/01/2022 01:17:06 - INFO - __main__ - ['others']
06/01/2022 01:17:06 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/01/2022 01:17:06 - INFO - __main__ - ['others']
06/01/2022 01:17:06 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/01/2022 01:17:06 - INFO - __main__ - ['others']
06/01/2022 01:17:06 - INFO - __main__ - Tokenizing Input ...
06/01/2022 01:17:06 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 01:17:06 - INFO - __main__ - Printing 3 examples
06/01/2022 01:17:06 - INFO - __main__ -  [emo] how cause yes am listening
06/01/2022 01:17:06 - INFO - __main__ - ['others']
06/01/2022 01:17:06 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/01/2022 01:17:06 - INFO - __main__ - ['others']
06/01/2022 01:17:06 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/01/2022 01:17:06 - INFO - __main__ - ['others']
06/01/2022 01:17:06 - INFO - __main__ - Tokenizing Input ...
06/01/2022 01:17:06 - INFO - __main__ - Tokenizing Output ...
06/01/2022 01:17:06 - INFO - __main__ - Tokenizing Output ...
06/01/2022 01:17:06 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 01:17:06 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 01:17:06 - INFO - __main__ - Printing 3 examples
06/01/2022 01:17:06 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
06/01/2022 01:17:06 - INFO - __main__ - ['others']
06/01/2022 01:17:06 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
06/01/2022 01:17:06 - INFO - __main__ - ['others']
06/01/2022 01:17:06 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
06/01/2022 01:17:06 - INFO - __main__ - ['others']
06/01/2022 01:17:06 - INFO - __main__ - Tokenizing Input ...
06/01/2022 01:17:06 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 01:17:06 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 01:17:06 - INFO - __main__ - Printing 3 examples
06/01/2022 01:17:06 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
06/01/2022 01:17:06 - INFO - __main__ - ['others']
06/01/2022 01:17:06 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
06/01/2022 01:17:06 - INFO - __main__ - ['others']
06/01/2022 01:17:06 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
06/01/2022 01:17:06 - INFO - __main__ - ['others']
06/01/2022 01:17:06 - INFO - __main__ - Tokenizing Input ...
06/01/2022 01:17:06 - INFO - __main__ - Tokenizing Output ...
06/01/2022 01:17:06 - INFO - __main__ - Tokenizing Output ...
06/01/2022 01:17:06 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 01:17:06 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 01:17:24 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 01:17:24 - INFO - __main__ - load prompt embedding from ckpt
06/10/2022 15:03:15 - INFO - __main__ - Namespace(task_dir='data/emo/', task_name='emo', identifier='T5-large-multitask-cls2cls-5e-1-4-20-up32shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-multitask-cls2cls-5e-1-4-20-up32shot/singletask-emo', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-multitask-cls2cls-5e-1-4-20-32shot/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='4,5')
06/10/2022 15:03:15 - INFO - __main__ - models/T5-large-multitask-cls2cls-5e-1-4-20-up32shot/singletask-emo
06/10/2022 15:03:15 - INFO - __main__ - Namespace(task_dir='data/emo/', task_name='emo', identifier='T5-large-multitask-cls2cls-5e-1-4-20-up32shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-multitask-cls2cls-5e-1-4-20-up32shot/singletask-emo', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-multitask-cls2cls-5e-1-4-20-32shot/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='4,5')
06/10/2022 15:03:15 - INFO - __main__ - models/T5-large-multitask-cls2cls-5e-1-4-20-up32shot/singletask-emo
06/10/2022 15:03:15 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
06/10/2022 15:03:15 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
06/10/2022 15:03:15 - INFO - __main__ - args.device: cuda:0
06/10/2022 15:03:15 - INFO - __main__ - args.device: cuda:1
06/10/2022 15:03:15 - INFO - __main__ - Using 2 gpus
06/10/2022 15:03:15 - INFO - __main__ - Using 2 gpus
06/10/2022 15:03:16 - INFO - __main__ - Fine-tuning the following samples: ['emo_16_100', 'emo_16_13', 'emo_16_21', 'emo_16_42', 'emo_16_87']
06/10/2022 15:03:16 - INFO - __main__ - Fine-tuning the following samples: ['emo_16_100', 'emo_16_13', 'emo_16_21', 'emo_16_42', 'emo_16_87']
06/10/2022 15:03:20 - INFO - __main__ - Running ... prefix=emo_16_100, lr=0.5, bsz=8 ...
06/10/2022 15:03:21 - INFO - __main__ - Start tokenizing ... 64 instances
06/10/2022 15:03:21 - INFO - __main__ - Printing 3 examples
06/10/2022 15:03:21 - INFO - __main__ -  [emo] how cause yes am listening
06/10/2022 15:03:21 - INFO - __main__ - ['others']
06/10/2022 15:03:21 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/10/2022 15:03:21 - INFO - __main__ - ['others']
06/10/2022 15:03:21 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/10/2022 15:03:21 - INFO - __main__ - ['others']
06/10/2022 15:03:21 - INFO - __main__ - Tokenizing Input ...
06/10/2022 15:03:21 - INFO - __main__ - Start tokenizing ... 64 instances
06/10/2022 15:03:21 - INFO - __main__ - Printing 3 examples
06/10/2022 15:03:21 - INFO - __main__ -  [emo] how cause yes am listening
06/10/2022 15:03:21 - INFO - __main__ - ['others']
06/10/2022 15:03:21 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/10/2022 15:03:21 - INFO - __main__ - ['others']
06/10/2022 15:03:21 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/10/2022 15:03:21 - INFO - __main__ - ['others']
06/10/2022 15:03:21 - INFO - __main__ - Tokenizing Input ...
06/10/2022 15:03:21 - INFO - __main__ - Tokenizing Output ...
06/10/2022 15:03:21 - INFO - __main__ - Tokenizing Output ...
06/10/2022 15:03:21 - INFO - __main__ - Loaded 64 examples from train data
06/10/2022 15:03:21 - INFO - __main__ - Start tokenizing ... 64 instances
06/10/2022 15:03:21 - INFO - __main__ - Printing 3 examples
06/10/2022 15:03:21 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
06/10/2022 15:03:21 - INFO - __main__ - ['others']
06/10/2022 15:03:21 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
06/10/2022 15:03:21 - INFO - __main__ - ['others']
06/10/2022 15:03:21 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
06/10/2022 15:03:21 - INFO - __main__ - Loaded 64 examples from train data
06/10/2022 15:03:21 - INFO - __main__ - ['others']
06/10/2022 15:03:21 - INFO - __main__ - Tokenizing Input ...
06/10/2022 15:03:21 - INFO - __main__ - Start tokenizing ... 64 instances
06/10/2022 15:03:21 - INFO - __main__ - Printing 3 examples
06/10/2022 15:03:21 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
06/10/2022 15:03:21 - INFO - __main__ - ['others']
06/10/2022 15:03:21 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
06/10/2022 15:03:21 - INFO - __main__ - ['others']
06/10/2022 15:03:21 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
06/10/2022 15:03:21 - INFO - __main__ - ['others']
06/10/2022 15:03:21 - INFO - __main__ - Tokenizing Input ...
06/10/2022 15:03:21 - INFO - __main__ - Tokenizing Output ...
06/10/2022 15:03:21 - INFO - __main__ - Tokenizing Output ...
06/10/2022 15:03:21 - INFO - __main__ - Loaded 64 examples from dev data
06/10/2022 15:03:21 - INFO - __main__ - Loaded 64 examples from dev data
06/10/2022 15:03:39 - INFO - __main__ - load prompt embedding from ckpt
06/10/2022 15:03:39 - INFO - __main__ - load prompt embedding from ckpt
06/10/2022 15:03:40 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/10/2022 15:03:40 - INFO - __main__ - Starting training!
06/10/2022 15:03:45 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/10/2022 15:03:45 - INFO - __main__ - Starting training!
06/10/2022 15:03:48 - INFO - __main__ - Step 10 Global step 10 Train loss 3.62 on epoch=2
06/10/2022 15:03:51 - INFO - __main__ - Step 20 Global step 20 Train loss 2.33 on epoch=4
06/10/2022 15:03:53 - INFO - __main__ - Step 30 Global step 30 Train loss 1.80 on epoch=7
06/10/2022 15:03:55 - INFO - __main__ - Step 40 Global step 40 Train loss 1.33 on epoch=9
06/10/2022 15:03:58 - INFO - __main__ - Step 50 Global step 50 Train loss 1.21 on epoch=12
06/10/2022 15:03:59 - INFO - __main__ - Global step 50 Train loss 2.06 Classification-F1 0.3128654970760234 on epoch=12
06/10/2022 15:03:59 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.3128654970760234 on epoch=12, global_step=50
06/10/2022 15:04:01 - INFO - __main__ - Step 60 Global step 60 Train loss 0.85 on epoch=14
06/10/2022 15:04:03 - INFO - __main__ - Step 70 Global step 70 Train loss 0.87 on epoch=17
06/10/2022 15:04:06 - INFO - __main__ - Step 80 Global step 80 Train loss 0.90 on epoch=19
06/10/2022 15:04:08 - INFO - __main__ - Step 90 Global step 90 Train loss 0.76 on epoch=22
06/10/2022 15:04:10 - INFO - __main__ - Step 100 Global step 100 Train loss 0.83 on epoch=24
06/10/2022 15:04:11 - INFO - __main__ - Global step 100 Train loss 0.84 Classification-F1 0.5182555091283407 on epoch=24
06/10/2022 15:04:11 - INFO - __main__ - Saving model with best Classification-F1: 0.3128654970760234 -> 0.5182555091283407 on epoch=24, global_step=100
06/10/2022 15:04:14 - INFO - __main__ - Step 110 Global step 110 Train loss 0.67 on epoch=27
06/10/2022 15:04:16 - INFO - __main__ - Step 120 Global step 120 Train loss 0.72 on epoch=29
06/10/2022 15:04:18 - INFO - __main__ - Step 130 Global step 130 Train loss 0.65 on epoch=32
06/10/2022 15:04:21 - INFO - __main__ - Step 140 Global step 140 Train loss 0.69 on epoch=34
06/10/2022 15:04:23 - INFO - __main__ - Step 150 Global step 150 Train loss 0.59 on epoch=37
06/10/2022 15:04:24 - INFO - __main__ - Global step 150 Train loss 0.67 Classification-F1 0.5831890331890333 on epoch=37
06/10/2022 15:04:24 - INFO - __main__ - Saving model with best Classification-F1: 0.5182555091283407 -> 0.5831890331890333 on epoch=37, global_step=150
06/10/2022 15:04:26 - INFO - __main__ - Step 160 Global step 160 Train loss 0.62 on epoch=39
06/10/2022 15:04:29 - INFO - __main__ - Step 170 Global step 170 Train loss 0.60 on epoch=42
06/10/2022 15:04:31 - INFO - __main__ - Step 180 Global step 180 Train loss 0.62 on epoch=44
06/10/2022 15:04:33 - INFO - __main__ - Step 190 Global step 190 Train loss 0.57 on epoch=47
06/10/2022 15:04:36 - INFO - __main__ - Step 200 Global step 200 Train loss 0.46 on epoch=49
06/10/2022 15:04:37 - INFO - __main__ - Global step 200 Train loss 0.57 Classification-F1 0.5961188867438867 on epoch=49
06/10/2022 15:04:37 - INFO - __main__ - Saving model with best Classification-F1: 0.5831890331890333 -> 0.5961188867438867 on epoch=49, global_step=200
06/10/2022 15:04:39 - INFO - __main__ - Step 210 Global step 210 Train loss 0.60 on epoch=52
06/10/2022 15:04:41 - INFO - __main__ - Step 220 Global step 220 Train loss 0.50 on epoch=54
06/10/2022 15:04:44 - INFO - __main__ - Step 230 Global step 230 Train loss 0.52 on epoch=57
06/10/2022 15:04:46 - INFO - __main__ - Step 240 Global step 240 Train loss 0.52 on epoch=59
06/10/2022 15:04:48 - INFO - __main__ - Step 250 Global step 250 Train loss 0.46 on epoch=62
06/10/2022 15:04:49 - INFO - __main__ - Global step 250 Train loss 0.52 Classification-F1 0.6094660837307897 on epoch=62
06/10/2022 15:04:49 - INFO - __main__ - Saving model with best Classification-F1: 0.5961188867438867 -> 0.6094660837307897 on epoch=62, global_step=250
06/10/2022 15:04:52 - INFO - __main__ - Step 260 Global step 260 Train loss 0.47 on epoch=64
06/10/2022 15:04:54 - INFO - __main__ - Step 270 Global step 270 Train loss 0.43 on epoch=67
06/10/2022 15:04:56 - INFO - __main__ - Step 280 Global step 280 Train loss 0.42 on epoch=69
06/10/2022 15:04:59 - INFO - __main__ - Step 290 Global step 290 Train loss 0.45 on epoch=72
06/10/2022 15:05:01 - INFO - __main__ - Step 300 Global step 300 Train loss 0.47 on epoch=74
06/10/2022 15:05:02 - INFO - __main__ - Global step 300 Train loss 0.45 Classification-F1 0.6495098039215687 on epoch=74
06/10/2022 15:05:02 - INFO - __main__ - Saving model with best Classification-F1: 0.6094660837307897 -> 0.6495098039215687 on epoch=74, global_step=300
06/10/2022 15:05:04 - INFO - __main__ - Step 310 Global step 310 Train loss 0.44 on epoch=77
06/10/2022 15:05:06 - INFO - __main__ - Step 320 Global step 320 Train loss 0.32 on epoch=79
06/10/2022 15:05:09 - INFO - __main__ - Step 330 Global step 330 Train loss 0.46 on epoch=82
06/10/2022 15:05:11 - INFO - __main__ - Step 340 Global step 340 Train loss 0.43 on epoch=84
06/10/2022 15:05:13 - INFO - __main__ - Step 350 Global step 350 Train loss 0.42 on epoch=87
06/10/2022 15:05:14 - INFO - __main__ - Global step 350 Train loss 0.41 Classification-F1 0.6400913187855788 on epoch=87
06/10/2022 15:05:17 - INFO - __main__ - Step 360 Global step 360 Train loss 0.30 on epoch=89
06/10/2022 15:05:19 - INFO - __main__ - Step 370 Global step 370 Train loss 0.38 on epoch=92
06/10/2022 15:05:21 - INFO - __main__ - Step 380 Global step 380 Train loss 0.38 on epoch=94
06/10/2022 15:05:24 - INFO - __main__ - Step 390 Global step 390 Train loss 0.31 on epoch=97
06/10/2022 15:05:26 - INFO - __main__ - Step 400 Global step 400 Train loss 0.30 on epoch=99
06/10/2022 15:05:27 - INFO - __main__ - Global step 400 Train loss 0.33 Classification-F1 0.6146236559139784 on epoch=99
06/10/2022 15:05:29 - INFO - __main__ - Step 410 Global step 410 Train loss 0.30 on epoch=102
06/10/2022 15:05:31 - INFO - __main__ - Step 420 Global step 420 Train loss 0.32 on epoch=104
06/10/2022 15:05:34 - INFO - __main__ - Step 430 Global step 430 Train loss 0.30 on epoch=107
06/10/2022 15:05:36 - INFO - __main__ - Step 440 Global step 440 Train loss 0.31 on epoch=109
06/10/2022 15:05:38 - INFO - __main__ - Step 450 Global step 450 Train loss 0.25 on epoch=112
06/10/2022 15:05:39 - INFO - __main__ - Global step 450 Train loss 0.30 Classification-F1 0.7022129416282642 on epoch=112
06/10/2022 15:05:39 - INFO - __main__ - Saving model with best Classification-F1: 0.6495098039215687 -> 0.7022129416282642 on epoch=112, global_step=450
06/10/2022 15:05:42 - INFO - __main__ - Step 460 Global step 460 Train loss 0.32 on epoch=114
06/10/2022 15:05:44 - INFO - __main__ - Step 470 Global step 470 Train loss 0.30 on epoch=117
06/10/2022 15:05:46 - INFO - __main__ - Step 480 Global step 480 Train loss 0.22 on epoch=119
06/10/2022 15:05:49 - INFO - __main__ - Step 490 Global step 490 Train loss 0.21 on epoch=122
06/10/2022 15:05:51 - INFO - __main__ - Step 500 Global step 500 Train loss 0.24 on epoch=124
06/10/2022 15:05:52 - INFO - __main__ - Global step 500 Train loss 0.26 Classification-F1 0.6992845117845118 on epoch=124
06/10/2022 15:05:54 - INFO - __main__ - Step 510 Global step 510 Train loss 0.20 on epoch=127
06/10/2022 15:05:56 - INFO - __main__ - Step 520 Global step 520 Train loss 0.22 on epoch=129
06/10/2022 15:05:59 - INFO - __main__ - Step 530 Global step 530 Train loss 0.25 on epoch=132
06/10/2022 15:06:01 - INFO - __main__ - Step 540 Global step 540 Train loss 0.19 on epoch=134
06/10/2022 15:06:03 - INFO - __main__ - Step 550 Global step 550 Train loss 0.19 on epoch=137
06/10/2022 15:06:04 - INFO - __main__ - Global step 550 Train loss 0.21 Classification-F1 0.6859848484848484 on epoch=137
06/10/2022 15:06:07 - INFO - __main__ - Step 560 Global step 560 Train loss 0.21 on epoch=139
06/10/2022 15:06:09 - INFO - __main__ - Step 570 Global step 570 Train loss 0.21 on epoch=142
06/10/2022 15:06:11 - INFO - __main__ - Step 580 Global step 580 Train loss 0.19 on epoch=144
06/10/2022 15:06:14 - INFO - __main__ - Step 590 Global step 590 Train loss 0.13 on epoch=147
06/10/2022 15:06:16 - INFO - __main__ - Step 600 Global step 600 Train loss 0.15 on epoch=149
06/10/2022 15:06:17 - INFO - __main__ - Global step 600 Train loss 0.18 Classification-F1 0.6279185520361992 on epoch=149
06/10/2022 15:06:19 - INFO - __main__ - Step 610 Global step 610 Train loss 0.12 on epoch=152
06/10/2022 15:06:22 - INFO - __main__ - Step 620 Global step 620 Train loss 0.17 on epoch=154
06/10/2022 15:06:24 - INFO - __main__ - Step 630 Global step 630 Train loss 0.22 on epoch=157
06/10/2022 15:06:26 - INFO - __main__ - Step 640 Global step 640 Train loss 0.16 on epoch=159
06/10/2022 15:06:28 - INFO - __main__ - Step 650 Global step 650 Train loss 0.17 on epoch=162
06/10/2022 15:06:29 - INFO - __main__ - Global step 650 Train loss 0.17 Classification-F1 0.6493125986026594 on epoch=162
06/10/2022 15:06:32 - INFO - __main__ - Step 660 Global step 660 Train loss 0.10 on epoch=164
06/10/2022 15:06:34 - INFO - __main__ - Step 670 Global step 670 Train loss 0.14 on epoch=167
06/10/2022 15:06:36 - INFO - __main__ - Step 680 Global step 680 Train loss 0.19 on epoch=169
06/10/2022 15:06:39 - INFO - __main__ - Step 690 Global step 690 Train loss 0.13 on epoch=172
06/10/2022 15:06:41 - INFO - __main__ - Step 700 Global step 700 Train loss 0.10 on epoch=174
06/10/2022 15:06:42 - INFO - __main__ - Global step 700 Train loss 0.13 Classification-F1 0.6749593543711191 on epoch=174
06/10/2022 15:06:44 - INFO - __main__ - Step 710 Global step 710 Train loss 0.09 on epoch=177
06/10/2022 15:06:47 - INFO - __main__ - Step 720 Global step 720 Train loss 0.17 on epoch=179
06/10/2022 15:06:49 - INFO - __main__ - Step 730 Global step 730 Train loss 0.09 on epoch=182
06/10/2022 15:06:51 - INFO - __main__ - Step 740 Global step 740 Train loss 0.14 on epoch=184
06/10/2022 15:06:54 - INFO - __main__ - Step 750 Global step 750 Train loss 0.08 on epoch=187
06/10/2022 15:06:55 - INFO - __main__ - Global step 750 Train loss 0.11 Classification-F1 0.6887017231134879 on epoch=187
06/10/2022 15:06:57 - INFO - __main__ - Step 760 Global step 760 Train loss 0.09 on epoch=189
06/10/2022 15:06:59 - INFO - __main__ - Step 770 Global step 770 Train loss 0.11 on epoch=192
06/10/2022 15:07:02 - INFO - __main__ - Step 780 Global step 780 Train loss 0.09 on epoch=194
06/10/2022 15:07:04 - INFO - __main__ - Step 790 Global step 790 Train loss 0.04 on epoch=197
06/10/2022 15:07:06 - INFO - __main__ - Step 800 Global step 800 Train loss 0.05 on epoch=199
06/10/2022 15:07:07 - INFO - __main__ - Global step 800 Train loss 0.08 Classification-F1 0.7314047835738604 on epoch=199
06/10/2022 15:07:07 - INFO - __main__ - Saving model with best Classification-F1: 0.7022129416282642 -> 0.7314047835738604 on epoch=199, global_step=800
06/10/2022 15:07:10 - INFO - __main__ - Step 810 Global step 810 Train loss 0.05 on epoch=202
06/10/2022 15:07:12 - INFO - __main__ - Step 820 Global step 820 Train loss 0.04 on epoch=204
06/10/2022 15:07:14 - INFO - __main__ - Step 830 Global step 830 Train loss 0.04 on epoch=207
06/10/2022 15:07:17 - INFO - __main__ - Step 840 Global step 840 Train loss 0.10 on epoch=209
06/10/2022 15:07:19 - INFO - __main__ - Step 850 Global step 850 Train loss 0.05 on epoch=212
06/10/2022 15:07:20 - INFO - __main__ - Global step 850 Train loss 0.06 Classification-F1 0.7231285831285832 on epoch=212
06/10/2022 15:07:22 - INFO - __main__ - Step 860 Global step 860 Train loss 0.08 on epoch=214
06/10/2022 15:07:25 - INFO - __main__ - Step 870 Global step 870 Train loss 0.04 on epoch=217
06/10/2022 15:07:27 - INFO - __main__ - Step 880 Global step 880 Train loss 0.05 on epoch=219
06/10/2022 15:07:29 - INFO - __main__ - Step 890 Global step 890 Train loss 0.05 on epoch=222
06/10/2022 15:07:32 - INFO - __main__ - Step 900 Global step 900 Train loss 0.05 on epoch=224
06/10/2022 15:07:32 - INFO - __main__ - Global step 900 Train loss 0.05 Classification-F1 0.7959051724137931 on epoch=224
06/10/2022 15:07:32 - INFO - __main__ - Saving model with best Classification-F1: 0.7314047835738604 -> 0.7959051724137931 on epoch=224, global_step=900
06/10/2022 15:07:35 - INFO - __main__ - Step 910 Global step 910 Train loss 0.06 on epoch=227
06/10/2022 15:07:37 - INFO - __main__ - Step 920 Global step 920 Train loss 0.05 on epoch=229
06/10/2022 15:07:39 - INFO - __main__ - Step 930 Global step 930 Train loss 0.12 on epoch=232
06/10/2022 15:07:42 - INFO - __main__ - Step 940 Global step 940 Train loss 0.08 on epoch=234
06/10/2022 15:07:44 - INFO - __main__ - Step 950 Global step 950 Train loss 0.13 on epoch=237
06/10/2022 15:07:45 - INFO - __main__ - Global step 950 Train loss 0.09 Classification-F1 0.7165936687675818 on epoch=237
06/10/2022 15:07:47 - INFO - __main__ - Step 960 Global step 960 Train loss 0.08 on epoch=239
06/10/2022 15:07:50 - INFO - __main__ - Step 970 Global step 970 Train loss 0.07 on epoch=242
06/10/2022 15:07:52 - INFO - __main__ - Step 980 Global step 980 Train loss 0.01 on epoch=244
06/10/2022 15:07:54 - INFO - __main__ - Step 990 Global step 990 Train loss 0.03 on epoch=247
06/10/2022 15:07:57 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.13 on epoch=249
06/10/2022 15:07:58 - INFO - __main__ - Global step 1000 Train loss 0.06 Classification-F1 0.7524551971326165 on epoch=249
06/10/2022 15:08:00 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.05 on epoch=252
06/10/2022 15:08:02 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.04 on epoch=254
06/10/2022 15:08:05 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.05 on epoch=257
06/10/2022 15:08:07 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.02 on epoch=259
06/10/2022 15:08:09 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.05 on epoch=262
06/10/2022 15:08:10 - INFO - __main__ - Global step 1050 Train loss 0.04 Classification-F1 0.7462902453343221 on epoch=262
06/10/2022 15:08:12 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.08 on epoch=264
06/10/2022 15:08:15 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.03 on epoch=267
06/10/2022 15:08:17 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.07 on epoch=269
06/10/2022 15:08:19 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.03 on epoch=272
06/10/2022 15:08:22 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.05 on epoch=274
06/10/2022 15:08:23 - INFO - __main__ - Global step 1100 Train loss 0.05 Classification-F1 0.7788952745849298 on epoch=274
06/10/2022 15:08:25 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.02 on epoch=277
06/10/2022 15:08:27 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.04 on epoch=279
06/10/2022 15:08:30 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.07 on epoch=282
06/10/2022 15:08:32 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.04 on epoch=284
06/10/2022 15:08:34 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.03 on epoch=287
06/10/2022 15:08:35 - INFO - __main__ - Global step 1150 Train loss 0.04 Classification-F1 0.7572979512317748 on epoch=287
06/10/2022 15:08:37 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.02 on epoch=289
06/10/2022 15:08:40 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.01 on epoch=292
06/10/2022 15:08:42 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.03 on epoch=294
06/10/2022 15:08:44 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.02 on epoch=297
06/10/2022 15:08:47 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.08 on epoch=299
06/10/2022 15:08:47 - INFO - __main__ - Global step 1200 Train loss 0.03 Classification-F1 0.7523801220575415 on epoch=299
06/10/2022 15:08:50 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.05 on epoch=302
06/10/2022 15:08:52 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=304
06/10/2022 15:08:54 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=307
06/10/2022 15:08:57 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.08 on epoch=309
06/10/2022 15:08:59 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.04 on epoch=312
06/10/2022 15:09:00 - INFO - __main__ - Global step 1250 Train loss 0.04 Classification-F1 0.7578388047138047 on epoch=312
06/10/2022 15:09:02 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.05 on epoch=314
06/10/2022 15:09:05 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.01 on epoch=317
06/10/2022 15:09:07 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=319
06/10/2022 15:09:09 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.03 on epoch=322
06/10/2022 15:09:12 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=324
06/10/2022 15:09:12 - INFO - __main__ - Global step 1300 Train loss 0.02 Classification-F1 0.7375694444444444 on epoch=324
06/10/2022 15:09:15 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.08 on epoch=327
06/10/2022 15:09:17 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.04 on epoch=329
06/10/2022 15:09:19 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=332
06/10/2022 15:09:22 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.03 on epoch=334
06/10/2022 15:09:24 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.02 on epoch=337
06/10/2022 15:09:25 - INFO - __main__ - Global step 1350 Train loss 0.04 Classification-F1 0.7381719772611613 on epoch=337
06/10/2022 15:09:27 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.08 on epoch=339
06/10/2022 15:09:30 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=342
06/10/2022 15:09:32 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.03 on epoch=344
06/10/2022 15:09:34 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.03 on epoch=347
06/10/2022 15:09:37 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.09 on epoch=349
06/10/2022 15:09:37 - INFO - __main__ - Global step 1400 Train loss 0.05 Classification-F1 0.716812865497076 on epoch=349
06/10/2022 15:09:40 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=352
06/10/2022 15:09:42 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=354
06/10/2022 15:09:44 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.07 on epoch=357
06/10/2022 15:09:47 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.04 on epoch=359
06/10/2022 15:09:49 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=362
06/10/2022 15:09:50 - INFO - __main__ - Global step 1450 Train loss 0.03 Classification-F1 0.6812950937950939 on epoch=362
06/10/2022 15:09:52 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=364
06/10/2022 15:09:55 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=367
06/10/2022 15:09:57 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.07 on epoch=369
06/10/2022 15:09:59 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=372
06/10/2022 15:10:02 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.02 on epoch=374
06/10/2022 15:10:02 - INFO - __main__ - Global step 1500 Train loss 0.02 Classification-F1 0.7109169311778746 on epoch=374
06/10/2022 15:10:05 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=377
06/10/2022 15:10:07 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.03 on epoch=379
06/10/2022 15:10:09 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.16 on epoch=382
06/10/2022 15:10:12 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=384
06/10/2022 15:10:14 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=387
06/10/2022 15:10:15 - INFO - __main__ - Global step 1550 Train loss 0.05 Classification-F1 0.7773809523809523 on epoch=387
06/10/2022 15:10:17 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.02 on epoch=389
06/10/2022 15:10:20 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.03 on epoch=392
06/10/2022 15:10:22 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=394
06/10/2022 15:10:24 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=397
06/10/2022 15:10:27 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=399
06/10/2022 15:10:28 - INFO - __main__ - Global step 1600 Train loss 0.01 Classification-F1 0.7100060534843143 on epoch=399
06/10/2022 15:10:30 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=402
06/10/2022 15:10:32 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=404
06/10/2022 15:10:35 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.05 on epoch=407
06/10/2022 15:10:37 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.04 on epoch=409
06/10/2022 15:10:39 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=412
06/10/2022 15:10:40 - INFO - __main__ - Global step 1650 Train loss 0.03 Classification-F1 0.722296494355318 on epoch=412
06/10/2022 15:10:43 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=414
06/10/2022 15:10:45 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=417
06/10/2022 15:10:47 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=419
06/10/2022 15:10:50 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=422
06/10/2022 15:10:52 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=424
06/10/2022 15:10:53 - INFO - __main__ - Global step 1700 Train loss 0.00 Classification-F1 0.722904722904723 on epoch=424
06/10/2022 15:10:55 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=427
06/10/2022 15:10:57 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=429
06/10/2022 15:11:00 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=432
06/10/2022 15:11:02 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=434
06/10/2022 15:11:05 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=437
06/10/2022 15:11:05 - INFO - __main__ - Global step 1750 Train loss 0.01 Classification-F1 0.722296494355318 on epoch=437
06/10/2022 15:11:08 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=439
06/10/2022 15:11:10 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=442
06/10/2022 15:11:13 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=444
06/10/2022 15:11:15 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=447
06/10/2022 15:11:17 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=449
06/10/2022 15:11:18 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.6991721728563833 on epoch=449
06/10/2022 15:11:21 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=452
06/10/2022 15:11:23 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.05 on epoch=454
06/10/2022 15:11:25 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=457
06/10/2022 15:11:28 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=459
06/10/2022 15:11:30 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=462
06/10/2022 15:11:31 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.6847540818129053 on epoch=462
06/10/2022 15:11:33 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.03 on epoch=464
06/10/2022 15:11:35 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=467
06/10/2022 15:11:38 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=469
06/10/2022 15:11:40 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=472
06/10/2022 15:11:43 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=474
06/10/2022 15:11:43 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.7185663082437276 on epoch=474
06/10/2022 15:11:46 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=477
06/10/2022 15:11:48 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=479
06/10/2022 15:11:50 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=482
06/10/2022 15:11:53 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=484
06/10/2022 15:11:55 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=487
06/10/2022 15:11:56 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.671067821067821 on epoch=487
06/10/2022 15:11:58 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=489
06/10/2022 15:12:01 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=492
06/10/2022 15:12:03 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=494
06/10/2022 15:12:05 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.04 on epoch=497
06/10/2022 15:12:08 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=499
06/10/2022 15:12:09 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.6974777196551389 on epoch=499
06/10/2022 15:12:11 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=502
06/10/2022 15:12:13 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.04 on epoch=504
06/10/2022 15:12:16 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/10/2022 15:12:18 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.03 on epoch=509
06/10/2022 15:12:20 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.04 on epoch=512
06/10/2022 15:12:21 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.6724124692874692 on epoch=512
06/10/2022 15:12:24 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.02 on epoch=514
06/10/2022 15:12:26 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=517
06/10/2022 15:12:28 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=519
06/10/2022 15:12:31 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/10/2022 15:12:33 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.04 on epoch=524
06/10/2022 15:12:34 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.725145569973156 on epoch=524
06/10/2022 15:12:36 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=527
06/10/2022 15:12:39 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/10/2022 15:12:41 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/10/2022 15:12:43 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
06/10/2022 15:12:46 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=537
06/10/2022 15:12:47 - INFO - __main__ - Global step 2150 Train loss 0.00 Classification-F1 0.7387372484146677 on epoch=537
06/10/2022 15:12:49 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/10/2022 15:12:51 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=542
06/10/2022 15:12:54 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/10/2022 15:12:56 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=547
06/10/2022 15:12:58 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/10/2022 15:12:59 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.781143951833607 on epoch=549
06/10/2022 15:13:02 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=552
06/10/2022 15:13:04 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/10/2022 15:13:06 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.03 on epoch=557
06/10/2022 15:13:09 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=559
06/10/2022 15:13:11 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=562
06/10/2022 15:13:12 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.7453337725076855 on epoch=562
06/10/2022 15:13:14 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.05 on epoch=564
06/10/2022 15:13:17 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=567
06/10/2022 15:13:19 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/10/2022 15:13:21 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/10/2022 15:13:24 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/10/2022 15:13:25 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.7578255675029868 on epoch=574
06/10/2022 15:13:27 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/10/2022 15:13:29 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=579
06/10/2022 15:13:32 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/10/2022 15:13:34 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/10/2022 15:13:36 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/10/2022 15:13:37 - INFO - __main__ - Global step 2350 Train loss 0.00 Classification-F1 0.7592592592592592 on epoch=587
06/10/2022 15:13:40 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=589
06/10/2022 15:13:42 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/10/2022 15:13:44 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.04 on epoch=594
06/10/2022 15:13:47 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/10/2022 15:13:49 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=599
06/10/2022 15:13:50 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.7773809523809523 on epoch=599
06/10/2022 15:13:52 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/10/2022 15:13:55 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/10/2022 15:13:57 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=607
06/10/2022 15:13:59 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=609
06/10/2022 15:14:02 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/10/2022 15:14:03 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.7638888888888888 on epoch=612
06/10/2022 15:14:05 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.02 on epoch=614
06/10/2022 15:14:08 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/10/2022 15:14:10 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=619
06/10/2022 15:14:12 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/10/2022 15:14:15 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=624
06/10/2022 15:14:16 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.8133536173089926 on epoch=624
06/10/2022 15:14:16 - INFO - __main__ - Saving model with best Classification-F1: 0.7959051724137931 -> 0.8133536173089926 on epoch=624, global_step=2500
06/10/2022 15:14:18 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.07 on epoch=627
06/10/2022 15:14:20 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=629
06/10/2022 15:14:23 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/10/2022 15:14:25 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=634
06/10/2022 15:14:27 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/10/2022 15:14:28 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.7459945549047109 on epoch=637
06/10/2022 15:14:31 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/10/2022 15:14:33 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=642
06/10/2022 15:14:35 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.03 on epoch=644
06/10/2022 15:14:38 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/10/2022 15:14:40 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/10/2022 15:14:41 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.7425925925925925 on epoch=649
06/10/2022 15:14:44 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.04 on epoch=652
06/10/2022 15:14:46 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/10/2022 15:14:48 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/10/2022 15:14:51 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/10/2022 15:14:53 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/10/2022 15:14:54 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.757968017645437 on epoch=662
06/10/2022 15:14:57 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/10/2022 15:14:59 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/10/2022 15:15:01 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=669
06/10/2022 15:15:04 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=672
06/10/2022 15:15:06 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/10/2022 15:15:07 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.7952790682457633 on epoch=674
06/10/2022 15:15:09 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/10/2022 15:15:12 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/10/2022 15:15:14 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/10/2022 15:15:17 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/10/2022 15:15:19 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/10/2022 15:15:20 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.7531944444444444 on epoch=687
06/10/2022 15:15:22 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=689
06/10/2022 15:15:25 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/10/2022 15:15:27 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=694
06/10/2022 15:15:29 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=697
06/10/2022 15:15:32 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=699
06/10/2022 15:15:33 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.7665732959850606 on epoch=699
06/10/2022 15:15:35 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.04 on epoch=702
06/10/2022 15:15:37 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/10/2022 15:15:40 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/10/2022 15:15:42 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.03 on epoch=709
06/10/2022 15:15:45 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/10/2022 15:15:46 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.7776972079154242 on epoch=712
06/10/2022 15:15:48 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.06 on epoch=714
06/10/2022 15:15:50 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/10/2022 15:15:53 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/10/2022 15:15:55 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/10/2022 15:15:57 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/10/2022 15:15:59 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.7023529411764705 on epoch=724
06/10/2022 15:16:01 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.05 on epoch=727
06/10/2022 15:16:03 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.04 on epoch=729
06/10/2022 15:16:05 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/10/2022 15:16:08 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/10/2022 15:16:10 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/10/2022 15:16:11 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.7385663082437276 on epoch=737
06/10/2022 15:16:14 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/10/2022 15:16:16 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/10/2022 15:16:18 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=744
06/10/2022 15:16:21 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/10/2022 15:16:23 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/10/2022 15:16:24 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.720045045045045 on epoch=749
06/10/2022 15:16:24 - INFO - __main__ - save last model!
06/10/2022 15:16:24 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/10/2022 15:16:24 - INFO - __main__ - Start tokenizing ... 5509 instances
06/10/2022 15:16:24 - INFO - __main__ - Printing 3 examples
06/10/2022 15:16:24 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/10/2022 15:16:24 - INFO - __main__ - ['others']
06/10/2022 15:16:24 - INFO - __main__ -  [emo] what you like very little things ok
06/10/2022 15:16:24 - INFO - __main__ - ['others']
06/10/2022 15:16:24 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/10/2022 15:16:24 - INFO - __main__ - ['others']
06/10/2022 15:16:24 - INFO - __main__ - Tokenizing Input ...
06/10/2022 15:16:24 - INFO - __main__ - Start tokenizing ... 64 instances
06/10/2022 15:16:24 - INFO - __main__ - Printing 3 examples
06/10/2022 15:16:24 - INFO - __main__ -  [emo] how cause yes am listening
06/10/2022 15:16:24 - INFO - __main__ - ['others']
06/10/2022 15:16:24 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/10/2022 15:16:24 - INFO - __main__ - ['others']
06/10/2022 15:16:24 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/10/2022 15:16:24 - INFO - __main__ - ['others']
06/10/2022 15:16:24 - INFO - __main__ - Tokenizing Input ...
06/10/2022 15:16:24 - INFO - __main__ - Tokenizing Output ...
06/10/2022 15:16:24 - INFO - __main__ - Loaded 64 examples from train data
06/10/2022 15:16:24 - INFO - __main__ - Start tokenizing ... 64 instances
06/10/2022 15:16:24 - INFO - __main__ - Printing 3 examples
06/10/2022 15:16:24 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
06/10/2022 15:16:24 - INFO - __main__ - ['others']
06/10/2022 15:16:24 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
06/10/2022 15:16:24 - INFO - __main__ - ['others']
06/10/2022 15:16:24 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
06/10/2022 15:16:24 - INFO - __main__ - ['others']
06/10/2022 15:16:24 - INFO - __main__ - Tokenizing Input ...
06/10/2022 15:16:25 - INFO - __main__ - Tokenizing Output ...
06/10/2022 15:16:25 - INFO - __main__ - Loaded 64 examples from dev data
06/10/2022 15:16:26 - INFO - __main__ - Tokenizing Output ...
06/10/2022 15:16:32 - INFO - __main__ - Loaded 5509 examples from test data
06/10/2022 15:16:39 - INFO - __main__ - load prompt embedding from ckpt
06/10/2022 15:16:40 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/10/2022 15:16:40 - INFO - __main__ - Starting training!
06/10/2022 15:18:04 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-up32shot/singletask-emo/emo_16_100_0.5_8_predictions.txt
06/10/2022 15:18:04 - INFO - __main__ - Classification-F1 on test data: 0.1833
06/10/2022 15:18:04 - INFO - __main__ - prefix=emo_16_100, lr=0.5, bsz=8, dev_performance=0.8133536173089926, test_performance=0.18326505366955692
06/10/2022 15:18:04 - INFO - __main__ - Running ... prefix=emo_16_100, lr=0.4, bsz=8 ...
06/10/2022 15:18:05 - INFO - __main__ - Start tokenizing ... 64 instances
06/10/2022 15:18:05 - INFO - __main__ - Printing 3 examples
06/10/2022 15:18:05 - INFO - __main__ -  [emo] how cause yes am listening
06/10/2022 15:18:05 - INFO - __main__ - ['others']
06/10/2022 15:18:05 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/10/2022 15:18:05 - INFO - __main__ - ['others']
06/10/2022 15:18:05 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/10/2022 15:18:05 - INFO - __main__ - ['others']
06/10/2022 15:18:05 - INFO - __main__ - Tokenizing Input ...
06/10/2022 15:18:05 - INFO - __main__ - Tokenizing Output ...
06/10/2022 15:18:05 - INFO - __main__ - Loaded 64 examples from train data
06/10/2022 15:18:05 - INFO - __main__ - Start tokenizing ... 64 instances
06/10/2022 15:18:05 - INFO - __main__ - Printing 3 examples
06/10/2022 15:18:05 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
06/10/2022 15:18:05 - INFO - __main__ - ['others']
06/10/2022 15:18:05 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
06/10/2022 15:18:05 - INFO - __main__ - ['others']
06/10/2022 15:18:05 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
06/10/2022 15:18:05 - INFO - __main__ - ['others']
06/10/2022 15:18:05 - INFO - __main__ - Tokenizing Input ...
06/10/2022 15:18:05 - INFO - __main__ - Tokenizing Output ...
06/10/2022 15:18:05 - INFO - __main__ - Loaded 64 examples from dev data
06/10/2022 15:18:20 - INFO - __main__ - load prompt embedding from ckpt
06/10/2022 15:18:21 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/10/2022 15:18:21 - INFO - __main__ - Starting training!
06/10/2022 15:18:24 - INFO - __main__ - Step 10 Global step 10 Train loss 3.93 on epoch=2
06/10/2022 15:18:26 - INFO - __main__ - Step 20 Global step 20 Train loss 2.45 on epoch=4
06/10/2022 15:18:28 - INFO - __main__ - Step 30 Global step 30 Train loss 2.02 on epoch=7
06/10/2022 15:18:31 - INFO - __main__ - Step 40 Global step 40 Train loss 1.59 on epoch=9
06/10/2022 15:18:33 - INFO - __main__ - Step 50 Global step 50 Train loss 1.44 on epoch=12
06/10/2022 15:18:34 - INFO - __main__ - Global step 50 Train loss 2.29 Classification-F1 0.22862554112554112 on epoch=12
06/10/2022 15:18:34 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.22862554112554112 on epoch=12, global_step=50
06/10/2022 15:18:36 - INFO - __main__ - Step 60 Global step 60 Train loss 1.13 on epoch=14
06/10/2022 15:18:39 - INFO - __main__ - Step 70 Global step 70 Train loss 0.90 on epoch=17
06/10/2022 15:18:41 - INFO - __main__ - Step 80 Global step 80 Train loss 0.86 on epoch=19
06/10/2022 15:18:43 - INFO - __main__ - Step 90 Global step 90 Train loss 0.89 on epoch=22
06/10/2022 15:18:46 - INFO - __main__ - Step 100 Global step 100 Train loss 0.78 on epoch=24
06/10/2022 15:18:47 - INFO - __main__ - Global step 100 Train loss 0.91 Classification-F1 0.47769949827876657 on epoch=24
06/10/2022 15:18:47 - INFO - __main__ - Saving model with best Classification-F1: 0.22862554112554112 -> 0.47769949827876657 on epoch=24, global_step=100
06/10/2022 15:18:49 - INFO - __main__ - Step 110 Global step 110 Train loss 0.81 on epoch=27
06/10/2022 15:18:51 - INFO - __main__ - Step 120 Global step 120 Train loss 0.72 on epoch=29
06/10/2022 15:18:54 - INFO - __main__ - Step 130 Global step 130 Train loss 0.69 on epoch=32
06/10/2022 15:18:56 - INFO - __main__ - Step 140 Global step 140 Train loss 0.66 on epoch=34
06/10/2022 15:18:58 - INFO - __main__ - Step 150 Global step 150 Train loss 0.71 on epoch=37
06/10/2022 15:18:59 - INFO - __main__ - Global step 150 Train loss 0.72 Classification-F1 0.6077386026874518 on epoch=37
06/10/2022 15:18:59 - INFO - __main__ - Saving model with best Classification-F1: 0.47769949827876657 -> 0.6077386026874518 on epoch=37, global_step=150
06/10/2022 15:19:02 - INFO - __main__ - Step 160 Global step 160 Train loss 0.64 on epoch=39
06/10/2022 15:19:04 - INFO - __main__ - Step 170 Global step 170 Train loss 0.63 on epoch=42
06/10/2022 15:19:06 - INFO - __main__ - Step 180 Global step 180 Train loss 0.67 on epoch=44
06/10/2022 15:19:09 - INFO - __main__ - Step 190 Global step 190 Train loss 0.57 on epoch=47
06/10/2022 15:19:11 - INFO - __main__ - Step 200 Global step 200 Train loss 0.61 on epoch=49
06/10/2022 15:19:12 - INFO - __main__ - Global step 200 Train loss 0.62 Classification-F1 0.575 on epoch=49
06/10/2022 15:19:14 - INFO - __main__ - Step 210 Global step 210 Train loss 0.63 on epoch=52
06/10/2022 15:19:16 - INFO - __main__ - Step 220 Global step 220 Train loss 0.54 on epoch=54
06/10/2022 15:19:19 - INFO - __main__ - Step 230 Global step 230 Train loss 0.53 on epoch=57
06/10/2022 15:19:21 - INFO - __main__ - Step 240 Global step 240 Train loss 0.59 on epoch=59
06/10/2022 15:19:23 - INFO - __main__ - Step 250 Global step 250 Train loss 0.62 on epoch=62
06/10/2022 15:19:24 - INFO - __main__ - Global step 250 Train loss 0.58 Classification-F1 0.6681756573597182 on epoch=62
06/10/2022 15:19:24 - INFO - __main__ - Saving model with best Classification-F1: 0.6077386026874518 -> 0.6681756573597182 on epoch=62, global_step=250
06/10/2022 15:19:27 - INFO - __main__ - Step 260 Global step 260 Train loss 0.55 on epoch=64
06/10/2022 15:19:29 - INFO - __main__ - Step 270 Global step 270 Train loss 0.65 on epoch=67
06/10/2022 15:19:31 - INFO - __main__ - Step 280 Global step 280 Train loss 0.44 on epoch=69
06/10/2022 15:19:34 - INFO - __main__ - Step 290 Global step 290 Train loss 0.52 on epoch=72
06/10/2022 15:19:36 - INFO - __main__ - Step 300 Global step 300 Train loss 0.50 on epoch=74
06/10/2022 15:19:37 - INFO - __main__ - Global step 300 Train loss 0.53 Classification-F1 0.6645428419621967 on epoch=74
06/10/2022 15:19:39 - INFO - __main__ - Step 310 Global step 310 Train loss 0.55 on epoch=77
06/10/2022 15:19:41 - INFO - __main__ - Step 320 Global step 320 Train loss 0.47 on epoch=79
06/10/2022 15:19:44 - INFO - __main__ - Step 330 Global step 330 Train loss 0.49 on epoch=82
06/10/2022 15:19:46 - INFO - __main__ - Step 340 Global step 340 Train loss 0.40 on epoch=84
06/10/2022 15:19:49 - INFO - __main__ - Step 350 Global step 350 Train loss 0.40 on epoch=87
06/10/2022 15:19:49 - INFO - __main__ - Global step 350 Train loss 0.46 Classification-F1 0.6836038961038962 on epoch=87
06/10/2022 15:19:49 - INFO - __main__ - Saving model with best Classification-F1: 0.6681756573597182 -> 0.6836038961038962 on epoch=87, global_step=350
06/10/2022 15:19:52 - INFO - __main__ - Step 360 Global step 360 Train loss 0.31 on epoch=89
06/10/2022 15:19:54 - INFO - __main__ - Step 370 Global step 370 Train loss 0.40 on epoch=92
06/10/2022 15:19:56 - INFO - __main__ - Step 380 Global step 380 Train loss 0.36 on epoch=94
06/10/2022 15:19:59 - INFO - __main__ - Step 390 Global step 390 Train loss 0.39 on epoch=97
06/10/2022 15:20:01 - INFO - __main__ - Step 400 Global step 400 Train loss 0.44 on epoch=99
06/10/2022 15:20:02 - INFO - __main__ - Global step 400 Train loss 0.38 Classification-F1 0.682894248970591 on epoch=99
06/10/2022 15:20:04 - INFO - __main__ - Step 410 Global step 410 Train loss 0.48 on epoch=102
06/10/2022 15:20:07 - INFO - __main__ - Step 420 Global step 420 Train loss 0.47 on epoch=104
06/10/2022 15:20:09 - INFO - __main__ - Step 430 Global step 430 Train loss 0.38 on epoch=107
06/10/2022 15:20:11 - INFO - __main__ - Step 440 Global step 440 Train loss 0.38 on epoch=109
06/10/2022 15:20:14 - INFO - __main__ - Step 450 Global step 450 Train loss 0.39 on epoch=112
06/10/2022 15:20:14 - INFO - __main__ - Global step 450 Train loss 0.42 Classification-F1 0.6538920559881349 on epoch=112
06/10/2022 15:20:17 - INFO - __main__ - Step 460 Global step 460 Train loss 0.31 on epoch=114
06/10/2022 15:20:19 - INFO - __main__ - Step 470 Global step 470 Train loss 0.32 on epoch=117
06/10/2022 15:20:21 - INFO - __main__ - Step 480 Global step 480 Train loss 0.28 on epoch=119
06/10/2022 15:20:24 - INFO - __main__ - Step 490 Global step 490 Train loss 0.35 on epoch=122
06/10/2022 15:20:26 - INFO - __main__ - Step 500 Global step 500 Train loss 0.36 on epoch=124
06/10/2022 15:20:27 - INFO - __main__ - Global step 500 Train loss 0.33 Classification-F1 0.6643335218702865 on epoch=124
06/10/2022 15:20:29 - INFO - __main__ - Step 510 Global step 510 Train loss 0.36 on epoch=127
06/10/2022 15:20:32 - INFO - __main__ - Step 520 Global step 520 Train loss 0.27 on epoch=129
06/10/2022 15:20:34 - INFO - __main__ - Step 530 Global step 530 Train loss 0.33 on epoch=132
06/10/2022 15:20:36 - INFO - __main__ - Step 540 Global step 540 Train loss 0.23 on epoch=134
06/10/2022 15:20:39 - INFO - __main__ - Step 550 Global step 550 Train loss 0.25 on epoch=137
06/10/2022 15:20:39 - INFO - __main__ - Global step 550 Train loss 0.29 Classification-F1 0.6834059448770238 on epoch=137
06/10/2022 15:20:42 - INFO - __main__ - Step 560 Global step 560 Train loss 0.23 on epoch=139
06/10/2022 15:20:44 - INFO - __main__ - Step 570 Global step 570 Train loss 0.22 on epoch=142
06/10/2022 15:20:47 - INFO - __main__ - Step 580 Global step 580 Train loss 0.27 on epoch=144
06/10/2022 15:20:49 - INFO - __main__ - Step 590 Global step 590 Train loss 0.25 on epoch=147
06/10/2022 15:20:51 - INFO - __main__ - Step 600 Global step 600 Train loss 0.26 on epoch=149
06/10/2022 15:20:52 - INFO - __main__ - Global step 600 Train loss 0.24 Classification-F1 0.6799659165945063 on epoch=149
06/10/2022 15:20:54 - INFO - __main__ - Step 610 Global step 610 Train loss 0.23 on epoch=152
06/10/2022 15:20:57 - INFO - __main__ - Step 620 Global step 620 Train loss 0.21 on epoch=154
06/10/2022 15:20:59 - INFO - __main__ - Step 630 Global step 630 Train loss 0.30 on epoch=157
06/10/2022 15:21:01 - INFO - __main__ - Step 640 Global step 640 Train loss 0.15 on epoch=159
06/10/2022 15:21:04 - INFO - __main__ - Step 650 Global step 650 Train loss 0.19 on epoch=162
06/10/2022 15:21:05 - INFO - __main__ - Global step 650 Train loss 0.22 Classification-F1 0.6646945646945646 on epoch=162
06/10/2022 15:21:07 - INFO - __main__ - Step 660 Global step 660 Train loss 0.19 on epoch=164
06/10/2022 15:21:09 - INFO - __main__ - Step 670 Global step 670 Train loss 0.32 on epoch=167
06/10/2022 15:21:12 - INFO - __main__ - Step 680 Global step 680 Train loss 0.18 on epoch=169
06/10/2022 15:21:14 - INFO - __main__ - Step 690 Global step 690 Train loss 0.17 on epoch=172
06/10/2022 15:21:16 - INFO - __main__ - Step 700 Global step 700 Train loss 0.18 on epoch=174
06/10/2022 15:21:17 - INFO - __main__ - Global step 700 Train loss 0.21 Classification-F1 0.6828828568539358 on epoch=174
06/10/2022 15:21:20 - INFO - __main__ - Step 710 Global step 710 Train loss 0.19 on epoch=177
06/10/2022 15:21:22 - INFO - __main__ - Step 720 Global step 720 Train loss 0.10 on epoch=179
06/10/2022 15:21:24 - INFO - __main__ - Step 730 Global step 730 Train loss 0.16 on epoch=182
06/10/2022 15:21:27 - INFO - __main__ - Step 740 Global step 740 Train loss 0.12 on epoch=184
06/10/2022 15:21:29 - INFO - __main__ - Step 750 Global step 750 Train loss 0.07 on epoch=187
06/10/2022 15:21:30 - INFO - __main__ - Global step 750 Train loss 0.12 Classification-F1 0.7441595441595441 on epoch=187
06/10/2022 15:21:30 - INFO - __main__ - Saving model with best Classification-F1: 0.6836038961038962 -> 0.7441595441595441 on epoch=187, global_step=750
06/10/2022 15:21:32 - INFO - __main__ - Step 760 Global step 760 Train loss 0.16 on epoch=189
06/10/2022 15:21:35 - INFO - __main__ - Step 770 Global step 770 Train loss 0.14 on epoch=192
06/10/2022 15:21:37 - INFO - __main__ - Step 780 Global step 780 Train loss 0.23 on epoch=194
06/10/2022 15:21:39 - INFO - __main__ - Step 790 Global step 790 Train loss 0.12 on epoch=197
06/10/2022 15:21:42 - INFO - __main__ - Step 800 Global step 800 Train loss 0.09 on epoch=199
06/10/2022 15:21:42 - INFO - __main__ - Global step 800 Train loss 0.15 Classification-F1 0.7310758082497213 on epoch=199
06/10/2022 15:21:45 - INFO - __main__ - Step 810 Global step 810 Train loss 0.15 on epoch=202
06/10/2022 15:21:47 - INFO - __main__ - Step 820 Global step 820 Train loss 0.16 on epoch=204
06/10/2022 15:21:49 - INFO - __main__ - Step 830 Global step 830 Train loss 0.09 on epoch=207
06/10/2022 15:21:52 - INFO - __main__ - Step 840 Global step 840 Train loss 0.07 on epoch=209
06/10/2022 15:21:54 - INFO - __main__ - Step 850 Global step 850 Train loss 0.07 on epoch=212
06/10/2022 15:21:55 - INFO - __main__ - Global step 850 Train loss 0.11 Classification-F1 0.7371471471471471 on epoch=212
06/10/2022 15:21:57 - INFO - __main__ - Step 860 Global step 860 Train loss 0.20 on epoch=214
06/10/2022 15:22:00 - INFO - __main__ - Step 870 Global step 870 Train loss 0.17 on epoch=217
06/10/2022 15:22:02 - INFO - __main__ - Step 880 Global step 880 Train loss 0.08 on epoch=219
06/10/2022 15:22:04 - INFO - __main__ - Step 890 Global step 890 Train loss 0.13 on epoch=222
06/10/2022 15:22:07 - INFO - __main__ - Step 900 Global step 900 Train loss 0.20 on epoch=224
06/10/2022 15:22:08 - INFO - __main__ - Global step 900 Train loss 0.16 Classification-F1 0.7173480116271879 on epoch=224
06/10/2022 15:22:10 - INFO - __main__ - Step 910 Global step 910 Train loss 0.07 on epoch=227
06/10/2022 15:22:13 - INFO - __main__ - Step 920 Global step 920 Train loss 0.19 on epoch=229
06/10/2022 15:22:15 - INFO - __main__ - Step 930 Global step 930 Train loss 0.07 on epoch=232
06/10/2022 15:22:17 - INFO - __main__ - Step 940 Global step 940 Train loss 0.05 on epoch=234
06/10/2022 15:22:20 - INFO - __main__ - Step 950 Global step 950 Train loss 0.11 on epoch=237
06/10/2022 15:22:20 - INFO - __main__ - Global step 950 Train loss 0.10 Classification-F1 0.7025247296986428 on epoch=237
06/10/2022 15:22:23 - INFO - __main__ - Step 960 Global step 960 Train loss 0.09 on epoch=239
06/10/2022 15:22:25 - INFO - __main__ - Step 970 Global step 970 Train loss 0.10 on epoch=242
06/10/2022 15:22:28 - INFO - __main__ - Step 980 Global step 980 Train loss 0.14 on epoch=244
06/10/2022 15:22:30 - INFO - __main__ - Step 990 Global step 990 Train loss 0.06 on epoch=247
06/10/2022 15:22:32 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.04 on epoch=249
06/10/2022 15:22:33 - INFO - __main__ - Global step 1000 Train loss 0.09 Classification-F1 0.7325375773651636 on epoch=249
06/10/2022 15:22:36 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.10 on epoch=252
06/10/2022 15:22:38 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.06 on epoch=254
06/10/2022 15:22:40 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.08 on epoch=257
06/10/2022 15:22:43 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.11 on epoch=259
06/10/2022 15:22:45 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.10 on epoch=262
06/10/2022 15:22:46 - INFO - __main__ - Global step 1050 Train loss 0.09 Classification-F1 0.7168918918918918 on epoch=262
06/10/2022 15:22:48 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.07 on epoch=264
06/10/2022 15:22:51 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.11 on epoch=267
06/10/2022 15:22:53 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.06 on epoch=269
06/10/2022 15:22:55 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.06 on epoch=272
06/10/2022 15:22:58 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.07 on epoch=274
06/10/2022 15:22:59 - INFO - __main__ - Global step 1100 Train loss 0.07 Classification-F1 0.7238045738045737 on epoch=274
06/10/2022 15:23:01 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.08 on epoch=277
06/10/2022 15:23:03 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.08 on epoch=279
06/10/2022 15:23:06 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.06 on epoch=282
06/10/2022 15:23:08 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.02 on epoch=284
06/10/2022 15:23:10 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.06 on epoch=287
06/10/2022 15:23:11 - INFO - __main__ - Global step 1150 Train loss 0.06 Classification-F1 0.715010395010395 on epoch=287
06/10/2022 15:23:14 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.14 on epoch=289
06/10/2022 15:23:16 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.10 on epoch=292
06/10/2022 15:23:18 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.03 on epoch=294
06/10/2022 15:23:21 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.03 on epoch=297
06/10/2022 15:23:23 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.15 on epoch=299
06/10/2022 15:23:24 - INFO - __main__ - Global step 1200 Train loss 0.09 Classification-F1 0.7021367521367521 on epoch=299
06/10/2022 15:23:26 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.06 on epoch=302
06/10/2022 15:23:29 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.04 on epoch=304
06/10/2022 15:23:31 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.08 on epoch=307
06/10/2022 15:23:33 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.02 on epoch=309
06/10/2022 15:23:35 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.06 on epoch=312
06/10/2022 15:23:36 - INFO - __main__ - Global step 1250 Train loss 0.05 Classification-F1 0.7329480101219231 on epoch=312
06/10/2022 15:23:39 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.05 on epoch=314
06/10/2022 15:23:41 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.05 on epoch=317
06/10/2022 15:23:43 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.05 on epoch=319
06/10/2022 15:23:46 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.08 on epoch=322
06/10/2022 15:23:48 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.07 on epoch=324
06/10/2022 15:23:49 - INFO - __main__ - Global step 1300 Train loss 0.06 Classification-F1 0.7376373626373626 on epoch=324
06/10/2022 15:23:51 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.02 on epoch=327
06/10/2022 15:23:54 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.05 on epoch=329
06/10/2022 15:23:56 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.08 on epoch=332
06/10/2022 15:23:58 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.07 on epoch=334
06/10/2022 15:24:01 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.05 on epoch=337
06/10/2022 15:24:02 - INFO - __main__ - Global step 1350 Train loss 0.05 Classification-F1 0.7659467503217504 on epoch=337
06/10/2022 15:24:02 - INFO - __main__ - Saving model with best Classification-F1: 0.7441595441595441 -> 0.7659467503217504 on epoch=337, global_step=1350
06/10/2022 15:24:04 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.03 on epoch=339
06/10/2022 15:24:06 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.06 on epoch=342
06/10/2022 15:24:09 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.03 on epoch=344
06/10/2022 15:24:11 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.04 on epoch=347
06/10/2022 15:24:13 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.03 on epoch=349
06/10/2022 15:24:14 - INFO - __main__ - Global step 1400 Train loss 0.04 Classification-F1 0.7342961092961093 on epoch=349
06/10/2022 15:24:17 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.02 on epoch=352
06/10/2022 15:24:19 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.05 on epoch=354
06/10/2022 15:24:21 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.03 on epoch=357
06/10/2022 15:24:24 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.04 on epoch=359
06/10/2022 15:24:26 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.04 on epoch=362
06/10/2022 15:24:27 - INFO - __main__ - Global step 1450 Train loss 0.04 Classification-F1 0.7665467887242081 on epoch=362
06/10/2022 15:24:27 - INFO - __main__ - Saving model with best Classification-F1: 0.7659467503217504 -> 0.7665467887242081 on epoch=362, global_step=1450
06/10/2022 15:24:30 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.06 on epoch=364
06/10/2022 15:24:32 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=367
06/10/2022 15:24:34 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=369
06/10/2022 15:24:36 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.03 on epoch=372
06/10/2022 15:24:39 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.02 on epoch=374
06/10/2022 15:24:40 - INFO - __main__ - Global step 1500 Train loss 0.03 Classification-F1 0.7458139563494993 on epoch=374
06/10/2022 15:24:42 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.11 on epoch=377
06/10/2022 15:24:44 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.02 on epoch=379
06/10/2022 15:24:47 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.05 on epoch=382
06/10/2022 15:24:49 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.05 on epoch=384
06/10/2022 15:24:51 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.05 on epoch=387
06/10/2022 15:24:52 - INFO - __main__ - Global step 1550 Train loss 0.06 Classification-F1 0.7523801220575415 on epoch=387
06/10/2022 15:24:55 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.04 on epoch=389
06/10/2022 15:24:57 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.04 on epoch=392
06/10/2022 15:24:59 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.04 on epoch=394
06/10/2022 15:25:02 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.06 on epoch=397
06/10/2022 15:25:04 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.07 on epoch=399
06/10/2022 15:25:05 - INFO - __main__ - Global step 1600 Train loss 0.05 Classification-F1 0.7455176073689398 on epoch=399
06/10/2022 15:25:07 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.05 on epoch=402
06/10/2022 15:25:10 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.15 on epoch=404
06/10/2022 15:25:12 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.02 on epoch=407
06/10/2022 15:25:14 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=409
06/10/2022 15:25:17 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=412
06/10/2022 15:25:18 - INFO - __main__ - Global step 1650 Train loss 0.05 Classification-F1 0.7665467887242081 on epoch=412
06/10/2022 15:25:20 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=414
06/10/2022 15:25:22 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.10 on epoch=417
06/10/2022 15:25:25 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=419
06/10/2022 15:25:27 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.02 on epoch=422
06/10/2022 15:25:29 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=424
06/10/2022 15:25:30 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.7525983061101029 on epoch=424
06/10/2022 15:25:33 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=427
06/10/2022 15:25:35 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.02 on epoch=429
06/10/2022 15:25:37 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.05 on epoch=432
06/10/2022 15:25:40 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=434
06/10/2022 15:25:42 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=437
06/10/2022 15:25:43 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.7234266221108325 on epoch=437
06/10/2022 15:25:45 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.05 on epoch=439
06/10/2022 15:25:48 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=442
06/10/2022 15:25:50 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.08 on epoch=444
06/10/2022 15:25:53 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.05 on epoch=447
06/10/2022 15:25:55 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=449
06/10/2022 15:25:56 - INFO - __main__ - Global step 1800 Train loss 0.04 Classification-F1 0.7523019571295434 on epoch=449
06/10/2022 15:25:58 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=452
06/10/2022 15:26:00 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=454
06/10/2022 15:26:03 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=457
06/10/2022 15:26:05 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.04 on epoch=459
06/10/2022 15:26:07 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.05 on epoch=462
06/10/2022 15:26:08 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.7510360360360361 on epoch=462
06/10/2022 15:26:11 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=464
06/10/2022 15:26:13 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=467
06/10/2022 15:26:15 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=469
06/10/2022 15:26:18 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=472
06/10/2022 15:26:20 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=474
06/10/2022 15:26:21 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.7665467887242081 on epoch=474
06/10/2022 15:26:23 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=477
06/10/2022 15:26:26 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.06 on epoch=479
06/10/2022 15:26:28 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.13 on epoch=482
06/10/2022 15:26:30 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.04 on epoch=484
06/10/2022 15:26:33 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.06 on epoch=487
06/10/2022 15:26:34 - INFO - __main__ - Global step 1950 Train loss 0.06 Classification-F1 0.7258190883190883 on epoch=487
06/10/2022 15:26:36 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=489
06/10/2022 15:26:38 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=492
06/10/2022 15:26:41 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=494
06/10/2022 15:26:43 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.06 on epoch=497
06/10/2022 15:26:45 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=499
06/10/2022 15:26:46 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.7451255702163143 on epoch=499
06/10/2022 15:26:49 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.06 on epoch=502
06/10/2022 15:26:51 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.06 on epoch=504
06/10/2022 15:26:53 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/10/2022 15:26:56 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=509
06/10/2022 15:26:58 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.02 on epoch=512
06/10/2022 15:26:59 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.7388803573921541 on epoch=512
06/10/2022 15:27:01 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.05 on epoch=514
06/10/2022 15:27:04 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=517
06/10/2022 15:27:06 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=519
06/10/2022 15:27:08 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.04 on epoch=522
06/10/2022 15:27:11 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=524
06/10/2022 15:27:12 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.7412087912087911 on epoch=524
06/10/2022 15:27:14 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
06/10/2022 15:27:16 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=529
06/10/2022 15:27:19 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=532
06/10/2022 15:27:21 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=534
06/10/2022 15:27:24 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=537
06/10/2022 15:27:24 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.7367457104299209 on epoch=537
06/10/2022 15:27:27 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.03 on epoch=539
06/10/2022 15:27:29 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.04 on epoch=542
06/10/2022 15:27:31 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/10/2022 15:27:34 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.04 on epoch=547
06/10/2022 15:27:36 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=549
06/10/2022 15:27:37 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.7525224944089042 on epoch=549
06/10/2022 15:27:40 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=552
06/10/2022 15:27:42 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.05 on epoch=554
06/10/2022 15:27:44 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.03 on epoch=557
06/10/2022 15:27:47 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.03 on epoch=559
06/10/2022 15:27:49 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/10/2022 15:27:50 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.7471725730306966 on epoch=562
06/10/2022 15:27:52 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/10/2022 15:27:54 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.03 on epoch=567
06/10/2022 15:27:57 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/10/2022 15:27:59 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/10/2022 15:28:02 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/10/2022 15:28:03 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.7589718510863414 on epoch=574
06/10/2022 15:28:05 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=577
06/10/2022 15:28:07 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=579
06/10/2022 15:28:10 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=582
06/10/2022 15:28:12 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=584
06/10/2022 15:28:14 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.05 on epoch=587
06/10/2022 15:28:15 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.7589718510863414 on epoch=587
06/10/2022 15:28:18 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/10/2022 15:28:20 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=592
06/10/2022 15:28:22 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=594
06/10/2022 15:28:25 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/10/2022 15:28:27 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/10/2022 15:28:28 - INFO - __main__ - Global step 2400 Train loss 0.00 Classification-F1 0.7663104711380573 on epoch=599
06/10/2022 15:28:30 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.03 on epoch=602
06/10/2022 15:28:33 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=604
06/10/2022 15:28:35 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=607
06/10/2022 15:28:37 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/10/2022 15:28:40 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/10/2022 15:28:40 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.7605629877369007 on epoch=612
06/10/2022 15:28:43 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=614
06/10/2022 15:28:45 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/10/2022 15:28:47 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/10/2022 15:28:50 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=622
06/10/2022 15:28:52 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=624
06/10/2022 15:28:53 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.7373180873180873 on epoch=624
06/10/2022 15:28:55 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.03 on epoch=627
06/10/2022 15:28:58 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/10/2022 15:29:00 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/10/2022 15:29:03 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/10/2022 15:29:05 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=637
06/10/2022 15:29:06 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.7523019571295434 on epoch=637
06/10/2022 15:29:08 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.04 on epoch=639
06/10/2022 15:29:11 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.04 on epoch=642
06/10/2022 15:29:13 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.04 on epoch=644
06/10/2022 15:29:15 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=647
06/10/2022 15:29:18 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/10/2022 15:29:19 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.7386590834866696 on epoch=649
06/10/2022 15:29:21 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=652
06/10/2022 15:29:23 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/10/2022 15:29:26 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/10/2022 15:29:28 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/10/2022 15:29:30 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/10/2022 15:29:31 - INFO - __main__ - Global step 2650 Train loss 0.00 Classification-F1 0.7523019571295434 on epoch=662
06/10/2022 15:29:34 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/10/2022 15:29:36 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=667
06/10/2022 15:29:38 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/10/2022 15:29:41 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.05 on epoch=672
06/10/2022 15:29:43 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/10/2022 15:29:44 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.7392288840564702 on epoch=674
06/10/2022 15:29:46 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.08 on epoch=677
06/10/2022 15:29:49 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=679
06/10/2022 15:29:51 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/10/2022 15:29:53 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/10/2022 15:29:56 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=687
06/10/2022 15:29:56 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.7605629877369007 on epoch=687
06/10/2022 15:29:59 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.03 on epoch=689
06/10/2022 15:30:01 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.05 on epoch=692
06/10/2022 15:30:04 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=694
06/10/2022 15:30:06 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.10 on epoch=697
06/10/2022 15:30:08 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=699
06/10/2022 15:30:09 - INFO - __main__ - Global step 2800 Train loss 0.04 Classification-F1 0.7526261373035567 on epoch=699
06/10/2022 15:30:12 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/10/2022 15:30:14 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/10/2022 15:30:16 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=707
06/10/2022 15:30:19 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=709
06/10/2022 15:30:21 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/10/2022 15:30:22 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.7445958186447318 on epoch=712
06/10/2022 15:30:24 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/10/2022 15:30:27 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/10/2022 15:30:29 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.04 on epoch=719
06/10/2022 15:30:31 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/10/2022 15:30:34 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=724
06/10/2022 15:30:35 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.7605629877369007 on epoch=724
06/10/2022 15:30:37 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=727
06/10/2022 15:30:39 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.04 on epoch=729
06/10/2022 15:30:42 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=732
06/10/2022 15:30:44 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.05 on epoch=734
06/10/2022 15:30:46 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/10/2022 15:30:47 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.7665467887242081 on epoch=737
06/10/2022 15:30:50 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/10/2022 15:30:52 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/10/2022 15:30:54 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/10/2022 15:30:57 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=747
06/10/2022 15:30:59 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.09 on epoch=749
06/10/2022 15:31:00 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.7455176073689398 on epoch=749
06/10/2022 15:31:00 - INFO - __main__ - save last model!
06/10/2022 15:31:00 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/10/2022 15:31:00 - INFO - __main__ - Start tokenizing ... 5509 instances
06/10/2022 15:31:00 - INFO - __main__ - Printing 3 examples
06/10/2022 15:31:00 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/10/2022 15:31:00 - INFO - __main__ - ['others']
06/10/2022 15:31:00 - INFO - __main__ -  [emo] what you like very little things ok
06/10/2022 15:31:00 - INFO - __main__ - ['others']
06/10/2022 15:31:00 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/10/2022 15:31:00 - INFO - __main__ - ['others']
06/10/2022 15:31:00 - INFO - __main__ - Tokenizing Input ...
06/10/2022 15:31:00 - INFO - __main__ - Start tokenizing ... 64 instances
06/10/2022 15:31:00 - INFO - __main__ - Printing 3 examples
06/10/2022 15:31:00 - INFO - __main__ -  [emo] how cause yes am listening
06/10/2022 15:31:00 - INFO - __main__ - ['others']
06/10/2022 15:31:00 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/10/2022 15:31:00 - INFO - __main__ - ['others']
06/10/2022 15:31:00 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/10/2022 15:31:00 - INFO - __main__ - ['others']
06/10/2022 15:31:00 - INFO - __main__ - Tokenizing Input ...
06/10/2022 15:31:00 - INFO - __main__ - Tokenizing Output ...
06/10/2022 15:31:00 - INFO - __main__ - Loaded 64 examples from train data
06/10/2022 15:31:00 - INFO - __main__ - Start tokenizing ... 64 instances
06/10/2022 15:31:00 - INFO - __main__ - Printing 3 examples
06/10/2022 15:31:00 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
06/10/2022 15:31:00 - INFO - __main__ - ['others']
06/10/2022 15:31:00 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
06/10/2022 15:31:00 - INFO - __main__ - ['others']
06/10/2022 15:31:00 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
06/10/2022 15:31:00 - INFO - __main__ - ['others']
06/10/2022 15:31:00 - INFO - __main__ - Tokenizing Input ...
06/10/2022 15:31:00 - INFO - __main__ - Tokenizing Output ...
06/10/2022 15:31:00 - INFO - __main__ - Loaded 64 examples from dev data
06/10/2022 15:31:02 - INFO - __main__ - Tokenizing Output ...
06/10/2022 15:31:08 - INFO - __main__ - Loaded 5509 examples from test data
06/10/2022 15:31:16 - INFO - __main__ - load prompt embedding from ckpt
06/10/2022 15:31:17 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/10/2022 15:31:17 - INFO - __main__ - Starting training!
06/10/2022 15:32:33 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-up32shot/singletask-emo/emo_16_100_0.4_8_predictions.txt
06/10/2022 15:32:33 - INFO - __main__ - Classification-F1 on test data: 0.4117
06/10/2022 15:32:33 - INFO - __main__ - prefix=emo_16_100, lr=0.4, bsz=8, dev_performance=0.7665467887242081, test_performance=0.41173079274357555
06/10/2022 15:32:33 - INFO - __main__ - Running ... prefix=emo_16_100, lr=0.3, bsz=8 ...
06/10/2022 15:32:34 - INFO - __main__ - Start tokenizing ... 64 instances
06/10/2022 15:32:34 - INFO - __main__ - Printing 3 examples
06/10/2022 15:32:34 - INFO - __main__ -  [emo] how cause yes am listening
06/10/2022 15:32:34 - INFO - __main__ - ['others']
06/10/2022 15:32:34 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/10/2022 15:32:34 - INFO - __main__ - ['others']
06/10/2022 15:32:34 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/10/2022 15:32:34 - INFO - __main__ - ['others']
06/10/2022 15:32:34 - INFO - __main__ - Tokenizing Input ...
06/10/2022 15:32:34 - INFO - __main__ - Tokenizing Output ...
06/10/2022 15:32:34 - INFO - __main__ - Loaded 64 examples from train data
06/10/2022 15:32:34 - INFO - __main__ - Start tokenizing ... 64 instances
06/10/2022 15:32:34 - INFO - __main__ - Printing 3 examples
06/10/2022 15:32:34 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
06/10/2022 15:32:34 - INFO - __main__ - ['others']
06/10/2022 15:32:34 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
06/10/2022 15:32:34 - INFO - __main__ - ['others']
06/10/2022 15:32:34 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
06/10/2022 15:32:34 - INFO - __main__ - ['others']
06/10/2022 15:32:34 - INFO - __main__ - Tokenizing Input ...
06/10/2022 15:32:34 - INFO - __main__ - Tokenizing Output ...
06/10/2022 15:32:34 - INFO - __main__ - Loaded 64 examples from dev data
06/10/2022 15:32:50 - INFO - __main__ - load prompt embedding from ckpt
06/10/2022 15:32:50 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/10/2022 15:32:50 - INFO - __main__ - Starting training!
06/10/2022 15:32:53 - INFO - __main__ - Step 10 Global step 10 Train loss 4.11 on epoch=2
06/10/2022 15:32:56 - INFO - __main__ - Step 20 Global step 20 Train loss 2.81 on epoch=4
06/10/2022 15:32:58 - INFO - __main__ - Step 30 Global step 30 Train loss 2.35 on epoch=7
06/10/2022 15:33:00 - INFO - __main__ - Step 40 Global step 40 Train loss 1.85 on epoch=9
06/10/2022 15:33:03 - INFO - __main__ - Step 50 Global step 50 Train loss 1.70 on epoch=12
06/10/2022 15:33:03 - INFO - __main__ - Global step 50 Train loss 2.56 Classification-F1 0.09770817417876242 on epoch=12
06/10/2022 15:33:03 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.09770817417876242 on epoch=12, global_step=50
06/10/2022 15:33:06 - INFO - __main__ - Step 60 Global step 60 Train loss 1.24 on epoch=14
06/10/2022 15:33:08 - INFO - __main__ - Step 70 Global step 70 Train loss 1.18 on epoch=17
06/10/2022 15:33:11 - INFO - __main__ - Step 80 Global step 80 Train loss 1.02 on epoch=19
06/10/2022 15:33:13 - INFO - __main__ - Step 90 Global step 90 Train loss 0.94 on epoch=22
06/10/2022 15:33:15 - INFO - __main__ - Step 100 Global step 100 Train loss 0.92 on epoch=24
06/10/2022 15:33:16 - INFO - __main__ - Global step 100 Train loss 1.06 Classification-F1 0.3728223410576352 on epoch=24
06/10/2022 15:33:16 - INFO - __main__ - Saving model with best Classification-F1: 0.09770817417876242 -> 0.3728223410576352 on epoch=24, global_step=100
06/10/2022 15:33:19 - INFO - __main__ - Step 110 Global step 110 Train loss 0.91 on epoch=27
06/10/2022 15:33:21 - INFO - __main__ - Step 120 Global step 120 Train loss 0.77 on epoch=29
06/10/2022 15:33:23 - INFO - __main__ - Step 130 Global step 130 Train loss 0.89 on epoch=32
06/10/2022 15:33:26 - INFO - __main__ - Step 140 Global step 140 Train loss 0.78 on epoch=34
06/10/2022 15:33:28 - INFO - __main__ - Step 150 Global step 150 Train loss 0.76 on epoch=37
06/10/2022 15:33:29 - INFO - __main__ - Global step 150 Train loss 0.82 Classification-F1 0.5847985347985348 on epoch=37
06/10/2022 15:33:29 - INFO - __main__ - Saving model with best Classification-F1: 0.3728223410576352 -> 0.5847985347985348 on epoch=37, global_step=150
06/10/2022 15:33:31 - INFO - __main__ - Step 160 Global step 160 Train loss 0.75 on epoch=39
06/10/2022 15:33:33 - INFO - __main__ - Step 170 Global step 170 Train loss 0.73 on epoch=42
06/10/2022 15:33:36 - INFO - __main__ - Step 180 Global step 180 Train loss 0.60 on epoch=44
06/10/2022 15:33:38 - INFO - __main__ - Step 190 Global step 190 Train loss 0.63 on epoch=47
06/10/2022 15:33:41 - INFO - __main__ - Step 200 Global step 200 Train loss 0.63 on epoch=49
06/10/2022 15:33:41 - INFO - __main__ - Global step 200 Train loss 0.67 Classification-F1 0.5914473684210526 on epoch=49
06/10/2022 15:33:41 - INFO - __main__ - Saving model with best Classification-F1: 0.5847985347985348 -> 0.5914473684210526 on epoch=49, global_step=200
06/10/2022 15:33:44 - INFO - __main__ - Step 210 Global step 210 Train loss 0.69 on epoch=52
06/10/2022 15:33:46 - INFO - __main__ - Step 220 Global step 220 Train loss 0.58 on epoch=54
06/10/2022 15:33:49 - INFO - __main__ - Step 230 Global step 230 Train loss 0.65 on epoch=57
06/10/2022 15:33:51 - INFO - __main__ - Step 240 Global step 240 Train loss 0.68 on epoch=59
06/10/2022 15:33:53 - INFO - __main__ - Step 250 Global step 250 Train loss 0.51 on epoch=62
06/10/2022 15:33:54 - INFO - __main__ - Global step 250 Train loss 0.62 Classification-F1 0.6013071895424836 on epoch=62
06/10/2022 15:33:54 - INFO - __main__ - Saving model with best Classification-F1: 0.5914473684210526 -> 0.6013071895424836 on epoch=62, global_step=250
06/10/2022 15:33:56 - INFO - __main__ - Step 260 Global step 260 Train loss 0.53 on epoch=64
06/10/2022 15:33:59 - INFO - __main__ - Step 270 Global step 270 Train loss 0.60 on epoch=67
06/10/2022 15:34:01 - INFO - __main__ - Step 280 Global step 280 Train loss 0.56 on epoch=69
06/10/2022 15:34:04 - INFO - __main__ - Step 290 Global step 290 Train loss 0.66 on epoch=72
06/10/2022 15:34:06 - INFO - __main__ - Step 300 Global step 300 Train loss 0.58 on epoch=74
06/10/2022 15:34:07 - INFO - __main__ - Global step 300 Train loss 0.59 Classification-F1 0.6098939604445897 on epoch=74
06/10/2022 15:34:07 - INFO - __main__ - Saving model with best Classification-F1: 0.6013071895424836 -> 0.6098939604445897 on epoch=74, global_step=300
06/10/2022 15:34:09 - INFO - __main__ - Step 310 Global step 310 Train loss 0.52 on epoch=77
06/10/2022 15:34:11 - INFO - __main__ - Step 320 Global step 320 Train loss 0.63 on epoch=79
06/10/2022 15:34:14 - INFO - __main__ - Step 330 Global step 330 Train loss 0.53 on epoch=82
06/10/2022 15:34:16 - INFO - __main__ - Step 340 Global step 340 Train loss 0.50 on epoch=84
06/10/2022 15:34:18 - INFO - __main__ - Step 350 Global step 350 Train loss 0.53 on epoch=87
06/10/2022 15:34:19 - INFO - __main__ - Global step 350 Train loss 0.54 Classification-F1 0.6302083333333333 on epoch=87
06/10/2022 15:34:19 - INFO - __main__ - Saving model with best Classification-F1: 0.6098939604445897 -> 0.6302083333333333 on epoch=87, global_step=350
06/10/2022 15:34:22 - INFO - __main__ - Step 360 Global step 360 Train loss 0.49 on epoch=89
06/10/2022 15:34:24 - INFO - __main__ - Step 370 Global step 370 Train loss 0.53 on epoch=92
06/10/2022 15:34:26 - INFO - __main__ - Step 380 Global step 380 Train loss 0.47 on epoch=94
06/10/2022 15:34:28 - INFO - __main__ - Step 390 Global step 390 Train loss 0.53 on epoch=97
06/10/2022 15:34:31 - INFO - __main__ - Step 400 Global step 400 Train loss 0.44 on epoch=99
06/10/2022 15:34:32 - INFO - __main__ - Global step 400 Train loss 0.49 Classification-F1 0.6510293284486832 on epoch=99
06/10/2022 15:34:32 - INFO - __main__ - Saving model with best Classification-F1: 0.6302083333333333 -> 0.6510293284486832 on epoch=99, global_step=400
06/10/2022 15:34:34 - INFO - __main__ - Step 410 Global step 410 Train loss 0.47 on epoch=102
06/10/2022 15:34:36 - INFO - __main__ - Step 420 Global step 420 Train loss 0.42 on epoch=104
06/10/2022 15:34:39 - INFO - __main__ - Step 430 Global step 430 Train loss 0.44 on epoch=107
06/10/2022 15:34:41 - INFO - __main__ - Step 440 Global step 440 Train loss 0.44 on epoch=109
06/10/2022 15:34:43 - INFO - __main__ - Step 450 Global step 450 Train loss 0.37 on epoch=112
06/10/2022 15:34:44 - INFO - __main__ - Global step 450 Train loss 0.43 Classification-F1 0.6510293284486832 on epoch=112
06/10/2022 15:34:47 - INFO - __main__ - Step 460 Global step 460 Train loss 0.37 on epoch=114
06/10/2022 15:34:49 - INFO - __main__ - Step 470 Global step 470 Train loss 0.38 on epoch=117
06/10/2022 15:34:51 - INFO - __main__ - Step 480 Global step 480 Train loss 0.47 on epoch=119
06/10/2022 15:34:54 - INFO - __main__ - Step 490 Global step 490 Train loss 0.46 on epoch=122
06/10/2022 15:34:56 - INFO - __main__ - Step 500 Global step 500 Train loss 0.38 on epoch=124
06/10/2022 15:34:57 - INFO - __main__ - Global step 500 Train loss 0.41 Classification-F1 0.650904203323558 on epoch=124
06/10/2022 15:34:59 - INFO - __main__ - Step 510 Global step 510 Train loss 0.38 on epoch=127
06/10/2022 15:35:02 - INFO - __main__ - Step 520 Global step 520 Train loss 0.32 on epoch=129
06/10/2022 15:35:04 - INFO - __main__ - Step 530 Global step 530 Train loss 0.34 on epoch=132
06/10/2022 15:35:06 - INFO - __main__ - Step 540 Global step 540 Train loss 0.32 on epoch=134
06/10/2022 15:35:09 - INFO - __main__ - Step 550 Global step 550 Train loss 0.38 on epoch=137
06/10/2022 15:35:10 - INFO - __main__ - Global step 550 Train loss 0.35 Classification-F1 0.6361475428729486 on epoch=137
06/10/2022 15:35:12 - INFO - __main__ - Step 560 Global step 560 Train loss 0.35 on epoch=139
06/10/2022 15:35:14 - INFO - __main__ - Step 570 Global step 570 Train loss 0.39 on epoch=142
06/10/2022 15:35:17 - INFO - __main__ - Step 580 Global step 580 Train loss 0.32 on epoch=144
06/10/2022 15:35:19 - INFO - __main__ - Step 590 Global step 590 Train loss 0.34 on epoch=147
06/10/2022 15:35:21 - INFO - __main__ - Step 600 Global step 600 Train loss 0.30 on epoch=149
06/10/2022 15:35:22 - INFO - __main__ - Global step 600 Train loss 0.34 Classification-F1 0.6501862393703001 on epoch=149
06/10/2022 15:35:24 - INFO - __main__ - Step 610 Global step 610 Train loss 0.36 on epoch=152
06/10/2022 15:35:27 - INFO - __main__ - Step 620 Global step 620 Train loss 0.35 on epoch=154
06/10/2022 15:35:29 - INFO - __main__ - Step 630 Global step 630 Train loss 0.24 on epoch=157
06/10/2022 15:35:31 - INFO - __main__ - Step 640 Global step 640 Train loss 0.23 on epoch=159
06/10/2022 15:35:34 - INFO - __main__ - Step 650 Global step 650 Train loss 0.36 on epoch=162
06/10/2022 15:35:35 - INFO - __main__ - Global step 650 Train loss 0.31 Classification-F1 0.6545977011494253 on epoch=162
06/10/2022 15:35:35 - INFO - __main__ - Saving model with best Classification-F1: 0.6510293284486832 -> 0.6545977011494253 on epoch=162, global_step=650
06/10/2022 15:35:37 - INFO - __main__ - Step 660 Global step 660 Train loss 0.31 on epoch=164
06/10/2022 15:35:39 - INFO - __main__ - Step 670 Global step 670 Train loss 0.29 on epoch=167
06/10/2022 15:35:42 - INFO - __main__ - Step 680 Global step 680 Train loss 0.24 on epoch=169
06/10/2022 15:35:44 - INFO - __main__ - Step 690 Global step 690 Train loss 0.34 on epoch=172
06/10/2022 15:35:46 - INFO - __main__ - Step 700 Global step 700 Train loss 0.26 on epoch=174
06/10/2022 15:35:47 - INFO - __main__ - Global step 700 Train loss 0.29 Classification-F1 0.6464905622690502 on epoch=174
06/10/2022 15:35:50 - INFO - __main__ - Step 710 Global step 710 Train loss 0.21 on epoch=177
06/10/2022 15:35:52 - INFO - __main__ - Step 720 Global step 720 Train loss 0.33 on epoch=179
06/10/2022 15:35:54 - INFO - __main__ - Step 730 Global step 730 Train loss 0.29 on epoch=182
06/10/2022 15:35:57 - INFO - __main__ - Step 740 Global step 740 Train loss 0.27 on epoch=184
06/10/2022 15:35:59 - INFO - __main__ - Step 750 Global step 750 Train loss 0.32 on epoch=187
06/10/2022 15:36:00 - INFO - __main__ - Global step 750 Train loss 0.28 Classification-F1 0.6370700489721624 on epoch=187
06/10/2022 15:36:02 - INFO - __main__ - Step 760 Global step 760 Train loss 0.24 on epoch=189
06/10/2022 15:36:04 - INFO - __main__ - Step 770 Global step 770 Train loss 0.30 on epoch=192
06/10/2022 15:36:07 - INFO - __main__ - Step 780 Global step 780 Train loss 0.29 on epoch=194
06/10/2022 15:36:09 - INFO - __main__ - Step 790 Global step 790 Train loss 0.28 on epoch=197
06/10/2022 15:36:12 - INFO - __main__ - Step 800 Global step 800 Train loss 0.21 on epoch=199
06/10/2022 15:36:12 - INFO - __main__ - Global step 800 Train loss 0.27 Classification-F1 0.6407378740970072 on epoch=199
06/10/2022 15:36:15 - INFO - __main__ - Step 810 Global step 810 Train loss 0.25 on epoch=202
06/10/2022 15:36:17 - INFO - __main__ - Step 820 Global step 820 Train loss 0.21 on epoch=204
06/10/2022 15:36:19 - INFO - __main__ - Step 830 Global step 830 Train loss 0.20 on epoch=207
06/10/2022 15:36:22 - INFO - __main__ - Step 840 Global step 840 Train loss 0.19 on epoch=209
06/10/2022 15:36:24 - INFO - __main__ - Step 850 Global step 850 Train loss 0.12 on epoch=212
06/10/2022 15:36:25 - INFO - __main__ - Global step 850 Train loss 0.20 Classification-F1 0.68006993006993 on epoch=212
06/10/2022 15:36:25 - INFO - __main__ - Saving model with best Classification-F1: 0.6545977011494253 -> 0.68006993006993 on epoch=212, global_step=850
06/10/2022 15:36:27 - INFO - __main__ - Step 860 Global step 860 Train loss 0.20 on epoch=214
06/10/2022 15:36:30 - INFO - __main__ - Step 870 Global step 870 Train loss 0.20 on epoch=217
06/10/2022 15:36:32 - INFO - __main__ - Step 880 Global step 880 Train loss 0.25 on epoch=219
06/10/2022 15:36:34 - INFO - __main__ - Step 890 Global step 890 Train loss 0.23 on epoch=222
06/10/2022 15:36:37 - INFO - __main__ - Step 900 Global step 900 Train loss 0.20 on epoch=224
06/10/2022 15:36:38 - INFO - __main__ - Global step 900 Train loss 0.21 Classification-F1 0.6613667582417583 on epoch=224
06/10/2022 15:36:40 - INFO - __main__ - Step 910 Global step 910 Train loss 0.26 on epoch=227
06/10/2022 15:36:42 - INFO - __main__ - Step 920 Global step 920 Train loss 0.20 on epoch=229
06/10/2022 15:36:45 - INFO - __main__ - Step 930 Global step 930 Train loss 0.20 on epoch=232
06/10/2022 15:36:47 - INFO - __main__ - Step 940 Global step 940 Train loss 0.14 on epoch=234
06/10/2022 15:36:49 - INFO - __main__ - Step 950 Global step 950 Train loss 0.22 on epoch=237
06/10/2022 15:36:50 - INFO - __main__ - Global step 950 Train loss 0.20 Classification-F1 0.6386554621848739 on epoch=237
06/10/2022 15:36:53 - INFO - __main__ - Step 960 Global step 960 Train loss 0.13 on epoch=239
06/10/2022 15:36:55 - INFO - __main__ - Step 970 Global step 970 Train loss 0.18 on epoch=242
06/10/2022 15:36:57 - INFO - __main__ - Step 980 Global step 980 Train loss 0.15 on epoch=244
06/10/2022 15:37:00 - INFO - __main__ - Step 990 Global step 990 Train loss 0.09 on epoch=247
06/10/2022 15:37:02 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.15 on epoch=249
06/10/2022 15:37:03 - INFO - __main__ - Global step 1000 Train loss 0.14 Classification-F1 0.6392195203170813 on epoch=249
06/10/2022 15:37:06 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.14 on epoch=252
06/10/2022 15:37:08 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.20 on epoch=254
06/10/2022 15:37:10 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.13 on epoch=257
06/10/2022 15:37:13 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.17 on epoch=259
06/10/2022 15:37:15 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.13 on epoch=262
06/10/2022 15:37:16 - INFO - __main__ - Global step 1050 Train loss 0.15 Classification-F1 0.5538194444444444 on epoch=262
06/10/2022 15:37:18 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.12 on epoch=264
06/10/2022 15:37:20 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.16 on epoch=267
06/10/2022 15:37:23 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.11 on epoch=269
06/10/2022 15:37:25 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.15 on epoch=272
06/10/2022 15:37:28 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.10 on epoch=274
06/10/2022 15:37:28 - INFO - __main__ - Global step 1100 Train loss 0.13 Classification-F1 0.6497475497475498 on epoch=274
06/10/2022 15:37:31 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.12 on epoch=277
06/10/2022 15:37:33 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.13 on epoch=279
06/10/2022 15:37:35 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.20 on epoch=282
06/10/2022 15:37:38 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.10 on epoch=284
06/10/2022 15:37:40 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.10 on epoch=287
06/10/2022 15:37:41 - INFO - __main__ - Global step 1150 Train loss 0.13 Classification-F1 0.663609022556391 on epoch=287
06/10/2022 15:37:43 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.09 on epoch=289
06/10/2022 15:37:46 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.05 on epoch=292
06/10/2022 15:37:48 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.15 on epoch=294
06/10/2022 15:37:51 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.09 on epoch=297
06/10/2022 15:37:53 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.08 on epoch=299
06/10/2022 15:37:54 - INFO - __main__ - Global step 1200 Train loss 0.09 Classification-F1 0.6565058479532164 on epoch=299
06/10/2022 15:37:56 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.05 on epoch=302
06/10/2022 15:37:59 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.06 on epoch=304
06/10/2022 15:38:01 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.11 on epoch=307
06/10/2022 15:38:03 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.09 on epoch=309
06/10/2022 15:38:06 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.16 on epoch=312
06/10/2022 15:38:06 - INFO - __main__ - Global step 1250 Train loss 0.09 Classification-F1 0.6111398405516053 on epoch=312
06/10/2022 15:38:09 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.11 on epoch=314
06/10/2022 15:38:11 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.06 on epoch=317
06/10/2022 15:38:14 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.09 on epoch=319
06/10/2022 15:38:16 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.04 on epoch=322
06/10/2022 15:38:18 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.13 on epoch=324
06/10/2022 15:38:19 - INFO - __main__ - Global step 1300 Train loss 0.09 Classification-F1 0.6564636327503974 on epoch=324
06/10/2022 15:38:21 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.06 on epoch=327
06/10/2022 15:38:24 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.05 on epoch=329
06/10/2022 15:38:26 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.05 on epoch=332
06/10/2022 15:38:28 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.08 on epoch=334
06/10/2022 15:38:31 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.04 on epoch=337
06/10/2022 15:38:32 - INFO - __main__ - Global step 1350 Train loss 0.06 Classification-F1 0.6648425446599888 on epoch=337
06/10/2022 15:38:34 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.10 on epoch=339
06/10/2022 15:38:36 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.03 on epoch=342
06/10/2022 15:38:39 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.08 on epoch=344
06/10/2022 15:38:41 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.10 on epoch=347
06/10/2022 15:38:43 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.04 on epoch=349
06/10/2022 15:38:44 - INFO - __main__ - Global step 1400 Train loss 0.07 Classification-F1 0.6766066066066065 on epoch=349
06/10/2022 15:38:47 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.04 on epoch=352
06/10/2022 15:38:49 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.07 on epoch=354
06/10/2022 15:38:51 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.04 on epoch=357
06/10/2022 15:38:54 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.07 on epoch=359
06/10/2022 15:38:56 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.07 on epoch=362
06/10/2022 15:38:57 - INFO - __main__ - Global step 1450 Train loss 0.06 Classification-F1 0.6565058479532164 on epoch=362
06/10/2022 15:38:59 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.03 on epoch=364
06/10/2022 15:39:02 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.04 on epoch=367
06/10/2022 15:39:04 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.09 on epoch=369
06/10/2022 15:39:06 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.04 on epoch=372
06/10/2022 15:39:09 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.07 on epoch=374
06/10/2022 15:39:10 - INFO - __main__ - Global step 1500 Train loss 0.05 Classification-F1 0.6279113214597086 on epoch=374
06/10/2022 15:39:12 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.11 on epoch=377
06/10/2022 15:39:14 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.04 on epoch=379
06/10/2022 15:39:17 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.06 on epoch=382
06/10/2022 15:39:19 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.06 on epoch=384
06/10/2022 15:39:21 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.06 on epoch=387
06/10/2022 15:39:22 - INFO - __main__ - Global step 1550 Train loss 0.07 Classification-F1 0.6931246218995766 on epoch=387
06/10/2022 15:39:22 - INFO - __main__ - Saving model with best Classification-F1: 0.68006993006993 -> 0.6931246218995766 on epoch=387, global_step=1550
06/10/2022 15:39:25 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.07 on epoch=389
06/10/2022 15:39:27 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.04 on epoch=392
06/10/2022 15:39:29 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.12 on epoch=394
06/10/2022 15:39:32 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.06 on epoch=397
06/10/2022 15:39:34 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.09 on epoch=399
06/10/2022 15:39:35 - INFO - __main__ - Global step 1600 Train loss 0.08 Classification-F1 0.6645216645216645 on epoch=399
06/10/2022 15:39:37 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=402
06/10/2022 15:39:40 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.08 on epoch=404
06/10/2022 15:39:42 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.04 on epoch=407
06/10/2022 15:39:44 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.04 on epoch=409
06/10/2022 15:39:47 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.07 on epoch=412
06/10/2022 15:39:47 - INFO - __main__ - Global step 1650 Train loss 0.05 Classification-F1 0.6730901451489687 on epoch=412
06/10/2022 15:39:50 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.08 on epoch=414
06/10/2022 15:39:52 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.03 on epoch=417
06/10/2022 15:39:55 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.12 on epoch=419
06/10/2022 15:39:57 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.03 on epoch=422
06/10/2022 15:39:59 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=424
06/10/2022 15:40:00 - INFO - __main__ - Global step 1700 Train loss 0.06 Classification-F1 0.6843696717817562 on epoch=424
06/10/2022 15:40:03 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.14 on epoch=427
06/10/2022 15:40:05 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.07 on epoch=429
06/10/2022 15:40:07 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.06 on epoch=432
06/10/2022 15:40:10 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.07 on epoch=434
06/10/2022 15:40:12 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.04 on epoch=437
06/10/2022 15:40:13 - INFO - __main__ - Global step 1750 Train loss 0.08 Classification-F1 0.6531400966183575 on epoch=437
06/10/2022 15:40:15 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.06 on epoch=439
06/10/2022 15:40:18 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.04 on epoch=442
06/10/2022 15:40:20 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.08 on epoch=444
06/10/2022 15:40:22 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.05 on epoch=447
06/10/2022 15:40:25 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.09 on epoch=449
06/10/2022 15:40:26 - INFO - __main__ - Global step 1800 Train loss 0.06 Classification-F1 0.659352155496345 on epoch=449
06/10/2022 15:40:28 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.05 on epoch=452
06/10/2022 15:40:30 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.05 on epoch=454
06/10/2022 15:40:33 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=457
06/10/2022 15:40:35 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.04 on epoch=459
06/10/2022 15:40:37 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=462
06/10/2022 15:40:38 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.643452380952381 on epoch=462
06/10/2022 15:40:41 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=464
06/10/2022 15:40:43 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.05 on epoch=467
06/10/2022 15:40:45 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=469
06/10/2022 15:40:48 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.03 on epoch=472
06/10/2022 15:40:50 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=474
06/10/2022 15:40:51 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.6450757575757576 on epoch=474
06/10/2022 15:40:53 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.05 on epoch=477
06/10/2022 15:40:56 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=479
06/10/2022 15:40:58 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=482
06/10/2022 15:41:00 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.13 on epoch=484
06/10/2022 15:41:03 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.05 on epoch=487
06/10/2022 15:41:04 - INFO - __main__ - Global step 1950 Train loss 0.06 Classification-F1 0.6677201939570755 on epoch=487
06/10/2022 15:41:06 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.04 on epoch=489
06/10/2022 15:41:08 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=492
06/10/2022 15:41:11 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.06 on epoch=494
06/10/2022 15:41:13 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.07 on epoch=497
06/10/2022 15:41:15 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.04 on epoch=499
06/10/2022 15:41:16 - INFO - __main__ - Global step 2000 Train loss 0.05 Classification-F1 0.6667718772192851 on epoch=499
06/10/2022 15:41:19 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.04 on epoch=502
06/10/2022 15:41:21 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=504
06/10/2022 15:41:23 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.02 on epoch=507
06/10/2022 15:41:26 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=509
06/10/2022 15:41:28 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.06 on epoch=512
06/10/2022 15:41:29 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.6305704099821747 on epoch=512
06/10/2022 15:41:31 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.07 on epoch=514
06/10/2022 15:41:34 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.05 on epoch=517
06/10/2022 15:41:36 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.12 on epoch=519
06/10/2022 15:41:39 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.08 on epoch=522
06/10/2022 15:41:41 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=524
06/10/2022 15:41:42 - INFO - __main__ - Global step 2100 Train loss 0.07 Classification-F1 0.6706263922118637 on epoch=524
06/10/2022 15:41:44 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.04 on epoch=527
06/10/2022 15:41:47 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.06 on epoch=529
06/10/2022 15:41:49 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=532
06/10/2022 15:41:51 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.08 on epoch=534
06/10/2022 15:41:54 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.09 on epoch=537
06/10/2022 15:41:54 - INFO - __main__ - Global step 2150 Train loss 0.05 Classification-F1 0.6502791563275434 on epoch=537
06/10/2022 15:41:57 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.05 on epoch=539
06/10/2022 15:41:59 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=542
06/10/2022 15:42:02 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.04 on epoch=544
06/10/2022 15:42:04 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.04 on epoch=547
06/10/2022 15:42:06 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=549
06/10/2022 15:42:07 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.6967514499071301 on epoch=549
06/10/2022 15:42:07 - INFO - __main__ - Saving model with best Classification-F1: 0.6931246218995766 -> 0.6967514499071301 on epoch=549, global_step=2200
06/10/2022 15:42:10 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.08 on epoch=552
06/10/2022 15:42:12 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=554
06/10/2022 15:42:14 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=557
06/10/2022 15:42:17 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=559
06/10/2022 15:42:19 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.04 on epoch=562
06/10/2022 15:42:20 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.6575015747341724 on epoch=562
06/10/2022 15:42:22 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.03 on epoch=564
06/10/2022 15:42:25 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=567
06/10/2022 15:42:27 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.06 on epoch=569
06/10/2022 15:42:29 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=572
06/10/2022 15:42:32 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.04 on epoch=574
06/10/2022 15:42:33 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.6960311784897025 on epoch=574
06/10/2022 15:42:35 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.04 on epoch=577
06/10/2022 15:42:37 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.06 on epoch=579
06/10/2022 15:42:40 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=582
06/10/2022 15:42:42 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=584
06/10/2022 15:42:44 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.07 on epoch=587
06/10/2022 15:42:45 - INFO - __main__ - Global step 2350 Train loss 0.04 Classification-F1 0.7102270120096945 on epoch=587
06/10/2022 15:42:45 - INFO - __main__ - Saving model with best Classification-F1: 0.6967514499071301 -> 0.7102270120096945 on epoch=587, global_step=2350
06/10/2022 15:42:48 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=589
06/10/2022 15:42:50 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.04 on epoch=592
06/10/2022 15:42:52 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/10/2022 15:42:55 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=597
06/10/2022 15:42:57 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=599
06/10/2022 15:42:58 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.6967514499071301 on epoch=599
06/10/2022 15:43:00 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.03 on epoch=602
06/10/2022 15:43:03 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=604
06/10/2022 15:43:05 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.04 on epoch=607
06/10/2022 15:43:07 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.07 on epoch=609
06/10/2022 15:43:10 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=612
06/10/2022 15:43:11 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.7090690559440559 on epoch=612
06/10/2022 15:43:13 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.02 on epoch=614
06/10/2022 15:43:15 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.04 on epoch=617
06/10/2022 15:43:18 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.04 on epoch=619
06/10/2022 15:43:20 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=622
06/10/2022 15:43:22 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=624
06/10/2022 15:43:23 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.6832134553908747 on epoch=624
06/10/2022 15:43:26 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=627
06/10/2022 15:43:28 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.04 on epoch=629
06/10/2022 15:43:30 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.07 on epoch=632
06/10/2022 15:43:33 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=634
06/10/2022 15:43:35 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.06 on epoch=637
06/10/2022 15:43:36 - INFO - __main__ - Global step 2550 Train loss 0.04 Classification-F1 0.7102270120096945 on epoch=637
06/10/2022 15:43:38 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/10/2022 15:43:41 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=642
06/10/2022 15:43:43 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/10/2022 15:43:45 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=647
06/10/2022 15:43:48 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=649
06/10/2022 15:43:49 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.7425163094128612 on epoch=649
06/10/2022 15:43:49 - INFO - __main__ - Saving model with best Classification-F1: 0.7102270120096945 -> 0.7425163094128612 on epoch=649, global_step=2600
06/10/2022 15:43:51 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.03 on epoch=652
06/10/2022 15:43:53 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=654
06/10/2022 15:43:56 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.03 on epoch=657
06/10/2022 15:43:58 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.06 on epoch=659
06/10/2022 15:44:00 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=662
06/10/2022 15:44:01 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.6843395815170009 on epoch=662
06/10/2022 15:44:04 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=664
06/10/2022 15:44:06 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=667
06/10/2022 15:44:08 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.05 on epoch=669
06/10/2022 15:44:11 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.03 on epoch=672
06/10/2022 15:44:13 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=674
06/10/2022 15:44:14 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.7102270120096945 on epoch=674
06/10/2022 15:44:16 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/10/2022 15:44:19 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=679
06/10/2022 15:44:21 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.03 on epoch=682
06/10/2022 15:44:24 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=684
06/10/2022 15:44:26 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=687
06/10/2022 15:44:27 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.6967514499071301 on epoch=687
06/10/2022 15:44:30 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.03 on epoch=689
06/10/2022 15:44:32 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=692
06/10/2022 15:44:34 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/10/2022 15:44:37 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.03 on epoch=697
06/10/2022 15:44:39 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.25 on epoch=699
06/10/2022 15:44:40 - INFO - __main__ - Global step 2800 Train loss 0.06 Classification-F1 0.6852763242565875 on epoch=699
06/10/2022 15:44:42 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=702
06/10/2022 15:44:45 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=704
06/10/2022 15:44:47 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=707
06/10/2022 15:44:49 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.03 on epoch=709
06/10/2022 15:44:52 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=712
06/10/2022 15:44:53 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.6852763242565875 on epoch=712
06/10/2022 15:44:55 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.05 on epoch=714
06/10/2022 15:44:57 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.03 on epoch=717
06/10/2022 15:45:00 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=719
06/10/2022 15:45:02 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.03 on epoch=722
06/10/2022 15:45:05 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.06 on epoch=724
06/10/2022 15:45:06 - INFO - __main__ - Global step 2900 Train loss 0.04 Classification-F1 0.6967514499071301 on epoch=724
06/10/2022 15:45:08 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=727
06/10/2022 15:45:10 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.03 on epoch=729
06/10/2022 15:45:13 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/10/2022 15:45:15 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=734
06/10/2022 15:45:17 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.03 on epoch=737
06/10/2022 15:45:18 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.6967514499071301 on epoch=737
06/10/2022 15:45:21 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=739
06/10/2022 15:45:23 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/10/2022 15:45:26 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/10/2022 15:45:28 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/10/2022 15:45:30 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=749
06/10/2022 15:45:31 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.6852763242565875 on epoch=749
06/10/2022 15:45:31 - INFO - __main__ - save last model!
06/10/2022 15:45:31 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/10/2022 15:45:31 - INFO - __main__ - Start tokenizing ... 5509 instances
06/10/2022 15:45:31 - INFO - __main__ - Printing 3 examples
06/10/2022 15:45:31 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/10/2022 15:45:31 - INFO - __main__ - ['others']
06/10/2022 15:45:31 - INFO - __main__ -  [emo] what you like very little things ok
06/10/2022 15:45:31 - INFO - __main__ - ['others']
06/10/2022 15:45:31 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/10/2022 15:45:31 - INFO - __main__ - ['others']
06/10/2022 15:45:31 - INFO - __main__ - Tokenizing Input ...
06/10/2022 15:45:31 - INFO - __main__ - Start tokenizing ... 64 instances
06/10/2022 15:45:31 - INFO - __main__ - Printing 3 examples
06/10/2022 15:45:31 - INFO - __main__ -  [emo] how cause yes am listening
06/10/2022 15:45:31 - INFO - __main__ - ['others']
06/10/2022 15:45:31 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/10/2022 15:45:31 - INFO - __main__ - ['others']
06/10/2022 15:45:31 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/10/2022 15:45:31 - INFO - __main__ - ['others']
06/10/2022 15:45:31 - INFO - __main__ - Tokenizing Input ...
06/10/2022 15:45:31 - INFO - __main__ - Tokenizing Output ...
06/10/2022 15:45:32 - INFO - __main__ - Loaded 64 examples from train data
06/10/2022 15:45:32 - INFO - __main__ - Start tokenizing ... 64 instances
06/10/2022 15:45:32 - INFO - __main__ - Printing 3 examples
06/10/2022 15:45:32 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
06/10/2022 15:45:32 - INFO - __main__ - ['others']
06/10/2022 15:45:32 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
06/10/2022 15:45:32 - INFO - __main__ - ['others']
06/10/2022 15:45:32 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
06/10/2022 15:45:32 - INFO - __main__ - ['others']
06/10/2022 15:45:32 - INFO - __main__ - Tokenizing Input ...
06/10/2022 15:45:32 - INFO - __main__ - Tokenizing Output ...
06/10/2022 15:45:32 - INFO - __main__ - Loaded 64 examples from dev data
06/10/2022 15:45:33 - INFO - __main__ - Tokenizing Output ...
06/10/2022 15:45:39 - INFO - __main__ - Loaded 5509 examples from test data
06/10/2022 15:45:47 - INFO - __main__ - load prompt embedding from ckpt
06/10/2022 15:45:48 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/10/2022 15:45:48 - INFO - __main__ - Starting training!
06/10/2022 15:47:01 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-up32shot/singletask-emo/emo_16_100_0.3_8_predictions.txt
06/10/2022 15:47:01 - INFO - __main__ - Classification-F1 on test data: 0.2783
06/10/2022 15:47:01 - INFO - __main__ - prefix=emo_16_100, lr=0.3, bsz=8, dev_performance=0.7425163094128612, test_performance=0.2782898157456647
06/10/2022 15:47:01 - INFO - __main__ - Running ... prefix=emo_16_100, lr=0.2, bsz=8 ...
06/10/2022 15:47:02 - INFO - __main__ - Start tokenizing ... 64 instances
06/10/2022 15:47:02 - INFO - __main__ - Printing 3 examples
06/10/2022 15:47:02 - INFO - __main__ -  [emo] how cause yes am listening
06/10/2022 15:47:02 - INFO - __main__ - ['others']
06/10/2022 15:47:02 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/10/2022 15:47:02 - INFO - __main__ - ['others']
06/10/2022 15:47:02 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/10/2022 15:47:02 - INFO - __main__ - ['others']
06/10/2022 15:47:02 - INFO - __main__ - Tokenizing Input ...
06/10/2022 15:47:02 - INFO - __main__ - Tokenizing Output ...
06/10/2022 15:47:03 - INFO - __main__ - Loaded 64 examples from train data
06/10/2022 15:47:03 - INFO - __main__ - Start tokenizing ... 64 instances
06/10/2022 15:47:03 - INFO - __main__ - Printing 3 examples
06/10/2022 15:47:03 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
06/10/2022 15:47:03 - INFO - __main__ - ['others']
06/10/2022 15:47:03 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
06/10/2022 15:47:03 - INFO - __main__ - ['others']
06/10/2022 15:47:03 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
06/10/2022 15:47:03 - INFO - __main__ - ['others']
06/10/2022 15:47:03 - INFO - __main__ - Tokenizing Input ...
06/10/2022 15:47:03 - INFO - __main__ - Tokenizing Output ...
06/10/2022 15:47:03 - INFO - __main__ - Loaded 64 examples from dev data
06/10/2022 15:47:18 - INFO - __main__ - load prompt embedding from ckpt
06/10/2022 15:47:19 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/10/2022 15:47:19 - INFO - __main__ - Starting training!
06/10/2022 15:47:21 - INFO - __main__ - Step 10 Global step 10 Train loss 4.21 on epoch=2
06/10/2022 15:47:24 - INFO - __main__ - Step 20 Global step 20 Train loss 3.23 on epoch=4
06/10/2022 15:47:26 - INFO - __main__ - Step 30 Global step 30 Train loss 2.59 on epoch=7
06/10/2022 15:47:28 - INFO - __main__ - Step 40 Global step 40 Train loss 2.37 on epoch=9
06/10/2022 15:47:31 - INFO - __main__ - Step 50 Global step 50 Train loss 2.13 on epoch=12
06/10/2022 15:47:32 - INFO - __main__ - Global step 50 Train loss 2.91 Classification-F1 0.03728757630754 on epoch=12
06/10/2022 15:47:32 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.03728757630754 on epoch=12, global_step=50
06/10/2022 15:47:34 - INFO - __main__ - Step 60 Global step 60 Train loss 1.87 on epoch=14
06/10/2022 15:47:37 - INFO - __main__ - Step 70 Global step 70 Train loss 1.64 on epoch=17
06/10/2022 15:47:39 - INFO - __main__ - Step 80 Global step 80 Train loss 1.41 on epoch=19
06/10/2022 15:47:41 - INFO - __main__ - Step 90 Global step 90 Train loss 1.40 on epoch=22
06/10/2022 15:47:44 - INFO - __main__ - Step 100 Global step 100 Train loss 1.23 on epoch=24
06/10/2022 15:47:45 - INFO - __main__ - Global step 100 Train loss 1.51 Classification-F1 0.225 on epoch=24
06/10/2022 15:47:45 - INFO - __main__ - Saving model with best Classification-F1: 0.03728757630754 -> 0.225 on epoch=24, global_step=100
06/10/2022 15:47:47 - INFO - __main__ - Step 110 Global step 110 Train loss 1.08 on epoch=27
06/10/2022 15:47:49 - INFO - __main__ - Step 120 Global step 120 Train loss 1.03 on epoch=29
06/10/2022 15:47:52 - INFO - __main__ - Step 130 Global step 130 Train loss 0.92 on epoch=32
06/10/2022 15:47:54 - INFO - __main__ - Step 140 Global step 140 Train loss 0.81 on epoch=34
06/10/2022 15:47:57 - INFO - __main__ - Step 150 Global step 150 Train loss 1.00 on epoch=37
06/10/2022 15:47:57 - INFO - __main__ - Global step 150 Train loss 0.97 Classification-F1 0.39817429753244904 on epoch=37
06/10/2022 15:47:57 - INFO - __main__ - Saving model with best Classification-F1: 0.225 -> 0.39817429753244904 on epoch=37, global_step=150
06/10/2022 15:48:00 - INFO - __main__ - Step 160 Global step 160 Train loss 0.73 on epoch=39
06/10/2022 15:48:02 - INFO - __main__ - Step 170 Global step 170 Train loss 0.81 on epoch=42
06/10/2022 15:48:05 - INFO - __main__ - Step 180 Global step 180 Train loss 0.74 on epoch=44
06/10/2022 15:48:07 - INFO - __main__ - Step 190 Global step 190 Train loss 0.79 on epoch=47
06/10/2022 15:48:09 - INFO - __main__ - Step 200 Global step 200 Train loss 0.78 on epoch=49
06/10/2022 15:48:10 - INFO - __main__ - Global step 200 Train loss 0.77 Classification-F1 0.5211587436332767 on epoch=49
06/10/2022 15:48:10 - INFO - __main__ - Saving model with best Classification-F1: 0.39817429753244904 -> 0.5211587436332767 on epoch=49, global_step=200
06/10/2022 15:48:13 - INFO - __main__ - Step 210 Global step 210 Train loss 0.83 on epoch=52
06/10/2022 15:48:15 - INFO - __main__ - Step 220 Global step 220 Train loss 0.66 on epoch=54
06/10/2022 15:48:17 - INFO - __main__ - Step 230 Global step 230 Train loss 0.68 on epoch=57
06/10/2022 15:48:20 - INFO - __main__ - Step 240 Global step 240 Train loss 0.62 on epoch=59
06/10/2022 15:48:22 - INFO - __main__ - Step 250 Global step 250 Train loss 0.64 on epoch=62
06/10/2022 15:48:23 - INFO - __main__ - Global step 250 Train loss 0.69 Classification-F1 0.5602756892230577 on epoch=62
06/10/2022 15:48:23 - INFO - __main__ - Saving model with best Classification-F1: 0.5211587436332767 -> 0.5602756892230577 on epoch=62, global_step=250
06/10/2022 15:48:25 - INFO - __main__ - Step 260 Global step 260 Train loss 0.76 on epoch=64
06/10/2022 15:48:27 - INFO - __main__ - Step 270 Global step 270 Train loss 0.68 on epoch=67
06/10/2022 15:48:30 - INFO - __main__ - Step 280 Global step 280 Train loss 0.68 on epoch=69
06/10/2022 15:48:32 - INFO - __main__ - Step 290 Global step 290 Train loss 0.82 on epoch=72
06/10/2022 15:48:35 - INFO - __main__ - Step 300 Global step 300 Train loss 0.56 on epoch=74
06/10/2022 15:48:35 - INFO - __main__ - Global step 300 Train loss 0.70 Classification-F1 0.5602921468775127 on epoch=74
06/10/2022 15:48:35 - INFO - __main__ - Saving model with best Classification-F1: 0.5602756892230577 -> 0.5602921468775127 on epoch=74, global_step=300
06/10/2022 15:48:38 - INFO - __main__ - Step 310 Global step 310 Train loss 0.60 on epoch=77
06/10/2022 15:48:40 - INFO - __main__ - Step 320 Global step 320 Train loss 0.67 on epoch=79
06/10/2022 15:48:43 - INFO - __main__ - Step 330 Global step 330 Train loss 0.64 on epoch=82
06/10/2022 15:48:45 - INFO - __main__ - Step 340 Global step 340 Train loss 0.58 on epoch=84
06/10/2022 15:48:47 - INFO - __main__ - Step 350 Global step 350 Train loss 0.63 on epoch=87
06/10/2022 15:48:48 - INFO - __main__ - Global step 350 Train loss 0.62 Classification-F1 0.636927349722268 on epoch=87
06/10/2022 15:48:48 - INFO - __main__ - Saving model with best Classification-F1: 0.5602921468775127 -> 0.636927349722268 on epoch=87, global_step=350
06/10/2022 15:48:51 - INFO - __main__ - Step 360 Global step 360 Train loss 0.60 on epoch=89
06/10/2022 15:48:53 - INFO - __main__ - Step 370 Global step 370 Train loss 0.64 on epoch=92
06/10/2022 15:48:55 - INFO - __main__ - Step 380 Global step 380 Train loss 0.57 on epoch=94
06/10/2022 15:48:58 - INFO - __main__ - Step 390 Global step 390 Train loss 0.64 on epoch=97
06/10/2022 15:49:00 - INFO - __main__ - Step 400 Global step 400 Train loss 0.53 on epoch=99
06/10/2022 15:49:01 - INFO - __main__ - Global step 400 Train loss 0.59 Classification-F1 0.6055174076163581 on epoch=99
06/10/2022 15:49:03 - INFO - __main__ - Step 410 Global step 410 Train loss 0.60 on epoch=102
06/10/2022 15:49:05 - INFO - __main__ - Step 420 Global step 420 Train loss 0.56 on epoch=104
06/10/2022 15:49:08 - INFO - __main__ - Step 430 Global step 430 Train loss 0.63 on epoch=107
06/10/2022 15:49:10 - INFO - __main__ - Step 440 Global step 440 Train loss 0.59 on epoch=109
06/10/2022 15:49:13 - INFO - __main__ - Step 450 Global step 450 Train loss 0.57 on epoch=112
06/10/2022 15:49:14 - INFO - __main__ - Global step 450 Train loss 0.59 Classification-F1 0.6482866595769821 on epoch=112
06/10/2022 15:49:14 - INFO - __main__ - Saving model with best Classification-F1: 0.636927349722268 -> 0.6482866595769821 on epoch=112, global_step=450
06/10/2022 15:49:16 - INFO - __main__ - Step 460 Global step 460 Train loss 0.52 on epoch=114
06/10/2022 15:49:18 - INFO - __main__ - Step 470 Global step 470 Train loss 0.56 on epoch=117
06/10/2022 15:49:21 - INFO - __main__ - Step 480 Global step 480 Train loss 0.49 on epoch=119
06/10/2022 15:49:23 - INFO - __main__ - Step 490 Global step 490 Train loss 0.53 on epoch=122
06/10/2022 15:49:25 - INFO - __main__ - Step 500 Global step 500 Train loss 0.42 on epoch=124
06/10/2022 15:49:26 - INFO - __main__ - Global step 500 Train loss 0.50 Classification-F1 0.6619080831984058 on epoch=124
06/10/2022 15:49:26 - INFO - __main__ - Saving model with best Classification-F1: 0.6482866595769821 -> 0.6619080831984058 on epoch=124, global_step=500
06/10/2022 15:49:29 - INFO - __main__ - Step 510 Global step 510 Train loss 0.51 on epoch=127
06/10/2022 15:49:31 - INFO - __main__ - Step 520 Global step 520 Train loss 0.54 on epoch=129
06/10/2022 15:49:33 - INFO - __main__ - Step 530 Global step 530 Train loss 0.54 on epoch=132
06/10/2022 15:49:36 - INFO - __main__ - Step 540 Global step 540 Train loss 0.47 on epoch=134
06/10/2022 15:49:38 - INFO - __main__ - Step 550 Global step 550 Train loss 0.48 on epoch=137
06/10/2022 15:49:39 - INFO - __main__ - Global step 550 Train loss 0.51 Classification-F1 0.6499061273254823 on epoch=137
06/10/2022 15:49:41 - INFO - __main__ - Step 560 Global step 560 Train loss 0.47 on epoch=139
06/10/2022 15:49:44 - INFO - __main__ - Step 570 Global step 570 Train loss 0.44 on epoch=142
06/10/2022 15:49:46 - INFO - __main__ - Step 580 Global step 580 Train loss 0.39 on epoch=144
06/10/2022 15:49:49 - INFO - __main__ - Step 590 Global step 590 Train loss 0.41 on epoch=147
06/10/2022 15:49:51 - INFO - __main__ - Step 600 Global step 600 Train loss 0.44 on epoch=149
06/10/2022 15:49:52 - INFO - __main__ - Global step 600 Train loss 0.43 Classification-F1 0.6777526395173454 on epoch=149
06/10/2022 15:49:52 - INFO - __main__ - Saving model with best Classification-F1: 0.6619080831984058 -> 0.6777526395173454 on epoch=149, global_step=600
06/10/2022 15:49:54 - INFO - __main__ - Step 610 Global step 610 Train loss 0.46 on epoch=152
06/10/2022 15:49:56 - INFO - __main__ - Step 620 Global step 620 Train loss 0.47 on epoch=154
06/10/2022 15:49:59 - INFO - __main__ - Step 630 Global step 630 Train loss 0.50 on epoch=157
06/10/2022 15:50:01 - INFO - __main__ - Step 640 Global step 640 Train loss 0.43 on epoch=159
06/10/2022 15:50:04 - INFO - __main__ - Step 650 Global step 650 Train loss 0.44 on epoch=162
06/10/2022 15:50:04 - INFO - __main__ - Global step 650 Train loss 0.46 Classification-F1 0.6617804172951232 on epoch=162
06/10/2022 15:50:07 - INFO - __main__ - Step 660 Global step 660 Train loss 0.48 on epoch=164
06/10/2022 15:50:09 - INFO - __main__ - Step 670 Global step 670 Train loss 0.47 on epoch=167
06/10/2022 15:50:12 - INFO - __main__ - Step 680 Global step 680 Train loss 0.45 on epoch=169
06/10/2022 15:50:14 - INFO - __main__ - Step 690 Global step 690 Train loss 0.41 on epoch=172
06/10/2022 15:50:16 - INFO - __main__ - Step 700 Global step 700 Train loss 0.38 on epoch=174
06/10/2022 15:50:17 - INFO - __main__ - Global step 700 Train loss 0.44 Classification-F1 0.6496831055654585 on epoch=174
06/10/2022 15:50:19 - INFO - __main__ - Step 710 Global step 710 Train loss 0.45 on epoch=177
06/10/2022 15:50:22 - INFO - __main__ - Step 720 Global step 720 Train loss 0.49 on epoch=179
06/10/2022 15:50:24 - INFO - __main__ - Step 730 Global step 730 Train loss 0.39 on epoch=182
06/10/2022 15:50:27 - INFO - __main__ - Step 740 Global step 740 Train loss 0.37 on epoch=184
06/10/2022 15:50:29 - INFO - __main__ - Step 750 Global step 750 Train loss 0.33 on epoch=187
06/10/2022 15:50:30 - INFO - __main__ - Global step 750 Train loss 0.41 Classification-F1 0.6503185145025752 on epoch=187
06/10/2022 15:50:32 - INFO - __main__ - Step 760 Global step 760 Train loss 0.41 on epoch=189
06/10/2022 15:50:35 - INFO - __main__ - Step 770 Global step 770 Train loss 0.42 on epoch=192
06/10/2022 15:50:37 - INFO - __main__ - Step 780 Global step 780 Train loss 0.35 on epoch=194
06/10/2022 15:50:39 - INFO - __main__ - Step 790 Global step 790 Train loss 0.32 on epoch=197
06/10/2022 15:50:42 - INFO - __main__ - Step 800 Global step 800 Train loss 0.33 on epoch=199
06/10/2022 15:50:43 - INFO - __main__ - Global step 800 Train loss 0.36 Classification-F1 0.6651092268739328 on epoch=199
06/10/2022 15:50:45 - INFO - __main__ - Step 810 Global step 810 Train loss 0.42 on epoch=202
06/10/2022 15:50:47 - INFO - __main__ - Step 820 Global step 820 Train loss 0.32 on epoch=204
06/10/2022 15:50:50 - INFO - __main__ - Step 830 Global step 830 Train loss 0.33 on epoch=207
06/10/2022 15:50:52 - INFO - __main__ - Step 840 Global step 840 Train loss 0.40 on epoch=209
06/10/2022 15:50:54 - INFO - __main__ - Step 850 Global step 850 Train loss 0.34 on epoch=212
06/10/2022 15:50:55 - INFO - __main__ - Global step 850 Train loss 0.36 Classification-F1 0.6794842412489472 on epoch=212
06/10/2022 15:50:55 - INFO - __main__ - Saving model with best Classification-F1: 0.6777526395173454 -> 0.6794842412489472 on epoch=212, global_step=850
06/10/2022 15:50:58 - INFO - __main__ - Step 860 Global step 860 Train loss 0.38 on epoch=214
06/10/2022 15:51:00 - INFO - __main__ - Step 870 Global step 870 Train loss 0.34 on epoch=217
06/10/2022 15:51:02 - INFO - __main__ - Step 880 Global step 880 Train loss 0.31 on epoch=219
06/10/2022 15:51:05 - INFO - __main__ - Step 890 Global step 890 Train loss 0.49 on epoch=222
06/10/2022 15:51:07 - INFO - __main__ - Step 900 Global step 900 Train loss 0.28 on epoch=224
06/10/2022 15:51:08 - INFO - __main__ - Global step 900 Train loss 0.36 Classification-F1 0.6545977011494253 on epoch=224
06/10/2022 15:51:10 - INFO - __main__ - Step 910 Global step 910 Train loss 0.36 on epoch=227
06/10/2022 15:51:13 - INFO - __main__ - Step 920 Global step 920 Train loss 0.25 on epoch=229
06/10/2022 15:51:15 - INFO - __main__ - Step 930 Global step 930 Train loss 0.23 on epoch=232
06/10/2022 15:51:17 - INFO - __main__ - Step 940 Global step 940 Train loss 0.36 on epoch=234
06/10/2022 15:51:20 - INFO - __main__ - Step 950 Global step 950 Train loss 0.21 on epoch=237
06/10/2022 15:51:21 - INFO - __main__ - Global step 950 Train loss 0.28 Classification-F1 0.6507352941176471 on epoch=237
06/10/2022 15:51:23 - INFO - __main__ - Step 960 Global step 960 Train loss 0.28 on epoch=239
06/10/2022 15:51:25 - INFO - __main__ - Step 970 Global step 970 Train loss 0.35 on epoch=242
06/10/2022 15:51:28 - INFO - __main__ - Step 980 Global step 980 Train loss 0.25 on epoch=244
06/10/2022 15:51:30 - INFO - __main__ - Step 990 Global step 990 Train loss 0.34 on epoch=247
06/10/2022 15:51:32 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.28 on epoch=249
06/10/2022 15:51:33 - INFO - __main__ - Global step 1000 Train loss 0.30 Classification-F1 0.6690476190476191 on epoch=249
06/10/2022 15:51:36 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.33 on epoch=252
06/10/2022 15:51:38 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.30 on epoch=254
06/10/2022 15:51:40 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.31 on epoch=257
06/10/2022 15:51:43 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.27 on epoch=259
06/10/2022 15:51:45 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.24 on epoch=262
06/10/2022 15:51:46 - INFO - __main__ - Global step 1050 Train loss 0.29 Classification-F1 0.6697147156971799 on epoch=262
06/10/2022 15:51:48 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.17 on epoch=264
06/10/2022 15:51:51 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.32 on epoch=267
06/10/2022 15:51:53 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.31 on epoch=269
06/10/2022 15:51:55 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.21 on epoch=272
06/10/2022 15:51:58 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.21 on epoch=274
06/10/2022 15:51:59 - INFO - __main__ - Global step 1100 Train loss 0.24 Classification-F1 0.6838603739604853 on epoch=274
06/10/2022 15:51:59 - INFO - __main__ - Saving model with best Classification-F1: 0.6794842412489472 -> 0.6838603739604853 on epoch=274, global_step=1100
06/10/2022 15:52:01 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.35 on epoch=277
06/10/2022 15:52:03 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.21 on epoch=279
06/10/2022 15:52:06 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.20 on epoch=282
06/10/2022 15:52:08 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.24 on epoch=284
06/10/2022 15:52:10 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.24 on epoch=287
06/10/2022 15:52:11 - INFO - __main__ - Global step 1150 Train loss 0.25 Classification-F1 0.6838603739604853 on epoch=287
06/10/2022 15:52:14 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.18 on epoch=289
06/10/2022 15:52:16 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.22 on epoch=292
06/10/2022 15:52:18 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.22 on epoch=294
06/10/2022 15:52:21 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.19 on epoch=297
06/10/2022 15:52:23 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.20 on epoch=299
06/10/2022 15:52:24 - INFO - __main__ - Global step 1200 Train loss 0.21 Classification-F1 0.6838603739604853 on epoch=299
06/10/2022 15:52:26 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.23 on epoch=302
06/10/2022 15:52:29 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.27 on epoch=304
06/10/2022 15:52:31 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.21 on epoch=307
06/10/2022 15:52:33 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.13 on epoch=309
06/10/2022 15:52:36 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.23 on epoch=312
06/10/2022 15:52:37 - INFO - __main__ - Global step 1250 Train loss 0.21 Classification-F1 0.6838603739604853 on epoch=312
06/10/2022 15:52:39 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.22 on epoch=314
06/10/2022 15:52:41 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.21 on epoch=317
06/10/2022 15:52:44 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.19 on epoch=319
06/10/2022 15:52:46 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.16 on epoch=322
06/10/2022 15:52:48 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.20 on epoch=324
06/10/2022 15:52:49 - INFO - __main__ - Global step 1300 Train loss 0.20 Classification-F1 0.6985904039034969 on epoch=324
06/10/2022 15:52:49 - INFO - __main__ - Saving model with best Classification-F1: 0.6838603739604853 -> 0.6985904039034969 on epoch=324, global_step=1300
06/10/2022 15:52:52 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.15 on epoch=327
06/10/2022 15:52:54 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.25 on epoch=329
06/10/2022 15:52:57 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.17 on epoch=332
06/10/2022 15:52:59 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.23 on epoch=334
06/10/2022 15:53:01 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.18 on epoch=337
06/10/2022 15:53:02 - INFO - __main__ - Global step 1350 Train loss 0.20 Classification-F1 0.6976190476190477 on epoch=337
06/10/2022 15:53:05 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.16 on epoch=339
06/10/2022 15:53:07 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.18 on epoch=342
06/10/2022 15:53:09 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.17 on epoch=344
06/10/2022 15:53:12 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.12 on epoch=347
06/10/2022 15:53:14 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.15 on epoch=349
06/10/2022 15:53:15 - INFO - __main__ - Global step 1400 Train loss 0.16 Classification-F1 0.7111250348092453 on epoch=349
06/10/2022 15:53:15 - INFO - __main__ - Saving model with best Classification-F1: 0.6985904039034969 -> 0.7111250348092453 on epoch=349, global_step=1400
06/10/2022 15:53:17 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.30 on epoch=352
06/10/2022 15:53:20 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.17 on epoch=354
06/10/2022 15:53:22 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.18 on epoch=357
06/10/2022 15:53:25 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.26 on epoch=359
06/10/2022 15:53:27 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.20 on epoch=362
06/10/2022 15:53:28 - INFO - __main__ - Global step 1450 Train loss 0.22 Classification-F1 0.7126710454296662 on epoch=362
06/10/2022 15:53:28 - INFO - __main__ - Saving model with best Classification-F1: 0.7111250348092453 -> 0.7126710454296662 on epoch=362, global_step=1450
06/10/2022 15:53:30 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.21 on epoch=364
06/10/2022 15:53:33 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.20 on epoch=367
06/10/2022 15:53:35 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.19 on epoch=369
06/10/2022 15:53:37 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.12 on epoch=372
06/10/2022 15:53:40 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.10 on epoch=374
06/10/2022 15:53:41 - INFO - __main__ - Global step 1500 Train loss 0.17 Classification-F1 0.6976190476190477 on epoch=374
06/10/2022 15:53:43 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.07 on epoch=377
06/10/2022 15:53:45 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.14 on epoch=379
06/10/2022 15:53:48 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.09 on epoch=382
06/10/2022 15:53:50 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.12 on epoch=384
06/10/2022 15:53:53 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.11 on epoch=387
06/10/2022 15:53:53 - INFO - __main__ - Global step 1550 Train loss 0.11 Classification-F1 0.7427350427350426 on epoch=387
06/10/2022 15:53:54 - INFO - __main__ - Saving model with best Classification-F1: 0.7126710454296662 -> 0.7427350427350426 on epoch=387, global_step=1550
06/10/2022 15:53:56 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.22 on epoch=389
06/10/2022 15:53:58 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.13 on epoch=392
06/10/2022 15:54:01 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.12 on epoch=394
06/10/2022 15:54:03 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.09 on epoch=397
06/10/2022 15:54:05 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.13 on epoch=399
06/10/2022 15:54:06 - INFO - __main__ - Global step 1600 Train loss 0.14 Classification-F1 0.7304485012395763 on epoch=399
06/10/2022 15:54:09 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.10 on epoch=402
06/10/2022 15:54:11 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.17 on epoch=404
06/10/2022 15:54:13 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.13 on epoch=407
06/10/2022 15:54:16 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.13 on epoch=409
06/10/2022 15:54:18 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.08 on epoch=412
06/10/2022 15:54:19 - INFO - __main__ - Global step 1650 Train loss 0.12 Classification-F1 0.7132962862564382 on epoch=412
06/10/2022 15:54:21 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.06 on epoch=414
06/10/2022 15:54:24 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.16 on epoch=417
06/10/2022 15:54:26 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.09 on epoch=419
06/10/2022 15:54:28 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.16 on epoch=422
06/10/2022 15:54:31 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.07 on epoch=424
06/10/2022 15:54:32 - INFO - __main__ - Global step 1700 Train loss 0.11 Classification-F1 0.740648473407094 on epoch=424
06/10/2022 15:54:34 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.14 on epoch=427
06/10/2022 15:54:37 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.15 on epoch=429
06/10/2022 15:54:39 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.18 on epoch=432
06/10/2022 15:54:41 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.08 on epoch=434
06/10/2022 15:54:44 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.05 on epoch=437
06/10/2022 15:54:45 - INFO - __main__ - Global step 1750 Train loss 0.12 Classification-F1 0.7308316430020283 on epoch=437
06/10/2022 15:54:47 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.15 on epoch=439
06/10/2022 15:54:49 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.11 on epoch=442
06/10/2022 15:54:52 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.11 on epoch=444
06/10/2022 15:54:54 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.08 on epoch=447
06/10/2022 15:54:56 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.09 on epoch=449
06/10/2022 15:54:57 - INFO - __main__ - Global step 1800 Train loss 0.11 Classification-F1 0.7364996951839058 on epoch=449
06/10/2022 15:55:00 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.11 on epoch=452
06/10/2022 15:55:02 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.12 on epoch=454
06/10/2022 15:55:05 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.10 on epoch=457
06/10/2022 15:55:07 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.07 on epoch=459
06/10/2022 15:55:09 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.12 on epoch=462
06/10/2022 15:55:10 - INFO - __main__ - Global step 1850 Train loss 0.10 Classification-F1 0.7373753217503218 on epoch=462
06/10/2022 15:55:13 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.09 on epoch=464
06/10/2022 15:55:15 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.06 on epoch=467
06/10/2022 15:55:17 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.06 on epoch=469
06/10/2022 15:55:20 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.06 on epoch=472
06/10/2022 15:55:22 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.10 on epoch=474
06/10/2022 15:55:23 - INFO - __main__ - Global step 1900 Train loss 0.07 Classification-F1 0.7528010088128056 on epoch=474
06/10/2022 15:55:23 - INFO - __main__ - Saving model with best Classification-F1: 0.7427350427350426 -> 0.7528010088128056 on epoch=474, global_step=1900
06/10/2022 15:55:25 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.06 on epoch=477
06/10/2022 15:55:28 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.07 on epoch=479
06/10/2022 15:55:30 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.10 on epoch=482
06/10/2022 15:55:32 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.12 on epoch=484
06/10/2022 15:55:35 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.07 on epoch=487
06/10/2022 15:55:36 - INFO - __main__ - Global step 1950 Train loss 0.09 Classification-F1 0.7417238667238667 on epoch=487
06/10/2022 15:55:38 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.05 on epoch=489
06/10/2022 15:55:41 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.05 on epoch=492
06/10/2022 15:55:43 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.08 on epoch=494
06/10/2022 15:55:45 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.07 on epoch=497
06/10/2022 15:55:48 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.10 on epoch=499
06/10/2022 15:55:48 - INFO - __main__ - Global step 2000 Train loss 0.07 Classification-F1 0.7723019571295434 on epoch=499
06/10/2022 15:55:49 - INFO - __main__ - Saving model with best Classification-F1: 0.7528010088128056 -> 0.7723019571295434 on epoch=499, global_step=2000
06/10/2022 15:55:51 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.06 on epoch=502
06/10/2022 15:55:53 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.06 on epoch=504
06/10/2022 15:55:56 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.03 on epoch=507
06/10/2022 15:55:58 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.08 on epoch=509
06/10/2022 15:56:00 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.06 on epoch=512
06/10/2022 15:56:01 - INFO - __main__ - Global step 2050 Train loss 0.06 Classification-F1 0.7723019571295434 on epoch=512
06/10/2022 15:56:04 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.06 on epoch=514
06/10/2022 15:56:06 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.08 on epoch=517
06/10/2022 15:56:09 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.06 on epoch=519
06/10/2022 15:56:11 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=522
06/10/2022 15:56:13 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.09 on epoch=524
06/10/2022 15:56:14 - INFO - __main__ - Global step 2100 Train loss 0.06 Classification-F1 0.7417238667238667 on epoch=524
06/10/2022 15:56:17 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.07 on epoch=527
06/10/2022 15:56:19 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.06 on epoch=529
06/10/2022 15:56:21 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.07 on epoch=532
06/10/2022 15:56:24 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.15 on epoch=534
06/10/2022 15:56:26 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.06 on epoch=537
06/10/2022 15:56:27 - INFO - __main__ - Global step 2150 Train loss 0.08 Classification-F1 0.7565488565488565 on epoch=537
06/10/2022 15:56:29 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.12 on epoch=539
06/10/2022 15:56:32 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.04 on epoch=542
06/10/2022 15:56:34 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.04 on epoch=544
06/10/2022 15:56:36 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.12 on epoch=547
06/10/2022 15:56:39 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=549
06/10/2022 15:56:40 - INFO - __main__ - Global step 2200 Train loss 0.07 Classification-F1 0.7556801306801307 on epoch=549
06/10/2022 15:56:42 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.09 on epoch=552
06/10/2022 15:56:44 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.04 on epoch=554
06/10/2022 15:56:47 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.05 on epoch=557
06/10/2022 15:56:49 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.09 on epoch=559
06/10/2022 15:56:52 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.06 on epoch=562
06/10/2022 15:56:52 - INFO - __main__ - Global step 2250 Train loss 0.07 Classification-F1 0.7757757757757758 on epoch=562
06/10/2022 15:56:53 - INFO - __main__ - Saving model with best Classification-F1: 0.7723019571295434 -> 0.7757757757757758 on epoch=562, global_step=2250
06/10/2022 15:56:55 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.07 on epoch=564
06/10/2022 15:56:57 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.06 on epoch=567
06/10/2022 15:57:00 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.10 on epoch=569
06/10/2022 15:57:02 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.04 on epoch=572
06/10/2022 15:57:04 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.07 on epoch=574
06/10/2022 15:57:05 - INFO - __main__ - Global step 2300 Train loss 0.07 Classification-F1 0.7556801306801307 on epoch=574
06/10/2022 15:57:08 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=577
06/10/2022 15:57:10 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.06 on epoch=579
06/10/2022 15:57:13 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.06 on epoch=582
06/10/2022 15:57:15 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.21 on epoch=584
06/10/2022 15:57:17 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=587
06/10/2022 15:57:18 - INFO - __main__ - Global step 2350 Train loss 0.08 Classification-F1 0.7556801306801307 on epoch=587
06/10/2022 15:57:21 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.08 on epoch=589
06/10/2022 15:57:23 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.07 on epoch=592
06/10/2022 15:57:25 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.04 on epoch=594
06/10/2022 15:57:28 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.06 on epoch=597
06/10/2022 15:57:30 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.12 on epoch=599
06/10/2022 15:57:31 - INFO - __main__ - Global step 2400 Train loss 0.07 Classification-F1 0.7364996951839058 on epoch=599
06/10/2022 15:57:33 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.09 on epoch=602
06/10/2022 15:57:36 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.15 on epoch=604
06/10/2022 15:57:38 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=607
06/10/2022 15:57:40 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.10 on epoch=609
06/10/2022 15:57:43 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=612
06/10/2022 15:57:44 - INFO - __main__ - Global step 2450 Train loss 0.08 Classification-F1 0.7377252252252252 on epoch=612
06/10/2022 15:57:46 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=614
06/10/2022 15:57:48 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.07 on epoch=617
06/10/2022 15:57:51 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.11 on epoch=619
06/10/2022 15:57:53 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.03 on epoch=622
06/10/2022 15:57:56 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.07 on epoch=624
06/10/2022 15:57:56 - INFO - __main__ - Global step 2500 Train loss 0.06 Classification-F1 0.7364996951839058 on epoch=624
06/10/2022 15:57:59 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=627
06/10/2022 15:58:01 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=629
06/10/2022 15:58:04 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=632
06/10/2022 15:58:06 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.04 on epoch=634
06/10/2022 15:58:08 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.09 on epoch=637
06/10/2022 15:58:09 - INFO - __main__ - Global step 2550 Train loss 0.04 Classification-F1 0.7226399786883658 on epoch=637
06/10/2022 15:58:12 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=639
06/10/2022 15:58:14 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=642
06/10/2022 15:58:16 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.03 on epoch=644
06/10/2022 15:58:19 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.10 on epoch=647
06/10/2022 15:58:21 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.05 on epoch=649
06/10/2022 15:58:22 - INFO - __main__ - Global step 2600 Train loss 0.04 Classification-F1 0.7556801306801307 on epoch=649
06/10/2022 15:58:24 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.05 on epoch=652
06/10/2022 15:58:27 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.06 on epoch=654
06/10/2022 15:58:29 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.13 on epoch=657
06/10/2022 15:58:32 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.11 on epoch=659
06/10/2022 15:58:34 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=662
06/10/2022 15:58:35 - INFO - __main__ - Global step 2650 Train loss 0.07 Classification-F1 0.7556801306801307 on epoch=662
06/10/2022 15:58:37 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.08 on epoch=664
06/10/2022 15:58:40 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.04 on epoch=667
06/10/2022 15:58:42 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=669
06/10/2022 15:58:44 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=672
06/10/2022 15:58:47 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.05 on epoch=674
06/10/2022 15:58:48 - INFO - __main__ - Global step 2700 Train loss 0.04 Classification-F1 0.7417238667238667 on epoch=674
06/10/2022 15:58:50 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=677
06/10/2022 15:58:52 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.03 on epoch=679
06/10/2022 15:58:55 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.04 on epoch=682
06/10/2022 15:58:57 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.05 on epoch=684
06/10/2022 15:59:00 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=687
06/10/2022 15:59:00 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.7556801306801307 on epoch=687
06/10/2022 15:59:03 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.04 on epoch=689
06/10/2022 15:59:05 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.06 on epoch=692
06/10/2022 15:59:08 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=694
06/10/2022 15:59:10 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.04 on epoch=697
06/10/2022 15:59:12 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=699
06/10/2022 15:59:13 - INFO - __main__ - Global step 2800 Train loss 0.04 Classification-F1 0.7420634920634921 on epoch=699
06/10/2022 15:59:16 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.06 on epoch=702
06/10/2022 15:59:18 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.07 on epoch=704
06/10/2022 15:59:20 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.05 on epoch=707
06/10/2022 15:59:23 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=709
06/10/2022 15:59:25 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.07 on epoch=712
06/10/2022 15:59:26 - INFO - __main__ - Global step 2850 Train loss 0.05 Classification-F1 0.7578898527174389 on epoch=712
06/10/2022 15:59:28 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.04 on epoch=714
06/10/2022 15:59:31 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=717
06/10/2022 15:59:33 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.05 on epoch=719
06/10/2022 15:59:36 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.05 on epoch=722
06/10/2022 15:59:38 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.05 on epoch=724
06/10/2022 15:59:39 - INFO - __main__ - Global step 2900 Train loss 0.04 Classification-F1 0.7417238667238667 on epoch=724
06/10/2022 15:59:41 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=727
06/10/2022 15:59:44 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.04 on epoch=729
06/10/2022 15:59:46 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=732
06/10/2022 15:59:48 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=734
06/10/2022 15:59:51 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=737
06/10/2022 15:59:52 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.7420875907718012 on epoch=737
06/10/2022 15:59:54 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.06 on epoch=739
06/10/2022 15:59:56 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=742
06/10/2022 15:59:59 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=744
06/10/2022 16:00:01 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.06 on epoch=747
06/10/2022 16:00:03 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.03 on epoch=749
06/10/2022 16:00:04 - INFO - __main__ - Global step 3000 Train loss 0.04 Classification-F1 0.7578898527174389 on epoch=749
06/10/2022 16:00:04 - INFO - __main__ - save last model!
06/10/2022 16:00:04 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/10/2022 16:00:04 - INFO - __main__ - Start tokenizing ... 5509 instances
06/10/2022 16:00:04 - INFO - __main__ - Printing 3 examples
06/10/2022 16:00:04 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/10/2022 16:00:04 - INFO - __main__ - ['others']
06/10/2022 16:00:04 - INFO - __main__ -  [emo] what you like very little things ok
06/10/2022 16:00:04 - INFO - __main__ - ['others']
06/10/2022 16:00:04 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/10/2022 16:00:04 - INFO - __main__ - ['others']
06/10/2022 16:00:04 - INFO - __main__ - Tokenizing Input ...
06/10/2022 16:00:05 - INFO - __main__ - Start tokenizing ... 64 instances
06/10/2022 16:00:05 - INFO - __main__ - Printing 3 examples
06/10/2022 16:00:05 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/10/2022 16:00:05 - INFO - __main__ - ['others']
06/10/2022 16:00:05 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/10/2022 16:00:05 - INFO - __main__ - ['others']
06/10/2022 16:00:05 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/10/2022 16:00:05 - INFO - __main__ - ['others']
06/10/2022 16:00:05 - INFO - __main__ - Tokenizing Input ...
06/10/2022 16:00:05 - INFO - __main__ - Tokenizing Output ...
06/10/2022 16:00:05 - INFO - __main__ - Loaded 64 examples from train data
06/10/2022 16:00:05 - INFO - __main__ - Start tokenizing ... 64 instances
06/10/2022 16:00:05 - INFO - __main__ - Printing 3 examples
06/10/2022 16:00:05 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
06/10/2022 16:00:05 - INFO - __main__ - ['others']
06/10/2022 16:00:05 - INFO - __main__ -  [emo] i did ask now you did tell ms
06/10/2022 16:00:05 - INFO - __main__ - ['others']
06/10/2022 16:00:05 - INFO - __main__ -  [emo] buddy how you tell me your contact no
06/10/2022 16:00:05 - INFO - __main__ - ['others']
06/10/2022 16:00:05 - INFO - __main__ - Tokenizing Input ...
06/10/2022 16:00:05 - INFO - __main__ - Tokenizing Output ...
06/10/2022 16:00:05 - INFO - __main__ - Loaded 64 examples from dev data
06/10/2022 16:00:06 - INFO - __main__ - Tokenizing Output ...
06/10/2022 16:00:12 - INFO - __main__ - Loaded 5509 examples from test data
06/10/2022 16:00:20 - INFO - __main__ - load prompt embedding from ckpt
06/10/2022 16:00:21 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/10/2022 16:00:21 - INFO - __main__ - Starting training!
06/10/2022 16:01:27 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-up32shot/singletask-emo/emo_16_100_0.2_8_predictions.txt
06/10/2022 16:01:27 - INFO - __main__ - Classification-F1 on test data: 0.2135
06/10/2022 16:01:28 - INFO - __main__ - prefix=emo_16_100, lr=0.2, bsz=8, dev_performance=0.7757757757757758, test_performance=0.21345138118255652
06/10/2022 16:01:28 - INFO - __main__ - Running ... prefix=emo_16_13, lr=0.5, bsz=8 ...
06/10/2022 16:01:29 - INFO - __main__ - Start tokenizing ... 64 instances
06/10/2022 16:01:29 - INFO - __main__ - Printing 3 examples
06/10/2022 16:01:29 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/10/2022 16:01:29 - INFO - __main__ - ['others']
06/10/2022 16:01:29 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/10/2022 16:01:29 - INFO - __main__ - ['others']
06/10/2022 16:01:29 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/10/2022 16:01:29 - INFO - __main__ - ['others']
06/10/2022 16:01:29 - INFO - __main__ - Tokenizing Input ...
06/10/2022 16:01:29 - INFO - __main__ - Tokenizing Output ...
06/10/2022 16:01:29 - INFO - __main__ - Loaded 64 examples from train data
06/10/2022 16:01:29 - INFO - __main__ - Start tokenizing ... 64 instances
06/10/2022 16:01:29 - INFO - __main__ - Printing 3 examples
06/10/2022 16:01:29 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
06/10/2022 16:01:29 - INFO - __main__ - ['others']
06/10/2022 16:01:29 - INFO - __main__ -  [emo] i did ask now you did tell ms
06/10/2022 16:01:29 - INFO - __main__ - ['others']
06/10/2022 16:01:29 - INFO - __main__ -  [emo] buddy how you tell me your contact no
06/10/2022 16:01:29 - INFO - __main__ - ['others']
06/10/2022 16:01:29 - INFO - __main__ - Tokenizing Input ...
06/10/2022 16:01:29 - INFO - __main__ - Tokenizing Output ...
06/10/2022 16:01:29 - INFO - __main__ - Loaded 64 examples from dev data
06/10/2022 16:01:44 - INFO - __main__ - load prompt embedding from ckpt
06/10/2022 16:01:45 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/10/2022 16:01:45 - INFO - __main__ - Starting training!
06/10/2022 16:01:48 - INFO - __main__ - Step 10 Global step 10 Train loss 3.46 on epoch=2
06/10/2022 16:01:50 - INFO - __main__ - Step 20 Global step 20 Train loss 2.20 on epoch=4
06/10/2022 16:01:53 - INFO - __main__ - Step 30 Global step 30 Train loss 1.58 on epoch=7
06/10/2022 16:01:55 - INFO - __main__ - Step 40 Global step 40 Train loss 1.10 on epoch=9
06/10/2022 16:01:57 - INFO - __main__ - Step 50 Global step 50 Train loss 0.88 on epoch=12
06/10/2022 16:01:58 - INFO - __main__ - Global step 50 Train loss 1.84 Classification-F1 0.5572863291658127 on epoch=12
06/10/2022 16:01:58 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.5572863291658127 on epoch=12, global_step=50
06/10/2022 16:02:00 - INFO - __main__ - Step 60 Global step 60 Train loss 0.78 on epoch=14
06/10/2022 16:02:03 - INFO - __main__ - Step 70 Global step 70 Train loss 0.60 on epoch=17
06/10/2022 16:02:05 - INFO - __main__ - Step 80 Global step 80 Train loss 0.73 on epoch=19
06/10/2022 16:02:08 - INFO - __main__ - Step 90 Global step 90 Train loss 0.57 on epoch=22
06/10/2022 16:02:10 - INFO - __main__ - Step 100 Global step 100 Train loss 0.62 on epoch=24
06/10/2022 16:02:11 - INFO - __main__ - Global step 100 Train loss 0.66 Classification-F1 0.5961472417184869 on epoch=24
06/10/2022 16:02:11 - INFO - __main__ - Saving model with best Classification-F1: 0.5572863291658127 -> 0.5961472417184869 on epoch=24, global_step=100
06/10/2022 16:02:13 - INFO - __main__ - Step 110 Global step 110 Train loss 0.60 on epoch=27
06/10/2022 16:02:16 - INFO - __main__ - Step 120 Global step 120 Train loss 0.52 on epoch=29
06/10/2022 16:02:18 - INFO - __main__ - Step 130 Global step 130 Train loss 0.49 on epoch=32
06/10/2022 16:02:20 - INFO - __main__ - Step 140 Global step 140 Train loss 0.52 on epoch=34
06/10/2022 16:02:23 - INFO - __main__ - Step 150 Global step 150 Train loss 0.50 on epoch=37
06/10/2022 16:02:23 - INFO - __main__ - Global step 150 Train loss 0.53 Classification-F1 0.7627960275019099 on epoch=37
06/10/2022 16:02:23 - INFO - __main__ - Saving model with best Classification-F1: 0.5961472417184869 -> 0.7627960275019099 on epoch=37, global_step=150
06/10/2022 16:02:26 - INFO - __main__ - Step 160 Global step 160 Train loss 0.43 on epoch=39
06/10/2022 16:02:28 - INFO - __main__ - Step 170 Global step 170 Train loss 0.48 on epoch=42
06/10/2022 16:02:30 - INFO - __main__ - Step 180 Global step 180 Train loss 0.36 on epoch=44
06/10/2022 16:02:33 - INFO - __main__ - Step 190 Global step 190 Train loss 0.42 on epoch=47
06/10/2022 16:02:35 - INFO - __main__ - Step 200 Global step 200 Train loss 0.43 on epoch=49
06/10/2022 16:02:36 - INFO - __main__ - Global step 200 Train loss 0.42 Classification-F1 0.6865453306629777 on epoch=49
06/10/2022 16:02:38 - INFO - __main__ - Step 210 Global step 210 Train loss 0.44 on epoch=52
06/10/2022 16:02:41 - INFO - __main__ - Step 220 Global step 220 Train loss 0.34 on epoch=54
06/10/2022 16:02:43 - INFO - __main__ - Step 230 Global step 230 Train loss 0.43 on epoch=57
06/10/2022 16:02:45 - INFO - __main__ - Step 240 Global step 240 Train loss 0.31 on epoch=59
06/10/2022 16:02:48 - INFO - __main__ - Step 250 Global step 250 Train loss 0.37 on epoch=62
06/10/2022 16:02:49 - INFO - __main__ - Global step 250 Train loss 0.38 Classification-F1 0.7450978075978076 on epoch=62
06/10/2022 16:02:51 - INFO - __main__ - Step 260 Global step 260 Train loss 0.37 on epoch=64
06/10/2022 16:02:53 - INFO - __main__ - Step 270 Global step 270 Train loss 0.35 on epoch=67
06/10/2022 16:02:56 - INFO - __main__ - Step 280 Global step 280 Train loss 0.26 on epoch=69
06/10/2022 16:02:58 - INFO - __main__ - Step 290 Global step 290 Train loss 0.34 on epoch=72
06/10/2022 16:03:00 - INFO - __main__ - Step 300 Global step 300 Train loss 0.26 on epoch=74
06/10/2022 16:03:01 - INFO - __main__ - Global step 300 Train loss 0.32 Classification-F1 0.7786324786324786 on epoch=74
06/10/2022 16:03:01 - INFO - __main__ - Saving model with best Classification-F1: 0.7627960275019099 -> 0.7786324786324786 on epoch=74, global_step=300
06/10/2022 16:03:04 - INFO - __main__ - Step 310 Global step 310 Train loss 0.31 on epoch=77
06/10/2022 16:03:06 - INFO - __main__ - Step 320 Global step 320 Train loss 0.27 on epoch=79
06/10/2022 16:03:08 - INFO - __main__ - Step 330 Global step 330 Train loss 0.30 on epoch=82
06/10/2022 16:03:11 - INFO - __main__ - Step 340 Global step 340 Train loss 0.30 on epoch=84
06/10/2022 16:03:13 - INFO - __main__ - Step 350 Global step 350 Train loss 0.23 on epoch=87
06/10/2022 16:03:14 - INFO - __main__ - Global step 350 Train loss 0.28 Classification-F1 0.8578410836475353 on epoch=87
06/10/2022 16:03:14 - INFO - __main__ - Saving model with best Classification-F1: 0.7786324786324786 -> 0.8578410836475353 on epoch=87, global_step=350
06/10/2022 16:03:16 - INFO - __main__ - Step 360 Global step 360 Train loss 0.16 on epoch=89
06/10/2022 16:03:19 - INFO - __main__ - Step 370 Global step 370 Train loss 0.15 on epoch=92
06/10/2022 16:03:21 - INFO - __main__ - Step 380 Global step 380 Train loss 0.17 on epoch=94
06/10/2022 16:03:23 - INFO - __main__ - Step 390 Global step 390 Train loss 0.20 on epoch=97
06/10/2022 16:03:26 - INFO - __main__ - Step 400 Global step 400 Train loss 0.17 on epoch=99
06/10/2022 16:03:26 - INFO - __main__ - Global step 400 Train loss 0.17 Classification-F1 0.825944170771757 on epoch=99
06/10/2022 16:03:29 - INFO - __main__ - Step 410 Global step 410 Train loss 0.18 on epoch=102
06/10/2022 16:03:31 - INFO - __main__ - Step 420 Global step 420 Train loss 0.22 on epoch=104
06/10/2022 16:03:33 - INFO - __main__ - Step 430 Global step 430 Train loss 0.15 on epoch=107
06/10/2022 16:03:36 - INFO - __main__ - Step 440 Global step 440 Train loss 0.20 on epoch=109
06/10/2022 16:03:38 - INFO - __main__ - Step 450 Global step 450 Train loss 0.15 on epoch=112
06/10/2022 16:03:39 - INFO - __main__ - Global step 450 Train loss 0.18 Classification-F1 0.8265605362379557 on epoch=112
06/10/2022 16:03:41 - INFO - __main__ - Step 460 Global step 460 Train loss 0.15 on epoch=114
06/10/2022 16:03:44 - INFO - __main__ - Step 470 Global step 470 Train loss 0.17 on epoch=117
06/10/2022 16:03:46 - INFO - __main__ - Step 480 Global step 480 Train loss 0.18 on epoch=119
06/10/2022 16:03:48 - INFO - __main__ - Step 490 Global step 490 Train loss 0.16 on epoch=122
06/10/2022 16:03:51 - INFO - __main__ - Step 500 Global step 500 Train loss 0.14 on epoch=124
06/10/2022 16:03:51 - INFO - __main__ - Global step 500 Train loss 0.16 Classification-F1 0.825944170771757 on epoch=124
06/10/2022 16:03:54 - INFO - __main__ - Step 510 Global step 510 Train loss 0.13 on epoch=127
06/10/2022 16:03:56 - INFO - __main__ - Step 520 Global step 520 Train loss 0.14 on epoch=129
06/10/2022 16:03:58 - INFO - __main__ - Step 530 Global step 530 Train loss 0.16 on epoch=132
06/10/2022 16:04:01 - INFO - __main__ - Step 540 Global step 540 Train loss 0.16 on epoch=134
06/10/2022 16:04:03 - INFO - __main__ - Step 550 Global step 550 Train loss 0.12 on epoch=137
06/10/2022 16:04:04 - INFO - __main__ - Global step 550 Train loss 0.14 Classification-F1 0.7904176093514329 on epoch=137
06/10/2022 16:04:06 - INFO - __main__ - Step 560 Global step 560 Train loss 0.14 on epoch=139
06/10/2022 16:04:09 - INFO - __main__ - Step 570 Global step 570 Train loss 0.10 on epoch=142
06/10/2022 16:04:11 - INFO - __main__ - Step 580 Global step 580 Train loss 0.07 on epoch=144
06/10/2022 16:04:13 - INFO - __main__ - Step 590 Global step 590 Train loss 0.08 on epoch=147
06/10/2022 16:04:16 - INFO - __main__ - Step 600 Global step 600 Train loss 0.13 on epoch=149
06/10/2022 16:04:17 - INFO - __main__ - Global step 600 Train loss 0.11 Classification-F1 0.7718551587301588 on epoch=149
06/10/2022 16:04:19 - INFO - __main__ - Step 610 Global step 610 Train loss 0.10 on epoch=152
06/10/2022 16:04:21 - INFO - __main__ - Step 620 Global step 620 Train loss 0.06 on epoch=154
06/10/2022 16:04:24 - INFO - __main__ - Step 630 Global step 630 Train loss 0.08 on epoch=157
06/10/2022 16:04:26 - INFO - __main__ - Step 640 Global step 640 Train loss 0.12 on epoch=159
06/10/2022 16:04:28 - INFO - __main__ - Step 650 Global step 650 Train loss 0.04 on epoch=162
06/10/2022 16:04:29 - INFO - __main__ - Global step 650 Train loss 0.08 Classification-F1 0.7570232905716777 on epoch=162
06/10/2022 16:04:32 - INFO - __main__ - Step 660 Global step 660 Train loss 0.20 on epoch=164
06/10/2022 16:04:34 - INFO - __main__ - Step 670 Global step 670 Train loss 0.03 on epoch=167
06/10/2022 16:04:36 - INFO - __main__ - Step 680 Global step 680 Train loss 0.05 on epoch=169
06/10/2022 16:04:39 - INFO - __main__ - Step 690 Global step 690 Train loss 0.05 on epoch=172
06/10/2022 16:04:41 - INFO - __main__ - Step 700 Global step 700 Train loss 0.06 on epoch=174
06/10/2022 16:04:42 - INFO - __main__ - Global step 700 Train loss 0.08 Classification-F1 0.7904876373626373 on epoch=174
06/10/2022 16:04:44 - INFO - __main__ - Step 710 Global step 710 Train loss 0.04 on epoch=177
06/10/2022 16:04:47 - INFO - __main__ - Step 720 Global step 720 Train loss 0.09 on epoch=179
06/10/2022 16:04:49 - INFO - __main__ - Step 730 Global step 730 Train loss 0.05 on epoch=182
06/10/2022 16:04:51 - INFO - __main__ - Step 740 Global step 740 Train loss 0.03 on epoch=184
06/10/2022 16:04:54 - INFO - __main__ - Step 750 Global step 750 Train loss 0.08 on epoch=187
06/10/2022 16:04:54 - INFO - __main__ - Global step 750 Train loss 0.06 Classification-F1 0.7912554112554113 on epoch=187
06/10/2022 16:04:57 - INFO - __main__ - Step 760 Global step 760 Train loss 0.06 on epoch=189
06/10/2022 16:04:59 - INFO - __main__ - Step 770 Global step 770 Train loss 0.03 on epoch=192
06/10/2022 16:05:01 - INFO - __main__ - Step 780 Global step 780 Train loss 0.07 on epoch=194
06/10/2022 16:05:04 - INFO - __main__ - Step 790 Global step 790 Train loss 0.04 on epoch=197
06/10/2022 16:05:06 - INFO - __main__ - Step 800 Global step 800 Train loss 0.04 on epoch=199
06/10/2022 16:05:07 - INFO - __main__ - Global step 800 Train loss 0.05 Classification-F1 0.7904176093514329 on epoch=199
06/10/2022 16:05:09 - INFO - __main__ - Step 810 Global step 810 Train loss 0.07 on epoch=202
06/10/2022 16:05:12 - INFO - __main__ - Step 820 Global step 820 Train loss 0.04 on epoch=204
06/10/2022 16:05:14 - INFO - __main__ - Step 830 Global step 830 Train loss 0.05 on epoch=207
06/10/2022 16:05:16 - INFO - __main__ - Step 840 Global step 840 Train loss 0.03 on epoch=209
06/10/2022 16:05:19 - INFO - __main__ - Step 850 Global step 850 Train loss 0.02 on epoch=212
06/10/2022 16:05:20 - INFO - __main__ - Global step 850 Train loss 0.04 Classification-F1 0.7714583333333334 on epoch=212
06/10/2022 16:05:22 - INFO - __main__ - Step 860 Global step 860 Train loss 0.03 on epoch=214
06/10/2022 16:05:24 - INFO - __main__ - Step 870 Global step 870 Train loss 0.04 on epoch=217
06/10/2022 16:05:27 - INFO - __main__ - Step 880 Global step 880 Train loss 0.04 on epoch=219
06/10/2022 16:05:29 - INFO - __main__ - Step 890 Global step 890 Train loss 0.04 on epoch=222
06/10/2022 16:05:31 - INFO - __main__ - Step 900 Global step 900 Train loss 0.05 on epoch=224
06/10/2022 16:05:32 - INFO - __main__ - Global step 900 Train loss 0.04 Classification-F1 0.7519354392755928 on epoch=224
06/10/2022 16:05:35 - INFO - __main__ - Step 910 Global step 910 Train loss 0.02 on epoch=227
06/10/2022 16:05:37 - INFO - __main__ - Step 920 Global step 920 Train loss 0.02 on epoch=229
06/10/2022 16:05:39 - INFO - __main__ - Step 930 Global step 930 Train loss 0.04 on epoch=232
06/10/2022 16:05:42 - INFO - __main__ - Step 940 Global step 940 Train loss 0.03 on epoch=234
06/10/2022 16:05:44 - INFO - __main__ - Step 950 Global step 950 Train loss 0.03 on epoch=237
06/10/2022 16:05:45 - INFO - __main__ - Global step 950 Train loss 0.03 Classification-F1 0.7567991610905823 on epoch=237
06/10/2022 16:05:47 - INFO - __main__ - Step 960 Global step 960 Train loss 0.04 on epoch=239
06/10/2022 16:05:50 - INFO - __main__ - Step 970 Global step 970 Train loss 0.04 on epoch=242
06/10/2022 16:05:52 - INFO - __main__ - Step 980 Global step 980 Train loss 0.04 on epoch=244
06/10/2022 16:05:54 - INFO - __main__ - Step 990 Global step 990 Train loss 0.07 on epoch=247
06/10/2022 16:05:57 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.02 on epoch=249
06/10/2022 16:05:58 - INFO - __main__ - Global step 1000 Train loss 0.04 Classification-F1 0.771969696969697 on epoch=249
06/10/2022 16:06:00 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.02 on epoch=252
06/10/2022 16:06:02 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.04 on epoch=254
06/10/2022 16:06:05 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.02 on epoch=257
06/10/2022 16:06:07 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.03 on epoch=259
06/10/2022 16:06:09 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.01 on epoch=262
06/10/2022 16:06:10 - INFO - __main__ - Global step 1050 Train loss 0.02 Classification-F1 0.8114018334606571 on epoch=262
06/10/2022 16:06:13 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.02 on epoch=264
06/10/2022 16:06:15 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.04 on epoch=267
06/10/2022 16:06:17 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.12 on epoch=269
06/10/2022 16:06:20 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.02 on epoch=272
06/10/2022 16:06:22 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.03 on epoch=274
06/10/2022 16:06:23 - INFO - __main__ - Global step 1100 Train loss 0.05 Classification-F1 0.8259604978354979 on epoch=274
06/10/2022 16:06:25 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.01 on epoch=277
06/10/2022 16:06:28 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=279
06/10/2022 16:06:30 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=282
06/10/2022 16:06:32 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.02 on epoch=284
06/10/2022 16:06:34 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.04 on epoch=287
06/10/2022 16:06:35 - INFO - __main__ - Global step 1150 Train loss 0.02 Classification-F1 0.7910258379008379 on epoch=287
06/10/2022 16:06:38 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.02 on epoch=289
06/10/2022 16:06:40 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.01 on epoch=292
06/10/2022 16:06:43 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.03 on epoch=294
06/10/2022 16:06:45 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.08 on epoch=297
06/10/2022 16:06:47 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=299
06/10/2022 16:06:48 - INFO - __main__ - Global step 1200 Train loss 0.03 Classification-F1 0.7568693693693693 on epoch=299
06/10/2022 16:06:50 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.03 on epoch=302
06/10/2022 16:06:53 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=304
06/10/2022 16:06:55 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.04 on epoch=307
06/10/2022 16:06:57 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.07 on epoch=309
06/10/2022 16:07:00 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.04 on epoch=312
06/10/2022 16:07:01 - INFO - __main__ - Global step 1250 Train loss 0.04 Classification-F1 0.7917936117936119 on epoch=312
06/10/2022 16:07:03 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.06 on epoch=314
06/10/2022 16:07:05 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.01 on epoch=317
06/10/2022 16:07:08 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.00 on epoch=319
06/10/2022 16:07:10 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.05 on epoch=322
06/10/2022 16:07:12 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=324
06/10/2022 16:07:13 - INFO - __main__ - Global step 1300 Train loss 0.03 Classification-F1 0.7726670520788168 on epoch=324
06/10/2022 16:07:16 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.00 on epoch=327
06/10/2022 16:07:18 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.04 on epoch=329
06/10/2022 16:07:20 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=332
06/10/2022 16:07:23 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=334
06/10/2022 16:07:25 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=337
06/10/2022 16:07:26 - INFO - __main__ - Global step 1350 Train loss 0.01 Classification-F1 0.7912554112554113 on epoch=337
06/10/2022 16:07:28 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.02 on epoch=339
06/10/2022 16:07:31 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.00 on epoch=342
06/10/2022 16:07:33 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.00 on epoch=344
06/10/2022 16:07:35 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.00 on epoch=347
06/10/2022 16:07:38 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=349
06/10/2022 16:07:38 - INFO - __main__ - Global step 1400 Train loss 0.01 Classification-F1 0.7910258379008379 on epoch=349
06/10/2022 16:07:41 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=352
06/10/2022 16:07:43 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.01 on epoch=354
06/10/2022 16:07:45 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.09 on epoch=357
06/10/2022 16:07:48 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=359
06/10/2022 16:07:50 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=362
06/10/2022 16:07:51 - INFO - __main__ - Global step 1450 Train loss 0.03 Classification-F1 0.7575694444444444 on epoch=362
06/10/2022 16:07:53 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.09 on epoch=364
06/10/2022 16:07:56 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=367
06/10/2022 16:07:58 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=369
06/10/2022 16:08:00 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=372
06/10/2022 16:08:03 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.03 on epoch=374
06/10/2022 16:08:04 - INFO - __main__ - Global step 1500 Train loss 0.03 Classification-F1 0.8087647306397306 on epoch=374
06/10/2022 16:08:06 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=377
06/10/2022 16:08:08 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.14 on epoch=379
06/10/2022 16:08:11 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=382
06/10/2022 16:08:13 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=384
06/10/2022 16:08:15 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=387
06/10/2022 16:08:16 - INFO - __main__ - Global step 1550 Train loss 0.04 Classification-F1 0.7758547008547009 on epoch=387
06/10/2022 16:08:19 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.03 on epoch=389
06/10/2022 16:08:21 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=392
06/10/2022 16:08:23 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=394
06/10/2022 16:08:26 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.02 on epoch=397
06/10/2022 16:08:28 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=399
06/10/2022 16:08:29 - INFO - __main__ - Global step 1600 Train loss 0.01 Classification-F1 0.8259604978354979 on epoch=399
06/10/2022 16:08:31 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=402
06/10/2022 16:08:34 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.02 on epoch=404
06/10/2022 16:08:36 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.04 on epoch=407
06/10/2022 16:08:38 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=409
06/10/2022 16:08:41 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=412
06/10/2022 16:08:42 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.7521038850322739 on epoch=412
06/10/2022 16:08:44 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=414
06/10/2022 16:08:46 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=417
06/10/2022 16:08:49 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.03 on epoch=419
06/10/2022 16:08:51 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=422
06/10/2022 16:08:53 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=424
06/10/2022 16:08:54 - INFO - __main__ - Global step 1700 Train loss 0.01 Classification-F1 0.8085618085618086 on epoch=424
06/10/2022 16:08:57 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=427
06/10/2022 16:08:59 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=429
06/10/2022 16:09:01 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=432
06/10/2022 16:09:04 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=434
06/10/2022 16:09:06 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=437
06/10/2022 16:09:07 - INFO - __main__ - Global step 1750 Train loss 0.01 Classification-F1 0.7771987868762062 on epoch=437
06/10/2022 16:09:09 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=439
06/10/2022 16:09:12 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=442
06/10/2022 16:09:14 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=444
06/10/2022 16:09:16 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.07 on epoch=447
06/10/2022 16:09:19 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=449
06/10/2022 16:09:20 - INFO - __main__ - Global step 1800 Train loss 0.02 Classification-F1 0.776201923076923 on epoch=449
06/10/2022 16:09:22 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=452
06/10/2022 16:09:24 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=454
06/10/2022 16:09:27 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.08 on epoch=457
06/10/2022 16:09:29 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=459
06/10/2022 16:09:31 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=462
06/10/2022 16:09:32 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.7717936117936118 on epoch=462
06/10/2022 16:09:35 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=464
06/10/2022 16:09:37 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=467
06/10/2022 16:09:39 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=469
06/10/2022 16:09:42 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=472
06/10/2022 16:09:44 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=474
06/10/2022 16:09:45 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.7521739130434782 on epoch=474
06/10/2022 16:09:47 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=477
06/10/2022 16:09:50 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=479
06/10/2022 16:09:52 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=482
06/10/2022 16:09:54 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=484
06/10/2022 16:09:57 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=487
06/10/2022 16:09:58 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.7427375762859634 on epoch=487
06/10/2022 16:10:00 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=489
06/10/2022 16:10:02 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=492
06/10/2022 16:10:05 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.09 on epoch=494
06/10/2022 16:10:07 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=497
06/10/2022 16:10:10 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=499
06/10/2022 16:10:10 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.7905011655011656 on epoch=499
06/10/2022 16:10:13 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.04 on epoch=502
06/10/2022 16:10:15 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
06/10/2022 16:10:17 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/10/2022 16:10:20 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=509
06/10/2022 16:10:22 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.02 on epoch=512
06/10/2022 16:10:23 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.7774959973235835 on epoch=512
06/10/2022 16:10:25 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=514
06/10/2022 16:10:28 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.03 on epoch=517
06/10/2022 16:10:30 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=519
06/10/2022 16:10:33 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/10/2022 16:10:35 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/10/2022 16:10:36 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.8096865193639388 on epoch=524
06/10/2022 16:10:38 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
06/10/2022 16:10:40 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/10/2022 16:10:43 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/10/2022 16:10:45 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
06/10/2022 16:10:47 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
06/10/2022 16:10:48 - INFO - __main__ - Global step 2150 Train loss 0.00 Classification-F1 0.7757796257796258 on epoch=537
06/10/2022 16:10:51 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=539
06/10/2022 16:10:53 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/10/2022 16:10:56 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/10/2022 16:10:58 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/10/2022 16:11:00 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=549
06/10/2022 16:11:01 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.7610697546181417 on epoch=549
06/10/2022 16:11:04 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/10/2022 16:11:06 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/10/2022 16:11:08 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
06/10/2022 16:11:11 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/10/2022 16:11:13 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=562
06/10/2022 16:11:14 - INFO - __main__ - Global step 2250 Train loss 0.00 Classification-F1 0.7941925381263616 on epoch=562
06/10/2022 16:11:16 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=564
06/10/2022 16:11:19 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/10/2022 16:11:21 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=569
06/10/2022 16:11:23 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/10/2022 16:11:26 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/10/2022 16:11:27 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.8087647306397306 on epoch=574
06/10/2022 16:11:29 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/10/2022 16:11:32 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/10/2022 16:11:34 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/10/2022 16:11:36 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/10/2022 16:11:39 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=587
06/10/2022 16:11:40 - INFO - __main__ - Global step 2350 Train loss 0.00 Classification-F1 0.8265605362379557 on epoch=587
06/10/2022 16:11:42 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=589
06/10/2022 16:11:44 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/10/2022 16:11:47 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/10/2022 16:11:49 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/10/2022 16:11:51 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/10/2022 16:11:52 - INFO - __main__ - Global step 2400 Train loss 0.00 Classification-F1 0.8087647306397306 on epoch=599
06/10/2022 16:11:55 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/10/2022 16:11:57 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.05 on epoch=604
06/10/2022 16:11:59 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/10/2022 16:12:02 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/10/2022 16:12:04 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=612
06/10/2022 16:12:05 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.7905011655011656 on epoch=612
06/10/2022 16:12:07 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.04 on epoch=614
06/10/2022 16:12:10 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/10/2022 16:12:12 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/10/2022 16:12:15 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/10/2022 16:12:17 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=624
06/10/2022 16:12:18 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.8087647306397306 on epoch=624
06/10/2022 16:12:20 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/10/2022 16:12:23 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/10/2022 16:12:25 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/10/2022 16:12:27 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/10/2022 16:12:30 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/10/2022 16:12:31 - INFO - __main__ - Global step 2550 Train loss 0.00 Classification-F1 0.7941925381263616 on epoch=637
06/10/2022 16:12:33 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=639
06/10/2022 16:12:35 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.04 on epoch=642
06/10/2022 16:12:38 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/10/2022 16:12:40 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/10/2022 16:12:42 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=649
06/10/2022 16:12:43 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.8087647306397306 on epoch=649
06/10/2022 16:12:46 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/10/2022 16:12:48 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.07 on epoch=654
06/10/2022 16:12:50 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/10/2022 16:12:53 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.05 on epoch=659
06/10/2022 16:12:55 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/10/2022 16:12:56 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.7904876373626373 on epoch=662
06/10/2022 16:12:59 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/10/2022 16:13:01 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.04 on epoch=667
06/10/2022 16:13:03 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/10/2022 16:13:06 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/10/2022 16:13:08 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/10/2022 16:13:09 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.7905011655011656 on epoch=674
06/10/2022 16:13:11 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/10/2022 16:13:14 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/10/2022 16:13:16 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=682
06/10/2022 16:13:18 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=684
06/10/2022 16:13:21 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/10/2022 16:13:22 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.7516610360360361 on epoch=687
06/10/2022 16:13:24 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.05 on epoch=689
06/10/2022 16:13:26 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/10/2022 16:13:29 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/10/2022 16:13:31 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/10/2022 16:13:33 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=699
06/10/2022 16:13:34 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.8096865193639388 on epoch=699
06/10/2022 16:13:37 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/10/2022 16:13:39 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=704
06/10/2022 16:13:41 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/10/2022 16:13:44 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/10/2022 16:13:46 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=712
06/10/2022 16:13:47 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.8087647306397306 on epoch=712
06/10/2022 16:13:49 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/10/2022 16:13:52 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/10/2022 16:13:54 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/10/2022 16:13:56 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/10/2022 16:13:59 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/10/2022 16:14:00 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.7910258379008379 on epoch=724
06/10/2022 16:14:02 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/10/2022 16:14:05 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/10/2022 16:14:07 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/10/2022 16:14:09 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/10/2022 16:14:12 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/10/2022 16:14:13 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.7910258379008379 on epoch=737
06/10/2022 16:14:15 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/10/2022 16:14:17 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/10/2022 16:14:20 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/10/2022 16:14:22 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=747
06/10/2022 16:14:24 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=749
06/10/2022 16:14:25 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.7926497926497926 on epoch=749
06/10/2022 16:14:25 - INFO - __main__ - save last model!
06/10/2022 16:14:25 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/10/2022 16:14:25 - INFO - __main__ - Start tokenizing ... 5509 instances
06/10/2022 16:14:25 - INFO - __main__ - Printing 3 examples
06/10/2022 16:14:25 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/10/2022 16:14:25 - INFO - __main__ - ['others']
06/10/2022 16:14:25 - INFO - __main__ -  [emo] what you like very little things ok
06/10/2022 16:14:25 - INFO - __main__ - ['others']
06/10/2022 16:14:25 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/10/2022 16:14:25 - INFO - __main__ - ['others']
06/10/2022 16:14:25 - INFO - __main__ - Tokenizing Input ...
06/10/2022 16:14:26 - INFO - __main__ - Start tokenizing ... 64 instances
06/10/2022 16:14:26 - INFO - __main__ - Printing 3 examples
06/10/2022 16:14:26 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/10/2022 16:14:26 - INFO - __main__ - ['others']
06/10/2022 16:14:26 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/10/2022 16:14:26 - INFO - __main__ - ['others']
06/10/2022 16:14:26 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/10/2022 16:14:26 - INFO - __main__ - ['others']
06/10/2022 16:14:26 - INFO - __main__ - Tokenizing Input ...
06/10/2022 16:14:26 - INFO - __main__ - Tokenizing Output ...
06/10/2022 16:14:26 - INFO - __main__ - Loaded 64 examples from train data
06/10/2022 16:14:26 - INFO - __main__ - Start tokenizing ... 64 instances
06/10/2022 16:14:26 - INFO - __main__ - Printing 3 examples
06/10/2022 16:14:26 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
06/10/2022 16:14:26 - INFO - __main__ - ['others']
06/10/2022 16:14:26 - INFO - __main__ -  [emo] i did ask now you did tell ms
06/10/2022 16:14:26 - INFO - __main__ - ['others']
06/10/2022 16:14:26 - INFO - __main__ -  [emo] buddy how you tell me your contact no
06/10/2022 16:14:26 - INFO - __main__ - ['others']
06/10/2022 16:14:26 - INFO - __main__ - Tokenizing Input ...
06/10/2022 16:14:26 - INFO - __main__ - Tokenizing Output ...
06/10/2022 16:14:26 - INFO - __main__ - Loaded 64 examples from dev data
06/10/2022 16:14:28 - INFO - __main__ - Tokenizing Output ...
06/10/2022 16:14:33 - INFO - __main__ - Loaded 5509 examples from test data
06/10/2022 16:14:41 - INFO - __main__ - load prompt embedding from ckpt
06/10/2022 16:14:42 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/10/2022 16:14:42 - INFO - __main__ - Starting training!
06/10/2022 16:16:05 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-up32shot/singletask-emo/emo_16_13_0.5_8_predictions.txt
06/10/2022 16:16:05 - INFO - __main__ - Classification-F1 on test data: 0.2359
06/10/2022 16:16:05 - INFO - __main__ - prefix=emo_16_13, lr=0.5, bsz=8, dev_performance=0.8578410836475353, test_performance=0.23591370399868072
06/10/2022 16:16:05 - INFO - __main__ - Running ... prefix=emo_16_13, lr=0.4, bsz=8 ...
06/10/2022 16:16:06 - INFO - __main__ - Start tokenizing ... 64 instances
06/10/2022 16:16:06 - INFO - __main__ - Printing 3 examples
06/10/2022 16:16:06 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/10/2022 16:16:06 - INFO - __main__ - ['others']
06/10/2022 16:16:06 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/10/2022 16:16:06 - INFO - __main__ - ['others']
06/10/2022 16:16:06 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/10/2022 16:16:06 - INFO - __main__ - ['others']
06/10/2022 16:16:06 - INFO - __main__ - Tokenizing Input ...
06/10/2022 16:16:06 - INFO - __main__ - Tokenizing Output ...
06/10/2022 16:16:06 - INFO - __main__ - Loaded 64 examples from train data
06/10/2022 16:16:06 - INFO - __main__ - Start tokenizing ... 64 instances
06/10/2022 16:16:06 - INFO - __main__ - Printing 3 examples
06/10/2022 16:16:06 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
06/10/2022 16:16:06 - INFO - __main__ - ['others']
06/10/2022 16:16:06 - INFO - __main__ -  [emo] i did ask now you did tell ms
06/10/2022 16:16:06 - INFO - __main__ - ['others']
06/10/2022 16:16:06 - INFO - __main__ -  [emo] buddy how you tell me your contact no
06/10/2022 16:16:06 - INFO - __main__ - ['others']
06/10/2022 16:16:06 - INFO - __main__ - Tokenizing Input ...
06/10/2022 16:16:07 - INFO - __main__ - Tokenizing Output ...
06/10/2022 16:16:07 - INFO - __main__ - Loaded 64 examples from dev data
06/10/2022 16:16:22 - INFO - __main__ - load prompt embedding from ckpt
06/10/2022 16:16:23 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/10/2022 16:16:23 - INFO - __main__ - Starting training!
06/10/2022 16:16:25 - INFO - __main__ - Step 10 Global step 10 Train loss 3.54 on epoch=2
06/10/2022 16:16:28 - INFO - __main__ - Step 20 Global step 20 Train loss 2.47 on epoch=4
06/10/2022 16:16:30 - INFO - __main__ - Step 30 Global step 30 Train loss 1.95 on epoch=7
06/10/2022 16:16:33 - INFO - __main__ - Step 40 Global step 40 Train loss 1.47 on epoch=9
06/10/2022 16:16:35 - INFO - __main__ - Step 50 Global step 50 Train loss 1.25 on epoch=12
06/10/2022 16:16:36 - INFO - __main__ - Global step 50 Train loss 2.14 Classification-F1 0.19855442176870747 on epoch=12
06/10/2022 16:16:36 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.19855442176870747 on epoch=12, global_step=50
06/10/2022 16:16:38 - INFO - __main__ - Step 60 Global step 60 Train loss 0.96 on epoch=14
06/10/2022 16:16:41 - INFO - __main__ - Step 70 Global step 70 Train loss 0.82 on epoch=17
06/10/2022 16:16:43 - INFO - __main__ - Step 80 Global step 80 Train loss 0.67 on epoch=19
06/10/2022 16:16:45 - INFO - __main__ - Step 90 Global step 90 Train loss 0.61 on epoch=22
06/10/2022 16:16:48 - INFO - __main__ - Step 100 Global step 100 Train loss 0.53 on epoch=24
06/10/2022 16:16:49 - INFO - __main__ - Global step 100 Train loss 0.72 Classification-F1 0.5130971041993235 on epoch=24
06/10/2022 16:16:49 - INFO - __main__ - Saving model with best Classification-F1: 0.19855442176870747 -> 0.5130971041993235 on epoch=24, global_step=100
06/10/2022 16:16:51 - INFO - __main__ - Step 110 Global step 110 Train loss 0.66 on epoch=27
06/10/2022 16:16:53 - INFO - __main__ - Step 120 Global step 120 Train loss 0.57 on epoch=29
06/10/2022 16:16:56 - INFO - __main__ - Step 130 Global step 130 Train loss 0.65 on epoch=32
06/10/2022 16:16:58 - INFO - __main__ - Step 140 Global step 140 Train loss 0.62 on epoch=34
06/10/2022 16:17:01 - INFO - __main__ - Step 150 Global step 150 Train loss 0.53 on epoch=37
06/10/2022 16:17:01 - INFO - __main__ - Global step 150 Train loss 0.61 Classification-F1 0.5855407750144592 on epoch=37
06/10/2022 16:17:01 - INFO - __main__ - Saving model with best Classification-F1: 0.5130971041993235 -> 0.5855407750144592 on epoch=37, global_step=150
06/10/2022 16:17:04 - INFO - __main__ - Step 160 Global step 160 Train loss 0.50 on epoch=39
06/10/2022 16:17:06 - INFO - __main__ - Step 170 Global step 170 Train loss 0.53 on epoch=42
06/10/2022 16:17:09 - INFO - __main__ - Step 180 Global step 180 Train loss 0.52 on epoch=44
06/10/2022 16:17:11 - INFO - __main__ - Step 190 Global step 190 Train loss 0.44 on epoch=47
06/10/2022 16:17:13 - INFO - __main__ - Step 200 Global step 200 Train loss 0.38 on epoch=49
06/10/2022 16:17:14 - INFO - __main__ - Global step 200 Train loss 0.47 Classification-F1 0.6161409087105681 on epoch=49
06/10/2022 16:17:14 - INFO - __main__ - Saving model with best Classification-F1: 0.5855407750144592 -> 0.6161409087105681 on epoch=49, global_step=200
06/10/2022 16:17:17 - INFO - __main__ - Step 210 Global step 210 Train loss 0.46 on epoch=52
06/10/2022 16:17:19 - INFO - __main__ - Step 220 Global step 220 Train loss 0.46 on epoch=54
06/10/2022 16:17:21 - INFO - __main__ - Step 230 Global step 230 Train loss 0.36 on epoch=57
06/10/2022 16:17:24 - INFO - __main__ - Step 240 Global step 240 Train loss 0.38 on epoch=59
06/10/2022 16:17:26 - INFO - __main__ - Step 250 Global step 250 Train loss 0.29 on epoch=62
06/10/2022 16:17:27 - INFO - __main__ - Global step 250 Train loss 0.39 Classification-F1 0.7336946836946837 on epoch=62
06/10/2022 16:17:27 - INFO - __main__ - Saving model with best Classification-F1: 0.6161409087105681 -> 0.7336946836946837 on epoch=62, global_step=250
06/10/2022 16:17:29 - INFO - __main__ - Step 260 Global step 260 Train loss 0.41 on epoch=64
06/10/2022 16:17:32 - INFO - __main__ - Step 270 Global step 270 Train loss 0.41 on epoch=67
06/10/2022 16:17:34 - INFO - __main__ - Step 280 Global step 280 Train loss 0.37 on epoch=69
06/10/2022 16:17:36 - INFO - __main__ - Step 290 Global step 290 Train loss 0.38 on epoch=72
06/10/2022 16:17:39 - INFO - __main__ - Step 300 Global step 300 Train loss 0.35 on epoch=74
06/10/2022 16:17:40 - INFO - __main__ - Global step 300 Train loss 0.39 Classification-F1 0.7091264651748523 on epoch=74
06/10/2022 16:17:42 - INFO - __main__ - Step 310 Global step 310 Train loss 0.33 on epoch=77
06/10/2022 16:17:44 - INFO - __main__ - Step 320 Global step 320 Train loss 0.35 on epoch=79
06/10/2022 16:17:47 - INFO - __main__ - Step 330 Global step 330 Train loss 0.25 on epoch=82
06/10/2022 16:17:49 - INFO - __main__ - Step 340 Global step 340 Train loss 0.20 on epoch=84
06/10/2022 16:17:51 - INFO - __main__ - Step 350 Global step 350 Train loss 0.25 on epoch=87
06/10/2022 16:17:52 - INFO - __main__ - Global step 350 Train loss 0.27 Classification-F1 0.7653439153439153 on epoch=87
06/10/2022 16:17:52 - INFO - __main__ - Saving model with best Classification-F1: 0.7336946836946837 -> 0.7653439153439153 on epoch=87, global_step=350
06/10/2022 16:17:55 - INFO - __main__ - Step 360 Global step 360 Train loss 0.28 on epoch=89
06/10/2022 16:17:57 - INFO - __main__ - Step 370 Global step 370 Train loss 0.29 on epoch=92
06/10/2022 16:17:59 - INFO - __main__ - Step 380 Global step 380 Train loss 0.28 on epoch=94
06/10/2022 16:18:02 - INFO - __main__ - Step 390 Global step 390 Train loss 0.32 on epoch=97
06/10/2022 16:18:04 - INFO - __main__ - Step 400 Global step 400 Train loss 0.22 on epoch=99
06/10/2022 16:18:05 - INFO - __main__ - Global step 400 Train loss 0.28 Classification-F1 0.757296494355318 on epoch=99
06/10/2022 16:18:07 - INFO - __main__ - Step 410 Global step 410 Train loss 0.21 on epoch=102
06/10/2022 16:18:10 - INFO - __main__ - Step 420 Global step 420 Train loss 0.21 on epoch=104
06/10/2022 16:18:12 - INFO - __main__ - Step 430 Global step 430 Train loss 0.31 on epoch=107
06/10/2022 16:18:15 - INFO - __main__ - Step 440 Global step 440 Train loss 0.20 on epoch=109
06/10/2022 16:18:17 - INFO - __main__ - Step 450 Global step 450 Train loss 0.32 on epoch=112
06/10/2022 16:18:18 - INFO - __main__ - Global step 450 Train loss 0.25 Classification-F1 0.8096865193639388 on epoch=112
06/10/2022 16:18:18 - INFO - __main__ - Saving model with best Classification-F1: 0.7653439153439153 -> 0.8096865193639388 on epoch=112, global_step=450
06/10/2022 16:18:21 - INFO - __main__ - Step 460 Global step 460 Train loss 0.25 on epoch=114
06/10/2022 16:18:23 - INFO - __main__ - Step 470 Global step 470 Train loss 0.17 on epoch=117
06/10/2022 16:18:25 - INFO - __main__ - Step 480 Global step 480 Train loss 0.17 on epoch=119
06/10/2022 16:18:28 - INFO - __main__ - Step 490 Global step 490 Train loss 0.17 on epoch=122
06/10/2022 16:18:30 - INFO - __main__ - Step 500 Global step 500 Train loss 0.21 on epoch=124
06/10/2022 16:18:31 - INFO - __main__ - Global step 500 Train loss 0.19 Classification-F1 0.7910258379008379 on epoch=124
06/10/2022 16:18:34 - INFO - __main__ - Step 510 Global step 510 Train loss 0.12 on epoch=127
06/10/2022 16:18:36 - INFO - __main__ - Step 520 Global step 520 Train loss 0.14 on epoch=129
06/10/2022 16:18:38 - INFO - __main__ - Step 530 Global step 530 Train loss 0.23 on epoch=132
06/10/2022 16:18:41 - INFO - __main__ - Step 540 Global step 540 Train loss 0.18 on epoch=134
06/10/2022 16:18:43 - INFO - __main__ - Step 550 Global step 550 Train loss 0.15 on epoch=137
06/10/2022 16:18:44 - INFO - __main__ - Global step 550 Train loss 0.16 Classification-F1 0.7726146331738437 on epoch=137
06/10/2022 16:18:46 - INFO - __main__ - Step 560 Global step 560 Train loss 0.17 on epoch=139
06/10/2022 16:18:49 - INFO - __main__ - Step 570 Global step 570 Train loss 0.19 on epoch=142
06/10/2022 16:18:51 - INFO - __main__ - Step 580 Global step 580 Train loss 0.18 on epoch=144
06/10/2022 16:18:53 - INFO - __main__ - Step 590 Global step 590 Train loss 0.15 on epoch=147
06/10/2022 16:18:56 - INFO - __main__ - Step 600 Global step 600 Train loss 0.08 on epoch=149
06/10/2022 16:18:57 - INFO - __main__ - Global step 600 Train loss 0.15 Classification-F1 0.7910258379008379 on epoch=149
06/10/2022 16:18:59 - INFO - __main__ - Step 610 Global step 610 Train loss 0.12 on epoch=152
06/10/2022 16:19:01 - INFO - __main__ - Step 620 Global step 620 Train loss 0.07 on epoch=154
06/10/2022 16:19:04 - INFO - __main__ - Step 630 Global step 630 Train loss 0.12 on epoch=157
06/10/2022 16:19:06 - INFO - __main__ - Step 640 Global step 640 Train loss 0.10 on epoch=159
06/10/2022 16:19:09 - INFO - __main__ - Step 650 Global step 650 Train loss 0.10 on epoch=162
06/10/2022 16:19:09 - INFO - __main__ - Global step 650 Train loss 0.10 Classification-F1 0.7910258379008379 on epoch=162
06/10/2022 16:19:12 - INFO - __main__ - Step 660 Global step 660 Train loss 0.06 on epoch=164
06/10/2022 16:19:14 - INFO - __main__ - Step 670 Global step 670 Train loss 0.08 on epoch=167
06/10/2022 16:19:17 - INFO - __main__ - Step 680 Global step 680 Train loss 0.05 on epoch=169
06/10/2022 16:19:19 - INFO - __main__ - Step 690 Global step 690 Train loss 0.10 on epoch=172
06/10/2022 16:19:21 - INFO - __main__ - Step 700 Global step 700 Train loss 0.08 on epoch=174
06/10/2022 16:19:22 - INFO - __main__ - Global step 700 Train loss 0.07 Classification-F1 0.7419444444444444 on epoch=174
06/10/2022 16:19:25 - INFO - __main__ - Step 710 Global step 710 Train loss 0.11 on epoch=177
06/10/2022 16:19:27 - INFO - __main__ - Step 720 Global step 720 Train loss 0.07 on epoch=179
06/10/2022 16:19:29 - INFO - __main__ - Step 730 Global step 730 Train loss 0.10 on epoch=182
06/10/2022 16:19:32 - INFO - __main__ - Step 740 Global step 740 Train loss 0.04 on epoch=184
06/10/2022 16:19:34 - INFO - __main__ - Step 750 Global step 750 Train loss 0.15 on epoch=187
06/10/2022 16:19:35 - INFO - __main__ - Global step 750 Train loss 0.09 Classification-F1 0.6936499907088143 on epoch=187
06/10/2022 16:19:37 - INFO - __main__ - Step 760 Global step 760 Train loss 0.07 on epoch=189
06/10/2022 16:19:40 - INFO - __main__ - Step 770 Global step 770 Train loss 0.11 on epoch=192
06/10/2022 16:19:42 - INFO - __main__ - Step 780 Global step 780 Train loss 0.06 on epoch=194
06/10/2022 16:19:44 - INFO - __main__ - Step 790 Global step 790 Train loss 0.11 on epoch=197
06/10/2022 16:19:47 - INFO - __main__ - Step 800 Global step 800 Train loss 0.06 on epoch=199
06/10/2022 16:19:48 - INFO - __main__ - Global step 800 Train loss 0.08 Classification-F1 0.7512254901960785 on epoch=199
06/10/2022 16:19:50 - INFO - __main__ - Step 810 Global step 810 Train loss 0.06 on epoch=202
06/10/2022 16:19:52 - INFO - __main__ - Step 820 Global step 820 Train loss 0.12 on epoch=204
06/10/2022 16:19:55 - INFO - __main__ - Step 830 Global step 830 Train loss 0.07 on epoch=207
06/10/2022 16:19:57 - INFO - __main__ - Step 840 Global step 840 Train loss 0.11 on epoch=209
06/10/2022 16:20:00 - INFO - __main__ - Step 850 Global step 850 Train loss 0.06 on epoch=212
06/10/2022 16:20:01 - INFO - __main__ - Global step 850 Train loss 0.08 Classification-F1 0.7520021645021646 on epoch=212
06/10/2022 16:20:03 - INFO - __main__ - Step 860 Global step 860 Train loss 0.06 on epoch=214
06/10/2022 16:20:05 - INFO - __main__ - Step 870 Global step 870 Train loss 0.05 on epoch=217
06/10/2022 16:20:08 - INFO - __main__ - Step 880 Global step 880 Train loss 0.15 on epoch=219
06/10/2022 16:20:10 - INFO - __main__ - Step 890 Global step 890 Train loss 0.04 on epoch=222
06/10/2022 16:20:12 - INFO - __main__ - Step 900 Global step 900 Train loss 0.02 on epoch=224
06/10/2022 16:20:13 - INFO - __main__ - Global step 900 Train loss 0.07 Classification-F1 0.7401220575414124 on epoch=224
06/10/2022 16:20:16 - INFO - __main__ - Step 910 Global step 910 Train loss 0.02 on epoch=227
06/10/2022 16:20:18 - INFO - __main__ - Step 920 Global step 920 Train loss 0.03 on epoch=229
06/10/2022 16:20:20 - INFO - __main__ - Step 930 Global step 930 Train loss 0.04 on epoch=232
06/10/2022 16:20:23 - INFO - __main__ - Step 940 Global step 940 Train loss 0.09 on epoch=234
06/10/2022 16:20:25 - INFO - __main__ - Step 950 Global step 950 Train loss 0.07 on epoch=237
06/10/2022 16:20:26 - INFO - __main__ - Global step 950 Train loss 0.05 Classification-F1 0.7231259968102074 on epoch=237
06/10/2022 16:20:29 - INFO - __main__ - Step 960 Global step 960 Train loss 0.08 on epoch=239
06/10/2022 16:20:31 - INFO - __main__ - Step 970 Global step 970 Train loss 0.09 on epoch=242
06/10/2022 16:20:33 - INFO - __main__ - Step 980 Global step 980 Train loss 0.04 on epoch=244
06/10/2022 16:20:36 - INFO - __main__ - Step 990 Global step 990 Train loss 0.11 on epoch=247
06/10/2022 16:20:38 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.01 on epoch=249
06/10/2022 16:20:39 - INFO - __main__ - Global step 1000 Train loss 0.07 Classification-F1 0.7523989898989899 on epoch=249
06/10/2022 16:20:41 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.07 on epoch=252
06/10/2022 16:20:44 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.06 on epoch=254
06/10/2022 16:20:46 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.02 on epoch=257
06/10/2022 16:20:48 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.06 on epoch=259
06/10/2022 16:20:51 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.02 on epoch=262
06/10/2022 16:20:52 - INFO - __main__ - Global step 1050 Train loss 0.05 Classification-F1 0.7721212121212121 on epoch=262
06/10/2022 16:20:54 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.02 on epoch=264
06/10/2022 16:20:56 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.05 on epoch=267
06/10/2022 16:20:59 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.02 on epoch=269
06/10/2022 16:21:01 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.07 on epoch=272
06/10/2022 16:21:04 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.03 on epoch=274
06/10/2022 16:21:04 - INFO - __main__ - Global step 1100 Train loss 0.04 Classification-F1 0.7419444444444444 on epoch=274
06/10/2022 16:21:07 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.08 on epoch=277
06/10/2022 16:21:09 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.05 on epoch=279
06/10/2022 16:21:12 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.03 on epoch=282
06/10/2022 16:21:14 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.01 on epoch=284
06/10/2022 16:21:16 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.05 on epoch=287
06/10/2022 16:21:17 - INFO - __main__ - Global step 1150 Train loss 0.04 Classification-F1 0.7759289729877966 on epoch=287
06/10/2022 16:21:20 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.06 on epoch=289
06/10/2022 16:21:22 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.04 on epoch=292
06/10/2022 16:21:24 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.02 on epoch=294
06/10/2022 16:21:27 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.02 on epoch=297
06/10/2022 16:21:29 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.08 on epoch=299
06/10/2022 16:21:30 - INFO - __main__ - Global step 1200 Train loss 0.05 Classification-F1 0.7517156862745098 on epoch=299
06/10/2022 16:21:32 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.04 on epoch=302
06/10/2022 16:21:35 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.02 on epoch=304
06/10/2022 16:21:37 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.08 on epoch=307
06/10/2022 16:21:39 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.03 on epoch=309
06/10/2022 16:21:42 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.03 on epoch=312
06/10/2022 16:21:43 - INFO - __main__ - Global step 1250 Train loss 0.04 Classification-F1 0.7759289729877965 on epoch=312
06/10/2022 16:21:45 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.04 on epoch=314
06/10/2022 16:21:48 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.03 on epoch=317
06/10/2022 16:21:50 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.04 on epoch=319
06/10/2022 16:21:52 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=322
06/10/2022 16:21:55 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.02 on epoch=324
06/10/2022 16:21:56 - INFO - __main__ - Global step 1300 Train loss 0.03 Classification-F1 0.7759289729877966 on epoch=324
06/10/2022 16:21:58 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.06 on epoch=327
06/10/2022 16:22:00 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.02 on epoch=329
06/10/2022 16:22:03 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.02 on epoch=332
06/10/2022 16:22:05 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=334
06/10/2022 16:22:07 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.02 on epoch=337
06/10/2022 16:22:08 - INFO - __main__ - Global step 1350 Train loss 0.02 Classification-F1 0.7759289729877966 on epoch=337
06/10/2022 16:22:11 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=339
06/10/2022 16:22:13 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=342
06/10/2022 16:22:15 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=344
06/10/2022 16:22:18 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.03 on epoch=347
06/10/2022 16:22:20 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=349
06/10/2022 16:22:21 - INFO - __main__ - Global step 1400 Train loss 0.02 Classification-F1 0.7759289729877966 on epoch=349
06/10/2022 16:22:24 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.06 on epoch=352
06/10/2022 16:22:26 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=354
06/10/2022 16:22:28 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.04 on epoch=357
06/10/2022 16:22:31 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.03 on epoch=359
06/10/2022 16:22:33 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=362
06/10/2022 16:22:34 - INFO - __main__ - Global step 1450 Train loss 0.04 Classification-F1 0.760576923076923 on epoch=362
06/10/2022 16:22:36 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=364
06/10/2022 16:22:39 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=367
06/10/2022 16:22:41 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.02 on epoch=369
06/10/2022 16:22:43 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.03 on epoch=372
06/10/2022 16:22:46 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=374
06/10/2022 16:22:47 - INFO - __main__ - Global step 1500 Train loss 0.01 Classification-F1 0.7518337187454835 on epoch=374
06/10/2022 16:22:49 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.03 on epoch=377
06/10/2022 16:22:51 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=379
06/10/2022 16:22:54 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.06 on epoch=382
06/10/2022 16:22:56 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=384
06/10/2022 16:22:58 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.09 on epoch=387
06/10/2022 16:22:59 - INFO - __main__ - Global step 1550 Train loss 0.04 Classification-F1 0.7721212121212121 on epoch=387
06/10/2022 16:23:02 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.02 on epoch=389
06/10/2022 16:23:04 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=392
06/10/2022 16:23:06 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=394
06/10/2022 16:23:09 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=397
06/10/2022 16:23:11 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.04 on epoch=399
06/10/2022 16:23:12 - INFO - __main__ - Global step 1600 Train loss 0.02 Classification-F1 0.71495566712958 on epoch=399
06/10/2022 16:23:14 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=402
06/10/2022 16:23:17 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.05 on epoch=404
06/10/2022 16:23:19 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.02 on epoch=407
06/10/2022 16:23:22 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=409
06/10/2022 16:23:24 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=412
06/10/2022 16:23:25 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.757296494355318 on epoch=412
06/10/2022 16:23:27 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=414
06/10/2022 16:23:29 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=417
06/10/2022 16:23:32 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=419
06/10/2022 16:23:34 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.06 on epoch=422
06/10/2022 16:23:36 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=424
06/10/2022 16:23:37 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.8060426093514329 on epoch=424
06/10/2022 16:23:40 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=427
06/10/2022 16:23:42 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.06 on epoch=429
06/10/2022 16:23:44 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=432
06/10/2022 16:23:47 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=434
06/10/2022 16:23:49 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=437
06/10/2022 16:23:50 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.760903720462544 on epoch=437
06/10/2022 16:23:53 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.22 on epoch=439
06/10/2022 16:23:55 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=442
06/10/2022 16:23:57 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=444
06/10/2022 16:24:00 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=447
06/10/2022 16:24:02 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=449
06/10/2022 16:24:03 - INFO - __main__ - Global step 1800 Train loss 0.05 Classification-F1 0.7905011655011656 on epoch=449
06/10/2022 16:24:06 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=452
06/10/2022 16:24:08 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=454
06/10/2022 16:24:10 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=457
06/10/2022 16:24:13 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=459
06/10/2022 16:24:15 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.04 on epoch=462
06/10/2022 16:24:16 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.7717936117936118 on epoch=462
06/10/2022 16:24:18 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=464
06/10/2022 16:24:21 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=467
06/10/2022 16:24:23 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=469
06/10/2022 16:24:25 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=472
06/10/2022 16:24:28 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=474
06/10/2022 16:24:29 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.7558333333333334 on epoch=474
06/10/2022 16:24:31 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=477
06/10/2022 16:24:33 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=479
06/10/2022 16:24:36 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=482
06/10/2022 16:24:38 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=484
06/10/2022 16:24:40 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=487
06/10/2022 16:24:41 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.7747926093514329 on epoch=487
06/10/2022 16:24:44 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=489
06/10/2022 16:24:46 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=492
06/10/2022 16:24:48 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=494
06/10/2022 16:24:51 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=497
06/10/2022 16:24:53 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=499
06/10/2022 16:24:54 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.7905011655011656 on epoch=499
06/10/2022 16:24:56 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=502
06/10/2022 16:24:59 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
06/10/2022 16:25:01 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.04 on epoch=507
06/10/2022 16:25:03 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=509
06/10/2022 16:25:06 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/10/2022 16:25:06 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.8060426093514329 on epoch=512
06/10/2022 16:25:09 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.06 on epoch=514
06/10/2022 16:25:11 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=517
06/10/2022 16:25:14 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=519
06/10/2022 16:25:16 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/10/2022 16:25:18 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/10/2022 16:25:19 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.7725961538461539 on epoch=524
06/10/2022 16:25:22 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
06/10/2022 16:25:24 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.07 on epoch=529
06/10/2022 16:25:26 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/10/2022 16:25:29 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
06/10/2022 16:25:31 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.04 on epoch=537
06/10/2022 16:25:32 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.8060426093514329 on epoch=537
06/10/2022 16:25:34 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=539
06/10/2022 16:25:37 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=542
06/10/2022 16:25:39 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=544
06/10/2022 16:25:41 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/10/2022 16:25:44 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/10/2022 16:25:45 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.7512254901960785 on epoch=549
06/10/2022 16:25:47 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=552
06/10/2022 16:25:49 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/10/2022 16:25:52 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=557
06/10/2022 16:25:54 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=559
06/10/2022 16:25:56 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/10/2022 16:25:57 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.7225225225225225 on epoch=562
06/10/2022 16:26:00 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.05 on epoch=564
06/10/2022 16:26:02 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=567
06/10/2022 16:26:04 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/10/2022 16:26:07 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/10/2022 16:26:09 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/10/2022 16:26:10 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.760576923076923 on epoch=574
06/10/2022 16:26:12 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/10/2022 16:26:15 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/10/2022 16:26:17 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=582
06/10/2022 16:26:19 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/10/2022 16:26:22 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=587
06/10/2022 16:26:23 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.7560850556438793 on epoch=587
06/10/2022 16:26:25 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=589
06/10/2022 16:26:27 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/10/2022 16:26:30 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/10/2022 16:26:32 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=597
06/10/2022 16:26:35 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/10/2022 16:26:35 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.7717936117936118 on epoch=599
06/10/2022 16:26:38 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/10/2022 16:26:40 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=604
06/10/2022 16:26:42 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.05 on epoch=607
06/10/2022 16:26:45 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=609
06/10/2022 16:26:47 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=612
06/10/2022 16:26:48 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.7717936117936118 on epoch=612
06/10/2022 16:26:50 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/10/2022 16:26:53 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/10/2022 16:26:55 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=619
06/10/2022 16:26:57 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=622
06/10/2022 16:27:00 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/10/2022 16:27:01 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.7711853832442068 on epoch=624
06/10/2022 16:27:03 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/10/2022 16:27:05 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/10/2022 16:27:08 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=632
06/10/2022 16:27:10 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=634
06/10/2022 16:27:12 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/10/2022 16:27:13 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.7717936117936118 on epoch=637
06/10/2022 16:27:16 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/10/2022 16:27:18 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=642
06/10/2022 16:27:20 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/10/2022 16:27:23 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/10/2022 16:27:25 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=649
06/10/2022 16:27:26 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.7717936117936118 on epoch=649
06/10/2022 16:27:28 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/10/2022 16:27:31 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=654
06/10/2022 16:27:33 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=657
06/10/2022 16:27:35 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=659
06/10/2022 16:27:38 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/10/2022 16:27:39 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.7910876757650951 on epoch=662
06/10/2022 16:27:41 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/10/2022 16:27:43 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/10/2022 16:27:46 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/10/2022 16:27:48 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=672
06/10/2022 16:27:51 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=674
06/10/2022 16:27:52 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.7717936117936118 on epoch=674
06/10/2022 16:27:54 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=677
06/10/2022 16:27:56 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/10/2022 16:27:59 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/10/2022 16:28:01 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/10/2022 16:28:03 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=687
06/10/2022 16:28:04 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.7905011655011656 on epoch=687
06/10/2022 16:28:07 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/10/2022 16:28:09 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/10/2022 16:28:11 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=694
06/10/2022 16:28:14 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=697
06/10/2022 16:28:16 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=699
06/10/2022 16:28:17 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.7905011655011656 on epoch=699
06/10/2022 16:28:19 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/10/2022 16:28:22 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=704
06/10/2022 16:28:24 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.06 on epoch=707
06/10/2022 16:28:26 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.07 on epoch=709
06/10/2022 16:28:29 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/10/2022 16:28:30 - INFO - __main__ - Global step 2850 Train loss 0.03 Classification-F1 0.7518337187454835 on epoch=712
06/10/2022 16:28:32 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/10/2022 16:28:34 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=717
06/10/2022 16:28:37 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=719
06/10/2022 16:28:39 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/10/2022 16:28:41 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/10/2022 16:28:42 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.7518337187454835 on epoch=724
06/10/2022 16:28:45 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/10/2022 16:28:47 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/10/2022 16:28:49 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.03 on epoch=732
06/10/2022 16:28:52 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/10/2022 16:28:54 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/10/2022 16:28:55 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.7419444444444444 on epoch=737
06/10/2022 16:28:58 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/10/2022 16:29:00 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/10/2022 16:29:02 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/10/2022 16:29:05 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/10/2022 16:29:07 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=749
06/10/2022 16:29:08 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.7905011655011656 on epoch=749
06/10/2022 16:29:08 - INFO - __main__ - save last model!
06/10/2022 16:29:08 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/10/2022 16:29:08 - INFO - __main__ - Start tokenizing ... 5509 instances
06/10/2022 16:29:08 - INFO - __main__ - Printing 3 examples
06/10/2022 16:29:08 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/10/2022 16:29:08 - INFO - __main__ - ['others']
06/10/2022 16:29:08 - INFO - __main__ -  [emo] what you like very little things ok
06/10/2022 16:29:08 - INFO - __main__ - ['others']
06/10/2022 16:29:08 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/10/2022 16:29:08 - INFO - __main__ - ['others']
06/10/2022 16:29:08 - INFO - __main__ - Tokenizing Input ...
06/10/2022 16:29:08 - INFO - __main__ - Start tokenizing ... 64 instances
06/10/2022 16:29:08 - INFO - __main__ - Printing 3 examples
06/10/2022 16:29:08 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/10/2022 16:29:08 - INFO - __main__ - ['others']
06/10/2022 16:29:08 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/10/2022 16:29:08 - INFO - __main__ - ['others']
06/10/2022 16:29:08 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/10/2022 16:29:08 - INFO - __main__ - ['others']
06/10/2022 16:29:08 - INFO - __main__ - Tokenizing Input ...
06/10/2022 16:29:08 - INFO - __main__ - Tokenizing Output ...
06/10/2022 16:29:08 - INFO - __main__ - Loaded 64 examples from train data
06/10/2022 16:29:08 - INFO - __main__ - Start tokenizing ... 64 instances
06/10/2022 16:29:08 - INFO - __main__ - Printing 3 examples
06/10/2022 16:29:08 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
06/10/2022 16:29:08 - INFO - __main__ - ['others']
06/10/2022 16:29:08 - INFO - __main__ -  [emo] i did ask now you did tell ms
06/10/2022 16:29:08 - INFO - __main__ - ['others']
06/10/2022 16:29:08 - INFO - __main__ -  [emo] buddy how you tell me your contact no
06/10/2022 16:29:08 - INFO - __main__ - ['others']
06/10/2022 16:29:08 - INFO - __main__ - Tokenizing Input ...
06/10/2022 16:29:08 - INFO - __main__ - Tokenizing Output ...
06/10/2022 16:29:09 - INFO - __main__ - Loaded 64 examples from dev data
06/10/2022 16:29:10 - INFO - __main__ - Tokenizing Output ...
06/10/2022 16:29:16 - INFO - __main__ - Loaded 5509 examples from test data
06/10/2022 16:29:24 - INFO - __main__ - load prompt embedding from ckpt
06/10/2022 16:29:25 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/10/2022 16:29:25 - INFO - __main__ - Starting training!
06/10/2022 16:30:37 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-up32shot/singletask-emo/emo_16_13_0.4_8_predictions.txt
06/10/2022 16:30:37 - INFO - __main__ - Classification-F1 on test data: 0.2692
06/10/2022 16:30:37 - INFO - __main__ - prefix=emo_16_13, lr=0.4, bsz=8, dev_performance=0.8096865193639388, test_performance=0.2691938086849133
06/10/2022 16:30:37 - INFO - __main__ - Running ... prefix=emo_16_13, lr=0.3, bsz=8 ...
06/10/2022 16:30:38 - INFO - __main__ - Start tokenizing ... 64 instances
06/10/2022 16:30:38 - INFO - __main__ - Printing 3 examples
06/10/2022 16:30:38 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/10/2022 16:30:38 - INFO - __main__ - ['others']
06/10/2022 16:30:38 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/10/2022 16:30:38 - INFO - __main__ - ['others']
06/10/2022 16:30:38 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/10/2022 16:30:38 - INFO - __main__ - ['others']
06/10/2022 16:30:38 - INFO - __main__ - Tokenizing Input ...
06/10/2022 16:30:38 - INFO - __main__ - Tokenizing Output ...
06/10/2022 16:30:38 - INFO - __main__ - Loaded 64 examples from train data
06/10/2022 16:30:38 - INFO - __main__ - Start tokenizing ... 64 instances
06/10/2022 16:30:38 - INFO - __main__ - Printing 3 examples
06/10/2022 16:30:38 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
06/10/2022 16:30:38 - INFO - __main__ - ['others']
06/10/2022 16:30:38 - INFO - __main__ -  [emo] i did ask now you did tell ms
06/10/2022 16:30:38 - INFO - __main__ - ['others']
06/10/2022 16:30:38 - INFO - __main__ -  [emo] buddy how you tell me your contact no
06/10/2022 16:30:38 - INFO - __main__ - ['others']
06/10/2022 16:30:38 - INFO - __main__ - Tokenizing Input ...
06/10/2022 16:30:38 - INFO - __main__ - Tokenizing Output ...
06/10/2022 16:30:38 - INFO - __main__ - Loaded 64 examples from dev data
06/10/2022 16:30:53 - INFO - __main__ - load prompt embedding from ckpt
06/10/2022 16:30:54 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/10/2022 16:30:54 - INFO - __main__ - Starting training!
06/10/2022 16:30:57 - INFO - __main__ - Step 10 Global step 10 Train loss 3.88 on epoch=2
06/10/2022 16:30:59 - INFO - __main__ - Step 20 Global step 20 Train loss 2.73 on epoch=4
06/10/2022 16:31:02 - INFO - __main__ - Step 30 Global step 30 Train loss 2.22 on epoch=7
06/10/2022 16:31:04 - INFO - __main__ - Step 40 Global step 40 Train loss 1.80 on epoch=9
06/10/2022 16:31:06 - INFO - __main__ - Step 50 Global step 50 Train loss 1.54 on epoch=12
06/10/2022 16:31:07 - INFO - __main__ - Global step 50 Train loss 2.44 Classification-F1 0.09912390488110137 on epoch=12
06/10/2022 16:31:07 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.09912390488110137 on epoch=12, global_step=50
06/10/2022 16:31:10 - INFO - __main__ - Step 60 Global step 60 Train loss 1.16 on epoch=14
06/10/2022 16:31:12 - INFO - __main__ - Step 70 Global step 70 Train loss 1.08 on epoch=17
06/10/2022 16:31:14 - INFO - __main__ - Step 80 Global step 80 Train loss 0.77 on epoch=19
06/10/2022 16:31:17 - INFO - __main__ - Step 90 Global step 90 Train loss 0.69 on epoch=22
06/10/2022 16:31:19 - INFO - __main__ - Step 100 Global step 100 Train loss 0.74 on epoch=24
06/10/2022 16:31:20 - INFO - __main__ - Global step 100 Train loss 0.89 Classification-F1 0.4939542483660131 on epoch=24
06/10/2022 16:31:20 - INFO - __main__ - Saving model with best Classification-F1: 0.09912390488110137 -> 0.4939542483660131 on epoch=24, global_step=100
06/10/2022 16:31:22 - INFO - __main__ - Step 110 Global step 110 Train loss 0.69 on epoch=27
06/10/2022 16:31:25 - INFO - __main__ - Step 120 Global step 120 Train loss 0.61 on epoch=29
06/10/2022 16:31:27 - INFO - __main__ - Step 130 Global step 130 Train loss 0.66 on epoch=32
06/10/2022 16:31:29 - INFO - __main__ - Step 140 Global step 140 Train loss 0.59 on epoch=34
06/10/2022 16:31:32 - INFO - __main__ - Step 150 Global step 150 Train loss 0.67 on epoch=37
06/10/2022 16:31:33 - INFO - __main__ - Global step 150 Train loss 0.64 Classification-F1 0.6092930742141646 on epoch=37
06/10/2022 16:31:33 - INFO - __main__ - Saving model with best Classification-F1: 0.4939542483660131 -> 0.6092930742141646 on epoch=37, global_step=150
06/10/2022 16:31:35 - INFO - __main__ - Step 160 Global step 160 Train loss 0.54 on epoch=39
06/10/2022 16:31:37 - INFO - __main__ - Step 170 Global step 170 Train loss 0.60 on epoch=42
06/10/2022 16:31:40 - INFO - __main__ - Step 180 Global step 180 Train loss 0.58 on epoch=44
06/10/2022 16:31:42 - INFO - __main__ - Step 190 Global step 190 Train loss 0.56 on epoch=47
06/10/2022 16:31:44 - INFO - __main__ - Step 200 Global step 200 Train loss 0.51 on epoch=49
06/10/2022 16:31:45 - INFO - __main__ - Global step 200 Train loss 0.56 Classification-F1 0.573773397457608 on epoch=49
06/10/2022 16:31:48 - INFO - __main__ - Step 210 Global step 210 Train loss 0.50 on epoch=52
06/10/2022 16:31:50 - INFO - __main__ - Step 220 Global step 220 Train loss 0.51 on epoch=54
06/10/2022 16:31:52 - INFO - __main__ - Step 230 Global step 230 Train loss 0.54 on epoch=57
06/10/2022 16:31:55 - INFO - __main__ - Step 240 Global step 240 Train loss 0.49 on epoch=59
06/10/2022 16:31:57 - INFO - __main__ - Step 250 Global step 250 Train loss 0.46 on epoch=62
06/10/2022 16:31:58 - INFO - __main__ - Global step 250 Train loss 0.50 Classification-F1 0.6277777777777778 on epoch=62
06/10/2022 16:31:58 - INFO - __main__ - Saving model with best Classification-F1: 0.6092930742141646 -> 0.6277777777777778 on epoch=62, global_step=250
06/10/2022 16:32:00 - INFO - __main__ - Step 260 Global step 260 Train loss 0.45 on epoch=64
06/10/2022 16:32:03 - INFO - __main__ - Step 270 Global step 270 Train loss 0.43 on epoch=67
06/10/2022 16:32:05 - INFO - __main__ - Step 280 Global step 280 Train loss 0.45 on epoch=69
06/10/2022 16:32:07 - INFO - __main__ - Step 290 Global step 290 Train loss 0.41 on epoch=72
06/10/2022 16:32:10 - INFO - __main__ - Step 300 Global step 300 Train loss 0.43 on epoch=74
06/10/2022 16:32:11 - INFO - __main__ - Global step 300 Train loss 0.43 Classification-F1 0.5889859784596627 on epoch=74
06/10/2022 16:32:13 - INFO - __main__ - Step 310 Global step 310 Train loss 0.38 on epoch=77
06/10/2022 16:32:15 - INFO - __main__ - Step 320 Global step 320 Train loss 0.39 on epoch=79
06/10/2022 16:32:18 - INFO - __main__ - Step 330 Global step 330 Train loss 0.44 on epoch=82
06/10/2022 16:32:20 - INFO - __main__ - Step 340 Global step 340 Train loss 0.36 on epoch=84
06/10/2022 16:32:22 - INFO - __main__ - Step 350 Global step 350 Train loss 0.37 on epoch=87
06/10/2022 16:32:23 - INFO - __main__ - Global step 350 Train loss 0.39 Classification-F1 0.6992899584076055 on epoch=87
06/10/2022 16:32:23 - INFO - __main__ - Saving model with best Classification-F1: 0.6277777777777778 -> 0.6992899584076055 on epoch=87, global_step=350
06/10/2022 16:32:26 - INFO - __main__ - Step 360 Global step 360 Train loss 0.31 on epoch=89
06/10/2022 16:32:28 - INFO - __main__ - Step 370 Global step 370 Train loss 0.37 on epoch=92
06/10/2022 16:32:30 - INFO - __main__ - Step 380 Global step 380 Train loss 0.35 on epoch=94
06/10/2022 16:32:33 - INFO - __main__ - Step 390 Global step 390 Train loss 0.47 on epoch=97
06/10/2022 16:32:35 - INFO - __main__ - Step 400 Global step 400 Train loss 0.38 on epoch=99
06/10/2022 16:32:36 - INFO - __main__ - Global step 400 Train loss 0.38 Classification-F1 0.7096551765669413 on epoch=99
06/10/2022 16:32:36 - INFO - __main__ - Saving model with best Classification-F1: 0.6992899584076055 -> 0.7096551765669413 on epoch=99, global_step=400
06/10/2022 16:32:38 - INFO - __main__ - Step 410 Global step 410 Train loss 0.32 on epoch=102
06/10/2022 16:32:41 - INFO - __main__ - Step 420 Global step 420 Train loss 0.35 on epoch=104
06/10/2022 16:32:43 - INFO - __main__ - Step 430 Global step 430 Train loss 0.39 on epoch=107
06/10/2022 16:32:45 - INFO - __main__ - Step 440 Global step 440 Train loss 0.27 on epoch=109
06/10/2022 16:32:48 - INFO - __main__ - Step 450 Global step 450 Train loss 0.25 on epoch=112
06/10/2022 16:32:49 - INFO - __main__ - Global step 450 Train loss 0.32 Classification-F1 0.7427375762859634 on epoch=112
06/10/2022 16:32:49 - INFO - __main__ - Saving model with best Classification-F1: 0.7096551765669413 -> 0.7427375762859634 on epoch=112, global_step=450
06/10/2022 16:32:51 - INFO - __main__ - Step 460 Global step 460 Train loss 0.30 on epoch=114
06/10/2022 16:32:53 - INFO - __main__ - Step 470 Global step 470 Train loss 0.27 on epoch=117
06/10/2022 16:32:56 - INFO - __main__ - Step 480 Global step 480 Train loss 0.30 on epoch=119
06/10/2022 16:32:58 - INFO - __main__ - Step 490 Global step 490 Train loss 0.22 on epoch=122
06/10/2022 16:33:00 - INFO - __main__ - Step 500 Global step 500 Train loss 0.35 on epoch=124
06/10/2022 16:33:01 - INFO - __main__ - Global step 500 Train loss 0.29 Classification-F1 0.7951894019256448 on epoch=124
06/10/2022 16:33:01 - INFO - __main__ - Saving model with best Classification-F1: 0.7427375762859634 -> 0.7951894019256448 on epoch=124, global_step=500
06/10/2022 16:33:04 - INFO - __main__ - Step 510 Global step 510 Train loss 0.30 on epoch=127
06/10/2022 16:33:06 - INFO - __main__ - Step 520 Global step 520 Train loss 0.22 on epoch=129
06/10/2022 16:33:08 - INFO - __main__ - Step 530 Global step 530 Train loss 0.33 on epoch=132
06/10/2022 16:33:11 - INFO - __main__ - Step 540 Global step 540 Train loss 0.30 on epoch=134
06/10/2022 16:33:13 - INFO - __main__ - Step 550 Global step 550 Train loss 0.28 on epoch=137
06/10/2022 16:33:14 - INFO - __main__ - Global step 550 Train loss 0.29 Classification-F1 0.7922439756056054 on epoch=137
06/10/2022 16:33:16 - INFO - __main__ - Step 560 Global step 560 Train loss 0.20 on epoch=139
06/10/2022 16:33:19 - INFO - __main__ - Step 570 Global step 570 Train loss 0.22 on epoch=142
06/10/2022 16:33:21 - INFO - __main__ - Step 580 Global step 580 Train loss 0.25 on epoch=144
06/10/2022 16:33:23 - INFO - __main__ - Step 590 Global step 590 Train loss 0.25 on epoch=147
06/10/2022 16:33:26 - INFO - __main__ - Step 600 Global step 600 Train loss 0.23 on epoch=149
06/10/2022 16:33:26 - INFO - __main__ - Global step 600 Train loss 0.23 Classification-F1 0.7763276970707312 on epoch=149
06/10/2022 16:33:29 - INFO - __main__ - Step 610 Global step 610 Train loss 0.21 on epoch=152
06/10/2022 16:33:31 - INFO - __main__ - Step 620 Global step 620 Train loss 0.16 on epoch=154
06/10/2022 16:33:34 - INFO - __main__ - Step 630 Global step 630 Train loss 0.20 on epoch=157
06/10/2022 16:33:36 - INFO - __main__ - Step 640 Global step 640 Train loss 0.19 on epoch=159
06/10/2022 16:33:39 - INFO - __main__ - Step 650 Global step 650 Train loss 0.25 on epoch=162
06/10/2022 16:33:40 - INFO - __main__ - Global step 650 Train loss 0.20 Classification-F1 0.7922439756056054 on epoch=162
06/10/2022 16:33:42 - INFO - __main__ - Step 660 Global step 660 Train loss 0.21 on epoch=164
06/10/2022 16:33:44 - INFO - __main__ - Step 670 Global step 670 Train loss 0.17 on epoch=167
06/10/2022 16:33:47 - INFO - __main__ - Step 680 Global step 680 Train loss 0.16 on epoch=169
06/10/2022 16:33:49 - INFO - __main__ - Step 690 Global step 690 Train loss 0.19 on epoch=172
06/10/2022 16:33:52 - INFO - __main__ - Step 700 Global step 700 Train loss 0.13 on epoch=174
06/10/2022 16:33:53 - INFO - __main__ - Global step 700 Train loss 0.17 Classification-F1 0.7463657291243497 on epoch=174
06/10/2022 16:33:55 - INFO - __main__ - Step 710 Global step 710 Train loss 0.16 on epoch=177
06/10/2022 16:33:57 - INFO - __main__ - Step 720 Global step 720 Train loss 0.17 on epoch=179
06/10/2022 16:34:00 - INFO - __main__ - Step 730 Global step 730 Train loss 0.15 on epoch=182
06/10/2022 16:34:02 - INFO - __main__ - Step 740 Global step 740 Train loss 0.13 on epoch=184
06/10/2022 16:34:04 - INFO - __main__ - Step 750 Global step 750 Train loss 0.13 on epoch=187
06/10/2022 16:34:05 - INFO - __main__ - Global step 750 Train loss 0.15 Classification-F1 0.7365841073271414 on epoch=187
06/10/2022 16:34:08 - INFO - __main__ - Step 760 Global step 760 Train loss 0.16 on epoch=189
06/10/2022 16:34:10 - INFO - __main__ - Step 770 Global step 770 Train loss 0.13 on epoch=192
06/10/2022 16:34:12 - INFO - __main__ - Step 780 Global step 780 Train loss 0.08 on epoch=194
06/10/2022 16:34:15 - INFO - __main__ - Step 790 Global step 790 Train loss 0.11 on epoch=197
06/10/2022 16:34:17 - INFO - __main__ - Step 800 Global step 800 Train loss 0.13 on epoch=199
06/10/2022 16:34:18 - INFO - __main__ - Global step 800 Train loss 0.12 Classification-F1 0.7225225225225225 on epoch=199
06/10/2022 16:34:20 - INFO - __main__ - Step 810 Global step 810 Train loss 0.16 on epoch=202
06/10/2022 16:34:23 - INFO - __main__ - Step 820 Global step 820 Train loss 0.12 on epoch=204
06/10/2022 16:34:25 - INFO - __main__ - Step 830 Global step 830 Train loss 0.14 on epoch=207
06/10/2022 16:34:27 - INFO - __main__ - Step 840 Global step 840 Train loss 0.14 on epoch=209
06/10/2022 16:34:30 - INFO - __main__ - Step 850 Global step 850 Train loss 0.11 on epoch=212
06/10/2022 16:34:30 - INFO - __main__ - Global step 850 Train loss 0.14 Classification-F1 0.7910258379008379 on epoch=212
06/10/2022 16:34:33 - INFO - __main__ - Step 860 Global step 860 Train loss 0.08 on epoch=214
06/10/2022 16:34:35 - INFO - __main__ - Step 870 Global step 870 Train loss 0.09 on epoch=217
06/10/2022 16:34:37 - INFO - __main__ - Step 880 Global step 880 Train loss 0.10 on epoch=219
06/10/2022 16:34:40 - INFO - __main__ - Step 890 Global step 890 Train loss 0.08 on epoch=222
06/10/2022 16:34:42 - INFO - __main__ - Step 900 Global step 900 Train loss 0.13 on epoch=224
06/10/2022 16:34:43 - INFO - __main__ - Global step 900 Train loss 0.09 Classification-F1 0.7230153540637412 on epoch=224
06/10/2022 16:34:45 - INFO - __main__ - Step 910 Global step 910 Train loss 0.07 on epoch=227
06/10/2022 16:34:48 - INFO - __main__ - Step 920 Global step 920 Train loss 0.11 on epoch=229
06/10/2022 16:34:50 - INFO - __main__ - Step 930 Global step 930 Train loss 0.06 on epoch=232
06/10/2022 16:34:52 - INFO - __main__ - Step 940 Global step 940 Train loss 0.07 on epoch=234
06/10/2022 16:34:55 - INFO - __main__ - Step 950 Global step 950 Train loss 0.09 on epoch=237
06/10/2022 16:34:56 - INFO - __main__ - Global step 950 Train loss 0.08 Classification-F1 0.7230153540637412 on epoch=237
06/10/2022 16:34:58 - INFO - __main__ - Step 960 Global step 960 Train loss 0.12 on epoch=239
06/10/2022 16:35:00 - INFO - __main__ - Step 970 Global step 970 Train loss 0.06 on epoch=242
06/10/2022 16:35:03 - INFO - __main__ - Step 980 Global step 980 Train loss 0.12 on epoch=244
06/10/2022 16:35:05 - INFO - __main__ - Step 990 Global step 990 Train loss 0.09 on epoch=247
06/10/2022 16:35:07 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.03 on epoch=249
06/10/2022 16:35:08 - INFO - __main__ - Global step 1000 Train loss 0.08 Classification-F1 0.7227731092436975 on epoch=249
06/10/2022 16:35:11 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.09 on epoch=252
06/10/2022 16:35:13 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.07 on epoch=254
06/10/2022 16:35:15 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.07 on epoch=257
06/10/2022 16:35:18 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.03 on epoch=259
06/10/2022 16:35:20 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.10 on epoch=262
06/10/2022 16:35:21 - INFO - __main__ - Global step 1050 Train loss 0.07 Classification-F1 0.737874572433396 on epoch=262
06/10/2022 16:35:23 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.05 on epoch=264
06/10/2022 16:35:25 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.04 on epoch=267
06/10/2022 16:35:28 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.06 on epoch=269
06/10/2022 16:35:30 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.04 on epoch=272
06/10/2022 16:35:33 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.03 on epoch=274
06/10/2022 16:35:33 - INFO - __main__ - Global step 1100 Train loss 0.04 Classification-F1 0.694422191481015 on epoch=274
06/10/2022 16:35:36 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.04 on epoch=277
06/10/2022 16:35:38 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.04 on epoch=279
06/10/2022 16:35:40 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.07 on epoch=282
06/10/2022 16:35:43 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.02 on epoch=284
06/10/2022 16:35:45 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.04 on epoch=287
06/10/2022 16:35:46 - INFO - __main__ - Global step 1150 Train loss 0.04 Classification-F1 0.7160556976413752 on epoch=287
06/10/2022 16:35:48 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.03 on epoch=289
06/10/2022 16:35:51 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.05 on epoch=292
06/10/2022 16:35:53 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.06 on epoch=294
06/10/2022 16:35:55 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.03 on epoch=297
06/10/2022 16:35:58 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.07 on epoch=299
06/10/2022 16:35:59 - INFO - __main__ - Global step 1200 Train loss 0.05 Classification-F1 0.7941925381263616 on epoch=299
06/10/2022 16:36:01 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.03 on epoch=302
06/10/2022 16:36:03 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.03 on epoch=304
06/10/2022 16:36:06 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.03 on epoch=307
06/10/2022 16:36:08 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=309
06/10/2022 16:36:10 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.04 on epoch=312
06/10/2022 16:36:11 - INFO - __main__ - Global step 1250 Train loss 0.03 Classification-F1 0.7941925381263616 on epoch=312
06/10/2022 16:36:14 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.05 on epoch=314
06/10/2022 16:36:16 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.09 on epoch=317
06/10/2022 16:36:18 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.02 on epoch=319
06/10/2022 16:36:21 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=322
06/10/2022 16:36:23 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.02 on epoch=324
06/10/2022 16:36:24 - INFO - __main__ - Global step 1300 Train loss 0.04 Classification-F1 0.7765287204625441 on epoch=324
06/10/2022 16:36:26 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.03 on epoch=327
06/10/2022 16:36:29 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.02 on epoch=329
06/10/2022 16:36:31 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.02 on epoch=332
06/10/2022 16:36:34 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.05 on epoch=334
06/10/2022 16:36:36 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.09 on epoch=337
06/10/2022 16:36:37 - INFO - __main__ - Global step 1350 Train loss 0.04 Classification-F1 0.7808316430020283 on epoch=337
06/10/2022 16:36:39 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=339
06/10/2022 16:36:42 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.04 on epoch=342
06/10/2022 16:36:44 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.02 on epoch=344
06/10/2022 16:36:46 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.02 on epoch=347
06/10/2022 16:36:49 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.06 on epoch=349
06/10/2022 16:36:50 - INFO - __main__ - Global step 1400 Train loss 0.03 Classification-F1 0.7177703089244851 on epoch=349
06/10/2022 16:36:52 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.03 on epoch=352
06/10/2022 16:36:54 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=354
06/10/2022 16:36:57 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=357
06/10/2022 16:36:59 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.07 on epoch=359
06/10/2022 16:37:01 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.05 on epoch=362
06/10/2022 16:37:02 - INFO - __main__ - Global step 1450 Train loss 0.04 Classification-F1 0.7941925381263616 on epoch=362
06/10/2022 16:37:05 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.02 on epoch=364
06/10/2022 16:37:07 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.02 on epoch=367
06/10/2022 16:37:09 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.06 on epoch=369
06/10/2022 16:37:12 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.04 on epoch=372
06/10/2022 16:37:14 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.03 on epoch=374
06/10/2022 16:37:15 - INFO - __main__ - Global step 1500 Train loss 0.03 Classification-F1 0.7424372759856631 on epoch=374
06/10/2022 16:37:17 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=377
06/10/2022 16:37:20 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.07 on epoch=379
06/10/2022 16:37:22 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=382
06/10/2022 16:37:24 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=384
06/10/2022 16:37:27 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.04 on epoch=387
06/10/2022 16:37:28 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.7941925381263616 on epoch=387
06/10/2022 16:37:30 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.05 on epoch=389
06/10/2022 16:37:32 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.08 on epoch=392
06/10/2022 16:37:35 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.04 on epoch=394
06/10/2022 16:37:37 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.02 on epoch=397
06/10/2022 16:37:39 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=399
06/10/2022 16:37:40 - INFO - __main__ - Global step 1600 Train loss 0.04 Classification-F1 0.7759289729877966 on epoch=399
06/10/2022 16:37:43 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=402
06/10/2022 16:37:45 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.06 on epoch=404
06/10/2022 16:37:47 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=407
06/10/2022 16:37:50 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.02 on epoch=409
06/10/2022 16:37:52 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.07 on epoch=412
06/10/2022 16:37:53 - INFO - __main__ - Global step 1650 Train loss 0.03 Classification-F1 0.776201923076923 on epoch=412
06/10/2022 16:37:55 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=414
06/10/2022 16:37:58 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.06 on epoch=417
06/10/2022 16:38:00 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=419
06/10/2022 16:38:02 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.10 on epoch=422
06/10/2022 16:38:05 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=424
06/10/2022 16:38:06 - INFO - __main__ - Global step 1700 Train loss 0.04 Classification-F1 0.7941925381263616 on epoch=424
06/10/2022 16:38:08 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=427
06/10/2022 16:38:10 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.04 on epoch=429
06/10/2022 16:38:13 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=432
06/10/2022 16:38:15 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=434
06/10/2022 16:38:17 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=437
06/10/2022 16:38:18 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.7765287204625441 on epoch=437
06/10/2022 16:38:20 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=439
06/10/2022 16:38:23 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=442
06/10/2022 16:38:25 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=444
06/10/2022 16:38:27 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=447
06/10/2022 16:38:30 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=449
06/10/2022 16:38:31 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.7575694444444444 on epoch=449
06/10/2022 16:38:33 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.04 on epoch=452
06/10/2022 16:38:35 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.04 on epoch=454
06/10/2022 16:38:38 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=457
06/10/2022 16:38:40 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=459
06/10/2022 16:38:43 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=462
06/10/2022 16:38:43 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.7941925381263616 on epoch=462
06/10/2022 16:38:46 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.04 on epoch=464
06/10/2022 16:38:48 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=467
06/10/2022 16:38:51 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=469
06/10/2022 16:38:53 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=472
06/10/2022 16:38:55 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.04 on epoch=474
06/10/2022 16:38:56 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.7941925381263616 on epoch=474
06/10/2022 16:38:59 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=477
06/10/2022 16:39:01 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=479
06/10/2022 16:39:03 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.04 on epoch=482
06/10/2022 16:39:06 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=484
06/10/2022 16:39:08 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=487
06/10/2022 16:39:09 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.7610697546181417 on epoch=487
06/10/2022 16:39:11 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=489
06/10/2022 16:39:14 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=492
06/10/2022 16:39:16 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=494
06/10/2022 16:39:18 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=497
06/10/2022 16:39:21 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=499
06/10/2022 16:39:22 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.756969696969697 on epoch=499
06/10/2022 16:39:24 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=502
06/10/2022 16:39:26 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=504
06/10/2022 16:39:29 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/10/2022 16:39:31 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=509
06/10/2022 16:39:33 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/10/2022 16:39:34 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.771764705882353 on epoch=512
06/10/2022 16:39:36 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=514
06/10/2022 16:39:39 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.03 on epoch=517
06/10/2022 16:39:41 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=519
06/10/2022 16:39:44 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=522
06/10/2022 16:39:46 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=524
06/10/2022 16:39:47 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.7941925381263616 on epoch=524
06/10/2022 16:39:49 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=527
06/10/2022 16:39:51 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=529
06/10/2022 16:39:54 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=532
06/10/2022 16:39:56 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=534
06/10/2022 16:39:58 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=537
06/10/2022 16:39:59 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.7941925381263616 on epoch=537
06/10/2022 16:40:02 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=539
06/10/2022 16:40:04 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=542
06/10/2022 16:40:06 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/10/2022 16:40:09 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/10/2022 16:40:11 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=549
06/10/2022 16:40:12 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.7941925381263616 on epoch=549
06/10/2022 16:40:15 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/10/2022 16:40:17 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=554
06/10/2022 16:40:19 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
06/10/2022 16:40:22 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.03 on epoch=559
06/10/2022 16:40:24 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/10/2022 16:40:25 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.7941925381263616 on epoch=562
06/10/2022 16:40:27 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=564
06/10/2022 16:40:30 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=567
06/10/2022 16:40:32 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=569
06/10/2022 16:40:34 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.07 on epoch=572
06/10/2022 16:40:37 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=574
06/10/2022 16:40:38 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.7787335722819593 on epoch=574
06/10/2022 16:40:40 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/10/2022 16:40:42 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=579
06/10/2022 16:40:45 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.09 on epoch=582
06/10/2022 16:40:47 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=584
06/10/2022 16:40:49 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/10/2022 16:40:50 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.7374299719887956 on epoch=587
06/10/2022 16:40:53 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=589
06/10/2022 16:40:55 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/10/2022 16:40:58 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/10/2022 16:41:00 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.06 on epoch=597
06/10/2022 16:41:03 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.05 on epoch=599
06/10/2022 16:41:03 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.7905011655011656 on epoch=599
06/10/2022 16:41:06 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=602
06/10/2022 16:41:08 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.03 on epoch=604
06/10/2022 16:41:11 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=607
06/10/2022 16:41:13 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=609
06/10/2022 16:41:15 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.03 on epoch=612
06/10/2022 16:41:16 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.7222222222222222 on epoch=612
06/10/2022 16:41:18 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=614
06/10/2022 16:41:21 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.08 on epoch=617
06/10/2022 16:41:23 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.05 on epoch=619
06/10/2022 16:41:25 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=622
06/10/2022 16:41:28 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=624
06/10/2022 16:41:29 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.7941925381263616 on epoch=624
06/10/2022 16:41:31 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/10/2022 16:41:33 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=629
06/10/2022 16:41:36 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=632
06/10/2022 16:41:38 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/10/2022 16:41:41 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/10/2022 16:41:42 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.7787335722819593 on epoch=637
06/10/2022 16:41:44 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/10/2022 16:41:46 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=642
06/10/2022 16:41:49 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=644
06/10/2022 16:41:51 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=647
06/10/2022 16:41:54 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.06 on epoch=649
06/10/2022 16:41:55 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.7759289729877966 on epoch=649
06/10/2022 16:41:57 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=652
06/10/2022 16:41:59 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/10/2022 16:42:02 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=657
06/10/2022 16:42:04 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/10/2022 16:42:06 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/10/2022 16:42:07 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.7759289729877966 on epoch=662
06/10/2022 16:42:10 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/10/2022 16:42:12 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/10/2022 16:42:14 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=669
06/10/2022 16:42:17 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=672
06/10/2022 16:42:19 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=674
06/10/2022 16:42:20 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.760576923076923 on epoch=674
06/10/2022 16:42:22 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=677
06/10/2022 16:42:25 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/10/2022 16:42:27 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/10/2022 16:42:29 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=684
06/10/2022 16:42:32 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=687
06/10/2022 16:42:33 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.7015684162423292 on epoch=687
06/10/2022 16:42:35 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/10/2022 16:42:37 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.13 on epoch=692
06/10/2022 16:42:40 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/10/2022 16:42:42 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=697
06/10/2022 16:42:45 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=699
06/10/2022 16:42:46 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.757296494355318 on epoch=699
06/10/2022 16:42:48 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/10/2022 16:42:50 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=704
06/10/2022 16:42:53 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.06 on epoch=707
06/10/2022 16:42:55 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/10/2022 16:42:57 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=712
06/10/2022 16:42:58 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.7419444444444444 on epoch=712
06/10/2022 16:43:01 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=714
06/10/2022 16:43:03 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=717
06/10/2022 16:43:05 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/10/2022 16:43:08 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=722
06/10/2022 16:43:10 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=724
06/10/2022 16:43:11 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.7941925381263616 on epoch=724
06/10/2022 16:43:13 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/10/2022 16:43:16 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/10/2022 16:43:18 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=732
06/10/2022 16:43:21 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=734
06/10/2022 16:43:23 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=737
06/10/2022 16:43:24 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.7941925381263616 on epoch=737
06/10/2022 16:43:26 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/10/2022 16:43:29 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/10/2022 16:43:31 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/10/2022 16:43:33 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/10/2022 16:43:36 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=749
06/10/2022 16:43:37 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.7941925381263616 on epoch=749
06/10/2022 16:43:37 - INFO - __main__ - save last model!
06/10/2022 16:43:37 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/10/2022 16:43:37 - INFO - __main__ - Start tokenizing ... 5509 instances
06/10/2022 16:43:37 - INFO - __main__ - Printing 3 examples
06/10/2022 16:43:37 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/10/2022 16:43:37 - INFO - __main__ - ['others']
06/10/2022 16:43:37 - INFO - __main__ -  [emo] what you like very little things ok
06/10/2022 16:43:37 - INFO - __main__ - ['others']
06/10/2022 16:43:37 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/10/2022 16:43:37 - INFO - __main__ - ['others']
06/10/2022 16:43:37 - INFO - __main__ - Tokenizing Input ...
06/10/2022 16:43:37 - INFO - __main__ - Start tokenizing ... 64 instances
06/10/2022 16:43:37 - INFO - __main__ - Printing 3 examples
06/10/2022 16:43:37 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/10/2022 16:43:37 - INFO - __main__ - ['others']
06/10/2022 16:43:37 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/10/2022 16:43:37 - INFO - __main__ - ['others']
06/10/2022 16:43:37 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/10/2022 16:43:37 - INFO - __main__ - ['others']
06/10/2022 16:43:37 - INFO - __main__ - Tokenizing Input ...
06/10/2022 16:43:37 - INFO - __main__ - Tokenizing Output ...
06/10/2022 16:43:37 - INFO - __main__ - Loaded 64 examples from train data
06/10/2022 16:43:37 - INFO - __main__ - Start tokenizing ... 64 instances
06/10/2022 16:43:37 - INFO - __main__ - Printing 3 examples
06/10/2022 16:43:37 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
06/10/2022 16:43:37 - INFO - __main__ - ['others']
06/10/2022 16:43:37 - INFO - __main__ -  [emo] i did ask now you did tell ms
06/10/2022 16:43:37 - INFO - __main__ - ['others']
06/10/2022 16:43:37 - INFO - __main__ -  [emo] buddy how you tell me your contact no
06/10/2022 16:43:37 - INFO - __main__ - ['others']
06/10/2022 16:43:37 - INFO - __main__ - Tokenizing Input ...
06/10/2022 16:43:37 - INFO - __main__ - Tokenizing Output ...
06/10/2022 16:43:37 - INFO - __main__ - Loaded 64 examples from dev data
06/10/2022 16:43:39 - INFO - __main__ - Tokenizing Output ...
06/10/2022 16:43:44 - INFO - __main__ - Loaded 5509 examples from test data
06/10/2022 16:43:53 - INFO - __main__ - load prompt embedding from ckpt
06/10/2022 16:43:53 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/10/2022 16:43:53 - INFO - __main__ - Starting training!
06/10/2022 16:45:10 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-up32shot/singletask-emo/emo_16_13_0.3_8_predictions.txt
06/10/2022 16:45:10 - INFO - __main__ - Classification-F1 on test data: 0.2157
06/10/2022 16:45:10 - INFO - __main__ - prefix=emo_16_13, lr=0.3, bsz=8, dev_performance=0.7951894019256448, test_performance=0.21572442386057786
06/10/2022 16:45:10 - INFO - __main__ - Running ... prefix=emo_16_13, lr=0.2, bsz=8 ...
06/10/2022 16:45:11 - INFO - __main__ - Start tokenizing ... 64 instances
06/10/2022 16:45:11 - INFO - __main__ - Printing 3 examples
06/10/2022 16:45:11 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/10/2022 16:45:11 - INFO - __main__ - ['others']
06/10/2022 16:45:11 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/10/2022 16:45:11 - INFO - __main__ - ['others']
06/10/2022 16:45:11 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/10/2022 16:45:11 - INFO - __main__ - ['others']
06/10/2022 16:45:11 - INFO - __main__ - Tokenizing Input ...
06/10/2022 16:45:11 - INFO - __main__ - Tokenizing Output ...
06/10/2022 16:45:11 - INFO - __main__ - Loaded 64 examples from train data
06/10/2022 16:45:11 - INFO - __main__ - Start tokenizing ... 64 instances
06/10/2022 16:45:11 - INFO - __main__ - Printing 3 examples
06/10/2022 16:45:11 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
06/10/2022 16:45:11 - INFO - __main__ - ['others']
06/10/2022 16:45:11 - INFO - __main__ -  [emo] i did ask now you did tell ms
06/10/2022 16:45:11 - INFO - __main__ - ['others']
06/10/2022 16:45:11 - INFO - __main__ -  [emo] buddy how you tell me your contact no
06/10/2022 16:45:11 - INFO - __main__ - ['others']
06/10/2022 16:45:11 - INFO - __main__ - Tokenizing Input ...
06/10/2022 16:45:11 - INFO - __main__ - Tokenizing Output ...
06/10/2022 16:45:11 - INFO - __main__ - Loaded 64 examples from dev data
06/10/2022 16:45:26 - INFO - __main__ - load prompt embedding from ckpt
06/10/2022 16:45:27 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/10/2022 16:45:27 - INFO - __main__ - Starting training!
06/10/2022 16:45:30 - INFO - __main__ - Step 10 Global step 10 Train loss 3.86 on epoch=2
06/10/2022 16:45:32 - INFO - __main__ - Step 20 Global step 20 Train loss 3.19 on epoch=4
06/10/2022 16:45:35 - INFO - __main__ - Step 30 Global step 30 Train loss 2.57 on epoch=7
06/10/2022 16:45:37 - INFO - __main__ - Step 40 Global step 40 Train loss 2.29 on epoch=9
06/10/2022 16:45:39 - INFO - __main__ - Step 50 Global step 50 Train loss 2.10 on epoch=12
06/10/2022 16:45:40 - INFO - __main__ - Global step 50 Train loss 2.80 Classification-F1 0.043867243867243874 on epoch=12
06/10/2022 16:45:41 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.043867243867243874 on epoch=12, global_step=50
06/10/2022 16:45:43 - INFO - __main__ - Step 60 Global step 60 Train loss 1.84 on epoch=14
06/10/2022 16:45:45 - INFO - __main__ - Step 70 Global step 70 Train loss 1.65 on epoch=17
06/10/2022 16:45:48 - INFO - __main__ - Step 80 Global step 80 Train loss 1.41 on epoch=19
06/10/2022 16:45:50 - INFO - __main__ - Step 90 Global step 90 Train loss 1.25 on epoch=22
06/10/2022 16:45:52 - INFO - __main__ - Step 100 Global step 100 Train loss 1.00 on epoch=24
06/10/2022 16:45:53 - INFO - __main__ - Global step 100 Train loss 1.43 Classification-F1 0.21046905222437134 on epoch=24
06/10/2022 16:45:53 - INFO - __main__ - Saving model with best Classification-F1: 0.043867243867243874 -> 0.21046905222437134 on epoch=24, global_step=100
06/10/2022 16:45:56 - INFO - __main__ - Step 110 Global step 110 Train loss 1.00 on epoch=27
06/10/2022 16:45:58 - INFO - __main__ - Step 120 Global step 120 Train loss 0.90 on epoch=29
06/10/2022 16:46:00 - INFO - __main__ - Step 130 Global step 130 Train loss 0.79 on epoch=32
06/10/2022 16:46:03 - INFO - __main__ - Step 140 Global step 140 Train loss 0.79 on epoch=34
06/10/2022 16:46:05 - INFO - __main__ - Step 150 Global step 150 Train loss 0.75 on epoch=37
06/10/2022 16:46:06 - INFO - __main__ - Global step 150 Train loss 0.85 Classification-F1 0.425081518194861 on epoch=37
06/10/2022 16:46:06 - INFO - __main__ - Saving model with best Classification-F1: 0.21046905222437134 -> 0.425081518194861 on epoch=37, global_step=150
06/10/2022 16:46:08 - INFO - __main__ - Step 160 Global step 160 Train loss 0.73 on epoch=39
06/10/2022 16:46:11 - INFO - __main__ - Step 170 Global step 170 Train loss 0.67 on epoch=42
06/10/2022 16:46:13 - INFO - __main__ - Step 180 Global step 180 Train loss 0.63 on epoch=44
06/10/2022 16:46:15 - INFO - __main__ - Step 190 Global step 190 Train loss 0.68 on epoch=47
06/10/2022 16:46:18 - INFO - __main__ - Step 200 Global step 200 Train loss 0.66 on epoch=49
06/10/2022 16:46:19 - INFO - __main__ - Global step 200 Train loss 0.67 Classification-F1 0.5102480016396802 on epoch=49
06/10/2022 16:46:19 - INFO - __main__ - Saving model with best Classification-F1: 0.425081518194861 -> 0.5102480016396802 on epoch=49, global_step=200
06/10/2022 16:46:21 - INFO - __main__ - Step 210 Global step 210 Train loss 0.60 on epoch=52
06/10/2022 16:46:23 - INFO - __main__ - Step 220 Global step 220 Train loss 0.61 on epoch=54
06/10/2022 16:46:26 - INFO - __main__ - Step 230 Global step 230 Train loss 0.53 on epoch=57
06/10/2022 16:46:28 - INFO - __main__ - Step 240 Global step 240 Train loss 0.59 on epoch=59
06/10/2022 16:46:30 - INFO - __main__ - Step 250 Global step 250 Train loss 0.51 on epoch=62
06/10/2022 16:46:31 - INFO - __main__ - Global step 250 Train loss 0.57 Classification-F1 0.5809633704370546 on epoch=62
06/10/2022 16:46:31 - INFO - __main__ - Saving model with best Classification-F1: 0.5102480016396802 -> 0.5809633704370546 on epoch=62, global_step=250
06/10/2022 16:46:34 - INFO - __main__ - Step 260 Global step 260 Train loss 0.54 on epoch=64
06/10/2022 16:46:36 - INFO - __main__ - Step 270 Global step 270 Train loss 0.53 on epoch=67
06/10/2022 16:46:38 - INFO - __main__ - Step 280 Global step 280 Train loss 0.56 on epoch=69
06/10/2022 16:46:41 - INFO - __main__ - Step 290 Global step 290 Train loss 0.62 on epoch=72
06/10/2022 16:46:43 - INFO - __main__ - Step 300 Global step 300 Train loss 0.47 on epoch=74
06/10/2022 16:46:44 - INFO - __main__ - Global step 300 Train loss 0.54 Classification-F1 0.6102769177846578 on epoch=74
06/10/2022 16:46:44 - INFO - __main__ - Saving model with best Classification-F1: 0.5809633704370546 -> 0.6102769177846578 on epoch=74, global_step=300
06/10/2022 16:46:46 - INFO - __main__ - Step 310 Global step 310 Train loss 0.47 on epoch=77
06/10/2022 16:46:49 - INFO - __main__ - Step 320 Global step 320 Train loss 0.51 on epoch=79
06/10/2022 16:46:51 - INFO - __main__ - Step 330 Global step 330 Train loss 0.55 on epoch=82
06/10/2022 16:46:53 - INFO - __main__ - Step 340 Global step 340 Train loss 0.57 on epoch=84
06/10/2022 16:46:56 - INFO - __main__ - Step 350 Global step 350 Train loss 0.46 on epoch=87
06/10/2022 16:46:57 - INFO - __main__ - Global step 350 Train loss 0.51 Classification-F1 0.6713629507747154 on epoch=87
06/10/2022 16:46:57 - INFO - __main__ - Saving model with best Classification-F1: 0.6102769177846578 -> 0.6713629507747154 on epoch=87, global_step=350
06/10/2022 16:46:59 - INFO - __main__ - Step 360 Global step 360 Train loss 0.44 on epoch=89
06/10/2022 16:47:01 - INFO - __main__ - Step 370 Global step 370 Train loss 0.53 on epoch=92
06/10/2022 16:47:04 - INFO - __main__ - Step 380 Global step 380 Train loss 0.41 on epoch=94
06/10/2022 16:47:06 - INFO - __main__ - Step 390 Global step 390 Train loss 0.40 on epoch=97
06/10/2022 16:47:08 - INFO - __main__ - Step 400 Global step 400 Train loss 0.48 on epoch=99
06/10/2022 16:47:09 - INFO - __main__ - Global step 400 Train loss 0.45 Classification-F1 0.6874057315233786 on epoch=99
06/10/2022 16:47:09 - INFO - __main__ - Saving model with best Classification-F1: 0.6713629507747154 -> 0.6874057315233786 on epoch=99, global_step=400
06/10/2022 16:47:12 - INFO - __main__ - Step 410 Global step 410 Train loss 0.40 on epoch=102
06/10/2022 16:47:14 - INFO - __main__ - Step 420 Global step 420 Train loss 0.35 on epoch=104
06/10/2022 16:47:16 - INFO - __main__ - Step 430 Global step 430 Train loss 0.47 on epoch=107
06/10/2022 16:47:19 - INFO - __main__ - Step 440 Global step 440 Train loss 0.51 on epoch=109
06/10/2022 16:47:21 - INFO - __main__ - Step 450 Global step 450 Train loss 0.44 on epoch=112
06/10/2022 16:47:22 - INFO - __main__ - Global step 450 Train loss 0.43 Classification-F1 0.6874057315233786 on epoch=112
06/10/2022 16:47:24 - INFO - __main__ - Step 460 Global step 460 Train loss 0.39 on epoch=114
06/10/2022 16:47:27 - INFO - __main__ - Step 470 Global step 470 Train loss 0.36 on epoch=117
06/10/2022 16:47:29 - INFO - __main__ - Step 480 Global step 480 Train loss 0.42 on epoch=119
06/10/2022 16:47:31 - INFO - __main__ - Step 490 Global step 490 Train loss 0.41 on epoch=122
06/10/2022 16:47:34 - INFO - __main__ - Step 500 Global step 500 Train loss 0.35 on epoch=124
06/10/2022 16:47:35 - INFO - __main__ - Global step 500 Train loss 0.39 Classification-F1 0.673515339150014 on epoch=124
06/10/2022 16:47:37 - INFO - __main__ - Step 510 Global step 510 Train loss 0.40 on epoch=127
06/10/2022 16:47:39 - INFO - __main__ - Step 520 Global step 520 Train loss 0.37 on epoch=129
06/10/2022 16:47:42 - INFO - __main__ - Step 530 Global step 530 Train loss 0.33 on epoch=132
06/10/2022 16:47:44 - INFO - __main__ - Step 540 Global step 540 Train loss 0.29 on epoch=134
06/10/2022 16:47:46 - INFO - __main__ - Step 550 Global step 550 Train loss 0.35 on epoch=137
06/10/2022 16:47:47 - INFO - __main__ - Global step 550 Train loss 0.35 Classification-F1 0.7309200603318251 on epoch=137
06/10/2022 16:47:47 - INFO - __main__ - Saving model with best Classification-F1: 0.6874057315233786 -> 0.7309200603318251 on epoch=137, global_step=550
06/10/2022 16:47:50 - INFO - __main__ - Step 560 Global step 560 Train loss 0.27 on epoch=139
06/10/2022 16:47:52 - INFO - __main__ - Step 570 Global step 570 Train loss 0.36 on epoch=142
06/10/2022 16:47:55 - INFO - __main__ - Step 580 Global step 580 Train loss 0.37 on epoch=144
06/10/2022 16:47:57 - INFO - __main__ - Step 590 Global step 590 Train loss 0.38 on epoch=147
06/10/2022 16:47:59 - INFO - __main__ - Step 600 Global step 600 Train loss 0.28 on epoch=149
06/10/2022 16:48:00 - INFO - __main__ - Global step 600 Train loss 0.33 Classification-F1 0.7767947738535975 on epoch=149
06/10/2022 16:48:00 - INFO - __main__ - Saving model with best Classification-F1: 0.7309200603318251 -> 0.7767947738535975 on epoch=149, global_step=600
06/10/2022 16:48:03 - INFO - __main__ - Step 610 Global step 610 Train loss 0.37 on epoch=152
06/10/2022 16:48:05 - INFO - __main__ - Step 620 Global step 620 Train loss 0.37 on epoch=154
06/10/2022 16:48:07 - INFO - __main__ - Step 630 Global step 630 Train loss 0.35 on epoch=157
06/10/2022 16:48:10 - INFO - __main__ - Step 640 Global step 640 Train loss 0.42 on epoch=159
06/10/2022 16:48:12 - INFO - __main__ - Step 650 Global step 650 Train loss 0.34 on epoch=162
06/10/2022 16:48:13 - INFO - __main__ - Global step 650 Train loss 0.37 Classification-F1 0.7958994708994709 on epoch=162
06/10/2022 16:48:13 - INFO - __main__ - Saving model with best Classification-F1: 0.7767947738535975 -> 0.7958994708994709 on epoch=162, global_step=650
06/10/2022 16:48:15 - INFO - __main__ - Step 660 Global step 660 Train loss 0.28 on epoch=164
06/10/2022 16:48:18 - INFO - __main__ - Step 670 Global step 670 Train loss 0.27 on epoch=167
06/10/2022 16:48:20 - INFO - __main__ - Step 680 Global step 680 Train loss 0.34 on epoch=169
06/10/2022 16:48:22 - INFO - __main__ - Step 690 Global step 690 Train loss 0.26 on epoch=172
06/10/2022 16:48:25 - INFO - __main__ - Step 700 Global step 700 Train loss 0.31 on epoch=174
06/10/2022 16:48:26 - INFO - __main__ - Global step 700 Train loss 0.29 Classification-F1 0.776801961479381 on epoch=174
06/10/2022 16:48:28 - INFO - __main__ - Step 710 Global step 710 Train loss 0.31 on epoch=177
06/10/2022 16:48:30 - INFO - __main__ - Step 720 Global step 720 Train loss 0.24 on epoch=179
06/10/2022 16:48:33 - INFO - __main__ - Step 730 Global step 730 Train loss 0.30 on epoch=182
06/10/2022 16:48:35 - INFO - __main__ - Step 740 Global step 740 Train loss 0.32 on epoch=184
06/10/2022 16:48:37 - INFO - __main__ - Step 750 Global step 750 Train loss 0.20 on epoch=187
06/10/2022 16:48:38 - INFO - __main__ - Global step 750 Train loss 0.27 Classification-F1 0.8105820105820105 on epoch=187
06/10/2022 16:48:38 - INFO - __main__ - Saving model with best Classification-F1: 0.7958994708994709 -> 0.8105820105820105 on epoch=187, global_step=750
06/10/2022 16:48:41 - INFO - __main__ - Step 760 Global step 760 Train loss 0.29 on epoch=189
06/10/2022 16:48:43 - INFO - __main__ - Step 770 Global step 770 Train loss 0.25 on epoch=192
06/10/2022 16:48:45 - INFO - __main__ - Step 780 Global step 780 Train loss 0.26 on epoch=194
06/10/2022 16:48:48 - INFO - __main__ - Step 790 Global step 790 Train loss 0.25 on epoch=197
06/10/2022 16:48:50 - INFO - __main__ - Step 800 Global step 800 Train loss 0.23 on epoch=199
06/10/2022 16:48:51 - INFO - __main__ - Global step 800 Train loss 0.26 Classification-F1 0.7914845011619206 on epoch=199
06/10/2022 16:48:53 - INFO - __main__ - Step 810 Global step 810 Train loss 0.20 on epoch=202
06/10/2022 16:48:56 - INFO - __main__ - Step 820 Global step 820 Train loss 0.31 on epoch=204
06/10/2022 16:48:58 - INFO - __main__ - Step 830 Global step 830 Train loss 0.25 on epoch=207
06/10/2022 16:49:00 - INFO - __main__ - Step 840 Global step 840 Train loss 0.25 on epoch=209
06/10/2022 16:49:03 - INFO - __main__ - Step 850 Global step 850 Train loss 0.25 on epoch=212
06/10/2022 16:49:04 - INFO - __main__ - Global step 850 Train loss 0.25 Classification-F1 0.7910258379008379 on epoch=212
06/10/2022 16:49:06 - INFO - __main__ - Step 860 Global step 860 Train loss 0.21 on epoch=214
06/10/2022 16:49:09 - INFO - __main__ - Step 870 Global step 870 Train loss 0.21 on epoch=217
06/10/2022 16:49:11 - INFO - __main__ - Step 880 Global step 880 Train loss 0.20 on epoch=219
06/10/2022 16:49:13 - INFO - __main__ - Step 890 Global step 890 Train loss 0.21 on epoch=222
06/10/2022 16:49:16 - INFO - __main__ - Step 900 Global step 900 Train loss 0.19 on epoch=224
06/10/2022 16:49:17 - INFO - __main__ - Global step 900 Train loss 0.20 Classification-F1 0.8251427898486722 on epoch=224
06/10/2022 16:49:17 - INFO - __main__ - Saving model with best Classification-F1: 0.8105820105820105 -> 0.8251427898486722 on epoch=224, global_step=900
06/10/2022 16:49:19 - INFO - __main__ - Step 910 Global step 910 Train loss 0.20 on epoch=227
06/10/2022 16:49:21 - INFO - __main__ - Step 920 Global step 920 Train loss 0.20 on epoch=229
06/10/2022 16:49:24 - INFO - __main__ - Step 930 Global step 930 Train loss 0.22 on epoch=232
06/10/2022 16:49:26 - INFO - __main__ - Step 940 Global step 940 Train loss 0.21 on epoch=234
06/10/2022 16:49:28 - INFO - __main__ - Step 950 Global step 950 Train loss 0.15 on epoch=237
06/10/2022 16:49:29 - INFO - __main__ - Global step 950 Train loss 0.20 Classification-F1 0.8090701538977401 on epoch=237
06/10/2022 16:49:31 - INFO - __main__ - Step 960 Global step 960 Train loss 0.18 on epoch=239
06/10/2022 16:49:34 - INFO - __main__ - Step 970 Global step 970 Train loss 0.17 on epoch=242
06/10/2022 16:49:36 - INFO - __main__ - Step 980 Global step 980 Train loss 0.18 on epoch=244
06/10/2022 16:49:38 - INFO - __main__ - Step 990 Global step 990 Train loss 0.19 on epoch=247
06/10/2022 16:49:41 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.21 on epoch=249
06/10/2022 16:49:42 - INFO - __main__ - Global step 1000 Train loss 0.19 Classification-F1 0.7763276970707312 on epoch=249
06/10/2022 16:49:44 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.25 on epoch=252
06/10/2022 16:49:46 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.18 on epoch=254
06/10/2022 16:49:49 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.27 on epoch=257
06/10/2022 16:49:51 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.14 on epoch=259
06/10/2022 16:49:53 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.15 on epoch=262
06/10/2022 16:49:54 - INFO - __main__ - Global step 1050 Train loss 0.20 Classification-F1 0.8096865193639388 on epoch=262
06/10/2022 16:49:57 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.16 on epoch=264
06/10/2022 16:49:59 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.12 on epoch=267
06/10/2022 16:50:02 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.21 on epoch=269
06/10/2022 16:50:04 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.17 on epoch=272
06/10/2022 16:50:06 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.17 on epoch=274
06/10/2022 16:50:07 - INFO - __main__ - Global step 1100 Train loss 0.17 Classification-F1 0.7922439756056054 on epoch=274
06/10/2022 16:50:10 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.16 on epoch=277
06/10/2022 16:50:12 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.22 on epoch=279
06/10/2022 16:50:14 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.10 on epoch=282
06/10/2022 16:50:17 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.13 on epoch=284
06/10/2022 16:50:19 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.12 on epoch=287
06/10/2022 16:50:20 - INFO - __main__ - Global step 1150 Train loss 0.15 Classification-F1 0.7922439756056054 on epoch=287
06/10/2022 16:50:23 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.13 on epoch=289
06/10/2022 16:50:25 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.13 on epoch=292
06/10/2022 16:50:28 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.11 on epoch=294
06/10/2022 16:50:30 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.12 on epoch=297
06/10/2022 16:50:32 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.12 on epoch=299
06/10/2022 16:50:33 - INFO - __main__ - Global step 1200 Train loss 0.12 Classification-F1 0.7763276970707312 on epoch=299
06/10/2022 16:50:36 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.13 on epoch=302
06/10/2022 16:50:38 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.08 on epoch=304
06/10/2022 16:50:41 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.13 on epoch=307
06/10/2022 16:50:43 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.15 on epoch=309
06/10/2022 16:50:45 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.13 on epoch=312
06/10/2022 16:50:46 - INFO - __main__ - Global step 1250 Train loss 0.12 Classification-F1 0.7601005165433476 on epoch=312
06/10/2022 16:50:49 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.11 on epoch=314
06/10/2022 16:50:51 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.08 on epoch=317
06/10/2022 16:50:54 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.11 on epoch=319
06/10/2022 16:50:56 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.16 on epoch=322
06/10/2022 16:50:58 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.13 on epoch=324
06/10/2022 16:50:59 - INFO - __main__ - Global step 1300 Train loss 0.12 Classification-F1 0.7937702408290643 on epoch=324
06/10/2022 16:51:02 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.13 on epoch=327
06/10/2022 16:51:04 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.08 on epoch=329
06/10/2022 16:51:06 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.11 on epoch=332
06/10/2022 16:51:09 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.11 on epoch=334
06/10/2022 16:51:11 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.14 on epoch=337
06/10/2022 16:51:12 - INFO - __main__ - Global step 1350 Train loss 0.11 Classification-F1 0.7910258379008379 on epoch=337
06/10/2022 16:51:14 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.06 on epoch=339
06/10/2022 16:51:17 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.08 on epoch=342
06/10/2022 16:51:19 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.08 on epoch=344
06/10/2022 16:51:21 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.15 on epoch=347
06/10/2022 16:51:24 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.06 on epoch=349
06/10/2022 16:51:25 - INFO - __main__ - Global step 1400 Train loss 0.09 Classification-F1 0.7225225225225225 on epoch=349
06/10/2022 16:51:27 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.08 on epoch=352
06/10/2022 16:51:29 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.08 on epoch=354
06/10/2022 16:51:32 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.04 on epoch=357
06/10/2022 16:51:34 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.10 on epoch=359
06/10/2022 16:51:36 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.07 on epoch=362
06/10/2022 16:51:37 - INFO - __main__ - Global step 1450 Train loss 0.07 Classification-F1 0.8096865193639388 on epoch=362
06/10/2022 16:51:40 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.06 on epoch=364
06/10/2022 16:51:42 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.09 on epoch=367
06/10/2022 16:51:44 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.07 on epoch=369
06/10/2022 16:51:47 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.03 on epoch=372
06/10/2022 16:51:49 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.10 on epoch=374
06/10/2022 16:51:50 - INFO - __main__ - Global step 1500 Train loss 0.07 Classification-F1 0.8096865193639388 on epoch=374
06/10/2022 16:51:52 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.07 on epoch=377
06/10/2022 16:51:55 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.06 on epoch=379
06/10/2022 16:51:57 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.14 on epoch=382
06/10/2022 16:51:59 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.05 on epoch=384
06/10/2022 16:52:02 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.03 on epoch=387
06/10/2022 16:52:03 - INFO - __main__ - Global step 1550 Train loss 0.07 Classification-F1 0.7610697546181417 on epoch=387
06/10/2022 16:52:05 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.06 on epoch=389
06/10/2022 16:52:07 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.14 on epoch=392
06/10/2022 16:52:10 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.05 on epoch=394
06/10/2022 16:52:12 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.07 on epoch=397
06/10/2022 16:52:14 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.09 on epoch=399
06/10/2022 16:52:15 - INFO - __main__ - Global step 1600 Train loss 0.08 Classification-F1 0.7419444444444444 on epoch=399
06/10/2022 16:52:18 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=402
06/10/2022 16:52:20 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.08 on epoch=404
06/10/2022 16:52:22 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.07 on epoch=407
06/10/2022 16:52:25 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.03 on epoch=409
06/10/2022 16:52:27 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.10 on epoch=412
06/10/2022 16:52:28 - INFO - __main__ - Global step 1650 Train loss 0.06 Classification-F1 0.7964285714285714 on epoch=412
06/10/2022 16:52:30 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.03 on epoch=414
06/10/2022 16:52:33 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.05 on epoch=417
06/10/2022 16:52:35 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.04 on epoch=419
06/10/2022 16:52:37 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.10 on epoch=422
06/10/2022 16:52:40 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.04 on epoch=424
06/10/2022 16:52:41 - INFO - __main__ - Global step 1700 Train loss 0.05 Classification-F1 0.757296494355318 on epoch=424
06/10/2022 16:52:43 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.04 on epoch=427
06/10/2022 16:52:45 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.08 on epoch=429
06/10/2022 16:52:48 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=432
06/10/2022 16:52:50 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.06 on epoch=434
06/10/2022 16:52:53 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.08 on epoch=437
06/10/2022 16:52:53 - INFO - __main__ - Global step 1750 Train loss 0.05 Classification-F1 0.7610697546181417 on epoch=437
06/10/2022 16:52:56 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.04 on epoch=439
06/10/2022 16:52:58 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=442
06/10/2022 16:53:00 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.04 on epoch=444
06/10/2022 16:53:03 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.05 on epoch=447
06/10/2022 16:53:05 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=449
06/10/2022 16:53:06 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.7419444444444444 on epoch=449
06/10/2022 16:53:09 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.07 on epoch=452
06/10/2022 16:53:11 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.05 on epoch=454
06/10/2022 16:53:13 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=457
06/10/2022 16:53:16 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=459
06/10/2022 16:53:18 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=462
06/10/2022 16:53:19 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.7951894019256448 on epoch=462
06/10/2022 16:53:21 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=464
06/10/2022 16:53:24 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.03 on epoch=467
06/10/2022 16:53:26 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.04 on epoch=469
06/10/2022 16:53:28 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.03 on epoch=472
06/10/2022 16:53:31 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=474
06/10/2022 16:53:32 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.7587884436160298 on epoch=474
06/10/2022 16:53:34 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=477
06/10/2022 16:53:36 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.05 on epoch=479
06/10/2022 16:53:39 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=482
06/10/2022 16:53:41 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.06 on epoch=484
06/10/2022 16:53:43 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=487
06/10/2022 16:53:44 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.7419444444444444 on epoch=487
06/10/2022 16:53:47 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.05 on epoch=489
06/10/2022 16:53:49 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.08 on epoch=492
06/10/2022 16:53:51 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.04 on epoch=494
06/10/2022 16:53:54 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.05 on epoch=497
06/10/2022 16:53:56 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.03 on epoch=499
06/10/2022 16:53:57 - INFO - __main__ - Global step 2000 Train loss 0.05 Classification-F1 0.7610697546181417 on epoch=499
06/10/2022 16:53:59 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.03 on epoch=502
06/10/2022 16:54:02 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=504
06/10/2022 16:54:04 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.03 on epoch=507
06/10/2022 16:54:06 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.06 on epoch=509
06/10/2022 16:54:09 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.04 on epoch=512
06/10/2022 16:54:10 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.7610697546181417 on epoch=512
06/10/2022 16:54:12 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.12 on epoch=514
06/10/2022 16:54:14 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.07 on epoch=517
06/10/2022 16:54:17 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.15 on epoch=519
06/10/2022 16:54:19 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.04 on epoch=522
06/10/2022 16:54:22 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=524
06/10/2022 16:54:22 - INFO - __main__ - Global step 2100 Train loss 0.08 Classification-F1 0.7369042429526301 on epoch=524
06/10/2022 16:54:25 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=527
06/10/2022 16:54:27 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=529
06/10/2022 16:54:30 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=532
06/10/2022 16:54:32 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.07 on epoch=534
06/10/2022 16:54:34 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=537
06/10/2022 16:54:35 - INFO - __main__ - Global step 2150 Train loss 0.03 Classification-F1 0.7575225225225225 on epoch=537
06/10/2022 16:54:38 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=539
06/10/2022 16:54:40 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.06 on epoch=542
06/10/2022 16:54:42 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.07 on epoch=544
06/10/2022 16:54:45 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.05 on epoch=547
06/10/2022 16:54:47 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=549
06/10/2022 16:54:48 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.7369042429526301 on epoch=549
06/10/2022 16:54:50 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=552
06/10/2022 16:54:53 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=554
06/10/2022 16:54:55 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.10 on epoch=557
06/10/2022 16:54:57 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.03 on epoch=559
06/10/2022 16:55:00 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.05 on epoch=562
06/10/2022 16:55:01 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.7787335722819593 on epoch=562
06/10/2022 16:55:03 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=564
06/10/2022 16:55:05 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=567
06/10/2022 16:55:08 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.06 on epoch=569
06/10/2022 16:55:10 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.04 on epoch=572
06/10/2022 16:55:13 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.04 on epoch=574
06/10/2022 16:55:13 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.7575225225225225 on epoch=574
06/10/2022 16:55:16 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=577
06/10/2022 16:55:18 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=579
06/10/2022 16:55:21 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=582
06/10/2022 16:55:23 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=584
06/10/2022 16:55:25 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.04 on epoch=587
06/10/2022 16:55:26 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.737874572433396 on epoch=587
06/10/2022 16:55:28 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=589
06/10/2022 16:55:31 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=592
06/10/2022 16:55:33 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.03 on epoch=594
06/10/2022 16:55:35 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=597
06/10/2022 16:55:38 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=599
06/10/2022 16:55:39 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.7951894019256448 on epoch=599
06/10/2022 16:55:41 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.06 on epoch=602
06/10/2022 16:55:43 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.03 on epoch=604
06/10/2022 16:55:46 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=607
06/10/2022 16:55:48 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=609
06/10/2022 16:55:51 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=612
06/10/2022 16:55:52 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.7778258845621274 on epoch=612
06/10/2022 16:55:54 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=614
06/10/2022 16:55:56 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=617
06/10/2022 16:55:59 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=619
06/10/2022 16:56:01 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=622
06/10/2022 16:56:03 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=624
06/10/2022 16:56:04 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.7765287204625441 on epoch=624
06/10/2022 16:56:07 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.03 on epoch=627
06/10/2022 16:56:09 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.03 on epoch=629
06/10/2022 16:56:11 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=632
06/10/2022 16:56:14 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.05 on epoch=634
06/10/2022 16:56:16 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=637
06/10/2022 16:56:17 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.7765287204625441 on epoch=637
06/10/2022 16:56:19 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=639
06/10/2022 16:56:22 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=642
06/10/2022 16:56:24 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.08 on epoch=644
06/10/2022 16:56:26 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=647
06/10/2022 16:56:29 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.04 on epoch=649
06/10/2022 16:56:30 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.737874572433396 on epoch=649
06/10/2022 16:56:32 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.12 on epoch=652
06/10/2022 16:56:35 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=654
06/10/2022 16:56:37 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.03 on epoch=657
06/10/2022 16:56:39 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=659
06/10/2022 16:56:42 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=662
06/10/2022 16:56:43 - INFO - __main__ - Global step 2650 Train loss 0.04 Classification-F1 0.7419444444444444 on epoch=662
06/10/2022 16:56:45 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=664
06/10/2022 16:56:47 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=667
06/10/2022 16:56:50 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.05 on epoch=669
06/10/2022 16:56:52 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=672
06/10/2022 16:56:54 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=674
06/10/2022 16:56:55 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.7610697546181417 on epoch=674
06/10/2022 16:56:58 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.03 on epoch=677
06/10/2022 16:57:00 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=679
06/10/2022 16:57:02 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=682
06/10/2022 16:57:05 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=684
06/10/2022 16:57:07 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=687
06/10/2022 16:57:08 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.7610697546181417 on epoch=687
06/10/2022 16:57:10 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=689
06/10/2022 16:57:13 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=692
06/10/2022 16:57:15 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=694
06/10/2022 16:57:18 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=697
06/10/2022 16:57:20 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=699
06/10/2022 16:57:21 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.7419444444444444 on epoch=699
06/10/2022 16:57:23 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=702
06/10/2022 16:57:26 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=704
06/10/2022 16:57:28 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.08 on epoch=707
06/10/2022 16:57:30 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=709
06/10/2022 16:57:33 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=712
06/10/2022 16:57:34 - INFO - __main__ - Global step 2850 Train loss 0.03 Classification-F1 0.7964285714285714 on epoch=712
06/10/2022 16:57:36 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.03 on epoch=714
06/10/2022 16:57:38 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.04 on epoch=717
06/10/2022 16:57:41 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/10/2022 16:57:43 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=722
06/10/2022 16:57:45 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=724
06/10/2022 16:57:46 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.7787335722819593 on epoch=724
06/10/2022 16:57:49 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=727
06/10/2022 16:57:51 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/10/2022 16:57:53 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.03 on epoch=732
06/10/2022 16:57:56 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=734
06/10/2022 16:57:58 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/10/2022 16:57:59 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.7787335722819593 on epoch=737
06/10/2022 16:58:01 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=739
06/10/2022 16:58:04 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/10/2022 16:58:06 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.07 on epoch=744
06/10/2022 16:58:08 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=747
06/10/2022 16:58:11 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=749
06/10/2022 16:58:12 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.7964285714285714 on epoch=749
06/10/2022 16:58:12 - INFO - __main__ - save last model!
06/10/2022 16:58:12 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/10/2022 16:58:12 - INFO - __main__ - Start tokenizing ... 5509 instances
06/10/2022 16:58:12 - INFO - __main__ - Printing 3 examples
06/10/2022 16:58:12 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/10/2022 16:58:12 - INFO - __main__ - ['others']
06/10/2022 16:58:12 - INFO - __main__ -  [emo] what you like very little things ok
06/10/2022 16:58:12 - INFO - __main__ - ['others']
06/10/2022 16:58:12 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/10/2022 16:58:12 - INFO - __main__ - ['others']
06/10/2022 16:58:12 - INFO - __main__ - Tokenizing Input ...
06/10/2022 16:58:12 - INFO - __main__ - Start tokenizing ... 64 instances
06/10/2022 16:58:12 - INFO - __main__ - Printing 3 examples
06/10/2022 16:58:12 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/10/2022 16:58:12 - INFO - __main__ - ['sad']
06/10/2022 16:58:12 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/10/2022 16:58:12 - INFO - __main__ - ['sad']
06/10/2022 16:58:12 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/10/2022 16:58:12 - INFO - __main__ - ['sad']
06/10/2022 16:58:12 - INFO - __main__ - Tokenizing Input ...
06/10/2022 16:58:12 - INFO - __main__ - Tokenizing Output ...
06/10/2022 16:58:12 - INFO - __main__ - Loaded 64 examples from train data
06/10/2022 16:58:12 - INFO - __main__ - Start tokenizing ... 64 instances
06/10/2022 16:58:12 - INFO - __main__ - Printing 3 examples
06/10/2022 16:58:12 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
06/10/2022 16:58:12 - INFO - __main__ - ['sad']
06/10/2022 16:58:12 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
06/10/2022 16:58:12 - INFO - __main__ - ['sad']
06/10/2022 16:58:12 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
06/10/2022 16:58:12 - INFO - __main__ - ['sad']
06/10/2022 16:58:12 - INFO - __main__ - Tokenizing Input ...
06/10/2022 16:58:12 - INFO - __main__ - Tokenizing Output ...
06/10/2022 16:58:12 - INFO - __main__ - Loaded 64 examples from dev data
06/10/2022 16:58:14 - INFO - __main__ - Tokenizing Output ...
06/10/2022 16:58:19 - INFO - __main__ - Loaded 5509 examples from test data
06/10/2022 16:58:27 - INFO - __main__ - load prompt embedding from ckpt
06/10/2022 16:58:28 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/10/2022 16:58:28 - INFO - __main__ - Starting training!
06/10/2022 16:59:34 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-up32shot/singletask-emo/emo_16_13_0.2_8_predictions.txt
06/10/2022 16:59:34 - INFO - __main__ - Classification-F1 on test data: 0.1685
06/10/2022 16:59:35 - INFO - __main__ - prefix=emo_16_13, lr=0.2, bsz=8, dev_performance=0.8251427898486722, test_performance=0.1684649320854927
06/10/2022 16:59:35 - INFO - __main__ - Running ... prefix=emo_16_21, lr=0.5, bsz=8 ...
06/10/2022 16:59:36 - INFO - __main__ - Start tokenizing ... 64 instances
06/10/2022 16:59:36 - INFO - __main__ - Printing 3 examples
06/10/2022 16:59:36 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/10/2022 16:59:36 - INFO - __main__ - ['sad']
06/10/2022 16:59:36 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/10/2022 16:59:36 - INFO - __main__ - ['sad']
06/10/2022 16:59:36 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/10/2022 16:59:36 - INFO - __main__ - ['sad']
06/10/2022 16:59:36 - INFO - __main__ - Tokenizing Input ...
06/10/2022 16:59:36 - INFO - __main__ - Tokenizing Output ...
06/10/2022 16:59:36 - INFO - __main__ - Loaded 64 examples from train data
06/10/2022 16:59:36 - INFO - __main__ - Start tokenizing ... 64 instances
06/10/2022 16:59:36 - INFO - __main__ - Printing 3 examples
06/10/2022 16:59:36 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
06/10/2022 16:59:36 - INFO - __main__ - ['sad']
06/10/2022 16:59:36 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
06/10/2022 16:59:36 - INFO - __main__ - ['sad']
06/10/2022 16:59:36 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
06/10/2022 16:59:36 - INFO - __main__ - ['sad']
06/10/2022 16:59:36 - INFO - __main__ - Tokenizing Input ...
06/10/2022 16:59:36 - INFO - __main__ - Tokenizing Output ...
06/10/2022 16:59:36 - INFO - __main__ - Loaded 64 examples from dev data
06/10/2022 16:59:51 - INFO - __main__ - load prompt embedding from ckpt
06/10/2022 16:59:52 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/10/2022 16:59:52 - INFO - __main__ - Starting training!
06/10/2022 16:59:55 - INFO - __main__ - Step 10 Global step 10 Train loss 3.85 on epoch=2
06/10/2022 16:59:57 - INFO - __main__ - Step 20 Global step 20 Train loss 2.45 on epoch=4
06/10/2022 16:59:59 - INFO - __main__ - Step 30 Global step 30 Train loss 1.90 on epoch=7
06/10/2022 17:00:02 - INFO - __main__ - Step 40 Global step 40 Train loss 1.22 on epoch=9
06/10/2022 17:00:04 - INFO - __main__ - Step 50 Global step 50 Train loss 0.94 on epoch=12
06/10/2022 17:00:05 - INFO - __main__ - Global step 50 Train loss 2.07 Classification-F1 0.4842347195288372 on epoch=12
06/10/2022 17:00:05 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.4842347195288372 on epoch=12, global_step=50
06/10/2022 17:00:07 - INFO - __main__ - Step 60 Global step 60 Train loss 0.73 on epoch=14
06/10/2022 17:00:10 - INFO - __main__ - Step 70 Global step 70 Train loss 0.70 on epoch=17
06/10/2022 17:00:12 - INFO - __main__ - Step 80 Global step 80 Train loss 0.56 on epoch=19
06/10/2022 17:00:14 - INFO - __main__ - Step 90 Global step 90 Train loss 0.48 on epoch=22
06/10/2022 17:00:17 - INFO - __main__ - Step 100 Global step 100 Train loss 0.48 on epoch=24
06/10/2022 17:00:18 - INFO - __main__ - Global step 100 Train loss 0.59 Classification-F1 0.5485338279455927 on epoch=24
06/10/2022 17:00:18 - INFO - __main__ - Saving model with best Classification-F1: 0.4842347195288372 -> 0.5485338279455927 on epoch=24, global_step=100
06/10/2022 17:00:20 - INFO - __main__ - Step 110 Global step 110 Train loss 0.48 on epoch=27
06/10/2022 17:00:22 - INFO - __main__ - Step 120 Global step 120 Train loss 0.48 on epoch=29
06/10/2022 17:00:25 - INFO - __main__ - Step 130 Global step 130 Train loss 0.45 on epoch=32
06/10/2022 17:00:27 - INFO - __main__ - Step 140 Global step 140 Train loss 0.43 on epoch=34
06/10/2022 17:00:29 - INFO - __main__ - Step 150 Global step 150 Train loss 0.45 on epoch=37
06/10/2022 17:00:30 - INFO - __main__ - Global step 150 Train loss 0.46 Classification-F1 0.6386272526319734 on epoch=37
06/10/2022 17:00:30 - INFO - __main__ - Saving model with best Classification-F1: 0.5485338279455927 -> 0.6386272526319734 on epoch=37, global_step=150
06/10/2022 17:00:33 - INFO - __main__ - Step 160 Global step 160 Train loss 0.46 on epoch=39
06/10/2022 17:00:35 - INFO - __main__ - Step 170 Global step 170 Train loss 0.39 on epoch=42
06/10/2022 17:00:37 - INFO - __main__ - Step 180 Global step 180 Train loss 0.39 on epoch=44
06/10/2022 17:00:40 - INFO - __main__ - Step 190 Global step 190 Train loss 0.36 on epoch=47
06/10/2022 17:00:42 - INFO - __main__ - Step 200 Global step 200 Train loss 0.40 on epoch=49
06/10/2022 17:00:43 - INFO - __main__ - Global step 200 Train loss 0.40 Classification-F1 0.6527052926433732 on epoch=49
06/10/2022 17:00:43 - INFO - __main__ - Saving model with best Classification-F1: 0.6386272526319734 -> 0.6527052926433732 on epoch=49, global_step=200
06/10/2022 17:00:45 - INFO - __main__ - Step 210 Global step 210 Train loss 0.37 on epoch=52
06/10/2022 17:00:48 - INFO - __main__ - Step 220 Global step 220 Train loss 0.36 on epoch=54
06/10/2022 17:00:50 - INFO - __main__ - Step 230 Global step 230 Train loss 0.41 on epoch=57
06/10/2022 17:00:52 - INFO - __main__ - Step 240 Global step 240 Train loss 0.37 on epoch=59
06/10/2022 17:00:55 - INFO - __main__ - Step 250 Global step 250 Train loss 0.28 on epoch=62
06/10/2022 17:00:56 - INFO - __main__ - Global step 250 Train loss 0.36 Classification-F1 0.638961038961039 on epoch=62
06/10/2022 17:00:58 - INFO - __main__ - Step 260 Global step 260 Train loss 0.37 on epoch=64
06/10/2022 17:01:00 - INFO - __main__ - Step 270 Global step 270 Train loss 0.25 on epoch=67
06/10/2022 17:01:03 - INFO - __main__ - Step 280 Global step 280 Train loss 0.31 on epoch=69
06/10/2022 17:01:05 - INFO - __main__ - Step 290 Global step 290 Train loss 0.27 on epoch=72
06/10/2022 17:01:07 - INFO - __main__ - Step 300 Global step 300 Train loss 0.21 on epoch=74
06/10/2022 17:01:08 - INFO - __main__ - Global step 300 Train loss 0.28 Classification-F1 0.6383526383526384 on epoch=74
06/10/2022 17:01:10 - INFO - __main__ - Step 310 Global step 310 Train loss 0.29 on epoch=77
06/10/2022 17:01:13 - INFO - __main__ - Step 320 Global step 320 Train loss 0.22 on epoch=79
06/10/2022 17:01:15 - INFO - __main__ - Step 330 Global step 330 Train loss 0.21 on epoch=82
06/10/2022 17:01:18 - INFO - __main__ - Step 340 Global step 340 Train loss 0.17 on epoch=84
06/10/2022 17:01:20 - INFO - __main__ - Step 350 Global step 350 Train loss 0.20 on epoch=87
06/10/2022 17:01:21 - INFO - __main__ - Global step 350 Train loss 0.22 Classification-F1 0.611904761904762 on epoch=87
06/10/2022 17:01:23 - INFO - __main__ - Step 360 Global step 360 Train loss 0.25 on epoch=89
06/10/2022 17:01:26 - INFO - __main__ - Step 370 Global step 370 Train loss 0.24 on epoch=92
06/10/2022 17:01:28 - INFO - __main__ - Step 380 Global step 380 Train loss 0.19 on epoch=94
06/10/2022 17:01:30 - INFO - __main__ - Step 390 Global step 390 Train loss 0.11 on epoch=97
06/10/2022 17:01:33 - INFO - __main__ - Step 400 Global step 400 Train loss 0.14 on epoch=99
06/10/2022 17:01:34 - INFO - __main__ - Global step 400 Train loss 0.19 Classification-F1 0.6123511904761905 on epoch=99
06/10/2022 17:01:36 - INFO - __main__ - Step 410 Global step 410 Train loss 0.20 on epoch=102
06/10/2022 17:01:38 - INFO - __main__ - Step 420 Global step 420 Train loss 0.13 on epoch=104
06/10/2022 17:01:41 - INFO - __main__ - Step 430 Global step 430 Train loss 0.12 on epoch=107
06/10/2022 17:01:43 - INFO - __main__ - Step 440 Global step 440 Train loss 0.23 on epoch=109
06/10/2022 17:01:45 - INFO - __main__ - Step 450 Global step 450 Train loss 0.13 on epoch=112
06/10/2022 17:01:46 - INFO - __main__ - Global step 450 Train loss 0.16 Classification-F1 0.4925435540069687 on epoch=112
06/10/2022 17:01:49 - INFO - __main__ - Step 460 Global step 460 Train loss 0.15 on epoch=114
06/10/2022 17:01:51 - INFO - __main__ - Step 470 Global step 470 Train loss 0.13 on epoch=117
06/10/2022 17:01:53 - INFO - __main__ - Step 480 Global step 480 Train loss 0.09 on epoch=119
06/10/2022 17:01:56 - INFO - __main__ - Step 490 Global step 490 Train loss 0.10 on epoch=122
06/10/2022 17:01:58 - INFO - __main__ - Step 500 Global step 500 Train loss 0.12 on epoch=124
06/10/2022 17:01:59 - INFO - __main__ - Global step 500 Train loss 0.12 Classification-F1 0.624806426635695 on epoch=124
06/10/2022 17:02:01 - INFO - __main__ - Step 510 Global step 510 Train loss 0.11 on epoch=127
06/10/2022 17:02:04 - INFO - __main__ - Step 520 Global step 520 Train loss 0.12 on epoch=129
06/10/2022 17:02:06 - INFO - __main__ - Step 530 Global step 530 Train loss 0.24 on epoch=132
06/10/2022 17:02:09 - INFO - __main__ - Step 540 Global step 540 Train loss 0.08 on epoch=134
06/10/2022 17:02:11 - INFO - __main__ - Step 550 Global step 550 Train loss 0.10 on epoch=137
06/10/2022 17:02:12 - INFO - __main__ - Global step 550 Train loss 0.13 Classification-F1 0.6395225294418843 on epoch=137
06/10/2022 17:02:14 - INFO - __main__ - Step 560 Global step 560 Train loss 0.09 on epoch=139
06/10/2022 17:02:17 - INFO - __main__ - Step 570 Global step 570 Train loss 0.12 on epoch=142
06/10/2022 17:02:19 - INFO - __main__ - Step 580 Global step 580 Train loss 0.11 on epoch=144
06/10/2022 17:02:21 - INFO - __main__ - Step 590 Global step 590 Train loss 0.05 on epoch=147
06/10/2022 17:02:24 - INFO - __main__ - Step 600 Global step 600 Train loss 0.07 on epoch=149
06/10/2022 17:02:25 - INFO - __main__ - Global step 600 Train loss 0.09 Classification-F1 0.6395225294418843 on epoch=149
06/10/2022 17:02:27 - INFO - __main__ - Step 610 Global step 610 Train loss 0.08 on epoch=152
06/10/2022 17:02:29 - INFO - __main__ - Step 620 Global step 620 Train loss 0.21 on epoch=154
06/10/2022 17:02:32 - INFO - __main__ - Step 630 Global step 630 Train loss 0.07 on epoch=157
06/10/2022 17:02:34 - INFO - __main__ - Step 640 Global step 640 Train loss 0.11 on epoch=159
06/10/2022 17:02:37 - INFO - __main__ - Step 650 Global step 650 Train loss 0.20 on epoch=162
06/10/2022 17:02:38 - INFO - __main__ - Global step 650 Train loss 0.13 Classification-F1 0.6264321306807539 on epoch=162
06/10/2022 17:02:40 - INFO - __main__ - Step 660 Global step 660 Train loss 0.04 on epoch=164
06/10/2022 17:02:42 - INFO - __main__ - Step 670 Global step 670 Train loss 0.10 on epoch=167
06/10/2022 17:02:45 - INFO - __main__ - Step 680 Global step 680 Train loss 0.12 on epoch=169
06/10/2022 17:02:47 - INFO - __main__ - Step 690 Global step 690 Train loss 0.08 on epoch=172
06/10/2022 17:02:49 - INFO - __main__ - Step 700 Global step 700 Train loss 0.04 on epoch=174
06/10/2022 17:02:50 - INFO - __main__ - Global step 700 Train loss 0.08 Classification-F1 0.6264321306807539 on epoch=174
06/10/2022 17:02:53 - INFO - __main__ - Step 710 Global step 710 Train loss 0.07 on epoch=177
06/10/2022 17:02:55 - INFO - __main__ - Step 720 Global step 720 Train loss 0.05 on epoch=179
06/10/2022 17:02:57 - INFO - __main__ - Step 730 Global step 730 Train loss 0.08 on epoch=182
06/10/2022 17:03:00 - INFO - __main__ - Step 740 Global step 740 Train loss 0.02 on epoch=184
06/10/2022 17:03:02 - INFO - __main__ - Step 750 Global step 750 Train loss 0.05 on epoch=187
06/10/2022 17:03:03 - INFO - __main__ - Global step 750 Train loss 0.05 Classification-F1 0.6264321306807539 on epoch=187
06/10/2022 17:03:05 - INFO - __main__ - Step 760 Global step 760 Train loss 0.14 on epoch=189
06/10/2022 17:03:08 - INFO - __main__ - Step 770 Global step 770 Train loss 0.04 on epoch=192
06/10/2022 17:03:10 - INFO - __main__ - Step 780 Global step 780 Train loss 0.03 on epoch=194
06/10/2022 17:03:12 - INFO - __main__ - Step 790 Global step 790 Train loss 0.05 on epoch=197
06/10/2022 17:03:15 - INFO - __main__ - Step 800 Global step 800 Train loss 0.03 on epoch=199
06/10/2022 17:03:16 - INFO - __main__ - Global step 800 Train loss 0.06 Classification-F1 0.6395225294418843 on epoch=199
06/10/2022 17:03:18 - INFO - __main__ - Step 810 Global step 810 Train loss 0.08 on epoch=202
06/10/2022 17:03:21 - INFO - __main__ - Step 820 Global step 820 Train loss 0.04 on epoch=204
06/10/2022 17:03:23 - INFO - __main__ - Step 830 Global step 830 Train loss 0.04 on epoch=207
06/10/2022 17:03:25 - INFO - __main__ - Step 840 Global step 840 Train loss 0.04 on epoch=209
06/10/2022 17:03:28 - INFO - __main__ - Step 850 Global step 850 Train loss 0.03 on epoch=212
06/10/2022 17:03:28 - INFO - __main__ - Global step 850 Train loss 0.04 Classification-F1 0.6395225294418843 on epoch=212
06/10/2022 17:03:31 - INFO - __main__ - Step 860 Global step 860 Train loss 0.10 on epoch=214
06/10/2022 17:03:33 - INFO - __main__ - Step 870 Global step 870 Train loss 0.02 on epoch=217
06/10/2022 17:03:36 - INFO - __main__ - Step 880 Global step 880 Train loss 0.04 on epoch=219
06/10/2022 17:03:38 - INFO - __main__ - Step 890 Global step 890 Train loss 0.03 on epoch=222
06/10/2022 17:03:40 - INFO - __main__ - Step 900 Global step 900 Train loss 0.06 on epoch=224
06/10/2022 17:03:41 - INFO - __main__ - Global step 900 Train loss 0.05 Classification-F1 0.6526383526383527 on epoch=224
06/10/2022 17:03:44 - INFO - __main__ - Step 910 Global step 910 Train loss 0.02 on epoch=227
06/10/2022 17:03:46 - INFO - __main__ - Step 920 Global step 920 Train loss 0.08 on epoch=229
06/10/2022 17:03:48 - INFO - __main__ - Step 930 Global step 930 Train loss 0.02 on epoch=232
06/10/2022 17:03:51 - INFO - __main__ - Step 940 Global step 940 Train loss 0.06 on epoch=234
06/10/2022 17:03:53 - INFO - __main__ - Step 950 Global step 950 Train loss 0.01 on epoch=237
06/10/2022 17:03:54 - INFO - __main__ - Global step 950 Train loss 0.04 Classification-F1 0.681272374820762 on epoch=237
06/10/2022 17:03:54 - INFO - __main__ - Saving model with best Classification-F1: 0.6527052926433732 -> 0.681272374820762 on epoch=237, global_step=950
06/10/2022 17:03:56 - INFO - __main__ - Step 960 Global step 960 Train loss 0.08 on epoch=239
06/10/2022 17:03:59 - INFO - __main__ - Step 970 Global step 970 Train loss 0.03 on epoch=242
06/10/2022 17:04:01 - INFO - __main__ - Step 980 Global step 980 Train loss 0.05 on epoch=244
06/10/2022 17:04:04 - INFO - __main__ - Step 990 Global step 990 Train loss 0.02 on epoch=247
06/10/2022 17:04:06 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.02 on epoch=249
06/10/2022 17:04:07 - INFO - __main__ - Global step 1000 Train loss 0.04 Classification-F1 0.6395021645021645 on epoch=249
06/10/2022 17:04:09 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.06 on epoch=252
06/10/2022 17:04:12 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.01 on epoch=254
06/10/2022 17:04:14 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.04 on epoch=257
06/10/2022 17:04:16 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.04 on epoch=259
06/10/2022 17:04:19 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.01 on epoch=262
06/10/2022 17:04:20 - INFO - __main__ - Global step 1050 Train loss 0.03 Classification-F1 0.6956316807659519 on epoch=262
06/10/2022 17:04:20 - INFO - __main__ - Saving model with best Classification-F1: 0.681272374820762 -> 0.6956316807659519 on epoch=262, global_step=1050
06/10/2022 17:04:22 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.10 on epoch=264
06/10/2022 17:04:24 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.02 on epoch=267
06/10/2022 17:04:27 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.04 on epoch=269
06/10/2022 17:04:29 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.03 on epoch=272
06/10/2022 17:04:31 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.03 on epoch=274
06/10/2022 17:04:32 - INFO - __main__ - Global step 1100 Train loss 0.04 Classification-F1 0.6536682152535812 on epoch=274
06/10/2022 17:04:35 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.01 on epoch=277
06/10/2022 17:04:37 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.10 on epoch=279
06/10/2022 17:04:39 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.03 on epoch=282
06/10/2022 17:04:42 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.03 on epoch=284
06/10/2022 17:04:44 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=287
06/10/2022 17:04:45 - INFO - __main__ - Global step 1150 Train loss 0.03 Classification-F1 0.6442240627724499 on epoch=287
06/10/2022 17:04:47 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.01 on epoch=289
06/10/2022 17:04:50 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.01 on epoch=292
06/10/2022 17:04:52 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.04 on epoch=294
06/10/2022 17:04:54 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.03 on epoch=297
06/10/2022 17:04:57 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=299
06/10/2022 17:04:58 - INFO - __main__ - Global step 1200 Train loss 0.02 Classification-F1 0.6681515616999489 on epoch=299
06/10/2022 17:05:00 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.03 on epoch=302
06/10/2022 17:05:03 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=304
06/10/2022 17:05:05 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.02 on epoch=307
06/10/2022 17:05:07 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=309
06/10/2022 17:05:10 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.01 on epoch=312
06/10/2022 17:05:11 - INFO - __main__ - Global step 1250 Train loss 0.01 Classification-F1 0.681272374820762 on epoch=312
06/10/2022 17:05:13 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.03 on epoch=314
06/10/2022 17:05:15 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.03 on epoch=317
06/10/2022 17:05:18 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=319
06/10/2022 17:05:20 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=322
06/10/2022 17:05:23 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.02 on epoch=324
06/10/2022 17:05:24 - INFO - __main__ - Global step 1300 Train loss 0.02 Classification-F1 0.6690476190476191 on epoch=324
06/10/2022 17:05:26 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.02 on epoch=327
06/10/2022 17:05:28 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=329
06/10/2022 17:05:31 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.02 on epoch=332
06/10/2022 17:05:33 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=334
06/10/2022 17:05:35 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=337
06/10/2022 17:05:36 - INFO - __main__ - Global step 1350 Train loss 0.01 Classification-F1 0.7182295932295932 on epoch=337
06/10/2022 17:05:36 - INFO - __main__ - Saving model with best Classification-F1: 0.6956316807659519 -> 0.7182295932295932 on epoch=337, global_step=1350
06/10/2022 17:05:39 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=339
06/10/2022 17:05:41 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.02 on epoch=342
06/10/2022 17:05:44 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.03 on epoch=344
06/10/2022 17:05:46 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.02 on epoch=347
06/10/2022 17:05:48 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=349
06/10/2022 17:05:49 - INFO - __main__ - Global step 1400 Train loss 0.02 Classification-F1 0.6681515616999489 on epoch=349
06/10/2022 17:05:52 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.04 on epoch=352
06/10/2022 17:05:54 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.03 on epoch=354
06/10/2022 17:05:57 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=357
06/10/2022 17:05:59 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=359
06/10/2022 17:06:01 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=362
06/10/2022 17:06:02 - INFO - __main__ - Global step 1450 Train loss 0.02 Classification-F1 0.6825300038714672 on epoch=362
06/10/2022 17:06:05 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.02 on epoch=364
06/10/2022 17:06:07 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.06 on epoch=367
06/10/2022 17:06:09 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=369
06/10/2022 17:06:12 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=372
06/10/2022 17:06:14 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=374
06/10/2022 17:06:15 - INFO - __main__ - Global step 1500 Train loss 0.02 Classification-F1 0.7034845946387709 on epoch=374
06/10/2022 17:06:18 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=377
06/10/2022 17:06:20 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=379
06/10/2022 17:06:22 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=382
06/10/2022 17:06:25 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=384
06/10/2022 17:06:27 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=387
06/10/2022 17:06:28 - INFO - __main__ - Global step 1550 Train loss 0.00 Classification-F1 0.7033117389653892 on epoch=387
06/10/2022 17:06:30 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=389
06/10/2022 17:06:33 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=392
06/10/2022 17:06:35 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=394
06/10/2022 17:06:37 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=397
06/10/2022 17:06:40 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=399
06/10/2022 17:06:41 - INFO - __main__ - Global step 1600 Train loss 0.00 Classification-F1 0.7033117389653892 on epoch=399
06/10/2022 17:06:43 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=402
06/10/2022 17:06:45 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=404
06/10/2022 17:06:48 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=407
06/10/2022 17:06:50 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=409
06/10/2022 17:06:52 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=412
06/10/2022 17:06:53 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.7178670147420146 on epoch=412
06/10/2022 17:06:56 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=414
06/10/2022 17:06:58 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=417
06/10/2022 17:07:00 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=419
06/10/2022 17:07:03 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=422
06/10/2022 17:07:05 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=424
06/10/2022 17:07:06 - INFO - __main__ - Global step 1700 Train loss 0.00 Classification-F1 0.6955723345525977 on epoch=424
06/10/2022 17:07:09 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.03 on epoch=427
06/10/2022 17:07:11 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=429
06/10/2022 17:07:13 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=432
06/10/2022 17:07:16 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=434
06/10/2022 17:07:18 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=437
06/10/2022 17:07:19 - INFO - __main__ - Global step 1750 Train loss 0.01 Classification-F1 0.7033117389653892 on epoch=437
06/10/2022 17:07:21 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=439
06/10/2022 17:07:24 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=442
06/10/2022 17:07:26 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=444
06/10/2022 17:07:28 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=447
06/10/2022 17:07:31 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=449
06/10/2022 17:07:32 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.6957368082368082 on epoch=449
06/10/2022 17:07:34 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=452
06/10/2022 17:07:37 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=454
06/10/2022 17:07:39 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=457
06/10/2022 17:07:41 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=459
06/10/2022 17:07:44 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=462
06/10/2022 17:07:45 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.7178670147420146 on epoch=462
06/10/2022 17:07:47 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=464
06/10/2022 17:07:50 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=467
06/10/2022 17:07:52 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=469
06/10/2022 17:07:54 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=472
06/10/2022 17:07:57 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=474
06/10/2022 17:07:58 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.671546052631579 on epoch=474
06/10/2022 17:08:00 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=477
06/10/2022 17:08:02 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=479
06/10/2022 17:08:05 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=482
06/10/2022 17:08:07 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=484
06/10/2022 17:08:10 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=487
06/10/2022 17:08:11 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.718904303581723 on epoch=487
06/10/2022 17:08:11 - INFO - __main__ - Saving model with best Classification-F1: 0.7182295932295932 -> 0.718904303581723 on epoch=487, global_step=1950
06/10/2022 17:08:13 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=489
06/10/2022 17:08:15 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=492
06/10/2022 17:08:18 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=494
06/10/2022 17:08:20 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=497
06/10/2022 17:08:22 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=499
06/10/2022 17:08:23 - INFO - __main__ - Global step 2000 Train loss 0.00 Classification-F1 0.6955723345525977 on epoch=499
06/10/2022 17:08:26 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=502
06/10/2022 17:08:28 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.10 on epoch=504
06/10/2022 17:08:31 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/10/2022 17:08:33 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=509
06/10/2022 17:08:35 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/10/2022 17:08:36 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.6957368082368082 on epoch=512
06/10/2022 17:08:39 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=514
06/10/2022 17:08:41 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=517
06/10/2022 17:08:43 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/10/2022 17:08:46 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=522
06/10/2022 17:08:48 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/10/2022 17:08:49 - INFO - __main__ - Global step 2100 Train loss 0.00 Classification-F1 0.7178670147420146 on epoch=524
06/10/2022 17:08:52 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=527
06/10/2022 17:08:54 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/10/2022 17:08:56 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/10/2022 17:08:59 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
06/10/2022 17:09:01 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
06/10/2022 17:09:02 - INFO - __main__ - Global step 2150 Train loss 0.00 Classification-F1 0.6899547585031457 on epoch=537
06/10/2022 17:09:04 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=539
06/10/2022 17:09:07 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/10/2022 17:09:09 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=544
06/10/2022 17:09:12 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/10/2022 17:09:14 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/10/2022 17:09:15 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.6899547585031457 on epoch=549
06/10/2022 17:09:17 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/10/2022 17:09:20 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/10/2022 17:09:22 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=557
06/10/2022 17:09:24 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.03 on epoch=559
06/10/2022 17:09:27 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/10/2022 17:09:28 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.6822153540903542 on epoch=562
06/10/2022 17:09:30 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=564
06/10/2022 17:09:33 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/10/2022 17:09:35 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=569
06/10/2022 17:09:37 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/10/2022 17:09:40 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/10/2022 17:09:41 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.732695374800638 on epoch=574
06/10/2022 17:09:41 - INFO - __main__ - Saving model with best Classification-F1: 0.718904303581723 -> 0.732695374800638 on epoch=574, global_step=2300
06/10/2022 17:09:43 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/10/2022 17:09:45 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/10/2022 17:09:48 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.04 on epoch=582
06/10/2022 17:09:50 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/10/2022 17:09:53 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/10/2022 17:09:54 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.6955723345525977 on epoch=587
06/10/2022 17:09:56 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/10/2022 17:09:58 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/10/2022 17:10:01 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/10/2022 17:10:03 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=597
06/10/2022 17:10:05 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=599
06/10/2022 17:10:06 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.703357100415924 on epoch=599
06/10/2022 17:10:09 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=602
06/10/2022 17:10:11 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/10/2022 17:10:13 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.06 on epoch=607
06/10/2022 17:10:16 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/10/2022 17:10:18 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=612
06/10/2022 17:10:19 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.681272374820762 on epoch=612
06/10/2022 17:10:22 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/10/2022 17:10:24 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=617
06/10/2022 17:10:26 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.03 on epoch=619
06/10/2022 17:10:29 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/10/2022 17:10:31 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/10/2022 17:10:32 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.671546052631579 on epoch=624
06/10/2022 17:10:34 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=627
06/10/2022 17:10:37 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=629
06/10/2022 17:10:39 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=632
06/10/2022 17:10:41 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.04 on epoch=634
06/10/2022 17:10:44 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=637
06/10/2022 17:10:45 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.671546052631579 on epoch=637
06/10/2022 17:10:47 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=639
06/10/2022 17:10:49 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/10/2022 17:10:52 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/10/2022 17:10:54 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/10/2022 17:10:57 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/10/2022 17:10:58 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.671546052631579 on epoch=649
06/10/2022 17:11:00 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/10/2022 17:11:02 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=654
06/10/2022 17:11:05 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/10/2022 17:11:07 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/10/2022 17:11:09 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=662
06/10/2022 17:11:10 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.671546052631579 on epoch=662
06/10/2022 17:11:13 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/10/2022 17:11:15 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=667
06/10/2022 17:11:17 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/10/2022 17:11:20 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/10/2022 17:11:22 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/10/2022 17:11:23 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.681272374820762 on epoch=674
06/10/2022 17:11:26 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/10/2022 17:11:28 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/10/2022 17:11:30 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/10/2022 17:11:33 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=684
06/10/2022 17:11:35 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.03 on epoch=687
06/10/2022 17:11:36 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.7095472095472095 on epoch=687
06/10/2022 17:11:38 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/10/2022 17:11:41 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.05 on epoch=692
06/10/2022 17:11:43 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/10/2022 17:11:45 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.05 on epoch=697
06/10/2022 17:11:48 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/10/2022 17:11:49 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.6822153540903542 on epoch=699
06/10/2022 17:11:51 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/10/2022 17:11:53 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/10/2022 17:11:56 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/10/2022 17:11:58 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/10/2022 17:12:00 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=712
06/10/2022 17:12:01 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.6955723345525977 on epoch=712
06/10/2022 17:12:04 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/10/2022 17:12:06 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/10/2022 17:12:09 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/10/2022 17:12:11 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/10/2022 17:12:13 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/10/2022 17:12:14 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.6955723345525977 on epoch=724
06/10/2022 17:12:17 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/10/2022 17:12:19 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/10/2022 17:12:21 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/10/2022 17:12:24 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/10/2022 17:12:26 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/10/2022 17:12:27 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.6955723345525977 on epoch=737
06/10/2022 17:12:29 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/10/2022 17:12:32 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/10/2022 17:12:34 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/10/2022 17:12:36 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/10/2022 17:12:39 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/10/2022 17:12:40 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.6955723345525977 on epoch=749
06/10/2022 17:12:40 - INFO - __main__ - save last model!
06/10/2022 17:12:40 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/10/2022 17:12:40 - INFO - __main__ - Start tokenizing ... 5509 instances
06/10/2022 17:12:40 - INFO - __main__ - Printing 3 examples
06/10/2022 17:12:40 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/10/2022 17:12:40 - INFO - __main__ - ['others']
06/10/2022 17:12:40 - INFO - __main__ -  [emo] what you like very little things ok
06/10/2022 17:12:40 - INFO - __main__ - ['others']
06/10/2022 17:12:40 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/10/2022 17:12:40 - INFO - __main__ - ['others']
06/10/2022 17:12:40 - INFO - __main__ - Tokenizing Input ...
06/10/2022 17:12:40 - INFO - __main__ - Start tokenizing ... 64 instances
06/10/2022 17:12:40 - INFO - __main__ - Printing 3 examples
06/10/2022 17:12:40 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/10/2022 17:12:40 - INFO - __main__ - ['sad']
06/10/2022 17:12:40 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/10/2022 17:12:40 - INFO - __main__ - ['sad']
06/10/2022 17:12:40 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/10/2022 17:12:40 - INFO - __main__ - ['sad']
06/10/2022 17:12:40 - INFO - __main__ - Tokenizing Input ...
06/10/2022 17:12:40 - INFO - __main__ - Tokenizing Output ...
06/10/2022 17:12:40 - INFO - __main__ - Loaded 64 examples from train data
06/10/2022 17:12:40 - INFO - __main__ - Start tokenizing ... 64 instances
06/10/2022 17:12:40 - INFO - __main__ - Printing 3 examples
06/10/2022 17:12:40 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
06/10/2022 17:12:40 - INFO - __main__ - ['sad']
06/10/2022 17:12:40 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
06/10/2022 17:12:40 - INFO - __main__ - ['sad']
06/10/2022 17:12:40 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
06/10/2022 17:12:40 - INFO - __main__ - ['sad']
06/10/2022 17:12:40 - INFO - __main__ - Tokenizing Input ...
06/10/2022 17:12:40 - INFO - __main__ - Tokenizing Output ...
06/10/2022 17:12:40 - INFO - __main__ - Loaded 64 examples from dev data
06/10/2022 17:12:42 - INFO - __main__ - Tokenizing Output ...
06/10/2022 17:12:47 - INFO - __main__ - Loaded 5509 examples from test data
06/10/2022 17:12:56 - INFO - __main__ - load prompt embedding from ckpt
06/10/2022 17:12:57 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/10/2022 17:12:57 - INFO - __main__ - Starting training!
06/10/2022 17:14:19 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-up32shot/singletask-emo/emo_16_21_0.5_8_predictions.txt
06/10/2022 17:14:19 - INFO - __main__ - Classification-F1 on test data: 0.2420
06/10/2022 17:14:20 - INFO - __main__ - prefix=emo_16_21, lr=0.5, bsz=8, dev_performance=0.732695374800638, test_performance=0.2419533175023131
06/10/2022 17:14:20 - INFO - __main__ - Running ... prefix=emo_16_21, lr=0.4, bsz=8 ...
06/10/2022 17:14:21 - INFO - __main__ - Start tokenizing ... 64 instances
06/10/2022 17:14:21 - INFO - __main__ - Printing 3 examples
06/10/2022 17:14:21 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/10/2022 17:14:21 - INFO - __main__ - ['sad']
06/10/2022 17:14:21 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/10/2022 17:14:21 - INFO - __main__ - ['sad']
06/10/2022 17:14:21 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/10/2022 17:14:21 - INFO - __main__ - ['sad']
06/10/2022 17:14:21 - INFO - __main__ - Tokenizing Input ...
06/10/2022 17:14:21 - INFO - __main__ - Tokenizing Output ...
06/10/2022 17:14:21 - INFO - __main__ - Loaded 64 examples from train data
06/10/2022 17:14:21 - INFO - __main__ - Start tokenizing ... 64 instances
06/10/2022 17:14:21 - INFO - __main__ - Printing 3 examples
06/10/2022 17:14:21 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
06/10/2022 17:14:21 - INFO - __main__ - ['sad']
06/10/2022 17:14:21 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
06/10/2022 17:14:21 - INFO - __main__ - ['sad']
06/10/2022 17:14:21 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
06/10/2022 17:14:21 - INFO - __main__ - ['sad']
06/10/2022 17:14:21 - INFO - __main__ - Tokenizing Input ...
06/10/2022 17:14:21 - INFO - __main__ - Tokenizing Output ...
06/10/2022 17:14:21 - INFO - __main__ - Loaded 64 examples from dev data
06/10/2022 17:14:36 - INFO - __main__ - load prompt embedding from ckpt
06/10/2022 17:14:37 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/10/2022 17:14:37 - INFO - __main__ - Starting training!
06/10/2022 17:14:40 - INFO - __main__ - Step 10 Global step 10 Train loss 3.89 on epoch=2
06/10/2022 17:14:42 - INFO - __main__ - Step 20 Global step 20 Train loss 2.69 on epoch=4
06/10/2022 17:14:44 - INFO - __main__ - Step 30 Global step 30 Train loss 1.97 on epoch=7
06/10/2022 17:14:47 - INFO - __main__ - Step 40 Global step 40 Train loss 1.46 on epoch=9
06/10/2022 17:14:49 - INFO - __main__ - Step 50 Global step 50 Train loss 1.11 on epoch=12
06/10/2022 17:14:50 - INFO - __main__ - Global step 50 Train loss 2.23 Classification-F1 0.4668240454076368 on epoch=12
06/10/2022 17:14:50 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.4668240454076368 on epoch=12, global_step=50
06/10/2022 17:14:52 - INFO - __main__ - Step 60 Global step 60 Train loss 1.06 on epoch=14
06/10/2022 17:14:55 - INFO - __main__ - Step 70 Global step 70 Train loss 0.81 on epoch=17
06/10/2022 17:14:57 - INFO - __main__ - Step 80 Global step 80 Train loss 0.77 on epoch=19
06/10/2022 17:14:59 - INFO - __main__ - Step 90 Global step 90 Train loss 0.69 on epoch=22
06/10/2022 17:15:02 - INFO - __main__ - Step 100 Global step 100 Train loss 0.56 on epoch=24
06/10/2022 17:15:03 - INFO - __main__ - Global step 100 Train loss 0.78 Classification-F1 0.5485338279455927 on epoch=24
06/10/2022 17:15:03 - INFO - __main__ - Saving model with best Classification-F1: 0.4668240454076368 -> 0.5485338279455927 on epoch=24, global_step=100
06/10/2022 17:15:05 - INFO - __main__ - Step 110 Global step 110 Train loss 0.52 on epoch=27
06/10/2022 17:15:07 - INFO - __main__ - Step 120 Global step 120 Train loss 0.59 on epoch=29
06/10/2022 17:15:10 - INFO - __main__ - Step 130 Global step 130 Train loss 0.53 on epoch=32
06/10/2022 17:15:12 - INFO - __main__ - Step 140 Global step 140 Train loss 0.50 on epoch=34
06/10/2022 17:15:14 - INFO - __main__ - Step 150 Global step 150 Train loss 0.63 on epoch=37
06/10/2022 17:15:15 - INFO - __main__ - Global step 150 Train loss 0.56 Classification-F1 0.6180223285486444 on epoch=37
06/10/2022 17:15:15 - INFO - __main__ - Saving model with best Classification-F1: 0.5485338279455927 -> 0.6180223285486444 on epoch=37, global_step=150
06/10/2022 17:15:18 - INFO - __main__ - Step 160 Global step 160 Train loss 0.44 on epoch=39
06/10/2022 17:15:20 - INFO - __main__ - Step 170 Global step 170 Train loss 0.32 on epoch=42
06/10/2022 17:15:22 - INFO - __main__ - Step 180 Global step 180 Train loss 0.38 on epoch=44
06/10/2022 17:15:25 - INFO - __main__ - Step 190 Global step 190 Train loss 0.40 on epoch=47
06/10/2022 17:15:27 - INFO - __main__ - Step 200 Global step 200 Train loss 0.42 on epoch=49
06/10/2022 17:15:28 - INFO - __main__ - Global step 200 Train loss 0.39 Classification-F1 0.6567595459236326 on epoch=49
06/10/2022 17:15:28 - INFO - __main__ - Saving model with best Classification-F1: 0.6180223285486444 -> 0.6567595459236326 on epoch=49, global_step=200
06/10/2022 17:15:30 - INFO - __main__ - Step 210 Global step 210 Train loss 0.44 on epoch=52
06/10/2022 17:15:32 - INFO - __main__ - Step 220 Global step 220 Train loss 0.32 on epoch=54
06/10/2022 17:15:35 - INFO - __main__ - Step 230 Global step 230 Train loss 0.42 on epoch=57
06/10/2022 17:15:37 - INFO - __main__ - Step 240 Global step 240 Train loss 0.40 on epoch=59
06/10/2022 17:15:39 - INFO - __main__ - Step 250 Global step 250 Train loss 0.31 on epoch=62
06/10/2022 17:15:40 - INFO - __main__ - Global step 250 Train loss 0.38 Classification-F1 0.6238095238095238 on epoch=62
06/10/2022 17:15:43 - INFO - __main__ - Step 260 Global step 260 Train loss 0.34 on epoch=64
06/10/2022 17:15:45 - INFO - __main__ - Step 270 Global step 270 Train loss 0.25 on epoch=67
06/10/2022 17:15:47 - INFO - __main__ - Step 280 Global step 280 Train loss 0.34 on epoch=69
06/10/2022 17:15:50 - INFO - __main__ - Step 290 Global step 290 Train loss 0.30 on epoch=72
06/10/2022 17:15:52 - INFO - __main__ - Step 300 Global step 300 Train loss 0.36 on epoch=74
06/10/2022 17:15:53 - INFO - __main__ - Global step 300 Train loss 0.32 Classification-F1 0.6386272526319734 on epoch=74
06/10/2022 17:15:56 - INFO - __main__ - Step 310 Global step 310 Train loss 0.26 on epoch=77
06/10/2022 17:15:58 - INFO - __main__ - Step 320 Global step 320 Train loss 0.25 on epoch=79
06/10/2022 17:16:00 - INFO - __main__ - Step 330 Global step 330 Train loss 0.25 on epoch=82
06/10/2022 17:16:03 - INFO - __main__ - Step 340 Global step 340 Train loss 0.24 on epoch=84
06/10/2022 17:16:05 - INFO - __main__ - Step 350 Global step 350 Train loss 0.27 on epoch=87
06/10/2022 17:16:06 - INFO - __main__ - Global step 350 Train loss 0.25 Classification-F1 0.6386272526319734 on epoch=87
06/10/2022 17:16:08 - INFO - __main__ - Step 360 Global step 360 Train loss 0.20 on epoch=89
06/10/2022 17:16:11 - INFO - __main__ - Step 370 Global step 370 Train loss 0.29 on epoch=92
06/10/2022 17:16:13 - INFO - __main__ - Step 380 Global step 380 Train loss 0.21 on epoch=94
06/10/2022 17:16:16 - INFO - __main__ - Step 390 Global step 390 Train loss 0.30 on epoch=97
06/10/2022 17:16:18 - INFO - __main__ - Step 400 Global step 400 Train loss 0.25 on epoch=99
06/10/2022 17:16:19 - INFO - __main__ - Global step 400 Train loss 0.25 Classification-F1 0.6404761904761904 on epoch=99
06/10/2022 17:16:21 - INFO - __main__ - Step 410 Global step 410 Train loss 0.21 on epoch=102
06/10/2022 17:16:24 - INFO - __main__ - Step 420 Global step 420 Train loss 0.23 on epoch=104
06/10/2022 17:16:26 - INFO - __main__ - Step 430 Global step 430 Train loss 0.18 on epoch=107
06/10/2022 17:16:28 - INFO - __main__ - Step 440 Global step 440 Train loss 0.17 on epoch=109
06/10/2022 17:16:31 - INFO - __main__ - Step 450 Global step 450 Train loss 0.19 on epoch=112
06/10/2022 17:16:32 - INFO - __main__ - Global step 450 Train loss 0.20 Classification-F1 0.6628342245989305 on epoch=112
06/10/2022 17:16:32 - INFO - __main__ - Saving model with best Classification-F1: 0.6567595459236326 -> 0.6628342245989305 on epoch=112, global_step=450
06/10/2022 17:16:34 - INFO - __main__ - Step 460 Global step 460 Train loss 0.18 on epoch=114
06/10/2022 17:16:36 - INFO - __main__ - Step 470 Global step 470 Train loss 0.21 on epoch=117
06/10/2022 17:16:39 - INFO - __main__ - Step 480 Global step 480 Train loss 0.19 on epoch=119
06/10/2022 17:16:41 - INFO - __main__ - Step 490 Global step 490 Train loss 0.22 on epoch=122
06/10/2022 17:16:44 - INFO - __main__ - Step 500 Global step 500 Train loss 0.17 on epoch=124
06/10/2022 17:16:45 - INFO - __main__ - Global step 500 Train loss 0.20 Classification-F1 0.6404761904761904 on epoch=124
06/10/2022 17:16:47 - INFO - __main__ - Step 510 Global step 510 Train loss 0.16 on epoch=127
06/10/2022 17:16:49 - INFO - __main__ - Step 520 Global step 520 Train loss 0.18 on epoch=129
06/10/2022 17:16:52 - INFO - __main__ - Step 530 Global step 530 Train loss 0.10 on epoch=132
06/10/2022 17:16:54 - INFO - __main__ - Step 540 Global step 540 Train loss 0.15 on epoch=134
06/10/2022 17:16:57 - INFO - __main__ - Step 550 Global step 550 Train loss 0.14 on epoch=137
06/10/2022 17:16:58 - INFO - __main__ - Global step 550 Train loss 0.15 Classification-F1 0.49658536585365853 on epoch=137
06/10/2022 17:17:00 - INFO - __main__ - Step 560 Global step 560 Train loss 0.11 on epoch=139
06/10/2022 17:17:02 - INFO - __main__ - Step 570 Global step 570 Train loss 0.12 on epoch=142
06/10/2022 17:17:05 - INFO - __main__ - Step 580 Global step 580 Train loss 0.19 on epoch=144
06/10/2022 17:17:07 - INFO - __main__ - Step 590 Global step 590 Train loss 0.13 on epoch=147
06/10/2022 17:17:09 - INFO - __main__ - Step 600 Global step 600 Train loss 0.07 on epoch=149
06/10/2022 17:17:10 - INFO - __main__ - Global step 600 Train loss 0.12 Classification-F1 0.6752525252525253 on epoch=149
06/10/2022 17:17:10 - INFO - __main__ - Saving model with best Classification-F1: 0.6628342245989305 -> 0.6752525252525253 on epoch=149, global_step=600
06/10/2022 17:17:13 - INFO - __main__ - Step 610 Global step 610 Train loss 0.11 on epoch=152
06/10/2022 17:17:15 - INFO - __main__ - Step 620 Global step 620 Train loss 0.14 on epoch=154
06/10/2022 17:17:17 - INFO - __main__ - Step 630 Global step 630 Train loss 0.09 on epoch=157
06/10/2022 17:17:20 - INFO - __main__ - Step 640 Global step 640 Train loss 0.14 on epoch=159
06/10/2022 17:17:22 - INFO - __main__ - Step 650 Global step 650 Train loss 0.12 on epoch=162
06/10/2022 17:17:23 - INFO - __main__ - Global step 650 Train loss 0.12 Classification-F1 0.6477115626309174 on epoch=162
06/10/2022 17:17:25 - INFO - __main__ - Step 660 Global step 660 Train loss 0.13 on epoch=164
06/10/2022 17:17:28 - INFO - __main__ - Step 670 Global step 670 Train loss 0.05 on epoch=167
06/10/2022 17:17:30 - INFO - __main__ - Step 680 Global step 680 Train loss 0.13 on epoch=169
06/10/2022 17:17:32 - INFO - __main__ - Step 690 Global step 690 Train loss 0.07 on epoch=172
06/10/2022 17:17:35 - INFO - __main__ - Step 700 Global step 700 Train loss 0.14 on epoch=174
06/10/2022 17:17:36 - INFO - __main__ - Global step 700 Train loss 0.10 Classification-F1 0.6166666666666667 on epoch=174
06/10/2022 17:17:38 - INFO - __main__ - Step 710 Global step 710 Train loss 0.07 on epoch=177
06/10/2022 17:17:41 - INFO - __main__ - Step 720 Global step 720 Train loss 0.07 on epoch=179
06/10/2022 17:17:43 - INFO - __main__ - Step 730 Global step 730 Train loss 0.10 on epoch=182
06/10/2022 17:17:45 - INFO - __main__ - Step 740 Global step 740 Train loss 0.10 on epoch=184
06/10/2022 17:17:48 - INFO - __main__ - Step 750 Global step 750 Train loss 0.07 on epoch=187
06/10/2022 17:17:49 - INFO - __main__ - Global step 750 Train loss 0.08 Classification-F1 0.6425438596491229 on epoch=187
06/10/2022 17:17:51 - INFO - __main__ - Step 760 Global step 760 Train loss 0.11 on epoch=189
06/10/2022 17:17:53 - INFO - __main__ - Step 770 Global step 770 Train loss 0.07 on epoch=192
06/10/2022 17:17:56 - INFO - __main__ - Step 780 Global step 780 Train loss 0.09 on epoch=194
06/10/2022 17:17:58 - INFO - __main__ - Step 790 Global step 790 Train loss 0.05 on epoch=197
06/10/2022 17:18:00 - INFO - __main__ - Step 800 Global step 800 Train loss 0.06 on epoch=199
06/10/2022 17:18:01 - INFO - __main__ - Global step 800 Train loss 0.08 Classification-F1 0.6610052134245683 on epoch=199
06/10/2022 17:18:04 - INFO - __main__ - Step 810 Global step 810 Train loss 0.08 on epoch=202
06/10/2022 17:18:06 - INFO - __main__ - Step 820 Global step 820 Train loss 0.07 on epoch=204
06/10/2022 17:18:08 - INFO - __main__ - Step 830 Global step 830 Train loss 0.06 on epoch=207
06/10/2022 17:18:11 - INFO - __main__ - Step 840 Global step 840 Train loss 0.05 on epoch=209
06/10/2022 17:18:13 - INFO - __main__ - Step 850 Global step 850 Train loss 0.05 on epoch=212
06/10/2022 17:18:14 - INFO - __main__ - Global step 850 Train loss 0.06 Classification-F1 0.6517301317810655 on epoch=212
06/10/2022 17:18:16 - INFO - __main__ - Step 860 Global step 860 Train loss 0.04 on epoch=214
06/10/2022 17:18:19 - INFO - __main__ - Step 870 Global step 870 Train loss 0.06 on epoch=217
06/10/2022 17:18:21 - INFO - __main__ - Step 880 Global step 880 Train loss 0.02 on epoch=219
06/10/2022 17:18:23 - INFO - __main__ - Step 890 Global step 890 Train loss 0.03 on epoch=222
06/10/2022 17:18:26 - INFO - __main__ - Step 900 Global step 900 Train loss 0.04 on epoch=224
06/10/2022 17:18:27 - INFO - __main__ - Global step 900 Train loss 0.04 Classification-F1 0.7033045273534404 on epoch=224
06/10/2022 17:18:27 - INFO - __main__ - Saving model with best Classification-F1: 0.6752525252525253 -> 0.7033045273534404 on epoch=224, global_step=900
06/10/2022 17:18:29 - INFO - __main__ - Step 910 Global step 910 Train loss 0.05 on epoch=227
06/10/2022 17:18:32 - INFO - __main__ - Step 920 Global step 920 Train loss 0.07 on epoch=229
06/10/2022 17:18:34 - INFO - __main__ - Step 930 Global step 930 Train loss 0.04 on epoch=232
06/10/2022 17:18:36 - INFO - __main__ - Step 940 Global step 940 Train loss 0.02 on epoch=234
06/10/2022 17:18:39 - INFO - __main__ - Step 950 Global step 950 Train loss 0.06 on epoch=237
06/10/2022 17:18:40 - INFO - __main__ - Global step 950 Train loss 0.05 Classification-F1 0.6664338210390842 on epoch=237
06/10/2022 17:18:42 - INFO - __main__ - Step 960 Global step 960 Train loss 0.04 on epoch=239
06/10/2022 17:18:44 - INFO - __main__ - Step 970 Global step 970 Train loss 0.05 on epoch=242
06/10/2022 17:18:47 - INFO - __main__ - Step 980 Global step 980 Train loss 0.04 on epoch=244
06/10/2022 17:18:49 - INFO - __main__ - Step 990 Global step 990 Train loss 0.05 on epoch=247
06/10/2022 17:18:51 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.01 on epoch=249
06/10/2022 17:18:52 - INFO - __main__ - Global step 1000 Train loss 0.04 Classification-F1 0.680783397888661 on epoch=249
06/10/2022 17:18:55 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.01 on epoch=252
06/10/2022 17:18:57 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.10 on epoch=254
06/10/2022 17:18:59 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.03 on epoch=257
06/10/2022 17:19:02 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.02 on epoch=259
06/10/2022 17:19:04 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.04 on epoch=262
06/10/2022 17:19:05 - INFO - __main__ - Global step 1050 Train loss 0.04 Classification-F1 0.6810170587759722 on epoch=262
06/10/2022 17:19:07 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.02 on epoch=264
06/10/2022 17:19:10 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.01 on epoch=267
06/10/2022 17:19:12 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.03 on epoch=269
06/10/2022 17:19:14 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.05 on epoch=272
06/10/2022 17:19:17 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.05 on epoch=274
06/10/2022 17:19:18 - INFO - __main__ - Global step 1100 Train loss 0.03 Classification-F1 0.7042547182349814 on epoch=274
06/10/2022 17:19:18 - INFO - __main__ - Saving model with best Classification-F1: 0.7033045273534404 -> 0.7042547182349814 on epoch=274, global_step=1100
06/10/2022 17:19:20 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.04 on epoch=277
06/10/2022 17:19:22 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.02 on epoch=279
06/10/2022 17:19:25 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.07 on epoch=282
06/10/2022 17:19:27 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.01 on epoch=284
06/10/2022 17:19:29 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.02 on epoch=287
06/10/2022 17:19:30 - INFO - __main__ - Global step 1150 Train loss 0.03 Classification-F1 0.7042547182349814 on epoch=287
06/10/2022 17:19:33 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.09 on epoch=289
06/10/2022 17:19:35 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.03 on epoch=292
06/10/2022 17:19:38 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.03 on epoch=294
06/10/2022 17:19:40 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.08 on epoch=297
06/10/2022 17:19:42 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=299
06/10/2022 17:19:43 - INFO - __main__ - Global step 1200 Train loss 0.05 Classification-F1 0.7042547182349814 on epoch=299
06/10/2022 17:19:46 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.01 on epoch=302
06/10/2022 17:19:48 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.04 on epoch=304
06/10/2022 17:19:50 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.15 on epoch=307
06/10/2022 17:19:53 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.10 on epoch=309
06/10/2022 17:19:55 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.09 on epoch=312
06/10/2022 17:19:56 - INFO - __main__ - Global step 1250 Train loss 0.08 Classification-F1 0.6755913568399727 on epoch=312
06/10/2022 17:19:58 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=314
06/10/2022 17:20:01 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.02 on epoch=317
06/10/2022 17:20:03 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=319
06/10/2022 17:20:05 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.07 on epoch=322
06/10/2022 17:20:08 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.02 on epoch=324
06/10/2022 17:20:09 - INFO - __main__ - Global step 1300 Train loss 0.03 Classification-F1 0.6665701415701416 on epoch=324
06/10/2022 17:20:11 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=327
06/10/2022 17:20:13 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.04 on epoch=329
06/10/2022 17:20:16 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.02 on epoch=332
06/10/2022 17:20:18 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.06 on epoch=334
06/10/2022 17:20:20 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.02 on epoch=337
06/10/2022 17:20:21 - INFO - __main__ - Global step 1350 Train loss 0.03 Classification-F1 0.7033117389653892 on epoch=337
06/10/2022 17:20:24 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=339
06/10/2022 17:20:26 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.02 on epoch=342
06/10/2022 17:20:28 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=344
06/10/2022 17:20:31 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=347
06/10/2022 17:20:33 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=349
06/10/2022 17:20:34 - INFO - __main__ - Global step 1400 Train loss 0.01 Classification-F1 0.7033117389653892 on epoch=349
06/10/2022 17:20:36 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.03 on epoch=352
06/10/2022 17:20:39 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.01 on epoch=354
06/10/2022 17:20:41 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.03 on epoch=357
06/10/2022 17:20:43 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=359
06/10/2022 17:20:46 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=362
06/10/2022 17:20:47 - INFO - __main__ - Global step 1450 Train loss 0.02 Classification-F1 0.6702375762859634 on epoch=362
06/10/2022 17:20:49 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=364
06/10/2022 17:20:51 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=367
06/10/2022 17:20:54 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=369
06/10/2022 17:20:56 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.05 on epoch=372
06/10/2022 17:20:58 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=374
06/10/2022 17:20:59 - INFO - __main__ - Global step 1500 Train loss 0.02 Classification-F1 0.6572460928997432 on epoch=374
06/10/2022 17:21:02 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.03 on epoch=377
06/10/2022 17:21:04 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.02 on epoch=379
06/10/2022 17:21:06 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=382
06/10/2022 17:21:09 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=384
06/10/2022 17:21:11 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.04 on epoch=387
06/10/2022 17:21:12 - INFO - __main__ - Global step 1550 Train loss 0.02 Classification-F1 0.6854531001589824 on epoch=387
06/10/2022 17:21:14 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=389
06/10/2022 17:21:17 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.07 on epoch=392
06/10/2022 17:21:19 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=394
06/10/2022 17:21:21 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=397
06/10/2022 17:21:24 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=399
06/10/2022 17:21:25 - INFO - __main__ - Global step 1600 Train loss 0.02 Classification-F1 0.6752525252525253 on epoch=399
06/10/2022 17:21:27 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=402
06/10/2022 17:21:29 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=404
06/10/2022 17:21:32 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=407
06/10/2022 17:21:34 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=409
06/10/2022 17:21:36 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=412
06/10/2022 17:21:37 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.7042547182349814 on epoch=412
06/10/2022 17:21:40 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.03 on epoch=414
06/10/2022 17:21:42 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=417
06/10/2022 17:21:44 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=419
06/10/2022 17:21:47 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=422
06/10/2022 17:21:49 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=424
06/10/2022 17:21:50 - INFO - __main__ - Global step 1700 Train loss 0.01 Classification-F1 0.731951871657754 on epoch=424
06/10/2022 17:21:50 - INFO - __main__ - Saving model with best Classification-F1: 0.7042547182349814 -> 0.731951871657754 on epoch=424, global_step=1700
06/10/2022 17:21:53 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=427
06/10/2022 17:21:55 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=429
06/10/2022 17:21:57 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=432
06/10/2022 17:22:00 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=434
06/10/2022 17:22:02 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.07 on epoch=437
06/10/2022 17:22:03 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.731951871657754 on epoch=437
06/10/2022 17:22:05 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=439
06/10/2022 17:22:08 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=442
06/10/2022 17:22:10 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=444
06/10/2022 17:22:12 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=447
06/10/2022 17:22:15 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=449
06/10/2022 17:22:16 - INFO - __main__ - Global step 1800 Train loss 0.00 Classification-F1 0.6899547585031457 on epoch=449
06/10/2022 17:22:18 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=452
06/10/2022 17:22:20 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=454
06/10/2022 17:22:23 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=457
06/10/2022 17:22:25 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=459
06/10/2022 17:22:27 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.06 on epoch=462
06/10/2022 17:22:28 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.6881180223285487 on epoch=462
06/10/2022 17:22:31 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=464
06/10/2022 17:22:33 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.04 on epoch=467
06/10/2022 17:22:35 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=469
06/10/2022 17:22:38 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=472
06/10/2022 17:22:40 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.08 on epoch=474
06/10/2022 17:22:41 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.7326275473334296 on epoch=474
06/10/2022 17:22:41 - INFO - __main__ - Saving model with best Classification-F1: 0.731951871657754 -> 0.7326275473334296 on epoch=474, global_step=1900
06/10/2022 17:22:43 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=477
06/10/2022 17:22:46 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=479
06/10/2022 17:22:48 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=482
06/10/2022 17:22:50 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=484
06/10/2022 17:22:53 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=487
06/10/2022 17:22:54 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.7186049686049686 on epoch=487
06/10/2022 17:22:56 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=489
06/10/2022 17:22:59 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=492
06/10/2022 17:23:01 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=494
06/10/2022 17:23:03 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=497
06/10/2022 17:23:06 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=499
06/10/2022 17:23:07 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.7466748937337173 on epoch=499
06/10/2022 17:23:07 - INFO - __main__ - Saving model with best Classification-F1: 0.7326275473334296 -> 0.7466748937337173 on epoch=499, global_step=2000
06/10/2022 17:23:09 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=502
06/10/2022 17:23:11 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
06/10/2022 17:23:14 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=507
06/10/2022 17:23:16 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=509
06/10/2022 17:23:19 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/10/2022 17:23:19 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.696104242979243 on epoch=512
06/10/2022 17:23:22 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=514
06/10/2022 17:23:24 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=517
06/10/2022 17:23:26 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=519
06/10/2022 17:23:29 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=522
06/10/2022 17:23:31 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/10/2022 17:23:32 - INFO - __main__ - Global step 2100 Train loss 0.00 Classification-F1 0.7250053867700927 on epoch=524
06/10/2022 17:23:34 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
06/10/2022 17:23:37 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/10/2022 17:23:39 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=532
06/10/2022 17:23:41 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
06/10/2022 17:23:44 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=537
06/10/2022 17:23:45 - INFO - __main__ - Global step 2150 Train loss 0.00 Classification-F1 0.7245511841100077 on epoch=537
06/10/2022 17:23:47 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/10/2022 17:23:49 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=542
06/10/2022 17:23:52 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/10/2022 17:23:54 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/10/2022 17:23:56 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=549
06/10/2022 17:23:57 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.7234765234765235 on epoch=549
06/10/2022 17:24:00 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=552
06/10/2022 17:24:02 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/10/2022 17:24:05 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
06/10/2022 17:24:07 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=559
06/10/2022 17:24:10 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/10/2022 17:24:11 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.7245511841100077 on epoch=562
06/10/2022 17:24:13 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=564
06/10/2022 17:24:15 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/10/2022 17:24:18 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=569
06/10/2022 17:24:20 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/10/2022 17:24:22 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=574
06/10/2022 17:24:23 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.709672619047619 on epoch=574
06/10/2022 17:24:26 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.07 on epoch=577
06/10/2022 17:24:28 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/10/2022 17:24:31 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/10/2022 17:24:33 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/10/2022 17:24:35 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/10/2022 17:24:36 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.7106560106560106 on epoch=587
06/10/2022 17:24:39 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=589
06/10/2022 17:24:41 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/10/2022 17:24:43 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/10/2022 17:24:46 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/10/2022 17:24:48 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/10/2022 17:24:49 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.7106560106560106 on epoch=599
06/10/2022 17:24:51 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=602
06/10/2022 17:24:53 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=604
06/10/2022 17:24:56 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/10/2022 17:24:58 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=609
06/10/2022 17:25:01 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=612
06/10/2022 17:25:01 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.7392570664629489 on epoch=612
06/10/2022 17:25:04 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/10/2022 17:25:06 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=617
06/10/2022 17:25:09 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=619
06/10/2022 17:25:11 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=622
06/10/2022 17:25:13 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/10/2022 17:25:14 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.709672619047619 on epoch=624
06/10/2022 17:25:16 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.08 on epoch=627
06/10/2022 17:25:19 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/10/2022 17:25:21 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.04 on epoch=632
06/10/2022 17:25:24 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/10/2022 17:25:26 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/10/2022 17:25:27 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.7033117389653892 on epoch=637
06/10/2022 17:25:29 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=639
06/10/2022 17:25:32 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.04 on epoch=642
06/10/2022 17:25:34 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=644
06/10/2022 17:25:36 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/10/2022 17:25:39 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/10/2022 17:25:39 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.6959349130401763 on epoch=649
06/10/2022 17:25:42 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/10/2022 17:25:44 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/10/2022 17:25:46 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/10/2022 17:25:49 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=659
06/10/2022 17:25:51 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=662
06/10/2022 17:25:52 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.7182295932295932 on epoch=662
06/10/2022 17:25:54 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/10/2022 17:25:57 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/10/2022 17:25:59 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/10/2022 17:26:01 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=672
06/10/2022 17:26:04 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/10/2022 17:26:05 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.7182295932295932 on epoch=674
06/10/2022 17:26:07 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=677
06/10/2022 17:26:09 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/10/2022 17:26:12 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/10/2022 17:26:14 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/10/2022 17:26:16 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.03 on epoch=687
06/10/2022 17:26:17 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.7039459561198691 on epoch=687
06/10/2022 17:26:20 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/10/2022 17:26:22 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/10/2022 17:26:25 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.04 on epoch=694
06/10/2022 17:26:27 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/10/2022 17:26:29 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/10/2022 17:26:30 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.7178751641667243 on epoch=699
06/10/2022 17:26:33 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=702
06/10/2022 17:26:35 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/10/2022 17:26:37 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/10/2022 17:26:40 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/10/2022 17:26:42 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/10/2022 17:26:43 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.732695374800638 on epoch=712
06/10/2022 17:26:45 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=714
06/10/2022 17:26:48 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/10/2022 17:26:50 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/10/2022 17:26:52 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/10/2022 17:26:55 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/10/2022 17:26:56 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.7179429916339325 on epoch=724
06/10/2022 17:26:58 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/10/2022 17:27:00 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/10/2022 17:27:03 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/10/2022 17:27:05 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/10/2022 17:27:07 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.03 on epoch=737
06/10/2022 17:27:08 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.7106560106560106 on epoch=737
06/10/2022 17:27:11 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/10/2022 17:27:13 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/10/2022 17:27:15 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/10/2022 17:27:18 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=747
06/10/2022 17:27:20 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/10/2022 17:27:21 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.7102272727272728 on epoch=749
06/10/2022 17:27:21 - INFO - __main__ - save last model!
06/10/2022 17:27:21 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/10/2022 17:27:21 - INFO - __main__ - Start tokenizing ... 5509 instances
06/10/2022 17:27:21 - INFO - __main__ - Printing 3 examples
06/10/2022 17:27:21 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/10/2022 17:27:21 - INFO - __main__ - ['others']
06/10/2022 17:27:21 - INFO - __main__ -  [emo] what you like very little things ok
06/10/2022 17:27:21 - INFO - __main__ - ['others']
06/10/2022 17:27:21 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/10/2022 17:27:21 - INFO - __main__ - ['others']
06/10/2022 17:27:21 - INFO - __main__ - Tokenizing Input ...
06/10/2022 17:27:21 - INFO - __main__ - Start tokenizing ... 64 instances
06/10/2022 17:27:21 - INFO - __main__ - Printing 3 examples
06/10/2022 17:27:21 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/10/2022 17:27:21 - INFO - __main__ - ['sad']
06/10/2022 17:27:21 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/10/2022 17:27:21 - INFO - __main__ - ['sad']
06/10/2022 17:27:21 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/10/2022 17:27:21 - INFO - __main__ - ['sad']
06/10/2022 17:27:21 - INFO - __main__ - Tokenizing Input ...
06/10/2022 17:27:21 - INFO - __main__ - Tokenizing Output ...
06/10/2022 17:27:21 - INFO - __main__ - Loaded 64 examples from train data
06/10/2022 17:27:21 - INFO - __main__ - Start tokenizing ... 64 instances
06/10/2022 17:27:22 - INFO - __main__ - Printing 3 examples
06/10/2022 17:27:22 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
06/10/2022 17:27:22 - INFO - __main__ - ['sad']
06/10/2022 17:27:22 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
06/10/2022 17:27:22 - INFO - __main__ - ['sad']
06/10/2022 17:27:22 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
06/10/2022 17:27:22 - INFO - __main__ - ['sad']
06/10/2022 17:27:22 - INFO - __main__ - Tokenizing Input ...
06/10/2022 17:27:22 - INFO - __main__ - Tokenizing Output ...
06/10/2022 17:27:22 - INFO - __main__ - Loaded 64 examples from dev data
06/10/2022 17:27:23 - INFO - __main__ - Tokenizing Output ...
06/10/2022 17:27:29 - INFO - __main__ - Loaded 5509 examples from test data
06/10/2022 17:27:37 - INFO - __main__ - load prompt embedding from ckpt
06/10/2022 17:27:38 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/10/2022 17:27:38 - INFO - __main__ - Starting training!
06/10/2022 17:29:03 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-up32shot/singletask-emo/emo_16_21_0.4_8_predictions.txt
06/10/2022 17:29:03 - INFO - __main__ - Classification-F1 on test data: 0.1690
06/10/2022 17:29:03 - INFO - __main__ - prefix=emo_16_21, lr=0.4, bsz=8, dev_performance=0.7466748937337173, test_performance=0.16895084829046764
06/10/2022 17:29:03 - INFO - __main__ - Running ... prefix=emo_16_21, lr=0.3, bsz=8 ...
06/10/2022 17:29:04 - INFO - __main__ - Start tokenizing ... 64 instances
06/10/2022 17:29:04 - INFO - __main__ - Printing 3 examples
06/10/2022 17:29:04 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/10/2022 17:29:04 - INFO - __main__ - ['sad']
06/10/2022 17:29:04 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/10/2022 17:29:04 - INFO - __main__ - ['sad']
06/10/2022 17:29:04 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/10/2022 17:29:04 - INFO - __main__ - ['sad']
06/10/2022 17:29:04 - INFO - __main__ - Tokenizing Input ...
06/10/2022 17:29:04 - INFO - __main__ - Tokenizing Output ...
06/10/2022 17:29:04 - INFO - __main__ - Loaded 64 examples from train data
06/10/2022 17:29:04 - INFO - __main__ - Start tokenizing ... 64 instances
06/10/2022 17:29:04 - INFO - __main__ - Printing 3 examples
06/10/2022 17:29:04 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
06/10/2022 17:29:04 - INFO - __main__ - ['sad']
06/10/2022 17:29:04 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
06/10/2022 17:29:04 - INFO - __main__ - ['sad']
06/10/2022 17:29:04 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
06/10/2022 17:29:04 - INFO - __main__ - ['sad']
06/10/2022 17:29:04 - INFO - __main__ - Tokenizing Input ...
06/10/2022 17:29:04 - INFO - __main__ - Tokenizing Output ...
06/10/2022 17:29:04 - INFO - __main__ - Loaded 64 examples from dev data
06/10/2022 17:29:20 - INFO - __main__ - load prompt embedding from ckpt
06/10/2022 17:29:20 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/10/2022 17:29:20 - INFO - __main__ - Starting training!
06/10/2022 17:29:23 - INFO - __main__ - Step 10 Global step 10 Train loss 4.08 on epoch=2
06/10/2022 17:29:26 - INFO - __main__ - Step 20 Global step 20 Train loss 3.35 on epoch=4
06/10/2022 17:29:28 - INFO - __main__ - Step 30 Global step 30 Train loss 2.57 on epoch=7
06/10/2022 17:29:30 - INFO - __main__ - Step 40 Global step 40 Train loss 2.05 on epoch=9
06/10/2022 17:29:33 - INFO - __main__ - Step 50 Global step 50 Train loss 1.62 on epoch=12
06/10/2022 17:29:34 - INFO - __main__ - Global step 50 Train loss 2.73 Classification-F1 0.09585253456221199 on epoch=12
06/10/2022 17:29:34 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.09585253456221199 on epoch=12, global_step=50
06/10/2022 17:29:36 - INFO - __main__ - Step 60 Global step 60 Train loss 1.28 on epoch=14
06/10/2022 17:29:38 - INFO - __main__ - Step 70 Global step 70 Train loss 1.21 on epoch=17
06/10/2022 17:29:41 - INFO - __main__ - Step 80 Global step 80 Train loss 1.01 on epoch=19
06/10/2022 17:29:43 - INFO - __main__ - Step 90 Global step 90 Train loss 0.84 on epoch=22
06/10/2022 17:29:45 - INFO - __main__ - Step 100 Global step 100 Train loss 0.74 on epoch=24
06/10/2022 17:29:46 - INFO - __main__ - Global step 100 Train loss 1.01 Classification-F1 0.5319370172311348 on epoch=24
06/10/2022 17:29:46 - INFO - __main__ - Saving model with best Classification-F1: 0.09585253456221199 -> 0.5319370172311348 on epoch=24, global_step=100
06/10/2022 17:29:49 - INFO - __main__ - Step 110 Global step 110 Train loss 0.71 on epoch=27
06/10/2022 17:29:51 - INFO - __main__ - Step 120 Global step 120 Train loss 0.69 on epoch=29
06/10/2022 17:29:54 - INFO - __main__ - Step 130 Global step 130 Train loss 0.65 on epoch=32
06/10/2022 17:29:56 - INFO - __main__ - Step 140 Global step 140 Train loss 0.61 on epoch=34
06/10/2022 17:29:58 - INFO - __main__ - Step 150 Global step 150 Train loss 0.54 on epoch=37
06/10/2022 17:29:59 - INFO - __main__ - Global step 150 Train loss 0.64 Classification-F1 0.5626603876603877 on epoch=37
06/10/2022 17:29:59 - INFO - __main__ - Saving model with best Classification-F1: 0.5319370172311348 -> 0.5626603876603877 on epoch=37, global_step=150
06/10/2022 17:30:02 - INFO - __main__ - Step 160 Global step 160 Train loss 0.45 on epoch=39
06/10/2022 17:30:04 - INFO - __main__ - Step 170 Global step 170 Train loss 0.50 on epoch=42
06/10/2022 17:30:06 - INFO - __main__ - Step 180 Global step 180 Train loss 0.45 on epoch=44
06/10/2022 17:30:09 - INFO - __main__ - Step 190 Global step 190 Train loss 0.46 on epoch=47
06/10/2022 17:30:11 - INFO - __main__ - Step 200 Global step 200 Train loss 0.46 on epoch=49
06/10/2022 17:30:12 - INFO - __main__ - Global step 200 Train loss 0.46 Classification-F1 0.5905819326871958 on epoch=49
06/10/2022 17:30:12 - INFO - __main__ - Saving model with best Classification-F1: 0.5626603876603877 -> 0.5905819326871958 on epoch=49, global_step=200
06/10/2022 17:30:15 - INFO - __main__ - Step 210 Global step 210 Train loss 0.53 on epoch=52
06/10/2022 17:30:17 - INFO - __main__ - Step 220 Global step 220 Train loss 0.55 on epoch=54
06/10/2022 17:30:19 - INFO - __main__ - Step 230 Global step 230 Train loss 0.53 on epoch=57
06/10/2022 17:30:22 - INFO - __main__ - Step 240 Global step 240 Train loss 0.49 on epoch=59
06/10/2022 17:30:24 - INFO - __main__ - Step 250 Global step 250 Train loss 0.43 on epoch=62
06/10/2022 17:30:25 - INFO - __main__ - Global step 250 Train loss 0.51 Classification-F1 0.666933066933067 on epoch=62
06/10/2022 17:30:25 - INFO - __main__ - Saving model with best Classification-F1: 0.5905819326871958 -> 0.666933066933067 on epoch=62, global_step=250
06/10/2022 17:30:27 - INFO - __main__ - Step 260 Global step 260 Train loss 0.44 on epoch=64
06/10/2022 17:30:30 - INFO - __main__ - Step 270 Global step 270 Train loss 0.36 on epoch=67
06/10/2022 17:30:32 - INFO - __main__ - Step 280 Global step 280 Train loss 0.42 on epoch=69
06/10/2022 17:30:35 - INFO - __main__ - Step 290 Global step 290 Train loss 0.44 on epoch=72
06/10/2022 17:30:37 - INFO - __main__ - Step 300 Global step 300 Train loss 0.35 on epoch=74
06/10/2022 17:30:38 - INFO - __main__ - Global step 300 Train loss 0.40 Classification-F1 0.6661518661518662 on epoch=74
06/10/2022 17:30:40 - INFO - __main__ - Step 310 Global step 310 Train loss 0.44 on epoch=77
06/10/2022 17:30:43 - INFO - __main__ - Step 320 Global step 320 Train loss 0.30 on epoch=79
06/10/2022 17:30:45 - INFO - __main__ - Step 330 Global step 330 Train loss 0.36 on epoch=82
06/10/2022 17:30:47 - INFO - __main__ - Step 340 Global step 340 Train loss 0.37 on epoch=84
06/10/2022 17:30:50 - INFO - __main__ - Step 350 Global step 350 Train loss 0.35 on epoch=87
06/10/2022 17:30:50 - INFO - __main__ - Global step 350 Train loss 0.36 Classification-F1 0.6661518661518662 on epoch=87
06/10/2022 17:30:53 - INFO - __main__ - Step 360 Global step 360 Train loss 0.31 on epoch=89
06/10/2022 17:30:55 - INFO - __main__ - Step 370 Global step 370 Train loss 0.34 on epoch=92
06/10/2022 17:30:57 - INFO - __main__ - Step 380 Global step 380 Train loss 0.33 on epoch=94
06/10/2022 17:31:00 - INFO - __main__ - Step 390 Global step 390 Train loss 0.29 on epoch=97
06/10/2022 17:31:02 - INFO - __main__ - Step 400 Global step 400 Train loss 0.22 on epoch=99
06/10/2022 17:31:03 - INFO - __main__ - Global step 400 Train loss 0.30 Classification-F1 0.6386272526319734 on epoch=99
06/10/2022 17:31:05 - INFO - __main__ - Step 410 Global step 410 Train loss 0.34 on epoch=102
06/10/2022 17:31:08 - INFO - __main__ - Step 420 Global step 420 Train loss 0.32 on epoch=104
06/10/2022 17:31:10 - INFO - __main__ - Step 430 Global step 430 Train loss 0.29 on epoch=107
06/10/2022 17:31:12 - INFO - __main__ - Step 440 Global step 440 Train loss 0.32 on epoch=109
06/10/2022 17:31:15 - INFO - __main__ - Step 450 Global step 450 Train loss 0.35 on epoch=112
06/10/2022 17:31:16 - INFO - __main__ - Global step 450 Train loss 0.32 Classification-F1 0.638961038961039 on epoch=112
06/10/2022 17:31:18 - INFO - __main__ - Step 460 Global step 460 Train loss 0.24 on epoch=114
06/10/2022 17:31:20 - INFO - __main__ - Step 470 Global step 470 Train loss 0.31 on epoch=117
06/10/2022 17:31:23 - INFO - __main__ - Step 480 Global step 480 Train loss 0.26 on epoch=119
06/10/2022 17:31:25 - INFO - __main__ - Step 490 Global step 490 Train loss 0.32 on epoch=122
06/10/2022 17:31:27 - INFO - __main__ - Step 500 Global step 500 Train loss 0.29 on epoch=124
06/10/2022 17:31:28 - INFO - __main__ - Global step 500 Train loss 0.28 Classification-F1 0.638961038961039 on epoch=124
06/10/2022 17:31:31 - INFO - __main__ - Step 510 Global step 510 Train loss 0.26 on epoch=127
06/10/2022 17:31:33 - INFO - __main__ - Step 520 Global step 520 Train loss 0.21 on epoch=129
06/10/2022 17:31:35 - INFO - __main__ - Step 530 Global step 530 Train loss 0.26 on epoch=132
06/10/2022 17:31:38 - INFO - __main__ - Step 540 Global step 540 Train loss 0.22 on epoch=134
06/10/2022 17:31:40 - INFO - __main__ - Step 550 Global step 550 Train loss 0.21 on epoch=137
06/10/2022 17:31:41 - INFO - __main__ - Global step 550 Train loss 0.23 Classification-F1 0.6248511904761904 on epoch=137
06/10/2022 17:31:44 - INFO - __main__ - Step 560 Global step 560 Train loss 0.15 on epoch=139
06/10/2022 17:31:46 - INFO - __main__ - Step 570 Global step 570 Train loss 0.28 on epoch=142
06/10/2022 17:31:49 - INFO - __main__ - Step 580 Global step 580 Train loss 0.23 on epoch=144
06/10/2022 17:31:51 - INFO - __main__ - Step 590 Global step 590 Train loss 0.20 on epoch=147
06/10/2022 17:31:53 - INFO - __main__ - Step 600 Global step 600 Train loss 0.15 on epoch=149
06/10/2022 17:31:54 - INFO - __main__ - Global step 600 Train loss 0.20 Classification-F1 0.6264321306807539 on epoch=149
06/10/2022 17:31:56 - INFO - __main__ - Step 610 Global step 610 Train loss 0.19 on epoch=152
06/10/2022 17:31:59 - INFO - __main__ - Step 620 Global step 620 Train loss 0.27 on epoch=154
06/10/2022 17:32:01 - INFO - __main__ - Step 630 Global step 630 Train loss 0.13 on epoch=157
06/10/2022 17:32:04 - INFO - __main__ - Step 640 Global step 640 Train loss 0.16 on epoch=159
06/10/2022 17:32:06 - INFO - __main__ - Step 650 Global step 650 Train loss 0.20 on epoch=162
06/10/2022 17:32:07 - INFO - __main__ - Global step 650 Train loss 0.19 Classification-F1 0.6264321306807539 on epoch=162
06/10/2022 17:32:09 - INFO - __main__ - Step 660 Global step 660 Train loss 0.12 on epoch=164
06/10/2022 17:32:11 - INFO - __main__ - Step 670 Global step 670 Train loss 0.25 on epoch=167
06/10/2022 17:32:14 - INFO - __main__ - Step 680 Global step 680 Train loss 0.15 on epoch=169
06/10/2022 17:32:16 - INFO - __main__ - Step 690 Global step 690 Train loss 0.15 on epoch=172
06/10/2022 17:32:19 - INFO - __main__ - Step 700 Global step 700 Train loss 0.13 on epoch=174
06/10/2022 17:32:20 - INFO - __main__ - Global step 700 Train loss 0.16 Classification-F1 0.6248511904761904 on epoch=174
06/10/2022 17:32:22 - INFO - __main__ - Step 710 Global step 710 Train loss 0.13 on epoch=177
06/10/2022 17:32:24 - INFO - __main__ - Step 720 Global step 720 Train loss 0.11 on epoch=179
06/10/2022 17:32:27 - INFO - __main__ - Step 730 Global step 730 Train loss 0.09 on epoch=182
06/10/2022 17:32:29 - INFO - __main__ - Step 740 Global step 740 Train loss 0.17 on epoch=184
06/10/2022 17:32:31 - INFO - __main__ - Step 750 Global step 750 Train loss 0.11 on epoch=187
06/10/2022 17:32:32 - INFO - __main__ - Global step 750 Train loss 0.12 Classification-F1 0.6264321306807539 on epoch=187
06/10/2022 17:32:35 - INFO - __main__ - Step 760 Global step 760 Train loss 0.12 on epoch=189
06/10/2022 17:32:37 - INFO - __main__ - Step 770 Global step 770 Train loss 0.16 on epoch=192
06/10/2022 17:32:39 - INFO - __main__ - Step 780 Global step 780 Train loss 0.12 on epoch=194
06/10/2022 17:32:42 - INFO - __main__ - Step 790 Global step 790 Train loss 0.13 on epoch=197
06/10/2022 17:32:44 - INFO - __main__ - Step 800 Global step 800 Train loss 0.17 on epoch=199
06/10/2022 17:32:45 - INFO - __main__ - Global step 800 Train loss 0.14 Classification-F1 0.5043164362519201 on epoch=199
06/10/2022 17:32:47 - INFO - __main__ - Step 810 Global step 810 Train loss 0.10 on epoch=202
06/10/2022 17:32:50 - INFO - __main__ - Step 820 Global step 820 Train loss 0.11 on epoch=204
06/10/2022 17:32:52 - INFO - __main__ - Step 830 Global step 830 Train loss 0.16 on epoch=207
06/10/2022 17:32:54 - INFO - __main__ - Step 840 Global step 840 Train loss 0.13 on epoch=209
06/10/2022 17:32:57 - INFO - __main__ - Step 850 Global step 850 Train loss 0.10 on epoch=212
06/10/2022 17:32:58 - INFO - __main__ - Global step 850 Train loss 0.12 Classification-F1 0.6264321306807539 on epoch=212
06/10/2022 17:33:00 - INFO - __main__ - Step 860 Global step 860 Train loss 0.11 on epoch=214
06/10/2022 17:33:02 - INFO - __main__ - Step 870 Global step 870 Train loss 0.12 on epoch=217
06/10/2022 17:33:05 - INFO - __main__ - Step 880 Global step 880 Train loss 0.07 on epoch=219
06/10/2022 17:33:07 - INFO - __main__ - Step 890 Global step 890 Train loss 0.17 on epoch=222
06/10/2022 17:33:09 - INFO - __main__ - Step 900 Global step 900 Train loss 0.10 on epoch=224
06/10/2022 17:33:10 - INFO - __main__ - Global step 900 Train loss 0.12 Classification-F1 0.6264321306807539 on epoch=224
06/10/2022 17:33:13 - INFO - __main__ - Step 910 Global step 910 Train loss 0.06 on epoch=227
06/10/2022 17:33:15 - INFO - __main__ - Step 920 Global step 920 Train loss 0.11 on epoch=229
06/10/2022 17:33:17 - INFO - __main__ - Step 930 Global step 930 Train loss 0.07 on epoch=232
06/10/2022 17:33:20 - INFO - __main__ - Step 940 Global step 940 Train loss 0.06 on epoch=234
06/10/2022 17:33:22 - INFO - __main__ - Step 950 Global step 950 Train loss 0.05 on epoch=237
06/10/2022 17:33:23 - INFO - __main__ - Global step 950 Train loss 0.07 Classification-F1 0.6264321306807539 on epoch=237
06/10/2022 17:33:25 - INFO - __main__ - Step 960 Global step 960 Train loss 0.08 on epoch=239
06/10/2022 17:33:28 - INFO - __main__ - Step 970 Global step 970 Train loss 0.10 on epoch=242
06/10/2022 17:33:30 - INFO - __main__ - Step 980 Global step 980 Train loss 0.05 on epoch=244
06/10/2022 17:33:32 - INFO - __main__ - Step 990 Global step 990 Train loss 0.08 on epoch=247
06/10/2022 17:33:35 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.12 on epoch=249
06/10/2022 17:33:36 - INFO - __main__ - Global step 1000 Train loss 0.08 Classification-F1 0.6155950305143852 on epoch=249
06/10/2022 17:33:38 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.03 on epoch=252
06/10/2022 17:33:40 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.11 on epoch=254
06/10/2022 17:33:43 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.05 on epoch=257
06/10/2022 17:33:45 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.10 on epoch=259
06/10/2022 17:33:48 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.06 on epoch=262
06/10/2022 17:33:49 - INFO - __main__ - Global step 1050 Train loss 0.07 Classification-F1 0.6026226068712299 on epoch=262
06/10/2022 17:33:51 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.04 on epoch=264
06/10/2022 17:33:53 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.06 on epoch=267
06/10/2022 17:33:56 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.05 on epoch=269
06/10/2022 17:33:58 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.10 on epoch=272
06/10/2022 17:34:00 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.02 on epoch=274
06/10/2022 17:34:01 - INFO - __main__ - Global step 1100 Train loss 0.06 Classification-F1 0.6404761904761904 on epoch=274
06/10/2022 17:34:04 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.11 on epoch=277
06/10/2022 17:34:06 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.04 on epoch=279
06/10/2022 17:34:09 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.04 on epoch=282
06/10/2022 17:34:11 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.05 on epoch=284
06/10/2022 17:34:13 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.02 on epoch=287
06/10/2022 17:34:14 - INFO - __main__ - Global step 1150 Train loss 0.05 Classification-F1 0.6619588744588745 on epoch=287
06/10/2022 17:34:17 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.07 on epoch=289
06/10/2022 17:34:19 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.10 on epoch=292
06/10/2022 17:34:21 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.05 on epoch=294
06/10/2022 17:34:24 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.07 on epoch=297
06/10/2022 17:34:26 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.06 on epoch=299
06/10/2022 17:34:27 - INFO - __main__ - Global step 1200 Train loss 0.07 Classification-F1 0.6264321306807539 on epoch=299
06/10/2022 17:34:29 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.06 on epoch=302
06/10/2022 17:34:32 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.12 on epoch=304
06/10/2022 17:34:34 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.09 on epoch=307
06/10/2022 17:34:36 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.04 on epoch=309
06/10/2022 17:34:39 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.08 on epoch=312
06/10/2022 17:34:40 - INFO - __main__ - Global step 1250 Train loss 0.08 Classification-F1 0.6395225294418843 on epoch=312
06/10/2022 17:34:42 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.05 on epoch=314
06/10/2022 17:34:44 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.08 on epoch=317
06/10/2022 17:34:47 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.03 on epoch=319
06/10/2022 17:34:49 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.02 on epoch=322
06/10/2022 17:34:51 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.03 on epoch=324
06/10/2022 17:34:52 - INFO - __main__ - Global step 1300 Train loss 0.04 Classification-F1 0.6395225294418843 on epoch=324
06/10/2022 17:34:55 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.06 on epoch=327
06/10/2022 17:34:57 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.02 on epoch=329
06/10/2022 17:35:00 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.05 on epoch=332
06/10/2022 17:35:02 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.04 on epoch=334
06/10/2022 17:35:04 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.03 on epoch=337
06/10/2022 17:35:05 - INFO - __main__ - Global step 1350 Train loss 0.04 Classification-F1 0.6026226068712299 on epoch=337
06/10/2022 17:35:08 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.06 on epoch=339
06/10/2022 17:35:10 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.10 on epoch=342
06/10/2022 17:35:12 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=344
06/10/2022 17:35:15 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.04 on epoch=347
06/10/2022 17:35:17 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.04 on epoch=349
06/10/2022 17:35:18 - INFO - __main__ - Global step 1400 Train loss 0.05 Classification-F1 0.6536682152535812 on epoch=349
06/10/2022 17:35:20 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.08 on epoch=352
06/10/2022 17:35:23 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.05 on epoch=354
06/10/2022 17:35:25 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=357
06/10/2022 17:35:27 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.09 on epoch=359
06/10/2022 17:35:30 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=362
06/10/2022 17:35:31 - INFO - __main__ - Global step 1450 Train loss 0.05 Classification-F1 0.6256336405529953 on epoch=362
06/10/2022 17:35:33 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=364
06/10/2022 17:35:35 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.02 on epoch=367
06/10/2022 17:35:38 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.05 on epoch=369
06/10/2022 17:35:40 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=372
06/10/2022 17:35:43 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.03 on epoch=374
06/10/2022 17:35:44 - INFO - __main__ - Global step 1500 Train loss 0.02 Classification-F1 0.6752525252525253 on epoch=374
06/10/2022 17:35:44 - INFO - __main__ - Saving model with best Classification-F1: 0.666933066933067 -> 0.6752525252525253 on epoch=374, global_step=1500
06/10/2022 17:35:46 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.07 on epoch=377
06/10/2022 17:35:48 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.02 on epoch=379
06/10/2022 17:35:51 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.08 on epoch=382
06/10/2022 17:35:53 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=384
06/10/2022 17:35:55 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.04 on epoch=387
06/10/2022 17:35:56 - INFO - __main__ - Global step 1550 Train loss 0.05 Classification-F1 0.6166666666666667 on epoch=387
06/10/2022 17:35:59 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.02 on epoch=389
06/10/2022 17:36:01 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=392
06/10/2022 17:36:03 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=394
06/10/2022 17:36:06 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.04 on epoch=397
06/10/2022 17:36:08 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.05 on epoch=399
06/10/2022 17:36:09 - INFO - __main__ - Global step 1600 Train loss 0.02 Classification-F1 0.6298423423423423 on epoch=399
06/10/2022 17:36:11 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=402
06/10/2022 17:36:14 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=404
06/10/2022 17:36:16 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.04 on epoch=407
06/10/2022 17:36:19 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.02 on epoch=409
06/10/2022 17:36:21 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=412
06/10/2022 17:36:22 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.6297407163260822 on epoch=412
06/10/2022 17:36:24 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.04 on epoch=414
06/10/2022 17:36:27 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=417
06/10/2022 17:36:29 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=419
06/10/2022 17:36:31 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.06 on epoch=422
06/10/2022 17:36:34 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=424
06/10/2022 17:36:35 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.6536682152535812 on epoch=424
06/10/2022 17:36:37 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=427
06/10/2022 17:36:39 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.05 on epoch=429
06/10/2022 17:36:42 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.04 on epoch=432
06/10/2022 17:36:44 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=434
06/10/2022 17:36:46 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=437
06/10/2022 17:36:47 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.6166666666666667 on epoch=437
06/10/2022 17:36:50 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=439
06/10/2022 17:36:52 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.05 on epoch=442
06/10/2022 17:36:54 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=444
06/10/2022 17:36:57 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.03 on epoch=447
06/10/2022 17:36:59 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=449
06/10/2022 17:37:00 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.6166666666666667 on epoch=449
06/10/2022 17:37:02 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=452
06/10/2022 17:37:05 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=454
06/10/2022 17:37:07 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.05 on epoch=457
06/10/2022 17:37:09 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=459
06/10/2022 17:37:12 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=462
06/10/2022 17:37:13 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.6166666666666667 on epoch=462
06/10/2022 17:37:15 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=464
06/10/2022 17:37:18 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=467
06/10/2022 17:37:20 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=469
06/10/2022 17:37:22 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.03 on epoch=472
06/10/2022 17:37:25 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=474
06/10/2022 17:37:26 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.6397793263646923 on epoch=474
06/10/2022 17:37:28 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=477
06/10/2022 17:37:30 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=479
06/10/2022 17:37:33 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=482
06/10/2022 17:37:35 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=484
06/10/2022 17:37:37 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.03 on epoch=487
06/10/2022 17:37:38 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.6678297755883963 on epoch=487
06/10/2022 17:37:41 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=489
06/10/2022 17:37:43 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=492
06/10/2022 17:37:45 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=494
06/10/2022 17:37:48 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=497
06/10/2022 17:37:50 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=499
06/10/2022 17:37:51 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.6904043872793872 on epoch=499
06/10/2022 17:37:51 - INFO - __main__ - Saving model with best Classification-F1: 0.6752525252525253 -> 0.6904043872793872 on epoch=499, global_step=2000
06/10/2022 17:37:54 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.07 on epoch=502
06/10/2022 17:37:56 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=504
06/10/2022 17:37:58 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.13 on epoch=507
06/10/2022 17:38:01 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=509
06/10/2022 17:38:03 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=512
06/10/2022 17:38:04 - INFO - __main__ - Global step 2050 Train loss 0.05 Classification-F1 0.6547562848900379 on epoch=512
06/10/2022 17:38:07 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=514
06/10/2022 17:38:09 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=517
06/10/2022 17:38:11 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/10/2022 17:38:14 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=522
06/10/2022 17:38:16 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=524
06/10/2022 17:38:17 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.676340594888982 on epoch=524
06/10/2022 17:38:19 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=527
06/10/2022 17:38:22 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=529
06/10/2022 17:38:24 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=532
06/10/2022 17:38:26 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.04 on epoch=534
06/10/2022 17:38:29 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=537
06/10/2022 17:38:30 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.6547562848900379 on epoch=537
06/10/2022 17:38:32 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.03 on epoch=539
06/10/2022 17:38:34 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=542
06/10/2022 17:38:37 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=544
06/10/2022 17:38:39 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=547
06/10/2022 17:38:42 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=549
06/10/2022 17:38:43 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.6547562848900379 on epoch=549
06/10/2022 17:38:45 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=552
06/10/2022 17:38:47 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=554
06/10/2022 17:38:50 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.06 on epoch=557
06/10/2022 17:38:52 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/10/2022 17:38:54 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/10/2022 17:38:56 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.676340594888982 on epoch=562
06/10/2022 17:38:58 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.03 on epoch=564
06/10/2022 17:39:00 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=567
06/10/2022 17:39:03 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=569
06/10/2022 17:39:05 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.03 on epoch=572
06/10/2022 17:39:07 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=574
06/10/2022 17:39:08 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.6404761904761904 on epoch=574
06/10/2022 17:39:11 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.04 on epoch=577
06/10/2022 17:39:13 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/10/2022 17:39:15 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=582
06/10/2022 17:39:18 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=584
06/10/2022 17:39:20 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=587
06/10/2022 17:39:21 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.676340594888982 on epoch=587
06/10/2022 17:39:23 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/10/2022 17:39:26 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=592
06/10/2022 17:39:28 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=594
06/10/2022 17:39:31 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=597
06/10/2022 17:39:33 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=599
06/10/2022 17:39:34 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.6899547585031457 on epoch=599
06/10/2022 17:39:36 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=602
06/10/2022 17:39:39 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/10/2022 17:39:41 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=607
06/10/2022 17:39:43 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=609
06/10/2022 17:39:46 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=612
06/10/2022 17:39:47 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.65426267281106 on epoch=612
06/10/2022 17:39:49 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=614
06/10/2022 17:39:52 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=617
06/10/2022 17:39:54 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.03 on epoch=619
06/10/2022 17:39:56 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=622
06/10/2022 17:39:59 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=624
06/10/2022 17:40:00 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.6677588613072485 on epoch=624
06/10/2022 17:40:02 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/10/2022 17:40:05 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=629
06/10/2022 17:40:07 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=632
06/10/2022 17:40:09 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=634
06/10/2022 17:40:12 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=637
06/10/2022 17:40:13 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.65426267281106 on epoch=637
06/10/2022 17:40:15 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=639
06/10/2022 17:40:17 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.05 on epoch=642
06/10/2022 17:40:20 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/10/2022 17:40:22 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/10/2022 17:40:24 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=649
06/10/2022 17:40:25 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.6309467610805141 on epoch=649
06/10/2022 17:40:28 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.05 on epoch=652
06/10/2022 17:40:30 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=654
06/10/2022 17:40:33 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/10/2022 17:40:35 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=659
06/10/2022 17:40:37 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=662
06/10/2022 17:40:38 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.65426267281106 on epoch=662
06/10/2022 17:40:41 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=664
06/10/2022 17:40:43 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/10/2022 17:40:45 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=669
06/10/2022 17:40:48 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=672
06/10/2022 17:40:50 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=674
06/10/2022 17:40:51 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.6677588613072485 on epoch=674
06/10/2022 17:40:53 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.04 on epoch=677
06/10/2022 17:40:56 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/10/2022 17:40:58 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=682
06/10/2022 17:41:00 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=684
06/10/2022 17:41:03 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/10/2022 17:41:04 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.6405180840664713 on epoch=687
06/10/2022 17:41:06 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=689
06/10/2022 17:41:09 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=692
06/10/2022 17:41:11 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=694
06/10/2022 17:41:13 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=697
06/10/2022 17:41:16 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=699
06/10/2022 17:41:17 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.6405180840664713 on epoch=699
06/10/2022 17:41:19 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/10/2022 17:41:21 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/10/2022 17:41:24 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/10/2022 17:41:26 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/10/2022 17:41:28 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/10/2022 17:41:29 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.653913057987761 on epoch=712
06/10/2022 17:41:32 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=714
06/10/2022 17:41:34 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=717
06/10/2022 17:41:36 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=719
06/10/2022 17:41:39 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/10/2022 17:41:41 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/10/2022 17:41:42 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.6812723748207619 on epoch=724
06/10/2022 17:41:45 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=727
06/10/2022 17:41:47 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=729
06/10/2022 17:41:49 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=732
06/10/2022 17:41:52 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=734
06/10/2022 17:41:54 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=737
06/10/2022 17:41:55 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.6539130579877609 on epoch=737
06/10/2022 17:41:57 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/10/2022 17:42:00 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=742
06/10/2022 17:42:02 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/10/2022 17:42:04 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/10/2022 17:42:07 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.06 on epoch=749
06/10/2022 17:42:08 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.6405180840664713 on epoch=749
06/10/2022 17:42:08 - INFO - __main__ - save last model!
06/10/2022 17:42:08 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/10/2022 17:42:08 - INFO - __main__ - Start tokenizing ... 5509 instances
06/10/2022 17:42:08 - INFO - __main__ - Printing 3 examples
06/10/2022 17:42:08 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/10/2022 17:42:08 - INFO - __main__ - ['others']
06/10/2022 17:42:08 - INFO - __main__ -  [emo] what you like very little things ok
06/10/2022 17:42:08 - INFO - __main__ - ['others']
06/10/2022 17:42:08 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/10/2022 17:42:08 - INFO - __main__ - ['others']
06/10/2022 17:42:08 - INFO - __main__ - Tokenizing Input ...
06/10/2022 17:42:08 - INFO - __main__ - Start tokenizing ... 64 instances
06/10/2022 17:42:08 - INFO - __main__ - Printing 3 examples
06/10/2022 17:42:08 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/10/2022 17:42:08 - INFO - __main__ - ['sad']
06/10/2022 17:42:08 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/10/2022 17:42:08 - INFO - __main__ - ['sad']
06/10/2022 17:42:08 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/10/2022 17:42:08 - INFO - __main__ - ['sad']
06/10/2022 17:42:08 - INFO - __main__ - Tokenizing Input ...
06/10/2022 17:42:08 - INFO - __main__ - Tokenizing Output ...
06/10/2022 17:42:08 - INFO - __main__ - Loaded 64 examples from train data
06/10/2022 17:42:08 - INFO - __main__ - Start tokenizing ... 64 instances
06/10/2022 17:42:08 - INFO - __main__ - Printing 3 examples
06/10/2022 17:42:08 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
06/10/2022 17:42:08 - INFO - __main__ - ['sad']
06/10/2022 17:42:08 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
06/10/2022 17:42:08 - INFO - __main__ - ['sad']
06/10/2022 17:42:08 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
06/10/2022 17:42:08 - INFO - __main__ - ['sad']
06/10/2022 17:42:08 - INFO - __main__ - Tokenizing Input ...
06/10/2022 17:42:08 - INFO - __main__ - Tokenizing Output ...
06/10/2022 17:42:08 - INFO - __main__ - Loaded 64 examples from dev data
06/10/2022 17:42:10 - INFO - __main__ - Tokenizing Output ...
06/10/2022 17:42:15 - INFO - __main__ - Loaded 5509 examples from test data
06/10/2022 17:42:23 - INFO - __main__ - load prompt embedding from ckpt
06/10/2022 17:42:24 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/10/2022 17:42:24 - INFO - __main__ - Starting training!
06/10/2022 17:43:41 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-up32shot/singletask-emo/emo_16_21_0.3_8_predictions.txt
06/10/2022 17:43:41 - INFO - __main__ - Classification-F1 on test data: 0.1920
06/10/2022 17:43:41 - INFO - __main__ - prefix=emo_16_21, lr=0.3, bsz=8, dev_performance=0.6904043872793872, test_performance=0.19199070179292954
06/10/2022 17:43:41 - INFO - __main__ - Running ... prefix=emo_16_21, lr=0.2, bsz=8 ...
06/10/2022 17:43:42 - INFO - __main__ - Start tokenizing ... 64 instances
06/10/2022 17:43:42 - INFO - __main__ - Printing 3 examples
06/10/2022 17:43:42 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/10/2022 17:43:42 - INFO - __main__ - ['sad']
06/10/2022 17:43:42 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/10/2022 17:43:42 - INFO - __main__ - ['sad']
06/10/2022 17:43:42 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/10/2022 17:43:42 - INFO - __main__ - ['sad']
06/10/2022 17:43:42 - INFO - __main__ - Tokenizing Input ...
06/10/2022 17:43:42 - INFO - __main__ - Tokenizing Output ...
06/10/2022 17:43:42 - INFO - __main__ - Loaded 64 examples from train data
06/10/2022 17:43:42 - INFO - __main__ - Start tokenizing ... 64 instances
06/10/2022 17:43:42 - INFO - __main__ - Printing 3 examples
06/10/2022 17:43:42 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
06/10/2022 17:43:42 - INFO - __main__ - ['sad']
06/10/2022 17:43:43 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
06/10/2022 17:43:43 - INFO - __main__ - ['sad']
06/10/2022 17:43:43 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
06/10/2022 17:43:43 - INFO - __main__ - ['sad']
06/10/2022 17:43:43 - INFO - __main__ - Tokenizing Input ...
06/10/2022 17:43:43 - INFO - __main__ - Tokenizing Output ...
06/10/2022 17:43:43 - INFO - __main__ - Loaded 64 examples from dev data
06/10/2022 17:43:58 - INFO - __main__ - load prompt embedding from ckpt
06/10/2022 17:43:59 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/10/2022 17:43:59 - INFO - __main__ - Starting training!
06/10/2022 17:44:01 - INFO - __main__ - Step 10 Global step 10 Train loss 4.43 on epoch=2
06/10/2022 17:44:04 - INFO - __main__ - Step 20 Global step 20 Train loss 3.57 on epoch=4
06/10/2022 17:44:06 - INFO - __main__ - Step 30 Global step 30 Train loss 3.08 on epoch=7
06/10/2022 17:44:08 - INFO - __main__ - Step 40 Global step 40 Train loss 2.30 on epoch=9
06/10/2022 17:44:11 - INFO - __main__ - Step 50 Global step 50 Train loss 2.17 on epoch=12
06/10/2022 17:44:12 - INFO - __main__ - Global step 50 Train loss 3.11 Classification-F1 0.07242063492063493 on epoch=12
06/10/2022 17:44:12 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.07242063492063493 on epoch=12, global_step=50
06/10/2022 17:44:14 - INFO - __main__ - Step 60 Global step 60 Train loss 1.78 on epoch=14
06/10/2022 17:44:17 - INFO - __main__ - Step 70 Global step 70 Train loss 1.70 on epoch=17
06/10/2022 17:44:19 - INFO - __main__ - Step 80 Global step 80 Train loss 1.40 on epoch=19
06/10/2022 17:44:21 - INFO - __main__ - Step 90 Global step 90 Train loss 1.34 on epoch=22
06/10/2022 17:44:24 - INFO - __main__ - Step 100 Global step 100 Train loss 1.03 on epoch=24
06/10/2022 17:44:24 - INFO - __main__ - Global step 100 Train loss 1.45 Classification-F1 0.36638655462184877 on epoch=24
06/10/2022 17:44:24 - INFO - __main__ - Saving model with best Classification-F1: 0.07242063492063493 -> 0.36638655462184877 on epoch=24, global_step=100
06/10/2022 17:44:27 - INFO - __main__ - Step 110 Global step 110 Train loss 0.92 on epoch=27
06/10/2022 17:44:29 - INFO - __main__ - Step 120 Global step 120 Train loss 0.85 on epoch=29
06/10/2022 17:44:31 - INFO - __main__ - Step 130 Global step 130 Train loss 0.82 on epoch=32
06/10/2022 17:44:34 - INFO - __main__ - Step 140 Global step 140 Train loss 0.76 on epoch=34
06/10/2022 17:44:36 - INFO - __main__ - Step 150 Global step 150 Train loss 0.73 on epoch=37
06/10/2022 17:44:37 - INFO - __main__ - Global step 150 Train loss 0.82 Classification-F1 0.5165197786431647 on epoch=37
06/10/2022 17:44:37 - INFO - __main__ - Saving model with best Classification-F1: 0.36638655462184877 -> 0.5165197786431647 on epoch=37, global_step=150
06/10/2022 17:44:39 - INFO - __main__ - Step 160 Global step 160 Train loss 0.72 on epoch=39
06/10/2022 17:44:42 - INFO - __main__ - Step 170 Global step 170 Train loss 0.55 on epoch=42
06/10/2022 17:44:44 - INFO - __main__ - Step 180 Global step 180 Train loss 0.53 on epoch=44
06/10/2022 17:44:46 - INFO - __main__ - Step 190 Global step 190 Train loss 0.62 on epoch=47
06/10/2022 17:44:49 - INFO - __main__ - Step 200 Global step 200 Train loss 0.55 on epoch=49
06/10/2022 17:44:50 - INFO - __main__ - Global step 200 Train loss 0.59 Classification-F1 0.5460526315789473 on epoch=49
06/10/2022 17:44:50 - INFO - __main__ - Saving model with best Classification-F1: 0.5165197786431647 -> 0.5460526315789473 on epoch=49, global_step=200
06/10/2022 17:44:52 - INFO - __main__ - Step 210 Global step 210 Train loss 0.63 on epoch=52
06/10/2022 17:44:54 - INFO - __main__ - Step 220 Global step 220 Train loss 0.56 on epoch=54
06/10/2022 17:44:57 - INFO - __main__ - Step 230 Global step 230 Train loss 0.64 on epoch=57
06/10/2022 17:44:59 - INFO - __main__ - Step 240 Global step 240 Train loss 0.50 on epoch=59
06/10/2022 17:45:01 - INFO - __main__ - Step 250 Global step 250 Train loss 0.55 on epoch=62
06/10/2022 17:45:02 - INFO - __main__ - Global step 250 Train loss 0.58 Classification-F1 0.6149859943977591 on epoch=62
06/10/2022 17:45:02 - INFO - __main__ - Saving model with best Classification-F1: 0.5460526315789473 -> 0.6149859943977591 on epoch=62, global_step=250
06/10/2022 17:45:05 - INFO - __main__ - Step 260 Global step 260 Train loss 0.46 on epoch=64
06/10/2022 17:45:07 - INFO - __main__ - Step 270 Global step 270 Train loss 0.51 on epoch=67
06/10/2022 17:45:09 - INFO - __main__ - Step 280 Global step 280 Train loss 0.46 on epoch=69
06/10/2022 17:45:12 - INFO - __main__ - Step 290 Global step 290 Train loss 0.53 on epoch=72
06/10/2022 17:45:14 - INFO - __main__ - Step 300 Global step 300 Train loss 0.46 on epoch=74
06/10/2022 17:45:15 - INFO - __main__ - Global step 300 Train loss 0.48 Classification-F1 0.6423423423423422 on epoch=74
06/10/2022 17:45:15 - INFO - __main__ - Saving model with best Classification-F1: 0.6149859943977591 -> 0.6423423423423422 on epoch=74, global_step=300
06/10/2022 17:45:17 - INFO - __main__ - Step 310 Global step 310 Train loss 0.49 on epoch=77
06/10/2022 17:45:20 - INFO - __main__ - Step 320 Global step 320 Train loss 0.41 on epoch=79
06/10/2022 17:45:22 - INFO - __main__ - Step 330 Global step 330 Train loss 0.32 on epoch=82
06/10/2022 17:45:24 - INFO - __main__ - Step 340 Global step 340 Train loss 0.35 on epoch=84
06/10/2022 17:45:27 - INFO - __main__ - Step 350 Global step 350 Train loss 0.39 on epoch=87
06/10/2022 17:45:28 - INFO - __main__ - Global step 350 Train loss 0.39 Classification-F1 0.6423423423423422 on epoch=87
06/10/2022 17:45:30 - INFO - __main__ - Step 360 Global step 360 Train loss 0.35 on epoch=89
06/10/2022 17:45:32 - INFO - __main__ - Step 370 Global step 370 Train loss 0.31 on epoch=92
06/10/2022 17:45:35 - INFO - __main__ - Step 380 Global step 380 Train loss 0.36 on epoch=94
06/10/2022 17:45:37 - INFO - __main__ - Step 390 Global step 390 Train loss 0.48 on epoch=97
06/10/2022 17:45:39 - INFO - __main__ - Step 400 Global step 400 Train loss 0.40 on epoch=99
06/10/2022 17:45:40 - INFO - __main__ - Global step 400 Train loss 0.38 Classification-F1 0.6423423423423422 on epoch=99
06/10/2022 17:45:42 - INFO - __main__ - Step 410 Global step 410 Train loss 0.34 on epoch=102
06/10/2022 17:45:45 - INFO - __main__ - Step 420 Global step 420 Train loss 0.33 on epoch=104
06/10/2022 17:45:47 - INFO - __main__ - Step 430 Global step 430 Train loss 0.39 on epoch=107
06/10/2022 17:45:49 - INFO - __main__ - Step 440 Global step 440 Train loss 0.32 on epoch=109
06/10/2022 17:45:52 - INFO - __main__ - Step 450 Global step 450 Train loss 0.46 on epoch=112
06/10/2022 17:45:53 - INFO - __main__ - Global step 450 Train loss 0.37 Classification-F1 0.6527052926433732 on epoch=112
06/10/2022 17:45:53 - INFO - __main__ - Saving model with best Classification-F1: 0.6423423423423422 -> 0.6527052926433732 on epoch=112, global_step=450
06/10/2022 17:45:55 - INFO - __main__ - Step 460 Global step 460 Train loss 0.36 on epoch=114
06/10/2022 17:45:57 - INFO - __main__ - Step 470 Global step 470 Train loss 0.43 on epoch=117
06/10/2022 17:46:00 - INFO - __main__ - Step 480 Global step 480 Train loss 0.34 on epoch=119
06/10/2022 17:46:02 - INFO - __main__ - Step 490 Global step 490 Train loss 0.31 on epoch=122
06/10/2022 17:46:04 - INFO - __main__ - Step 500 Global step 500 Train loss 0.30 on epoch=124
06/10/2022 17:46:05 - INFO - __main__ - Global step 500 Train loss 0.35 Classification-F1 0.6386272526319734 on epoch=124
06/10/2022 17:46:08 - INFO - __main__ - Step 510 Global step 510 Train loss 0.32 on epoch=127
06/10/2022 17:46:10 - INFO - __main__ - Step 520 Global step 520 Train loss 0.32 on epoch=129
06/10/2022 17:46:12 - INFO - __main__ - Step 530 Global step 530 Train loss 0.38 on epoch=132
06/10/2022 17:46:15 - INFO - __main__ - Step 540 Global step 540 Train loss 0.29 on epoch=134
06/10/2022 17:46:17 - INFO - __main__ - Step 550 Global step 550 Train loss 0.25 on epoch=137
06/10/2022 17:46:18 - INFO - __main__ - Global step 550 Train loss 0.31 Classification-F1 0.6248511904761904 on epoch=137
06/10/2022 17:46:20 - INFO - __main__ - Step 560 Global step 560 Train loss 0.31 on epoch=139
06/10/2022 17:46:23 - INFO - __main__ - Step 570 Global step 570 Train loss 0.33 on epoch=142
06/10/2022 17:46:25 - INFO - __main__ - Step 580 Global step 580 Train loss 0.38 on epoch=144
06/10/2022 17:46:27 - INFO - __main__ - Step 590 Global step 590 Train loss 0.31 on epoch=147
06/10/2022 17:46:30 - INFO - __main__ - Step 600 Global step 600 Train loss 0.27 on epoch=149
06/10/2022 17:46:30 - INFO - __main__ - Global step 600 Train loss 0.32 Classification-F1 0.638961038961039 on epoch=149
06/10/2022 17:46:33 - INFO - __main__ - Step 610 Global step 610 Train loss 0.32 on epoch=152
06/10/2022 17:46:35 - INFO - __main__ - Step 620 Global step 620 Train loss 0.30 on epoch=154
06/10/2022 17:46:38 - INFO - __main__ - Step 630 Global step 630 Train loss 0.29 on epoch=157
06/10/2022 17:46:40 - INFO - __main__ - Step 640 Global step 640 Train loss 0.27 on epoch=159
06/10/2022 17:46:42 - INFO - __main__ - Step 650 Global step 650 Train loss 0.30 on epoch=162
06/10/2022 17:46:43 - INFO - __main__ - Global step 650 Train loss 0.30 Classification-F1 0.6248511904761904 on epoch=162
06/10/2022 17:46:45 - INFO - __main__ - Step 660 Global step 660 Train loss 0.25 on epoch=164
06/10/2022 17:46:48 - INFO - __main__ - Step 670 Global step 670 Train loss 0.26 on epoch=167
06/10/2022 17:46:50 - INFO - __main__ - Step 680 Global step 680 Train loss 0.32 on epoch=169
06/10/2022 17:46:52 - INFO - __main__ - Step 690 Global step 690 Train loss 0.27 on epoch=172
06/10/2022 17:46:55 - INFO - __main__ - Step 700 Global step 700 Train loss 0.26 on epoch=174
06/10/2022 17:46:56 - INFO - __main__ - Global step 700 Train loss 0.27 Classification-F1 0.6248511904761904 on epoch=174
06/10/2022 17:46:58 - INFO - __main__ - Step 710 Global step 710 Train loss 0.21 on epoch=177
06/10/2022 17:47:00 - INFO - __main__ - Step 720 Global step 720 Train loss 0.24 on epoch=179
06/10/2022 17:47:03 - INFO - __main__ - Step 730 Global step 730 Train loss 0.22 on epoch=182
06/10/2022 17:47:05 - INFO - __main__ - Step 740 Global step 740 Train loss 0.22 on epoch=184
06/10/2022 17:47:07 - INFO - __main__ - Step 750 Global step 750 Train loss 0.28 on epoch=187
06/10/2022 17:47:08 - INFO - __main__ - Global step 750 Train loss 0.23 Classification-F1 0.6248511904761904 on epoch=187
06/10/2022 17:47:11 - INFO - __main__ - Step 760 Global step 760 Train loss 0.28 on epoch=189
06/10/2022 17:47:13 - INFO - __main__ - Step 770 Global step 770 Train loss 0.22 on epoch=192
06/10/2022 17:47:15 - INFO - __main__ - Step 780 Global step 780 Train loss 0.20 on epoch=194
06/10/2022 17:47:18 - INFO - __main__ - Step 790 Global step 790 Train loss 0.18 on epoch=197
06/10/2022 17:47:20 - INFO - __main__ - Step 800 Global step 800 Train loss 0.22 on epoch=199
06/10/2022 17:47:21 - INFO - __main__ - Global step 800 Train loss 0.22 Classification-F1 0.6248511904761904 on epoch=199
06/10/2022 17:47:23 - INFO - __main__ - Step 810 Global step 810 Train loss 0.23 on epoch=202
06/10/2022 17:47:26 - INFO - __main__ - Step 820 Global step 820 Train loss 0.18 on epoch=204
06/10/2022 17:47:28 - INFO - __main__ - Step 830 Global step 830 Train loss 0.21 on epoch=207
06/10/2022 17:47:30 - INFO - __main__ - Step 840 Global step 840 Train loss 0.19 on epoch=209
06/10/2022 17:47:33 - INFO - __main__ - Step 850 Global step 850 Train loss 0.17 on epoch=212
06/10/2022 17:47:34 - INFO - __main__ - Global step 850 Train loss 0.20 Classification-F1 0.6477115626309174 on epoch=212
06/10/2022 17:47:36 - INFO - __main__ - Step 860 Global step 860 Train loss 0.17 on epoch=214
06/10/2022 17:47:38 - INFO - __main__ - Step 870 Global step 870 Train loss 0.19 on epoch=217
06/10/2022 17:47:41 - INFO - __main__ - Step 880 Global step 880 Train loss 0.26 on epoch=219
06/10/2022 17:47:43 - INFO - __main__ - Step 890 Global step 890 Train loss 0.11 on epoch=222
06/10/2022 17:47:45 - INFO - __main__ - Step 900 Global step 900 Train loss 0.19 on epoch=224
06/10/2022 17:47:46 - INFO - __main__ - Global step 900 Train loss 0.18 Classification-F1 0.6248511904761904 on epoch=224
06/10/2022 17:47:49 - INFO - __main__ - Step 910 Global step 910 Train loss 0.22 on epoch=227
06/10/2022 17:47:51 - INFO - __main__ - Step 920 Global step 920 Train loss 0.17 on epoch=229
06/10/2022 17:47:53 - INFO - __main__ - Step 930 Global step 930 Train loss 0.14 on epoch=232
06/10/2022 17:47:56 - INFO - __main__ - Step 940 Global step 940 Train loss 0.12 on epoch=234
06/10/2022 17:47:58 - INFO - __main__ - Step 950 Global step 950 Train loss 0.15 on epoch=237
06/10/2022 17:47:59 - INFO - __main__ - Global step 950 Train loss 0.16 Classification-F1 0.6477115626309174 on epoch=237
06/10/2022 17:48:01 - INFO - __main__ - Step 960 Global step 960 Train loss 0.12 on epoch=239
06/10/2022 17:48:04 - INFO - __main__ - Step 970 Global step 970 Train loss 0.18 on epoch=242
06/10/2022 17:48:06 - INFO - __main__ - Step 980 Global step 980 Train loss 0.08 on epoch=244
06/10/2022 17:48:08 - INFO - __main__ - Step 990 Global step 990 Train loss 0.12 on epoch=247
06/10/2022 17:48:11 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.21 on epoch=249
06/10/2022 17:48:11 - INFO - __main__ - Global step 1000 Train loss 0.14 Classification-F1 0.6264321306807539 on epoch=249
06/10/2022 17:48:14 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.14 on epoch=252
06/10/2022 17:48:16 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.10 on epoch=254
06/10/2022 17:48:19 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.14 on epoch=257
06/10/2022 17:48:21 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.08 on epoch=259
06/10/2022 17:48:23 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.14 on epoch=262
06/10/2022 17:48:24 - INFO - __main__ - Global step 1050 Train loss 0.12 Classification-F1 0.6264321306807539 on epoch=262
06/10/2022 17:48:27 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.18 on epoch=264
06/10/2022 17:48:29 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.12 on epoch=267
06/10/2022 17:48:31 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.15 on epoch=269
06/10/2022 17:48:34 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.15 on epoch=272
06/10/2022 17:48:36 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.09 on epoch=274
06/10/2022 17:48:37 - INFO - __main__ - Global step 1100 Train loss 0.14 Classification-F1 0.6264321306807539 on epoch=274
06/10/2022 17:48:39 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.10 on epoch=277
06/10/2022 17:48:42 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.07 on epoch=279
06/10/2022 17:48:44 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.10 on epoch=282
06/10/2022 17:48:46 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.18 on epoch=284
06/10/2022 17:48:49 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.14 on epoch=287
06/10/2022 17:48:50 - INFO - __main__ - Global step 1150 Train loss 0.12 Classification-F1 0.6264321306807539 on epoch=287
06/10/2022 17:48:52 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.14 on epoch=289
06/10/2022 17:48:54 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.10 on epoch=292
06/10/2022 17:48:57 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.12 on epoch=294
06/10/2022 17:48:59 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.15 on epoch=297
06/10/2022 17:49:01 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.07 on epoch=299
06/10/2022 17:49:02 - INFO - __main__ - Global step 1200 Train loss 0.12 Classification-F1 0.6264321306807539 on epoch=299
06/10/2022 17:49:05 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.13 on epoch=302
06/10/2022 17:49:07 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.10 on epoch=304
06/10/2022 17:49:09 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.07 on epoch=307
06/10/2022 17:49:12 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.08 on epoch=309
06/10/2022 17:49:14 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.12 on epoch=312
06/10/2022 17:49:15 - INFO - __main__ - Global step 1250 Train loss 0.10 Classification-F1 0.6264321306807539 on epoch=312
06/10/2022 17:49:17 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.11 on epoch=314
06/10/2022 17:49:20 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.08 on epoch=317
06/10/2022 17:49:22 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.10 on epoch=319
06/10/2022 17:49:24 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.09 on epoch=322
06/10/2022 17:49:27 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.09 on epoch=324
06/10/2022 17:49:28 - INFO - __main__ - Global step 1300 Train loss 0.09 Classification-F1 0.6264321306807539 on epoch=324
06/10/2022 17:49:30 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.09 on epoch=327
06/10/2022 17:49:32 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.09 on epoch=329
06/10/2022 17:49:35 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.08 on epoch=332
06/10/2022 17:49:37 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.08 on epoch=334
06/10/2022 17:49:39 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.10 on epoch=337
06/10/2022 17:49:40 - INFO - __main__ - Global step 1350 Train loss 0.09 Classification-F1 0.6395225294418843 on epoch=337
06/10/2022 17:49:43 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.08 on epoch=339
06/10/2022 17:49:45 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.12 on epoch=342
06/10/2022 17:49:47 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.08 on epoch=344
06/10/2022 17:49:50 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.14 on epoch=347
06/10/2022 17:49:52 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.07 on epoch=349
06/10/2022 17:49:53 - INFO - __main__ - Global step 1400 Train loss 0.10 Classification-F1 0.6609903381642512 on epoch=349
06/10/2022 17:49:53 - INFO - __main__ - Saving model with best Classification-F1: 0.6527052926433732 -> 0.6609903381642512 on epoch=349, global_step=1400
06/10/2022 17:49:55 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.06 on epoch=352
06/10/2022 17:49:58 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.10 on epoch=354
06/10/2022 17:50:00 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.03 on epoch=357
06/10/2022 17:50:03 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.05 on epoch=359
06/10/2022 17:50:05 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.07 on epoch=362
06/10/2022 17:50:06 - INFO - __main__ - Global step 1450 Train loss 0.06 Classification-F1 0.6610052134245683 on epoch=362
06/10/2022 17:50:06 - INFO - __main__ - Saving model with best Classification-F1: 0.6609903381642512 -> 0.6610052134245683 on epoch=362, global_step=1450
06/10/2022 17:50:08 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.12 on epoch=364
06/10/2022 17:50:11 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.09 on epoch=367
06/10/2022 17:50:13 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.08 on epoch=369
06/10/2022 17:50:15 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.06 on epoch=372
06/10/2022 17:50:18 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.06 on epoch=374
06/10/2022 17:50:19 - INFO - __main__ - Global step 1500 Train loss 0.08 Classification-F1 0.6395225294418843 on epoch=374
06/10/2022 17:50:21 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.07 on epoch=377
06/10/2022 17:50:23 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.03 on epoch=379
06/10/2022 17:50:26 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.12 on epoch=382
06/10/2022 17:50:28 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.09 on epoch=384
06/10/2022 17:50:30 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.04 on epoch=387
06/10/2022 17:50:32 - INFO - __main__ - Global step 1550 Train loss 0.07 Classification-F1 0.6395225294418843 on epoch=387
06/10/2022 17:50:34 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.06 on epoch=389
06/10/2022 17:50:36 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.04 on epoch=392
06/10/2022 17:50:39 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.03 on epoch=394
06/10/2022 17:50:41 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.04 on epoch=397
06/10/2022 17:50:43 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.08 on epoch=399
06/10/2022 17:50:44 - INFO - __main__ - Global step 1600 Train loss 0.05 Classification-F1 0.6395225294418843 on epoch=399
06/10/2022 17:50:47 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.06 on epoch=402
06/10/2022 17:50:49 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.04 on epoch=404
06/10/2022 17:50:51 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.11 on epoch=407
06/10/2022 17:50:54 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.04 on epoch=409
06/10/2022 17:50:56 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.03 on epoch=412
06/10/2022 17:50:57 - INFO - __main__ - Global step 1650 Train loss 0.06 Classification-F1 0.638809316228671 on epoch=412
06/10/2022 17:50:59 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.04 on epoch=414
06/10/2022 17:51:02 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.10 on epoch=417
06/10/2022 17:51:04 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.05 on epoch=419
06/10/2022 17:51:06 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.05 on epoch=422
06/10/2022 17:51:09 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.06 on epoch=424
06/10/2022 17:51:10 - INFO - __main__ - Global step 1700 Train loss 0.06 Classification-F1 0.638809316228671 on epoch=424
06/10/2022 17:51:12 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.05 on epoch=427
06/10/2022 17:51:14 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=429
06/10/2022 17:51:17 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.05 on epoch=432
06/10/2022 17:51:19 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.05 on epoch=434
06/10/2022 17:51:22 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.04 on epoch=437
06/10/2022 17:51:23 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.6897910138399268 on epoch=437
06/10/2022 17:51:23 - INFO - __main__ - Saving model with best Classification-F1: 0.6610052134245683 -> 0.6897910138399268 on epoch=437, global_step=1750
06/10/2022 17:51:25 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.06 on epoch=439
06/10/2022 17:51:27 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.04 on epoch=442
06/10/2022 17:51:30 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.07 on epoch=444
06/10/2022 17:51:32 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.11 on epoch=447
06/10/2022 17:51:34 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.05 on epoch=449
06/10/2022 17:51:35 - INFO - __main__ - Global step 1800 Train loss 0.06 Classification-F1 0.638809316228671 on epoch=449
06/10/2022 17:51:38 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.03 on epoch=452
06/10/2022 17:51:40 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=454
06/10/2022 17:51:42 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.08 on epoch=457
06/10/2022 17:51:45 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.08 on epoch=459
06/10/2022 17:51:47 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=462
06/10/2022 17:51:48 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.6673686673686674 on epoch=462
06/10/2022 17:51:50 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=464
06/10/2022 17:51:53 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.04 on epoch=467
06/10/2022 17:51:55 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.03 on epoch=469
06/10/2022 17:51:58 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.07 on epoch=472
06/10/2022 17:52:00 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.04 on epoch=474
06/10/2022 17:52:01 - INFO - __main__ - Global step 1900 Train loss 0.04 Classification-F1 0.6539130579877609 on epoch=474
06/10/2022 17:52:03 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=477
06/10/2022 17:52:06 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=479
06/10/2022 17:52:08 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=482
06/10/2022 17:52:10 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=484
06/10/2022 17:52:13 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.06 on epoch=487
06/10/2022 17:52:14 - INFO - __main__ - Global step 1950 Train loss 0.04 Classification-F1 0.6436980042243201 on epoch=487
06/10/2022 17:52:16 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.06 on epoch=489
06/10/2022 17:52:18 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=492
06/10/2022 17:52:21 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=494
06/10/2022 17:52:23 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.06 on epoch=497
06/10/2022 17:52:25 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=499
06/10/2022 17:52:26 - INFO - __main__ - Global step 2000 Train loss 0.04 Classification-F1 0.6311288246772118 on epoch=499
06/10/2022 17:52:29 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=502
06/10/2022 17:52:31 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.06 on epoch=504
06/10/2022 17:52:33 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.02 on epoch=507
06/10/2022 17:52:36 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=509
06/10/2022 17:52:38 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.03 on epoch=512
06/10/2022 17:52:39 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.6155950305143852 on epoch=512
06/10/2022 17:52:41 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.04 on epoch=514
06/10/2022 17:52:44 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=517
06/10/2022 17:52:46 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.03 on epoch=519
06/10/2022 17:52:48 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.03 on epoch=522
06/10/2022 17:52:51 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=524
06/10/2022 17:52:52 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.6539130579877609 on epoch=524
06/10/2022 17:52:54 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.04 on epoch=527
06/10/2022 17:52:56 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.04 on epoch=529
06/10/2022 17:52:59 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.05 on epoch=532
06/10/2022 17:53:01 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.04 on epoch=534
06/10/2022 17:53:04 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.05 on epoch=537
06/10/2022 17:53:05 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.6532759263022421 on epoch=537
06/10/2022 17:53:07 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.03 on epoch=539
06/10/2022 17:53:09 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.11 on epoch=542
06/10/2022 17:53:12 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=544
06/10/2022 17:53:14 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.04 on epoch=547
06/10/2022 17:53:16 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=549
06/10/2022 17:53:17 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.6539130579877609 on epoch=549
06/10/2022 17:53:20 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=552
06/10/2022 17:53:22 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=554
06/10/2022 17:53:24 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.05 on epoch=557
06/10/2022 17:53:27 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.08 on epoch=559
06/10/2022 17:53:29 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.03 on epoch=562
06/10/2022 17:53:30 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.6683695507708667 on epoch=562
06/10/2022 17:53:32 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=564
06/10/2022 17:53:35 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=567
06/10/2022 17:53:37 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=569
06/10/2022 17:53:39 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=572
06/10/2022 17:53:42 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=574
06/10/2022 17:53:43 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.6683695507708667 on epoch=574
06/10/2022 17:53:45 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=577
06/10/2022 17:53:47 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=579
06/10/2022 17:53:50 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=582
06/10/2022 17:53:52 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=584
06/10/2022 17:53:54 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=587
06/10/2022 17:53:55 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.667625503151819 on epoch=587
06/10/2022 17:53:58 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=589
06/10/2022 17:54:00 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=592
06/10/2022 17:54:03 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.03 on epoch=594
06/10/2022 17:54:05 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.06 on epoch=597
06/10/2022 17:54:07 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=599
06/10/2022 17:54:08 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.6539130579877609 on epoch=599
06/10/2022 17:54:11 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.04 on epoch=602
06/10/2022 17:54:13 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.04 on epoch=604
06/10/2022 17:54:15 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.04 on epoch=607
06/10/2022 17:54:18 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=609
06/10/2022 17:54:20 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.04 on epoch=612
06/10/2022 17:54:21 - INFO - __main__ - Global step 2450 Train loss 0.04 Classification-F1 0.6753345210568211 on epoch=612
06/10/2022 17:54:23 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=614
06/10/2022 17:54:26 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.12 on epoch=617
06/10/2022 17:54:28 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=619
06/10/2022 17:54:30 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/10/2022 17:54:33 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=624
06/10/2022 17:54:34 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.6539130579877609 on epoch=624
06/10/2022 17:54:36 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=627
06/10/2022 17:54:39 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=629
06/10/2022 17:54:41 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.04 on epoch=632
06/10/2022 17:54:43 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.03 on epoch=634
06/10/2022 17:54:46 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=637
06/10/2022 17:54:47 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.6539130579877609 on epoch=637
06/10/2022 17:54:49 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/10/2022 17:54:52 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=642
06/10/2022 17:54:54 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.03 on epoch=644
06/10/2022 17:54:56 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=647
06/10/2022 17:54:59 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.04 on epoch=649
06/10/2022 17:55:00 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.6532759263022421 on epoch=649
06/10/2022 17:55:02 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.03 on epoch=652
06/10/2022 17:55:04 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/10/2022 17:55:07 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=657
06/10/2022 17:55:09 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=659
06/10/2022 17:55:11 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=662
06/10/2022 17:55:13 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.6539130579877609 on epoch=662
06/10/2022 17:55:15 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.08 on epoch=664
06/10/2022 17:55:17 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.09 on epoch=667
06/10/2022 17:55:20 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.06 on epoch=669
06/10/2022 17:55:22 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.04 on epoch=672
06/10/2022 17:55:24 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/10/2022 17:55:25 - INFO - __main__ - Global step 2700 Train loss 0.05 Classification-F1 0.6539130579877609 on epoch=674
06/10/2022 17:55:28 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=677
06/10/2022 17:55:30 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=679
06/10/2022 17:55:33 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=682
06/10/2022 17:55:35 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/10/2022 17:55:37 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=687
06/10/2022 17:55:38 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.6683695507708667 on epoch=687
06/10/2022 17:55:41 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=689
06/10/2022 17:55:43 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=692
06/10/2022 17:55:45 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=694
06/10/2022 17:55:48 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=697
06/10/2022 17:55:50 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=699
06/10/2022 17:55:51 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.6539130579877609 on epoch=699
06/10/2022 17:55:54 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.03 on epoch=702
06/10/2022 17:55:56 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=704
06/10/2022 17:55:58 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.09 on epoch=707
06/10/2022 17:56:00 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/10/2022 17:56:03 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.08 on epoch=712
06/10/2022 17:56:04 - INFO - __main__ - Global step 2850 Train loss 0.04 Classification-F1 0.6683695507708667 on epoch=712
06/10/2022 17:56:06 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=714
06/10/2022 17:56:09 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=717
06/10/2022 17:56:11 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=719
06/10/2022 17:56:13 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=722
06/10/2022 17:56:16 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.03 on epoch=724
06/10/2022 17:56:17 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.6539130579877609 on epoch=724
06/10/2022 17:56:19 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=727
06/10/2022 17:56:22 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.03 on epoch=729
06/10/2022 17:56:24 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.04 on epoch=732
06/10/2022 17:56:26 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=734
06/10/2022 17:56:29 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/10/2022 17:56:30 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.6897910138399268 on epoch=737
06/10/2022 17:56:32 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=739
06/10/2022 17:56:34 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=742
06/10/2022 17:56:37 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=744
06/10/2022 17:56:39 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=747
06/10/2022 17:56:41 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/10/2022 17:56:42 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.6683695507708667 on epoch=749
06/10/2022 17:56:42 - INFO - __main__ - save last model!
06/10/2022 17:56:42 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/10/2022 17:56:42 - INFO - __main__ - Start tokenizing ... 5509 instances
06/10/2022 17:56:42 - INFO - __main__ - Printing 3 examples
06/10/2022 17:56:42 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/10/2022 17:56:42 - INFO - __main__ - ['others']
06/10/2022 17:56:42 - INFO - __main__ -  [emo] what you like very little things ok
06/10/2022 17:56:42 - INFO - __main__ - ['others']
06/10/2022 17:56:42 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/10/2022 17:56:42 - INFO - __main__ - ['others']
06/10/2022 17:56:42 - INFO - __main__ - Tokenizing Input ...
06/10/2022 17:56:43 - INFO - __main__ - Start tokenizing ... 64 instances
06/10/2022 17:56:43 - INFO - __main__ - Printing 3 examples
06/10/2022 17:56:43 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/10/2022 17:56:43 - INFO - __main__ - ['happy']
06/10/2022 17:56:43 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/10/2022 17:56:43 - INFO - __main__ - ['happy']
06/10/2022 17:56:43 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/10/2022 17:56:43 - INFO - __main__ - ['happy']
06/10/2022 17:56:43 - INFO - __main__ - Tokenizing Input ...
06/10/2022 17:56:43 - INFO - __main__ - Tokenizing Output ...
06/10/2022 17:56:43 - INFO - __main__ - Loaded 64 examples from train data
06/10/2022 17:56:43 - INFO - __main__ - Start tokenizing ... 64 instances
06/10/2022 17:56:43 - INFO - __main__ - Printing 3 examples
06/10/2022 17:56:43 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
06/10/2022 17:56:43 - INFO - __main__ - ['happy']
06/10/2022 17:56:43 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
06/10/2022 17:56:43 - INFO - __main__ - ['happy']
06/10/2022 17:56:43 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
06/10/2022 17:56:43 - INFO - __main__ - ['happy']
06/10/2022 17:56:43 - INFO - __main__ - Tokenizing Input ...
06/10/2022 17:56:43 - INFO - __main__ - Tokenizing Output ...
06/10/2022 17:56:43 - INFO - __main__ - Loaded 64 examples from dev data
06/10/2022 17:56:44 - INFO - __main__ - Tokenizing Output ...
06/10/2022 17:56:50 - INFO - __main__ - Loaded 5509 examples from test data
06/10/2022 17:56:58 - INFO - __main__ - load prompt embedding from ckpt
06/10/2022 17:56:59 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/10/2022 17:56:59 - INFO - __main__ - Starting training!
06/10/2022 17:58:11 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-up32shot/singletask-emo/emo_16_21_0.2_8_predictions.txt
06/10/2022 17:58:11 - INFO - __main__ - Classification-F1 on test data: 0.1259
06/10/2022 17:58:11 - INFO - __main__ - prefix=emo_16_21, lr=0.2, bsz=8, dev_performance=0.6897910138399268, test_performance=0.1258846984288021
06/10/2022 17:58:11 - INFO - __main__ - Running ... prefix=emo_16_42, lr=0.5, bsz=8 ...
06/10/2022 17:58:12 - INFO - __main__ - Start tokenizing ... 64 instances
06/10/2022 17:58:12 - INFO - __main__ - Printing 3 examples
06/10/2022 17:58:12 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/10/2022 17:58:12 - INFO - __main__ - ['happy']
06/10/2022 17:58:12 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/10/2022 17:58:12 - INFO - __main__ - ['happy']
06/10/2022 17:58:12 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/10/2022 17:58:12 - INFO - __main__ - ['happy']
06/10/2022 17:58:12 - INFO - __main__ - Tokenizing Input ...
06/10/2022 17:58:12 - INFO - __main__ - Tokenizing Output ...
06/10/2022 17:58:12 - INFO - __main__ - Loaded 64 examples from train data
06/10/2022 17:58:12 - INFO - __main__ - Start tokenizing ... 64 instances
06/10/2022 17:58:12 - INFO - __main__ - Printing 3 examples
06/10/2022 17:58:12 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
06/10/2022 17:58:12 - INFO - __main__ - ['happy']
06/10/2022 17:58:12 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
06/10/2022 17:58:12 - INFO - __main__ - ['happy']
06/10/2022 17:58:12 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
06/10/2022 17:58:12 - INFO - __main__ - ['happy']
06/10/2022 17:58:12 - INFO - __main__ - Tokenizing Input ...
06/10/2022 17:58:12 - INFO - __main__ - Tokenizing Output ...
06/10/2022 17:58:12 - INFO - __main__ - Loaded 64 examples from dev data
06/10/2022 17:58:28 - INFO - __main__ - load prompt embedding from ckpt
06/10/2022 17:58:28 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/10/2022 17:58:28 - INFO - __main__ - Starting training!
06/10/2022 17:58:31 - INFO - __main__ - Step 10 Global step 10 Train loss 3.57 on epoch=2
06/10/2022 17:58:34 - INFO - __main__ - Step 20 Global step 20 Train loss 2.53 on epoch=4
06/10/2022 17:58:36 - INFO - __main__ - Step 30 Global step 30 Train loss 1.68 on epoch=7
06/10/2022 17:58:38 - INFO - __main__ - Step 40 Global step 40 Train loss 1.41 on epoch=9
06/10/2022 17:58:41 - INFO - __main__ - Step 50 Global step 50 Train loss 0.95 on epoch=12
06/10/2022 17:58:42 - INFO - __main__ - Global step 50 Train loss 2.03 Classification-F1 0.46679566563467495 on epoch=12
06/10/2022 17:58:42 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.46679566563467495 on epoch=12, global_step=50
06/10/2022 17:58:44 - INFO - __main__ - Step 60 Global step 60 Train loss 0.85 on epoch=14
06/10/2022 17:58:46 - INFO - __main__ - Step 70 Global step 70 Train loss 0.82 on epoch=17
06/10/2022 17:58:49 - INFO - __main__ - Step 80 Global step 80 Train loss 0.76 on epoch=19
06/10/2022 17:58:51 - INFO - __main__ - Step 90 Global step 90 Train loss 0.68 on epoch=22
06/10/2022 17:58:53 - INFO - __main__ - Step 100 Global step 100 Train loss 0.68 on epoch=24
06/10/2022 17:58:54 - INFO - __main__ - Global step 100 Train loss 0.76 Classification-F1 0.5245337159253944 on epoch=24
06/10/2022 17:58:54 - INFO - __main__ - Saving model with best Classification-F1: 0.46679566563467495 -> 0.5245337159253944 on epoch=24, global_step=100
06/10/2022 17:58:57 - INFO - __main__ - Step 110 Global step 110 Train loss 0.69 on epoch=27
06/10/2022 17:58:59 - INFO - __main__ - Step 120 Global step 120 Train loss 0.62 on epoch=29
06/10/2022 17:59:01 - INFO - __main__ - Step 130 Global step 130 Train loss 0.61 on epoch=32
06/10/2022 17:59:04 - INFO - __main__ - Step 140 Global step 140 Train loss 0.48 on epoch=34
06/10/2022 17:59:06 - INFO - __main__ - Step 150 Global step 150 Train loss 0.58 on epoch=37
06/10/2022 17:59:07 - INFO - __main__ - Global step 150 Train loss 0.59 Classification-F1 0.43686816405082657 on epoch=37
06/10/2022 17:59:09 - INFO - __main__ - Step 160 Global step 160 Train loss 0.61 on epoch=39
06/10/2022 17:59:12 - INFO - __main__ - Step 170 Global step 170 Train loss 0.60 on epoch=42
06/10/2022 17:59:14 - INFO - __main__ - Step 180 Global step 180 Train loss 0.52 on epoch=44
06/10/2022 17:59:16 - INFO - __main__ - Step 190 Global step 190 Train loss 0.58 on epoch=47
06/10/2022 17:59:19 - INFO - __main__ - Step 200 Global step 200 Train loss 0.44 on epoch=49
06/10/2022 17:59:20 - INFO - __main__ - Global step 200 Train loss 0.55 Classification-F1 0.5260317460317461 on epoch=49
06/10/2022 17:59:20 - INFO - __main__ - Saving model with best Classification-F1: 0.5245337159253944 -> 0.5260317460317461 on epoch=49, global_step=200
06/10/2022 17:59:22 - INFO - __main__ - Step 210 Global step 210 Train loss 0.48 on epoch=52
06/10/2022 17:59:24 - INFO - __main__ - Step 220 Global step 220 Train loss 0.51 on epoch=54
06/10/2022 17:59:27 - INFO - __main__ - Step 230 Global step 230 Train loss 0.41 on epoch=57
06/10/2022 17:59:29 - INFO - __main__ - Step 240 Global step 240 Train loss 0.51 on epoch=59
06/10/2022 17:59:31 - INFO - __main__ - Step 250 Global step 250 Train loss 0.38 on epoch=62
06/10/2022 17:59:32 - INFO - __main__ - Global step 250 Train loss 0.46 Classification-F1 0.5672785084549791 on epoch=62
06/10/2022 17:59:32 - INFO - __main__ - Saving model with best Classification-F1: 0.5260317460317461 -> 0.5672785084549791 on epoch=62, global_step=250
06/10/2022 17:59:35 - INFO - __main__ - Step 260 Global step 260 Train loss 0.41 on epoch=64
06/10/2022 17:59:37 - INFO - __main__ - Step 270 Global step 270 Train loss 0.31 on epoch=67
06/10/2022 17:59:39 - INFO - __main__ - Step 280 Global step 280 Train loss 0.29 on epoch=69
06/10/2022 17:59:42 - INFO - __main__ - Step 290 Global step 290 Train loss 0.40 on epoch=72
06/10/2022 17:59:44 - INFO - __main__ - Step 300 Global step 300 Train loss 0.33 on epoch=74
06/10/2022 17:59:45 - INFO - __main__ - Global step 300 Train loss 0.35 Classification-F1 0.5909875222816399 on epoch=74
06/10/2022 17:59:45 - INFO - __main__ - Saving model with best Classification-F1: 0.5672785084549791 -> 0.5909875222816399 on epoch=74, global_step=300
06/10/2022 17:59:47 - INFO - __main__ - Step 310 Global step 310 Train loss 0.31 on epoch=77
06/10/2022 17:59:50 - INFO - __main__ - Step 320 Global step 320 Train loss 0.24 on epoch=79
06/10/2022 17:59:52 - INFO - __main__ - Step 330 Global step 330 Train loss 0.31 on epoch=82
06/10/2022 17:59:54 - INFO - __main__ - Step 340 Global step 340 Train loss 0.33 on epoch=84
06/10/2022 17:59:57 - INFO - __main__ - Step 350 Global step 350 Train loss 0.34 on epoch=87
06/10/2022 17:59:58 - INFO - __main__ - Global step 350 Train loss 0.31 Classification-F1 0.6157171717171718 on epoch=87
06/10/2022 17:59:58 - INFO - __main__ - Saving model with best Classification-F1: 0.5909875222816399 -> 0.6157171717171718 on epoch=87, global_step=350
06/10/2022 18:00:00 - INFO - __main__ - Step 360 Global step 360 Train loss 0.31 on epoch=89
06/10/2022 18:00:02 - INFO - __main__ - Step 370 Global step 370 Train loss 0.27 on epoch=92
06/10/2022 18:00:05 - INFO - __main__ - Step 380 Global step 380 Train loss 0.22 on epoch=94
06/10/2022 18:00:07 - INFO - __main__ - Step 390 Global step 390 Train loss 0.23 on epoch=97
06/10/2022 18:00:09 - INFO - __main__ - Step 400 Global step 400 Train loss 0.22 on epoch=99
06/10/2022 18:00:10 - INFO - __main__ - Global step 400 Train loss 0.25 Classification-F1 0.6158722109533469 on epoch=99
06/10/2022 18:00:10 - INFO - __main__ - Saving model with best Classification-F1: 0.6157171717171718 -> 0.6158722109533469 on epoch=99, global_step=400
06/10/2022 18:00:13 - INFO - __main__ - Step 410 Global step 410 Train loss 0.21 on epoch=102
06/10/2022 18:00:15 - INFO - __main__ - Step 420 Global step 420 Train loss 0.27 on epoch=104
06/10/2022 18:00:17 - INFO - __main__ - Step 430 Global step 430 Train loss 0.28 on epoch=107
06/10/2022 18:00:20 - INFO - __main__ - Step 440 Global step 440 Train loss 0.19 on epoch=109
06/10/2022 18:00:22 - INFO - __main__ - Step 450 Global step 450 Train loss 0.14 on epoch=112
06/10/2022 18:00:23 - INFO - __main__ - Global step 450 Train loss 0.22 Classification-F1 0.7644441536347576 on epoch=112
06/10/2022 18:00:23 - INFO - __main__ - Saving model with best Classification-F1: 0.6158722109533469 -> 0.7644441536347576 on epoch=112, global_step=450
06/10/2022 18:00:25 - INFO - __main__ - Step 460 Global step 460 Train loss 0.21 on epoch=114
06/10/2022 18:00:28 - INFO - __main__ - Step 470 Global step 470 Train loss 0.21 on epoch=117
06/10/2022 18:00:30 - INFO - __main__ - Step 480 Global step 480 Train loss 0.17 on epoch=119
06/10/2022 18:00:32 - INFO - __main__ - Step 490 Global step 490 Train loss 0.17 on epoch=122
06/10/2022 18:00:35 - INFO - __main__ - Step 500 Global step 500 Train loss 0.13 on epoch=124
06/10/2022 18:00:36 - INFO - __main__ - Global step 500 Train loss 0.18 Classification-F1 0.8407300420168067 on epoch=124
06/10/2022 18:00:36 - INFO - __main__ - Saving model with best Classification-F1: 0.7644441536347576 -> 0.8407300420168067 on epoch=124, global_step=500
06/10/2022 18:00:38 - INFO - __main__ - Step 510 Global step 510 Train loss 0.11 on epoch=127
06/10/2022 18:00:40 - INFO - __main__ - Step 520 Global step 520 Train loss 0.22 on epoch=129
06/10/2022 18:00:43 - INFO - __main__ - Step 530 Global step 530 Train loss 0.13 on epoch=132
06/10/2022 18:00:45 - INFO - __main__ - Step 540 Global step 540 Train loss 0.13 on epoch=134
06/10/2022 18:00:48 - INFO - __main__ - Step 550 Global step 550 Train loss 0.16 on epoch=137
06/10/2022 18:00:48 - INFO - __main__ - Global step 550 Train loss 0.15 Classification-F1 0.8115301724137931 on epoch=137
06/10/2022 18:00:51 - INFO - __main__ - Step 560 Global step 560 Train loss 0.13 on epoch=139
06/10/2022 18:00:53 - INFO - __main__ - Step 570 Global step 570 Train loss 0.14 on epoch=142
06/10/2022 18:00:55 - INFO - __main__ - Step 580 Global step 580 Train loss 0.13 on epoch=144
06/10/2022 18:00:58 - INFO - __main__ - Step 590 Global step 590 Train loss 0.15 on epoch=147
06/10/2022 18:01:00 - INFO - __main__ - Step 600 Global step 600 Train loss 0.13 on epoch=149
06/10/2022 18:01:01 - INFO - __main__ - Global step 600 Train loss 0.14 Classification-F1 0.7892385392385393 on epoch=149
06/10/2022 18:01:03 - INFO - __main__ - Step 610 Global step 610 Train loss 0.10 on epoch=152
06/10/2022 18:01:06 - INFO - __main__ - Step 620 Global step 620 Train loss 0.07 on epoch=154
06/10/2022 18:01:08 - INFO - __main__ - Step 630 Global step 630 Train loss 0.12 on epoch=157
06/10/2022 18:01:10 - INFO - __main__ - Step 640 Global step 640 Train loss 0.11 on epoch=159
06/10/2022 18:01:13 - INFO - __main__ - Step 650 Global step 650 Train loss 0.08 on epoch=162
06/10/2022 18:01:14 - INFO - __main__ - Global step 650 Train loss 0.10 Classification-F1 0.7747926093514329 on epoch=162
06/10/2022 18:01:16 - INFO - __main__ - Step 660 Global step 660 Train loss 0.09 on epoch=164
06/10/2022 18:01:18 - INFO - __main__ - Step 670 Global step 670 Train loss 0.07 on epoch=167
06/10/2022 18:01:21 - INFO - __main__ - Step 680 Global step 680 Train loss 0.07 on epoch=169
06/10/2022 18:01:23 - INFO - __main__ - Step 690 Global step 690 Train loss 0.04 on epoch=172
06/10/2022 18:01:25 - INFO - __main__ - Step 700 Global step 700 Train loss 0.06 on epoch=174
06/10/2022 18:01:26 - INFO - __main__ - Global step 700 Train loss 0.06 Classification-F1 0.8081033549783551 on epoch=174
06/10/2022 18:01:29 - INFO - __main__ - Step 710 Global step 710 Train loss 0.09 on epoch=177
06/10/2022 18:01:31 - INFO - __main__ - Step 720 Global step 720 Train loss 0.05 on epoch=179
06/10/2022 18:01:33 - INFO - __main__ - Step 730 Global step 730 Train loss 0.05 on epoch=182
06/10/2022 18:01:36 - INFO - __main__ - Step 740 Global step 740 Train loss 0.04 on epoch=184
06/10/2022 18:01:38 - INFO - __main__ - Step 750 Global step 750 Train loss 0.03 on epoch=187
06/10/2022 18:01:39 - INFO - __main__ - Global step 750 Train loss 0.05 Classification-F1 0.8234020881079706 on epoch=187
06/10/2022 18:01:41 - INFO - __main__ - Step 760 Global step 760 Train loss 0.05 on epoch=189
06/10/2022 18:01:44 - INFO - __main__ - Step 770 Global step 770 Train loss 0.04 on epoch=192
06/10/2022 18:01:46 - INFO - __main__ - Step 780 Global step 780 Train loss 0.05 on epoch=194
06/10/2022 18:01:48 - INFO - __main__ - Step 790 Global step 790 Train loss 0.07 on epoch=197
06/10/2022 18:01:51 - INFO - __main__ - Step 800 Global step 800 Train loss 0.02 on epoch=199
06/10/2022 18:01:52 - INFO - __main__ - Global step 800 Train loss 0.05 Classification-F1 0.7858585858585858 on epoch=199
06/10/2022 18:01:54 - INFO - __main__ - Step 810 Global step 810 Train loss 0.06 on epoch=202
06/10/2022 18:01:56 - INFO - __main__ - Step 820 Global step 820 Train loss 0.02 on epoch=204
06/10/2022 18:01:59 - INFO - __main__ - Step 830 Global step 830 Train loss 0.04 on epoch=207
06/10/2022 18:02:01 - INFO - __main__ - Step 840 Global step 840 Train loss 0.05 on epoch=209
06/10/2022 18:02:04 - INFO - __main__ - Step 850 Global step 850 Train loss 0.02 on epoch=212
06/10/2022 18:02:04 - INFO - __main__ - Global step 850 Train loss 0.04 Classification-F1 0.8129032258064516 on epoch=212
06/10/2022 18:02:07 - INFO - __main__ - Step 860 Global step 860 Train loss 0.03 on epoch=214
06/10/2022 18:02:09 - INFO - __main__ - Step 870 Global step 870 Train loss 0.12 on epoch=217
06/10/2022 18:02:12 - INFO - __main__ - Step 880 Global step 880 Train loss 0.13 on epoch=219
06/10/2022 18:02:14 - INFO - __main__ - Step 890 Global step 890 Train loss 0.03 on epoch=222
06/10/2022 18:02:16 - INFO - __main__ - Step 900 Global step 900 Train loss 0.06 on epoch=224
06/10/2022 18:02:17 - INFO - __main__ - Global step 900 Train loss 0.07 Classification-F1 0.8108100094876661 on epoch=224
06/10/2022 18:02:20 - INFO - __main__ - Step 910 Global step 910 Train loss 0.03 on epoch=227
06/10/2022 18:02:22 - INFO - __main__ - Step 920 Global step 920 Train loss 0.07 on epoch=229
06/10/2022 18:02:24 - INFO - __main__ - Step 930 Global step 930 Train loss 0.02 on epoch=232
06/10/2022 18:02:27 - INFO - __main__ - Step 940 Global step 940 Train loss 0.01 on epoch=234
06/10/2022 18:02:29 - INFO - __main__ - Step 950 Global step 950 Train loss 0.03 on epoch=237
06/10/2022 18:02:30 - INFO - __main__ - Global step 950 Train loss 0.03 Classification-F1 0.7944396526939222 on epoch=237
06/10/2022 18:02:32 - INFO - __main__ - Step 960 Global step 960 Train loss 0.03 on epoch=239
06/10/2022 18:02:35 - INFO - __main__ - Step 970 Global step 970 Train loss 0.04 on epoch=242
06/10/2022 18:02:37 - INFO - __main__ - Step 980 Global step 980 Train loss 0.10 on epoch=244
06/10/2022 18:02:39 - INFO - __main__ - Step 990 Global step 990 Train loss 0.04 on epoch=247
06/10/2022 18:02:42 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.04 on epoch=249
06/10/2022 18:02:43 - INFO - __main__ - Global step 1000 Train loss 0.05 Classification-F1 0.7975215517241379 on epoch=249
06/10/2022 18:02:45 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.04 on epoch=252
06/10/2022 18:02:47 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.02 on epoch=254
06/10/2022 18:02:50 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.02 on epoch=257
06/10/2022 18:02:52 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.02 on epoch=259
06/10/2022 18:02:55 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.02 on epoch=262
06/10/2022 18:02:55 - INFO - __main__ - Global step 1050 Train loss 0.02 Classification-F1 0.8114538038898439 on epoch=262
06/10/2022 18:02:58 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.03 on epoch=264
06/10/2022 18:03:00 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.06 on epoch=267
06/10/2022 18:03:03 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.03 on epoch=269
06/10/2022 18:03:05 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.02 on epoch=272
06/10/2022 18:03:07 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.04 on epoch=274
06/10/2022 18:03:08 - INFO - __main__ - Global step 1100 Train loss 0.03 Classification-F1 0.7954545454545454 on epoch=274
06/10/2022 18:03:10 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.03 on epoch=277
06/10/2022 18:03:13 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.04 on epoch=279
06/10/2022 18:03:15 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.02 on epoch=282
06/10/2022 18:03:18 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.04 on epoch=284
06/10/2022 18:03:20 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.03 on epoch=287
06/10/2022 18:03:21 - INFO - __main__ - Global step 1150 Train loss 0.03 Classification-F1 0.8267763845350052 on epoch=287
06/10/2022 18:03:23 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.04 on epoch=289
06/10/2022 18:03:25 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.03 on epoch=292
06/10/2022 18:03:28 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.02 on epoch=294
06/10/2022 18:03:30 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.01 on epoch=297
06/10/2022 18:03:33 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=299
06/10/2022 18:03:33 - INFO - __main__ - Global step 1200 Train loss 0.02 Classification-F1 0.808779761904762 on epoch=299
06/10/2022 18:03:36 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.03 on epoch=302
06/10/2022 18:03:38 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=304
06/10/2022 18:03:40 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=307
06/10/2022 18:03:43 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.02 on epoch=309
06/10/2022 18:03:45 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.01 on epoch=312
06/10/2022 18:03:46 - INFO - __main__ - Global step 1250 Train loss 0.01 Classification-F1 0.7942924347158219 on epoch=312
06/10/2022 18:03:48 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.00 on epoch=314
06/10/2022 18:03:51 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.01 on epoch=317
06/10/2022 18:03:53 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=319
06/10/2022 18:03:56 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=322
06/10/2022 18:03:58 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=324
06/10/2022 18:03:59 - INFO - __main__ - Global step 1300 Train loss 0.01 Classification-F1 0.8264159251019653 on epoch=324
06/10/2022 18:04:01 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=327
06/10/2022 18:04:04 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.05 on epoch=329
06/10/2022 18:04:06 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.00 on epoch=332
06/10/2022 18:04:08 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=334
06/10/2022 18:04:11 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=337
06/10/2022 18:04:12 - INFO - __main__ - Global step 1350 Train loss 0.02 Classification-F1 0.8264159251019653 on epoch=337
06/10/2022 18:04:14 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.00 on epoch=339
06/10/2022 18:04:16 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.02 on epoch=342
06/10/2022 18:04:19 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.02 on epoch=344
06/10/2022 18:04:21 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.02 on epoch=347
06/10/2022 18:04:23 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=349
06/10/2022 18:04:24 - INFO - __main__ - Global step 1400 Train loss 0.02 Classification-F1 0.7938176406926407 on epoch=349
06/10/2022 18:04:27 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.03 on epoch=352
06/10/2022 18:04:29 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.08 on epoch=354
06/10/2022 18:04:31 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.00 on epoch=357
06/10/2022 18:04:34 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=359
06/10/2022 18:04:36 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=362
06/10/2022 18:04:37 - INFO - __main__ - Global step 1450 Train loss 0.03 Classification-F1 0.8114538038898439 on epoch=362
06/10/2022 18:04:39 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=364
06/10/2022 18:04:42 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=367
06/10/2022 18:04:44 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.02 on epoch=369
06/10/2022 18:04:46 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=372
06/10/2022 18:04:49 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.02 on epoch=374
06/10/2022 18:04:50 - INFO - __main__ - Global step 1500 Train loss 0.02 Classification-F1 0.7718497189085425 on epoch=374
06/10/2022 18:04:52 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=377
06/10/2022 18:04:54 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=379
06/10/2022 18:04:57 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.02 on epoch=382
06/10/2022 18:04:59 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=384
06/10/2022 18:05:01 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.03 on epoch=387
06/10/2022 18:05:02 - INFO - __main__ - Global step 1550 Train loss 0.01 Classification-F1 0.7955492424242425 on epoch=387
06/10/2022 18:05:05 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=389
06/10/2022 18:05:07 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=392
06/10/2022 18:05:09 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=394
06/10/2022 18:05:12 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=397
06/10/2022 18:05:14 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=399
06/10/2022 18:05:15 - INFO - __main__ - Global step 1600 Train loss 0.01 Classification-F1 0.7941312008674437 on epoch=399
06/10/2022 18:05:17 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=402
06/10/2022 18:05:20 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=404
06/10/2022 18:05:22 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=407
06/10/2022 18:05:24 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.03 on epoch=409
06/10/2022 18:05:27 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=412
06/10/2022 18:05:28 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.8264159251019653 on epoch=412
06/10/2022 18:05:30 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.03 on epoch=414
06/10/2022 18:05:32 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=417
06/10/2022 18:05:35 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.03 on epoch=419
06/10/2022 18:05:37 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=422
06/10/2022 18:05:40 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=424
06/10/2022 18:05:40 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.8264159251019653 on epoch=424
06/10/2022 18:05:43 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=427
06/10/2022 18:05:45 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=429
06/10/2022 18:05:48 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=432
06/10/2022 18:05:50 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=434
06/10/2022 18:05:52 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.04 on epoch=437
06/10/2022 18:05:53 - INFO - __main__ - Global step 1750 Train loss 0.01 Classification-F1 0.8447916666666667 on epoch=437
06/10/2022 18:05:53 - INFO - __main__ - Saving model with best Classification-F1: 0.8407300420168067 -> 0.8447916666666667 on epoch=437, global_step=1750
06/10/2022 18:05:56 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.11 on epoch=439
06/10/2022 18:05:58 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.03 on epoch=442
06/10/2022 18:06:00 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=444
06/10/2022 18:06:03 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=447
06/10/2022 18:06:05 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=449
06/10/2022 18:06:06 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.8117127138261733 on epoch=449
06/10/2022 18:06:08 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=452
06/10/2022 18:06:11 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=454
06/10/2022 18:06:13 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=457
06/10/2022 18:06:15 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=459
06/10/2022 18:06:18 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=462
06/10/2022 18:06:19 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.8264159251019653 on epoch=462
06/10/2022 18:06:21 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=464
06/10/2022 18:06:23 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=467
06/10/2022 18:06:26 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=469
06/10/2022 18:06:28 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=472
06/10/2022 18:06:30 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=474
06/10/2022 18:06:31 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.7952946883337375 on epoch=474
06/10/2022 18:06:34 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=477
06/10/2022 18:06:36 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=479
06/10/2022 18:06:38 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=482
06/10/2022 18:06:41 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=484
06/10/2022 18:06:43 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=487
06/10/2022 18:06:44 - INFO - __main__ - Global step 1950 Train loss 0.00 Classification-F1 0.8066658363432558 on epoch=487
06/10/2022 18:06:47 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.07 on epoch=489
06/10/2022 18:06:49 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=492
06/10/2022 18:06:51 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=494
06/10/2022 18:06:54 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=497
06/10/2022 18:06:56 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=499
06/10/2022 18:06:57 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.8294690860215053 on epoch=499
06/10/2022 18:06:59 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=502
06/10/2022 18:07:02 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=504
06/10/2022 18:07:04 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/10/2022 18:07:06 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=509
06/10/2022 18:07:09 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/10/2022 18:07:10 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.8114538038898439 on epoch=512
06/10/2022 18:07:12 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.04 on epoch=514
06/10/2022 18:07:15 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=517
06/10/2022 18:07:17 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/10/2022 18:07:19 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/10/2022 18:07:22 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/10/2022 18:07:23 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.8114538038898439 on epoch=524
06/10/2022 18:07:25 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
06/10/2022 18:07:27 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=529
06/10/2022 18:07:30 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=532
06/10/2022 18:07:32 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
06/10/2022 18:07:35 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
06/10/2022 18:07:35 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.8129032258064516 on epoch=537
06/10/2022 18:07:38 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/10/2022 18:07:40 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/10/2022 18:07:43 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/10/2022 18:07:45 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/10/2022 18:07:47 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/10/2022 18:07:48 - INFO - __main__ - Global step 2200 Train loss 0.00 Classification-F1 0.8129032258064516 on epoch=549
06/10/2022 18:07:51 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=552
06/10/2022 18:07:53 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/10/2022 18:07:55 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
06/10/2022 18:07:58 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/10/2022 18:08:00 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/10/2022 18:08:01 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.7971774193548387 on epoch=562
06/10/2022 18:08:04 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/10/2022 18:08:06 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=567
06/10/2022 18:08:08 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/10/2022 18:08:11 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/10/2022 18:08:13 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=574
06/10/2022 18:08:14 - INFO - __main__ - Global step 2300 Train loss 0.00 Classification-F1 0.778225806451613 on epoch=574
06/10/2022 18:08:16 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/10/2022 18:08:19 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/10/2022 18:08:21 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.05 on epoch=582
06/10/2022 18:08:23 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=584
06/10/2022 18:08:26 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/10/2022 18:08:27 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.808779761904762 on epoch=587
06/10/2022 18:08:29 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/10/2022 18:08:32 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/10/2022 18:08:34 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/10/2022 18:08:36 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/10/2022 18:08:39 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.12 on epoch=599
06/10/2022 18:08:40 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.8129032258064516 on epoch=599
06/10/2022 18:08:42 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/10/2022 18:08:44 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/10/2022 18:08:47 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/10/2022 18:08:49 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/10/2022 18:08:52 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/10/2022 18:08:53 - INFO - __main__ - Global step 2450 Train loss 0.00 Classification-F1 0.8138440860215053 on epoch=612
06/10/2022 18:08:55 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.05 on epoch=614
06/10/2022 18:08:57 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/10/2022 18:09:00 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/10/2022 18:09:02 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/10/2022 18:09:04 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=624
06/10/2022 18:09:05 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.8426197458455523 on epoch=624
06/10/2022 18:09:08 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/10/2022 18:09:10 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/10/2022 18:09:13 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/10/2022 18:09:15 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/10/2022 18:09:17 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.07 on epoch=637
06/10/2022 18:09:18 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.8140446207808637 on epoch=637
06/10/2022 18:09:21 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=639
06/10/2022 18:09:23 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=642
06/10/2022 18:09:25 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/10/2022 18:09:28 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/10/2022 18:09:30 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/10/2022 18:09:31 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.8116747835497835 on epoch=649
06/10/2022 18:09:34 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/10/2022 18:09:36 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/10/2022 18:09:38 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=657
06/10/2022 18:09:41 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/10/2022 18:09:43 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=662
06/10/2022 18:09:44 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.7905011655011656 on epoch=662
06/10/2022 18:09:46 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/10/2022 18:09:49 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=667
06/10/2022 18:09:51 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=669
06/10/2022 18:09:54 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/10/2022 18:09:56 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/10/2022 18:09:57 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.7938176406926407 on epoch=674
06/10/2022 18:09:59 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/10/2022 18:10:02 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/10/2022 18:10:04 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/10/2022 18:10:06 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=684
06/10/2022 18:10:09 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/10/2022 18:10:10 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.8282258064516129 on epoch=687
06/10/2022 18:10:12 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/10/2022 18:10:15 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/10/2022 18:10:17 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=694
06/10/2022 18:10:19 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/10/2022 18:10:22 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/10/2022 18:10:23 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.7971774193548387 on epoch=699
06/10/2022 18:10:25 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/10/2022 18:10:28 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/10/2022 18:10:30 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=707
06/10/2022 18:10:32 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/10/2022 18:10:35 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/10/2022 18:10:36 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.7971774193548387 on epoch=712
06/10/2022 18:10:38 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/10/2022 18:10:40 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/10/2022 18:10:43 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/10/2022 18:10:45 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/10/2022 18:10:48 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/10/2022 18:10:49 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.7942760942760942 on epoch=724
06/10/2022 18:10:51 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/10/2022 18:10:53 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=729
06/10/2022 18:10:56 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=732
06/10/2022 18:10:58 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=734
06/10/2022 18:11:00 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/10/2022 18:11:02 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.7912346028154851 on epoch=737
06/10/2022 18:11:04 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/10/2022 18:11:06 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.12 on epoch=742
06/10/2022 18:11:09 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.03 on epoch=744
06/10/2022 18:11:11 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/10/2022 18:11:13 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/10/2022 18:11:14 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.7786637931034482 on epoch=749
06/10/2022 18:11:14 - INFO - __main__ - save last model!
06/10/2022 18:11:14 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/10/2022 18:11:14 - INFO - __main__ - Start tokenizing ... 5509 instances
06/10/2022 18:11:14 - INFO - __main__ - Printing 3 examples
06/10/2022 18:11:14 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/10/2022 18:11:14 - INFO - __main__ - ['others']
06/10/2022 18:11:14 - INFO - __main__ -  [emo] what you like very little things ok
06/10/2022 18:11:15 - INFO - __main__ - ['others']
06/10/2022 18:11:15 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/10/2022 18:11:15 - INFO - __main__ - ['others']
06/10/2022 18:11:15 - INFO - __main__ - Tokenizing Input ...
06/10/2022 18:11:15 - INFO - __main__ - Start tokenizing ... 64 instances
06/10/2022 18:11:15 - INFO - __main__ - Printing 3 examples
06/10/2022 18:11:15 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/10/2022 18:11:15 - INFO - __main__ - ['happy']
06/10/2022 18:11:15 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/10/2022 18:11:15 - INFO - __main__ - ['happy']
06/10/2022 18:11:15 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/10/2022 18:11:15 - INFO - __main__ - ['happy']
06/10/2022 18:11:15 - INFO - __main__ - Tokenizing Input ...
06/10/2022 18:11:15 - INFO - __main__ - Tokenizing Output ...
06/10/2022 18:11:15 - INFO - __main__ - Loaded 64 examples from train data
06/10/2022 18:11:15 - INFO - __main__ - Start tokenizing ... 64 instances
06/10/2022 18:11:15 - INFO - __main__ - Printing 3 examples
06/10/2022 18:11:15 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
06/10/2022 18:11:15 - INFO - __main__ - ['happy']
06/10/2022 18:11:15 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
06/10/2022 18:11:15 - INFO - __main__ - ['happy']
06/10/2022 18:11:15 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
06/10/2022 18:11:15 - INFO - __main__ - ['happy']
06/10/2022 18:11:15 - INFO - __main__ - Tokenizing Input ...
06/10/2022 18:11:15 - INFO - __main__ - Tokenizing Output ...
06/10/2022 18:11:15 - INFO - __main__ - Loaded 64 examples from dev data
06/10/2022 18:11:17 - INFO - __main__ - Tokenizing Output ...
06/10/2022 18:11:22 - INFO - __main__ - Loaded 5509 examples from test data
06/10/2022 18:11:30 - INFO - __main__ - load prompt embedding from ckpt
06/10/2022 18:11:31 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/10/2022 18:11:31 - INFO - __main__ - Starting training!
06/10/2022 18:12:53 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-up32shot/singletask-emo/emo_16_42_0.5_8_predictions.txt
06/10/2022 18:12:53 - INFO - __main__ - Classification-F1 on test data: 0.3103
06/10/2022 18:12:54 - INFO - __main__ - prefix=emo_16_42, lr=0.5, bsz=8, dev_performance=0.8447916666666667, test_performance=0.3103025694706843
06/10/2022 18:12:54 - INFO - __main__ - Running ... prefix=emo_16_42, lr=0.4, bsz=8 ...
06/10/2022 18:12:54 - INFO - __main__ - Start tokenizing ... 64 instances
06/10/2022 18:12:54 - INFO - __main__ - Printing 3 examples
06/10/2022 18:12:54 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/10/2022 18:12:54 - INFO - __main__ - ['happy']
06/10/2022 18:12:54 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/10/2022 18:12:54 - INFO - __main__ - ['happy']
06/10/2022 18:12:54 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/10/2022 18:12:54 - INFO - __main__ - ['happy']
06/10/2022 18:12:54 - INFO - __main__ - Tokenizing Input ...
06/10/2022 18:12:55 - INFO - __main__ - Tokenizing Output ...
06/10/2022 18:12:55 - INFO - __main__ - Loaded 64 examples from train data
06/10/2022 18:12:55 - INFO - __main__ - Start tokenizing ... 64 instances
06/10/2022 18:12:55 - INFO - __main__ - Printing 3 examples
06/10/2022 18:12:55 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
06/10/2022 18:12:55 - INFO - __main__ - ['happy']
06/10/2022 18:12:55 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
06/10/2022 18:12:55 - INFO - __main__ - ['happy']
06/10/2022 18:12:55 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
06/10/2022 18:12:55 - INFO - __main__ - ['happy']
06/10/2022 18:12:55 - INFO - __main__ - Tokenizing Input ...
06/10/2022 18:12:55 - INFO - __main__ - Tokenizing Output ...
06/10/2022 18:12:55 - INFO - __main__ - Loaded 64 examples from dev data
06/10/2022 18:13:10 - INFO - __main__ - load prompt embedding from ckpt
06/10/2022 18:13:11 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/10/2022 18:13:11 - INFO - __main__ - Starting training!
06/10/2022 18:13:14 - INFO - __main__ - Step 10 Global step 10 Train loss 3.48 on epoch=2
06/10/2022 18:13:16 - INFO - __main__ - Step 20 Global step 20 Train loss 2.78 on epoch=4
06/10/2022 18:13:18 - INFO - __main__ - Step 30 Global step 30 Train loss 2.02 on epoch=7
06/10/2022 18:13:21 - INFO - __main__ - Step 40 Global step 40 Train loss 1.58 on epoch=9
06/10/2022 18:13:23 - INFO - __main__ - Step 50 Global step 50 Train loss 1.30 on epoch=12
06/10/2022 18:13:24 - INFO - __main__ - Global step 50 Train loss 2.23 Classification-F1 0.4762254901960785 on epoch=12
06/10/2022 18:13:24 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.4762254901960785 on epoch=12, global_step=50
06/10/2022 18:13:27 - INFO - __main__ - Step 60 Global step 60 Train loss 1.11 on epoch=14
06/10/2022 18:13:29 - INFO - __main__ - Step 70 Global step 70 Train loss 0.89 on epoch=17
06/10/2022 18:13:32 - INFO - __main__ - Step 80 Global step 80 Train loss 0.76 on epoch=19
06/10/2022 18:13:34 - INFO - __main__ - Step 90 Global step 90 Train loss 0.77 on epoch=22
06/10/2022 18:13:36 - INFO - __main__ - Step 100 Global step 100 Train loss 0.86 on epoch=24
06/10/2022 18:13:37 - INFO - __main__ - Global step 100 Train loss 0.88 Classification-F1 0.4108692948638229 on epoch=24
06/10/2022 18:13:39 - INFO - __main__ - Step 110 Global step 110 Train loss 0.77 on epoch=27
06/10/2022 18:13:42 - INFO - __main__ - Step 120 Global step 120 Train loss 0.74 on epoch=29
06/10/2022 18:13:44 - INFO - __main__ - Step 130 Global step 130 Train loss 0.65 on epoch=32
06/10/2022 18:13:47 - INFO - __main__ - Step 140 Global step 140 Train loss 0.74 on epoch=34
06/10/2022 18:13:49 - INFO - __main__ - Step 150 Global step 150 Train loss 0.54 on epoch=37
06/10/2022 18:13:50 - INFO - __main__ - Global step 150 Train loss 0.69 Classification-F1 0.4343567024700453 on epoch=37
06/10/2022 18:13:52 - INFO - __main__ - Step 160 Global step 160 Train loss 0.63 on epoch=39
06/10/2022 18:13:55 - INFO - __main__ - Step 170 Global step 170 Train loss 0.60 on epoch=42
06/10/2022 18:13:57 - INFO - __main__ - Step 180 Global step 180 Train loss 0.70 on epoch=44
06/10/2022 18:13:59 - INFO - __main__ - Step 190 Global step 190 Train loss 0.55 on epoch=47
06/10/2022 18:14:02 - INFO - __main__ - Step 200 Global step 200 Train loss 0.50 on epoch=49
06/10/2022 18:14:03 - INFO - __main__ - Global step 200 Train loss 0.60 Classification-F1 0.5998879551820728 on epoch=49
06/10/2022 18:14:03 - INFO - __main__ - Saving model with best Classification-F1: 0.4762254901960785 -> 0.5998879551820728 on epoch=49, global_step=200
06/10/2022 18:14:05 - INFO - __main__ - Step 210 Global step 210 Train loss 0.55 on epoch=52
06/10/2022 18:14:07 - INFO - __main__ - Step 220 Global step 220 Train loss 0.48 on epoch=54
06/10/2022 18:14:10 - INFO - __main__ - Step 230 Global step 230 Train loss 0.52 on epoch=57
06/10/2022 18:14:12 - INFO - __main__ - Step 240 Global step 240 Train loss 0.54 on epoch=59
06/10/2022 18:14:14 - INFO - __main__ - Step 250 Global step 250 Train loss 0.43 on epoch=62
06/10/2022 18:14:15 - INFO - __main__ - Global step 250 Train loss 0.50 Classification-F1 0.5931143366437484 on epoch=62
06/10/2022 18:14:18 - INFO - __main__ - Step 260 Global step 260 Train loss 0.51 on epoch=64
06/10/2022 18:14:20 - INFO - __main__ - Step 270 Global step 270 Train loss 0.48 on epoch=67
06/10/2022 18:14:22 - INFO - __main__ - Step 280 Global step 280 Train loss 0.34 on epoch=69
06/10/2022 18:14:25 - INFO - __main__ - Step 290 Global step 290 Train loss 0.42 on epoch=72
06/10/2022 18:14:27 - INFO - __main__ - Step 300 Global step 300 Train loss 0.39 on epoch=74
06/10/2022 18:14:28 - INFO - __main__ - Global step 300 Train loss 0.43 Classification-F1 0.618100539811066 on epoch=74
06/10/2022 18:14:28 - INFO - __main__ - Saving model with best Classification-F1: 0.5998879551820728 -> 0.618100539811066 on epoch=74, global_step=300
06/10/2022 18:14:30 - INFO - __main__ - Step 310 Global step 310 Train loss 0.46 on epoch=77
06/10/2022 18:14:33 - INFO - __main__ - Step 320 Global step 320 Train loss 0.39 on epoch=79
06/10/2022 18:14:35 - INFO - __main__ - Step 330 Global step 330 Train loss 0.40 on epoch=82
06/10/2022 18:14:37 - INFO - __main__ - Step 340 Global step 340 Train loss 0.41 on epoch=84
06/10/2022 18:14:40 - INFO - __main__ - Step 350 Global step 350 Train loss 0.36 on epoch=87
06/10/2022 18:14:41 - INFO - __main__ - Global step 350 Train loss 0.40 Classification-F1 0.5786600496277916 on epoch=87
06/10/2022 18:14:43 - INFO - __main__ - Step 360 Global step 360 Train loss 0.32 on epoch=89
06/10/2022 18:14:45 - INFO - __main__ - Step 370 Global step 370 Train loss 0.25 on epoch=92
06/10/2022 18:14:48 - INFO - __main__ - Step 380 Global step 380 Train loss 0.31 on epoch=94
06/10/2022 18:14:50 - INFO - __main__ - Step 390 Global step 390 Train loss 0.31 on epoch=97
06/10/2022 18:14:53 - INFO - __main__ - Step 400 Global step 400 Train loss 0.34 on epoch=99
06/10/2022 18:14:53 - INFO - __main__ - Global step 400 Train loss 0.31 Classification-F1 0.6172562920950018 on epoch=99
06/10/2022 18:14:56 - INFO - __main__ - Step 410 Global step 410 Train loss 0.34 on epoch=102
06/10/2022 18:14:58 - INFO - __main__ - Step 420 Global step 420 Train loss 0.27 on epoch=104
06/10/2022 18:15:00 - INFO - __main__ - Step 430 Global step 430 Train loss 0.20 on epoch=107
06/10/2022 18:15:03 - INFO - __main__ - Step 440 Global step 440 Train loss 0.37 on epoch=109
06/10/2022 18:15:05 - INFO - __main__ - Step 450 Global step 450 Train loss 0.30 on epoch=112
06/10/2022 18:15:06 - INFO - __main__ - Global step 450 Train loss 0.30 Classification-F1 0.6031984549730554 on epoch=112
06/10/2022 18:15:08 - INFO - __main__ - Step 460 Global step 460 Train loss 0.28 on epoch=114
06/10/2022 18:15:11 - INFO - __main__ - Step 470 Global step 470 Train loss 0.29 on epoch=117
06/10/2022 18:15:13 - INFO - __main__ - Step 480 Global step 480 Train loss 0.24 on epoch=119
06/10/2022 18:15:16 - INFO - __main__ - Step 490 Global step 490 Train loss 0.22 on epoch=122
06/10/2022 18:15:18 - INFO - __main__ - Step 500 Global step 500 Train loss 0.23 on epoch=124
06/10/2022 18:15:19 - INFO - __main__ - Global step 500 Train loss 0.25 Classification-F1 0.6295035290101703 on epoch=124
06/10/2022 18:15:19 - INFO - __main__ - Saving model with best Classification-F1: 0.618100539811066 -> 0.6295035290101703 on epoch=124, global_step=500
06/10/2022 18:15:21 - INFO - __main__ - Step 510 Global step 510 Train loss 0.18 on epoch=127
06/10/2022 18:15:24 - INFO - __main__ - Step 520 Global step 520 Train loss 0.20 on epoch=129
06/10/2022 18:15:26 - INFO - __main__ - Step 530 Global step 530 Train loss 0.17 on epoch=132
06/10/2022 18:15:28 - INFO - __main__ - Step 540 Global step 540 Train loss 0.20 on epoch=134
06/10/2022 18:15:31 - INFO - __main__ - Step 550 Global step 550 Train loss 0.15 on epoch=137
06/10/2022 18:15:32 - INFO - __main__ - Global step 550 Train loss 0.18 Classification-F1 0.7589869281045751 on epoch=137
06/10/2022 18:15:32 - INFO - __main__ - Saving model with best Classification-F1: 0.6295035290101703 -> 0.7589869281045751 on epoch=137, global_step=550
06/10/2022 18:15:34 - INFO - __main__ - Step 560 Global step 560 Train loss 0.20 on epoch=139
06/10/2022 18:15:36 - INFO - __main__ - Step 570 Global step 570 Train loss 0.18 on epoch=142
06/10/2022 18:15:39 - INFO - __main__ - Step 580 Global step 580 Train loss 0.14 on epoch=144
06/10/2022 18:15:41 - INFO - __main__ - Step 590 Global step 590 Train loss 0.20 on epoch=147
06/10/2022 18:15:43 - INFO - __main__ - Step 600 Global step 600 Train loss 0.11 on epoch=149
06/10/2022 18:15:44 - INFO - __main__ - Global step 600 Train loss 0.17 Classification-F1 0.8413660413660414 on epoch=149
06/10/2022 18:15:44 - INFO - __main__ - Saving model with best Classification-F1: 0.7589869281045751 -> 0.8413660413660414 on epoch=149, global_step=600
06/10/2022 18:15:47 - INFO - __main__ - Step 610 Global step 610 Train loss 0.16 on epoch=152
06/10/2022 18:15:49 - INFO - __main__ - Step 620 Global step 620 Train loss 0.14 on epoch=154
06/10/2022 18:15:52 - INFO - __main__ - Step 630 Global step 630 Train loss 0.19 on epoch=157
06/10/2022 18:15:54 - INFO - __main__ - Step 640 Global step 640 Train loss 0.12 on epoch=159
06/10/2022 18:15:56 - INFO - __main__ - Step 650 Global step 650 Train loss 0.12 on epoch=162
06/10/2022 18:15:57 - INFO - __main__ - Global step 650 Train loss 0.15 Classification-F1 0.8146569865319866 on epoch=162
06/10/2022 18:16:00 - INFO - __main__ - Step 660 Global step 660 Train loss 0.12 on epoch=164
06/10/2022 18:16:02 - INFO - __main__ - Step 670 Global step 670 Train loss 0.09 on epoch=167
06/10/2022 18:16:04 - INFO - __main__ - Step 680 Global step 680 Train loss 0.10 on epoch=169
06/10/2022 18:16:07 - INFO - __main__ - Step 690 Global step 690 Train loss 0.08 on epoch=172
06/10/2022 18:16:09 - INFO - __main__ - Step 700 Global step 700 Train loss 0.16 on epoch=174
06/10/2022 18:16:10 - INFO - __main__ - Global step 700 Train loss 0.11 Classification-F1 0.8407756205930649 on epoch=174
06/10/2022 18:16:12 - INFO - __main__ - Step 710 Global step 710 Train loss 0.09 on epoch=177
06/10/2022 18:16:15 - INFO - __main__ - Step 720 Global step 720 Train loss 0.12 on epoch=179
06/10/2022 18:16:17 - INFO - __main__ - Step 730 Global step 730 Train loss 0.04 on epoch=182
06/10/2022 18:16:19 - INFO - __main__ - Step 740 Global step 740 Train loss 0.11 on epoch=184
06/10/2022 18:16:22 - INFO - __main__ - Step 750 Global step 750 Train loss 0.13 on epoch=187
06/10/2022 18:16:23 - INFO - __main__ - Global step 750 Train loss 0.10 Classification-F1 0.8167664087967692 on epoch=187
06/10/2022 18:16:25 - INFO - __main__ - Step 760 Global step 760 Train loss 0.07 on epoch=189
06/10/2022 18:16:27 - INFO - __main__ - Step 770 Global step 770 Train loss 0.08 on epoch=192
06/10/2022 18:16:30 - INFO - __main__ - Step 780 Global step 780 Train loss 0.08 on epoch=194
06/10/2022 18:16:32 - INFO - __main__ - Step 790 Global step 790 Train loss 0.12 on epoch=197
06/10/2022 18:16:35 - INFO - __main__ - Step 800 Global step 800 Train loss 0.09 on epoch=199
06/10/2022 18:16:35 - INFO - __main__ - Global step 800 Train loss 0.09 Classification-F1 0.8209722222222222 on epoch=199
06/10/2022 18:16:38 - INFO - __main__ - Step 810 Global step 810 Train loss 0.16 on epoch=202
06/10/2022 18:16:40 - INFO - __main__ - Step 820 Global step 820 Train loss 0.06 on epoch=204
06/10/2022 18:16:43 - INFO - __main__ - Step 830 Global step 830 Train loss 0.05 on epoch=207
06/10/2022 18:16:45 - INFO - __main__ - Step 840 Global step 840 Train loss 0.10 on epoch=209
06/10/2022 18:16:47 - INFO - __main__ - Step 850 Global step 850 Train loss 0.08 on epoch=212
06/10/2022 18:16:48 - INFO - __main__ - Global step 850 Train loss 0.09 Classification-F1 0.835654761904762 on epoch=212
06/10/2022 18:16:51 - INFO - __main__ - Step 860 Global step 860 Train loss 0.12 on epoch=214
06/10/2022 18:16:53 - INFO - __main__ - Step 870 Global step 870 Train loss 0.08 on epoch=217
06/10/2022 18:16:55 - INFO - __main__ - Step 880 Global step 880 Train loss 0.06 on epoch=219
06/10/2022 18:16:58 - INFO - __main__ - Step 890 Global step 890 Train loss 0.06 on epoch=222
06/10/2022 18:17:00 - INFO - __main__ - Step 900 Global step 900 Train loss 0.05 on epoch=224
06/10/2022 18:17:01 - INFO - __main__ - Global step 900 Train loss 0.07 Classification-F1 0.834978354978355 on epoch=224
06/10/2022 18:17:03 - INFO - __main__ - Step 910 Global step 910 Train loss 0.11 on epoch=227
06/10/2022 18:17:06 - INFO - __main__ - Step 920 Global step 920 Train loss 0.10 on epoch=229
06/10/2022 18:17:08 - INFO - __main__ - Step 930 Global step 930 Train loss 0.05 on epoch=232
06/10/2022 18:17:11 - INFO - __main__ - Step 940 Global step 940 Train loss 0.15 on epoch=234
06/10/2022 18:17:13 - INFO - __main__ - Step 950 Global step 950 Train loss 0.05 on epoch=237
06/10/2022 18:17:14 - INFO - __main__ - Global step 950 Train loss 0.09 Classification-F1 0.8130310684711408 on epoch=237
06/10/2022 18:17:16 - INFO - __main__ - Step 960 Global step 960 Train loss 0.04 on epoch=239
06/10/2022 18:17:19 - INFO - __main__ - Step 970 Global step 970 Train loss 0.04 on epoch=242
06/10/2022 18:17:21 - INFO - __main__ - Step 980 Global step 980 Train loss 0.09 on epoch=244
06/10/2022 18:17:23 - INFO - __main__ - Step 990 Global step 990 Train loss 0.03 on epoch=247
06/10/2022 18:17:26 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.16 on epoch=249
06/10/2022 18:17:26 - INFO - __main__ - Global step 1000 Train loss 0.07 Classification-F1 0.8049765646539839 on epoch=249
06/10/2022 18:17:29 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.03 on epoch=252
06/10/2022 18:17:31 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.04 on epoch=254
06/10/2022 18:17:34 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.04 on epoch=257
06/10/2022 18:17:36 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.08 on epoch=259
06/10/2022 18:17:38 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.04 on epoch=262
06/10/2022 18:17:39 - INFO - __main__ - Global step 1050 Train loss 0.05 Classification-F1 0.8060452804285821 on epoch=262
06/10/2022 18:17:42 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.03 on epoch=264
06/10/2022 18:17:44 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.07 on epoch=267
06/10/2022 18:17:46 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.08 on epoch=269
06/10/2022 18:17:49 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.03 on epoch=272
06/10/2022 18:17:51 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.02 on epoch=274
06/10/2022 18:17:52 - INFO - __main__ - Global step 1100 Train loss 0.05 Classification-F1 0.8196591043365237 on epoch=274
06/10/2022 18:17:54 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.04 on epoch=277
06/10/2022 18:17:57 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.04 on epoch=279
06/10/2022 18:17:59 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.04 on epoch=282
06/10/2022 18:18:01 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.02 on epoch=284
06/10/2022 18:18:04 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.02 on epoch=287
06/10/2022 18:18:05 - INFO - __main__ - Global step 1150 Train loss 0.03 Classification-F1 0.7806020733652312 on epoch=287
06/10/2022 18:18:07 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.03 on epoch=289
06/10/2022 18:18:09 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.11 on epoch=292
06/10/2022 18:18:12 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.03 on epoch=294
06/10/2022 18:18:14 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.02 on epoch=297
06/10/2022 18:18:17 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.07 on epoch=299
06/10/2022 18:18:17 - INFO - __main__ - Global step 1200 Train loss 0.05 Classification-F1 0.8052656546489564 on epoch=299
06/10/2022 18:18:20 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.03 on epoch=302
06/10/2022 18:18:22 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=304
06/10/2022 18:18:25 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.03 on epoch=307
06/10/2022 18:18:27 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=309
06/10/2022 18:18:29 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.03 on epoch=312
06/10/2022 18:18:30 - INFO - __main__ - Global step 1250 Train loss 0.02 Classification-F1 0.7911680008454203 on epoch=312
06/10/2022 18:18:33 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.07 on epoch=314
06/10/2022 18:18:35 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.05 on epoch=317
06/10/2022 18:18:37 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.04 on epoch=319
06/10/2022 18:18:40 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.02 on epoch=322
06/10/2022 18:18:42 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.02 on epoch=324
06/10/2022 18:18:43 - INFO - __main__ - Global step 1300 Train loss 0.04 Classification-F1 0.7864159379968204 on epoch=324
06/10/2022 18:18:45 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.02 on epoch=327
06/10/2022 18:18:48 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.08 on epoch=329
06/10/2022 18:18:50 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.02 on epoch=332
06/10/2022 18:18:52 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.03 on epoch=334
06/10/2022 18:18:55 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.05 on epoch=337
06/10/2022 18:18:56 - INFO - __main__ - Global step 1350 Train loss 0.04 Classification-F1 0.7732009925558312 on epoch=337
06/10/2022 18:18:58 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=339
06/10/2022 18:19:00 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.03 on epoch=342
06/10/2022 18:19:03 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.02 on epoch=344
06/10/2022 18:19:05 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=347
06/10/2022 18:19:08 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.03 on epoch=349
06/10/2022 18:19:08 - INFO - __main__ - Global step 1400 Train loss 0.02 Classification-F1 0.8435972629521017 on epoch=349
06/10/2022 18:19:08 - INFO - __main__ - Saving model with best Classification-F1: 0.8413660413660414 -> 0.8435972629521017 on epoch=349, global_step=1400
06/10/2022 18:19:11 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=352
06/10/2022 18:19:13 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=354
06/10/2022 18:19:16 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.05 on epoch=357
06/10/2022 18:19:18 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=359
06/10/2022 18:19:20 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.03 on epoch=362
06/10/2022 18:19:21 - INFO - __main__ - Global step 1450 Train loss 0.02 Classification-F1 0.7861354331942568 on epoch=362
06/10/2022 18:19:24 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=364
06/10/2022 18:19:26 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=367
06/10/2022 18:19:28 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=369
06/10/2022 18:19:31 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=372
06/10/2022 18:19:33 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.03 on epoch=374
06/10/2022 18:19:34 - INFO - __main__ - Global step 1500 Train loss 0.01 Classification-F1 0.8061126373626373 on epoch=374
06/10/2022 18:19:36 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.03 on epoch=377
06/10/2022 18:19:39 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.02 on epoch=379
06/10/2022 18:19:41 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=382
06/10/2022 18:19:43 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=384
06/10/2022 18:19:46 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.07 on epoch=387
06/10/2022 18:19:47 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.8243897306397306 on epoch=387
06/10/2022 18:19:49 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=389
06/10/2022 18:19:51 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.03 on epoch=392
06/10/2022 18:19:54 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.02 on epoch=394
06/10/2022 18:19:56 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=397
06/10/2022 18:19:58 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=399
06/10/2022 18:19:59 - INFO - __main__ - Global step 1600 Train loss 0.02 Classification-F1 0.8275828361479085 on epoch=399
06/10/2022 18:20:02 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=402
06/10/2022 18:20:04 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=404
06/10/2022 18:20:06 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=407
06/10/2022 18:20:09 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=409
06/10/2022 18:20:11 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=412
06/10/2022 18:20:12 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.806650837900838 on epoch=412
06/10/2022 18:20:14 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=414
06/10/2022 18:20:17 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=417
06/10/2022 18:20:19 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.03 on epoch=419
06/10/2022 18:20:21 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.03 on epoch=422
06/10/2022 18:20:24 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=424
06/10/2022 18:20:25 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.8102602331255083 on epoch=424
06/10/2022 18:20:27 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.03 on epoch=427
06/10/2022 18:20:29 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=429
06/10/2022 18:20:32 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=432
06/10/2022 18:20:34 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=434
06/10/2022 18:20:37 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=437
06/10/2022 18:20:37 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.8203828828828829 on epoch=437
06/10/2022 18:20:40 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.05 on epoch=439
06/10/2022 18:20:42 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.05 on epoch=442
06/10/2022 18:20:44 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=444
06/10/2022 18:20:47 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=447
06/10/2022 18:20:49 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=449
06/10/2022 18:20:50 - INFO - __main__ - Global step 1800 Train loss 0.02 Classification-F1 0.7912990196078431 on epoch=449
06/10/2022 18:20:52 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=452
06/10/2022 18:20:55 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=454
06/10/2022 18:20:57 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=457
06/10/2022 18:20:59 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.06 on epoch=459
06/10/2022 18:21:02 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=462
06/10/2022 18:21:03 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.805620401810979 on epoch=462
06/10/2022 18:21:05 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.05 on epoch=464
06/10/2022 18:21:08 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=467
06/10/2022 18:21:10 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=469
06/10/2022 18:21:12 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=472
06/10/2022 18:21:15 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=474
06/10/2022 18:21:15 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.8238477209065445 on epoch=474
06/10/2022 18:21:18 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=477
06/10/2022 18:21:20 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=479
06/10/2022 18:21:23 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=482
06/10/2022 18:21:25 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=484
06/10/2022 18:21:27 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=487
06/10/2022 18:21:28 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.8203828828828829 on epoch=487
06/10/2022 18:21:31 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=489
06/10/2022 18:21:33 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=492
06/10/2022 18:21:35 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=494
06/10/2022 18:21:38 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.04 on epoch=497
06/10/2022 18:21:40 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=499
06/10/2022 18:21:41 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.7818965517241379 on epoch=499
06/10/2022 18:21:43 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=502
06/10/2022 18:21:46 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.04 on epoch=504
06/10/2022 18:21:48 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=507
06/10/2022 18:21:51 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.10 on epoch=509
06/10/2022 18:21:53 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.13 on epoch=512
06/10/2022 18:21:54 - INFO - __main__ - Global step 2050 Train loss 0.06 Classification-F1 0.7644153225806452 on epoch=512
06/10/2022 18:21:56 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.03 on epoch=514
06/10/2022 18:21:59 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=517
06/10/2022 18:22:01 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/10/2022 18:22:03 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=522
06/10/2022 18:22:06 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=524
06/10/2022 18:22:07 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.8564612135176651 on epoch=524
06/10/2022 18:22:07 - INFO - __main__ - Saving model with best Classification-F1: 0.8435972629521017 -> 0.8564612135176651 on epoch=524, global_step=2100
06/10/2022 18:22:09 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=527
06/10/2022 18:22:11 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=529
06/10/2022 18:22:14 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=532
06/10/2022 18:22:16 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=534
06/10/2022 18:22:18 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
06/10/2022 18:22:19 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.8090535334368352 on epoch=537
06/10/2022 18:22:22 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=539
06/10/2022 18:22:24 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/10/2022 18:22:26 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/10/2022 18:22:29 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/10/2022 18:22:31 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/10/2022 18:22:32 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.8414746543778802 on epoch=549
06/10/2022 18:22:35 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=552
06/10/2022 18:22:37 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=554
06/10/2022 18:22:39 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=557
06/10/2022 18:22:42 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/10/2022 18:22:44 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=562
06/10/2022 18:22:45 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.8259856630824373 on epoch=562
06/10/2022 18:22:47 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/10/2022 18:22:50 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/10/2022 18:22:52 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/10/2022 18:22:54 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=572
06/10/2022 18:22:57 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=574
06/10/2022 18:22:58 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.8053579212853407 on epoch=574
06/10/2022 18:23:00 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/10/2022 18:23:02 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/10/2022 18:23:05 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/10/2022 18:23:07 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.05 on epoch=584
06/10/2022 18:23:10 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=587
06/10/2022 18:23:11 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.8585445468509983 on epoch=587
06/10/2022 18:23:11 - INFO - __main__ - Saving model with best Classification-F1: 0.8564612135176651 -> 0.8585445468509983 on epoch=587, global_step=2350
06/10/2022 18:23:13 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/10/2022 18:23:15 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=592
06/10/2022 18:23:18 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=594
06/10/2022 18:23:20 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.09 on epoch=597
06/10/2022 18:23:23 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/10/2022 18:23:23 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.8198330295104489 on epoch=599
06/10/2022 18:23:26 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/10/2022 18:23:28 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/10/2022 18:23:31 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=607
06/10/2022 18:23:33 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=609
06/10/2022 18:23:35 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=612
06/10/2022 18:23:36 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.7755199101973296 on epoch=612
06/10/2022 18:23:39 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=614
06/10/2022 18:23:41 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=617
06/10/2022 18:23:43 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/10/2022 18:23:46 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=622
06/10/2022 18:23:48 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/10/2022 18:23:49 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.8084981388652134 on epoch=624
06/10/2022 18:23:51 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/10/2022 18:23:54 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/10/2022 18:23:56 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/10/2022 18:23:59 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/10/2022 18:24:01 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=637
06/10/2022 18:24:02 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.8564612135176651 on epoch=637
06/10/2022 18:24:04 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.04 on epoch=639
06/10/2022 18:24:07 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/10/2022 18:24:09 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/10/2022 18:24:11 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/10/2022 18:24:14 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.04 on epoch=649
06/10/2022 18:24:15 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.8049765646539839 on epoch=649
06/10/2022 18:24:17 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/10/2022 18:24:19 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/10/2022 18:24:22 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=657
06/10/2022 18:24:24 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/10/2022 18:24:27 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=662
06/10/2022 18:24:27 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.8198330295104489 on epoch=662
06/10/2022 18:24:30 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/10/2022 18:24:32 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/10/2022 18:24:35 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/10/2022 18:24:37 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/10/2022 18:24:39 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/10/2022 18:24:40 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.8424676066500316 on epoch=674
06/10/2022 18:24:43 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/10/2022 18:24:45 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=679
06/10/2022 18:24:47 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/10/2022 18:24:50 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/10/2022 18:24:52 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=687
06/10/2022 18:24:53 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.8582437275985663 on epoch=687
06/10/2022 18:24:55 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/10/2022 18:24:58 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=692
06/10/2022 18:25:00 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/10/2022 18:25:03 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=697
06/10/2022 18:25:05 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/10/2022 18:25:06 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.8418492323615664 on epoch=699
06/10/2022 18:25:08 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=702
06/10/2022 18:25:11 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/10/2022 18:25:13 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/10/2022 18:25:15 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/10/2022 18:25:18 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/10/2022 18:25:19 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.8418492323615664 on epoch=712
06/10/2022 18:25:21 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/10/2022 18:25:24 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/10/2022 18:25:26 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=719
06/10/2022 18:25:28 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/10/2022 18:25:31 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/10/2022 18:25:32 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.8586930740037951 on epoch=724
06/10/2022 18:25:32 - INFO - __main__ - Saving model with best Classification-F1: 0.8585445468509983 -> 0.8586930740037951 on epoch=724, global_step=2900
06/10/2022 18:25:34 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/10/2022 18:25:36 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=729
06/10/2022 18:25:39 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/10/2022 18:25:41 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/10/2022 18:25:44 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=737
06/10/2022 18:25:45 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.8238095238095239 on epoch=737
06/10/2022 18:25:47 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=739
06/10/2022 18:25:49 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=742
06/10/2022 18:25:52 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/10/2022 18:25:54 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/10/2022 18:25:57 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/10/2022 18:25:58 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.8271433500086252 on epoch=749
06/10/2022 18:25:58 - INFO - __main__ - save last model!
06/10/2022 18:25:58 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/10/2022 18:25:58 - INFO - __main__ - Start tokenizing ... 5509 instances
06/10/2022 18:25:58 - INFO - __main__ - Printing 3 examples
06/10/2022 18:25:58 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/10/2022 18:25:58 - INFO - __main__ - ['others']
06/10/2022 18:25:58 - INFO - __main__ -  [emo] what you like very little things ok
06/10/2022 18:25:58 - INFO - __main__ - ['others']
06/10/2022 18:25:58 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/10/2022 18:25:58 - INFO - __main__ - ['others']
06/10/2022 18:25:58 - INFO - __main__ - Tokenizing Input ...
06/10/2022 18:25:58 - INFO - __main__ - Start tokenizing ... 64 instances
06/10/2022 18:25:58 - INFO - __main__ - Printing 3 examples
06/10/2022 18:25:58 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/10/2022 18:25:58 - INFO - __main__ - ['happy']
06/10/2022 18:25:58 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/10/2022 18:25:58 - INFO - __main__ - ['happy']
06/10/2022 18:25:58 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/10/2022 18:25:58 - INFO - __main__ - ['happy']
06/10/2022 18:25:58 - INFO - __main__ - Tokenizing Input ...
06/10/2022 18:25:58 - INFO - __main__ - Tokenizing Output ...
06/10/2022 18:25:58 - INFO - __main__ - Loaded 64 examples from train data
06/10/2022 18:25:58 - INFO - __main__ - Start tokenizing ... 64 instances
06/10/2022 18:25:58 - INFO - __main__ - Printing 3 examples
06/10/2022 18:25:58 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
06/10/2022 18:25:58 - INFO - __main__ - ['happy']
06/10/2022 18:25:58 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
06/10/2022 18:25:58 - INFO - __main__ - ['happy']
06/10/2022 18:25:58 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
06/10/2022 18:25:58 - INFO - __main__ - ['happy']
06/10/2022 18:25:58 - INFO - __main__ - Tokenizing Input ...
06/10/2022 18:25:58 - INFO - __main__ - Tokenizing Output ...
06/10/2022 18:25:58 - INFO - __main__ - Loaded 64 examples from dev data
06/10/2022 18:26:00 - INFO - __main__ - Tokenizing Output ...
06/10/2022 18:26:05 - INFO - __main__ - Loaded 5509 examples from test data
06/10/2022 18:26:13 - INFO - __main__ - load prompt embedding from ckpt
06/10/2022 18:26:14 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/10/2022 18:26:14 - INFO - __main__ - Starting training!
06/10/2022 18:27:39 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-up32shot/singletask-emo/emo_16_42_0.4_8_predictions.txt
06/10/2022 18:27:39 - INFO - __main__ - Classification-F1 on test data: 0.3676
06/10/2022 18:27:39 - INFO - __main__ - prefix=emo_16_42, lr=0.4, bsz=8, dev_performance=0.8586930740037951, test_performance=0.36760683985298803
06/10/2022 18:27:39 - INFO - __main__ - Running ... prefix=emo_16_42, lr=0.3, bsz=8 ...
06/10/2022 18:27:40 - INFO - __main__ - Start tokenizing ... 64 instances
06/10/2022 18:27:40 - INFO - __main__ - Printing 3 examples
06/10/2022 18:27:40 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/10/2022 18:27:40 - INFO - __main__ - ['happy']
06/10/2022 18:27:40 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/10/2022 18:27:40 - INFO - __main__ - ['happy']
06/10/2022 18:27:40 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/10/2022 18:27:40 - INFO - __main__ - ['happy']
06/10/2022 18:27:40 - INFO - __main__ - Tokenizing Input ...
06/10/2022 18:27:40 - INFO - __main__ - Tokenizing Output ...
06/10/2022 18:27:40 - INFO - __main__ - Loaded 64 examples from train data
06/10/2022 18:27:40 - INFO - __main__ - Start tokenizing ... 64 instances
06/10/2022 18:27:40 - INFO - __main__ - Printing 3 examples
06/10/2022 18:27:40 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
06/10/2022 18:27:40 - INFO - __main__ - ['happy']
06/10/2022 18:27:40 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
06/10/2022 18:27:40 - INFO - __main__ - ['happy']
06/10/2022 18:27:40 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
06/10/2022 18:27:40 - INFO - __main__ - ['happy']
06/10/2022 18:27:40 - INFO - __main__ - Tokenizing Input ...
06/10/2022 18:27:40 - INFO - __main__ - Tokenizing Output ...
06/10/2022 18:27:40 - INFO - __main__ - Loaded 64 examples from dev data
06/10/2022 18:27:55 - INFO - __main__ - load prompt embedding from ckpt
06/10/2022 18:27:56 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/10/2022 18:27:56 - INFO - __main__ - Starting training!
06/10/2022 18:27:59 - INFO - __main__ - Step 10 Global step 10 Train loss 4.23 on epoch=2
06/10/2022 18:28:01 - INFO - __main__ - Step 20 Global step 20 Train loss 3.02 on epoch=4
06/10/2022 18:28:04 - INFO - __main__ - Step 30 Global step 30 Train loss 2.50 on epoch=7
06/10/2022 18:28:06 - INFO - __main__ - Step 40 Global step 40 Train loss 2.24 on epoch=9
06/10/2022 18:28:09 - INFO - __main__ - Step 50 Global step 50 Train loss 1.76 on epoch=12
06/10/2022 18:28:10 - INFO - __main__ - Global step 50 Train loss 2.75 Classification-F1 0.15301606753812635 on epoch=12
06/10/2022 18:28:10 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.15301606753812635 on epoch=12, global_step=50
06/10/2022 18:28:12 - INFO - __main__ - Step 60 Global step 60 Train loss 1.39 on epoch=14
06/10/2022 18:28:14 - INFO - __main__ - Step 70 Global step 70 Train loss 1.31 on epoch=17
06/10/2022 18:28:17 - INFO - __main__ - Step 80 Global step 80 Train loss 1.12 on epoch=19
06/10/2022 18:28:19 - INFO - __main__ - Step 90 Global step 90 Train loss 0.99 on epoch=22
06/10/2022 18:28:21 - INFO - __main__ - Step 100 Global step 100 Train loss 0.92 on epoch=24
06/10/2022 18:28:22 - INFO - __main__ - Global step 100 Train loss 1.15 Classification-F1 0.4649659182036888 on epoch=24
06/10/2022 18:28:22 - INFO - __main__ - Saving model with best Classification-F1: 0.15301606753812635 -> 0.4649659182036888 on epoch=24, global_step=100
06/10/2022 18:28:25 - INFO - __main__ - Step 110 Global step 110 Train loss 0.75 on epoch=27
06/10/2022 18:28:27 - INFO - __main__ - Step 120 Global step 120 Train loss 0.74 on epoch=29
06/10/2022 18:28:29 - INFO - __main__ - Step 130 Global step 130 Train loss 0.83 on epoch=32
06/10/2022 18:28:32 - INFO - __main__ - Step 140 Global step 140 Train loss 0.72 on epoch=34
06/10/2022 18:28:34 - INFO - __main__ - Step 150 Global step 150 Train loss 0.72 on epoch=37
06/10/2022 18:28:35 - INFO - __main__ - Global step 150 Train loss 0.75 Classification-F1 0.4787115339440921 on epoch=37
06/10/2022 18:28:35 - INFO - __main__ - Saving model with best Classification-F1: 0.4649659182036888 -> 0.4787115339440921 on epoch=37, global_step=150
06/10/2022 18:28:37 - INFO - __main__ - Step 160 Global step 160 Train loss 0.74 on epoch=39
06/10/2022 18:28:40 - INFO - __main__ - Step 170 Global step 170 Train loss 0.65 on epoch=42
06/10/2022 18:28:42 - INFO - __main__ - Step 180 Global step 180 Train loss 0.70 on epoch=44
06/10/2022 18:28:44 - INFO - __main__ - Step 190 Global step 190 Train loss 0.53 on epoch=47
06/10/2022 18:28:47 - INFO - __main__ - Step 200 Global step 200 Train loss 0.65 on epoch=49
06/10/2022 18:28:48 - INFO - __main__ - Global step 200 Train loss 0.65 Classification-F1 0.4245098039215686 on epoch=49
06/10/2022 18:28:50 - INFO - __main__ - Step 210 Global step 210 Train loss 0.55 on epoch=52
06/10/2022 18:28:52 - INFO - __main__ - Step 220 Global step 220 Train loss 0.62 on epoch=54
06/10/2022 18:28:55 - INFO - __main__ - Step 230 Global step 230 Train loss 0.63 on epoch=57
06/10/2022 18:28:57 - INFO - __main__ - Step 240 Global step 240 Train loss 0.57 on epoch=59
06/10/2022 18:28:59 - INFO - __main__ - Step 250 Global step 250 Train loss 0.56 on epoch=62
06/10/2022 18:29:00 - INFO - __main__ - Global step 250 Train loss 0.59 Classification-F1 0.49406926406926405 on epoch=62
06/10/2022 18:29:00 - INFO - __main__ - Saving model with best Classification-F1: 0.4787115339440921 -> 0.49406926406926405 on epoch=62, global_step=250
06/10/2022 18:29:03 - INFO - __main__ - Step 260 Global step 260 Train loss 0.55 on epoch=64
06/10/2022 18:29:05 - INFO - __main__ - Step 270 Global step 270 Train loss 0.57 on epoch=67
06/10/2022 18:29:07 - INFO - __main__ - Step 280 Global step 280 Train loss 0.61 on epoch=69
06/10/2022 18:29:10 - INFO - __main__ - Step 290 Global step 290 Train loss 0.53 on epoch=72
06/10/2022 18:29:12 - INFO - __main__ - Step 300 Global step 300 Train loss 0.49 on epoch=74
06/10/2022 18:29:13 - INFO - __main__ - Global step 300 Train loss 0.55 Classification-F1 0.5699727211683734 on epoch=74
06/10/2022 18:29:13 - INFO - __main__ - Saving model with best Classification-F1: 0.49406926406926405 -> 0.5699727211683734 on epoch=74, global_step=300
06/10/2022 18:29:15 - INFO - __main__ - Step 310 Global step 310 Train loss 0.55 on epoch=77
06/10/2022 18:29:18 - INFO - __main__ - Step 320 Global step 320 Train loss 0.40 on epoch=79
06/10/2022 18:29:20 - INFO - __main__ - Step 330 Global step 330 Train loss 0.51 on epoch=82
06/10/2022 18:29:22 - INFO - __main__ - Step 340 Global step 340 Train loss 0.47 on epoch=84
06/10/2022 18:29:25 - INFO - __main__ - Step 350 Global step 350 Train loss 0.38 on epoch=87
06/10/2022 18:29:26 - INFO - __main__ - Global step 350 Train loss 0.46 Classification-F1 0.6010388225037182 on epoch=87
06/10/2022 18:29:26 - INFO - __main__ - Saving model with best Classification-F1: 0.5699727211683734 -> 0.6010388225037182 on epoch=87, global_step=350
06/10/2022 18:29:28 - INFO - __main__ - Step 360 Global step 360 Train loss 0.45 on epoch=89
06/10/2022 18:29:30 - INFO - __main__ - Step 370 Global step 370 Train loss 0.35 on epoch=92
06/10/2022 18:29:33 - INFO - __main__ - Step 380 Global step 380 Train loss 0.44 on epoch=94
06/10/2022 18:29:35 - INFO - __main__ - Step 390 Global step 390 Train loss 0.41 on epoch=97
06/10/2022 18:29:38 - INFO - __main__ - Step 400 Global step 400 Train loss 0.49 on epoch=99
06/10/2022 18:29:38 - INFO - __main__ - Global step 400 Train loss 0.43 Classification-F1 0.5902745098039215 on epoch=99
06/10/2022 18:29:41 - INFO - __main__ - Step 410 Global step 410 Train loss 0.44 on epoch=102
06/10/2022 18:29:43 - INFO - __main__ - Step 420 Global step 420 Train loss 0.35 on epoch=104
06/10/2022 18:29:46 - INFO - __main__ - Step 430 Global step 430 Train loss 0.40 on epoch=107
06/10/2022 18:29:48 - INFO - __main__ - Step 440 Global step 440 Train loss 0.34 on epoch=109
06/10/2022 18:29:50 - INFO - __main__ - Step 450 Global step 450 Train loss 0.42 on epoch=112
06/10/2022 18:29:51 - INFO - __main__ - Global step 450 Train loss 0.39 Classification-F1 0.6027522281639929 on epoch=112
06/10/2022 18:29:51 - INFO - __main__ - Saving model with best Classification-F1: 0.6010388225037182 -> 0.6027522281639929 on epoch=112, global_step=450
06/10/2022 18:29:54 - INFO - __main__ - Step 460 Global step 460 Train loss 0.26 on epoch=114
06/10/2022 18:29:56 - INFO - __main__ - Step 470 Global step 470 Train loss 0.31 on epoch=117
06/10/2022 18:29:58 - INFO - __main__ - Step 480 Global step 480 Train loss 0.30 on epoch=119
06/10/2022 18:30:01 - INFO - __main__ - Step 490 Global step 490 Train loss 0.40 on epoch=122
06/10/2022 18:30:03 - INFO - __main__ - Step 500 Global step 500 Train loss 0.32 on epoch=124
06/10/2022 18:30:04 - INFO - __main__ - Global step 500 Train loss 0.32 Classification-F1 0.6219815668202765 on epoch=124
06/10/2022 18:30:04 - INFO - __main__ - Saving model with best Classification-F1: 0.6027522281639929 -> 0.6219815668202765 on epoch=124, global_step=500
06/10/2022 18:30:06 - INFO - __main__ - Step 510 Global step 510 Train loss 0.34 on epoch=127
06/10/2022 18:30:09 - INFO - __main__ - Step 520 Global step 520 Train loss 0.25 on epoch=129
06/10/2022 18:30:11 - INFO - __main__ - Step 530 Global step 530 Train loss 0.33 on epoch=132
06/10/2022 18:30:13 - INFO - __main__ - Step 540 Global step 540 Train loss 0.29 on epoch=134
06/10/2022 18:30:16 - INFO - __main__ - Step 550 Global step 550 Train loss 0.28 on epoch=137
06/10/2022 18:30:16 - INFO - __main__ - Global step 550 Train loss 0.30 Classification-F1 0.6169244970715559 on epoch=137
06/10/2022 18:30:19 - INFO - __main__ - Step 560 Global step 560 Train loss 0.23 on epoch=139
06/10/2022 18:30:21 - INFO - __main__ - Step 570 Global step 570 Train loss 0.29 on epoch=142
06/10/2022 18:30:24 - INFO - __main__ - Step 580 Global step 580 Train loss 0.27 on epoch=144
06/10/2022 18:30:26 - INFO - __main__ - Step 590 Global step 590 Train loss 0.26 on epoch=147
06/10/2022 18:30:28 - INFO - __main__ - Step 600 Global step 600 Train loss 0.25 on epoch=149
06/10/2022 18:30:29 - INFO - __main__ - Global step 600 Train loss 0.26 Classification-F1 0.6152095747389865 on epoch=149
06/10/2022 18:30:32 - INFO - __main__ - Step 610 Global step 610 Train loss 0.29 on epoch=152
06/10/2022 18:30:34 - INFO - __main__ - Step 620 Global step 620 Train loss 0.29 on epoch=154
06/10/2022 18:30:36 - INFO - __main__ - Step 630 Global step 630 Train loss 0.23 on epoch=157
06/10/2022 18:30:39 - INFO - __main__ - Step 640 Global step 640 Train loss 0.20 on epoch=159
06/10/2022 18:30:41 - INFO - __main__ - Step 650 Global step 650 Train loss 0.23 on epoch=162
06/10/2022 18:30:42 - INFO - __main__ - Global step 650 Train loss 0.25 Classification-F1 0.627548321048321 on epoch=162
06/10/2022 18:30:42 - INFO - __main__ - Saving model with best Classification-F1: 0.6219815668202765 -> 0.627548321048321 on epoch=162, global_step=650
06/10/2022 18:30:44 - INFO - __main__ - Step 660 Global step 660 Train loss 0.24 on epoch=164
06/10/2022 18:30:47 - INFO - __main__ - Step 670 Global step 670 Train loss 0.14 on epoch=167
06/10/2022 18:30:49 - INFO - __main__ - Step 680 Global step 680 Train loss 0.22 on epoch=169
06/10/2022 18:30:51 - INFO - __main__ - Step 690 Global step 690 Train loss 0.18 on epoch=172
06/10/2022 18:30:54 - INFO - __main__ - Step 700 Global step 700 Train loss 0.26 on epoch=174
06/10/2022 18:30:55 - INFO - __main__ - Global step 700 Train loss 0.21 Classification-F1 0.8101097178683386 on epoch=174
06/10/2022 18:30:55 - INFO - __main__ - Saving model with best Classification-F1: 0.627548321048321 -> 0.8101097178683386 on epoch=174, global_step=700
06/10/2022 18:30:57 - INFO - __main__ - Step 710 Global step 710 Train loss 0.28 on epoch=177
06/10/2022 18:31:00 - INFO - __main__ - Step 720 Global step 720 Train loss 0.23 on epoch=179
06/10/2022 18:31:02 - INFO - __main__ - Step 730 Global step 730 Train loss 0.18 on epoch=182
06/10/2022 18:31:04 - INFO - __main__ - Step 740 Global step 740 Train loss 0.15 on epoch=184
06/10/2022 18:31:07 - INFO - __main__ - Step 750 Global step 750 Train loss 0.19 on epoch=187
06/10/2022 18:31:07 - INFO - __main__ - Global step 750 Train loss 0.21 Classification-F1 0.8260241596638656 on epoch=187
06/10/2022 18:31:07 - INFO - __main__ - Saving model with best Classification-F1: 0.8101097178683386 -> 0.8260241596638656 on epoch=187, global_step=750
06/10/2022 18:31:10 - INFO - __main__ - Step 760 Global step 760 Train loss 0.26 on epoch=189
06/10/2022 18:31:12 - INFO - __main__ - Step 770 Global step 770 Train loss 0.25 on epoch=192
06/10/2022 18:31:15 - INFO - __main__ - Step 780 Global step 780 Train loss 0.15 on epoch=194
06/10/2022 18:31:17 - INFO - __main__ - Step 790 Global step 790 Train loss 0.14 on epoch=197
06/10/2022 18:31:19 - INFO - __main__ - Step 800 Global step 800 Train loss 0.17 on epoch=199
06/10/2022 18:31:20 - INFO - __main__ - Global step 800 Train loss 0.19 Classification-F1 0.8107837374761818 on epoch=199
06/10/2022 18:31:22 - INFO - __main__ - Step 810 Global step 810 Train loss 0.12 on epoch=202
06/10/2022 18:31:25 - INFO - __main__ - Step 820 Global step 820 Train loss 0.14 on epoch=204
06/10/2022 18:31:27 - INFO - __main__ - Step 830 Global step 830 Train loss 0.13 on epoch=207
06/10/2022 18:31:30 - INFO - __main__ - Step 840 Global step 840 Train loss 0.13 on epoch=209
06/10/2022 18:31:32 - INFO - __main__ - Step 850 Global step 850 Train loss 0.12 on epoch=212
06/10/2022 18:31:33 - INFO - __main__ - Global step 850 Train loss 0.13 Classification-F1 0.8231841347650171 on epoch=212
06/10/2022 18:31:35 - INFO - __main__ - Step 860 Global step 860 Train loss 0.11 on epoch=214
06/10/2022 18:31:38 - INFO - __main__ - Step 870 Global step 870 Train loss 0.11 on epoch=217
06/10/2022 18:31:40 - INFO - __main__ - Step 880 Global step 880 Train loss 0.15 on epoch=219
06/10/2022 18:31:42 - INFO - __main__ - Step 890 Global step 890 Train loss 0.08 on epoch=222
06/10/2022 18:31:45 - INFO - __main__ - Step 900 Global step 900 Train loss 0.14 on epoch=224
06/10/2022 18:31:45 - INFO - __main__ - Global step 900 Train loss 0.12 Classification-F1 0.8110906862745099 on epoch=224
06/10/2022 18:31:48 - INFO - __main__ - Step 910 Global step 910 Train loss 0.13 on epoch=227
06/10/2022 18:31:50 - INFO - __main__ - Step 920 Global step 920 Train loss 0.12 on epoch=229
06/10/2022 18:31:53 - INFO - __main__ - Step 930 Global step 930 Train loss 0.11 on epoch=232
06/10/2022 18:31:55 - INFO - __main__ - Step 940 Global step 940 Train loss 0.08 on epoch=234
06/10/2022 18:31:57 - INFO - __main__ - Step 950 Global step 950 Train loss 0.05 on epoch=237
06/10/2022 18:31:58 - INFO - __main__ - Global step 950 Train loss 0.10 Classification-F1 0.7713445378151261 on epoch=237
06/10/2022 18:32:00 - INFO - __main__ - Step 960 Global step 960 Train loss 0.08 on epoch=239
06/10/2022 18:32:03 - INFO - __main__ - Step 970 Global step 970 Train loss 0.10 on epoch=242
06/10/2022 18:32:05 - INFO - __main__ - Step 980 Global step 980 Train loss 0.13 on epoch=244
06/10/2022 18:32:08 - INFO - __main__ - Step 990 Global step 990 Train loss 0.06 on epoch=247
06/10/2022 18:32:10 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.10 on epoch=249
06/10/2022 18:32:11 - INFO - __main__ - Global step 1000 Train loss 0.09 Classification-F1 0.8237133237133237 on epoch=249
06/10/2022 18:32:13 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.11 on epoch=252
06/10/2022 18:32:15 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.07 on epoch=254
06/10/2022 18:32:18 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.08 on epoch=257
06/10/2022 18:32:20 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.12 on epoch=259
06/10/2022 18:32:23 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.06 on epoch=262
06/10/2022 18:32:23 - INFO - __main__ - Global step 1050 Train loss 0.09 Classification-F1 0.7602493227493228 on epoch=262
06/10/2022 18:32:26 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.06 on epoch=264
06/10/2022 18:32:28 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.03 on epoch=267
06/10/2022 18:32:31 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.03 on epoch=269
06/10/2022 18:32:33 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.05 on epoch=272
06/10/2022 18:32:35 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.05 on epoch=274
06/10/2022 18:32:36 - INFO - __main__ - Global step 1100 Train loss 0.04 Classification-F1 0.8007002801120447 on epoch=274
06/10/2022 18:32:39 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.09 on epoch=277
06/10/2022 18:32:41 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.06 on epoch=279
06/10/2022 18:32:43 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.07 on epoch=282
06/10/2022 18:32:46 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.15 on epoch=284
06/10/2022 18:32:48 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.09 on epoch=287
06/10/2022 18:32:49 - INFO - __main__ - Global step 1150 Train loss 0.09 Classification-F1 0.7582223109957056 on epoch=287
06/10/2022 18:32:51 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.03 on epoch=289
06/10/2022 18:32:54 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.03 on epoch=292
06/10/2022 18:32:56 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.08 on epoch=294
06/10/2022 18:32:58 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.09 on epoch=297
06/10/2022 18:33:01 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.07 on epoch=299
06/10/2022 18:33:01 - INFO - __main__ - Global step 1200 Train loss 0.06 Classification-F1 0.7858585858585858 on epoch=299
06/10/2022 18:33:04 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.07 on epoch=302
06/10/2022 18:33:06 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.07 on epoch=304
06/10/2022 18:33:09 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.05 on epoch=307
06/10/2022 18:33:11 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.04 on epoch=309
06/10/2022 18:33:13 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.06 on epoch=312
06/10/2022 18:33:14 - INFO - __main__ - Global step 1250 Train loss 0.06 Classification-F1 0.8268822223246667 on epoch=312
06/10/2022 18:33:14 - INFO - __main__ - Saving model with best Classification-F1: 0.8260241596638656 -> 0.8268822223246667 on epoch=312, global_step=1250
06/10/2022 18:33:17 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.06 on epoch=314
06/10/2022 18:33:19 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.04 on epoch=317
06/10/2022 18:33:21 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.09 on epoch=319
06/10/2022 18:33:24 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.12 on epoch=322
06/10/2022 18:33:26 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.04 on epoch=324
06/10/2022 18:33:27 - INFO - __main__ - Global step 1300 Train loss 0.07 Classification-F1 0.7714040861099685 on epoch=324
06/10/2022 18:33:29 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.03 on epoch=327
06/10/2022 18:33:32 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.05 on epoch=329
06/10/2022 18:33:34 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.07 on epoch=332
06/10/2022 18:33:36 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.06 on epoch=334
06/10/2022 18:33:39 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.03 on epoch=337
06/10/2022 18:33:40 - INFO - __main__ - Global step 1350 Train loss 0.05 Classification-F1 0.8115771615771616 on epoch=337
06/10/2022 18:33:42 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.05 on epoch=339
06/10/2022 18:33:44 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=342
06/10/2022 18:33:47 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.04 on epoch=344
06/10/2022 18:33:49 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.12 on epoch=347
06/10/2022 18:33:52 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.09 on epoch=349
06/10/2022 18:33:52 - INFO - __main__ - Global step 1400 Train loss 0.06 Classification-F1 0.8275921658986175 on epoch=349
06/10/2022 18:33:52 - INFO - __main__ - Saving model with best Classification-F1: 0.8268822223246667 -> 0.8275921658986175 on epoch=349, global_step=1400
06/10/2022 18:33:55 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.05 on epoch=352
06/10/2022 18:33:57 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.04 on epoch=354
06/10/2022 18:33:59 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.05 on epoch=357
06/10/2022 18:34:02 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.04 on epoch=359
06/10/2022 18:34:04 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.03 on epoch=362
06/10/2022 18:34:05 - INFO - __main__ - Global step 1450 Train loss 0.04 Classification-F1 0.8125000000000001 on epoch=362
06/10/2022 18:34:07 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.10 on epoch=364
06/10/2022 18:34:10 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.08 on epoch=367
06/10/2022 18:34:12 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.04 on epoch=369
06/10/2022 18:34:14 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.04 on epoch=372
06/10/2022 18:34:17 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.04 on epoch=374
06/10/2022 18:34:18 - INFO - __main__ - Global step 1500 Train loss 0.06 Classification-F1 0.825935252627697 on epoch=374
06/10/2022 18:34:20 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.03 on epoch=377
06/10/2022 18:34:23 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.05 on epoch=379
06/10/2022 18:34:25 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.04 on epoch=382
06/10/2022 18:34:27 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.09 on epoch=384
06/10/2022 18:34:30 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.03 on epoch=387
06/10/2022 18:34:31 - INFO - __main__ - Global step 1550 Train loss 0.05 Classification-F1 0.7858927224736049 on epoch=387
06/10/2022 18:34:33 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.03 on epoch=389
06/10/2022 18:34:35 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.03 on epoch=392
06/10/2022 18:34:38 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.02 on epoch=394
06/10/2022 18:34:40 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=397
06/10/2022 18:34:42 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.05 on epoch=399
06/10/2022 18:34:43 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.7862474696356275 on epoch=399
06/10/2022 18:34:46 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=402
06/10/2022 18:34:48 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.05 on epoch=404
06/10/2022 18:34:50 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=407
06/10/2022 18:34:53 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.02 on epoch=409
06/10/2022 18:34:55 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=412
06/10/2022 18:34:56 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.8423297219633427 on epoch=412
06/10/2022 18:34:56 - INFO - __main__ - Saving model with best Classification-F1: 0.8275921658986175 -> 0.8423297219633427 on epoch=412, global_step=1650
06/10/2022 18:34:58 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.04 on epoch=414
06/10/2022 18:35:01 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=417
06/10/2022 18:35:03 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.09 on epoch=419
06/10/2022 18:35:05 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.02 on epoch=422
06/10/2022 18:35:08 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.04 on epoch=424
06/10/2022 18:35:09 - INFO - __main__ - Global step 1700 Train loss 0.04 Classification-F1 0.7857349327937564 on epoch=424
06/10/2022 18:35:11 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.07 on epoch=427
06/10/2022 18:35:13 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.02 on epoch=429
06/10/2022 18:35:16 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=432
06/10/2022 18:35:18 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=434
06/10/2022 18:35:20 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=437
06/10/2022 18:35:21 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.7858927224736049 on epoch=437
06/10/2022 18:35:24 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=439
06/10/2022 18:35:26 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.03 on epoch=442
06/10/2022 18:35:28 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.04 on epoch=444
06/10/2022 18:35:31 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.07 on epoch=447
06/10/2022 18:35:33 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=449
06/10/2022 18:35:34 - INFO - __main__ - Global step 1800 Train loss 0.04 Classification-F1 0.8009049773755657 on epoch=449
06/10/2022 18:35:36 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=452
06/10/2022 18:35:39 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.05 on epoch=454
06/10/2022 18:35:41 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=457
06/10/2022 18:35:43 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=459
06/10/2022 18:35:46 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=462
06/10/2022 18:35:47 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.7747172182656055 on epoch=462
06/10/2022 18:35:49 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.05 on epoch=464
06/10/2022 18:35:51 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=467
06/10/2022 18:35:54 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.04 on epoch=469
06/10/2022 18:35:56 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=472
06/10/2022 18:35:58 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.02 on epoch=474
06/10/2022 18:35:59 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.7714583333333334 on epoch=474
06/10/2022 18:36:02 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.05 on epoch=477
06/10/2022 18:36:04 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=479
06/10/2022 18:36:06 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=482
06/10/2022 18:36:09 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=484
06/10/2022 18:36:11 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.04 on epoch=487
06/10/2022 18:36:12 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.7612554112554113 on epoch=487
06/10/2022 18:36:14 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.13 on epoch=489
06/10/2022 18:36:17 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=492
06/10/2022 18:36:19 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.05 on epoch=494
06/10/2022 18:36:21 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=497
06/10/2022 18:36:24 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=499
06/10/2022 18:36:25 - INFO - __main__ - Global step 2000 Train loss 0.04 Classification-F1 0.7935451154877969 on epoch=499
06/10/2022 18:36:27 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=502
06/10/2022 18:36:29 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=504
06/10/2022 18:36:32 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=507
06/10/2022 18:36:34 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=509
06/10/2022 18:36:36 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=512
06/10/2022 18:36:37 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.7903799019607842 on epoch=512
06/10/2022 18:36:40 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.02 on epoch=514
06/10/2022 18:36:42 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=517
06/10/2022 18:36:44 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=519
06/10/2022 18:36:47 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.03 on epoch=522
06/10/2022 18:36:49 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.04 on epoch=524
06/10/2022 18:36:50 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.7954229199010983 on epoch=524
06/10/2022 18:36:52 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.08 on epoch=527
06/10/2022 18:36:55 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=529
06/10/2022 18:36:57 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=532
06/10/2022 18:36:59 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=534
06/10/2022 18:37:02 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.03 on epoch=537
06/10/2022 18:37:03 - INFO - __main__ - Global step 2150 Train loss 0.03 Classification-F1 0.793154761904762 on epoch=537
06/10/2022 18:37:05 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.15 on epoch=539
06/10/2022 18:37:08 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.05 on epoch=542
06/10/2022 18:37:10 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/10/2022 18:37:12 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=547
06/10/2022 18:37:15 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=549
06/10/2022 18:37:15 - INFO - __main__ - Global step 2200 Train loss 0.05 Classification-F1 0.8203463203463204 on epoch=549
06/10/2022 18:37:18 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=552
06/10/2022 18:37:20 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=554
06/10/2022 18:37:23 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=557
06/10/2022 18:37:25 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=559
06/10/2022 18:37:27 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/10/2022 18:37:28 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.7858936355710548 on epoch=562
06/10/2022 18:37:31 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/10/2022 18:37:33 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=567
06/10/2022 18:37:35 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=569
06/10/2022 18:37:38 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.03 on epoch=572
06/10/2022 18:37:40 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=574
06/10/2022 18:37:41 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.7766708834071263 on epoch=574
06/10/2022 18:37:43 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=577
06/10/2022 18:37:46 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=579
06/10/2022 18:37:48 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=582
06/10/2022 18:37:50 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=584
06/10/2022 18:37:53 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=587
06/10/2022 18:37:54 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.8199314982403217 on epoch=587
06/10/2022 18:37:56 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=589
06/10/2022 18:37:58 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=592
06/10/2022 18:38:01 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/10/2022 18:38:03 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=597
06/10/2022 18:38:06 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=599
06/10/2022 18:38:06 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.8203828828828829 on epoch=599
06/10/2022 18:38:09 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.05 on epoch=602
06/10/2022 18:38:11 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.06 on epoch=604
06/10/2022 18:38:14 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/10/2022 18:38:16 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/10/2022 18:38:18 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.03 on epoch=612
06/10/2022 18:38:19 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.8144899809453563 on epoch=612
06/10/2022 18:38:21 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=614
06/10/2022 18:38:24 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=617
06/10/2022 18:38:26 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=619
06/10/2022 18:38:28 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/10/2022 18:38:31 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=624
06/10/2022 18:38:32 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.8110906862745099 on epoch=624
06/10/2022 18:38:34 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=627
06/10/2022 18:38:36 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=629
06/10/2022 18:38:39 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=632
06/10/2022 18:38:41 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=634
06/10/2022 18:38:43 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=637
06/10/2022 18:38:44 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.78193447111286 on epoch=637
06/10/2022 18:38:47 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.04 on epoch=639
06/10/2022 18:38:49 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=642
06/10/2022 18:38:51 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/10/2022 18:38:54 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=647
06/10/2022 18:38:56 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=649
06/10/2022 18:38:57 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.7925743611227483 on epoch=649
06/10/2022 18:38:59 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=652
06/10/2022 18:39:02 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/10/2022 18:39:04 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=657
06/10/2022 18:39:07 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.05 on epoch=659
06/10/2022 18:39:09 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.04 on epoch=662
06/10/2022 18:39:10 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.8597402597402597 on epoch=662
06/10/2022 18:39:10 - INFO - __main__ - Saving model with best Classification-F1: 0.8423297219633427 -> 0.8597402597402597 on epoch=662, global_step=2650
06/10/2022 18:39:12 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=664
06/10/2022 18:39:15 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.03 on epoch=667
06/10/2022 18:39:17 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.03 on epoch=669
06/10/2022 18:39:19 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=672
06/10/2022 18:39:22 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=674
06/10/2022 18:39:23 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.7955492424242425 on epoch=674
06/10/2022 18:39:25 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/10/2022 18:39:27 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/10/2022 18:39:30 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=682
06/10/2022 18:39:32 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/10/2022 18:39:35 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/10/2022 18:39:35 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.8254896198291228 on epoch=687
06/10/2022 18:39:38 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=689
06/10/2022 18:39:40 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/10/2022 18:39:43 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/10/2022 18:39:45 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=697
06/10/2022 18:39:47 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/10/2022 18:39:48 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.8389014014014013 on epoch=699
06/10/2022 18:39:51 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=702
06/10/2022 18:39:53 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.04 on epoch=704
06/10/2022 18:39:55 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/10/2022 18:39:58 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=709
06/10/2022 18:40:00 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=712
06/10/2022 18:40:01 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.8014069264069265 on epoch=712
06/10/2022 18:40:03 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=714
06/10/2022 18:40:06 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=717
06/10/2022 18:40:08 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.07 on epoch=719
06/10/2022 18:40:10 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/10/2022 18:40:13 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/10/2022 18:40:14 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.8104166666666667 on epoch=724
06/10/2022 18:40:16 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/10/2022 18:40:18 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=729
06/10/2022 18:40:21 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/10/2022 18:40:23 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.03 on epoch=734
06/10/2022 18:40:25 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/10/2022 18:40:26 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.8414408866995075 on epoch=737
06/10/2022 18:40:29 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/10/2022 18:40:31 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/10/2022 18:40:33 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/10/2022 18:40:36 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=747
06/10/2022 18:40:38 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/10/2022 18:40:39 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.8237133237133237 on epoch=749
06/10/2022 18:40:39 - INFO - __main__ - save last model!
06/10/2022 18:40:39 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/10/2022 18:40:39 - INFO - __main__ - Start tokenizing ... 5509 instances
06/10/2022 18:40:39 - INFO - __main__ - Printing 3 examples
06/10/2022 18:40:39 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/10/2022 18:40:39 - INFO - __main__ - ['others']
06/10/2022 18:40:39 - INFO - __main__ -  [emo] what you like very little things ok
06/10/2022 18:40:39 - INFO - __main__ - ['others']
06/10/2022 18:40:39 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/10/2022 18:40:39 - INFO - __main__ - ['others']
06/10/2022 18:40:39 - INFO - __main__ - Tokenizing Input ...
06/10/2022 18:40:41 - INFO - __main__ - Tokenizing Output ...
06/10/2022 18:40:47 - INFO - __main__ - Loaded 5509 examples from test data
06/13/2022 07:20:06 - INFO - __main__ - Namespace(task_dir='data/emo/', task_name='emo', identifier='T5-large-multitask-cls2cls-5e-1-4-20-up32shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-multitask-cls2cls-5e-1-4-20-up32shot/singletask-emo', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-multitask-cls2cls-5e-1-4-20-32shot/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='4,5')
06/13/2022 07:20:06 - INFO - __main__ - models/T5-large-multitask-cls2cls-5e-1-4-20-up32shot/singletask-emo
06/13/2022 07:20:06 - INFO - __main__ - Namespace(task_dir='data/emo/', task_name='emo', identifier='T5-large-multitask-cls2cls-5e-1-4-20-up32shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-multitask-cls2cls-5e-1-4-20-up32shot/singletask-emo', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-multitask-cls2cls-5e-1-4-20-32shot/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='4,5')
06/13/2022 07:20:06 - INFO - __main__ - models/T5-large-multitask-cls2cls-5e-1-4-20-up32shot/singletask-emo
06/13/2022 07:20:08 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
06/13/2022 07:20:08 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
06/13/2022 07:20:08 - INFO - __main__ - args.device: cuda:0
06/13/2022 07:20:08 - INFO - __main__ - Using 2 gpus
06/13/2022 07:20:08 - INFO - __main__ - args.device: cuda:1
06/13/2022 07:20:08 - INFO - __main__ - Using 2 gpus
06/13/2022 07:20:08 - INFO - __main__ - Fine-tuning the following samples: ['emo_16_100', 'emo_16_13', 'emo_16_21', 'emo_16_42', 'emo_16_87']
06/13/2022 07:20:08 - INFO - __main__ - Fine-tuning the following samples: ['emo_16_100', 'emo_16_13', 'emo_16_21', 'emo_16_42', 'emo_16_87']
06/13/2022 07:20:12 - INFO - __main__ - Running ... prefix=emo_16_100, lr=0.5, bsz=8 ...
06/13/2022 07:20:13 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 07:20:13 - INFO - __main__ - Printing 3 examples
06/13/2022 07:20:13 - INFO - __main__ -  [emo] how cause yes am listening
06/13/2022 07:20:13 - INFO - __main__ - ['others']
06/13/2022 07:20:13 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/13/2022 07:20:13 - INFO - __main__ - ['others']
06/13/2022 07:20:13 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/13/2022 07:20:13 - INFO - __main__ - ['others']
06/13/2022 07:20:13 - INFO - __main__ - Tokenizing Input ...
06/13/2022 07:20:13 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 07:20:13 - INFO - __main__ - Printing 3 examples
06/13/2022 07:20:13 - INFO - __main__ -  [emo] how cause yes am listening
06/13/2022 07:20:13 - INFO - __main__ - ['others']
06/13/2022 07:20:13 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/13/2022 07:20:13 - INFO - __main__ - ['others']
06/13/2022 07:20:13 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/13/2022 07:20:13 - INFO - __main__ - ['others']
06/13/2022 07:20:13 - INFO - __main__ - Tokenizing Input ...
06/13/2022 07:20:13 - INFO - __main__ - Tokenizing Output ...
06/13/2022 07:20:13 - INFO - __main__ - Tokenizing Output ...
06/13/2022 07:20:13 - INFO - __main__ - Loaded 64 examples from train data
06/13/2022 07:20:13 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 07:20:13 - INFO - __main__ - Printing 3 examples
06/13/2022 07:20:13 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
06/13/2022 07:20:13 - INFO - __main__ - ['others']
06/13/2022 07:20:13 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
06/13/2022 07:20:13 - INFO - __main__ - ['others']
06/13/2022 07:20:13 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
06/13/2022 07:20:13 - INFO - __main__ - ['others']
06/13/2022 07:20:13 - INFO - __main__ - Tokenizing Input ...
06/13/2022 07:20:13 - INFO - __main__ - Loaded 64 examples from train data
06/13/2022 07:20:13 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 07:20:13 - INFO - __main__ - Printing 3 examples
06/13/2022 07:20:13 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
06/13/2022 07:20:13 - INFO - __main__ - ['others']
06/13/2022 07:20:13 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
06/13/2022 07:20:13 - INFO - __main__ - ['others']
06/13/2022 07:20:13 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
06/13/2022 07:20:13 - INFO - __main__ - ['others']
06/13/2022 07:20:13 - INFO - __main__ - Tokenizing Input ...
06/13/2022 07:20:13 - INFO - __main__ - Tokenizing Output ...
06/13/2022 07:20:13 - INFO - __main__ - Tokenizing Output ...
06/13/2022 07:20:13 - INFO - __main__ - Loaded 64 examples from dev data
06/13/2022 07:20:13 - INFO - __main__ - Loaded 64 examples from dev data
06/13/2022 07:20:31 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 07:20:31 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 07:20:32 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 07:20:32 - INFO - __main__ - Starting training!
06/13/2022 07:20:37 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 07:20:37 - INFO - __main__ - Starting training!
06/13/2022 07:20:40 - INFO - __main__ - Step 10 Global step 10 Train loss 3.62 on epoch=2
06/13/2022 07:20:43 - INFO - __main__ - Step 20 Global step 20 Train loss 2.33 on epoch=4
06/13/2022 07:20:45 - INFO - __main__ - Step 30 Global step 30 Train loss 1.80 on epoch=7
06/13/2022 07:20:47 - INFO - __main__ - Step 40 Global step 40 Train loss 1.33 on epoch=9
06/13/2022 07:20:50 - INFO - __main__ - Step 50 Global step 50 Train loss 1.21 on epoch=12
06/13/2022 07:20:51 - INFO - __main__ - Global step 50 Train loss 2.06 Classification-F1 0.3128654970760234 on epoch=12
06/13/2022 07:20:51 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.3128654970760234 on epoch=12, global_step=50
06/13/2022 07:20:53 - INFO - __main__ - Step 60 Global step 60 Train loss 0.85 on epoch=14
06/13/2022 07:20:56 - INFO - __main__ - Step 70 Global step 70 Train loss 0.87 on epoch=17
06/13/2022 07:20:58 - INFO - __main__ - Step 80 Global step 80 Train loss 0.90 on epoch=19
06/13/2022 07:21:01 - INFO - __main__ - Step 90 Global step 90 Train loss 0.76 on epoch=22
06/13/2022 07:21:03 - INFO - __main__ - Step 100 Global step 100 Train loss 0.83 on epoch=24
06/13/2022 07:21:04 - INFO - __main__ - Global step 100 Train loss 0.84 Classification-F1 0.5182555091283407 on epoch=24
06/13/2022 07:21:04 - INFO - __main__ - Saving model with best Classification-F1: 0.3128654970760234 -> 0.5182555091283407 on epoch=24, global_step=100
06/13/2022 07:21:06 - INFO - __main__ - Step 110 Global step 110 Train loss 0.67 on epoch=27
06/13/2022 07:21:09 - INFO - __main__ - Step 120 Global step 120 Train loss 0.72 on epoch=29
06/13/2022 07:21:11 - INFO - __main__ - Step 130 Global step 130 Train loss 0.65 on epoch=32
06/13/2022 07:21:14 - INFO - __main__ - Step 140 Global step 140 Train loss 0.69 on epoch=34
06/13/2022 07:21:16 - INFO - __main__ - Step 150 Global step 150 Train loss 0.59 on epoch=37
06/13/2022 07:21:17 - INFO - __main__ - Global step 150 Train loss 0.67 Classification-F1 0.5831890331890333 on epoch=37
06/13/2022 07:21:17 - INFO - __main__ - Saving model with best Classification-F1: 0.5182555091283407 -> 0.5831890331890333 on epoch=37, global_step=150
06/13/2022 07:21:19 - INFO - __main__ - Step 160 Global step 160 Train loss 0.62 on epoch=39
06/13/2022 07:21:22 - INFO - __main__ - Step 170 Global step 170 Train loss 0.60 on epoch=42
06/13/2022 07:21:24 - INFO - __main__ - Step 180 Global step 180 Train loss 0.62 on epoch=44
06/13/2022 07:21:27 - INFO - __main__ - Step 190 Global step 190 Train loss 0.57 on epoch=47
06/13/2022 07:21:29 - INFO - __main__ - Step 200 Global step 200 Train loss 0.46 on epoch=49
06/13/2022 07:21:30 - INFO - __main__ - Global step 200 Train loss 0.57 Classification-F1 0.5961188867438867 on epoch=49
06/13/2022 07:21:30 - INFO - __main__ - Saving model with best Classification-F1: 0.5831890331890333 -> 0.5961188867438867 on epoch=49, global_step=200
06/13/2022 07:21:32 - INFO - __main__ - Step 210 Global step 210 Train loss 0.60 on epoch=52
06/13/2022 07:21:35 - INFO - __main__ - Step 220 Global step 220 Train loss 0.50 on epoch=54
06/13/2022 07:21:37 - INFO - __main__ - Step 230 Global step 230 Train loss 0.52 on epoch=57
06/13/2022 07:21:40 - INFO - __main__ - Step 240 Global step 240 Train loss 0.52 on epoch=59
06/13/2022 07:21:42 - INFO - __main__ - Step 250 Global step 250 Train loss 0.46 on epoch=62
06/13/2022 07:21:43 - INFO - __main__ - Global step 250 Train loss 0.52 Classification-F1 0.6094660837307897 on epoch=62
06/13/2022 07:21:43 - INFO - __main__ - Saving model with best Classification-F1: 0.5961188867438867 -> 0.6094660837307897 on epoch=62, global_step=250
06/13/2022 07:21:45 - INFO - __main__ - Step 260 Global step 260 Train loss 0.47 on epoch=64
06/13/2022 07:21:48 - INFO - __main__ - Step 270 Global step 270 Train loss 0.43 on epoch=67
06/13/2022 07:21:50 - INFO - __main__ - Step 280 Global step 280 Train loss 0.42 on epoch=69
06/13/2022 07:21:53 - INFO - __main__ - Step 290 Global step 290 Train loss 0.45 on epoch=72
06/13/2022 07:21:55 - INFO - __main__ - Step 300 Global step 300 Train loss 0.47 on epoch=74
06/13/2022 07:21:56 - INFO - __main__ - Global step 300 Train loss 0.45 Classification-F1 0.6495098039215687 on epoch=74
06/13/2022 07:21:56 - INFO - __main__ - Saving model with best Classification-F1: 0.6094660837307897 -> 0.6495098039215687 on epoch=74, global_step=300
06/13/2022 07:21:58 - INFO - __main__ - Step 310 Global step 310 Train loss 0.44 on epoch=77
06/13/2022 07:22:01 - INFO - __main__ - Step 320 Global step 320 Train loss 0.32 on epoch=79
06/13/2022 07:22:03 - INFO - __main__ - Step 330 Global step 330 Train loss 0.46 on epoch=82
06/13/2022 07:22:06 - INFO - __main__ - Step 340 Global step 340 Train loss 0.43 on epoch=84
06/13/2022 07:22:08 - INFO - __main__ - Step 350 Global step 350 Train loss 0.42 on epoch=87
06/13/2022 07:22:09 - INFO - __main__ - Global step 350 Train loss 0.41 Classification-F1 0.6400913187855788 on epoch=87
06/13/2022 07:22:11 - INFO - __main__ - Step 360 Global step 360 Train loss 0.30 on epoch=89
06/13/2022 07:22:14 - INFO - __main__ - Step 370 Global step 370 Train loss 0.38 on epoch=92
06/13/2022 07:22:16 - INFO - __main__ - Step 380 Global step 380 Train loss 0.38 on epoch=94
06/13/2022 07:22:19 - INFO - __main__ - Step 390 Global step 390 Train loss 0.31 on epoch=97
06/13/2022 07:22:21 - INFO - __main__ - Step 400 Global step 400 Train loss 0.30 on epoch=99
06/13/2022 07:22:22 - INFO - __main__ - Global step 400 Train loss 0.33 Classification-F1 0.6146236559139784 on epoch=99
06/13/2022 07:22:24 - INFO - __main__ - Step 410 Global step 410 Train loss 0.30 on epoch=102
06/13/2022 07:22:27 - INFO - __main__ - Step 420 Global step 420 Train loss 0.32 on epoch=104
06/13/2022 07:22:29 - INFO - __main__ - Step 430 Global step 430 Train loss 0.30 on epoch=107
06/13/2022 07:22:32 - INFO - __main__ - Step 440 Global step 440 Train loss 0.31 on epoch=109
06/13/2022 07:22:34 - INFO - __main__ - Step 450 Global step 450 Train loss 0.25 on epoch=112
06/13/2022 07:22:35 - INFO - __main__ - Global step 450 Train loss 0.30 Classification-F1 0.7022129416282642 on epoch=112
06/13/2022 07:22:35 - INFO - __main__ - Saving model with best Classification-F1: 0.6495098039215687 -> 0.7022129416282642 on epoch=112, global_step=450
06/13/2022 07:22:37 - INFO - __main__ - Step 460 Global step 460 Train loss 0.32 on epoch=114
06/13/2022 07:22:40 - INFO - __main__ - Step 470 Global step 470 Train loss 0.30 on epoch=117
06/13/2022 07:22:42 - INFO - __main__ - Step 480 Global step 480 Train loss 0.22 on epoch=119
06/13/2022 07:22:45 - INFO - __main__ - Step 490 Global step 490 Train loss 0.21 on epoch=122
06/13/2022 07:22:47 - INFO - __main__ - Step 500 Global step 500 Train loss 0.24 on epoch=124
06/13/2022 07:22:48 - INFO - __main__ - Global step 500 Train loss 0.26 Classification-F1 0.6992845117845118 on epoch=124
06/13/2022 07:22:51 - INFO - __main__ - Step 510 Global step 510 Train loss 0.20 on epoch=127
06/13/2022 07:22:53 - INFO - __main__ - Step 520 Global step 520 Train loss 0.22 on epoch=129
06/13/2022 07:22:55 - INFO - __main__ - Step 530 Global step 530 Train loss 0.25 on epoch=132
06/13/2022 07:22:58 - INFO - __main__ - Step 540 Global step 540 Train loss 0.19 on epoch=134
06/13/2022 07:23:00 - INFO - __main__ - Step 550 Global step 550 Train loss 0.19 on epoch=137
06/13/2022 07:23:01 - INFO - __main__ - Global step 550 Train loss 0.21 Classification-F1 0.6859848484848484 on epoch=137
06/13/2022 07:23:04 - INFO - __main__ - Step 560 Global step 560 Train loss 0.21 on epoch=139
06/13/2022 07:23:06 - INFO - __main__ - Step 570 Global step 570 Train loss 0.21 on epoch=142
06/13/2022 07:23:08 - INFO - __main__ - Step 580 Global step 580 Train loss 0.19 on epoch=144
06/13/2022 07:23:11 - INFO - __main__ - Step 590 Global step 590 Train loss 0.13 on epoch=147
06/13/2022 07:23:13 - INFO - __main__ - Step 600 Global step 600 Train loss 0.15 on epoch=149
06/13/2022 07:23:14 - INFO - __main__ - Global step 600 Train loss 0.18 Classification-F1 0.6279185520361992 on epoch=149
06/13/2022 07:23:17 - INFO - __main__ - Step 610 Global step 610 Train loss 0.12 on epoch=152
06/13/2022 07:23:19 - INFO - __main__ - Step 620 Global step 620 Train loss 0.17 on epoch=154
06/13/2022 07:23:21 - INFO - __main__ - Step 630 Global step 630 Train loss 0.22 on epoch=157
06/13/2022 07:23:24 - INFO - __main__ - Step 640 Global step 640 Train loss 0.16 on epoch=159
06/13/2022 07:23:26 - INFO - __main__ - Step 650 Global step 650 Train loss 0.17 on epoch=162
06/13/2022 07:23:27 - INFO - __main__ - Global step 650 Train loss 0.17 Classification-F1 0.6493125986026594 on epoch=162
06/13/2022 07:23:30 - INFO - __main__ - Step 660 Global step 660 Train loss 0.10 on epoch=164
06/13/2022 07:23:32 - INFO - __main__ - Step 670 Global step 670 Train loss 0.14 on epoch=167
06/13/2022 07:23:34 - INFO - __main__ - Step 680 Global step 680 Train loss 0.19 on epoch=169
06/13/2022 07:23:37 - INFO - __main__ - Step 690 Global step 690 Train loss 0.13 on epoch=172
06/13/2022 07:23:39 - INFO - __main__ - Step 700 Global step 700 Train loss 0.10 on epoch=174
06/13/2022 07:23:40 - INFO - __main__ - Global step 700 Train loss 0.13 Classification-F1 0.6749593543711191 on epoch=174
06/13/2022 07:23:43 - INFO - __main__ - Step 710 Global step 710 Train loss 0.09 on epoch=177
06/13/2022 07:23:45 - INFO - __main__ - Step 720 Global step 720 Train loss 0.17 on epoch=179
06/13/2022 07:23:47 - INFO - __main__ - Step 730 Global step 730 Train loss 0.09 on epoch=182
06/13/2022 07:23:50 - INFO - __main__ - Step 740 Global step 740 Train loss 0.14 on epoch=184
06/13/2022 07:23:52 - INFO - __main__ - Step 750 Global step 750 Train loss 0.08 on epoch=187
06/13/2022 07:23:53 - INFO - __main__ - Global step 750 Train loss 0.11 Classification-F1 0.6887017231134879 on epoch=187
06/13/2022 07:23:56 - INFO - __main__ - Step 760 Global step 760 Train loss 0.09 on epoch=189
06/13/2022 07:23:58 - INFO - __main__ - Step 770 Global step 770 Train loss 0.11 on epoch=192
06/13/2022 07:24:01 - INFO - __main__ - Step 780 Global step 780 Train loss 0.09 on epoch=194
06/13/2022 07:24:03 - INFO - __main__ - Step 790 Global step 790 Train loss 0.04 on epoch=197
06/13/2022 07:24:05 - INFO - __main__ - Step 800 Global step 800 Train loss 0.05 on epoch=199
06/13/2022 07:24:06 - INFO - __main__ - Global step 800 Train loss 0.08 Classification-F1 0.7314047835738604 on epoch=199
06/13/2022 07:24:06 - INFO - __main__ - Saving model with best Classification-F1: 0.7022129416282642 -> 0.7314047835738604 on epoch=199, global_step=800
06/13/2022 07:24:09 - INFO - __main__ - Step 810 Global step 810 Train loss 0.05 on epoch=202
06/13/2022 07:24:11 - INFO - __main__ - Step 820 Global step 820 Train loss 0.04 on epoch=204
06/13/2022 07:24:13 - INFO - __main__ - Step 830 Global step 830 Train loss 0.04 on epoch=207
06/13/2022 07:24:16 - INFO - __main__ - Step 840 Global step 840 Train loss 0.10 on epoch=209
06/13/2022 07:24:18 - INFO - __main__ - Step 850 Global step 850 Train loss 0.05 on epoch=212
06/13/2022 07:24:19 - INFO - __main__ - Global step 850 Train loss 0.06 Classification-F1 0.7231285831285832 on epoch=212
06/13/2022 07:24:22 - INFO - __main__ - Step 860 Global step 860 Train loss 0.08 on epoch=214
06/13/2022 07:24:24 - INFO - __main__ - Step 870 Global step 870 Train loss 0.04 on epoch=217
06/13/2022 07:24:26 - INFO - __main__ - Step 880 Global step 880 Train loss 0.05 on epoch=219
06/13/2022 07:24:29 - INFO - __main__ - Step 890 Global step 890 Train loss 0.05 on epoch=222
06/13/2022 07:24:31 - INFO - __main__ - Step 900 Global step 900 Train loss 0.05 on epoch=224
06/13/2022 07:24:32 - INFO - __main__ - Global step 900 Train loss 0.05 Classification-F1 0.7959051724137931 on epoch=224
06/13/2022 07:24:32 - INFO - __main__ - Saving model with best Classification-F1: 0.7314047835738604 -> 0.7959051724137931 on epoch=224, global_step=900
06/13/2022 07:24:35 - INFO - __main__ - Step 910 Global step 910 Train loss 0.06 on epoch=227
06/13/2022 07:24:37 - INFO - __main__ - Step 920 Global step 920 Train loss 0.05 on epoch=229
06/13/2022 07:24:40 - INFO - __main__ - Step 930 Global step 930 Train loss 0.12 on epoch=232
06/13/2022 07:24:42 - INFO - __main__ - Step 940 Global step 940 Train loss 0.08 on epoch=234
06/13/2022 07:24:44 - INFO - __main__ - Step 950 Global step 950 Train loss 0.13 on epoch=237
06/13/2022 07:24:45 - INFO - __main__ - Global step 950 Train loss 0.09 Classification-F1 0.7165936687675818 on epoch=237
06/13/2022 07:24:48 - INFO - __main__ - Step 960 Global step 960 Train loss 0.08 on epoch=239
06/13/2022 07:24:50 - INFO - __main__ - Step 970 Global step 970 Train loss 0.07 on epoch=242
06/13/2022 07:24:53 - INFO - __main__ - Step 980 Global step 980 Train loss 0.01 on epoch=244
06/13/2022 07:24:55 - INFO - __main__ - Step 990 Global step 990 Train loss 0.03 on epoch=247
06/13/2022 07:24:57 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.13 on epoch=249
06/13/2022 07:24:58 - INFO - __main__ - Global step 1000 Train loss 0.06 Classification-F1 0.7524551971326165 on epoch=249
06/13/2022 07:25:01 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.05 on epoch=252
06/13/2022 07:25:03 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.04 on epoch=254
06/13/2022 07:25:06 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.05 on epoch=257
06/13/2022 07:25:08 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.02 on epoch=259
06/13/2022 07:25:10 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.05 on epoch=262
06/13/2022 07:25:11 - INFO - __main__ - Global step 1050 Train loss 0.04 Classification-F1 0.7462902453343221 on epoch=262
06/13/2022 07:25:14 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.08 on epoch=264
06/13/2022 07:25:16 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.03 on epoch=267
06/13/2022 07:25:19 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.07 on epoch=269
06/13/2022 07:25:21 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.03 on epoch=272
06/13/2022 07:25:24 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.05 on epoch=274
06/13/2022 07:25:24 - INFO - __main__ - Global step 1100 Train loss 0.05 Classification-F1 0.7788952745849298 on epoch=274
06/13/2022 07:25:27 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.02 on epoch=277
06/13/2022 07:25:29 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.04 on epoch=279
06/13/2022 07:25:32 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.07 on epoch=282
06/13/2022 07:25:34 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.04 on epoch=284
06/13/2022 07:25:37 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.03 on epoch=287
06/13/2022 07:25:37 - INFO - __main__ - Global step 1150 Train loss 0.04 Classification-F1 0.7572979512317748 on epoch=287
06/13/2022 07:25:40 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.02 on epoch=289
06/13/2022 07:25:42 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.01 on epoch=292
06/13/2022 07:25:45 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.03 on epoch=294
06/13/2022 07:25:47 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.02 on epoch=297
06/13/2022 07:25:50 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.08 on epoch=299
06/13/2022 07:25:51 - INFO - __main__ - Global step 1200 Train loss 0.03 Classification-F1 0.7523801220575415 on epoch=299
06/13/2022 07:25:53 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.05 on epoch=302
06/13/2022 07:25:55 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=304
06/13/2022 07:25:58 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=307
06/13/2022 07:26:00 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.08 on epoch=309
06/13/2022 07:26:03 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.04 on epoch=312
06/13/2022 07:26:04 - INFO - __main__ - Global step 1250 Train loss 0.04 Classification-F1 0.7578388047138047 on epoch=312
06/13/2022 07:26:06 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.05 on epoch=314
06/13/2022 07:26:08 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.01 on epoch=317
06/13/2022 07:26:11 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=319
06/13/2022 07:26:13 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.03 on epoch=322
06/13/2022 07:26:16 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=324
06/13/2022 07:26:17 - INFO - __main__ - Global step 1300 Train loss 0.02 Classification-F1 0.7375694444444444 on epoch=324
06/13/2022 07:26:19 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.08 on epoch=327
06/13/2022 07:26:22 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.04 on epoch=329
06/13/2022 07:26:24 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=332
06/13/2022 07:26:26 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.03 on epoch=334
06/13/2022 07:26:29 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.02 on epoch=337
06/13/2022 07:26:30 - INFO - __main__ - Global step 1350 Train loss 0.04 Classification-F1 0.7381719772611613 on epoch=337
06/13/2022 07:26:32 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.08 on epoch=339
06/13/2022 07:26:35 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=342
06/13/2022 07:26:37 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.03 on epoch=344
06/13/2022 07:26:39 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.03 on epoch=347
06/13/2022 07:26:42 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.09 on epoch=349
06/13/2022 07:26:43 - INFO - __main__ - Global step 1400 Train loss 0.05 Classification-F1 0.716812865497076 on epoch=349
06/13/2022 07:26:45 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=352
06/13/2022 07:26:48 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=354
06/13/2022 07:26:50 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.07 on epoch=357
06/13/2022 07:26:53 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.04 on epoch=359
06/13/2022 07:26:55 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=362
06/13/2022 07:26:56 - INFO - __main__ - Global step 1450 Train loss 0.03 Classification-F1 0.6812950937950939 on epoch=362
06/13/2022 07:26:58 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=364
06/13/2022 07:27:01 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=367
06/13/2022 07:27:03 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.07 on epoch=369
06/13/2022 07:27:06 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=372
06/13/2022 07:27:08 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.02 on epoch=374
06/13/2022 07:27:09 - INFO - __main__ - Global step 1500 Train loss 0.02 Classification-F1 0.7109169311778746 on epoch=374
06/13/2022 07:27:11 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=377
06/13/2022 07:27:14 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.03 on epoch=379
06/13/2022 07:27:16 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.16 on epoch=382
06/13/2022 07:27:19 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=384
06/13/2022 07:27:21 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=387
06/13/2022 07:27:22 - INFO - __main__ - Global step 1550 Train loss 0.05 Classification-F1 0.7773809523809523 on epoch=387
06/13/2022 07:27:24 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.02 on epoch=389
06/13/2022 07:27:27 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.03 on epoch=392
06/13/2022 07:27:29 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=394
06/13/2022 07:27:32 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=397
06/13/2022 07:27:34 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=399
06/13/2022 07:27:35 - INFO - __main__ - Global step 1600 Train loss 0.01 Classification-F1 0.7100060534843143 on epoch=399
06/13/2022 07:27:38 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=402
06/13/2022 07:27:40 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=404
06/13/2022 07:27:42 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.05 on epoch=407
06/13/2022 07:27:45 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.04 on epoch=409
06/13/2022 07:27:47 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=412
06/13/2022 07:27:48 - INFO - __main__ - Global step 1650 Train loss 0.03 Classification-F1 0.722296494355318 on epoch=412
06/13/2022 07:27:51 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=414
06/13/2022 07:27:53 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=417
06/13/2022 07:27:56 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=419
06/13/2022 07:27:58 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=422
06/13/2022 07:28:00 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=424
06/13/2022 07:28:01 - INFO - __main__ - Global step 1700 Train loss 0.00 Classification-F1 0.722904722904723 on epoch=424
06/13/2022 07:28:04 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=427
06/13/2022 07:28:06 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=429
06/13/2022 07:28:09 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=432
06/13/2022 07:28:11 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=434
06/13/2022 07:28:14 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=437
06/13/2022 07:28:14 - INFO - __main__ - Global step 1750 Train loss 0.01 Classification-F1 0.722296494355318 on epoch=437
06/13/2022 07:28:17 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=439
06/13/2022 07:28:19 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=442
06/13/2022 07:28:22 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=444
06/13/2022 07:28:24 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=447
06/13/2022 07:28:27 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=449
06/13/2022 07:28:28 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.6991721728563833 on epoch=449
06/13/2022 07:28:30 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=452
06/13/2022 07:28:32 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.05 on epoch=454
06/13/2022 07:28:35 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=457
06/13/2022 07:28:37 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=459
06/13/2022 07:28:40 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=462
06/13/2022 07:28:41 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.6847540818129053 on epoch=462
06/13/2022 07:28:43 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.03 on epoch=464
06/13/2022 07:28:46 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=467
06/13/2022 07:28:48 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=469
06/13/2022 07:28:51 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=472
06/13/2022 07:28:53 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=474
06/13/2022 07:28:54 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.7185663082437276 on epoch=474
06/13/2022 07:28:57 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=477
06/13/2022 07:28:59 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=479
06/13/2022 07:29:02 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=482
06/13/2022 07:29:04 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=484
06/13/2022 07:29:06 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=487
06/13/2022 07:29:07 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.671067821067821 on epoch=487
06/13/2022 07:29:10 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=489
06/13/2022 07:29:12 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=492
06/13/2022 07:29:15 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=494
06/13/2022 07:29:17 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.04 on epoch=497
06/13/2022 07:29:20 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=499
06/13/2022 07:29:21 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.6974777196551389 on epoch=499
06/13/2022 07:29:23 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=502
06/13/2022 07:29:26 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.04 on epoch=504
06/13/2022 07:29:28 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/13/2022 07:29:30 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.03 on epoch=509
06/13/2022 07:29:33 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.04 on epoch=512
06/13/2022 07:29:34 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.6724124692874692 on epoch=512
06/13/2022 07:29:36 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.02 on epoch=514
06/13/2022 07:29:39 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=517
06/13/2022 07:29:41 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=519
06/13/2022 07:29:44 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/13/2022 07:29:46 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.04 on epoch=524
06/13/2022 07:29:47 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.725145569973156 on epoch=524
06/13/2022 07:29:50 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=527
06/13/2022 07:29:52 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/13/2022 07:29:54 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/13/2022 07:29:57 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
06/13/2022 07:29:59 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=537
06/13/2022 07:30:00 - INFO - __main__ - Global step 2150 Train loss 0.00 Classification-F1 0.7387372484146677 on epoch=537
06/13/2022 07:30:03 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/13/2022 07:30:05 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=542
06/13/2022 07:30:08 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/13/2022 07:30:10 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=547
06/13/2022 07:30:13 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/13/2022 07:30:14 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.781143951833607 on epoch=549
06/13/2022 07:30:16 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=552
06/13/2022 07:30:19 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/13/2022 07:30:21 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.03 on epoch=557
06/13/2022 07:30:24 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=559
06/13/2022 07:30:26 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=562
06/13/2022 07:30:27 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.7453337725076855 on epoch=562
06/13/2022 07:30:29 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.05 on epoch=564
06/13/2022 07:30:32 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=567
06/13/2022 07:30:34 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/13/2022 07:30:37 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/13/2022 07:30:39 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/13/2022 07:30:40 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.7578255675029868 on epoch=574
06/13/2022 07:30:43 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/13/2022 07:30:45 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=579
06/13/2022 07:30:48 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/13/2022 07:30:50 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/13/2022 07:30:53 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/13/2022 07:30:54 - INFO - __main__ - Global step 2350 Train loss 0.00 Classification-F1 0.7592592592592592 on epoch=587
06/13/2022 07:30:56 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=589
06/13/2022 07:30:59 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/13/2022 07:31:01 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.04 on epoch=594
06/13/2022 07:31:04 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/13/2022 07:31:06 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=599
06/13/2022 07:31:07 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.7773809523809523 on epoch=599
06/13/2022 07:31:10 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/13/2022 07:31:12 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/13/2022 07:31:14 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=607
06/13/2022 07:31:17 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=609
06/13/2022 07:31:19 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/13/2022 07:31:20 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.7638888888888888 on epoch=612
06/13/2022 07:31:23 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.02 on epoch=614
06/13/2022 07:31:25 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/13/2022 07:31:28 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=619
06/13/2022 07:31:30 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/13/2022 07:31:33 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=624
06/13/2022 07:31:34 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.8133536173089926 on epoch=624
06/13/2022 07:31:34 - INFO - __main__ - Saving model with best Classification-F1: 0.7959051724137931 -> 0.8133536173089926 on epoch=624, global_step=2500
06/13/2022 07:31:36 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.07 on epoch=627
06/13/2022 07:31:39 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=629
06/13/2022 07:31:41 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/13/2022 07:31:44 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=634
06/13/2022 07:31:46 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/13/2022 07:31:48 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.7459945549047109 on epoch=637
06/13/2022 07:31:50 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/13/2022 07:31:53 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=642
06/13/2022 07:31:55 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.03 on epoch=644
06/13/2022 07:31:57 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/13/2022 07:32:00 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/13/2022 07:32:01 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.7425925925925925 on epoch=649
06/13/2022 07:32:04 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.04 on epoch=652
06/13/2022 07:32:06 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/13/2022 07:32:08 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/13/2022 07:32:11 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/13/2022 07:32:13 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/13/2022 07:32:15 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.757968017645437 on epoch=662
06/13/2022 07:32:17 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/13/2022 07:32:19 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/13/2022 07:32:22 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=669
06/13/2022 07:32:24 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=672
06/13/2022 07:32:27 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/13/2022 07:32:28 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.7952790682457633 on epoch=674
06/13/2022 07:32:30 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/13/2022 07:32:33 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/13/2022 07:32:35 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/13/2022 07:32:38 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/13/2022 07:32:40 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/13/2022 07:32:42 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.7531944444444444 on epoch=687
06/13/2022 07:32:44 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=689
06/13/2022 07:32:47 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/13/2022 07:32:49 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=694
06/13/2022 07:32:51 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=697
06/13/2022 07:32:54 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=699
06/13/2022 07:32:55 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.7665732959850606 on epoch=699
06/13/2022 07:32:57 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.04 on epoch=702
06/13/2022 07:33:00 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/13/2022 07:33:02 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/13/2022 07:33:05 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.03 on epoch=709
06/13/2022 07:33:07 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/13/2022 07:33:08 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.7776972079154242 on epoch=712
06/13/2022 07:33:11 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.06 on epoch=714
06/13/2022 07:33:13 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/13/2022 07:33:16 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/13/2022 07:33:18 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/13/2022 07:33:21 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/13/2022 07:33:22 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.7023529411764705 on epoch=724
06/13/2022 07:33:24 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.05 on epoch=727
06/13/2022 07:33:27 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.04 on epoch=729
06/13/2022 07:33:29 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/13/2022 07:33:32 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/13/2022 07:33:34 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/13/2022 07:33:35 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.7385663082437276 on epoch=737
06/13/2022 07:33:38 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/13/2022 07:33:40 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/13/2022 07:33:43 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=744
06/13/2022 07:33:45 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/13/2022 07:33:48 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/13/2022 07:33:49 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.720045045045045 on epoch=749
06/13/2022 07:33:49 - INFO - __main__ - save last model!
06/13/2022 07:33:49 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/13/2022 07:33:49 - INFO - __main__ - Start tokenizing ... 5509 instances
06/13/2022 07:33:49 - INFO - __main__ - Printing 3 examples
06/13/2022 07:33:49 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/13/2022 07:33:49 - INFO - __main__ - ['others']
06/13/2022 07:33:49 - INFO - __main__ -  [emo] what you like very little things ok
06/13/2022 07:33:49 - INFO - __main__ - ['others']
06/13/2022 07:33:49 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/13/2022 07:33:49 - INFO - __main__ - ['others']
06/13/2022 07:33:49 - INFO - __main__ - Tokenizing Input ...
06/13/2022 07:33:49 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 07:33:49 - INFO - __main__ - Printing 3 examples
06/13/2022 07:33:49 - INFO - __main__ -  [emo] how cause yes am listening
06/13/2022 07:33:49 - INFO - __main__ - ['others']
06/13/2022 07:33:49 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/13/2022 07:33:49 - INFO - __main__ - ['others']
06/13/2022 07:33:49 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/13/2022 07:33:49 - INFO - __main__ - ['others']
06/13/2022 07:33:49 - INFO - __main__ - Tokenizing Input ...
06/13/2022 07:33:49 - INFO - __main__ - Tokenizing Output ...
06/13/2022 07:33:49 - INFO - __main__ - Loaded 64 examples from train data
06/13/2022 07:33:49 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 07:33:49 - INFO - __main__ - Printing 3 examples
06/13/2022 07:33:49 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
06/13/2022 07:33:49 - INFO - __main__ - ['others']
06/13/2022 07:33:49 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
06/13/2022 07:33:49 - INFO - __main__ - ['others']
06/13/2022 07:33:49 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
06/13/2022 07:33:49 - INFO - __main__ - ['others']
06/13/2022 07:33:49 - INFO - __main__ - Tokenizing Input ...
06/13/2022 07:33:49 - INFO - __main__ - Tokenizing Output ...
06/13/2022 07:33:49 - INFO - __main__ - Loaded 64 examples from dev data
06/13/2022 07:33:51 - INFO - __main__ - Tokenizing Output ...
06/13/2022 07:33:57 - INFO - __main__ - Loaded 5509 examples from test data
06/13/2022 07:34:04 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 07:34:05 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 07:34:05 - INFO - __main__ - Starting training!
06/13/2022 07:35:33 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-up32shot/singletask-emo/emo_16_100_0.5_8_predictions.txt
06/13/2022 07:35:33 - INFO - __main__ - Classification-F1 on test data: 0.1833
06/13/2022 07:35:33 - INFO - __main__ - prefix=emo_16_100, lr=0.5, bsz=8, dev_performance=0.8133536173089926, test_performance=0.18326505366955692
06/13/2022 07:35:33 - INFO - __main__ - Running ... prefix=emo_16_100, lr=0.4, bsz=8 ...
06/13/2022 07:35:34 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 07:35:34 - INFO - __main__ - Printing 3 examples
06/13/2022 07:35:34 - INFO - __main__ -  [emo] how cause yes am listening
06/13/2022 07:35:34 - INFO - __main__ - ['others']
06/13/2022 07:35:34 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/13/2022 07:35:34 - INFO - __main__ - ['others']
06/13/2022 07:35:34 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/13/2022 07:35:34 - INFO - __main__ - ['others']
06/13/2022 07:35:34 - INFO - __main__ - Tokenizing Input ...
06/13/2022 07:35:34 - INFO - __main__ - Tokenizing Output ...
06/13/2022 07:35:34 - INFO - __main__ - Loaded 64 examples from train data
06/13/2022 07:35:34 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 07:35:34 - INFO - __main__ - Printing 3 examples
06/13/2022 07:35:34 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
06/13/2022 07:35:34 - INFO - __main__ - ['others']
06/13/2022 07:35:34 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
06/13/2022 07:35:34 - INFO - __main__ - ['others']
06/13/2022 07:35:34 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
06/13/2022 07:35:34 - INFO - __main__ - ['others']
06/13/2022 07:35:34 - INFO - __main__ - Tokenizing Input ...
06/13/2022 07:35:34 - INFO - __main__ - Tokenizing Output ...
06/13/2022 07:35:34 - INFO - __main__ - Loaded 64 examples from dev data
06/13/2022 07:35:49 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 07:35:50 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 07:35:50 - INFO - __main__ - Starting training!
06/13/2022 07:35:53 - INFO - __main__ - Step 10 Global step 10 Train loss 3.93 on epoch=2
06/13/2022 07:35:55 - INFO - __main__ - Step 20 Global step 20 Train loss 2.45 on epoch=4
06/13/2022 07:35:57 - INFO - __main__ - Step 30 Global step 30 Train loss 2.02 on epoch=7
06/13/2022 07:36:00 - INFO - __main__ - Step 40 Global step 40 Train loss 1.59 on epoch=9
06/13/2022 07:36:02 - INFO - __main__ - Step 50 Global step 50 Train loss 1.44 on epoch=12
06/13/2022 07:36:03 - INFO - __main__ - Global step 50 Train loss 2.29 Classification-F1 0.22862554112554112 on epoch=12
06/13/2022 07:36:03 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.22862554112554112 on epoch=12, global_step=50
06/13/2022 07:36:06 - INFO - __main__ - Step 60 Global step 60 Train loss 1.13 on epoch=14
06/13/2022 07:36:08 - INFO - __main__ - Step 70 Global step 70 Train loss 0.90 on epoch=17
06/13/2022 07:36:11 - INFO - __main__ - Step 80 Global step 80 Train loss 0.86 on epoch=19
06/13/2022 07:36:13 - INFO - __main__ - Step 90 Global step 90 Train loss 0.89 on epoch=22
06/13/2022 07:36:16 - INFO - __main__ - Step 100 Global step 100 Train loss 0.78 on epoch=24
06/13/2022 07:36:16 - INFO - __main__ - Global step 100 Train loss 0.91 Classification-F1 0.47769949827876657 on epoch=24
06/13/2022 07:36:16 - INFO - __main__ - Saving model with best Classification-F1: 0.22862554112554112 -> 0.47769949827876657 on epoch=24, global_step=100
06/13/2022 07:36:19 - INFO - __main__ - Step 110 Global step 110 Train loss 0.81 on epoch=27
06/13/2022 07:36:21 - INFO - __main__ - Step 120 Global step 120 Train loss 0.72 on epoch=29
06/13/2022 07:36:24 - INFO - __main__ - Step 130 Global step 130 Train loss 0.69 on epoch=32
06/13/2022 07:36:26 - INFO - __main__ - Step 140 Global step 140 Train loss 0.66 on epoch=34
06/13/2022 07:36:29 - INFO - __main__ - Step 150 Global step 150 Train loss 0.71 on epoch=37
06/13/2022 07:36:29 - INFO - __main__ - Global step 150 Train loss 0.72 Classification-F1 0.6077386026874518 on epoch=37
06/13/2022 07:36:29 - INFO - __main__ - Saving model with best Classification-F1: 0.47769949827876657 -> 0.6077386026874518 on epoch=37, global_step=150
06/13/2022 07:36:32 - INFO - __main__ - Step 160 Global step 160 Train loss 0.64 on epoch=39
06/13/2022 07:36:34 - INFO - __main__ - Step 170 Global step 170 Train loss 0.63 on epoch=42
06/13/2022 07:36:37 - INFO - __main__ - Step 180 Global step 180 Train loss 0.67 on epoch=44
06/13/2022 07:36:39 - INFO - __main__ - Step 190 Global step 190 Train loss 0.57 on epoch=47
06/13/2022 07:36:42 - INFO - __main__ - Step 200 Global step 200 Train loss 0.61 on epoch=49
06/13/2022 07:36:43 - INFO - __main__ - Global step 200 Train loss 0.62 Classification-F1 0.575 on epoch=49
06/13/2022 07:36:45 - INFO - __main__ - Step 210 Global step 210 Train loss 0.63 on epoch=52
06/13/2022 07:36:47 - INFO - __main__ - Step 220 Global step 220 Train loss 0.54 on epoch=54
06/13/2022 07:36:50 - INFO - __main__ - Step 230 Global step 230 Train loss 0.53 on epoch=57
06/13/2022 07:36:52 - INFO - __main__ - Step 240 Global step 240 Train loss 0.59 on epoch=59
06/13/2022 07:36:55 - INFO - __main__ - Step 250 Global step 250 Train loss 0.62 on epoch=62
06/13/2022 07:36:56 - INFO - __main__ - Global step 250 Train loss 0.58 Classification-F1 0.6681756573597182 on epoch=62
06/13/2022 07:36:56 - INFO - __main__ - Saving model with best Classification-F1: 0.6077386026874518 -> 0.6681756573597182 on epoch=62, global_step=250
06/13/2022 07:36:58 - INFO - __main__ - Step 260 Global step 260 Train loss 0.55 on epoch=64
06/13/2022 07:37:00 - INFO - __main__ - Step 270 Global step 270 Train loss 0.65 on epoch=67
06/13/2022 07:37:03 - INFO - __main__ - Step 280 Global step 280 Train loss 0.44 on epoch=69
06/13/2022 07:37:05 - INFO - __main__ - Step 290 Global step 290 Train loss 0.52 on epoch=72
06/13/2022 07:37:08 - INFO - __main__ - Step 300 Global step 300 Train loss 0.50 on epoch=74
06/13/2022 07:37:09 - INFO - __main__ - Global step 300 Train loss 0.53 Classification-F1 0.6645428419621967 on epoch=74
06/13/2022 07:37:11 - INFO - __main__ - Step 310 Global step 310 Train loss 0.55 on epoch=77
06/13/2022 07:37:13 - INFO - __main__ - Step 320 Global step 320 Train loss 0.47 on epoch=79
06/13/2022 07:37:16 - INFO - __main__ - Step 330 Global step 330 Train loss 0.49 on epoch=82
06/13/2022 07:37:18 - INFO - __main__ - Step 340 Global step 340 Train loss 0.40 on epoch=84
06/13/2022 07:37:21 - INFO - __main__ - Step 350 Global step 350 Train loss 0.40 on epoch=87
06/13/2022 07:37:22 - INFO - __main__ - Global step 350 Train loss 0.46 Classification-F1 0.6836038961038962 on epoch=87
06/13/2022 07:37:22 - INFO - __main__ - Saving model with best Classification-F1: 0.6681756573597182 -> 0.6836038961038962 on epoch=87, global_step=350
06/13/2022 07:37:24 - INFO - __main__ - Step 360 Global step 360 Train loss 0.31 on epoch=89
06/13/2022 07:37:27 - INFO - __main__ - Step 370 Global step 370 Train loss 0.40 on epoch=92
06/13/2022 07:37:29 - INFO - __main__ - Step 380 Global step 380 Train loss 0.36 on epoch=94
06/13/2022 07:37:31 - INFO - __main__ - Step 390 Global step 390 Train loss 0.39 on epoch=97
06/13/2022 07:37:34 - INFO - __main__ - Step 400 Global step 400 Train loss 0.44 on epoch=99
06/13/2022 07:37:35 - INFO - __main__ - Global step 400 Train loss 0.38 Classification-F1 0.682894248970591 on epoch=99
06/13/2022 07:37:37 - INFO - __main__ - Step 410 Global step 410 Train loss 0.48 on epoch=102
06/13/2022 07:37:40 - INFO - __main__ - Step 420 Global step 420 Train loss 0.47 on epoch=104
06/13/2022 07:37:42 - INFO - __main__ - Step 430 Global step 430 Train loss 0.38 on epoch=107
06/13/2022 07:37:45 - INFO - __main__ - Step 440 Global step 440 Train loss 0.38 on epoch=109
06/13/2022 07:37:47 - INFO - __main__ - Step 450 Global step 450 Train loss 0.39 on epoch=112
06/13/2022 07:37:48 - INFO - __main__ - Global step 450 Train loss 0.42 Classification-F1 0.6538920559881349 on epoch=112
06/13/2022 07:37:50 - INFO - __main__ - Step 460 Global step 460 Train loss 0.31 on epoch=114
06/13/2022 07:37:53 - INFO - __main__ - Step 470 Global step 470 Train loss 0.32 on epoch=117
06/13/2022 07:37:55 - INFO - __main__ - Step 480 Global step 480 Train loss 0.28 on epoch=119
06/13/2022 07:37:58 - INFO - __main__ - Step 490 Global step 490 Train loss 0.35 on epoch=122
06/13/2022 07:38:00 - INFO - __main__ - Step 500 Global step 500 Train loss 0.36 on epoch=124
06/13/2022 07:38:01 - INFO - __main__ - Global step 500 Train loss 0.33 Classification-F1 0.6643335218702865 on epoch=124
06/13/2022 07:38:03 - INFO - __main__ - Step 510 Global step 510 Train loss 0.36 on epoch=127
06/13/2022 07:38:06 - INFO - __main__ - Step 520 Global step 520 Train loss 0.27 on epoch=129
06/13/2022 07:38:08 - INFO - __main__ - Step 530 Global step 530 Train loss 0.33 on epoch=132
06/13/2022 07:38:11 - INFO - __main__ - Step 540 Global step 540 Train loss 0.23 on epoch=134
06/13/2022 07:38:13 - INFO - __main__ - Step 550 Global step 550 Train loss 0.25 on epoch=137
06/13/2022 07:38:14 - INFO - __main__ - Global step 550 Train loss 0.29 Classification-F1 0.6834059448770238 on epoch=137
06/13/2022 07:38:16 - INFO - __main__ - Step 560 Global step 560 Train loss 0.23 on epoch=139
06/13/2022 07:38:19 - INFO - __main__ - Step 570 Global step 570 Train loss 0.22 on epoch=142
06/13/2022 07:38:21 - INFO - __main__ - Step 580 Global step 580 Train loss 0.27 on epoch=144
06/13/2022 07:38:24 - INFO - __main__ - Step 590 Global step 590 Train loss 0.25 on epoch=147
06/13/2022 07:38:26 - INFO - __main__ - Step 600 Global step 600 Train loss 0.26 on epoch=149
06/13/2022 07:38:27 - INFO - __main__ - Global step 600 Train loss 0.24 Classification-F1 0.6799659165945063 on epoch=149
06/13/2022 07:38:30 - INFO - __main__ - Step 610 Global step 610 Train loss 0.23 on epoch=152
06/13/2022 07:38:32 - INFO - __main__ - Step 620 Global step 620 Train loss 0.21 on epoch=154
06/13/2022 07:38:34 - INFO - __main__ - Step 630 Global step 630 Train loss 0.30 on epoch=157
06/13/2022 07:38:37 - INFO - __main__ - Step 640 Global step 640 Train loss 0.15 on epoch=159
06/13/2022 07:38:39 - INFO - __main__ - Step 650 Global step 650 Train loss 0.19 on epoch=162
06/13/2022 07:38:40 - INFO - __main__ - Global step 650 Train loss 0.22 Classification-F1 0.6646945646945646 on epoch=162
06/13/2022 07:38:43 - INFO - __main__ - Step 660 Global step 660 Train loss 0.19 on epoch=164
06/13/2022 07:38:45 - INFO - __main__ - Step 670 Global step 670 Train loss 0.32 on epoch=167
06/13/2022 07:38:48 - INFO - __main__ - Step 680 Global step 680 Train loss 0.18 on epoch=169
06/13/2022 07:38:50 - INFO - __main__ - Step 690 Global step 690 Train loss 0.17 on epoch=172
06/13/2022 07:38:52 - INFO - __main__ - Step 700 Global step 700 Train loss 0.18 on epoch=174
06/13/2022 07:38:53 - INFO - __main__ - Global step 700 Train loss 0.21 Classification-F1 0.6828828568539358 on epoch=174
06/13/2022 07:38:56 - INFO - __main__ - Step 710 Global step 710 Train loss 0.19 on epoch=177
06/13/2022 07:38:58 - INFO - __main__ - Step 720 Global step 720 Train loss 0.10 on epoch=179
06/13/2022 07:39:01 - INFO - __main__ - Step 730 Global step 730 Train loss 0.16 on epoch=182
06/13/2022 07:39:03 - INFO - __main__ - Step 740 Global step 740 Train loss 0.12 on epoch=184
06/13/2022 07:39:05 - INFO - __main__ - Step 750 Global step 750 Train loss 0.07 on epoch=187
06/13/2022 07:39:06 - INFO - __main__ - Global step 750 Train loss 0.12 Classification-F1 0.7441595441595441 on epoch=187
06/13/2022 07:39:06 - INFO - __main__ - Saving model with best Classification-F1: 0.6836038961038962 -> 0.7441595441595441 on epoch=187, global_step=750
06/13/2022 07:39:09 - INFO - __main__ - Step 760 Global step 760 Train loss 0.16 on epoch=189
06/13/2022 07:39:11 - INFO - __main__ - Step 770 Global step 770 Train loss 0.14 on epoch=192
06/13/2022 07:39:14 - INFO - __main__ - Step 780 Global step 780 Train loss 0.23 on epoch=194
06/13/2022 07:39:16 - INFO - __main__ - Step 790 Global step 790 Train loss 0.12 on epoch=197
06/13/2022 07:39:18 - INFO - __main__ - Step 800 Global step 800 Train loss 0.09 on epoch=199
06/13/2022 07:39:19 - INFO - __main__ - Global step 800 Train loss 0.15 Classification-F1 0.7310758082497213 on epoch=199
06/13/2022 07:39:22 - INFO - __main__ - Step 810 Global step 810 Train loss 0.15 on epoch=202
06/13/2022 07:39:24 - INFO - __main__ - Step 820 Global step 820 Train loss 0.16 on epoch=204
06/13/2022 07:39:27 - INFO - __main__ - Step 830 Global step 830 Train loss 0.09 on epoch=207
06/13/2022 07:39:29 - INFO - __main__ - Step 840 Global step 840 Train loss 0.07 on epoch=209
06/13/2022 07:39:31 - INFO - __main__ - Step 850 Global step 850 Train loss 0.07 on epoch=212
06/13/2022 07:39:32 - INFO - __main__ - Global step 850 Train loss 0.11 Classification-F1 0.7371471471471471 on epoch=212
06/13/2022 07:39:35 - INFO - __main__ - Step 860 Global step 860 Train loss 0.20 on epoch=214
06/13/2022 07:39:37 - INFO - __main__ - Step 870 Global step 870 Train loss 0.17 on epoch=217
06/13/2022 07:39:40 - INFO - __main__ - Step 880 Global step 880 Train loss 0.08 on epoch=219
06/13/2022 07:39:42 - INFO - __main__ - Step 890 Global step 890 Train loss 0.13 on epoch=222
06/13/2022 07:39:44 - INFO - __main__ - Step 900 Global step 900 Train loss 0.20 on epoch=224
06/13/2022 07:39:45 - INFO - __main__ - Global step 900 Train loss 0.16 Classification-F1 0.7173480116271879 on epoch=224
06/13/2022 07:39:48 - INFO - __main__ - Step 910 Global step 910 Train loss 0.07 on epoch=227
06/13/2022 07:39:50 - INFO - __main__ - Step 920 Global step 920 Train loss 0.19 on epoch=229
06/13/2022 07:39:53 - INFO - __main__ - Step 930 Global step 930 Train loss 0.07 on epoch=232
06/13/2022 07:39:55 - INFO - __main__ - Step 940 Global step 940 Train loss 0.05 on epoch=234
06/13/2022 07:39:57 - INFO - __main__ - Step 950 Global step 950 Train loss 0.11 on epoch=237
06/13/2022 07:39:58 - INFO - __main__ - Global step 950 Train loss 0.10 Classification-F1 0.7025247296986428 on epoch=237
06/13/2022 07:40:01 - INFO - __main__ - Step 960 Global step 960 Train loss 0.09 on epoch=239
06/13/2022 07:40:03 - INFO - __main__ - Step 970 Global step 970 Train loss 0.10 on epoch=242
06/13/2022 07:40:06 - INFO - __main__ - Step 980 Global step 980 Train loss 0.14 on epoch=244
06/13/2022 07:40:08 - INFO - __main__ - Step 990 Global step 990 Train loss 0.06 on epoch=247
06/13/2022 07:40:10 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.04 on epoch=249
06/13/2022 07:40:11 - INFO - __main__ - Global step 1000 Train loss 0.09 Classification-F1 0.7325375773651636 on epoch=249
06/13/2022 07:40:14 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.10 on epoch=252
06/13/2022 07:40:16 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.06 on epoch=254
06/13/2022 07:40:18 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.08 on epoch=257
06/13/2022 07:40:21 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.11 on epoch=259
06/13/2022 07:40:23 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.10 on epoch=262
06/13/2022 07:40:24 - INFO - __main__ - Global step 1050 Train loss 0.09 Classification-F1 0.7168918918918918 on epoch=262
06/13/2022 07:40:27 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.07 on epoch=264
06/13/2022 07:40:29 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.11 on epoch=267
06/13/2022 07:40:32 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.06 on epoch=269
06/13/2022 07:40:34 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.06 on epoch=272
06/13/2022 07:40:36 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.07 on epoch=274
06/13/2022 07:40:37 - INFO - __main__ - Global step 1100 Train loss 0.07 Classification-F1 0.7238045738045737 on epoch=274
06/13/2022 07:40:40 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.08 on epoch=277
06/13/2022 07:40:42 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.08 on epoch=279
06/13/2022 07:40:45 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.06 on epoch=282
06/13/2022 07:40:47 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.02 on epoch=284
06/13/2022 07:40:49 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.06 on epoch=287
06/13/2022 07:40:50 - INFO - __main__ - Global step 1150 Train loss 0.06 Classification-F1 0.715010395010395 on epoch=287
06/13/2022 07:40:53 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.14 on epoch=289
06/13/2022 07:40:55 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.10 on epoch=292
06/13/2022 07:40:57 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.03 on epoch=294
06/13/2022 07:41:00 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.03 on epoch=297
06/13/2022 07:41:02 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.15 on epoch=299
06/13/2022 07:41:03 - INFO - __main__ - Global step 1200 Train loss 0.09 Classification-F1 0.7021367521367521 on epoch=299
06/13/2022 07:41:06 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.06 on epoch=302
06/13/2022 07:41:08 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.04 on epoch=304
06/13/2022 07:41:11 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.08 on epoch=307
06/13/2022 07:41:13 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.02 on epoch=309
06/13/2022 07:41:15 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.06 on epoch=312
06/13/2022 07:41:16 - INFO - __main__ - Global step 1250 Train loss 0.05 Classification-F1 0.7329480101219231 on epoch=312
06/13/2022 07:41:19 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.05 on epoch=314
06/13/2022 07:41:21 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.05 on epoch=317
06/13/2022 07:41:24 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.05 on epoch=319
06/13/2022 07:41:26 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.08 on epoch=322
06/13/2022 07:41:28 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.07 on epoch=324
06/13/2022 07:41:29 - INFO - __main__ - Global step 1300 Train loss 0.06 Classification-F1 0.7376373626373626 on epoch=324
06/13/2022 07:41:32 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.02 on epoch=327
06/13/2022 07:41:34 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.05 on epoch=329
06/13/2022 07:41:37 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.08 on epoch=332
06/13/2022 07:41:39 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.07 on epoch=334
06/13/2022 07:41:41 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.05 on epoch=337
06/13/2022 07:41:42 - INFO - __main__ - Global step 1350 Train loss 0.05 Classification-F1 0.7659467503217504 on epoch=337
06/13/2022 07:41:42 - INFO - __main__ - Saving model with best Classification-F1: 0.7441595441595441 -> 0.7659467503217504 on epoch=337, global_step=1350
06/13/2022 07:41:45 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.03 on epoch=339
06/13/2022 07:41:47 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.06 on epoch=342
06/13/2022 07:41:50 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.03 on epoch=344
06/13/2022 07:41:52 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.04 on epoch=347
06/13/2022 07:41:54 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.03 on epoch=349
06/13/2022 07:41:55 - INFO - __main__ - Global step 1400 Train loss 0.04 Classification-F1 0.7342961092961093 on epoch=349
06/13/2022 07:41:58 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.02 on epoch=352
06/13/2022 07:42:00 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.05 on epoch=354
06/13/2022 07:42:03 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.03 on epoch=357
06/13/2022 07:42:05 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.04 on epoch=359
06/13/2022 07:42:07 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.04 on epoch=362
06/13/2022 07:42:08 - INFO - __main__ - Global step 1450 Train loss 0.04 Classification-F1 0.7665467887242081 on epoch=362
06/13/2022 07:42:08 - INFO - __main__ - Saving model with best Classification-F1: 0.7659467503217504 -> 0.7665467887242081 on epoch=362, global_step=1450
06/13/2022 07:42:11 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.06 on epoch=364
06/13/2022 07:42:13 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=367
06/13/2022 07:42:16 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=369
06/13/2022 07:42:18 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.03 on epoch=372
06/13/2022 07:42:21 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.02 on epoch=374
06/13/2022 07:42:21 - INFO - __main__ - Global step 1500 Train loss 0.03 Classification-F1 0.7458139563494993 on epoch=374
06/13/2022 07:42:24 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.11 on epoch=377
06/13/2022 07:42:26 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.02 on epoch=379
06/13/2022 07:42:29 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.05 on epoch=382
06/13/2022 07:42:31 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.05 on epoch=384
06/13/2022 07:42:33 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.05 on epoch=387
06/13/2022 07:42:34 - INFO - __main__ - Global step 1550 Train loss 0.06 Classification-F1 0.7523801220575415 on epoch=387
06/13/2022 07:42:37 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.04 on epoch=389
06/13/2022 07:42:39 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.04 on epoch=392
06/13/2022 07:42:42 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.04 on epoch=394
06/13/2022 07:42:44 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.06 on epoch=397
06/13/2022 07:42:47 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.07 on epoch=399
06/13/2022 07:42:48 - INFO - __main__ - Global step 1600 Train loss 0.05 Classification-F1 0.7455176073689398 on epoch=399
06/13/2022 07:42:50 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.05 on epoch=402
06/13/2022 07:42:52 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.15 on epoch=404
06/13/2022 07:42:55 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.02 on epoch=407
06/13/2022 07:42:57 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=409
06/13/2022 07:43:00 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=412
06/13/2022 07:43:01 - INFO - __main__ - Global step 1650 Train loss 0.05 Classification-F1 0.7665467887242081 on epoch=412
06/13/2022 07:43:03 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=414
06/13/2022 07:43:05 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.10 on epoch=417
06/13/2022 07:43:08 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=419
06/13/2022 07:43:10 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.02 on epoch=422
06/13/2022 07:43:13 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=424
06/13/2022 07:43:14 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.7525983061101029 on epoch=424
06/13/2022 07:43:16 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=427
06/13/2022 07:43:19 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.02 on epoch=429
06/13/2022 07:43:21 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.05 on epoch=432
06/13/2022 07:43:23 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=434
06/13/2022 07:43:26 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=437
06/13/2022 07:43:27 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.7234266221108325 on epoch=437
06/13/2022 07:43:29 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.05 on epoch=439
06/13/2022 07:43:32 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=442
06/13/2022 07:43:34 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.08 on epoch=444
06/13/2022 07:43:37 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.05 on epoch=447
06/13/2022 07:43:39 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=449
06/13/2022 07:43:40 - INFO - __main__ - Global step 1800 Train loss 0.04 Classification-F1 0.7523019571295434 on epoch=449
06/13/2022 07:43:42 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=452
06/13/2022 07:43:45 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=454
06/13/2022 07:43:47 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=457
06/13/2022 07:43:50 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.04 on epoch=459
06/13/2022 07:43:52 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.05 on epoch=462
06/13/2022 07:43:53 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.7510360360360361 on epoch=462
06/13/2022 07:43:55 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=464
06/13/2022 07:43:58 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=467
06/13/2022 07:44:00 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=469
06/13/2022 07:44:03 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=472
06/13/2022 07:44:05 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=474
06/13/2022 07:44:06 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.7665467887242081 on epoch=474
06/13/2022 07:44:08 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=477
06/13/2022 07:44:11 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.06 on epoch=479
06/13/2022 07:44:13 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.13 on epoch=482
06/13/2022 07:44:16 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.04 on epoch=484
06/13/2022 07:44:18 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.06 on epoch=487
06/13/2022 07:44:19 - INFO - __main__ - Global step 1950 Train loss 0.06 Classification-F1 0.7258190883190883 on epoch=487
06/13/2022 07:44:22 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=489
06/13/2022 07:44:24 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=492
06/13/2022 07:44:26 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=494
06/13/2022 07:44:29 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.06 on epoch=497
06/13/2022 07:44:31 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=499
06/13/2022 07:44:32 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.7451255702163143 on epoch=499
06/13/2022 07:44:35 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.06 on epoch=502
06/13/2022 07:44:37 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.06 on epoch=504
06/13/2022 07:44:39 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/13/2022 07:44:42 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=509
06/13/2022 07:44:44 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.02 on epoch=512
06/13/2022 07:44:45 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.7388803573921541 on epoch=512
06/13/2022 07:44:47 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.05 on epoch=514
06/13/2022 07:44:50 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=517
06/13/2022 07:44:52 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=519
06/13/2022 07:44:55 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.04 on epoch=522
06/13/2022 07:44:57 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=524
06/13/2022 07:44:58 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.7412087912087911 on epoch=524
06/13/2022 07:45:00 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
06/13/2022 07:45:03 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=529
06/13/2022 07:45:05 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=532
06/13/2022 07:45:08 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=534
06/13/2022 07:45:10 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=537
06/13/2022 07:45:11 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.7367457104299209 on epoch=537
06/13/2022 07:45:13 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.03 on epoch=539
06/13/2022 07:45:16 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.04 on epoch=542
06/13/2022 07:45:18 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/13/2022 07:45:21 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.04 on epoch=547
06/13/2022 07:45:23 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=549
06/13/2022 07:45:24 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.7525224944089042 on epoch=549
06/13/2022 07:45:26 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=552
06/13/2022 07:45:29 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.05 on epoch=554
06/13/2022 07:45:31 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.03 on epoch=557
06/13/2022 07:45:34 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.03 on epoch=559
06/13/2022 07:45:36 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/13/2022 07:45:37 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.7471725730306966 on epoch=562
06/13/2022 07:45:39 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/13/2022 07:45:42 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.03 on epoch=567
06/13/2022 07:45:44 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/13/2022 07:45:47 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/13/2022 07:45:49 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/13/2022 07:45:50 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.7589718510863414 on epoch=574
06/13/2022 07:45:53 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=577
06/13/2022 07:45:55 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=579
06/13/2022 07:45:58 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=582
06/13/2022 07:46:00 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=584
06/13/2022 07:46:02 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.05 on epoch=587
06/13/2022 07:46:03 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.7589718510863414 on epoch=587
06/13/2022 07:46:06 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/13/2022 07:46:08 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=592
06/13/2022 07:46:11 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=594
06/13/2022 07:46:13 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/13/2022 07:46:15 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/13/2022 07:46:16 - INFO - __main__ - Global step 2400 Train loss 0.00 Classification-F1 0.7663104711380573 on epoch=599
06/13/2022 07:46:19 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.03 on epoch=602
06/13/2022 07:46:21 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=604
06/13/2022 07:46:24 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=607
06/13/2022 07:46:26 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/13/2022 07:46:28 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/13/2022 07:46:29 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.7605629877369007 on epoch=612
06/13/2022 07:46:32 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=614
06/13/2022 07:46:34 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/13/2022 07:46:37 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/13/2022 07:46:39 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=622
06/13/2022 07:46:41 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=624
06/13/2022 07:46:42 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.7373180873180873 on epoch=624
06/13/2022 07:46:45 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.03 on epoch=627
06/13/2022 07:46:47 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/13/2022 07:46:50 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/13/2022 07:46:52 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/13/2022 07:46:54 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=637
06/13/2022 07:46:55 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.7523019571295434 on epoch=637
06/13/2022 07:46:58 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.04 on epoch=639
06/13/2022 07:47:00 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.04 on epoch=642
06/13/2022 07:47:03 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.04 on epoch=644
06/13/2022 07:47:05 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=647
06/13/2022 07:47:07 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/13/2022 07:47:08 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.7386590834866696 on epoch=649
06/13/2022 07:47:11 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=652
06/13/2022 07:47:13 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/13/2022 07:47:16 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/13/2022 07:47:18 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/13/2022 07:47:21 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/13/2022 07:47:21 - INFO - __main__ - Global step 2650 Train loss 0.00 Classification-F1 0.7523019571295434 on epoch=662
06/13/2022 07:47:24 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/13/2022 07:47:26 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=667
06/13/2022 07:47:29 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/13/2022 07:47:31 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.05 on epoch=672
06/13/2022 07:47:34 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/13/2022 07:47:35 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.7392288840564702 on epoch=674
06/13/2022 07:47:37 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.08 on epoch=677
06/13/2022 07:47:39 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=679
06/13/2022 07:47:42 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/13/2022 07:47:44 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/13/2022 07:47:47 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=687
06/13/2022 07:47:48 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.7605629877369007 on epoch=687
06/13/2022 07:47:50 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.03 on epoch=689
06/13/2022 07:47:52 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.05 on epoch=692
06/13/2022 07:47:55 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=694
06/13/2022 07:47:57 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.10 on epoch=697
06/13/2022 07:48:00 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=699
06/13/2022 07:48:01 - INFO - __main__ - Global step 2800 Train loss 0.04 Classification-F1 0.7526261373035567 on epoch=699
06/13/2022 07:48:03 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/13/2022 07:48:06 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/13/2022 07:48:08 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=707
06/13/2022 07:48:11 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=709
06/13/2022 07:48:13 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/13/2022 07:48:14 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.7445958186447318 on epoch=712
06/13/2022 07:48:16 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/13/2022 07:48:19 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/13/2022 07:48:21 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.04 on epoch=719
06/13/2022 07:48:24 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/13/2022 07:48:26 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=724
06/13/2022 07:48:27 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.7605629877369007 on epoch=724
06/13/2022 07:48:29 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=727
06/13/2022 07:48:32 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.04 on epoch=729
06/13/2022 07:48:34 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=732
06/13/2022 07:48:37 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.05 on epoch=734
06/13/2022 07:48:39 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/13/2022 07:48:40 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.7665467887242081 on epoch=737
06/13/2022 07:48:42 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/13/2022 07:48:45 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/13/2022 07:48:47 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/13/2022 07:48:50 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=747
06/13/2022 07:48:52 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.09 on epoch=749
06/13/2022 07:48:53 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.7455176073689398 on epoch=749
06/13/2022 07:48:53 - INFO - __main__ - save last model!
06/13/2022 07:48:53 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/13/2022 07:48:53 - INFO - __main__ - Start tokenizing ... 5509 instances
06/13/2022 07:48:53 - INFO - __main__ - Printing 3 examples
06/13/2022 07:48:53 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/13/2022 07:48:53 - INFO - __main__ - ['others']
06/13/2022 07:48:53 - INFO - __main__ -  [emo] what you like very little things ok
06/13/2022 07:48:53 - INFO - __main__ - ['others']
06/13/2022 07:48:53 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/13/2022 07:48:53 - INFO - __main__ - ['others']
06/13/2022 07:48:53 - INFO - __main__ - Tokenizing Input ...
06/13/2022 07:48:54 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 07:48:54 - INFO - __main__ - Printing 3 examples
06/13/2022 07:48:54 - INFO - __main__ -  [emo] how cause yes am listening
06/13/2022 07:48:54 - INFO - __main__ - ['others']
06/13/2022 07:48:54 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/13/2022 07:48:54 - INFO - __main__ - ['others']
06/13/2022 07:48:54 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/13/2022 07:48:54 - INFO - __main__ - ['others']
06/13/2022 07:48:54 - INFO - __main__ - Tokenizing Input ...
06/13/2022 07:48:54 - INFO - __main__ - Tokenizing Output ...
06/13/2022 07:48:54 - INFO - __main__ - Loaded 64 examples from train data
06/13/2022 07:48:54 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 07:48:54 - INFO - __main__ - Printing 3 examples
06/13/2022 07:48:54 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
06/13/2022 07:48:54 - INFO - __main__ - ['others']
06/13/2022 07:48:54 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
06/13/2022 07:48:54 - INFO - __main__ - ['others']
06/13/2022 07:48:54 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
06/13/2022 07:48:54 - INFO - __main__ - ['others']
06/13/2022 07:48:54 - INFO - __main__ - Tokenizing Input ...
06/13/2022 07:48:54 - INFO - __main__ - Tokenizing Output ...
06/13/2022 07:48:54 - INFO - __main__ - Loaded 64 examples from dev data
06/13/2022 07:48:55 - INFO - __main__ - Tokenizing Output ...
06/13/2022 07:49:01 - INFO - __main__ - Loaded 5509 examples from test data
06/13/2022 07:49:09 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 07:49:09 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 07:49:09 - INFO - __main__ - Starting training!
06/13/2022 07:50:26 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-up32shot/singletask-emo/emo_16_100_0.4_8_predictions.txt
06/13/2022 07:50:26 - INFO - __main__ - Classification-F1 on test data: 0.4117
06/13/2022 07:50:26 - INFO - __main__ - prefix=emo_16_100, lr=0.4, bsz=8, dev_performance=0.7665467887242081, test_performance=0.41173079274357555
06/13/2022 07:50:26 - INFO - __main__ - Running ... prefix=emo_16_100, lr=0.3, bsz=8 ...
06/13/2022 07:50:27 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 07:50:27 - INFO - __main__ - Printing 3 examples
06/13/2022 07:50:27 - INFO - __main__ -  [emo] how cause yes am listening
06/13/2022 07:50:27 - INFO - __main__ - ['others']
06/13/2022 07:50:27 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/13/2022 07:50:27 - INFO - __main__ - ['others']
06/13/2022 07:50:27 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/13/2022 07:50:27 - INFO - __main__ - ['others']
06/13/2022 07:50:27 - INFO - __main__ - Tokenizing Input ...
06/13/2022 07:50:27 - INFO - __main__ - Tokenizing Output ...
06/13/2022 07:50:27 - INFO - __main__ - Loaded 64 examples from train data
06/13/2022 07:50:27 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 07:50:27 - INFO - __main__ - Printing 3 examples
06/13/2022 07:50:27 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
06/13/2022 07:50:27 - INFO - __main__ - ['others']
06/13/2022 07:50:27 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
06/13/2022 07:50:27 - INFO - __main__ - ['others']
06/13/2022 07:50:27 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
06/13/2022 07:50:27 - INFO - __main__ - ['others']
06/13/2022 07:50:27 - INFO - __main__ - Tokenizing Input ...
06/13/2022 07:50:27 - INFO - __main__ - Tokenizing Output ...
06/13/2022 07:50:28 - INFO - __main__ - Loaded 64 examples from dev data
06/13/2022 07:50:46 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 07:50:47 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 07:50:47 - INFO - __main__ - Starting training!
06/13/2022 07:50:50 - INFO - __main__ - Step 10 Global step 10 Train loss 4.11 on epoch=2
06/13/2022 07:50:53 - INFO - __main__ - Step 20 Global step 20 Train loss 2.81 on epoch=4
06/13/2022 07:50:55 - INFO - __main__ - Step 30 Global step 30 Train loss 2.35 on epoch=7
06/13/2022 07:50:58 - INFO - __main__ - Step 40 Global step 40 Train loss 1.85 on epoch=9
06/13/2022 07:51:00 - INFO - __main__ - Step 50 Global step 50 Train loss 1.70 on epoch=12
06/13/2022 07:51:01 - INFO - __main__ - Global step 50 Train loss 2.56 Classification-F1 0.09770817417876242 on epoch=12
06/13/2022 07:51:01 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.09770817417876242 on epoch=12, global_step=50
06/13/2022 07:51:04 - INFO - __main__ - Step 60 Global step 60 Train loss 1.24 on epoch=14
06/13/2022 07:51:06 - INFO - __main__ - Step 70 Global step 70 Train loss 1.18 on epoch=17
06/13/2022 07:51:09 - INFO - __main__ - Step 80 Global step 80 Train loss 1.02 on epoch=19
06/13/2022 07:51:11 - INFO - __main__ - Step 90 Global step 90 Train loss 0.94 on epoch=22
06/13/2022 07:51:14 - INFO - __main__ - Step 100 Global step 100 Train loss 0.92 on epoch=24
06/13/2022 07:51:15 - INFO - __main__ - Global step 100 Train loss 1.06 Classification-F1 0.3728223410576352 on epoch=24
06/13/2022 07:51:15 - INFO - __main__ - Saving model with best Classification-F1: 0.09770817417876242 -> 0.3728223410576352 on epoch=24, global_step=100
06/13/2022 07:51:17 - INFO - __main__ - Step 110 Global step 110 Train loss 0.91 on epoch=27
06/13/2022 07:51:20 - INFO - __main__ - Step 120 Global step 120 Train loss 0.77 on epoch=29
06/13/2022 07:51:22 - INFO - __main__ - Step 130 Global step 130 Train loss 0.89 on epoch=32
06/13/2022 07:51:25 - INFO - __main__ - Step 140 Global step 140 Train loss 0.78 on epoch=34
06/13/2022 07:51:27 - INFO - __main__ - Step 150 Global step 150 Train loss 0.76 on epoch=37
06/13/2022 07:51:28 - INFO - __main__ - Global step 150 Train loss 0.82 Classification-F1 0.5847985347985348 on epoch=37
06/13/2022 07:51:28 - INFO - __main__ - Saving model with best Classification-F1: 0.3728223410576352 -> 0.5847985347985348 on epoch=37, global_step=150
06/13/2022 07:51:31 - INFO - __main__ - Step 160 Global step 160 Train loss 0.75 on epoch=39
06/13/2022 07:51:33 - INFO - __main__ - Step 170 Global step 170 Train loss 0.73 on epoch=42
06/13/2022 07:51:36 - INFO - __main__ - Step 180 Global step 180 Train loss 0.60 on epoch=44
06/13/2022 07:51:38 - INFO - __main__ - Step 190 Global step 190 Train loss 0.63 on epoch=47
06/13/2022 07:51:41 - INFO - __main__ - Step 200 Global step 200 Train loss 0.63 on epoch=49
06/13/2022 07:51:41 - INFO - __main__ - Global step 200 Train loss 0.67 Classification-F1 0.5914473684210526 on epoch=49
06/13/2022 07:51:41 - INFO - __main__ - Saving model with best Classification-F1: 0.5847985347985348 -> 0.5914473684210526 on epoch=49, global_step=200
06/13/2022 07:51:44 - INFO - __main__ - Step 210 Global step 210 Train loss 0.69 on epoch=52
06/13/2022 07:51:46 - INFO - __main__ - Step 220 Global step 220 Train loss 0.58 on epoch=54
06/13/2022 07:51:49 - INFO - __main__ - Step 230 Global step 230 Train loss 0.65 on epoch=57
06/13/2022 07:51:51 - INFO - __main__ - Step 240 Global step 240 Train loss 0.68 on epoch=59
06/13/2022 07:51:54 - INFO - __main__ - Step 250 Global step 250 Train loss 0.51 on epoch=62
06/13/2022 07:51:55 - INFO - __main__ - Global step 250 Train loss 0.62 Classification-F1 0.6013071895424836 on epoch=62
06/13/2022 07:51:55 - INFO - __main__ - Saving model with best Classification-F1: 0.5914473684210526 -> 0.6013071895424836 on epoch=62, global_step=250
06/13/2022 07:51:57 - INFO - __main__ - Step 260 Global step 260 Train loss 0.53 on epoch=64
06/13/2022 07:52:00 - INFO - __main__ - Step 270 Global step 270 Train loss 0.60 on epoch=67
06/13/2022 07:52:02 - INFO - __main__ - Step 280 Global step 280 Train loss 0.56 on epoch=69
06/13/2022 07:52:05 - INFO - __main__ - Step 290 Global step 290 Train loss 0.66 on epoch=72
06/13/2022 07:52:07 - INFO - __main__ - Step 300 Global step 300 Train loss 0.58 on epoch=74
06/13/2022 07:52:08 - INFO - __main__ - Global step 300 Train loss 0.59 Classification-F1 0.6098939604445897 on epoch=74
06/13/2022 07:52:08 - INFO - __main__ - Saving model with best Classification-F1: 0.6013071895424836 -> 0.6098939604445897 on epoch=74, global_step=300
06/13/2022 07:52:10 - INFO - __main__ - Step 310 Global step 310 Train loss 0.52 on epoch=77
06/13/2022 07:52:13 - INFO - __main__ - Step 320 Global step 320 Train loss 0.63 on epoch=79
06/13/2022 07:52:15 - INFO - __main__ - Step 330 Global step 330 Train loss 0.53 on epoch=82
06/13/2022 07:52:18 - INFO - __main__ - Step 340 Global step 340 Train loss 0.50 on epoch=84
06/13/2022 07:52:20 - INFO - __main__ - Step 350 Global step 350 Train loss 0.53 on epoch=87
06/13/2022 07:52:21 - INFO - __main__ - Global step 350 Train loss 0.54 Classification-F1 0.6302083333333333 on epoch=87
06/13/2022 07:52:21 - INFO - __main__ - Saving model with best Classification-F1: 0.6098939604445897 -> 0.6302083333333333 on epoch=87, global_step=350
06/13/2022 07:52:24 - INFO - __main__ - Step 360 Global step 360 Train loss 0.49 on epoch=89
06/13/2022 07:52:26 - INFO - __main__ - Step 370 Global step 370 Train loss 0.53 on epoch=92
06/13/2022 07:52:29 - INFO - __main__ - Step 380 Global step 380 Train loss 0.47 on epoch=94
06/13/2022 07:52:31 - INFO - __main__ - Step 390 Global step 390 Train loss 0.53 on epoch=97
06/13/2022 07:52:34 - INFO - __main__ - Step 400 Global step 400 Train loss 0.44 on epoch=99
06/13/2022 07:52:34 - INFO - __main__ - Global step 400 Train loss 0.49 Classification-F1 0.6510293284486832 on epoch=99
06/13/2022 07:52:35 - INFO - __main__ - Saving model with best Classification-F1: 0.6302083333333333 -> 0.6510293284486832 on epoch=99, global_step=400
06/13/2022 07:52:37 - INFO - __main__ - Step 410 Global step 410 Train loss 0.47 on epoch=102
06/13/2022 07:52:39 - INFO - __main__ - Step 420 Global step 420 Train loss 0.42 on epoch=104
06/13/2022 07:52:42 - INFO - __main__ - Step 430 Global step 430 Train loss 0.44 on epoch=107
06/13/2022 07:52:44 - INFO - __main__ - Step 440 Global step 440 Train loss 0.44 on epoch=109
06/13/2022 07:52:47 - INFO - __main__ - Step 450 Global step 450 Train loss 0.37 on epoch=112
06/13/2022 07:52:48 - INFO - __main__ - Global step 450 Train loss 0.43 Classification-F1 0.6510293284486832 on epoch=112
06/13/2022 07:52:50 - INFO - __main__ - Step 460 Global step 460 Train loss 0.37 on epoch=114
06/13/2022 07:52:53 - INFO - __main__ - Step 470 Global step 470 Train loss 0.38 on epoch=117
06/13/2022 07:52:55 - INFO - __main__ - Step 480 Global step 480 Train loss 0.47 on epoch=119
06/13/2022 07:52:58 - INFO - __main__ - Step 490 Global step 490 Train loss 0.46 on epoch=122
06/13/2022 07:53:00 - INFO - __main__ - Step 500 Global step 500 Train loss 0.38 on epoch=124
06/13/2022 07:53:01 - INFO - __main__ - Global step 500 Train loss 0.41 Classification-F1 0.650904203323558 on epoch=124
06/13/2022 07:53:04 - INFO - __main__ - Step 510 Global step 510 Train loss 0.38 on epoch=127
06/13/2022 07:53:06 - INFO - __main__ - Step 520 Global step 520 Train loss 0.32 on epoch=129
06/13/2022 07:53:09 - INFO - __main__ - Step 530 Global step 530 Train loss 0.34 on epoch=132
06/13/2022 07:53:11 - INFO - __main__ - Step 540 Global step 540 Train loss 0.32 on epoch=134
06/13/2022 07:53:14 - INFO - __main__ - Step 550 Global step 550 Train loss 0.38 on epoch=137
06/13/2022 07:53:15 - INFO - __main__ - Global step 550 Train loss 0.35 Classification-F1 0.6361475428729486 on epoch=137
06/13/2022 07:53:17 - INFO - __main__ - Step 560 Global step 560 Train loss 0.35 on epoch=139
06/13/2022 07:53:20 - INFO - __main__ - Step 570 Global step 570 Train loss 0.39 on epoch=142
06/13/2022 07:53:22 - INFO - __main__ - Step 580 Global step 580 Train loss 0.32 on epoch=144
06/13/2022 07:53:25 - INFO - __main__ - Step 590 Global step 590 Train loss 0.34 on epoch=147
06/13/2022 07:53:27 - INFO - __main__ - Step 600 Global step 600 Train loss 0.30 on epoch=149
06/13/2022 07:53:28 - INFO - __main__ - Global step 600 Train loss 0.34 Classification-F1 0.6501862393703001 on epoch=149
06/13/2022 07:53:30 - INFO - __main__ - Step 610 Global step 610 Train loss 0.36 on epoch=152
06/13/2022 07:53:33 - INFO - __main__ - Step 620 Global step 620 Train loss 0.35 on epoch=154
06/13/2022 07:53:35 - INFO - __main__ - Step 630 Global step 630 Train loss 0.24 on epoch=157
06/13/2022 07:53:38 - INFO - __main__ - Step 640 Global step 640 Train loss 0.23 on epoch=159
06/13/2022 07:53:40 - INFO - __main__ - Step 650 Global step 650 Train loss 0.36 on epoch=162
06/13/2022 07:53:41 - INFO - __main__ - Global step 650 Train loss 0.31 Classification-F1 0.6545977011494253 on epoch=162
06/13/2022 07:53:41 - INFO - __main__ - Saving model with best Classification-F1: 0.6510293284486832 -> 0.6545977011494253 on epoch=162, global_step=650
06/13/2022 07:53:44 - INFO - __main__ - Step 660 Global step 660 Train loss 0.31 on epoch=164
06/13/2022 07:53:46 - INFO - __main__ - Step 670 Global step 670 Train loss 0.29 on epoch=167
06/13/2022 07:53:49 - INFO - __main__ - Step 680 Global step 680 Train loss 0.24 on epoch=169
06/13/2022 07:53:51 - INFO - __main__ - Step 690 Global step 690 Train loss 0.34 on epoch=172
06/13/2022 07:53:54 - INFO - __main__ - Step 700 Global step 700 Train loss 0.26 on epoch=174
06/13/2022 07:53:55 - INFO - __main__ - Global step 700 Train loss 0.29 Classification-F1 0.6464905622690502 on epoch=174
06/13/2022 07:53:57 - INFO - __main__ - Step 710 Global step 710 Train loss 0.21 on epoch=177
06/13/2022 07:53:59 - INFO - __main__ - Step 720 Global step 720 Train loss 0.33 on epoch=179
06/13/2022 07:54:02 - INFO - __main__ - Step 730 Global step 730 Train loss 0.29 on epoch=182
06/13/2022 07:54:04 - INFO - __main__ - Step 740 Global step 740 Train loss 0.27 on epoch=184
06/13/2022 07:54:07 - INFO - __main__ - Step 750 Global step 750 Train loss 0.32 on epoch=187
06/13/2022 07:54:08 - INFO - __main__ - Global step 750 Train loss 0.28 Classification-F1 0.6370700489721624 on epoch=187
06/13/2022 07:54:10 - INFO - __main__ - Step 760 Global step 760 Train loss 0.24 on epoch=189
06/13/2022 07:54:13 - INFO - __main__ - Step 770 Global step 770 Train loss 0.30 on epoch=192
06/13/2022 07:54:15 - INFO - __main__ - Step 780 Global step 780 Train loss 0.29 on epoch=194
06/13/2022 07:54:18 - INFO - __main__ - Step 790 Global step 790 Train loss 0.28 on epoch=197
06/13/2022 07:54:20 - INFO - __main__ - Step 800 Global step 800 Train loss 0.21 on epoch=199
06/13/2022 07:54:21 - INFO - __main__ - Global step 800 Train loss 0.27 Classification-F1 0.6407378740970072 on epoch=199
06/13/2022 07:54:24 - INFO - __main__ - Step 810 Global step 810 Train loss 0.25 on epoch=202
06/13/2022 07:54:26 - INFO - __main__ - Step 820 Global step 820 Train loss 0.21 on epoch=204
06/13/2022 07:54:29 - INFO - __main__ - Step 830 Global step 830 Train loss 0.20 on epoch=207
06/13/2022 07:54:31 - INFO - __main__ - Step 840 Global step 840 Train loss 0.19 on epoch=209
06/13/2022 07:54:34 - INFO - __main__ - Step 850 Global step 850 Train loss 0.12 on epoch=212
06/13/2022 07:54:34 - INFO - __main__ - Global step 850 Train loss 0.20 Classification-F1 0.68006993006993 on epoch=212
06/13/2022 07:54:34 - INFO - __main__ - Saving model with best Classification-F1: 0.6545977011494253 -> 0.68006993006993 on epoch=212, global_step=850
06/13/2022 07:54:37 - INFO - __main__ - Step 860 Global step 860 Train loss 0.20 on epoch=214
06/13/2022 07:54:39 - INFO - __main__ - Step 870 Global step 870 Train loss 0.20 on epoch=217
06/13/2022 07:54:42 - INFO - __main__ - Step 880 Global step 880 Train loss 0.25 on epoch=219
06/13/2022 07:54:45 - INFO - __main__ - Step 890 Global step 890 Train loss 0.23 on epoch=222
06/13/2022 07:54:47 - INFO - __main__ - Step 900 Global step 900 Train loss 0.20 on epoch=224
06/13/2022 07:54:48 - INFO - __main__ - Global step 900 Train loss 0.21 Classification-F1 0.6613667582417583 on epoch=224
06/13/2022 07:54:50 - INFO - __main__ - Step 910 Global step 910 Train loss 0.26 on epoch=227
06/13/2022 07:54:53 - INFO - __main__ - Step 920 Global step 920 Train loss 0.20 on epoch=229
06/13/2022 07:54:55 - INFO - __main__ - Step 930 Global step 930 Train loss 0.20 on epoch=232
06/13/2022 07:54:58 - INFO - __main__ - Step 940 Global step 940 Train loss 0.14 on epoch=234
06/13/2022 07:55:00 - INFO - __main__ - Step 950 Global step 950 Train loss 0.22 on epoch=237
06/13/2022 07:55:01 - INFO - __main__ - Global step 950 Train loss 0.20 Classification-F1 0.6386554621848739 on epoch=237
06/13/2022 07:55:04 - INFO - __main__ - Step 960 Global step 960 Train loss 0.13 on epoch=239
06/13/2022 07:55:06 - INFO - __main__ - Step 970 Global step 970 Train loss 0.18 on epoch=242
06/13/2022 07:55:09 - INFO - __main__ - Step 980 Global step 980 Train loss 0.15 on epoch=244
06/13/2022 07:55:11 - INFO - __main__ - Step 990 Global step 990 Train loss 0.09 on epoch=247
06/13/2022 07:55:14 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.15 on epoch=249
06/13/2022 07:55:14 - INFO - __main__ - Global step 1000 Train loss 0.14 Classification-F1 0.6392195203170813 on epoch=249
06/13/2022 07:55:17 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.14 on epoch=252
06/13/2022 07:55:19 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.20 on epoch=254
06/13/2022 07:55:22 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.13 on epoch=257
06/13/2022 07:55:24 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.17 on epoch=259
06/13/2022 07:55:27 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.13 on epoch=262
06/13/2022 07:55:28 - INFO - __main__ - Global step 1050 Train loss 0.15 Classification-F1 0.5538194444444444 on epoch=262
06/13/2022 07:55:30 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.12 on epoch=264
06/13/2022 07:55:33 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.16 on epoch=267
06/13/2022 07:55:35 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.11 on epoch=269
06/13/2022 07:55:38 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.15 on epoch=272
06/13/2022 07:55:40 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.10 on epoch=274
06/13/2022 07:55:41 - INFO - __main__ - Global step 1100 Train loss 0.13 Classification-F1 0.6497475497475498 on epoch=274
06/13/2022 07:55:43 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.12 on epoch=277
06/13/2022 07:55:46 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.13 on epoch=279
06/13/2022 07:55:48 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.20 on epoch=282
06/13/2022 07:55:51 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.10 on epoch=284
06/13/2022 07:55:53 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.10 on epoch=287
06/13/2022 07:55:54 - INFO - __main__ - Global step 1150 Train loss 0.13 Classification-F1 0.663609022556391 on epoch=287
06/13/2022 07:55:57 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.09 on epoch=289
06/13/2022 07:55:59 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.05 on epoch=292
06/13/2022 07:56:02 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.15 on epoch=294
06/13/2022 07:56:04 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.09 on epoch=297
06/13/2022 07:56:07 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.08 on epoch=299
06/13/2022 07:56:08 - INFO - __main__ - Global step 1200 Train loss 0.09 Classification-F1 0.6565058479532164 on epoch=299
06/13/2022 07:56:10 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.05 on epoch=302
06/13/2022 07:56:13 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.06 on epoch=304
06/13/2022 07:56:15 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.11 on epoch=307
06/13/2022 07:56:18 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.09 on epoch=309
06/13/2022 07:56:20 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.16 on epoch=312
06/13/2022 07:56:21 - INFO - __main__ - Global step 1250 Train loss 0.09 Classification-F1 0.6111398405516053 on epoch=312
06/13/2022 07:56:24 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.11 on epoch=314
06/13/2022 07:56:26 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.06 on epoch=317
06/13/2022 07:56:29 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.09 on epoch=319
06/13/2022 07:56:31 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.04 on epoch=322
06/13/2022 07:56:33 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.13 on epoch=324
06/13/2022 07:56:34 - INFO - __main__ - Global step 1300 Train loss 0.09 Classification-F1 0.6564636327503974 on epoch=324
06/13/2022 07:56:37 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.06 on epoch=327
06/13/2022 07:56:39 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.05 on epoch=329
06/13/2022 07:56:42 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.05 on epoch=332
06/13/2022 07:56:44 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.08 on epoch=334
06/13/2022 07:56:47 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.04 on epoch=337
06/13/2022 07:56:48 - INFO - __main__ - Global step 1350 Train loss 0.06 Classification-F1 0.6648425446599888 on epoch=337
06/13/2022 07:56:50 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.10 on epoch=339
06/13/2022 07:56:53 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.03 on epoch=342
06/13/2022 07:56:55 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.08 on epoch=344
06/13/2022 07:56:58 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.10 on epoch=347
06/13/2022 07:57:00 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.04 on epoch=349
06/13/2022 07:57:01 - INFO - __main__ - Global step 1400 Train loss 0.07 Classification-F1 0.6766066066066065 on epoch=349
06/13/2022 07:57:04 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.04 on epoch=352
06/13/2022 07:57:06 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.07 on epoch=354
06/13/2022 07:57:09 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.04 on epoch=357
06/13/2022 07:57:11 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.07 on epoch=359
06/13/2022 07:57:13 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.07 on epoch=362
06/13/2022 07:57:14 - INFO - __main__ - Global step 1450 Train loss 0.06 Classification-F1 0.6565058479532164 on epoch=362
06/13/2022 07:57:17 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.03 on epoch=364
06/13/2022 07:57:19 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.04 on epoch=367
06/13/2022 07:57:22 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.09 on epoch=369
06/13/2022 07:57:24 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.04 on epoch=372
06/13/2022 07:57:27 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.07 on epoch=374
06/13/2022 07:57:28 - INFO - __main__ - Global step 1500 Train loss 0.05 Classification-F1 0.6279113214597086 on epoch=374
06/13/2022 07:57:30 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.11 on epoch=377
06/13/2022 07:57:32 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.04 on epoch=379
06/13/2022 07:57:35 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.06 on epoch=382
06/13/2022 07:57:37 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.06 on epoch=384
06/13/2022 07:57:40 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.06 on epoch=387
06/13/2022 07:57:41 - INFO - __main__ - Global step 1550 Train loss 0.07 Classification-F1 0.6931246218995766 on epoch=387
06/13/2022 07:57:41 - INFO - __main__ - Saving model with best Classification-F1: 0.68006993006993 -> 0.6931246218995766 on epoch=387, global_step=1550
06/13/2022 07:57:43 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.07 on epoch=389
06/13/2022 07:57:46 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.04 on epoch=392
06/13/2022 07:57:48 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.12 on epoch=394
06/13/2022 07:57:51 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.06 on epoch=397
06/13/2022 07:57:53 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.09 on epoch=399
06/13/2022 07:57:54 - INFO - __main__ - Global step 1600 Train loss 0.08 Classification-F1 0.6645216645216645 on epoch=399
06/13/2022 07:57:57 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=402
06/13/2022 07:57:59 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.08 on epoch=404
06/13/2022 07:58:02 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.04 on epoch=407
06/13/2022 07:58:04 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.04 on epoch=409
06/13/2022 07:58:07 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.07 on epoch=412
06/13/2022 07:58:08 - INFO - __main__ - Global step 1650 Train loss 0.05 Classification-F1 0.6730901451489687 on epoch=412
06/13/2022 07:58:10 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.08 on epoch=414
06/13/2022 07:58:12 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.03 on epoch=417
06/13/2022 07:58:15 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.12 on epoch=419
06/13/2022 07:58:17 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.03 on epoch=422
06/13/2022 07:58:20 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=424
06/13/2022 07:58:21 - INFO - __main__ - Global step 1700 Train loss 0.06 Classification-F1 0.6843696717817562 on epoch=424
06/13/2022 07:58:23 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.14 on epoch=427
06/13/2022 07:58:26 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.07 on epoch=429
06/13/2022 07:58:28 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.06 on epoch=432
06/13/2022 07:58:31 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.07 on epoch=434
06/13/2022 07:58:33 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.04 on epoch=437
06/13/2022 07:58:34 - INFO - __main__ - Global step 1750 Train loss 0.08 Classification-F1 0.6531400966183575 on epoch=437
06/13/2022 07:58:37 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.06 on epoch=439
06/13/2022 07:58:39 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.04 on epoch=442
06/13/2022 07:58:42 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.08 on epoch=444
06/13/2022 07:58:44 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.05 on epoch=447
06/13/2022 07:58:47 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.09 on epoch=449
06/13/2022 07:58:48 - INFO - __main__ - Global step 1800 Train loss 0.06 Classification-F1 0.659352155496345 on epoch=449
06/13/2022 07:58:50 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.05 on epoch=452
06/13/2022 07:58:53 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.05 on epoch=454
06/13/2022 07:58:55 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=457
06/13/2022 07:58:58 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.04 on epoch=459
06/13/2022 07:59:00 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=462
06/13/2022 07:59:01 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.643452380952381 on epoch=462
06/13/2022 07:59:03 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=464
06/13/2022 07:59:06 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.05 on epoch=467
06/13/2022 07:59:08 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=469
06/13/2022 07:59:11 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.03 on epoch=472
06/13/2022 07:59:13 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=474
06/13/2022 07:59:14 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.6450757575757576 on epoch=474
06/13/2022 07:59:17 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.05 on epoch=477
06/13/2022 07:59:19 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=479
06/13/2022 07:59:22 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=482
06/13/2022 07:59:24 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.13 on epoch=484
06/13/2022 07:59:27 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.05 on epoch=487
06/13/2022 07:59:28 - INFO - __main__ - Global step 1950 Train loss 0.06 Classification-F1 0.6677201939570755 on epoch=487
06/13/2022 07:59:30 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.04 on epoch=489
06/13/2022 07:59:32 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=492
06/13/2022 07:59:35 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.06 on epoch=494
06/13/2022 07:59:37 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.07 on epoch=497
06/13/2022 07:59:40 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.04 on epoch=499
06/13/2022 07:59:41 - INFO - __main__ - Global step 2000 Train loss 0.05 Classification-F1 0.6667718772192851 on epoch=499
06/13/2022 07:59:43 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.04 on epoch=502
06/13/2022 07:59:46 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=504
06/13/2022 07:59:48 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.02 on epoch=507
06/13/2022 07:59:51 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=509
06/13/2022 07:59:53 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.06 on epoch=512
06/13/2022 07:59:54 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.6305704099821747 on epoch=512
06/13/2022 07:59:57 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.07 on epoch=514
06/13/2022 07:59:59 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.05 on epoch=517
06/13/2022 08:00:02 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.12 on epoch=519
06/13/2022 08:00:04 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.08 on epoch=522
06/13/2022 08:00:07 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=524
06/13/2022 08:00:08 - INFO - __main__ - Global step 2100 Train loss 0.07 Classification-F1 0.6706263922118637 on epoch=524
06/13/2022 08:00:10 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.04 on epoch=527
06/13/2022 08:00:13 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.06 on epoch=529
06/13/2022 08:00:15 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=532
06/13/2022 08:00:17 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.08 on epoch=534
06/13/2022 08:00:20 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.09 on epoch=537
06/13/2022 08:00:21 - INFO - __main__ - Global step 2150 Train loss 0.05 Classification-F1 0.6502791563275434 on epoch=537
06/13/2022 08:00:23 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.05 on epoch=539
06/13/2022 08:00:26 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=542
06/13/2022 08:00:28 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.04 on epoch=544
06/13/2022 08:00:31 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.04 on epoch=547
06/13/2022 08:00:33 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=549
06/13/2022 08:00:34 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.6967514499071301 on epoch=549
06/13/2022 08:00:34 - INFO - __main__ - Saving model with best Classification-F1: 0.6931246218995766 -> 0.6967514499071301 on epoch=549, global_step=2200
06/13/2022 08:00:37 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.08 on epoch=552
06/13/2022 08:00:39 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=554
06/13/2022 08:00:42 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=557
06/13/2022 08:00:44 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=559
06/13/2022 08:00:47 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.04 on epoch=562
06/13/2022 08:00:47 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.6575015747341724 on epoch=562
06/13/2022 08:00:50 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.03 on epoch=564
06/13/2022 08:00:52 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=567
06/13/2022 08:00:55 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.06 on epoch=569
06/13/2022 08:00:57 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=572
06/13/2022 08:01:00 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.04 on epoch=574
06/13/2022 08:01:01 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.6960311784897025 on epoch=574
06/13/2022 08:01:03 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.04 on epoch=577
06/13/2022 08:01:06 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.06 on epoch=579
06/13/2022 08:01:08 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=582
06/13/2022 08:01:11 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=584
06/13/2022 08:01:13 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.07 on epoch=587
06/13/2022 08:01:14 - INFO - __main__ - Global step 2350 Train loss 0.04 Classification-F1 0.7102270120096945 on epoch=587
06/13/2022 08:01:14 - INFO - __main__ - Saving model with best Classification-F1: 0.6967514499071301 -> 0.7102270120096945 on epoch=587, global_step=2350
06/13/2022 08:01:17 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=589
06/13/2022 08:01:19 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.04 on epoch=592
06/13/2022 08:01:22 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/13/2022 08:01:24 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=597
06/13/2022 08:01:27 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=599
06/13/2022 08:01:28 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.6967514499071301 on epoch=599
06/13/2022 08:01:30 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.03 on epoch=602
06/13/2022 08:01:33 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=604
06/13/2022 08:01:35 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.04 on epoch=607
06/13/2022 08:01:38 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.07 on epoch=609
06/13/2022 08:01:40 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=612
06/13/2022 08:01:41 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.7090690559440559 on epoch=612
06/13/2022 08:01:44 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.02 on epoch=614
06/13/2022 08:01:46 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.04 on epoch=617
06/13/2022 08:01:49 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.04 on epoch=619
06/13/2022 08:01:51 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=622
06/13/2022 08:01:54 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=624
06/13/2022 08:01:54 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.6832134553908747 on epoch=624
06/13/2022 08:01:57 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=627
06/13/2022 08:02:00 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.04 on epoch=629
06/13/2022 08:02:02 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.07 on epoch=632
06/13/2022 08:02:04 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=634
06/13/2022 08:02:07 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.06 on epoch=637
06/13/2022 08:02:08 - INFO - __main__ - Global step 2550 Train loss 0.04 Classification-F1 0.7102270120096945 on epoch=637
06/13/2022 08:02:10 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/13/2022 08:02:13 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=642
06/13/2022 08:02:15 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/13/2022 08:02:18 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=647
06/13/2022 08:02:20 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=649
06/13/2022 08:02:21 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.7425163094128612 on epoch=649
06/13/2022 08:02:21 - INFO - __main__ - Saving model with best Classification-F1: 0.7102270120096945 -> 0.7425163094128612 on epoch=649, global_step=2600
06/13/2022 08:02:24 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.03 on epoch=652
06/13/2022 08:02:26 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=654
06/13/2022 08:02:29 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.03 on epoch=657
06/13/2022 08:02:31 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.06 on epoch=659
06/13/2022 08:02:34 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=662
06/13/2022 08:02:35 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.6843395815170009 on epoch=662
06/13/2022 08:02:37 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=664
06/13/2022 08:02:40 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=667
06/13/2022 08:02:42 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.05 on epoch=669
06/13/2022 08:02:45 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.03 on epoch=672
06/13/2022 08:02:47 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=674
06/13/2022 08:02:48 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.7102270120096945 on epoch=674
06/13/2022 08:02:51 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/13/2022 08:02:53 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=679
06/13/2022 08:02:56 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.03 on epoch=682
06/13/2022 08:02:58 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=684
06/13/2022 08:03:01 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=687
06/13/2022 08:03:02 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.6967514499071301 on epoch=687
06/13/2022 08:03:04 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.03 on epoch=689
06/13/2022 08:03:07 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=692
06/13/2022 08:03:09 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/13/2022 08:03:12 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.03 on epoch=697
06/13/2022 08:03:14 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.25 on epoch=699
06/13/2022 08:03:15 - INFO - __main__ - Global step 2800 Train loss 0.06 Classification-F1 0.6852763242565875 on epoch=699
06/13/2022 08:03:18 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=702
06/13/2022 08:03:20 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=704
06/13/2022 08:03:23 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=707
06/13/2022 08:03:25 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.03 on epoch=709
06/13/2022 08:03:28 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=712
06/13/2022 08:03:29 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.6852763242565875 on epoch=712
06/13/2022 08:03:31 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.05 on epoch=714
06/13/2022 08:03:34 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.03 on epoch=717
06/13/2022 08:03:36 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=719
06/13/2022 08:03:39 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.03 on epoch=722
06/13/2022 08:03:41 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.06 on epoch=724
06/13/2022 08:03:42 - INFO - __main__ - Global step 2900 Train loss 0.04 Classification-F1 0.6967514499071301 on epoch=724
06/13/2022 08:03:45 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=727
06/13/2022 08:03:47 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.03 on epoch=729
06/13/2022 08:03:50 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/13/2022 08:03:52 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=734
06/13/2022 08:03:55 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.03 on epoch=737
06/13/2022 08:03:55 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.6967514499071301 on epoch=737
06/13/2022 08:03:58 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=739
06/13/2022 08:04:00 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/13/2022 08:04:03 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/13/2022 08:04:05 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/13/2022 08:04:08 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=749
06/13/2022 08:04:09 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.6852763242565875 on epoch=749
06/13/2022 08:04:09 - INFO - __main__ - save last model!
06/13/2022 08:04:09 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/13/2022 08:04:09 - INFO - __main__ - Start tokenizing ... 5509 instances
06/13/2022 08:04:09 - INFO - __main__ - Printing 3 examples
06/13/2022 08:04:09 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/13/2022 08:04:09 - INFO - __main__ - ['others']
06/13/2022 08:04:09 - INFO - __main__ -  [emo] what you like very little things ok
06/13/2022 08:04:09 - INFO - __main__ - ['others']
06/13/2022 08:04:09 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/13/2022 08:04:09 - INFO - __main__ - ['others']
06/13/2022 08:04:09 - INFO - __main__ - Tokenizing Input ...
06/13/2022 08:04:09 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 08:04:09 - INFO - __main__ - Printing 3 examples
06/13/2022 08:04:09 - INFO - __main__ -  [emo] how cause yes am listening
06/13/2022 08:04:09 - INFO - __main__ - ['others']
06/13/2022 08:04:09 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/13/2022 08:04:09 - INFO - __main__ - ['others']
06/13/2022 08:04:09 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/13/2022 08:04:09 - INFO - __main__ - ['others']
06/13/2022 08:04:09 - INFO - __main__ - Tokenizing Input ...
06/13/2022 08:04:09 - INFO - __main__ - Tokenizing Output ...
06/13/2022 08:04:09 - INFO - __main__ - Loaded 64 examples from train data
06/13/2022 08:04:09 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 08:04:09 - INFO - __main__ - Printing 3 examples
06/13/2022 08:04:09 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
06/13/2022 08:04:09 - INFO - __main__ - ['others']
06/13/2022 08:04:09 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
06/13/2022 08:04:09 - INFO - __main__ - ['others']
06/13/2022 08:04:09 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
06/13/2022 08:04:09 - INFO - __main__ - ['others']
06/13/2022 08:04:09 - INFO - __main__ - Tokenizing Input ...
06/13/2022 08:04:09 - INFO - __main__ - Tokenizing Output ...
06/13/2022 08:04:09 - INFO - __main__ - Loaded 64 examples from dev data
06/13/2022 08:04:11 - INFO - __main__ - Tokenizing Output ...
06/13/2022 08:04:16 - INFO - __main__ - Loaded 5509 examples from test data
06/13/2022 08:04:24 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 08:04:25 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 08:04:25 - INFO - __main__ - Starting training!
06/13/2022 08:05:39 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-up32shot/singletask-emo/emo_16_100_0.3_8_predictions.txt
06/13/2022 08:05:39 - INFO - __main__ - Classification-F1 on test data: 0.2783
06/13/2022 08:05:39 - INFO - __main__ - prefix=emo_16_100, lr=0.3, bsz=8, dev_performance=0.7425163094128612, test_performance=0.2782898157456647
06/13/2022 08:05:39 - INFO - __main__ - Running ... prefix=emo_16_100, lr=0.2, bsz=8 ...
06/13/2022 08:05:40 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 08:05:40 - INFO - __main__ - Printing 3 examples
06/13/2022 08:05:40 - INFO - __main__ -  [emo] how cause yes am listening
06/13/2022 08:05:40 - INFO - __main__ - ['others']
06/13/2022 08:05:40 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/13/2022 08:05:40 - INFO - __main__ - ['others']
06/13/2022 08:05:40 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/13/2022 08:05:40 - INFO - __main__ - ['others']
06/13/2022 08:05:40 - INFO - __main__ - Tokenizing Input ...
06/13/2022 08:05:40 - INFO - __main__ - Tokenizing Output ...
06/13/2022 08:05:40 - INFO - __main__ - Loaded 64 examples from train data
06/13/2022 08:05:40 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 08:05:40 - INFO - __main__ - Printing 3 examples
06/13/2022 08:05:40 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
06/13/2022 08:05:40 - INFO - __main__ - ['others']
06/13/2022 08:05:40 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
06/13/2022 08:05:40 - INFO - __main__ - ['others']
06/13/2022 08:05:40 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
06/13/2022 08:05:40 - INFO - __main__ - ['others']
06/13/2022 08:05:40 - INFO - __main__ - Tokenizing Input ...
06/13/2022 08:05:40 - INFO - __main__ - Tokenizing Output ...
06/13/2022 08:05:40 - INFO - __main__ - Loaded 64 examples from dev data
06/13/2022 08:05:59 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 08:06:00 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 08:06:00 - INFO - __main__ - Starting training!
06/13/2022 08:06:03 - INFO - __main__ - Step 10 Global step 10 Train loss 4.21 on epoch=2
06/13/2022 08:06:05 - INFO - __main__ - Step 20 Global step 20 Train loss 3.23 on epoch=4
06/13/2022 08:06:08 - INFO - __main__ - Step 30 Global step 30 Train loss 2.59 on epoch=7
06/13/2022 08:06:10 - INFO - __main__ - Step 40 Global step 40 Train loss 2.37 on epoch=9
06/13/2022 08:06:13 - INFO - __main__ - Step 50 Global step 50 Train loss 2.13 on epoch=12
06/13/2022 08:06:14 - INFO - __main__ - Global step 50 Train loss 2.91 Classification-F1 0.03728757630754 on epoch=12
06/13/2022 08:06:14 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.03728757630754 on epoch=12, global_step=50
06/13/2022 08:06:16 - INFO - __main__ - Step 60 Global step 60 Train loss 1.87 on epoch=14
06/13/2022 08:06:19 - INFO - __main__ - Step 70 Global step 70 Train loss 1.64 on epoch=17
06/13/2022 08:06:21 - INFO - __main__ - Step 80 Global step 80 Train loss 1.41 on epoch=19
06/13/2022 08:06:24 - INFO - __main__ - Step 90 Global step 90 Train loss 1.40 on epoch=22
06/13/2022 08:06:26 - INFO - __main__ - Step 100 Global step 100 Train loss 1.23 on epoch=24
06/13/2022 08:06:27 - INFO - __main__ - Global step 100 Train loss 1.51 Classification-F1 0.225 on epoch=24
06/13/2022 08:06:27 - INFO - __main__ - Saving model with best Classification-F1: 0.03728757630754 -> 0.225 on epoch=24, global_step=100
06/13/2022 08:06:30 - INFO - __main__ - Step 110 Global step 110 Train loss 1.08 on epoch=27
06/13/2022 08:06:32 - INFO - __main__ - Step 120 Global step 120 Train loss 1.03 on epoch=29
06/13/2022 08:06:35 - INFO - __main__ - Step 130 Global step 130 Train loss 0.92 on epoch=32
06/13/2022 08:06:37 - INFO - __main__ - Step 140 Global step 140 Train loss 0.81 on epoch=34
06/13/2022 08:06:40 - INFO - __main__ - Step 150 Global step 150 Train loss 1.00 on epoch=37
06/13/2022 08:06:41 - INFO - __main__ - Global step 150 Train loss 0.97 Classification-F1 0.39817429753244904 on epoch=37
06/13/2022 08:06:41 - INFO - __main__ - Saving model with best Classification-F1: 0.225 -> 0.39817429753244904 on epoch=37, global_step=150
06/13/2022 08:06:43 - INFO - __main__ - Step 160 Global step 160 Train loss 0.73 on epoch=39
06/13/2022 08:06:46 - INFO - __main__ - Step 170 Global step 170 Train loss 0.81 on epoch=42
06/13/2022 08:06:48 - INFO - __main__ - Step 180 Global step 180 Train loss 0.74 on epoch=44
06/13/2022 08:06:51 - INFO - __main__ - Step 190 Global step 190 Train loss 0.79 on epoch=47
06/13/2022 08:06:53 - INFO - __main__ - Step 200 Global step 200 Train loss 0.78 on epoch=49
06/13/2022 08:06:54 - INFO - __main__ - Global step 200 Train loss 0.77 Classification-F1 0.5211587436332767 on epoch=49
06/13/2022 08:06:54 - INFO - __main__ - Saving model with best Classification-F1: 0.39817429753244904 -> 0.5211587436332767 on epoch=49, global_step=200
06/13/2022 08:06:57 - INFO - __main__ - Step 210 Global step 210 Train loss 0.83 on epoch=52
06/13/2022 08:06:59 - INFO - __main__ - Step 220 Global step 220 Train loss 0.66 on epoch=54
06/13/2022 08:07:01 - INFO - __main__ - Step 230 Global step 230 Train loss 0.68 on epoch=57
06/13/2022 08:07:04 - INFO - __main__ - Step 240 Global step 240 Train loss 0.62 on epoch=59
06/13/2022 08:07:06 - INFO - __main__ - Step 250 Global step 250 Train loss 0.64 on epoch=62
06/13/2022 08:07:07 - INFO - __main__ - Global step 250 Train loss 0.69 Classification-F1 0.5602756892230577 on epoch=62
06/13/2022 08:07:07 - INFO - __main__ - Saving model with best Classification-F1: 0.5211587436332767 -> 0.5602756892230577 on epoch=62, global_step=250
06/13/2022 08:07:10 - INFO - __main__ - Step 260 Global step 260 Train loss 0.76 on epoch=64
06/13/2022 08:07:12 - INFO - __main__ - Step 270 Global step 270 Train loss 0.68 on epoch=67
06/13/2022 08:07:15 - INFO - __main__ - Step 280 Global step 280 Train loss 0.68 on epoch=69
06/13/2022 08:07:17 - INFO - __main__ - Step 290 Global step 290 Train loss 0.82 on epoch=72
06/13/2022 08:07:20 - INFO - __main__ - Step 300 Global step 300 Train loss 0.56 on epoch=74
06/13/2022 08:07:21 - INFO - __main__ - Global step 300 Train loss 0.70 Classification-F1 0.5602921468775127 on epoch=74
06/13/2022 08:07:21 - INFO - __main__ - Saving model with best Classification-F1: 0.5602756892230577 -> 0.5602921468775127 on epoch=74, global_step=300
06/13/2022 08:07:23 - INFO - __main__ - Step 310 Global step 310 Train loss 0.60 on epoch=77
06/13/2022 08:07:26 - INFO - __main__ - Step 320 Global step 320 Train loss 0.67 on epoch=79
06/13/2022 08:07:28 - INFO - __main__ - Step 330 Global step 330 Train loss 0.64 on epoch=82
06/13/2022 08:07:31 - INFO - __main__ - Step 340 Global step 340 Train loss 0.58 on epoch=84
06/13/2022 08:07:33 - INFO - __main__ - Step 350 Global step 350 Train loss 0.63 on epoch=87
06/13/2022 08:07:34 - INFO - __main__ - Global step 350 Train loss 0.62 Classification-F1 0.636927349722268 on epoch=87
06/13/2022 08:07:34 - INFO - __main__ - Saving model with best Classification-F1: 0.5602921468775127 -> 0.636927349722268 on epoch=87, global_step=350
06/13/2022 08:07:36 - INFO - __main__ - Step 360 Global step 360 Train loss 0.60 on epoch=89
06/13/2022 08:07:39 - INFO - __main__ - Step 370 Global step 370 Train loss 0.64 on epoch=92
06/13/2022 08:07:41 - INFO - __main__ - Step 380 Global step 380 Train loss 0.57 on epoch=94
06/13/2022 08:07:44 - INFO - __main__ - Step 390 Global step 390 Train loss 0.64 on epoch=97
06/13/2022 08:07:46 - INFO - __main__ - Step 400 Global step 400 Train loss 0.53 on epoch=99
06/13/2022 08:07:47 - INFO - __main__ - Global step 400 Train loss 0.59 Classification-F1 0.6055174076163581 on epoch=99
06/13/2022 08:07:50 - INFO - __main__ - Step 410 Global step 410 Train loss 0.60 on epoch=102
06/13/2022 08:07:52 - INFO - __main__ - Step 420 Global step 420 Train loss 0.56 on epoch=104
06/13/2022 08:07:55 - INFO - __main__ - Step 430 Global step 430 Train loss 0.63 on epoch=107
06/13/2022 08:07:57 - INFO - __main__ - Step 440 Global step 440 Train loss 0.59 on epoch=109
06/13/2022 08:08:00 - INFO - __main__ - Step 450 Global step 450 Train loss 0.57 on epoch=112
06/13/2022 08:08:00 - INFO - __main__ - Global step 450 Train loss 0.59 Classification-F1 0.6482866595769821 on epoch=112
06/13/2022 08:08:01 - INFO - __main__ - Saving model with best Classification-F1: 0.636927349722268 -> 0.6482866595769821 on epoch=112, global_step=450
06/13/2022 08:08:03 - INFO - __main__ - Step 460 Global step 460 Train loss 0.52 on epoch=114
06/13/2022 08:08:05 - INFO - __main__ - Step 470 Global step 470 Train loss 0.56 on epoch=117
06/13/2022 08:08:08 - INFO - __main__ - Step 480 Global step 480 Train loss 0.49 on epoch=119
06/13/2022 08:08:10 - INFO - __main__ - Step 490 Global step 490 Train loss 0.53 on epoch=122
06/13/2022 08:08:13 - INFO - __main__ - Step 500 Global step 500 Train loss 0.42 on epoch=124
06/13/2022 08:08:14 - INFO - __main__ - Global step 500 Train loss 0.50 Classification-F1 0.6619080831984058 on epoch=124
06/13/2022 08:08:14 - INFO - __main__ - Saving model with best Classification-F1: 0.6482866595769821 -> 0.6619080831984058 on epoch=124, global_step=500
06/13/2022 08:08:16 - INFO - __main__ - Step 510 Global step 510 Train loss 0.51 on epoch=127
06/13/2022 08:08:19 - INFO - __main__ - Step 520 Global step 520 Train loss 0.54 on epoch=129
06/13/2022 08:08:21 - INFO - __main__ - Step 530 Global step 530 Train loss 0.54 on epoch=132
06/13/2022 08:08:24 - INFO - __main__ - Step 540 Global step 540 Train loss 0.47 on epoch=134
06/13/2022 08:08:26 - INFO - __main__ - Step 550 Global step 550 Train loss 0.48 on epoch=137
06/13/2022 08:08:27 - INFO - __main__ - Global step 550 Train loss 0.51 Classification-F1 0.6499061273254823 on epoch=137
06/13/2022 08:08:30 - INFO - __main__ - Step 560 Global step 560 Train loss 0.47 on epoch=139
06/13/2022 08:08:32 - INFO - __main__ - Step 570 Global step 570 Train loss 0.44 on epoch=142
06/13/2022 08:08:35 - INFO - __main__ - Step 580 Global step 580 Train loss 0.39 on epoch=144
06/13/2022 08:08:37 - INFO - __main__ - Step 590 Global step 590 Train loss 0.41 on epoch=147
06/13/2022 08:08:40 - INFO - __main__ - Step 600 Global step 600 Train loss 0.44 on epoch=149
06/13/2022 08:08:40 - INFO - __main__ - Global step 600 Train loss 0.43 Classification-F1 0.6777526395173454 on epoch=149
06/13/2022 08:08:40 - INFO - __main__ - Saving model with best Classification-F1: 0.6619080831984058 -> 0.6777526395173454 on epoch=149, global_step=600
06/13/2022 08:08:43 - INFO - __main__ - Step 610 Global step 610 Train loss 0.46 on epoch=152
06/13/2022 08:08:45 - INFO - __main__ - Step 620 Global step 620 Train loss 0.47 on epoch=154
06/13/2022 08:08:48 - INFO - __main__ - Step 630 Global step 630 Train loss 0.50 on epoch=157
06/13/2022 08:08:50 - INFO - __main__ - Step 640 Global step 640 Train loss 0.43 on epoch=159
06/13/2022 08:08:53 - INFO - __main__ - Step 650 Global step 650 Train loss 0.44 on epoch=162
06/13/2022 08:08:54 - INFO - __main__ - Global step 650 Train loss 0.46 Classification-F1 0.6617804172951232 on epoch=162
06/13/2022 08:08:56 - INFO - __main__ - Step 660 Global step 660 Train loss 0.48 on epoch=164
06/13/2022 08:08:59 - INFO - __main__ - Step 670 Global step 670 Train loss 0.47 on epoch=167
06/13/2022 08:09:01 - INFO - __main__ - Step 680 Global step 680 Train loss 0.45 on epoch=169
06/13/2022 08:09:04 - INFO - __main__ - Step 690 Global step 690 Train loss 0.41 on epoch=172
06/13/2022 08:09:06 - INFO - __main__ - Step 700 Global step 700 Train loss 0.38 on epoch=174
06/13/2022 08:09:07 - INFO - __main__ - Global step 700 Train loss 0.44 Classification-F1 0.6496831055654585 on epoch=174
06/13/2022 08:09:10 - INFO - __main__ - Step 710 Global step 710 Train loss 0.45 on epoch=177
06/13/2022 08:09:12 - INFO - __main__ - Step 720 Global step 720 Train loss 0.49 on epoch=179
06/13/2022 08:09:14 - INFO - __main__ - Step 730 Global step 730 Train loss 0.39 on epoch=182
06/13/2022 08:09:17 - INFO - __main__ - Step 740 Global step 740 Train loss 0.37 on epoch=184
06/13/2022 08:09:19 - INFO - __main__ - Step 750 Global step 750 Train loss 0.33 on epoch=187
06/13/2022 08:09:20 - INFO - __main__ - Global step 750 Train loss 0.41 Classification-F1 0.6503185145025752 on epoch=187
06/13/2022 08:09:23 - INFO - __main__ - Step 760 Global step 760 Train loss 0.41 on epoch=189
06/13/2022 08:09:25 - INFO - __main__ - Step 770 Global step 770 Train loss 0.42 on epoch=192
06/13/2022 08:09:28 - INFO - __main__ - Step 780 Global step 780 Train loss 0.35 on epoch=194
06/13/2022 08:09:30 - INFO - __main__ - Step 790 Global step 790 Train loss 0.32 on epoch=197
06/13/2022 08:09:33 - INFO - __main__ - Step 800 Global step 800 Train loss 0.33 on epoch=199
06/13/2022 08:09:34 - INFO - __main__ - Global step 800 Train loss 0.36 Classification-F1 0.6651092268739328 on epoch=199
06/13/2022 08:09:36 - INFO - __main__ - Step 810 Global step 810 Train loss 0.42 on epoch=202
06/13/2022 08:09:38 - INFO - __main__ - Step 820 Global step 820 Train loss 0.32 on epoch=204
06/13/2022 08:09:41 - INFO - __main__ - Step 830 Global step 830 Train loss 0.33 on epoch=207
06/13/2022 08:09:43 - INFO - __main__ - Step 840 Global step 840 Train loss 0.40 on epoch=209
06/13/2022 08:09:46 - INFO - __main__ - Step 850 Global step 850 Train loss 0.34 on epoch=212
06/13/2022 08:09:47 - INFO - __main__ - Global step 850 Train loss 0.36 Classification-F1 0.6794842412489472 on epoch=212
06/13/2022 08:09:47 - INFO - __main__ - Saving model with best Classification-F1: 0.6777526395173454 -> 0.6794842412489472 on epoch=212, global_step=850
06/13/2022 08:09:49 - INFO - __main__ - Step 860 Global step 860 Train loss 0.38 on epoch=214
06/13/2022 08:09:52 - INFO - __main__ - Step 870 Global step 870 Train loss 0.34 on epoch=217
06/13/2022 08:09:54 - INFO - __main__ - Step 880 Global step 880 Train loss 0.31 on epoch=219
06/13/2022 08:09:57 - INFO - __main__ - Step 890 Global step 890 Train loss 0.49 on epoch=222
06/13/2022 08:09:59 - INFO - __main__ - Step 900 Global step 900 Train loss 0.28 on epoch=224
06/13/2022 08:10:00 - INFO - __main__ - Global step 900 Train loss 0.36 Classification-F1 0.6545977011494253 on epoch=224
06/13/2022 08:10:03 - INFO - __main__ - Step 910 Global step 910 Train loss 0.36 on epoch=227
06/13/2022 08:10:05 - INFO - __main__ - Step 920 Global step 920 Train loss 0.25 on epoch=229
06/13/2022 08:10:08 - INFO - __main__ - Step 930 Global step 930 Train loss 0.23 on epoch=232
06/13/2022 08:10:10 - INFO - __main__ - Step 940 Global step 940 Train loss 0.36 on epoch=234
06/13/2022 08:10:13 - INFO - __main__ - Step 950 Global step 950 Train loss 0.21 on epoch=237
06/13/2022 08:10:14 - INFO - __main__ - Global step 950 Train loss 0.28 Classification-F1 0.6507352941176471 on epoch=237
06/13/2022 08:10:16 - INFO - __main__ - Step 960 Global step 960 Train loss 0.28 on epoch=239
06/13/2022 08:10:19 - INFO - __main__ - Step 970 Global step 970 Train loss 0.35 on epoch=242
06/13/2022 08:10:21 - INFO - __main__ - Step 980 Global step 980 Train loss 0.25 on epoch=244
06/13/2022 08:10:24 - INFO - __main__ - Step 990 Global step 990 Train loss 0.34 on epoch=247
06/13/2022 08:10:26 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.28 on epoch=249
06/13/2022 08:10:27 - INFO - __main__ - Global step 1000 Train loss 0.30 Classification-F1 0.6690476190476191 on epoch=249
06/13/2022 08:10:29 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.33 on epoch=252
06/13/2022 08:10:32 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.30 on epoch=254
06/13/2022 08:10:35 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.31 on epoch=257
06/13/2022 08:10:37 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.27 on epoch=259
06/13/2022 08:10:40 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.24 on epoch=262
06/13/2022 08:10:41 - INFO - __main__ - Global step 1050 Train loss 0.29 Classification-F1 0.6697147156971799 on epoch=262
06/13/2022 08:10:43 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.17 on epoch=264
06/13/2022 08:10:46 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.32 on epoch=267
06/13/2022 08:10:48 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.31 on epoch=269
06/13/2022 08:10:50 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.21 on epoch=272
06/13/2022 08:10:53 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.21 on epoch=274
06/13/2022 08:10:54 - INFO - __main__ - Global step 1100 Train loss 0.24 Classification-F1 0.6838603739604853 on epoch=274
06/13/2022 08:10:54 - INFO - __main__ - Saving model with best Classification-F1: 0.6794842412489472 -> 0.6838603739604853 on epoch=274, global_step=1100
06/13/2022 08:10:56 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.35 on epoch=277
06/13/2022 08:10:59 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.21 on epoch=279
06/13/2022 08:11:01 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.20 on epoch=282
06/13/2022 08:11:04 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.24 on epoch=284
06/13/2022 08:11:06 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.24 on epoch=287
06/13/2022 08:11:07 - INFO - __main__ - Global step 1150 Train loss 0.25 Classification-F1 0.6838603739604853 on epoch=287
06/13/2022 08:11:10 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.18 on epoch=289
06/13/2022 08:11:12 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.22 on epoch=292
06/13/2022 08:11:15 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.22 on epoch=294
06/13/2022 08:11:17 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.19 on epoch=297
06/13/2022 08:11:20 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.20 on epoch=299
06/13/2022 08:11:20 - INFO - __main__ - Global step 1200 Train loss 0.21 Classification-F1 0.6838603739604853 on epoch=299
06/13/2022 08:11:23 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.23 on epoch=302
06/13/2022 08:11:25 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.27 on epoch=304
06/13/2022 08:11:28 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.21 on epoch=307
06/13/2022 08:11:30 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.13 on epoch=309
06/13/2022 08:11:33 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.23 on epoch=312
06/13/2022 08:11:34 - INFO - __main__ - Global step 1250 Train loss 0.21 Classification-F1 0.6838603739604853 on epoch=312
06/13/2022 08:11:36 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.22 on epoch=314
06/13/2022 08:11:39 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.21 on epoch=317
06/13/2022 08:11:41 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.19 on epoch=319
06/13/2022 08:11:44 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.16 on epoch=322
06/13/2022 08:11:46 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.20 on epoch=324
06/13/2022 08:11:47 - INFO - __main__ - Global step 1300 Train loss 0.20 Classification-F1 0.6985904039034969 on epoch=324
06/13/2022 08:11:47 - INFO - __main__ - Saving model with best Classification-F1: 0.6838603739604853 -> 0.6985904039034969 on epoch=324, global_step=1300
06/13/2022 08:11:50 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.15 on epoch=327
06/13/2022 08:11:52 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.25 on epoch=329
06/13/2022 08:11:55 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.17 on epoch=332
06/13/2022 08:11:57 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.23 on epoch=334
06/13/2022 08:12:00 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.18 on epoch=337
06/13/2022 08:12:01 - INFO - __main__ - Global step 1350 Train loss 0.20 Classification-F1 0.6976190476190477 on epoch=337
06/13/2022 08:12:03 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.16 on epoch=339
06/13/2022 08:12:06 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.18 on epoch=342
06/13/2022 08:12:08 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.17 on epoch=344
06/13/2022 08:12:10 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.12 on epoch=347
06/13/2022 08:12:13 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.15 on epoch=349
06/13/2022 08:12:14 - INFO - __main__ - Global step 1400 Train loss 0.16 Classification-F1 0.7111250348092453 on epoch=349
06/13/2022 08:12:14 - INFO - __main__ - Saving model with best Classification-F1: 0.6985904039034969 -> 0.7111250348092453 on epoch=349, global_step=1400
06/13/2022 08:12:16 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.30 on epoch=352
06/13/2022 08:12:19 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.17 on epoch=354
06/13/2022 08:12:21 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.18 on epoch=357
06/13/2022 08:12:24 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.26 on epoch=359
06/13/2022 08:12:26 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.20 on epoch=362
06/13/2022 08:12:27 - INFO - __main__ - Global step 1450 Train loss 0.22 Classification-F1 0.7126710454296662 on epoch=362
06/13/2022 08:12:27 - INFO - __main__ - Saving model with best Classification-F1: 0.7111250348092453 -> 0.7126710454296662 on epoch=362, global_step=1450
06/13/2022 08:12:30 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.21 on epoch=364
06/13/2022 08:12:32 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.20 on epoch=367
06/13/2022 08:12:35 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.19 on epoch=369
06/13/2022 08:12:37 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.12 on epoch=372
06/13/2022 08:12:40 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.10 on epoch=374
06/13/2022 08:12:41 - INFO - __main__ - Global step 1500 Train loss 0.17 Classification-F1 0.6976190476190477 on epoch=374
06/13/2022 08:12:43 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.07 on epoch=377
06/13/2022 08:12:46 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.14 on epoch=379
06/13/2022 08:12:48 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.09 on epoch=382
06/13/2022 08:12:51 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.12 on epoch=384
06/13/2022 08:12:53 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.11 on epoch=387
06/13/2022 08:12:54 - INFO - __main__ - Global step 1550 Train loss 0.11 Classification-F1 0.7427350427350426 on epoch=387
06/13/2022 08:12:54 - INFO - __main__ - Saving model with best Classification-F1: 0.7126710454296662 -> 0.7427350427350426 on epoch=387, global_step=1550
06/13/2022 08:12:56 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.22 on epoch=389
06/13/2022 08:12:59 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.13 on epoch=392
06/13/2022 08:13:01 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.12 on epoch=394
06/13/2022 08:13:04 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.09 on epoch=397
06/13/2022 08:13:06 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.13 on epoch=399
06/13/2022 08:13:07 - INFO - __main__ - Global step 1600 Train loss 0.14 Classification-F1 0.7304485012395763 on epoch=399
06/13/2022 08:13:10 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.10 on epoch=402
06/13/2022 08:13:12 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.17 on epoch=404
06/13/2022 08:13:15 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.13 on epoch=407
06/13/2022 08:13:17 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.13 on epoch=409
06/13/2022 08:13:20 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.08 on epoch=412
06/13/2022 08:13:21 - INFO - __main__ - Global step 1650 Train loss 0.12 Classification-F1 0.7132962862564382 on epoch=412
06/13/2022 08:13:23 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.06 on epoch=414
06/13/2022 08:13:26 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.16 on epoch=417
06/13/2022 08:13:28 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.09 on epoch=419
06/13/2022 08:13:31 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.16 on epoch=422
06/13/2022 08:13:33 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.07 on epoch=424
06/13/2022 08:13:34 - INFO - __main__ - Global step 1700 Train loss 0.11 Classification-F1 0.740648473407094 on epoch=424
06/13/2022 08:13:37 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.14 on epoch=427
06/13/2022 08:13:39 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.15 on epoch=429
06/13/2022 08:13:42 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.18 on epoch=432
06/13/2022 08:13:44 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.08 on epoch=434
06/13/2022 08:13:46 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.05 on epoch=437
06/13/2022 08:13:47 - INFO - __main__ - Global step 1750 Train loss 0.12 Classification-F1 0.7308316430020283 on epoch=437
06/13/2022 08:13:50 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.15 on epoch=439
06/13/2022 08:13:52 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.11 on epoch=442
06/13/2022 08:13:55 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.11 on epoch=444
06/13/2022 08:13:57 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.08 on epoch=447
06/13/2022 08:14:00 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.09 on epoch=449
06/13/2022 08:14:01 - INFO - __main__ - Global step 1800 Train loss 0.11 Classification-F1 0.7364996951839058 on epoch=449
06/13/2022 08:14:03 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.11 on epoch=452
06/13/2022 08:14:05 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.12 on epoch=454
06/13/2022 08:14:08 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.10 on epoch=457
06/13/2022 08:14:10 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.07 on epoch=459
06/13/2022 08:14:13 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.12 on epoch=462
06/13/2022 08:14:14 - INFO - __main__ - Global step 1850 Train loss 0.10 Classification-F1 0.7373753217503218 on epoch=462
06/13/2022 08:14:16 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.09 on epoch=464
06/13/2022 08:14:18 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.06 on epoch=467
06/13/2022 08:14:21 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.06 on epoch=469
06/13/2022 08:14:23 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.06 on epoch=472
06/13/2022 08:14:26 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.10 on epoch=474
06/13/2022 08:14:27 - INFO - __main__ - Global step 1900 Train loss 0.07 Classification-F1 0.7528010088128056 on epoch=474
06/13/2022 08:14:27 - INFO - __main__ - Saving model with best Classification-F1: 0.7427350427350426 -> 0.7528010088128056 on epoch=474, global_step=1900
06/13/2022 08:14:29 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.06 on epoch=477
06/13/2022 08:14:31 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.07 on epoch=479
06/13/2022 08:14:34 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.10 on epoch=482
06/13/2022 08:14:36 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.12 on epoch=484
06/13/2022 08:14:39 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.07 on epoch=487
06/13/2022 08:14:40 - INFO - __main__ - Global step 1950 Train loss 0.09 Classification-F1 0.7417238667238667 on epoch=487
06/13/2022 08:14:42 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.05 on epoch=489
06/13/2022 08:14:45 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.05 on epoch=492
06/13/2022 08:14:47 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.08 on epoch=494
06/13/2022 08:14:49 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.07 on epoch=497
06/13/2022 08:14:52 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.10 on epoch=499
06/13/2022 08:14:53 - INFO - __main__ - Global step 2000 Train loss 0.07 Classification-F1 0.7723019571295434 on epoch=499
06/13/2022 08:14:53 - INFO - __main__ - Saving model with best Classification-F1: 0.7528010088128056 -> 0.7723019571295434 on epoch=499, global_step=2000
06/13/2022 08:14:55 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.06 on epoch=502
06/13/2022 08:14:58 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.06 on epoch=504
06/13/2022 08:15:00 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.03 on epoch=507
06/13/2022 08:15:03 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.08 on epoch=509
06/13/2022 08:15:05 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.06 on epoch=512
06/13/2022 08:15:06 - INFO - __main__ - Global step 2050 Train loss 0.06 Classification-F1 0.7723019571295434 on epoch=512
06/13/2022 08:15:08 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.06 on epoch=514
06/13/2022 08:15:11 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.08 on epoch=517
06/13/2022 08:15:13 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.06 on epoch=519
06/13/2022 08:15:16 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=522
06/13/2022 08:15:18 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.09 on epoch=524
06/13/2022 08:15:19 - INFO - __main__ - Global step 2100 Train loss 0.06 Classification-F1 0.7417238667238667 on epoch=524
06/13/2022 08:15:22 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.07 on epoch=527
06/13/2022 08:15:24 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.06 on epoch=529
06/13/2022 08:15:27 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.07 on epoch=532
06/13/2022 08:15:29 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.15 on epoch=534
06/13/2022 08:15:31 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.06 on epoch=537
06/13/2022 08:15:32 - INFO - __main__ - Global step 2150 Train loss 0.08 Classification-F1 0.7565488565488565 on epoch=537
06/13/2022 08:15:35 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.12 on epoch=539
06/13/2022 08:15:37 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.04 on epoch=542
06/13/2022 08:15:40 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.04 on epoch=544
06/13/2022 08:15:42 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.12 on epoch=547
06/13/2022 08:15:45 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=549
06/13/2022 08:15:46 - INFO - __main__ - Global step 2200 Train loss 0.07 Classification-F1 0.7556801306801307 on epoch=549
06/13/2022 08:15:48 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.09 on epoch=552
06/13/2022 08:15:51 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.04 on epoch=554
06/13/2022 08:15:53 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.05 on epoch=557
06/13/2022 08:15:55 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.09 on epoch=559
06/13/2022 08:15:58 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.06 on epoch=562
06/13/2022 08:15:59 - INFO - __main__ - Global step 2250 Train loss 0.07 Classification-F1 0.7757757757757758 on epoch=562
06/13/2022 08:15:59 - INFO - __main__ - Saving model with best Classification-F1: 0.7723019571295434 -> 0.7757757757757758 on epoch=562, global_step=2250
06/13/2022 08:16:01 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.07 on epoch=564
06/13/2022 08:16:04 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.06 on epoch=567
06/13/2022 08:16:06 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.10 on epoch=569
06/13/2022 08:16:09 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.04 on epoch=572
06/13/2022 08:16:11 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.07 on epoch=574
06/13/2022 08:16:12 - INFO - __main__ - Global step 2300 Train loss 0.07 Classification-F1 0.7556801306801307 on epoch=574
06/13/2022 08:16:15 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=577
06/13/2022 08:16:17 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.06 on epoch=579
06/13/2022 08:16:20 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.06 on epoch=582
06/13/2022 08:16:22 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.21 on epoch=584
06/13/2022 08:16:25 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=587
06/13/2022 08:16:26 - INFO - __main__ - Global step 2350 Train loss 0.08 Classification-F1 0.7556801306801307 on epoch=587
06/13/2022 08:16:28 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.08 on epoch=589
06/13/2022 08:16:31 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.07 on epoch=592
06/13/2022 08:16:33 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.04 on epoch=594
06/13/2022 08:16:35 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.06 on epoch=597
06/13/2022 08:16:38 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.12 on epoch=599
06/13/2022 08:16:39 - INFO - __main__ - Global step 2400 Train loss 0.07 Classification-F1 0.7364996951839058 on epoch=599
06/13/2022 08:16:41 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.09 on epoch=602
06/13/2022 08:16:44 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.15 on epoch=604
06/13/2022 08:16:46 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=607
06/13/2022 08:16:48 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.10 on epoch=609
06/13/2022 08:16:51 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=612
06/13/2022 08:16:52 - INFO - __main__ - Global step 2450 Train loss 0.08 Classification-F1 0.7377252252252252 on epoch=612
06/13/2022 08:16:54 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=614
06/13/2022 08:16:57 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.07 on epoch=617
06/13/2022 08:16:59 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.11 on epoch=619
06/13/2022 08:17:02 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.03 on epoch=622
06/13/2022 08:17:04 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.07 on epoch=624
06/13/2022 08:17:05 - INFO - __main__ - Global step 2500 Train loss 0.06 Classification-F1 0.7364996951839058 on epoch=624
06/13/2022 08:17:07 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=627
06/13/2022 08:17:10 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=629
06/13/2022 08:17:12 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=632
06/13/2022 08:17:15 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.04 on epoch=634
06/13/2022 08:17:17 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.09 on epoch=637
06/13/2022 08:17:18 - INFO - __main__ - Global step 2550 Train loss 0.04 Classification-F1 0.7226399786883658 on epoch=637
06/13/2022 08:17:21 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=639
06/13/2022 08:17:23 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=642
06/13/2022 08:17:26 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.03 on epoch=644
06/13/2022 08:17:28 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.10 on epoch=647
06/13/2022 08:17:30 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.05 on epoch=649
06/13/2022 08:17:31 - INFO - __main__ - Global step 2600 Train loss 0.04 Classification-F1 0.7556801306801307 on epoch=649
06/13/2022 08:17:34 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.05 on epoch=652
06/13/2022 08:17:36 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.06 on epoch=654
06/13/2022 08:17:39 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.13 on epoch=657
06/13/2022 08:17:41 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.11 on epoch=659
06/13/2022 08:17:44 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=662
06/13/2022 08:17:45 - INFO - __main__ - Global step 2650 Train loss 0.07 Classification-F1 0.7556801306801307 on epoch=662
06/13/2022 08:17:47 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.08 on epoch=664
06/13/2022 08:17:49 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.04 on epoch=667
06/13/2022 08:17:52 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=669
06/13/2022 08:17:54 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=672
06/13/2022 08:17:57 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.05 on epoch=674
06/13/2022 08:17:58 - INFO - __main__ - Global step 2700 Train loss 0.04 Classification-F1 0.7417238667238667 on epoch=674
06/13/2022 08:18:00 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=677
06/13/2022 08:18:03 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.03 on epoch=679
06/13/2022 08:18:05 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.04 on epoch=682
06/13/2022 08:18:08 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.05 on epoch=684
06/13/2022 08:18:10 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=687
06/13/2022 08:18:11 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.7556801306801307 on epoch=687
06/13/2022 08:18:13 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.04 on epoch=689
06/13/2022 08:18:16 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.06 on epoch=692
06/13/2022 08:18:18 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=694
06/13/2022 08:18:21 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.04 on epoch=697
06/13/2022 08:18:23 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=699
06/13/2022 08:18:24 - INFO - __main__ - Global step 2800 Train loss 0.04 Classification-F1 0.7420634920634921 on epoch=699
06/13/2022 08:18:27 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.06 on epoch=702
06/13/2022 08:18:29 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.07 on epoch=704
06/13/2022 08:18:32 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.05 on epoch=707
06/13/2022 08:18:34 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=709
06/13/2022 08:18:37 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.07 on epoch=712
06/13/2022 08:18:38 - INFO - __main__ - Global step 2850 Train loss 0.05 Classification-F1 0.7578898527174389 on epoch=712
06/13/2022 08:18:40 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.04 on epoch=714
06/13/2022 08:18:43 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=717
06/13/2022 08:18:45 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.05 on epoch=719
06/13/2022 08:18:47 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.05 on epoch=722
06/13/2022 08:18:50 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.05 on epoch=724
06/13/2022 08:18:51 - INFO - __main__ - Global step 2900 Train loss 0.04 Classification-F1 0.7417238667238667 on epoch=724
06/13/2022 08:18:53 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=727
06/13/2022 08:18:56 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.04 on epoch=729
06/13/2022 08:18:58 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=732
06/13/2022 08:19:01 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=734
06/13/2022 08:19:03 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=737
06/13/2022 08:19:04 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.7420875907718012 on epoch=737
06/13/2022 08:19:06 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.06 on epoch=739
06/13/2022 08:19:09 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=742
06/13/2022 08:19:11 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=744
06/13/2022 08:19:14 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.06 on epoch=747
06/13/2022 08:19:16 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.03 on epoch=749
06/13/2022 08:19:17 - INFO - __main__ - Global step 3000 Train loss 0.04 Classification-F1 0.7578898527174389 on epoch=749
06/13/2022 08:19:17 - INFO - __main__ - save last model!
06/13/2022 08:19:17 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/13/2022 08:19:17 - INFO - __main__ - Start tokenizing ... 5509 instances
06/13/2022 08:19:17 - INFO - __main__ - Printing 3 examples
06/13/2022 08:19:17 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/13/2022 08:19:17 - INFO - __main__ - ['others']
06/13/2022 08:19:17 - INFO - __main__ -  [emo] what you like very little things ok
06/13/2022 08:19:17 - INFO - __main__ - ['others']
06/13/2022 08:19:17 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/13/2022 08:19:17 - INFO - __main__ - ['others']
06/13/2022 08:19:17 - INFO - __main__ - Tokenizing Input ...
06/13/2022 08:19:17 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 08:19:17 - INFO - __main__ - Printing 3 examples
06/13/2022 08:19:17 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/13/2022 08:19:17 - INFO - __main__ - ['others']
06/13/2022 08:19:17 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/13/2022 08:19:17 - INFO - __main__ - ['others']
06/13/2022 08:19:17 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/13/2022 08:19:17 - INFO - __main__ - ['others']
06/13/2022 08:19:17 - INFO - __main__ - Tokenizing Input ...
06/13/2022 08:19:17 - INFO - __main__ - Tokenizing Output ...
06/13/2022 08:19:18 - INFO - __main__ - Loaded 64 examples from train data
06/13/2022 08:19:18 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 08:19:18 - INFO - __main__ - Printing 3 examples
06/13/2022 08:19:18 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
06/13/2022 08:19:18 - INFO - __main__ - ['others']
06/13/2022 08:19:18 - INFO - __main__ -  [emo] i did ask now you did tell ms
06/13/2022 08:19:18 - INFO - __main__ - ['others']
06/13/2022 08:19:18 - INFO - __main__ -  [emo] buddy how you tell me your contact no
06/13/2022 08:19:18 - INFO - __main__ - ['others']
06/13/2022 08:19:18 - INFO - __main__ - Tokenizing Input ...
06/13/2022 08:19:18 - INFO - __main__ - Tokenizing Output ...
06/13/2022 08:19:18 - INFO - __main__ - Loaded 64 examples from dev data
06/13/2022 08:19:19 - INFO - __main__ - Tokenizing Output ...
06/13/2022 08:19:25 - INFO - __main__ - Loaded 5509 examples from test data
06/13/2022 08:19:33 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 08:19:34 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 08:19:34 - INFO - __main__ - Starting training!
06/13/2022 08:20:40 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-up32shot/singletask-emo/emo_16_100_0.2_8_predictions.txt
06/13/2022 08:20:40 - INFO - __main__ - Classification-F1 on test data: 0.2135
06/13/2022 08:20:40 - INFO - __main__ - prefix=emo_16_100, lr=0.2, bsz=8, dev_performance=0.7757757757757758, test_performance=0.21345138118255652
06/13/2022 08:20:40 - INFO - __main__ - Running ... prefix=emo_16_13, lr=0.5, bsz=8 ...
06/13/2022 08:20:41 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 08:20:41 - INFO - __main__ - Printing 3 examples
06/13/2022 08:20:41 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/13/2022 08:20:41 - INFO - __main__ - ['others']
06/13/2022 08:20:41 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/13/2022 08:20:41 - INFO - __main__ - ['others']
06/13/2022 08:20:41 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/13/2022 08:20:41 - INFO - __main__ - ['others']
06/13/2022 08:20:41 - INFO - __main__ - Tokenizing Input ...
06/13/2022 08:20:41 - INFO - __main__ - Tokenizing Output ...
06/13/2022 08:20:41 - INFO - __main__ - Loaded 64 examples from train data
06/13/2022 08:20:41 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 08:20:41 - INFO - __main__ - Printing 3 examples
06/13/2022 08:20:41 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
06/13/2022 08:20:41 - INFO - __main__ - ['others']
06/13/2022 08:20:41 - INFO - __main__ -  [emo] i did ask now you did tell ms
06/13/2022 08:20:41 - INFO - __main__ - ['others']
06/13/2022 08:20:41 - INFO - __main__ -  [emo] buddy how you tell me your contact no
06/13/2022 08:20:41 - INFO - __main__ - ['others']
06/13/2022 08:20:41 - INFO - __main__ - Tokenizing Input ...
06/13/2022 08:20:41 - INFO - __main__ - Tokenizing Output ...
06/13/2022 08:20:41 - INFO - __main__ - Loaded 64 examples from dev data
06/13/2022 08:20:57 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 08:20:57 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 08:20:57 - INFO - __main__ - Starting training!
06/13/2022 08:21:00 - INFO - __main__ - Step 10 Global step 10 Train loss 3.46 on epoch=2
06/13/2022 08:21:03 - INFO - __main__ - Step 20 Global step 20 Train loss 2.20 on epoch=4
06/13/2022 08:21:05 - INFO - __main__ - Step 30 Global step 30 Train loss 1.58 on epoch=7
06/13/2022 08:21:08 - INFO - __main__ - Step 40 Global step 40 Train loss 1.10 on epoch=9
06/13/2022 08:21:10 - INFO - __main__ - Step 50 Global step 50 Train loss 0.88 on epoch=12
06/13/2022 08:21:11 - INFO - __main__ - Global step 50 Train loss 1.84 Classification-F1 0.5572863291658127 on epoch=12
06/13/2022 08:21:11 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.5572863291658127 on epoch=12, global_step=50
06/13/2022 08:21:14 - INFO - __main__ - Step 60 Global step 60 Train loss 0.78 on epoch=14
06/13/2022 08:21:16 - INFO - __main__ - Step 70 Global step 70 Train loss 0.60 on epoch=17
06/13/2022 08:21:19 - INFO - __main__ - Step 80 Global step 80 Train loss 0.73 on epoch=19
06/13/2022 08:21:21 - INFO - __main__ - Step 90 Global step 90 Train loss 0.57 on epoch=22
06/13/2022 08:21:23 - INFO - __main__ - Step 100 Global step 100 Train loss 0.62 on epoch=24
06/13/2022 08:21:24 - INFO - __main__ - Global step 100 Train loss 0.66 Classification-F1 0.5961472417184869 on epoch=24
06/13/2022 08:21:24 - INFO - __main__ - Saving model with best Classification-F1: 0.5572863291658127 -> 0.5961472417184869 on epoch=24, global_step=100
06/13/2022 08:21:27 - INFO - __main__ - Step 110 Global step 110 Train loss 0.60 on epoch=27
06/13/2022 08:21:29 - INFO - __main__ - Step 120 Global step 120 Train loss 0.52 on epoch=29
06/13/2022 08:21:32 - INFO - __main__ - Step 130 Global step 130 Train loss 0.49 on epoch=32
06/13/2022 08:21:34 - INFO - __main__ - Step 140 Global step 140 Train loss 0.52 on epoch=34
06/13/2022 08:21:37 - INFO - __main__ - Step 150 Global step 150 Train loss 0.50 on epoch=37
06/13/2022 08:21:37 - INFO - __main__ - Global step 150 Train loss 0.53 Classification-F1 0.7627960275019099 on epoch=37
06/13/2022 08:21:37 - INFO - __main__ - Saving model with best Classification-F1: 0.5961472417184869 -> 0.7627960275019099 on epoch=37, global_step=150
06/13/2022 08:21:40 - INFO - __main__ - Step 160 Global step 160 Train loss 0.43 on epoch=39
06/13/2022 08:21:42 - INFO - __main__ - Step 170 Global step 170 Train loss 0.48 on epoch=42
06/13/2022 08:21:45 - INFO - __main__ - Step 180 Global step 180 Train loss 0.36 on epoch=44
06/13/2022 08:21:47 - INFO - __main__ - Step 190 Global step 190 Train loss 0.42 on epoch=47
06/13/2022 08:21:50 - INFO - __main__ - Step 200 Global step 200 Train loss 0.43 on epoch=49
06/13/2022 08:21:51 - INFO - __main__ - Global step 200 Train loss 0.42 Classification-F1 0.6865453306629777 on epoch=49
06/13/2022 08:21:53 - INFO - __main__ - Step 210 Global step 210 Train loss 0.44 on epoch=52
06/13/2022 08:21:55 - INFO - __main__ - Step 220 Global step 220 Train loss 0.34 on epoch=54
06/13/2022 08:21:58 - INFO - __main__ - Step 230 Global step 230 Train loss 0.43 on epoch=57
06/13/2022 08:22:00 - INFO - __main__ - Step 240 Global step 240 Train loss 0.31 on epoch=59
06/13/2022 08:22:03 - INFO - __main__ - Step 250 Global step 250 Train loss 0.37 on epoch=62
06/13/2022 08:22:04 - INFO - __main__ - Global step 250 Train loss 0.38 Classification-F1 0.7450978075978076 on epoch=62
06/13/2022 08:22:06 - INFO - __main__ - Step 260 Global step 260 Train loss 0.37 on epoch=64
06/13/2022 08:22:09 - INFO - __main__ - Step 270 Global step 270 Train loss 0.35 on epoch=67
06/13/2022 08:22:11 - INFO - __main__ - Step 280 Global step 280 Train loss 0.26 on epoch=69
06/13/2022 08:22:13 - INFO - __main__ - Step 290 Global step 290 Train loss 0.34 on epoch=72
06/13/2022 08:22:16 - INFO - __main__ - Step 300 Global step 300 Train loss 0.26 on epoch=74
06/13/2022 08:22:17 - INFO - __main__ - Global step 300 Train loss 0.32 Classification-F1 0.7786324786324786 on epoch=74
06/13/2022 08:22:17 - INFO - __main__ - Saving model with best Classification-F1: 0.7627960275019099 -> 0.7786324786324786 on epoch=74, global_step=300
06/13/2022 08:22:19 - INFO - __main__ - Step 310 Global step 310 Train loss 0.31 on epoch=77
06/13/2022 08:22:22 - INFO - __main__ - Step 320 Global step 320 Train loss 0.27 on epoch=79
06/13/2022 08:22:24 - INFO - __main__ - Step 330 Global step 330 Train loss 0.30 on epoch=82
06/13/2022 08:22:26 - INFO - __main__ - Step 340 Global step 340 Train loss 0.30 on epoch=84
06/13/2022 08:22:29 - INFO - __main__ - Step 350 Global step 350 Train loss 0.23 on epoch=87
06/13/2022 08:22:30 - INFO - __main__ - Global step 350 Train loss 0.28 Classification-F1 0.8578410836475353 on epoch=87
06/13/2022 08:22:30 - INFO - __main__ - Saving model with best Classification-F1: 0.7786324786324786 -> 0.8578410836475353 on epoch=87, global_step=350
06/13/2022 08:22:32 - INFO - __main__ - Step 360 Global step 360 Train loss 0.16 on epoch=89
06/13/2022 08:22:35 - INFO - __main__ - Step 370 Global step 370 Train loss 0.15 on epoch=92
06/13/2022 08:22:37 - INFO - __main__ - Step 380 Global step 380 Train loss 0.17 on epoch=94
06/13/2022 08:22:40 - INFO - __main__ - Step 390 Global step 390 Train loss 0.20 on epoch=97
06/13/2022 08:22:42 - INFO - __main__ - Step 400 Global step 400 Train loss 0.17 on epoch=99
06/13/2022 08:22:43 - INFO - __main__ - Global step 400 Train loss 0.17 Classification-F1 0.825944170771757 on epoch=99
06/13/2022 08:22:45 - INFO - __main__ - Step 410 Global step 410 Train loss 0.18 on epoch=102
06/13/2022 08:22:48 - INFO - __main__ - Step 420 Global step 420 Train loss 0.22 on epoch=104
06/13/2022 08:22:50 - INFO - __main__ - Step 430 Global step 430 Train loss 0.15 on epoch=107
06/13/2022 08:22:52 - INFO - __main__ - Step 440 Global step 440 Train loss 0.20 on epoch=109
06/13/2022 08:22:55 - INFO - __main__ - Step 450 Global step 450 Train loss 0.15 on epoch=112
06/13/2022 08:22:56 - INFO - __main__ - Global step 450 Train loss 0.18 Classification-F1 0.8265605362379557 on epoch=112
06/13/2022 08:22:58 - INFO - __main__ - Step 460 Global step 460 Train loss 0.15 on epoch=114
06/13/2022 08:23:01 - INFO - __main__ - Step 470 Global step 470 Train loss 0.17 on epoch=117
06/13/2022 08:23:03 - INFO - __main__ - Step 480 Global step 480 Train loss 0.18 on epoch=119
06/13/2022 08:23:06 - INFO - __main__ - Step 490 Global step 490 Train loss 0.16 on epoch=122
06/13/2022 08:23:08 - INFO - __main__ - Step 500 Global step 500 Train loss 0.14 on epoch=124
06/13/2022 08:23:09 - INFO - __main__ - Global step 500 Train loss 0.16 Classification-F1 0.825944170771757 on epoch=124
06/13/2022 08:23:11 - INFO - __main__ - Step 510 Global step 510 Train loss 0.13 on epoch=127
06/13/2022 08:23:14 - INFO - __main__ - Step 520 Global step 520 Train loss 0.14 on epoch=129
06/13/2022 08:23:16 - INFO - __main__ - Step 530 Global step 530 Train loss 0.16 on epoch=132
06/13/2022 08:23:19 - INFO - __main__ - Step 540 Global step 540 Train loss 0.16 on epoch=134
06/13/2022 08:23:21 - INFO - __main__ - Step 550 Global step 550 Train loss 0.12 on epoch=137
06/13/2022 08:23:22 - INFO - __main__ - Global step 550 Train loss 0.14 Classification-F1 0.7904176093514329 on epoch=137
06/13/2022 08:23:25 - INFO - __main__ - Step 560 Global step 560 Train loss 0.14 on epoch=139
06/13/2022 08:23:27 - INFO - __main__ - Step 570 Global step 570 Train loss 0.10 on epoch=142
06/13/2022 08:23:29 - INFO - __main__ - Step 580 Global step 580 Train loss 0.07 on epoch=144
06/13/2022 08:23:32 - INFO - __main__ - Step 590 Global step 590 Train loss 0.08 on epoch=147
06/13/2022 08:23:34 - INFO - __main__ - Step 600 Global step 600 Train loss 0.13 on epoch=149
06/13/2022 08:23:35 - INFO - __main__ - Global step 600 Train loss 0.11 Classification-F1 0.7718551587301588 on epoch=149
06/13/2022 08:23:38 - INFO - __main__ - Step 610 Global step 610 Train loss 0.10 on epoch=152
06/13/2022 08:23:40 - INFO - __main__ - Step 620 Global step 620 Train loss 0.06 on epoch=154
06/13/2022 08:23:42 - INFO - __main__ - Step 630 Global step 630 Train loss 0.08 on epoch=157
06/13/2022 08:23:45 - INFO - __main__ - Step 640 Global step 640 Train loss 0.12 on epoch=159
06/13/2022 08:23:47 - INFO - __main__ - Step 650 Global step 650 Train loss 0.04 on epoch=162
06/13/2022 08:23:48 - INFO - __main__ - Global step 650 Train loss 0.08 Classification-F1 0.7570232905716777 on epoch=162
06/13/2022 08:23:51 - INFO - __main__ - Step 660 Global step 660 Train loss 0.20 on epoch=164
06/13/2022 08:23:53 - INFO - __main__ - Step 670 Global step 670 Train loss 0.03 on epoch=167
06/13/2022 08:23:56 - INFO - __main__ - Step 680 Global step 680 Train loss 0.05 on epoch=169
06/13/2022 08:23:58 - INFO - __main__ - Step 690 Global step 690 Train loss 0.05 on epoch=172
06/13/2022 08:24:00 - INFO - __main__ - Step 700 Global step 700 Train loss 0.06 on epoch=174
06/13/2022 08:24:01 - INFO - __main__ - Global step 700 Train loss 0.08 Classification-F1 0.7904876373626373 on epoch=174
06/13/2022 08:24:04 - INFO - __main__ - Step 710 Global step 710 Train loss 0.04 on epoch=177
06/13/2022 08:24:06 - INFO - __main__ - Step 720 Global step 720 Train loss 0.09 on epoch=179
06/13/2022 08:24:08 - INFO - __main__ - Step 730 Global step 730 Train loss 0.05 on epoch=182
06/13/2022 08:24:11 - INFO - __main__ - Step 740 Global step 740 Train loss 0.03 on epoch=184
06/13/2022 08:24:13 - INFO - __main__ - Step 750 Global step 750 Train loss 0.08 on epoch=187
06/13/2022 08:24:14 - INFO - __main__ - Global step 750 Train loss 0.06 Classification-F1 0.7912554112554113 on epoch=187
06/13/2022 08:24:17 - INFO - __main__ - Step 760 Global step 760 Train loss 0.06 on epoch=189
06/13/2022 08:24:19 - INFO - __main__ - Step 770 Global step 770 Train loss 0.03 on epoch=192
06/13/2022 08:24:22 - INFO - __main__ - Step 780 Global step 780 Train loss 0.07 on epoch=194
06/13/2022 08:24:24 - INFO - __main__ - Step 790 Global step 790 Train loss 0.04 on epoch=197
06/13/2022 08:24:26 - INFO - __main__ - Step 800 Global step 800 Train loss 0.04 on epoch=199
06/13/2022 08:24:27 - INFO - __main__ - Global step 800 Train loss 0.05 Classification-F1 0.7904176093514329 on epoch=199
06/13/2022 08:24:30 - INFO - __main__ - Step 810 Global step 810 Train loss 0.07 on epoch=202
06/13/2022 08:24:32 - INFO - __main__ - Step 820 Global step 820 Train loss 0.04 on epoch=204
06/13/2022 08:24:35 - INFO - __main__ - Step 830 Global step 830 Train loss 0.05 on epoch=207
06/13/2022 08:24:37 - INFO - __main__ - Step 840 Global step 840 Train loss 0.03 on epoch=209
06/13/2022 08:24:39 - INFO - __main__ - Step 850 Global step 850 Train loss 0.02 on epoch=212
06/13/2022 08:24:40 - INFO - __main__ - Global step 850 Train loss 0.04 Classification-F1 0.7714583333333334 on epoch=212
06/13/2022 08:24:43 - INFO - __main__ - Step 860 Global step 860 Train loss 0.03 on epoch=214
06/13/2022 08:24:45 - INFO - __main__ - Step 870 Global step 870 Train loss 0.04 on epoch=217
06/13/2022 08:24:48 - INFO - __main__ - Step 880 Global step 880 Train loss 0.04 on epoch=219
06/13/2022 08:24:50 - INFO - __main__ - Step 890 Global step 890 Train loss 0.04 on epoch=222
06/13/2022 08:24:52 - INFO - __main__ - Step 900 Global step 900 Train loss 0.05 on epoch=224
06/13/2022 08:24:53 - INFO - __main__ - Global step 900 Train loss 0.04 Classification-F1 0.7519354392755928 on epoch=224
06/13/2022 08:24:56 - INFO - __main__ - Step 910 Global step 910 Train loss 0.02 on epoch=227
06/13/2022 08:24:58 - INFO - __main__ - Step 920 Global step 920 Train loss 0.02 on epoch=229
06/13/2022 08:25:01 - INFO - __main__ - Step 930 Global step 930 Train loss 0.04 on epoch=232
06/13/2022 08:25:03 - INFO - __main__ - Step 940 Global step 940 Train loss 0.03 on epoch=234
06/13/2022 08:25:06 - INFO - __main__ - Step 950 Global step 950 Train loss 0.03 on epoch=237
06/13/2022 08:25:06 - INFO - __main__ - Global step 950 Train loss 0.03 Classification-F1 0.7567991610905823 on epoch=237
06/13/2022 08:25:09 - INFO - __main__ - Step 960 Global step 960 Train loss 0.04 on epoch=239
06/13/2022 08:25:11 - INFO - __main__ - Step 970 Global step 970 Train loss 0.04 on epoch=242
06/13/2022 08:25:14 - INFO - __main__ - Step 980 Global step 980 Train loss 0.04 on epoch=244
06/13/2022 08:25:16 - INFO - __main__ - Step 990 Global step 990 Train loss 0.07 on epoch=247
06/13/2022 08:25:19 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.02 on epoch=249
06/13/2022 08:25:20 - INFO - __main__ - Global step 1000 Train loss 0.04 Classification-F1 0.771969696969697 on epoch=249
06/13/2022 08:25:22 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.02 on epoch=252
06/13/2022 08:25:24 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.04 on epoch=254
06/13/2022 08:25:27 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.02 on epoch=257
06/13/2022 08:25:29 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.03 on epoch=259
06/13/2022 08:25:32 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.01 on epoch=262
06/13/2022 08:25:33 - INFO - __main__ - Global step 1050 Train loss 0.02 Classification-F1 0.8114018334606571 on epoch=262
06/13/2022 08:25:35 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.02 on epoch=264
06/13/2022 08:25:37 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.04 on epoch=267
06/13/2022 08:25:40 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.12 on epoch=269
06/13/2022 08:25:42 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.02 on epoch=272
06/13/2022 08:25:45 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.03 on epoch=274
06/13/2022 08:25:45 - INFO - __main__ - Global step 1100 Train loss 0.05 Classification-F1 0.8259604978354979 on epoch=274
06/13/2022 08:25:48 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.01 on epoch=277
06/13/2022 08:25:50 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=279
06/13/2022 08:25:53 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=282
06/13/2022 08:25:55 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.02 on epoch=284
06/13/2022 08:25:58 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.04 on epoch=287
06/13/2022 08:25:59 - INFO - __main__ - Global step 1150 Train loss 0.02 Classification-F1 0.7910258379008379 on epoch=287
06/13/2022 08:26:01 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.02 on epoch=289
06/13/2022 08:26:04 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.01 on epoch=292
06/13/2022 08:26:06 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.03 on epoch=294
06/13/2022 08:26:08 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.08 on epoch=297
06/13/2022 08:26:11 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=299
06/13/2022 08:26:12 - INFO - __main__ - Global step 1200 Train loss 0.03 Classification-F1 0.7568693693693693 on epoch=299
06/13/2022 08:26:14 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.03 on epoch=302
06/13/2022 08:26:17 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=304
06/13/2022 08:26:19 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.04 on epoch=307
06/13/2022 08:26:21 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.07 on epoch=309
06/13/2022 08:26:24 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.04 on epoch=312
06/13/2022 08:26:25 - INFO - __main__ - Global step 1250 Train loss 0.04 Classification-F1 0.7917936117936119 on epoch=312
06/13/2022 08:26:27 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.06 on epoch=314
06/13/2022 08:26:30 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.01 on epoch=317
06/13/2022 08:26:32 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.00 on epoch=319
06/13/2022 08:26:35 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.05 on epoch=322
06/13/2022 08:26:37 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=324
06/13/2022 08:26:38 - INFO - __main__ - Global step 1300 Train loss 0.03 Classification-F1 0.7726670520788168 on epoch=324
06/13/2022 08:26:40 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.00 on epoch=327
06/13/2022 08:26:43 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.04 on epoch=329
06/13/2022 08:26:45 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=332
06/13/2022 08:26:48 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=334
06/13/2022 08:26:50 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=337
06/13/2022 08:26:51 - INFO - __main__ - Global step 1350 Train loss 0.01 Classification-F1 0.7912554112554113 on epoch=337
06/13/2022 08:26:54 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.02 on epoch=339
06/13/2022 08:26:56 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.00 on epoch=342
06/13/2022 08:26:58 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.00 on epoch=344
06/13/2022 08:27:01 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.00 on epoch=347
06/13/2022 08:27:03 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=349
06/13/2022 08:27:04 - INFO - __main__ - Global step 1400 Train loss 0.01 Classification-F1 0.7910258379008379 on epoch=349
06/13/2022 08:27:07 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=352
06/13/2022 08:27:09 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.01 on epoch=354
06/13/2022 08:27:12 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.09 on epoch=357
06/13/2022 08:27:14 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=359
06/13/2022 08:27:16 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=362
06/13/2022 08:27:17 - INFO - __main__ - Global step 1450 Train loss 0.03 Classification-F1 0.7575694444444444 on epoch=362
06/13/2022 08:27:20 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.09 on epoch=364
06/13/2022 08:27:22 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=367
06/13/2022 08:27:25 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=369
06/13/2022 08:27:27 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=372
06/13/2022 08:27:29 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.03 on epoch=374
06/13/2022 08:27:30 - INFO - __main__ - Global step 1500 Train loss 0.03 Classification-F1 0.8087647306397306 on epoch=374
06/13/2022 08:27:33 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=377
06/13/2022 08:27:35 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.14 on epoch=379
06/13/2022 08:27:38 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=382
06/13/2022 08:27:40 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=384
06/13/2022 08:27:42 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=387
06/13/2022 08:27:43 - INFO - __main__ - Global step 1550 Train loss 0.04 Classification-F1 0.7758547008547009 on epoch=387
06/13/2022 08:27:46 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.03 on epoch=389
06/13/2022 08:27:48 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=392
06/13/2022 08:27:51 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=394
06/13/2022 08:27:53 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.02 on epoch=397
06/13/2022 08:27:56 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=399
06/13/2022 08:27:56 - INFO - __main__ - Global step 1600 Train loss 0.01 Classification-F1 0.8259604978354979 on epoch=399
06/13/2022 08:27:59 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=402
06/13/2022 08:28:01 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.02 on epoch=404
06/13/2022 08:28:04 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.04 on epoch=407
06/13/2022 08:28:06 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=409
06/13/2022 08:28:09 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=412
06/13/2022 08:28:10 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.7521038850322739 on epoch=412
06/13/2022 08:28:12 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=414
06/13/2022 08:28:15 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=417
06/13/2022 08:28:17 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.03 on epoch=419
06/13/2022 08:28:19 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=422
06/13/2022 08:28:22 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=424
06/13/2022 08:28:23 - INFO - __main__ - Global step 1700 Train loss 0.01 Classification-F1 0.8085618085618086 on epoch=424
06/13/2022 08:28:25 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=427
06/13/2022 08:28:28 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=429
06/13/2022 08:28:30 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=432
06/13/2022 08:28:32 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=434
06/13/2022 08:28:35 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=437
06/13/2022 08:28:36 - INFO - __main__ - Global step 1750 Train loss 0.01 Classification-F1 0.7771987868762062 on epoch=437
06/13/2022 08:28:38 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=439
06/13/2022 08:28:41 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=442
06/13/2022 08:28:43 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=444
06/13/2022 08:28:46 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.07 on epoch=447
06/13/2022 08:28:48 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=449
06/13/2022 08:28:49 - INFO - __main__ - Global step 1800 Train loss 0.02 Classification-F1 0.776201923076923 on epoch=449
06/13/2022 08:28:52 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=452
06/13/2022 08:28:54 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=454
06/13/2022 08:28:57 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.08 on epoch=457
06/13/2022 08:28:59 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=459
06/13/2022 08:29:01 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=462
06/13/2022 08:29:02 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.7717936117936118 on epoch=462
06/13/2022 08:29:05 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=464
06/13/2022 08:29:07 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=467
06/13/2022 08:29:10 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=469
06/13/2022 08:29:12 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=472
06/13/2022 08:29:15 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=474
06/13/2022 08:29:16 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.7521739130434782 on epoch=474
06/13/2022 08:29:18 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=477
06/13/2022 08:29:20 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=479
06/13/2022 08:29:23 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=482
06/13/2022 08:29:25 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=484
06/13/2022 08:29:28 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=487
06/13/2022 08:29:29 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.7427375762859634 on epoch=487
06/13/2022 08:29:31 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=489
06/13/2022 08:29:34 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=492
06/13/2022 08:29:36 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.09 on epoch=494
06/13/2022 08:29:39 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=497
06/13/2022 08:29:41 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=499
06/13/2022 08:29:42 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.7905011655011656 on epoch=499
06/13/2022 08:29:44 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.04 on epoch=502
06/13/2022 08:29:47 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
06/13/2022 08:29:49 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/13/2022 08:29:52 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=509
06/13/2022 08:29:54 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.02 on epoch=512
06/13/2022 08:29:55 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.7774959973235835 on epoch=512
06/13/2022 08:29:57 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=514
06/13/2022 08:30:00 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.03 on epoch=517
06/13/2022 08:30:02 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=519
06/13/2022 08:30:05 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/13/2022 08:30:07 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/13/2022 08:30:08 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.8096865193639388 on epoch=524
06/13/2022 08:30:11 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
06/13/2022 08:30:13 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/13/2022 08:30:15 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/13/2022 08:30:18 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
06/13/2022 08:30:20 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
06/13/2022 08:30:21 - INFO - __main__ - Global step 2150 Train loss 0.00 Classification-F1 0.7757796257796258 on epoch=537
06/13/2022 08:30:24 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=539
06/13/2022 08:30:26 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/13/2022 08:30:28 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/13/2022 08:30:31 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/13/2022 08:30:33 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=549
06/13/2022 08:30:34 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.7610697546181417 on epoch=549
06/13/2022 08:30:37 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/13/2022 08:30:39 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/13/2022 08:30:42 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
06/13/2022 08:30:44 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/13/2022 08:30:47 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=562
06/13/2022 08:30:48 - INFO - __main__ - Global step 2250 Train loss 0.00 Classification-F1 0.7941925381263616 on epoch=562
06/13/2022 08:30:50 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=564
06/13/2022 08:30:52 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/13/2022 08:30:55 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=569
06/13/2022 08:30:57 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/13/2022 08:31:00 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/13/2022 08:31:01 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.8087647306397306 on epoch=574
06/13/2022 08:31:03 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/13/2022 08:31:06 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/13/2022 08:31:08 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/13/2022 08:31:11 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/13/2022 08:31:13 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=587
06/13/2022 08:31:14 - INFO - __main__ - Global step 2350 Train loss 0.00 Classification-F1 0.8265605362379557 on epoch=587
06/13/2022 08:31:16 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=589
06/13/2022 08:31:19 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/13/2022 08:31:21 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/13/2022 08:31:24 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/13/2022 08:31:26 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/13/2022 08:31:27 - INFO - __main__ - Global step 2400 Train loss 0.00 Classification-F1 0.8087647306397306 on epoch=599
06/13/2022 08:31:30 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/13/2022 08:31:32 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.05 on epoch=604
06/13/2022 08:31:35 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/13/2022 08:31:37 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/13/2022 08:31:39 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=612
06/13/2022 08:31:40 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.7905011655011656 on epoch=612
06/13/2022 08:31:43 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.04 on epoch=614
06/13/2022 08:31:45 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/13/2022 08:31:48 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/13/2022 08:31:50 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/13/2022 08:31:53 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=624
06/13/2022 08:31:54 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.8087647306397306 on epoch=624
06/13/2022 08:31:56 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/13/2022 08:31:59 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/13/2022 08:32:01 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/13/2022 08:32:03 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/13/2022 08:32:06 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/13/2022 08:32:07 - INFO - __main__ - Global step 2550 Train loss 0.00 Classification-F1 0.7941925381263616 on epoch=637
06/13/2022 08:32:09 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=639
06/13/2022 08:32:12 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.04 on epoch=642
06/13/2022 08:32:14 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/13/2022 08:32:17 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/13/2022 08:32:19 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=649
06/13/2022 08:32:20 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.8087647306397306 on epoch=649
06/13/2022 08:32:22 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/13/2022 08:32:25 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.07 on epoch=654
06/13/2022 08:32:27 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/13/2022 08:32:30 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.05 on epoch=659
06/13/2022 08:32:33 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/13/2022 08:32:34 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.7904876373626373 on epoch=662
06/13/2022 08:32:36 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/13/2022 08:32:38 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.04 on epoch=667
06/13/2022 08:32:41 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/13/2022 08:32:43 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/13/2022 08:32:46 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/13/2022 08:32:47 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.7905011655011656 on epoch=674
06/13/2022 08:32:49 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/13/2022 08:32:52 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/13/2022 08:32:54 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=682
06/13/2022 08:32:56 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=684
06/13/2022 08:32:59 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/13/2022 08:33:00 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.7516610360360361 on epoch=687
06/13/2022 08:33:02 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.05 on epoch=689
06/13/2022 08:33:05 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/13/2022 08:33:07 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/13/2022 08:33:10 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/13/2022 08:33:12 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=699
06/13/2022 08:33:13 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.8096865193639388 on epoch=699
06/13/2022 08:33:16 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/13/2022 08:33:18 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=704
06/13/2022 08:33:20 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/13/2022 08:33:23 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/13/2022 08:33:25 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=712
06/13/2022 08:33:26 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.8087647306397306 on epoch=712
06/13/2022 08:33:29 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/13/2022 08:33:31 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/13/2022 08:33:34 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/13/2022 08:33:36 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/13/2022 08:33:39 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/13/2022 08:33:40 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.7910258379008379 on epoch=724
06/13/2022 08:33:42 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/13/2022 08:33:44 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/13/2022 08:33:47 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/13/2022 08:33:49 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/13/2022 08:33:52 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/13/2022 08:33:53 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.7910258379008379 on epoch=737
06/13/2022 08:33:55 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/13/2022 08:33:58 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/13/2022 08:34:00 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/13/2022 08:34:02 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=747
06/13/2022 08:34:05 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=749
06/13/2022 08:34:06 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.7926497926497926 on epoch=749
06/13/2022 08:34:06 - INFO - __main__ - save last model!
06/13/2022 08:34:06 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/13/2022 08:34:06 - INFO - __main__ - Start tokenizing ... 5509 instances
06/13/2022 08:34:06 - INFO - __main__ - Printing 3 examples
06/13/2022 08:34:06 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/13/2022 08:34:06 - INFO - __main__ - ['others']
06/13/2022 08:34:06 - INFO - __main__ -  [emo] what you like very little things ok
06/13/2022 08:34:06 - INFO - __main__ - ['others']
06/13/2022 08:34:06 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/13/2022 08:34:06 - INFO - __main__ - ['others']
06/13/2022 08:34:06 - INFO - __main__ - Tokenizing Input ...
06/13/2022 08:34:06 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 08:34:06 - INFO - __main__ - Printing 3 examples
06/13/2022 08:34:06 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/13/2022 08:34:06 - INFO - __main__ - ['others']
06/13/2022 08:34:06 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/13/2022 08:34:06 - INFO - __main__ - ['others']
06/13/2022 08:34:06 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/13/2022 08:34:06 - INFO - __main__ - ['others']
06/13/2022 08:34:06 - INFO - __main__ - Tokenizing Input ...
06/13/2022 08:34:06 - INFO - __main__ - Tokenizing Output ...
06/13/2022 08:34:06 - INFO - __main__ - Loaded 64 examples from train data
06/13/2022 08:34:06 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 08:34:06 - INFO - __main__ - Printing 3 examples
06/13/2022 08:34:06 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
06/13/2022 08:34:06 - INFO - __main__ - ['others']
06/13/2022 08:34:06 - INFO - __main__ -  [emo] i did ask now you did tell ms
06/13/2022 08:34:06 - INFO - __main__ - ['others']
06/13/2022 08:34:06 - INFO - __main__ -  [emo] buddy how you tell me your contact no
06/13/2022 08:34:06 - INFO - __main__ - ['others']
06/13/2022 08:34:06 - INFO - __main__ - Tokenizing Input ...
06/13/2022 08:34:06 - INFO - __main__ - Tokenizing Output ...
06/13/2022 08:34:06 - INFO - __main__ - Loaded 64 examples from dev data
06/13/2022 08:34:08 - INFO - __main__ - Tokenizing Output ...
06/13/2022 08:34:13 - INFO - __main__ - Loaded 5509 examples from test data
06/13/2022 08:34:22 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 08:34:22 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 08:34:22 - INFO - __main__ - Starting training!
06/13/2022 08:35:46 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-up32shot/singletask-emo/emo_16_13_0.5_8_predictions.txt
06/13/2022 08:35:46 - INFO - __main__ - Classification-F1 on test data: 0.2359
06/13/2022 08:35:46 - INFO - __main__ - prefix=emo_16_13, lr=0.5, bsz=8, dev_performance=0.8578410836475353, test_performance=0.23591370399868072
06/13/2022 08:35:46 - INFO - __main__ - Running ... prefix=emo_16_13, lr=0.4, bsz=8 ...
06/13/2022 08:35:47 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 08:35:47 - INFO - __main__ - Printing 3 examples
06/13/2022 08:35:47 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/13/2022 08:35:47 - INFO - __main__ - ['others']
06/13/2022 08:35:47 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/13/2022 08:35:47 - INFO - __main__ - ['others']
06/13/2022 08:35:47 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/13/2022 08:35:47 - INFO - __main__ - ['others']
06/13/2022 08:35:47 - INFO - __main__ - Tokenizing Input ...
06/13/2022 08:35:47 - INFO - __main__ - Tokenizing Output ...
06/13/2022 08:35:47 - INFO - __main__ - Loaded 64 examples from train data
06/13/2022 08:35:47 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 08:35:47 - INFO - __main__ - Printing 3 examples
06/13/2022 08:35:47 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
06/13/2022 08:35:47 - INFO - __main__ - ['others']
06/13/2022 08:35:47 - INFO - __main__ -  [emo] i did ask now you did tell ms
06/13/2022 08:35:47 - INFO - __main__ - ['others']
06/13/2022 08:35:47 - INFO - __main__ -  [emo] buddy how you tell me your contact no
06/13/2022 08:35:47 - INFO - __main__ - ['others']
06/13/2022 08:35:47 - INFO - __main__ - Tokenizing Input ...
06/13/2022 08:35:47 - INFO - __main__ - Tokenizing Output ...
06/13/2022 08:35:47 - INFO - __main__ - Loaded 64 examples from dev data
06/13/2022 08:36:03 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 08:36:03 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 08:36:03 - INFO - __main__ - Starting training!
06/13/2022 08:36:06 - INFO - __main__ - Step 10 Global step 10 Train loss 3.54 on epoch=2
06/13/2022 08:36:09 - INFO - __main__ - Step 20 Global step 20 Train loss 2.47 on epoch=4
06/13/2022 08:36:11 - INFO - __main__ - Step 30 Global step 30 Train loss 1.95 on epoch=7
06/13/2022 08:36:13 - INFO - __main__ - Step 40 Global step 40 Train loss 1.47 on epoch=9
06/13/2022 08:36:16 - INFO - __main__ - Step 50 Global step 50 Train loss 1.25 on epoch=12
06/13/2022 08:36:17 - INFO - __main__ - Global step 50 Train loss 2.14 Classification-F1 0.19855442176870747 on epoch=12
06/13/2022 08:36:17 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.19855442176870747 on epoch=12, global_step=50
06/13/2022 08:36:19 - INFO - __main__ - Step 60 Global step 60 Train loss 0.96 on epoch=14
06/13/2022 08:36:22 - INFO - __main__ - Step 70 Global step 70 Train loss 0.82 on epoch=17
06/13/2022 08:36:24 - INFO - __main__ - Step 80 Global step 80 Train loss 0.67 on epoch=19
06/13/2022 08:36:27 - INFO - __main__ - Step 90 Global step 90 Train loss 0.61 on epoch=22
06/13/2022 08:36:29 - INFO - __main__ - Step 100 Global step 100 Train loss 0.53 on epoch=24
06/13/2022 08:36:30 - INFO - __main__ - Global step 100 Train loss 0.72 Classification-F1 0.5130971041993235 on epoch=24
06/13/2022 08:36:30 - INFO - __main__ - Saving model with best Classification-F1: 0.19855442176870747 -> 0.5130971041993235 on epoch=24, global_step=100
06/13/2022 08:36:33 - INFO - __main__ - Step 110 Global step 110 Train loss 0.66 on epoch=27
06/13/2022 08:36:35 - INFO - __main__ - Step 120 Global step 120 Train loss 0.57 on epoch=29
06/13/2022 08:36:37 - INFO - __main__ - Step 130 Global step 130 Train loss 0.65 on epoch=32
06/13/2022 08:36:40 - INFO - __main__ - Step 140 Global step 140 Train loss 0.62 on epoch=34
06/13/2022 08:36:42 - INFO - __main__ - Step 150 Global step 150 Train loss 0.53 on epoch=37
06/13/2022 08:36:43 - INFO - __main__ - Global step 150 Train loss 0.61 Classification-F1 0.5855407750144592 on epoch=37
06/13/2022 08:36:43 - INFO - __main__ - Saving model with best Classification-F1: 0.5130971041993235 -> 0.5855407750144592 on epoch=37, global_step=150
06/13/2022 08:36:46 - INFO - __main__ - Step 160 Global step 160 Train loss 0.50 on epoch=39
06/13/2022 08:36:48 - INFO - __main__ - Step 170 Global step 170 Train loss 0.53 on epoch=42
06/13/2022 08:36:51 - INFO - __main__ - Step 180 Global step 180 Train loss 0.52 on epoch=44
06/13/2022 08:36:53 - INFO - __main__ - Step 190 Global step 190 Train loss 0.44 on epoch=47
06/13/2022 08:36:55 - INFO - __main__ - Step 200 Global step 200 Train loss 0.38 on epoch=49
06/13/2022 08:36:56 - INFO - __main__ - Global step 200 Train loss 0.47 Classification-F1 0.6161409087105681 on epoch=49
06/13/2022 08:36:56 - INFO - __main__ - Saving model with best Classification-F1: 0.5855407750144592 -> 0.6161409087105681 on epoch=49, global_step=200
06/13/2022 08:36:59 - INFO - __main__ - Step 210 Global step 210 Train loss 0.46 on epoch=52
06/13/2022 08:37:01 - INFO - __main__ - Step 220 Global step 220 Train loss 0.46 on epoch=54
06/13/2022 08:37:04 - INFO - __main__ - Step 230 Global step 230 Train loss 0.36 on epoch=57
06/13/2022 08:37:06 - INFO - __main__ - Step 240 Global step 240 Train loss 0.38 on epoch=59
06/13/2022 08:37:08 - INFO - __main__ - Step 250 Global step 250 Train loss 0.29 on epoch=62
06/13/2022 08:37:09 - INFO - __main__ - Global step 250 Train loss 0.39 Classification-F1 0.7336946836946837 on epoch=62
06/13/2022 08:37:09 - INFO - __main__ - Saving model with best Classification-F1: 0.6161409087105681 -> 0.7336946836946837 on epoch=62, global_step=250
06/13/2022 08:37:12 - INFO - __main__ - Step 260 Global step 260 Train loss 0.41 on epoch=64
06/13/2022 08:37:14 - INFO - __main__ - Step 270 Global step 270 Train loss 0.41 on epoch=67
06/13/2022 08:37:17 - INFO - __main__ - Step 280 Global step 280 Train loss 0.37 on epoch=69
06/13/2022 08:37:19 - INFO - __main__ - Step 290 Global step 290 Train loss 0.38 on epoch=72
06/13/2022 08:37:22 - INFO - __main__ - Step 300 Global step 300 Train loss 0.35 on epoch=74
06/13/2022 08:37:23 - INFO - __main__ - Global step 300 Train loss 0.39 Classification-F1 0.7091264651748523 on epoch=74
06/13/2022 08:37:25 - INFO - __main__ - Step 310 Global step 310 Train loss 0.33 on epoch=77
06/13/2022 08:37:27 - INFO - __main__ - Step 320 Global step 320 Train loss 0.35 on epoch=79
06/13/2022 08:37:30 - INFO - __main__ - Step 330 Global step 330 Train loss 0.25 on epoch=82
06/13/2022 08:37:32 - INFO - __main__ - Step 340 Global step 340 Train loss 0.20 on epoch=84
06/13/2022 08:37:35 - INFO - __main__ - Step 350 Global step 350 Train loss 0.25 on epoch=87
06/13/2022 08:37:36 - INFO - __main__ - Global step 350 Train loss 0.27 Classification-F1 0.7653439153439153 on epoch=87
06/13/2022 08:37:36 - INFO - __main__ - Saving model with best Classification-F1: 0.7336946836946837 -> 0.7653439153439153 on epoch=87, global_step=350
06/13/2022 08:37:38 - INFO - __main__ - Step 360 Global step 360 Train loss 0.28 on epoch=89
06/13/2022 08:37:41 - INFO - __main__ - Step 370 Global step 370 Train loss 0.29 on epoch=92
06/13/2022 08:37:43 - INFO - __main__ - Step 380 Global step 380 Train loss 0.28 on epoch=94
06/13/2022 08:37:46 - INFO - __main__ - Step 390 Global step 390 Train loss 0.32 on epoch=97
06/13/2022 08:37:48 - INFO - __main__ - Step 400 Global step 400 Train loss 0.22 on epoch=99
06/13/2022 08:37:49 - INFO - __main__ - Global step 400 Train loss 0.28 Classification-F1 0.757296494355318 on epoch=99
06/13/2022 08:37:51 - INFO - __main__ - Step 410 Global step 410 Train loss 0.21 on epoch=102
06/13/2022 08:37:54 - INFO - __main__ - Step 420 Global step 420 Train loss 0.21 on epoch=104
06/13/2022 08:37:56 - INFO - __main__ - Step 430 Global step 430 Train loss 0.31 on epoch=107
06/13/2022 08:37:59 - INFO - __main__ - Step 440 Global step 440 Train loss 0.20 on epoch=109
06/13/2022 08:38:01 - INFO - __main__ - Step 450 Global step 450 Train loss 0.32 on epoch=112
06/13/2022 08:38:02 - INFO - __main__ - Global step 450 Train loss 0.25 Classification-F1 0.8096865193639388 on epoch=112
06/13/2022 08:38:02 - INFO - __main__ - Saving model with best Classification-F1: 0.7653439153439153 -> 0.8096865193639388 on epoch=112, global_step=450
06/13/2022 08:38:05 - INFO - __main__ - Step 460 Global step 460 Train loss 0.25 on epoch=114
06/13/2022 08:38:07 - INFO - __main__ - Step 470 Global step 470 Train loss 0.17 on epoch=117
06/13/2022 08:38:10 - INFO - __main__ - Step 480 Global step 480 Train loss 0.17 on epoch=119
06/13/2022 08:38:12 - INFO - __main__ - Step 490 Global step 490 Train loss 0.17 on epoch=122
06/13/2022 08:38:14 - INFO - __main__ - Step 500 Global step 500 Train loss 0.21 on epoch=124
06/13/2022 08:38:16 - INFO - __main__ - Global step 500 Train loss 0.19 Classification-F1 0.7910258379008379 on epoch=124
06/13/2022 08:38:18 - INFO - __main__ - Step 510 Global step 510 Train loss 0.12 on epoch=127
06/13/2022 08:38:20 - INFO - __main__ - Step 520 Global step 520 Train loss 0.14 on epoch=129
06/13/2022 08:38:23 - INFO - __main__ - Step 530 Global step 530 Train loss 0.23 on epoch=132
06/13/2022 08:38:25 - INFO - __main__ - Step 540 Global step 540 Train loss 0.18 on epoch=134
06/13/2022 08:38:28 - INFO - __main__ - Step 550 Global step 550 Train loss 0.15 on epoch=137
06/13/2022 08:38:29 - INFO - __main__ - Global step 550 Train loss 0.16 Classification-F1 0.7726146331738437 on epoch=137
06/13/2022 08:38:31 - INFO - __main__ - Step 560 Global step 560 Train loss 0.17 on epoch=139
06/13/2022 08:38:34 - INFO - __main__ - Step 570 Global step 570 Train loss 0.19 on epoch=142
06/13/2022 08:38:36 - INFO - __main__ - Step 580 Global step 580 Train loss 0.18 on epoch=144
06/13/2022 08:38:39 - INFO - __main__ - Step 590 Global step 590 Train loss 0.15 on epoch=147
06/13/2022 08:38:41 - INFO - __main__ - Step 600 Global step 600 Train loss 0.08 on epoch=149
06/13/2022 08:38:42 - INFO - __main__ - Global step 600 Train loss 0.15 Classification-F1 0.7910258379008379 on epoch=149
06/13/2022 08:38:44 - INFO - __main__ - Step 610 Global step 610 Train loss 0.12 on epoch=152
06/13/2022 08:38:47 - INFO - __main__ - Step 620 Global step 620 Train loss 0.07 on epoch=154
06/13/2022 08:38:49 - INFO - __main__ - Step 630 Global step 630 Train loss 0.12 on epoch=157
06/13/2022 08:38:52 - INFO - __main__ - Step 640 Global step 640 Train loss 0.10 on epoch=159
06/13/2022 08:38:54 - INFO - __main__ - Step 650 Global step 650 Train loss 0.10 on epoch=162
06/13/2022 08:38:55 - INFO - __main__ - Global step 650 Train loss 0.10 Classification-F1 0.7910258379008379 on epoch=162
06/13/2022 08:38:57 - INFO - __main__ - Step 660 Global step 660 Train loss 0.06 on epoch=164
06/13/2022 08:39:00 - INFO - __main__ - Step 670 Global step 670 Train loss 0.08 on epoch=167
06/13/2022 08:39:02 - INFO - __main__ - Step 680 Global step 680 Train loss 0.05 on epoch=169
06/13/2022 08:39:05 - INFO - __main__ - Step 690 Global step 690 Train loss 0.10 on epoch=172
06/13/2022 08:39:07 - INFO - __main__ - Step 700 Global step 700 Train loss 0.08 on epoch=174
06/13/2022 08:39:08 - INFO - __main__ - Global step 700 Train loss 0.07 Classification-F1 0.7419444444444444 on epoch=174
06/13/2022 08:39:10 - INFO - __main__ - Step 710 Global step 710 Train loss 0.11 on epoch=177
06/13/2022 08:39:13 - INFO - __main__ - Step 720 Global step 720 Train loss 0.07 on epoch=179
06/13/2022 08:39:15 - INFO - __main__ - Step 730 Global step 730 Train loss 0.10 on epoch=182
06/13/2022 08:39:18 - INFO - __main__ - Step 740 Global step 740 Train loss 0.04 on epoch=184
06/13/2022 08:39:20 - INFO - __main__ - Step 750 Global step 750 Train loss 0.15 on epoch=187
06/13/2022 08:39:21 - INFO - __main__ - Global step 750 Train loss 0.09 Classification-F1 0.6936499907088143 on epoch=187
06/13/2022 08:39:23 - INFO - __main__ - Step 760 Global step 760 Train loss 0.07 on epoch=189
06/13/2022 08:39:26 - INFO - __main__ - Step 770 Global step 770 Train loss 0.11 on epoch=192
06/13/2022 08:39:28 - INFO - __main__ - Step 780 Global step 780 Train loss 0.06 on epoch=194
06/13/2022 08:39:31 - INFO - __main__ - Step 790 Global step 790 Train loss 0.11 on epoch=197
06/13/2022 08:39:33 - INFO - __main__ - Step 800 Global step 800 Train loss 0.06 on epoch=199
06/13/2022 08:39:34 - INFO - __main__ - Global step 800 Train loss 0.08 Classification-F1 0.7512254901960785 on epoch=199
06/13/2022 08:39:36 - INFO - __main__ - Step 810 Global step 810 Train loss 0.06 on epoch=202
06/13/2022 08:39:39 - INFO - __main__ - Step 820 Global step 820 Train loss 0.12 on epoch=204
06/13/2022 08:39:41 - INFO - __main__ - Step 830 Global step 830 Train loss 0.07 on epoch=207
06/13/2022 08:39:44 - INFO - __main__ - Step 840 Global step 840 Train loss 0.11 on epoch=209
06/13/2022 08:39:46 - INFO - __main__ - Step 850 Global step 850 Train loss 0.06 on epoch=212
06/13/2022 08:39:47 - INFO - __main__ - Global step 850 Train loss 0.08 Classification-F1 0.7520021645021646 on epoch=212
06/13/2022 08:39:50 - INFO - __main__ - Step 860 Global step 860 Train loss 0.06 on epoch=214
06/13/2022 08:39:52 - INFO - __main__ - Step 870 Global step 870 Train loss 0.05 on epoch=217
06/13/2022 08:39:54 - INFO - __main__ - Step 880 Global step 880 Train loss 0.15 on epoch=219
06/13/2022 08:39:57 - INFO - __main__ - Step 890 Global step 890 Train loss 0.04 on epoch=222
06/13/2022 08:39:59 - INFO - __main__ - Step 900 Global step 900 Train loss 0.02 on epoch=224
06/13/2022 08:40:00 - INFO - __main__ - Global step 900 Train loss 0.07 Classification-F1 0.7401220575414124 on epoch=224
06/13/2022 08:40:03 - INFO - __main__ - Step 910 Global step 910 Train loss 0.02 on epoch=227
06/13/2022 08:40:05 - INFO - __main__ - Step 920 Global step 920 Train loss 0.03 on epoch=229
06/13/2022 08:40:07 - INFO - __main__ - Step 930 Global step 930 Train loss 0.04 on epoch=232
06/13/2022 08:40:10 - INFO - __main__ - Step 940 Global step 940 Train loss 0.09 on epoch=234
06/13/2022 08:40:12 - INFO - __main__ - Step 950 Global step 950 Train loss 0.07 on epoch=237
06/13/2022 08:40:13 - INFO - __main__ - Global step 950 Train loss 0.05 Classification-F1 0.7231259968102074 on epoch=237
06/13/2022 08:40:16 - INFO - __main__ - Step 960 Global step 960 Train loss 0.08 on epoch=239
06/13/2022 08:40:18 - INFO - __main__ - Step 970 Global step 970 Train loss 0.09 on epoch=242
06/13/2022 08:40:20 - INFO - __main__ - Step 980 Global step 980 Train loss 0.04 on epoch=244
06/13/2022 08:40:23 - INFO - __main__ - Step 990 Global step 990 Train loss 0.11 on epoch=247
06/13/2022 08:40:25 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.01 on epoch=249
06/13/2022 08:40:26 - INFO - __main__ - Global step 1000 Train loss 0.07 Classification-F1 0.7523989898989899 on epoch=249
06/13/2022 08:40:29 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.07 on epoch=252
06/13/2022 08:40:31 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.06 on epoch=254
06/13/2022 08:40:34 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.02 on epoch=257
06/13/2022 08:40:36 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.06 on epoch=259
06/13/2022 08:40:39 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.02 on epoch=262
06/13/2022 08:40:39 - INFO - __main__ - Global step 1050 Train loss 0.05 Classification-F1 0.7721212121212121 on epoch=262
06/13/2022 08:40:42 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.02 on epoch=264
06/13/2022 08:40:44 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.05 on epoch=267
06/13/2022 08:40:47 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.02 on epoch=269
06/13/2022 08:40:49 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.07 on epoch=272
06/13/2022 08:40:52 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.03 on epoch=274
06/13/2022 08:40:53 - INFO - __main__ - Global step 1100 Train loss 0.04 Classification-F1 0.7419444444444444 on epoch=274
06/13/2022 08:40:55 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.08 on epoch=277
06/13/2022 08:40:58 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.05 on epoch=279
06/13/2022 08:41:00 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.03 on epoch=282
06/13/2022 08:41:02 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.01 on epoch=284
06/13/2022 08:41:05 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.05 on epoch=287
06/13/2022 08:41:06 - INFO - __main__ - Global step 1150 Train loss 0.04 Classification-F1 0.7759289729877966 on epoch=287
06/13/2022 08:41:08 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.06 on epoch=289
06/13/2022 08:41:11 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.04 on epoch=292
06/13/2022 08:41:13 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.02 on epoch=294
06/13/2022 08:41:16 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.02 on epoch=297
06/13/2022 08:41:18 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.08 on epoch=299
06/13/2022 08:41:19 - INFO - __main__ - Global step 1200 Train loss 0.05 Classification-F1 0.7517156862745098 on epoch=299
06/13/2022 08:41:21 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.04 on epoch=302
06/13/2022 08:41:24 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.02 on epoch=304
06/13/2022 08:41:26 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.08 on epoch=307
06/13/2022 08:41:29 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.03 on epoch=309
06/13/2022 08:41:31 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.03 on epoch=312
06/13/2022 08:41:32 - INFO - __main__ - Global step 1250 Train loss 0.04 Classification-F1 0.7759289729877965 on epoch=312
06/13/2022 08:41:35 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.04 on epoch=314
06/13/2022 08:41:37 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.03 on epoch=317
06/13/2022 08:41:40 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.04 on epoch=319
06/13/2022 08:41:42 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=322
06/13/2022 08:41:45 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.02 on epoch=324
06/13/2022 08:41:45 - INFO - __main__ - Global step 1300 Train loss 0.03 Classification-F1 0.7759289729877966 on epoch=324
06/13/2022 08:41:48 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.06 on epoch=327
06/13/2022 08:41:50 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.02 on epoch=329
06/13/2022 08:41:53 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.02 on epoch=332
06/13/2022 08:41:55 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=334
06/13/2022 08:41:58 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.02 on epoch=337
06/13/2022 08:41:58 - INFO - __main__ - Global step 1350 Train loss 0.02 Classification-F1 0.7759289729877966 on epoch=337
06/13/2022 08:42:01 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=339
06/13/2022 08:42:03 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=342
06/13/2022 08:42:06 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=344
06/13/2022 08:42:08 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.03 on epoch=347
06/13/2022 08:42:11 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=349
06/13/2022 08:42:12 - INFO - __main__ - Global step 1400 Train loss 0.02 Classification-F1 0.7759289729877966 on epoch=349
06/13/2022 08:42:14 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.06 on epoch=352
06/13/2022 08:42:17 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=354
06/13/2022 08:42:19 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.04 on epoch=357
06/13/2022 08:42:21 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.03 on epoch=359
06/13/2022 08:42:24 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=362
06/13/2022 08:42:25 - INFO - __main__ - Global step 1450 Train loss 0.04 Classification-F1 0.760576923076923 on epoch=362
06/13/2022 08:42:27 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=364
06/13/2022 08:42:30 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=367
06/13/2022 08:42:32 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.02 on epoch=369
06/13/2022 08:42:35 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.03 on epoch=372
06/13/2022 08:42:37 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=374
06/13/2022 08:42:38 - INFO - __main__ - Global step 1500 Train loss 0.01 Classification-F1 0.7518337187454835 on epoch=374
06/13/2022 08:42:41 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.03 on epoch=377
06/13/2022 08:42:43 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=379
06/13/2022 08:42:45 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.06 on epoch=382
06/13/2022 08:42:48 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=384
06/13/2022 08:42:50 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.09 on epoch=387
06/13/2022 08:42:51 - INFO - __main__ - Global step 1550 Train loss 0.04 Classification-F1 0.7721212121212121 on epoch=387
06/13/2022 08:42:54 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.02 on epoch=389
06/13/2022 08:42:56 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=392
06/13/2022 08:42:59 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=394
06/13/2022 08:43:01 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=397
06/13/2022 08:43:03 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.04 on epoch=399
06/13/2022 08:43:04 - INFO - __main__ - Global step 1600 Train loss 0.02 Classification-F1 0.71495566712958 on epoch=399
06/13/2022 08:43:07 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=402
06/13/2022 08:43:09 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.05 on epoch=404
06/13/2022 08:43:12 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.02 on epoch=407
06/13/2022 08:43:14 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=409
06/13/2022 08:43:16 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=412
06/13/2022 08:43:17 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.757296494355318 on epoch=412
06/13/2022 08:43:20 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=414
06/13/2022 08:43:22 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=417
06/13/2022 08:43:25 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=419
06/13/2022 08:43:27 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.06 on epoch=422
06/13/2022 08:43:29 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=424
06/13/2022 08:43:30 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.8060426093514329 on epoch=424
06/13/2022 08:43:33 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=427
06/13/2022 08:43:35 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.06 on epoch=429
06/13/2022 08:43:38 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=432
06/13/2022 08:43:40 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=434
06/13/2022 08:43:43 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=437
06/13/2022 08:43:44 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.760903720462544 on epoch=437
06/13/2022 08:43:46 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.22 on epoch=439
06/13/2022 08:43:48 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=442
06/13/2022 08:43:51 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=444
06/13/2022 08:43:53 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=447
06/13/2022 08:43:56 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=449
06/13/2022 08:43:57 - INFO - __main__ - Global step 1800 Train loss 0.05 Classification-F1 0.7905011655011656 on epoch=449
06/13/2022 08:43:59 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=452
06/13/2022 08:44:02 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=454
06/13/2022 08:44:04 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=457
06/13/2022 08:44:06 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=459
06/13/2022 08:44:09 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.04 on epoch=462
06/13/2022 08:44:10 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.7717936117936118 on epoch=462
06/13/2022 08:44:12 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=464
06/13/2022 08:44:15 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=467
06/13/2022 08:44:17 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=469
06/13/2022 08:44:20 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=472
06/13/2022 08:44:22 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=474
06/13/2022 08:44:23 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.7558333333333334 on epoch=474
06/13/2022 08:44:25 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=477
06/13/2022 08:44:28 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=479
06/13/2022 08:44:30 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=482
06/13/2022 08:44:33 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=484
06/13/2022 08:44:35 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=487
06/13/2022 08:44:36 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.7747926093514329 on epoch=487
06/13/2022 08:44:39 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=489
06/13/2022 08:44:41 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=492
06/13/2022 08:44:44 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=494
06/13/2022 08:44:46 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=497
06/13/2022 08:44:48 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=499
06/13/2022 08:44:49 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.7905011655011656 on epoch=499
06/13/2022 08:44:52 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=502
06/13/2022 08:44:54 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
06/13/2022 08:44:57 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.04 on epoch=507
06/13/2022 08:44:59 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=509
06/13/2022 08:45:01 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/13/2022 08:45:02 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.8060426093514329 on epoch=512
06/13/2022 08:45:05 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.06 on epoch=514
06/13/2022 08:45:07 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=517
06/13/2022 08:45:10 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=519
06/13/2022 08:45:12 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/13/2022 08:45:15 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/13/2022 08:45:15 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.7725961538461539 on epoch=524
06/13/2022 08:45:18 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
06/13/2022 08:45:20 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.07 on epoch=529
06/13/2022 08:45:23 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/13/2022 08:45:25 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
06/13/2022 08:45:28 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.04 on epoch=537
06/13/2022 08:45:29 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.8060426093514329 on epoch=537
06/13/2022 08:45:31 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=539
06/13/2022 08:45:33 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=542
06/13/2022 08:45:36 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=544
06/13/2022 08:45:38 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/13/2022 08:45:41 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/13/2022 08:45:42 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.7512254901960785 on epoch=549
06/13/2022 08:45:44 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=552
06/13/2022 08:45:47 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/13/2022 08:45:49 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=557
06/13/2022 08:45:52 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=559
06/13/2022 08:45:54 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/13/2022 08:45:55 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.7225225225225225 on epoch=562
06/13/2022 08:45:57 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.05 on epoch=564
06/13/2022 08:46:00 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=567
06/13/2022 08:46:02 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/13/2022 08:46:05 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/13/2022 08:46:07 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/13/2022 08:46:08 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.760576923076923 on epoch=574
06/13/2022 08:46:11 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/13/2022 08:46:13 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/13/2022 08:46:16 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=582
06/13/2022 08:46:18 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/13/2022 08:46:20 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=587
06/13/2022 08:46:21 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.7560850556438793 on epoch=587
06/13/2022 08:46:24 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=589
06/13/2022 08:46:26 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/13/2022 08:46:28 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/13/2022 08:46:31 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=597
06/13/2022 08:46:33 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/13/2022 08:46:34 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.7717936117936118 on epoch=599
06/13/2022 08:46:36 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/13/2022 08:46:39 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=604
06/13/2022 08:46:41 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.05 on epoch=607
06/13/2022 08:46:44 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=609
06/13/2022 08:46:46 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=612
06/13/2022 08:46:47 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.7717936117936118 on epoch=612
06/13/2022 08:46:49 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/13/2022 08:46:52 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/13/2022 08:46:54 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=619
06/13/2022 08:46:57 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=622
06/13/2022 08:46:59 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/13/2022 08:47:00 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.7711853832442068 on epoch=624
06/13/2022 08:47:02 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/13/2022 08:47:05 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/13/2022 08:47:07 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=632
06/13/2022 08:47:10 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=634
06/13/2022 08:47:12 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/13/2022 08:47:13 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.7717936117936118 on epoch=637
06/13/2022 08:47:15 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/13/2022 08:47:18 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=642
06/13/2022 08:47:20 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/13/2022 08:47:23 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/13/2022 08:47:25 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=649
06/13/2022 08:47:26 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.7717936117936118 on epoch=649
06/13/2022 08:47:28 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/13/2022 08:47:31 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=654
06/13/2022 08:47:33 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=657
06/13/2022 08:47:36 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=659
06/13/2022 08:47:38 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/13/2022 08:47:39 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.7910876757650951 on epoch=662
06/13/2022 08:47:42 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/13/2022 08:47:44 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/13/2022 08:47:46 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/13/2022 08:47:49 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=672
06/13/2022 08:47:51 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=674
06/13/2022 08:47:52 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.7717936117936118 on epoch=674
06/13/2022 08:47:55 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=677
06/13/2022 08:47:57 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/13/2022 08:48:00 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/13/2022 08:48:02 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/13/2022 08:48:05 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=687
06/13/2022 08:48:05 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.7905011655011656 on epoch=687
06/13/2022 08:48:08 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/13/2022 08:48:10 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/13/2022 08:48:13 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=694
06/13/2022 08:48:15 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=697
06/13/2022 08:48:18 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=699
06/13/2022 08:48:19 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.7905011655011656 on epoch=699
06/13/2022 08:48:21 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/13/2022 08:48:23 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=704
06/13/2022 08:48:26 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.06 on epoch=707
06/13/2022 08:48:28 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.07 on epoch=709
06/13/2022 08:48:31 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/13/2022 08:48:32 - INFO - __main__ - Global step 2850 Train loss 0.03 Classification-F1 0.7518337187454835 on epoch=712
06/13/2022 08:48:34 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/13/2022 08:48:37 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=717
06/13/2022 08:48:39 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=719
06/13/2022 08:48:41 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/13/2022 08:48:44 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/13/2022 08:48:45 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.7518337187454835 on epoch=724
06/13/2022 08:48:47 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/13/2022 08:48:50 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/13/2022 08:48:52 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.03 on epoch=732
06/13/2022 08:48:55 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/13/2022 08:48:57 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/13/2022 08:48:58 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.7419444444444444 on epoch=737
06/13/2022 08:49:01 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/13/2022 08:49:03 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/13/2022 08:49:05 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/13/2022 08:49:08 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/13/2022 08:49:10 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=749
06/13/2022 08:49:11 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.7905011655011656 on epoch=749
06/13/2022 08:49:11 - INFO - __main__ - save last model!
06/13/2022 08:49:11 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/13/2022 08:49:11 - INFO - __main__ - Start tokenizing ... 5509 instances
06/13/2022 08:49:11 - INFO - __main__ - Printing 3 examples
06/13/2022 08:49:11 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/13/2022 08:49:11 - INFO - __main__ - ['others']
06/13/2022 08:49:11 - INFO - __main__ -  [emo] what you like very little things ok
06/13/2022 08:49:11 - INFO - __main__ - ['others']
06/13/2022 08:49:11 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/13/2022 08:49:11 - INFO - __main__ - ['others']
06/13/2022 08:49:11 - INFO - __main__ - Tokenizing Input ...
06/13/2022 08:49:12 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 08:49:12 - INFO - __main__ - Printing 3 examples
06/13/2022 08:49:12 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/13/2022 08:49:12 - INFO - __main__ - ['others']
06/13/2022 08:49:12 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/13/2022 08:49:12 - INFO - __main__ - ['others']
06/13/2022 08:49:12 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/13/2022 08:49:12 - INFO - __main__ - ['others']
06/13/2022 08:49:12 - INFO - __main__ - Tokenizing Input ...
06/13/2022 08:49:12 - INFO - __main__ - Tokenizing Output ...
06/13/2022 08:49:12 - INFO - __main__ - Loaded 64 examples from train data
06/13/2022 08:49:12 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 08:49:12 - INFO - __main__ - Printing 3 examples
06/13/2022 08:49:12 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
06/13/2022 08:49:12 - INFO - __main__ - ['others']
06/13/2022 08:49:12 - INFO - __main__ -  [emo] i did ask now you did tell ms
06/13/2022 08:49:12 - INFO - __main__ - ['others']
06/13/2022 08:49:12 - INFO - __main__ -  [emo] buddy how you tell me your contact no
06/13/2022 08:49:12 - INFO - __main__ - ['others']
06/13/2022 08:49:12 - INFO - __main__ - Tokenizing Input ...
06/13/2022 08:49:12 - INFO - __main__ - Tokenizing Output ...
06/13/2022 08:49:12 - INFO - __main__ - Loaded 64 examples from dev data
06/13/2022 08:49:13 - INFO - __main__ - Tokenizing Output ...
06/13/2022 08:49:19 - INFO - __main__ - Loaded 5509 examples from test data
06/13/2022 08:49:27 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 08:49:27 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 08:49:28 - INFO - __main__ - Starting training!
06/13/2022 08:50:40 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-up32shot/singletask-emo/emo_16_13_0.4_8_predictions.txt
06/13/2022 08:50:40 - INFO - __main__ - Classification-F1 on test data: 0.2692
06/13/2022 08:50:40 - INFO - __main__ - prefix=emo_16_13, lr=0.4, bsz=8, dev_performance=0.8096865193639388, test_performance=0.2691938086849133
06/13/2022 08:50:40 - INFO - __main__ - Running ... prefix=emo_16_13, lr=0.3, bsz=8 ...
06/13/2022 08:50:41 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 08:50:41 - INFO - __main__ - Printing 3 examples
06/13/2022 08:50:41 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/13/2022 08:50:41 - INFO - __main__ - ['others']
06/13/2022 08:50:41 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/13/2022 08:50:41 - INFO - __main__ - ['others']
06/13/2022 08:50:41 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/13/2022 08:50:41 - INFO - __main__ - ['others']
06/13/2022 08:50:41 - INFO - __main__ - Tokenizing Input ...
06/13/2022 08:50:41 - INFO - __main__ - Tokenizing Output ...
06/13/2022 08:50:41 - INFO - __main__ - Loaded 64 examples from train data
06/13/2022 08:50:41 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 08:50:41 - INFO - __main__ - Printing 3 examples
06/13/2022 08:50:41 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
06/13/2022 08:50:41 - INFO - __main__ - ['others']
06/13/2022 08:50:41 - INFO - __main__ -  [emo] i did ask now you did tell ms
06/13/2022 08:50:41 - INFO - __main__ - ['others']
06/13/2022 08:50:41 - INFO - __main__ -  [emo] buddy how you tell me your contact no
06/13/2022 08:50:41 - INFO - __main__ - ['others']
06/13/2022 08:50:41 - INFO - __main__ - Tokenizing Input ...
06/13/2022 08:50:41 - INFO - __main__ - Tokenizing Output ...
06/13/2022 08:50:41 - INFO - __main__ - Loaded 64 examples from dev data
06/13/2022 08:50:56 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 08:50:57 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 08:50:57 - INFO - __main__ - Starting training!
06/13/2022 08:51:00 - INFO - __main__ - Step 10 Global step 10 Train loss 3.88 on epoch=2
06/13/2022 08:51:02 - INFO - __main__ - Step 20 Global step 20 Train loss 2.73 on epoch=4
06/13/2022 08:51:05 - INFO - __main__ - Step 30 Global step 30 Train loss 2.22 on epoch=7
06/13/2022 08:51:07 - INFO - __main__ - Step 40 Global step 40 Train loss 1.80 on epoch=9
06/13/2022 08:51:09 - INFO - __main__ - Step 50 Global step 50 Train loss 1.54 on epoch=12
06/13/2022 08:51:10 - INFO - __main__ - Global step 50 Train loss 2.44 Classification-F1 0.09912390488110137 on epoch=12
06/13/2022 08:51:10 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.09912390488110137 on epoch=12, global_step=50
06/13/2022 08:51:13 - INFO - __main__ - Step 60 Global step 60 Train loss 1.16 on epoch=14
06/13/2022 08:51:15 - INFO - __main__ - Step 70 Global step 70 Train loss 1.08 on epoch=17
06/13/2022 08:51:18 - INFO - __main__ - Step 80 Global step 80 Train loss 0.77 on epoch=19
06/13/2022 08:51:20 - INFO - __main__ - Step 90 Global step 90 Train loss 0.69 on epoch=22
06/13/2022 08:51:23 - INFO - __main__ - Step 100 Global step 100 Train loss 0.74 on epoch=24
06/13/2022 08:51:23 - INFO - __main__ - Global step 100 Train loss 0.89 Classification-F1 0.4939542483660131 on epoch=24
06/13/2022 08:51:23 - INFO - __main__ - Saving model with best Classification-F1: 0.09912390488110137 -> 0.4939542483660131 on epoch=24, global_step=100
06/13/2022 08:51:26 - INFO - __main__ - Step 110 Global step 110 Train loss 0.69 on epoch=27
06/13/2022 08:51:28 - INFO - __main__ - Step 120 Global step 120 Train loss 0.61 on epoch=29
06/13/2022 08:51:31 - INFO - __main__ - Step 130 Global step 130 Train loss 0.66 on epoch=32
06/13/2022 08:51:33 - INFO - __main__ - Step 140 Global step 140 Train loss 0.59 on epoch=34
06/13/2022 08:51:35 - INFO - __main__ - Step 150 Global step 150 Train loss 0.67 on epoch=37
06/13/2022 08:51:36 - INFO - __main__ - Global step 150 Train loss 0.64 Classification-F1 0.6092930742141646 on epoch=37
06/13/2022 08:51:36 - INFO - __main__ - Saving model with best Classification-F1: 0.4939542483660131 -> 0.6092930742141646 on epoch=37, global_step=150
06/13/2022 08:51:39 - INFO - __main__ - Step 160 Global step 160 Train loss 0.54 on epoch=39
06/13/2022 08:51:41 - INFO - __main__ - Step 170 Global step 170 Train loss 0.60 on epoch=42
06/13/2022 08:51:44 - INFO - __main__ - Step 180 Global step 180 Train loss 0.58 on epoch=44
06/13/2022 08:51:46 - INFO - __main__ - Step 190 Global step 190 Train loss 0.56 on epoch=47
06/13/2022 08:51:48 - INFO - __main__ - Step 200 Global step 200 Train loss 0.51 on epoch=49
06/13/2022 08:51:49 - INFO - __main__ - Global step 200 Train loss 0.56 Classification-F1 0.573773397457608 on epoch=49
06/13/2022 08:51:52 - INFO - __main__ - Step 210 Global step 210 Train loss 0.50 on epoch=52
06/13/2022 08:51:54 - INFO - __main__ - Step 220 Global step 220 Train loss 0.51 on epoch=54
06/13/2022 08:51:56 - INFO - __main__ - Step 230 Global step 230 Train loss 0.54 on epoch=57
06/13/2022 08:51:59 - INFO - __main__ - Step 240 Global step 240 Train loss 0.49 on epoch=59
06/13/2022 08:52:01 - INFO - __main__ - Step 250 Global step 250 Train loss 0.46 on epoch=62
06/13/2022 08:52:02 - INFO - __main__ - Global step 250 Train loss 0.50 Classification-F1 0.6277777777777778 on epoch=62
06/13/2022 08:52:02 - INFO - __main__ - Saving model with best Classification-F1: 0.6092930742141646 -> 0.6277777777777778 on epoch=62, global_step=250
06/13/2022 08:52:05 - INFO - __main__ - Step 260 Global step 260 Train loss 0.45 on epoch=64
06/13/2022 08:52:07 - INFO - __main__ - Step 270 Global step 270 Train loss 0.43 on epoch=67
06/13/2022 08:52:09 - INFO - __main__ - Step 280 Global step 280 Train loss 0.45 on epoch=69
06/13/2022 08:52:12 - INFO - __main__ - Step 290 Global step 290 Train loss 0.41 on epoch=72
06/13/2022 08:52:14 - INFO - __main__ - Step 300 Global step 300 Train loss 0.43 on epoch=74
06/13/2022 08:52:15 - INFO - __main__ - Global step 300 Train loss 0.43 Classification-F1 0.5889859784596627 on epoch=74
06/13/2022 08:52:18 - INFO - __main__ - Step 310 Global step 310 Train loss 0.38 on epoch=77
06/13/2022 08:52:20 - INFO - __main__ - Step 320 Global step 320 Train loss 0.39 on epoch=79
06/13/2022 08:52:22 - INFO - __main__ - Step 330 Global step 330 Train loss 0.44 on epoch=82
06/13/2022 08:52:25 - INFO - __main__ - Step 340 Global step 340 Train loss 0.36 on epoch=84
06/13/2022 08:52:27 - INFO - __main__ - Step 350 Global step 350 Train loss 0.37 on epoch=87
06/13/2022 08:52:28 - INFO - __main__ - Global step 350 Train loss 0.39 Classification-F1 0.6992899584076055 on epoch=87
06/13/2022 08:52:28 - INFO - __main__ - Saving model with best Classification-F1: 0.6277777777777778 -> 0.6992899584076055 on epoch=87, global_step=350
06/13/2022 08:52:31 - INFO - __main__ - Step 360 Global step 360 Train loss 0.31 on epoch=89
06/13/2022 08:52:33 - INFO - __main__ - Step 370 Global step 370 Train loss 0.37 on epoch=92
06/13/2022 08:52:35 - INFO - __main__ - Step 380 Global step 380 Train loss 0.35 on epoch=94
06/13/2022 08:52:38 - INFO - __main__ - Step 390 Global step 390 Train loss 0.47 on epoch=97
06/13/2022 08:52:40 - INFO - __main__ - Step 400 Global step 400 Train loss 0.38 on epoch=99
06/13/2022 08:52:41 - INFO - __main__ - Global step 400 Train loss 0.38 Classification-F1 0.7096551765669413 on epoch=99
06/13/2022 08:52:41 - INFO - __main__ - Saving model with best Classification-F1: 0.6992899584076055 -> 0.7096551765669413 on epoch=99, global_step=400
06/13/2022 08:52:43 - INFO - __main__ - Step 410 Global step 410 Train loss 0.32 on epoch=102
06/13/2022 08:52:46 - INFO - __main__ - Step 420 Global step 420 Train loss 0.35 on epoch=104
06/13/2022 08:52:48 - INFO - __main__ - Step 430 Global step 430 Train loss 0.39 on epoch=107
06/13/2022 08:52:51 - INFO - __main__ - Step 440 Global step 440 Train loss 0.27 on epoch=109
06/13/2022 08:52:53 - INFO - __main__ - Step 450 Global step 450 Train loss 0.25 on epoch=112
06/13/2022 08:52:54 - INFO - __main__ - Global step 450 Train loss 0.32 Classification-F1 0.7427375762859634 on epoch=112
06/13/2022 08:52:54 - INFO - __main__ - Saving model with best Classification-F1: 0.7096551765669413 -> 0.7427375762859634 on epoch=112, global_step=450
06/13/2022 08:52:56 - INFO - __main__ - Step 460 Global step 460 Train loss 0.30 on epoch=114
06/13/2022 08:52:59 - INFO - __main__ - Step 470 Global step 470 Train loss 0.27 on epoch=117
06/13/2022 08:53:01 - INFO - __main__ - Step 480 Global step 480 Train loss 0.30 on epoch=119
06/13/2022 08:53:04 - INFO - __main__ - Step 490 Global step 490 Train loss 0.22 on epoch=122
06/13/2022 08:53:06 - INFO - __main__ - Step 500 Global step 500 Train loss 0.35 on epoch=124
06/13/2022 08:53:07 - INFO - __main__ - Global step 500 Train loss 0.29 Classification-F1 0.7951894019256448 on epoch=124
06/13/2022 08:53:07 - INFO - __main__ - Saving model with best Classification-F1: 0.7427375762859634 -> 0.7951894019256448 on epoch=124, global_step=500
06/13/2022 08:53:09 - INFO - __main__ - Step 510 Global step 510 Train loss 0.30 on epoch=127
06/13/2022 08:53:12 - INFO - __main__ - Step 520 Global step 520 Train loss 0.22 on epoch=129
06/13/2022 08:53:14 - INFO - __main__ - Step 530 Global step 530 Train loss 0.33 on epoch=132
06/13/2022 08:53:17 - INFO - __main__ - Step 540 Global step 540 Train loss 0.30 on epoch=134
06/13/2022 08:53:19 - INFO - __main__ - Step 550 Global step 550 Train loss 0.28 on epoch=137
06/13/2022 08:53:20 - INFO - __main__ - Global step 550 Train loss 0.29 Classification-F1 0.7922439756056054 on epoch=137
06/13/2022 08:53:22 - INFO - __main__ - Step 560 Global step 560 Train loss 0.20 on epoch=139
06/13/2022 08:53:25 - INFO - __main__ - Step 570 Global step 570 Train loss 0.22 on epoch=142
06/13/2022 08:53:27 - INFO - __main__ - Step 580 Global step 580 Train loss 0.25 on epoch=144
06/13/2022 08:53:30 - INFO - __main__ - Step 590 Global step 590 Train loss 0.25 on epoch=147
06/13/2022 08:53:32 - INFO - __main__ - Step 600 Global step 600 Train loss 0.23 on epoch=149
06/13/2022 08:53:33 - INFO - __main__ - Global step 600 Train loss 0.23 Classification-F1 0.7763276970707312 on epoch=149
06/13/2022 08:53:35 - INFO - __main__ - Step 610 Global step 610 Train loss 0.21 on epoch=152
06/13/2022 08:53:38 - INFO - __main__ - Step 620 Global step 620 Train loss 0.16 on epoch=154
06/13/2022 08:53:40 - INFO - __main__ - Step 630 Global step 630 Train loss 0.20 on epoch=157
06/13/2022 08:53:43 - INFO - __main__ - Step 640 Global step 640 Train loss 0.19 on epoch=159
06/13/2022 08:53:45 - INFO - __main__ - Step 650 Global step 650 Train loss 0.25 on epoch=162
06/13/2022 08:53:46 - INFO - __main__ - Global step 650 Train loss 0.20 Classification-F1 0.7922439756056054 on epoch=162
06/13/2022 08:53:48 - INFO - __main__ - Step 660 Global step 660 Train loss 0.21 on epoch=164
06/13/2022 08:53:51 - INFO - __main__ - Step 670 Global step 670 Train loss 0.17 on epoch=167
06/13/2022 08:53:53 - INFO - __main__ - Step 680 Global step 680 Train loss 0.16 on epoch=169
06/13/2022 08:53:56 - INFO - __main__ - Step 690 Global step 690 Train loss 0.19 on epoch=172
06/13/2022 08:53:58 - INFO - __main__ - Step 700 Global step 700 Train loss 0.13 on epoch=174
06/13/2022 08:53:59 - INFO - __main__ - Global step 700 Train loss 0.17 Classification-F1 0.7463657291243497 on epoch=174
06/13/2022 08:54:02 - INFO - __main__ - Step 710 Global step 710 Train loss 0.16 on epoch=177
06/13/2022 08:54:04 - INFO - __main__ - Step 720 Global step 720 Train loss 0.17 on epoch=179
06/13/2022 08:54:06 - INFO - __main__ - Step 730 Global step 730 Train loss 0.15 on epoch=182
06/13/2022 08:54:09 - INFO - __main__ - Step 740 Global step 740 Train loss 0.13 on epoch=184
06/13/2022 08:54:11 - INFO - __main__ - Step 750 Global step 750 Train loss 0.13 on epoch=187
06/13/2022 08:54:12 - INFO - __main__ - Global step 750 Train loss 0.15 Classification-F1 0.7365841073271414 on epoch=187
06/13/2022 08:54:15 - INFO - __main__ - Step 760 Global step 760 Train loss 0.16 on epoch=189
06/13/2022 08:54:17 - INFO - __main__ - Step 770 Global step 770 Train loss 0.13 on epoch=192
06/13/2022 08:54:19 - INFO - __main__ - Step 780 Global step 780 Train loss 0.08 on epoch=194
06/13/2022 08:54:22 - INFO - __main__ - Step 790 Global step 790 Train loss 0.11 on epoch=197
06/13/2022 08:54:24 - INFO - __main__ - Step 800 Global step 800 Train loss 0.13 on epoch=199
06/13/2022 08:54:25 - INFO - __main__ - Global step 800 Train loss 0.12 Classification-F1 0.7225225225225225 on epoch=199
06/13/2022 08:54:28 - INFO - __main__ - Step 810 Global step 810 Train loss 0.16 on epoch=202
06/13/2022 08:54:30 - INFO - __main__ - Step 820 Global step 820 Train loss 0.12 on epoch=204
06/13/2022 08:54:33 - INFO - __main__ - Step 830 Global step 830 Train loss 0.14 on epoch=207
06/13/2022 08:54:35 - INFO - __main__ - Step 840 Global step 840 Train loss 0.14 on epoch=209
06/13/2022 08:54:37 - INFO - __main__ - Step 850 Global step 850 Train loss 0.11 on epoch=212
06/13/2022 08:54:38 - INFO - __main__ - Global step 850 Train loss 0.14 Classification-F1 0.7910258379008379 on epoch=212
06/13/2022 08:54:41 - INFO - __main__ - Step 860 Global step 860 Train loss 0.08 on epoch=214
06/13/2022 08:54:43 - INFO - __main__ - Step 870 Global step 870 Train loss 0.09 on epoch=217
06/13/2022 08:54:46 - INFO - __main__ - Step 880 Global step 880 Train loss 0.10 on epoch=219
06/13/2022 08:54:48 - INFO - __main__ - Step 890 Global step 890 Train loss 0.08 on epoch=222
06/13/2022 08:54:50 - INFO - __main__ - Step 900 Global step 900 Train loss 0.13 on epoch=224
06/13/2022 08:54:51 - INFO - __main__ - Global step 900 Train loss 0.09 Classification-F1 0.7230153540637412 on epoch=224
06/13/2022 08:54:54 - INFO - __main__ - Step 910 Global step 910 Train loss 0.07 on epoch=227
06/13/2022 08:54:56 - INFO - __main__ - Step 920 Global step 920 Train loss 0.11 on epoch=229
06/13/2022 08:54:59 - INFO - __main__ - Step 930 Global step 930 Train loss 0.06 on epoch=232
06/13/2022 08:55:01 - INFO - __main__ - Step 940 Global step 940 Train loss 0.07 on epoch=234
06/13/2022 08:55:03 - INFO - __main__ - Step 950 Global step 950 Train loss 0.09 on epoch=237
06/13/2022 08:55:04 - INFO - __main__ - Global step 950 Train loss 0.08 Classification-F1 0.7230153540637412 on epoch=237
06/13/2022 08:55:07 - INFO - __main__ - Step 960 Global step 960 Train loss 0.12 on epoch=239
06/13/2022 08:55:09 - INFO - __main__ - Step 970 Global step 970 Train loss 0.06 on epoch=242
06/13/2022 08:55:12 - INFO - __main__ - Step 980 Global step 980 Train loss 0.12 on epoch=244
06/13/2022 08:55:14 - INFO - __main__ - Step 990 Global step 990 Train loss 0.09 on epoch=247
06/13/2022 08:55:17 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.03 on epoch=249
06/13/2022 08:55:17 - INFO - __main__ - Global step 1000 Train loss 0.08 Classification-F1 0.7227731092436975 on epoch=249
06/13/2022 08:55:20 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.09 on epoch=252
06/13/2022 08:55:22 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.07 on epoch=254
06/13/2022 08:55:25 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.07 on epoch=257
06/13/2022 08:55:27 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.03 on epoch=259
06/13/2022 08:55:30 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.10 on epoch=262
06/13/2022 08:55:31 - INFO - __main__ - Global step 1050 Train loss 0.07 Classification-F1 0.737874572433396 on epoch=262
06/13/2022 08:55:33 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.05 on epoch=264
06/13/2022 08:55:35 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.04 on epoch=267
06/13/2022 08:55:38 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.06 on epoch=269
06/13/2022 08:55:40 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.04 on epoch=272
06/13/2022 08:55:43 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.03 on epoch=274
06/13/2022 08:55:44 - INFO - __main__ - Global step 1100 Train loss 0.04 Classification-F1 0.694422191481015 on epoch=274
06/13/2022 08:55:46 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.04 on epoch=277
06/13/2022 08:55:48 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.04 on epoch=279
06/13/2022 08:55:51 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.07 on epoch=282
06/13/2022 08:55:53 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.02 on epoch=284
06/13/2022 08:55:56 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.04 on epoch=287
06/13/2022 08:55:57 - INFO - __main__ - Global step 1150 Train loss 0.04 Classification-F1 0.7160556976413752 on epoch=287
06/13/2022 08:55:59 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.03 on epoch=289
06/13/2022 08:56:01 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.05 on epoch=292
06/13/2022 08:56:04 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.06 on epoch=294
06/13/2022 08:56:06 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.03 on epoch=297
06/13/2022 08:56:09 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.07 on epoch=299
06/13/2022 08:56:10 - INFO - __main__ - Global step 1200 Train loss 0.05 Classification-F1 0.7941925381263616 on epoch=299
06/13/2022 08:56:12 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.03 on epoch=302
06/13/2022 08:56:14 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.03 on epoch=304
06/13/2022 08:56:17 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.03 on epoch=307
06/13/2022 08:56:19 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=309
06/13/2022 08:56:22 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.04 on epoch=312
06/13/2022 08:56:23 - INFO - __main__ - Global step 1250 Train loss 0.03 Classification-F1 0.7941925381263616 on epoch=312
06/13/2022 08:56:25 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.05 on epoch=314
06/13/2022 08:56:27 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.09 on epoch=317
06/13/2022 08:56:30 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.02 on epoch=319
06/13/2022 08:56:32 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=322
06/13/2022 08:56:35 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.02 on epoch=324
06/13/2022 08:56:35 - INFO - __main__ - Global step 1300 Train loss 0.04 Classification-F1 0.7765287204625441 on epoch=324
06/13/2022 08:56:38 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.03 on epoch=327
06/13/2022 08:56:40 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.02 on epoch=329
06/13/2022 08:56:43 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.02 on epoch=332
06/13/2022 08:56:45 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.05 on epoch=334
06/13/2022 08:56:48 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.09 on epoch=337
06/13/2022 08:56:48 - INFO - __main__ - Global step 1350 Train loss 0.04 Classification-F1 0.7808316430020283 on epoch=337
06/13/2022 08:56:51 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=339
06/13/2022 08:56:53 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.04 on epoch=342
06/13/2022 08:56:56 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.02 on epoch=344
06/13/2022 08:56:58 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.02 on epoch=347
06/13/2022 08:57:01 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.06 on epoch=349
06/13/2022 08:57:02 - INFO - __main__ - Global step 1400 Train loss 0.03 Classification-F1 0.7177703089244851 on epoch=349
06/13/2022 08:57:04 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.03 on epoch=352
06/13/2022 08:57:06 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=354
06/13/2022 08:57:09 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=357
06/13/2022 08:57:11 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.07 on epoch=359
06/13/2022 08:57:14 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.05 on epoch=362
06/13/2022 08:57:15 - INFO - __main__ - Global step 1450 Train loss 0.04 Classification-F1 0.7941925381263616 on epoch=362
06/13/2022 08:57:17 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.02 on epoch=364
06/13/2022 08:57:20 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.02 on epoch=367
06/13/2022 08:57:22 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.06 on epoch=369
06/13/2022 08:57:24 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.04 on epoch=372
06/13/2022 08:57:27 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.03 on epoch=374
06/13/2022 08:57:28 - INFO - __main__ - Global step 1500 Train loss 0.03 Classification-F1 0.7424372759856631 on epoch=374
06/13/2022 08:57:30 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=377
06/13/2022 08:57:33 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.07 on epoch=379
06/13/2022 08:57:35 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=382
06/13/2022 08:57:37 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=384
06/13/2022 08:57:40 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.04 on epoch=387
06/13/2022 08:57:41 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.7941925381263616 on epoch=387
06/13/2022 08:57:43 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.05 on epoch=389
06/13/2022 08:57:46 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.08 on epoch=392
06/13/2022 08:57:48 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.04 on epoch=394
06/13/2022 08:57:51 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.02 on epoch=397
06/13/2022 08:57:53 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=399
06/13/2022 08:57:54 - INFO - __main__ - Global step 1600 Train loss 0.04 Classification-F1 0.7759289729877966 on epoch=399
06/13/2022 08:57:56 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=402
06/13/2022 08:57:59 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.06 on epoch=404
06/13/2022 08:58:01 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=407
06/13/2022 08:58:04 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.02 on epoch=409
06/13/2022 08:58:06 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.07 on epoch=412
06/13/2022 08:58:07 - INFO - __main__ - Global step 1650 Train loss 0.03 Classification-F1 0.776201923076923 on epoch=412
06/13/2022 08:58:10 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=414
06/13/2022 08:58:12 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.06 on epoch=417
06/13/2022 08:58:14 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=419
06/13/2022 08:58:17 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.10 on epoch=422
06/13/2022 08:58:19 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=424
06/13/2022 08:58:20 - INFO - __main__ - Global step 1700 Train loss 0.04 Classification-F1 0.7941925381263616 on epoch=424
06/13/2022 08:58:23 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=427
06/13/2022 08:58:25 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.04 on epoch=429
06/13/2022 08:58:27 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=432
06/13/2022 08:58:30 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=434
06/13/2022 08:58:32 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=437
06/13/2022 08:58:33 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.7765287204625441 on epoch=437
06/13/2022 08:58:36 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=439
06/13/2022 08:58:38 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=442
06/13/2022 08:58:40 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=444
06/13/2022 08:58:43 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=447
06/13/2022 08:58:45 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=449
06/13/2022 08:58:46 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.7575694444444444 on epoch=449
06/13/2022 08:58:49 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.04 on epoch=452
06/13/2022 08:58:51 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.04 on epoch=454
06/13/2022 08:58:53 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=457
06/13/2022 08:58:56 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=459
06/13/2022 08:58:58 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=462
06/13/2022 08:58:59 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.7941925381263616 on epoch=462
06/13/2022 08:59:02 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.04 on epoch=464
06/13/2022 08:59:04 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=467
06/13/2022 08:59:06 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=469
06/13/2022 08:59:09 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=472
06/13/2022 08:59:11 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.04 on epoch=474
06/13/2022 08:59:12 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.7941925381263616 on epoch=474
06/13/2022 08:59:15 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=477
06/13/2022 08:59:17 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=479
06/13/2022 08:59:20 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.04 on epoch=482
06/13/2022 08:59:22 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=484
06/13/2022 08:59:24 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=487
06/13/2022 08:59:25 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.7610697546181417 on epoch=487
06/13/2022 08:59:28 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=489
06/13/2022 08:59:30 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=492
06/13/2022 08:59:32 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=494
06/13/2022 08:59:35 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=497
06/13/2022 08:59:37 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=499
06/13/2022 08:59:38 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.756969696969697 on epoch=499
06/13/2022 08:59:41 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=502
06/13/2022 08:59:43 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=504
06/13/2022 08:59:46 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/13/2022 08:59:48 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=509
06/13/2022 08:59:50 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/13/2022 08:59:51 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.771764705882353 on epoch=512
06/13/2022 08:59:54 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=514
06/13/2022 08:59:56 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.03 on epoch=517
06/13/2022 08:59:59 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=519
06/13/2022 09:00:01 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=522
06/13/2022 09:00:04 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=524
06/13/2022 09:00:04 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.7941925381263616 on epoch=524
06/13/2022 09:00:07 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=527
06/13/2022 09:00:09 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=529
06/13/2022 09:00:12 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=532
06/13/2022 09:00:14 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=534
06/13/2022 09:00:17 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=537
06/13/2022 09:00:18 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.7941925381263616 on epoch=537
06/13/2022 09:00:20 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=539
06/13/2022 09:00:22 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=542
06/13/2022 09:00:25 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/13/2022 09:00:27 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/13/2022 09:00:30 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=549
06/13/2022 09:00:31 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.7941925381263616 on epoch=549
06/13/2022 09:00:33 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/13/2022 09:00:35 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=554
06/13/2022 09:00:38 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
06/13/2022 09:00:40 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.03 on epoch=559
06/13/2022 09:00:43 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/13/2022 09:00:44 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.7941925381263616 on epoch=562
06/13/2022 09:00:46 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=564
06/13/2022 09:00:48 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=567
06/13/2022 09:00:51 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=569
06/13/2022 09:00:53 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.07 on epoch=572
06/13/2022 09:00:56 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=574
06/13/2022 09:00:57 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.7787335722819593 on epoch=574
06/13/2022 09:00:59 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/13/2022 09:01:02 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=579
06/13/2022 09:01:04 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.09 on epoch=582
06/13/2022 09:01:06 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=584
06/13/2022 09:01:09 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/13/2022 09:01:10 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.7374299719887956 on epoch=587
06/13/2022 09:01:12 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=589
06/13/2022 09:01:15 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/13/2022 09:01:17 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/13/2022 09:01:19 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.06 on epoch=597
06/13/2022 09:01:22 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.05 on epoch=599
06/13/2022 09:01:23 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.7905011655011656 on epoch=599
06/13/2022 09:01:25 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=602
06/13/2022 09:01:28 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.03 on epoch=604
06/13/2022 09:01:30 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=607
06/13/2022 09:01:33 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=609
06/13/2022 09:01:35 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.03 on epoch=612
06/13/2022 09:01:36 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.7222222222222222 on epoch=612
06/13/2022 09:01:38 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=614
06/13/2022 09:01:41 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.08 on epoch=617
06/13/2022 09:01:43 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.05 on epoch=619
06/13/2022 09:01:46 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=622
06/13/2022 09:01:48 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=624
06/13/2022 09:01:49 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.7941925381263616 on epoch=624
06/13/2022 09:01:51 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/13/2022 09:01:54 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=629
06/13/2022 09:01:56 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=632
06/13/2022 09:01:59 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/13/2022 09:02:01 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/13/2022 09:02:02 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.7787335722819593 on epoch=637
06/13/2022 09:02:04 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/13/2022 09:02:07 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=642
06/13/2022 09:02:09 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=644
06/13/2022 09:02:12 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=647
06/13/2022 09:02:14 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.06 on epoch=649
06/13/2022 09:02:15 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.7759289729877966 on epoch=649
06/13/2022 09:02:18 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=652
06/13/2022 09:02:20 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/13/2022 09:02:22 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=657
06/13/2022 09:02:25 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/13/2022 09:02:27 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/13/2022 09:02:28 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.7759289729877966 on epoch=662
06/13/2022 09:02:31 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/13/2022 09:02:33 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/13/2022 09:02:36 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=669
06/13/2022 09:02:38 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=672
06/13/2022 09:02:40 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=674
06/13/2022 09:02:41 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.760576923076923 on epoch=674
06/13/2022 09:02:44 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=677
06/13/2022 09:02:46 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/13/2022 09:02:49 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/13/2022 09:02:51 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=684
06/13/2022 09:02:53 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=687
06/13/2022 09:02:54 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.7015684162423292 on epoch=687
06/13/2022 09:02:57 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/13/2022 09:02:59 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.13 on epoch=692
06/13/2022 09:03:02 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/13/2022 09:03:04 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=697
06/13/2022 09:03:07 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=699
06/13/2022 09:03:07 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.757296494355318 on epoch=699
06/13/2022 09:03:10 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/13/2022 09:03:12 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=704
06/13/2022 09:03:15 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.06 on epoch=707
06/13/2022 09:03:17 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/13/2022 09:03:20 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=712
06/13/2022 09:03:21 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.7419444444444444 on epoch=712
06/13/2022 09:03:23 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=714
06/13/2022 09:03:25 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=717
06/13/2022 09:03:28 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/13/2022 09:03:30 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=722
06/13/2022 09:03:33 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=724
06/13/2022 09:03:34 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.7941925381263616 on epoch=724
06/13/2022 09:03:36 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/13/2022 09:03:38 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/13/2022 09:03:41 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=732
06/13/2022 09:03:43 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=734
06/13/2022 09:03:46 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=737
06/13/2022 09:03:47 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.7941925381263616 on epoch=737
06/13/2022 09:03:49 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/13/2022 09:03:52 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/13/2022 09:03:54 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/13/2022 09:03:56 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/13/2022 09:03:59 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=749
06/13/2022 09:04:00 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.7941925381263616 on epoch=749
06/13/2022 09:04:00 - INFO - __main__ - save last model!
06/13/2022 09:04:00 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/13/2022 09:04:00 - INFO - __main__ - Start tokenizing ... 5509 instances
06/13/2022 09:04:00 - INFO - __main__ - Printing 3 examples
06/13/2022 09:04:00 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/13/2022 09:04:00 - INFO - __main__ - ['others']
06/13/2022 09:04:00 - INFO - __main__ -  [emo] what you like very little things ok
06/13/2022 09:04:00 - INFO - __main__ - ['others']
06/13/2022 09:04:00 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/13/2022 09:04:00 - INFO - __main__ - ['others']
06/13/2022 09:04:00 - INFO - __main__ - Tokenizing Input ...
06/13/2022 09:04:00 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 09:04:00 - INFO - __main__ - Printing 3 examples
06/13/2022 09:04:00 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/13/2022 09:04:00 - INFO - __main__ - ['others']
06/13/2022 09:04:00 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/13/2022 09:04:00 - INFO - __main__ - ['others']
06/13/2022 09:04:00 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/13/2022 09:04:00 - INFO - __main__ - ['others']
06/13/2022 09:04:00 - INFO - __main__ - Tokenizing Input ...
06/13/2022 09:04:00 - INFO - __main__ - Tokenizing Output ...
06/13/2022 09:04:00 - INFO - __main__ - Loaded 64 examples from train data
06/13/2022 09:04:00 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 09:04:00 - INFO - __main__ - Printing 3 examples
06/13/2022 09:04:00 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
06/13/2022 09:04:00 - INFO - __main__ - ['others']
06/13/2022 09:04:00 - INFO - __main__ -  [emo] i did ask now you did tell ms
06/13/2022 09:04:00 - INFO - __main__ - ['others']
06/13/2022 09:04:00 - INFO - __main__ -  [emo] buddy how you tell me your contact no
06/13/2022 09:04:00 - INFO - __main__ - ['others']
06/13/2022 09:04:00 - INFO - __main__ - Tokenizing Input ...
06/13/2022 09:04:00 - INFO - __main__ - Tokenizing Output ...
06/13/2022 09:04:00 - INFO - __main__ - Loaded 64 examples from dev data
06/13/2022 09:04:02 - INFO - __main__ - Tokenizing Output ...
06/13/2022 09:04:07 - INFO - __main__ - Loaded 5509 examples from test data
06/13/2022 09:04:15 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 09:04:16 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 09:04:16 - INFO - __main__ - Starting training!
06/13/2022 09:05:33 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-up32shot/singletask-emo/emo_16_13_0.3_8_predictions.txt
06/13/2022 09:05:33 - INFO - __main__ - Classification-F1 on test data: 0.2157
06/13/2022 09:05:33 - INFO - __main__ - prefix=emo_16_13, lr=0.3, bsz=8, dev_performance=0.7951894019256448, test_performance=0.21572442386057786
06/13/2022 09:05:33 - INFO - __main__ - Running ... prefix=emo_16_13, lr=0.2, bsz=8 ...
06/13/2022 09:05:34 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 09:05:34 - INFO - __main__ - Printing 3 examples
06/13/2022 09:05:34 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/13/2022 09:05:34 - INFO - __main__ - ['others']
06/13/2022 09:05:34 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/13/2022 09:05:34 - INFO - __main__ - ['others']
06/13/2022 09:05:34 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/13/2022 09:05:34 - INFO - __main__ - ['others']
06/13/2022 09:05:34 - INFO - __main__ - Tokenizing Input ...
06/13/2022 09:05:34 - INFO - __main__ - Tokenizing Output ...
06/13/2022 09:05:34 - INFO - __main__ - Loaded 64 examples from train data
06/13/2022 09:05:34 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 09:05:34 - INFO - __main__ - Printing 3 examples
06/13/2022 09:05:34 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
06/13/2022 09:05:34 - INFO - __main__ - ['others']
06/13/2022 09:05:34 - INFO - __main__ -  [emo] i did ask now you did tell ms
06/13/2022 09:05:34 - INFO - __main__ - ['others']
06/13/2022 09:05:34 - INFO - __main__ -  [emo] buddy how you tell me your contact no
06/13/2022 09:05:34 - INFO - __main__ - ['others']
06/13/2022 09:05:34 - INFO - __main__ - Tokenizing Input ...
06/13/2022 09:05:34 - INFO - __main__ - Tokenizing Output ...
06/13/2022 09:05:34 - INFO - __main__ - Loaded 64 examples from dev data
06/13/2022 09:05:49 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 09:05:50 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 09:05:50 - INFO - __main__ - Starting training!
06/13/2022 09:05:53 - INFO - __main__ - Step 10 Global step 10 Train loss 3.86 on epoch=2
06/13/2022 09:05:55 - INFO - __main__ - Step 20 Global step 20 Train loss 3.19 on epoch=4
06/13/2022 09:05:58 - INFO - __main__ - Step 30 Global step 30 Train loss 2.57 on epoch=7
06/13/2022 09:06:00 - INFO - __main__ - Step 40 Global step 40 Train loss 2.29 on epoch=9
06/13/2022 09:06:03 - INFO - __main__ - Step 50 Global step 50 Train loss 2.10 on epoch=12
06/13/2022 09:06:04 - INFO - __main__ - Global step 50 Train loss 2.80 Classification-F1 0.043867243867243874 on epoch=12
06/13/2022 09:06:04 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.043867243867243874 on epoch=12, global_step=50
06/13/2022 09:06:06 - INFO - __main__ - Step 60 Global step 60 Train loss 1.84 on epoch=14
06/13/2022 09:06:09 - INFO - __main__ - Step 70 Global step 70 Train loss 1.65 on epoch=17
06/13/2022 09:06:11 - INFO - __main__ - Step 80 Global step 80 Train loss 1.41 on epoch=19
06/13/2022 09:06:13 - INFO - __main__ - Step 90 Global step 90 Train loss 1.25 on epoch=22
06/13/2022 09:06:16 - INFO - __main__ - Step 100 Global step 100 Train loss 1.00 on epoch=24
06/13/2022 09:06:17 - INFO - __main__ - Global step 100 Train loss 1.43 Classification-F1 0.21046905222437134 on epoch=24
06/13/2022 09:06:17 - INFO - __main__ - Saving model with best Classification-F1: 0.043867243867243874 -> 0.21046905222437134 on epoch=24, global_step=100
06/13/2022 09:06:19 - INFO - __main__ - Step 110 Global step 110 Train loss 1.00 on epoch=27
06/13/2022 09:06:22 - INFO - __main__ - Step 120 Global step 120 Train loss 0.90 on epoch=29
06/13/2022 09:06:24 - INFO - __main__ - Step 130 Global step 130 Train loss 0.79 on epoch=32
06/13/2022 09:06:26 - INFO - __main__ - Step 140 Global step 140 Train loss 0.79 on epoch=34
06/13/2022 09:06:29 - INFO - __main__ - Step 150 Global step 150 Train loss 0.75 on epoch=37
06/13/2022 09:06:30 - INFO - __main__ - Global step 150 Train loss 0.85 Classification-F1 0.425081518194861 on epoch=37
06/13/2022 09:06:30 - INFO - __main__ - Saving model with best Classification-F1: 0.21046905222437134 -> 0.425081518194861 on epoch=37, global_step=150
06/13/2022 09:06:32 - INFO - __main__ - Step 160 Global step 160 Train loss 0.73 on epoch=39
06/13/2022 09:06:34 - INFO - __main__ - Step 170 Global step 170 Train loss 0.67 on epoch=42
06/13/2022 09:06:37 - INFO - __main__ - Step 180 Global step 180 Train loss 0.63 on epoch=44
06/13/2022 09:06:39 - INFO - __main__ - Step 190 Global step 190 Train loss 0.68 on epoch=47
06/13/2022 09:06:42 - INFO - __main__ - Step 200 Global step 200 Train loss 0.66 on epoch=49
06/13/2022 09:06:42 - INFO - __main__ - Global step 200 Train loss 0.67 Classification-F1 0.5102480016396802 on epoch=49
06/13/2022 09:06:43 - INFO - __main__ - Saving model with best Classification-F1: 0.425081518194861 -> 0.5102480016396802 on epoch=49, global_step=200
06/13/2022 09:06:45 - INFO - __main__ - Step 210 Global step 210 Train loss 0.60 on epoch=52
06/13/2022 09:06:47 - INFO - __main__ - Step 220 Global step 220 Train loss 0.61 on epoch=54
06/13/2022 09:06:50 - INFO - __main__ - Step 230 Global step 230 Train loss 0.53 on epoch=57
06/13/2022 09:06:52 - INFO - __main__ - Step 240 Global step 240 Train loss 0.59 on epoch=59
06/13/2022 09:06:54 - INFO - __main__ - Step 250 Global step 250 Train loss 0.51 on epoch=62
06/13/2022 09:06:55 - INFO - __main__ - Global step 250 Train loss 0.57 Classification-F1 0.5809633704370546 on epoch=62
06/13/2022 09:06:55 - INFO - __main__ - Saving model with best Classification-F1: 0.5102480016396802 -> 0.5809633704370546 on epoch=62, global_step=250
06/13/2022 09:06:58 - INFO - __main__ - Step 260 Global step 260 Train loss 0.54 on epoch=64
06/13/2022 09:07:00 - INFO - __main__ - Step 270 Global step 270 Train loss 0.53 on epoch=67
06/13/2022 09:07:03 - INFO - __main__ - Step 280 Global step 280 Train loss 0.56 on epoch=69
06/13/2022 09:07:05 - INFO - __main__ - Step 290 Global step 290 Train loss 0.62 on epoch=72
06/13/2022 09:07:07 - INFO - __main__ - Step 300 Global step 300 Train loss 0.47 on epoch=74
06/13/2022 09:07:08 - INFO - __main__ - Global step 300 Train loss 0.54 Classification-F1 0.6102769177846578 on epoch=74
06/13/2022 09:07:08 - INFO - __main__ - Saving model with best Classification-F1: 0.5809633704370546 -> 0.6102769177846578 on epoch=74, global_step=300
06/13/2022 09:07:11 - INFO - __main__ - Step 310 Global step 310 Train loss 0.47 on epoch=77
06/13/2022 09:07:13 - INFO - __main__ - Step 320 Global step 320 Train loss 0.51 on epoch=79
06/13/2022 09:07:16 - INFO - __main__ - Step 330 Global step 330 Train loss 0.55 on epoch=82
06/13/2022 09:07:18 - INFO - __main__ - Step 340 Global step 340 Train loss 0.57 on epoch=84
06/13/2022 09:07:21 - INFO - __main__ - Step 350 Global step 350 Train loss 0.46 on epoch=87
06/13/2022 09:07:21 - INFO - __main__ - Global step 350 Train loss 0.51 Classification-F1 0.6713629507747154 on epoch=87
06/13/2022 09:07:21 - INFO - __main__ - Saving model with best Classification-F1: 0.6102769177846578 -> 0.6713629507747154 on epoch=87, global_step=350
06/13/2022 09:07:24 - INFO - __main__ - Step 360 Global step 360 Train loss 0.44 on epoch=89
06/13/2022 09:07:26 - INFO - __main__ - Step 370 Global step 370 Train loss 0.53 on epoch=92
06/13/2022 09:07:29 - INFO - __main__ - Step 380 Global step 380 Train loss 0.41 on epoch=94
06/13/2022 09:07:31 - INFO - __main__ - Step 390 Global step 390 Train loss 0.40 on epoch=97
06/13/2022 09:07:34 - INFO - __main__ - Step 400 Global step 400 Train loss 0.48 on epoch=99
06/13/2022 09:07:35 - INFO - __main__ - Global step 400 Train loss 0.45 Classification-F1 0.6874057315233786 on epoch=99
06/13/2022 09:07:35 - INFO - __main__ - Saving model with best Classification-F1: 0.6713629507747154 -> 0.6874057315233786 on epoch=99, global_step=400
06/13/2022 09:07:37 - INFO - __main__ - Step 410 Global step 410 Train loss 0.40 on epoch=102
06/13/2022 09:07:40 - INFO - __main__ - Step 420 Global step 420 Train loss 0.35 on epoch=104
06/13/2022 09:07:42 - INFO - __main__ - Step 430 Global step 430 Train loss 0.47 on epoch=107
06/13/2022 09:07:44 - INFO - __main__ - Step 440 Global step 440 Train loss 0.51 on epoch=109
06/13/2022 09:07:47 - INFO - __main__ - Step 450 Global step 450 Train loss 0.44 on epoch=112
06/13/2022 09:07:48 - INFO - __main__ - Global step 450 Train loss 0.43 Classification-F1 0.6874057315233786 on epoch=112
06/13/2022 09:07:50 - INFO - __main__ - Step 460 Global step 460 Train loss 0.39 on epoch=114
06/13/2022 09:07:53 - INFO - __main__ - Step 470 Global step 470 Train loss 0.36 on epoch=117
06/13/2022 09:07:55 - INFO - __main__ - Step 480 Global step 480 Train loss 0.42 on epoch=119
06/13/2022 09:07:58 - INFO - __main__ - Step 490 Global step 490 Train loss 0.41 on epoch=122
06/13/2022 09:08:00 - INFO - __main__ - Step 500 Global step 500 Train loss 0.35 on epoch=124
06/13/2022 09:08:01 - INFO - __main__ - Global step 500 Train loss 0.39 Classification-F1 0.673515339150014 on epoch=124
06/13/2022 09:08:03 - INFO - __main__ - Step 510 Global step 510 Train loss 0.40 on epoch=127
06/13/2022 09:08:06 - INFO - __main__ - Step 520 Global step 520 Train loss 0.37 on epoch=129
06/13/2022 09:08:08 - INFO - __main__ - Step 530 Global step 530 Train loss 0.33 on epoch=132
06/13/2022 09:08:11 - INFO - __main__ - Step 540 Global step 540 Train loss 0.29 on epoch=134
06/13/2022 09:08:13 - INFO - __main__ - Step 550 Global step 550 Train loss 0.35 on epoch=137
06/13/2022 09:08:14 - INFO - __main__ - Global step 550 Train loss 0.35 Classification-F1 0.7309200603318251 on epoch=137
06/13/2022 09:08:14 - INFO - __main__ - Saving model with best Classification-F1: 0.6874057315233786 -> 0.7309200603318251 on epoch=137, global_step=550
06/13/2022 09:08:16 - INFO - __main__ - Step 560 Global step 560 Train loss 0.27 on epoch=139
06/13/2022 09:08:19 - INFO - __main__ - Step 570 Global step 570 Train loss 0.36 on epoch=142
06/13/2022 09:08:21 - INFO - __main__ - Step 580 Global step 580 Train loss 0.37 on epoch=144
06/13/2022 09:08:24 - INFO - __main__ - Step 590 Global step 590 Train loss 0.38 on epoch=147
06/13/2022 09:08:26 - INFO - __main__ - Step 600 Global step 600 Train loss 0.28 on epoch=149
06/13/2022 09:08:27 - INFO - __main__ - Global step 600 Train loss 0.33 Classification-F1 0.7767947738535975 on epoch=149
06/13/2022 09:08:27 - INFO - __main__ - Saving model with best Classification-F1: 0.7309200603318251 -> 0.7767947738535975 on epoch=149, global_step=600
06/13/2022 09:08:30 - INFO - __main__ - Step 610 Global step 610 Train loss 0.37 on epoch=152
06/13/2022 09:08:32 - INFO - __main__ - Step 620 Global step 620 Train loss 0.37 on epoch=154
06/13/2022 09:08:35 - INFO - __main__ - Step 630 Global step 630 Train loss 0.35 on epoch=157
06/13/2022 09:08:37 - INFO - __main__ - Step 640 Global step 640 Train loss 0.42 on epoch=159
06/13/2022 09:08:39 - INFO - __main__ - Step 650 Global step 650 Train loss 0.34 on epoch=162
06/13/2022 09:08:40 - INFO - __main__ - Global step 650 Train loss 0.37 Classification-F1 0.7958994708994709 on epoch=162
06/13/2022 09:08:40 - INFO - __main__ - Saving model with best Classification-F1: 0.7767947738535975 -> 0.7958994708994709 on epoch=162, global_step=650
06/13/2022 09:08:43 - INFO - __main__ - Step 660 Global step 660 Train loss 0.28 on epoch=164
06/13/2022 09:08:45 - INFO - __main__ - Step 670 Global step 670 Train loss 0.27 on epoch=167
06/13/2022 09:08:47 - INFO - __main__ - Step 680 Global step 680 Train loss 0.34 on epoch=169
06/13/2022 09:08:50 - INFO - __main__ - Step 690 Global step 690 Train loss 0.26 on epoch=172
06/13/2022 09:08:52 - INFO - __main__ - Step 700 Global step 700 Train loss 0.31 on epoch=174
06/13/2022 09:08:53 - INFO - __main__ - Global step 700 Train loss 0.29 Classification-F1 0.776801961479381 on epoch=174
06/13/2022 09:08:56 - INFO - __main__ - Step 710 Global step 710 Train loss 0.31 on epoch=177
06/13/2022 09:08:58 - INFO - __main__ - Step 720 Global step 720 Train loss 0.24 on epoch=179
06/13/2022 09:09:01 - INFO - __main__ - Step 730 Global step 730 Train loss 0.30 on epoch=182
06/13/2022 09:09:03 - INFO - __main__ - Step 740 Global step 740 Train loss 0.32 on epoch=184
06/13/2022 09:09:05 - INFO - __main__ - Step 750 Global step 750 Train loss 0.20 on epoch=187
06/13/2022 09:09:06 - INFO - __main__ - Global step 750 Train loss 0.27 Classification-F1 0.8105820105820105 on epoch=187
06/13/2022 09:09:06 - INFO - __main__ - Saving model with best Classification-F1: 0.7958994708994709 -> 0.8105820105820105 on epoch=187, global_step=750
06/13/2022 09:09:09 - INFO - __main__ - Step 760 Global step 760 Train loss 0.29 on epoch=189
06/13/2022 09:09:11 - INFO - __main__ - Step 770 Global step 770 Train loss 0.25 on epoch=192
06/13/2022 09:09:14 - INFO - __main__ - Step 780 Global step 780 Train loss 0.26 on epoch=194
06/13/2022 09:09:16 - INFO - __main__ - Step 790 Global step 790 Train loss 0.25 on epoch=197
06/13/2022 09:09:18 - INFO - __main__ - Step 800 Global step 800 Train loss 0.23 on epoch=199
06/13/2022 09:09:19 - INFO - __main__ - Global step 800 Train loss 0.26 Classification-F1 0.7914845011619206 on epoch=199
06/13/2022 09:09:22 - INFO - __main__ - Step 810 Global step 810 Train loss 0.20 on epoch=202
06/13/2022 09:09:24 - INFO - __main__ - Step 820 Global step 820 Train loss 0.31 on epoch=204
06/13/2022 09:09:27 - INFO - __main__ - Step 830 Global step 830 Train loss 0.25 on epoch=207
06/13/2022 09:09:29 - INFO - __main__ - Step 840 Global step 840 Train loss 0.25 on epoch=209
06/13/2022 09:09:31 - INFO - __main__ - Step 850 Global step 850 Train loss 0.25 on epoch=212
06/13/2022 09:09:32 - INFO - __main__ - Global step 850 Train loss 0.25 Classification-F1 0.7910258379008379 on epoch=212
06/13/2022 09:09:35 - INFO - __main__ - Step 860 Global step 860 Train loss 0.21 on epoch=214
06/13/2022 09:09:37 - INFO - __main__ - Step 870 Global step 870 Train loss 0.21 on epoch=217
06/13/2022 09:09:40 - INFO - __main__ - Step 880 Global step 880 Train loss 0.20 on epoch=219
06/13/2022 09:09:42 - INFO - __main__ - Step 890 Global step 890 Train loss 0.21 on epoch=222
06/13/2022 09:09:44 - INFO - __main__ - Step 900 Global step 900 Train loss 0.19 on epoch=224
06/13/2022 09:09:45 - INFO - __main__ - Global step 900 Train loss 0.20 Classification-F1 0.8251427898486722 on epoch=224
06/13/2022 09:09:45 - INFO - __main__ - Saving model with best Classification-F1: 0.8105820105820105 -> 0.8251427898486722 on epoch=224, global_step=900
06/13/2022 09:09:48 - INFO - __main__ - Step 910 Global step 910 Train loss 0.20 on epoch=227
06/13/2022 09:09:50 - INFO - __main__ - Step 920 Global step 920 Train loss 0.20 on epoch=229
06/13/2022 09:09:52 - INFO - __main__ - Step 930 Global step 930 Train loss 0.22 on epoch=232
06/13/2022 09:09:55 - INFO - __main__ - Step 940 Global step 940 Train loss 0.21 on epoch=234
06/13/2022 09:09:57 - INFO - __main__ - Step 950 Global step 950 Train loss 0.15 on epoch=237
06/13/2022 09:09:58 - INFO - __main__ - Global step 950 Train loss 0.20 Classification-F1 0.8090701538977401 on epoch=237
06/13/2022 09:10:01 - INFO - __main__ - Step 960 Global step 960 Train loss 0.18 on epoch=239
06/13/2022 09:10:03 - INFO - __main__ - Step 970 Global step 970 Train loss 0.17 on epoch=242
06/13/2022 09:10:05 - INFO - __main__ - Step 980 Global step 980 Train loss 0.18 on epoch=244
06/13/2022 09:10:08 - INFO - __main__ - Step 990 Global step 990 Train loss 0.19 on epoch=247
06/13/2022 09:10:10 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.21 on epoch=249
06/13/2022 09:10:11 - INFO - __main__ - Global step 1000 Train loss 0.19 Classification-F1 0.7763276970707312 on epoch=249
06/13/2022 09:10:13 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.25 on epoch=252
06/13/2022 09:10:16 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.18 on epoch=254
06/13/2022 09:10:18 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.27 on epoch=257
06/13/2022 09:10:21 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.14 on epoch=259
06/13/2022 09:10:23 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.15 on epoch=262
06/13/2022 09:10:24 - INFO - __main__ - Global step 1050 Train loss 0.20 Classification-F1 0.8096865193639388 on epoch=262
06/13/2022 09:10:27 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.16 on epoch=264
06/13/2022 09:10:29 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.12 on epoch=267
06/13/2022 09:10:31 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.21 on epoch=269
06/13/2022 09:10:34 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.17 on epoch=272
06/13/2022 09:10:36 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.17 on epoch=274
06/13/2022 09:10:37 - INFO - __main__ - Global step 1100 Train loss 0.17 Classification-F1 0.7922439756056054 on epoch=274
06/13/2022 09:10:40 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.16 on epoch=277
06/13/2022 09:10:42 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.22 on epoch=279
06/13/2022 09:10:44 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.10 on epoch=282
06/13/2022 09:10:47 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.13 on epoch=284
06/13/2022 09:10:49 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.12 on epoch=287
06/13/2022 09:10:50 - INFO - __main__ - Global step 1150 Train loss 0.15 Classification-F1 0.7922439756056054 on epoch=287
06/13/2022 09:10:53 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.13 on epoch=289
06/13/2022 09:10:55 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.13 on epoch=292
06/13/2022 09:10:57 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.11 on epoch=294
06/13/2022 09:11:00 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.12 on epoch=297
06/13/2022 09:11:02 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.12 on epoch=299
06/13/2022 09:11:03 - INFO - __main__ - Global step 1200 Train loss 0.12 Classification-F1 0.7763276970707312 on epoch=299
06/13/2022 09:11:06 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.13 on epoch=302
06/13/2022 09:11:08 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.08 on epoch=304
06/13/2022 09:11:10 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.13 on epoch=307
06/13/2022 09:11:13 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.15 on epoch=309
06/13/2022 09:11:15 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.13 on epoch=312
06/13/2022 09:11:16 - INFO - __main__ - Global step 1250 Train loss 0.12 Classification-F1 0.7601005165433476 on epoch=312
06/13/2022 09:11:19 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.11 on epoch=314
06/13/2022 09:11:21 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.08 on epoch=317
06/13/2022 09:11:24 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.11 on epoch=319
06/13/2022 09:11:26 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.16 on epoch=322
06/13/2022 09:11:28 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.13 on epoch=324
06/13/2022 09:11:29 - INFO - __main__ - Global step 1300 Train loss 0.12 Classification-F1 0.7937702408290643 on epoch=324
06/13/2022 09:11:32 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.13 on epoch=327
06/13/2022 09:11:34 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.08 on epoch=329
06/13/2022 09:11:37 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.11 on epoch=332
06/13/2022 09:11:39 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.11 on epoch=334
06/13/2022 09:11:41 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.14 on epoch=337
06/13/2022 09:11:42 - INFO - __main__ - Global step 1350 Train loss 0.11 Classification-F1 0.7910258379008379 on epoch=337
06/13/2022 09:11:45 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.06 on epoch=339
06/13/2022 09:11:47 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.08 on epoch=342
06/13/2022 09:11:50 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.08 on epoch=344
06/13/2022 09:11:52 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.15 on epoch=347
06/13/2022 09:11:54 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.06 on epoch=349
06/13/2022 09:11:55 - INFO - __main__ - Global step 1400 Train loss 0.09 Classification-F1 0.7225225225225225 on epoch=349
06/13/2022 09:11:58 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.08 on epoch=352
06/13/2022 09:12:00 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.08 on epoch=354
06/13/2022 09:12:03 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.04 on epoch=357
06/13/2022 09:12:05 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.10 on epoch=359
06/13/2022 09:12:07 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.07 on epoch=362
06/13/2022 09:12:08 - INFO - __main__ - Global step 1450 Train loss 0.07 Classification-F1 0.8096865193639388 on epoch=362
06/13/2022 09:12:11 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.06 on epoch=364
06/13/2022 09:12:13 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.09 on epoch=367
06/13/2022 09:12:16 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.07 on epoch=369
06/13/2022 09:12:18 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.03 on epoch=372
06/13/2022 09:12:21 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.10 on epoch=374
06/13/2022 09:12:21 - INFO - __main__ - Global step 1500 Train loss 0.07 Classification-F1 0.8096865193639388 on epoch=374
06/13/2022 09:12:24 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.07 on epoch=377
06/13/2022 09:12:26 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.06 on epoch=379
06/13/2022 09:12:29 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.14 on epoch=382
06/13/2022 09:12:31 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.05 on epoch=384
06/13/2022 09:12:34 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.03 on epoch=387
06/13/2022 09:12:35 - INFO - __main__ - Global step 1550 Train loss 0.07 Classification-F1 0.7610697546181417 on epoch=387
06/13/2022 09:12:37 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.06 on epoch=389
06/13/2022 09:12:40 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.14 on epoch=392
06/13/2022 09:12:42 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.05 on epoch=394
06/13/2022 09:12:44 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.07 on epoch=397
06/13/2022 09:12:47 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.09 on epoch=399
06/13/2022 09:12:48 - INFO - __main__ - Global step 1600 Train loss 0.08 Classification-F1 0.7419444444444444 on epoch=399
06/13/2022 09:12:50 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=402
06/13/2022 09:12:53 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.08 on epoch=404
06/13/2022 09:12:55 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.07 on epoch=407
06/13/2022 09:12:57 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.03 on epoch=409
06/13/2022 09:13:00 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.10 on epoch=412
06/13/2022 09:13:01 - INFO - __main__ - Global step 1650 Train loss 0.06 Classification-F1 0.7964285714285714 on epoch=412
06/13/2022 09:13:03 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.03 on epoch=414
06/13/2022 09:13:06 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.05 on epoch=417
06/13/2022 09:13:08 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.04 on epoch=419
06/13/2022 09:13:10 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.10 on epoch=422
06/13/2022 09:13:13 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.04 on epoch=424
06/13/2022 09:13:14 - INFO - __main__ - Global step 1700 Train loss 0.05 Classification-F1 0.757296494355318 on epoch=424
06/13/2022 09:13:16 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.04 on epoch=427
06/13/2022 09:13:19 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.08 on epoch=429
06/13/2022 09:13:21 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=432
06/13/2022 09:13:23 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.06 on epoch=434
06/13/2022 09:13:26 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.08 on epoch=437
06/13/2022 09:13:27 - INFO - __main__ - Global step 1750 Train loss 0.05 Classification-F1 0.7610697546181417 on epoch=437
06/13/2022 09:13:29 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.04 on epoch=439
06/13/2022 09:13:32 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=442
06/13/2022 09:13:34 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.04 on epoch=444
06/13/2022 09:13:37 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.05 on epoch=447
06/13/2022 09:13:39 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=449
06/13/2022 09:13:40 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.7419444444444444 on epoch=449
06/13/2022 09:13:42 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.07 on epoch=452
06/13/2022 09:13:45 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.05 on epoch=454
06/13/2022 09:13:47 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=457
06/13/2022 09:13:50 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=459
06/13/2022 09:13:52 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=462
06/13/2022 09:13:53 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.7951894019256448 on epoch=462
06/13/2022 09:13:56 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=464
06/13/2022 09:13:58 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.03 on epoch=467
06/13/2022 09:14:00 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.04 on epoch=469
06/13/2022 09:14:03 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.03 on epoch=472
06/13/2022 09:14:05 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=474
06/13/2022 09:14:06 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.7587884436160298 on epoch=474
06/13/2022 09:14:09 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=477
06/13/2022 09:14:11 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.05 on epoch=479
06/13/2022 09:14:14 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=482
06/13/2022 09:14:16 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.06 on epoch=484
06/13/2022 09:14:18 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=487
06/13/2022 09:14:19 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.7419444444444444 on epoch=487
06/13/2022 09:14:22 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.05 on epoch=489
06/13/2022 09:14:24 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.08 on epoch=492
06/13/2022 09:14:27 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.04 on epoch=494
06/13/2022 09:14:29 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.05 on epoch=497
06/13/2022 09:14:32 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.03 on epoch=499
06/13/2022 09:14:32 - INFO - __main__ - Global step 2000 Train loss 0.05 Classification-F1 0.7610697546181417 on epoch=499
06/13/2022 09:14:35 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.03 on epoch=502
06/13/2022 09:14:37 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=504
06/13/2022 09:14:40 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.03 on epoch=507
06/13/2022 09:14:42 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.06 on epoch=509
06/13/2022 09:14:45 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.04 on epoch=512
06/13/2022 09:14:46 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.7610697546181417 on epoch=512
06/13/2022 09:14:48 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.12 on epoch=514
06/13/2022 09:14:51 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.07 on epoch=517
06/13/2022 09:14:53 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.15 on epoch=519
06/13/2022 09:14:55 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.04 on epoch=522
06/13/2022 09:14:58 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=524
06/13/2022 09:14:59 - INFO - __main__ - Global step 2100 Train loss 0.08 Classification-F1 0.7369042429526301 on epoch=524
06/13/2022 09:15:01 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=527
06/13/2022 09:15:04 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=529
06/13/2022 09:15:06 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=532
06/13/2022 09:15:08 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.07 on epoch=534
06/13/2022 09:15:11 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=537
06/13/2022 09:15:12 - INFO - __main__ - Global step 2150 Train loss 0.03 Classification-F1 0.7575225225225225 on epoch=537
06/13/2022 09:15:14 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=539
06/13/2022 09:15:17 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.06 on epoch=542
06/13/2022 09:15:19 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.07 on epoch=544
06/13/2022 09:15:22 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.05 on epoch=547
06/13/2022 09:15:24 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=549
06/13/2022 09:15:25 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.7369042429526301 on epoch=549
06/13/2022 09:15:27 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=552
06/13/2022 09:15:30 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=554
06/13/2022 09:15:32 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.10 on epoch=557
06/13/2022 09:15:35 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.03 on epoch=559
06/13/2022 09:15:37 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.05 on epoch=562
06/13/2022 09:15:38 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.7787335722819593 on epoch=562
06/13/2022 09:15:40 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=564
06/13/2022 09:15:43 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=567
06/13/2022 09:15:45 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.06 on epoch=569
06/13/2022 09:15:48 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.04 on epoch=572
06/13/2022 09:15:50 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.04 on epoch=574
06/13/2022 09:15:51 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.7575225225225225 on epoch=574
06/13/2022 09:15:53 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=577
06/13/2022 09:15:56 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=579
06/13/2022 09:15:58 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=582
06/13/2022 09:16:01 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=584
06/13/2022 09:16:03 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.04 on epoch=587
06/13/2022 09:16:04 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.737874572433396 on epoch=587
06/13/2022 09:16:07 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=589
06/13/2022 09:16:09 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=592
06/13/2022 09:16:12 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.03 on epoch=594
06/13/2022 09:16:14 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=597
06/13/2022 09:16:17 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=599
06/13/2022 09:16:18 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.7951894019256448 on epoch=599
06/13/2022 09:16:20 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.06 on epoch=602
06/13/2022 09:16:23 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.03 on epoch=604
06/13/2022 09:16:25 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=607
06/13/2022 09:16:28 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=609
06/13/2022 09:16:30 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=612
06/13/2022 09:16:31 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.7778258845621274 on epoch=612
06/13/2022 09:16:34 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=614
06/13/2022 09:16:36 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=617
06/13/2022 09:16:39 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=619
06/13/2022 09:16:42 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=622
06/13/2022 09:16:44 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=624
06/13/2022 09:16:45 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.7765287204625441 on epoch=624
06/13/2022 09:16:47 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.03 on epoch=627
06/13/2022 09:16:50 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.03 on epoch=629
06/13/2022 09:16:52 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=632
06/13/2022 09:16:55 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.05 on epoch=634
06/13/2022 09:16:57 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=637
06/13/2022 09:16:58 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.7765287204625441 on epoch=637
06/13/2022 09:17:00 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=639
06/13/2022 09:17:03 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=642
06/13/2022 09:17:05 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.08 on epoch=644
06/13/2022 09:17:08 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=647
06/13/2022 09:17:10 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.04 on epoch=649
06/13/2022 09:17:11 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.737874572433396 on epoch=649
06/13/2022 09:17:14 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.12 on epoch=652
06/13/2022 09:17:16 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=654
06/13/2022 09:17:18 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.03 on epoch=657
06/13/2022 09:17:21 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=659
06/13/2022 09:17:23 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=662
06/13/2022 09:17:24 - INFO - __main__ - Global step 2650 Train loss 0.04 Classification-F1 0.7419444444444444 on epoch=662
06/13/2022 09:17:27 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=664
06/13/2022 09:17:29 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=667
06/13/2022 09:17:32 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.05 on epoch=669
06/13/2022 09:17:34 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=672
06/13/2022 09:17:37 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=674
06/13/2022 09:17:38 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.7610697546181417 on epoch=674
06/13/2022 09:17:40 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.03 on epoch=677
06/13/2022 09:17:42 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=679
06/13/2022 09:17:45 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=682
06/13/2022 09:17:47 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=684
06/13/2022 09:17:50 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=687
06/13/2022 09:17:51 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.7610697546181417 on epoch=687
06/13/2022 09:17:53 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=689
06/13/2022 09:17:56 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=692
06/13/2022 09:17:58 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=694
06/13/2022 09:18:00 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=697
06/13/2022 09:18:03 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=699
06/13/2022 09:18:04 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.7419444444444444 on epoch=699
06/13/2022 09:18:06 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=702
06/13/2022 09:18:09 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=704
06/13/2022 09:18:11 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.08 on epoch=707
06/13/2022 09:18:14 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=709
06/13/2022 09:18:16 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=712
06/13/2022 09:18:17 - INFO - __main__ - Global step 2850 Train loss 0.03 Classification-F1 0.7964285714285714 on epoch=712
06/13/2022 09:18:19 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.03 on epoch=714
06/13/2022 09:18:22 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.04 on epoch=717
06/13/2022 09:18:24 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/13/2022 09:18:27 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=722
06/13/2022 09:18:29 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=724
06/13/2022 09:18:30 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.7787335722819593 on epoch=724
06/13/2022 09:18:32 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=727
06/13/2022 09:18:35 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/13/2022 09:18:37 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.03 on epoch=732
06/13/2022 09:18:40 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=734
06/13/2022 09:18:42 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/13/2022 09:18:43 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.7787335722819593 on epoch=737
06/13/2022 09:18:46 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=739
06/13/2022 09:18:48 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/13/2022 09:18:50 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.07 on epoch=744
06/13/2022 09:18:53 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=747
06/13/2022 09:18:55 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=749
06/13/2022 09:18:56 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.7964285714285714 on epoch=749
06/13/2022 09:18:56 - INFO - __main__ - save last model!
06/13/2022 09:18:56 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/13/2022 09:18:56 - INFO - __main__ - Start tokenizing ... 5509 instances
06/13/2022 09:18:56 - INFO - __main__ - Printing 3 examples
06/13/2022 09:18:56 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/13/2022 09:18:56 - INFO - __main__ - ['others']
06/13/2022 09:18:56 - INFO - __main__ -  [emo] what you like very little things ok
06/13/2022 09:18:56 - INFO - __main__ - ['others']
06/13/2022 09:18:56 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/13/2022 09:18:56 - INFO - __main__ - ['others']
06/13/2022 09:18:56 - INFO - __main__ - Tokenizing Input ...
06/13/2022 09:18:57 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 09:18:57 - INFO - __main__ - Printing 3 examples
06/13/2022 09:18:57 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/13/2022 09:18:57 - INFO - __main__ - ['sad']
06/13/2022 09:18:57 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/13/2022 09:18:57 - INFO - __main__ - ['sad']
06/13/2022 09:18:57 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/13/2022 09:18:57 - INFO - __main__ - ['sad']
06/13/2022 09:18:57 - INFO - __main__ - Tokenizing Input ...
06/13/2022 09:18:57 - INFO - __main__ - Tokenizing Output ...
06/13/2022 09:18:57 - INFO - __main__ - Loaded 64 examples from train data
06/13/2022 09:18:57 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 09:18:57 - INFO - __main__ - Printing 3 examples
06/13/2022 09:18:57 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
06/13/2022 09:18:57 - INFO - __main__ - ['sad']
06/13/2022 09:18:57 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
06/13/2022 09:18:57 - INFO - __main__ - ['sad']
06/13/2022 09:18:57 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
06/13/2022 09:18:57 - INFO - __main__ - ['sad']
06/13/2022 09:18:57 - INFO - __main__ - Tokenizing Input ...
06/13/2022 09:18:57 - INFO - __main__ - Tokenizing Output ...
06/13/2022 09:18:57 - INFO - __main__ - Loaded 64 examples from dev data
06/13/2022 09:18:58 - INFO - __main__ - Tokenizing Output ...
06/13/2022 09:19:04 - INFO - __main__ - Loaded 5509 examples from test data
06/13/2022 09:19:12 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 09:19:13 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 09:19:13 - INFO - __main__ - Starting training!
06/13/2022 09:20:19 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-up32shot/singletask-emo/emo_16_13_0.2_8_predictions.txt
06/13/2022 09:20:19 - INFO - __main__ - Classification-F1 on test data: 0.1685
06/13/2022 09:20:20 - INFO - __main__ - prefix=emo_16_13, lr=0.2, bsz=8, dev_performance=0.8251427898486722, test_performance=0.1684649320854927
06/13/2022 09:20:20 - INFO - __main__ - Running ... prefix=emo_16_21, lr=0.5, bsz=8 ...
06/13/2022 09:20:21 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 09:20:21 - INFO - __main__ - Printing 3 examples
06/13/2022 09:20:21 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/13/2022 09:20:21 - INFO - __main__ - ['sad']
06/13/2022 09:20:21 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/13/2022 09:20:21 - INFO - __main__ - ['sad']
06/13/2022 09:20:21 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/13/2022 09:20:21 - INFO - __main__ - ['sad']
06/13/2022 09:20:21 - INFO - __main__ - Tokenizing Input ...
06/13/2022 09:20:21 - INFO - __main__ - Tokenizing Output ...
06/13/2022 09:20:21 - INFO - __main__ - Loaded 64 examples from train data
06/13/2022 09:20:21 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 09:20:21 - INFO - __main__ - Printing 3 examples
06/13/2022 09:20:21 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
06/13/2022 09:20:21 - INFO - __main__ - ['sad']
06/13/2022 09:20:21 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
06/13/2022 09:20:21 - INFO - __main__ - ['sad']
06/13/2022 09:20:21 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
06/13/2022 09:20:21 - INFO - __main__ - ['sad']
06/13/2022 09:20:21 - INFO - __main__ - Tokenizing Input ...
06/13/2022 09:20:21 - INFO - __main__ - Tokenizing Output ...
06/13/2022 09:20:21 - INFO - __main__ - Loaded 64 examples from dev data
06/13/2022 09:20:36 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 09:20:37 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 09:20:37 - INFO - __main__ - Starting training!
06/13/2022 09:20:40 - INFO - __main__ - Step 10 Global step 10 Train loss 3.85 on epoch=2
06/13/2022 09:20:42 - INFO - __main__ - Step 20 Global step 20 Train loss 2.45 on epoch=4
06/13/2022 09:20:45 - INFO - __main__ - Step 30 Global step 30 Train loss 1.90 on epoch=7
06/13/2022 09:20:47 - INFO - __main__ - Step 40 Global step 40 Train loss 1.22 on epoch=9
06/13/2022 09:20:49 - INFO - __main__ - Step 50 Global step 50 Train loss 0.94 on epoch=12
06/13/2022 09:20:50 - INFO - __main__ - Global step 50 Train loss 2.07 Classification-F1 0.4842347195288372 on epoch=12
06/13/2022 09:20:50 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.4842347195288372 on epoch=12, global_step=50
06/13/2022 09:20:53 - INFO - __main__ - Step 60 Global step 60 Train loss 0.73 on epoch=14
06/13/2022 09:20:55 - INFO - __main__ - Step 70 Global step 70 Train loss 0.70 on epoch=17
06/13/2022 09:20:58 - INFO - __main__ - Step 80 Global step 80 Train loss 0.56 on epoch=19
06/13/2022 09:21:00 - INFO - __main__ - Step 90 Global step 90 Train loss 0.48 on epoch=22
06/13/2022 09:21:03 - INFO - __main__ - Step 100 Global step 100 Train loss 0.48 on epoch=24
06/13/2022 09:21:04 - INFO - __main__ - Global step 100 Train loss 0.59 Classification-F1 0.5485338279455927 on epoch=24
06/13/2022 09:21:04 - INFO - __main__ - Saving model with best Classification-F1: 0.4842347195288372 -> 0.5485338279455927 on epoch=24, global_step=100
06/13/2022 09:21:06 - INFO - __main__ - Step 110 Global step 110 Train loss 0.48 on epoch=27
06/13/2022 09:21:08 - INFO - __main__ - Step 120 Global step 120 Train loss 0.48 on epoch=29
06/13/2022 09:21:11 - INFO - __main__ - Step 130 Global step 130 Train loss 0.45 on epoch=32
06/13/2022 09:21:13 - INFO - __main__ - Step 140 Global step 140 Train loss 0.43 on epoch=34
06/13/2022 09:21:16 - INFO - __main__ - Step 150 Global step 150 Train loss 0.45 on epoch=37
06/13/2022 09:21:17 - INFO - __main__ - Global step 150 Train loss 0.46 Classification-F1 0.6386272526319734 on epoch=37
06/13/2022 09:21:17 - INFO - __main__ - Saving model with best Classification-F1: 0.5485338279455927 -> 0.6386272526319734 on epoch=37, global_step=150
06/13/2022 09:21:19 - INFO - __main__ - Step 160 Global step 160 Train loss 0.46 on epoch=39
06/13/2022 09:21:21 - INFO - __main__ - Step 170 Global step 170 Train loss 0.39 on epoch=42
06/13/2022 09:21:24 - INFO - __main__ - Step 180 Global step 180 Train loss 0.39 on epoch=44
06/13/2022 09:21:26 - INFO - __main__ - Step 190 Global step 190 Train loss 0.36 on epoch=47
06/13/2022 09:21:29 - INFO - __main__ - Step 200 Global step 200 Train loss 0.40 on epoch=49
06/13/2022 09:21:30 - INFO - __main__ - Global step 200 Train loss 0.40 Classification-F1 0.6527052926433732 on epoch=49
06/13/2022 09:21:30 - INFO - __main__ - Saving model with best Classification-F1: 0.6386272526319734 -> 0.6527052926433732 on epoch=49, global_step=200
06/13/2022 09:21:32 - INFO - __main__ - Step 210 Global step 210 Train loss 0.37 on epoch=52
06/13/2022 09:21:35 - INFO - __main__ - Step 220 Global step 220 Train loss 0.36 on epoch=54
06/13/2022 09:21:37 - INFO - __main__ - Step 230 Global step 230 Train loss 0.41 on epoch=57
06/13/2022 09:21:39 - INFO - __main__ - Step 240 Global step 240 Train loss 0.37 on epoch=59
06/13/2022 09:21:42 - INFO - __main__ - Step 250 Global step 250 Train loss 0.28 on epoch=62
06/13/2022 09:21:43 - INFO - __main__ - Global step 250 Train loss 0.36 Classification-F1 0.638961038961039 on epoch=62
06/13/2022 09:21:45 - INFO - __main__ - Step 260 Global step 260 Train loss 0.37 on epoch=64
06/13/2022 09:21:48 - INFO - __main__ - Step 270 Global step 270 Train loss 0.25 on epoch=67
06/13/2022 09:21:50 - INFO - __main__ - Step 280 Global step 280 Train loss 0.31 on epoch=69
06/13/2022 09:21:53 - INFO - __main__ - Step 290 Global step 290 Train loss 0.27 on epoch=72
06/13/2022 09:21:55 - INFO - __main__ - Step 300 Global step 300 Train loss 0.21 on epoch=74
06/13/2022 09:21:56 - INFO - __main__ - Global step 300 Train loss 0.28 Classification-F1 0.6383526383526384 on epoch=74
06/13/2022 09:21:58 - INFO - __main__ - Step 310 Global step 310 Train loss 0.29 on epoch=77
06/13/2022 09:22:01 - INFO - __main__ - Step 320 Global step 320 Train loss 0.22 on epoch=79
06/13/2022 09:22:03 - INFO - __main__ - Step 330 Global step 330 Train loss 0.21 on epoch=82
06/13/2022 09:22:06 - INFO - __main__ - Step 340 Global step 340 Train loss 0.17 on epoch=84
06/13/2022 09:22:08 - INFO - __main__ - Step 350 Global step 350 Train loss 0.20 on epoch=87
06/13/2022 09:22:09 - INFO - __main__ - Global step 350 Train loss 0.22 Classification-F1 0.611904761904762 on epoch=87
06/13/2022 09:22:11 - INFO - __main__ - Step 360 Global step 360 Train loss 0.25 on epoch=89
06/13/2022 09:22:14 - INFO - __main__ - Step 370 Global step 370 Train loss 0.24 on epoch=92
06/13/2022 09:22:16 - INFO - __main__ - Step 380 Global step 380 Train loss 0.19 on epoch=94
06/13/2022 09:22:19 - INFO - __main__ - Step 390 Global step 390 Train loss 0.11 on epoch=97
06/13/2022 09:22:21 - INFO - __main__ - Step 400 Global step 400 Train loss 0.14 on epoch=99
06/13/2022 09:22:22 - INFO - __main__ - Global step 400 Train loss 0.19 Classification-F1 0.6123511904761905 on epoch=99
06/13/2022 09:22:25 - INFO - __main__ - Step 410 Global step 410 Train loss 0.20 on epoch=102
06/13/2022 09:22:27 - INFO - __main__ - Step 420 Global step 420 Train loss 0.13 on epoch=104
06/13/2022 09:22:29 - INFO - __main__ - Step 430 Global step 430 Train loss 0.12 on epoch=107
06/13/2022 09:22:32 - INFO - __main__ - Step 440 Global step 440 Train loss 0.23 on epoch=109
06/13/2022 09:22:34 - INFO - __main__ - Step 450 Global step 450 Train loss 0.13 on epoch=112
06/13/2022 09:22:35 - INFO - __main__ - Global step 450 Train loss 0.16 Classification-F1 0.4925435540069687 on epoch=112
06/13/2022 09:22:38 - INFO - __main__ - Step 460 Global step 460 Train loss 0.15 on epoch=114
06/13/2022 09:22:40 - INFO - __main__ - Step 470 Global step 470 Train loss 0.13 on epoch=117
06/13/2022 09:22:42 - INFO - __main__ - Step 480 Global step 480 Train loss 0.09 on epoch=119
06/13/2022 09:22:45 - INFO - __main__ - Step 490 Global step 490 Train loss 0.10 on epoch=122
06/13/2022 09:22:47 - INFO - __main__ - Step 500 Global step 500 Train loss 0.12 on epoch=124
06/13/2022 09:22:48 - INFO - __main__ - Global step 500 Train loss 0.12 Classification-F1 0.624806426635695 on epoch=124
06/13/2022 09:22:51 - INFO - __main__ - Step 510 Global step 510 Train loss 0.11 on epoch=127
06/13/2022 09:22:53 - INFO - __main__ - Step 520 Global step 520 Train loss 0.12 on epoch=129
06/13/2022 09:22:56 - INFO - __main__ - Step 530 Global step 530 Train loss 0.24 on epoch=132
06/13/2022 09:22:58 - INFO - __main__ - Step 540 Global step 540 Train loss 0.08 on epoch=134
06/13/2022 09:23:01 - INFO - __main__ - Step 550 Global step 550 Train loss 0.10 on epoch=137
06/13/2022 09:23:02 - INFO - __main__ - Global step 550 Train loss 0.13 Classification-F1 0.6395225294418843 on epoch=137
06/13/2022 09:23:04 - INFO - __main__ - Step 560 Global step 560 Train loss 0.09 on epoch=139
06/13/2022 09:23:06 - INFO - __main__ - Step 570 Global step 570 Train loss 0.12 on epoch=142
06/13/2022 09:23:09 - INFO - __main__ - Step 580 Global step 580 Train loss 0.11 on epoch=144
06/13/2022 09:23:11 - INFO - __main__ - Step 590 Global step 590 Train loss 0.05 on epoch=147
06/13/2022 09:23:14 - INFO - __main__ - Step 600 Global step 600 Train loss 0.07 on epoch=149
06/13/2022 09:23:15 - INFO - __main__ - Global step 600 Train loss 0.09 Classification-F1 0.6395225294418843 on epoch=149
06/13/2022 09:23:17 - INFO - __main__ - Step 610 Global step 610 Train loss 0.08 on epoch=152
06/13/2022 09:23:20 - INFO - __main__ - Step 620 Global step 620 Train loss 0.21 on epoch=154
06/13/2022 09:23:22 - INFO - __main__ - Step 630 Global step 630 Train loss 0.07 on epoch=157
06/13/2022 09:23:24 - INFO - __main__ - Step 640 Global step 640 Train loss 0.11 on epoch=159
06/13/2022 09:23:27 - INFO - __main__ - Step 650 Global step 650 Train loss 0.20 on epoch=162
06/13/2022 09:23:28 - INFO - __main__ - Global step 650 Train loss 0.13 Classification-F1 0.6264321306807539 on epoch=162
06/13/2022 09:23:30 - INFO - __main__ - Step 660 Global step 660 Train loss 0.04 on epoch=164
06/13/2022 09:23:33 - INFO - __main__ - Step 670 Global step 670 Train loss 0.10 on epoch=167
06/13/2022 09:23:35 - INFO - __main__ - Step 680 Global step 680 Train loss 0.12 on epoch=169
06/13/2022 09:23:38 - INFO - __main__ - Step 690 Global step 690 Train loss 0.08 on epoch=172
06/13/2022 09:23:40 - INFO - __main__ - Step 700 Global step 700 Train loss 0.04 on epoch=174
06/13/2022 09:23:41 - INFO - __main__ - Global step 700 Train loss 0.08 Classification-F1 0.6264321306807539 on epoch=174
06/13/2022 09:23:44 - INFO - __main__ - Step 710 Global step 710 Train loss 0.07 on epoch=177
06/13/2022 09:23:46 - INFO - __main__ - Step 720 Global step 720 Train loss 0.05 on epoch=179
06/13/2022 09:23:48 - INFO - __main__ - Step 730 Global step 730 Train loss 0.08 on epoch=182
06/13/2022 09:23:51 - INFO - __main__ - Step 740 Global step 740 Train loss 0.02 on epoch=184
06/13/2022 09:23:53 - INFO - __main__ - Step 750 Global step 750 Train loss 0.05 on epoch=187
06/13/2022 09:23:54 - INFO - __main__ - Global step 750 Train loss 0.05 Classification-F1 0.6264321306807539 on epoch=187
06/13/2022 09:23:57 - INFO - __main__ - Step 760 Global step 760 Train loss 0.14 on epoch=189
06/13/2022 09:23:59 - INFO - __main__ - Step 770 Global step 770 Train loss 0.04 on epoch=192
06/13/2022 09:24:01 - INFO - __main__ - Step 780 Global step 780 Train loss 0.03 on epoch=194
06/13/2022 09:24:04 - INFO - __main__ - Step 790 Global step 790 Train loss 0.05 on epoch=197
06/13/2022 09:24:06 - INFO - __main__ - Step 800 Global step 800 Train loss 0.03 on epoch=199
06/13/2022 09:24:07 - INFO - __main__ - Global step 800 Train loss 0.06 Classification-F1 0.6395225294418843 on epoch=199
06/13/2022 09:24:10 - INFO - __main__ - Step 810 Global step 810 Train loss 0.08 on epoch=202
06/13/2022 09:24:12 - INFO - __main__ - Step 820 Global step 820 Train loss 0.04 on epoch=204
06/13/2022 09:24:14 - INFO - __main__ - Step 830 Global step 830 Train loss 0.04 on epoch=207
06/13/2022 09:24:17 - INFO - __main__ - Step 840 Global step 840 Train loss 0.04 on epoch=209
06/13/2022 09:24:19 - INFO - __main__ - Step 850 Global step 850 Train loss 0.03 on epoch=212
06/13/2022 09:24:20 - INFO - __main__ - Global step 850 Train loss 0.04 Classification-F1 0.6395225294418843 on epoch=212
06/13/2022 09:24:23 - INFO - __main__ - Step 860 Global step 860 Train loss 0.10 on epoch=214
06/13/2022 09:24:25 - INFO - __main__ - Step 870 Global step 870 Train loss 0.02 on epoch=217
06/13/2022 09:24:28 - INFO - __main__ - Step 880 Global step 880 Train loss 0.04 on epoch=219
06/13/2022 09:24:30 - INFO - __main__ - Step 890 Global step 890 Train loss 0.03 on epoch=222
06/13/2022 09:24:32 - INFO - __main__ - Step 900 Global step 900 Train loss 0.06 on epoch=224
06/13/2022 09:24:33 - INFO - __main__ - Global step 900 Train loss 0.05 Classification-F1 0.6526383526383527 on epoch=224
06/13/2022 09:24:36 - INFO - __main__ - Step 910 Global step 910 Train loss 0.02 on epoch=227
06/13/2022 09:24:38 - INFO - __main__ - Step 920 Global step 920 Train loss 0.08 on epoch=229
06/13/2022 09:24:41 - INFO - __main__ - Step 930 Global step 930 Train loss 0.02 on epoch=232
06/13/2022 09:24:43 - INFO - __main__ - Step 940 Global step 940 Train loss 0.06 on epoch=234
06/13/2022 09:24:46 - INFO - __main__ - Step 950 Global step 950 Train loss 0.01 on epoch=237
06/13/2022 09:24:47 - INFO - __main__ - Global step 950 Train loss 0.04 Classification-F1 0.681272374820762 on epoch=237
06/13/2022 09:24:47 - INFO - __main__ - Saving model with best Classification-F1: 0.6527052926433732 -> 0.681272374820762 on epoch=237, global_step=950
06/13/2022 09:24:49 - INFO - __main__ - Step 960 Global step 960 Train loss 0.08 on epoch=239
06/13/2022 09:24:51 - INFO - __main__ - Step 970 Global step 970 Train loss 0.03 on epoch=242
06/13/2022 09:24:54 - INFO - __main__ - Step 980 Global step 980 Train loss 0.05 on epoch=244
06/13/2022 09:24:56 - INFO - __main__ - Step 990 Global step 990 Train loss 0.02 on epoch=247
06/13/2022 09:24:59 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.02 on epoch=249
06/13/2022 09:25:00 - INFO - __main__ - Global step 1000 Train loss 0.04 Classification-F1 0.6395021645021645 on epoch=249
06/13/2022 09:25:02 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.06 on epoch=252
06/13/2022 09:25:05 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.01 on epoch=254
06/13/2022 09:25:07 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.04 on epoch=257
06/13/2022 09:25:09 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.04 on epoch=259
06/13/2022 09:25:12 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.01 on epoch=262
06/13/2022 09:25:13 - INFO - __main__ - Global step 1050 Train loss 0.03 Classification-F1 0.6956316807659519 on epoch=262
06/13/2022 09:25:13 - INFO - __main__ - Saving model with best Classification-F1: 0.681272374820762 -> 0.6956316807659519 on epoch=262, global_step=1050
06/13/2022 09:25:15 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.10 on epoch=264
06/13/2022 09:25:18 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.02 on epoch=267
06/13/2022 09:25:20 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.04 on epoch=269
06/13/2022 09:25:23 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.03 on epoch=272
06/13/2022 09:25:25 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.03 on epoch=274
06/13/2022 09:25:26 - INFO - __main__ - Global step 1100 Train loss 0.04 Classification-F1 0.6536682152535812 on epoch=274
06/13/2022 09:25:28 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.01 on epoch=277
06/13/2022 09:25:31 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.10 on epoch=279
06/13/2022 09:25:33 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.03 on epoch=282
06/13/2022 09:25:36 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.03 on epoch=284
06/13/2022 09:25:38 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=287
06/13/2022 09:25:39 - INFO - __main__ - Global step 1150 Train loss 0.03 Classification-F1 0.6442240627724499 on epoch=287
06/13/2022 09:25:42 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.01 on epoch=289
06/13/2022 09:25:44 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.01 on epoch=292
06/13/2022 09:25:47 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.04 on epoch=294
06/13/2022 09:25:49 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.03 on epoch=297
06/13/2022 09:25:51 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=299
06/13/2022 09:25:53 - INFO - __main__ - Global step 1200 Train loss 0.02 Classification-F1 0.6681515616999489 on epoch=299
06/13/2022 09:25:55 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.03 on epoch=302
06/13/2022 09:25:57 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=304
06/13/2022 09:26:00 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.02 on epoch=307
06/13/2022 09:26:02 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=309
06/13/2022 09:26:05 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.01 on epoch=312
06/13/2022 09:26:06 - INFO - __main__ - Global step 1250 Train loss 0.01 Classification-F1 0.681272374820762 on epoch=312
06/13/2022 09:26:08 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.03 on epoch=314
06/13/2022 09:26:10 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.03 on epoch=317
06/13/2022 09:26:13 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=319
06/13/2022 09:26:15 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=322
06/13/2022 09:26:18 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.02 on epoch=324
06/13/2022 09:26:19 - INFO - __main__ - Global step 1300 Train loss 0.02 Classification-F1 0.6690476190476191 on epoch=324
06/13/2022 09:26:21 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.02 on epoch=327
06/13/2022 09:26:24 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=329
06/13/2022 09:26:26 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.02 on epoch=332
06/13/2022 09:26:28 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=334
06/13/2022 09:26:31 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=337
06/13/2022 09:26:32 - INFO - __main__ - Global step 1350 Train loss 0.01 Classification-F1 0.7182295932295932 on epoch=337
06/13/2022 09:26:32 - INFO - __main__ - Saving model with best Classification-F1: 0.6956316807659519 -> 0.7182295932295932 on epoch=337, global_step=1350
06/13/2022 09:26:34 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=339
06/13/2022 09:26:37 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.02 on epoch=342
06/13/2022 09:26:39 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.03 on epoch=344
06/13/2022 09:26:42 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.02 on epoch=347
06/13/2022 09:26:44 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=349
06/13/2022 09:26:45 - INFO - __main__ - Global step 1400 Train loss 0.02 Classification-F1 0.6681515616999489 on epoch=349
06/13/2022 09:26:48 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.04 on epoch=352
06/13/2022 09:26:50 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.03 on epoch=354
06/13/2022 09:26:52 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=357
06/13/2022 09:26:55 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=359
06/13/2022 09:26:57 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=362
06/13/2022 09:26:58 - INFO - __main__ - Global step 1450 Train loss 0.02 Classification-F1 0.6825300038714672 on epoch=362
06/13/2022 09:27:01 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.02 on epoch=364
06/13/2022 09:27:03 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.06 on epoch=367
06/13/2022 09:27:06 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=369
06/13/2022 09:27:08 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=372
06/13/2022 09:27:11 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=374
06/13/2022 09:27:11 - INFO - __main__ - Global step 1500 Train loss 0.02 Classification-F1 0.7034845946387709 on epoch=374
06/13/2022 09:27:14 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=377
06/13/2022 09:27:16 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=379
06/13/2022 09:27:19 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=382
06/13/2022 09:27:21 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=384
06/13/2022 09:27:24 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=387
06/13/2022 09:27:25 - INFO - __main__ - Global step 1550 Train loss 0.00 Classification-F1 0.7033117389653892 on epoch=387
06/13/2022 09:27:27 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=389
06/13/2022 09:27:29 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=392
06/13/2022 09:27:32 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=394
06/13/2022 09:27:34 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=397
06/13/2022 09:27:37 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=399
06/13/2022 09:27:38 - INFO - __main__ - Global step 1600 Train loss 0.00 Classification-F1 0.7033117389653892 on epoch=399
06/13/2022 09:27:40 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=402
06/13/2022 09:27:43 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=404
06/13/2022 09:27:45 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=407
06/13/2022 09:27:48 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=409
06/13/2022 09:27:50 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=412
06/13/2022 09:27:51 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.7178670147420146 on epoch=412
06/13/2022 09:27:54 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=414
06/13/2022 09:27:56 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=417
06/13/2022 09:27:58 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=419
06/13/2022 09:28:01 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=422
06/13/2022 09:28:03 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=424
06/13/2022 09:28:04 - INFO - __main__ - Global step 1700 Train loss 0.00 Classification-F1 0.6955723345525977 on epoch=424
06/13/2022 09:28:07 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.03 on epoch=427
06/13/2022 09:28:09 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=429
06/13/2022 09:28:12 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=432
06/13/2022 09:28:14 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=434
06/13/2022 09:28:17 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=437
06/13/2022 09:28:18 - INFO - __main__ - Global step 1750 Train loss 0.01 Classification-F1 0.7033117389653892 on epoch=437
06/13/2022 09:28:20 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=439
06/13/2022 09:28:23 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=442
06/13/2022 09:28:25 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=444
06/13/2022 09:28:27 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=447
06/13/2022 09:28:30 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=449
06/13/2022 09:28:31 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.6957368082368082 on epoch=449
06/13/2022 09:28:33 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=452
06/13/2022 09:28:36 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=454
06/13/2022 09:28:38 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=457
06/13/2022 09:28:41 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=459
06/13/2022 09:28:43 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=462
06/13/2022 09:28:44 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.7178670147420146 on epoch=462
06/13/2022 09:28:47 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=464
06/13/2022 09:28:49 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=467
06/13/2022 09:28:52 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=469
06/13/2022 09:28:54 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=472
06/13/2022 09:28:57 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=474
06/13/2022 09:28:58 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.671546052631579 on epoch=474
06/13/2022 09:29:00 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=477
06/13/2022 09:29:03 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=479
06/13/2022 09:29:05 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=482
06/13/2022 09:29:07 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=484
06/13/2022 09:29:10 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=487
06/13/2022 09:29:11 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.718904303581723 on epoch=487
06/13/2022 09:29:11 - INFO - __main__ - Saving model with best Classification-F1: 0.7182295932295932 -> 0.718904303581723 on epoch=487, global_step=1950
06/13/2022 09:29:14 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=489
06/13/2022 09:29:16 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=492
06/13/2022 09:29:18 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=494
06/13/2022 09:29:21 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=497
06/13/2022 09:29:23 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=499
06/13/2022 09:29:24 - INFO - __main__ - Global step 2000 Train loss 0.00 Classification-F1 0.6955723345525977 on epoch=499
06/13/2022 09:29:27 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=502
06/13/2022 09:29:29 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.10 on epoch=504
06/13/2022 09:29:32 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/13/2022 09:29:34 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=509
06/13/2022 09:29:37 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/13/2022 09:29:38 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.6957368082368082 on epoch=512
06/13/2022 09:29:40 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=514
06/13/2022 09:29:43 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=517
06/13/2022 09:29:45 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/13/2022 09:29:47 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=522
06/13/2022 09:29:50 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/13/2022 09:29:51 - INFO - __main__ - Global step 2100 Train loss 0.00 Classification-F1 0.7178670147420146 on epoch=524
06/13/2022 09:29:53 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=527
06/13/2022 09:29:56 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/13/2022 09:29:58 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/13/2022 09:30:01 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
06/13/2022 09:30:03 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
06/13/2022 09:30:04 - INFO - __main__ - Global step 2150 Train loss 0.00 Classification-F1 0.6899547585031457 on epoch=537
06/13/2022 09:30:07 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=539
06/13/2022 09:30:09 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/13/2022 09:30:12 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=544
06/13/2022 09:30:14 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/13/2022 09:30:17 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/13/2022 09:30:18 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.6899547585031457 on epoch=549
06/13/2022 09:30:20 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/13/2022 09:30:22 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/13/2022 09:30:25 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=557
06/13/2022 09:30:27 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.03 on epoch=559
06/13/2022 09:30:30 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/13/2022 09:30:31 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.6822153540903542 on epoch=562
06/13/2022 09:30:33 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=564
06/13/2022 09:30:36 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/13/2022 09:30:38 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=569
06/13/2022 09:30:41 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/13/2022 09:30:43 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/13/2022 09:30:44 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.732695374800638 on epoch=574
06/13/2022 09:30:44 - INFO - __main__ - Saving model with best Classification-F1: 0.718904303581723 -> 0.732695374800638 on epoch=574, global_step=2300
06/13/2022 09:30:47 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/13/2022 09:30:49 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/13/2022 09:30:52 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.04 on epoch=582
06/13/2022 09:30:54 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/13/2022 09:30:57 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/13/2022 09:30:58 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.6955723345525977 on epoch=587
06/13/2022 09:31:00 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/13/2022 09:31:02 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/13/2022 09:31:05 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/13/2022 09:31:07 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=597
06/13/2022 09:31:10 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=599
06/13/2022 09:31:11 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.703357100415924 on epoch=599
06/13/2022 09:31:13 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=602
06/13/2022 09:31:16 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/13/2022 09:31:18 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.06 on epoch=607
06/13/2022 09:31:20 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/13/2022 09:31:23 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=612
06/13/2022 09:31:24 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.681272374820762 on epoch=612
06/13/2022 09:31:26 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/13/2022 09:31:29 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=617
06/13/2022 09:31:31 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.03 on epoch=619
06/13/2022 09:31:34 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/13/2022 09:31:36 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/13/2022 09:31:37 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.671546052631579 on epoch=624
06/13/2022 09:31:40 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=627
06/13/2022 09:31:42 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=629
06/13/2022 09:31:45 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=632
06/13/2022 09:31:47 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.04 on epoch=634
06/13/2022 09:31:49 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=637
06/13/2022 09:31:51 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.671546052631579 on epoch=637
06/13/2022 09:31:53 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=639
06/13/2022 09:31:55 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/13/2022 09:31:58 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/13/2022 09:32:00 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/13/2022 09:32:03 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/13/2022 09:32:04 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.671546052631579 on epoch=649
06/13/2022 09:32:06 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/13/2022 09:32:09 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=654
06/13/2022 09:32:11 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/13/2022 09:32:14 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/13/2022 09:32:16 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=662
06/13/2022 09:32:17 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.671546052631579 on epoch=662
06/13/2022 09:32:19 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/13/2022 09:32:22 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=667
06/13/2022 09:32:24 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/13/2022 09:32:27 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/13/2022 09:32:29 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/13/2022 09:32:30 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.681272374820762 on epoch=674
06/13/2022 09:32:33 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/13/2022 09:32:35 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/13/2022 09:32:37 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/13/2022 09:32:40 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=684
06/13/2022 09:32:42 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.03 on epoch=687
06/13/2022 09:32:43 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.7095472095472095 on epoch=687
06/13/2022 09:32:46 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/13/2022 09:32:48 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.05 on epoch=692
06/13/2022 09:32:51 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/13/2022 09:32:53 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.05 on epoch=697
06/13/2022 09:32:56 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/13/2022 09:32:57 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.6822153540903542 on epoch=699
06/13/2022 09:32:59 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/13/2022 09:33:01 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/13/2022 09:33:04 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/13/2022 09:33:06 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/13/2022 09:33:09 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=712
06/13/2022 09:33:10 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.6955723345525977 on epoch=712
06/13/2022 09:33:12 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/13/2022 09:33:15 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/13/2022 09:33:17 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/13/2022 09:33:19 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/13/2022 09:33:22 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/13/2022 09:33:23 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.6955723345525977 on epoch=724
06/13/2022 09:33:25 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/13/2022 09:33:28 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/13/2022 09:33:30 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/13/2022 09:33:33 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/13/2022 09:33:35 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/13/2022 09:33:36 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.6955723345525977 on epoch=737
06/13/2022 09:33:39 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/13/2022 09:33:41 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/13/2022 09:33:43 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/13/2022 09:33:46 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/13/2022 09:33:48 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/13/2022 09:33:49 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.6955723345525977 on epoch=749
06/13/2022 09:33:49 - INFO - __main__ - save last model!
06/13/2022 09:33:49 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/13/2022 09:33:49 - INFO - __main__ - Start tokenizing ... 5509 instances
06/13/2022 09:33:49 - INFO - __main__ - Printing 3 examples
06/13/2022 09:33:49 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/13/2022 09:33:49 - INFO - __main__ - ['others']
06/13/2022 09:33:49 - INFO - __main__ -  [emo] what you like very little things ok
06/13/2022 09:33:49 - INFO - __main__ - ['others']
06/13/2022 09:33:49 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/13/2022 09:33:49 - INFO - __main__ - ['others']
06/13/2022 09:33:49 - INFO - __main__ - Tokenizing Input ...
06/13/2022 09:33:50 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 09:33:50 - INFO - __main__ - Printing 3 examples
06/13/2022 09:33:50 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/13/2022 09:33:50 - INFO - __main__ - ['sad']
06/13/2022 09:33:50 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/13/2022 09:33:50 - INFO - __main__ - ['sad']
06/13/2022 09:33:50 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/13/2022 09:33:50 - INFO - __main__ - ['sad']
06/13/2022 09:33:50 - INFO - __main__ - Tokenizing Input ...
06/13/2022 09:33:50 - INFO - __main__ - Tokenizing Output ...
06/13/2022 09:33:50 - INFO - __main__ - Loaded 64 examples from train data
06/13/2022 09:33:50 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 09:33:50 - INFO - __main__ - Printing 3 examples
06/13/2022 09:33:50 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
06/13/2022 09:33:50 - INFO - __main__ - ['sad']
06/13/2022 09:33:50 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
06/13/2022 09:33:50 - INFO - __main__ - ['sad']
06/13/2022 09:33:50 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
06/13/2022 09:33:50 - INFO - __main__ - ['sad']
06/13/2022 09:33:50 - INFO - __main__ - Tokenizing Input ...
06/13/2022 09:33:50 - INFO - __main__ - Tokenizing Output ...
06/13/2022 09:33:50 - INFO - __main__ - Loaded 64 examples from dev data
06/13/2022 09:33:52 - INFO - __main__ - Tokenizing Output ...
06/13/2022 09:33:57 - INFO - __main__ - Loaded 5509 examples from test data
06/13/2022 09:34:05 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 09:34:06 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 09:34:06 - INFO - __main__ - Starting training!
06/13/2022 09:35:33 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-up32shot/singletask-emo/emo_16_21_0.5_8_predictions.txt
06/13/2022 09:35:33 - INFO - __main__ - Classification-F1 on test data: 0.2420
06/13/2022 09:35:33 - INFO - __main__ - prefix=emo_16_21, lr=0.5, bsz=8, dev_performance=0.732695374800638, test_performance=0.2419533175023131
06/13/2022 09:35:33 - INFO - __main__ - Running ... prefix=emo_16_21, lr=0.4, bsz=8 ...
06/13/2022 09:35:34 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 09:35:34 - INFO - __main__ - Printing 3 examples
06/13/2022 09:35:34 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/13/2022 09:35:34 - INFO - __main__ - ['sad']
06/13/2022 09:35:34 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/13/2022 09:35:34 - INFO - __main__ - ['sad']
06/13/2022 09:35:34 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/13/2022 09:35:34 - INFO - __main__ - ['sad']
06/13/2022 09:35:34 - INFO - __main__ - Tokenizing Input ...
06/13/2022 09:35:34 - INFO - __main__ - Tokenizing Output ...
06/13/2022 09:35:34 - INFO - __main__ - Loaded 64 examples from train data
06/13/2022 09:35:34 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 09:35:34 - INFO - __main__ - Printing 3 examples
06/13/2022 09:35:34 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
06/13/2022 09:35:34 - INFO - __main__ - ['sad']
06/13/2022 09:35:34 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
06/13/2022 09:35:34 - INFO - __main__ - ['sad']
06/13/2022 09:35:34 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
06/13/2022 09:35:34 - INFO - __main__ - ['sad']
06/13/2022 09:35:34 - INFO - __main__ - Tokenizing Input ...
06/13/2022 09:35:34 - INFO - __main__ - Tokenizing Output ...
06/13/2022 09:35:34 - INFO - __main__ - Loaded 64 examples from dev data
06/13/2022 09:35:50 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 09:35:50 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 09:35:50 - INFO - __main__ - Starting training!
06/13/2022 09:35:53 - INFO - __main__ - Step 10 Global step 10 Train loss 3.89 on epoch=2
06/13/2022 09:35:56 - INFO - __main__ - Step 20 Global step 20 Train loss 2.69 on epoch=4
06/13/2022 09:35:58 - INFO - __main__ - Step 30 Global step 30 Train loss 1.97 on epoch=7
06/13/2022 09:36:01 - INFO - __main__ - Step 40 Global step 40 Train loss 1.46 on epoch=9
06/13/2022 09:36:03 - INFO - __main__ - Step 50 Global step 50 Train loss 1.11 on epoch=12
06/13/2022 09:36:04 - INFO - __main__ - Global step 50 Train loss 2.23 Classification-F1 0.4668240454076368 on epoch=12
06/13/2022 09:36:04 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.4668240454076368 on epoch=12, global_step=50
06/13/2022 09:36:07 - INFO - __main__ - Step 60 Global step 60 Train loss 1.06 on epoch=14
06/13/2022 09:36:09 - INFO - __main__ - Step 70 Global step 70 Train loss 0.81 on epoch=17
06/13/2022 09:36:11 - INFO - __main__ - Step 80 Global step 80 Train loss 0.77 on epoch=19
06/13/2022 09:36:14 - INFO - __main__ - Step 90 Global step 90 Train loss 0.69 on epoch=22
06/13/2022 09:36:16 - INFO - __main__ - Step 100 Global step 100 Train loss 0.56 on epoch=24
06/13/2022 09:36:17 - INFO - __main__ - Global step 100 Train loss 0.78 Classification-F1 0.5485338279455927 on epoch=24
06/13/2022 09:36:17 - INFO - __main__ - Saving model with best Classification-F1: 0.4668240454076368 -> 0.5485338279455927 on epoch=24, global_step=100
06/13/2022 09:36:20 - INFO - __main__ - Step 110 Global step 110 Train loss 0.52 on epoch=27
06/13/2022 09:36:22 - INFO - __main__ - Step 120 Global step 120 Train loss 0.59 on epoch=29
06/13/2022 09:36:24 - INFO - __main__ - Step 130 Global step 130 Train loss 0.53 on epoch=32
06/13/2022 09:36:27 - INFO - __main__ - Step 140 Global step 140 Train loss 0.50 on epoch=34
06/13/2022 09:36:29 - INFO - __main__ - Step 150 Global step 150 Train loss 0.63 on epoch=37
06/13/2022 09:36:30 - INFO - __main__ - Global step 150 Train loss 0.56 Classification-F1 0.6180223285486444 on epoch=37
06/13/2022 09:36:30 - INFO - __main__ - Saving model with best Classification-F1: 0.5485338279455927 -> 0.6180223285486444 on epoch=37, global_step=150
06/13/2022 09:36:33 - INFO - __main__ - Step 160 Global step 160 Train loss 0.44 on epoch=39
06/13/2022 09:36:35 - INFO - __main__ - Step 170 Global step 170 Train loss 0.32 on epoch=42
06/13/2022 09:36:38 - INFO - __main__ - Step 180 Global step 180 Train loss 0.38 on epoch=44
06/13/2022 09:36:40 - INFO - __main__ - Step 190 Global step 190 Train loss 0.40 on epoch=47
06/13/2022 09:36:42 - INFO - __main__ - Step 200 Global step 200 Train loss 0.42 on epoch=49
06/13/2022 09:36:43 - INFO - __main__ - Global step 200 Train loss 0.39 Classification-F1 0.6567595459236326 on epoch=49
06/13/2022 09:36:43 - INFO - __main__ - Saving model with best Classification-F1: 0.6180223285486444 -> 0.6567595459236326 on epoch=49, global_step=200
06/13/2022 09:36:46 - INFO - __main__ - Step 210 Global step 210 Train loss 0.44 on epoch=52
06/13/2022 09:36:48 - INFO - __main__ - Step 220 Global step 220 Train loss 0.32 on epoch=54
06/13/2022 09:36:51 - INFO - __main__ - Step 230 Global step 230 Train loss 0.42 on epoch=57
06/13/2022 09:36:53 - INFO - __main__ - Step 240 Global step 240 Train loss 0.40 on epoch=59
06/13/2022 09:36:56 - INFO - __main__ - Step 250 Global step 250 Train loss 0.31 on epoch=62
06/13/2022 09:36:56 - INFO - __main__ - Global step 250 Train loss 0.38 Classification-F1 0.6238095238095238 on epoch=62
06/13/2022 09:36:59 - INFO - __main__ - Step 260 Global step 260 Train loss 0.34 on epoch=64
06/13/2022 09:37:01 - INFO - __main__ - Step 270 Global step 270 Train loss 0.25 on epoch=67
06/13/2022 09:37:04 - INFO - __main__ - Step 280 Global step 280 Train loss 0.34 on epoch=69
06/13/2022 09:37:06 - INFO - __main__ - Step 290 Global step 290 Train loss 0.30 on epoch=72
06/13/2022 09:37:09 - INFO - __main__ - Step 300 Global step 300 Train loss 0.36 on epoch=74
06/13/2022 09:37:10 - INFO - __main__ - Global step 300 Train loss 0.32 Classification-F1 0.6386272526319734 on epoch=74
06/13/2022 09:37:12 - INFO - __main__ - Step 310 Global step 310 Train loss 0.26 on epoch=77
06/13/2022 09:37:15 - INFO - __main__ - Step 320 Global step 320 Train loss 0.25 on epoch=79
06/13/2022 09:37:17 - INFO - __main__ - Step 330 Global step 330 Train loss 0.25 on epoch=82
06/13/2022 09:37:19 - INFO - __main__ - Step 340 Global step 340 Train loss 0.24 on epoch=84
06/13/2022 09:37:22 - INFO - __main__ - Step 350 Global step 350 Train loss 0.27 on epoch=87
06/13/2022 09:37:23 - INFO - __main__ - Global step 350 Train loss 0.25 Classification-F1 0.6386272526319734 on epoch=87
06/13/2022 09:37:25 - INFO - __main__ - Step 360 Global step 360 Train loss 0.20 on epoch=89
06/13/2022 09:37:28 - INFO - __main__ - Step 370 Global step 370 Train loss 0.29 on epoch=92
06/13/2022 09:37:30 - INFO - __main__ - Step 380 Global step 380 Train loss 0.21 on epoch=94
06/13/2022 09:37:33 - INFO - __main__ - Step 390 Global step 390 Train loss 0.30 on epoch=97
06/13/2022 09:37:35 - INFO - __main__ - Step 400 Global step 400 Train loss 0.25 on epoch=99
06/13/2022 09:37:36 - INFO - __main__ - Global step 400 Train loss 0.25 Classification-F1 0.6404761904761904 on epoch=99
06/13/2022 09:37:38 - INFO - __main__ - Step 410 Global step 410 Train loss 0.21 on epoch=102
06/13/2022 09:37:41 - INFO - __main__ - Step 420 Global step 420 Train loss 0.23 on epoch=104
06/13/2022 09:37:43 - INFO - __main__ - Step 430 Global step 430 Train loss 0.18 on epoch=107
06/13/2022 09:37:46 - INFO - __main__ - Step 440 Global step 440 Train loss 0.17 on epoch=109
06/13/2022 09:37:48 - INFO - __main__ - Step 450 Global step 450 Train loss 0.19 on epoch=112
06/13/2022 09:37:49 - INFO - __main__ - Global step 450 Train loss 0.20 Classification-F1 0.6628342245989305 on epoch=112
06/13/2022 09:37:49 - INFO - __main__ - Saving model with best Classification-F1: 0.6567595459236326 -> 0.6628342245989305 on epoch=112, global_step=450
06/13/2022 09:37:52 - INFO - __main__ - Step 460 Global step 460 Train loss 0.18 on epoch=114
06/13/2022 09:37:54 - INFO - __main__ - Step 470 Global step 470 Train loss 0.21 on epoch=117
06/13/2022 09:37:57 - INFO - __main__ - Step 480 Global step 480 Train loss 0.19 on epoch=119
06/13/2022 09:37:59 - INFO - __main__ - Step 490 Global step 490 Train loss 0.22 on epoch=122
06/13/2022 09:38:02 - INFO - __main__ - Step 500 Global step 500 Train loss 0.17 on epoch=124
06/13/2022 09:38:03 - INFO - __main__ - Global step 500 Train loss 0.20 Classification-F1 0.6404761904761904 on epoch=124
06/13/2022 09:38:05 - INFO - __main__ - Step 510 Global step 510 Train loss 0.16 on epoch=127
06/13/2022 09:38:08 - INFO - __main__ - Step 520 Global step 520 Train loss 0.18 on epoch=129
06/13/2022 09:38:10 - INFO - __main__ - Step 530 Global step 530 Train loss 0.10 on epoch=132
06/13/2022 09:38:13 - INFO - __main__ - Step 540 Global step 540 Train loss 0.15 on epoch=134
06/13/2022 09:38:15 - INFO - __main__ - Step 550 Global step 550 Train loss 0.14 on epoch=137
06/13/2022 09:38:16 - INFO - __main__ - Global step 550 Train loss 0.15 Classification-F1 0.49658536585365853 on epoch=137
06/13/2022 09:38:19 - INFO - __main__ - Step 560 Global step 560 Train loss 0.11 on epoch=139
06/13/2022 09:38:21 - INFO - __main__ - Step 570 Global step 570 Train loss 0.12 on epoch=142
06/13/2022 09:38:23 - INFO - __main__ - Step 580 Global step 580 Train loss 0.19 on epoch=144
06/13/2022 09:38:26 - INFO - __main__ - Step 590 Global step 590 Train loss 0.13 on epoch=147
06/13/2022 09:38:28 - INFO - __main__ - Step 600 Global step 600 Train loss 0.07 on epoch=149
06/13/2022 09:38:29 - INFO - __main__ - Global step 600 Train loss 0.12 Classification-F1 0.6752525252525253 on epoch=149
06/13/2022 09:38:29 - INFO - __main__ - Saving model with best Classification-F1: 0.6628342245989305 -> 0.6752525252525253 on epoch=149, global_step=600
06/13/2022 09:38:32 - INFO - __main__ - Step 610 Global step 610 Train loss 0.11 on epoch=152
06/13/2022 09:38:34 - INFO - __main__ - Step 620 Global step 620 Train loss 0.14 on epoch=154
06/13/2022 09:38:37 - INFO - __main__ - Step 630 Global step 630 Train loss 0.09 on epoch=157
06/13/2022 09:38:39 - INFO - __main__ - Step 640 Global step 640 Train loss 0.14 on epoch=159
06/13/2022 09:38:42 - INFO - __main__ - Step 650 Global step 650 Train loss 0.12 on epoch=162
06/13/2022 09:38:43 - INFO - __main__ - Global step 650 Train loss 0.12 Classification-F1 0.6477115626309174 on epoch=162
06/13/2022 09:38:45 - INFO - __main__ - Step 660 Global step 660 Train loss 0.13 on epoch=164
06/13/2022 09:38:47 - INFO - __main__ - Step 670 Global step 670 Train loss 0.05 on epoch=167
06/13/2022 09:38:50 - INFO - __main__ - Step 680 Global step 680 Train loss 0.13 on epoch=169
06/13/2022 09:38:52 - INFO - __main__ - Step 690 Global step 690 Train loss 0.07 on epoch=172
06/13/2022 09:38:55 - INFO - __main__ - Step 700 Global step 700 Train loss 0.14 on epoch=174
06/13/2022 09:38:56 - INFO - __main__ - Global step 700 Train loss 0.10 Classification-F1 0.6166666666666667 on epoch=174
06/13/2022 09:38:58 - INFO - __main__ - Step 710 Global step 710 Train loss 0.07 on epoch=177
06/13/2022 09:39:01 - INFO - __main__ - Step 720 Global step 720 Train loss 0.07 on epoch=179
06/13/2022 09:39:03 - INFO - __main__ - Step 730 Global step 730 Train loss 0.10 on epoch=182
06/13/2022 09:39:05 - INFO - __main__ - Step 740 Global step 740 Train loss 0.10 on epoch=184
06/13/2022 09:39:08 - INFO - __main__ - Step 750 Global step 750 Train loss 0.07 on epoch=187
06/13/2022 09:39:09 - INFO - __main__ - Global step 750 Train loss 0.08 Classification-F1 0.6425438596491229 on epoch=187
06/13/2022 09:39:11 - INFO - __main__ - Step 760 Global step 760 Train loss 0.11 on epoch=189
06/13/2022 09:39:14 - INFO - __main__ - Step 770 Global step 770 Train loss 0.07 on epoch=192
06/13/2022 09:39:16 - INFO - __main__ - Step 780 Global step 780 Train loss 0.09 on epoch=194
06/13/2022 09:39:19 - INFO - __main__ - Step 790 Global step 790 Train loss 0.05 on epoch=197
06/13/2022 09:39:21 - INFO - __main__ - Step 800 Global step 800 Train loss 0.06 on epoch=199
06/13/2022 09:39:22 - INFO - __main__ - Global step 800 Train loss 0.08 Classification-F1 0.6610052134245683 on epoch=199
06/13/2022 09:39:25 - INFO - __main__ - Step 810 Global step 810 Train loss 0.08 on epoch=202
06/13/2022 09:39:27 - INFO - __main__ - Step 820 Global step 820 Train loss 0.07 on epoch=204
06/13/2022 09:39:30 - INFO - __main__ - Step 830 Global step 830 Train loss 0.06 on epoch=207
06/13/2022 09:39:32 - INFO - __main__ - Step 840 Global step 840 Train loss 0.05 on epoch=209
06/13/2022 09:39:34 - INFO - __main__ - Step 850 Global step 850 Train loss 0.05 on epoch=212
06/13/2022 09:39:35 - INFO - __main__ - Global step 850 Train loss 0.06 Classification-F1 0.6517301317810655 on epoch=212
06/13/2022 09:39:38 - INFO - __main__ - Step 860 Global step 860 Train loss 0.04 on epoch=214
06/13/2022 09:39:40 - INFO - __main__ - Step 870 Global step 870 Train loss 0.06 on epoch=217
06/13/2022 09:39:43 - INFO - __main__ - Step 880 Global step 880 Train loss 0.02 on epoch=219
06/13/2022 09:39:45 - INFO - __main__ - Step 890 Global step 890 Train loss 0.03 on epoch=222
06/13/2022 09:39:48 - INFO - __main__ - Step 900 Global step 900 Train loss 0.04 on epoch=224
06/13/2022 09:39:49 - INFO - __main__ - Global step 900 Train loss 0.04 Classification-F1 0.7033045273534404 on epoch=224
06/13/2022 09:39:49 - INFO - __main__ - Saving model with best Classification-F1: 0.6752525252525253 -> 0.7033045273534404 on epoch=224, global_step=900
06/13/2022 09:39:51 - INFO - __main__ - Step 910 Global step 910 Train loss 0.05 on epoch=227
06/13/2022 09:39:54 - INFO - __main__ - Step 920 Global step 920 Train loss 0.07 on epoch=229
06/13/2022 09:39:56 - INFO - __main__ - Step 930 Global step 930 Train loss 0.04 on epoch=232
06/13/2022 09:39:59 - INFO - __main__ - Step 940 Global step 940 Train loss 0.02 on epoch=234
06/13/2022 09:40:01 - INFO - __main__ - Step 950 Global step 950 Train loss 0.06 on epoch=237
06/13/2022 09:40:02 - INFO - __main__ - Global step 950 Train loss 0.05 Classification-F1 0.6664338210390842 on epoch=237
06/13/2022 09:40:05 - INFO - __main__ - Step 960 Global step 960 Train loss 0.04 on epoch=239
06/13/2022 09:40:07 - INFO - __main__ - Step 970 Global step 970 Train loss 0.05 on epoch=242
06/13/2022 09:40:10 - INFO - __main__ - Step 980 Global step 980 Train loss 0.04 on epoch=244
06/13/2022 09:40:12 - INFO - __main__ - Step 990 Global step 990 Train loss 0.05 on epoch=247
06/13/2022 09:40:14 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.01 on epoch=249
06/13/2022 09:40:15 - INFO - __main__ - Global step 1000 Train loss 0.04 Classification-F1 0.680783397888661 on epoch=249
06/13/2022 09:40:18 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.01 on epoch=252
06/13/2022 09:40:20 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.10 on epoch=254
06/13/2022 09:40:23 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.03 on epoch=257
06/13/2022 09:40:25 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.02 on epoch=259
06/13/2022 09:40:28 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.04 on epoch=262
06/13/2022 09:40:29 - INFO - __main__ - Global step 1050 Train loss 0.04 Classification-F1 0.6810170587759722 on epoch=262
06/13/2022 09:40:31 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.02 on epoch=264
06/13/2022 09:40:33 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.01 on epoch=267
06/13/2022 09:40:36 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.03 on epoch=269
06/13/2022 09:40:38 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.05 on epoch=272
06/13/2022 09:40:41 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.05 on epoch=274
06/13/2022 09:40:42 - INFO - __main__ - Global step 1100 Train loss 0.03 Classification-F1 0.7042547182349814 on epoch=274
06/13/2022 09:40:42 - INFO - __main__ - Saving model with best Classification-F1: 0.7033045273534404 -> 0.7042547182349814 on epoch=274, global_step=1100
06/13/2022 09:40:44 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.04 on epoch=277
06/13/2022 09:40:47 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.02 on epoch=279
06/13/2022 09:40:49 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.07 on epoch=282
06/13/2022 09:40:51 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.01 on epoch=284
06/13/2022 09:40:54 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.02 on epoch=287
06/13/2022 09:40:55 - INFO - __main__ - Global step 1150 Train loss 0.03 Classification-F1 0.7042547182349814 on epoch=287
06/13/2022 09:40:57 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.09 on epoch=289
06/13/2022 09:41:00 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.03 on epoch=292
06/13/2022 09:41:02 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.03 on epoch=294
06/13/2022 09:41:04 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.08 on epoch=297
06/13/2022 09:41:07 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=299
06/13/2022 09:41:08 - INFO - __main__ - Global step 1200 Train loss 0.05 Classification-F1 0.7042547182349814 on epoch=299
06/13/2022 09:41:10 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.01 on epoch=302
06/13/2022 09:41:13 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.04 on epoch=304
06/13/2022 09:41:15 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.15 on epoch=307
06/13/2022 09:41:18 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.10 on epoch=309
06/13/2022 09:41:20 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.09 on epoch=312
06/13/2022 09:41:21 - INFO - __main__ - Global step 1250 Train loss 0.08 Classification-F1 0.6755913568399727 on epoch=312
06/13/2022 09:41:23 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=314
06/13/2022 09:41:26 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.02 on epoch=317
06/13/2022 09:41:28 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=319
06/13/2022 09:41:31 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.07 on epoch=322
06/13/2022 09:41:33 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.02 on epoch=324
06/13/2022 09:41:34 - INFO - __main__ - Global step 1300 Train loss 0.03 Classification-F1 0.6665701415701416 on epoch=324
06/13/2022 09:41:37 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=327
06/13/2022 09:41:39 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.04 on epoch=329
06/13/2022 09:41:41 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.02 on epoch=332
06/13/2022 09:41:44 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.06 on epoch=334
06/13/2022 09:41:46 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.02 on epoch=337
06/13/2022 09:41:47 - INFO - __main__ - Global step 1350 Train loss 0.03 Classification-F1 0.7033117389653892 on epoch=337
06/13/2022 09:41:50 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=339
06/13/2022 09:41:52 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.02 on epoch=342
06/13/2022 09:41:55 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=344
06/13/2022 09:41:57 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=347
06/13/2022 09:41:59 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=349
06/13/2022 09:42:00 - INFO - __main__ - Global step 1400 Train loss 0.01 Classification-F1 0.7033117389653892 on epoch=349
06/13/2022 09:42:03 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.03 on epoch=352
06/13/2022 09:42:05 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.01 on epoch=354
06/13/2022 09:42:08 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.03 on epoch=357
06/13/2022 09:42:10 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=359
06/13/2022 09:42:12 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=362
06/13/2022 09:42:13 - INFO - __main__ - Global step 1450 Train loss 0.02 Classification-F1 0.6702375762859634 on epoch=362
06/13/2022 09:42:16 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=364
06/13/2022 09:42:18 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=367
06/13/2022 09:42:21 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=369
06/13/2022 09:42:23 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.05 on epoch=372
06/13/2022 09:42:26 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=374
06/13/2022 09:42:27 - INFO - __main__ - Global step 1500 Train loss 0.02 Classification-F1 0.6572460928997432 on epoch=374
06/13/2022 09:42:29 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.03 on epoch=377
06/13/2022 09:42:31 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.02 on epoch=379
06/13/2022 09:42:34 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=382
06/13/2022 09:42:36 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=384
06/13/2022 09:42:39 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.04 on epoch=387
06/13/2022 09:42:40 - INFO - __main__ - Global step 1550 Train loss 0.02 Classification-F1 0.6854531001589824 on epoch=387
06/13/2022 09:42:42 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=389
06/13/2022 09:42:45 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.07 on epoch=392
06/13/2022 09:42:47 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=394
06/13/2022 09:42:50 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=397
06/13/2022 09:42:52 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=399
06/13/2022 09:42:53 - INFO - __main__ - Global step 1600 Train loss 0.02 Classification-F1 0.6752525252525253 on epoch=399
06/13/2022 09:42:56 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=402
06/13/2022 09:42:58 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=404
06/13/2022 09:43:00 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=407
06/13/2022 09:43:03 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=409
06/13/2022 09:43:05 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=412
06/13/2022 09:43:06 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.7042547182349814 on epoch=412
06/13/2022 09:43:09 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.03 on epoch=414
06/13/2022 09:43:11 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=417
06/13/2022 09:43:14 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=419
06/13/2022 09:43:16 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=422
06/13/2022 09:43:19 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=424
06/13/2022 09:43:20 - INFO - __main__ - Global step 1700 Train loss 0.01 Classification-F1 0.731951871657754 on epoch=424
06/13/2022 09:43:20 - INFO - __main__ - Saving model with best Classification-F1: 0.7042547182349814 -> 0.731951871657754 on epoch=424, global_step=1700
06/13/2022 09:43:22 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=427
06/13/2022 09:43:24 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=429
06/13/2022 09:43:27 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=432
06/13/2022 09:43:29 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=434
06/13/2022 09:43:32 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.07 on epoch=437
06/13/2022 09:43:33 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.731951871657754 on epoch=437
06/13/2022 09:43:35 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=439
06/13/2022 09:43:38 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=442
06/13/2022 09:43:40 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=444
06/13/2022 09:43:43 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=447
06/13/2022 09:43:45 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=449
06/13/2022 09:43:46 - INFO - __main__ - Global step 1800 Train loss 0.00 Classification-F1 0.6899547585031457 on epoch=449
06/13/2022 09:43:49 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=452
06/13/2022 09:43:51 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=454
06/13/2022 09:43:54 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=457
06/13/2022 09:43:56 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=459
06/13/2022 09:43:58 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.06 on epoch=462
06/13/2022 09:43:59 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.6881180223285487 on epoch=462
06/13/2022 09:44:02 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=464
06/13/2022 09:44:04 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.04 on epoch=467
06/13/2022 09:44:07 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=469
06/13/2022 09:44:09 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=472
06/13/2022 09:44:12 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.08 on epoch=474
06/13/2022 09:44:13 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.7326275473334296 on epoch=474
06/13/2022 09:44:13 - INFO - __main__ - Saving model with best Classification-F1: 0.731951871657754 -> 0.7326275473334296 on epoch=474, global_step=1900
06/13/2022 09:44:15 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=477
06/13/2022 09:44:18 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=479
06/13/2022 09:44:20 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=482
06/13/2022 09:44:23 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=484
06/13/2022 09:44:25 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=487
06/13/2022 09:44:26 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.7186049686049686 on epoch=487
06/13/2022 09:44:29 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=489
06/13/2022 09:44:31 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=492
06/13/2022 09:44:34 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=494
06/13/2022 09:44:36 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=497
06/13/2022 09:44:38 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=499
06/13/2022 09:44:39 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.7466748937337173 on epoch=499
06/13/2022 09:44:39 - INFO - __main__ - Saving model with best Classification-F1: 0.7326275473334296 -> 0.7466748937337173 on epoch=499, global_step=2000
06/13/2022 09:44:42 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=502
06/13/2022 09:44:44 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
06/13/2022 09:44:47 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=507
06/13/2022 09:44:49 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=509
06/13/2022 09:44:52 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/13/2022 09:44:53 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.696104242979243 on epoch=512
06/13/2022 09:44:55 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=514
06/13/2022 09:44:58 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=517
06/13/2022 09:45:00 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=519
06/13/2022 09:45:03 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=522
06/13/2022 09:45:05 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/13/2022 09:45:06 - INFO - __main__ - Global step 2100 Train loss 0.00 Classification-F1 0.7250053867700927 on epoch=524
06/13/2022 09:45:08 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
06/13/2022 09:45:11 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/13/2022 09:45:13 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=532
06/13/2022 09:45:16 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
06/13/2022 09:45:18 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=537
06/13/2022 09:45:19 - INFO - __main__ - Global step 2150 Train loss 0.00 Classification-F1 0.7245511841100077 on epoch=537
06/13/2022 09:45:22 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/13/2022 09:45:24 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=542
06/13/2022 09:45:27 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/13/2022 09:45:29 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/13/2022 09:45:32 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=549
06/13/2022 09:45:33 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.7234765234765235 on epoch=549
06/13/2022 09:45:35 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=552
06/13/2022 09:45:38 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/13/2022 09:45:40 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
06/13/2022 09:45:43 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=559
06/13/2022 09:45:45 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/13/2022 09:45:46 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.7245511841100077 on epoch=562
06/13/2022 09:45:49 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=564
06/13/2022 09:45:51 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/13/2022 09:45:53 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=569
06/13/2022 09:45:56 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/13/2022 09:45:58 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=574
06/13/2022 09:45:59 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.709672619047619 on epoch=574
06/13/2022 09:46:02 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.07 on epoch=577
06/13/2022 09:46:04 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/13/2022 09:46:07 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/13/2022 09:46:09 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/13/2022 09:46:12 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/13/2022 09:46:12 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.7106560106560106 on epoch=587
06/13/2022 09:46:15 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=589
06/13/2022 09:46:17 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/13/2022 09:46:20 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/13/2022 09:46:22 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/13/2022 09:46:25 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/13/2022 09:46:26 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.7106560106560106 on epoch=599
06/13/2022 09:46:28 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=602
06/13/2022 09:46:31 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=604
06/13/2022 09:46:33 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/13/2022 09:46:36 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=609
06/13/2022 09:46:38 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=612
06/13/2022 09:46:39 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.7392570664629489 on epoch=612
06/13/2022 09:46:41 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/13/2022 09:46:44 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=617
06/13/2022 09:46:46 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=619
06/13/2022 09:46:49 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=622
06/13/2022 09:46:51 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/13/2022 09:46:52 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.709672619047619 on epoch=624
06/13/2022 09:46:54 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.08 on epoch=627
06/13/2022 09:46:57 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/13/2022 09:46:59 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.04 on epoch=632
06/13/2022 09:47:01 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/13/2022 09:47:04 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/13/2022 09:47:05 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.7033117389653892 on epoch=637
06/13/2022 09:47:07 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=639
06/13/2022 09:47:10 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.04 on epoch=642
06/13/2022 09:47:12 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=644
06/13/2022 09:47:15 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/13/2022 09:47:17 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/13/2022 09:47:18 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.6959349130401763 on epoch=649
06/13/2022 09:47:20 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/13/2022 09:47:23 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/13/2022 09:47:25 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/13/2022 09:47:28 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=659
06/13/2022 09:47:30 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=662
06/13/2022 09:47:31 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.7182295932295932 on epoch=662
06/13/2022 09:47:34 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/13/2022 09:47:36 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/13/2022 09:47:39 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/13/2022 09:47:41 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=672
06/13/2022 09:47:44 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/13/2022 09:47:45 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.7182295932295932 on epoch=674
06/13/2022 09:47:47 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=677
06/13/2022 09:47:49 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/13/2022 09:47:52 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/13/2022 09:47:54 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/13/2022 09:47:57 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.03 on epoch=687
06/13/2022 09:47:58 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.7039459561198691 on epoch=687
06/13/2022 09:48:00 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/13/2022 09:48:03 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/13/2022 09:48:05 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.04 on epoch=694
06/13/2022 09:48:08 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/13/2022 09:48:10 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/13/2022 09:48:11 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.7178751641667243 on epoch=699
06/13/2022 09:48:14 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=702
06/13/2022 09:48:16 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/13/2022 09:48:19 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/13/2022 09:48:21 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/13/2022 09:48:23 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/13/2022 09:48:24 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.732695374800638 on epoch=712
06/13/2022 09:48:27 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=714
06/13/2022 09:48:30 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/13/2022 09:48:32 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/13/2022 09:48:35 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/13/2022 09:48:37 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/13/2022 09:48:38 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.7179429916339325 on epoch=724
06/13/2022 09:48:40 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/13/2022 09:48:43 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/13/2022 09:48:45 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/13/2022 09:48:48 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/13/2022 09:48:50 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.03 on epoch=737
06/13/2022 09:48:51 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.7106560106560106 on epoch=737
06/13/2022 09:48:54 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/13/2022 09:48:56 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/13/2022 09:48:59 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/13/2022 09:49:01 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=747
06/13/2022 09:49:04 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/13/2022 09:49:05 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.7102272727272728 on epoch=749
06/13/2022 09:49:05 - INFO - __main__ - save last model!
06/13/2022 09:49:05 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/13/2022 09:49:05 - INFO - __main__ - Start tokenizing ... 5509 instances
06/13/2022 09:49:05 - INFO - __main__ - Printing 3 examples
06/13/2022 09:49:05 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/13/2022 09:49:05 - INFO - __main__ - ['others']
06/13/2022 09:49:05 - INFO - __main__ -  [emo] what you like very little things ok
06/13/2022 09:49:05 - INFO - __main__ - ['others']
06/13/2022 09:49:05 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/13/2022 09:49:05 - INFO - __main__ - ['others']
06/13/2022 09:49:05 - INFO - __main__ - Tokenizing Input ...
06/13/2022 09:49:05 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 09:49:05 - INFO - __main__ - Printing 3 examples
06/13/2022 09:49:05 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/13/2022 09:49:05 - INFO - __main__ - ['sad']
06/13/2022 09:49:05 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/13/2022 09:49:05 - INFO - __main__ - ['sad']
06/13/2022 09:49:05 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/13/2022 09:49:05 - INFO - __main__ - ['sad']
06/13/2022 09:49:05 - INFO - __main__ - Tokenizing Input ...
06/13/2022 09:49:05 - INFO - __main__ - Tokenizing Output ...
06/13/2022 09:49:05 - INFO - __main__ - Loaded 64 examples from train data
06/13/2022 09:49:05 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 09:49:05 - INFO - __main__ - Printing 3 examples
06/13/2022 09:49:05 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
06/13/2022 09:49:05 - INFO - __main__ - ['sad']
06/13/2022 09:49:05 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
06/13/2022 09:49:05 - INFO - __main__ - ['sad']
06/13/2022 09:49:05 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
06/13/2022 09:49:05 - INFO - __main__ - ['sad']
06/13/2022 09:49:05 - INFO - __main__ - Tokenizing Input ...
06/13/2022 09:49:05 - INFO - __main__ - Tokenizing Output ...
06/13/2022 09:49:05 - INFO - __main__ - Loaded 64 examples from dev data
06/13/2022 09:49:07 - INFO - __main__ - Tokenizing Output ...
06/13/2022 09:49:12 - INFO - __main__ - Loaded 5509 examples from test data
06/13/2022 09:49:20 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 09:49:21 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 09:49:21 - INFO - __main__ - Starting training!
06/13/2022 09:50:46 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-up32shot/singletask-emo/emo_16_21_0.4_8_predictions.txt
06/13/2022 09:50:46 - INFO - __main__ - Classification-F1 on test data: 0.1690
06/13/2022 09:50:46 - INFO - __main__ - prefix=emo_16_21, lr=0.4, bsz=8, dev_performance=0.7466748937337173, test_performance=0.16895084829046764
06/13/2022 09:50:46 - INFO - __main__ - Running ... prefix=emo_16_21, lr=0.3, bsz=8 ...
06/13/2022 09:50:47 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 09:50:47 - INFO - __main__ - Printing 3 examples
06/13/2022 09:50:47 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/13/2022 09:50:47 - INFO - __main__ - ['sad']
06/13/2022 09:50:47 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/13/2022 09:50:47 - INFO - __main__ - ['sad']
06/13/2022 09:50:47 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/13/2022 09:50:47 - INFO - __main__ - ['sad']
06/13/2022 09:50:47 - INFO - __main__ - Tokenizing Input ...
06/13/2022 09:50:47 - INFO - __main__ - Tokenizing Output ...
06/13/2022 09:50:47 - INFO - __main__ - Loaded 64 examples from train data
06/13/2022 09:50:47 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 09:50:47 - INFO - __main__ - Printing 3 examples
06/13/2022 09:50:47 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
06/13/2022 09:50:47 - INFO - __main__ - ['sad']
06/13/2022 09:50:47 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
06/13/2022 09:50:47 - INFO - __main__ - ['sad']
06/13/2022 09:50:47 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
06/13/2022 09:50:47 - INFO - __main__ - ['sad']
06/13/2022 09:50:47 - INFO - __main__ - Tokenizing Input ...
06/13/2022 09:50:47 - INFO - __main__ - Tokenizing Output ...
06/13/2022 09:50:47 - INFO - __main__ - Loaded 64 examples from dev data
06/13/2022 09:51:06 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 09:51:07 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 09:51:07 - INFO - __main__ - Starting training!
06/13/2022 09:51:10 - INFO - __main__ - Step 10 Global step 10 Train loss 4.08 on epoch=2
06/13/2022 09:51:12 - INFO - __main__ - Step 20 Global step 20 Train loss 3.35 on epoch=4
06/13/2022 09:51:14 - INFO - __main__ - Step 30 Global step 30 Train loss 2.57 on epoch=7
06/13/2022 09:51:17 - INFO - __main__ - Step 40 Global step 40 Train loss 2.05 on epoch=9
06/13/2022 09:51:19 - INFO - __main__ - Step 50 Global step 50 Train loss 1.62 on epoch=12
06/13/2022 09:51:20 - INFO - __main__ - Global step 50 Train loss 2.73 Classification-F1 0.09585253456221199 on epoch=12
06/13/2022 09:51:20 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.09585253456221199 on epoch=12, global_step=50
06/13/2022 09:51:23 - INFO - __main__ - Step 60 Global step 60 Train loss 1.28 on epoch=14
06/13/2022 09:51:25 - INFO - __main__ - Step 70 Global step 70 Train loss 1.21 on epoch=17
06/13/2022 09:51:28 - INFO - __main__ - Step 80 Global step 80 Train loss 1.01 on epoch=19
06/13/2022 09:51:30 - INFO - __main__ - Step 90 Global step 90 Train loss 0.84 on epoch=22
06/13/2022 09:51:32 - INFO - __main__ - Step 100 Global step 100 Train loss 0.74 on epoch=24
06/13/2022 09:51:33 - INFO - __main__ - Global step 100 Train loss 1.01 Classification-F1 0.5319370172311348 on epoch=24
06/13/2022 09:51:33 - INFO - __main__ - Saving model with best Classification-F1: 0.09585253456221199 -> 0.5319370172311348 on epoch=24, global_step=100
06/13/2022 09:51:36 - INFO - __main__ - Step 110 Global step 110 Train loss 0.71 on epoch=27
06/13/2022 09:51:38 - INFO - __main__ - Step 120 Global step 120 Train loss 0.69 on epoch=29
06/13/2022 09:51:41 - INFO - __main__ - Step 130 Global step 130 Train loss 0.65 on epoch=32
06/13/2022 09:51:43 - INFO - __main__ - Step 140 Global step 140 Train loss 0.61 on epoch=34
06/13/2022 09:51:46 - INFO - __main__ - Step 150 Global step 150 Train loss 0.54 on epoch=37
06/13/2022 09:51:47 - INFO - __main__ - Global step 150 Train loss 0.64 Classification-F1 0.5626603876603877 on epoch=37
06/13/2022 09:51:47 - INFO - __main__ - Saving model with best Classification-F1: 0.5319370172311348 -> 0.5626603876603877 on epoch=37, global_step=150
06/13/2022 09:51:49 - INFO - __main__ - Step 160 Global step 160 Train loss 0.45 on epoch=39
06/13/2022 09:51:51 - INFO - __main__ - Step 170 Global step 170 Train loss 0.50 on epoch=42
06/13/2022 09:51:54 - INFO - __main__ - Step 180 Global step 180 Train loss 0.45 on epoch=44
06/13/2022 09:51:56 - INFO - __main__ - Step 190 Global step 190 Train loss 0.46 on epoch=47
06/13/2022 09:51:59 - INFO - __main__ - Step 200 Global step 200 Train loss 0.46 on epoch=49
06/13/2022 09:52:00 - INFO - __main__ - Global step 200 Train loss 0.46 Classification-F1 0.5905819326871958 on epoch=49
06/13/2022 09:52:00 - INFO - __main__ - Saving model with best Classification-F1: 0.5626603876603877 -> 0.5905819326871958 on epoch=49, global_step=200
06/13/2022 09:52:02 - INFO - __main__ - Step 210 Global step 210 Train loss 0.53 on epoch=52
06/13/2022 09:52:04 - INFO - __main__ - Step 220 Global step 220 Train loss 0.55 on epoch=54
06/13/2022 09:52:07 - INFO - __main__ - Step 230 Global step 230 Train loss 0.53 on epoch=57
06/13/2022 09:52:09 - INFO - __main__ - Step 240 Global step 240 Train loss 0.49 on epoch=59
06/13/2022 09:52:12 - INFO - __main__ - Step 250 Global step 250 Train loss 0.43 on epoch=62
06/13/2022 09:52:12 - INFO - __main__ - Global step 250 Train loss 0.51 Classification-F1 0.666933066933067 on epoch=62
06/13/2022 09:52:13 - INFO - __main__ - Saving model with best Classification-F1: 0.5905819326871958 -> 0.666933066933067 on epoch=62, global_step=250
06/13/2022 09:52:15 - INFO - __main__ - Step 260 Global step 260 Train loss 0.44 on epoch=64
06/13/2022 09:52:17 - INFO - __main__ - Step 270 Global step 270 Train loss 0.36 on epoch=67
06/13/2022 09:52:20 - INFO - __main__ - Step 280 Global step 280 Train loss 0.42 on epoch=69
06/13/2022 09:52:22 - INFO - __main__ - Step 290 Global step 290 Train loss 0.44 on epoch=72
06/13/2022 09:52:25 - INFO - __main__ - Step 300 Global step 300 Train loss 0.35 on epoch=74
06/13/2022 09:52:25 - INFO - __main__ - Global step 300 Train loss 0.40 Classification-F1 0.6661518661518662 on epoch=74
06/13/2022 09:52:28 - INFO - __main__ - Step 310 Global step 310 Train loss 0.44 on epoch=77
06/13/2022 09:52:30 - INFO - __main__ - Step 320 Global step 320 Train loss 0.30 on epoch=79
06/13/2022 09:52:33 - INFO - __main__ - Step 330 Global step 330 Train loss 0.36 on epoch=82
06/13/2022 09:52:35 - INFO - __main__ - Step 340 Global step 340 Train loss 0.37 on epoch=84
06/13/2022 09:52:38 - INFO - __main__ - Step 350 Global step 350 Train loss 0.35 on epoch=87
06/13/2022 09:52:39 - INFO - __main__ - Global step 350 Train loss 0.36 Classification-F1 0.6661518661518662 on epoch=87
06/13/2022 09:52:41 - INFO - __main__ - Step 360 Global step 360 Train loss 0.31 on epoch=89
06/13/2022 09:52:43 - INFO - __main__ - Step 370 Global step 370 Train loss 0.34 on epoch=92
06/13/2022 09:52:46 - INFO - __main__ - Step 380 Global step 380 Train loss 0.33 on epoch=94
06/13/2022 09:52:48 - INFO - __main__ - Step 390 Global step 390 Train loss 0.29 on epoch=97
06/13/2022 09:52:51 - INFO - __main__ - Step 400 Global step 400 Train loss 0.22 on epoch=99
06/13/2022 09:52:52 - INFO - __main__ - Global step 400 Train loss 0.30 Classification-F1 0.6386272526319734 on epoch=99
06/13/2022 09:52:54 - INFO - __main__ - Step 410 Global step 410 Train loss 0.34 on epoch=102
06/13/2022 09:52:56 - INFO - __main__ - Step 420 Global step 420 Train loss 0.32 on epoch=104
06/13/2022 09:52:59 - INFO - __main__ - Step 430 Global step 430 Train loss 0.29 on epoch=107
06/13/2022 09:53:01 - INFO - __main__ - Step 440 Global step 440 Train loss 0.32 on epoch=109
06/13/2022 09:53:04 - INFO - __main__ - Step 450 Global step 450 Train loss 0.35 on epoch=112
06/13/2022 09:53:05 - INFO - __main__ - Global step 450 Train loss 0.32 Classification-F1 0.638961038961039 on epoch=112
06/13/2022 09:53:07 - INFO - __main__ - Step 460 Global step 460 Train loss 0.24 on epoch=114
06/13/2022 09:53:10 - INFO - __main__ - Step 470 Global step 470 Train loss 0.31 on epoch=117
06/13/2022 09:53:12 - INFO - __main__ - Step 480 Global step 480 Train loss 0.26 on epoch=119
06/13/2022 09:53:14 - INFO - __main__ - Step 490 Global step 490 Train loss 0.32 on epoch=122
06/13/2022 09:53:17 - INFO - __main__ - Step 500 Global step 500 Train loss 0.29 on epoch=124
06/13/2022 09:53:18 - INFO - __main__ - Global step 500 Train loss 0.28 Classification-F1 0.638961038961039 on epoch=124
06/13/2022 09:53:20 - INFO - __main__ - Step 510 Global step 510 Train loss 0.26 on epoch=127
06/13/2022 09:53:23 - INFO - __main__ - Step 520 Global step 520 Train loss 0.21 on epoch=129
06/13/2022 09:53:25 - INFO - __main__ - Step 530 Global step 530 Train loss 0.26 on epoch=132
06/13/2022 09:53:27 - INFO - __main__ - Step 540 Global step 540 Train loss 0.22 on epoch=134
06/13/2022 09:53:30 - INFO - __main__ - Step 550 Global step 550 Train loss 0.21 on epoch=137
06/13/2022 09:53:31 - INFO - __main__ - Global step 550 Train loss 0.23 Classification-F1 0.6248511904761904 on epoch=137
06/13/2022 09:53:33 - INFO - __main__ - Step 560 Global step 560 Train loss 0.15 on epoch=139
06/13/2022 09:53:36 - INFO - __main__ - Step 570 Global step 570 Train loss 0.28 on epoch=142
06/13/2022 09:53:38 - INFO - __main__ - Step 580 Global step 580 Train loss 0.23 on epoch=144
06/13/2022 09:53:40 - INFO - __main__ - Step 590 Global step 590 Train loss 0.20 on epoch=147
06/13/2022 09:53:43 - INFO - __main__ - Step 600 Global step 600 Train loss 0.15 on epoch=149
06/13/2022 09:53:44 - INFO - __main__ - Global step 600 Train loss 0.20 Classification-F1 0.6264321306807539 on epoch=149
06/13/2022 09:53:46 - INFO - __main__ - Step 610 Global step 610 Train loss 0.19 on epoch=152
06/13/2022 09:53:49 - INFO - __main__ - Step 620 Global step 620 Train loss 0.27 on epoch=154
06/13/2022 09:53:51 - INFO - __main__ - Step 630 Global step 630 Train loss 0.13 on epoch=157
06/13/2022 09:53:53 - INFO - __main__ - Step 640 Global step 640 Train loss 0.16 on epoch=159
06/13/2022 09:53:56 - INFO - __main__ - Step 650 Global step 650 Train loss 0.20 on epoch=162
06/13/2022 09:53:57 - INFO - __main__ - Global step 650 Train loss 0.19 Classification-F1 0.6264321306807539 on epoch=162
06/13/2022 09:53:59 - INFO - __main__ - Step 660 Global step 660 Train loss 0.12 on epoch=164
06/13/2022 09:54:02 - INFO - __main__ - Step 670 Global step 670 Train loss 0.25 on epoch=167
06/13/2022 09:54:04 - INFO - __main__ - Step 680 Global step 680 Train loss 0.15 on epoch=169
06/13/2022 09:54:07 - INFO - __main__ - Step 690 Global step 690 Train loss 0.15 on epoch=172
06/13/2022 09:54:09 - INFO - __main__ - Step 700 Global step 700 Train loss 0.13 on epoch=174
06/13/2022 09:54:10 - INFO - __main__ - Global step 700 Train loss 0.16 Classification-F1 0.6248511904761904 on epoch=174
06/13/2022 09:54:12 - INFO - __main__ - Step 710 Global step 710 Train loss 0.13 on epoch=177
06/13/2022 09:54:15 - INFO - __main__ - Step 720 Global step 720 Train loss 0.11 on epoch=179
06/13/2022 09:54:17 - INFO - __main__ - Step 730 Global step 730 Train loss 0.09 on epoch=182
06/13/2022 09:54:20 - INFO - __main__ - Step 740 Global step 740 Train loss 0.17 on epoch=184
06/13/2022 09:54:22 - INFO - __main__ - Step 750 Global step 750 Train loss 0.11 on epoch=187
06/13/2022 09:54:23 - INFO - __main__ - Global step 750 Train loss 0.12 Classification-F1 0.6264321306807539 on epoch=187
06/13/2022 09:54:26 - INFO - __main__ - Step 760 Global step 760 Train loss 0.12 on epoch=189
06/13/2022 09:54:28 - INFO - __main__ - Step 770 Global step 770 Train loss 0.16 on epoch=192
06/13/2022 09:54:30 - INFO - __main__ - Step 780 Global step 780 Train loss 0.12 on epoch=194
06/13/2022 09:54:33 - INFO - __main__ - Step 790 Global step 790 Train loss 0.13 on epoch=197
06/13/2022 09:54:35 - INFO - __main__ - Step 800 Global step 800 Train loss 0.17 on epoch=199
06/13/2022 09:54:36 - INFO - __main__ - Global step 800 Train loss 0.14 Classification-F1 0.5043164362519201 on epoch=199
06/13/2022 09:54:39 - INFO - __main__ - Step 810 Global step 810 Train loss 0.10 on epoch=202
06/13/2022 09:54:41 - INFO - __main__ - Step 820 Global step 820 Train loss 0.11 on epoch=204
06/13/2022 09:54:43 - INFO - __main__ - Step 830 Global step 830 Train loss 0.16 on epoch=207
06/13/2022 09:54:46 - INFO - __main__ - Step 840 Global step 840 Train loss 0.13 on epoch=209
06/13/2022 09:54:48 - INFO - __main__ - Step 850 Global step 850 Train loss 0.10 on epoch=212
06/13/2022 09:54:49 - INFO - __main__ - Global step 850 Train loss 0.12 Classification-F1 0.6264321306807539 on epoch=212
06/13/2022 09:54:52 - INFO - __main__ - Step 860 Global step 860 Train loss 0.11 on epoch=214
06/13/2022 09:54:54 - INFO - __main__ - Step 870 Global step 870 Train loss 0.12 on epoch=217
06/13/2022 09:54:56 - INFO - __main__ - Step 880 Global step 880 Train loss 0.07 on epoch=219
06/13/2022 09:54:59 - INFO - __main__ - Step 890 Global step 890 Train loss 0.17 on epoch=222
06/13/2022 09:55:01 - INFO - __main__ - Step 900 Global step 900 Train loss 0.10 on epoch=224
06/13/2022 09:55:02 - INFO - __main__ - Global step 900 Train loss 0.12 Classification-F1 0.6264321306807539 on epoch=224
06/13/2022 09:55:05 - INFO - __main__ - Step 910 Global step 910 Train loss 0.06 on epoch=227
06/13/2022 09:55:07 - INFO - __main__ - Step 920 Global step 920 Train loss 0.11 on epoch=229
06/13/2022 09:55:10 - INFO - __main__ - Step 930 Global step 930 Train loss 0.07 on epoch=232
06/13/2022 09:55:12 - INFO - __main__ - Step 940 Global step 940 Train loss 0.06 on epoch=234
06/13/2022 09:55:15 - INFO - __main__ - Step 950 Global step 950 Train loss 0.05 on epoch=237
06/13/2022 09:55:15 - INFO - __main__ - Global step 950 Train loss 0.07 Classification-F1 0.6264321306807539 on epoch=237
06/13/2022 09:55:18 - INFO - __main__ - Step 960 Global step 960 Train loss 0.08 on epoch=239
06/13/2022 09:55:20 - INFO - __main__ - Step 970 Global step 970 Train loss 0.10 on epoch=242
06/13/2022 09:55:23 - INFO - __main__ - Step 980 Global step 980 Train loss 0.05 on epoch=244
06/13/2022 09:55:25 - INFO - __main__ - Step 990 Global step 990 Train loss 0.08 on epoch=247
06/13/2022 09:55:28 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.12 on epoch=249
06/13/2022 09:55:29 - INFO - __main__ - Global step 1000 Train loss 0.08 Classification-F1 0.6155950305143852 on epoch=249
06/13/2022 09:55:31 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.03 on epoch=252
06/13/2022 09:55:33 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.11 on epoch=254
06/13/2022 09:55:36 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.05 on epoch=257
06/13/2022 09:55:38 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.10 on epoch=259
06/13/2022 09:55:41 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.06 on epoch=262
06/13/2022 09:55:42 - INFO - __main__ - Global step 1050 Train loss 0.07 Classification-F1 0.6026226068712299 on epoch=262
06/13/2022 09:55:44 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.04 on epoch=264
06/13/2022 09:55:46 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.06 on epoch=267
06/13/2022 09:55:49 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.05 on epoch=269
06/13/2022 09:55:51 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.10 on epoch=272
06/13/2022 09:55:54 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.02 on epoch=274
06/13/2022 09:55:55 - INFO - __main__ - Global step 1100 Train loss 0.06 Classification-F1 0.6404761904761904 on epoch=274
06/13/2022 09:55:57 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.11 on epoch=277
06/13/2022 09:56:00 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.04 on epoch=279
06/13/2022 09:56:02 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.04 on epoch=282
06/13/2022 09:56:04 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.05 on epoch=284
06/13/2022 09:56:07 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.02 on epoch=287
06/13/2022 09:56:08 - INFO - __main__ - Global step 1150 Train loss 0.05 Classification-F1 0.6619588744588745 on epoch=287
06/13/2022 09:56:10 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.07 on epoch=289
06/13/2022 09:56:13 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.10 on epoch=292
06/13/2022 09:56:15 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.05 on epoch=294
06/13/2022 09:56:18 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.07 on epoch=297
06/13/2022 09:56:20 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.06 on epoch=299
06/13/2022 09:56:21 - INFO - __main__ - Global step 1200 Train loss 0.07 Classification-F1 0.6264321306807539 on epoch=299
06/13/2022 09:56:23 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.06 on epoch=302
06/13/2022 09:56:26 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.12 on epoch=304
06/13/2022 09:56:28 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.09 on epoch=307
06/13/2022 09:56:31 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.04 on epoch=309
06/13/2022 09:56:33 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.08 on epoch=312
06/13/2022 09:56:34 - INFO - __main__ - Global step 1250 Train loss 0.08 Classification-F1 0.6395225294418843 on epoch=312
06/13/2022 09:56:37 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.05 on epoch=314
06/13/2022 09:56:39 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.08 on epoch=317
06/13/2022 09:56:41 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.03 on epoch=319
06/13/2022 09:56:44 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.02 on epoch=322
06/13/2022 09:56:46 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.03 on epoch=324
06/13/2022 09:56:47 - INFO - __main__ - Global step 1300 Train loss 0.04 Classification-F1 0.6395225294418843 on epoch=324
06/13/2022 09:56:50 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.06 on epoch=327
06/13/2022 09:56:52 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.02 on epoch=329
06/13/2022 09:56:54 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.05 on epoch=332
06/13/2022 09:56:57 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.04 on epoch=334
06/13/2022 09:56:59 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.03 on epoch=337
06/13/2022 09:57:00 - INFO - __main__ - Global step 1350 Train loss 0.04 Classification-F1 0.6026226068712299 on epoch=337
06/13/2022 09:57:03 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.06 on epoch=339
06/13/2022 09:57:05 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.10 on epoch=342
06/13/2022 09:57:08 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=344
06/13/2022 09:57:10 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.04 on epoch=347
06/13/2022 09:57:12 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.04 on epoch=349
06/13/2022 09:57:13 - INFO - __main__ - Global step 1400 Train loss 0.05 Classification-F1 0.6536682152535812 on epoch=349
06/13/2022 09:57:16 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.08 on epoch=352
06/13/2022 09:57:18 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.05 on epoch=354
06/13/2022 09:57:21 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=357
06/13/2022 09:57:23 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.09 on epoch=359
06/13/2022 09:57:26 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=362
06/13/2022 09:57:27 - INFO - __main__ - Global step 1450 Train loss 0.05 Classification-F1 0.6256336405529953 on epoch=362
06/13/2022 09:57:29 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=364
06/13/2022 09:57:32 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.02 on epoch=367
06/13/2022 09:57:34 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.05 on epoch=369
06/13/2022 09:57:36 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=372
06/13/2022 09:57:39 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.03 on epoch=374
06/13/2022 09:57:40 - INFO - __main__ - Global step 1500 Train loss 0.02 Classification-F1 0.6752525252525253 on epoch=374
06/13/2022 09:57:40 - INFO - __main__ - Saving model with best Classification-F1: 0.666933066933067 -> 0.6752525252525253 on epoch=374, global_step=1500
06/13/2022 09:57:42 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.07 on epoch=377
06/13/2022 09:57:45 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.02 on epoch=379
06/13/2022 09:57:47 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.08 on epoch=382
06/13/2022 09:57:50 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=384
06/13/2022 09:57:52 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.04 on epoch=387
06/13/2022 09:57:53 - INFO - __main__ - Global step 1550 Train loss 0.05 Classification-F1 0.6166666666666667 on epoch=387
06/13/2022 09:57:55 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.02 on epoch=389
06/13/2022 09:57:58 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=392
06/13/2022 09:58:00 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=394
06/13/2022 09:58:03 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.04 on epoch=397
06/13/2022 09:58:05 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.05 on epoch=399
06/13/2022 09:58:06 - INFO - __main__ - Global step 1600 Train loss 0.02 Classification-F1 0.6298423423423423 on epoch=399
06/13/2022 09:58:09 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=402
06/13/2022 09:58:11 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=404
06/13/2022 09:58:13 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.04 on epoch=407
06/13/2022 09:58:16 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.02 on epoch=409
06/13/2022 09:58:18 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=412
06/13/2022 09:58:19 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.6297407163260822 on epoch=412
06/13/2022 09:58:22 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.04 on epoch=414
06/13/2022 09:58:24 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=417
06/13/2022 09:58:27 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=419
06/13/2022 09:58:29 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.06 on epoch=422
06/13/2022 09:58:31 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=424
06/13/2022 09:58:32 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.6536682152535812 on epoch=424
06/13/2022 09:58:35 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=427
06/13/2022 09:58:37 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.05 on epoch=429
06/13/2022 09:58:40 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.04 on epoch=432
06/13/2022 09:58:42 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=434
06/13/2022 09:58:45 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=437
06/13/2022 09:58:46 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.6166666666666667 on epoch=437
06/13/2022 09:58:48 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=439
06/13/2022 09:58:51 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.05 on epoch=442
06/13/2022 09:58:53 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=444
06/13/2022 09:58:55 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.03 on epoch=447
06/13/2022 09:58:58 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=449
06/13/2022 09:58:59 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.6166666666666667 on epoch=449
06/13/2022 09:59:01 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=452
06/13/2022 09:59:04 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=454
06/13/2022 09:59:06 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.05 on epoch=457
06/13/2022 09:59:09 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=459
06/13/2022 09:59:11 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=462
06/13/2022 09:59:12 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.6166666666666667 on epoch=462
06/13/2022 09:59:14 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=464
06/13/2022 09:59:17 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=467
06/13/2022 09:59:19 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=469
06/13/2022 09:59:22 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.03 on epoch=472
06/13/2022 09:59:24 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=474
06/13/2022 09:59:25 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.6397793263646923 on epoch=474
06/13/2022 09:59:27 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=477
06/13/2022 09:59:30 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=479
06/13/2022 09:59:32 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=482
06/13/2022 09:59:35 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=484
06/13/2022 09:59:37 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.03 on epoch=487
06/13/2022 09:59:38 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.6678297755883963 on epoch=487
06/13/2022 09:59:41 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=489
06/13/2022 09:59:43 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=492
06/13/2022 09:59:46 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=494
06/13/2022 09:59:48 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=497
06/13/2022 09:59:50 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=499
06/13/2022 09:59:52 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.6904043872793872 on epoch=499
06/13/2022 09:59:52 - INFO - __main__ - Saving model with best Classification-F1: 0.6752525252525253 -> 0.6904043872793872 on epoch=499, global_step=2000
06/13/2022 09:59:54 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.07 on epoch=502
06/13/2022 09:59:57 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=504
06/13/2022 09:59:59 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.13 on epoch=507
06/13/2022 10:00:01 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=509
06/13/2022 10:00:04 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=512
06/13/2022 10:00:05 - INFO - __main__ - Global step 2050 Train loss 0.05 Classification-F1 0.6547562848900379 on epoch=512
06/13/2022 10:00:07 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=514
06/13/2022 10:00:10 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=517
06/13/2022 10:00:12 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/13/2022 10:00:15 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=522
06/13/2022 10:00:17 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=524
06/13/2022 10:00:18 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.676340594888982 on epoch=524
06/13/2022 10:00:20 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=527
06/13/2022 10:00:23 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=529
06/13/2022 10:00:25 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=532
06/13/2022 10:00:28 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.04 on epoch=534
06/13/2022 10:00:30 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=537
06/13/2022 10:00:31 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.6547562848900379 on epoch=537
06/13/2022 10:00:34 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.03 on epoch=539
06/13/2022 10:00:36 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=542
06/13/2022 10:00:38 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=544
06/13/2022 10:00:41 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=547
06/13/2022 10:00:43 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=549
06/13/2022 10:00:44 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.6547562848900379 on epoch=549
06/13/2022 10:00:47 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=552
06/13/2022 10:00:49 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=554
06/13/2022 10:00:52 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.06 on epoch=557
06/13/2022 10:00:54 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/13/2022 10:00:57 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/13/2022 10:00:58 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.676340594888982 on epoch=562
06/13/2022 10:01:00 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.03 on epoch=564
06/13/2022 10:01:02 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=567
06/13/2022 10:01:05 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=569
06/13/2022 10:01:07 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.03 on epoch=572
06/13/2022 10:01:10 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=574
06/13/2022 10:01:11 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.6404761904761904 on epoch=574
06/13/2022 10:01:13 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.04 on epoch=577
06/13/2022 10:01:16 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/13/2022 10:01:18 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=582
06/13/2022 10:01:21 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=584
06/13/2022 10:01:23 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=587
06/13/2022 10:01:24 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.676340594888982 on epoch=587
06/13/2022 10:01:27 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/13/2022 10:01:29 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=592
06/13/2022 10:01:31 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=594
06/13/2022 10:01:34 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=597
06/13/2022 10:01:36 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=599
06/13/2022 10:01:37 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.6899547585031457 on epoch=599
06/13/2022 10:01:40 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=602
06/13/2022 10:01:42 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/13/2022 10:01:45 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=607
06/13/2022 10:01:47 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=609
06/13/2022 10:01:50 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=612
06/13/2022 10:01:51 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.65426267281106 on epoch=612
06/13/2022 10:01:53 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=614
06/13/2022 10:01:56 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=617
06/13/2022 10:01:58 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.03 on epoch=619
06/13/2022 10:02:01 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=622
06/13/2022 10:02:03 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=624
06/13/2022 10:02:04 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.6677588613072485 on epoch=624
06/13/2022 10:02:06 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/13/2022 10:02:09 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=629
06/13/2022 10:02:11 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=632
06/13/2022 10:02:14 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=634
06/13/2022 10:02:16 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=637
06/13/2022 10:02:17 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.65426267281106 on epoch=637
06/13/2022 10:02:20 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=639
06/13/2022 10:02:22 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.05 on epoch=642
06/13/2022 10:02:25 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/13/2022 10:02:27 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/13/2022 10:02:30 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=649
06/13/2022 10:02:31 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.6309467610805141 on epoch=649
06/13/2022 10:02:33 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.05 on epoch=652
06/13/2022 10:02:35 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=654
06/13/2022 10:02:38 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/13/2022 10:02:40 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=659
06/13/2022 10:02:43 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=662
06/13/2022 10:02:44 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.65426267281106 on epoch=662
06/13/2022 10:02:46 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=664
06/13/2022 10:02:49 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/13/2022 10:02:51 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=669
06/13/2022 10:02:54 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=672
06/13/2022 10:02:56 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=674
06/13/2022 10:02:57 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.6677588613072485 on epoch=674
06/13/2022 10:02:59 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.04 on epoch=677
06/13/2022 10:03:02 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/13/2022 10:03:04 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=682
06/13/2022 10:03:07 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=684
06/13/2022 10:03:09 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/13/2022 10:03:10 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.6405180840664713 on epoch=687
06/13/2022 10:03:13 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=689
06/13/2022 10:03:15 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=692
06/13/2022 10:03:18 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=694
06/13/2022 10:03:20 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=697
06/13/2022 10:03:23 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=699
06/13/2022 10:03:24 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.6405180840664713 on epoch=699
06/13/2022 10:03:26 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/13/2022 10:03:28 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/13/2022 10:03:31 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/13/2022 10:03:33 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/13/2022 10:03:36 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/13/2022 10:03:37 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.653913057987761 on epoch=712
06/13/2022 10:03:39 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=714
06/13/2022 10:03:42 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=717
06/13/2022 10:03:44 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=719
06/13/2022 10:03:47 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/13/2022 10:03:49 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/13/2022 10:03:50 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.6812723748207619 on epoch=724
06/13/2022 10:03:53 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=727
06/13/2022 10:03:55 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=729
06/13/2022 10:03:58 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=732
06/13/2022 10:04:00 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=734
06/13/2022 10:04:03 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=737
06/13/2022 10:04:04 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.6539130579877609 on epoch=737
06/13/2022 10:04:06 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/13/2022 10:04:08 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=742
06/13/2022 10:04:11 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/13/2022 10:04:13 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/13/2022 10:04:16 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.06 on epoch=749
06/13/2022 10:04:17 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.6405180840664713 on epoch=749
06/13/2022 10:04:17 - INFO - __main__ - save last model!
06/13/2022 10:04:17 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/13/2022 10:04:17 - INFO - __main__ - Start tokenizing ... 5509 instances
06/13/2022 10:04:17 - INFO - __main__ - Printing 3 examples
06/13/2022 10:04:17 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/13/2022 10:04:17 - INFO - __main__ - ['others']
06/13/2022 10:04:17 - INFO - __main__ -  [emo] what you like very little things ok
06/13/2022 10:04:17 - INFO - __main__ - ['others']
06/13/2022 10:04:17 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/13/2022 10:04:17 - INFO - __main__ - ['others']
06/13/2022 10:04:17 - INFO - __main__ - Tokenizing Input ...
06/13/2022 10:04:17 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 10:04:17 - INFO - __main__ - Printing 3 examples
06/13/2022 10:04:17 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/13/2022 10:04:17 - INFO - __main__ - ['sad']
06/13/2022 10:04:17 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/13/2022 10:04:17 - INFO - __main__ - ['sad']
06/13/2022 10:04:17 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/13/2022 10:04:17 - INFO - __main__ - ['sad']
06/13/2022 10:04:17 - INFO - __main__ - Tokenizing Input ...
06/13/2022 10:04:17 - INFO - __main__ - Tokenizing Output ...
06/13/2022 10:04:17 - INFO - __main__ - Loaded 64 examples from train data
06/13/2022 10:04:17 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 10:04:17 - INFO - __main__ - Printing 3 examples
06/13/2022 10:04:17 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
06/13/2022 10:04:17 - INFO - __main__ - ['sad']
06/13/2022 10:04:17 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
06/13/2022 10:04:17 - INFO - __main__ - ['sad']
06/13/2022 10:04:17 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
06/13/2022 10:04:17 - INFO - __main__ - ['sad']
06/13/2022 10:04:17 - INFO - __main__ - Tokenizing Input ...
06/13/2022 10:04:17 - INFO - __main__ - Tokenizing Output ...
06/13/2022 10:04:17 - INFO - __main__ - Loaded 64 examples from dev data
06/13/2022 10:04:19 - INFO - __main__ - Tokenizing Output ...
06/13/2022 10:04:24 - INFO - __main__ - Loaded 5509 examples from test data
06/13/2022 10:04:33 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 10:04:33 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 10:04:33 - INFO - __main__ - Starting training!
06/13/2022 10:05:50 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-up32shot/singletask-emo/emo_16_21_0.3_8_predictions.txt
06/13/2022 10:05:50 - INFO - __main__ - Classification-F1 on test data: 0.1920
06/13/2022 10:05:50 - INFO - __main__ - prefix=emo_16_21, lr=0.3, bsz=8, dev_performance=0.6904043872793872, test_performance=0.19199070179292954
06/13/2022 10:05:50 - INFO - __main__ - Running ... prefix=emo_16_21, lr=0.2, bsz=8 ...
06/13/2022 10:05:51 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 10:05:51 - INFO - __main__ - Printing 3 examples
06/13/2022 10:05:51 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/13/2022 10:05:51 - INFO - __main__ - ['sad']
06/13/2022 10:05:51 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/13/2022 10:05:51 - INFO - __main__ - ['sad']
06/13/2022 10:05:51 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/13/2022 10:05:51 - INFO - __main__ - ['sad']
06/13/2022 10:05:51 - INFO - __main__ - Tokenizing Input ...
06/13/2022 10:05:51 - INFO - __main__ - Tokenizing Output ...
06/13/2022 10:05:51 - INFO - __main__ - Loaded 64 examples from train data
06/13/2022 10:05:51 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 10:05:51 - INFO - __main__ - Printing 3 examples
06/13/2022 10:05:51 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
06/13/2022 10:05:51 - INFO - __main__ - ['sad']
06/13/2022 10:05:51 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
06/13/2022 10:05:51 - INFO - __main__ - ['sad']
06/13/2022 10:05:51 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
06/13/2022 10:05:51 - INFO - __main__ - ['sad']
06/13/2022 10:05:51 - INFO - __main__ - Tokenizing Input ...
06/13/2022 10:05:51 - INFO - __main__ - Tokenizing Output ...
06/13/2022 10:05:51 - INFO - __main__ - Loaded 64 examples from dev data
06/13/2022 10:06:10 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 10:06:11 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 10:06:11 - INFO - __main__ - Starting training!
06/13/2022 10:06:14 - INFO - __main__ - Step 10 Global step 10 Train loss 4.43 on epoch=2
06/13/2022 10:06:16 - INFO - __main__ - Step 20 Global step 20 Train loss 3.57 on epoch=4
06/13/2022 10:06:19 - INFO - __main__ - Step 30 Global step 30 Train loss 3.08 on epoch=7
06/13/2022 10:06:21 - INFO - __main__ - Step 40 Global step 40 Train loss 2.30 on epoch=9
06/13/2022 10:06:23 - INFO - __main__ - Step 50 Global step 50 Train loss 2.17 on epoch=12
06/13/2022 10:06:25 - INFO - __main__ - Global step 50 Train loss 3.11 Classification-F1 0.07242063492063493 on epoch=12
06/13/2022 10:06:25 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.07242063492063493 on epoch=12, global_step=50
06/13/2022 10:06:27 - INFO - __main__ - Step 60 Global step 60 Train loss 1.78 on epoch=14
06/13/2022 10:06:30 - INFO - __main__ - Step 70 Global step 70 Train loss 1.70 on epoch=17
06/13/2022 10:06:32 - INFO - __main__ - Step 80 Global step 80 Train loss 1.40 on epoch=19
06/13/2022 10:06:34 - INFO - __main__ - Step 90 Global step 90 Train loss 1.34 on epoch=22
06/13/2022 10:06:37 - INFO - __main__ - Step 100 Global step 100 Train loss 1.03 on epoch=24
06/13/2022 10:06:38 - INFO - __main__ - Global step 100 Train loss 1.45 Classification-F1 0.36638655462184877 on epoch=24
06/13/2022 10:06:38 - INFO - __main__ - Saving model with best Classification-F1: 0.07242063492063493 -> 0.36638655462184877 on epoch=24, global_step=100
06/13/2022 10:06:40 - INFO - __main__ - Step 110 Global step 110 Train loss 0.92 on epoch=27
06/13/2022 10:06:43 - INFO - __main__ - Step 120 Global step 120 Train loss 0.85 on epoch=29
06/13/2022 10:06:45 - INFO - __main__ - Step 130 Global step 130 Train loss 0.82 on epoch=32
06/13/2022 10:06:47 - INFO - __main__ - Step 140 Global step 140 Train loss 0.76 on epoch=34
06/13/2022 10:06:50 - INFO - __main__ - Step 150 Global step 150 Train loss 0.73 on epoch=37
06/13/2022 10:06:51 - INFO - __main__ - Global step 150 Train loss 0.82 Classification-F1 0.5165197786431647 on epoch=37
06/13/2022 10:06:51 - INFO - __main__ - Saving model with best Classification-F1: 0.36638655462184877 -> 0.5165197786431647 on epoch=37, global_step=150
06/13/2022 10:06:53 - INFO - __main__ - Step 160 Global step 160 Train loss 0.72 on epoch=39
06/13/2022 10:06:56 - INFO - __main__ - Step 170 Global step 170 Train loss 0.55 on epoch=42
06/13/2022 10:06:58 - INFO - __main__ - Step 180 Global step 180 Train loss 0.53 on epoch=44
06/13/2022 10:07:01 - INFO - __main__ - Step 190 Global step 190 Train loss 0.62 on epoch=47
06/13/2022 10:07:03 - INFO - __main__ - Step 200 Global step 200 Train loss 0.55 on epoch=49
06/13/2022 10:07:04 - INFO - __main__ - Global step 200 Train loss 0.59 Classification-F1 0.5460526315789473 on epoch=49
06/13/2022 10:07:04 - INFO - __main__ - Saving model with best Classification-F1: 0.5165197786431647 -> 0.5460526315789473 on epoch=49, global_step=200
06/13/2022 10:07:07 - INFO - __main__ - Step 210 Global step 210 Train loss 0.63 on epoch=52
06/13/2022 10:07:09 - INFO - __main__ - Step 220 Global step 220 Train loss 0.56 on epoch=54
06/13/2022 10:07:11 - INFO - __main__ - Step 230 Global step 230 Train loss 0.64 on epoch=57
06/13/2022 10:07:14 - INFO - __main__ - Step 240 Global step 240 Train loss 0.50 on epoch=59
06/13/2022 10:07:16 - INFO - __main__ - Step 250 Global step 250 Train loss 0.55 on epoch=62
06/13/2022 10:07:17 - INFO - __main__ - Global step 250 Train loss 0.58 Classification-F1 0.6149859943977591 on epoch=62
06/13/2022 10:07:17 - INFO - __main__ - Saving model with best Classification-F1: 0.5460526315789473 -> 0.6149859943977591 on epoch=62, global_step=250
06/13/2022 10:07:20 - INFO - __main__ - Step 260 Global step 260 Train loss 0.46 on epoch=64
06/13/2022 10:07:22 - INFO - __main__ - Step 270 Global step 270 Train loss 0.51 on epoch=67
06/13/2022 10:07:25 - INFO - __main__ - Step 280 Global step 280 Train loss 0.46 on epoch=69
06/13/2022 10:07:27 - INFO - __main__ - Step 290 Global step 290 Train loss 0.53 on epoch=72
06/13/2022 10:07:30 - INFO - __main__ - Step 300 Global step 300 Train loss 0.46 on epoch=74
06/13/2022 10:07:30 - INFO - __main__ - Global step 300 Train loss 0.48 Classification-F1 0.6423423423423422 on epoch=74
06/13/2022 10:07:30 - INFO - __main__ - Saving model with best Classification-F1: 0.6149859943977591 -> 0.6423423423423422 on epoch=74, global_step=300
06/13/2022 10:07:33 - INFO - __main__ - Step 310 Global step 310 Train loss 0.49 on epoch=77
06/13/2022 10:07:35 - INFO - __main__ - Step 320 Global step 320 Train loss 0.41 on epoch=79
06/13/2022 10:07:38 - INFO - __main__ - Step 330 Global step 330 Train loss 0.32 on epoch=82
06/13/2022 10:07:40 - INFO - __main__ - Step 340 Global step 340 Train loss 0.35 on epoch=84
06/13/2022 10:07:43 - INFO - __main__ - Step 350 Global step 350 Train loss 0.39 on epoch=87
06/13/2022 10:07:44 - INFO - __main__ - Global step 350 Train loss 0.39 Classification-F1 0.6423423423423422 on epoch=87
06/13/2022 10:07:46 - INFO - __main__ - Step 360 Global step 360 Train loss 0.35 on epoch=89
06/13/2022 10:07:48 - INFO - __main__ - Step 370 Global step 370 Train loss 0.31 on epoch=92
06/13/2022 10:07:51 - INFO - __main__ - Step 380 Global step 380 Train loss 0.36 on epoch=94
06/13/2022 10:07:53 - INFO - __main__ - Step 390 Global step 390 Train loss 0.48 on epoch=97
06/13/2022 10:07:56 - INFO - __main__ - Step 400 Global step 400 Train loss 0.40 on epoch=99
06/13/2022 10:07:57 - INFO - __main__ - Global step 400 Train loss 0.38 Classification-F1 0.6423423423423422 on epoch=99
06/13/2022 10:07:59 - INFO - __main__ - Step 410 Global step 410 Train loss 0.34 on epoch=102
06/13/2022 10:08:02 - INFO - __main__ - Step 420 Global step 420 Train loss 0.33 on epoch=104
06/13/2022 10:08:04 - INFO - __main__ - Step 430 Global step 430 Train loss 0.39 on epoch=107
06/13/2022 10:08:07 - INFO - __main__ - Step 440 Global step 440 Train loss 0.32 on epoch=109
06/13/2022 10:08:09 - INFO - __main__ - Step 450 Global step 450 Train loss 0.46 on epoch=112
06/13/2022 10:08:10 - INFO - __main__ - Global step 450 Train loss 0.37 Classification-F1 0.6527052926433732 on epoch=112
06/13/2022 10:08:10 - INFO - __main__ - Saving model with best Classification-F1: 0.6423423423423422 -> 0.6527052926433732 on epoch=112, global_step=450
06/13/2022 10:08:12 - INFO - __main__ - Step 460 Global step 460 Train loss 0.36 on epoch=114
06/13/2022 10:08:15 - INFO - __main__ - Step 470 Global step 470 Train loss 0.43 on epoch=117
06/13/2022 10:08:17 - INFO - __main__ - Step 480 Global step 480 Train loss 0.34 on epoch=119
06/13/2022 10:08:20 - INFO - __main__ - Step 490 Global step 490 Train loss 0.31 on epoch=122
06/13/2022 10:08:22 - INFO - __main__ - Step 500 Global step 500 Train loss 0.30 on epoch=124
06/13/2022 10:08:23 - INFO - __main__ - Global step 500 Train loss 0.35 Classification-F1 0.6386272526319734 on epoch=124
06/13/2022 10:08:25 - INFO - __main__ - Step 510 Global step 510 Train loss 0.32 on epoch=127
06/13/2022 10:08:28 - INFO - __main__ - Step 520 Global step 520 Train loss 0.32 on epoch=129
06/13/2022 10:08:30 - INFO - __main__ - Step 530 Global step 530 Train loss 0.38 on epoch=132
06/13/2022 10:08:33 - INFO - __main__ - Step 540 Global step 540 Train loss 0.29 on epoch=134
06/13/2022 10:08:35 - INFO - __main__ - Step 550 Global step 550 Train loss 0.25 on epoch=137
06/13/2022 10:08:36 - INFO - __main__ - Global step 550 Train loss 0.31 Classification-F1 0.6248511904761904 on epoch=137
06/13/2022 10:08:39 - INFO - __main__ - Step 560 Global step 560 Train loss 0.31 on epoch=139
06/13/2022 10:08:41 - INFO - __main__ - Step 570 Global step 570 Train loss 0.33 on epoch=142
06/13/2022 10:08:43 - INFO - __main__ - Step 580 Global step 580 Train loss 0.38 on epoch=144
06/13/2022 10:08:46 - INFO - __main__ - Step 590 Global step 590 Train loss 0.31 on epoch=147
06/13/2022 10:08:48 - INFO - __main__ - Step 600 Global step 600 Train loss 0.27 on epoch=149
06/13/2022 10:08:49 - INFO - __main__ - Global step 600 Train loss 0.32 Classification-F1 0.638961038961039 on epoch=149
06/13/2022 10:08:52 - INFO - __main__ - Step 610 Global step 610 Train loss 0.32 on epoch=152
06/13/2022 10:08:54 - INFO - __main__ - Step 620 Global step 620 Train loss 0.30 on epoch=154
06/13/2022 10:08:57 - INFO - __main__ - Step 630 Global step 630 Train loss 0.29 on epoch=157
06/13/2022 10:08:59 - INFO - __main__ - Step 640 Global step 640 Train loss 0.27 on epoch=159
06/13/2022 10:09:01 - INFO - __main__ - Step 650 Global step 650 Train loss 0.30 on epoch=162
06/13/2022 10:09:02 - INFO - __main__ - Global step 650 Train loss 0.30 Classification-F1 0.6248511904761904 on epoch=162
06/13/2022 10:09:05 - INFO - __main__ - Step 660 Global step 660 Train loss 0.25 on epoch=164
06/13/2022 10:09:07 - INFO - __main__ - Step 670 Global step 670 Train loss 0.26 on epoch=167
06/13/2022 10:09:10 - INFO - __main__ - Step 680 Global step 680 Train loss 0.32 on epoch=169
06/13/2022 10:09:12 - INFO - __main__ - Step 690 Global step 690 Train loss 0.27 on epoch=172
06/13/2022 10:09:15 - INFO - __main__ - Step 700 Global step 700 Train loss 0.26 on epoch=174
06/13/2022 10:09:16 - INFO - __main__ - Global step 700 Train loss 0.27 Classification-F1 0.6248511904761904 on epoch=174
06/13/2022 10:09:18 - INFO - __main__ - Step 710 Global step 710 Train loss 0.21 on epoch=177
06/13/2022 10:09:20 - INFO - __main__ - Step 720 Global step 720 Train loss 0.24 on epoch=179
06/13/2022 10:09:23 - INFO - __main__ - Step 730 Global step 730 Train loss 0.22 on epoch=182
06/13/2022 10:09:25 - INFO - __main__ - Step 740 Global step 740 Train loss 0.22 on epoch=184
06/13/2022 10:09:28 - INFO - __main__ - Step 750 Global step 750 Train loss 0.28 on epoch=187
06/13/2022 10:09:29 - INFO - __main__ - Global step 750 Train loss 0.23 Classification-F1 0.6248511904761904 on epoch=187
06/13/2022 10:09:31 - INFO - __main__ - Step 760 Global step 760 Train loss 0.28 on epoch=189
06/13/2022 10:09:34 - INFO - __main__ - Step 770 Global step 770 Train loss 0.22 on epoch=192
06/13/2022 10:09:36 - INFO - __main__ - Step 780 Global step 780 Train loss 0.20 on epoch=194
06/13/2022 10:09:38 - INFO - __main__ - Step 790 Global step 790 Train loss 0.18 on epoch=197
06/13/2022 10:09:41 - INFO - __main__ - Step 800 Global step 800 Train loss 0.22 on epoch=199
06/13/2022 10:09:42 - INFO - __main__ - Global step 800 Train loss 0.22 Classification-F1 0.6248511904761904 on epoch=199
06/13/2022 10:09:44 - INFO - __main__ - Step 810 Global step 810 Train loss 0.23 on epoch=202
06/13/2022 10:09:47 - INFO - __main__ - Step 820 Global step 820 Train loss 0.18 on epoch=204
06/13/2022 10:09:49 - INFO - __main__ - Step 830 Global step 830 Train loss 0.21 on epoch=207
06/13/2022 10:09:52 - INFO - __main__ - Step 840 Global step 840 Train loss 0.19 on epoch=209
06/13/2022 10:09:54 - INFO - __main__ - Step 850 Global step 850 Train loss 0.17 on epoch=212
06/13/2022 10:09:55 - INFO - __main__ - Global step 850 Train loss 0.20 Classification-F1 0.6477115626309174 on epoch=212
06/13/2022 10:09:57 - INFO - __main__ - Step 860 Global step 860 Train loss 0.17 on epoch=214
06/13/2022 10:10:00 - INFO - __main__ - Step 870 Global step 870 Train loss 0.19 on epoch=217
06/13/2022 10:10:02 - INFO - __main__ - Step 880 Global step 880 Train loss 0.26 on epoch=219
06/13/2022 10:10:05 - INFO - __main__ - Step 890 Global step 890 Train loss 0.11 on epoch=222
06/13/2022 10:10:07 - INFO - __main__ - Step 900 Global step 900 Train loss 0.19 on epoch=224
06/13/2022 10:10:08 - INFO - __main__ - Global step 900 Train loss 0.18 Classification-F1 0.6248511904761904 on epoch=224
06/13/2022 10:10:11 - INFO - __main__ - Step 910 Global step 910 Train loss 0.22 on epoch=227
06/13/2022 10:10:13 - INFO - __main__ - Step 920 Global step 920 Train loss 0.17 on epoch=229
06/13/2022 10:10:15 - INFO - __main__ - Step 930 Global step 930 Train loss 0.14 on epoch=232
06/13/2022 10:10:18 - INFO - __main__ - Step 940 Global step 940 Train loss 0.12 on epoch=234
06/13/2022 10:10:20 - INFO - __main__ - Step 950 Global step 950 Train loss 0.15 on epoch=237
06/13/2022 10:10:21 - INFO - __main__ - Global step 950 Train loss 0.16 Classification-F1 0.6477115626309174 on epoch=237
06/13/2022 10:10:24 - INFO - __main__ - Step 960 Global step 960 Train loss 0.12 on epoch=239
06/13/2022 10:10:26 - INFO - __main__ - Step 970 Global step 970 Train loss 0.18 on epoch=242
06/13/2022 10:10:29 - INFO - __main__ - Step 980 Global step 980 Train loss 0.08 on epoch=244
06/13/2022 10:10:31 - INFO - __main__ - Step 990 Global step 990 Train loss 0.12 on epoch=247
06/13/2022 10:10:34 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.21 on epoch=249
06/13/2022 10:10:35 - INFO - __main__ - Global step 1000 Train loss 0.14 Classification-F1 0.6264321306807539 on epoch=249
06/13/2022 10:10:37 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.14 on epoch=252
06/13/2022 10:10:39 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.10 on epoch=254
06/13/2022 10:10:42 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.14 on epoch=257
06/13/2022 10:10:44 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.08 on epoch=259
06/13/2022 10:10:47 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.14 on epoch=262
06/13/2022 10:10:48 - INFO - __main__ - Global step 1050 Train loss 0.12 Classification-F1 0.6264321306807539 on epoch=262
06/13/2022 10:10:50 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.18 on epoch=264
06/13/2022 10:10:52 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.12 on epoch=267
06/13/2022 10:10:55 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.15 on epoch=269
06/13/2022 10:10:57 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.15 on epoch=272
06/13/2022 10:11:00 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.09 on epoch=274
06/13/2022 10:11:01 - INFO - __main__ - Global step 1100 Train loss 0.14 Classification-F1 0.6264321306807539 on epoch=274
06/13/2022 10:11:03 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.10 on epoch=277
06/13/2022 10:11:06 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.07 on epoch=279
06/13/2022 10:11:08 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.10 on epoch=282
06/13/2022 10:11:10 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.18 on epoch=284
06/13/2022 10:11:13 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.14 on epoch=287
06/13/2022 10:11:14 - INFO - __main__ - Global step 1150 Train loss 0.12 Classification-F1 0.6264321306807539 on epoch=287
06/13/2022 10:11:16 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.14 on epoch=289
06/13/2022 10:11:19 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.10 on epoch=292
06/13/2022 10:11:21 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.12 on epoch=294
06/13/2022 10:11:24 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.15 on epoch=297
06/13/2022 10:11:26 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.07 on epoch=299
06/13/2022 10:11:27 - INFO - __main__ - Global step 1200 Train loss 0.12 Classification-F1 0.6264321306807539 on epoch=299
06/13/2022 10:11:29 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.13 on epoch=302
06/13/2022 10:11:32 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.10 on epoch=304
06/13/2022 10:11:34 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.07 on epoch=307
06/13/2022 10:11:37 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.08 on epoch=309
06/13/2022 10:11:39 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.12 on epoch=312
06/13/2022 10:11:40 - INFO - __main__ - Global step 1250 Train loss 0.10 Classification-F1 0.6264321306807539 on epoch=312
06/13/2022 10:11:42 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.11 on epoch=314
06/13/2022 10:11:45 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.08 on epoch=317
06/13/2022 10:11:47 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.10 on epoch=319
06/13/2022 10:11:50 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.09 on epoch=322
06/13/2022 10:11:52 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.09 on epoch=324
06/13/2022 10:11:53 - INFO - __main__ - Global step 1300 Train loss 0.09 Classification-F1 0.6264321306807539 on epoch=324
06/13/2022 10:11:56 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.09 on epoch=327
06/13/2022 10:11:58 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.09 on epoch=329
06/13/2022 10:12:01 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.08 on epoch=332
06/13/2022 10:12:03 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.08 on epoch=334
06/13/2022 10:12:05 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.10 on epoch=337
06/13/2022 10:12:06 - INFO - __main__ - Global step 1350 Train loss 0.09 Classification-F1 0.6395225294418843 on epoch=337
06/13/2022 10:12:09 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.08 on epoch=339
06/13/2022 10:12:11 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.12 on epoch=342
06/13/2022 10:12:14 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.08 on epoch=344
06/13/2022 10:12:16 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.14 on epoch=347
06/13/2022 10:12:19 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.07 on epoch=349
06/13/2022 10:12:20 - INFO - __main__ - Global step 1400 Train loss 0.10 Classification-F1 0.6609903381642512 on epoch=349
06/13/2022 10:12:20 - INFO - __main__ - Saving model with best Classification-F1: 0.6527052926433732 -> 0.6609903381642512 on epoch=349, global_step=1400
06/13/2022 10:12:22 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.06 on epoch=352
06/13/2022 10:12:25 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.10 on epoch=354
06/13/2022 10:12:27 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.03 on epoch=357
06/13/2022 10:12:29 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.05 on epoch=359
06/13/2022 10:12:32 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.07 on epoch=362
06/13/2022 10:12:33 - INFO - __main__ - Global step 1450 Train loss 0.06 Classification-F1 0.6610052134245683 on epoch=362
06/13/2022 10:12:33 - INFO - __main__ - Saving model with best Classification-F1: 0.6609903381642512 -> 0.6610052134245683 on epoch=362, global_step=1450
06/13/2022 10:12:35 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.12 on epoch=364
06/13/2022 10:12:38 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.09 on epoch=367
06/13/2022 10:12:40 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.08 on epoch=369
06/13/2022 10:12:43 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.06 on epoch=372
06/13/2022 10:12:45 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.06 on epoch=374
06/13/2022 10:12:46 - INFO - __main__ - Global step 1500 Train loss 0.08 Classification-F1 0.6395225294418843 on epoch=374
06/13/2022 10:12:49 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.07 on epoch=377
06/13/2022 10:12:51 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.03 on epoch=379
06/13/2022 10:12:54 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.12 on epoch=382
06/13/2022 10:12:56 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.09 on epoch=384
06/13/2022 10:12:58 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.04 on epoch=387
06/13/2022 10:13:00 - INFO - __main__ - Global step 1550 Train loss 0.07 Classification-F1 0.6395225294418843 on epoch=387
06/13/2022 10:13:02 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.06 on epoch=389
06/13/2022 10:13:05 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.04 on epoch=392
06/13/2022 10:13:07 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.03 on epoch=394
06/13/2022 10:13:09 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.04 on epoch=397
06/13/2022 10:13:12 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.08 on epoch=399
06/13/2022 10:13:13 - INFO - __main__ - Global step 1600 Train loss 0.05 Classification-F1 0.6395225294418843 on epoch=399
06/13/2022 10:13:15 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.06 on epoch=402
06/13/2022 10:13:18 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.04 on epoch=404
06/13/2022 10:13:20 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.11 on epoch=407
06/13/2022 10:13:23 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.04 on epoch=409
06/13/2022 10:13:25 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.03 on epoch=412
06/13/2022 10:13:26 - INFO - __main__ - Global step 1650 Train loss 0.06 Classification-F1 0.638809316228671 on epoch=412
06/13/2022 10:13:29 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.04 on epoch=414
06/13/2022 10:13:31 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.10 on epoch=417
06/13/2022 10:13:34 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.05 on epoch=419
06/13/2022 10:13:36 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.05 on epoch=422
06/13/2022 10:13:38 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.06 on epoch=424
06/13/2022 10:13:39 - INFO - __main__ - Global step 1700 Train loss 0.06 Classification-F1 0.638809316228671 on epoch=424
06/13/2022 10:13:42 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.05 on epoch=427
06/13/2022 10:13:44 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=429
06/13/2022 10:13:47 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.05 on epoch=432
06/13/2022 10:13:49 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.05 on epoch=434
06/13/2022 10:13:52 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.04 on epoch=437
06/13/2022 10:13:52 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.6897910138399268 on epoch=437
06/13/2022 10:13:53 - INFO - __main__ - Saving model with best Classification-F1: 0.6610052134245683 -> 0.6897910138399268 on epoch=437, global_step=1750
06/13/2022 10:13:55 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.06 on epoch=439
06/13/2022 10:13:58 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.04 on epoch=442
06/13/2022 10:14:00 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.07 on epoch=444
06/13/2022 10:14:02 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.11 on epoch=447
06/13/2022 10:14:05 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.05 on epoch=449
06/13/2022 10:14:06 - INFO - __main__ - Global step 1800 Train loss 0.06 Classification-F1 0.638809316228671 on epoch=449
06/13/2022 10:14:08 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.03 on epoch=452
06/13/2022 10:14:11 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=454
06/13/2022 10:14:13 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.08 on epoch=457
06/13/2022 10:14:16 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.08 on epoch=459
06/13/2022 10:14:18 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=462
06/13/2022 10:14:19 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.6673686673686674 on epoch=462
06/13/2022 10:14:21 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=464
06/13/2022 10:14:24 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.04 on epoch=467
06/13/2022 10:14:26 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.03 on epoch=469
06/13/2022 10:14:29 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.07 on epoch=472
06/13/2022 10:14:31 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.04 on epoch=474
06/13/2022 10:14:32 - INFO - __main__ - Global step 1900 Train loss 0.04 Classification-F1 0.6539130579877609 on epoch=474
06/13/2022 10:14:35 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=477
06/13/2022 10:14:37 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=479
06/13/2022 10:14:40 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=482
06/13/2022 10:14:42 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=484
06/13/2022 10:14:44 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.06 on epoch=487
06/13/2022 10:14:45 - INFO - __main__ - Global step 1950 Train loss 0.04 Classification-F1 0.6436980042243201 on epoch=487
06/13/2022 10:14:48 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.06 on epoch=489
06/13/2022 10:14:50 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=492
06/13/2022 10:14:53 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=494
06/13/2022 10:14:55 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.06 on epoch=497
06/13/2022 10:14:58 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=499
06/13/2022 10:14:59 - INFO - __main__ - Global step 2000 Train loss 0.04 Classification-F1 0.6311288246772118 on epoch=499
06/13/2022 10:15:01 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=502
06/13/2022 10:15:04 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.06 on epoch=504
06/13/2022 10:15:06 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.02 on epoch=507
06/13/2022 10:15:09 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=509
06/13/2022 10:15:11 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.03 on epoch=512
06/13/2022 10:15:12 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.6155950305143852 on epoch=512
06/13/2022 10:15:14 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.04 on epoch=514
06/13/2022 10:15:17 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=517
06/13/2022 10:15:19 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.03 on epoch=519
06/13/2022 10:15:22 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.03 on epoch=522
06/13/2022 10:15:24 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=524
06/13/2022 10:15:25 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.6539130579877609 on epoch=524
06/13/2022 10:15:28 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.04 on epoch=527
06/13/2022 10:15:30 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.04 on epoch=529
06/13/2022 10:15:33 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.05 on epoch=532
06/13/2022 10:15:35 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.04 on epoch=534
06/13/2022 10:15:37 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.05 on epoch=537
06/13/2022 10:15:39 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.6532759263022421 on epoch=537
06/13/2022 10:15:41 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.03 on epoch=539
06/13/2022 10:15:44 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.11 on epoch=542
06/13/2022 10:15:46 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=544
06/13/2022 10:15:49 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.04 on epoch=547
06/13/2022 10:15:51 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=549
06/13/2022 10:15:52 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.6539130579877609 on epoch=549
06/13/2022 10:15:54 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=552
06/13/2022 10:15:57 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=554
06/13/2022 10:15:59 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.05 on epoch=557
06/13/2022 10:16:02 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.08 on epoch=559
06/13/2022 10:16:04 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.03 on epoch=562
06/13/2022 10:16:05 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.6683695507708667 on epoch=562
06/13/2022 10:16:08 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=564
06/13/2022 10:16:10 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=567
06/13/2022 10:16:13 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=569
06/13/2022 10:16:15 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=572
06/13/2022 10:16:18 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=574
06/13/2022 10:16:19 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.6683695507708667 on epoch=574
06/13/2022 10:16:21 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=577
06/13/2022 10:16:23 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=579
06/13/2022 10:16:26 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=582
06/13/2022 10:16:28 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=584
06/13/2022 10:16:31 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=587
06/13/2022 10:16:32 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.667625503151819 on epoch=587
06/13/2022 10:16:34 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=589
06/13/2022 10:16:36 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=592
06/13/2022 10:16:39 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.03 on epoch=594
06/13/2022 10:16:41 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.06 on epoch=597
06/13/2022 10:16:44 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=599
06/13/2022 10:16:45 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.6539130579877609 on epoch=599
06/13/2022 10:16:47 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.04 on epoch=602
06/13/2022 10:16:50 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.04 on epoch=604
06/13/2022 10:16:52 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.04 on epoch=607
06/13/2022 10:16:54 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=609
06/13/2022 10:16:57 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.04 on epoch=612
06/13/2022 10:16:58 - INFO - __main__ - Global step 2450 Train loss 0.04 Classification-F1 0.6753345210568211 on epoch=612
06/13/2022 10:17:00 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=614
06/13/2022 10:17:03 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.12 on epoch=617
06/13/2022 10:17:05 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=619
06/13/2022 10:17:07 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/13/2022 10:17:10 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=624
06/13/2022 10:17:11 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.6539130579877609 on epoch=624
06/13/2022 10:17:14 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=627
06/13/2022 10:17:16 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=629
06/13/2022 10:17:18 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.04 on epoch=632
06/13/2022 10:17:21 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.03 on epoch=634
06/13/2022 10:17:23 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=637
06/13/2022 10:17:24 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.6539130579877609 on epoch=637
06/13/2022 10:17:27 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/13/2022 10:17:29 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=642
06/13/2022 10:17:32 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.03 on epoch=644
06/13/2022 10:17:34 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=647
06/13/2022 10:17:37 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.04 on epoch=649
06/13/2022 10:17:38 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.6532759263022421 on epoch=649
06/13/2022 10:17:40 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.03 on epoch=652
06/13/2022 10:17:43 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/13/2022 10:17:45 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=657
06/13/2022 10:17:47 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=659
06/13/2022 10:17:50 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=662
06/13/2022 10:17:51 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.6539130579877609 on epoch=662
06/13/2022 10:17:54 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.08 on epoch=664
06/13/2022 10:17:56 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.09 on epoch=667
06/13/2022 10:17:58 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.06 on epoch=669
06/13/2022 10:18:01 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.04 on epoch=672
06/13/2022 10:18:03 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/13/2022 10:18:04 - INFO - __main__ - Global step 2700 Train loss 0.05 Classification-F1 0.6539130579877609 on epoch=674
06/13/2022 10:18:07 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=677
06/13/2022 10:18:09 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=679
06/13/2022 10:18:12 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=682
06/13/2022 10:18:14 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/13/2022 10:18:16 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=687
06/13/2022 10:18:18 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.6683695507708667 on epoch=687
06/13/2022 10:18:20 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=689
06/13/2022 10:18:22 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=692
06/13/2022 10:18:25 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=694
06/13/2022 10:18:27 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=697
06/13/2022 10:18:30 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=699
06/13/2022 10:18:31 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.6539130579877609 on epoch=699
06/13/2022 10:18:33 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.03 on epoch=702
06/13/2022 10:18:36 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=704
06/13/2022 10:18:38 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.09 on epoch=707
06/13/2022 10:18:40 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/13/2022 10:18:43 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.08 on epoch=712
06/13/2022 10:18:44 - INFO - __main__ - Global step 2850 Train loss 0.04 Classification-F1 0.6683695507708667 on epoch=712
06/13/2022 10:18:47 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=714
06/13/2022 10:18:49 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=717
06/13/2022 10:18:52 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=719
06/13/2022 10:18:54 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=722
06/13/2022 10:18:56 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.03 on epoch=724
06/13/2022 10:18:58 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.6539130579877609 on epoch=724
06/13/2022 10:19:00 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=727
06/13/2022 10:19:02 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.03 on epoch=729
06/13/2022 10:19:05 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.04 on epoch=732
06/13/2022 10:19:07 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=734
06/13/2022 10:19:10 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/13/2022 10:19:11 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.6897910138399268 on epoch=737
06/13/2022 10:19:13 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=739
06/13/2022 10:19:16 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=742
06/13/2022 10:19:18 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=744
06/13/2022 10:19:20 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=747
06/13/2022 10:19:23 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/13/2022 10:19:24 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.6683695507708667 on epoch=749
06/13/2022 10:19:24 - INFO - __main__ - save last model!
06/13/2022 10:19:24 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/13/2022 10:19:24 - INFO - __main__ - Start tokenizing ... 5509 instances
06/13/2022 10:19:24 - INFO - __main__ - Printing 3 examples
06/13/2022 10:19:24 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/13/2022 10:19:24 - INFO - __main__ - ['others']
06/13/2022 10:19:24 - INFO - __main__ -  [emo] what you like very little things ok
06/13/2022 10:19:24 - INFO - __main__ - ['others']
06/13/2022 10:19:24 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/13/2022 10:19:24 - INFO - __main__ - ['others']
06/13/2022 10:19:24 - INFO - __main__ - Tokenizing Input ...
06/13/2022 10:19:24 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 10:19:24 - INFO - __main__ - Printing 3 examples
06/13/2022 10:19:24 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/13/2022 10:19:24 - INFO - __main__ - ['happy']
06/13/2022 10:19:24 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/13/2022 10:19:24 - INFO - __main__ - ['happy']
06/13/2022 10:19:24 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/13/2022 10:19:24 - INFO - __main__ - ['happy']
06/13/2022 10:19:24 - INFO - __main__ - Tokenizing Input ...
06/13/2022 10:19:24 - INFO - __main__ - Tokenizing Output ...
06/13/2022 10:19:24 - INFO - __main__ - Loaded 64 examples from train data
06/13/2022 10:19:24 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 10:19:24 - INFO - __main__ - Printing 3 examples
06/13/2022 10:19:24 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
06/13/2022 10:19:24 - INFO - __main__ - ['happy']
06/13/2022 10:19:24 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
06/13/2022 10:19:24 - INFO - __main__ - ['happy']
06/13/2022 10:19:24 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
06/13/2022 10:19:24 - INFO - __main__ - ['happy']
06/13/2022 10:19:24 - INFO - __main__ - Tokenizing Input ...
06/13/2022 10:19:24 - INFO - __main__ - Tokenizing Output ...
06/13/2022 10:19:24 - INFO - __main__ - Loaded 64 examples from dev data
06/13/2022 10:19:26 - INFO - __main__ - Tokenizing Output ...
06/13/2022 10:19:31 - INFO - __main__ - Loaded 5509 examples from test data
06/13/2022 10:19:39 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 10:19:40 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 10:19:40 - INFO - __main__ - Starting training!
06/13/2022 10:20:53 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-up32shot/singletask-emo/emo_16_21_0.2_8_predictions.txt
06/13/2022 10:20:53 - INFO - __main__ - Classification-F1 on test data: 0.1259
06/13/2022 10:20:53 - INFO - __main__ - prefix=emo_16_21, lr=0.2, bsz=8, dev_performance=0.6897910138399268, test_performance=0.1258846984288021
06/13/2022 10:20:53 - INFO - __main__ - Running ... prefix=emo_16_42, lr=0.5, bsz=8 ...
06/13/2022 10:20:54 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 10:20:54 - INFO - __main__ - Printing 3 examples
06/13/2022 10:20:54 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/13/2022 10:20:54 - INFO - __main__ - ['happy']
06/13/2022 10:20:54 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/13/2022 10:20:54 - INFO - __main__ - ['happy']
06/13/2022 10:20:54 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/13/2022 10:20:54 - INFO - __main__ - ['happy']
06/13/2022 10:20:54 - INFO - __main__ - Tokenizing Input ...
06/13/2022 10:20:54 - INFO - __main__ - Tokenizing Output ...
06/13/2022 10:20:54 - INFO - __main__ - Loaded 64 examples from train data
06/13/2022 10:20:54 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 10:20:54 - INFO - __main__ - Printing 3 examples
06/13/2022 10:20:54 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
06/13/2022 10:20:54 - INFO - __main__ - ['happy']
06/13/2022 10:20:54 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
06/13/2022 10:20:54 - INFO - __main__ - ['happy']
06/13/2022 10:20:54 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
06/13/2022 10:20:54 - INFO - __main__ - ['happy']
06/13/2022 10:20:54 - INFO - __main__ - Tokenizing Input ...
06/13/2022 10:20:54 - INFO - __main__ - Tokenizing Output ...
06/13/2022 10:20:54 - INFO - __main__ - Loaded 64 examples from dev data
06/13/2022 10:21:11 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 10:21:12 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 10:21:12 - INFO - __main__ - Starting training!
06/13/2022 10:21:15 - INFO - __main__ - Step 10 Global step 10 Train loss 3.57 on epoch=2
06/13/2022 10:21:17 - INFO - __main__ - Step 20 Global step 20 Train loss 2.53 on epoch=4
06/13/2022 10:21:20 - INFO - __main__ - Step 30 Global step 30 Train loss 1.68 on epoch=7
06/13/2022 10:21:22 - INFO - __main__ - Step 40 Global step 40 Train loss 1.41 on epoch=9
06/13/2022 10:21:25 - INFO - __main__ - Step 50 Global step 50 Train loss 0.95 on epoch=12
06/13/2022 10:21:26 - INFO - __main__ - Global step 50 Train loss 2.03 Classification-F1 0.46679566563467495 on epoch=12
06/13/2022 10:21:26 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.46679566563467495 on epoch=12, global_step=50
06/13/2022 10:21:28 - INFO - __main__ - Step 60 Global step 60 Train loss 0.85 on epoch=14
06/13/2022 10:21:31 - INFO - __main__ - Step 70 Global step 70 Train loss 0.82 on epoch=17
06/13/2022 10:21:33 - INFO - __main__ - Step 80 Global step 80 Train loss 0.76 on epoch=19
06/13/2022 10:21:36 - INFO - __main__ - Step 90 Global step 90 Train loss 0.68 on epoch=22
06/13/2022 10:21:38 - INFO - __main__ - Step 100 Global step 100 Train loss 0.68 on epoch=24
06/13/2022 10:21:39 - INFO - __main__ - Global step 100 Train loss 0.76 Classification-F1 0.5245337159253944 on epoch=24
06/13/2022 10:21:39 - INFO - __main__ - Saving model with best Classification-F1: 0.46679566563467495 -> 0.5245337159253944 on epoch=24, global_step=100
06/13/2022 10:21:41 - INFO - __main__ - Step 110 Global step 110 Train loss 0.69 on epoch=27
06/13/2022 10:21:44 - INFO - __main__ - Step 120 Global step 120 Train loss 0.62 on epoch=29
06/13/2022 10:21:46 - INFO - __main__ - Step 130 Global step 130 Train loss 0.61 on epoch=32
06/13/2022 10:21:49 - INFO - __main__ - Step 140 Global step 140 Train loss 0.48 on epoch=34
06/13/2022 10:21:51 - INFO - __main__ - Step 150 Global step 150 Train loss 0.58 on epoch=37
06/13/2022 10:21:52 - INFO - __main__ - Global step 150 Train loss 0.59 Classification-F1 0.43686816405082657 on epoch=37
06/13/2022 10:21:55 - INFO - __main__ - Step 160 Global step 160 Train loss 0.61 on epoch=39
06/13/2022 10:21:57 - INFO - __main__ - Step 170 Global step 170 Train loss 0.60 on epoch=42
06/13/2022 10:21:59 - INFO - __main__ - Step 180 Global step 180 Train loss 0.52 on epoch=44
06/13/2022 10:22:02 - INFO - __main__ - Step 190 Global step 190 Train loss 0.58 on epoch=47
06/13/2022 10:22:04 - INFO - __main__ - Step 200 Global step 200 Train loss 0.44 on epoch=49
06/13/2022 10:22:05 - INFO - __main__ - Global step 200 Train loss 0.55 Classification-F1 0.5260317460317461 on epoch=49
06/13/2022 10:22:05 - INFO - __main__ - Saving model with best Classification-F1: 0.5245337159253944 -> 0.5260317460317461 on epoch=49, global_step=200
06/13/2022 10:22:08 - INFO - __main__ - Step 210 Global step 210 Train loss 0.48 on epoch=52
06/13/2022 10:22:10 - INFO - __main__ - Step 220 Global step 220 Train loss 0.51 on epoch=54
06/13/2022 10:22:12 - INFO - __main__ - Step 230 Global step 230 Train loss 0.41 on epoch=57
06/13/2022 10:22:15 - INFO - __main__ - Step 240 Global step 240 Train loss 0.51 on epoch=59
06/13/2022 10:22:17 - INFO - __main__ - Step 250 Global step 250 Train loss 0.38 on epoch=62
06/13/2022 10:22:18 - INFO - __main__ - Global step 250 Train loss 0.46 Classification-F1 0.5672785084549791 on epoch=62
06/13/2022 10:22:18 - INFO - __main__ - Saving model with best Classification-F1: 0.5260317460317461 -> 0.5672785084549791 on epoch=62, global_step=250
06/13/2022 10:22:21 - INFO - __main__ - Step 260 Global step 260 Train loss 0.41 on epoch=64
06/13/2022 10:22:23 - INFO - __main__ - Step 270 Global step 270 Train loss 0.31 on epoch=67
06/13/2022 10:22:26 - INFO - __main__ - Step 280 Global step 280 Train loss 0.29 on epoch=69
06/13/2022 10:22:28 - INFO - __main__ - Step 290 Global step 290 Train loss 0.40 on epoch=72
06/13/2022 10:22:31 - INFO - __main__ - Step 300 Global step 300 Train loss 0.33 on epoch=74
06/13/2022 10:22:32 - INFO - __main__ - Global step 300 Train loss 0.35 Classification-F1 0.5909875222816399 on epoch=74
06/13/2022 10:22:32 - INFO - __main__ - Saving model with best Classification-F1: 0.5672785084549791 -> 0.5909875222816399 on epoch=74, global_step=300
06/13/2022 10:22:34 - INFO - __main__ - Step 310 Global step 310 Train loss 0.31 on epoch=77
06/13/2022 10:22:37 - INFO - __main__ - Step 320 Global step 320 Train loss 0.24 on epoch=79
06/13/2022 10:22:39 - INFO - __main__ - Step 330 Global step 330 Train loss 0.31 on epoch=82
06/13/2022 10:22:41 - INFO - __main__ - Step 340 Global step 340 Train loss 0.33 on epoch=84
06/13/2022 10:22:44 - INFO - __main__ - Step 350 Global step 350 Train loss 0.34 on epoch=87
06/13/2022 10:22:45 - INFO - __main__ - Global step 350 Train loss 0.31 Classification-F1 0.6157171717171718 on epoch=87
06/13/2022 10:22:45 - INFO - __main__ - Saving model with best Classification-F1: 0.5909875222816399 -> 0.6157171717171718 on epoch=87, global_step=350
06/13/2022 10:22:47 - INFO - __main__ - Step 360 Global step 360 Train loss 0.31 on epoch=89
06/13/2022 10:22:50 - INFO - __main__ - Step 370 Global step 370 Train loss 0.27 on epoch=92
06/13/2022 10:22:52 - INFO - __main__ - Step 380 Global step 380 Train loss 0.22 on epoch=94
06/13/2022 10:22:55 - INFO - __main__ - Step 390 Global step 390 Train loss 0.23 on epoch=97
06/13/2022 10:22:57 - INFO - __main__ - Step 400 Global step 400 Train loss 0.22 on epoch=99
06/13/2022 10:22:58 - INFO - __main__ - Global step 400 Train loss 0.25 Classification-F1 0.6158722109533469 on epoch=99
06/13/2022 10:22:58 - INFO - __main__ - Saving model with best Classification-F1: 0.6157171717171718 -> 0.6158722109533469 on epoch=99, global_step=400
06/13/2022 10:23:01 - INFO - __main__ - Step 410 Global step 410 Train loss 0.21 on epoch=102
06/13/2022 10:23:03 - INFO - __main__ - Step 420 Global step 420 Train loss 0.27 on epoch=104
06/13/2022 10:23:06 - INFO - __main__ - Step 430 Global step 430 Train loss 0.28 on epoch=107
06/13/2022 10:23:08 - INFO - __main__ - Step 440 Global step 440 Train loss 0.19 on epoch=109
06/13/2022 10:23:10 - INFO - __main__ - Step 450 Global step 450 Train loss 0.14 on epoch=112
06/13/2022 10:23:11 - INFO - __main__ - Global step 450 Train loss 0.22 Classification-F1 0.7644441536347576 on epoch=112
06/13/2022 10:23:11 - INFO - __main__ - Saving model with best Classification-F1: 0.6158722109533469 -> 0.7644441536347576 on epoch=112, global_step=450
06/13/2022 10:23:14 - INFO - __main__ - Step 460 Global step 460 Train loss 0.21 on epoch=114
06/13/2022 10:23:16 - INFO - __main__ - Step 470 Global step 470 Train loss 0.21 on epoch=117
06/13/2022 10:23:19 - INFO - __main__ - Step 480 Global step 480 Train loss 0.17 on epoch=119
06/13/2022 10:23:21 - INFO - __main__ - Step 490 Global step 490 Train loss 0.17 on epoch=122
06/13/2022 10:23:23 - INFO - __main__ - Step 500 Global step 500 Train loss 0.13 on epoch=124
06/13/2022 10:23:24 - INFO - __main__ - Global step 500 Train loss 0.18 Classification-F1 0.8407300420168067 on epoch=124
06/13/2022 10:23:24 - INFO - __main__ - Saving model with best Classification-F1: 0.7644441536347576 -> 0.8407300420168067 on epoch=124, global_step=500
06/13/2022 10:23:27 - INFO - __main__ - Step 510 Global step 510 Train loss 0.11 on epoch=127
06/13/2022 10:23:29 - INFO - __main__ - Step 520 Global step 520 Train loss 0.22 on epoch=129
06/13/2022 10:23:32 - INFO - __main__ - Step 530 Global step 530 Train loss 0.13 on epoch=132
06/13/2022 10:23:34 - INFO - __main__ - Step 540 Global step 540 Train loss 0.13 on epoch=134
06/13/2022 10:23:37 - INFO - __main__ - Step 550 Global step 550 Train loss 0.16 on epoch=137
06/13/2022 10:23:37 - INFO - __main__ - Global step 550 Train loss 0.15 Classification-F1 0.8115301724137931 on epoch=137
06/13/2022 10:23:40 - INFO - __main__ - Step 560 Global step 560 Train loss 0.13 on epoch=139
06/13/2022 10:23:42 - INFO - __main__ - Step 570 Global step 570 Train loss 0.14 on epoch=142
06/13/2022 10:23:45 - INFO - __main__ - Step 580 Global step 580 Train loss 0.13 on epoch=144
06/13/2022 10:23:47 - INFO - __main__ - Step 590 Global step 590 Train loss 0.15 on epoch=147
06/13/2022 10:23:50 - INFO - __main__ - Step 600 Global step 600 Train loss 0.13 on epoch=149
06/13/2022 10:23:51 - INFO - __main__ - Global step 600 Train loss 0.14 Classification-F1 0.7892385392385393 on epoch=149
06/13/2022 10:23:53 - INFO - __main__ - Step 610 Global step 610 Train loss 0.10 on epoch=152
06/13/2022 10:23:56 - INFO - __main__ - Step 620 Global step 620 Train loss 0.07 on epoch=154
06/13/2022 10:23:58 - INFO - __main__ - Step 630 Global step 630 Train loss 0.12 on epoch=157
06/13/2022 10:24:01 - INFO - __main__ - Step 640 Global step 640 Train loss 0.11 on epoch=159
06/13/2022 10:24:03 - INFO - __main__ - Step 650 Global step 650 Train loss 0.08 on epoch=162
06/13/2022 10:24:04 - INFO - __main__ - Global step 650 Train loss 0.10 Classification-F1 0.7747926093514329 on epoch=162
06/13/2022 10:24:06 - INFO - __main__ - Step 660 Global step 660 Train loss 0.09 on epoch=164
06/13/2022 10:24:09 - INFO - __main__ - Step 670 Global step 670 Train loss 0.07 on epoch=167
06/13/2022 10:24:11 - INFO - __main__ - Step 680 Global step 680 Train loss 0.07 on epoch=169
06/13/2022 10:24:14 - INFO - __main__ - Step 690 Global step 690 Train loss 0.04 on epoch=172
06/13/2022 10:24:16 - INFO - __main__ - Step 700 Global step 700 Train loss 0.06 on epoch=174
06/13/2022 10:24:17 - INFO - __main__ - Global step 700 Train loss 0.06 Classification-F1 0.8081033549783551 on epoch=174
06/13/2022 10:24:19 - INFO - __main__ - Step 710 Global step 710 Train loss 0.09 on epoch=177
06/13/2022 10:24:22 - INFO - __main__ - Step 720 Global step 720 Train loss 0.05 on epoch=179
06/13/2022 10:24:24 - INFO - __main__ - Step 730 Global step 730 Train loss 0.05 on epoch=182
06/13/2022 10:24:27 - INFO - __main__ - Step 740 Global step 740 Train loss 0.04 on epoch=184
06/13/2022 10:24:29 - INFO - __main__ - Step 750 Global step 750 Train loss 0.03 on epoch=187
06/13/2022 10:24:30 - INFO - __main__ - Global step 750 Train loss 0.05 Classification-F1 0.8234020881079706 on epoch=187
06/13/2022 10:24:32 - INFO - __main__ - Step 760 Global step 760 Train loss 0.05 on epoch=189
06/13/2022 10:24:35 - INFO - __main__ - Step 770 Global step 770 Train loss 0.04 on epoch=192
06/13/2022 10:24:37 - INFO - __main__ - Step 780 Global step 780 Train loss 0.05 on epoch=194
06/13/2022 10:24:40 - INFO - __main__ - Step 790 Global step 790 Train loss 0.07 on epoch=197
06/13/2022 10:24:42 - INFO - __main__ - Step 800 Global step 800 Train loss 0.02 on epoch=199
06/13/2022 10:24:43 - INFO - __main__ - Global step 800 Train loss 0.05 Classification-F1 0.7858585858585858 on epoch=199
06/13/2022 10:24:46 - INFO - __main__ - Step 810 Global step 810 Train loss 0.06 on epoch=202
06/13/2022 10:24:48 - INFO - __main__ - Step 820 Global step 820 Train loss 0.02 on epoch=204
06/13/2022 10:24:50 - INFO - __main__ - Step 830 Global step 830 Train loss 0.04 on epoch=207
06/13/2022 10:24:53 - INFO - __main__ - Step 840 Global step 840 Train loss 0.05 on epoch=209
06/13/2022 10:24:55 - INFO - __main__ - Step 850 Global step 850 Train loss 0.02 on epoch=212
06/13/2022 10:24:56 - INFO - __main__ - Global step 850 Train loss 0.04 Classification-F1 0.8129032258064516 on epoch=212
06/13/2022 10:24:59 - INFO - __main__ - Step 860 Global step 860 Train loss 0.03 on epoch=214
06/13/2022 10:25:01 - INFO - __main__ - Step 870 Global step 870 Train loss 0.12 on epoch=217
06/13/2022 10:25:03 - INFO - __main__ - Step 880 Global step 880 Train loss 0.13 on epoch=219
06/13/2022 10:25:06 - INFO - __main__ - Step 890 Global step 890 Train loss 0.03 on epoch=222
06/13/2022 10:25:08 - INFO - __main__ - Step 900 Global step 900 Train loss 0.06 on epoch=224
06/13/2022 10:25:09 - INFO - __main__ - Global step 900 Train loss 0.07 Classification-F1 0.8108100094876661 on epoch=224
06/13/2022 10:25:12 - INFO - __main__ - Step 910 Global step 910 Train loss 0.03 on epoch=227
06/13/2022 10:25:14 - INFO - __main__ - Step 920 Global step 920 Train loss 0.07 on epoch=229
06/13/2022 10:25:17 - INFO - __main__ - Step 930 Global step 930 Train loss 0.02 on epoch=232
06/13/2022 10:25:19 - INFO - __main__ - Step 940 Global step 940 Train loss 0.01 on epoch=234
06/13/2022 10:25:22 - INFO - __main__ - Step 950 Global step 950 Train loss 0.03 on epoch=237
06/13/2022 10:25:22 - INFO - __main__ - Global step 950 Train loss 0.03 Classification-F1 0.7944396526939222 on epoch=237
06/13/2022 10:25:25 - INFO - __main__ - Step 960 Global step 960 Train loss 0.03 on epoch=239
06/13/2022 10:25:27 - INFO - __main__ - Step 970 Global step 970 Train loss 0.04 on epoch=242
06/13/2022 10:25:30 - INFO - __main__ - Step 980 Global step 980 Train loss 0.10 on epoch=244
06/13/2022 10:25:32 - INFO - __main__ - Step 990 Global step 990 Train loss 0.04 on epoch=247
06/13/2022 10:25:35 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.04 on epoch=249
06/13/2022 10:25:36 - INFO - __main__ - Global step 1000 Train loss 0.05 Classification-F1 0.7975215517241379 on epoch=249
06/13/2022 10:25:38 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.04 on epoch=252
06/13/2022 10:25:41 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.02 on epoch=254
06/13/2022 10:25:43 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.02 on epoch=257
06/13/2022 10:25:46 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.02 on epoch=259
06/13/2022 10:25:48 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.02 on epoch=262
06/13/2022 10:25:49 - INFO - __main__ - Global step 1050 Train loss 0.02 Classification-F1 0.8114538038898439 on epoch=262
06/13/2022 10:25:51 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.03 on epoch=264
06/13/2022 10:25:54 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.06 on epoch=267
06/13/2022 10:25:56 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.03 on epoch=269
06/13/2022 10:25:59 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.02 on epoch=272
06/13/2022 10:26:01 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.04 on epoch=274
06/13/2022 10:26:02 - INFO - __main__ - Global step 1100 Train loss 0.03 Classification-F1 0.7954545454545454 on epoch=274
06/13/2022 10:26:04 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.03 on epoch=277
06/13/2022 10:26:07 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.04 on epoch=279
06/13/2022 10:26:09 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.02 on epoch=282
06/13/2022 10:26:12 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.04 on epoch=284
06/13/2022 10:26:14 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.03 on epoch=287
06/13/2022 10:26:15 - INFO - __main__ - Global step 1150 Train loss 0.03 Classification-F1 0.8267763845350052 on epoch=287
06/13/2022 10:26:18 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.04 on epoch=289
06/13/2022 10:26:20 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.03 on epoch=292
06/13/2022 10:26:22 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.02 on epoch=294
06/13/2022 10:26:25 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.01 on epoch=297
06/13/2022 10:26:27 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=299
06/13/2022 10:26:28 - INFO - __main__ - Global step 1200 Train loss 0.02 Classification-F1 0.808779761904762 on epoch=299
06/13/2022 10:26:31 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.03 on epoch=302
06/13/2022 10:26:33 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=304
06/13/2022 10:26:36 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=307
06/13/2022 10:26:38 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.02 on epoch=309
06/13/2022 10:26:40 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.01 on epoch=312
06/13/2022 10:26:41 - INFO - __main__ - Global step 1250 Train loss 0.01 Classification-F1 0.7942924347158219 on epoch=312
06/13/2022 10:26:44 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.00 on epoch=314
06/13/2022 10:26:46 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.01 on epoch=317
06/13/2022 10:26:49 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=319
06/13/2022 10:26:51 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=322
06/13/2022 10:26:53 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=324
06/13/2022 10:26:54 - INFO - __main__ - Global step 1300 Train loss 0.01 Classification-F1 0.8264159251019653 on epoch=324
06/13/2022 10:26:57 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=327
06/13/2022 10:26:59 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.05 on epoch=329
06/13/2022 10:27:02 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.00 on epoch=332
06/13/2022 10:27:04 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=334
06/13/2022 10:27:06 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=337
06/13/2022 10:27:07 - INFO - __main__ - Global step 1350 Train loss 0.02 Classification-F1 0.8264159251019653 on epoch=337
06/13/2022 10:27:10 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.00 on epoch=339
06/13/2022 10:27:12 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.02 on epoch=342
06/13/2022 10:27:14 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.02 on epoch=344
06/13/2022 10:27:17 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.02 on epoch=347
06/13/2022 10:27:19 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=349
06/13/2022 10:27:20 - INFO - __main__ - Global step 1400 Train loss 0.02 Classification-F1 0.7938176406926407 on epoch=349
06/13/2022 10:27:22 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.03 on epoch=352
06/13/2022 10:27:25 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.08 on epoch=354
06/13/2022 10:27:27 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.00 on epoch=357
06/13/2022 10:27:30 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=359
06/13/2022 10:27:32 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=362
06/13/2022 10:27:33 - INFO - __main__ - Global step 1450 Train loss 0.03 Classification-F1 0.8114538038898439 on epoch=362
06/13/2022 10:27:35 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=364
06/13/2022 10:27:38 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=367
06/13/2022 10:27:40 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.02 on epoch=369
06/13/2022 10:27:43 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=372
06/13/2022 10:27:45 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.02 on epoch=374
06/13/2022 10:27:46 - INFO - __main__ - Global step 1500 Train loss 0.02 Classification-F1 0.7718497189085425 on epoch=374
06/13/2022 10:27:48 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=377
06/13/2022 10:27:51 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=379
06/13/2022 10:27:53 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.02 on epoch=382
06/13/2022 10:27:55 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=384
06/13/2022 10:27:58 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.03 on epoch=387
06/13/2022 10:27:59 - INFO - __main__ - Global step 1550 Train loss 0.01 Classification-F1 0.7955492424242425 on epoch=387
06/13/2022 10:28:01 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=389
06/13/2022 10:28:04 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=392
06/13/2022 10:28:06 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=394
06/13/2022 10:28:08 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=397
06/13/2022 10:28:11 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=399
06/13/2022 10:28:12 - INFO - __main__ - Global step 1600 Train loss 0.01 Classification-F1 0.7941312008674437 on epoch=399
06/13/2022 10:28:14 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=402
06/13/2022 10:28:17 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=404
06/13/2022 10:28:19 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=407
06/13/2022 10:28:21 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.03 on epoch=409
06/13/2022 10:28:24 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=412
06/13/2022 10:28:25 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.8264159251019653 on epoch=412
06/13/2022 10:28:27 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.03 on epoch=414
06/13/2022 10:28:29 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=417
06/13/2022 10:28:32 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.03 on epoch=419
06/13/2022 10:28:34 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=422
06/13/2022 10:28:37 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=424
06/13/2022 10:28:37 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.8264159251019653 on epoch=424
06/13/2022 10:28:40 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=427
06/13/2022 10:28:42 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=429
06/13/2022 10:28:44 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=432
06/13/2022 10:28:47 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=434
06/13/2022 10:28:49 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.04 on epoch=437
06/13/2022 10:28:50 - INFO - __main__ - Global step 1750 Train loss 0.01 Classification-F1 0.8447916666666667 on epoch=437
06/13/2022 10:28:50 - INFO - __main__ - Saving model with best Classification-F1: 0.8407300420168067 -> 0.8447916666666667 on epoch=437, global_step=1750
06/13/2022 10:28:53 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.11 on epoch=439
06/13/2022 10:28:55 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.03 on epoch=442
06/13/2022 10:28:57 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=444
06/13/2022 10:29:00 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=447
06/13/2022 10:29:02 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=449
06/13/2022 10:29:03 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.8117127138261733 on epoch=449
06/13/2022 10:29:06 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=452
06/13/2022 10:29:08 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=454
06/13/2022 10:29:10 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=457
06/13/2022 10:29:13 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=459
06/13/2022 10:29:15 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=462
06/13/2022 10:29:16 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.8264159251019653 on epoch=462
06/13/2022 10:29:18 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=464
06/13/2022 10:29:21 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=467
06/13/2022 10:29:23 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=469
06/13/2022 10:29:26 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=472
06/13/2022 10:29:28 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=474
06/13/2022 10:29:29 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.7952946883337375 on epoch=474
06/13/2022 10:29:31 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=477
06/13/2022 10:29:34 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=479
06/13/2022 10:29:36 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=482
06/13/2022 10:29:39 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=484
06/13/2022 10:29:41 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=487
06/13/2022 10:29:42 - INFO - __main__ - Global step 1950 Train loss 0.00 Classification-F1 0.8066658363432558 on epoch=487
06/13/2022 10:29:45 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.07 on epoch=489
06/13/2022 10:29:47 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=492
06/13/2022 10:29:49 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=494
06/13/2022 10:29:52 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=497
06/13/2022 10:29:54 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=499
06/13/2022 10:29:55 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.8294690860215053 on epoch=499
06/13/2022 10:29:57 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=502
06/13/2022 10:30:00 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=504
06/13/2022 10:30:02 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/13/2022 10:30:05 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=509
06/13/2022 10:30:07 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/13/2022 10:30:08 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.8114538038898439 on epoch=512
06/13/2022 10:30:10 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.04 on epoch=514
06/13/2022 10:30:13 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=517
06/13/2022 10:30:15 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/13/2022 10:30:18 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/13/2022 10:30:20 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/13/2022 10:30:21 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.8114538038898439 on epoch=524
06/13/2022 10:30:24 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
06/13/2022 10:30:26 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=529
06/13/2022 10:30:28 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=532
06/13/2022 10:30:31 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
06/13/2022 10:30:33 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
06/13/2022 10:30:34 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.8129032258064516 on epoch=537
06/13/2022 10:30:36 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/13/2022 10:30:39 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/13/2022 10:30:41 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/13/2022 10:30:44 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/13/2022 10:30:46 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/13/2022 10:30:47 - INFO - __main__ - Global step 2200 Train loss 0.00 Classification-F1 0.8129032258064516 on epoch=549
06/13/2022 10:30:49 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=552
06/13/2022 10:30:52 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/13/2022 10:30:54 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
06/13/2022 10:30:57 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/13/2022 10:30:59 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/13/2022 10:31:00 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.7971774193548387 on epoch=562
06/13/2022 10:31:02 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/13/2022 10:31:05 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=567
06/13/2022 10:31:07 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/13/2022 10:31:10 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/13/2022 10:31:12 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=574
06/13/2022 10:31:13 - INFO - __main__ - Global step 2300 Train loss 0.00 Classification-F1 0.778225806451613 on epoch=574
06/13/2022 10:31:15 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/13/2022 10:31:18 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/13/2022 10:31:20 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.05 on epoch=582
06/13/2022 10:31:23 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=584
06/13/2022 10:31:25 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/13/2022 10:31:26 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.808779761904762 on epoch=587
06/13/2022 10:31:28 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/13/2022 10:31:31 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/13/2022 10:31:33 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/13/2022 10:31:36 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/13/2022 10:31:38 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.12 on epoch=599
06/13/2022 10:31:39 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.8129032258064516 on epoch=599
06/13/2022 10:31:42 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/13/2022 10:31:44 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/13/2022 10:31:46 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/13/2022 10:31:49 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/13/2022 10:31:51 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/13/2022 10:31:52 - INFO - __main__ - Global step 2450 Train loss 0.00 Classification-F1 0.8138440860215053 on epoch=612
06/13/2022 10:31:55 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.05 on epoch=614
06/13/2022 10:31:57 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/13/2022 10:31:59 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/13/2022 10:32:02 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/13/2022 10:32:04 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=624
06/13/2022 10:32:05 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.8426197458455523 on epoch=624
06/13/2022 10:32:08 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/13/2022 10:32:10 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/13/2022 10:32:12 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/13/2022 10:32:15 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/13/2022 10:32:17 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.07 on epoch=637
06/13/2022 10:32:18 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.8140446207808637 on epoch=637
06/13/2022 10:32:21 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=639
06/13/2022 10:32:23 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=642
06/13/2022 10:32:26 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/13/2022 10:32:28 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/13/2022 10:32:30 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/13/2022 10:32:31 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.8116747835497835 on epoch=649
06/13/2022 10:32:34 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/13/2022 10:32:36 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/13/2022 10:32:39 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=657
06/13/2022 10:32:41 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/13/2022 10:32:43 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=662
06/13/2022 10:32:45 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.7905011655011656 on epoch=662
06/13/2022 10:32:47 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/13/2022 10:32:49 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=667
06/13/2022 10:32:52 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=669
06/13/2022 10:32:54 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/13/2022 10:32:57 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/13/2022 10:32:58 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.7938176406926407 on epoch=674
06/13/2022 10:33:00 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/13/2022 10:33:03 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/13/2022 10:33:05 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/13/2022 10:33:08 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=684
06/13/2022 10:33:10 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/13/2022 10:33:11 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.8282258064516129 on epoch=687
06/13/2022 10:33:13 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/13/2022 10:33:16 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/13/2022 10:33:18 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=694
06/13/2022 10:33:21 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/13/2022 10:33:23 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/13/2022 10:33:24 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.7971774193548387 on epoch=699
06/13/2022 10:33:27 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/13/2022 10:33:29 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/13/2022 10:33:31 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=707
06/13/2022 10:33:34 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/13/2022 10:33:36 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/13/2022 10:33:37 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.7971774193548387 on epoch=712
06/13/2022 10:33:40 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/13/2022 10:33:42 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/13/2022 10:33:45 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/13/2022 10:33:47 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/13/2022 10:33:49 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/13/2022 10:33:50 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.7942760942760942 on epoch=724
06/13/2022 10:33:53 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/13/2022 10:33:55 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=729
06/13/2022 10:33:58 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=732
06/13/2022 10:34:00 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=734
06/13/2022 10:34:02 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/13/2022 10:34:03 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.7912346028154851 on epoch=737
06/13/2022 10:34:06 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/13/2022 10:34:08 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.12 on epoch=742
06/13/2022 10:34:11 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.03 on epoch=744
06/13/2022 10:34:13 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/13/2022 10:34:15 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/13/2022 10:34:17 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.7786637931034482 on epoch=749
06/13/2022 10:34:17 - INFO - __main__ - save last model!
06/13/2022 10:34:17 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/13/2022 10:34:17 - INFO - __main__ - Start tokenizing ... 5509 instances
06/13/2022 10:34:17 - INFO - __main__ - Printing 3 examples
06/13/2022 10:34:17 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/13/2022 10:34:17 - INFO - __main__ - ['others']
06/13/2022 10:34:17 - INFO - __main__ -  [emo] what you like very little things ok
06/13/2022 10:34:17 - INFO - __main__ - ['others']
06/13/2022 10:34:17 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/13/2022 10:34:17 - INFO - __main__ - ['others']
06/13/2022 10:34:17 - INFO - __main__ - Tokenizing Input ...
06/13/2022 10:34:17 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 10:34:17 - INFO - __main__ - Printing 3 examples
06/13/2022 10:34:17 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/13/2022 10:34:17 - INFO - __main__ - ['happy']
06/13/2022 10:34:17 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/13/2022 10:34:17 - INFO - __main__ - ['happy']
06/13/2022 10:34:17 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/13/2022 10:34:17 - INFO - __main__ - ['happy']
06/13/2022 10:34:17 - INFO - __main__ - Tokenizing Input ...
06/13/2022 10:34:17 - INFO - __main__ - Tokenizing Output ...
06/13/2022 10:34:17 - INFO - __main__ - Loaded 64 examples from train data
06/13/2022 10:34:17 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 10:34:17 - INFO - __main__ - Printing 3 examples
06/13/2022 10:34:17 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
06/13/2022 10:34:17 - INFO - __main__ - ['happy']
06/13/2022 10:34:17 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
06/13/2022 10:34:17 - INFO - __main__ - ['happy']
06/13/2022 10:34:17 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
06/13/2022 10:34:17 - INFO - __main__ - ['happy']
06/13/2022 10:34:17 - INFO - __main__ - Tokenizing Input ...
06/13/2022 10:34:17 - INFO - __main__ - Tokenizing Output ...
06/13/2022 10:34:17 - INFO - __main__ - Loaded 64 examples from dev data
06/13/2022 10:34:19 - INFO - __main__ - Tokenizing Output ...
06/13/2022 10:34:24 - INFO - __main__ - Loaded 5509 examples from test data
06/13/2022 10:34:35 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 10:34:36 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 10:34:36 - INFO - __main__ - Starting training!
06/13/2022 10:35:55 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-up32shot/singletask-emo/emo_16_42_0.5_8_predictions.txt
06/13/2022 10:35:55 - INFO - __main__ - Classification-F1 on test data: 0.3103
06/13/2022 10:35:55 - INFO - __main__ - prefix=emo_16_42, lr=0.5, bsz=8, dev_performance=0.8447916666666667, test_performance=0.3103025694706843
06/13/2022 10:35:55 - INFO - __main__ - Running ... prefix=emo_16_42, lr=0.4, bsz=8 ...
06/13/2022 10:35:56 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 10:35:56 - INFO - __main__ - Printing 3 examples
06/13/2022 10:35:56 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/13/2022 10:35:56 - INFO - __main__ - ['happy']
06/13/2022 10:35:56 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/13/2022 10:35:56 - INFO - __main__ - ['happy']
06/13/2022 10:35:56 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/13/2022 10:35:56 - INFO - __main__ - ['happy']
06/13/2022 10:35:56 - INFO - __main__ - Tokenizing Input ...
06/13/2022 10:35:56 - INFO - __main__ - Tokenizing Output ...
06/13/2022 10:35:56 - INFO - __main__ - Loaded 64 examples from train data
06/13/2022 10:35:56 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 10:35:56 - INFO - __main__ - Printing 3 examples
06/13/2022 10:35:56 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
06/13/2022 10:35:56 - INFO - __main__ - ['happy']
06/13/2022 10:35:56 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
06/13/2022 10:35:56 - INFO - __main__ - ['happy']
06/13/2022 10:35:56 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
06/13/2022 10:35:56 - INFO - __main__ - ['happy']
06/13/2022 10:35:56 - INFO - __main__ - Tokenizing Input ...
06/13/2022 10:35:56 - INFO - __main__ - Tokenizing Output ...
06/13/2022 10:35:56 - INFO - __main__ - Loaded 64 examples from dev data
06/13/2022 10:36:15 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 10:36:16 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 10:36:16 - INFO - __main__ - Starting training!
06/13/2022 10:36:19 - INFO - __main__ - Step 10 Global step 10 Train loss 3.48 on epoch=2
06/13/2022 10:36:21 - INFO - __main__ - Step 20 Global step 20 Train loss 2.78 on epoch=4
06/13/2022 10:36:24 - INFO - __main__ - Step 30 Global step 30 Train loss 2.02 on epoch=7
06/13/2022 10:36:26 - INFO - __main__ - Step 40 Global step 40 Train loss 1.58 on epoch=9
06/13/2022 10:36:29 - INFO - __main__ - Step 50 Global step 50 Train loss 1.30 on epoch=12
06/13/2022 10:36:30 - INFO - __main__ - Global step 50 Train loss 2.23 Classification-F1 0.4762254901960785 on epoch=12
06/13/2022 10:36:30 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.4762254901960785 on epoch=12, global_step=50
06/13/2022 10:36:32 - INFO - __main__ - Step 60 Global step 60 Train loss 1.11 on epoch=14
06/13/2022 10:36:35 - INFO - __main__ - Step 70 Global step 70 Train loss 0.89 on epoch=17
06/13/2022 10:36:37 - INFO - __main__ - Step 80 Global step 80 Train loss 0.76 on epoch=19
06/13/2022 10:36:40 - INFO - __main__ - Step 90 Global step 90 Train loss 0.77 on epoch=22
06/13/2022 10:36:42 - INFO - __main__ - Step 100 Global step 100 Train loss 0.86 on epoch=24
06/13/2022 10:36:43 - INFO - __main__ - Global step 100 Train loss 0.88 Classification-F1 0.4108692948638229 on epoch=24
06/13/2022 10:36:45 - INFO - __main__ - Step 110 Global step 110 Train loss 0.77 on epoch=27
06/13/2022 10:36:48 - INFO - __main__ - Step 120 Global step 120 Train loss 0.74 on epoch=29
06/13/2022 10:36:50 - INFO - __main__ - Step 130 Global step 130 Train loss 0.65 on epoch=32
06/13/2022 10:36:52 - INFO - __main__ - Step 140 Global step 140 Train loss 0.74 on epoch=34
06/13/2022 10:36:55 - INFO - __main__ - Step 150 Global step 150 Train loss 0.54 on epoch=37
06/13/2022 10:36:56 - INFO - __main__ - Global step 150 Train loss 0.69 Classification-F1 0.4343567024700453 on epoch=37
06/13/2022 10:36:58 - INFO - __main__ - Step 160 Global step 160 Train loss 0.63 on epoch=39
06/13/2022 10:37:00 - INFO - __main__ - Step 170 Global step 170 Train loss 0.60 on epoch=42
06/13/2022 10:37:03 - INFO - __main__ - Step 180 Global step 180 Train loss 0.70 on epoch=44
06/13/2022 10:37:05 - INFO - __main__ - Step 190 Global step 190 Train loss 0.55 on epoch=47
06/13/2022 10:37:07 - INFO - __main__ - Step 200 Global step 200 Train loss 0.50 on epoch=49
06/13/2022 10:37:08 - INFO - __main__ - Global step 200 Train loss 0.60 Classification-F1 0.5998879551820728 on epoch=49
06/13/2022 10:37:08 - INFO - __main__ - Saving model with best Classification-F1: 0.4762254901960785 -> 0.5998879551820728 on epoch=49, global_step=200
06/13/2022 10:37:11 - INFO - __main__ - Step 210 Global step 210 Train loss 0.55 on epoch=52
06/13/2022 10:37:13 - INFO - __main__ - Step 220 Global step 220 Train loss 0.48 on epoch=54
06/13/2022 10:37:16 - INFO - __main__ - Step 230 Global step 230 Train loss 0.52 on epoch=57
06/13/2022 10:37:18 - INFO - __main__ - Step 240 Global step 240 Train loss 0.54 on epoch=59
06/13/2022 10:37:21 - INFO - __main__ - Step 250 Global step 250 Train loss 0.43 on epoch=62
06/13/2022 10:37:21 - INFO - __main__ - Global step 250 Train loss 0.50 Classification-F1 0.5931143366437484 on epoch=62
06/13/2022 10:37:24 - INFO - __main__ - Step 260 Global step 260 Train loss 0.51 on epoch=64
06/13/2022 10:37:26 - INFO - __main__ - Step 270 Global step 270 Train loss 0.48 on epoch=67
06/13/2022 10:37:29 - INFO - __main__ - Step 280 Global step 280 Train loss 0.34 on epoch=69
06/13/2022 10:37:31 - INFO - __main__ - Step 290 Global step 290 Train loss 0.42 on epoch=72
06/13/2022 10:37:34 - INFO - __main__ - Step 300 Global step 300 Train loss 0.39 on epoch=74
06/13/2022 10:37:34 - INFO - __main__ - Global step 300 Train loss 0.43 Classification-F1 0.618100539811066 on epoch=74
06/13/2022 10:37:34 - INFO - __main__ - Saving model with best Classification-F1: 0.5998879551820728 -> 0.618100539811066 on epoch=74, global_step=300
06/13/2022 10:37:37 - INFO - __main__ - Step 310 Global step 310 Train loss 0.46 on epoch=77
06/13/2022 10:37:39 - INFO - __main__ - Step 320 Global step 320 Train loss 0.39 on epoch=79
06/13/2022 10:37:42 - INFO - __main__ - Step 330 Global step 330 Train loss 0.40 on epoch=82
06/13/2022 10:37:44 - INFO - __main__ - Step 340 Global step 340 Train loss 0.41 on epoch=84
06/13/2022 10:37:47 - INFO - __main__ - Step 350 Global step 350 Train loss 0.36 on epoch=87
06/13/2022 10:37:47 - INFO - __main__ - Global step 350 Train loss 0.40 Classification-F1 0.5786600496277916 on epoch=87
06/13/2022 10:37:50 - INFO - __main__ - Step 360 Global step 360 Train loss 0.32 on epoch=89
06/13/2022 10:37:52 - INFO - __main__ - Step 370 Global step 370 Train loss 0.25 on epoch=92
06/13/2022 10:37:55 - INFO - __main__ - Step 380 Global step 380 Train loss 0.31 on epoch=94
06/13/2022 10:37:57 - INFO - __main__ - Step 390 Global step 390 Train loss 0.31 on epoch=97
06/13/2022 10:38:00 - INFO - __main__ - Step 400 Global step 400 Train loss 0.34 on epoch=99
06/13/2022 10:38:01 - INFO - __main__ - Global step 400 Train loss 0.31 Classification-F1 0.6172562920950018 on epoch=99
06/13/2022 10:38:03 - INFO - __main__ - Step 410 Global step 410 Train loss 0.34 on epoch=102
06/13/2022 10:38:05 - INFO - __main__ - Step 420 Global step 420 Train loss 0.27 on epoch=104
06/13/2022 10:38:08 - INFO - __main__ - Step 430 Global step 430 Train loss 0.20 on epoch=107
06/13/2022 10:38:10 - INFO - __main__ - Step 440 Global step 440 Train loss 0.37 on epoch=109
06/13/2022 10:38:13 - INFO - __main__ - Step 450 Global step 450 Train loss 0.30 on epoch=112
06/13/2022 10:38:13 - INFO - __main__ - Global step 450 Train loss 0.30 Classification-F1 0.6031984549730554 on epoch=112
06/13/2022 10:38:16 - INFO - __main__ - Step 460 Global step 460 Train loss 0.28 on epoch=114
06/13/2022 10:38:18 - INFO - __main__ - Step 470 Global step 470 Train loss 0.29 on epoch=117
06/13/2022 10:38:21 - INFO - __main__ - Step 480 Global step 480 Train loss 0.24 on epoch=119
06/13/2022 10:38:23 - INFO - __main__ - Step 490 Global step 490 Train loss 0.22 on epoch=122
06/13/2022 10:38:26 - INFO - __main__ - Step 500 Global step 500 Train loss 0.23 on epoch=124
06/13/2022 10:38:26 - INFO - __main__ - Global step 500 Train loss 0.25 Classification-F1 0.6295035290101703 on epoch=124
06/13/2022 10:38:26 - INFO - __main__ - Saving model with best Classification-F1: 0.618100539811066 -> 0.6295035290101703 on epoch=124, global_step=500
06/13/2022 10:38:29 - INFO - __main__ - Step 510 Global step 510 Train loss 0.18 on epoch=127
06/13/2022 10:38:31 - INFO - __main__ - Step 520 Global step 520 Train loss 0.20 on epoch=129
06/13/2022 10:38:34 - INFO - __main__ - Step 530 Global step 530 Train loss 0.17 on epoch=132
06/13/2022 10:38:36 - INFO - __main__ - Step 540 Global step 540 Train loss 0.20 on epoch=134
06/13/2022 10:38:39 - INFO - __main__ - Step 550 Global step 550 Train loss 0.15 on epoch=137
06/13/2022 10:38:39 - INFO - __main__ - Global step 550 Train loss 0.18 Classification-F1 0.7589869281045751 on epoch=137
06/13/2022 10:38:39 - INFO - __main__ - Saving model with best Classification-F1: 0.6295035290101703 -> 0.7589869281045751 on epoch=137, global_step=550
06/13/2022 10:38:42 - INFO - __main__ - Step 560 Global step 560 Train loss 0.20 on epoch=139
06/13/2022 10:38:44 - INFO - __main__ - Step 570 Global step 570 Train loss 0.18 on epoch=142
06/13/2022 10:38:47 - INFO - __main__ - Step 580 Global step 580 Train loss 0.14 on epoch=144
06/13/2022 10:38:49 - INFO - __main__ - Step 590 Global step 590 Train loss 0.20 on epoch=147
06/13/2022 10:38:51 - INFO - __main__ - Step 600 Global step 600 Train loss 0.11 on epoch=149
06/13/2022 10:38:52 - INFO - __main__ - Global step 600 Train loss 0.17 Classification-F1 0.8413660413660414 on epoch=149
06/13/2022 10:38:52 - INFO - __main__ - Saving model with best Classification-F1: 0.7589869281045751 -> 0.8413660413660414 on epoch=149, global_step=600
06/13/2022 10:38:55 - INFO - __main__ - Step 610 Global step 610 Train loss 0.16 on epoch=152
06/13/2022 10:38:57 - INFO - __main__ - Step 620 Global step 620 Train loss 0.14 on epoch=154
06/13/2022 10:39:00 - INFO - __main__ - Step 630 Global step 630 Train loss 0.19 on epoch=157
06/13/2022 10:39:02 - INFO - __main__ - Step 640 Global step 640 Train loss 0.12 on epoch=159
06/13/2022 10:39:04 - INFO - __main__ - Step 650 Global step 650 Train loss 0.12 on epoch=162
06/13/2022 10:39:05 - INFO - __main__ - Global step 650 Train loss 0.15 Classification-F1 0.8146569865319866 on epoch=162
06/13/2022 10:39:08 - INFO - __main__ - Step 660 Global step 660 Train loss 0.12 on epoch=164
06/13/2022 10:39:10 - INFO - __main__ - Step 670 Global step 670 Train loss 0.09 on epoch=167
06/13/2022 10:39:13 - INFO - __main__ - Step 680 Global step 680 Train loss 0.10 on epoch=169
06/13/2022 10:39:15 - INFO - __main__ - Step 690 Global step 690 Train loss 0.08 on epoch=172
06/13/2022 10:39:17 - INFO - __main__ - Step 700 Global step 700 Train loss 0.16 on epoch=174
06/13/2022 10:39:18 - INFO - __main__ - Global step 700 Train loss 0.11 Classification-F1 0.8407756205930649 on epoch=174
06/13/2022 10:39:21 - INFO - __main__ - Step 710 Global step 710 Train loss 0.09 on epoch=177
06/13/2022 10:39:23 - INFO - __main__ - Step 720 Global step 720 Train loss 0.12 on epoch=179
06/13/2022 10:39:25 - INFO - __main__ - Step 730 Global step 730 Train loss 0.04 on epoch=182
06/13/2022 10:39:28 - INFO - __main__ - Step 740 Global step 740 Train loss 0.11 on epoch=184
06/13/2022 10:39:30 - INFO - __main__ - Step 750 Global step 750 Train loss 0.13 on epoch=187
06/13/2022 10:39:31 - INFO - __main__ - Global step 750 Train loss 0.10 Classification-F1 0.8167664087967692 on epoch=187
06/13/2022 10:39:33 - INFO - __main__ - Step 760 Global step 760 Train loss 0.07 on epoch=189
06/13/2022 10:39:36 - INFO - __main__ - Step 770 Global step 770 Train loss 0.08 on epoch=192
06/13/2022 10:39:38 - INFO - __main__ - Step 780 Global step 780 Train loss 0.08 on epoch=194
06/13/2022 10:39:41 - INFO - __main__ - Step 790 Global step 790 Train loss 0.12 on epoch=197
06/13/2022 10:39:43 - INFO - __main__ - Step 800 Global step 800 Train loss 0.09 on epoch=199
06/13/2022 10:39:44 - INFO - __main__ - Global step 800 Train loss 0.09 Classification-F1 0.8209722222222222 on epoch=199
06/13/2022 10:39:46 - INFO - __main__ - Step 810 Global step 810 Train loss 0.16 on epoch=202
06/13/2022 10:39:49 - INFO - __main__ - Step 820 Global step 820 Train loss 0.06 on epoch=204
06/13/2022 10:39:51 - INFO - __main__ - Step 830 Global step 830 Train loss 0.05 on epoch=207
06/13/2022 10:39:54 - INFO - __main__ - Step 840 Global step 840 Train loss 0.10 on epoch=209
06/13/2022 10:39:56 - INFO - __main__ - Step 850 Global step 850 Train loss 0.08 on epoch=212
06/13/2022 10:39:57 - INFO - __main__ - Global step 850 Train loss 0.09 Classification-F1 0.835654761904762 on epoch=212
06/13/2022 10:39:59 - INFO - __main__ - Step 860 Global step 860 Train loss 0.12 on epoch=214
06/13/2022 10:40:02 - INFO - __main__ - Step 870 Global step 870 Train loss 0.08 on epoch=217
06/13/2022 10:40:04 - INFO - __main__ - Step 880 Global step 880 Train loss 0.06 on epoch=219
06/13/2022 10:40:07 - INFO - __main__ - Step 890 Global step 890 Train loss 0.06 on epoch=222
06/13/2022 10:40:09 - INFO - __main__ - Step 900 Global step 900 Train loss 0.05 on epoch=224
06/13/2022 10:40:10 - INFO - __main__ - Global step 900 Train loss 0.07 Classification-F1 0.834978354978355 on epoch=224
06/13/2022 10:40:12 - INFO - __main__ - Step 910 Global step 910 Train loss 0.11 on epoch=227
06/13/2022 10:40:15 - INFO - __main__ - Step 920 Global step 920 Train loss 0.10 on epoch=229
06/13/2022 10:40:17 - INFO - __main__ - Step 930 Global step 930 Train loss 0.05 on epoch=232
06/13/2022 10:40:20 - INFO - __main__ - Step 940 Global step 940 Train loss 0.15 on epoch=234
06/13/2022 10:40:22 - INFO - __main__ - Step 950 Global step 950 Train loss 0.05 on epoch=237
06/13/2022 10:40:23 - INFO - __main__ - Global step 950 Train loss 0.09 Classification-F1 0.8130310684711408 on epoch=237
06/13/2022 10:40:25 - INFO - __main__ - Step 960 Global step 960 Train loss 0.04 on epoch=239
06/13/2022 10:40:28 - INFO - __main__ - Step 970 Global step 970 Train loss 0.04 on epoch=242
06/13/2022 10:40:30 - INFO - __main__ - Step 980 Global step 980 Train loss 0.09 on epoch=244
06/13/2022 10:40:33 - INFO - __main__ - Step 990 Global step 990 Train loss 0.03 on epoch=247
06/13/2022 10:40:35 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.16 on epoch=249
06/13/2022 10:40:36 - INFO - __main__ - Global step 1000 Train loss 0.07 Classification-F1 0.8049765646539839 on epoch=249
06/13/2022 10:40:38 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.03 on epoch=252
06/13/2022 10:40:41 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.04 on epoch=254
06/13/2022 10:40:43 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.04 on epoch=257
06/13/2022 10:40:46 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.08 on epoch=259
06/13/2022 10:40:48 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.04 on epoch=262
06/13/2022 10:40:49 - INFO - __main__ - Global step 1050 Train loss 0.05 Classification-F1 0.8060452804285821 on epoch=262
06/13/2022 10:40:51 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.03 on epoch=264
06/13/2022 10:40:54 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.07 on epoch=267
06/13/2022 10:40:56 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.08 on epoch=269
06/13/2022 10:40:58 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.03 on epoch=272
06/13/2022 10:41:01 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.02 on epoch=274
06/13/2022 10:41:02 - INFO - __main__ - Global step 1100 Train loss 0.05 Classification-F1 0.8196591043365237 on epoch=274
06/13/2022 10:41:04 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.04 on epoch=277
06/13/2022 10:41:07 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.04 on epoch=279
06/13/2022 10:41:09 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.04 on epoch=282
06/13/2022 10:41:11 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.02 on epoch=284
06/13/2022 10:41:14 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.02 on epoch=287
06/13/2022 10:41:15 - INFO - __main__ - Global step 1150 Train loss 0.03 Classification-F1 0.7806020733652312 on epoch=287
06/13/2022 10:41:17 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.03 on epoch=289
06/13/2022 10:41:20 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.11 on epoch=292
06/13/2022 10:41:22 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.03 on epoch=294
06/13/2022 10:41:24 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.02 on epoch=297
06/13/2022 10:41:27 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.07 on epoch=299
06/13/2022 10:41:28 - INFO - __main__ - Global step 1200 Train loss 0.05 Classification-F1 0.8052656546489564 on epoch=299
06/13/2022 10:41:30 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.03 on epoch=302
06/13/2022 10:41:32 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=304
06/13/2022 10:41:35 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.03 on epoch=307
06/13/2022 10:41:37 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=309
06/13/2022 10:41:40 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.03 on epoch=312
06/13/2022 10:41:40 - INFO - __main__ - Global step 1250 Train loss 0.02 Classification-F1 0.7911680008454203 on epoch=312
06/13/2022 10:41:43 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.07 on epoch=314
06/13/2022 10:41:45 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.05 on epoch=317
06/13/2022 10:41:48 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.04 on epoch=319
06/13/2022 10:41:50 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.02 on epoch=322
06/13/2022 10:41:53 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.02 on epoch=324
06/13/2022 10:41:54 - INFO - __main__ - Global step 1300 Train loss 0.04 Classification-F1 0.7864159379968204 on epoch=324
06/13/2022 10:41:56 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.02 on epoch=327
06/13/2022 10:41:58 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.08 on epoch=329
06/13/2022 10:42:01 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.02 on epoch=332
06/13/2022 10:42:03 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.03 on epoch=334
06/13/2022 10:42:06 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.05 on epoch=337
06/13/2022 10:42:06 - INFO - __main__ - Global step 1350 Train loss 0.04 Classification-F1 0.7732009925558312 on epoch=337
06/13/2022 10:42:09 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=339
06/13/2022 10:42:11 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.03 on epoch=342
06/13/2022 10:42:14 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.02 on epoch=344
06/13/2022 10:42:16 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=347
06/13/2022 10:42:18 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.03 on epoch=349
06/13/2022 10:42:19 - INFO - __main__ - Global step 1400 Train loss 0.02 Classification-F1 0.8435972629521017 on epoch=349
06/13/2022 10:42:19 - INFO - __main__ - Saving model with best Classification-F1: 0.8413660413660414 -> 0.8435972629521017 on epoch=349, global_step=1400
06/13/2022 10:42:22 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=352
06/13/2022 10:42:24 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=354
06/13/2022 10:42:27 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.05 on epoch=357
06/13/2022 10:42:29 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=359
06/13/2022 10:42:32 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.03 on epoch=362
06/13/2022 10:42:32 - INFO - __main__ - Global step 1450 Train loss 0.02 Classification-F1 0.7861354331942568 on epoch=362
06/13/2022 10:42:35 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=364
06/13/2022 10:42:37 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=367
06/13/2022 10:42:40 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=369
06/13/2022 10:42:42 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=372
06/13/2022 10:42:44 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.03 on epoch=374
06/13/2022 10:42:45 - INFO - __main__ - Global step 1500 Train loss 0.01 Classification-F1 0.8061126373626373 on epoch=374
06/13/2022 10:42:48 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.03 on epoch=377
06/13/2022 10:42:50 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.02 on epoch=379
06/13/2022 10:42:53 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=382
06/13/2022 10:42:55 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=384
06/13/2022 10:42:57 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.07 on epoch=387
06/13/2022 10:42:58 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.8243897306397306 on epoch=387
06/13/2022 10:43:01 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=389
06/13/2022 10:43:03 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.03 on epoch=392
06/13/2022 10:43:06 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.02 on epoch=394
06/13/2022 10:43:08 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=397
06/13/2022 10:43:10 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=399
06/13/2022 10:43:11 - INFO - __main__ - Global step 1600 Train loss 0.02 Classification-F1 0.8275828361479085 on epoch=399
06/13/2022 10:43:14 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=402
06/13/2022 10:43:16 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=404
06/13/2022 10:43:18 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=407
06/13/2022 10:43:21 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=409
06/13/2022 10:43:23 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=412
06/13/2022 10:43:24 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.806650837900838 on epoch=412
06/13/2022 10:43:27 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=414
06/13/2022 10:43:29 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=417
06/13/2022 10:43:32 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.03 on epoch=419
06/13/2022 10:43:34 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.03 on epoch=422
06/13/2022 10:43:36 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=424
06/13/2022 10:43:37 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.8102602331255083 on epoch=424
06/13/2022 10:43:40 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.03 on epoch=427
06/13/2022 10:43:42 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=429
06/13/2022 10:43:45 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=432
06/13/2022 10:43:47 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=434
06/13/2022 10:43:50 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=437
06/13/2022 10:43:51 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.8203828828828829 on epoch=437
06/13/2022 10:43:53 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.05 on epoch=439
06/13/2022 10:43:55 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.05 on epoch=442
06/13/2022 10:43:58 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=444
06/13/2022 10:44:00 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=447
06/13/2022 10:44:03 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=449
06/13/2022 10:44:03 - INFO - __main__ - Global step 1800 Train loss 0.02 Classification-F1 0.7912990196078431 on epoch=449
06/13/2022 10:44:06 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=452
06/13/2022 10:44:08 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=454
06/13/2022 10:44:11 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=457
06/13/2022 10:44:13 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.06 on epoch=459
06/13/2022 10:44:15 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=462
06/13/2022 10:44:16 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.805620401810979 on epoch=462
06/13/2022 10:44:19 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.05 on epoch=464
06/13/2022 10:44:21 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=467
06/13/2022 10:44:24 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=469
06/13/2022 10:44:26 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=472
06/13/2022 10:44:28 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=474
06/13/2022 10:44:29 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.8238477209065445 on epoch=474
06/13/2022 10:44:32 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=477
06/13/2022 10:44:34 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=479
06/13/2022 10:44:37 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=482
06/13/2022 10:44:39 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=484
06/13/2022 10:44:41 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=487
06/13/2022 10:44:42 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.8203828828828829 on epoch=487
06/13/2022 10:44:45 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=489
06/13/2022 10:44:47 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=492
06/13/2022 10:44:49 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=494
06/13/2022 10:44:52 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.04 on epoch=497
06/13/2022 10:44:54 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=499
06/13/2022 10:44:55 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.7818965517241379 on epoch=499
06/13/2022 10:44:58 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=502
06/13/2022 10:45:00 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.04 on epoch=504
06/13/2022 10:45:03 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=507
06/13/2022 10:45:05 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.10 on epoch=509
06/13/2022 10:45:07 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.13 on epoch=512
06/13/2022 10:45:08 - INFO - __main__ - Global step 2050 Train loss 0.06 Classification-F1 0.7644153225806452 on epoch=512
06/13/2022 10:45:11 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.03 on epoch=514
06/13/2022 10:45:13 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=517
06/13/2022 10:45:16 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/13/2022 10:45:18 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=522
06/13/2022 10:45:20 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=524
06/13/2022 10:45:21 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.8564612135176651 on epoch=524
06/13/2022 10:45:21 - INFO - __main__ - Saving model with best Classification-F1: 0.8435972629521017 -> 0.8564612135176651 on epoch=524, global_step=2100
06/13/2022 10:45:24 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=527
06/13/2022 10:45:26 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=529
06/13/2022 10:45:29 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=532
06/13/2022 10:45:31 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=534
06/13/2022 10:45:33 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
06/13/2022 10:45:34 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.8090535334368352 on epoch=537
06/13/2022 10:45:37 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=539
06/13/2022 10:45:39 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/13/2022 10:45:42 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/13/2022 10:45:44 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/13/2022 10:45:46 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/13/2022 10:45:47 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.8414746543778802 on epoch=549
06/13/2022 10:45:50 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=552
06/13/2022 10:45:52 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=554
06/13/2022 10:45:55 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=557
06/13/2022 10:45:57 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/13/2022 10:46:00 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=562
06/13/2022 10:46:00 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.8259856630824373 on epoch=562
06/13/2022 10:46:03 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/13/2022 10:46:05 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/13/2022 10:46:08 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/13/2022 10:46:10 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=572
06/13/2022 10:46:12 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=574
06/13/2022 10:46:13 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.8053579212853407 on epoch=574
06/13/2022 10:46:16 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/13/2022 10:46:18 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/13/2022 10:46:21 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/13/2022 10:46:23 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.05 on epoch=584
06/13/2022 10:46:26 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=587
06/13/2022 10:46:27 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.8585445468509983 on epoch=587
06/13/2022 10:46:27 - INFO - __main__ - Saving model with best Classification-F1: 0.8564612135176651 -> 0.8585445468509983 on epoch=587, global_step=2350
06/13/2022 10:46:29 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/13/2022 10:46:32 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=592
06/13/2022 10:46:34 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=594
06/13/2022 10:46:36 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.09 on epoch=597
06/13/2022 10:46:39 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/13/2022 10:46:40 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.8198330295104489 on epoch=599
06/13/2022 10:46:42 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/13/2022 10:46:45 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/13/2022 10:46:47 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=607
06/13/2022 10:46:49 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=609
06/13/2022 10:46:52 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=612
06/13/2022 10:46:53 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.7755199101973296 on epoch=612
06/13/2022 10:46:55 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=614
06/13/2022 10:46:58 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=617
06/13/2022 10:47:00 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/13/2022 10:47:02 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=622
06/13/2022 10:47:05 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/13/2022 10:47:06 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.8084981388652134 on epoch=624
06/13/2022 10:47:08 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/13/2022 10:47:11 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/13/2022 10:47:13 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/13/2022 10:47:16 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/13/2022 10:47:18 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=637
06/13/2022 10:47:19 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.8564612135176651 on epoch=637
06/13/2022 10:47:21 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.04 on epoch=639
06/13/2022 10:47:24 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/13/2022 10:47:26 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/13/2022 10:47:29 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/13/2022 10:47:31 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.04 on epoch=649
06/13/2022 10:47:32 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.8049765646539839 on epoch=649
06/13/2022 10:47:34 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/13/2022 10:47:37 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/13/2022 10:47:39 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=657
06/13/2022 10:47:42 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/13/2022 10:47:44 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=662
06/13/2022 10:47:45 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.8198330295104489 on epoch=662
06/13/2022 10:47:47 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/13/2022 10:47:50 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/13/2022 10:47:52 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/13/2022 10:47:55 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/13/2022 10:47:57 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/13/2022 10:47:58 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.8424676066500316 on epoch=674
06/13/2022 10:48:00 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/13/2022 10:48:03 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=679
06/13/2022 10:48:05 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/13/2022 10:48:08 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/13/2022 10:48:10 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=687
06/13/2022 10:48:11 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.8582437275985663 on epoch=687
06/13/2022 10:48:14 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/13/2022 10:48:16 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=692
06/13/2022 10:48:18 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/13/2022 10:48:21 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=697
06/13/2022 10:48:23 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/13/2022 10:48:24 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.8418492323615664 on epoch=699
06/13/2022 10:48:27 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=702
06/13/2022 10:48:29 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/13/2022 10:48:31 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/13/2022 10:48:34 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/13/2022 10:48:36 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/13/2022 10:48:37 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.8418492323615664 on epoch=712
06/13/2022 10:48:40 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/13/2022 10:48:42 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/13/2022 10:48:45 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=719
06/13/2022 10:48:47 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/13/2022 10:48:49 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/13/2022 10:48:50 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.8586930740037951 on epoch=724
06/13/2022 10:48:50 - INFO - __main__ - Saving model with best Classification-F1: 0.8585445468509983 -> 0.8586930740037951 on epoch=724, global_step=2900
06/13/2022 10:48:53 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/13/2022 10:48:55 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=729
06/13/2022 10:48:58 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/13/2022 10:49:00 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/13/2022 10:49:02 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=737
06/13/2022 10:49:03 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.8238095238095239 on epoch=737
06/13/2022 10:49:06 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=739
06/13/2022 10:49:08 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=742
06/13/2022 10:49:11 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/13/2022 10:49:13 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/13/2022 10:49:15 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/13/2022 10:49:17 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.8271433500086252 on epoch=749
06/13/2022 10:49:17 - INFO - __main__ - save last model!
06/13/2022 10:49:17 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/13/2022 10:49:17 - INFO - __main__ - Start tokenizing ... 5509 instances
06/13/2022 10:49:17 - INFO - __main__ - Printing 3 examples
06/13/2022 10:49:17 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/13/2022 10:49:17 - INFO - __main__ - ['others']
06/13/2022 10:49:17 - INFO - __main__ -  [emo] what you like very little things ok
06/13/2022 10:49:17 - INFO - __main__ - ['others']
06/13/2022 10:49:17 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/13/2022 10:49:17 - INFO - __main__ - ['others']
06/13/2022 10:49:17 - INFO - __main__ - Tokenizing Input ...
06/13/2022 10:49:17 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 10:49:17 - INFO - __main__ - Printing 3 examples
06/13/2022 10:49:17 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/13/2022 10:49:17 - INFO - __main__ - ['happy']
06/13/2022 10:49:17 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/13/2022 10:49:17 - INFO - __main__ - ['happy']
06/13/2022 10:49:17 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/13/2022 10:49:17 - INFO - __main__ - ['happy']
06/13/2022 10:49:17 - INFO - __main__ - Tokenizing Input ...
06/13/2022 10:49:17 - INFO - __main__ - Tokenizing Output ...
06/13/2022 10:49:17 - INFO - __main__ - Loaded 64 examples from train data
06/13/2022 10:49:17 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 10:49:17 - INFO - __main__ - Printing 3 examples
06/13/2022 10:49:17 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
06/13/2022 10:49:17 - INFO - __main__ - ['happy']
06/13/2022 10:49:17 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
06/13/2022 10:49:17 - INFO - __main__ - ['happy']
06/13/2022 10:49:17 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
06/13/2022 10:49:17 - INFO - __main__ - ['happy']
06/13/2022 10:49:17 - INFO - __main__ - Tokenizing Input ...
06/13/2022 10:49:17 - INFO - __main__ - Tokenizing Output ...
06/13/2022 10:49:17 - INFO - __main__ - Loaded 64 examples from dev data
06/13/2022 10:49:19 - INFO - __main__ - Tokenizing Output ...
06/13/2022 10:49:24 - INFO - __main__ - Loaded 5509 examples from test data
06/13/2022 10:49:36 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 10:49:37 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 10:49:37 - INFO - __main__ - Starting training!
06/13/2022 10:50:57 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-up32shot/singletask-emo/emo_16_42_0.4_8_predictions.txt
06/13/2022 10:50:57 - INFO - __main__ - Classification-F1 on test data: 0.3676
06/13/2022 10:50:57 - INFO - __main__ - prefix=emo_16_42, lr=0.4, bsz=8, dev_performance=0.8586930740037951, test_performance=0.36760683985298803
06/13/2022 10:50:57 - INFO - __main__ - Running ... prefix=emo_16_42, lr=0.3, bsz=8 ...
06/13/2022 10:50:58 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 10:50:58 - INFO - __main__ - Printing 3 examples
06/13/2022 10:50:58 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/13/2022 10:50:58 - INFO - __main__ - ['happy']
06/13/2022 10:50:58 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/13/2022 10:50:58 - INFO - __main__ - ['happy']
06/13/2022 10:50:58 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/13/2022 10:50:58 - INFO - __main__ - ['happy']
06/13/2022 10:50:58 - INFO - __main__ - Tokenizing Input ...
06/13/2022 10:50:58 - INFO - __main__ - Tokenizing Output ...
06/13/2022 10:50:59 - INFO - __main__ - Loaded 64 examples from train data
06/13/2022 10:50:59 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 10:50:59 - INFO - __main__ - Printing 3 examples
06/13/2022 10:50:59 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
06/13/2022 10:50:59 - INFO - __main__ - ['happy']
06/13/2022 10:50:59 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
06/13/2022 10:50:59 - INFO - __main__ - ['happy']
06/13/2022 10:50:59 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
06/13/2022 10:50:59 - INFO - __main__ - ['happy']
06/13/2022 10:50:59 - INFO - __main__ - Tokenizing Input ...
06/13/2022 10:50:59 - INFO - __main__ - Tokenizing Output ...
06/13/2022 10:50:59 - INFO - __main__ - Loaded 64 examples from dev data
06/13/2022 10:51:17 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 10:51:18 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 10:51:18 - INFO - __main__ - Starting training!
06/13/2022 10:51:21 - INFO - __main__ - Step 10 Global step 10 Train loss 4.23 on epoch=2
06/13/2022 10:51:24 - INFO - __main__ - Step 20 Global step 20 Train loss 3.02 on epoch=4
06/13/2022 10:51:26 - INFO - __main__ - Step 30 Global step 30 Train loss 2.50 on epoch=7
06/13/2022 10:51:28 - INFO - __main__ - Step 40 Global step 40 Train loss 2.24 on epoch=9
06/13/2022 10:51:31 - INFO - __main__ - Step 50 Global step 50 Train loss 1.76 on epoch=12
06/13/2022 10:51:32 - INFO - __main__ - Global step 50 Train loss 2.75 Classification-F1 0.15301606753812635 on epoch=12
06/13/2022 10:51:32 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.15301606753812635 on epoch=12, global_step=50
06/13/2022 10:51:34 - INFO - __main__ - Step 60 Global step 60 Train loss 1.39 on epoch=14
06/13/2022 10:51:37 - INFO - __main__ - Step 70 Global step 70 Train loss 1.31 on epoch=17
06/13/2022 10:51:39 - INFO - __main__ - Step 80 Global step 80 Train loss 1.12 on epoch=19
06/13/2022 10:51:41 - INFO - __main__ - Step 90 Global step 90 Train loss 0.99 on epoch=22
06/13/2022 10:51:44 - INFO - __main__ - Step 100 Global step 100 Train loss 0.92 on epoch=24
06/13/2022 10:51:45 - INFO - __main__ - Global step 100 Train loss 1.15 Classification-F1 0.4649659182036888 on epoch=24
06/13/2022 10:51:45 - INFO - __main__ - Saving model with best Classification-F1: 0.15301606753812635 -> 0.4649659182036888 on epoch=24, global_step=100
06/13/2022 10:51:47 - INFO - __main__ - Step 110 Global step 110 Train loss 0.75 on epoch=27
06/13/2022 10:51:50 - INFO - __main__ - Step 120 Global step 120 Train loss 0.74 on epoch=29
06/13/2022 10:51:52 - INFO - __main__ - Step 130 Global step 130 Train loss 0.83 on epoch=32
06/13/2022 10:51:54 - INFO - __main__ - Step 140 Global step 140 Train loss 0.72 on epoch=34
06/13/2022 10:51:57 - INFO - __main__ - Step 150 Global step 150 Train loss 0.72 on epoch=37
06/13/2022 10:51:58 - INFO - __main__ - Global step 150 Train loss 0.75 Classification-F1 0.4787115339440921 on epoch=37
06/13/2022 10:51:58 - INFO - __main__ - Saving model with best Classification-F1: 0.4649659182036888 -> 0.4787115339440921 on epoch=37, global_step=150
06/13/2022 10:52:00 - INFO - __main__ - Step 160 Global step 160 Train loss 0.74 on epoch=39
06/13/2022 10:52:02 - INFO - __main__ - Step 170 Global step 170 Train loss 0.65 on epoch=42
06/13/2022 10:52:05 - INFO - __main__ - Step 180 Global step 180 Train loss 0.70 on epoch=44
06/13/2022 10:52:07 - INFO - __main__ - Step 190 Global step 190 Train loss 0.53 on epoch=47
06/13/2022 10:52:10 - INFO - __main__ - Step 200 Global step 200 Train loss 0.65 on epoch=49
06/13/2022 10:52:10 - INFO - __main__ - Global step 200 Train loss 0.65 Classification-F1 0.4245098039215686 on epoch=49
06/13/2022 10:52:13 - INFO - __main__ - Step 210 Global step 210 Train loss 0.55 on epoch=52
06/13/2022 10:52:15 - INFO - __main__ - Step 220 Global step 220 Train loss 0.62 on epoch=54
06/13/2022 10:52:18 - INFO - __main__ - Step 230 Global step 230 Train loss 0.63 on epoch=57
06/13/2022 10:52:20 - INFO - __main__ - Step 240 Global step 240 Train loss 0.57 on epoch=59
06/13/2022 10:52:22 - INFO - __main__ - Step 250 Global step 250 Train loss 0.56 on epoch=62
06/13/2022 10:52:23 - INFO - __main__ - Global step 250 Train loss 0.59 Classification-F1 0.49406926406926405 on epoch=62
06/13/2022 10:52:23 - INFO - __main__ - Saving model with best Classification-F1: 0.4787115339440921 -> 0.49406926406926405 on epoch=62, global_step=250
06/13/2022 10:52:26 - INFO - __main__ - Step 260 Global step 260 Train loss 0.55 on epoch=64
06/13/2022 10:52:28 - INFO - __main__ - Step 270 Global step 270 Train loss 0.57 on epoch=67
06/13/2022 10:52:30 - INFO - __main__ - Step 280 Global step 280 Train loss 0.61 on epoch=69
06/13/2022 10:52:33 - INFO - __main__ - Step 290 Global step 290 Train loss 0.53 on epoch=72
06/13/2022 10:52:35 - INFO - __main__ - Step 300 Global step 300 Train loss 0.49 on epoch=74
06/13/2022 10:52:36 - INFO - __main__ - Global step 300 Train loss 0.55 Classification-F1 0.5699727211683734 on epoch=74
06/13/2022 10:52:36 - INFO - __main__ - Saving model with best Classification-F1: 0.49406926406926405 -> 0.5699727211683734 on epoch=74, global_step=300
06/13/2022 10:52:39 - INFO - __main__ - Step 310 Global step 310 Train loss 0.55 on epoch=77
06/13/2022 10:52:41 - INFO - __main__ - Step 320 Global step 320 Train loss 0.40 on epoch=79
06/13/2022 10:52:43 - INFO - __main__ - Step 330 Global step 330 Train loss 0.51 on epoch=82
06/13/2022 10:52:46 - INFO - __main__ - Step 340 Global step 340 Train loss 0.47 on epoch=84
06/13/2022 10:52:48 - INFO - __main__ - Step 350 Global step 350 Train loss 0.38 on epoch=87
06/13/2022 10:52:49 - INFO - __main__ - Global step 350 Train loss 0.46 Classification-F1 0.6010388225037182 on epoch=87
06/13/2022 10:52:49 - INFO - __main__ - Saving model with best Classification-F1: 0.5699727211683734 -> 0.6010388225037182 on epoch=87, global_step=350
06/13/2022 10:52:52 - INFO - __main__ - Step 360 Global step 360 Train loss 0.45 on epoch=89
06/13/2022 10:52:54 - INFO - __main__ - Step 370 Global step 370 Train loss 0.35 on epoch=92
06/13/2022 10:52:56 - INFO - __main__ - Step 380 Global step 380 Train loss 0.44 on epoch=94
06/13/2022 10:52:59 - INFO - __main__ - Step 390 Global step 390 Train loss 0.41 on epoch=97
06/13/2022 10:53:01 - INFO - __main__ - Step 400 Global step 400 Train loss 0.49 on epoch=99
06/13/2022 10:53:02 - INFO - __main__ - Global step 400 Train loss 0.43 Classification-F1 0.5902745098039215 on epoch=99
06/13/2022 10:53:04 - INFO - __main__ - Step 410 Global step 410 Train loss 0.44 on epoch=102
06/13/2022 10:53:07 - INFO - __main__ - Step 420 Global step 420 Train loss 0.35 on epoch=104
06/13/2022 10:53:09 - INFO - __main__ - Step 430 Global step 430 Train loss 0.40 on epoch=107
06/13/2022 10:53:12 - INFO - __main__ - Step 440 Global step 440 Train loss 0.34 on epoch=109
06/13/2022 10:53:14 - INFO - __main__ - Step 450 Global step 450 Train loss 0.42 on epoch=112
06/13/2022 10:53:15 - INFO - __main__ - Global step 450 Train loss 0.39 Classification-F1 0.6027522281639929 on epoch=112
06/13/2022 10:53:15 - INFO - __main__ - Saving model with best Classification-F1: 0.6010388225037182 -> 0.6027522281639929 on epoch=112, global_step=450
06/13/2022 10:53:17 - INFO - __main__ - Step 460 Global step 460 Train loss 0.26 on epoch=114
06/13/2022 10:53:20 - INFO - __main__ - Step 470 Global step 470 Train loss 0.31 on epoch=117
06/13/2022 10:53:22 - INFO - __main__ - Step 480 Global step 480 Train loss 0.30 on epoch=119
06/13/2022 10:53:25 - INFO - __main__ - Step 490 Global step 490 Train loss 0.40 on epoch=122
06/13/2022 10:53:27 - INFO - __main__ - Step 500 Global step 500 Train loss 0.32 on epoch=124
06/13/2022 10:53:28 - INFO - __main__ - Global step 500 Train loss 0.32 Classification-F1 0.6219815668202765 on epoch=124
06/13/2022 10:53:28 - INFO - __main__ - Saving model with best Classification-F1: 0.6027522281639929 -> 0.6219815668202765 on epoch=124, global_step=500
06/13/2022 10:53:30 - INFO - __main__ - Step 510 Global step 510 Train loss 0.34 on epoch=127
06/13/2022 10:53:33 - INFO - __main__ - Step 520 Global step 520 Train loss 0.25 on epoch=129
06/13/2022 10:53:35 - INFO - __main__ - Step 530 Global step 530 Train loss 0.33 on epoch=132
06/13/2022 10:53:37 - INFO - __main__ - Step 540 Global step 540 Train loss 0.29 on epoch=134
06/13/2022 10:53:40 - INFO - __main__ - Step 550 Global step 550 Train loss 0.28 on epoch=137
06/13/2022 10:53:41 - INFO - __main__ - Global step 550 Train loss 0.30 Classification-F1 0.6169244970715559 on epoch=137
06/13/2022 10:53:43 - INFO - __main__ - Step 560 Global step 560 Train loss 0.23 on epoch=139
06/13/2022 10:53:46 - INFO - __main__ - Step 570 Global step 570 Train loss 0.29 on epoch=142
06/13/2022 10:53:48 - INFO - __main__ - Step 580 Global step 580 Train loss 0.27 on epoch=144
06/13/2022 10:53:50 - INFO - __main__ - Step 590 Global step 590 Train loss 0.26 on epoch=147
06/13/2022 10:53:53 - INFO - __main__ - Step 600 Global step 600 Train loss 0.25 on epoch=149
06/13/2022 10:53:54 - INFO - __main__ - Global step 600 Train loss 0.26 Classification-F1 0.6152095747389865 on epoch=149
06/13/2022 10:53:56 - INFO - __main__ - Step 610 Global step 610 Train loss 0.29 on epoch=152
06/13/2022 10:53:58 - INFO - __main__ - Step 620 Global step 620 Train loss 0.29 on epoch=154
06/13/2022 10:54:01 - INFO - __main__ - Step 630 Global step 630 Train loss 0.23 on epoch=157
06/13/2022 10:54:03 - INFO - __main__ - Step 640 Global step 640 Train loss 0.20 on epoch=159
06/13/2022 10:54:06 - INFO - __main__ - Step 650 Global step 650 Train loss 0.23 on epoch=162
06/13/2022 10:54:06 - INFO - __main__ - Global step 650 Train loss 0.25 Classification-F1 0.627548321048321 on epoch=162
06/13/2022 10:54:06 - INFO - __main__ - Saving model with best Classification-F1: 0.6219815668202765 -> 0.627548321048321 on epoch=162, global_step=650
06/13/2022 10:54:09 - INFO - __main__ - Step 660 Global step 660 Train loss 0.24 on epoch=164
06/13/2022 10:54:11 - INFO - __main__ - Step 670 Global step 670 Train loss 0.14 on epoch=167
06/13/2022 10:54:14 - INFO - __main__ - Step 680 Global step 680 Train loss 0.22 on epoch=169
06/13/2022 10:54:16 - INFO - __main__ - Step 690 Global step 690 Train loss 0.18 on epoch=172
06/13/2022 10:54:18 - INFO - __main__ - Step 700 Global step 700 Train loss 0.26 on epoch=174
06/13/2022 10:54:19 - INFO - __main__ - Global step 700 Train loss 0.21 Classification-F1 0.8101097178683386 on epoch=174
06/13/2022 10:54:19 - INFO - __main__ - Saving model with best Classification-F1: 0.627548321048321 -> 0.8101097178683386 on epoch=174, global_step=700
06/13/2022 10:54:22 - INFO - __main__ - Step 710 Global step 710 Train loss 0.28 on epoch=177
06/13/2022 10:54:24 - INFO - __main__ - Step 720 Global step 720 Train loss 0.23 on epoch=179
06/13/2022 10:54:26 - INFO - __main__ - Step 730 Global step 730 Train loss 0.18 on epoch=182
06/13/2022 10:54:29 - INFO - __main__ - Step 740 Global step 740 Train loss 0.15 on epoch=184
06/13/2022 10:54:31 - INFO - __main__ - Step 750 Global step 750 Train loss 0.19 on epoch=187
06/13/2022 10:54:32 - INFO - __main__ - Global step 750 Train loss 0.21 Classification-F1 0.8260241596638656 on epoch=187
06/13/2022 10:54:32 - INFO - __main__ - Saving model with best Classification-F1: 0.8101097178683386 -> 0.8260241596638656 on epoch=187, global_step=750
06/13/2022 10:54:35 - INFO - __main__ - Step 760 Global step 760 Train loss 0.26 on epoch=189
06/13/2022 10:54:37 - INFO - __main__ - Step 770 Global step 770 Train loss 0.25 on epoch=192
06/13/2022 10:54:40 - INFO - __main__ - Step 780 Global step 780 Train loss 0.15 on epoch=194
06/13/2022 10:54:42 - INFO - __main__ - Step 790 Global step 790 Train loss 0.14 on epoch=197
06/13/2022 10:54:44 - INFO - __main__ - Step 800 Global step 800 Train loss 0.17 on epoch=199
06/13/2022 10:54:45 - INFO - __main__ - Global step 800 Train loss 0.19 Classification-F1 0.8107837374761818 on epoch=199
06/13/2022 10:54:48 - INFO - __main__ - Step 810 Global step 810 Train loss 0.12 on epoch=202
06/13/2022 10:54:50 - INFO - __main__ - Step 820 Global step 820 Train loss 0.14 on epoch=204
06/13/2022 10:54:52 - INFO - __main__ - Step 830 Global step 830 Train loss 0.13 on epoch=207
06/13/2022 10:54:55 - INFO - __main__ - Step 840 Global step 840 Train loss 0.13 on epoch=209
06/13/2022 10:54:57 - INFO - __main__ - Step 850 Global step 850 Train loss 0.12 on epoch=212
06/13/2022 10:54:58 - INFO - __main__ - Global step 850 Train loss 0.13 Classification-F1 0.8231841347650171 on epoch=212
06/13/2022 10:55:00 - INFO - __main__ - Step 860 Global step 860 Train loss 0.11 on epoch=214
06/13/2022 10:55:03 - INFO - __main__ - Step 870 Global step 870 Train loss 0.11 on epoch=217
06/13/2022 10:55:05 - INFO - __main__ - Step 880 Global step 880 Train loss 0.15 on epoch=219
06/13/2022 10:55:08 - INFO - __main__ - Step 890 Global step 890 Train loss 0.08 on epoch=222
06/13/2022 10:55:10 - INFO - __main__ - Step 900 Global step 900 Train loss 0.14 on epoch=224
06/13/2022 10:55:11 - INFO - __main__ - Global step 900 Train loss 0.12 Classification-F1 0.8110906862745099 on epoch=224
06/13/2022 10:55:13 - INFO - __main__ - Step 910 Global step 910 Train loss 0.13 on epoch=227
06/13/2022 10:55:16 - INFO - __main__ - Step 920 Global step 920 Train loss 0.12 on epoch=229
06/13/2022 10:55:18 - INFO - __main__ - Step 930 Global step 930 Train loss 0.11 on epoch=232
06/13/2022 10:55:21 - INFO - __main__ - Step 940 Global step 940 Train loss 0.08 on epoch=234
06/13/2022 10:55:23 - INFO - __main__ - Step 950 Global step 950 Train loss 0.05 on epoch=237
06/13/2022 10:55:24 - INFO - __main__ - Global step 950 Train loss 0.10 Classification-F1 0.7713445378151261 on epoch=237
06/13/2022 10:55:26 - INFO - __main__ - Step 960 Global step 960 Train loss 0.08 on epoch=239
06/13/2022 10:55:29 - INFO - __main__ - Step 970 Global step 970 Train loss 0.10 on epoch=242
06/13/2022 10:55:31 - INFO - __main__ - Step 980 Global step 980 Train loss 0.13 on epoch=244
06/13/2022 10:55:34 - INFO - __main__ - Step 990 Global step 990 Train loss 0.06 on epoch=247
06/13/2022 10:55:36 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.10 on epoch=249
06/13/2022 10:55:37 - INFO - __main__ - Global step 1000 Train loss 0.09 Classification-F1 0.8237133237133237 on epoch=249
06/13/2022 10:55:39 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.11 on epoch=252
06/13/2022 10:55:42 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.07 on epoch=254
06/13/2022 10:55:44 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.08 on epoch=257
06/13/2022 10:55:46 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.12 on epoch=259
06/13/2022 10:55:49 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.06 on epoch=262
06/13/2022 10:55:50 - INFO - __main__ - Global step 1050 Train loss 0.09 Classification-F1 0.7602493227493228 on epoch=262
06/13/2022 10:55:52 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.06 on epoch=264
06/13/2022 10:55:54 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.03 on epoch=267
06/13/2022 10:55:57 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.03 on epoch=269
06/13/2022 10:55:59 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.05 on epoch=272
06/13/2022 10:56:02 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.05 on epoch=274
06/13/2022 10:56:02 - INFO - __main__ - Global step 1100 Train loss 0.04 Classification-F1 0.8007002801120447 on epoch=274
06/13/2022 10:56:05 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.09 on epoch=277
06/13/2022 10:56:07 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.06 on epoch=279
06/13/2022 10:56:10 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.07 on epoch=282
06/13/2022 10:56:12 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.15 on epoch=284
06/13/2022 10:56:14 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.09 on epoch=287
06/13/2022 10:56:15 - INFO - __main__ - Global step 1150 Train loss 0.09 Classification-F1 0.7582223109957056 on epoch=287
06/13/2022 10:56:18 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.03 on epoch=289
06/13/2022 10:56:20 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.03 on epoch=292
06/13/2022 10:56:23 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.08 on epoch=294
06/13/2022 10:56:25 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.09 on epoch=297
06/13/2022 10:56:27 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.07 on epoch=299
06/13/2022 10:56:28 - INFO - __main__ - Global step 1200 Train loss 0.06 Classification-F1 0.7858585858585858 on epoch=299
06/13/2022 10:56:31 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.07 on epoch=302
06/13/2022 10:56:33 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.07 on epoch=304
06/13/2022 10:56:36 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.05 on epoch=307
06/13/2022 10:56:38 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.04 on epoch=309
06/13/2022 10:56:40 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.06 on epoch=312
06/13/2022 10:56:41 - INFO - __main__ - Global step 1250 Train loss 0.06 Classification-F1 0.8268822223246667 on epoch=312
06/13/2022 10:56:41 - INFO - __main__ - Saving model with best Classification-F1: 0.8260241596638656 -> 0.8268822223246667 on epoch=312, global_step=1250
06/13/2022 10:56:44 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.06 on epoch=314
06/13/2022 10:56:46 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.04 on epoch=317
06/13/2022 10:56:49 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.09 on epoch=319
06/13/2022 10:56:51 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.12 on epoch=322
06/13/2022 10:56:53 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.04 on epoch=324
06/13/2022 10:56:54 - INFO - __main__ - Global step 1300 Train loss 0.07 Classification-F1 0.7714040861099685 on epoch=324
06/13/2022 10:56:57 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.03 on epoch=327
06/13/2022 10:56:59 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.05 on epoch=329
06/13/2022 10:57:01 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.07 on epoch=332
06/13/2022 10:57:04 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.06 on epoch=334
06/13/2022 10:57:06 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.03 on epoch=337
06/13/2022 10:57:07 - INFO - __main__ - Global step 1350 Train loss 0.05 Classification-F1 0.8115771615771616 on epoch=337
06/13/2022 10:57:10 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.05 on epoch=339
06/13/2022 10:57:12 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=342
06/13/2022 10:57:14 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.04 on epoch=344
06/13/2022 10:57:17 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.12 on epoch=347
06/13/2022 10:57:19 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.09 on epoch=349
06/13/2022 10:57:20 - INFO - __main__ - Global step 1400 Train loss 0.06 Classification-F1 0.8275921658986175 on epoch=349
06/13/2022 10:57:20 - INFO - __main__ - Saving model with best Classification-F1: 0.8268822223246667 -> 0.8275921658986175 on epoch=349, global_step=1400
06/13/2022 10:57:23 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.05 on epoch=352
06/13/2022 10:57:25 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.04 on epoch=354
06/13/2022 10:57:27 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.05 on epoch=357
06/13/2022 10:57:30 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.04 on epoch=359
06/13/2022 10:57:32 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.03 on epoch=362
06/13/2022 10:57:33 - INFO - __main__ - Global step 1450 Train loss 0.04 Classification-F1 0.8125000000000001 on epoch=362
06/13/2022 10:57:35 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.10 on epoch=364
06/13/2022 10:57:38 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.08 on epoch=367
06/13/2022 10:57:40 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.04 on epoch=369
06/13/2022 10:57:43 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.04 on epoch=372
06/13/2022 10:57:45 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.04 on epoch=374
06/13/2022 10:57:46 - INFO - __main__ - Global step 1500 Train loss 0.06 Classification-F1 0.825935252627697 on epoch=374
06/13/2022 10:57:48 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.03 on epoch=377
06/13/2022 10:57:51 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.05 on epoch=379
06/13/2022 10:57:53 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.04 on epoch=382
06/13/2022 10:57:56 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.09 on epoch=384
06/13/2022 10:57:58 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.03 on epoch=387
06/13/2022 10:57:59 - INFO - __main__ - Global step 1550 Train loss 0.05 Classification-F1 0.7858927224736049 on epoch=387
06/13/2022 10:58:01 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.03 on epoch=389
06/13/2022 10:58:04 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.03 on epoch=392
06/13/2022 10:58:06 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.02 on epoch=394
06/13/2022 10:58:08 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=397
06/13/2022 10:58:11 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.05 on epoch=399
06/13/2022 10:58:12 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.7862474696356275 on epoch=399
06/13/2022 10:58:14 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=402
06/13/2022 10:58:16 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.05 on epoch=404
06/13/2022 10:58:19 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=407
06/13/2022 10:58:21 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.02 on epoch=409
06/13/2022 10:58:24 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=412
06/13/2022 10:58:25 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.8423297219633427 on epoch=412
06/13/2022 10:58:25 - INFO - __main__ - Saving model with best Classification-F1: 0.8275921658986175 -> 0.8423297219633427 on epoch=412, global_step=1650
06/13/2022 10:58:27 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.04 on epoch=414
06/13/2022 10:58:30 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=417
06/13/2022 10:58:32 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.09 on epoch=419
06/13/2022 10:58:34 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.02 on epoch=422
06/13/2022 10:58:37 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.04 on epoch=424
06/13/2022 10:58:38 - INFO - __main__ - Global step 1700 Train loss 0.04 Classification-F1 0.7857349327937564 on epoch=424
06/13/2022 10:58:40 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.07 on epoch=427
06/13/2022 10:58:42 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.02 on epoch=429
06/13/2022 10:58:45 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=432
06/13/2022 10:58:47 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=434
06/13/2022 10:58:50 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=437
06/13/2022 10:58:51 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.7858927224736049 on epoch=437
06/13/2022 10:58:53 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=439
06/13/2022 10:58:55 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.03 on epoch=442
06/13/2022 10:58:58 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.04 on epoch=444
06/13/2022 10:59:00 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.07 on epoch=447
06/13/2022 10:59:03 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=449
06/13/2022 10:59:04 - INFO - __main__ - Global step 1800 Train loss 0.04 Classification-F1 0.8009049773755657 on epoch=449
06/13/2022 10:59:06 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=452
06/13/2022 10:59:08 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.05 on epoch=454
06/13/2022 10:59:11 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=457
06/13/2022 10:59:13 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=459
06/13/2022 10:59:16 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=462
06/13/2022 10:59:17 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.7747172182656055 on epoch=462
06/13/2022 10:59:19 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.05 on epoch=464
06/13/2022 10:59:21 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=467
06/13/2022 10:59:24 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.04 on epoch=469
06/13/2022 10:59:26 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=472
06/13/2022 10:59:29 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.02 on epoch=474
06/13/2022 10:59:29 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.7714583333333334 on epoch=474
06/13/2022 10:59:32 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.05 on epoch=477
06/13/2022 10:59:34 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=479
06/13/2022 10:59:37 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=482
06/13/2022 10:59:39 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=484
06/13/2022 10:59:42 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.04 on epoch=487
06/13/2022 10:59:42 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.7612554112554113 on epoch=487
06/13/2022 10:59:45 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.13 on epoch=489
06/13/2022 10:59:47 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=492
06/13/2022 10:59:50 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.05 on epoch=494
06/13/2022 10:59:52 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=497
06/13/2022 10:59:55 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=499
06/13/2022 10:59:55 - INFO - __main__ - Global step 2000 Train loss 0.04 Classification-F1 0.7935451154877969 on epoch=499
06/13/2022 10:59:58 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=502
06/13/2022 11:00:00 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=504
06/13/2022 11:00:03 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=507
06/13/2022 11:00:05 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=509
06/13/2022 11:00:07 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=512
06/13/2022 11:00:08 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.7903799019607842 on epoch=512
06/13/2022 11:00:11 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.02 on epoch=514
06/13/2022 11:00:13 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=517
06/13/2022 11:00:16 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=519
06/13/2022 11:00:18 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.03 on epoch=522
06/13/2022 11:00:20 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.04 on epoch=524
06/13/2022 11:00:21 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.7954229199010983 on epoch=524
06/13/2022 11:00:24 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.08 on epoch=527
06/13/2022 11:00:26 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=529
06/13/2022 11:00:28 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=532
06/13/2022 11:00:31 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=534
06/13/2022 11:00:33 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.03 on epoch=537
06/13/2022 11:00:34 - INFO - __main__ - Global step 2150 Train loss 0.03 Classification-F1 0.793154761904762 on epoch=537
06/13/2022 11:00:37 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.15 on epoch=539
06/13/2022 11:00:39 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.05 on epoch=542
06/13/2022 11:00:41 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/13/2022 11:00:44 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=547
06/13/2022 11:00:46 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=549
06/13/2022 11:00:47 - INFO - __main__ - Global step 2200 Train loss 0.05 Classification-F1 0.8203463203463204 on epoch=549
06/13/2022 11:00:50 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=552
06/13/2022 11:00:52 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=554
06/13/2022 11:00:54 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=557
06/13/2022 11:00:57 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=559
06/13/2022 11:00:59 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/13/2022 11:01:00 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.7858936355710548 on epoch=562
06/13/2022 11:01:03 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/13/2022 11:01:05 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=567
06/13/2022 11:01:08 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=569
06/13/2022 11:01:10 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.03 on epoch=572
06/13/2022 11:01:12 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=574
06/13/2022 11:01:13 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.7766708834071263 on epoch=574
06/13/2022 11:01:16 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=577
06/13/2022 11:01:18 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=579
06/13/2022 11:01:21 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=582
06/13/2022 11:01:23 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=584
06/13/2022 11:01:25 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=587
06/13/2022 11:01:26 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.8199314982403217 on epoch=587
06/13/2022 11:01:29 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=589
06/13/2022 11:01:31 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=592
06/13/2022 11:01:34 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/13/2022 11:01:36 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=597
06/13/2022 11:01:38 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=599
06/13/2022 11:01:39 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.8203828828828829 on epoch=599
06/13/2022 11:01:42 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.05 on epoch=602
06/13/2022 11:01:44 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.06 on epoch=604
06/13/2022 11:01:47 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/13/2022 11:01:49 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/13/2022 11:01:51 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.03 on epoch=612
06/13/2022 11:01:52 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.8144899809453563 on epoch=612
06/13/2022 11:01:55 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=614
06/13/2022 11:01:57 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=617
06/13/2022 11:02:00 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=619
06/13/2022 11:02:02 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/13/2022 11:02:04 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=624
06/13/2022 11:02:05 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.8110906862745099 on epoch=624
06/13/2022 11:02:08 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=627
06/13/2022 11:02:10 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=629
06/13/2022 11:02:13 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=632
06/13/2022 11:02:15 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=634
06/13/2022 11:02:18 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=637
06/13/2022 11:02:18 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.78193447111286 on epoch=637
06/13/2022 11:02:21 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.04 on epoch=639
06/13/2022 11:02:23 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=642
06/13/2022 11:02:26 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/13/2022 11:02:28 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=647
06/13/2022 11:02:31 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=649
06/13/2022 11:02:31 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.7925743611227483 on epoch=649
06/13/2022 11:02:34 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=652
06/13/2022 11:02:36 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/13/2022 11:02:39 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=657
06/13/2022 11:02:41 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.05 on epoch=659
06/13/2022 11:02:44 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.04 on epoch=662
06/13/2022 11:02:45 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.8597402597402597 on epoch=662
06/13/2022 11:02:45 - INFO - __main__ - Saving model with best Classification-F1: 0.8423297219633427 -> 0.8597402597402597 on epoch=662, global_step=2650
06/13/2022 11:02:47 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=664
06/13/2022 11:02:49 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.03 on epoch=667
06/13/2022 11:02:52 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.03 on epoch=669
06/13/2022 11:02:54 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=672
06/13/2022 11:02:57 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=674
06/13/2022 11:02:58 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.7955492424242425 on epoch=674
06/13/2022 11:03:00 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/13/2022 11:03:02 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/13/2022 11:03:05 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=682
06/13/2022 11:03:07 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/13/2022 11:03:10 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/13/2022 11:03:11 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.8254896198291228 on epoch=687
06/13/2022 11:03:13 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=689
06/13/2022 11:03:15 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/13/2022 11:03:18 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/13/2022 11:03:20 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=697
06/13/2022 11:03:23 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/13/2022 11:03:24 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.8389014014014013 on epoch=699
06/13/2022 11:03:26 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=702
06/13/2022 11:03:29 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.04 on epoch=704
06/13/2022 11:03:31 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/13/2022 11:03:33 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=709
06/13/2022 11:03:36 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=712
06/13/2022 11:03:37 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.8014069264069265 on epoch=712
06/13/2022 11:03:39 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=714
06/13/2022 11:03:42 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=717
06/13/2022 11:03:44 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.07 on epoch=719
06/13/2022 11:03:47 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/13/2022 11:03:49 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/13/2022 11:03:50 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.8104166666666667 on epoch=724
06/13/2022 11:03:52 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/13/2022 11:03:55 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=729
06/13/2022 11:03:57 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/13/2022 11:04:00 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.03 on epoch=734
06/13/2022 11:04:02 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/13/2022 11:04:03 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.8414408866995075 on epoch=737
06/13/2022 11:04:05 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/13/2022 11:04:08 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/13/2022 11:04:10 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/13/2022 11:04:13 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=747
06/13/2022 11:04:15 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/13/2022 11:04:16 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.8237133237133237 on epoch=749
06/13/2022 11:04:16 - INFO - __main__ - save last model!
06/13/2022 11:04:16 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/13/2022 11:04:16 - INFO - __main__ - Start tokenizing ... 5509 instances
06/13/2022 11:04:16 - INFO - __main__ - Printing 3 examples
06/13/2022 11:04:16 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/13/2022 11:04:16 - INFO - __main__ - ['others']
06/13/2022 11:04:16 - INFO - __main__ -  [emo] what you like very little things ok
06/13/2022 11:04:16 - INFO - __main__ - ['others']
06/13/2022 11:04:16 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/13/2022 11:04:16 - INFO - __main__ - ['others']
06/13/2022 11:04:16 - INFO - __main__ - Tokenizing Input ...
06/13/2022 11:04:16 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 11:04:16 - INFO - __main__ - Printing 3 examples
06/13/2022 11:04:16 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/13/2022 11:04:16 - INFO - __main__ - ['happy']
06/13/2022 11:04:16 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/13/2022 11:04:16 - INFO - __main__ - ['happy']
06/13/2022 11:04:16 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/13/2022 11:04:16 - INFO - __main__ - ['happy']
06/13/2022 11:04:16 - INFO - __main__ - Tokenizing Input ...
06/13/2022 11:04:16 - INFO - __main__ - Tokenizing Output ...
06/13/2022 11:04:16 - INFO - __main__ - Loaded 64 examples from train data
06/13/2022 11:04:16 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 11:04:16 - INFO - __main__ - Printing 3 examples
06/13/2022 11:04:16 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
06/13/2022 11:04:16 - INFO - __main__ - ['happy']
06/13/2022 11:04:16 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
06/13/2022 11:04:16 - INFO - __main__ - ['happy']
06/13/2022 11:04:16 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
06/13/2022 11:04:16 - INFO - __main__ - ['happy']
06/13/2022 11:04:16 - INFO - __main__ - Tokenizing Input ...
06/13/2022 11:04:16 - INFO - __main__ - Tokenizing Output ...
06/13/2022 11:04:17 - INFO - __main__ - Loaded 64 examples from dev data
06/13/2022 11:04:18 - INFO - __main__ - Tokenizing Output ...
06/13/2022 11:04:24 - INFO - __main__ - Loaded 5509 examples from test data
06/13/2022 11:04:35 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 11:04:36 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 11:04:36 - INFO - __main__ - Starting training!
06/13/2022 11:05:49 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-up32shot/singletask-emo/emo_16_42_0.3_8_predictions.txt
06/13/2022 11:05:49 - INFO - __main__ - Classification-F1 on test data: 0.2220
06/13/2022 11:05:50 - INFO - __main__ - prefix=emo_16_42, lr=0.3, bsz=8, dev_performance=0.8597402597402597, test_performance=0.22197216489459798
06/13/2022 11:05:50 - INFO - __main__ - Running ... prefix=emo_16_42, lr=0.2, bsz=8 ...
06/13/2022 11:05:51 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 11:05:51 - INFO - __main__ - Printing 3 examples
06/13/2022 11:05:51 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/13/2022 11:05:51 - INFO - __main__ - ['happy']
06/13/2022 11:05:51 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/13/2022 11:05:51 - INFO - __main__ - ['happy']
06/13/2022 11:05:51 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/13/2022 11:05:51 - INFO - __main__ - ['happy']
06/13/2022 11:05:51 - INFO - __main__ - Tokenizing Input ...
06/13/2022 11:05:51 - INFO - __main__ - Tokenizing Output ...
06/13/2022 11:05:51 - INFO - __main__ - Loaded 64 examples from train data
06/13/2022 11:05:51 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 11:05:51 - INFO - __main__ - Printing 3 examples
06/13/2022 11:05:51 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
06/13/2022 11:05:51 - INFO - __main__ - ['happy']
06/13/2022 11:05:51 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
06/13/2022 11:05:51 - INFO - __main__ - ['happy']
06/13/2022 11:05:51 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
06/13/2022 11:05:51 - INFO - __main__ - ['happy']
06/13/2022 11:05:51 - INFO - __main__ - Tokenizing Input ...
06/13/2022 11:05:51 - INFO - __main__ - Tokenizing Output ...
06/13/2022 11:05:51 - INFO - __main__ - Loaded 64 examples from dev data
06/13/2022 11:06:09 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 11:06:10 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 11:06:10 - INFO - __main__ - Starting training!
06/13/2022 11:06:14 - INFO - __main__ - Step 10 Global step 10 Train loss 4.20 on epoch=2
06/13/2022 11:06:16 - INFO - __main__ - Step 20 Global step 20 Train loss 3.58 on epoch=4
06/13/2022 11:06:19 - INFO - __main__ - Step 30 Global step 30 Train loss 2.78 on epoch=7
06/13/2022 11:06:21 - INFO - __main__ - Step 40 Global step 40 Train loss 2.52 on epoch=9
06/13/2022 11:06:24 - INFO - __main__ - Step 50 Global step 50 Train loss 2.24 on epoch=12
06/13/2022 11:06:24 - INFO - __main__ - Global step 50 Train loss 3.06 Classification-F1 0.06694154741692944 on epoch=12
06/13/2022 11:06:24 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.06694154741692944 on epoch=12, global_step=50
06/13/2022 11:06:27 - INFO - __main__ - Step 60 Global step 60 Train loss 2.03 on epoch=14
06/13/2022 11:06:29 - INFO - __main__ - Step 70 Global step 70 Train loss 1.62 on epoch=17
06/13/2022 11:06:32 - INFO - __main__ - Step 80 Global step 80 Train loss 1.64 on epoch=19
06/13/2022 11:06:34 - INFO - __main__ - Step 90 Global step 90 Train loss 1.32 on epoch=22
06/13/2022 11:06:36 - INFO - __main__ - Step 100 Global step 100 Train loss 1.16 on epoch=24
06/13/2022 11:06:37 - INFO - __main__ - Global step 100 Train loss 1.56 Classification-F1 0.30736461251167135 on epoch=24
06/13/2022 11:06:37 - INFO - __main__ - Saving model with best Classification-F1: 0.06694154741692944 -> 0.30736461251167135 on epoch=24, global_step=100
06/13/2022 11:06:40 - INFO - __main__ - Step 110 Global step 110 Train loss 1.07 on epoch=27
06/13/2022 11:06:42 - INFO - __main__ - Step 120 Global step 120 Train loss 1.28 on epoch=29
06/13/2022 11:06:44 - INFO - __main__ - Step 130 Global step 130 Train loss 0.86 on epoch=32
06/13/2022 11:06:47 - INFO - __main__ - Step 140 Global step 140 Train loss 0.92 on epoch=34
06/13/2022 11:06:49 - INFO - __main__ - Step 150 Global step 150 Train loss 0.77 on epoch=37
06/13/2022 11:06:50 - INFO - __main__ - Global step 150 Train loss 0.98 Classification-F1 0.47840802987861814 on epoch=37
06/13/2022 11:06:50 - INFO - __main__ - Saving model with best Classification-F1: 0.30736461251167135 -> 0.47840802987861814 on epoch=37, global_step=150
06/13/2022 11:06:53 - INFO - __main__ - Step 160 Global step 160 Train loss 0.88 on epoch=39
06/13/2022 11:06:55 - INFO - __main__ - Step 170 Global step 170 Train loss 0.76 on epoch=42
06/13/2022 11:06:57 - INFO - __main__ - Step 180 Global step 180 Train loss 0.73 on epoch=44
06/13/2022 11:07:00 - INFO - __main__ - Step 190 Global step 190 Train loss 0.77 on epoch=47
06/13/2022 11:07:02 - INFO - __main__ - Step 200 Global step 200 Train loss 0.67 on epoch=49
06/13/2022 11:07:03 - INFO - __main__ - Global step 200 Train loss 0.76 Classification-F1 0.3846712317465556 on epoch=49
06/13/2022 11:07:06 - INFO - __main__ - Step 210 Global step 210 Train loss 0.77 on epoch=52
06/13/2022 11:07:08 - INFO - __main__ - Step 220 Global step 220 Train loss 0.65 on epoch=54
06/13/2022 11:07:10 - INFO - __main__ - Step 230 Global step 230 Train loss 0.68 on epoch=57
06/13/2022 11:07:13 - INFO - __main__ - Step 240 Global step 240 Train loss 0.62 on epoch=59
06/13/2022 11:07:15 - INFO - __main__ - Step 250 Global step 250 Train loss 0.65 on epoch=62
06/13/2022 11:07:16 - INFO - __main__ - Global step 250 Train loss 0.68 Classification-F1 0.4707072252512889 on epoch=62
06/13/2022 11:07:19 - INFO - __main__ - Step 260 Global step 260 Train loss 0.67 on epoch=64
06/13/2022 11:07:21 - INFO - __main__ - Step 270 Global step 270 Train loss 0.55 on epoch=67
06/13/2022 11:07:23 - INFO - __main__ - Step 280 Global step 280 Train loss 0.60 on epoch=69
06/13/2022 11:07:26 - INFO - __main__ - Step 290 Global step 290 Train loss 0.61 on epoch=72
06/13/2022 11:07:28 - INFO - __main__ - Step 300 Global step 300 Train loss 0.54 on epoch=74
06/13/2022 11:07:29 - INFO - __main__ - Global step 300 Train loss 0.60 Classification-F1 0.5264069264069263 on epoch=74
06/13/2022 11:07:29 - INFO - __main__ - Saving model with best Classification-F1: 0.47840802987861814 -> 0.5264069264069263 on epoch=74, global_step=300
06/13/2022 11:07:31 - INFO - __main__ - Step 310 Global step 310 Train loss 0.58 on epoch=77
06/13/2022 11:07:34 - INFO - __main__ - Step 320 Global step 320 Train loss 0.61 on epoch=79
06/13/2022 11:07:36 - INFO - __main__ - Step 330 Global step 330 Train loss 0.49 on epoch=82
06/13/2022 11:07:39 - INFO - __main__ - Step 340 Global step 340 Train loss 0.60 on epoch=84
06/13/2022 11:07:41 - INFO - __main__ - Step 350 Global step 350 Train loss 0.52 on epoch=87
06/13/2022 11:07:42 - INFO - __main__ - Global step 350 Train loss 0.56 Classification-F1 0.5141923436041084 on epoch=87
06/13/2022 11:07:44 - INFO - __main__ - Step 360 Global step 360 Train loss 0.67 on epoch=89
06/13/2022 11:07:47 - INFO - __main__ - Step 370 Global step 370 Train loss 0.51 on epoch=92
06/13/2022 11:07:49 - INFO - __main__ - Step 380 Global step 380 Train loss 0.63 on epoch=94
06/13/2022 11:07:51 - INFO - __main__ - Step 390 Global step 390 Train loss 0.49 on epoch=97
06/13/2022 11:07:54 - INFO - __main__ - Step 400 Global step 400 Train loss 0.56 on epoch=99
06/13/2022 11:07:55 - INFO - __main__ - Global step 400 Train loss 0.57 Classification-F1 0.5612222713476964 on epoch=99
06/13/2022 11:07:55 - INFO - __main__ - Saving model with best Classification-F1: 0.5264069264069263 -> 0.5612222713476964 on epoch=99, global_step=400
06/13/2022 11:07:57 - INFO - __main__ - Step 410 Global step 410 Train loss 0.52 on epoch=102
06/13/2022 11:08:00 - INFO - __main__ - Step 420 Global step 420 Train loss 0.58 on epoch=104
06/13/2022 11:08:02 - INFO - __main__ - Step 430 Global step 430 Train loss 0.42 on epoch=107
06/13/2022 11:08:05 - INFO - __main__ - Step 440 Global step 440 Train loss 0.51 on epoch=109
06/13/2022 11:08:07 - INFO - __main__ - Step 450 Global step 450 Train loss 0.51 on epoch=112
06/13/2022 11:08:08 - INFO - __main__ - Global step 450 Train loss 0.51 Classification-F1 0.5726113413881294 on epoch=112
06/13/2022 11:08:08 - INFO - __main__ - Saving model with best Classification-F1: 0.5612222713476964 -> 0.5726113413881294 on epoch=112, global_step=450
06/13/2022 11:08:10 - INFO - __main__ - Step 460 Global step 460 Train loss 0.56 on epoch=114
06/13/2022 11:08:13 - INFO - __main__ - Step 470 Global step 470 Train loss 0.45 on epoch=117
06/13/2022 11:08:15 - INFO - __main__ - Step 480 Global step 480 Train loss 0.49 on epoch=119
06/13/2022 11:08:18 - INFO - __main__ - Step 490 Global step 490 Train loss 0.50 on epoch=122
06/13/2022 11:08:20 - INFO - __main__ - Step 500 Global step 500 Train loss 0.47 on epoch=124
06/13/2022 11:08:21 - INFO - __main__ - Global step 500 Train loss 0.49 Classification-F1 0.5956934046345811 on epoch=124
06/13/2022 11:08:21 - INFO - __main__ - Saving model with best Classification-F1: 0.5726113413881294 -> 0.5956934046345811 on epoch=124, global_step=500
06/13/2022 11:08:24 - INFO - __main__ - Step 510 Global step 510 Train loss 0.52 on epoch=127
06/13/2022 11:08:26 - INFO - __main__ - Step 520 Global step 520 Train loss 0.47 on epoch=129
06/13/2022 11:08:29 - INFO - __main__ - Step 530 Global step 530 Train loss 0.48 on epoch=132
06/13/2022 11:08:31 - INFO - __main__ - Step 540 Global step 540 Train loss 0.41 on epoch=134
06/13/2022 11:08:33 - INFO - __main__ - Step 550 Global step 550 Train loss 0.43 on epoch=137
06/13/2022 11:08:34 - INFO - __main__ - Global step 550 Train loss 0.46 Classification-F1 0.6211080586080586 on epoch=137
06/13/2022 11:08:34 - INFO - __main__ - Saving model with best Classification-F1: 0.5956934046345811 -> 0.6211080586080586 on epoch=137, global_step=550
06/13/2022 11:08:37 - INFO - __main__ - Step 560 Global step 560 Train loss 0.49 on epoch=139
06/13/2022 11:08:39 - INFO - __main__ - Step 570 Global step 570 Train loss 0.38 on epoch=142
06/13/2022 11:08:41 - INFO - __main__ - Step 580 Global step 580 Train loss 0.36 on epoch=144
06/13/2022 11:08:44 - INFO - __main__ - Step 590 Global step 590 Train loss 0.32 on epoch=147
06/13/2022 11:08:46 - INFO - __main__ - Step 600 Global step 600 Train loss 0.47 on epoch=149
06/13/2022 11:08:47 - INFO - __main__ - Global step 600 Train loss 0.40 Classification-F1 0.6211080586080586 on epoch=149
06/13/2022 11:08:50 - INFO - __main__ - Step 610 Global step 610 Train loss 0.38 on epoch=152
06/13/2022 11:08:52 - INFO - __main__ - Step 620 Global step 620 Train loss 0.36 on epoch=154
06/13/2022 11:08:54 - INFO - __main__ - Step 630 Global step 630 Train loss 0.34 on epoch=157
06/13/2022 11:08:57 - INFO - __main__ - Step 640 Global step 640 Train loss 0.34 on epoch=159
06/13/2022 11:08:59 - INFO - __main__ - Step 650 Global step 650 Train loss 0.40 on epoch=162
06/13/2022 11:09:00 - INFO - __main__ - Global step 650 Train loss 0.36 Classification-F1 0.6467357642357643 on epoch=162
06/13/2022 11:09:00 - INFO - __main__ - Saving model with best Classification-F1: 0.6211080586080586 -> 0.6467357642357643 on epoch=162, global_step=650
06/13/2022 11:09:03 - INFO - __main__ - Step 660 Global step 660 Train loss 0.33 on epoch=164
06/13/2022 11:09:05 - INFO - __main__ - Step 670 Global step 670 Train loss 0.39 on epoch=167
06/13/2022 11:09:07 - INFO - __main__ - Step 680 Global step 680 Train loss 0.27 on epoch=169
06/13/2022 11:09:10 - INFO - __main__ - Step 690 Global step 690 Train loss 0.34 on epoch=172
06/13/2022 11:09:12 - INFO - __main__ - Step 700 Global step 700 Train loss 0.38 on epoch=174
06/13/2022 11:09:13 - INFO - __main__ - Global step 700 Train loss 0.34 Classification-F1 0.6316239316239316 on epoch=174
06/13/2022 11:09:15 - INFO - __main__ - Step 710 Global step 710 Train loss 0.41 on epoch=177
06/13/2022 11:09:18 - INFO - __main__ - Step 720 Global step 720 Train loss 0.24 on epoch=179
06/13/2022 11:09:20 - INFO - __main__ - Step 730 Global step 730 Train loss 0.35 on epoch=182
06/13/2022 11:09:23 - INFO - __main__ - Step 740 Global step 740 Train loss 0.29 on epoch=184
06/13/2022 11:09:25 - INFO - __main__ - Step 750 Global step 750 Train loss 0.39 on epoch=187
06/13/2022 11:09:26 - INFO - __main__ - Global step 750 Train loss 0.34 Classification-F1 0.6169729729729729 on epoch=187
06/13/2022 11:09:28 - INFO - __main__ - Step 760 Global step 760 Train loss 0.27 on epoch=189
06/13/2022 11:09:31 - INFO - __main__ - Step 770 Global step 770 Train loss 0.34 on epoch=192
06/13/2022 11:09:33 - INFO - __main__ - Step 780 Global step 780 Train loss 0.33 on epoch=194
06/13/2022 11:09:36 - INFO - __main__ - Step 790 Global step 790 Train loss 0.24 on epoch=197
06/13/2022 11:09:38 - INFO - __main__ - Step 800 Global step 800 Train loss 0.23 on epoch=199
06/13/2022 11:09:39 - INFO - __main__ - Global step 800 Train loss 0.28 Classification-F1 0.6588837685611879 on epoch=199
06/13/2022 11:09:39 - INFO - __main__ - Saving model with best Classification-F1: 0.6467357642357643 -> 0.6588837685611879 on epoch=199, global_step=800
06/13/2022 11:09:41 - INFO - __main__ - Step 810 Global step 810 Train loss 0.31 on epoch=202
06/13/2022 11:09:44 - INFO - __main__ - Step 820 Global step 820 Train loss 0.36 on epoch=204
06/13/2022 11:09:46 - INFO - __main__ - Step 830 Global step 830 Train loss 0.38 on epoch=207
06/13/2022 11:09:48 - INFO - __main__ - Step 840 Global step 840 Train loss 0.29 on epoch=209
06/13/2022 11:09:51 - INFO - __main__ - Step 850 Global step 850 Train loss 0.27 on epoch=212
06/13/2022 11:09:52 - INFO - __main__ - Global step 850 Train loss 0.32 Classification-F1 0.6445244322663678 on epoch=212
06/13/2022 11:09:54 - INFO - __main__ - Step 860 Global step 860 Train loss 0.26 on epoch=214
06/13/2022 11:09:56 - INFO - __main__ - Step 870 Global step 870 Train loss 0.24 on epoch=217
06/13/2022 11:09:59 - INFO - __main__ - Step 880 Global step 880 Train loss 0.18 on epoch=219
06/13/2022 11:10:01 - INFO - __main__ - Step 890 Global step 890 Train loss 0.23 on epoch=222
06/13/2022 11:10:04 - INFO - __main__ - Step 900 Global step 900 Train loss 0.26 on epoch=224
06/13/2022 11:10:05 - INFO - __main__ - Global step 900 Train loss 0.23 Classification-F1 0.825000984678404 on epoch=224
06/13/2022 11:10:05 - INFO - __main__ - Saving model with best Classification-F1: 0.6588837685611879 -> 0.825000984678404 on epoch=224, global_step=900
06/13/2022 11:10:07 - INFO - __main__ - Step 910 Global step 910 Train loss 0.30 on epoch=227
06/13/2022 11:10:10 - INFO - __main__ - Step 920 Global step 920 Train loss 0.23 on epoch=229
06/13/2022 11:10:12 - INFO - __main__ - Step 930 Global step 930 Train loss 0.29 on epoch=232
06/13/2022 11:10:14 - INFO - __main__ - Step 940 Global step 940 Train loss 0.20 on epoch=234
06/13/2022 11:10:17 - INFO - __main__ - Step 950 Global step 950 Train loss 0.18 on epoch=237
06/13/2022 11:10:18 - INFO - __main__ - Global step 950 Train loss 0.24 Classification-F1 0.8076340757015881 on epoch=237
06/13/2022 11:10:20 - INFO - __main__ - Step 960 Global step 960 Train loss 0.16 on epoch=239
06/13/2022 11:10:22 - INFO - __main__ - Step 970 Global step 970 Train loss 0.29 on epoch=242
06/13/2022 11:10:25 - INFO - __main__ - Step 980 Global step 980 Train loss 0.23 on epoch=244
06/13/2022 11:10:27 - INFO - __main__ - Step 990 Global step 990 Train loss 0.26 on epoch=247
06/13/2022 11:10:30 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.21 on epoch=249
06/13/2022 11:10:31 - INFO - __main__ - Global step 1000 Train loss 0.23 Classification-F1 0.8086186054936055 on epoch=249
06/13/2022 11:10:33 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.18 on epoch=252
06/13/2022 11:10:36 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.23 on epoch=254
06/13/2022 11:10:38 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.19 on epoch=257
06/13/2022 11:10:40 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.22 on epoch=259
06/13/2022 11:10:43 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.18 on epoch=262
06/13/2022 11:10:44 - INFO - __main__ - Global step 1050 Train loss 0.20 Classification-F1 0.8416666666666667 on epoch=262
06/13/2022 11:10:44 - INFO - __main__ - Saving model with best Classification-F1: 0.825000984678404 -> 0.8416666666666667 on epoch=262, global_step=1050
06/13/2022 11:10:46 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.13 on epoch=264
06/13/2022 11:10:49 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.19 on epoch=267
06/13/2022 11:10:51 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.12 on epoch=269
06/13/2022 11:10:54 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.17 on epoch=272
06/13/2022 11:10:56 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.16 on epoch=274
06/13/2022 11:10:57 - INFO - __main__ - Global step 1100 Train loss 0.15 Classification-F1 0.7929024244833068 on epoch=274
06/13/2022 11:10:59 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.16 on epoch=277
06/13/2022 11:11:02 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.16 on epoch=279
06/13/2022 11:11:04 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.26 on epoch=282
06/13/2022 11:11:07 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.22 on epoch=284
06/13/2022 11:11:09 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.17 on epoch=287
06/13/2022 11:11:10 - INFO - __main__ - Global step 1150 Train loss 0.20 Classification-F1 0.826274058010301 on epoch=287
06/13/2022 11:11:12 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.13 on epoch=289
06/13/2022 11:11:15 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.14 on epoch=292
06/13/2022 11:11:17 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.15 on epoch=294
06/13/2022 11:11:19 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.14 on epoch=297
06/13/2022 11:11:22 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.10 on epoch=299
06/13/2022 11:11:23 - INFO - __main__ - Global step 1200 Train loss 0.13 Classification-F1 0.8104653720462544 on epoch=299
06/13/2022 11:11:25 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.08 on epoch=302
06/13/2022 11:11:27 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.11 on epoch=304
06/13/2022 11:11:30 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.09 on epoch=307
06/13/2022 11:11:32 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.14 on epoch=309
06/13/2022 11:11:34 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.08 on epoch=312
06/13/2022 11:11:35 - INFO - __main__ - Global step 1250 Train loss 0.10 Classification-F1 0.8122373949579832 on epoch=312
06/13/2022 11:11:38 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.09 on epoch=314
06/13/2022 11:11:40 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.08 on epoch=317
06/13/2022 11:11:43 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.12 on epoch=319
06/13/2022 11:11:45 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.11 on epoch=322
06/13/2022 11:11:48 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.15 on epoch=324
06/13/2022 11:11:48 - INFO - __main__ - Global step 1300 Train loss 0.11 Classification-F1 0.8115301724137931 on epoch=324
06/13/2022 11:11:51 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.12 on epoch=327
06/13/2022 11:11:53 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.11 on epoch=329
06/13/2022 11:11:56 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.12 on epoch=332
06/13/2022 11:11:58 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.11 on epoch=334
06/13/2022 11:12:01 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.10 on epoch=337
06/13/2022 11:12:01 - INFO - __main__ - Global step 1350 Train loss 0.11 Classification-F1 0.8115301724137931 on epoch=337
06/13/2022 11:12:04 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.11 on epoch=339
06/13/2022 11:12:06 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.13 on epoch=342
06/13/2022 11:12:09 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.08 on epoch=344
06/13/2022 11:12:11 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.10 on epoch=347
06/13/2022 11:12:13 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.08 on epoch=349
06/13/2022 11:12:14 - INFO - __main__ - Global step 1400 Train loss 0.10 Classification-F1 0.7960778551232406 on epoch=349
06/13/2022 11:12:17 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.11 on epoch=352
06/13/2022 11:12:19 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.06 on epoch=354
06/13/2022 11:12:22 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.15 on epoch=357
06/13/2022 11:12:24 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.11 on epoch=359
06/13/2022 11:12:26 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.14 on epoch=362
06/13/2022 11:12:27 - INFO - __main__ - Global step 1450 Train loss 0.11 Classification-F1 0.7960778551232406 on epoch=362
06/13/2022 11:12:30 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.07 on epoch=364
06/13/2022 11:12:32 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.14 on epoch=367
06/13/2022 11:12:34 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.07 on epoch=369
06/13/2022 11:12:37 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.05 on epoch=372
06/13/2022 11:12:39 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.08 on epoch=374
06/13/2022 11:12:40 - INFO - __main__ - Global step 1500 Train loss 0.08 Classification-F1 0.8115301724137931 on epoch=374
06/13/2022 11:12:42 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.06 on epoch=377
06/13/2022 11:12:45 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.15 on epoch=379
06/13/2022 11:12:47 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.08 on epoch=382
06/13/2022 11:12:49 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.10 on epoch=384
06/13/2022 11:12:52 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.10 on epoch=387
06/13/2022 11:12:53 - INFO - __main__ - Global step 1550 Train loss 0.10 Classification-F1 0.8264159251019653 on epoch=387
06/13/2022 11:12:55 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.07 on epoch=389
06/13/2022 11:12:57 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.08 on epoch=392
06/13/2022 11:13:00 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.04 on epoch=394
06/13/2022 11:13:02 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.08 on epoch=397
06/13/2022 11:13:05 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.05 on epoch=399
06/13/2022 11:13:06 - INFO - __main__ - Global step 1600 Train loss 0.06 Classification-F1 0.8414408866995075 on epoch=399
06/13/2022 11:13:08 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.08 on epoch=402
06/13/2022 11:13:10 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.10 on epoch=404
06/13/2022 11:13:13 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.03 on epoch=407
06/13/2022 11:13:15 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.10 on epoch=409
06/13/2022 11:13:17 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.08 on epoch=412
06/13/2022 11:13:18 - INFO - __main__ - Global step 1650 Train loss 0.08 Classification-F1 0.8114538038898439 on epoch=412
06/13/2022 11:13:21 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.10 on epoch=414
06/13/2022 11:13:23 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.05 on epoch=417
06/13/2022 11:13:25 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.04 on epoch=419
06/13/2022 11:13:28 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.06 on epoch=422
06/13/2022 11:13:30 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.09 on epoch=424
06/13/2022 11:13:31 - INFO - __main__ - Global step 1700 Train loss 0.07 Classification-F1 0.8264087374761818 on epoch=424
06/13/2022 11:13:33 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.06 on epoch=427
06/13/2022 11:13:36 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.06 on epoch=429
06/13/2022 11:13:38 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.09 on epoch=432
06/13/2022 11:13:41 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=434
06/13/2022 11:13:43 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.05 on epoch=437
06/13/2022 11:13:44 - INFO - __main__ - Global step 1750 Train loss 0.06 Classification-F1 0.7967680840664713 on epoch=437
06/13/2022 11:13:47 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.04 on epoch=439
06/13/2022 11:13:49 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.08 on epoch=442
06/13/2022 11:13:52 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.10 on epoch=444
06/13/2022 11:13:54 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.09 on epoch=447
06/13/2022 11:13:56 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.06 on epoch=449
06/13/2022 11:13:57 - INFO - __main__ - Global step 1800 Train loss 0.07 Classification-F1 0.7977150537634408 on epoch=449
06/13/2022 11:14:00 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.04 on epoch=452
06/13/2022 11:14:02 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.04 on epoch=454
06/13/2022 11:14:05 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.05 on epoch=457
06/13/2022 11:14:07 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.08 on epoch=459
06/13/2022 11:14:09 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.07 on epoch=462
06/13/2022 11:14:10 - INFO - __main__ - Global step 1850 Train loss 0.05 Classification-F1 0.8134622082897944 on epoch=462
06/13/2022 11:14:13 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=464
06/13/2022 11:14:15 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.06 on epoch=467
06/13/2022 11:14:18 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.06 on epoch=469
06/13/2022 11:14:20 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=472
06/13/2022 11:14:22 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.06 on epoch=474
06/13/2022 11:14:23 - INFO - __main__ - Global step 1900 Train loss 0.05 Classification-F1 0.8111078751164958 on epoch=474
06/13/2022 11:14:26 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.07 on epoch=477
06/13/2022 11:14:28 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.05 on epoch=479
06/13/2022 11:14:31 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.04 on epoch=482
06/13/2022 11:14:33 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.09 on epoch=484
06/13/2022 11:14:36 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.08 on epoch=487
06/13/2022 11:14:37 - INFO - __main__ - Global step 1950 Train loss 0.07 Classification-F1 0.7962208289794497 on epoch=487
06/13/2022 11:14:39 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.06 on epoch=489
06/13/2022 11:14:41 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.06 on epoch=492
06/13/2022 11:14:44 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.05 on epoch=494
06/13/2022 11:14:46 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.05 on epoch=497
06/13/2022 11:14:49 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.05 on epoch=499
06/13/2022 11:14:50 - INFO - __main__ - Global step 2000 Train loss 0.05 Classification-F1 0.7980143832653566 on epoch=499
06/13/2022 11:14:52 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.04 on epoch=502
06/13/2022 11:14:54 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.04 on epoch=504
06/13/2022 11:14:57 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.04 on epoch=507
06/13/2022 11:14:59 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.03 on epoch=509
06/13/2022 11:15:02 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=512
06/13/2022 11:15:02 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.7962208289794497 on epoch=512
06/13/2022 11:15:05 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.04 on epoch=514
06/13/2022 11:15:07 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.05 on epoch=517
06/13/2022 11:15:10 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.09 on epoch=519
06/13/2022 11:15:12 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.07 on epoch=522
06/13/2022 11:15:15 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.09 on epoch=524
06/13/2022 11:15:15 - INFO - __main__ - Global step 2100 Train loss 0.07 Classification-F1 0.8112572223246666 on epoch=524
06/13/2022 11:15:18 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.04 on epoch=527
06/13/2022 11:15:20 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.03 on epoch=529
06/13/2022 11:15:23 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=532
06/13/2022 11:15:25 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.07 on epoch=534
06/13/2022 11:15:28 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.03 on epoch=537
06/13/2022 11:15:29 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.796135752688172 on epoch=537
06/13/2022 11:15:31 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=539
06/13/2022 11:15:34 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=542
06/13/2022 11:15:36 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.05 on epoch=544
06/13/2022 11:15:39 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.04 on epoch=547
06/13/2022 11:15:41 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.05 on epoch=549
06/13/2022 11:15:42 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.7802714047495831 on epoch=549
06/13/2022 11:15:44 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.07 on epoch=552
06/13/2022 11:15:47 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=554
06/13/2022 11:15:49 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=557
06/13/2022 11:15:52 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.05 on epoch=559
06/13/2022 11:15:54 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=562
06/13/2022 11:15:55 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.7806451612903226 on epoch=562
06/13/2022 11:15:58 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.06 on epoch=564
06/13/2022 11:16:00 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.07 on epoch=567
06/13/2022 11:16:03 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=569
06/13/2022 11:16:05 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.03 on epoch=572
06/13/2022 11:16:07 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=574
06/13/2022 11:16:08 - INFO - __main__ - Global step 2300 Train loss 0.04 Classification-F1 0.8287878787878787 on epoch=574
06/13/2022 11:16:11 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=577
06/13/2022 11:16:13 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=579
06/13/2022 11:16:16 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.05 on epoch=582
06/13/2022 11:16:18 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=584
06/13/2022 11:16:20 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=587
06/13/2022 11:16:21 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.8287878787878787 on epoch=587
06/13/2022 11:16:24 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=589
06/13/2022 11:16:26 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=592
06/13/2022 11:16:29 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.05 on epoch=594
06/13/2022 11:16:31 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=597
06/13/2022 11:16:34 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=599
06/13/2022 11:16:34 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.7938176406926407 on epoch=599
06/13/2022 11:16:37 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.03 on epoch=602
06/13/2022 11:16:39 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.03 on epoch=604
06/13/2022 11:16:42 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=607
06/13/2022 11:16:44 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.03 on epoch=609
06/13/2022 11:16:47 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=612
06/13/2022 11:16:48 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.8284274193548387 on epoch=612
06/13/2022 11:16:50 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.02 on epoch=614
06/13/2022 11:16:52 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.04 on epoch=617
06/13/2022 11:16:55 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.03 on epoch=619
06/13/2022 11:16:57 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=622
06/13/2022 11:17:00 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.05 on epoch=624
06/13/2022 11:17:00 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.796135752688172 on epoch=624
06/13/2022 11:17:03 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=627
06/13/2022 11:17:05 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.05 on epoch=629
06/13/2022 11:17:08 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.07 on epoch=632
06/13/2022 11:17:10 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=634
06/13/2022 11:17:13 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.05 on epoch=637
06/13/2022 11:17:14 - INFO - __main__ - Global step 2550 Train loss 0.04 Classification-F1 0.796135752688172 on epoch=637
06/13/2022 11:17:16 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=639
06/13/2022 11:17:19 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=642
06/13/2022 11:17:21 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=644
06/13/2022 11:17:23 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=647
06/13/2022 11:17:26 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=649
06/13/2022 11:17:27 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.7805443548387095 on epoch=649
06/13/2022 11:17:29 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.08 on epoch=652
06/13/2022 11:17:32 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.05 on epoch=654
06/13/2022 11:17:34 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.03 on epoch=657
06/13/2022 11:17:36 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=659
06/13/2022 11:17:39 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=662
06/13/2022 11:17:40 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.796135752688172 on epoch=662
06/13/2022 11:17:42 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=664
06/13/2022 11:17:44 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=667
06/13/2022 11:17:47 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=669
06/13/2022 11:17:49 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=672
06/13/2022 11:17:52 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=674
06/13/2022 11:17:53 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.8129032258064516 on epoch=674
06/13/2022 11:17:55 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=677
06/13/2022 11:17:58 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.03 on epoch=679
06/13/2022 11:18:00 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=682
06/13/2022 11:18:03 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=684
06/13/2022 11:18:05 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.03 on epoch=687
06/13/2022 11:18:06 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.7786637931034482 on epoch=687
06/13/2022 11:18:08 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=689
06/13/2022 11:18:11 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=692
06/13/2022 11:18:13 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=694
06/13/2022 11:18:16 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=697
06/13/2022 11:18:18 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=699
06/13/2022 11:18:19 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.7786637931034482 on epoch=699
06/13/2022 11:18:21 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.05 on epoch=702
06/13/2022 11:18:24 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=704
06/13/2022 11:18:26 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.03 on epoch=707
06/13/2022 11:18:29 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.04 on epoch=709
06/13/2022 11:18:31 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.05 on epoch=712
06/13/2022 11:18:32 - INFO - __main__ - Global step 2850 Train loss 0.04 Classification-F1 0.7608089826839827 on epoch=712
06/13/2022 11:18:34 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=714
06/13/2022 11:18:37 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=717
06/13/2022 11:18:39 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=719
06/13/2022 11:18:42 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=722
06/13/2022 11:18:44 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=724
06/13/2022 11:18:45 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.796135752688172 on epoch=724
06/13/2022 11:18:47 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.11 on epoch=727
06/13/2022 11:18:50 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=729
06/13/2022 11:18:52 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=732
06/13/2022 11:18:55 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=734
06/13/2022 11:18:57 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=737
06/13/2022 11:18:58 - INFO - __main__ - Global step 2950 Train loss 0.04 Classification-F1 0.7786637931034482 on epoch=737
06/13/2022 11:19:00 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=739
06/13/2022 11:19:03 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=742
06/13/2022 11:19:05 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.03 on epoch=744
06/13/2022 11:19:08 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=747
06/13/2022 11:19:10 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=749
06/13/2022 11:19:11 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.8110143177505608 on epoch=749
06/13/2022 11:19:11 - INFO - __main__ - save last model!
06/13/2022 11:19:11 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/13/2022 11:19:11 - INFO - __main__ - Start tokenizing ... 5509 instances
06/13/2022 11:19:11 - INFO - __main__ - Printing 3 examples
06/13/2022 11:19:11 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/13/2022 11:19:11 - INFO - __main__ - ['others']
06/13/2022 11:19:11 - INFO - __main__ -  [emo] what you like very little things ok
06/13/2022 11:19:11 - INFO - __main__ - ['others']
06/13/2022 11:19:11 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/13/2022 11:19:11 - INFO - __main__ - ['others']
06/13/2022 11:19:11 - INFO - __main__ - Tokenizing Input ...
06/13/2022 11:19:11 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 11:19:11 - INFO - __main__ - Printing 3 examples
06/13/2022 11:19:11 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/13/2022 11:19:11 - INFO - __main__ - ['others']
06/13/2022 11:19:11 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/13/2022 11:19:11 - INFO - __main__ - ['others']
06/13/2022 11:19:11 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/13/2022 11:19:11 - INFO - __main__ - ['others']
06/13/2022 11:19:11 - INFO - __main__ - Tokenizing Input ...
06/13/2022 11:19:11 - INFO - __main__ - Tokenizing Output ...
06/13/2022 11:19:11 - INFO - __main__ - Loaded 64 examples from train data
06/13/2022 11:19:11 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 11:19:11 - INFO - __main__ - Printing 3 examples
06/13/2022 11:19:11 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
06/13/2022 11:19:11 - INFO - __main__ - ['others']
06/13/2022 11:19:11 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
06/13/2022 11:19:11 - INFO - __main__ - ['others']
06/13/2022 11:19:11 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
06/13/2022 11:19:11 - INFO - __main__ - ['others']
06/13/2022 11:19:11 - INFO - __main__ - Tokenizing Input ...
06/13/2022 11:19:11 - INFO - __main__ - Tokenizing Output ...
06/13/2022 11:19:11 - INFO - __main__ - Loaded 64 examples from dev data
06/13/2022 11:19:13 - INFO - __main__ - Tokenizing Output ...
06/13/2022 11:19:18 - INFO - __main__ - Loaded 5509 examples from test data
06/13/2022 11:19:30 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 11:19:31 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 11:19:31 - INFO - __main__ - Starting training!
06/13/2022 11:20:35 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-up32shot/singletask-emo/emo_16_42_0.2_8_predictions.txt
06/13/2022 11:20:35 - INFO - __main__ - Classification-F1 on test data: 0.1688
06/13/2022 11:20:35 - INFO - __main__ - prefix=emo_16_42, lr=0.2, bsz=8, dev_performance=0.8416666666666667, test_performance=0.16883889748761272
06/13/2022 11:20:35 - INFO - __main__ - Running ... prefix=emo_16_87, lr=0.5, bsz=8 ...
06/13/2022 11:20:36 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 11:20:36 - INFO - __main__ - Printing 3 examples
06/13/2022 11:20:36 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/13/2022 11:20:36 - INFO - __main__ - ['others']
06/13/2022 11:20:36 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/13/2022 11:20:36 - INFO - __main__ - ['others']
06/13/2022 11:20:36 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/13/2022 11:20:36 - INFO - __main__ - ['others']
06/13/2022 11:20:36 - INFO - __main__ - Tokenizing Input ...
06/13/2022 11:20:36 - INFO - __main__ - Tokenizing Output ...
06/13/2022 11:20:36 - INFO - __main__ - Loaded 64 examples from train data
06/13/2022 11:20:36 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 11:20:36 - INFO - __main__ - Printing 3 examples
06/13/2022 11:20:36 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
06/13/2022 11:20:36 - INFO - __main__ - ['others']
06/13/2022 11:20:36 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
06/13/2022 11:20:36 - INFO - __main__ - ['others']
06/13/2022 11:20:36 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
06/13/2022 11:20:36 - INFO - __main__ - ['others']
06/13/2022 11:20:36 - INFO - __main__ - Tokenizing Input ...
06/13/2022 11:20:36 - INFO - __main__ - Tokenizing Output ...
06/13/2022 11:20:36 - INFO - __main__ - Loaded 64 examples from dev data
06/13/2022 11:20:55 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 11:20:56 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 11:20:56 - INFO - __main__ - Starting training!
06/13/2022 11:20:59 - INFO - __main__ - Step 10 Global step 10 Train loss 3.46 on epoch=2
06/13/2022 11:21:01 - INFO - __main__ - Step 20 Global step 20 Train loss 2.14 on epoch=4
06/13/2022 11:21:03 - INFO - __main__ - Step 30 Global step 30 Train loss 1.64 on epoch=7
06/13/2022 11:21:06 - INFO - __main__ - Step 40 Global step 40 Train loss 1.14 on epoch=9
06/13/2022 11:21:08 - INFO - __main__ - Step 50 Global step 50 Train loss 0.98 on epoch=12
06/13/2022 11:21:09 - INFO - __main__ - Global step 50 Train loss 1.87 Classification-F1 0.28289241622574957 on epoch=12
06/13/2022 11:21:09 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.28289241622574957 on epoch=12, global_step=50
06/13/2022 11:21:12 - INFO - __main__ - Step 60 Global step 60 Train loss 0.81 on epoch=14
06/13/2022 11:21:14 - INFO - __main__ - Step 70 Global step 70 Train loss 0.74 on epoch=17
06/13/2022 11:21:16 - INFO - __main__ - Step 80 Global step 80 Train loss 0.75 on epoch=19
06/13/2022 11:21:19 - INFO - __main__ - Step 90 Global step 90 Train loss 0.65 on epoch=22
06/13/2022 11:21:21 - INFO - __main__ - Step 100 Global step 100 Train loss 0.66 on epoch=24
06/13/2022 11:21:22 - INFO - __main__ - Global step 100 Train loss 0.72 Classification-F1 0.5998444570135747 on epoch=24
06/13/2022 11:21:22 - INFO - __main__ - Saving model with best Classification-F1: 0.28289241622574957 -> 0.5998444570135747 on epoch=24, global_step=100
06/13/2022 11:21:24 - INFO - __main__ - Step 110 Global step 110 Train loss 0.60 on epoch=27
06/13/2022 11:21:27 - INFO - __main__ - Step 120 Global step 120 Train loss 0.56 on epoch=29
06/13/2022 11:21:29 - INFO - __main__ - Step 130 Global step 130 Train loss 0.56 on epoch=32
06/13/2022 11:21:32 - INFO - __main__ - Step 140 Global step 140 Train loss 0.53 on epoch=34
06/13/2022 11:21:34 - INFO - __main__ - Step 150 Global step 150 Train loss 0.56 on epoch=37
06/13/2022 11:21:35 - INFO - __main__ - Global step 150 Train loss 0.56 Classification-F1 0.6192282176028306 on epoch=37
06/13/2022 11:21:35 - INFO - __main__ - Saving model with best Classification-F1: 0.5998444570135747 -> 0.6192282176028306 on epoch=37, global_step=150
06/13/2022 11:21:37 - INFO - __main__ - Step 160 Global step 160 Train loss 0.48 on epoch=39
06/13/2022 11:21:40 - INFO - __main__ - Step 170 Global step 170 Train loss 0.40 on epoch=42
06/13/2022 11:21:42 - INFO - __main__ - Step 180 Global step 180 Train loss 0.48 on epoch=44
06/13/2022 11:21:44 - INFO - __main__ - Step 190 Global step 190 Train loss 0.46 on epoch=47
06/13/2022 11:21:47 - INFO - __main__ - Step 200 Global step 200 Train loss 0.45 on epoch=49
06/13/2022 11:21:48 - INFO - __main__ - Global step 200 Train loss 0.45 Classification-F1 0.6002973824665001 on epoch=49
06/13/2022 11:21:50 - INFO - __main__ - Step 210 Global step 210 Train loss 0.36 on epoch=52
06/13/2022 11:21:52 - INFO - __main__ - Step 220 Global step 220 Train loss 0.36 on epoch=54
06/13/2022 11:21:55 - INFO - __main__ - Step 230 Global step 230 Train loss 0.39 on epoch=57
06/13/2022 11:21:57 - INFO - __main__ - Step 240 Global step 240 Train loss 0.36 on epoch=59
06/13/2022 11:21:59 - INFO - __main__ - Step 250 Global step 250 Train loss 0.37 on epoch=62
06/13/2022 11:22:00 - INFO - __main__ - Global step 250 Train loss 0.37 Classification-F1 0.694422191481015 on epoch=62
06/13/2022 11:22:00 - INFO - __main__ - Saving model with best Classification-F1: 0.6192282176028306 -> 0.694422191481015 on epoch=62, global_step=250
06/13/2022 11:22:03 - INFO - __main__ - Step 260 Global step 260 Train loss 0.28 on epoch=64
06/13/2022 11:22:05 - INFO - __main__ - Step 270 Global step 270 Train loss 0.34 on epoch=67
06/13/2022 11:22:08 - INFO - __main__ - Step 280 Global step 280 Train loss 0.29 on epoch=69
06/13/2022 11:22:10 - INFO - __main__ - Step 290 Global step 290 Train loss 0.38 on epoch=72
06/13/2022 11:22:12 - INFO - __main__ - Step 300 Global step 300 Train loss 0.32 on epoch=74
06/13/2022 11:22:13 - INFO - __main__ - Global step 300 Train loss 0.32 Classification-F1 0.7150307422046552 on epoch=74
06/13/2022 11:22:13 - INFO - __main__ - Saving model with best Classification-F1: 0.694422191481015 -> 0.7150307422046552 on epoch=74, global_step=300
06/13/2022 11:22:16 - INFO - __main__ - Step 310 Global step 310 Train loss 0.25 on epoch=77
06/13/2022 11:22:18 - INFO - __main__ - Step 320 Global step 320 Train loss 0.27 on epoch=79
06/13/2022 11:22:20 - INFO - __main__ - Step 330 Global step 330 Train loss 0.27 on epoch=82
06/13/2022 11:22:23 - INFO - __main__ - Step 340 Global step 340 Train loss 0.25 on epoch=84
06/13/2022 11:22:25 - INFO - __main__ - Step 350 Global step 350 Train loss 0.21 on epoch=87
06/13/2022 11:22:26 - INFO - __main__ - Global step 350 Train loss 0.25 Classification-F1 0.7154573051312181 on epoch=87
06/13/2022 11:22:26 - INFO - __main__ - Saving model with best Classification-F1: 0.7150307422046552 -> 0.7154573051312181 on epoch=87, global_step=350
06/13/2022 11:22:29 - INFO - __main__ - Step 360 Global step 360 Train loss 0.19 on epoch=89
06/13/2022 11:22:31 - INFO - __main__ - Step 370 Global step 370 Train loss 0.22 on epoch=92
06/13/2022 11:22:33 - INFO - __main__ - Step 380 Global step 380 Train loss 0.16 on epoch=94
06/13/2022 11:22:36 - INFO - __main__ - Step 390 Global step 390 Train loss 0.17 on epoch=97
06/13/2022 11:22:38 - INFO - __main__ - Step 400 Global step 400 Train loss 0.17 on epoch=99
06/13/2022 11:22:39 - INFO - __main__ - Global step 400 Train loss 0.18 Classification-F1 0.7091023012075645 on epoch=99
06/13/2022 11:22:41 - INFO - __main__ - Step 410 Global step 410 Train loss 0.18 on epoch=102
06/13/2022 11:22:44 - INFO - __main__ - Step 420 Global step 420 Train loss 0.15 on epoch=104
06/13/2022 11:22:46 - INFO - __main__ - Step 430 Global step 430 Train loss 0.18 on epoch=107
06/13/2022 11:22:49 - INFO - __main__ - Step 440 Global step 440 Train loss 0.19 on epoch=109
06/13/2022 11:22:51 - INFO - __main__ - Step 450 Global step 450 Train loss 0.15 on epoch=112
06/13/2022 11:22:52 - INFO - __main__ - Global step 450 Train loss 0.17 Classification-F1 0.6936802232854864 on epoch=112
06/13/2022 11:22:54 - INFO - __main__ - Step 460 Global step 460 Train loss 0.16 on epoch=114
06/13/2022 11:22:57 - INFO - __main__ - Step 470 Global step 470 Train loss 0.18 on epoch=117
06/13/2022 11:22:59 - INFO - __main__ - Step 480 Global step 480 Train loss 0.11 on epoch=119
06/13/2022 11:23:01 - INFO - __main__ - Step 490 Global step 490 Train loss 0.07 on epoch=122
06/13/2022 11:23:04 - INFO - __main__ - Step 500 Global step 500 Train loss 0.11 on epoch=124
06/13/2022 11:23:05 - INFO - __main__ - Global step 500 Train loss 0.13 Classification-F1 0.6874271239596318 on epoch=124
06/13/2022 11:23:07 - INFO - __main__ - Step 510 Global step 510 Train loss 0.13 on epoch=127
06/13/2022 11:23:09 - INFO - __main__ - Step 520 Global step 520 Train loss 0.07 on epoch=129
06/13/2022 11:23:12 - INFO - __main__ - Step 530 Global step 530 Train loss 0.08 on epoch=132
06/13/2022 11:23:14 - INFO - __main__ - Step 540 Global step 540 Train loss 0.10 on epoch=134
06/13/2022 11:23:16 - INFO - __main__ - Step 550 Global step 550 Train loss 0.13 on epoch=137
06/13/2022 11:23:17 - INFO - __main__ - Global step 550 Train loss 0.10 Classification-F1 0.7229936200524436 on epoch=137
06/13/2022 11:23:17 - INFO - __main__ - Saving model with best Classification-F1: 0.7154573051312181 -> 0.7229936200524436 on epoch=137, global_step=550
06/13/2022 11:23:20 - INFO - __main__ - Step 560 Global step 560 Train loss 0.09 on epoch=139
06/13/2022 11:23:22 - INFO - __main__ - Step 570 Global step 570 Train loss 0.14 on epoch=142
06/13/2022 11:23:24 - INFO - __main__ - Step 580 Global step 580 Train loss 0.08 on epoch=144
06/13/2022 11:23:27 - INFO - __main__ - Step 590 Global step 590 Train loss 0.12 on epoch=147
06/13/2022 11:23:29 - INFO - __main__ - Step 600 Global step 600 Train loss 0.12 on epoch=149
06/13/2022 11:23:30 - INFO - __main__ - Global step 600 Train loss 0.11 Classification-F1 0.6737912556326878 on epoch=149
06/13/2022 11:23:33 - INFO - __main__ - Step 610 Global step 610 Train loss 0.06 on epoch=152
06/13/2022 11:23:35 - INFO - __main__ - Step 620 Global step 620 Train loss 0.07 on epoch=154
06/13/2022 11:23:37 - INFO - __main__ - Step 630 Global step 630 Train loss 0.08 on epoch=157
06/13/2022 11:23:40 - INFO - __main__ - Step 640 Global step 640 Train loss 0.11 on epoch=159
06/13/2022 11:23:42 - INFO - __main__ - Step 650 Global step 650 Train loss 0.05 on epoch=162
06/13/2022 11:23:43 - INFO - __main__ - Global step 650 Train loss 0.08 Classification-F1 0.7139705882352941 on epoch=162
06/13/2022 11:23:45 - INFO - __main__ - Step 660 Global step 660 Train loss 0.03 on epoch=164
06/13/2022 11:23:48 - INFO - __main__ - Step 670 Global step 670 Train loss 0.04 on epoch=167
06/13/2022 11:23:50 - INFO - __main__ - Step 680 Global step 680 Train loss 0.05 on epoch=169
06/13/2022 11:23:53 - INFO - __main__ - Step 690 Global step 690 Train loss 0.04 on epoch=172
06/13/2022 11:23:55 - INFO - __main__ - Step 700 Global step 700 Train loss 0.09 on epoch=174
06/13/2022 11:23:56 - INFO - __main__ - Global step 700 Train loss 0.05 Classification-F1 0.7239583333333334 on epoch=174
06/13/2022 11:23:56 - INFO - __main__ - Saving model with best Classification-F1: 0.7229936200524436 -> 0.7239583333333334 on epoch=174, global_step=700
06/13/2022 11:23:58 - INFO - __main__ - Step 710 Global step 710 Train loss 0.05 on epoch=177
06/13/2022 11:24:01 - INFO - __main__ - Step 720 Global step 720 Train loss 0.04 on epoch=179
06/13/2022 11:24:03 - INFO - __main__ - Step 730 Global step 730 Train loss 0.05 on epoch=182
06/13/2022 11:24:05 - INFO - __main__ - Step 740 Global step 740 Train loss 0.05 on epoch=184
06/13/2022 11:24:08 - INFO - __main__ - Step 750 Global step 750 Train loss 0.03 on epoch=187
06/13/2022 11:24:09 - INFO - __main__ - Global step 750 Train loss 0.05 Classification-F1 0.6761734997029114 on epoch=187
06/13/2022 11:24:11 - INFO - __main__ - Step 760 Global step 760 Train loss 0.05 on epoch=189
06/13/2022 11:24:13 - INFO - __main__ - Step 770 Global step 770 Train loss 0.03 on epoch=192
06/13/2022 11:24:16 - INFO - __main__ - Step 780 Global step 780 Train loss 0.03 on epoch=194
06/13/2022 11:24:18 - INFO - __main__ - Step 790 Global step 790 Train loss 0.04 on epoch=197
06/13/2022 11:24:21 - INFO - __main__ - Step 800 Global step 800 Train loss 0.03 on epoch=199
06/13/2022 11:24:21 - INFO - __main__ - Global step 800 Train loss 0.04 Classification-F1 0.7084293394777267 on epoch=199
06/13/2022 11:24:24 - INFO - __main__ - Step 810 Global step 810 Train loss 0.05 on epoch=202
06/13/2022 11:24:26 - INFO - __main__ - Step 820 Global step 820 Train loss 0.03 on epoch=204
06/13/2022 11:24:28 - INFO - __main__ - Step 830 Global step 830 Train loss 0.06 on epoch=207
06/13/2022 11:24:31 - INFO - __main__ - Step 840 Global step 840 Train loss 0.03 on epoch=209
06/13/2022 11:24:33 - INFO - __main__ - Step 850 Global step 850 Train loss 0.03 on epoch=212
06/13/2022 11:24:34 - INFO - __main__ - Global step 850 Train loss 0.04 Classification-F1 0.7222983930414272 on epoch=212
06/13/2022 11:24:36 - INFO - __main__ - Step 860 Global step 860 Train loss 0.03 on epoch=214
06/13/2022 11:24:39 - INFO - __main__ - Step 870 Global step 870 Train loss 0.03 on epoch=217
06/13/2022 11:24:41 - INFO - __main__ - Step 880 Global step 880 Train loss 0.06 on epoch=219
06/13/2022 11:24:44 - INFO - __main__ - Step 890 Global step 890 Train loss 0.02 on epoch=222
06/13/2022 11:24:46 - INFO - __main__ - Step 900 Global step 900 Train loss 0.04 on epoch=224
06/13/2022 11:24:47 - INFO - __main__ - Global step 900 Train loss 0.03 Classification-F1 0.6746482683982684 on epoch=224
06/13/2022 11:24:49 - INFO - __main__ - Step 910 Global step 910 Train loss 0.04 on epoch=227
06/13/2022 11:24:52 - INFO - __main__ - Step 920 Global step 920 Train loss 0.01 on epoch=229
06/13/2022 11:24:54 - INFO - __main__ - Step 930 Global step 930 Train loss 0.01 on epoch=232
06/13/2022 11:24:56 - INFO - __main__ - Step 940 Global step 940 Train loss 0.07 on epoch=234
06/13/2022 11:24:59 - INFO - __main__ - Step 950 Global step 950 Train loss 0.02 on epoch=237
06/13/2022 11:25:00 - INFO - __main__ - Global step 950 Train loss 0.03 Classification-F1 0.7226107226107227 on epoch=237
06/13/2022 11:25:02 - INFO - __main__ - Step 960 Global step 960 Train loss 0.02 on epoch=239
06/13/2022 11:25:04 - INFO - __main__ - Step 970 Global step 970 Train loss 0.05 on epoch=242
06/13/2022 11:25:07 - INFO - __main__ - Step 980 Global step 980 Train loss 0.04 on epoch=244
06/13/2022 11:25:09 - INFO - __main__ - Step 990 Global step 990 Train loss 0.05 on epoch=247
06/13/2022 11:25:12 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.01 on epoch=249
06/13/2022 11:25:12 - INFO - __main__ - Global step 1000 Train loss 0.03 Classification-F1 0.7228136446886447 on epoch=249
06/13/2022 11:25:15 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.02 on epoch=252
06/13/2022 11:25:17 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.05 on epoch=254
06/13/2022 11:25:19 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.01 on epoch=257
06/13/2022 11:25:22 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.01 on epoch=259
06/13/2022 11:25:24 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.05 on epoch=262
06/13/2022 11:25:25 - INFO - __main__ - Global step 1050 Train loss 0.03 Classification-F1 0.7106814753873578 on epoch=262
06/13/2022 11:25:27 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.01 on epoch=264
06/13/2022 11:25:30 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.03 on epoch=267
06/13/2022 11:25:32 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.05 on epoch=269
06/13/2022 11:25:35 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.04 on epoch=272
06/13/2022 11:25:37 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.02 on epoch=274
06/13/2022 11:25:38 - INFO - __main__ - Global step 1100 Train loss 0.03 Classification-F1 0.7031106148753209 on epoch=274
06/13/2022 11:25:40 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.01 on epoch=277
06/13/2022 11:25:43 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.06 on epoch=279
06/13/2022 11:25:45 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=282
06/13/2022 11:25:47 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.04 on epoch=284
06/13/2022 11:25:50 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=287
06/13/2022 11:25:51 - INFO - __main__ - Global step 1150 Train loss 0.03 Classification-F1 0.7365841073271414 on epoch=287
06/13/2022 11:25:51 - INFO - __main__ - Saving model with best Classification-F1: 0.7239583333333334 -> 0.7365841073271414 on epoch=287, global_step=1150
06/13/2022 11:25:53 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.02 on epoch=289
06/13/2022 11:25:55 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.01 on epoch=292
06/13/2022 11:25:58 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.01 on epoch=294
06/13/2022 11:26:00 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.02 on epoch=297
06/13/2022 11:26:02 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=299
06/13/2022 11:26:03 - INFO - __main__ - Global step 1200 Train loss 0.01 Classification-F1 0.7365841073271414 on epoch=299
06/13/2022 11:26:06 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.02 on epoch=302
06/13/2022 11:26:08 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=304
06/13/2022 11:26:10 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=307
06/13/2022 11:26:13 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.04 on epoch=309
06/13/2022 11:26:15 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.03 on epoch=312
06/13/2022 11:26:16 - INFO - __main__ - Global step 1250 Train loss 0.02 Classification-F1 0.6826839826839827 on epoch=312
06/13/2022 11:26:18 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=314
06/13/2022 11:26:21 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.04 on epoch=317
06/13/2022 11:26:23 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.02 on epoch=319
06/13/2022 11:26:26 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=322
06/13/2022 11:26:28 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=324
06/13/2022 11:26:29 - INFO - __main__ - Global step 1300 Train loss 0.02 Classification-F1 0.6902865312791784 on epoch=324
06/13/2022 11:26:31 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=327
06/13/2022 11:26:34 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=329
06/13/2022 11:26:36 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.00 on epoch=332
06/13/2022 11:26:38 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.00 on epoch=334
06/13/2022 11:26:41 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.02 on epoch=337
06/13/2022 11:26:41 - INFO - __main__ - Global step 1350 Train loss 0.01 Classification-F1 0.7377622377622378 on epoch=337
06/13/2022 11:26:41 - INFO - __main__ - Saving model with best Classification-F1: 0.7365841073271414 -> 0.7377622377622378 on epoch=337, global_step=1350
06/13/2022 11:26:44 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.03 on epoch=339
06/13/2022 11:26:46 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=342
06/13/2022 11:26:49 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=344
06/13/2022 11:26:51 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=347
06/13/2022 11:26:53 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=349
06/13/2022 11:26:54 - INFO - __main__ - Global step 1400 Train loss 0.01 Classification-F1 0.7377622377622378 on epoch=349
06/13/2022 11:26:57 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=352
06/13/2022 11:26:59 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=354
06/13/2022 11:27:01 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.00 on epoch=357
06/13/2022 11:27:04 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.07 on epoch=359
06/13/2022 11:27:06 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=362
06/13/2022 11:27:07 - INFO - __main__ - Global step 1450 Train loss 0.02 Classification-F1 0.7368705855547961 on epoch=362
06/13/2022 11:27:09 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.02 on epoch=364
06/13/2022 11:27:12 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.03 on epoch=367
06/13/2022 11:27:14 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.02 on epoch=369
06/13/2022 11:27:16 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.02 on epoch=372
06/13/2022 11:27:19 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=374
06/13/2022 11:27:20 - INFO - __main__ - Global step 1500 Train loss 0.02 Classification-F1 0.7450472942800309 on epoch=374
06/13/2022 11:27:20 - INFO - __main__ - Saving model with best Classification-F1: 0.7377622377622378 -> 0.7450472942800309 on epoch=374, global_step=1500
06/13/2022 11:27:22 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=377
06/13/2022 11:27:24 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=379
06/13/2022 11:27:27 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=382
06/13/2022 11:27:29 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=384
06/13/2022 11:27:32 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=387
06/13/2022 11:27:32 - INFO - __main__ - Global step 1550 Train loss 0.01 Classification-F1 0.7512899896800825 on epoch=387
06/13/2022 11:27:32 - INFO - __main__ - Saving model with best Classification-F1: 0.7450472942800309 -> 0.7512899896800825 on epoch=387, global_step=1550
06/13/2022 11:27:35 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.05 on epoch=389
06/13/2022 11:27:37 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=392
06/13/2022 11:27:39 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=394
06/13/2022 11:27:42 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=397
06/13/2022 11:27:44 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=399
06/13/2022 11:27:45 - INFO - __main__ - Global step 1600 Train loss 0.01 Classification-F1 0.7450472942800309 on epoch=399
06/13/2022 11:27:47 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=402
06/13/2022 11:27:50 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=404
06/13/2022 11:27:52 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=407
06/13/2022 11:27:55 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.02 on epoch=409
06/13/2022 11:27:57 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=412
06/13/2022 11:27:58 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.7592344062932299 on epoch=412
06/13/2022 11:27:58 - INFO - __main__ - Saving model with best Classification-F1: 0.7512899896800825 -> 0.7592344062932299 on epoch=412, global_step=1650
06/13/2022 11:28:00 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=414
06/13/2022 11:28:03 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.09 on epoch=417
06/13/2022 11:28:05 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=419
06/13/2022 11:28:07 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=422
06/13/2022 11:28:10 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.04 on epoch=424
06/13/2022 11:28:11 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.7365841073271414 on epoch=424
06/13/2022 11:28:13 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=427
06/13/2022 11:28:16 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=429
06/13/2022 11:28:18 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=432
06/13/2022 11:28:20 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=434
06/13/2022 11:28:23 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=437
06/13/2022 11:28:23 - INFO - __main__ - Global step 1750 Train loss 0.01 Classification-F1 0.7365841073271414 on epoch=437
06/13/2022 11:28:26 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=439
06/13/2022 11:28:28 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=442
06/13/2022 11:28:30 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=444
06/13/2022 11:28:33 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=447
06/13/2022 11:28:35 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=449
06/13/2022 11:28:36 - INFO - __main__ - Global step 1800 Train loss 0.00 Classification-F1 0.7365841073271414 on epoch=449
06/13/2022 11:28:38 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=452
06/13/2022 11:28:41 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=454
06/13/2022 11:28:43 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.12 on epoch=457
06/13/2022 11:28:46 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=459
06/13/2022 11:28:48 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.04 on epoch=462
06/13/2022 11:28:49 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.7365841073271414 on epoch=462
06/13/2022 11:28:51 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=464
06/13/2022 11:28:54 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=467
06/13/2022 11:28:56 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=469
06/13/2022 11:28:59 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=472
06/13/2022 11:29:01 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=474
06/13/2022 11:29:02 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.7365841073271414 on epoch=474
06/13/2022 11:29:04 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.04 on epoch=477
06/13/2022 11:29:06 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=479
06/13/2022 11:29:09 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=482
06/13/2022 11:29:11 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=484
06/13/2022 11:29:14 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.13 on epoch=487
06/13/2022 11:29:14 - INFO - __main__ - Global step 1950 Train loss 0.04 Classification-F1 0.7365841073271414 on epoch=487
06/13/2022 11:29:17 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=489
06/13/2022 11:29:19 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=492
06/13/2022 11:29:22 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=494
06/13/2022 11:29:24 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=497
06/13/2022 11:29:26 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=499
06/13/2022 11:29:27 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.7365841073271414 on epoch=499
06/13/2022 11:29:30 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.12 on epoch=502
06/13/2022 11:29:32 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=504
06/13/2022 11:29:34 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/13/2022 11:29:37 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=509
06/13/2022 11:29:39 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/13/2022 11:29:40 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.7450472942800309 on epoch=512
06/13/2022 11:29:42 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=514
06/13/2022 11:29:45 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=517
06/13/2022 11:29:47 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.04 on epoch=519
06/13/2022 11:29:49 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/13/2022 11:29:52 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/13/2022 11:29:53 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.7365841073271414 on epoch=524
06/13/2022 11:29:55 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.07 on epoch=527
06/13/2022 11:29:57 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.05 on epoch=529
06/13/2022 11:30:00 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/13/2022 11:30:02 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
06/13/2022 11:30:05 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
06/13/2022 11:30:05 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.7449874686716793 on epoch=537
06/13/2022 11:30:08 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/13/2022 11:30:10 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=542
06/13/2022 11:30:13 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/13/2022 11:30:15 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/13/2022 11:30:17 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/13/2022 11:30:18 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.7449874686716793 on epoch=549
06/13/2022 11:30:20 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/13/2022 11:30:23 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=554
06/13/2022 11:30:25 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
06/13/2022 11:30:28 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/13/2022 11:30:30 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/13/2022 11:30:31 - INFO - __main__ - Global step 2250 Train loss 0.00 Classification-F1 0.7378258995906055 on epoch=562
06/13/2022 11:30:33 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=564
06/13/2022 11:30:36 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/13/2022 11:30:38 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/13/2022 11:30:41 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/13/2022 11:30:43 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/13/2022 11:30:44 - INFO - __main__ - Global step 2300 Train loss 0.00 Classification-F1 0.7449874686716793 on epoch=574
06/13/2022 11:30:46 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/13/2022 11:30:49 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/13/2022 11:30:51 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=582
06/13/2022 11:30:54 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/13/2022 11:30:56 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/13/2022 11:30:57 - INFO - __main__ - Global step 2350 Train loss 0.00 Classification-F1 0.7592344062932299 on epoch=587
06/13/2022 11:30:59 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/13/2022 11:31:02 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/13/2022 11:31:04 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/13/2022 11:31:07 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/13/2022 11:31:09 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/13/2022 11:31:10 - INFO - __main__ - Global step 2400 Train loss 0.00 Classification-F1 0.7168109668109669 on epoch=599
06/13/2022 11:31:12 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=602
06/13/2022 11:31:15 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/13/2022 11:31:17 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.04 on epoch=607
06/13/2022 11:31:20 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/13/2022 11:31:22 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.06 on epoch=612
06/13/2022 11:31:23 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.7308823529411765 on epoch=612
06/13/2022 11:31:25 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/13/2022 11:31:27 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=617
06/13/2022 11:31:30 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=619
06/13/2022 11:31:32 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/13/2022 11:31:35 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/13/2022 11:31:36 - INFO - __main__ - Global step 2500 Train loss 0.00 Classification-F1 0.7592344062932299 on epoch=624
06/13/2022 11:31:38 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/13/2022 11:31:40 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/13/2022 11:31:43 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/13/2022 11:31:45 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/13/2022 11:31:47 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/13/2022 11:31:48 - INFO - __main__ - Global step 2550 Train loss 0.00 Classification-F1 0.746082042957043 on epoch=637
06/13/2022 11:31:51 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/13/2022 11:31:53 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/13/2022 11:31:56 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/13/2022 11:31:58 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=647
06/13/2022 11:32:00 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=649
06/13/2022 11:32:01 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.7365841073271414 on epoch=649
06/13/2022 11:32:04 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/13/2022 11:32:06 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=654
06/13/2022 11:32:08 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/13/2022 11:32:11 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=659
06/13/2022 11:32:13 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/13/2022 11:32:14 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.7168109668109669 on epoch=662
06/13/2022 11:32:16 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/13/2022 11:32:19 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/13/2022 11:32:21 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/13/2022 11:32:23 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=672
06/13/2022 11:32:26 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/13/2022 11:32:27 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.7227032227032227 on epoch=674
06/13/2022 11:32:29 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/13/2022 11:32:32 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/13/2022 11:32:34 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/13/2022 11:32:36 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/13/2022 11:32:39 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/13/2022 11:32:40 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.7168109668109669 on epoch=687
06/13/2022 11:32:42 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/13/2022 11:32:45 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=692
06/13/2022 11:32:47 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/13/2022 11:32:49 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=697
06/13/2022 11:32:52 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/13/2022 11:32:53 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.7449874686716793 on epoch=699
06/13/2022 11:32:55 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/13/2022 11:32:57 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=704
06/13/2022 11:33:00 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/13/2022 11:33:02 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/13/2022 11:33:05 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/13/2022 11:33:05 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.7449874686716793 on epoch=712
06/13/2022 11:33:08 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/13/2022 11:33:10 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/13/2022 11:33:13 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.06 on epoch=719
06/13/2022 11:33:15 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/13/2022 11:33:17 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/13/2022 11:33:18 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.7235109321506381 on epoch=724
06/13/2022 11:33:21 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/13/2022 11:33:23 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.07 on epoch=729
06/13/2022 11:33:26 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/13/2022 11:33:28 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/13/2022 11:33:30 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=737
06/13/2022 11:33:31 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.7320560232101994 on epoch=737
06/13/2022 11:33:34 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.04 on epoch=739
06/13/2022 11:33:36 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=742
06/13/2022 11:33:38 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/13/2022 11:33:41 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/13/2022 11:33:43 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=749
06/13/2022 11:33:44 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.7320560232101994 on epoch=749
06/13/2022 11:33:44 - INFO - __main__ - save last model!
06/13/2022 11:33:44 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/13/2022 11:33:44 - INFO - __main__ - Start tokenizing ... 5509 instances
06/13/2022 11:33:44 - INFO - __main__ - Printing 3 examples
06/13/2022 11:33:44 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/13/2022 11:33:44 - INFO - __main__ - ['others']
06/13/2022 11:33:44 - INFO - __main__ -  [emo] what you like very little things ok
06/13/2022 11:33:44 - INFO - __main__ - ['others']
06/13/2022 11:33:44 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/13/2022 11:33:44 - INFO - __main__ - ['others']
06/13/2022 11:33:44 - INFO - __main__ - Tokenizing Input ...
06/13/2022 11:33:45 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 11:33:45 - INFO - __main__ - Printing 3 examples
06/13/2022 11:33:45 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/13/2022 11:33:45 - INFO - __main__ - ['others']
06/13/2022 11:33:45 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/13/2022 11:33:45 - INFO - __main__ - ['others']
06/13/2022 11:33:45 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/13/2022 11:33:45 - INFO - __main__ - ['others']
06/13/2022 11:33:45 - INFO - __main__ - Tokenizing Input ...
06/13/2022 11:33:45 - INFO - __main__ - Tokenizing Output ...
06/13/2022 11:33:45 - INFO - __main__ - Loaded 64 examples from train data
06/13/2022 11:33:45 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 11:33:45 - INFO - __main__ - Printing 3 examples
06/13/2022 11:33:45 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
06/13/2022 11:33:45 - INFO - __main__ - ['others']
06/13/2022 11:33:45 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
06/13/2022 11:33:45 - INFO - __main__ - ['others']
06/13/2022 11:33:45 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
06/13/2022 11:33:45 - INFO - __main__ - ['others']
06/13/2022 11:33:45 - INFO - __main__ - Tokenizing Input ...
06/13/2022 11:33:45 - INFO - __main__ - Tokenizing Output ...
06/13/2022 11:33:45 - INFO - __main__ - Loaded 64 examples from dev data
06/13/2022 11:33:46 - INFO - __main__ - Tokenizing Output ...
06/13/2022 11:33:52 - INFO - __main__ - Loaded 5509 examples from test data
06/13/2022 11:34:03 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 11:34:04 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 11:34:04 - INFO - __main__ - Starting training!
06/13/2022 11:35:24 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-up32shot/singletask-emo/emo_16_87_0.5_8_predictions.txt
06/13/2022 11:35:24 - INFO - __main__ - Classification-F1 on test data: 0.1776
06/13/2022 11:35:24 - INFO - __main__ - prefix=emo_16_87, lr=0.5, bsz=8, dev_performance=0.7592344062932299, test_performance=0.17755935292443248
06/13/2022 11:35:24 - INFO - __main__ - Running ... prefix=emo_16_87, lr=0.4, bsz=8 ...
06/13/2022 11:35:25 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 11:35:25 - INFO - __main__ - Printing 3 examples
06/13/2022 11:35:25 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/13/2022 11:35:25 - INFO - __main__ - ['others']
06/13/2022 11:35:25 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/13/2022 11:35:25 - INFO - __main__ - ['others']
06/13/2022 11:35:25 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/13/2022 11:35:25 - INFO - __main__ - ['others']
06/13/2022 11:35:25 - INFO - __main__ - Tokenizing Input ...
06/13/2022 11:35:25 - INFO - __main__ - Tokenizing Output ...
06/13/2022 11:35:25 - INFO - __main__ - Loaded 64 examples from train data
06/13/2022 11:35:25 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 11:35:25 - INFO - __main__ - Printing 3 examples
06/13/2022 11:35:25 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
06/13/2022 11:35:25 - INFO - __main__ - ['others']
06/13/2022 11:35:25 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
06/13/2022 11:35:25 - INFO - __main__ - ['others']
06/13/2022 11:35:25 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
06/13/2022 11:35:25 - INFO - __main__ - ['others']
06/13/2022 11:35:25 - INFO - __main__ - Tokenizing Input ...
06/13/2022 11:35:25 - INFO - __main__ - Tokenizing Output ...
06/13/2022 11:35:25 - INFO - __main__ - Loaded 64 examples from dev data
06/13/2022 11:35:44 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 11:35:45 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 11:35:45 - INFO - __main__ - Starting training!
06/13/2022 11:35:48 - INFO - __main__ - Step 10 Global step 10 Train loss 3.62 on epoch=2
06/13/2022 11:35:50 - INFO - __main__ - Step 20 Global step 20 Train loss 2.36 on epoch=4
06/13/2022 11:35:53 - INFO - __main__ - Step 30 Global step 30 Train loss 1.82 on epoch=7
06/13/2022 11:35:55 - INFO - __main__ - Step 40 Global step 40 Train loss 1.35 on epoch=9
06/13/2022 11:35:58 - INFO - __main__ - Step 50 Global step 50 Train loss 1.05 on epoch=12
06/13/2022 11:35:59 - INFO - __main__ - Global step 50 Train loss 2.04 Classification-F1 0.2044817927170868 on epoch=12
06/13/2022 11:35:59 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.2044817927170868 on epoch=12, global_step=50
06/13/2022 11:36:01 - INFO - __main__ - Step 60 Global step 60 Train loss 0.97 on epoch=14
06/13/2022 11:36:03 - INFO - __main__ - Step 70 Global step 70 Train loss 0.76 on epoch=17
06/13/2022 11:36:06 - INFO - __main__ - Step 80 Global step 80 Train loss 0.76 on epoch=19
06/13/2022 11:36:08 - INFO - __main__ - Step 90 Global step 90 Train loss 0.68 on epoch=22
06/13/2022 11:36:11 - INFO - __main__ - Step 100 Global step 100 Train loss 0.64 on epoch=24
06/13/2022 11:36:12 - INFO - __main__ - Global step 100 Train loss 0.76 Classification-F1 0.534375 on epoch=24
06/13/2022 11:36:12 - INFO - __main__ - Saving model with best Classification-F1: 0.2044817927170868 -> 0.534375 on epoch=24, global_step=100
06/13/2022 11:36:14 - INFO - __main__ - Step 110 Global step 110 Train loss 0.61 on epoch=27
06/13/2022 11:36:16 - INFO - __main__ - Step 120 Global step 120 Train loss 0.60 on epoch=29
06/13/2022 11:36:19 - INFO - __main__ - Step 130 Global step 130 Train loss 0.61 on epoch=32
06/13/2022 11:36:21 - INFO - __main__ - Step 140 Global step 140 Train loss 0.48 on epoch=34
06/13/2022 11:36:23 - INFO - __main__ - Step 150 Global step 150 Train loss 0.53 on epoch=37
06/13/2022 11:36:24 - INFO - __main__ - Global step 150 Train loss 0.57 Classification-F1 0.5995465740130375 on epoch=37
06/13/2022 11:36:24 - INFO - __main__ - Saving model with best Classification-F1: 0.534375 -> 0.5995465740130375 on epoch=37, global_step=150
06/13/2022 11:36:27 - INFO - __main__ - Step 160 Global step 160 Train loss 0.55 on epoch=39
06/13/2022 11:36:29 - INFO - __main__ - Step 170 Global step 170 Train loss 0.57 on epoch=42
06/13/2022 11:36:32 - INFO - __main__ - Step 180 Global step 180 Train loss 0.51 on epoch=44
06/13/2022 11:36:34 - INFO - __main__ - Step 190 Global step 190 Train loss 0.52 on epoch=47
06/13/2022 11:36:36 - INFO - __main__ - Step 200 Global step 200 Train loss 0.46 on epoch=49
06/13/2022 11:36:37 - INFO - __main__ - Global step 200 Train loss 0.52 Classification-F1 0.5980528796884608 on epoch=49
06/13/2022 11:36:40 - INFO - __main__ - Step 210 Global step 210 Train loss 0.50 on epoch=52
06/13/2022 11:36:42 - INFO - __main__ - Step 220 Global step 220 Train loss 0.38 on epoch=54
06/13/2022 11:36:44 - INFO - __main__ - Step 230 Global step 230 Train loss 0.37 on epoch=57
06/13/2022 11:36:47 - INFO - __main__ - Step 240 Global step 240 Train loss 0.48 on epoch=59
06/13/2022 11:36:49 - INFO - __main__ - Step 250 Global step 250 Train loss 0.44 on epoch=62
06/13/2022 11:36:50 - INFO - __main__ - Global step 250 Train loss 0.43 Classification-F1 0.7249302232854865 on epoch=62
06/13/2022 11:36:50 - INFO - __main__ - Saving model with best Classification-F1: 0.5995465740130375 -> 0.7249302232854865 on epoch=62, global_step=250
06/13/2022 11:36:52 - INFO - __main__ - Step 260 Global step 260 Train loss 0.38 on epoch=64
06/13/2022 11:36:55 - INFO - __main__ - Step 270 Global step 270 Train loss 0.41 on epoch=67
06/13/2022 11:36:57 - INFO - __main__ - Step 280 Global step 280 Train loss 0.30 on epoch=69
06/13/2022 11:37:00 - INFO - __main__ - Step 290 Global step 290 Train loss 0.36 on epoch=72
06/13/2022 11:37:02 - INFO - __main__ - Step 300 Global step 300 Train loss 0.36 on epoch=74
06/13/2022 11:37:03 - INFO - __main__ - Global step 300 Train loss 0.36 Classification-F1 0.7391583202279297 on epoch=74
06/13/2022 11:37:03 - INFO - __main__ - Saving model with best Classification-F1: 0.7249302232854865 -> 0.7391583202279297 on epoch=74, global_step=300
06/13/2022 11:37:05 - INFO - __main__ - Step 310 Global step 310 Train loss 0.34 on epoch=77
06/13/2022 11:37:08 - INFO - __main__ - Step 320 Global step 320 Train loss 0.30 on epoch=79
06/13/2022 11:37:10 - INFO - __main__ - Step 330 Global step 330 Train loss 0.34 on epoch=82
06/13/2022 11:37:12 - INFO - __main__ - Step 340 Global step 340 Train loss 0.28 on epoch=84
06/13/2022 11:37:15 - INFO - __main__ - Step 350 Global step 350 Train loss 0.29 on epoch=87
06/13/2022 11:37:16 - INFO - __main__ - Global step 350 Train loss 0.31 Classification-F1 0.7187671727237682 on epoch=87
06/13/2022 11:37:18 - INFO - __main__ - Step 360 Global step 360 Train loss 0.28 on epoch=89
06/13/2022 11:37:21 - INFO - __main__ - Step 370 Global step 370 Train loss 0.21 on epoch=92
06/13/2022 11:37:23 - INFO - __main__ - Step 380 Global step 380 Train loss 0.34 on epoch=94
06/13/2022 11:37:25 - INFO - __main__ - Step 390 Global step 390 Train loss 0.23 on epoch=97
06/13/2022 11:37:28 - INFO - __main__ - Step 400 Global step 400 Train loss 0.28 on epoch=99
06/13/2022 11:37:29 - INFO - __main__ - Global step 400 Train loss 0.27 Classification-F1 0.6889880952380952 on epoch=99
06/13/2022 11:37:31 - INFO - __main__ - Step 410 Global step 410 Train loss 0.23 on epoch=102
06/13/2022 11:37:33 - INFO - __main__ - Step 420 Global step 420 Train loss 0.24 on epoch=104
06/13/2022 11:37:36 - INFO - __main__ - Step 430 Global step 430 Train loss 0.26 on epoch=107
06/13/2022 11:37:38 - INFO - __main__ - Step 440 Global step 440 Train loss 0.23 on epoch=109
06/13/2022 11:37:41 - INFO - __main__ - Step 450 Global step 450 Train loss 0.20 on epoch=112
06/13/2022 11:37:42 - INFO - __main__ - Global step 450 Train loss 0.23 Classification-F1 0.7460945600331789 on epoch=112
06/13/2022 11:37:42 - INFO - __main__ - Saving model with best Classification-F1: 0.7391583202279297 -> 0.7460945600331789 on epoch=112, global_step=450
06/13/2022 11:37:44 - INFO - __main__ - Step 460 Global step 460 Train loss 0.17 on epoch=114
06/13/2022 11:37:46 - INFO - __main__ - Step 470 Global step 470 Train loss 0.23 on epoch=117
06/13/2022 11:37:49 - INFO - __main__ - Step 480 Global step 480 Train loss 0.14 on epoch=119
06/13/2022 11:37:51 - INFO - __main__ - Step 490 Global step 490 Train loss 0.17 on epoch=122
06/13/2022 11:37:54 - INFO - __main__ - Step 500 Global step 500 Train loss 0.20 on epoch=124
06/13/2022 11:37:54 - INFO - __main__ - Global step 500 Train loss 0.18 Classification-F1 0.7174868718986366 on epoch=124
06/13/2022 11:37:57 - INFO - __main__ - Step 510 Global step 510 Train loss 0.17 on epoch=127
06/13/2022 11:37:59 - INFO - __main__ - Step 520 Global step 520 Train loss 0.15 on epoch=129
06/13/2022 11:38:02 - INFO - __main__ - Step 530 Global step 530 Train loss 0.23 on epoch=132
06/13/2022 11:38:04 - INFO - __main__ - Step 540 Global step 540 Train loss 0.13 on epoch=134
06/13/2022 11:38:07 - INFO - __main__ - Step 550 Global step 550 Train loss 0.20 on epoch=137
06/13/2022 11:38:08 - INFO - __main__ - Global step 550 Train loss 0.18 Classification-F1 0.7386535033593857 on epoch=137
06/13/2022 11:38:10 - INFO - __main__ - Step 560 Global step 560 Train loss 0.11 on epoch=139
06/13/2022 11:38:12 - INFO - __main__ - Step 570 Global step 570 Train loss 0.11 on epoch=142
06/13/2022 11:38:15 - INFO - __main__ - Step 580 Global step 580 Train loss 0.19 on epoch=144
06/13/2022 11:38:17 - INFO - __main__ - Step 590 Global step 590 Train loss 0.16 on epoch=147
06/13/2022 11:38:20 - INFO - __main__ - Step 600 Global step 600 Train loss 0.11 on epoch=149
06/13/2022 11:38:21 - INFO - __main__ - Global step 600 Train loss 0.14 Classification-F1 0.719903304580724 on epoch=149
06/13/2022 11:38:23 - INFO - __main__ - Step 610 Global step 610 Train loss 0.09 on epoch=152
06/13/2022 11:38:25 - INFO - __main__ - Step 620 Global step 620 Train loss 0.11 on epoch=154
06/13/2022 11:38:28 - INFO - __main__ - Step 630 Global step 630 Train loss 0.15 on epoch=157
06/13/2022 11:38:30 - INFO - __main__ - Step 640 Global step 640 Train loss 0.14 on epoch=159
06/13/2022 11:38:33 - INFO - __main__ - Step 650 Global step 650 Train loss 0.11 on epoch=162
06/13/2022 11:38:34 - INFO - __main__ - Global step 650 Train loss 0.12 Classification-F1 0.7472249034749034 on epoch=162
06/13/2022 11:38:34 - INFO - __main__ - Saving model with best Classification-F1: 0.7460945600331789 -> 0.7472249034749034 on epoch=162, global_step=650
06/13/2022 11:38:36 - INFO - __main__ - Step 660 Global step 660 Train loss 0.11 on epoch=164
06/13/2022 11:38:39 - INFO - __main__ - Step 670 Global step 670 Train loss 0.06 on epoch=167
06/13/2022 11:38:41 - INFO - __main__ - Step 680 Global step 680 Train loss 0.08 on epoch=169
06/13/2022 11:38:43 - INFO - __main__ - Step 690 Global step 690 Train loss 0.08 on epoch=172
06/13/2022 11:38:46 - INFO - __main__ - Step 700 Global step 700 Train loss 0.09 on epoch=174
06/13/2022 11:38:47 - INFO - __main__ - Global step 700 Train loss 0.08 Classification-F1 0.7472249034749034 on epoch=174
06/13/2022 11:38:49 - INFO - __main__ - Step 710 Global step 710 Train loss 0.10 on epoch=177
06/13/2022 11:38:52 - INFO - __main__ - Step 720 Global step 720 Train loss 0.10 on epoch=179
06/13/2022 11:38:54 - INFO - __main__ - Step 730 Global step 730 Train loss 0.07 on epoch=182
06/13/2022 11:38:56 - INFO - __main__ - Step 740 Global step 740 Train loss 0.07 on epoch=184
06/13/2022 11:38:59 - INFO - __main__ - Step 750 Global step 750 Train loss 0.10 on epoch=187
06/13/2022 11:39:00 - INFO - __main__ - Global step 750 Train loss 0.09 Classification-F1 0.7035562476738947 on epoch=187
06/13/2022 11:39:02 - INFO - __main__ - Step 760 Global step 760 Train loss 0.06 on epoch=189
06/13/2022 11:39:05 - INFO - __main__ - Step 770 Global step 770 Train loss 0.12 on epoch=192
06/13/2022 11:39:07 - INFO - __main__ - Step 780 Global step 780 Train loss 0.05 on epoch=194
06/13/2022 11:39:09 - INFO - __main__ - Step 790 Global step 790 Train loss 0.10 on epoch=197
06/13/2022 11:39:12 - INFO - __main__ - Step 800 Global step 800 Train loss 0.07 on epoch=199
06/13/2022 11:39:13 - INFO - __main__ - Global step 800 Train loss 0.08 Classification-F1 0.7259418927754169 on epoch=199
06/13/2022 11:39:15 - INFO - __main__ - Step 810 Global step 810 Train loss 0.10 on epoch=202
06/13/2022 11:39:18 - INFO - __main__ - Step 820 Global step 820 Train loss 0.07 on epoch=204
06/13/2022 11:39:20 - INFO - __main__ - Step 830 Global step 830 Train loss 0.09 on epoch=207
06/13/2022 11:39:22 - INFO - __main__ - Step 840 Global step 840 Train loss 0.05 on epoch=209
06/13/2022 11:39:25 - INFO - __main__ - Step 850 Global step 850 Train loss 0.08 on epoch=212
06/13/2022 11:39:26 - INFO - __main__ - Global step 850 Train loss 0.08 Classification-F1 0.7517570664629488 on epoch=212
06/13/2022 11:39:26 - INFO - __main__ - Saving model with best Classification-F1: 0.7472249034749034 -> 0.7517570664629488 on epoch=212, global_step=850
06/13/2022 11:39:28 - INFO - __main__ - Step 860 Global step 860 Train loss 0.05 on epoch=214
06/13/2022 11:39:30 - INFO - __main__ - Step 870 Global step 870 Train loss 0.05 on epoch=217
06/13/2022 11:39:33 - INFO - __main__ - Step 880 Global step 880 Train loss 0.04 on epoch=219
06/13/2022 11:39:35 - INFO - __main__ - Step 890 Global step 890 Train loss 0.03 on epoch=222
06/13/2022 11:39:38 - INFO - __main__ - Step 900 Global step 900 Train loss 0.04 on epoch=224
06/13/2022 11:39:39 - INFO - __main__ - Global step 900 Train loss 0.04 Classification-F1 0.7517570664629488 on epoch=224
06/13/2022 11:39:41 - INFO - __main__ - Step 910 Global step 910 Train loss 0.05 on epoch=227
06/13/2022 11:39:43 - INFO - __main__ - Step 920 Global step 920 Train loss 0.05 on epoch=229
06/13/2022 11:39:46 - INFO - __main__ - Step 930 Global step 930 Train loss 0.10 on epoch=232
06/13/2022 11:39:48 - INFO - __main__ - Step 940 Global step 940 Train loss 0.12 on epoch=234
06/13/2022 11:39:51 - INFO - __main__ - Step 950 Global step 950 Train loss 0.07 on epoch=237
06/13/2022 11:39:52 - INFO - __main__ - Global step 950 Train loss 0.08 Classification-F1 0.7517570664629488 on epoch=237
06/13/2022 11:39:54 - INFO - __main__ - Step 960 Global step 960 Train loss 0.02 on epoch=239
06/13/2022 11:39:57 - INFO - __main__ - Step 970 Global step 970 Train loss 0.08 on epoch=242
06/13/2022 11:39:59 - INFO - __main__ - Step 980 Global step 980 Train loss 0.03 on epoch=244
06/13/2022 11:40:02 - INFO - __main__ - Step 990 Global step 990 Train loss 0.03 on epoch=247
06/13/2022 11:40:04 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.03 on epoch=249
06/13/2022 11:40:05 - INFO - __main__ - Global step 1000 Train loss 0.04 Classification-F1 0.7407671410565474 on epoch=249
06/13/2022 11:40:07 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.02 on epoch=252
06/13/2022 11:40:10 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.03 on epoch=254
06/13/2022 11:40:12 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.03 on epoch=257
06/13/2022 11:40:15 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.09 on epoch=259
06/13/2022 11:40:17 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.04 on epoch=262
06/13/2022 11:40:18 - INFO - __main__ - Global step 1050 Train loss 0.04 Classification-F1 0.7125517897576721 on epoch=262
06/13/2022 11:40:20 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.05 on epoch=264
06/13/2022 11:40:23 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.02 on epoch=267
06/13/2022 11:40:25 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.02 on epoch=269
06/13/2022 11:40:28 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.01 on epoch=272
06/13/2022 11:40:30 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.03 on epoch=274
06/13/2022 11:40:31 - INFO - __main__ - Global step 1100 Train loss 0.03 Classification-F1 0.7386535033593857 on epoch=274
06/13/2022 11:40:34 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.07 on epoch=277
06/13/2022 11:40:36 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.07 on epoch=279
06/13/2022 11:40:38 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=282
06/13/2022 11:40:41 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.01 on epoch=284
06/13/2022 11:40:43 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.02 on epoch=287
06/13/2022 11:40:44 - INFO - __main__ - Global step 1150 Train loss 0.04 Classification-F1 0.7378258995906055 on epoch=287
06/13/2022 11:40:47 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.04 on epoch=289
06/13/2022 11:40:49 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.01 on epoch=292
06/13/2022 11:40:52 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.01 on epoch=294
06/13/2022 11:40:54 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.04 on epoch=297
06/13/2022 11:40:56 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.04 on epoch=299
06/13/2022 11:40:57 - INFO - __main__ - Global step 1200 Train loss 0.03 Classification-F1 0.7517570664629488 on epoch=299
06/13/2022 11:41:00 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.03 on epoch=302
06/13/2022 11:41:02 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.03 on epoch=304
06/13/2022 11:41:05 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.02 on epoch=307
06/13/2022 11:41:07 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.06 on epoch=309
06/13/2022 11:41:09 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.06 on epoch=312
06/13/2022 11:41:10 - INFO - __main__ - Global step 1250 Train loss 0.04 Classification-F1 0.6819327731092437 on epoch=312
06/13/2022 11:41:13 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.02 on epoch=314
06/13/2022 11:41:15 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.01 on epoch=317
06/13/2022 11:41:17 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.02 on epoch=319
06/13/2022 11:41:20 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.05 on epoch=322
06/13/2022 11:41:22 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.03 on epoch=324
06/13/2022 11:41:23 - INFO - __main__ - Global step 1300 Train loss 0.03 Classification-F1 0.7517570664629488 on epoch=324
06/13/2022 11:41:26 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=327
06/13/2022 11:41:28 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=329
06/13/2022 11:41:30 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.05 on epoch=332
06/13/2022 11:41:33 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=334
06/13/2022 11:41:35 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=337
06/13/2022 11:41:36 - INFO - __main__ - Global step 1350 Train loss 0.02 Classification-F1 0.7378258995906055 on epoch=337
06/13/2022 11:41:39 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.11 on epoch=339
06/13/2022 11:41:41 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.02 on epoch=342
06/13/2022 11:41:44 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=344
06/13/2022 11:41:46 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=347
06/13/2022 11:41:48 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=349
06/13/2022 11:41:49 - INFO - __main__ - Global step 1400 Train loss 0.03 Classification-F1 0.7365841073271414 on epoch=349
06/13/2022 11:41:52 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.07 on epoch=352
06/13/2022 11:41:54 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.01 on epoch=354
06/13/2022 11:41:56 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.02 on epoch=357
06/13/2022 11:41:59 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=359
06/13/2022 11:42:01 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=362
06/13/2022 11:42:02 - INFO - __main__ - Global step 1450 Train loss 0.02 Classification-F1 0.7229936200524436 on epoch=362
06/13/2022 11:42:05 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=364
06/13/2022 11:42:07 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.06 on epoch=367
06/13/2022 11:42:09 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.04 on epoch=369
06/13/2022 11:42:12 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.03 on epoch=372
06/13/2022 11:42:14 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=374
06/13/2022 11:42:15 - INFO - __main__ - Global step 1500 Train loss 0.03 Classification-F1 0.6836134453781513 on epoch=374
06/13/2022 11:42:18 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=377
06/13/2022 11:42:20 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.03 on epoch=379
06/13/2022 11:42:22 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.02 on epoch=382
06/13/2022 11:42:25 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=384
06/13/2022 11:42:27 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=387
06/13/2022 11:42:28 - INFO - __main__ - Global step 1550 Train loss 0.02 Classification-F1 0.7108419160848829 on epoch=387
06/13/2022 11:42:31 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.02 on epoch=389
06/13/2022 11:42:33 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.04 on epoch=392
06/13/2022 11:42:35 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=394
06/13/2022 11:42:38 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=397
06/13/2022 11:42:40 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.03 on epoch=399
06/13/2022 11:42:41 - INFO - __main__ - Global step 1600 Train loss 0.02 Classification-F1 0.7243174781874473 on epoch=399
06/13/2022 11:42:44 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=402
06/13/2022 11:42:46 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.02 on epoch=404
06/13/2022 11:42:48 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=407
06/13/2022 11:42:51 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=409
06/13/2022 11:42:53 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=412
06/13/2022 11:42:54 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.7108419160848829 on epoch=412
06/13/2022 11:42:56 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=414
06/13/2022 11:42:59 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=417
06/13/2022 11:43:01 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=419
06/13/2022 11:43:03 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=422
06/13/2022 11:43:06 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=424
06/13/2022 11:43:07 - INFO - __main__ - Global step 1700 Train loss 0.00 Classification-F1 0.7243174781874473 on epoch=424
06/13/2022 11:43:09 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.04 on epoch=427
06/13/2022 11:43:11 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=429
06/13/2022 11:43:14 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.04 on epoch=432
06/13/2022 11:43:16 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=434
06/13/2022 11:43:19 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=437
06/13/2022 11:43:19 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.7378258995906055 on epoch=437
06/13/2022 11:43:22 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=439
06/13/2022 11:43:24 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.03 on epoch=442
06/13/2022 11:43:27 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=444
06/13/2022 11:43:29 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.04 on epoch=447
06/13/2022 11:43:31 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=449
06/13/2022 11:43:32 - INFO - __main__ - Global step 1800 Train loss 0.02 Classification-F1 0.7378258995906055 on epoch=449
06/13/2022 11:43:35 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=452
06/13/2022 11:43:37 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=454
06/13/2022 11:43:39 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=457
06/13/2022 11:43:42 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=459
06/13/2022 11:43:44 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.08 on epoch=462
06/13/2022 11:43:45 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.7108419160848829 on epoch=462
06/13/2022 11:43:48 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=464
06/13/2022 11:43:50 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=467
06/13/2022 11:43:52 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=469
06/13/2022 11:43:55 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=472
06/13/2022 11:43:57 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=474
06/13/2022 11:43:58 - INFO - __main__ - Global step 1900 Train loss 0.00 Classification-F1 0.7378258995906055 on epoch=474
06/13/2022 11:44:00 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=477
06/13/2022 11:44:03 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=479
06/13/2022 11:44:05 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=482
06/13/2022 11:44:08 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=484
06/13/2022 11:44:10 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=487
06/13/2022 11:44:11 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.7378258995906055 on epoch=487
06/13/2022 11:44:13 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=489
06/13/2022 11:44:16 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=492
06/13/2022 11:44:18 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=494
06/13/2022 11:44:21 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=497
06/13/2022 11:44:23 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=499
06/13/2022 11:44:24 - INFO - __main__ - Global step 2000 Train loss 0.00 Classification-F1 0.7535078055612489 on epoch=499
06/13/2022 11:44:24 - INFO - __main__ - Saving model with best Classification-F1: 0.7517570664629488 -> 0.7535078055612489 on epoch=499, global_step=2000
06/13/2022 11:44:26 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=502
06/13/2022 11:44:29 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.03 on epoch=504
06/13/2022 11:44:31 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/13/2022 11:44:34 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=509
06/13/2022 11:44:36 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/13/2022 11:44:37 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.7365841073271414 on epoch=512
06/13/2022 11:44:40 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=514
06/13/2022 11:44:42 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.03 on epoch=517
06/13/2022 11:44:44 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/13/2022 11:44:47 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=522
06/13/2022 11:44:49 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/13/2022 11:44:50 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.7392570664629489 on epoch=524
06/13/2022 11:44:53 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=527
06/13/2022 11:44:55 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=529
06/13/2022 11:44:57 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/13/2022 11:45:00 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
06/13/2022 11:45:02 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
06/13/2022 11:45:03 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.725832990538873 on epoch=537
06/13/2022 11:45:06 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/13/2022 11:45:08 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/13/2022 11:45:10 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.04 on epoch=544
06/13/2022 11:45:13 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/13/2022 11:45:15 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/13/2022 11:45:16 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.7378258995906055 on epoch=549
06/13/2022 11:45:19 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=552
06/13/2022 11:45:21 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/13/2022 11:45:23 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
06/13/2022 11:45:26 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/13/2022 11:45:28 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=562
06/13/2022 11:45:29 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.7365841073271414 on epoch=562
06/13/2022 11:45:32 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=564
06/13/2022 11:45:34 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/13/2022 11:45:37 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/13/2022 11:45:39 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/13/2022 11:45:41 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.11 on epoch=574
06/13/2022 11:45:42 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.7278313986348419 on epoch=574
06/13/2022 11:45:45 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/13/2022 11:45:47 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/13/2022 11:45:49 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=582
06/13/2022 11:45:52 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.08 on epoch=584
06/13/2022 11:45:54 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=587
06/13/2022 11:45:55 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.7229936200524436 on epoch=587
06/13/2022 11:45:58 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/13/2022 11:46:00 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/13/2022 11:46:02 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.06 on epoch=594
06/13/2022 11:46:05 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/13/2022 11:46:07 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/13/2022 11:46:08 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.7124757595345831 on epoch=599
06/13/2022 11:46:11 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=602
06/13/2022 11:46:13 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/13/2022 11:46:15 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=607
06/13/2022 11:46:18 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/13/2022 11:46:20 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=612
06/13/2022 11:46:21 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.7264069264069265 on epoch=612
06/13/2022 11:46:23 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/13/2022 11:46:26 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=617
06/13/2022 11:46:28 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/13/2022 11:46:31 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/13/2022 11:46:33 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/13/2022 11:46:34 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.7229936200524436 on epoch=624
06/13/2022 11:46:36 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=627
06/13/2022 11:46:39 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.05 on epoch=629
06/13/2022 11:46:41 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/13/2022 11:46:43 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/13/2022 11:46:46 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=637
06/13/2022 11:46:47 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.6996166887807755 on epoch=637
06/13/2022 11:46:49 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/13/2022 11:46:52 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=642
06/13/2022 11:46:54 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/13/2022 11:46:57 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/13/2022 11:46:59 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/13/2022 11:47:00 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.7229936200524436 on epoch=649
06/13/2022 11:47:02 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/13/2022 11:47:05 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=654
06/13/2022 11:47:07 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/13/2022 11:47:10 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/13/2022 11:47:12 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=662
06/13/2022 11:47:13 - INFO - __main__ - Global step 2650 Train loss 0.00 Classification-F1 0.7229936200524436 on epoch=662
06/13/2022 11:47:16 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/13/2022 11:47:18 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/13/2022 11:47:21 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=669
06/13/2022 11:47:23 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/13/2022 11:47:25 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=674
06/13/2022 11:47:26 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.7229936200524436 on epoch=674
06/13/2022 11:47:29 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/13/2022 11:47:31 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/13/2022 11:47:34 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/13/2022 11:47:36 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/13/2022 11:47:38 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=687
06/13/2022 11:47:39 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.7365841073271414 on epoch=687
06/13/2022 11:47:42 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/13/2022 11:47:44 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/13/2022 11:47:47 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/13/2022 11:47:49 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/13/2022 11:47:52 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=699
06/13/2022 11:47:53 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.7229936200524436 on epoch=699
06/13/2022 11:47:55 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=702
06/13/2022 11:47:57 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/13/2022 11:48:00 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=707
06/13/2022 11:48:02 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=709
06/13/2022 11:48:05 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/13/2022 11:48:06 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.7094192749563595 on epoch=712
06/13/2022 11:48:08 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=714
06/13/2022 11:48:11 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.03 on epoch=717
06/13/2022 11:48:13 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=719
06/13/2022 11:48:15 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/13/2022 11:48:18 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/13/2022 11:48:19 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.7365841073271414 on epoch=724
06/13/2022 11:48:21 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/13/2022 11:48:23 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/13/2022 11:48:26 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/13/2022 11:48:28 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/13/2022 11:48:31 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/13/2022 11:48:31 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.7094192749563595 on epoch=737
06/13/2022 11:48:34 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/13/2022 11:48:36 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/13/2022 11:48:39 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/13/2022 11:48:41 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/13/2022 11:48:44 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.03 on epoch=749
06/13/2022 11:48:45 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.7365841073271414 on epoch=749
06/13/2022 11:48:45 - INFO - __main__ - save last model!
06/13/2022 11:48:45 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/13/2022 11:48:45 - INFO - __main__ - Start tokenizing ... 5509 instances
06/13/2022 11:48:45 - INFO - __main__ - Printing 3 examples
06/13/2022 11:48:45 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/13/2022 11:48:45 - INFO - __main__ - ['others']
06/13/2022 11:48:45 - INFO - __main__ -  [emo] what you like very little things ok
06/13/2022 11:48:45 - INFO - __main__ - ['others']
06/13/2022 11:48:45 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/13/2022 11:48:45 - INFO - __main__ - ['others']
06/13/2022 11:48:45 - INFO - __main__ - Tokenizing Input ...
06/13/2022 11:48:45 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 11:48:45 - INFO - __main__ - Printing 3 examples
06/13/2022 11:48:45 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/13/2022 11:48:45 - INFO - __main__ - ['others']
06/13/2022 11:48:45 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/13/2022 11:48:45 - INFO - __main__ - ['others']
06/13/2022 11:48:45 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/13/2022 11:48:45 - INFO - __main__ - ['others']
06/13/2022 11:48:45 - INFO - __main__ - Tokenizing Input ...
06/13/2022 11:48:45 - INFO - __main__ - Tokenizing Output ...
06/13/2022 11:48:45 - INFO - __main__ - Loaded 64 examples from train data
06/13/2022 11:48:45 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 11:48:45 - INFO - __main__ - Printing 3 examples
06/13/2022 11:48:45 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
06/13/2022 11:48:45 - INFO - __main__ - ['others']
06/13/2022 11:48:45 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
06/13/2022 11:48:45 - INFO - __main__ - ['others']
06/13/2022 11:48:45 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
06/13/2022 11:48:45 - INFO - __main__ - ['others']
06/13/2022 11:48:45 - INFO - __main__ - Tokenizing Input ...
06/13/2022 11:48:45 - INFO - __main__ - Tokenizing Output ...
06/13/2022 11:48:45 - INFO - __main__ - Loaded 64 examples from dev data
06/13/2022 11:48:47 - INFO - __main__ - Tokenizing Output ...
06/13/2022 11:48:52 - INFO - __main__ - Loaded 5509 examples from test data
06/13/2022 11:49:04 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 11:49:05 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 11:49:05 - INFO - __main__ - Starting training!
06/13/2022 11:50:29 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-up32shot/singletask-emo/emo_16_87_0.4_8_predictions.txt
06/13/2022 11:50:29 - INFO - __main__ - Classification-F1 on test data: 0.3055
06/13/2022 11:50:29 - INFO - __main__ - prefix=emo_16_87, lr=0.4, bsz=8, dev_performance=0.7535078055612489, test_performance=0.3055282918855763
06/13/2022 11:50:29 - INFO - __main__ - Running ... prefix=emo_16_87, lr=0.3, bsz=8 ...
06/13/2022 11:50:30 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 11:50:30 - INFO - __main__ - Printing 3 examples
06/13/2022 11:50:30 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/13/2022 11:50:30 - INFO - __main__ - ['others']
06/13/2022 11:50:30 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/13/2022 11:50:30 - INFO - __main__ - ['others']
06/13/2022 11:50:30 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/13/2022 11:50:30 - INFO - __main__ - ['others']
06/13/2022 11:50:30 - INFO - __main__ - Tokenizing Input ...
06/13/2022 11:50:30 - INFO - __main__ - Tokenizing Output ...
06/13/2022 11:50:30 - INFO - __main__ - Loaded 64 examples from train data
06/13/2022 11:50:30 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 11:50:30 - INFO - __main__ - Printing 3 examples
06/13/2022 11:50:30 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
06/13/2022 11:50:30 - INFO - __main__ - ['others']
06/13/2022 11:50:30 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
06/13/2022 11:50:30 - INFO - __main__ - ['others']
06/13/2022 11:50:30 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
06/13/2022 11:50:30 - INFO - __main__ - ['others']
06/13/2022 11:50:30 - INFO - __main__ - Tokenizing Input ...
06/13/2022 11:50:30 - INFO - __main__ - Tokenizing Output ...
06/13/2022 11:50:31 - INFO - __main__ - Loaded 64 examples from dev data
06/13/2022 11:50:46 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 11:50:47 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 11:50:47 - INFO - __main__ - Starting training!
06/13/2022 11:50:50 - INFO - __main__ - Step 10 Global step 10 Train loss 3.96 on epoch=2
06/13/2022 11:50:52 - INFO - __main__ - Step 20 Global step 20 Train loss 2.72 on epoch=4
06/13/2022 11:50:55 - INFO - __main__ - Step 30 Global step 30 Train loss 2.07 on epoch=7
06/13/2022 11:50:57 - INFO - __main__ - Step 40 Global step 40 Train loss 1.65 on epoch=9
06/13/2022 11:51:00 - INFO - __main__ - Step 50 Global step 50 Train loss 1.41 on epoch=12
06/13/2022 11:51:01 - INFO - __main__ - Global step 50 Train loss 2.36 Classification-F1 0.09371833839918946 on epoch=12
06/13/2022 11:51:01 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.09371833839918946 on epoch=12, global_step=50
06/13/2022 11:51:03 - INFO - __main__ - Step 60 Global step 60 Train loss 1.25 on epoch=14
06/13/2022 11:51:06 - INFO - __main__ - Step 70 Global step 70 Train loss 1.10 on epoch=17
06/13/2022 11:51:08 - INFO - __main__ - Step 80 Global step 80 Train loss 0.86 on epoch=19
06/13/2022 11:51:10 - INFO - __main__ - Step 90 Global step 90 Train loss 0.79 on epoch=22
06/13/2022 11:51:13 - INFO - __main__ - Step 100 Global step 100 Train loss 0.76 on epoch=24
06/13/2022 11:51:14 - INFO - __main__ - Global step 100 Train loss 0.95 Classification-F1 0.4238915470494418 on epoch=24
06/13/2022 11:51:14 - INFO - __main__ - Saving model with best Classification-F1: 0.09371833839918946 -> 0.4238915470494418 on epoch=24, global_step=100
06/13/2022 11:51:16 - INFO - __main__ - Step 110 Global step 110 Train loss 0.77 on epoch=27
06/13/2022 11:51:19 - INFO - __main__ - Step 120 Global step 120 Train loss 0.67 on epoch=29
06/13/2022 11:51:21 - INFO - __main__ - Step 130 Global step 130 Train loss 0.70 on epoch=32
06/13/2022 11:51:24 - INFO - __main__ - Step 140 Global step 140 Train loss 0.58 on epoch=34
06/13/2022 11:51:26 - INFO - __main__ - Step 150 Global step 150 Train loss 0.59 on epoch=37
06/13/2022 11:51:27 - INFO - __main__ - Global step 150 Train loss 0.66 Classification-F1 0.5495787995787995 on epoch=37
06/13/2022 11:51:27 - INFO - __main__ - Saving model with best Classification-F1: 0.4238915470494418 -> 0.5495787995787995 on epoch=37, global_step=150
06/13/2022 11:51:29 - INFO - __main__ - Step 160 Global step 160 Train loss 0.63 on epoch=39
06/13/2022 11:51:32 - INFO - __main__ - Step 170 Global step 170 Train loss 0.66 on epoch=42
06/13/2022 11:51:34 - INFO - __main__ - Step 180 Global step 180 Train loss 0.57 on epoch=44
06/13/2022 11:51:37 - INFO - __main__ - Step 190 Global step 190 Train loss 0.58 on epoch=47
06/13/2022 11:51:39 - INFO - __main__ - Step 200 Global step 200 Train loss 0.52 on epoch=49
06/13/2022 11:51:40 - INFO - __main__ - Global step 200 Train loss 0.59 Classification-F1 0.5876461988304094 on epoch=49
06/13/2022 11:51:40 - INFO - __main__ - Saving model with best Classification-F1: 0.5495787995787995 -> 0.5876461988304094 on epoch=49, global_step=200
06/13/2022 11:51:43 - INFO - __main__ - Step 210 Global step 210 Train loss 0.48 on epoch=52
06/13/2022 11:51:45 - INFO - __main__ - Step 220 Global step 220 Train loss 0.62 on epoch=54
06/13/2022 11:51:47 - INFO - __main__ - Step 230 Global step 230 Train loss 0.54 on epoch=57
06/13/2022 11:51:50 - INFO - __main__ - Step 240 Global step 240 Train loss 0.48 on epoch=59
06/13/2022 11:51:52 - INFO - __main__ - Step 250 Global step 250 Train loss 0.55 on epoch=62
06/13/2022 11:51:53 - INFO - __main__ - Global step 250 Train loss 0.53 Classification-F1 0.5876461988304094 on epoch=62
06/13/2022 11:51:56 - INFO - __main__ - Step 260 Global step 260 Train loss 0.45 on epoch=64
06/13/2022 11:51:58 - INFO - __main__ - Step 270 Global step 270 Train loss 0.50 on epoch=67
06/13/2022 11:52:01 - INFO - __main__ - Step 280 Global step 280 Train loss 0.49 on epoch=69
06/13/2022 11:52:03 - INFO - __main__ - Step 290 Global step 290 Train loss 0.42 on epoch=72
06/13/2022 11:52:06 - INFO - __main__ - Step 300 Global step 300 Train loss 0.42 on epoch=74
06/13/2022 11:52:07 - INFO - __main__ - Global step 300 Train loss 0.46 Classification-F1 0.585648551175227 on epoch=74
06/13/2022 11:52:09 - INFO - __main__ - Step 310 Global step 310 Train loss 0.49 on epoch=77
06/13/2022 11:52:11 - INFO - __main__ - Step 320 Global step 320 Train loss 0.38 on epoch=79
06/13/2022 11:52:14 - INFO - __main__ - Step 330 Global step 330 Train loss 0.36 on epoch=82
06/13/2022 11:52:16 - INFO - __main__ - Step 340 Global step 340 Train loss 0.34 on epoch=84
06/13/2022 11:52:19 - INFO - __main__ - Step 350 Global step 350 Train loss 0.38 on epoch=87
06/13/2022 11:52:20 - INFO - __main__ - Global step 350 Train loss 0.39 Classification-F1 0.6717840982546865 on epoch=87
06/13/2022 11:52:20 - INFO - __main__ - Saving model with best Classification-F1: 0.5876461988304094 -> 0.6717840982546865 on epoch=87, global_step=350
06/13/2022 11:52:22 - INFO - __main__ - Step 360 Global step 360 Train loss 0.37 on epoch=89
06/13/2022 11:52:25 - INFO - __main__ - Step 370 Global step 370 Train loss 0.39 on epoch=92
06/13/2022 11:52:27 - INFO - __main__ - Step 380 Global step 380 Train loss 0.34 on epoch=94
06/13/2022 11:52:30 - INFO - __main__ - Step 390 Global step 390 Train loss 0.36 on epoch=97
06/13/2022 11:52:32 - INFO - __main__ - Step 400 Global step 400 Train loss 0.33 on epoch=99
06/13/2022 11:52:33 - INFO - __main__ - Global step 400 Train loss 0.36 Classification-F1 0.6589330212187571 on epoch=99
06/13/2022 11:52:36 - INFO - __main__ - Step 410 Global step 410 Train loss 0.29 on epoch=102
06/13/2022 11:52:38 - INFO - __main__ - Step 420 Global step 420 Train loss 0.36 on epoch=104
06/13/2022 11:52:41 - INFO - __main__ - Step 430 Global step 430 Train loss 0.30 on epoch=107
06/13/2022 11:52:43 - INFO - __main__ - Step 440 Global step 440 Train loss 0.31 on epoch=109
06/13/2022 11:52:46 - INFO - __main__ - Step 450 Global step 450 Train loss 0.30 on epoch=112
06/13/2022 11:52:46 - INFO - __main__ - Global step 450 Train loss 0.31 Classification-F1 0.7093052232854864 on epoch=112
06/13/2022 11:52:46 - INFO - __main__ - Saving model with best Classification-F1: 0.6717840982546865 -> 0.7093052232854864 on epoch=112, global_step=450
06/13/2022 11:52:49 - INFO - __main__ - Step 460 Global step 460 Train loss 0.31 on epoch=114
06/13/2022 11:52:51 - INFO - __main__ - Step 470 Global step 470 Train loss 0.27 on epoch=117
06/13/2022 11:52:54 - INFO - __main__ - Step 480 Global step 480 Train loss 0.29 on epoch=119
06/13/2022 11:52:56 - INFO - __main__ - Step 490 Global step 490 Train loss 0.25 on epoch=122
06/13/2022 11:52:59 - INFO - __main__ - Step 500 Global step 500 Train loss 0.23 on epoch=124
06/13/2022 11:53:00 - INFO - __main__ - Global step 500 Train loss 0.27 Classification-F1 0.6852763242565874 on epoch=124
06/13/2022 11:53:02 - INFO - __main__ - Step 510 Global step 510 Train loss 0.28 on epoch=127
06/13/2022 11:53:05 - INFO - __main__ - Step 520 Global step 520 Train loss 0.17 on epoch=129
06/13/2022 11:53:07 - INFO - __main__ - Step 530 Global step 530 Train loss 0.34 on epoch=132
06/13/2022 11:53:09 - INFO - __main__ - Step 540 Global step 540 Train loss 0.23 on epoch=134
06/13/2022 11:53:12 - INFO - __main__ - Step 550 Global step 550 Train loss 0.23 on epoch=137
06/13/2022 11:53:13 - INFO - __main__ - Global step 550 Train loss 0.25 Classification-F1 0.6717840982546865 on epoch=137
06/13/2022 11:53:15 - INFO - __main__ - Step 560 Global step 560 Train loss 0.19 on epoch=139
06/13/2022 11:53:18 - INFO - __main__ - Step 570 Global step 570 Train loss 0.25 on epoch=142
06/13/2022 11:53:20 - INFO - __main__ - Step 580 Global step 580 Train loss 0.21 on epoch=144
06/13/2022 11:53:23 - INFO - __main__ - Step 590 Global step 590 Train loss 0.21 on epoch=147
06/13/2022 11:53:25 - INFO - __main__ - Step 600 Global step 600 Train loss 0.21 on epoch=149
06/13/2022 11:53:26 - INFO - __main__ - Global step 600 Train loss 0.22 Classification-F1 0.6724124692874693 on epoch=149
06/13/2022 11:53:28 - INFO - __main__ - Step 610 Global step 610 Train loss 0.23 on epoch=152
06/13/2022 11:53:31 - INFO - __main__ - Step 620 Global step 620 Train loss 0.15 on epoch=154
06/13/2022 11:53:33 - INFO - __main__ - Step 630 Global step 630 Train loss 0.16 on epoch=157
06/13/2022 11:53:36 - INFO - __main__ - Step 640 Global step 640 Train loss 0.14 on epoch=159
06/13/2022 11:53:38 - INFO - __main__ - Step 650 Global step 650 Train loss 0.14 on epoch=162
06/13/2022 11:53:39 - INFO - __main__ - Global step 650 Train loss 0.17 Classification-F1 0.6676796612280483 on epoch=162
06/13/2022 11:53:42 - INFO - __main__ - Step 660 Global step 660 Train loss 0.28 on epoch=164
06/13/2022 11:53:44 - INFO - __main__ - Step 670 Global step 670 Train loss 0.18 on epoch=167
06/13/2022 11:53:47 - INFO - __main__ - Step 680 Global step 680 Train loss 0.18 on epoch=169
06/13/2022 11:53:49 - INFO - __main__ - Step 690 Global step 690 Train loss 0.18 on epoch=172
06/13/2022 11:53:52 - INFO - __main__ - Step 700 Global step 700 Train loss 0.13 on epoch=174
06/13/2022 11:53:52 - INFO - __main__ - Global step 700 Train loss 0.19 Classification-F1 0.6724124692874693 on epoch=174
06/13/2022 11:53:55 - INFO - __main__ - Step 710 Global step 710 Train loss 0.12 on epoch=177
06/13/2022 11:53:57 - INFO - __main__ - Step 720 Global step 720 Train loss 0.11 on epoch=179
06/13/2022 11:54:00 - INFO - __main__ - Step 730 Global step 730 Train loss 0.08 on epoch=182
06/13/2022 11:54:02 - INFO - __main__ - Step 740 Global step 740 Train loss 0.25 on epoch=184
06/13/2022 11:54:05 - INFO - __main__ - Step 750 Global step 750 Train loss 0.12 on epoch=187
06/13/2022 11:54:06 - INFO - __main__ - Global step 750 Train loss 0.13 Classification-F1 0.6870393120393121 on epoch=187
06/13/2022 11:54:08 - INFO - __main__ - Step 760 Global step 760 Train loss 0.11 on epoch=189
06/13/2022 11:54:11 - INFO - __main__ - Step 770 Global step 770 Train loss 0.12 on epoch=192
06/13/2022 11:54:13 - INFO - __main__ - Step 780 Global step 780 Train loss 0.15 on epoch=194
06/13/2022 11:54:15 - INFO - __main__ - Step 790 Global step 790 Train loss 0.09 on epoch=197
06/13/2022 11:54:18 - INFO - __main__ - Step 800 Global step 800 Train loss 0.08 on epoch=199
06/13/2022 11:54:19 - INFO - __main__ - Global step 800 Train loss 0.11 Classification-F1 0.6861836080586081 on epoch=199
06/13/2022 11:54:21 - INFO - __main__ - Step 810 Global step 810 Train loss 0.08 on epoch=202
06/13/2022 11:54:24 - INFO - __main__ - Step 820 Global step 820 Train loss 0.06 on epoch=204
06/13/2022 11:54:26 - INFO - __main__ - Step 830 Global step 830 Train loss 0.11 on epoch=207
06/13/2022 11:54:29 - INFO - __main__ - Step 840 Global step 840 Train loss 0.11 on epoch=209
06/13/2022 11:54:31 - INFO - __main__ - Step 850 Global step 850 Train loss 0.07 on epoch=212
06/13/2022 11:54:32 - INFO - __main__ - Global step 850 Train loss 0.09 Classification-F1 0.6861836080586081 on epoch=212
06/13/2022 11:54:35 - INFO - __main__ - Step 860 Global step 860 Train loss 0.14 on epoch=214
06/13/2022 11:54:37 - INFO - __main__ - Step 870 Global step 870 Train loss 0.06 on epoch=217
06/13/2022 11:54:39 - INFO - __main__ - Step 880 Global step 880 Train loss 0.04 on epoch=219
06/13/2022 11:54:42 - INFO - __main__ - Step 890 Global step 890 Train loss 0.14 on epoch=222
06/13/2022 11:54:44 - INFO - __main__ - Step 900 Global step 900 Train loss 0.09 on epoch=224
06/13/2022 11:54:45 - INFO - __main__ - Global step 900 Train loss 0.09 Classification-F1 0.6809733120216992 on epoch=224
06/13/2022 11:54:48 - INFO - __main__ - Step 910 Global step 910 Train loss 0.10 on epoch=227
06/13/2022 11:54:50 - INFO - __main__ - Step 920 Global step 920 Train loss 0.12 on epoch=229
06/13/2022 11:54:53 - INFO - __main__ - Step 930 Global step 930 Train loss 0.05 on epoch=232
06/13/2022 11:54:55 - INFO - __main__ - Step 940 Global step 940 Train loss 0.07 on epoch=234
06/13/2022 11:54:58 - INFO - __main__ - Step 950 Global step 950 Train loss 0.10 on epoch=237
06/13/2022 11:54:58 - INFO - __main__ - Global step 950 Train loss 0.09 Classification-F1 0.697400274606157 on epoch=237
06/13/2022 11:55:01 - INFO - __main__ - Step 960 Global step 960 Train loss 0.10 on epoch=239
06/13/2022 11:55:03 - INFO - __main__ - Step 970 Global step 970 Train loss 0.06 on epoch=242
06/13/2022 11:55:06 - INFO - __main__ - Step 980 Global step 980 Train loss 0.05 on epoch=244
06/13/2022 11:55:08 - INFO - __main__ - Step 990 Global step 990 Train loss 0.08 on epoch=247
06/13/2022 11:55:11 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.05 on epoch=249
06/13/2022 11:55:12 - INFO - __main__ - Global step 1000 Train loss 0.07 Classification-F1 0.7234747875122589 on epoch=249
06/13/2022 11:55:12 - INFO - __main__ - Saving model with best Classification-F1: 0.7093052232854864 -> 0.7234747875122589 on epoch=249, global_step=1000
06/13/2022 11:55:14 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.12 on epoch=252
06/13/2022 11:55:17 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.05 on epoch=254
06/13/2022 11:55:19 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.08 on epoch=257
06/13/2022 11:55:22 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.04 on epoch=259
06/13/2022 11:55:24 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.02 on epoch=262
06/13/2022 11:55:25 - INFO - __main__ - Global step 1050 Train loss 0.06 Classification-F1 0.6959776334776335 on epoch=262
06/13/2022 11:55:27 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.07 on epoch=264
06/13/2022 11:55:30 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.03 on epoch=267
06/13/2022 11:55:32 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.04 on epoch=269
06/13/2022 11:55:35 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.03 on epoch=272
06/13/2022 11:55:37 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.04 on epoch=274
06/13/2022 11:55:38 - INFO - __main__ - Global step 1100 Train loss 0.04 Classification-F1 0.7229936200524436 on epoch=274
06/13/2022 11:55:41 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.06 on epoch=277
06/13/2022 11:55:43 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.05 on epoch=279
06/13/2022 11:55:46 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.03 on epoch=282
06/13/2022 11:55:48 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.04 on epoch=284
06/13/2022 11:55:51 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.10 on epoch=287
06/13/2022 11:55:52 - INFO - __main__ - Global step 1150 Train loss 0.06 Classification-F1 0.6957633053221289 on epoch=287
06/13/2022 11:55:54 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.05 on epoch=289
06/13/2022 11:55:56 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.04 on epoch=292
06/13/2022 11:55:59 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.03 on epoch=294
06/13/2022 11:56:01 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.03 on epoch=297
06/13/2022 11:56:04 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.07 on epoch=299
06/13/2022 11:56:05 - INFO - __main__ - Global step 1200 Train loss 0.05 Classification-F1 0.7091402526185135 on epoch=299
06/13/2022 11:56:07 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.02 on epoch=302
06/13/2022 11:56:10 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.03 on epoch=304
06/13/2022 11:56:12 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.05 on epoch=307
06/13/2022 11:56:15 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.02 on epoch=309
06/13/2022 11:56:17 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.04 on epoch=312
06/13/2022 11:56:18 - INFO - __main__ - Global step 1250 Train loss 0.03 Classification-F1 0.7232800982800983 on epoch=312
06/13/2022 11:56:20 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.02 on epoch=314
06/13/2022 11:56:23 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.01 on epoch=317
06/13/2022 11:56:25 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.14 on epoch=319
06/13/2022 11:56:28 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.03 on epoch=322
06/13/2022 11:56:30 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.02 on epoch=324
06/13/2022 11:56:31 - INFO - __main__ - Global step 1300 Train loss 0.04 Classification-F1 0.7365841073271414 on epoch=324
06/13/2022 11:56:31 - INFO - __main__ - Saving model with best Classification-F1: 0.7234747875122589 -> 0.7365841073271414 on epoch=324, global_step=1300
06/13/2022 11:56:34 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.05 on epoch=327
06/13/2022 11:56:36 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.03 on epoch=329
06/13/2022 11:56:39 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=332
06/13/2022 11:56:41 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.03 on epoch=334
06/13/2022 11:56:44 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.04 on epoch=337
06/13/2022 11:56:44 - INFO - __main__ - Global step 1350 Train loss 0.03 Classification-F1 0.7232800982800983 on epoch=337
06/13/2022 11:56:47 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.03 on epoch=339
06/13/2022 11:56:49 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.04 on epoch=342
06/13/2022 11:56:52 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.06 on epoch=344
06/13/2022 11:56:54 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.04 on epoch=347
06/13/2022 11:56:57 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=349
06/13/2022 11:56:58 - INFO - __main__ - Global step 1400 Train loss 0.04 Classification-F1 0.7229936200524436 on epoch=349
06/13/2022 11:57:00 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.02 on epoch=352
06/13/2022 11:57:03 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.01 on epoch=354
06/13/2022 11:57:05 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.03 on epoch=357
06/13/2022 11:57:08 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.04 on epoch=359
06/13/2022 11:57:10 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.03 on epoch=362
06/13/2022 11:57:11 - INFO - __main__ - Global step 1450 Train loss 0.03 Classification-F1 0.7229936200524436 on epoch=362
06/13/2022 11:57:14 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=364
06/13/2022 11:57:16 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=367
06/13/2022 11:57:19 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.03 on epoch=369
06/13/2022 11:57:21 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=372
06/13/2022 11:57:23 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.04 on epoch=374
06/13/2022 11:57:24 - INFO - __main__ - Global step 1500 Train loss 0.02 Classification-F1 0.7368705855547961 on epoch=374
06/13/2022 11:57:24 - INFO - __main__ - Saving model with best Classification-F1: 0.7365841073271414 -> 0.7368705855547961 on epoch=374, global_step=1500
06/13/2022 11:57:27 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.05 on epoch=377
06/13/2022 11:57:29 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.05 on epoch=379
06/13/2022 11:57:32 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.02 on epoch=382
06/13/2022 11:57:34 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=384
06/13/2022 11:57:37 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.06 on epoch=387
06/13/2022 11:57:38 - INFO - __main__ - Global step 1550 Train loss 0.04 Classification-F1 0.7229936200524436 on epoch=387
06/13/2022 11:57:40 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.02 on epoch=389
06/13/2022 11:57:43 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=392
06/13/2022 11:57:45 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.02 on epoch=394
06/13/2022 11:57:48 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=397
06/13/2022 11:57:50 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=399
06/13/2022 11:57:51 - INFO - __main__ - Global step 1600 Train loss 0.02 Classification-F1 0.7127622377622378 on epoch=399
06/13/2022 11:57:53 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=402
06/13/2022 11:57:56 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=404
06/13/2022 11:57:58 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.03 on epoch=407
06/13/2022 11:58:01 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=409
06/13/2022 11:58:03 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=412
06/13/2022 11:58:04 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.7232800982800983 on epoch=412
06/13/2022 11:58:07 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.07 on epoch=414
06/13/2022 11:58:09 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=417
06/13/2022 11:58:12 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=419
06/13/2022 11:58:14 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=422
06/13/2022 11:58:17 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=424
06/13/2022 11:58:18 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.7232800982800983 on epoch=424
06/13/2022 11:58:20 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=427
06/13/2022 11:58:22 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=429
06/13/2022 11:58:25 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=432
06/13/2022 11:58:27 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=434
06/13/2022 11:58:30 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=437
06/13/2022 11:58:31 - INFO - __main__ - Global step 1750 Train loss 0.01 Classification-F1 0.7229936200524436 on epoch=437
06/13/2022 11:58:33 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=439
06/13/2022 11:58:36 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=442
06/13/2022 11:58:38 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=444
06/13/2022 11:58:40 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=447
06/13/2022 11:58:43 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=449
06/13/2022 11:58:44 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.7365841073271414 on epoch=449
06/13/2022 11:58:46 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.05 on epoch=452
06/13/2022 11:58:49 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=454
06/13/2022 11:58:51 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=457
06/13/2022 11:58:54 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.04 on epoch=459
06/13/2022 11:58:56 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=462
06/13/2022 11:58:57 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.7229936200524436 on epoch=462
06/13/2022 11:59:00 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.04 on epoch=464
06/13/2022 11:59:02 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=467
06/13/2022 11:59:04 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=469
06/13/2022 11:59:07 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.03 on epoch=472
06/13/2022 11:59:09 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.09 on epoch=474
06/13/2022 11:59:10 - INFO - __main__ - Global step 1900 Train loss 0.04 Classification-F1 0.7232800982800983 on epoch=474
06/13/2022 11:59:13 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=477
06/13/2022 11:59:15 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.07 on epoch=479
06/13/2022 11:59:18 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=482
06/13/2022 11:59:20 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.05 on epoch=484
06/13/2022 11:59:23 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=487
06/13/2022 11:59:24 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.6986429707017943 on epoch=487
06/13/2022 11:59:26 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=489
06/13/2022 11:59:29 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.04 on epoch=492
06/13/2022 11:59:31 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=494
06/13/2022 11:59:33 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=497
06/13/2022 11:59:36 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=499
06/13/2022 11:59:37 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.6986429707017943 on epoch=499
06/13/2022 11:59:39 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=502
06/13/2022 11:59:42 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=504
06/13/2022 11:59:44 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=507
06/13/2022 11:59:47 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=509
06/13/2022 11:59:49 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.03 on epoch=512
06/13/2022 11:59:50 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.7115841073271414 on epoch=512
06/13/2022 11:59:53 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=514
06/13/2022 11:59:55 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=517
06/13/2022 11:59:57 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/13/2022 12:00:00 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=522
06/13/2022 12:00:02 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/13/2022 12:00:03 - INFO - __main__ - Global step 2100 Train loss 0.00 Classification-F1 0.6986429707017943 on epoch=524
06/13/2022 12:00:06 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.04 on epoch=527
06/13/2022 12:00:08 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=529
06/13/2022 12:00:11 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/13/2022 12:00:13 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=534
06/13/2022 12:00:16 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=537
06/13/2022 12:00:16 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.7229936200524436 on epoch=537
06/13/2022 12:00:19 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=539
06/13/2022 12:00:21 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=542
06/13/2022 12:00:24 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=544
06/13/2022 12:00:26 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=547
06/13/2022 12:00:29 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=549
06/13/2022 12:00:30 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.7229936200524436 on epoch=549
06/13/2022 12:00:32 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.03 on epoch=552
06/13/2022 12:00:35 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=554
06/13/2022 12:00:37 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=557
06/13/2022 12:00:39 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=559
06/13/2022 12:00:42 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=562
06/13/2022 12:00:43 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.7229936200524436 on epoch=562
06/13/2022 12:00:45 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=564
06/13/2022 12:00:48 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=567
06/13/2022 12:00:50 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=569
06/13/2022 12:00:53 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/13/2022 12:00:55 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/13/2022 12:00:56 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.7229936200524436 on epoch=574
06/13/2022 12:00:59 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=577
06/13/2022 12:01:01 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=579
06/13/2022 12:01:04 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=582
06/13/2022 12:01:06 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/13/2022 12:01:08 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=587
06/13/2022 12:01:09 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.7229936200524436 on epoch=587
06/13/2022 12:01:12 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=589
06/13/2022 12:01:14 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=592
06/13/2022 12:01:17 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/13/2022 12:01:19 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/13/2022 12:01:22 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/13/2022 12:01:22 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.7229936200524436 on epoch=599
06/13/2022 12:01:25 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=602
06/13/2022 12:01:27 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/13/2022 12:01:30 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.05 on epoch=607
06/13/2022 12:01:32 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=609
06/13/2022 12:01:35 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=612
06/13/2022 12:01:36 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.7232800982800983 on epoch=612
06/13/2022 12:01:38 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/13/2022 12:01:41 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=617
06/13/2022 12:01:43 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=619
06/13/2022 12:01:46 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=622
06/13/2022 12:01:48 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=624
06/13/2022 12:01:49 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.7365841073271414 on epoch=624
06/13/2022 12:01:51 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=627
06/13/2022 12:01:54 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/13/2022 12:01:56 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=632
06/13/2022 12:01:59 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/13/2022 12:02:01 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=637
06/13/2022 12:02:02 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.7232800982800983 on epoch=637
06/13/2022 12:02:05 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=639
06/13/2022 12:02:07 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=642
06/13/2022 12:02:10 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/13/2022 12:02:12 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=647
06/13/2022 12:02:15 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=649
06/13/2022 12:02:15 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.7169251336898397 on epoch=649
06/13/2022 12:02:18 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.05 on epoch=652
06/13/2022 12:02:20 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=654
06/13/2022 12:02:23 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/13/2022 12:02:25 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=659
06/13/2022 12:02:28 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/13/2022 12:02:29 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.7229936200524436 on epoch=662
06/13/2022 12:02:31 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/13/2022 12:02:34 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/13/2022 12:02:36 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/13/2022 12:02:39 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=672
06/13/2022 12:02:41 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/13/2022 12:02:42 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.7229936200524436 on epoch=674
06/13/2022 12:02:44 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.06 on epoch=677
06/13/2022 12:02:47 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/13/2022 12:02:49 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/13/2022 12:02:52 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=684
06/13/2022 12:02:54 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/13/2022 12:02:55 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.7450472942800309 on epoch=687
06/13/2022 12:02:55 - INFO - __main__ - Saving model with best Classification-F1: 0.7368705855547961 -> 0.7450472942800309 on epoch=687, global_step=2750
06/13/2022 12:02:58 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=689
06/13/2022 12:03:00 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/13/2022 12:03:03 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=694
06/13/2022 12:03:05 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/13/2022 12:03:08 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=699
06/13/2022 12:03:09 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.7229936200524436 on epoch=699
06/13/2022 12:03:11 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=702
06/13/2022 12:03:14 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=704
06/13/2022 12:03:16 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.05 on epoch=707
06/13/2022 12:03:18 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/13/2022 12:03:21 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/13/2022 12:03:22 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.722296494355318 on epoch=712
06/13/2022 12:03:24 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=714
06/13/2022 12:03:27 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/13/2022 12:03:29 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/13/2022 12:03:32 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/13/2022 12:03:34 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/13/2022 12:03:35 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.7229936200524436 on epoch=724
06/13/2022 12:03:37 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/13/2022 12:03:40 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/13/2022 12:03:42 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.03 on epoch=732
06/13/2022 12:03:45 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/13/2022 12:03:47 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=737
06/13/2022 12:03:48 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.6986429707017943 on epoch=737
06/13/2022 12:03:51 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/13/2022 12:03:53 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/13/2022 12:03:56 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=744
06/13/2022 12:03:58 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/13/2022 12:04:01 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/13/2022 12:04:01 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.6986429707017943 on epoch=749
06/13/2022 12:04:01 - INFO - __main__ - save last model!
06/13/2022 12:04:02 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/13/2022 12:04:02 - INFO - __main__ - Start tokenizing ... 5509 instances
06/13/2022 12:04:02 - INFO - __main__ - Printing 3 examples
06/13/2022 12:04:02 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/13/2022 12:04:02 - INFO - __main__ - ['others']
06/13/2022 12:04:02 - INFO - __main__ -  [emo] what you like very little things ok
06/13/2022 12:04:02 - INFO - __main__ - ['others']
06/13/2022 12:04:02 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/13/2022 12:04:02 - INFO - __main__ - ['others']
06/13/2022 12:04:02 - INFO - __main__ - Tokenizing Input ...
06/13/2022 12:04:02 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 12:04:02 - INFO - __main__ - Printing 3 examples
06/13/2022 12:04:02 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/13/2022 12:04:02 - INFO - __main__ - ['others']
06/13/2022 12:04:02 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/13/2022 12:04:02 - INFO - __main__ - ['others']
06/13/2022 12:04:02 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/13/2022 12:04:02 - INFO - __main__ - ['others']
06/13/2022 12:04:02 - INFO - __main__ - Tokenizing Input ...
06/13/2022 12:04:02 - INFO - __main__ - Tokenizing Output ...
06/13/2022 12:04:02 - INFO - __main__ - Loaded 64 examples from train data
06/13/2022 12:04:02 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 12:04:02 - INFO - __main__ - Printing 3 examples
06/13/2022 12:04:02 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
06/13/2022 12:04:02 - INFO - __main__ - ['others']
06/13/2022 12:04:02 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
06/13/2022 12:04:02 - INFO - __main__ - ['others']
06/13/2022 12:04:02 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
06/13/2022 12:04:02 - INFO - __main__ - ['others']
06/13/2022 12:04:02 - INFO - __main__ - Tokenizing Input ...
06/13/2022 12:04:02 - INFO - __main__ - Tokenizing Output ...
06/13/2022 12:04:02 - INFO - __main__ - Loaded 64 examples from dev data
06/13/2022 12:04:04 - INFO - __main__ - Tokenizing Output ...
06/13/2022 12:04:09 - INFO - __main__ - Loaded 5509 examples from test data
06/13/2022 12:04:18 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 12:04:18 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 12:04:18 - INFO - __main__ - Starting training!
06/13/2022 12:05:26 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-up32shot/singletask-emo/emo_16_87_0.3_8_predictions.txt
06/13/2022 12:05:26 - INFO - __main__ - Classification-F1 on test data: 0.1388
06/13/2022 12:05:27 - INFO - __main__ - prefix=emo_16_87, lr=0.3, bsz=8, dev_performance=0.7450472942800309, test_performance=0.13884259973736268
06/13/2022 12:05:27 - INFO - __main__ - Running ... prefix=emo_16_87, lr=0.2, bsz=8 ...
06/13/2022 12:05:28 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 12:05:28 - INFO - __main__ - Printing 3 examples
06/13/2022 12:05:28 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/13/2022 12:05:28 - INFO - __main__ - ['others']
06/13/2022 12:05:28 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/13/2022 12:05:28 - INFO - __main__ - ['others']
06/13/2022 12:05:28 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/13/2022 12:05:28 - INFO - __main__ - ['others']
06/13/2022 12:05:28 - INFO - __main__ - Tokenizing Input ...
06/13/2022 12:05:28 - INFO - __main__ - Tokenizing Output ...
06/13/2022 12:05:28 - INFO - __main__ - Loaded 64 examples from train data
06/13/2022 12:05:28 - INFO - __main__ - Start tokenizing ... 64 instances
06/13/2022 12:05:28 - INFO - __main__ - Printing 3 examples
06/13/2022 12:05:28 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
06/13/2022 12:05:28 - INFO - __main__ - ['others']
06/13/2022 12:05:28 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
06/13/2022 12:05:28 - INFO - __main__ - ['others']
06/13/2022 12:05:28 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
06/13/2022 12:05:28 - INFO - __main__ - ['others']
06/13/2022 12:05:28 - INFO - __main__ - Tokenizing Input ...
06/13/2022 12:05:28 - INFO - __main__ - Tokenizing Output ...
06/13/2022 12:05:28 - INFO - __main__ - Loaded 64 examples from dev data
06/13/2022 12:05:43 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 12:05:44 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 12:05:44 - INFO - __main__ - Starting training!
06/13/2022 12:05:47 - INFO - __main__ - Step 10 Global step 10 Train loss 4.01 on epoch=2
06/13/2022 12:05:49 - INFO - __main__ - Step 20 Global step 20 Train loss 3.03 on epoch=4
06/13/2022 12:05:52 - INFO - __main__ - Step 30 Global step 30 Train loss 2.53 on epoch=7
06/13/2022 12:05:54 - INFO - __main__ - Step 40 Global step 40 Train loss 2.24 on epoch=9
06/13/2022 12:05:57 - INFO - __main__ - Step 50 Global step 50 Train loss 1.85 on epoch=12
06/13/2022 12:05:58 - INFO - __main__ - Global step 50 Train loss 2.73 Classification-F1 0.06784188034188034 on epoch=12
06/13/2022 12:05:58 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.06784188034188034 on epoch=12, global_step=50
06/13/2022 12:06:00 - INFO - __main__ - Step 60 Global step 60 Train loss 1.65 on epoch=14
06/13/2022 12:06:03 - INFO - __main__ - Step 70 Global step 70 Train loss 1.40 on epoch=17
06/13/2022 12:06:05 - INFO - __main__ - Step 80 Global step 80 Train loss 1.50 on epoch=19
06/13/2022 12:06:07 - INFO - __main__ - Step 90 Global step 90 Train loss 1.11 on epoch=22
06/13/2022 12:06:10 - INFO - __main__ - Step 100 Global step 100 Train loss 0.99 on epoch=24
06/13/2022 12:06:11 - INFO - __main__ - Global step 100 Train loss 1.33 Classification-F1 0.255433338647112 on epoch=24
06/13/2022 12:06:11 - INFO - __main__ - Saving model with best Classification-F1: 0.06784188034188034 -> 0.255433338647112 on epoch=24, global_step=100
06/13/2022 12:06:13 - INFO - __main__ - Step 110 Global step 110 Train loss 0.83 on epoch=27
06/13/2022 12:06:16 - INFO - __main__ - Step 120 Global step 120 Train loss 0.89 on epoch=29
06/13/2022 12:06:18 - INFO - __main__ - Step 130 Global step 130 Train loss 0.83 on epoch=32
06/13/2022 12:06:21 - INFO - __main__ - Step 140 Global step 140 Train loss 0.76 on epoch=34
06/13/2022 12:06:23 - INFO - __main__ - Step 150 Global step 150 Train loss 0.63 on epoch=37
06/13/2022 12:06:24 - INFO - __main__ - Global step 150 Train loss 0.79 Classification-F1 0.4463414634146341 on epoch=37
06/13/2022 12:06:24 - INFO - __main__ - Saving model with best Classification-F1: 0.255433338647112 -> 0.4463414634146341 on epoch=37, global_step=150
06/13/2022 12:06:26 - INFO - __main__ - Step 160 Global step 160 Train loss 0.73 on epoch=39
06/13/2022 12:06:29 - INFO - __main__ - Step 170 Global step 170 Train loss 0.69 on epoch=42
06/13/2022 12:06:31 - INFO - __main__ - Step 180 Global step 180 Train loss 0.68 on epoch=44
06/13/2022 12:06:34 - INFO - __main__ - Step 190 Global step 190 Train loss 0.61 on epoch=47
06/13/2022 12:06:36 - INFO - __main__ - Step 200 Global step 200 Train loss 0.69 on epoch=49
06/13/2022 12:06:37 - INFO - __main__ - Global step 200 Train loss 0.68 Classification-F1 0.6129968203497616 on epoch=49
06/13/2022 12:06:37 - INFO - __main__ - Saving model with best Classification-F1: 0.4463414634146341 -> 0.6129968203497616 on epoch=49, global_step=200
06/13/2022 12:06:39 - INFO - __main__ - Step 210 Global step 210 Train loss 0.64 on epoch=52
06/13/2022 12:06:42 - INFO - __main__ - Step 220 Global step 220 Train loss 0.55 on epoch=54
06/13/2022 12:06:44 - INFO - __main__ - Step 230 Global step 230 Train loss 0.64 on epoch=57
06/13/2022 12:06:47 - INFO - __main__ - Step 240 Global step 240 Train loss 0.54 on epoch=59
06/13/2022 12:06:49 - INFO - __main__ - Step 250 Global step 250 Train loss 0.64 on epoch=62
06/13/2022 12:06:50 - INFO - __main__ - Global step 250 Train loss 0.60 Classification-F1 0.6126653913597959 on epoch=62
06/13/2022 12:06:53 - INFO - __main__ - Step 260 Global step 260 Train loss 0.60 on epoch=64
06/13/2022 12:06:55 - INFO - __main__ - Step 270 Global step 270 Train loss 0.49 on epoch=67
06/13/2022 12:06:57 - INFO - __main__ - Step 280 Global step 280 Train loss 0.55 on epoch=69
06/13/2022 12:07:00 - INFO - __main__ - Step 290 Global step 290 Train loss 0.54 on epoch=72
06/13/2022 12:07:02 - INFO - __main__ - Step 300 Global step 300 Train loss 0.58 on epoch=74
06/13/2022 12:07:03 - INFO - __main__ - Global step 300 Train loss 0.55 Classification-F1 0.6126653913597959 on epoch=74
06/13/2022 12:07:06 - INFO - __main__ - Step 310 Global step 310 Train loss 0.47 on epoch=77
06/13/2022 12:07:08 - INFO - __main__ - Step 320 Global step 320 Train loss 0.59 on epoch=79
06/13/2022 12:07:11 - INFO - __main__ - Step 330 Global step 330 Train loss 0.56 on epoch=82
06/13/2022 12:07:13 - INFO - __main__ - Step 340 Global step 340 Train loss 0.57 on epoch=84
06/13/2022 12:07:15 - INFO - __main__ - Step 350 Global step 350 Train loss 0.51 on epoch=87
06/13/2022 12:07:16 - INFO - __main__ - Global step 350 Train loss 0.54 Classification-F1 0.6449248120300752 on epoch=87
06/13/2022 12:07:16 - INFO - __main__ - Saving model with best Classification-F1: 0.6129968203497616 -> 0.6449248120300752 on epoch=87, global_step=350
06/13/2022 12:07:19 - INFO - __main__ - Step 360 Global step 360 Train loss 0.58 on epoch=89
06/13/2022 12:07:21 - INFO - __main__ - Step 370 Global step 370 Train loss 0.42 on epoch=92
06/13/2022 12:07:24 - INFO - __main__ - Step 380 Global step 380 Train loss 0.52 on epoch=94
06/13/2022 12:07:26 - INFO - __main__ - Step 390 Global step 390 Train loss 0.53 on epoch=97
06/13/2022 12:07:28 - INFO - __main__ - Step 400 Global step 400 Train loss 0.49 on epoch=99
06/13/2022 12:07:29 - INFO - __main__ - Global step 400 Train loss 0.51 Classification-F1 0.6839043309631545 on epoch=99
06/13/2022 12:07:29 - INFO - __main__ - Saving model with best Classification-F1: 0.6449248120300752 -> 0.6839043309631545 on epoch=99, global_step=400
06/13/2022 12:07:32 - INFO - __main__ - Step 410 Global step 410 Train loss 0.46 on epoch=102
06/13/2022 12:07:34 - INFO - __main__ - Step 420 Global step 420 Train loss 0.40 on epoch=104
06/13/2022 12:07:37 - INFO - __main__ - Step 430 Global step 430 Train loss 0.43 on epoch=107
06/13/2022 12:07:39 - INFO - __main__ - Step 440 Global step 440 Train loss 0.43 on epoch=109
06/13/2022 12:07:42 - INFO - __main__ - Step 450 Global step 450 Train loss 0.39 on epoch=112
06/13/2022 12:07:43 - INFO - __main__ - Global step 450 Train loss 0.42 Classification-F1 0.6850694444444444 on epoch=112
06/13/2022 12:07:43 - INFO - __main__ - Saving model with best Classification-F1: 0.6839043309631545 -> 0.6850694444444444 on epoch=112, global_step=450
06/13/2022 12:07:45 - INFO - __main__ - Step 460 Global step 460 Train loss 0.44 on epoch=114
06/13/2022 12:07:47 - INFO - __main__ - Step 470 Global step 470 Train loss 0.46 on epoch=117
06/13/2022 12:07:50 - INFO - __main__ - Step 480 Global step 480 Train loss 0.41 on epoch=119
06/13/2022 12:07:52 - INFO - __main__ - Step 490 Global step 490 Train loss 0.39 on epoch=122
06/13/2022 12:07:55 - INFO - __main__ - Step 500 Global step 500 Train loss 0.43 on epoch=124
06/13/2022 12:07:56 - INFO - __main__ - Global step 500 Train loss 0.43 Classification-F1 0.6621212121212121 on epoch=124
06/13/2022 12:07:58 - INFO - __main__ - Step 510 Global step 510 Train loss 0.38 on epoch=127
06/13/2022 12:08:00 - INFO - __main__ - Step 520 Global step 520 Train loss 0.43 on epoch=129
06/13/2022 12:08:03 - INFO - __main__ - Step 530 Global step 530 Train loss 0.41 on epoch=132
06/13/2022 12:08:05 - INFO - __main__ - Step 540 Global step 540 Train loss 0.39 on epoch=134
06/13/2022 12:08:08 - INFO - __main__ - Step 550 Global step 550 Train loss 0.38 on epoch=137
06/13/2022 12:08:09 - INFO - __main__ - Global step 550 Train loss 0.40 Classification-F1 0.7099681020733651 on epoch=137
06/13/2022 12:08:09 - INFO - __main__ - Saving model with best Classification-F1: 0.6850694444444444 -> 0.7099681020733651 on epoch=137, global_step=550
06/13/2022 12:08:11 - INFO - __main__ - Step 560 Global step 560 Train loss 0.30 on epoch=139
06/13/2022 12:08:14 - INFO - __main__ - Step 570 Global step 570 Train loss 0.40 on epoch=142
06/13/2022 12:08:16 - INFO - __main__ - Step 580 Global step 580 Train loss 0.36 on epoch=144
06/13/2022 12:08:19 - INFO - __main__ - Step 590 Global step 590 Train loss 0.42 on epoch=147
06/13/2022 12:08:21 - INFO - __main__ - Step 600 Global step 600 Train loss 0.43 on epoch=149
06/13/2022 12:08:22 - INFO - __main__ - Global step 600 Train loss 0.38 Classification-F1 0.6949057134815648 on epoch=149
06/13/2022 12:08:24 - INFO - __main__ - Step 610 Global step 610 Train loss 0.34 on epoch=152
06/13/2022 12:08:27 - INFO - __main__ - Step 620 Global step 620 Train loss 0.32 on epoch=154
06/13/2022 12:08:29 - INFO - __main__ - Step 630 Global step 630 Train loss 0.32 on epoch=157
06/13/2022 12:08:32 - INFO - __main__ - Step 640 Global step 640 Train loss 0.27 on epoch=159
06/13/2022 12:08:34 - INFO - __main__ - Step 650 Global step 650 Train loss 0.36 on epoch=162
06/13/2022 12:08:35 - INFO - __main__ - Global step 650 Train loss 0.32 Classification-F1 0.6868464868464869 on epoch=162
06/13/2022 12:08:37 - INFO - __main__ - Step 660 Global step 660 Train loss 0.30 on epoch=164
06/13/2022 12:08:40 - INFO - __main__ - Step 670 Global step 670 Train loss 0.29 on epoch=167
06/13/2022 12:08:42 - INFO - __main__ - Step 680 Global step 680 Train loss 0.25 on epoch=169
06/13/2022 12:08:45 - INFO - __main__ - Step 690 Global step 690 Train loss 0.30 on epoch=172
06/13/2022 12:08:47 - INFO - __main__ - Step 700 Global step 700 Train loss 0.34 on epoch=174
06/13/2022 12:08:48 - INFO - __main__ - Global step 700 Train loss 0.30 Classification-F1 0.6717840982546865 on epoch=174
06/13/2022 12:08:51 - INFO - __main__ - Step 710 Global step 710 Train loss 0.20 on epoch=177
06/13/2022 12:08:53 - INFO - __main__ - Step 720 Global step 720 Train loss 0.32 on epoch=179
06/13/2022 12:08:55 - INFO - __main__ - Step 730 Global step 730 Train loss 0.27 on epoch=182
06/13/2022 12:08:58 - INFO - __main__ - Step 740 Global step 740 Train loss 0.26 on epoch=184
06/13/2022 12:09:00 - INFO - __main__ - Step 750 Global step 750 Train loss 0.21 on epoch=187
06/13/2022 12:09:01 - INFO - __main__ - Global step 750 Train loss 0.25 Classification-F1 0.7099681020733651 on epoch=187
06/13/2022 12:09:04 - INFO - __main__ - Step 760 Global step 760 Train loss 0.25 on epoch=189
06/13/2022 12:09:06 - INFO - __main__ - Step 770 Global step 770 Train loss 0.23 on epoch=192
06/13/2022 12:09:09 - INFO - __main__ - Step 780 Global step 780 Train loss 0.18 on epoch=194
06/13/2022 12:09:11 - INFO - __main__ - Step 790 Global step 790 Train loss 0.24 on epoch=197
06/13/2022 12:09:13 - INFO - __main__ - Step 800 Global step 800 Train loss 0.25 on epoch=199
06/13/2022 12:09:14 - INFO - __main__ - Global step 800 Train loss 0.23 Classification-F1 0.6717840982546865 on epoch=199
06/13/2022 12:09:17 - INFO - __main__ - Step 810 Global step 810 Train loss 0.26 on epoch=202
06/13/2022 12:09:19 - INFO - __main__ - Step 820 Global step 820 Train loss 0.18 on epoch=204
06/13/2022 12:09:22 - INFO - __main__ - Step 830 Global step 830 Train loss 0.15 on epoch=207
06/13/2022 12:09:24 - INFO - __main__ - Step 840 Global step 840 Train loss 0.23 on epoch=209
06/13/2022 12:09:27 - INFO - __main__ - Step 850 Global step 850 Train loss 0.15 on epoch=212
06/13/2022 12:09:27 - INFO - __main__ - Global step 850 Train loss 0.19 Classification-F1 0.6735357779475426 on epoch=212
06/13/2022 12:09:30 - INFO - __main__ - Step 860 Global step 860 Train loss 0.20 on epoch=214
06/13/2022 12:09:32 - INFO - __main__ - Step 870 Global step 870 Train loss 0.24 on epoch=217
06/13/2022 12:09:35 - INFO - __main__ - Step 880 Global step 880 Train loss 0.12 on epoch=219
06/13/2022 12:09:37 - INFO - __main__ - Step 890 Global step 890 Train loss 0.20 on epoch=222
06/13/2022 12:09:40 - INFO - __main__ - Step 900 Global step 900 Train loss 0.23 on epoch=224
06/13/2022 12:09:40 - INFO - __main__ - Global step 900 Train loss 0.20 Classification-F1 0.7229936200524436 on epoch=224
06/13/2022 12:09:41 - INFO - __main__ - Saving model with best Classification-F1: 0.7099681020733651 -> 0.7229936200524436 on epoch=224, global_step=900
06/13/2022 12:09:43 - INFO - __main__ - Step 910 Global step 910 Train loss 0.25 on epoch=227
06/13/2022 12:09:45 - INFO - __main__ - Step 920 Global step 920 Train loss 0.29 on epoch=229
06/13/2022 12:09:48 - INFO - __main__ - Step 930 Global step 930 Train loss 0.17 on epoch=232
06/13/2022 12:09:50 - INFO - __main__ - Step 940 Global step 940 Train loss 0.28 on epoch=234
06/13/2022 12:09:53 - INFO - __main__ - Step 950 Global step 950 Train loss 0.15 on epoch=237
06/13/2022 12:09:54 - INFO - __main__ - Global step 950 Train loss 0.23 Classification-F1 0.6868464868464869 on epoch=237
06/13/2022 12:09:56 - INFO - __main__ - Step 960 Global step 960 Train loss 0.18 on epoch=239
06/13/2022 12:09:59 - INFO - __main__ - Step 970 Global step 970 Train loss 0.19 on epoch=242
06/13/2022 12:10:01 - INFO - __main__ - Step 980 Global step 980 Train loss 0.18 on epoch=244
06/13/2022 12:10:03 - INFO - __main__ - Step 990 Global step 990 Train loss 0.22 on epoch=247
06/13/2022 12:10:06 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.17 on epoch=249
06/13/2022 12:10:07 - INFO - __main__ - Global step 1000 Train loss 0.19 Classification-F1 0.7243174781874473 on epoch=249
06/13/2022 12:10:07 - INFO - __main__ - Saving model with best Classification-F1: 0.7229936200524436 -> 0.7243174781874473 on epoch=249, global_step=1000
06/13/2022 12:10:09 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.22 on epoch=252
06/13/2022 12:10:12 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.12 on epoch=254
06/13/2022 12:10:14 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.14 on epoch=257
06/13/2022 12:10:17 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.14 on epoch=259
06/13/2022 12:10:19 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.20 on epoch=262
06/13/2022 12:10:20 - INFO - __main__ - Global step 1050 Train loss 0.16 Classification-F1 0.7011958629605689 on epoch=262
06/13/2022 12:10:22 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.16 on epoch=264
06/13/2022 12:10:25 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.13 on epoch=267
06/13/2022 12:10:27 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.14 on epoch=269
06/13/2022 12:10:30 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.12 on epoch=272
06/13/2022 12:10:32 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.13 on epoch=274
06/13/2022 12:10:33 - INFO - __main__ - Global step 1100 Train loss 0.13 Classification-F1 0.697400274606157 on epoch=274
06/13/2022 12:10:36 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.09 on epoch=277
06/13/2022 12:10:38 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.16 on epoch=279
06/13/2022 12:10:41 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.21 on epoch=282
06/13/2022 12:10:43 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.11 on epoch=284
06/13/2022 12:10:46 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.09 on epoch=287
06/13/2022 12:10:47 - INFO - __main__ - Global step 1150 Train loss 0.13 Classification-F1 0.697400274606157 on epoch=287
06/13/2022 12:10:49 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.05 on epoch=289
06/13/2022 12:10:52 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.17 on epoch=292
06/13/2022 12:10:54 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.07 on epoch=294
06/13/2022 12:10:57 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.12 on epoch=297
06/13/2022 12:10:59 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.18 on epoch=299
06/13/2022 12:11:00 - INFO - __main__ - Global step 1200 Train loss 0.12 Classification-F1 0.6959776334776335 on epoch=299
06/13/2022 12:11:02 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.08 on epoch=302
06/13/2022 12:11:05 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.14 on epoch=304
06/13/2022 12:11:07 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.14 on epoch=307
06/13/2022 12:11:10 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.11 on epoch=309
06/13/2022 12:11:12 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.08 on epoch=312
06/13/2022 12:11:13 - INFO - __main__ - Global step 1250 Train loss 0.11 Classification-F1 0.6959776334776335 on epoch=312
06/13/2022 12:11:16 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.13 on epoch=314
06/13/2022 12:11:18 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.08 on epoch=317
06/13/2022 12:11:21 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.10 on epoch=319
06/13/2022 12:11:23 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.12 on epoch=322
06/13/2022 12:11:26 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.08 on epoch=324
06/13/2022 12:11:27 - INFO - __main__ - Global step 1300 Train loss 0.10 Classification-F1 0.7365841073271414 on epoch=324
06/13/2022 12:11:27 - INFO - __main__ - Saving model with best Classification-F1: 0.7243174781874473 -> 0.7365841073271414 on epoch=324, global_step=1300
06/13/2022 12:11:29 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.09 on epoch=327
06/13/2022 12:11:32 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.05 on epoch=329
06/13/2022 12:11:34 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.04 on epoch=332
06/13/2022 12:11:36 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.06 on epoch=334
06/13/2022 12:11:39 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.09 on epoch=337
06/13/2022 12:11:40 - INFO - __main__ - Global step 1350 Train loss 0.06 Classification-F1 0.6959776334776335 on epoch=337
06/13/2022 12:11:42 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.12 on epoch=339
06/13/2022 12:11:45 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.07 on epoch=342
06/13/2022 12:11:47 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.11 on epoch=344
06/13/2022 12:11:50 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.09 on epoch=347
06/13/2022 12:11:52 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.06 on epoch=349
06/13/2022 12:11:53 - INFO - __main__ - Global step 1400 Train loss 0.09 Classification-F1 0.6961805555555556 on epoch=349
06/13/2022 12:11:55 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.12 on epoch=352
06/13/2022 12:11:58 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.04 on epoch=354
06/13/2022 12:12:00 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.10 on epoch=357
06/13/2022 12:12:03 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.05 on epoch=359
06/13/2022 12:12:05 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.07 on epoch=362
06/13/2022 12:12:06 - INFO - __main__ - Global step 1450 Train loss 0.07 Classification-F1 0.7033135369532428 on epoch=362
06/13/2022 12:12:09 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.13 on epoch=364
06/13/2022 12:12:11 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.08 on epoch=367
06/13/2022 12:12:14 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.05 on epoch=369
06/13/2022 12:12:16 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.06 on epoch=372
06/13/2022 12:12:18 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.08 on epoch=374
06/13/2022 12:12:19 - INFO - __main__ - Global step 1500 Train loss 0.08 Classification-F1 0.6826839826839827 on epoch=374
06/13/2022 12:12:22 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=377
06/13/2022 12:12:24 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.10 on epoch=379
06/13/2022 12:12:27 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.06 on epoch=382
06/13/2022 12:12:29 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.07 on epoch=384
06/13/2022 12:12:32 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.11 on epoch=387
06/13/2022 12:12:33 - INFO - __main__ - Global step 1550 Train loss 0.07 Classification-F1 0.7094192749563595 on epoch=387
06/13/2022 12:12:35 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.02 on epoch=389
06/13/2022 12:12:38 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.06 on epoch=392
06/13/2022 12:12:40 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.04 on epoch=394
06/13/2022 12:12:42 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.07 on epoch=397
06/13/2022 12:12:45 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.03 on epoch=399
06/13/2022 12:12:46 - INFO - __main__ - Global step 1600 Train loss 0.05 Classification-F1 0.6826839826839827 on epoch=399
06/13/2022 12:12:48 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=402
06/13/2022 12:12:51 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.04 on epoch=404
06/13/2022 12:12:53 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.10 on epoch=407
06/13/2022 12:12:56 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.03 on epoch=409
06/13/2022 12:12:58 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.04 on epoch=412
06/13/2022 12:12:59 - INFO - __main__ - Global step 1650 Train loss 0.05 Classification-F1 0.6961805555555556 on epoch=412
06/13/2022 12:13:01 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.07 on epoch=414
06/13/2022 12:13:04 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.05 on epoch=417
06/13/2022 12:13:06 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=419
06/13/2022 12:13:09 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.04 on epoch=422
06/13/2022 12:13:11 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=424
06/13/2022 12:13:12 - INFO - __main__ - Global step 1700 Train loss 0.04 Classification-F1 0.7229936200524436 on epoch=424
06/13/2022 12:13:15 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.08 on epoch=427
06/13/2022 12:13:17 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=429
06/13/2022 12:13:20 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=432
06/13/2022 12:13:22 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=434
06/13/2022 12:13:24 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.04 on epoch=437
06/13/2022 12:13:25 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.6959776334776335 on epoch=437
06/13/2022 12:13:28 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.04 on epoch=439
06/13/2022 12:13:30 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.07 on epoch=442
06/13/2022 12:13:33 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=444
06/13/2022 12:13:35 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.07 on epoch=447
06/13/2022 12:13:38 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.10 on epoch=449
06/13/2022 12:13:39 - INFO - __main__ - Global step 1800 Train loss 0.06 Classification-F1 0.6959776334776335 on epoch=449
06/13/2022 12:13:41 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.05 on epoch=452
06/13/2022 12:13:44 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=454
06/13/2022 12:13:46 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=457
06/13/2022 12:13:49 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=459
06/13/2022 12:13:51 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.05 on epoch=462
06/13/2022 12:13:52 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.6959776334776335 on epoch=462
06/13/2022 12:13:54 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.03 on epoch=464
06/13/2022 12:13:57 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=467
06/13/2022 12:13:59 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.04 on epoch=469
06/13/2022 12:14:02 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.04 on epoch=472
06/13/2022 12:14:04 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.02 on epoch=474
06/13/2022 12:14:05 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.7229936200524436 on epoch=474
06/13/2022 12:14:08 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=477
06/13/2022 12:14:10 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=479
06/13/2022 12:14:13 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=482
06/13/2022 12:14:15 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=484
06/13/2022 12:14:17 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=487
06/13/2022 12:14:18 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.6959776334776335 on epoch=487
06/13/2022 12:14:21 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=489
06/13/2022 12:14:23 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.05 on epoch=492
06/13/2022 12:14:26 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.06 on epoch=494
06/13/2022 12:14:28 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=497
06/13/2022 12:14:31 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.06 on epoch=499
06/13/2022 12:14:32 - INFO - __main__ - Global step 2000 Train loss 0.04 Classification-F1 0.6826839826839827 on epoch=499
06/13/2022 12:14:34 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=502
06/13/2022 12:14:36 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.05 on epoch=504
06/13/2022 12:14:39 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.03 on epoch=507
06/13/2022 12:14:41 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.08 on epoch=509
06/13/2022 12:14:44 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=512
06/13/2022 12:14:45 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.6959776334776335 on epoch=512
06/13/2022 12:14:47 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=514
06/13/2022 12:14:50 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.04 on epoch=517
06/13/2022 12:14:52 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.03 on epoch=519
06/13/2022 12:14:55 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=522
06/13/2022 12:14:57 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=524
06/13/2022 12:14:58 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.7031106148753209 on epoch=524
06/13/2022 12:15:01 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=527
06/13/2022 12:15:03 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=529
06/13/2022 12:15:05 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.04 on epoch=532
06/13/2022 12:15:08 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=534
06/13/2022 12:15:10 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=537
06/13/2022 12:15:11 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.6826839826839827 on epoch=537
06/13/2022 12:15:14 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.03 on epoch=539
06/13/2022 12:15:16 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=542
06/13/2022 12:15:19 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=544
06/13/2022 12:15:21 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=547
06/13/2022 12:15:24 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=549
06/13/2022 12:15:25 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.7229936200524436 on epoch=549
06/13/2022 12:15:27 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=552
06/13/2022 12:15:29 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.04 on epoch=554
06/13/2022 12:15:32 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.04 on epoch=557
06/13/2022 12:15:34 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=559
06/13/2022 12:15:37 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=562
06/13/2022 12:15:38 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.7365841073271414 on epoch=562
06/13/2022 12:15:40 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=564
06/13/2022 12:15:43 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.04 on epoch=567
06/13/2022 12:15:45 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=569
06/13/2022 12:15:48 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=572
06/13/2022 12:15:50 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=574
06/13/2022 12:15:51 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.6826839826839827 on epoch=574
06/13/2022 12:15:53 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=577
06/13/2022 12:15:56 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=579
06/13/2022 12:15:58 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=582
06/13/2022 12:16:01 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.03 on epoch=584
06/13/2022 12:16:03 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=587
06/13/2022 12:16:04 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.7094192749563595 on epoch=587
06/13/2022 12:16:07 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=589
06/13/2022 12:16:09 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=592
06/13/2022 12:16:11 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=594
06/13/2022 12:16:14 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=597
06/13/2022 12:16:16 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=599
06/13/2022 12:16:17 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.7031106148753209 on epoch=599
06/13/2022 12:16:20 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.11 on epoch=602
06/13/2022 12:16:22 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=604
06/13/2022 12:16:25 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=607
06/13/2022 12:16:27 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.03 on epoch=609
06/13/2022 12:16:30 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.06 on epoch=612
06/13/2022 12:16:31 - INFO - __main__ - Global step 2450 Train loss 0.04 Classification-F1 0.6856803327391564 on epoch=612
06/13/2022 12:16:33 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=614
06/13/2022 12:16:36 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=617
06/13/2022 12:16:38 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=619
06/13/2022 12:16:41 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=622
06/13/2022 12:16:43 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=624
06/13/2022 12:16:44 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.6986429707017943 on epoch=624
06/13/2022 12:16:46 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=627
06/13/2022 12:16:49 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=629
06/13/2022 12:16:51 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=632
06/13/2022 12:16:54 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/13/2022 12:16:56 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=637
06/13/2022 12:16:57 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.6986429707017943 on epoch=637
06/13/2022 12:17:00 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.04 on epoch=639
06/13/2022 12:17:02 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=642
06/13/2022 12:17:05 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=644
06/13/2022 12:17:07 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=647
06/13/2022 12:17:10 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/13/2022 12:17:10 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.6986429707017943 on epoch=649
06/13/2022 12:17:13 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=652
06/13/2022 12:17:15 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=654
06/13/2022 12:17:18 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=657
06/13/2022 12:17:20 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=659
06/13/2022 12:17:23 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=662
06/13/2022 12:17:24 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.6733397799973888 on epoch=662
06/13/2022 12:17:26 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=664
06/13/2022 12:17:29 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=667
06/13/2022 12:17:31 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=669
06/13/2022 12:17:34 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=672
06/13/2022 12:17:36 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=674
06/13/2022 12:17:37 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.6826839826839827 on epoch=674
06/13/2022 12:17:39 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=677
06/13/2022 12:17:42 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=679
06/13/2022 12:17:44 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=682
06/13/2022 12:17:47 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.08 on epoch=684
06/13/2022 12:17:49 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/13/2022 12:17:50 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.6728151075977163 on epoch=687
06/13/2022 12:17:53 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=689
06/13/2022 12:17:55 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/13/2022 12:17:58 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=694
06/13/2022 12:18:00 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=697
06/13/2022 12:18:03 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=699
06/13/2022 12:18:04 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.6957086550836551 on epoch=699
06/13/2022 12:18:06 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=702
06/13/2022 12:18:08 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=704
06/13/2022 12:18:11 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=707
06/13/2022 12:18:13 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=709
06/13/2022 12:18:16 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=712
06/13/2022 12:18:17 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.6986429707017943 on epoch=712
06/13/2022 12:18:19 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/13/2022 12:18:22 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=717
06/13/2022 12:18:24 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=719
06/13/2022 12:18:27 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/13/2022 12:18:29 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=724
06/13/2022 12:18:30 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.6728151075977163 on epoch=724
06/13/2022 12:18:32 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/13/2022 12:18:35 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/13/2022 12:18:37 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=732
06/13/2022 12:18:40 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=734
06/13/2022 12:18:42 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.03 on epoch=737
06/13/2022 12:18:43 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.6728151075977163 on epoch=737
06/13/2022 12:18:46 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.10 on epoch=739
06/13/2022 12:18:48 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=742
06/13/2022 12:18:51 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=744
06/13/2022 12:18:53 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.05 on epoch=747
06/13/2022 12:18:56 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=749
06/13/2022 12:18:57 - INFO - __main__ - Global step 3000 Train loss 0.04 Classification-F1 0.6854707470032548 on epoch=749
06/13/2022 12:18:57 - INFO - __main__ - save last model!
06/13/2022 12:18:57 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/13/2022 12:18:57 - INFO - __main__ - Start tokenizing ... 5509 instances
06/13/2022 12:18:57 - INFO - __main__ - Printing 3 examples
06/13/2022 12:18:57 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/13/2022 12:18:57 - INFO - __main__ - ['others']
06/13/2022 12:18:57 - INFO - __main__ -  [emo] what you like very little things ok
06/13/2022 12:18:57 - INFO - __main__ - ['others']
06/13/2022 12:18:57 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/13/2022 12:18:57 - INFO - __main__ - ['others']
06/13/2022 12:18:57 - INFO - __main__ - Tokenizing Input ...
06/13/2022 12:18:59 - INFO - __main__ - Tokenizing Output ...
06/13/2022 12:19:04 - INFO - __main__ - Loaded 5509 examples from test data
06/13/2022 12:20:20 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-up32shot/singletask-emo/emo_16_87_0.2_8_predictions.txt
06/13/2022 12:20:20 - INFO - __main__ - Classification-F1 on test data: 0.1534
06/13/2022 12:20:20 - INFO - __main__ - prefix=emo_16_87, lr=0.2, bsz=8, dev_performance=0.7365841073271414, test_performance=0.15342193237182725
