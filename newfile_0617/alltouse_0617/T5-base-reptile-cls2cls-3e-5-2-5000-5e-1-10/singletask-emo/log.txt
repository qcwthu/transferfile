05/17/2022 11:22:16 - INFO - __main__ - Namespace(task_dir='data/emo/', task_name='emo', identifier='T5-base-reptile-cls2cls-3e-5-2-5000-5e-1-10', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-base-reptile-cls2cls-3e-5-2-5000-5e-1-10/singletask-emo', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-base-reptile-cls2cls-3e-5-2-5000-5e-1-10/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/base/pytorch_model.bin', model='google/t5-v1_1-base', prompt_number=100, cuda='6,7')
05/17/2022 11:22:16 - INFO - __main__ - models/T5-base-reptile-cls2cls-3e-5-2-5000-5e-1-10/singletask-emo
05/17/2022 11:22:16 - INFO - __main__ - Namespace(task_dir='data/emo/', task_name='emo', identifier='T5-base-reptile-cls2cls-3e-5-2-5000-5e-1-10', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-base-reptile-cls2cls-3e-5-2-5000-5e-1-10/singletask-emo', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-base-reptile-cls2cls-3e-5-2-5000-5e-1-10/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/base/pytorch_model.bin', model='google/t5-v1_1-base', prompt_number=100, cuda='6,7')
05/17/2022 11:22:16 - INFO - __main__ - models/T5-base-reptile-cls2cls-3e-5-2-5000-5e-1-10/singletask-emo
05/17/2022 11:22:18 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
05/17/2022 11:22:18 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
05/17/2022 11:22:18 - INFO - __main__ - args.device: cuda:0
05/17/2022 11:22:18 - INFO - __main__ - Using 2 gpus
05/17/2022 11:22:18 - INFO - __main__ - Fine-tuning the following samples: ['emo_16_100', 'emo_16_13', 'emo_16_21', 'emo_16_42', 'emo_16_87']
05/17/2022 11:22:18 - INFO - __main__ - args.device: cuda:1
05/17/2022 11:22:18 - INFO - __main__ - Using 2 gpus
05/17/2022 11:22:18 - INFO - __main__ - Fine-tuning the following samples: ['emo_16_100', 'emo_16_13', 'emo_16_21', 'emo_16_42', 'emo_16_87']
05/17/2022 11:22:25 - INFO - __main__ - Running ... prefix=emo_16_100, lr=0.5, bsz=8 ...
05/17/2022 11:22:26 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 11:22:26 - INFO - __main__ - Printing 3 examples
05/17/2022 11:22:26 - INFO - __main__ -  [emo] how cause yes am listening
05/17/2022 11:22:26 - INFO - __main__ - ['others']
05/17/2022 11:22:26 - INFO - __main__ -  [emo] ok that way i like living wwrong
05/17/2022 11:22:26 - INFO - __main__ - ['others']
05/17/2022 11:22:26 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
05/17/2022 11:22:26 - INFO - __main__ - ['others']
05/17/2022 11:22:26 - INFO - __main__ - Tokenizing Input ...
05/17/2022 11:22:26 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 11:22:26 - INFO - __main__ - Printing 3 examples
05/17/2022 11:22:26 - INFO - __main__ -  [emo] how cause yes am listening
05/17/2022 11:22:26 - INFO - __main__ - ['others']
05/17/2022 11:22:26 - INFO - __main__ -  [emo] ok that way i like living wwrong
05/17/2022 11:22:26 - INFO - __main__ - ['others']
05/17/2022 11:22:26 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
05/17/2022 11:22:26 - INFO - __main__ - ['others']
05/17/2022 11:22:26 - INFO - __main__ - Tokenizing Input ...
05/17/2022 11:22:26 - INFO - __main__ - Tokenizing Output ...
05/17/2022 11:22:26 - INFO - __main__ - Tokenizing Output ...
05/17/2022 11:22:26 - INFO - __main__ - Loaded 64 examples from train data
05/17/2022 11:22:26 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 11:22:26 - INFO - __main__ - Printing 3 examples
05/17/2022 11:22:26 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
05/17/2022 11:22:26 - INFO - __main__ - ['others']
05/17/2022 11:22:26 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
05/17/2022 11:22:26 - INFO - __main__ - ['others']
05/17/2022 11:22:26 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
05/17/2022 11:22:26 - INFO - __main__ - ['others']
05/17/2022 11:22:26 - INFO - __main__ - Tokenizing Input ...
05/17/2022 11:22:26 - INFO - __main__ - Loaded 64 examples from train data
05/17/2022 11:22:26 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 11:22:26 - INFO - __main__ - Printing 3 examples
05/17/2022 11:22:26 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
05/17/2022 11:22:26 - INFO - __main__ - ['others']
05/17/2022 11:22:26 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
05/17/2022 11:22:26 - INFO - __main__ - ['others']
05/17/2022 11:22:26 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
05/17/2022 11:22:26 - INFO - __main__ - ['others']
05/17/2022 11:22:26 - INFO - __main__ - Tokenizing Input ...
05/17/2022 11:22:26 - INFO - __main__ - Tokenizing Output ...
05/17/2022 11:22:26 - INFO - __main__ - Tokenizing Output ...
05/17/2022 11:22:26 - INFO - __main__ - Loaded 64 examples from dev data
05/17/2022 11:22:26 - INFO - __main__ - Loaded 64 examples from dev data
05/17/2022 11:22:33 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 11:22:33 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 11:22:33 - INFO - __main__ - Starting training!
05/17/2022 11:22:34 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 11:22:39 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 11:22:39 - INFO - __main__ - Starting training!
05/17/2022 11:22:41 - INFO - __main__ - Step 10 Global step 10 Train loss 9.02 on epoch=2
05/17/2022 11:22:43 - INFO - __main__ - Step 20 Global step 20 Train loss 8.88 on epoch=4
05/17/2022 11:22:44 - INFO - __main__ - Step 30 Global step 30 Train loss 8.91 on epoch=7
05/17/2022 11:22:45 - INFO - __main__ - Step 40 Global step 40 Train loss 8.82 on epoch=9
05/17/2022 11:22:47 - INFO - __main__ - Step 50 Global step 50 Train loss 8.70 on epoch=12
05/17/2022 11:22:54 - INFO - __main__ - Global step 50 Train loss 8.87 Classification-F1 0.0 on epoch=12
05/17/2022 11:22:54 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/17/2022 11:22:55 - INFO - __main__ - Step 60 Global step 60 Train loss 8.77 on epoch=14
05/17/2022 11:22:57 - INFO - __main__ - Step 70 Global step 70 Train loss 8.51 on epoch=17
05/17/2022 11:22:58 - INFO - __main__ - Step 80 Global step 80 Train loss 8.43 on epoch=19
05/17/2022 11:23:00 - INFO - __main__ - Step 90 Global step 90 Train loss 8.12 on epoch=22
05/17/2022 11:23:01 - INFO - __main__ - Step 100 Global step 100 Train loss 7.97 on epoch=24
05/17/2022 11:23:22 - INFO - __main__ - Global step 100 Train loss 8.36 Classification-F1 0.0 on epoch=24
05/17/2022 11:23:24 - INFO - __main__ - Step 110 Global step 110 Train loss 7.58 on epoch=27
05/17/2022 11:23:25 - INFO - __main__ - Step 120 Global step 120 Train loss 7.17 on epoch=29
05/17/2022 11:23:27 - INFO - __main__ - Step 130 Global step 130 Train loss 6.87 on epoch=32
05/17/2022 11:23:28 - INFO - __main__ - Step 140 Global step 140 Train loss 6.64 on epoch=34
05/17/2022 11:23:30 - INFO - __main__ - Step 150 Global step 150 Train loss 6.30 on epoch=37
05/17/2022 11:23:35 - INFO - __main__ - Global step 150 Train loss 6.91 Classification-F1 0.0 on epoch=37
05/17/2022 11:23:37 - INFO - __main__ - Step 160 Global step 160 Train loss 6.17 on epoch=39
05/17/2022 11:23:38 - INFO - __main__ - Step 170 Global step 170 Train loss 5.94 on epoch=42
05/17/2022 11:23:39 - INFO - __main__ - Step 180 Global step 180 Train loss 5.63 on epoch=44
05/17/2022 11:23:41 - INFO - __main__ - Step 190 Global step 190 Train loss 5.67 on epoch=47
05/17/2022 11:23:42 - INFO - __main__ - Step 200 Global step 200 Train loss 5.28 on epoch=49
05/17/2022 11:23:47 - INFO - __main__ - Global step 200 Train loss 5.74 Classification-F1 0.0 on epoch=49
05/17/2022 11:23:49 - INFO - __main__ - Step 210 Global step 210 Train loss 5.47 on epoch=52
05/17/2022 11:23:50 - INFO - __main__ - Step 220 Global step 220 Train loss 5.10 on epoch=54
05/17/2022 11:23:52 - INFO - __main__ - Step 230 Global step 230 Train loss 5.06 on epoch=57
05/17/2022 11:23:53 - INFO - __main__ - Step 240 Global step 240 Train loss 4.88 on epoch=59
05/17/2022 11:23:55 - INFO - __main__ - Step 250 Global step 250 Train loss 5.03 on epoch=62
05/17/2022 11:24:05 - INFO - __main__ - Global step 250 Train loss 5.11 Classification-F1 0.0 on epoch=62
05/17/2022 11:24:07 - INFO - __main__ - Step 260 Global step 260 Train loss 4.62 on epoch=64
05/17/2022 11:24:08 - INFO - __main__ - Step 270 Global step 270 Train loss 4.76 on epoch=67
05/17/2022 11:24:09 - INFO - __main__ - Step 280 Global step 280 Train loss 4.52 on epoch=69
05/17/2022 11:24:11 - INFO - __main__ - Step 290 Global step 290 Train loss 4.51 on epoch=72
05/17/2022 11:24:12 - INFO - __main__ - Step 300 Global step 300 Train loss 4.27 on epoch=74
05/17/2022 11:24:16 - INFO - __main__ - Global step 300 Train loss 4.54 Classification-F1 0.0 on epoch=74
05/17/2022 11:24:17 - INFO - __main__ - Step 310 Global step 310 Train loss 4.47 on epoch=77
05/17/2022 11:24:18 - INFO - __main__ - Step 320 Global step 320 Train loss 4.34 on epoch=79
05/17/2022 11:24:20 - INFO - __main__ - Step 330 Global step 330 Train loss 4.39 on epoch=82
05/17/2022 11:24:22 - INFO - __main__ - Step 340 Global step 340 Train loss 4.23 on epoch=84
05/17/2022 11:24:23 - INFO - __main__ - Step 350 Global step 350 Train loss 4.31 on epoch=87
05/17/2022 11:24:29 - INFO - __main__ - Global step 350 Train loss 4.35 Classification-F1 0.0 on epoch=87
05/17/2022 11:24:30 - INFO - __main__ - Step 360 Global step 360 Train loss 4.10 on epoch=89
05/17/2022 11:24:32 - INFO - __main__ - Step 370 Global step 370 Train loss 4.11 on epoch=92
05/17/2022 11:24:33 - INFO - __main__ - Step 380 Global step 380 Train loss 4.08 on epoch=94
05/17/2022 11:24:34 - INFO - __main__ - Step 390 Global step 390 Train loss 4.08 on epoch=97
05/17/2022 11:24:36 - INFO - __main__ - Step 400 Global step 400 Train loss 3.93 on epoch=99
05/17/2022 11:24:40 - INFO - __main__ - Global step 400 Train loss 4.06 Classification-F1 0.006578947368421052 on epoch=99
05/17/2022 11:24:40 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.006578947368421052 on epoch=99, global_step=400
05/17/2022 11:24:42 - INFO - __main__ - Step 410 Global step 410 Train loss 3.75 on epoch=102
05/17/2022 11:24:43 - INFO - __main__ - Step 420 Global step 420 Train loss 3.71 on epoch=104
05/17/2022 11:24:44 - INFO - __main__ - Step 430 Global step 430 Train loss 3.82 on epoch=107
05/17/2022 11:24:46 - INFO - __main__ - Step 440 Global step 440 Train loss 3.62 on epoch=109
05/17/2022 11:24:47 - INFO - __main__ - Step 450 Global step 450 Train loss 3.80 on epoch=112
05/17/2022 11:24:54 - INFO - __main__ - Global step 450 Train loss 3.74 Classification-F1 0.0 on epoch=112
05/17/2022 11:24:56 - INFO - __main__ - Step 460 Global step 460 Train loss 3.64 on epoch=114
05/17/2022 11:24:57 - INFO - __main__ - Step 470 Global step 470 Train loss 3.62 on epoch=117
05/17/2022 11:24:58 - INFO - __main__ - Step 480 Global step 480 Train loss 3.60 on epoch=119
05/17/2022 11:25:00 - INFO - __main__ - Step 490 Global step 490 Train loss 3.60 on epoch=122
05/17/2022 11:25:01 - INFO - __main__ - Step 500 Global step 500 Train loss 3.55 on epoch=124
05/17/2022 11:25:03 - INFO - __main__ - Global step 500 Train loss 3.60 Classification-F1 0.15277777777777776 on epoch=124
05/17/2022 11:25:03 - INFO - __main__ - Saving model with best Classification-F1: 0.006578947368421052 -> 0.15277777777777776 on epoch=124, global_step=500
05/17/2022 11:25:05 - INFO - __main__ - Step 510 Global step 510 Train loss 3.55 on epoch=127
05/17/2022 11:25:06 - INFO - __main__ - Step 520 Global step 520 Train loss 3.50 on epoch=129
05/17/2022 11:25:07 - INFO - __main__ - Step 530 Global step 530 Train loss 3.42 on epoch=132
05/17/2022 11:25:09 - INFO - __main__ - Step 540 Global step 540 Train loss 3.31 on epoch=134
05/17/2022 11:25:10 - INFO - __main__ - Step 550 Global step 550 Train loss 3.35 on epoch=137
05/17/2022 11:25:22 - INFO - __main__ - Global step 550 Train loss 3.43 Classification-F1 0.09472329472329473 on epoch=137
05/17/2022 11:25:23 - INFO - __main__ - Step 560 Global step 560 Train loss 3.15 on epoch=139
05/17/2022 11:25:25 - INFO - __main__ - Step 570 Global step 570 Train loss 3.30 on epoch=142
05/17/2022 11:25:26 - INFO - __main__ - Step 580 Global step 580 Train loss 3.27 on epoch=144
05/17/2022 11:25:27 - INFO - __main__ - Step 590 Global step 590 Train loss 3.40 on epoch=147
05/17/2022 11:25:29 - INFO - __main__ - Step 600 Global step 600 Train loss 3.27 on epoch=149
05/17/2022 11:25:37 - INFO - __main__ - Global step 600 Train loss 3.28 Classification-F1 0.11377091377091378 on epoch=149
05/17/2022 11:25:38 - INFO - __main__ - Step 610 Global step 610 Train loss 3.13 on epoch=152
05/17/2022 11:25:39 - INFO - __main__ - Step 620 Global step 620 Train loss 2.99 on epoch=154
05/17/2022 11:25:41 - INFO - __main__ - Step 630 Global step 630 Train loss 3.20 on epoch=157
05/17/2022 11:25:42 - INFO - __main__ - Step 640 Global step 640 Train loss 3.00 on epoch=159
05/17/2022 11:25:43 - INFO - __main__ - Step 650 Global step 650 Train loss 3.05 on epoch=162
05/17/2022 11:25:46 - INFO - __main__ - Global step 650 Train loss 3.07 Classification-F1 0.13067758749069247 on epoch=162
05/17/2022 11:25:48 - INFO - __main__ - Step 660 Global step 660 Train loss 3.13 on epoch=164
05/17/2022 11:25:49 - INFO - __main__ - Step 670 Global step 670 Train loss 2.98 on epoch=167
05/17/2022 11:25:50 - INFO - __main__ - Step 680 Global step 680 Train loss 2.92 on epoch=169
05/17/2022 11:25:52 - INFO - __main__ - Step 690 Global step 690 Train loss 2.86 on epoch=172
05/17/2022 11:25:53 - INFO - __main__ - Step 700 Global step 700 Train loss 3.08 on epoch=174
05/17/2022 11:25:57 - INFO - __main__ - Global step 700 Train loss 2.99 Classification-F1 0.1 on epoch=174
05/17/2022 11:25:58 - INFO - __main__ - Step 710 Global step 710 Train loss 2.86 on epoch=177
05/17/2022 11:26:00 - INFO - __main__ - Step 720 Global step 720 Train loss 2.69 on epoch=179
05/17/2022 11:26:01 - INFO - __main__ - Step 730 Global step 730 Train loss 2.60 on epoch=182
05/17/2022 11:26:03 - INFO - __main__ - Step 740 Global step 740 Train loss 2.72 on epoch=184
05/17/2022 11:26:04 - INFO - __main__ - Step 750 Global step 750 Train loss 2.75 on epoch=187
05/17/2022 11:26:05 - INFO - __main__ - Global step 750 Train loss 2.73 Classification-F1 0.09493670886075949 on epoch=187
05/17/2022 11:26:07 - INFO - __main__ - Step 760 Global step 760 Train loss 2.59 on epoch=189
05/17/2022 11:26:08 - INFO - __main__ - Step 770 Global step 770 Train loss 2.58 on epoch=192
05/17/2022 11:26:09 - INFO - __main__ - Step 780 Global step 780 Train loss 2.48 on epoch=194
05/17/2022 11:26:11 - INFO - __main__ - Step 790 Global step 790 Train loss 2.42 on epoch=197
05/17/2022 11:26:12 - INFO - __main__ - Step 800 Global step 800 Train loss 2.35 on epoch=199
05/17/2022 11:26:13 - INFO - __main__ - Global step 800 Train loss 2.49 Classification-F1 0.1484375 on epoch=199
05/17/2022 11:26:14 - INFO - __main__ - Step 810 Global step 810 Train loss 2.39 on epoch=202
05/17/2022 11:26:15 - INFO - __main__ - Step 820 Global step 820 Train loss 2.19 on epoch=204
05/17/2022 11:26:17 - INFO - __main__ - Step 830 Global step 830 Train loss 2.27 on epoch=207
05/17/2022 11:26:18 - INFO - __main__ - Step 840 Global step 840 Train loss 2.00 on epoch=209
05/17/2022 11:26:19 - INFO - __main__ - Step 850 Global step 850 Train loss 2.25 on epoch=212
05/17/2022 11:26:20 - INFO - __main__ - Global step 850 Train loss 2.22 Classification-F1 0.10126582278481013 on epoch=212
05/17/2022 11:26:21 - INFO - __main__ - Step 860 Global step 860 Train loss 2.09 on epoch=214
05/17/2022 11:26:23 - INFO - __main__ - Step 870 Global step 870 Train loss 2.04 on epoch=217
05/17/2022 11:26:24 - INFO - __main__ - Step 880 Global step 880 Train loss 1.79 on epoch=219
05/17/2022 11:26:25 - INFO - __main__ - Step 890 Global step 890 Train loss 1.85 on epoch=222
05/17/2022 11:26:27 - INFO - __main__ - Step 900 Global step 900 Train loss 1.75 on epoch=224
05/17/2022 11:26:27 - INFO - __main__ - Global step 900 Train loss 1.91 Classification-F1 0.10126582278481013 on epoch=224
05/17/2022 11:26:29 - INFO - __main__ - Step 910 Global step 910 Train loss 1.69 on epoch=227
05/17/2022 11:26:30 - INFO - __main__ - Step 920 Global step 920 Train loss 1.67 on epoch=229
05/17/2022 11:26:31 - INFO - __main__ - Step 930 Global step 930 Train loss 1.63 on epoch=232
05/17/2022 11:26:33 - INFO - __main__ - Step 940 Global step 940 Train loss 1.69 on epoch=234
05/17/2022 11:26:34 - INFO - __main__ - Step 950 Global step 950 Train loss 1.71 on epoch=237
05/17/2022 11:26:34 - INFO - __main__ - Global step 950 Train loss 1.68 Classification-F1 0.1575757575757576 on epoch=237
05/17/2022 11:26:34 - INFO - __main__ - Saving model with best Classification-F1: 0.15277777777777776 -> 0.1575757575757576 on epoch=237, global_step=950
05/17/2022 11:26:36 - INFO - __main__ - Step 960 Global step 960 Train loss 1.62 on epoch=239
05/17/2022 11:26:37 - INFO - __main__ - Step 970 Global step 970 Train loss 1.53 on epoch=242
05/17/2022 11:26:39 - INFO - __main__ - Step 980 Global step 980 Train loss 1.49 on epoch=244
05/17/2022 11:26:41 - INFO - __main__ - Step 990 Global step 990 Train loss 1.58 on epoch=247
05/17/2022 11:26:42 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.60 on epoch=249
05/17/2022 11:26:43 - INFO - __main__ - Global step 1000 Train loss 1.56 Classification-F1 0.14915966386554622 on epoch=249
05/17/2022 11:26:44 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.67 on epoch=252
05/17/2022 11:26:45 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.50 on epoch=254
05/17/2022 11:26:47 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.59 on epoch=257
05/17/2022 11:26:48 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.55 on epoch=259
05/17/2022 11:26:50 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.46 on epoch=262
05/17/2022 11:26:50 - INFO - __main__ - Global step 1050 Train loss 1.55 Classification-F1 0.10126582278481013 on epoch=262
05/17/2022 11:26:52 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.34 on epoch=264
05/17/2022 11:26:53 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.42 on epoch=267
05/17/2022 11:26:54 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.47 on epoch=269
05/17/2022 11:26:56 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.54 on epoch=272
05/17/2022 11:26:57 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.52 on epoch=274
05/17/2022 11:26:58 - INFO - __main__ - Global step 1100 Train loss 1.46 Classification-F1 0.16451612903225807 on epoch=274
05/17/2022 11:26:58 - INFO - __main__ - Saving model with best Classification-F1: 0.1575757575757576 -> 0.16451612903225807 on epoch=274, global_step=1100
05/17/2022 11:26:59 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.41 on epoch=277
05/17/2022 11:27:01 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.51 on epoch=279
05/17/2022 11:27:02 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.48 on epoch=282
05/17/2022 11:27:03 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.30 on epoch=284
05/17/2022 11:27:05 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.45 on epoch=287
05/17/2022 11:27:05 - INFO - __main__ - Global step 1150 Train loss 1.43 Classification-F1 0.12447885646217988 on epoch=287
05/17/2022 11:27:07 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.29 on epoch=289
05/17/2022 11:27:08 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.33 on epoch=292
05/17/2022 11:27:10 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.34 on epoch=294
05/17/2022 11:27:11 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.25 on epoch=297
05/17/2022 11:27:12 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.38 on epoch=299
05/17/2022 11:27:13 - INFO - __main__ - Global step 1200 Train loss 1.32 Classification-F1 0.10126582278481013 on epoch=299
05/17/2022 11:27:14 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.17 on epoch=302
05/17/2022 11:27:16 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.25 on epoch=304
05/17/2022 11:27:17 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.15 on epoch=307
05/17/2022 11:27:18 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.19 on epoch=309
05/17/2022 11:27:20 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.28 on epoch=312
05/17/2022 11:27:20 - INFO - __main__ - Global step 1250 Train loss 1.21 Classification-F1 0.1328125 on epoch=312
05/17/2022 11:27:21 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.27 on epoch=314
05/17/2022 11:27:23 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.23 on epoch=317
05/17/2022 11:27:24 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.22 on epoch=319
05/17/2022 11:27:26 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.16 on epoch=322
05/17/2022 11:27:27 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.10 on epoch=324
05/17/2022 11:27:27 - INFO - __main__ - Global step 1300 Train loss 1.20 Classification-F1 0.12447885646217988 on epoch=324
05/17/2022 11:27:29 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.21 on epoch=327
05/17/2022 11:27:30 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.11 on epoch=329
05/17/2022 11:27:31 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.22 on epoch=332
05/17/2022 11:27:33 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.24 on epoch=334
05/17/2022 11:27:34 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.24 on epoch=337
05/17/2022 11:27:35 - INFO - __main__ - Global step 1350 Train loss 1.20 Classification-F1 0.11762954139368673 on epoch=337
05/17/2022 11:27:36 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.08 on epoch=339
05/17/2022 11:27:37 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.17 on epoch=342
05/17/2022 11:27:39 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.09 on epoch=344
05/17/2022 11:27:40 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.21 on epoch=347
05/17/2022 11:27:41 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.08 on epoch=349
05/17/2022 11:27:42 - INFO - __main__ - Global step 1400 Train loss 1.12 Classification-F1 0.1237183868762816 on epoch=349
05/17/2022 11:27:43 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.16 on epoch=352
05/17/2022 11:27:45 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.28 on epoch=354
05/17/2022 11:27:46 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.23 on epoch=357
05/17/2022 11:27:47 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.08 on epoch=359
05/17/2022 11:27:49 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.16 on epoch=362
05/17/2022 11:27:49 - INFO - __main__ - Global step 1450 Train loss 1.18 Classification-F1 0.1855036855036855 on epoch=362
05/17/2022 11:27:49 - INFO - __main__ - Saving model with best Classification-F1: 0.16451612903225807 -> 0.1855036855036855 on epoch=362, global_step=1450
05/17/2022 11:27:51 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.09 on epoch=364
05/17/2022 11:27:52 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.09 on epoch=367
05/17/2022 11:27:53 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.13 on epoch=369
05/17/2022 11:27:55 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.19 on epoch=372
05/17/2022 11:27:56 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.01 on epoch=374
05/17/2022 11:27:57 - INFO - __main__ - Global step 1500 Train loss 1.10 Classification-F1 0.125 on epoch=374
05/17/2022 11:27:58 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.15 on epoch=377
05/17/2022 11:27:59 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.22 on epoch=379
05/17/2022 11:28:01 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.17 on epoch=382
05/17/2022 11:28:02 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.11 on epoch=384
05/17/2022 11:28:03 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.06 on epoch=387
05/17/2022 11:28:04 - INFO - __main__ - Global step 1550 Train loss 1.14 Classification-F1 0.15851775604734944 on epoch=387
05/17/2022 11:28:05 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.02 on epoch=389
05/17/2022 11:28:06 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.24 on epoch=392
05/17/2022 11:28:08 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.11 on epoch=394
05/17/2022 11:28:09 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.08 on epoch=397
05/17/2022 11:28:11 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.11 on epoch=399
05/17/2022 11:28:11 - INFO - __main__ - Global step 1600 Train loss 1.11 Classification-F1 0.1 on epoch=399
05/17/2022 11:28:12 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.05 on epoch=402
05/17/2022 11:28:14 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.11 on epoch=404
05/17/2022 11:28:15 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.03 on epoch=407
05/17/2022 11:28:16 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.04 on epoch=409
05/17/2022 11:28:18 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.19 on epoch=412
05/17/2022 11:28:18 - INFO - __main__ - Global step 1650 Train loss 1.09 Classification-F1 0.2206477732793522 on epoch=412
05/17/2022 11:28:18 - INFO - __main__ - Saving model with best Classification-F1: 0.1855036855036855 -> 0.2206477732793522 on epoch=412, global_step=1650
05/17/2022 11:28:20 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.12 on epoch=414
05/17/2022 11:28:21 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.05 on epoch=417
05/17/2022 11:28:23 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.00 on epoch=419
05/17/2022 11:28:24 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.06 on epoch=422
05/17/2022 11:28:25 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.17 on epoch=424
05/17/2022 11:28:26 - INFO - __main__ - Global step 1700 Train loss 1.08 Classification-F1 0.1576923076923077 on epoch=424
05/17/2022 11:28:27 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.00 on epoch=427
05/17/2022 11:28:29 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.06 on epoch=429
05/17/2022 11:28:30 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.15 on epoch=432
05/17/2022 11:28:31 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.99 on epoch=434
05/17/2022 11:28:33 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.22 on epoch=437
05/17/2022 11:28:33 - INFO - __main__ - Global step 1750 Train loss 1.09 Classification-F1 0.18768328445747798 on epoch=437
05/17/2022 11:28:35 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.02 on epoch=439
05/17/2022 11:28:36 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.02 on epoch=442
05/17/2022 11:28:37 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.94 on epoch=444
05/17/2022 11:28:39 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.06 on epoch=447
05/17/2022 11:28:40 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.98 on epoch=449
05/17/2022 11:28:41 - INFO - __main__ - Global step 1800 Train loss 1.00 Classification-F1 0.14509803921568626 on epoch=449
05/17/2022 11:28:42 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.97 on epoch=452
05/17/2022 11:28:43 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.02 on epoch=454
05/17/2022 11:28:45 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.09 on epoch=457
05/17/2022 11:28:46 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.97 on epoch=459
05/17/2022 11:28:47 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.02 on epoch=462
05/17/2022 11:28:48 - INFO - __main__ - Global step 1850 Train loss 1.02 Classification-F1 0.10256410256410256 on epoch=462
05/17/2022 11:28:49 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.97 on epoch=464
05/17/2022 11:28:51 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.01 on epoch=467
05/17/2022 11:28:52 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.10 on epoch=469
05/17/2022 11:28:53 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.93 on epoch=472
05/17/2022 11:28:55 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.92 on epoch=474
05/17/2022 11:28:55 - INFO - __main__ - Global step 1900 Train loss 0.99 Classification-F1 0.21061869240895126 on epoch=474
05/17/2022 11:28:57 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.12 on epoch=477
05/17/2022 11:28:58 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.92 on epoch=479
05/17/2022 11:28:59 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.05 on epoch=482
05/17/2022 11:29:01 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.93 on epoch=484
05/17/2022 11:29:02 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.00 on epoch=487
05/17/2022 11:29:03 - INFO - __main__ - Global step 1950 Train loss 1.01 Classification-F1 0.20329670329670332 on epoch=487
05/17/2022 11:29:04 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.93 on epoch=489
05/17/2022 11:29:05 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.08 on epoch=492
05/17/2022 11:29:07 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.00 on epoch=494
05/17/2022 11:29:08 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.01 on epoch=497
05/17/2022 11:29:10 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.15 on epoch=499
05/17/2022 11:29:10 - INFO - __main__ - Global step 2000 Train loss 1.04 Classification-F1 0.21862787668258793 on epoch=499
05/17/2022 11:29:12 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.99 on epoch=502
05/17/2022 11:29:13 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.91 on epoch=504
05/17/2022 11:29:14 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.06 on epoch=507
05/17/2022 11:29:16 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.08 on epoch=509
05/17/2022 11:29:17 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.02 on epoch=512
05/17/2022 11:29:18 - INFO - __main__ - Global step 2050 Train loss 1.01 Classification-F1 0.1569691706469822 on epoch=512
05/17/2022 11:29:19 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.06 on epoch=514
05/17/2022 11:29:20 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.06 on epoch=517
05/17/2022 11:29:21 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.98 on epoch=519
05/17/2022 11:29:23 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.99 on epoch=522
05/17/2022 11:29:25 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.99 on epoch=524
05/17/2022 11:29:25 - INFO - __main__ - Global step 2100 Train loss 1.02 Classification-F1 0.17521739130434785 on epoch=524
05/17/2022 11:29:27 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.87 on epoch=527
05/17/2022 11:29:28 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.95 on epoch=529
05/17/2022 11:29:29 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.12 on epoch=532
05/17/2022 11:29:31 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.07 on epoch=534
05/17/2022 11:29:32 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.13 on epoch=537
05/17/2022 11:29:33 - INFO - __main__ - Global step 2150 Train loss 1.03 Classification-F1 0.09615384615384615 on epoch=537
05/17/2022 11:29:34 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.03 on epoch=539
05/17/2022 11:29:36 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.97 on epoch=542
05/17/2022 11:29:37 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.97 on epoch=544
05/17/2022 11:29:38 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.05 on epoch=547
05/17/2022 11:29:40 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.95 on epoch=549
05/17/2022 11:29:40 - INFO - __main__ - Global step 2200 Train loss 0.99 Classification-F1 0.1237183868762816 on epoch=549
05/17/2022 11:29:42 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.00 on epoch=552
05/17/2022 11:29:43 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.97 on epoch=554
05/17/2022 11:29:45 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.00 on epoch=557
05/17/2022 11:29:46 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.89 on epoch=559
05/17/2022 11:29:48 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.00 on epoch=562
05/17/2022 11:29:48 - INFO - __main__ - Global step 2250 Train loss 0.97 Classification-F1 0.13034188034188032 on epoch=562
05/17/2022 11:29:50 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.05 on epoch=564
05/17/2022 11:29:51 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.04 on epoch=567
05/17/2022 11:29:52 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.97 on epoch=569
05/17/2022 11:29:54 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.12 on epoch=572
05/17/2022 11:29:55 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.99 on epoch=574
05/17/2022 11:29:56 - INFO - __main__ - Global step 2300 Train loss 1.03 Classification-F1 0.10389610389610389 on epoch=574
05/17/2022 11:29:57 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.07 on epoch=577
05/17/2022 11:29:59 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.93 on epoch=579
05/17/2022 11:30:00 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.97 on epoch=582
05/17/2022 11:30:02 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.93 on epoch=584
05/17/2022 11:30:03 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.01 on epoch=587
05/17/2022 11:30:03 - INFO - __main__ - Global step 2350 Train loss 0.98 Classification-F1 0.20923520923520922 on epoch=587
05/17/2022 11:30:05 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.93 on epoch=589
05/17/2022 11:30:06 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.92 on epoch=592
05/17/2022 11:30:08 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.02 on epoch=594
05/17/2022 11:30:09 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.98 on epoch=597
05/17/2022 11:30:10 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.03 on epoch=599
05/17/2022 11:30:11 - INFO - __main__ - Global step 2400 Train loss 0.98 Classification-F1 0.20923520923520922 on epoch=599
05/17/2022 11:30:12 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.05 on epoch=602
05/17/2022 11:30:14 - INFO - __main__ - Step 2420 Global step 2420 Train loss 1.04 on epoch=604
05/17/2022 11:30:15 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.96 on epoch=607
05/17/2022 11:30:16 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.86 on epoch=609
05/17/2022 11:30:18 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.90 on epoch=612
05/17/2022 11:30:18 - INFO - __main__ - Global step 2450 Train loss 0.96 Classification-F1 0.1762749445676275 on epoch=612
05/17/2022 11:30:20 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.98 on epoch=614
05/17/2022 11:30:21 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.88 on epoch=617
05/17/2022 11:30:23 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.06 on epoch=619
05/17/2022 11:30:24 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.95 on epoch=622
05/17/2022 11:30:25 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.94 on epoch=624
05/17/2022 11:30:26 - INFO - __main__ - Global step 2500 Train loss 0.96 Classification-F1 0.17552334943639292 on epoch=624
05/17/2022 11:30:27 - INFO - __main__ - Step 2510 Global step 2510 Train loss 1.06 on epoch=627
05/17/2022 11:30:29 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.89 on epoch=629
05/17/2022 11:30:30 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.08 on epoch=632
05/17/2022 11:30:31 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.95 on epoch=634
05/17/2022 11:30:33 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.99 on epoch=637
05/17/2022 11:30:33 - INFO - __main__ - Global step 2550 Train loss 0.99 Classification-F1 0.11859154929577466 on epoch=637
05/17/2022 11:30:34 - INFO - __main__ - Step 2560 Global step 2560 Train loss 1.04 on epoch=639
05/17/2022 11:30:36 - INFO - __main__ - Step 2570 Global step 2570 Train loss 1.00 on epoch=642
05/17/2022 11:30:37 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.89 on epoch=644
05/17/2022 11:30:39 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.01 on epoch=647
05/17/2022 11:30:40 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.99 on epoch=649
05/17/2022 11:30:41 - INFO - __main__ - Global step 2600 Train loss 0.98 Classification-F1 0.1 on epoch=649
05/17/2022 11:30:42 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.98 on epoch=652
05/17/2022 11:30:44 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.92 on epoch=654
05/17/2022 11:30:45 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.98 on epoch=657
05/17/2022 11:30:47 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.93 on epoch=659
05/17/2022 11:30:49 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.12 on epoch=662
05/17/2022 11:30:49 - INFO - __main__ - Global step 2650 Train loss 0.99 Classification-F1 0.10126582278481013 on epoch=662
05/17/2022 11:30:51 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.94 on epoch=664
05/17/2022 11:30:52 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.97 on epoch=667
05/17/2022 11:30:53 - INFO - __main__ - Step 2680 Global step 2680 Train loss 1.02 on epoch=669
05/17/2022 11:30:55 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.91 on epoch=672
05/17/2022 11:30:56 - INFO - __main__ - Step 2700 Global step 2700 Train loss 1.05 on epoch=674
05/17/2022 11:30:57 - INFO - __main__ - Global step 2700 Train loss 0.98 Classification-F1 0.1388888888888889 on epoch=674
05/17/2022 11:30:58 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.01 on epoch=677
05/17/2022 11:30:59 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.94 on epoch=679
05/17/2022 11:31:01 - INFO - __main__ - Step 2730 Global step 2730 Train loss 1.01 on epoch=682
05/17/2022 11:31:02 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.92 on epoch=684
05/17/2022 11:31:03 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.88 on epoch=687
05/17/2022 11:31:04 - INFO - __main__ - Global step 2750 Train loss 0.95 Classification-F1 0.22186932849364793 on epoch=687
05/17/2022 11:31:04 - INFO - __main__ - Saving model with best Classification-F1: 0.2206477732793522 -> 0.22186932849364793 on epoch=687, global_step=2750
05/17/2022 11:31:05 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.92 on epoch=689
05/17/2022 11:31:07 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.92 on epoch=692
05/17/2022 11:31:08 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.98 on epoch=694
05/17/2022 11:31:09 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.91 on epoch=697
05/17/2022 11:31:11 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.91 on epoch=699
05/17/2022 11:31:11 - INFO - __main__ - Global step 2800 Train loss 0.93 Classification-F1 0.13067758749069247 on epoch=699
05/17/2022 11:31:13 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.93 on epoch=702
05/17/2022 11:31:14 - INFO - __main__ - Step 2820 Global step 2820 Train loss 1.01 on epoch=704
05/17/2022 11:31:16 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.97 on epoch=707
05/17/2022 11:31:17 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.95 on epoch=709
05/17/2022 11:31:18 - INFO - __main__ - Step 2850 Global step 2850 Train loss 1.02 on epoch=712
05/17/2022 11:31:19 - INFO - __main__ - Global step 2850 Train loss 0.98 Classification-F1 0.11805555555555555 on epoch=712
05/17/2022 11:31:21 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.92 on epoch=714
05/17/2022 11:31:22 - INFO - __main__ - Step 2870 Global step 2870 Train loss 1.04 on epoch=717
05/17/2022 11:31:24 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.95 on epoch=719
05/17/2022 11:31:25 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.97 on epoch=722
05/17/2022 11:31:26 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.98 on epoch=724
05/17/2022 11:31:27 - INFO - __main__ - Global step 2900 Train loss 0.97 Classification-F1 0.13067758749069247 on epoch=724
05/17/2022 11:31:29 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.04 on epoch=727
05/17/2022 11:31:30 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.93 on epoch=729
05/17/2022 11:31:32 - INFO - __main__ - Step 2930 Global step 2930 Train loss 1.00 on epoch=732
05/17/2022 11:31:33 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.92 on epoch=734
05/17/2022 11:31:35 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.94 on epoch=737
05/17/2022 11:31:35 - INFO - __main__ - Global step 2950 Train loss 0.97 Classification-F1 0.1581196581196581 on epoch=737
05/17/2022 11:31:36 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.94 on epoch=739
05/17/2022 11:31:38 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.95 on epoch=742
05/17/2022 11:31:39 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.81 on epoch=744
05/17/2022 11:31:41 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.98 on epoch=747
05/17/2022 11:31:42 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.93 on epoch=749
05/17/2022 11:31:43 - INFO - __main__ - Global step 3000 Train loss 0.92 Classification-F1 0.1 on epoch=749
05/17/2022 11:31:43 - INFO - __main__ - save last model!
05/17/2022 11:31:43 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/17/2022 11:31:43 - INFO - __main__ - Start tokenizing ... 5509 instances
05/17/2022 11:31:43 - INFO - __main__ - Printing 3 examples
05/17/2022 11:31:43 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/17/2022 11:31:43 - INFO - __main__ - ['others']
05/17/2022 11:31:43 - INFO - __main__ -  [emo] what you like very little things ok
05/17/2022 11:31:43 - INFO - __main__ - ['others']
05/17/2022 11:31:43 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/17/2022 11:31:43 - INFO - __main__ - ['others']
05/17/2022 11:31:43 - INFO - __main__ - Tokenizing Input ...
05/17/2022 11:31:43 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 11:31:43 - INFO - __main__ - Printing 3 examples
05/17/2022 11:31:43 - INFO - __main__ -  [emo] how cause yes am listening
05/17/2022 11:31:43 - INFO - __main__ - ['others']
05/17/2022 11:31:43 - INFO - __main__ -  [emo] ok that way i like living wwrong
05/17/2022 11:31:43 - INFO - __main__ - ['others']
05/17/2022 11:31:43 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
05/17/2022 11:31:43 - INFO - __main__ - ['others']
05/17/2022 11:31:43 - INFO - __main__ - Tokenizing Input ...
05/17/2022 11:31:43 - INFO - __main__ - Tokenizing Output ...
05/17/2022 11:31:43 - INFO - __main__ - Loaded 64 examples from train data
05/17/2022 11:31:43 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 11:31:43 - INFO - __main__ - Printing 3 examples
05/17/2022 11:31:43 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
05/17/2022 11:31:43 - INFO - __main__ - ['others']
05/17/2022 11:31:43 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
05/17/2022 11:31:43 - INFO - __main__ - ['others']
05/17/2022 11:31:43 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
05/17/2022 11:31:43 - INFO - __main__ - ['others']
05/17/2022 11:31:43 - INFO - __main__ - Tokenizing Input ...
05/17/2022 11:31:43 - INFO - __main__ - Tokenizing Output ...
05/17/2022 11:31:43 - INFO - __main__ - Loaded 64 examples from dev data
05/17/2022 11:31:45 - INFO - __main__ - Tokenizing Output ...
05/17/2022 11:31:50 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 11:31:50 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 11:31:50 - INFO - __main__ - Starting training!
05/17/2022 11:31:51 - INFO - __main__ - Loaded 5509 examples from test data
05/17/2022 11:32:35 - INFO - __main__ - Saved prediction in models/T5-base-reptile-cls2cls-3e-5-2-5000-5e-1-10/singletask-emo/emo_16_100_0.5_8_predictions.txt
05/17/2022 11:32:35 - INFO - __main__ - Classification-F1 on test data: 0.0216
05/17/2022 11:32:35 - INFO - __main__ - prefix=emo_16_100, lr=0.5, bsz=8, dev_performance=0.22186932849364793, test_performance=0.021633362293657688
05/17/2022 11:32:35 - INFO - __main__ - Running ... prefix=emo_16_100, lr=0.4, bsz=8 ...
05/17/2022 11:32:36 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 11:32:36 - INFO - __main__ - Printing 3 examples
05/17/2022 11:32:36 - INFO - __main__ -  [emo] how cause yes am listening
05/17/2022 11:32:36 - INFO - __main__ - ['others']
05/17/2022 11:32:36 - INFO - __main__ -  [emo] ok that way i like living wwrong
05/17/2022 11:32:36 - INFO - __main__ - ['others']
05/17/2022 11:32:36 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
05/17/2022 11:32:36 - INFO - __main__ - ['others']
05/17/2022 11:32:36 - INFO - __main__ - Tokenizing Input ...
05/17/2022 11:32:36 - INFO - __main__ - Tokenizing Output ...
05/17/2022 11:32:36 - INFO - __main__ - Loaded 64 examples from train data
05/17/2022 11:32:36 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 11:32:36 - INFO - __main__ - Printing 3 examples
05/17/2022 11:32:36 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
05/17/2022 11:32:36 - INFO - __main__ - ['others']
05/17/2022 11:32:36 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
05/17/2022 11:32:36 - INFO - __main__ - ['others']
05/17/2022 11:32:36 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
05/17/2022 11:32:36 - INFO - __main__ - ['others']
05/17/2022 11:32:36 - INFO - __main__ - Tokenizing Input ...
05/17/2022 11:32:36 - INFO - __main__ - Tokenizing Output ...
05/17/2022 11:32:36 - INFO - __main__ - Loaded 64 examples from dev data
05/17/2022 11:32:42 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 11:32:42 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 11:32:42 - INFO - __main__ - Starting training!
05/17/2022 11:32:44 - INFO - __main__ - Step 10 Global step 10 Train loss 8.94 on epoch=2
05/17/2022 11:32:45 - INFO - __main__ - Step 20 Global step 20 Train loss 8.99 on epoch=4
05/17/2022 11:32:47 - INFO - __main__ - Step 30 Global step 30 Train loss 8.91 on epoch=7
05/17/2022 11:32:48 - INFO - __main__ - Step 40 Global step 40 Train loss 8.93 on epoch=9
05/17/2022 11:32:49 - INFO - __main__ - Step 50 Global step 50 Train loss 8.84 on epoch=12
05/17/2022 11:32:56 - INFO - __main__ - Global step 50 Train loss 8.92 Classification-F1 0.0 on epoch=12
05/17/2022 11:32:56 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/17/2022 11:32:57 - INFO - __main__ - Step 60 Global step 60 Train loss 8.89 on epoch=14
05/17/2022 11:32:59 - INFO - __main__ - Step 70 Global step 70 Train loss 8.78 on epoch=17
05/17/2022 11:33:00 - INFO - __main__ - Step 80 Global step 80 Train loss 8.65 on epoch=19
05/17/2022 11:33:01 - INFO - __main__ - Step 90 Global step 90 Train loss 8.67 on epoch=22
05/17/2022 11:33:03 - INFO - __main__ - Step 100 Global step 100 Train loss 8.58 on epoch=24
05/17/2022 11:33:09 - INFO - __main__ - Global step 100 Train loss 8.71 Classification-F1 0.0 on epoch=24
05/17/2022 11:33:10 - INFO - __main__ - Step 110 Global step 110 Train loss 8.55 on epoch=27
05/17/2022 11:33:11 - INFO - __main__ - Step 120 Global step 120 Train loss 8.49 on epoch=29
05/17/2022 11:33:13 - INFO - __main__ - Step 130 Global step 130 Train loss 8.27 on epoch=32
05/17/2022 11:33:14 - INFO - __main__ - Step 140 Global step 140 Train loss 8.08 on epoch=34
05/17/2022 11:33:15 - INFO - __main__ - Step 150 Global step 150 Train loss 8.02 on epoch=37
05/17/2022 11:33:36 - INFO - __main__ - Global step 150 Train loss 8.28 Classification-F1 0.0 on epoch=37
05/17/2022 11:33:38 - INFO - __main__ - Step 160 Global step 160 Train loss 7.86 on epoch=39
05/17/2022 11:33:39 - INFO - __main__ - Step 170 Global step 170 Train loss 7.72 on epoch=42
05/17/2022 11:33:40 - INFO - __main__ - Step 180 Global step 180 Train loss 7.65 on epoch=44
05/17/2022 11:33:42 - INFO - __main__ - Step 190 Global step 190 Train loss 7.34 on epoch=47
05/17/2022 11:33:43 - INFO - __main__ - Step 200 Global step 200 Train loss 7.17 on epoch=49
05/17/2022 11:33:47 - INFO - __main__ - Global step 200 Train loss 7.55 Classification-F1 0.0 on epoch=49
05/17/2022 11:33:48 - INFO - __main__ - Step 210 Global step 210 Train loss 7.08 on epoch=52
05/17/2022 11:33:49 - INFO - __main__ - Step 220 Global step 220 Train loss 7.15 on epoch=54
05/17/2022 11:33:51 - INFO - __main__ - Step 230 Global step 230 Train loss 6.78 on epoch=57
05/17/2022 11:33:52 - INFO - __main__ - Step 240 Global step 240 Train loss 6.61 on epoch=59
05/17/2022 11:33:53 - INFO - __main__ - Step 250 Global step 250 Train loss 6.60 on epoch=62
05/17/2022 11:33:57 - INFO - __main__ - Global step 250 Train loss 6.84 Classification-F1 0.0 on epoch=62
05/17/2022 11:33:59 - INFO - __main__ - Step 260 Global step 260 Train loss 6.37 on epoch=64
05/17/2022 11:34:00 - INFO - __main__ - Step 270 Global step 270 Train loss 6.26 on epoch=67
05/17/2022 11:34:01 - INFO - __main__ - Step 280 Global step 280 Train loss 5.78 on epoch=69
05/17/2022 11:34:03 - INFO - __main__ - Step 290 Global step 290 Train loss 5.84 on epoch=72
05/17/2022 11:34:04 - INFO - __main__ - Step 300 Global step 300 Train loss 5.53 on epoch=74
05/17/2022 11:34:08 - INFO - __main__ - Global step 300 Train loss 5.96 Classification-F1 0.0 on epoch=74
05/17/2022 11:34:09 - INFO - __main__ - Step 310 Global step 310 Train loss 5.37 on epoch=77
05/17/2022 11:34:11 - INFO - __main__ - Step 320 Global step 320 Train loss 5.45 on epoch=79
05/17/2022 11:34:12 - INFO - __main__ - Step 330 Global step 330 Train loss 4.96 on epoch=82
05/17/2022 11:34:14 - INFO - __main__ - Step 340 Global step 340 Train loss 4.90 on epoch=84
05/17/2022 11:34:15 - INFO - __main__ - Step 350 Global step 350 Train loss 4.84 on epoch=87
05/17/2022 11:34:25 - INFO - __main__ - Global step 350 Train loss 5.10 Classification-F1 0.0 on epoch=87
05/17/2022 11:34:27 - INFO - __main__ - Step 360 Global step 360 Train loss 4.57 on epoch=89
05/17/2022 11:34:28 - INFO - __main__ - Step 370 Global step 370 Train loss 4.74 on epoch=92
05/17/2022 11:34:29 - INFO - __main__ - Step 380 Global step 380 Train loss 4.60 on epoch=94
05/17/2022 11:34:31 - INFO - __main__ - Step 390 Global step 390 Train loss 4.73 on epoch=97
05/17/2022 11:34:32 - INFO - __main__ - Step 400 Global step 400 Train loss 4.45 on epoch=99
05/17/2022 11:34:38 - INFO - __main__ - Global step 400 Train loss 4.62 Classification-F1 0.0 on epoch=99
05/17/2022 11:34:40 - INFO - __main__ - Step 410 Global step 410 Train loss 4.43 on epoch=102
05/17/2022 11:34:41 - INFO - __main__ - Step 420 Global step 420 Train loss 4.12 on epoch=104
05/17/2022 11:34:43 - INFO - __main__ - Step 430 Global step 430 Train loss 4.11 on epoch=107
05/17/2022 11:34:44 - INFO - __main__ - Step 440 Global step 440 Train loss 3.99 on epoch=109
05/17/2022 11:34:46 - INFO - __main__ - Step 450 Global step 450 Train loss 4.11 on epoch=112
05/17/2022 11:34:51 - INFO - __main__ - Global step 450 Train loss 4.15 Classification-F1 0.0 on epoch=112
05/17/2022 11:34:52 - INFO - __main__ - Step 460 Global step 460 Train loss 3.70 on epoch=114
05/17/2022 11:34:53 - INFO - __main__ - Step 470 Global step 470 Train loss 3.85 on epoch=117
05/17/2022 11:34:55 - INFO - __main__ - Step 480 Global step 480 Train loss 3.72 on epoch=119
05/17/2022 11:34:56 - INFO - __main__ - Step 490 Global step 490 Train loss 3.64 on epoch=122
05/17/2022 11:34:57 - INFO - __main__ - Step 500 Global step 500 Train loss 3.51 on epoch=124
05/17/2022 11:35:02 - INFO - __main__ - Global step 500 Train loss 3.68 Classification-F1 0.0 on epoch=124
05/17/2022 11:35:03 - INFO - __main__ - Step 510 Global step 510 Train loss 3.48 on epoch=127
05/17/2022 11:35:05 - INFO - __main__ - Step 520 Global step 520 Train loss 3.34 on epoch=129
05/17/2022 11:35:06 - INFO - __main__ - Step 530 Global step 530 Train loss 3.50 on epoch=132
05/17/2022 11:35:07 - INFO - __main__ - Step 540 Global step 540 Train loss 3.38 on epoch=134
05/17/2022 11:35:09 - INFO - __main__ - Step 550 Global step 550 Train loss 3.21 on epoch=137
05/17/2022 11:35:09 - INFO - __main__ - Global step 550 Train loss 3.38 Classification-F1 0.10126582278481013 on epoch=137
05/17/2022 11:35:10 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.10126582278481013 on epoch=137, global_step=550
05/17/2022 11:35:11 - INFO - __main__ - Step 560 Global step 560 Train loss 3.02 on epoch=139
05/17/2022 11:35:12 - INFO - __main__ - Step 570 Global step 570 Train loss 3.33 on epoch=142
05/17/2022 11:35:14 - INFO - __main__ - Step 580 Global step 580 Train loss 2.88 on epoch=144
05/17/2022 11:35:15 - INFO - __main__ - Step 590 Global step 590 Train loss 2.93 on epoch=147
05/17/2022 11:35:16 - INFO - __main__ - Step 600 Global step 600 Train loss 2.80 on epoch=149
05/17/2022 11:35:21 - INFO - __main__ - Global step 600 Train loss 2.99 Classification-F1 0.17857142857142858 on epoch=149
05/17/2022 11:35:21 - INFO - __main__ - Saving model with best Classification-F1: 0.10126582278481013 -> 0.17857142857142858 on epoch=149, global_step=600
05/17/2022 11:35:23 - INFO - __main__ - Step 610 Global step 610 Train loss 2.78 on epoch=152
05/17/2022 11:35:24 - INFO - __main__ - Step 620 Global step 620 Train loss 2.52 on epoch=154
05/17/2022 11:35:25 - INFO - __main__ - Step 630 Global step 630 Train loss 2.82 on epoch=157
05/17/2022 11:35:27 - INFO - __main__ - Step 640 Global step 640 Train loss 2.44 on epoch=159
05/17/2022 11:35:28 - INFO - __main__ - Step 650 Global step 650 Train loss 2.51 on epoch=162
05/17/2022 11:35:29 - INFO - __main__ - Global step 650 Train loss 2.61 Classification-F1 0.18623481781376516 on epoch=162
05/17/2022 11:35:29 - INFO - __main__ - Saving model with best Classification-F1: 0.17857142857142858 -> 0.18623481781376516 on epoch=162, global_step=650
05/17/2022 11:35:30 - INFO - __main__ - Step 660 Global step 660 Train loss 2.39 on epoch=164
05/17/2022 11:35:31 - INFO - __main__ - Step 670 Global step 670 Train loss 2.30 on epoch=167
05/17/2022 11:35:33 - INFO - __main__ - Step 680 Global step 680 Train loss 2.26 on epoch=169
05/17/2022 11:35:34 - INFO - __main__ - Step 690 Global step 690 Train loss 2.32 on epoch=172
05/17/2022 11:35:35 - INFO - __main__ - Step 700 Global step 700 Train loss 2.02 on epoch=174
05/17/2022 11:35:36 - INFO - __main__ - Global step 700 Train loss 2.26 Classification-F1 0.1 on epoch=174
05/17/2022 11:35:37 - INFO - __main__ - Step 710 Global step 710 Train loss 2.26 on epoch=177
05/17/2022 11:35:38 - INFO - __main__ - Step 720 Global step 720 Train loss 2.01 on epoch=179
05/17/2022 11:35:40 - INFO - __main__ - Step 730 Global step 730 Train loss 1.90 on epoch=182
05/17/2022 11:35:41 - INFO - __main__ - Step 740 Global step 740 Train loss 2.00 on epoch=184
05/17/2022 11:35:43 - INFO - __main__ - Step 750 Global step 750 Train loss 1.95 on epoch=187
05/17/2022 11:35:43 - INFO - __main__ - Global step 750 Train loss 2.02 Classification-F1 0.1388888888888889 on epoch=187
05/17/2022 11:35:45 - INFO - __main__ - Step 760 Global step 760 Train loss 1.87 on epoch=189
05/17/2022 11:35:46 - INFO - __main__ - Step 770 Global step 770 Train loss 1.85 on epoch=192
05/17/2022 11:35:47 - INFO - __main__ - Step 780 Global step 780 Train loss 1.66 on epoch=194
05/17/2022 11:35:49 - INFO - __main__ - Step 790 Global step 790 Train loss 1.83 on epoch=197
05/17/2022 11:35:50 - INFO - __main__ - Step 800 Global step 800 Train loss 1.70 on epoch=199
05/17/2022 11:35:51 - INFO - __main__ - Global step 800 Train loss 1.78 Classification-F1 0.09493670886075949 on epoch=199
05/17/2022 11:35:52 - INFO - __main__ - Step 810 Global step 810 Train loss 1.69 on epoch=202
05/17/2022 11:35:53 - INFO - __main__ - Step 820 Global step 820 Train loss 1.78 on epoch=204
05/17/2022 11:35:55 - INFO - __main__ - Step 830 Global step 830 Train loss 1.60 on epoch=207
05/17/2022 11:35:56 - INFO - __main__ - Step 840 Global step 840 Train loss 1.46 on epoch=209
05/17/2022 11:35:57 - INFO - __main__ - Step 850 Global step 850 Train loss 1.59 on epoch=212
05/17/2022 11:35:58 - INFO - __main__ - Global step 850 Train loss 1.62 Classification-F1 0.13034188034188032 on epoch=212
05/17/2022 11:36:00 - INFO - __main__ - Step 860 Global step 860 Train loss 1.62 on epoch=214
05/17/2022 11:36:01 - INFO - __main__ - Step 870 Global step 870 Train loss 1.64 on epoch=217
05/17/2022 11:36:03 - INFO - __main__ - Step 880 Global step 880 Train loss 1.33 on epoch=219
05/17/2022 11:36:04 - INFO - __main__ - Step 890 Global step 890 Train loss 1.33 on epoch=222
05/17/2022 11:36:05 - INFO - __main__ - Step 900 Global step 900 Train loss 1.34 on epoch=224
05/17/2022 11:36:06 - INFO - __main__ - Global step 900 Train loss 1.45 Classification-F1 0.1 on epoch=224
05/17/2022 11:36:08 - INFO - __main__ - Step 910 Global step 910 Train loss 1.30 on epoch=227
05/17/2022 11:36:09 - INFO - __main__ - Step 920 Global step 920 Train loss 1.41 on epoch=229
05/17/2022 11:36:10 - INFO - __main__ - Step 930 Global step 930 Train loss 1.34 on epoch=232
05/17/2022 11:36:12 - INFO - __main__ - Step 940 Global step 940 Train loss 1.39 on epoch=234
05/17/2022 11:36:13 - INFO - __main__ - Step 950 Global step 950 Train loss 1.40 on epoch=237
05/17/2022 11:36:14 - INFO - __main__ - Global step 950 Train loss 1.37 Classification-F1 0.15966386554621848 on epoch=237
05/17/2022 11:36:15 - INFO - __main__ - Step 960 Global step 960 Train loss 1.33 on epoch=239
05/17/2022 11:36:16 - INFO - __main__ - Step 970 Global step 970 Train loss 1.93 on epoch=242
05/17/2022 11:36:18 - INFO - __main__ - Step 980 Global step 980 Train loss 1.27 on epoch=244
05/17/2022 11:36:19 - INFO - __main__ - Step 990 Global step 990 Train loss 1.33 on epoch=247
05/17/2022 11:36:21 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.32 on epoch=249
05/17/2022 11:36:21 - INFO - __main__ - Global step 1000 Train loss 1.44 Classification-F1 0.1 on epoch=249
05/17/2022 11:36:22 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.37 on epoch=252
05/17/2022 11:36:24 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.18 on epoch=254
05/17/2022 11:36:25 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.33 on epoch=257
05/17/2022 11:36:27 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.44 on epoch=259
05/17/2022 11:36:28 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.31 on epoch=262
05/17/2022 11:36:28 - INFO - __main__ - Global step 1050 Train loss 1.33 Classification-F1 0.1569691706469822 on epoch=262
05/17/2022 11:36:30 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.14 on epoch=264
05/17/2022 11:36:31 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.23 on epoch=267
05/17/2022 11:36:33 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.32 on epoch=269
05/17/2022 11:36:34 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.23 on epoch=272
05/17/2022 11:36:35 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.27 on epoch=274
05/17/2022 11:36:36 - INFO - __main__ - Global step 1100 Train loss 1.24 Classification-F1 0.18181818181818182 on epoch=274
05/17/2022 11:36:37 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.19 on epoch=277
05/17/2022 11:36:38 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.15 on epoch=279
05/17/2022 11:36:40 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.13 on epoch=282
05/17/2022 11:36:41 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.25 on epoch=284
05/17/2022 11:36:42 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.20 on epoch=287
05/17/2022 11:36:43 - INFO - __main__ - Global step 1150 Train loss 1.18 Classification-F1 0.12368421052631579 on epoch=287
05/17/2022 11:36:44 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.17 on epoch=289
05/17/2022 11:36:46 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.18 on epoch=292
05/17/2022 11:36:47 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.16 on epoch=294
05/17/2022 11:36:48 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.11 on epoch=297
05/17/2022 11:36:50 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.11 on epoch=299
05/17/2022 11:36:50 - INFO - __main__ - Global step 1200 Train loss 1.15 Classification-F1 0.1883587427065688 on epoch=299
05/17/2022 11:36:50 - INFO - __main__ - Saving model with best Classification-F1: 0.18623481781376516 -> 0.1883587427065688 on epoch=299, global_step=1200
05/17/2022 11:36:52 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.19 on epoch=302
05/17/2022 11:36:53 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.14 on epoch=304
05/17/2022 11:36:55 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.20 on epoch=307
05/17/2022 11:36:56 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.25 on epoch=309
05/17/2022 11:36:57 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.12 on epoch=312
05/17/2022 11:36:58 - INFO - __main__ - Global step 1250 Train loss 1.18 Classification-F1 0.17162540691952458 on epoch=312
05/17/2022 11:36:59 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.14 on epoch=314
05/17/2022 11:37:01 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.11 on epoch=317
05/17/2022 11:37:02 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.16 on epoch=319
05/17/2022 11:37:03 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.18 on epoch=322
05/17/2022 11:37:05 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.22 on epoch=324
05/17/2022 11:37:05 - INFO - __main__ - Global step 1300 Train loss 1.16 Classification-F1 0.13067758749069247 on epoch=324
05/17/2022 11:37:07 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.01 on epoch=327
05/17/2022 11:37:08 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.15 on epoch=329
05/17/2022 11:37:10 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.01 on epoch=332
05/17/2022 11:37:11 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.14 on epoch=334
05/17/2022 11:37:13 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.12 on epoch=337
05/17/2022 11:37:13 - INFO - __main__ - Global step 1350 Train loss 1.09 Classification-F1 0.20189600927305845 on epoch=337
05/17/2022 11:37:13 - INFO - __main__ - Saving model with best Classification-F1: 0.1883587427065688 -> 0.20189600927305845 on epoch=337, global_step=1350
05/17/2022 11:37:15 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.15 on epoch=339
05/17/2022 11:37:16 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.11 on epoch=342
05/17/2022 11:37:17 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.01 on epoch=344
05/17/2022 11:37:19 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.07 on epoch=347
05/17/2022 11:37:20 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.18 on epoch=349
05/17/2022 11:37:21 - INFO - __main__ - Global step 1400 Train loss 1.10 Classification-F1 0.2069069069069069 on epoch=349
05/17/2022 11:37:21 - INFO - __main__ - Saving model with best Classification-F1: 0.20189600927305845 -> 0.2069069069069069 on epoch=349, global_step=1400
05/17/2022 11:37:22 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.13 on epoch=352
05/17/2022 11:37:23 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.98 on epoch=354
05/17/2022 11:37:25 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.14 on epoch=357
05/17/2022 11:37:26 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.96 on epoch=359
05/17/2022 11:37:27 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.13 on epoch=362
05/17/2022 11:37:28 - INFO - __main__ - Global step 1450 Train loss 1.07 Classification-F1 0.28793650793650793 on epoch=362
05/17/2022 11:37:28 - INFO - __main__ - Saving model with best Classification-F1: 0.2069069069069069 -> 0.28793650793650793 on epoch=362, global_step=1450
05/17/2022 11:37:29 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.05 on epoch=364
05/17/2022 11:37:31 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.09 on epoch=367
05/17/2022 11:37:32 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.00 on epoch=369
05/17/2022 11:37:33 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.05 on epoch=372
05/17/2022 11:37:35 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.14 on epoch=374
05/17/2022 11:37:35 - INFO - __main__ - Global step 1500 Train loss 1.07 Classification-F1 0.1 on epoch=374
05/17/2022 11:37:37 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.24 on epoch=377
05/17/2022 11:37:38 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.07 on epoch=379
05/17/2022 11:37:40 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.12 on epoch=382
05/17/2022 11:37:41 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.98 on epoch=384
05/17/2022 11:37:42 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.10 on epoch=387
05/17/2022 11:37:43 - INFO - __main__ - Global step 1550 Train loss 1.10 Classification-F1 0.11732186732186733 on epoch=387
05/17/2022 11:37:44 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.06 on epoch=389
05/17/2022 11:37:46 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.07 on epoch=392
05/17/2022 11:37:47 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.09 on epoch=394
05/17/2022 11:37:48 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.08 on epoch=397
05/17/2022 11:37:50 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.04 on epoch=399
05/17/2022 11:37:50 - INFO - __main__ - Global step 1600 Train loss 1.07 Classification-F1 0.1 on epoch=399
05/17/2022 11:37:51 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.04 on epoch=402
05/17/2022 11:37:53 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.04 on epoch=404
05/17/2022 11:37:54 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.16 on epoch=407
05/17/2022 11:37:56 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.22 on epoch=409
05/17/2022 11:37:57 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.01 on epoch=412
05/17/2022 11:37:57 - INFO - __main__ - Global step 1650 Train loss 1.09 Classification-F1 0.191533180778032 on epoch=412
05/17/2022 11:37:59 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.95 on epoch=414
05/17/2022 11:38:00 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.94 on epoch=417
05/17/2022 11:38:02 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.05 on epoch=419
05/17/2022 11:38:03 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.07 on epoch=422
05/17/2022 11:38:05 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.04 on epoch=424
05/17/2022 11:38:06 - INFO - __main__ - Global step 1700 Train loss 1.01 Classification-F1 0.1769230769230769 on epoch=424
05/17/2022 11:38:07 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.12 on epoch=427
05/17/2022 11:38:08 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.91 on epoch=429
05/17/2022 11:38:10 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.99 on epoch=432
05/17/2022 11:38:11 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.95 on epoch=434
05/17/2022 11:38:13 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.06 on epoch=437
05/17/2022 11:38:14 - INFO - __main__ - Global step 1750 Train loss 1.01 Classification-F1 0.13067758749069247 on epoch=437
05/17/2022 11:38:15 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.05 on epoch=439
05/17/2022 11:38:17 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.02 on epoch=442
05/17/2022 11:38:19 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.08 on epoch=444
05/17/2022 11:38:20 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.90 on epoch=447
05/17/2022 11:38:22 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.05 on epoch=449
05/17/2022 11:38:22 - INFO - __main__ - Global step 1800 Train loss 1.02 Classification-F1 0.1 on epoch=449
05/17/2022 11:38:24 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.16 on epoch=452
05/17/2022 11:38:26 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.03 on epoch=454
05/17/2022 11:38:27 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.97 on epoch=457
05/17/2022 11:38:29 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.06 on epoch=459
05/17/2022 11:38:30 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.03 on epoch=462
05/17/2022 11:38:31 - INFO - __main__ - Global step 1850 Train loss 1.05 Classification-F1 0.12407862407862408 on epoch=462
05/17/2022 11:38:32 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.12 on epoch=464
05/17/2022 11:38:33 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.02 on epoch=467
05/17/2022 11:38:35 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.97 on epoch=469
05/17/2022 11:38:36 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.08 on epoch=472
05/17/2022 11:38:37 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.07 on epoch=474
05/17/2022 11:38:38 - INFO - __main__ - Global step 1900 Train loss 1.05 Classification-F1 0.10126582278481013 on epoch=474
05/17/2022 11:38:39 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.08 on epoch=477
05/17/2022 11:38:41 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.98 on epoch=479
05/17/2022 11:38:42 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.00 on epoch=482
05/17/2022 11:38:44 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.93 on epoch=484
05/17/2022 11:38:45 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.05 on epoch=487
05/17/2022 11:38:46 - INFO - __main__ - Global step 1950 Train loss 1.01 Classification-F1 0.17552334943639292 on epoch=487
05/17/2022 11:38:47 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.97 on epoch=489
05/17/2022 11:38:49 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.91 on epoch=492
05/17/2022 11:38:50 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.06 on epoch=494
05/17/2022 11:38:51 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.08 on epoch=497
05/17/2022 11:38:53 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.09 on epoch=499
05/17/2022 11:38:53 - INFO - __main__ - Global step 2000 Train loss 1.02 Classification-F1 0.1476190476190476 on epoch=499
05/17/2022 11:38:55 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.99 on epoch=502
05/17/2022 11:38:56 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.00 on epoch=504
05/17/2022 11:38:58 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.02 on epoch=507
05/17/2022 11:38:59 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.99 on epoch=509
05/17/2022 11:39:00 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.95 on epoch=512
05/17/2022 11:39:01 - INFO - __main__ - Global step 2050 Train loss 0.99 Classification-F1 0.09868421052631579 on epoch=512
05/17/2022 11:39:02 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.05 on epoch=514
05/17/2022 11:39:04 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.02 on epoch=517
05/17/2022 11:39:05 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.99 on epoch=519
05/17/2022 11:39:06 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.04 on epoch=522
05/17/2022 11:39:08 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.03 on epoch=524
05/17/2022 11:39:08 - INFO - __main__ - Global step 2100 Train loss 1.03 Classification-F1 0.12499999999999999 on epoch=524
05/17/2022 11:39:10 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.90 on epoch=527
05/17/2022 11:39:11 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.03 on epoch=529
05/17/2022 11:39:12 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.05 on epoch=532
05/17/2022 11:39:14 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.96 on epoch=534
05/17/2022 11:39:15 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.90 on epoch=537
05/17/2022 11:39:16 - INFO - __main__ - Global step 2150 Train loss 0.97 Classification-F1 0.20146520146520144 on epoch=537
05/17/2022 11:39:17 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.91 on epoch=539
05/17/2022 11:39:18 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.01 on epoch=542
05/17/2022 11:39:20 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.01 on epoch=544
05/17/2022 11:39:21 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.98 on epoch=547
05/17/2022 11:39:22 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.98 on epoch=549
05/17/2022 11:39:23 - INFO - __main__ - Global step 2200 Train loss 0.98 Classification-F1 0.14583333333333331 on epoch=549
05/17/2022 11:39:24 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.00 on epoch=552
05/17/2022 11:39:26 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.10 on epoch=554
05/17/2022 11:39:27 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.07 on epoch=557
05/17/2022 11:39:28 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.97 on epoch=559
05/17/2022 11:39:30 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.98 on epoch=562
05/17/2022 11:39:30 - INFO - __main__ - Global step 2250 Train loss 1.02 Classification-F1 0.203125 on epoch=562
05/17/2022 11:39:31 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.91 on epoch=564
05/17/2022 11:39:33 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.90 on epoch=567
05/17/2022 11:39:34 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.95 on epoch=569
05/17/2022 11:39:36 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.97 on epoch=572
05/17/2022 11:39:37 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.95 on epoch=574
05/17/2022 11:39:38 - INFO - __main__ - Global step 2300 Train loss 0.94 Classification-F1 0.17517605633802816 on epoch=574
05/17/2022 11:39:39 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.01 on epoch=577
05/17/2022 11:39:40 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.95 on epoch=579
05/17/2022 11:39:42 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.95 on epoch=582
05/17/2022 11:39:43 - INFO - __main__ - Step 2340 Global step 2340 Train loss 1.01 on epoch=584
05/17/2022 11:39:44 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.99 on epoch=587
05/17/2022 11:39:45 - INFO - __main__ - Global step 2350 Train loss 0.98 Classification-F1 0.147459165154265 on epoch=587
05/17/2022 11:39:46 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.88 on epoch=589
05/17/2022 11:39:47 - INFO - __main__ - Step 2370 Global step 2370 Train loss 1.03 on epoch=592
05/17/2022 11:39:49 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.03 on epoch=594
05/17/2022 11:39:50 - INFO - __main__ - Step 2390 Global step 2390 Train loss 1.05 on epoch=597
05/17/2022 11:39:52 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.92 on epoch=599
05/17/2022 11:39:52 - INFO - __main__ - Global step 2400 Train loss 0.98 Classification-F1 0.20867208672086718 on epoch=599
05/17/2022 11:39:53 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.98 on epoch=602
05/17/2022 11:39:55 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.94 on epoch=604
05/17/2022 11:39:56 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.00 on epoch=607
05/17/2022 11:39:58 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.93 on epoch=609
05/17/2022 11:39:59 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.02 on epoch=612
05/17/2022 11:40:00 - INFO - __main__ - Global step 2450 Train loss 0.98 Classification-F1 0.19615384615384615 on epoch=612
05/17/2022 11:40:01 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.93 on epoch=614
05/17/2022 11:40:02 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.97 on epoch=617
05/17/2022 11:40:04 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.86 on epoch=619
05/17/2022 11:40:05 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.93 on epoch=622
05/17/2022 11:40:07 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.84 on epoch=624
05/17/2022 11:40:07 - INFO - __main__ - Global step 2500 Train loss 0.91 Classification-F1 0.19615384615384615 on epoch=624
05/17/2022 11:40:09 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.99 on epoch=627
05/17/2022 11:40:10 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.97 on epoch=629
05/17/2022 11:40:12 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.94 on epoch=632
05/17/2022 11:40:13 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.95 on epoch=634
05/17/2022 11:40:15 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.94 on epoch=637
05/17/2022 11:40:16 - INFO - __main__ - Global step 2550 Train loss 0.96 Classification-F1 0.125 on epoch=637
05/17/2022 11:40:17 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.97 on epoch=639
05/17/2022 11:40:18 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.89 on epoch=642
05/17/2022 11:40:20 - INFO - __main__ - Step 2580 Global step 2580 Train loss 1.04 on epoch=644
05/17/2022 11:40:21 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.03 on epoch=647
05/17/2022 11:40:23 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.98 on epoch=649
05/17/2022 11:40:23 - INFO - __main__ - Global step 2600 Train loss 0.98 Classification-F1 0.15584415584415584 on epoch=649
05/17/2022 11:40:24 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.98 on epoch=652
05/17/2022 11:40:26 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.95 on epoch=654
05/17/2022 11:40:27 - INFO - __main__ - Step 2630 Global step 2630 Train loss 1.03 on epoch=657
05/17/2022 11:40:29 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.90 on epoch=659
05/17/2022 11:40:30 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.01 on epoch=662
05/17/2022 11:40:31 - INFO - __main__ - Global step 2650 Train loss 0.97 Classification-F1 0.16370023419203747 on epoch=662
05/17/2022 11:40:32 - INFO - __main__ - Step 2660 Global step 2660 Train loss 1.01 on epoch=664
05/17/2022 11:40:33 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.94 on epoch=667
05/17/2022 11:40:35 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.93 on epoch=669
05/17/2022 11:40:36 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.93 on epoch=672
05/17/2022 11:40:37 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.89 on epoch=674
05/17/2022 11:40:38 - INFO - __main__ - Global step 2700 Train loss 0.94 Classification-F1 0.1472743930371049 on epoch=674
05/17/2022 11:40:39 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.00 on epoch=677
05/17/2022 11:40:41 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.86 on epoch=679
05/17/2022 11:40:42 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.93 on epoch=682
05/17/2022 11:40:43 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.95 on epoch=684
05/17/2022 11:40:45 - INFO - __main__ - Step 2750 Global step 2750 Train loss 1.03 on epoch=687
05/17/2022 11:40:45 - INFO - __main__ - Global step 2750 Train loss 0.95 Classification-F1 0.2602840909090909 on epoch=687
05/17/2022 11:40:47 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.00 on epoch=689
05/17/2022 11:40:48 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.93 on epoch=692
05/17/2022 11:40:50 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.89 on epoch=694
05/17/2022 11:40:51 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.93 on epoch=697
05/17/2022 11:40:52 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.88 on epoch=699
05/17/2022 11:40:53 - INFO - __main__ - Global step 2800 Train loss 0.93 Classification-F1 0.15526315789473685 on epoch=699
05/17/2022 11:40:54 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.95 on epoch=702
05/17/2022 11:40:56 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.97 on epoch=704
05/17/2022 11:40:57 - INFO - __main__ - Step 2830 Global step 2830 Train loss 1.00 on epoch=707
05/17/2022 11:40:58 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.98 on epoch=709
05/17/2022 11:41:00 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.91 on epoch=712
05/17/2022 11:41:00 - INFO - __main__ - Global step 2850 Train loss 0.96 Classification-F1 0.1 on epoch=712
05/17/2022 11:41:02 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.87 on epoch=714
05/17/2022 11:41:03 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.99 on epoch=717
05/17/2022 11:41:04 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.91 on epoch=719
05/17/2022 11:41:06 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.94 on epoch=722
05/17/2022 11:41:07 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.93 on epoch=724
05/17/2022 11:41:08 - INFO - __main__ - Global step 2900 Train loss 0.93 Classification-F1 0.140625 on epoch=724
05/17/2022 11:41:09 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.00 on epoch=727
05/17/2022 11:41:11 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.93 on epoch=729
05/17/2022 11:41:12 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.95 on epoch=732
05/17/2022 11:41:13 - INFO - __main__ - Step 2940 Global step 2940 Train loss 1.03 on epoch=734
05/17/2022 11:41:15 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.87 on epoch=737
05/17/2022 11:41:15 - INFO - __main__ - Global step 2950 Train loss 0.96 Classification-F1 0.13482414242292662 on epoch=737
05/17/2022 11:41:17 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.90 on epoch=739
05/17/2022 11:41:18 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.90 on epoch=742
05/17/2022 11:41:20 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.87 on epoch=744
05/17/2022 11:41:21 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.93 on epoch=747
05/17/2022 11:41:22 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.93 on epoch=749
05/17/2022 11:41:23 - INFO - __main__ - Global step 3000 Train loss 0.90 Classification-F1 0.17220843672456576 on epoch=749
05/17/2022 11:41:23 - INFO - __main__ - save last model!
05/17/2022 11:41:23 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/17/2022 11:41:23 - INFO - __main__ - Start tokenizing ... 5509 instances
05/17/2022 11:41:23 - INFO - __main__ - Printing 3 examples
05/17/2022 11:41:23 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/17/2022 11:41:23 - INFO - __main__ - ['others']
05/17/2022 11:41:23 - INFO - __main__ -  [emo] what you like very little things ok
05/17/2022 11:41:23 - INFO - __main__ - ['others']
05/17/2022 11:41:23 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/17/2022 11:41:23 - INFO - __main__ - ['others']
05/17/2022 11:41:23 - INFO - __main__ - Tokenizing Input ...
05/17/2022 11:41:24 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 11:41:24 - INFO - __main__ - Printing 3 examples
05/17/2022 11:41:24 - INFO - __main__ -  [emo] how cause yes am listening
05/17/2022 11:41:24 - INFO - __main__ - ['others']
05/17/2022 11:41:24 - INFO - __main__ -  [emo] ok that way i like living wwrong
05/17/2022 11:41:24 - INFO - __main__ - ['others']
05/17/2022 11:41:24 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
05/17/2022 11:41:24 - INFO - __main__ - ['others']
05/17/2022 11:41:24 - INFO - __main__ - Tokenizing Input ...
05/17/2022 11:41:24 - INFO - __main__ - Tokenizing Output ...
05/17/2022 11:41:24 - INFO - __main__ - Loaded 64 examples from train data
05/17/2022 11:41:24 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 11:41:24 - INFO - __main__ - Printing 3 examples
05/17/2022 11:41:24 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
05/17/2022 11:41:24 - INFO - __main__ - ['others']
05/17/2022 11:41:24 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
05/17/2022 11:41:24 - INFO - __main__ - ['others']
05/17/2022 11:41:24 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
05/17/2022 11:41:24 - INFO - __main__ - ['others']
05/17/2022 11:41:24 - INFO - __main__ - Tokenizing Input ...
05/17/2022 11:41:24 - INFO - __main__ - Tokenizing Output ...
05/17/2022 11:41:24 - INFO - __main__ - Loaded 64 examples from dev data
05/17/2022 11:41:25 - INFO - __main__ - Tokenizing Output ...
05/17/2022 11:41:29 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 11:41:29 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 11:41:29 - INFO - __main__ - Starting training!
05/17/2022 11:41:32 - INFO - __main__ - Loaded 5509 examples from test data
05/17/2022 11:42:15 - INFO - __main__ - Saved prediction in models/T5-base-reptile-cls2cls-3e-5-2-5000-5e-1-10/singletask-emo/emo_16_100_0.4_8_predictions.txt
05/17/2022 11:42:15 - INFO - __main__ - Classification-F1 on test data: 0.0455
05/17/2022 11:42:16 - INFO - __main__ - prefix=emo_16_100, lr=0.4, bsz=8, dev_performance=0.28793650793650793, test_performance=0.04551121600250527
05/17/2022 11:42:16 - INFO - __main__ - Running ... prefix=emo_16_100, lr=0.3, bsz=8 ...
05/17/2022 11:42:17 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 11:42:17 - INFO - __main__ - Printing 3 examples
05/17/2022 11:42:17 - INFO - __main__ -  [emo] how cause yes am listening
05/17/2022 11:42:17 - INFO - __main__ - ['others']
05/17/2022 11:42:17 - INFO - __main__ -  [emo] ok that way i like living wwrong
05/17/2022 11:42:17 - INFO - __main__ - ['others']
05/17/2022 11:42:17 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
05/17/2022 11:42:17 - INFO - __main__ - ['others']
05/17/2022 11:42:17 - INFO - __main__ - Tokenizing Input ...
05/17/2022 11:42:17 - INFO - __main__ - Tokenizing Output ...
05/17/2022 11:42:17 - INFO - __main__ - Loaded 64 examples from train data
05/17/2022 11:42:17 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 11:42:17 - INFO - __main__ - Printing 3 examples
05/17/2022 11:42:17 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
05/17/2022 11:42:17 - INFO - __main__ - ['others']
05/17/2022 11:42:17 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
05/17/2022 11:42:17 - INFO - __main__ - ['others']
05/17/2022 11:42:17 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
05/17/2022 11:42:17 - INFO - __main__ - ['others']
05/17/2022 11:42:17 - INFO - __main__ - Tokenizing Input ...
05/17/2022 11:42:17 - INFO - __main__ - Tokenizing Output ...
05/17/2022 11:42:17 - INFO - __main__ - Loaded 64 examples from dev data
05/17/2022 11:42:23 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 11:42:23 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 11:42:23 - INFO - __main__ - Starting training!
05/17/2022 11:42:25 - INFO - __main__ - Step 10 Global step 10 Train loss 9.04 on epoch=2
05/17/2022 11:42:26 - INFO - __main__ - Step 20 Global step 20 Train loss 9.09 on epoch=4
05/17/2022 11:42:27 - INFO - __main__ - Step 30 Global step 30 Train loss 8.98 on epoch=7
05/17/2022 11:42:29 - INFO - __main__ - Step 40 Global step 40 Train loss 9.01 on epoch=9
05/17/2022 11:42:30 - INFO - __main__ - Step 50 Global step 50 Train loss 8.75 on epoch=12
05/17/2022 11:42:36 - INFO - __main__ - Global step 50 Train loss 8.97 Classification-F1 0.0 on epoch=12
05/17/2022 11:42:36 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/17/2022 11:42:38 - INFO - __main__ - Step 60 Global step 60 Train loss 8.91 on epoch=14
05/17/2022 11:42:39 - INFO - __main__ - Step 70 Global step 70 Train loss 8.86 on epoch=17
05/17/2022 11:42:41 - INFO - __main__ - Step 80 Global step 80 Train loss 8.85 on epoch=19
05/17/2022 11:42:42 - INFO - __main__ - Step 90 Global step 90 Train loss 8.80 on epoch=22
05/17/2022 11:42:44 - INFO - __main__ - Step 100 Global step 100 Train loss 8.79 on epoch=24
05/17/2022 11:42:51 - INFO - __main__ - Global step 100 Train loss 8.84 Classification-F1 0.0 on epoch=24
05/17/2022 11:42:52 - INFO - __main__ - Step 110 Global step 110 Train loss 8.67 on epoch=27
05/17/2022 11:42:54 - INFO - __main__ - Step 120 Global step 120 Train loss 8.67 on epoch=29
05/17/2022 11:42:55 - INFO - __main__ - Step 130 Global step 130 Train loss 8.55 on epoch=32
05/17/2022 11:42:57 - INFO - __main__ - Step 140 Global step 140 Train loss 8.56 on epoch=34
05/17/2022 11:42:59 - INFO - __main__ - Step 150 Global step 150 Train loss 8.62 on epoch=37
05/17/2022 11:43:06 - INFO - __main__ - Global step 150 Train loss 8.61 Classification-F1 0.0 on epoch=37
05/17/2022 11:43:07 - INFO - __main__ - Step 160 Global step 160 Train loss 8.46 on epoch=39
05/17/2022 11:43:08 - INFO - __main__ - Step 170 Global step 170 Train loss 8.38 on epoch=42
05/17/2022 11:43:10 - INFO - __main__ - Step 180 Global step 180 Train loss 8.27 on epoch=44
05/17/2022 11:43:11 - INFO - __main__ - Step 190 Global step 190 Train loss 8.12 on epoch=47
05/17/2022 11:43:12 - INFO - __main__ - Step 200 Global step 200 Train loss 8.02 on epoch=49
05/17/2022 11:43:25 - INFO - __main__ - Global step 200 Train loss 8.25 Classification-F1 0.0 on epoch=49
05/17/2022 11:43:27 - INFO - __main__ - Step 210 Global step 210 Train loss 8.08 on epoch=52
05/17/2022 11:43:28 - INFO - __main__ - Step 220 Global step 220 Train loss 7.79 on epoch=54
05/17/2022 11:43:29 - INFO - __main__ - Step 230 Global step 230 Train loss 7.63 on epoch=57
05/17/2022 11:43:31 - INFO - __main__ - Step 240 Global step 240 Train loss 7.66 on epoch=59
05/17/2022 11:43:32 - INFO - __main__ - Step 250 Global step 250 Train loss 7.34 on epoch=62
05/17/2022 11:43:45 - INFO - __main__ - Global step 250 Train loss 7.70 Classification-F1 0.0 on epoch=62
05/17/2022 11:43:46 - INFO - __main__ - Step 260 Global step 260 Train loss 7.44 on epoch=64
05/17/2022 11:43:48 - INFO - __main__ - Step 270 Global step 270 Train loss 7.35 on epoch=67
05/17/2022 11:43:49 - INFO - __main__ - Step 280 Global step 280 Train loss 7.19 on epoch=69
05/17/2022 11:43:50 - INFO - __main__ - Step 290 Global step 290 Train loss 7.14 on epoch=72
05/17/2022 11:43:52 - INFO - __main__ - Step 300 Global step 300 Train loss 6.90 on epoch=74
05/17/2022 11:43:59 - INFO - __main__ - Global step 300 Train loss 7.21 Classification-F1 0.0 on epoch=74
05/17/2022 11:44:01 - INFO - __main__ - Step 310 Global step 310 Train loss 6.90 on epoch=77
05/17/2022 11:44:02 - INFO - __main__ - Step 320 Global step 320 Train loss 6.83 on epoch=79
05/17/2022 11:44:03 - INFO - __main__ - Step 330 Global step 330 Train loss 6.69 on epoch=82
05/17/2022 11:44:05 - INFO - __main__ - Step 340 Global step 340 Train loss 6.69 on epoch=84
05/17/2022 11:44:06 - INFO - __main__ - Step 350 Global step 350 Train loss 6.48 on epoch=87
05/17/2022 11:44:11 - INFO - __main__ - Global step 350 Train loss 6.72 Classification-F1 0.0 on epoch=87
05/17/2022 11:44:12 - INFO - __main__ - Step 360 Global step 360 Train loss 6.44 on epoch=89
05/17/2022 11:44:13 - INFO - __main__ - Step 370 Global step 370 Train loss 6.37 on epoch=92
05/17/2022 11:44:15 - INFO - __main__ - Step 380 Global step 380 Train loss 6.28 on epoch=94
05/17/2022 11:44:16 - INFO - __main__ - Step 390 Global step 390 Train loss 6.29 on epoch=97
05/17/2022 11:44:17 - INFO - __main__ - Step 400 Global step 400 Train loss 6.08 on epoch=99
05/17/2022 11:44:21 - INFO - __main__ - Global step 400 Train loss 6.29 Classification-F1 0.0 on epoch=99
05/17/2022 11:44:22 - INFO - __main__ - Step 410 Global step 410 Train loss 5.99 on epoch=102
05/17/2022 11:44:24 - INFO - __main__ - Step 420 Global step 420 Train loss 5.92 on epoch=104
05/17/2022 11:44:25 - INFO - __main__ - Step 430 Global step 430 Train loss 6.04 on epoch=107
05/17/2022 11:44:26 - INFO - __main__ - Step 440 Global step 440 Train loss 5.82 on epoch=109
05/17/2022 11:44:28 - INFO - __main__ - Step 450 Global step 450 Train loss 5.88 on epoch=112
05/17/2022 11:44:32 - INFO - __main__ - Global step 450 Train loss 5.93 Classification-F1 0.0 on epoch=112
05/17/2022 11:44:33 - INFO - __main__ - Step 460 Global step 460 Train loss 5.76 on epoch=114
05/17/2022 11:44:35 - INFO - __main__ - Step 470 Global step 470 Train loss 5.84 on epoch=117
05/17/2022 11:44:36 - INFO - __main__ - Step 480 Global step 480 Train loss 5.54 on epoch=119
05/17/2022 11:44:37 - INFO - __main__ - Step 490 Global step 490 Train loss 5.54 on epoch=122
05/17/2022 11:44:38 - INFO - __main__ - Step 500 Global step 500 Train loss 5.53 on epoch=124
05/17/2022 11:44:42 - INFO - __main__ - Global step 500 Train loss 5.64 Classification-F1 0.0 on epoch=124
05/17/2022 11:44:44 - INFO - __main__ - Step 510 Global step 510 Train loss 5.34 on epoch=127
05/17/2022 11:44:45 - INFO - __main__ - Step 520 Global step 520 Train loss 5.50 on epoch=129
05/17/2022 11:44:46 - INFO - __main__ - Step 530 Global step 530 Train loss 5.14 on epoch=132
05/17/2022 11:44:48 - INFO - __main__ - Step 540 Global step 540 Train loss 5.13 on epoch=134
05/17/2022 11:44:49 - INFO - __main__ - Step 550 Global step 550 Train loss 5.19 on epoch=137
05/17/2022 11:44:53 - INFO - __main__ - Global step 550 Train loss 5.26 Classification-F1 0.0 on epoch=137
05/17/2022 11:44:55 - INFO - __main__ - Step 560 Global step 560 Train loss 5.17 on epoch=139
05/17/2022 11:44:56 - INFO - __main__ - Step 570 Global step 570 Train loss 4.86 on epoch=142
05/17/2022 11:44:57 - INFO - __main__ - Step 580 Global step 580 Train loss 4.92 on epoch=144
05/17/2022 11:44:59 - INFO - __main__ - Step 590 Global step 590 Train loss 4.93 on epoch=147
05/17/2022 11:45:00 - INFO - __main__ - Step 600 Global step 600 Train loss 4.79 on epoch=149
05/17/2022 11:45:05 - INFO - __main__ - Global step 600 Train loss 4.93 Classification-F1 0.0 on epoch=149
05/17/2022 11:45:06 - INFO - __main__ - Step 610 Global step 610 Train loss 4.75 on epoch=152
05/17/2022 11:45:07 - INFO - __main__ - Step 620 Global step 620 Train loss 4.68 on epoch=154
05/17/2022 11:45:09 - INFO - __main__ - Step 630 Global step 630 Train loss 4.85 on epoch=157
05/17/2022 11:45:10 - INFO - __main__ - Step 640 Global step 640 Train loss 4.50 on epoch=159
05/17/2022 11:45:12 - INFO - __main__ - Step 650 Global step 650 Train loss 4.69 on epoch=162
05/17/2022 11:45:15 - INFO - __main__ - Global step 650 Train loss 4.69 Classification-F1 0.0 on epoch=162
05/17/2022 11:45:17 - INFO - __main__ - Step 660 Global step 660 Train loss 4.39 on epoch=164
05/17/2022 11:45:18 - INFO - __main__ - Step 670 Global step 670 Train loss 4.46 on epoch=167
05/17/2022 11:45:20 - INFO - __main__ - Step 680 Global step 680 Train loss 4.35 on epoch=169
05/17/2022 11:45:21 - INFO - __main__ - Step 690 Global step 690 Train loss 4.44 on epoch=172
05/17/2022 11:45:22 - INFO - __main__ - Step 700 Global step 700 Train loss 4.33 on epoch=174
05/17/2022 11:45:26 - INFO - __main__ - Global step 700 Train loss 4.39 Classification-F1 0.0 on epoch=174
05/17/2022 11:45:27 - INFO - __main__ - Step 710 Global step 710 Train loss 4.30 on epoch=177
05/17/2022 11:45:29 - INFO - __main__ - Step 720 Global step 720 Train loss 4.31 on epoch=179
05/17/2022 11:45:30 - INFO - __main__ - Step 730 Global step 730 Train loss 4.13 on epoch=182
05/17/2022 11:45:32 - INFO - __main__ - Step 740 Global step 740 Train loss 4.17 on epoch=184
05/17/2022 11:45:33 - INFO - __main__ - Step 750 Global step 750 Train loss 4.02 on epoch=187
05/17/2022 11:45:36 - INFO - __main__ - Global step 750 Train loss 4.19 Classification-F1 0.0 on epoch=187
05/17/2022 11:45:38 - INFO - __main__ - Step 760 Global step 760 Train loss 3.93 on epoch=189
05/17/2022 11:45:39 - INFO - __main__ - Step 770 Global step 770 Train loss 3.99 on epoch=192
05/17/2022 11:45:41 - INFO - __main__ - Step 780 Global step 780 Train loss 3.67 on epoch=194
05/17/2022 11:45:42 - INFO - __main__ - Step 790 Global step 790 Train loss 4.01 on epoch=197
05/17/2022 11:45:43 - INFO - __main__ - Step 800 Global step 800 Train loss 3.73 on epoch=199
05/17/2022 11:45:46 - INFO - __main__ - Global step 800 Train loss 3.87 Classification-F1 0.0 on epoch=199
05/17/2022 11:45:47 - INFO - __main__ - Step 810 Global step 810 Train loss 3.46 on epoch=202
05/17/2022 11:45:49 - INFO - __main__ - Step 820 Global step 820 Train loss 3.64 on epoch=204
05/17/2022 11:45:50 - INFO - __main__ - Step 830 Global step 830 Train loss 3.57 on epoch=207
05/17/2022 11:45:51 - INFO - __main__ - Step 840 Global step 840 Train loss 3.60 on epoch=209
05/17/2022 11:45:53 - INFO - __main__ - Step 850 Global step 850 Train loss 3.51 on epoch=212
05/17/2022 11:45:53 - INFO - __main__ - Global step 850 Train loss 3.56 Classification-F1 0.06766917293233082 on epoch=212
05/17/2022 11:45:53 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.06766917293233082 on epoch=212, global_step=850
05/17/2022 11:45:55 - INFO - __main__ - Step 860 Global step 860 Train loss 3.33 on epoch=214
05/17/2022 11:45:56 - INFO - __main__ - Step 870 Global step 870 Train loss 3.67 on epoch=217
05/17/2022 11:45:57 - INFO - __main__ - Step 880 Global step 880 Train loss 3.48 on epoch=219
05/17/2022 11:45:59 - INFO - __main__ - Step 890 Global step 890 Train loss 3.38 on epoch=222
05/17/2022 11:46:00 - INFO - __main__ - Step 900 Global step 900 Train loss 3.52 on epoch=224
05/17/2022 11:46:01 - INFO - __main__ - Global step 900 Train loss 3.48 Classification-F1 0.09529411764705882 on epoch=224
05/17/2022 11:46:01 - INFO - __main__ - Saving model with best Classification-F1: 0.06766917293233082 -> 0.09529411764705882 on epoch=224, global_step=900
05/17/2022 11:46:02 - INFO - __main__ - Step 910 Global step 910 Train loss 3.39 on epoch=227
05/17/2022 11:46:04 - INFO - __main__ - Step 920 Global step 920 Train loss 3.20 on epoch=229
05/17/2022 11:46:05 - INFO - __main__ - Step 930 Global step 930 Train loss 2.98 on epoch=232
05/17/2022 11:46:06 - INFO - __main__ - Step 940 Global step 940 Train loss 3.06 on epoch=234
05/17/2022 11:46:08 - INFO - __main__ - Step 950 Global step 950 Train loss 3.27 on epoch=237
05/17/2022 11:46:08 - INFO - __main__ - Global step 950 Train loss 3.18 Classification-F1 0.1111111111111111 on epoch=237
05/17/2022 11:46:08 - INFO - __main__ - Saving model with best Classification-F1: 0.09529411764705882 -> 0.1111111111111111 on epoch=237, global_step=950
05/17/2022 11:46:09 - INFO - __main__ - Step 960 Global step 960 Train loss 2.99 on epoch=239
05/17/2022 11:46:11 - INFO - __main__ - Step 970 Global step 970 Train loss 3.00 on epoch=242
05/17/2022 11:46:12 - INFO - __main__ - Step 980 Global step 980 Train loss 3.00 on epoch=244
05/17/2022 11:46:13 - INFO - __main__ - Step 990 Global step 990 Train loss 2.93 on epoch=247
05/17/2022 11:46:15 - INFO - __main__ - Step 1000 Global step 1000 Train loss 2.74 on epoch=249
05/17/2022 11:46:16 - INFO - __main__ - Global step 1000 Train loss 2.93 Classification-F1 0.14838709677419354 on epoch=249
05/17/2022 11:46:16 - INFO - __main__ - Saving model with best Classification-F1: 0.1111111111111111 -> 0.14838709677419354 on epoch=249, global_step=1000
05/17/2022 11:46:17 - INFO - __main__ - Step 1010 Global step 1010 Train loss 2.90 on epoch=252
05/17/2022 11:46:19 - INFO - __main__ - Step 1020 Global step 1020 Train loss 2.78 on epoch=254
05/17/2022 11:46:20 - INFO - __main__ - Step 1030 Global step 1030 Train loss 2.62 on epoch=257
05/17/2022 11:46:22 - INFO - __main__ - Step 1040 Global step 1040 Train loss 2.52 on epoch=259
05/17/2022 11:46:23 - INFO - __main__ - Step 1050 Global step 1050 Train loss 2.45 on epoch=262
05/17/2022 11:46:24 - INFO - __main__ - Global step 1050 Train loss 2.65 Classification-F1 0.1570048309178744 on epoch=262
05/17/2022 11:46:24 - INFO - __main__ - Saving model with best Classification-F1: 0.14838709677419354 -> 0.1570048309178744 on epoch=262, global_step=1050
05/17/2022 11:46:25 - INFO - __main__ - Step 1060 Global step 1060 Train loss 2.50 on epoch=264
05/17/2022 11:46:26 - INFO - __main__ - Step 1070 Global step 1070 Train loss 2.27 on epoch=267
05/17/2022 11:46:28 - INFO - __main__ - Step 1080 Global step 1080 Train loss 2.27 on epoch=269
05/17/2022 11:46:29 - INFO - __main__ - Step 1090 Global step 1090 Train loss 2.17 on epoch=272
05/17/2022 11:46:30 - INFO - __main__ - Step 1100 Global step 1100 Train loss 2.22 on epoch=274
05/17/2022 11:46:31 - INFO - __main__ - Global step 1100 Train loss 2.29 Classification-F1 0.17744755244755245 on epoch=274
05/17/2022 11:46:31 - INFO - __main__ - Saving model with best Classification-F1: 0.1570048309178744 -> 0.17744755244755245 on epoch=274, global_step=1100
05/17/2022 11:46:32 - INFO - __main__ - Step 1110 Global step 1110 Train loss 2.16 on epoch=277
05/17/2022 11:46:34 - INFO - __main__ - Step 1120 Global step 1120 Train loss 2.17 on epoch=279
05/17/2022 11:46:35 - INFO - __main__ - Step 1130 Global step 1130 Train loss 2.25 on epoch=282
05/17/2022 11:46:37 - INFO - __main__ - Step 1140 Global step 1140 Train loss 2.08 on epoch=284
05/17/2022 11:46:38 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.98 on epoch=287
05/17/2022 11:46:39 - INFO - __main__ - Global step 1150 Train loss 2.13 Classification-F1 0.17328042328042326 on epoch=287
05/17/2022 11:46:40 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.99 on epoch=289
05/17/2022 11:46:41 - INFO - __main__ - Step 1170 Global step 1170 Train loss 2.03 on epoch=292
05/17/2022 11:46:43 - INFO - __main__ - Step 1180 Global step 1180 Train loss 2.00 on epoch=294
05/17/2022 11:46:44 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.69 on epoch=297
05/17/2022 11:46:46 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.69 on epoch=299
05/17/2022 11:46:46 - INFO - __main__ - Global step 1200 Train loss 1.88 Classification-F1 0.10256410256410256 on epoch=299
05/17/2022 11:46:48 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.81 on epoch=302
05/17/2022 11:46:49 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.59 on epoch=304
05/17/2022 11:46:50 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.83 on epoch=307
05/17/2022 11:46:52 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.72 on epoch=309
05/17/2022 11:46:53 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.87 on epoch=312
05/17/2022 11:46:54 - INFO - __main__ - Global step 1250 Train loss 1.76 Classification-F1 0.1 on epoch=312
05/17/2022 11:46:55 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.75 on epoch=314
05/17/2022 11:46:56 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.77 on epoch=317
05/17/2022 11:46:58 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.74 on epoch=319
05/17/2022 11:46:59 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.81 on epoch=322
05/17/2022 11:47:00 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.71 on epoch=324
05/17/2022 11:47:01 - INFO - __main__ - Global step 1300 Train loss 1.76 Classification-F1 0.1769230769230769 on epoch=324
05/17/2022 11:47:02 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.57 on epoch=327
05/17/2022 11:47:04 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.67 on epoch=329
05/17/2022 11:47:05 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.65 on epoch=332
05/17/2022 11:47:06 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.54 on epoch=334
05/17/2022 11:47:08 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.72 on epoch=337
05/17/2022 11:47:08 - INFO - __main__ - Global step 1350 Train loss 1.63 Classification-F1 0.17708333333333331 on epoch=337
05/17/2022 11:47:10 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.50 on epoch=339
05/17/2022 11:47:11 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.59 on epoch=342
05/17/2022 11:47:12 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.71 on epoch=344
05/17/2022 11:47:14 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.60 on epoch=347
05/17/2022 11:47:15 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.68 on epoch=349
05/17/2022 11:47:16 - INFO - __main__ - Global step 1400 Train loss 1.62 Classification-F1 0.1302118933697881 on epoch=349
05/17/2022 11:47:17 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.63 on epoch=352
05/17/2022 11:47:18 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.48 on epoch=354
05/17/2022 11:47:20 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.55 on epoch=357
05/17/2022 11:47:21 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.42 on epoch=359
05/17/2022 11:47:23 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.43 on epoch=362
05/17/2022 11:47:23 - INFO - __main__ - Global step 1450 Train loss 1.50 Classification-F1 0.14621798689696247 on epoch=362
05/17/2022 11:47:24 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.48 on epoch=364
05/17/2022 11:47:26 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.32 on epoch=367
05/17/2022 11:47:27 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.40 on epoch=369
05/17/2022 11:47:29 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.70 on epoch=372
05/17/2022 11:47:30 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.58 on epoch=374
05/17/2022 11:47:31 - INFO - __main__ - Global step 1500 Train loss 1.50 Classification-F1 0.15625 on epoch=374
05/17/2022 11:47:32 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.50 on epoch=377
05/17/2022 11:47:34 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.53 on epoch=379
05/17/2022 11:47:35 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.51 on epoch=382
05/17/2022 11:47:36 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.38 on epoch=384
05/17/2022 11:47:38 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.38 on epoch=387
05/17/2022 11:47:38 - INFO - __main__ - Global step 1550 Train loss 1.46 Classification-F1 0.19859154929577466 on epoch=387
05/17/2022 11:47:38 - INFO - __main__ - Saving model with best Classification-F1: 0.17744755244755245 -> 0.19859154929577466 on epoch=387, global_step=1550
05/17/2022 11:47:40 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.39 on epoch=389
05/17/2022 11:47:41 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.48 on epoch=392
05/17/2022 11:47:43 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.47 on epoch=394
05/17/2022 11:47:44 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.40 on epoch=397
05/17/2022 11:47:46 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.27 on epoch=399
05/17/2022 11:47:46 - INFO - __main__ - Global step 1600 Train loss 1.40 Classification-F1 0.09090909090909091 on epoch=399
05/17/2022 11:47:48 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.25 on epoch=402
05/17/2022 11:47:49 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.32 on epoch=404
05/17/2022 11:47:51 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.31 on epoch=407
05/17/2022 11:47:52 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.49 on epoch=409
05/17/2022 11:47:54 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.35 on epoch=412
05/17/2022 11:47:54 - INFO - __main__ - Global step 1650 Train loss 1.34 Classification-F1 0.1389603705609882 on epoch=412
05/17/2022 11:47:56 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.23 on epoch=414
05/17/2022 11:47:57 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.24 on epoch=417
05/17/2022 11:47:59 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.31 on epoch=419
05/17/2022 11:48:00 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.23 on epoch=422
05/17/2022 11:48:02 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.31 on epoch=424
05/17/2022 11:48:02 - INFO - __main__ - Global step 1700 Train loss 1.26 Classification-F1 0.17694311767260096 on epoch=424
05/17/2022 11:48:03 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.30 on epoch=427
05/17/2022 11:48:05 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.21 on epoch=429
05/17/2022 11:48:06 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.18 on epoch=432
05/17/2022 11:48:07 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.16 on epoch=434
05/17/2022 11:48:09 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.24 on epoch=437
05/17/2022 11:48:09 - INFO - __main__ - Global step 1750 Train loss 1.22 Classification-F1 0.18618266978922718 on epoch=437
05/17/2022 11:48:11 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.12 on epoch=439
05/17/2022 11:48:12 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.15 on epoch=442
05/17/2022 11:48:14 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.10 on epoch=444
05/17/2022 11:48:15 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.31 on epoch=447
05/17/2022 11:48:16 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.07 on epoch=449
05/17/2022 11:48:17 - INFO - __main__ - Global step 1800 Train loss 1.15 Classification-F1 0.16926248282180484 on epoch=449
05/17/2022 11:48:18 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.30 on epoch=452
05/17/2022 11:48:20 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.15 on epoch=454
05/17/2022 11:48:21 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.27 on epoch=457
05/17/2022 11:48:22 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.20 on epoch=459
05/17/2022 11:48:24 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.20 on epoch=462
05/17/2022 11:48:24 - INFO - __main__ - Global step 1850 Train loss 1.22 Classification-F1 0.19493006993006995 on epoch=462
05/17/2022 11:48:26 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.20 on epoch=464
05/17/2022 11:48:27 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.25 on epoch=467
05/17/2022 11:48:28 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.13 on epoch=469
05/17/2022 11:48:30 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.17 on epoch=472
05/17/2022 11:48:31 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.14 on epoch=474
05/17/2022 11:48:32 - INFO - __main__ - Global step 1900 Train loss 1.18 Classification-F1 0.12857142857142856 on epoch=474
05/17/2022 11:48:33 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.32 on epoch=477
05/17/2022 11:48:35 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.15 on epoch=479
05/17/2022 11:48:36 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.17 on epoch=482
05/17/2022 11:48:37 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.05 on epoch=484
05/17/2022 11:48:39 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.25 on epoch=487
05/17/2022 11:48:39 - INFO - __main__ - Global step 1950 Train loss 1.19 Classification-F1 0.27499999999999997 on epoch=487
05/17/2022 11:48:39 - INFO - __main__ - Saving model with best Classification-F1: 0.19859154929577466 -> 0.27499999999999997 on epoch=487, global_step=1950
05/17/2022 11:48:41 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.14 on epoch=489
05/17/2022 11:48:42 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.14 on epoch=492
05/17/2022 11:48:43 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.18 on epoch=494
05/17/2022 11:48:45 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.17 on epoch=497
05/17/2022 11:48:46 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.19 on epoch=499
05/17/2022 11:48:47 - INFO - __main__ - Global step 2000 Train loss 1.16 Classification-F1 0.17295285359801488 on epoch=499
05/17/2022 11:48:48 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.18 on epoch=502
05/17/2022 11:48:50 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.04 on epoch=504
05/17/2022 11:48:51 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.13 on epoch=507
05/17/2022 11:48:52 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.16 on epoch=509
05/17/2022 11:48:54 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.10 on epoch=512
05/17/2022 11:48:54 - INFO - __main__ - Global step 2050 Train loss 1.12 Classification-F1 0.13123993558776167 on epoch=512
05/17/2022 11:48:56 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.13 on epoch=514
05/17/2022 11:48:57 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.12 on epoch=517
05/17/2022 11:48:58 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.02 on epoch=519
05/17/2022 11:49:00 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.06 on epoch=522
05/17/2022 11:49:01 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.05 on epoch=524
05/17/2022 11:49:02 - INFO - __main__ - Global step 2100 Train loss 1.08 Classification-F1 0.1408918406072106 on epoch=524
05/17/2022 11:49:03 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.06 on epoch=527
05/17/2022 11:49:04 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.30 on epoch=529
05/17/2022 11:49:06 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.14 on epoch=532
05/17/2022 11:49:07 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.20 on epoch=534
05/17/2022 11:49:08 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.96 on epoch=537
05/17/2022 11:49:09 - INFO - __main__ - Global step 2150 Train loss 1.13 Classification-F1 0.1796875 on epoch=537
05/17/2022 11:49:10 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.07 on epoch=539
05/17/2022 11:49:12 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.10 on epoch=542
05/17/2022 11:49:13 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.19 on epoch=544
05/17/2022 11:49:14 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.09 on epoch=547
05/17/2022 11:49:16 - INFO - __main__ - Step 2200 Global step 2200 Train loss 1.09 on epoch=549
05/17/2022 11:49:16 - INFO - __main__ - Global step 2200 Train loss 1.11 Classification-F1 0.2093900966183575 on epoch=549
05/17/2022 11:49:18 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.12 on epoch=552
05/17/2022 11:49:19 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.00 on epoch=554
05/17/2022 11:49:21 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.16 on epoch=557
05/17/2022 11:49:22 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.02 on epoch=559
05/17/2022 11:49:24 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.18 on epoch=562
05/17/2022 11:49:25 - INFO - __main__ - Global step 2250 Train loss 1.10 Classification-F1 0.18721318314559865 on epoch=562
05/17/2022 11:49:26 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.92 on epoch=564
05/17/2022 11:49:27 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.13 on epoch=567
05/17/2022 11:49:29 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.07 on epoch=569
05/17/2022 11:49:30 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.02 on epoch=572
05/17/2022 11:49:32 - INFO - __main__ - Step 2300 Global step 2300 Train loss 1.10 on epoch=574
05/17/2022 11:49:32 - INFO - __main__ - Global step 2300 Train loss 1.05 Classification-F1 0.1581196581196581 on epoch=574
05/17/2022 11:49:34 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.14 on epoch=577
05/17/2022 11:49:36 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.04 on epoch=579
05/17/2022 11:49:37 - INFO - __main__ - Step 2330 Global step 2330 Train loss 1.10 on epoch=582
05/17/2022 11:49:39 - INFO - __main__ - Step 2340 Global step 2340 Train loss 1.14 on epoch=584
05/17/2022 11:49:40 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.06 on epoch=587
05/17/2022 11:49:41 - INFO - __main__ - Global step 2350 Train loss 1.10 Classification-F1 0.1527777777777778 on epoch=587
05/17/2022 11:49:42 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.92 on epoch=589
05/17/2022 11:49:43 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.95 on epoch=592
05/17/2022 11:49:45 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.08 on epoch=594
05/17/2022 11:49:47 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.95 on epoch=597
05/17/2022 11:49:48 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.13 on epoch=599
05/17/2022 11:49:49 - INFO - __main__ - Global step 2400 Train loss 1.01 Classification-F1 0.1 on epoch=599
05/17/2022 11:49:50 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.05 on epoch=602
05/17/2022 11:49:52 - INFO - __main__ - Step 2420 Global step 2420 Train loss 1.12 on epoch=604
05/17/2022 11:49:53 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.05 on epoch=607
05/17/2022 11:49:55 - INFO - __main__ - Step 2440 Global step 2440 Train loss 1.03 on epoch=609
05/17/2022 11:49:56 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.23 on epoch=612
05/17/2022 11:49:57 - INFO - __main__ - Global step 2450 Train loss 1.09 Classification-F1 0.1 on epoch=612
05/17/2022 11:49:58 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.98 on epoch=614
05/17/2022 11:50:00 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.14 on epoch=617
05/17/2022 11:50:01 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.14 on epoch=619
05/17/2022 11:50:03 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.10 on epoch=622
05/17/2022 11:50:04 - INFO - __main__ - Step 2500 Global step 2500 Train loss 1.10 on epoch=624
05/17/2022 11:50:05 - INFO - __main__ - Global step 2500 Train loss 1.09 Classification-F1 0.1 on epoch=624
05/17/2022 11:50:06 - INFO - __main__ - Step 2510 Global step 2510 Train loss 1.22 on epoch=627
05/17/2022 11:50:08 - INFO - __main__ - Step 2520 Global step 2520 Train loss 1.13 on epoch=629
05/17/2022 11:50:09 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.19 on epoch=632
05/17/2022 11:50:10 - INFO - __main__ - Step 2540 Global step 2540 Train loss 1.00 on epoch=634
05/17/2022 11:50:12 - INFO - __main__ - Step 2550 Global step 2550 Train loss 1.03 on epoch=637
05/17/2022 11:50:12 - INFO - __main__ - Global step 2550 Train loss 1.12 Classification-F1 0.139087656529517 on epoch=637
05/17/2022 11:50:14 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.97 on epoch=639
05/17/2022 11:50:15 - INFO - __main__ - Step 2570 Global step 2570 Train loss 1.02 on epoch=642
05/17/2022 11:50:17 - INFO - __main__ - Step 2580 Global step 2580 Train loss 1.06 on epoch=644
05/17/2022 11:50:18 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.09 on epoch=647
05/17/2022 11:50:20 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.08 on epoch=649
05/17/2022 11:50:20 - INFO - __main__ - Global step 2600 Train loss 1.04 Classification-F1 0.11056511056511056 on epoch=649
05/17/2022 11:50:22 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.99 on epoch=652
05/17/2022 11:50:23 - INFO - __main__ - Step 2620 Global step 2620 Train loss 1.03 on epoch=654
05/17/2022 11:50:24 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.89 on epoch=657
05/17/2022 11:50:26 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.01 on epoch=659
05/17/2022 11:50:27 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.06 on epoch=662
05/17/2022 11:50:28 - INFO - __main__ - Global step 2650 Train loss 1.00 Classification-F1 0.1 on epoch=662
05/17/2022 11:50:29 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.90 on epoch=664
05/17/2022 11:50:31 - INFO - __main__ - Step 2670 Global step 2670 Train loss 1.00 on epoch=667
05/17/2022 11:50:32 - INFO - __main__ - Step 2680 Global step 2680 Train loss 1.00 on epoch=669
05/17/2022 11:50:33 - INFO - __main__ - Step 2690 Global step 2690 Train loss 1.03 on epoch=672
05/17/2022 11:50:35 - INFO - __main__ - Step 2700 Global step 2700 Train loss 1.08 on epoch=674
05/17/2022 11:50:35 - INFO - __main__ - Global step 2700 Train loss 1.00 Classification-F1 0.1 on epoch=674
05/17/2022 11:50:37 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.98 on epoch=677
05/17/2022 11:50:38 - INFO - __main__ - Step 2720 Global step 2720 Train loss 1.00 on epoch=679
05/17/2022 11:50:39 - INFO - __main__ - Step 2730 Global step 2730 Train loss 1.15 on epoch=682
05/17/2022 11:50:41 - INFO - __main__ - Step 2740 Global step 2740 Train loss 1.02 on epoch=684
05/17/2022 11:50:42 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.93 on epoch=687
05/17/2022 11:50:43 - INFO - __main__ - Global step 2750 Train loss 1.02 Classification-F1 0.10126582278481013 on epoch=687
05/17/2022 11:50:44 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.97 on epoch=689
05/17/2022 11:50:46 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.91 on epoch=692
05/17/2022 11:50:47 - INFO - __main__ - Step 2780 Global step 2780 Train loss 1.00 on epoch=694
05/17/2022 11:50:49 - INFO - __main__ - Step 2790 Global step 2790 Train loss 1.00 on epoch=697
05/17/2022 11:50:50 - INFO - __main__ - Step 2800 Global step 2800 Train loss 1.05 on epoch=699
05/17/2022 11:50:50 - INFO - __main__ - Global step 2800 Train loss 0.99 Classification-F1 0.09493670886075949 on epoch=699
05/17/2022 11:50:52 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.09 on epoch=702
05/17/2022 11:50:53 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.99 on epoch=704
05/17/2022 11:50:55 - INFO - __main__ - Step 2830 Global step 2830 Train loss 1.03 on epoch=707
05/17/2022 11:50:56 - INFO - __main__ - Step 2840 Global step 2840 Train loss 1.00 on epoch=709
05/17/2022 11:50:57 - INFO - __main__ - Step 2850 Global step 2850 Train loss 1.04 on epoch=712
05/17/2022 11:50:58 - INFO - __main__ - Global step 2850 Train loss 1.03 Classification-F1 0.1 on epoch=712
05/17/2022 11:50:59 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.98 on epoch=714
05/17/2022 11:51:01 - INFO - __main__ - Step 2870 Global step 2870 Train loss 1.01 on epoch=717
05/17/2022 11:51:02 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.91 on epoch=719
05/17/2022 11:51:04 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.06 on epoch=722
05/17/2022 11:51:05 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.88 on epoch=724
05/17/2022 11:51:06 - INFO - __main__ - Global step 2900 Train loss 0.97 Classification-F1 0.13936867182846935 on epoch=724
05/17/2022 11:51:07 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.11 on epoch=727
05/17/2022 11:51:08 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.95 on epoch=729
05/17/2022 11:51:10 - INFO - __main__ - Step 2930 Global step 2930 Train loss 1.00 on epoch=732
05/17/2022 11:51:11 - INFO - __main__ - Step 2940 Global step 2940 Train loss 1.05 on epoch=734
05/17/2022 11:51:12 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.92 on epoch=737
05/17/2022 11:51:13 - INFO - __main__ - Global step 2950 Train loss 1.01 Classification-F1 0.1736111111111111 on epoch=737
05/17/2022 11:51:14 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.89 on epoch=739
05/17/2022 11:51:16 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.07 on epoch=742
05/17/2022 11:51:17 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.03 on epoch=744
05/17/2022 11:51:18 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.97 on epoch=747
05/17/2022 11:51:20 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.92 on epoch=749
05/17/2022 11:51:20 - INFO - __main__ - Global step 3000 Train loss 0.98 Classification-F1 0.142512077294686 on epoch=749
05/17/2022 11:51:20 - INFO - __main__ - save last model!
05/17/2022 11:51:21 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/17/2022 11:51:21 - INFO - __main__ - Start tokenizing ... 5509 instances
05/17/2022 11:51:21 - INFO - __main__ - Printing 3 examples
05/17/2022 11:51:21 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/17/2022 11:51:21 - INFO - __main__ - ['others']
05/17/2022 11:51:21 - INFO - __main__ -  [emo] what you like very little things ok
05/17/2022 11:51:21 - INFO - __main__ - ['others']
05/17/2022 11:51:21 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/17/2022 11:51:21 - INFO - __main__ - ['others']
05/17/2022 11:51:21 - INFO - __main__ - Tokenizing Input ...
05/17/2022 11:51:21 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 11:51:21 - INFO - __main__ - Printing 3 examples
05/17/2022 11:51:21 - INFO - __main__ -  [emo] how cause yes am listening
05/17/2022 11:51:21 - INFO - __main__ - ['others']
05/17/2022 11:51:21 - INFO - __main__ -  [emo] ok that way i like living wwrong
05/17/2022 11:51:21 - INFO - __main__ - ['others']
05/17/2022 11:51:21 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
05/17/2022 11:51:21 - INFO - __main__ - ['others']
05/17/2022 11:51:21 - INFO - __main__ - Tokenizing Input ...
05/17/2022 11:51:21 - INFO - __main__ - Tokenizing Output ...
05/17/2022 11:51:21 - INFO - __main__ - Loaded 64 examples from train data
05/17/2022 11:51:21 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 11:51:21 - INFO - __main__ - Printing 3 examples
05/17/2022 11:51:21 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
05/17/2022 11:51:21 - INFO - __main__ - ['others']
05/17/2022 11:51:21 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
05/17/2022 11:51:21 - INFO - __main__ - ['others']
05/17/2022 11:51:21 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
05/17/2022 11:51:21 - INFO - __main__ - ['others']
05/17/2022 11:51:21 - INFO - __main__ - Tokenizing Input ...
05/17/2022 11:51:21 - INFO - __main__ - Tokenizing Output ...
05/17/2022 11:51:21 - INFO - __main__ - Loaded 64 examples from dev data
05/17/2022 11:51:23 - INFO - __main__ - Tokenizing Output ...
05/17/2022 11:51:27 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 11:51:27 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 11:51:27 - INFO - __main__ - Starting training!
05/17/2022 11:51:30 - INFO - __main__ - Loaded 5509 examples from test data
05/17/2022 11:52:17 - INFO - __main__ - Saved prediction in models/T5-base-reptile-cls2cls-3e-5-2-5000-5e-1-10/singletask-emo/emo_16_100_0.3_8_predictions.txt
05/17/2022 11:52:17 - INFO - __main__ - Classification-F1 on test data: 0.0450
05/17/2022 11:52:18 - INFO - __main__ - prefix=emo_16_100, lr=0.3, bsz=8, dev_performance=0.27499999999999997, test_performance=0.044995617606100644
05/17/2022 11:52:18 - INFO - __main__ - Running ... prefix=emo_16_100, lr=0.2, bsz=8 ...
05/17/2022 11:52:19 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 11:52:19 - INFO - __main__ - Printing 3 examples
05/17/2022 11:52:19 - INFO - __main__ -  [emo] how cause yes am listening
05/17/2022 11:52:19 - INFO - __main__ - ['others']
05/17/2022 11:52:19 - INFO - __main__ -  [emo] ok that way i like living wwrong
05/17/2022 11:52:19 - INFO - __main__ - ['others']
05/17/2022 11:52:19 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
05/17/2022 11:52:19 - INFO - __main__ - ['others']
05/17/2022 11:52:19 - INFO - __main__ - Tokenizing Input ...
05/17/2022 11:52:19 - INFO - __main__ - Tokenizing Output ...
05/17/2022 11:52:19 - INFO - __main__ - Loaded 64 examples from train data
05/17/2022 11:52:19 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 11:52:19 - INFO - __main__ - Printing 3 examples
05/17/2022 11:52:19 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
05/17/2022 11:52:19 - INFO - __main__ - ['others']
05/17/2022 11:52:19 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
05/17/2022 11:52:19 - INFO - __main__ - ['others']
05/17/2022 11:52:19 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
05/17/2022 11:52:19 - INFO - __main__ - ['others']
05/17/2022 11:52:19 - INFO - __main__ - Tokenizing Input ...
05/17/2022 11:52:19 - INFO - __main__ - Tokenizing Output ...
05/17/2022 11:52:19 - INFO - __main__ - Loaded 64 examples from dev data
05/17/2022 11:52:25 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 11:52:25 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 11:52:25 - INFO - __main__ - Starting training!
05/17/2022 11:52:27 - INFO - __main__ - Step 10 Global step 10 Train loss 8.97 on epoch=2
05/17/2022 11:52:28 - INFO - __main__ - Step 20 Global step 20 Train loss 9.00 on epoch=4
05/17/2022 11:52:29 - INFO - __main__ - Step 30 Global step 30 Train loss 8.96 on epoch=7
05/17/2022 11:52:31 - INFO - __main__ - Step 40 Global step 40 Train loss 8.96 on epoch=9
05/17/2022 11:52:32 - INFO - __main__ - Step 50 Global step 50 Train loss 8.83 on epoch=12
05/17/2022 11:52:43 - INFO - __main__ - Global step 50 Train loss 8.94 Classification-F1 0.0 on epoch=12
05/17/2022 11:52:43 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/17/2022 11:52:45 - INFO - __main__ - Step 60 Global step 60 Train loss 9.06 on epoch=14
05/17/2022 11:52:46 - INFO - __main__ - Step 70 Global step 70 Train loss 8.88 on epoch=17
05/17/2022 11:52:47 - INFO - __main__ - Step 80 Global step 80 Train loss 8.88 on epoch=19
05/17/2022 11:52:49 - INFO - __main__ - Step 90 Global step 90 Train loss 8.87 on epoch=22
05/17/2022 11:52:50 - INFO - __main__ - Step 100 Global step 100 Train loss 8.91 on epoch=24
05/17/2022 11:53:02 - INFO - __main__ - Global step 100 Train loss 8.92 Classification-F1 0.0 on epoch=24
05/17/2022 11:53:03 - INFO - __main__ - Step 110 Global step 110 Train loss 8.76 on epoch=27
05/17/2022 11:53:05 - INFO - __main__ - Step 120 Global step 120 Train loss 8.85 on epoch=29
05/17/2022 11:53:06 - INFO - __main__ - Step 130 Global step 130 Train loss 8.74 on epoch=32
05/17/2022 11:53:07 - INFO - __main__ - Step 140 Global step 140 Train loss 8.63 on epoch=34
05/17/2022 11:53:09 - INFO - __main__ - Step 150 Global step 150 Train loss 8.67 on epoch=37
05/17/2022 11:53:18 - INFO - __main__ - Global step 150 Train loss 8.73 Classification-F1 0.0 on epoch=37
05/17/2022 11:53:20 - INFO - __main__ - Step 160 Global step 160 Train loss 8.65 on epoch=39
05/17/2022 11:53:21 - INFO - __main__ - Step 170 Global step 170 Train loss 8.69 on epoch=42
05/17/2022 11:53:22 - INFO - __main__ - Step 180 Global step 180 Train loss 8.49 on epoch=44
05/17/2022 11:53:24 - INFO - __main__ - Step 190 Global step 190 Train loss 8.36 on epoch=47
05/17/2022 11:53:25 - INFO - __main__ - Step 200 Global step 200 Train loss 8.54 on epoch=49
05/17/2022 11:53:43 - INFO - __main__ - Global step 200 Train loss 8.55 Classification-F1 0.0 on epoch=49
05/17/2022 11:53:44 - INFO - __main__ - Step 210 Global step 210 Train loss 8.25 on epoch=52
05/17/2022 11:53:46 - INFO - __main__ - Step 220 Global step 220 Train loss 8.17 on epoch=54
05/17/2022 11:53:47 - INFO - __main__ - Step 230 Global step 230 Train loss 8.14 on epoch=57
05/17/2022 11:53:48 - INFO - __main__ - Step 240 Global step 240 Train loss 8.02 on epoch=59
05/17/2022 11:53:50 - INFO - __main__ - Step 250 Global step 250 Train loss 7.94 on epoch=62
05/17/2022 11:54:05 - INFO - __main__ - Global step 250 Train loss 8.10 Classification-F1 0.0 on epoch=62
05/17/2022 11:54:06 - INFO - __main__ - Step 260 Global step 260 Train loss 8.06 on epoch=64
05/17/2022 11:54:08 - INFO - __main__ - Step 270 Global step 270 Train loss 7.82 on epoch=67
05/17/2022 11:54:09 - INFO - __main__ - Step 280 Global step 280 Train loss 7.68 on epoch=69
05/17/2022 11:54:10 - INFO - __main__ - Step 290 Global step 290 Train loss 7.73 on epoch=72
05/17/2022 11:54:12 - INFO - __main__ - Step 300 Global step 300 Train loss 7.51 on epoch=74
05/17/2022 11:54:26 - INFO - __main__ - Global step 300 Train loss 7.76 Classification-F1 0.0 on epoch=74
05/17/2022 11:54:27 - INFO - __main__ - Step 310 Global step 310 Train loss 7.58 on epoch=77
05/17/2022 11:54:29 - INFO - __main__ - Step 320 Global step 320 Train loss 7.44 on epoch=79
05/17/2022 11:54:30 - INFO - __main__ - Step 330 Global step 330 Train loss 7.30 on epoch=82
05/17/2022 11:54:31 - INFO - __main__ - Step 340 Global step 340 Train loss 7.29 on epoch=84
05/17/2022 11:54:33 - INFO - __main__ - Step 350 Global step 350 Train loss 7.20 on epoch=87
05/17/2022 11:54:47 - INFO - __main__ - Global step 350 Train loss 7.36 Classification-F1 0.0 on epoch=87
05/17/2022 11:54:49 - INFO - __main__ - Step 360 Global step 360 Train loss 7.14 on epoch=89
05/17/2022 11:54:50 - INFO - __main__ - Step 370 Global step 370 Train loss 6.99 on epoch=92
05/17/2022 11:54:52 - INFO - __main__ - Step 380 Global step 380 Train loss 6.73 on epoch=94
05/17/2022 11:54:53 - INFO - __main__ - Step 390 Global step 390 Train loss 6.70 on epoch=97
05/17/2022 11:54:54 - INFO - __main__ - Step 400 Global step 400 Train loss 6.73 on epoch=99
05/17/2022 11:54:59 - INFO - __main__ - Global step 400 Train loss 6.86 Classification-F1 0.0 on epoch=99
05/17/2022 11:55:00 - INFO - __main__ - Step 410 Global step 410 Train loss 6.61 on epoch=102
05/17/2022 11:55:01 - INFO - __main__ - Step 420 Global step 420 Train loss 6.34 on epoch=104
05/17/2022 11:55:03 - INFO - __main__ - Step 430 Global step 430 Train loss 6.34 on epoch=107
05/17/2022 11:55:04 - INFO - __main__ - Step 440 Global step 440 Train loss 6.18 on epoch=109
05/17/2022 11:55:06 - INFO - __main__ - Step 450 Global step 450 Train loss 6.33 on epoch=112
05/17/2022 11:55:13 - INFO - __main__ - Global step 450 Train loss 6.36 Classification-F1 0.0 on epoch=112
05/17/2022 11:55:14 - INFO - __main__ - Step 460 Global step 460 Train loss 5.99 on epoch=114
05/17/2022 11:55:16 - INFO - __main__ - Step 470 Global step 470 Train loss 6.07 on epoch=117
05/17/2022 11:55:17 - INFO - __main__ - Step 480 Global step 480 Train loss 5.78 on epoch=119
05/17/2022 11:55:18 - INFO - __main__ - Step 490 Global step 490 Train loss 5.92 on epoch=122
05/17/2022 11:55:20 - INFO - __main__ - Step 500 Global step 500 Train loss 5.73 on epoch=124
05/17/2022 11:55:26 - INFO - __main__ - Global step 500 Train loss 5.90 Classification-F1 0.0 on epoch=124
05/17/2022 11:55:27 - INFO - __main__ - Step 510 Global step 510 Train loss 5.83 on epoch=127
05/17/2022 11:55:29 - INFO - __main__ - Step 520 Global step 520 Train loss 5.60 on epoch=129
05/17/2022 11:55:30 - INFO - __main__ - Step 530 Global step 530 Train loss 5.69 on epoch=132
05/17/2022 11:55:31 - INFO - __main__ - Step 540 Global step 540 Train loss 5.61 on epoch=134
05/17/2022 11:55:33 - INFO - __main__ - Step 550 Global step 550 Train loss 5.46 on epoch=137
05/17/2022 11:55:38 - INFO - __main__ - Global step 550 Train loss 5.64 Classification-F1 0.0 on epoch=137
05/17/2022 11:55:39 - INFO - __main__ - Step 560 Global step 560 Train loss 5.33 on epoch=139
05/17/2022 11:55:41 - INFO - __main__ - Step 570 Global step 570 Train loss 5.32 on epoch=142
05/17/2022 11:55:42 - INFO - __main__ - Step 580 Global step 580 Train loss 5.14 on epoch=144
05/17/2022 11:55:43 - INFO - __main__ - Step 590 Global step 590 Train loss 5.52 on epoch=147
05/17/2022 11:55:45 - INFO - __main__ - Step 600 Global step 600 Train loss 5.23 on epoch=149
05/17/2022 11:55:49 - INFO - __main__ - Global step 600 Train loss 5.31 Classification-F1 0.0 on epoch=149
05/17/2022 11:55:50 - INFO - __main__ - Step 610 Global step 610 Train loss 5.21 on epoch=152
05/17/2022 11:55:52 - INFO - __main__ - Step 620 Global step 620 Train loss 4.97 on epoch=154
05/17/2022 11:55:53 - INFO - __main__ - Step 630 Global step 630 Train loss 4.98 on epoch=157
05/17/2022 11:55:54 - INFO - __main__ - Step 640 Global step 640 Train loss 4.94 on epoch=159
05/17/2022 11:55:56 - INFO - __main__ - Step 650 Global step 650 Train loss 5.02 on epoch=162
05/17/2022 11:56:00 - INFO - __main__ - Global step 650 Train loss 5.02 Classification-F1 0.0 on epoch=162
05/17/2022 11:56:02 - INFO - __main__ - Step 660 Global step 660 Train loss 4.68 on epoch=164
05/17/2022 11:56:03 - INFO - __main__ - Step 670 Global step 670 Train loss 4.83 on epoch=167
05/17/2022 11:56:04 - INFO - __main__ - Step 680 Global step 680 Train loss 4.57 on epoch=169
05/17/2022 11:56:06 - INFO - __main__ - Step 690 Global step 690 Train loss 4.70 on epoch=172
05/17/2022 11:56:07 - INFO - __main__ - Step 700 Global step 700 Train loss 4.50 on epoch=174
05/17/2022 11:56:12 - INFO - __main__ - Global step 700 Train loss 4.66 Classification-F1 0.0 on epoch=174
05/17/2022 11:56:13 - INFO - __main__ - Step 710 Global step 710 Train loss 4.54 on epoch=177
05/17/2022 11:56:15 - INFO - __main__ - Step 720 Global step 720 Train loss 4.41 on epoch=179
05/17/2022 11:56:16 - INFO - __main__ - Step 730 Global step 730 Train loss 4.45 on epoch=182
05/17/2022 11:56:18 - INFO - __main__ - Step 740 Global step 740 Train loss 4.21 on epoch=184
05/17/2022 11:56:19 - INFO - __main__ - Step 750 Global step 750 Train loss 4.44 on epoch=187
05/17/2022 11:56:24 - INFO - __main__ - Global step 750 Train loss 4.41 Classification-F1 0.0 on epoch=187
05/17/2022 11:56:26 - INFO - __main__ - Step 760 Global step 760 Train loss 4.14 on epoch=189
05/17/2022 11:56:27 - INFO - __main__ - Step 770 Global step 770 Train loss 4.18 on epoch=192
05/17/2022 11:56:29 - INFO - __main__ - Step 780 Global step 780 Train loss 4.01 on epoch=194
05/17/2022 11:56:30 - INFO - __main__ - Step 790 Global step 790 Train loss 4.27 on epoch=197
05/17/2022 11:56:31 - INFO - __main__ - Step 800 Global step 800 Train loss 4.09 on epoch=199
05/17/2022 11:56:35 - INFO - __main__ - Global step 800 Train loss 4.14 Classification-F1 0.0 on epoch=199
05/17/2022 11:56:37 - INFO - __main__ - Step 810 Global step 810 Train loss 4.00 on epoch=202
05/17/2022 11:56:38 - INFO - __main__ - Step 820 Global step 820 Train loss 3.96 on epoch=204
05/17/2022 11:56:39 - INFO - __main__ - Step 830 Global step 830 Train loss 4.00 on epoch=207
05/17/2022 11:56:41 - INFO - __main__ - Step 840 Global step 840 Train loss 3.81 on epoch=209
05/17/2022 11:56:42 - INFO - __main__ - Step 850 Global step 850 Train loss 4.02 on epoch=212
05/17/2022 11:56:50 - INFO - __main__ - Global step 850 Train loss 3.96 Classification-F1 0.0 on epoch=212
05/17/2022 11:56:51 - INFO - __main__ - Step 860 Global step 860 Train loss 3.80 on epoch=214
05/17/2022 11:56:53 - INFO - __main__ - Step 870 Global step 870 Train loss 3.91 on epoch=217
05/17/2022 11:56:54 - INFO - __main__ - Step 880 Global step 880 Train loss 3.69 on epoch=219
05/17/2022 11:56:56 - INFO - __main__ - Step 890 Global step 890 Train loss 3.68 on epoch=222
05/17/2022 11:56:57 - INFO - __main__ - Step 900 Global step 900 Train loss 3.74 on epoch=224
05/17/2022 11:56:59 - INFO - __main__ - Global step 900 Train loss 3.76 Classification-F1 0.12324324324324323 on epoch=224
05/17/2022 11:56:59 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.12324324324324323 on epoch=224, global_step=900
05/17/2022 11:57:00 - INFO - __main__ - Step 910 Global step 910 Train loss 3.49 on epoch=227
05/17/2022 11:57:02 - INFO - __main__ - Step 920 Global step 920 Train loss 3.54 on epoch=229
05/17/2022 11:57:03 - INFO - __main__ - Step 930 Global step 930 Train loss 3.63 on epoch=232
05/17/2022 11:57:05 - INFO - __main__ - Step 940 Global step 940 Train loss 3.38 on epoch=234
05/17/2022 11:57:06 - INFO - __main__ - Step 950 Global step 950 Train loss 3.39 on epoch=237
05/17/2022 11:57:07 - INFO - __main__ - Global step 950 Train loss 3.49 Classification-F1 0.12368421052631579 on epoch=237
05/17/2022 11:57:07 - INFO - __main__ - Saving model with best Classification-F1: 0.12324324324324323 -> 0.12368421052631579 on epoch=237, global_step=950
05/17/2022 11:57:08 - INFO - __main__ - Step 960 Global step 960 Train loss 3.29 on epoch=239
05/17/2022 11:57:10 - INFO - __main__ - Step 970 Global step 970 Train loss 3.41 on epoch=242
05/17/2022 11:57:11 - INFO - __main__ - Step 980 Global step 980 Train loss 3.32 on epoch=244
05/17/2022 11:57:13 - INFO - __main__ - Step 990 Global step 990 Train loss 3.23 on epoch=247
05/17/2022 11:57:14 - INFO - __main__ - Step 1000 Global step 1000 Train loss 3.13 on epoch=249
05/17/2022 11:57:15 - INFO - __main__ - Global step 1000 Train loss 3.28 Classification-F1 0.1875 on epoch=249
05/17/2022 11:57:15 - INFO - __main__ - Saving model with best Classification-F1: 0.12368421052631579 -> 0.1875 on epoch=249, global_step=1000
05/17/2022 11:57:17 - INFO - __main__ - Step 1010 Global step 1010 Train loss 3.18 on epoch=252
05/17/2022 11:57:18 - INFO - __main__ - Step 1020 Global step 1020 Train loss 3.18 on epoch=254
05/17/2022 11:57:20 - INFO - __main__ - Step 1030 Global step 1030 Train loss 3.09 on epoch=257
05/17/2022 11:57:21 - INFO - __main__ - Step 1040 Global step 1040 Train loss 3.04 on epoch=259
05/17/2022 11:57:22 - INFO - __main__ - Step 1050 Global step 1050 Train loss 3.07 on epoch=262
05/17/2022 11:57:23 - INFO - __main__ - Global step 1050 Train loss 3.11 Classification-F1 0.18614718614718614 on epoch=262
05/17/2022 11:57:24 - INFO - __main__ - Step 1060 Global step 1060 Train loss 2.90 on epoch=264
05/17/2022 11:57:26 - INFO - __main__ - Step 1070 Global step 1070 Train loss 3.13 on epoch=267
05/17/2022 11:57:27 - INFO - __main__ - Step 1080 Global step 1080 Train loss 3.03 on epoch=269
05/17/2022 11:57:28 - INFO - __main__ - Step 1090 Global step 1090 Train loss 2.73 on epoch=272
05/17/2022 11:57:30 - INFO - __main__ - Step 1100 Global step 1100 Train loss 2.79 on epoch=274
05/17/2022 11:57:31 - INFO - __main__ - Global step 1100 Train loss 2.92 Classification-F1 0.11923076923076922 on epoch=274
05/17/2022 11:57:32 - INFO - __main__ - Step 1110 Global step 1110 Train loss 2.77 on epoch=277
05/17/2022 11:57:33 - INFO - __main__ - Step 1120 Global step 1120 Train loss 2.61 on epoch=279
05/17/2022 11:57:35 - INFO - __main__ - Step 1130 Global step 1130 Train loss 2.54 on epoch=282
05/17/2022 11:57:36 - INFO - __main__ - Step 1140 Global step 1140 Train loss 2.72 on epoch=284
05/17/2022 11:57:37 - INFO - __main__ - Step 1150 Global step 1150 Train loss 2.65 on epoch=287
05/17/2022 11:57:43 - INFO - __main__ - Global step 1150 Train loss 2.66 Classification-F1 0.11732186732186733 on epoch=287
05/17/2022 11:57:44 - INFO - __main__ - Step 1160 Global step 1160 Train loss 2.49 on epoch=289
05/17/2022 11:57:45 - INFO - __main__ - Step 1170 Global step 1170 Train loss 2.73 on epoch=292
05/17/2022 11:57:47 - INFO - __main__ - Step 1180 Global step 1180 Train loss 2.44 on epoch=294
05/17/2022 11:57:48 - INFO - __main__ - Step 1190 Global step 1190 Train loss 2.58 on epoch=297
05/17/2022 11:57:49 - INFO - __main__ - Step 1200 Global step 1200 Train loss 2.57 on epoch=299
05/17/2022 11:57:50 - INFO - __main__ - Global step 1200 Train loss 2.56 Classification-F1 0.1 on epoch=299
05/17/2022 11:57:51 - INFO - __main__ - Step 1210 Global step 1210 Train loss 2.43 on epoch=302
05/17/2022 11:57:52 - INFO - __main__ - Step 1220 Global step 1220 Train loss 2.43 on epoch=304
05/17/2022 11:57:54 - INFO - __main__ - Step 1230 Global step 1230 Train loss 2.40 on epoch=307
05/17/2022 11:57:55 - INFO - __main__ - Step 1240 Global step 1240 Train loss 2.26 on epoch=309
05/17/2022 11:57:56 - INFO - __main__ - Step 1250 Global step 1250 Train loss 2.39 on epoch=312
05/17/2022 11:57:57 - INFO - __main__ - Global step 1250 Train loss 2.38 Classification-F1 0.1 on epoch=312
05/17/2022 11:57:58 - INFO - __main__ - Step 1260 Global step 1260 Train loss 2.34 on epoch=314
05/17/2022 11:57:59 - INFO - __main__ - Step 1270 Global step 1270 Train loss 2.27 on epoch=317
05/17/2022 11:58:01 - INFO - __main__ - Step 1280 Global step 1280 Train loss 2.07 on epoch=319
05/17/2022 11:58:02 - INFO - __main__ - Step 1290 Global step 1290 Train loss 2.29 on epoch=322
05/17/2022 11:58:04 - INFO - __main__ - Step 1300 Global step 1300 Train loss 2.24 on epoch=324
05/17/2022 11:58:04 - INFO - __main__ - Global step 1300 Train loss 2.24 Classification-F1 0.1 on epoch=324
05/17/2022 11:58:05 - INFO - __main__ - Step 1310 Global step 1310 Train loss 2.28 on epoch=327
05/17/2022 11:58:07 - INFO - __main__ - Step 1320 Global step 1320 Train loss 2.11 on epoch=329
05/17/2022 11:58:08 - INFO - __main__ - Step 1330 Global step 1330 Train loss 2.08 on epoch=332
05/17/2022 11:58:10 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.98 on epoch=334
05/17/2022 11:58:11 - INFO - __main__ - Step 1350 Global step 1350 Train loss 2.01 on epoch=337
05/17/2022 11:58:12 - INFO - __main__ - Global step 1350 Train loss 2.09 Classification-F1 0.1 on epoch=337
05/17/2022 11:58:13 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.96 on epoch=339
05/17/2022 11:58:15 - INFO - __main__ - Step 1370 Global step 1370 Train loss 2.04 on epoch=342
05/17/2022 11:58:16 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.92 on epoch=344
05/17/2022 11:58:18 - INFO - __main__ - Step 1390 Global step 1390 Train loss 2.04 on epoch=347
05/17/2022 11:58:19 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.78 on epoch=349
05/17/2022 11:58:19 - INFO - __main__ - Global step 1400 Train loss 1.95 Classification-F1 0.1 on epoch=349
05/17/2022 11:58:21 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.92 on epoch=352
05/17/2022 11:58:22 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.89 on epoch=354
05/17/2022 11:58:24 - INFO - __main__ - Step 1430 Global step 1430 Train loss 2.00 on epoch=357
05/17/2022 11:58:25 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.86 on epoch=359
05/17/2022 11:58:26 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.96 on epoch=362
05/17/2022 11:58:27 - INFO - __main__ - Global step 1450 Train loss 1.93 Classification-F1 0.1 on epoch=362
05/17/2022 11:58:28 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.64 on epoch=364
05/17/2022 11:58:30 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.74 on epoch=367
05/17/2022 11:58:31 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.68 on epoch=369
05/17/2022 11:58:33 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.88 on epoch=372
05/17/2022 11:58:34 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.78 on epoch=374
05/17/2022 11:58:34 - INFO - __main__ - Global step 1500 Train loss 1.75 Classification-F1 0.10126582278481013 on epoch=374
05/17/2022 11:58:36 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.80 on epoch=377
05/17/2022 11:58:37 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.85 on epoch=379
05/17/2022 11:58:39 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.79 on epoch=382
05/17/2022 11:58:40 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.69 on epoch=384
05/17/2022 11:58:41 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.68 on epoch=387
05/17/2022 11:58:42 - INFO - __main__ - Global step 1550 Train loss 1.76 Classification-F1 0.10450704225352113 on epoch=387
05/17/2022 11:58:43 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.68 on epoch=389
05/17/2022 11:58:45 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.71 on epoch=392
05/17/2022 11:58:46 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.50 on epoch=394
05/17/2022 11:58:47 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.68 on epoch=397
05/17/2022 11:58:49 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.62 on epoch=399
05/17/2022 11:58:49 - INFO - __main__ - Global step 1600 Train loss 1.64 Classification-F1 0.20417422867513613 on epoch=399
05/17/2022 11:58:49 - INFO - __main__ - Saving model with best Classification-F1: 0.1875 -> 0.20417422867513613 on epoch=399, global_step=1600
05/17/2022 11:58:51 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.62 on epoch=402
05/17/2022 11:58:52 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.40 on epoch=404
05/17/2022 11:58:53 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.48 on epoch=407
05/17/2022 11:58:55 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.59 on epoch=409
05/17/2022 11:58:56 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.58 on epoch=412
05/17/2022 11:58:57 - INFO - __main__ - Global step 1650 Train loss 1.54 Classification-F1 0.161078431372549 on epoch=412
05/17/2022 11:58:58 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.56 on epoch=414
05/17/2022 11:58:59 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.54 on epoch=417
05/17/2022 11:59:01 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.42 on epoch=419
05/17/2022 11:59:02 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.48 on epoch=422
05/17/2022 11:59:03 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.35 on epoch=424
05/17/2022 11:59:04 - INFO - __main__ - Global step 1700 Train loss 1.47 Classification-F1 0.13034188034188032 on epoch=424
05/17/2022 11:59:05 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.28 on epoch=427
05/17/2022 11:59:07 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.34 on epoch=429
05/17/2022 11:59:08 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.39 on epoch=432
05/17/2022 11:59:09 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.44 on epoch=434
05/17/2022 11:59:11 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.35 on epoch=437
05/17/2022 11:59:11 - INFO - __main__ - Global step 1750 Train loss 1.36 Classification-F1 0.22832890218234186 on epoch=437
05/17/2022 11:59:11 - INFO - __main__ - Saving model with best Classification-F1: 0.20417422867513613 -> 0.22832890218234186 on epoch=437, global_step=1750
05/17/2022 11:59:13 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.28 on epoch=439
05/17/2022 11:59:14 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.48 on epoch=442
05/17/2022 11:59:16 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.42 on epoch=444
05/17/2022 11:59:17 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.51 on epoch=447
05/17/2022 11:59:18 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.41 on epoch=449
05/17/2022 11:59:19 - INFO - __main__ - Global step 1800 Train loss 1.42 Classification-F1 0.1302118933697881 on epoch=449
05/17/2022 11:59:20 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.31 on epoch=452
05/17/2022 11:59:22 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.34 on epoch=454
05/17/2022 11:59:23 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.31 on epoch=457
05/17/2022 11:59:24 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.26 on epoch=459
05/17/2022 11:59:26 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.44 on epoch=462
05/17/2022 11:59:27 - INFO - __main__ - Global step 1850 Train loss 1.33 Classification-F1 0.12368421052631579 on epoch=462
05/17/2022 11:59:28 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.34 on epoch=464
05/17/2022 11:59:30 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.26 on epoch=467
05/17/2022 11:59:31 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.31 on epoch=469
05/17/2022 11:59:33 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.47 on epoch=472
05/17/2022 11:59:34 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.20 on epoch=474
05/17/2022 11:59:35 - INFO - __main__ - Global step 1900 Train loss 1.31 Classification-F1 0.09868421052631579 on epoch=474
05/17/2022 11:59:36 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.32 on epoch=477
05/17/2022 11:59:37 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.26 on epoch=479
05/17/2022 11:59:39 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.21 on epoch=482
05/17/2022 11:59:40 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.29 on epoch=484
05/17/2022 11:59:42 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.40 on epoch=487
05/17/2022 11:59:42 - INFO - __main__ - Global step 1950 Train loss 1.30 Classification-F1 0.1500341763499658 on epoch=487
05/17/2022 11:59:44 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.35 on epoch=489
05/17/2022 11:59:45 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.36 on epoch=492
05/17/2022 11:59:46 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.33 on epoch=494
05/17/2022 11:59:48 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.30 on epoch=497
05/17/2022 11:59:49 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.23 on epoch=499
05/17/2022 11:59:50 - INFO - __main__ - Global step 2000 Train loss 1.31 Classification-F1 0.1 on epoch=499
05/17/2022 11:59:51 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.21 on epoch=502
05/17/2022 11:59:53 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.19 on epoch=504
05/17/2022 11:59:54 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.22 on epoch=507
05/17/2022 11:59:56 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.37 on epoch=509
05/17/2022 11:59:57 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.29 on epoch=512
05/17/2022 11:59:57 - INFO - __main__ - Global step 2050 Train loss 1.26 Classification-F1 0.13067758749069247 on epoch=512
05/17/2022 11:59:59 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.24 on epoch=514
05/17/2022 12:00:00 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.27 on epoch=517
05/17/2022 12:00:02 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.19 on epoch=519
05/17/2022 12:00:03 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.26 on epoch=522
05/17/2022 12:00:04 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.07 on epoch=524
05/17/2022 12:00:05 - INFO - __main__ - Global step 2100 Train loss 1.21 Classification-F1 0.10126582278481013 on epoch=524
05/17/2022 12:00:06 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.24 on epoch=527
05/17/2022 12:00:08 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.35 on epoch=529
05/17/2022 12:00:09 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.34 on epoch=532
05/17/2022 12:00:10 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.14 on epoch=534
05/17/2022 12:00:12 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.28 on epoch=537
05/17/2022 12:00:12 - INFO - __main__ - Global step 2150 Train loss 1.27 Classification-F1 0.1581196581196581 on epoch=537
05/17/2022 12:00:14 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.19 on epoch=539
05/17/2022 12:00:15 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.22 on epoch=542
05/17/2022 12:00:17 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.22 on epoch=544
05/17/2022 12:00:18 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.20 on epoch=547
05/17/2022 12:00:19 - INFO - __main__ - Step 2200 Global step 2200 Train loss 1.26 on epoch=549
05/17/2022 12:00:20 - INFO - __main__ - Global step 2200 Train loss 1.22 Classification-F1 0.23941798941798942 on epoch=549
05/17/2022 12:00:20 - INFO - __main__ - Saving model with best Classification-F1: 0.22832890218234186 -> 0.23941798941798942 on epoch=549, global_step=2200
05/17/2022 12:00:21 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.27 on epoch=552
05/17/2022 12:00:23 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.20 on epoch=554
05/17/2022 12:00:24 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.16 on epoch=557
05/17/2022 12:00:25 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.19 on epoch=559
05/17/2022 12:00:27 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.21 on epoch=562
05/17/2022 12:00:27 - INFO - __main__ - Global step 2250 Train loss 1.21 Classification-F1 0.2190620929222753 on epoch=562
05/17/2022 12:00:29 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.08 on epoch=564
05/17/2022 12:00:30 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.15 on epoch=567
05/17/2022 12:00:31 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.30 on epoch=569
05/17/2022 12:00:33 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.27 on epoch=572
05/17/2022 12:00:34 - INFO - __main__ - Step 2300 Global step 2300 Train loss 1.06 on epoch=574
05/17/2022 12:00:35 - INFO - __main__ - Global step 2300 Train loss 1.18 Classification-F1 0.19957983193277312 on epoch=574
05/17/2022 12:00:36 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.37 on epoch=577
05/17/2022 12:00:37 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.11 on epoch=579
05/17/2022 12:00:39 - INFO - __main__ - Step 2330 Global step 2330 Train loss 1.32 on epoch=582
05/17/2022 12:00:40 - INFO - __main__ - Step 2340 Global step 2340 Train loss 1.10 on epoch=584
05/17/2022 12:00:41 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.24 on epoch=587
05/17/2022 12:00:42 - INFO - __main__ - Global step 2350 Train loss 1.23 Classification-F1 0.14777327935222673 on epoch=587
05/17/2022 12:00:43 - INFO - __main__ - Step 2360 Global step 2360 Train loss 1.05 on epoch=589
05/17/2022 12:00:45 - INFO - __main__ - Step 2370 Global step 2370 Train loss 1.22 on epoch=592
05/17/2022 12:00:46 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.05 on epoch=594
05/17/2022 12:00:47 - INFO - __main__ - Step 2390 Global step 2390 Train loss 1.09 on epoch=597
05/17/2022 12:00:49 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.13 on epoch=599
05/17/2022 12:00:49 - INFO - __main__ - Global step 2400 Train loss 1.11 Classification-F1 0.1565349544072948 on epoch=599
05/17/2022 12:00:51 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.25 on epoch=602
05/17/2022 12:00:52 - INFO - __main__ - Step 2420 Global step 2420 Train loss 1.10 on epoch=604
05/17/2022 12:00:54 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.02 on epoch=607
05/17/2022 12:00:55 - INFO - __main__ - Step 2440 Global step 2440 Train loss 1.12 on epoch=609
05/17/2022 12:00:56 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.13 on epoch=612
05/17/2022 12:00:57 - INFO - __main__ - Global step 2450 Train loss 1.13 Classification-F1 0.1 on epoch=612
05/17/2022 12:00:58 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.06 on epoch=614
05/17/2022 12:00:59 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.09 on epoch=617
05/17/2022 12:01:01 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.21 on epoch=619
05/17/2022 12:01:02 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.10 on epoch=622
05/17/2022 12:01:04 - INFO - __main__ - Step 2500 Global step 2500 Train loss 1.22 on epoch=624
05/17/2022 12:01:04 - INFO - __main__ - Global step 2500 Train loss 1.14 Classification-F1 0.1302118933697881 on epoch=624
05/17/2022 12:01:05 - INFO - __main__ - Step 2510 Global step 2510 Train loss 1.31 on epoch=627
05/17/2022 12:01:07 - INFO - __main__ - Step 2520 Global step 2520 Train loss 1.14 on epoch=629
05/17/2022 12:01:08 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.29 on epoch=632
05/17/2022 12:01:10 - INFO - __main__ - Step 2540 Global step 2540 Train loss 1.06 on epoch=634
05/17/2022 12:01:11 - INFO - __main__ - Step 2550 Global step 2550 Train loss 1.20 on epoch=637
05/17/2022 12:01:12 - INFO - __main__ - Global step 2550 Train loss 1.20 Classification-F1 0.09493670886075949 on epoch=637
05/17/2022 12:01:13 - INFO - __main__ - Step 2560 Global step 2560 Train loss 1.17 on epoch=639
05/17/2022 12:01:15 - INFO - __main__ - Step 2570 Global step 2570 Train loss 1.17 on epoch=642
05/17/2022 12:01:16 - INFO - __main__ - Step 2580 Global step 2580 Train loss 1.26 on epoch=644
05/17/2022 12:01:17 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.13 on epoch=647
05/17/2022 12:01:19 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.12 on epoch=649
05/17/2022 12:01:19 - INFO - __main__ - Global step 2600 Train loss 1.17 Classification-F1 0.1 on epoch=649
05/17/2022 12:01:21 - INFO - __main__ - Step 2610 Global step 2610 Train loss 1.19 on epoch=652
05/17/2022 12:01:22 - INFO - __main__ - Step 2620 Global step 2620 Train loss 1.11 on epoch=654
05/17/2022 12:01:24 - INFO - __main__ - Step 2630 Global step 2630 Train loss 1.20 on epoch=657
05/17/2022 12:01:25 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.12 on epoch=659
05/17/2022 12:01:26 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.03 on epoch=662
05/17/2022 12:01:27 - INFO - __main__ - Global step 2650 Train loss 1.13 Classification-F1 0.1 on epoch=662
05/17/2022 12:01:29 - INFO - __main__ - Step 2660 Global step 2660 Train loss 1.12 on epoch=664
05/17/2022 12:01:30 - INFO - __main__ - Step 2670 Global step 2670 Train loss 1.15 on epoch=667
05/17/2022 12:01:31 - INFO - __main__ - Step 2680 Global step 2680 Train loss 1.08 on epoch=669
05/17/2022 12:01:33 - INFO - __main__ - Step 2690 Global step 2690 Train loss 1.06 on epoch=672
05/17/2022 12:01:34 - INFO - __main__ - Step 2700 Global step 2700 Train loss 1.10 on epoch=674
05/17/2022 12:01:35 - INFO - __main__ - Global step 2700 Train loss 1.10 Classification-F1 0.1 on epoch=674
05/17/2022 12:01:36 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.02 on epoch=677
05/17/2022 12:01:38 - INFO - __main__ - Step 2720 Global step 2720 Train loss 1.13 on epoch=679
05/17/2022 12:01:39 - INFO - __main__ - Step 2730 Global step 2730 Train loss 1.14 on epoch=682
05/17/2022 12:01:40 - INFO - __main__ - Step 2740 Global step 2740 Train loss 1.02 on epoch=684
05/17/2022 12:01:42 - INFO - __main__ - Step 2750 Global step 2750 Train loss 1.12 on epoch=687
05/17/2022 12:01:42 - INFO - __main__ - Global step 2750 Train loss 1.09 Classification-F1 0.09615384615384615 on epoch=687
05/17/2022 12:01:44 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.18 on epoch=689
05/17/2022 12:01:45 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.16 on epoch=692
05/17/2022 12:01:46 - INFO - __main__ - Step 2780 Global step 2780 Train loss 1.06 on epoch=694
05/17/2022 12:01:48 - INFO - __main__ - Step 2790 Global step 2790 Train loss 1.08 on epoch=697
05/17/2022 12:01:49 - INFO - __main__ - Step 2800 Global step 2800 Train loss 1.12 on epoch=699
05/17/2022 12:01:50 - INFO - __main__ - Global step 2800 Train loss 1.12 Classification-F1 0.1237183868762816 on epoch=699
05/17/2022 12:01:51 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.20 on epoch=702
05/17/2022 12:01:53 - INFO - __main__ - Step 2820 Global step 2820 Train loss 1.11 on epoch=704
05/17/2022 12:01:54 - INFO - __main__ - Step 2830 Global step 2830 Train loss 1.11 on epoch=707
05/17/2022 12:01:56 - INFO - __main__ - Step 2840 Global step 2840 Train loss 1.00 on epoch=709
05/17/2022 12:01:57 - INFO - __main__ - Step 2850 Global step 2850 Train loss 1.12 on epoch=712
05/17/2022 12:01:57 - INFO - __main__ - Global step 2850 Train loss 1.11 Classification-F1 0.16515151515151516 on epoch=712
05/17/2022 12:01:59 - INFO - __main__ - Step 2860 Global step 2860 Train loss 1.01 on epoch=714
05/17/2022 12:02:00 - INFO - __main__ - Step 2870 Global step 2870 Train loss 1.14 on epoch=717
05/17/2022 12:02:02 - INFO - __main__ - Step 2880 Global step 2880 Train loss 1.19 on epoch=719
05/17/2022 12:02:03 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.25 on epoch=722
05/17/2022 12:02:04 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.05 on epoch=724
05/17/2022 12:02:05 - INFO - __main__ - Global step 2900 Train loss 1.13 Classification-F1 0.18284347231715653 on epoch=724
05/17/2022 12:02:06 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.13 on epoch=727
05/17/2022 12:02:08 - INFO - __main__ - Step 2920 Global step 2920 Train loss 1.09 on epoch=729
05/17/2022 12:02:09 - INFO - __main__ - Step 2930 Global step 2930 Train loss 1.00 on epoch=732
05/17/2022 12:02:10 - INFO - __main__ - Step 2940 Global step 2940 Train loss 1.15 on epoch=734
05/17/2022 12:02:12 - INFO - __main__ - Step 2950 Global step 2950 Train loss 1.06 on epoch=737
05/17/2022 12:02:12 - INFO - __main__ - Global step 2950 Train loss 1.09 Classification-F1 0.23973977889027953 on epoch=737
05/17/2022 12:02:12 - INFO - __main__ - Saving model with best Classification-F1: 0.23941798941798942 -> 0.23973977889027953 on epoch=737, global_step=2950
05/17/2022 12:02:14 - INFO - __main__ - Step 2960 Global step 2960 Train loss 1.04 on epoch=739
05/17/2022 12:02:15 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.07 on epoch=742
05/17/2022 12:02:17 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.13 on epoch=744
05/17/2022 12:02:18 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.99 on epoch=747
05/17/2022 12:02:19 - INFO - __main__ - Step 3000 Global step 3000 Train loss 1.03 on epoch=749
05/17/2022 12:02:20 - INFO - __main__ - Global step 3000 Train loss 1.05 Classification-F1 0.13067758749069247 on epoch=749
05/17/2022 12:02:20 - INFO - __main__ - save last model!
05/17/2022 12:02:20 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/17/2022 12:02:20 - INFO - __main__ - Start tokenizing ... 5509 instances
05/17/2022 12:02:20 - INFO - __main__ - Printing 3 examples
05/17/2022 12:02:20 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/17/2022 12:02:20 - INFO - __main__ - ['others']
05/17/2022 12:02:20 - INFO - __main__ -  [emo] what you like very little things ok
05/17/2022 12:02:20 - INFO - __main__ - ['others']
05/17/2022 12:02:20 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/17/2022 12:02:20 - INFO - __main__ - ['others']
05/17/2022 12:02:20 - INFO - __main__ - Tokenizing Input ...
05/17/2022 12:02:21 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 12:02:21 - INFO - __main__ - Printing 3 examples
05/17/2022 12:02:21 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
05/17/2022 12:02:21 - INFO - __main__ - ['others']
05/17/2022 12:02:21 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
05/17/2022 12:02:21 - INFO - __main__ - ['others']
05/17/2022 12:02:21 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
05/17/2022 12:02:21 - INFO - __main__ - ['others']
05/17/2022 12:02:21 - INFO - __main__ - Tokenizing Input ...
05/17/2022 12:02:21 - INFO - __main__ - Tokenizing Output ...
05/17/2022 12:02:21 - INFO - __main__ - Loaded 64 examples from train data
05/17/2022 12:02:21 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 12:02:21 - INFO - __main__ - Printing 3 examples
05/17/2022 12:02:21 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
05/17/2022 12:02:21 - INFO - __main__ - ['others']
05/17/2022 12:02:21 - INFO - __main__ -  [emo] i did ask now you did tell ms
05/17/2022 12:02:21 - INFO - __main__ - ['others']
05/17/2022 12:02:21 - INFO - __main__ -  [emo] buddy how you tell me your contact no
05/17/2022 12:02:21 - INFO - __main__ - ['others']
05/17/2022 12:02:21 - INFO - __main__ - Tokenizing Input ...
05/17/2022 12:02:21 - INFO - __main__ - Tokenizing Output ...
05/17/2022 12:02:21 - INFO - __main__ - Loaded 64 examples from dev data
05/17/2022 12:02:23 - INFO - __main__ - Tokenizing Output ...
05/17/2022 12:02:26 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 12:02:27 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 12:02:27 - INFO - __main__ - Starting training!
05/17/2022 12:02:29 - INFO - __main__ - Loaded 5509 examples from test data
05/17/2022 12:03:11 - INFO - __main__ - Saved prediction in models/T5-base-reptile-cls2cls-3e-5-2-5000-5e-1-10/singletask-emo/emo_16_100_0.2_8_predictions.txt
05/17/2022 12:03:11 - INFO - __main__ - Classification-F1 on test data: 0.0314
05/17/2022 12:03:12 - INFO - __main__ - prefix=emo_16_100, lr=0.2, bsz=8, dev_performance=0.23973977889027953, test_performance=0.031425552753034214
05/17/2022 12:03:12 - INFO - __main__ - Running ... prefix=emo_16_13, lr=0.5, bsz=8 ...
05/17/2022 12:03:13 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 12:03:13 - INFO - __main__ - Printing 3 examples
05/17/2022 12:03:13 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
05/17/2022 12:03:13 - INFO - __main__ - ['others']
05/17/2022 12:03:13 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
05/17/2022 12:03:13 - INFO - __main__ - ['others']
05/17/2022 12:03:13 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
05/17/2022 12:03:13 - INFO - __main__ - ['others']
05/17/2022 12:03:13 - INFO - __main__ - Tokenizing Input ...
05/17/2022 12:03:13 - INFO - __main__ - Tokenizing Output ...
05/17/2022 12:03:13 - INFO - __main__ - Loaded 64 examples from train data
05/17/2022 12:03:13 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 12:03:13 - INFO - __main__ - Printing 3 examples
05/17/2022 12:03:13 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
05/17/2022 12:03:13 - INFO - __main__ - ['others']
05/17/2022 12:03:13 - INFO - __main__ -  [emo] i did ask now you did tell ms
05/17/2022 12:03:13 - INFO - __main__ - ['others']
05/17/2022 12:03:13 - INFO - __main__ -  [emo] buddy how you tell me your contact no
05/17/2022 12:03:13 - INFO - __main__ - ['others']
05/17/2022 12:03:13 - INFO - __main__ - Tokenizing Input ...
05/17/2022 12:03:13 - INFO - __main__ - Tokenizing Output ...
05/17/2022 12:03:13 - INFO - __main__ - Loaded 64 examples from dev data
05/17/2022 12:03:19 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 12:03:19 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 12:03:19 - INFO - __main__ - Starting training!
05/17/2022 12:03:22 - INFO - __main__ - Step 10 Global step 10 Train loss 9.02 on epoch=2
05/17/2022 12:03:23 - INFO - __main__ - Step 20 Global step 20 Train loss 8.94 on epoch=4
05/17/2022 12:03:25 - INFO - __main__ - Step 30 Global step 30 Train loss 8.81 on epoch=7
05/17/2022 12:03:26 - INFO - __main__ - Step 40 Global step 40 Train loss 8.91 on epoch=9
05/17/2022 12:03:28 - INFO - __main__ - Step 50 Global step 50 Train loss 8.63 on epoch=12
05/17/2022 12:03:32 - INFO - __main__ - Global step 50 Train loss 8.86 Classification-F1 0.0 on epoch=12
05/17/2022 12:03:32 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/17/2022 12:03:34 - INFO - __main__ - Step 60 Global step 60 Train loss 8.60 on epoch=14
05/17/2022 12:03:35 - INFO - __main__ - Step 70 Global step 70 Train loss 8.50 on epoch=17
05/17/2022 12:03:36 - INFO - __main__ - Step 80 Global step 80 Train loss 8.34 on epoch=19
05/17/2022 12:03:38 - INFO - __main__ - Step 90 Global step 90 Train loss 8.16 on epoch=22
05/17/2022 12:03:39 - INFO - __main__ - Step 100 Global step 100 Train loss 8.04 on epoch=24
05/17/2022 12:03:54 - INFO - __main__ - Global step 100 Train loss 8.33 Classification-F1 0.0 on epoch=24
05/17/2022 12:03:55 - INFO - __main__ - Step 110 Global step 110 Train loss 7.73 on epoch=27
05/17/2022 12:03:57 - INFO - __main__ - Step 120 Global step 120 Train loss 7.63 on epoch=29
05/17/2022 12:03:58 - INFO - __main__ - Step 130 Global step 130 Train loss 7.62 on epoch=32
05/17/2022 12:03:59 - INFO - __main__ - Step 140 Global step 140 Train loss 7.33 on epoch=34
05/17/2022 12:04:01 - INFO - __main__ - Step 150 Global step 150 Train loss 7.02 on epoch=37
05/17/2022 12:04:06 - INFO - __main__ - Global step 150 Train loss 7.47 Classification-F1 0.0 on epoch=37
05/17/2022 12:04:07 - INFO - __main__ - Step 160 Global step 160 Train loss 6.82 on epoch=39
05/17/2022 12:04:08 - INFO - __main__ - Step 170 Global step 170 Train loss 6.65 on epoch=42
05/17/2022 12:04:10 - INFO - __main__ - Step 180 Global step 180 Train loss 6.37 on epoch=44
05/17/2022 12:04:11 - INFO - __main__ - Step 190 Global step 190 Train loss 6.41 on epoch=47
05/17/2022 12:04:13 - INFO - __main__ - Step 200 Global step 200 Train loss 6.01 on epoch=49
05/17/2022 12:04:17 - INFO - __main__ - Global step 200 Train loss 6.45 Classification-F1 0.0 on epoch=49
05/17/2022 12:04:18 - INFO - __main__ - Step 210 Global step 210 Train loss 5.89 on epoch=52
05/17/2022 12:04:19 - INFO - __main__ - Step 220 Global step 220 Train loss 5.59 on epoch=54
05/17/2022 12:04:21 - INFO - __main__ - Step 230 Global step 230 Train loss 5.64 on epoch=57
05/17/2022 12:04:22 - INFO - __main__ - Step 240 Global step 240 Train loss 5.42 on epoch=59
05/17/2022 12:04:24 - INFO - __main__ - Step 250 Global step 250 Train loss 5.19 on epoch=62
05/17/2022 12:04:38 - INFO - __main__ - Global step 250 Train loss 5.54 Classification-F1 0.0 on epoch=62
05/17/2022 12:04:40 - INFO - __main__ - Step 260 Global step 260 Train loss 5.14 on epoch=64
05/17/2022 12:04:41 - INFO - __main__ - Step 270 Global step 270 Train loss 4.96 on epoch=67
05/17/2022 12:04:42 - INFO - __main__ - Step 280 Global step 280 Train loss 4.73 on epoch=69
05/17/2022 12:04:44 - INFO - __main__ - Step 290 Global step 290 Train loss 4.82 on epoch=72
05/17/2022 12:04:45 - INFO - __main__ - Step 300 Global step 300 Train loss 4.44 on epoch=74
05/17/2022 12:04:49 - INFO - __main__ - Global step 300 Train loss 4.82 Classification-F1 0.0 on epoch=74
05/17/2022 12:04:51 - INFO - __main__ - Step 310 Global step 310 Train loss 4.50 on epoch=77
05/17/2022 12:04:52 - INFO - __main__ - Step 320 Global step 320 Train loss 4.19 on epoch=79
05/17/2022 12:04:53 - INFO - __main__ - Step 330 Global step 330 Train loss 4.19 on epoch=82
05/17/2022 12:04:55 - INFO - __main__ - Step 340 Global step 340 Train loss 3.96 on epoch=84
05/17/2022 12:04:56 - INFO - __main__ - Step 350 Global step 350 Train loss 3.86 on epoch=87
05/17/2022 12:04:58 - INFO - __main__ - Global step 350 Train loss 4.14 Classification-F1 0.06356356356356356 on epoch=87
05/17/2022 12:04:58 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.06356356356356356 on epoch=87, global_step=350
05/17/2022 12:04:59 - INFO - __main__ - Step 360 Global step 360 Train loss 3.81 on epoch=89
05/17/2022 12:05:01 - INFO - __main__ - Step 370 Global step 370 Train loss 3.89 on epoch=92
05/17/2022 12:05:02 - INFO - __main__ - Step 380 Global step 380 Train loss 3.40 on epoch=94
05/17/2022 12:05:03 - INFO - __main__ - Step 390 Global step 390 Train loss 3.67 on epoch=97
05/17/2022 12:05:05 - INFO - __main__ - Step 400 Global step 400 Train loss 3.34 on epoch=99
05/17/2022 12:05:06 - INFO - __main__ - Global step 400 Train loss 3.62 Classification-F1 0.13434704830053668 on epoch=99
05/17/2022 12:05:06 - INFO - __main__ - Saving model with best Classification-F1: 0.06356356356356356 -> 0.13434704830053668 on epoch=99, global_step=400
05/17/2022 12:05:07 - INFO - __main__ - Step 410 Global step 410 Train loss 3.46 on epoch=102
05/17/2022 12:05:08 - INFO - __main__ - Step 420 Global step 420 Train loss 3.10 on epoch=104
05/17/2022 12:05:10 - INFO - __main__ - Step 430 Global step 430 Train loss 3.11 on epoch=107
05/17/2022 12:05:11 - INFO - __main__ - Step 440 Global step 440 Train loss 2.81 on epoch=109
05/17/2022 12:05:12 - INFO - __main__ - Step 450 Global step 450 Train loss 3.24 on epoch=112
05/17/2022 12:05:13 - INFO - __main__ - Global step 450 Train loss 3.14 Classification-F1 0.17328042328042326 on epoch=112
05/17/2022 12:05:13 - INFO - __main__ - Saving model with best Classification-F1: 0.13434704830053668 -> 0.17328042328042326 on epoch=112, global_step=450
05/17/2022 12:05:14 - INFO - __main__ - Step 460 Global step 460 Train loss 2.95 on epoch=114
05/17/2022 12:05:16 - INFO - __main__ - Step 470 Global step 470 Train loss 2.98 on epoch=117
05/17/2022 12:05:17 - INFO - __main__ - Step 480 Global step 480 Train loss 2.68 on epoch=119
05/17/2022 12:05:18 - INFO - __main__ - Step 490 Global step 490 Train loss 2.77 on epoch=122
05/17/2022 12:05:20 - INFO - __main__ - Step 500 Global step 500 Train loss 2.49 on epoch=124
05/17/2022 12:05:20 - INFO - __main__ - Global step 500 Train loss 2.78 Classification-F1 0.164021164021164 on epoch=124
05/17/2022 12:05:21 - INFO - __main__ - Step 510 Global step 510 Train loss 2.54 on epoch=127
05/17/2022 12:05:23 - INFO - __main__ - Step 520 Global step 520 Train loss 2.53 on epoch=129
05/17/2022 12:05:24 - INFO - __main__ - Step 530 Global step 530 Train loss 2.39 on epoch=132
05/17/2022 12:05:26 - INFO - __main__ - Step 540 Global step 540 Train loss 2.29 on epoch=134
05/17/2022 12:05:27 - INFO - __main__ - Step 550 Global step 550 Train loss 2.29 on epoch=137
05/17/2022 12:05:27 - INFO - __main__ - Global step 550 Train loss 2.41 Classification-F1 0.11859154929577466 on epoch=137
05/17/2022 12:05:29 - INFO - __main__ - Step 560 Global step 560 Train loss 2.10 on epoch=139
05/17/2022 12:05:30 - INFO - __main__ - Step 570 Global step 570 Train loss 2.04 on epoch=142
05/17/2022 12:05:32 - INFO - __main__ - Step 580 Global step 580 Train loss 2.04 on epoch=144
05/17/2022 12:05:33 - INFO - __main__ - Step 590 Global step 590 Train loss 1.96 on epoch=147
05/17/2022 12:05:34 - INFO - __main__ - Step 600 Global step 600 Train loss 1.77 on epoch=149
05/17/2022 12:05:35 - INFO - __main__ - Global step 600 Train loss 1.98 Classification-F1 0.1825396825396825 on epoch=149
05/17/2022 12:05:35 - INFO - __main__ - Saving model with best Classification-F1: 0.17328042328042326 -> 0.1825396825396825 on epoch=149, global_step=600
05/17/2022 12:05:36 - INFO - __main__ - Step 610 Global step 610 Train loss 1.84 on epoch=152
05/17/2022 12:05:38 - INFO - __main__ - Step 620 Global step 620 Train loss 1.77 on epoch=154
05/17/2022 12:05:39 - INFO - __main__ - Step 630 Global step 630 Train loss 1.64 on epoch=157
05/17/2022 12:05:41 - INFO - __main__ - Step 640 Global step 640 Train loss 1.56 on epoch=159
05/17/2022 12:05:42 - INFO - __main__ - Step 650 Global step 650 Train loss 1.61 on epoch=162
05/17/2022 12:05:42 - INFO - __main__ - Global step 650 Train loss 1.68 Classification-F1 0.10126582278481013 on epoch=162
05/17/2022 12:05:44 - INFO - __main__ - Step 660 Global step 660 Train loss 1.57 on epoch=164
05/17/2022 12:05:45 - INFO - __main__ - Step 670 Global step 670 Train loss 1.50 on epoch=167
05/17/2022 12:05:47 - INFO - __main__ - Step 680 Global step 680 Train loss 1.62 on epoch=169
05/17/2022 12:05:48 - INFO - __main__ - Step 690 Global step 690 Train loss 1.61 on epoch=172
05/17/2022 12:05:49 - INFO - __main__ - Step 700 Global step 700 Train loss 1.41 on epoch=174
05/17/2022 12:05:50 - INFO - __main__ - Global step 700 Train loss 1.54 Classification-F1 0.1302118933697881 on epoch=174
05/17/2022 12:05:51 - INFO - __main__ - Step 710 Global step 710 Train loss 1.53 on epoch=177
05/17/2022 12:05:53 - INFO - __main__ - Step 720 Global step 720 Train loss 1.39 on epoch=179
05/17/2022 12:05:54 - INFO - __main__ - Step 730 Global step 730 Train loss 1.52 on epoch=182
05/17/2022 12:05:55 - INFO - __main__ - Step 740 Global step 740 Train loss 1.37 on epoch=184
05/17/2022 12:05:57 - INFO - __main__ - Step 750 Global step 750 Train loss 1.34 on epoch=187
05/17/2022 12:05:57 - INFO - __main__ - Global step 750 Train loss 1.43 Classification-F1 0.16953316953316955 on epoch=187
05/17/2022 12:05:59 - INFO - __main__ - Step 760 Global step 760 Train loss 1.21 on epoch=189
05/17/2022 12:06:00 - INFO - __main__ - Step 770 Global step 770 Train loss 1.27 on epoch=192
05/17/2022 12:06:02 - INFO - __main__ - Step 780 Global step 780 Train loss 1.36 on epoch=194
05/17/2022 12:06:03 - INFO - __main__ - Step 790 Global step 790 Train loss 1.27 on epoch=197
05/17/2022 12:06:04 - INFO - __main__ - Step 800 Global step 800 Train loss 1.10 on epoch=199
05/17/2022 12:06:05 - INFO - __main__ - Global step 800 Train loss 1.24 Classification-F1 0.1 on epoch=199
05/17/2022 12:06:06 - INFO - __main__ - Step 810 Global step 810 Train loss 1.32 on epoch=202
05/17/2022 12:06:08 - INFO - __main__ - Step 820 Global step 820 Train loss 1.29 on epoch=204
05/17/2022 12:06:09 - INFO - __main__ - Step 830 Global step 830 Train loss 1.25 on epoch=207
05/17/2022 12:06:10 - INFO - __main__ - Step 840 Global step 840 Train loss 1.11 on epoch=209
05/17/2022 12:06:12 - INFO - __main__ - Step 850 Global step 850 Train loss 1.19 on epoch=212
05/17/2022 12:06:12 - INFO - __main__ - Global step 850 Train loss 1.23 Classification-F1 0.10126582278481013 on epoch=212
05/17/2022 12:06:14 - INFO - __main__ - Step 860 Global step 860 Train loss 1.23 on epoch=214
05/17/2022 12:06:15 - INFO - __main__ - Step 870 Global step 870 Train loss 1.18 on epoch=217
05/17/2022 12:06:16 - INFO - __main__ - Step 880 Global step 880 Train loss 1.18 on epoch=219
05/17/2022 12:06:18 - INFO - __main__ - Step 890 Global step 890 Train loss 1.13 on epoch=222
05/17/2022 12:06:19 - INFO - __main__ - Step 900 Global step 900 Train loss 1.20 on epoch=224
05/17/2022 12:06:20 - INFO - __main__ - Global step 900 Train loss 1.18 Classification-F1 0.17436974789915968 on epoch=224
05/17/2022 12:06:21 - INFO - __main__ - Step 910 Global step 910 Train loss 1.15 on epoch=227
05/17/2022 12:06:22 - INFO - __main__ - Step 920 Global step 920 Train loss 1.26 on epoch=229
05/17/2022 12:06:24 - INFO - __main__ - Step 930 Global step 930 Train loss 1.25 on epoch=232
05/17/2022 12:06:25 - INFO - __main__ - Step 940 Global step 940 Train loss 1.16 on epoch=234
05/17/2022 12:06:26 - INFO - __main__ - Step 950 Global step 950 Train loss 1.11 on epoch=237
05/17/2022 12:06:27 - INFO - __main__ - Global step 950 Train loss 1.19 Classification-F1 0.12393162393162392 on epoch=237
05/17/2022 12:06:28 - INFO - __main__ - Step 960 Global step 960 Train loss 1.24 on epoch=239
05/17/2022 12:06:30 - INFO - __main__ - Step 970 Global step 970 Train loss 1.14 on epoch=242
05/17/2022 12:06:31 - INFO - __main__ - Step 980 Global step 980 Train loss 1.20 on epoch=244
05/17/2022 12:06:32 - INFO - __main__ - Step 990 Global step 990 Train loss 1.29 on epoch=247
05/17/2022 12:06:34 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.40 on epoch=249
05/17/2022 12:06:34 - INFO - __main__ - Global step 1000 Train loss 1.25 Classification-F1 0.13777777777777778 on epoch=249
05/17/2022 12:06:36 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.09 on epoch=252
05/17/2022 12:06:37 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.13 on epoch=254
05/17/2022 12:06:38 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.12 on epoch=257
05/17/2022 12:06:40 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.11 on epoch=259
05/17/2022 12:06:41 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.26 on epoch=262
05/17/2022 12:06:42 - INFO - __main__ - Global step 1050 Train loss 1.14 Classification-F1 0.1302118933697881 on epoch=262
05/17/2022 12:06:43 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.08 on epoch=264
05/17/2022 12:06:44 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.12 on epoch=267
05/17/2022 12:06:46 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.21 on epoch=269
05/17/2022 12:06:47 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.13 on epoch=272
05/17/2022 12:06:49 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.04 on epoch=274
05/17/2022 12:06:49 - INFO - __main__ - Global step 1100 Train loss 1.11 Classification-F1 0.1 on epoch=274
05/17/2022 12:06:51 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.25 on epoch=277
05/17/2022 12:06:52 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.28 on epoch=279
05/17/2022 12:06:53 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.18 on epoch=282
05/17/2022 12:06:55 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.16 on epoch=284
05/17/2022 12:06:56 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.13 on epoch=287
05/17/2022 12:06:56 - INFO - __main__ - Global step 1150 Train loss 1.20 Classification-F1 0.12368421052631579 on epoch=287
05/17/2022 12:06:58 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.99 on epoch=289
05/17/2022 12:06:59 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.10 on epoch=292
05/17/2022 12:07:01 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.20 on epoch=294
05/17/2022 12:07:02 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.11 on epoch=297
05/17/2022 12:07:03 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.09 on epoch=299
05/17/2022 12:07:04 - INFO - __main__ - Global step 1200 Train loss 1.10 Classification-F1 0.09615384615384615 on epoch=299
05/17/2022 12:07:05 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.15 on epoch=302
05/17/2022 12:07:06 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.06 on epoch=304
05/17/2022 12:07:08 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.04 on epoch=307
05/17/2022 12:07:09 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.11 on epoch=309
05/17/2022 12:07:11 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.28 on epoch=312
05/17/2022 12:07:11 - INFO - __main__ - Global step 1250 Train loss 1.13 Classification-F1 0.1 on epoch=312
05/17/2022 12:07:12 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.07 on epoch=314
05/17/2022 12:07:14 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.13 on epoch=317
05/17/2022 12:07:15 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.08 on epoch=319
05/17/2022 12:07:17 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.00 on epoch=322
05/17/2022 12:07:18 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.06 on epoch=324
05/17/2022 12:07:18 - INFO - __main__ - Global step 1300 Train loss 1.07 Classification-F1 0.1 on epoch=324
05/17/2022 12:07:20 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.15 on epoch=327
05/17/2022 12:07:21 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.21 on epoch=329
05/17/2022 12:07:22 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.00 on epoch=332
05/17/2022 12:07:24 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.01 on epoch=334
05/17/2022 12:07:25 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.19 on epoch=337
05/17/2022 12:07:26 - INFO - __main__ - Global step 1350 Train loss 1.11 Classification-F1 0.09615384615384615 on epoch=337
05/17/2022 12:07:27 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.10 on epoch=339
05/17/2022 12:07:28 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.01 on epoch=342
05/17/2022 12:07:30 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.04 on epoch=344
05/17/2022 12:07:31 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.15 on epoch=347
05/17/2022 12:07:33 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.04 on epoch=349
05/17/2022 12:07:33 - INFO - __main__ - Global step 1400 Train loss 1.07 Classification-F1 0.10126582278481013 on epoch=349
05/17/2022 12:07:35 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.23 on epoch=352
05/17/2022 12:07:36 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.08 on epoch=354
05/17/2022 12:07:37 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.97 on epoch=357
05/17/2022 12:07:39 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.98 on epoch=359
05/17/2022 12:07:40 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.04 on epoch=362
05/17/2022 12:07:40 - INFO - __main__ - Global step 1450 Train loss 1.06 Classification-F1 0.10389610389610389 on epoch=362
05/17/2022 12:07:42 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.02 on epoch=364
05/17/2022 12:07:43 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.09 on epoch=367
05/17/2022 12:07:45 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.07 on epoch=369
05/17/2022 12:07:46 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.03 on epoch=372
05/17/2022 12:07:47 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.08 on epoch=374
05/17/2022 12:07:48 - INFO - __main__ - Global step 1500 Train loss 1.06 Classification-F1 0.1 on epoch=374
05/17/2022 12:07:49 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.06 on epoch=377
05/17/2022 12:07:51 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.94 on epoch=379
05/17/2022 12:07:52 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.11 on epoch=382
05/17/2022 12:07:54 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.09 on epoch=384
05/17/2022 12:07:55 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.96 on epoch=387
05/17/2022 12:07:55 - INFO - __main__ - Global step 1550 Train loss 1.03 Classification-F1 0.10389610389610389 on epoch=387
05/17/2022 12:07:57 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.88 on epoch=389
05/17/2022 12:07:58 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.13 on epoch=392
05/17/2022 12:08:00 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.05 on epoch=394
05/17/2022 12:08:01 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.09 on epoch=397
05/17/2022 12:08:02 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.16 on epoch=399
05/17/2022 12:08:03 - INFO - __main__ - Global step 1600 Train loss 1.06 Classification-F1 0.1 on epoch=399
05/17/2022 12:08:04 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.10 on epoch=402
05/17/2022 12:08:05 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.09 on epoch=404
05/17/2022 12:08:07 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.08 on epoch=407
05/17/2022 12:08:08 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.05 on epoch=409
05/17/2022 12:08:10 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.07 on epoch=412
05/17/2022 12:08:10 - INFO - __main__ - Global step 1650 Train loss 1.08 Classification-F1 0.13034188034188032 on epoch=412
05/17/2022 12:08:11 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.05 on epoch=414
05/17/2022 12:08:13 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.96 on epoch=417
05/17/2022 12:08:14 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.07 on epoch=419
05/17/2022 12:08:16 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.08 on epoch=422
05/17/2022 12:08:17 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.97 on epoch=424
05/17/2022 12:08:18 - INFO - __main__ - Global step 1700 Train loss 1.03 Classification-F1 0.1 on epoch=424
05/17/2022 12:08:19 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.06 on epoch=427
05/17/2022 12:08:21 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.07 on epoch=429
05/17/2022 12:08:22 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.99 on epoch=432
05/17/2022 12:08:23 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.94 on epoch=434
05/17/2022 12:08:25 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.95 on epoch=437
05/17/2022 12:08:25 - INFO - __main__ - Global step 1750 Train loss 1.00 Classification-F1 0.1 on epoch=437
05/17/2022 12:08:27 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.03 on epoch=439
05/17/2022 12:08:28 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.97 on epoch=442
05/17/2022 12:08:29 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.97 on epoch=444
05/17/2022 12:08:31 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.06 on epoch=447
05/17/2022 12:08:32 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.03 on epoch=449
05/17/2022 12:08:33 - INFO - __main__ - Global step 1800 Train loss 1.01 Classification-F1 0.1 on epoch=449
05/17/2022 12:08:34 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.96 on epoch=452
05/17/2022 12:08:35 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.02 on epoch=454
05/17/2022 12:08:37 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.01 on epoch=457
05/17/2022 12:08:38 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.99 on epoch=459
05/17/2022 12:08:39 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.03 on epoch=462
05/17/2022 12:08:40 - INFO - __main__ - Global step 1850 Train loss 1.01 Classification-F1 0.09493670886075949 on epoch=462
05/17/2022 12:08:41 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.01 on epoch=464
05/17/2022 12:08:43 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.01 on epoch=467
05/17/2022 12:08:44 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.04 on epoch=469
05/17/2022 12:08:46 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.06 on epoch=472
05/17/2022 12:08:47 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.97 on epoch=474
05/17/2022 12:08:48 - INFO - __main__ - Global step 1900 Train loss 1.02 Classification-F1 0.13026315789473686 on epoch=474
05/17/2022 12:08:49 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.94 on epoch=477
05/17/2022 12:08:50 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.06 on epoch=479
05/17/2022 12:08:52 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.05 on epoch=482
05/17/2022 12:08:53 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.04 on epoch=484
05/17/2022 12:08:54 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.01 on epoch=487
05/17/2022 12:08:55 - INFO - __main__ - Global step 1950 Train loss 1.02 Classification-F1 0.09615384615384615 on epoch=487
05/17/2022 12:08:56 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.95 on epoch=489
05/17/2022 12:08:58 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.90 on epoch=492
05/17/2022 12:08:59 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.96 on epoch=494
05/17/2022 12:09:01 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.04 on epoch=497
05/17/2022 12:09:02 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.95 on epoch=499
05/17/2022 12:09:03 - INFO - __main__ - Global step 2000 Train loss 0.96 Classification-F1 0.1 on epoch=499
05/17/2022 12:09:04 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.98 on epoch=502
05/17/2022 12:09:06 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.96 on epoch=504
05/17/2022 12:09:07 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.05 on epoch=507
05/17/2022 12:09:08 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.00 on epoch=509
05/17/2022 12:09:10 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.99 on epoch=512
05/17/2022 12:09:10 - INFO - __main__ - Global step 2050 Train loss 0.99 Classification-F1 0.09493670886075949 on epoch=512
05/17/2022 12:09:12 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.01 on epoch=514
05/17/2022 12:09:13 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.01 on epoch=517
05/17/2022 12:09:14 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.07 on epoch=519
05/17/2022 12:09:16 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.01 on epoch=522
05/17/2022 12:09:17 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.07 on epoch=524
05/17/2022 12:09:18 - INFO - __main__ - Global step 2100 Train loss 1.04 Classification-F1 0.12368421052631579 on epoch=524
05/17/2022 12:09:19 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.97 on epoch=527
05/17/2022 12:09:20 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.98 on epoch=529
05/17/2022 12:09:22 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.03 on epoch=532
05/17/2022 12:09:23 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.90 on epoch=534
05/17/2022 12:09:24 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.91 on epoch=537
05/17/2022 12:09:25 - INFO - __main__ - Global step 2150 Train loss 0.96 Classification-F1 0.1623759305210918 on epoch=537
05/17/2022 12:09:26 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.08 on epoch=539
05/17/2022 12:09:28 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.94 on epoch=542
05/17/2022 12:09:29 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.92 on epoch=544
05/17/2022 12:09:31 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.99 on epoch=547
05/17/2022 12:09:32 - INFO - __main__ - Step 2200 Global step 2200 Train loss 1.03 on epoch=549
05/17/2022 12:09:33 - INFO - __main__ - Global step 2200 Train loss 0.99 Classification-F1 0.24441687344913154 on epoch=549
05/17/2022 12:09:33 - INFO - __main__ - Saving model with best Classification-F1: 0.1825396825396825 -> 0.24441687344913154 on epoch=549, global_step=2200
05/17/2022 12:09:34 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.04 on epoch=552
05/17/2022 12:09:35 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.92 on epoch=554
05/17/2022 12:09:37 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.09 on epoch=557
05/17/2022 12:09:38 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.99 on epoch=559
05/17/2022 12:09:39 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.11 on epoch=562
05/17/2022 12:09:40 - INFO - __main__ - Global step 2250 Train loss 1.03 Classification-F1 0.13848631239935588 on epoch=562
05/17/2022 12:09:42 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.94 on epoch=564
05/17/2022 12:09:43 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.93 on epoch=567
05/17/2022 12:09:44 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.01 on epoch=569
05/17/2022 12:09:46 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.95 on epoch=572
05/17/2022 12:09:47 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.91 on epoch=574
05/17/2022 12:09:48 - INFO - __main__ - Global step 2300 Train loss 0.95 Classification-F1 0.1 on epoch=574
05/17/2022 12:09:49 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.95 on epoch=577
05/17/2022 12:09:50 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.90 on epoch=579
05/17/2022 12:09:52 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.94 on epoch=582
05/17/2022 12:09:53 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.95 on epoch=584
05/17/2022 12:09:54 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.91 on epoch=587
05/17/2022 12:09:55 - INFO - __main__ - Global step 2350 Train loss 0.93 Classification-F1 0.2004079254079254 on epoch=587
05/17/2022 12:09:56 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.89 on epoch=589
05/17/2022 12:09:58 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.95 on epoch=592
05/17/2022 12:09:59 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.99 on epoch=594
05/17/2022 12:10:00 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.97 on epoch=597
05/17/2022 12:10:02 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.83 on epoch=599
05/17/2022 12:10:02 - INFO - __main__ - Global step 2400 Train loss 0.93 Classification-F1 0.13067758749069247 on epoch=599
05/17/2022 12:10:04 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.00 on epoch=602
05/17/2022 12:10:05 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.96 on epoch=604
05/17/2022 12:10:06 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.98 on epoch=607
05/17/2022 12:10:08 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.93 on epoch=609
05/17/2022 12:10:09 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.95 on epoch=612
05/17/2022 12:10:10 - INFO - __main__ - Global step 2450 Train loss 0.96 Classification-F1 0.1875 on epoch=612
05/17/2022 12:10:11 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.00 on epoch=614
05/17/2022 12:10:12 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.97 on epoch=617
05/17/2022 12:10:14 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.95 on epoch=619
05/17/2022 12:10:15 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.01 on epoch=622
05/17/2022 12:10:17 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.83 on epoch=624
05/17/2022 12:10:18 - INFO - __main__ - Global step 2500 Train loss 0.95 Classification-F1 0.14004914004914004 on epoch=624
05/17/2022 12:10:19 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.92 on epoch=627
05/17/2022 12:10:21 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.90 on epoch=629
05/17/2022 12:10:22 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.05 on epoch=632
05/17/2022 12:10:23 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.95 on epoch=634
05/17/2022 12:10:25 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.95 on epoch=637
05/17/2022 12:10:25 - INFO - __main__ - Global step 2550 Train loss 0.96 Classification-F1 0.1975609756097561 on epoch=637
05/17/2022 12:10:27 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.97 on epoch=639
05/17/2022 12:10:28 - INFO - __main__ - Step 2570 Global step 2570 Train loss 1.00 on epoch=642
05/17/2022 12:10:30 - INFO - __main__ - Step 2580 Global step 2580 Train loss 1.00 on epoch=644
05/17/2022 12:10:31 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.89 on epoch=647
05/17/2022 12:10:33 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.89 on epoch=649
05/17/2022 12:10:33 - INFO - __main__ - Global step 2600 Train loss 0.95 Classification-F1 0.10256410256410256 on epoch=649
05/17/2022 12:10:35 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.99 on epoch=652
05/17/2022 12:10:36 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.99 on epoch=654
05/17/2022 12:10:38 - INFO - __main__ - Step 2630 Global step 2630 Train loss 1.04 on epoch=657
05/17/2022 12:10:39 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.94 on epoch=659
05/17/2022 12:10:40 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.01 on epoch=662
05/17/2022 12:10:41 - INFO - __main__ - Global step 2650 Train loss 0.99 Classification-F1 0.16110780226325194 on epoch=662
05/17/2022 12:10:42 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.99 on epoch=664
05/17/2022 12:10:44 - INFO - __main__ - Step 2670 Global step 2670 Train loss 1.01 on epoch=667
05/17/2022 12:10:45 - INFO - __main__ - Step 2680 Global step 2680 Train loss 1.03 on epoch=669
05/17/2022 12:10:47 - INFO - __main__ - Step 2690 Global step 2690 Train loss 1.02 on epoch=672
05/17/2022 12:10:48 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.89 on epoch=674
05/17/2022 12:10:49 - INFO - __main__ - Global step 2700 Train loss 0.99 Classification-F1 0.18836850231600616 on epoch=674
05/17/2022 12:10:50 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.91 on epoch=677
05/17/2022 12:10:51 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.89 on epoch=679
05/17/2022 12:10:53 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.96 on epoch=682
05/17/2022 12:10:54 - INFO - __main__ - Step 2740 Global step 2740 Train loss 1.02 on epoch=684
05/17/2022 12:10:56 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.94 on epoch=687
05/17/2022 12:10:56 - INFO - __main__ - Global step 2750 Train loss 0.94 Classification-F1 0.15559772296015179 on epoch=687
05/17/2022 12:10:58 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.93 on epoch=689
05/17/2022 12:10:59 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.05 on epoch=692
05/17/2022 12:11:00 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.99 on epoch=694
05/17/2022 12:11:02 - INFO - __main__ - Step 2790 Global step 2790 Train loss 1.00 on epoch=697
05/17/2022 12:11:03 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.97 on epoch=699
05/17/2022 12:11:04 - INFO - __main__ - Global step 2800 Train loss 0.99 Classification-F1 0.16097560975609757 on epoch=699
05/17/2022 12:11:05 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.07 on epoch=702
05/17/2022 12:11:06 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.99 on epoch=704
05/17/2022 12:11:08 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.94 on epoch=707
05/17/2022 12:11:09 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.95 on epoch=709
05/17/2022 12:11:11 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.92 on epoch=712
05/17/2022 12:11:11 - INFO - __main__ - Global step 2850 Train loss 0.97 Classification-F1 0.14450704225352112 on epoch=712
05/17/2022 12:11:13 - INFO - __main__ - Step 2860 Global step 2860 Train loss 1.01 on epoch=714
05/17/2022 12:11:14 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.86 on epoch=717
05/17/2022 12:11:16 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.98 on epoch=719
05/17/2022 12:11:17 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.90 on epoch=722
05/17/2022 12:11:19 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.86 on epoch=724
05/17/2022 12:11:19 - INFO - __main__ - Global step 2900 Train loss 0.92 Classification-F1 0.10126582278481013 on epoch=724
05/17/2022 12:11:20 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.96 on epoch=727
05/17/2022 12:11:22 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.91 on epoch=729
05/17/2022 12:11:23 - INFO - __main__ - Step 2930 Global step 2930 Train loss 1.08 on epoch=732
05/17/2022 12:11:25 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.95 on epoch=734
05/17/2022 12:11:26 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.98 on epoch=737
05/17/2022 12:11:27 - INFO - __main__ - Global step 2950 Train loss 0.97 Classification-F1 0.1486842105263158 on epoch=737
05/17/2022 12:11:29 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.98 on epoch=739
05/17/2022 12:11:30 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.96 on epoch=742
05/17/2022 12:11:31 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.95 on epoch=744
05/17/2022 12:11:33 - INFO - __main__ - Step 2990 Global step 2990 Train loss 1.04 on epoch=747
05/17/2022 12:11:34 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.94 on epoch=749
05/17/2022 12:11:35 - INFO - __main__ - Global step 3000 Train loss 0.97 Classification-F1 0.1 on epoch=749
05/17/2022 12:11:35 - INFO - __main__ - save last model!
05/17/2022 12:11:35 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/17/2022 12:11:35 - INFO - __main__ - Start tokenizing ... 5509 instances
05/17/2022 12:11:35 - INFO - __main__ - Printing 3 examples
05/17/2022 12:11:35 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/17/2022 12:11:35 - INFO - __main__ - ['others']
05/17/2022 12:11:35 - INFO - __main__ -  [emo] what you like very little things ok
05/17/2022 12:11:35 - INFO - __main__ - ['others']
05/17/2022 12:11:35 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/17/2022 12:11:35 - INFO - __main__ - ['others']
05/17/2022 12:11:35 - INFO - __main__ - Tokenizing Input ...
05/17/2022 12:11:35 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 12:11:35 - INFO - __main__ - Printing 3 examples
05/17/2022 12:11:35 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
05/17/2022 12:11:35 - INFO - __main__ - ['others']
05/17/2022 12:11:35 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
05/17/2022 12:11:35 - INFO - __main__ - ['others']
05/17/2022 12:11:35 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
05/17/2022 12:11:35 - INFO - __main__ - ['others']
05/17/2022 12:11:35 - INFO - __main__ - Tokenizing Input ...
05/17/2022 12:11:35 - INFO - __main__ - Tokenizing Output ...
05/17/2022 12:11:36 - INFO - __main__ - Loaded 64 examples from train data
05/17/2022 12:11:36 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 12:11:36 - INFO - __main__ - Printing 3 examples
05/17/2022 12:11:36 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
05/17/2022 12:11:36 - INFO - __main__ - ['others']
05/17/2022 12:11:36 - INFO - __main__ -  [emo] i did ask now you did tell ms
05/17/2022 12:11:36 - INFO - __main__ - ['others']
05/17/2022 12:11:36 - INFO - __main__ -  [emo] buddy how you tell me your contact no
05/17/2022 12:11:36 - INFO - __main__ - ['others']
05/17/2022 12:11:36 - INFO - __main__ - Tokenizing Input ...
05/17/2022 12:11:36 - INFO - __main__ - Tokenizing Output ...
05/17/2022 12:11:36 - INFO - __main__ - Loaded 64 examples from dev data
05/17/2022 12:11:38 - INFO - __main__ - Tokenizing Output ...
05/17/2022 12:11:42 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 12:11:43 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 12:11:43 - INFO - __main__ - Starting training!
05/17/2022 12:11:44 - INFO - __main__ - Loaded 5509 examples from test data
05/17/2022 12:12:31 - INFO - __main__ - Saved prediction in models/T5-base-reptile-cls2cls-3e-5-2-5000-5e-1-10/singletask-emo/emo_16_13_0.5_8_predictions.txt
05/17/2022 12:12:31 - INFO - __main__ - Classification-F1 on test data: 0.0234
05/17/2022 12:12:32 - INFO - __main__ - prefix=emo_16_13, lr=0.5, bsz=8, dev_performance=0.24441687344913154, test_performance=0.023360614581241213
05/17/2022 12:12:32 - INFO - __main__ - Running ... prefix=emo_16_13, lr=0.4, bsz=8 ...
05/17/2022 12:12:32 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 12:12:32 - INFO - __main__ - Printing 3 examples
05/17/2022 12:12:32 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
05/17/2022 12:12:32 - INFO - __main__ - ['others']
05/17/2022 12:12:32 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
05/17/2022 12:12:32 - INFO - __main__ - ['others']
05/17/2022 12:12:32 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
05/17/2022 12:12:32 - INFO - __main__ - ['others']
05/17/2022 12:12:32 - INFO - __main__ - Tokenizing Input ...
05/17/2022 12:12:33 - INFO - __main__ - Tokenizing Output ...
05/17/2022 12:12:33 - INFO - __main__ - Loaded 64 examples from train data
05/17/2022 12:12:33 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 12:12:33 - INFO - __main__ - Printing 3 examples
05/17/2022 12:12:33 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
05/17/2022 12:12:33 - INFO - __main__ - ['others']
05/17/2022 12:12:33 - INFO - __main__ -  [emo] i did ask now you did tell ms
05/17/2022 12:12:33 - INFO - __main__ - ['others']
05/17/2022 12:12:33 - INFO - __main__ -  [emo] buddy how you tell me your contact no
05/17/2022 12:12:33 - INFO - __main__ - ['others']
05/17/2022 12:12:33 - INFO - __main__ - Tokenizing Input ...
05/17/2022 12:12:33 - INFO - __main__ - Tokenizing Output ...
05/17/2022 12:12:33 - INFO - __main__ - Loaded 64 examples from dev data
05/17/2022 12:12:40 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 12:12:40 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 12:12:40 - INFO - __main__ - Starting training!
05/17/2022 12:12:41 - INFO - __main__ - Step 10 Global step 10 Train loss 8.93 on epoch=2
05/17/2022 12:12:43 - INFO - __main__ - Step 20 Global step 20 Train loss 8.98 on epoch=4
05/17/2022 12:12:44 - INFO - __main__ - Step 30 Global step 30 Train loss 8.92 on epoch=7
05/17/2022 12:12:46 - INFO - __main__ - Step 40 Global step 40 Train loss 8.76 on epoch=9
05/17/2022 12:12:47 - INFO - __main__ - Step 50 Global step 50 Train loss 8.71 on epoch=12
05/17/2022 12:12:54 - INFO - __main__ - Global step 50 Train loss 8.86 Classification-F1 0.0 on epoch=12
05/17/2022 12:12:54 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/17/2022 12:12:56 - INFO - __main__ - Step 60 Global step 60 Train loss 8.67 on epoch=14
05/17/2022 12:12:57 - INFO - __main__ - Step 70 Global step 70 Train loss 8.64 on epoch=17
05/17/2022 12:12:58 - INFO - __main__ - Step 80 Global step 80 Train loss 8.55 on epoch=19
05/17/2022 12:13:00 - INFO - __main__ - Step 90 Global step 90 Train loss 8.25 on epoch=22
05/17/2022 12:13:01 - INFO - __main__ - Step 100 Global step 100 Train loss 8.34 on epoch=24
05/17/2022 12:13:13 - INFO - __main__ - Global step 100 Train loss 8.49 Classification-F1 0.0 on epoch=24
05/17/2022 12:13:15 - INFO - __main__ - Step 110 Global step 110 Train loss 8.02 on epoch=27
05/17/2022 12:13:16 - INFO - __main__ - Step 120 Global step 120 Train loss 7.84 on epoch=29
05/17/2022 12:13:17 - INFO - __main__ - Step 130 Global step 130 Train loss 7.60 on epoch=32
05/17/2022 12:13:19 - INFO - __main__ - Step 140 Global step 140 Train loss 7.31 on epoch=34
05/17/2022 12:13:20 - INFO - __main__ - Step 150 Global step 150 Train loss 7.18 on epoch=37
05/17/2022 12:13:25 - INFO - __main__ - Global step 150 Train loss 7.59 Classification-F1 0.0 on epoch=37
05/17/2022 12:13:26 - INFO - __main__ - Step 160 Global step 160 Train loss 7.07 on epoch=39
05/17/2022 12:13:28 - INFO - __main__ - Step 170 Global step 170 Train loss 6.83 on epoch=42
05/17/2022 12:13:29 - INFO - __main__ - Step 180 Global step 180 Train loss 6.75 on epoch=44
05/17/2022 12:13:31 - INFO - __main__ - Step 190 Global step 190 Train loss 6.53 on epoch=47
05/17/2022 12:13:32 - INFO - __main__ - Step 200 Global step 200 Train loss 6.19 on epoch=49
05/17/2022 12:13:36 - INFO - __main__ - Global step 200 Train loss 6.67 Classification-F1 0.0 on epoch=49
05/17/2022 12:13:37 - INFO - __main__ - Step 210 Global step 210 Train loss 6.08 on epoch=52
05/17/2022 12:13:39 - INFO - __main__ - Step 220 Global step 220 Train loss 5.82 on epoch=54
05/17/2022 12:13:40 - INFO - __main__ - Step 230 Global step 230 Train loss 5.69 on epoch=57
05/17/2022 12:13:41 - INFO - __main__ - Step 240 Global step 240 Train loss 5.41 on epoch=59
05/17/2022 12:13:43 - INFO - __main__ - Step 250 Global step 250 Train loss 5.44 on epoch=62
05/17/2022 12:13:47 - INFO - __main__ - Global step 250 Train loss 5.69 Classification-F1 0.0 on epoch=62
05/17/2022 12:13:48 - INFO - __main__ - Step 260 Global step 260 Train loss 4.91 on epoch=64
05/17/2022 12:13:50 - INFO - __main__ - Step 270 Global step 270 Train loss 4.92 on epoch=67
05/17/2022 12:13:51 - INFO - __main__ - Step 280 Global step 280 Train loss 4.83 on epoch=69
05/17/2022 12:13:53 - INFO - __main__ - Step 290 Global step 290 Train loss 4.92 on epoch=72
05/17/2022 12:13:54 - INFO - __main__ - Step 300 Global step 300 Train loss 4.76 on epoch=74
05/17/2022 12:14:03 - INFO - __main__ - Global step 300 Train loss 4.87 Classification-F1 0.0 on epoch=74
05/17/2022 12:14:04 - INFO - __main__ - Step 310 Global step 310 Train loss 4.86 on epoch=77
05/17/2022 12:14:06 - INFO - __main__ - Step 320 Global step 320 Train loss 4.65 on epoch=79
05/17/2022 12:14:07 - INFO - __main__ - Step 330 Global step 330 Train loss 4.50 on epoch=82
05/17/2022 12:14:08 - INFO - __main__ - Step 340 Global step 340 Train loss 4.37 on epoch=84
05/17/2022 12:14:10 - INFO - __main__ - Step 350 Global step 350 Train loss 4.41 on epoch=87
05/17/2022 12:14:14 - INFO - __main__ - Global step 350 Train loss 4.56 Classification-F1 0.022624434389140274 on epoch=87
05/17/2022 12:14:14 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.022624434389140274 on epoch=87, global_step=350
05/17/2022 12:14:15 - INFO - __main__ - Step 360 Global step 360 Train loss 4.10 on epoch=89
05/17/2022 12:14:16 - INFO - __main__ - Step 370 Global step 370 Train loss 4.38 on epoch=92
05/17/2022 12:14:18 - INFO - __main__ - Step 380 Global step 380 Train loss 4.03 on epoch=94
05/17/2022 12:14:19 - INFO - __main__ - Step 390 Global step 390 Train loss 4.08 on epoch=97
05/17/2022 12:14:21 - INFO - __main__ - Step 400 Global step 400 Train loss 3.78 on epoch=99
05/17/2022 12:14:30 - INFO - __main__ - Global step 400 Train loss 4.07 Classification-F1 0.02934851359898798 on epoch=99
05/17/2022 12:14:30 - INFO - __main__ - Saving model with best Classification-F1: 0.022624434389140274 -> 0.02934851359898798 on epoch=99, global_step=400
05/17/2022 12:14:31 - INFO - __main__ - Step 410 Global step 410 Train loss 4.04 on epoch=102
05/17/2022 12:14:33 - INFO - __main__ - Step 420 Global step 420 Train loss 3.75 on epoch=104
05/17/2022 12:14:34 - INFO - __main__ - Step 430 Global step 430 Train loss 3.93 on epoch=107
05/17/2022 12:14:35 - INFO - __main__ - Step 440 Global step 440 Train loss 3.74 on epoch=109
05/17/2022 12:14:37 - INFO - __main__ - Step 450 Global step 450 Train loss 3.69 on epoch=112
05/17/2022 12:14:43 - INFO - __main__ - Global step 450 Train loss 3.83 Classification-F1 0.0693407960199005 on epoch=112
05/17/2022 12:14:43 - INFO - __main__ - Saving model with best Classification-F1: 0.02934851359898798 -> 0.0693407960199005 on epoch=112, global_step=450
05/17/2022 12:14:44 - INFO - __main__ - Step 460 Global step 460 Train loss 3.52 on epoch=114
05/17/2022 12:14:45 - INFO - __main__ - Step 470 Global step 470 Train loss 3.77 on epoch=117
05/17/2022 12:14:47 - INFO - __main__ - Step 480 Global step 480 Train loss 3.30 on epoch=119
05/17/2022 12:14:48 - INFO - __main__ - Step 490 Global step 490 Train loss 3.50 on epoch=122
05/17/2022 12:14:50 - INFO - __main__ - Step 500 Global step 500 Train loss 3.27 on epoch=124
05/17/2022 12:14:53 - INFO - __main__ - Global step 500 Train loss 3.47 Classification-F1 0.14044687642498857 on epoch=124
05/17/2022 12:14:53 - INFO - __main__ - Saving model with best Classification-F1: 0.0693407960199005 -> 0.14044687642498857 on epoch=124, global_step=500
05/17/2022 12:14:55 - INFO - __main__ - Step 510 Global step 510 Train loss 3.30 on epoch=127
05/17/2022 12:14:56 - INFO - __main__ - Step 520 Global step 520 Train loss 3.22 on epoch=129
05/17/2022 12:14:58 - INFO - __main__ - Step 530 Global step 530 Train loss 3.15 on epoch=132
05/17/2022 12:14:59 - INFO - __main__ - Step 540 Global step 540 Train loss 3.07 on epoch=134
05/17/2022 12:15:00 - INFO - __main__ - Step 550 Global step 550 Train loss 3.01 on epoch=137
05/17/2022 12:15:04 - INFO - __main__ - Global step 550 Train loss 3.15 Classification-F1 0.19973544973544974 on epoch=137
05/17/2022 12:15:04 - INFO - __main__ - Saving model with best Classification-F1: 0.14044687642498857 -> 0.19973544973544974 on epoch=137, global_step=550
05/17/2022 12:15:05 - INFO - __main__ - Step 560 Global step 560 Train loss 2.91 on epoch=139
05/17/2022 12:15:07 - INFO - __main__ - Step 570 Global step 570 Train loss 2.92 on epoch=142
05/17/2022 12:15:08 - INFO - __main__ - Step 580 Global step 580 Train loss 2.78 on epoch=144
05/17/2022 12:15:09 - INFO - __main__ - Step 590 Global step 590 Train loss 2.77 on epoch=147
05/17/2022 12:15:11 - INFO - __main__ - Step 600 Global step 600 Train loss 2.65 on epoch=149
05/17/2022 12:15:16 - INFO - __main__ - Global step 600 Train loss 2.80 Classification-F1 0.10389610389610389 on epoch=149
05/17/2022 12:15:17 - INFO - __main__ - Step 610 Global step 610 Train loss 2.75 on epoch=152
05/17/2022 12:15:19 - INFO - __main__ - Step 620 Global step 620 Train loss 2.58 on epoch=154
05/17/2022 12:15:20 - INFO - __main__ - Step 630 Global step 630 Train loss 2.47 on epoch=157
05/17/2022 12:15:21 - INFO - __main__ - Step 640 Global step 640 Train loss 2.45 on epoch=159
05/17/2022 12:15:23 - INFO - __main__ - Step 650 Global step 650 Train loss 2.61 on epoch=162
05/17/2022 12:15:24 - INFO - __main__ - Global step 650 Train loss 2.57 Classification-F1 0.13067758749069247 on epoch=162
05/17/2022 12:15:25 - INFO - __main__ - Step 660 Global step 660 Train loss 2.27 on epoch=164
05/17/2022 12:15:27 - INFO - __main__ - Step 670 Global step 670 Train loss 2.38 on epoch=167
05/17/2022 12:15:28 - INFO - __main__ - Step 680 Global step 680 Train loss 2.11 on epoch=169
05/17/2022 12:15:29 - INFO - __main__ - Step 690 Global step 690 Train loss 2.19 on epoch=172
05/17/2022 12:15:31 - INFO - __main__ - Step 700 Global step 700 Train loss 1.96 on epoch=174
05/17/2022 12:15:32 - INFO - __main__ - Global step 700 Train loss 2.18 Classification-F1 0.1 on epoch=174
05/17/2022 12:15:33 - INFO - __main__ - Step 710 Global step 710 Train loss 2.06 on epoch=177
05/17/2022 12:15:35 - INFO - __main__ - Step 720 Global step 720 Train loss 2.01 on epoch=179
05/17/2022 12:15:36 - INFO - __main__ - Step 730 Global step 730 Train loss 2.10 on epoch=182
05/17/2022 12:15:37 - INFO - __main__ - Step 740 Global step 740 Train loss 1.82 on epoch=184
05/17/2022 12:15:39 - INFO - __main__ - Step 750 Global step 750 Train loss 1.87 on epoch=187
05/17/2022 12:15:39 - INFO - __main__ - Global step 750 Train loss 1.97 Classification-F1 0.13218954248366013 on epoch=187
05/17/2022 12:15:41 - INFO - __main__ - Step 760 Global step 760 Train loss 1.77 on epoch=189
05/17/2022 12:15:42 - INFO - __main__ - Step 770 Global step 770 Train loss 1.95 on epoch=192
05/17/2022 12:15:43 - INFO - __main__ - Step 780 Global step 780 Train loss 1.76 on epoch=194
05/17/2022 12:15:45 - INFO - __main__ - Step 790 Global step 790 Train loss 1.82 on epoch=197
05/17/2022 12:15:46 - INFO - __main__ - Step 800 Global step 800 Train loss 1.79 on epoch=199
05/17/2022 12:15:47 - INFO - __main__ - Global step 800 Train loss 1.82 Classification-F1 0.11552106430155212 on epoch=199
05/17/2022 12:15:48 - INFO - __main__ - Step 810 Global step 810 Train loss 1.75 on epoch=202
05/17/2022 12:15:50 - INFO - __main__ - Step 820 Global step 820 Train loss 1.58 on epoch=204
05/17/2022 12:15:51 - INFO - __main__ - Step 830 Global step 830 Train loss 1.49 on epoch=207
05/17/2022 12:15:52 - INFO - __main__ - Step 840 Global step 840 Train loss 1.68 on epoch=209
05/17/2022 12:15:54 - INFO - __main__ - Step 850 Global step 850 Train loss 1.44 on epoch=212
05/17/2022 12:15:54 - INFO - __main__ - Global step 850 Train loss 1.59 Classification-F1 0.1 on epoch=212
05/17/2022 12:15:56 - INFO - __main__ - Step 860 Global step 860 Train loss 1.44 on epoch=214
05/17/2022 12:15:57 - INFO - __main__ - Step 870 Global step 870 Train loss 1.50 on epoch=217
05/17/2022 12:15:59 - INFO - __main__ - Step 880 Global step 880 Train loss 1.53 on epoch=219
05/17/2022 12:16:00 - INFO - __main__ - Step 890 Global step 890 Train loss 1.51 on epoch=222
05/17/2022 12:16:01 - INFO - __main__ - Step 900 Global step 900 Train loss 1.42 on epoch=224
05/17/2022 12:16:02 - INFO - __main__ - Global step 900 Train loss 1.48 Classification-F1 0.13123993558776167 on epoch=224
05/17/2022 12:16:03 - INFO - __main__ - Step 910 Global step 910 Train loss 1.29 on epoch=227
05/17/2022 12:16:05 - INFO - __main__ - Step 920 Global step 920 Train loss 1.33 on epoch=229
05/17/2022 12:16:06 - INFO - __main__ - Step 930 Global step 930 Train loss 1.50 on epoch=232
05/17/2022 12:16:07 - INFO - __main__ - Step 940 Global step 940 Train loss 1.47 on epoch=234
05/17/2022 12:16:09 - INFO - __main__ - Step 950 Global step 950 Train loss 1.28 on epoch=237
05/17/2022 12:16:10 - INFO - __main__ - Global step 950 Train loss 1.38 Classification-F1 0.20718262398359094 on epoch=237
05/17/2022 12:16:10 - INFO - __main__ - Saving model with best Classification-F1: 0.19973544973544974 -> 0.20718262398359094 on epoch=237, global_step=950
05/17/2022 12:16:11 - INFO - __main__ - Step 960 Global step 960 Train loss 1.35 on epoch=239
05/17/2022 12:16:12 - INFO - __main__ - Step 970 Global step 970 Train loss 1.46 on epoch=242
05/17/2022 12:16:14 - INFO - __main__ - Step 980 Global step 980 Train loss 1.31 on epoch=244
05/17/2022 12:16:15 - INFO - __main__ - Step 990 Global step 990 Train loss 1.35 on epoch=247
05/17/2022 12:16:17 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.35 on epoch=249
05/17/2022 12:16:17 - INFO - __main__ - Global step 1000 Train loss 1.36 Classification-F1 0.15274725274725276 on epoch=249
05/17/2022 12:16:19 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.23 on epoch=252
05/17/2022 12:16:20 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.28 on epoch=254
05/17/2022 12:16:21 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.30 on epoch=257
05/17/2022 12:16:23 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.33 on epoch=259
05/17/2022 12:16:24 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.25 on epoch=262
05/17/2022 12:16:25 - INFO - __main__ - Global step 1050 Train loss 1.28 Classification-F1 0.13067758749069247 on epoch=262
05/17/2022 12:16:26 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.26 on epoch=264
05/17/2022 12:16:27 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.16 on epoch=267
05/17/2022 12:16:29 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.39 on epoch=269
05/17/2022 12:16:31 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.17 on epoch=272
05/17/2022 12:16:32 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.21 on epoch=274
05/17/2022 12:16:33 - INFO - __main__ - Global step 1100 Train loss 1.24 Classification-F1 0.1581196581196581 on epoch=274
05/17/2022 12:16:34 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.17 on epoch=277
05/17/2022 12:16:35 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.38 on epoch=279
05/17/2022 12:16:37 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.18 on epoch=282
05/17/2022 12:16:38 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.04 on epoch=284
05/17/2022 12:16:39 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.26 on epoch=287
05/17/2022 12:16:40 - INFO - __main__ - Global step 1150 Train loss 1.21 Classification-F1 0.16123642439431912 on epoch=287
05/17/2022 12:16:41 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.15 on epoch=289
05/17/2022 12:16:43 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.15 on epoch=292
05/17/2022 12:16:44 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.22 on epoch=294
05/17/2022 12:16:45 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.32 on epoch=297
05/17/2022 12:16:47 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.21 on epoch=299
05/17/2022 12:16:47 - INFO - __main__ - Global step 1200 Train loss 1.21 Classification-F1 0.1 on epoch=299
05/17/2022 12:16:49 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.13 on epoch=302
05/17/2022 12:16:50 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.17 on epoch=304
05/17/2022 12:16:52 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.22 on epoch=307
05/17/2022 12:16:53 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.05 on epoch=309
05/17/2022 12:16:55 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.20 on epoch=312
05/17/2022 12:16:55 - INFO - __main__ - Global step 1250 Train loss 1.15 Classification-F1 0.13067758749069247 on epoch=312
05/17/2022 12:16:57 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.37 on epoch=314
05/17/2022 12:16:58 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.22 on epoch=317
05/17/2022 12:17:00 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.24 on epoch=319
05/17/2022 12:17:02 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.16 on epoch=322
05/17/2022 12:17:03 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.06 on epoch=324
05/17/2022 12:17:04 - INFO - __main__ - Global step 1300 Train loss 1.21 Classification-F1 0.1 on epoch=324
05/17/2022 12:17:05 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.09 on epoch=327
05/17/2022 12:17:07 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.21 on epoch=329
05/17/2022 12:17:08 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.14 on epoch=332
05/17/2022 12:17:09 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.17 on epoch=334
05/17/2022 12:17:11 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.14 on epoch=337
05/17/2022 12:17:11 - INFO - __main__ - Global step 1350 Train loss 1.15 Classification-F1 0.1 on epoch=337
05/17/2022 12:17:13 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.15 on epoch=339
05/17/2022 12:17:14 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.10 on epoch=342
05/17/2022 12:17:16 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.09 on epoch=344
05/17/2022 12:17:17 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.20 on epoch=347
05/17/2022 12:17:18 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.06 on epoch=349
05/17/2022 12:17:19 - INFO - __main__ - Global step 1400 Train loss 1.12 Classification-F1 0.1 on epoch=349
05/17/2022 12:17:21 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.13 on epoch=352
05/17/2022 12:17:22 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.05 on epoch=354
05/17/2022 12:17:23 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.12 on epoch=357
05/17/2022 12:17:25 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.15 on epoch=359
05/17/2022 12:17:26 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.12 on epoch=362
05/17/2022 12:17:27 - INFO - __main__ - Global step 1450 Train loss 1.11 Classification-F1 0.1 on epoch=362
05/17/2022 12:17:28 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.12 on epoch=364
05/17/2022 12:17:30 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.17 on epoch=367
05/17/2022 12:17:31 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.09 on epoch=369
05/17/2022 12:17:32 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.06 on epoch=372
05/17/2022 12:17:34 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.09 on epoch=374
05/17/2022 12:17:34 - INFO - __main__ - Global step 1500 Train loss 1.10 Classification-F1 0.1 on epoch=374
05/17/2022 12:17:36 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.22 on epoch=377
05/17/2022 12:17:37 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.06 on epoch=379
05/17/2022 12:17:39 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.17 on epoch=382
05/17/2022 12:17:40 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.07 on epoch=384
05/17/2022 12:17:42 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.06 on epoch=387
05/17/2022 12:17:42 - INFO - __main__ - Global step 1550 Train loss 1.12 Classification-F1 0.10126582278481013 on epoch=387
05/17/2022 12:17:44 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.07 on epoch=389
05/17/2022 12:17:45 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.03 on epoch=392
05/17/2022 12:17:46 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.24 on epoch=394
05/17/2022 12:17:48 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.23 on epoch=397
05/17/2022 12:17:49 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.16 on epoch=399
05/17/2022 12:17:50 - INFO - __main__ - Global step 1600 Train loss 1.15 Classification-F1 0.1 on epoch=399
05/17/2022 12:17:51 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.14 on epoch=402
05/17/2022 12:17:52 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.06 on epoch=404
05/17/2022 12:17:54 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.11 on epoch=407
05/17/2022 12:17:55 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.92 on epoch=409
05/17/2022 12:17:57 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.01 on epoch=412
05/17/2022 12:17:57 - INFO - __main__ - Global step 1650 Train loss 1.05 Classification-F1 0.10526315789473685 on epoch=412
05/17/2022 12:17:59 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.07 on epoch=414
05/17/2022 12:18:00 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.97 on epoch=417
05/17/2022 12:18:01 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.14 on epoch=419
05/17/2022 12:18:03 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.00 on epoch=422
05/17/2022 12:18:04 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.12 on epoch=424
05/17/2022 12:18:05 - INFO - __main__ - Global step 1700 Train loss 1.06 Classification-F1 0.1 on epoch=424
05/17/2022 12:18:06 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.05 on epoch=427
05/17/2022 12:18:08 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.09 on epoch=429
05/17/2022 12:18:09 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.07 on epoch=432
05/17/2022 12:18:10 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.14 on epoch=434
05/17/2022 12:18:12 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.13 on epoch=437
05/17/2022 12:18:12 - INFO - __main__ - Global step 1750 Train loss 1.09 Classification-F1 0.13067758749069247 on epoch=437
05/17/2022 12:18:14 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.89 on epoch=439
05/17/2022 12:18:15 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.13 on epoch=442
05/17/2022 12:18:17 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.11 on epoch=444
05/17/2022 12:18:18 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.14 on epoch=447
05/17/2022 12:18:19 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.11 on epoch=449
05/17/2022 12:18:20 - INFO - __main__ - Global step 1800 Train loss 1.07 Classification-F1 0.1 on epoch=449
05/17/2022 12:18:21 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.16 on epoch=452
05/17/2022 12:18:23 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.98 on epoch=454
05/17/2022 12:18:24 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.03 on epoch=457
05/17/2022 12:18:26 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.00 on epoch=459
05/17/2022 12:18:27 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.04 on epoch=462
05/17/2022 12:18:28 - INFO - __main__ - Global step 1850 Train loss 1.04 Classification-F1 0.1 on epoch=462
05/17/2022 12:18:29 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.08 on epoch=464
05/17/2022 12:18:30 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.03 on epoch=467
05/17/2022 12:18:32 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.94 on epoch=469
05/17/2022 12:18:33 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.96 on epoch=472
05/17/2022 12:18:34 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.07 on epoch=474
05/17/2022 12:18:35 - INFO - __main__ - Global step 1900 Train loss 1.01 Classification-F1 0.1 on epoch=474
05/17/2022 12:18:36 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.08 on epoch=477
05/17/2022 12:18:38 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.02 on epoch=479
05/17/2022 12:18:39 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.96 on epoch=482
05/17/2022 12:18:41 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.02 on epoch=484
05/17/2022 12:18:42 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.02 on epoch=487
05/17/2022 12:18:42 - INFO - __main__ - Global step 1950 Train loss 1.02 Classification-F1 0.1 on epoch=487
05/17/2022 12:18:44 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.96 on epoch=489
05/17/2022 12:18:45 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.97 on epoch=492
05/17/2022 12:18:46 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.01 on epoch=494
05/17/2022 12:18:48 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.07 on epoch=497
05/17/2022 12:18:49 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.14 on epoch=499
05/17/2022 12:18:50 - INFO - __main__ - Global step 2000 Train loss 1.03 Classification-F1 0.1 on epoch=499
05/17/2022 12:18:51 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.96 on epoch=502
05/17/2022 12:18:53 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.99 on epoch=504
05/17/2022 12:18:54 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.04 on epoch=507
05/17/2022 12:18:55 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.07 on epoch=509
05/17/2022 12:18:57 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.00 on epoch=512
05/17/2022 12:18:57 - INFO - __main__ - Global step 2050 Train loss 1.01 Classification-F1 0.10256410256410256 on epoch=512
05/17/2022 12:18:59 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.03 on epoch=514
05/17/2022 12:19:00 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.98 on epoch=517
05/17/2022 12:19:02 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.90 on epoch=519
05/17/2022 12:19:03 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.02 on epoch=522
05/17/2022 12:19:04 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.11 on epoch=524
05/17/2022 12:19:05 - INFO - __main__ - Global step 2100 Train loss 1.01 Classification-F1 0.1 on epoch=524
05/17/2022 12:19:06 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.14 on epoch=527
05/17/2022 12:19:08 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.07 on epoch=529
05/17/2022 12:19:09 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.97 on epoch=532
05/17/2022 12:19:10 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.98 on epoch=534
05/17/2022 12:19:12 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.04 on epoch=537
05/17/2022 12:19:12 - INFO - __main__ - Global step 2150 Train loss 1.04 Classification-F1 0.1337028824833703 on epoch=537
05/17/2022 12:19:14 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.99 on epoch=539
05/17/2022 12:19:15 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.99 on epoch=542
05/17/2022 12:19:16 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.05 on epoch=544
05/17/2022 12:19:18 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.13 on epoch=547
05/17/2022 12:19:19 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.98 on epoch=549
05/17/2022 12:19:20 - INFO - __main__ - Global step 2200 Train loss 1.03 Classification-F1 0.10126582278481013 on epoch=549
05/17/2022 12:19:21 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.99 on epoch=552
05/17/2022 12:19:23 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.09 on epoch=554
05/17/2022 12:19:24 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.98 on epoch=557
05/17/2022 12:19:26 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.94 on epoch=559
05/17/2022 12:19:27 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.08 on epoch=562
05/17/2022 12:19:28 - INFO - __main__ - Global step 2250 Train loss 1.02 Classification-F1 0.19740740740740742 on epoch=562
05/17/2022 12:19:29 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.02 on epoch=564
05/17/2022 12:19:31 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.00 on epoch=567
05/17/2022 12:19:32 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.01 on epoch=569
05/17/2022 12:19:33 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.96 on epoch=572
05/17/2022 12:19:35 - INFO - __main__ - Step 2300 Global step 2300 Train loss 1.01 on epoch=574
05/17/2022 12:19:35 - INFO - __main__ - Global step 2300 Train loss 1.00 Classification-F1 0.09493670886075949 on epoch=574
05/17/2022 12:19:37 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.09 on epoch=577
05/17/2022 12:19:38 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.06 on epoch=579
05/17/2022 12:19:39 - INFO - __main__ - Step 2330 Global step 2330 Train loss 1.02 on epoch=582
05/17/2022 12:19:41 - INFO - __main__ - Step 2340 Global step 2340 Train loss 1.00 on epoch=584
05/17/2022 12:19:42 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.96 on epoch=587
05/17/2022 12:19:43 - INFO - __main__ - Global step 2350 Train loss 1.03 Classification-F1 0.1527777777777778 on epoch=587
05/17/2022 12:19:44 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.86 on epoch=589
05/17/2022 12:19:46 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.99 on epoch=592
05/17/2022 12:19:47 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.00 on epoch=594
05/17/2022 12:19:49 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.97 on epoch=597
05/17/2022 12:19:50 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.12 on epoch=599
05/17/2022 12:19:50 - INFO - __main__ - Global step 2400 Train loss 0.99 Classification-F1 0.1426456882846335 on epoch=599
05/17/2022 12:19:52 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.95 on epoch=602
05/17/2022 12:19:53 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.96 on epoch=604
05/17/2022 12:19:55 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.97 on epoch=607
05/17/2022 12:19:56 - INFO - __main__ - Step 2440 Global step 2440 Train loss 1.00 on epoch=609
05/17/2022 12:19:58 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.96 on epoch=612
05/17/2022 12:19:58 - INFO - __main__ - Global step 2450 Train loss 0.97 Classification-F1 0.1 on epoch=612
05/17/2022 12:20:00 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.96 on epoch=614
05/17/2022 12:20:01 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.99 on epoch=617
05/17/2022 12:20:02 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.98 on epoch=619
05/17/2022 12:20:04 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.98 on epoch=622
05/17/2022 12:20:05 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.98 on epoch=624
05/17/2022 12:20:06 - INFO - __main__ - Global step 2500 Train loss 0.97 Classification-F1 0.13034188034188032 on epoch=624
05/17/2022 12:20:07 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.99 on epoch=627
05/17/2022 12:20:09 - INFO - __main__ - Step 2520 Global step 2520 Train loss 1.10 on epoch=629
05/17/2022 12:20:10 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.98 on epoch=632
05/17/2022 12:20:11 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.87 on epoch=634
05/17/2022 12:20:13 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.95 on epoch=637
05/17/2022 12:20:13 - INFO - __main__ - Global step 2550 Train loss 0.98 Classification-F1 0.10416666666666666 on epoch=637
05/17/2022 12:20:15 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.97 on epoch=639
05/17/2022 12:20:16 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.92 on epoch=642
05/17/2022 12:20:17 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.92 on epoch=644
05/17/2022 12:20:19 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.99 on epoch=647
05/17/2022 12:20:20 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.92 on epoch=649
05/17/2022 12:20:21 - INFO - __main__ - Global step 2600 Train loss 0.94 Classification-F1 0.1 on epoch=649
05/17/2022 12:20:22 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.95 on epoch=652
05/17/2022 12:20:24 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.86 on epoch=654
05/17/2022 12:20:25 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.99 on epoch=657
05/17/2022 12:20:26 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.93 on epoch=659
05/17/2022 12:20:28 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.99 on epoch=662
05/17/2022 12:20:28 - INFO - __main__ - Global step 2650 Train loss 0.95 Classification-F1 0.1 on epoch=662
05/17/2022 12:20:30 - INFO - __main__ - Step 2660 Global step 2660 Train loss 1.02 on epoch=664
05/17/2022 12:20:31 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.92 on epoch=667
05/17/2022 12:20:32 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.89 on epoch=669
05/17/2022 12:20:34 - INFO - __main__ - Step 2690 Global step 2690 Train loss 1.07 on epoch=672
05/17/2022 12:20:35 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.94 on epoch=674
05/17/2022 12:20:36 - INFO - __main__ - Global step 2700 Train loss 0.97 Classification-F1 0.1 on epoch=674
05/17/2022 12:20:37 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.93 on epoch=677
05/17/2022 12:20:38 - INFO - __main__ - Step 2720 Global step 2720 Train loss 1.03 on epoch=679
05/17/2022 12:20:40 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.88 on epoch=682
05/17/2022 12:20:41 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.91 on epoch=684
05/17/2022 12:20:42 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.85 on epoch=687
05/17/2022 12:20:43 - INFO - __main__ - Global step 2750 Train loss 0.92 Classification-F1 0.1 on epoch=687
05/17/2022 12:20:44 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.02 on epoch=689
05/17/2022 12:20:46 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.99 on epoch=692
05/17/2022 12:20:47 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.96 on epoch=694
05/17/2022 12:20:49 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.84 on epoch=697
05/17/2022 12:20:50 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.94 on epoch=699
05/17/2022 12:20:51 - INFO - __main__ - Global step 2800 Train loss 0.95 Classification-F1 0.1 on epoch=699
05/17/2022 12:20:52 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.04 on epoch=702
05/17/2022 12:20:53 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.95 on epoch=704
05/17/2022 12:20:55 - INFO - __main__ - Step 2830 Global step 2830 Train loss 1.01 on epoch=707
05/17/2022 12:20:56 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.94 on epoch=709
05/17/2022 12:20:58 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.96 on epoch=712
05/17/2022 12:20:58 - INFO - __main__ - Global step 2850 Train loss 0.98 Classification-F1 0.1 on epoch=712
05/17/2022 12:21:00 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.97 on epoch=714
05/17/2022 12:21:01 - INFO - __main__ - Step 2870 Global step 2870 Train loss 1.01 on epoch=717
05/17/2022 12:21:02 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.95 on epoch=719
05/17/2022 12:21:04 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.05 on epoch=722
05/17/2022 12:21:05 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.96 on epoch=724
05/17/2022 12:21:06 - INFO - __main__ - Global step 2900 Train loss 0.99 Classification-F1 0.1 on epoch=724
05/17/2022 12:21:07 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.05 on epoch=727
05/17/2022 12:21:09 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.98 on epoch=729
05/17/2022 12:21:10 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.91 on epoch=732
05/17/2022 12:21:11 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.97 on epoch=734
05/17/2022 12:21:13 - INFO - __main__ - Step 2950 Global step 2950 Train loss 1.00 on epoch=737
05/17/2022 12:21:13 - INFO - __main__ - Global step 2950 Train loss 0.98 Classification-F1 0.1 on epoch=737
05/17/2022 12:21:15 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.95 on epoch=739
05/17/2022 12:21:16 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.98 on epoch=742
05/17/2022 12:21:17 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.99 on epoch=744
05/17/2022 12:21:19 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.98 on epoch=747
05/17/2022 12:21:20 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.97 on epoch=749
05/17/2022 12:21:21 - INFO - __main__ - Global step 3000 Train loss 0.97 Classification-F1 0.1 on epoch=749
05/17/2022 12:21:21 - INFO - __main__ - save last model!
05/17/2022 12:21:21 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/17/2022 12:21:21 - INFO - __main__ - Start tokenizing ... 5509 instances
05/17/2022 12:21:21 - INFO - __main__ - Printing 3 examples
05/17/2022 12:21:21 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/17/2022 12:21:21 - INFO - __main__ - ['others']
05/17/2022 12:21:21 - INFO - __main__ -  [emo] what you like very little things ok
05/17/2022 12:21:21 - INFO - __main__ - ['others']
05/17/2022 12:21:21 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/17/2022 12:21:21 - INFO - __main__ - ['others']
05/17/2022 12:21:21 - INFO - __main__ - Tokenizing Input ...
05/17/2022 12:21:22 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 12:21:22 - INFO - __main__ - Printing 3 examples
05/17/2022 12:21:22 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
05/17/2022 12:21:22 - INFO - __main__ - ['others']
05/17/2022 12:21:22 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
05/17/2022 12:21:22 - INFO - __main__ - ['others']
05/17/2022 12:21:22 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
05/17/2022 12:21:22 - INFO - __main__ - ['others']
05/17/2022 12:21:22 - INFO - __main__ - Tokenizing Input ...
05/17/2022 12:21:22 - INFO - __main__ - Tokenizing Output ...
05/17/2022 12:21:22 - INFO - __main__ - Loaded 64 examples from train data
05/17/2022 12:21:22 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 12:21:22 - INFO - __main__ - Printing 3 examples
05/17/2022 12:21:22 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
05/17/2022 12:21:22 - INFO - __main__ - ['others']
05/17/2022 12:21:22 - INFO - __main__ -  [emo] i did ask now you did tell ms
05/17/2022 12:21:22 - INFO - __main__ - ['others']
05/17/2022 12:21:22 - INFO - __main__ -  [emo] buddy how you tell me your contact no
05/17/2022 12:21:22 - INFO - __main__ - ['others']
05/17/2022 12:21:22 - INFO - __main__ - Tokenizing Input ...
05/17/2022 12:21:22 - INFO - __main__ - Tokenizing Output ...
05/17/2022 12:21:22 - INFO - __main__ - Loaded 64 examples from dev data
05/17/2022 12:21:23 - INFO - __main__ - Tokenizing Output ...
05/17/2022 12:21:28 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 12:21:28 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 12:21:28 - INFO - __main__ - Starting training!
05/17/2022 12:21:30 - INFO - __main__ - Loaded 5509 examples from test data
05/17/2022 12:22:15 - INFO - __main__ - Saved prediction in models/T5-base-reptile-cls2cls-3e-5-2-5000-5e-1-10/singletask-emo/emo_16_13_0.4_8_predictions.txt
05/17/2022 12:22:15 - INFO - __main__ - Classification-F1 on test data: 0.0217
05/17/2022 12:22:15 - INFO - __main__ - prefix=emo_16_13, lr=0.4, bsz=8, dev_performance=0.20718262398359094, test_performance=0.021705157145337734
05/17/2022 12:22:15 - INFO - __main__ - Running ... prefix=emo_16_13, lr=0.3, bsz=8 ...
05/17/2022 12:22:16 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 12:22:16 - INFO - __main__ - Printing 3 examples
05/17/2022 12:22:16 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
05/17/2022 12:22:16 - INFO - __main__ - ['others']
05/17/2022 12:22:16 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
05/17/2022 12:22:16 - INFO - __main__ - ['others']
05/17/2022 12:22:16 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
05/17/2022 12:22:16 - INFO - __main__ - ['others']
05/17/2022 12:22:16 - INFO - __main__ - Tokenizing Input ...
05/17/2022 12:22:16 - INFO - __main__ - Tokenizing Output ...
05/17/2022 12:22:16 - INFO - __main__ - Loaded 64 examples from train data
05/17/2022 12:22:16 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 12:22:16 - INFO - __main__ - Printing 3 examples
05/17/2022 12:22:16 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
05/17/2022 12:22:16 - INFO - __main__ - ['others']
05/17/2022 12:22:16 - INFO - __main__ -  [emo] i did ask now you did tell ms
05/17/2022 12:22:16 - INFO - __main__ - ['others']
05/17/2022 12:22:16 - INFO - __main__ -  [emo] buddy how you tell me your contact no
05/17/2022 12:22:16 - INFO - __main__ - ['others']
05/17/2022 12:22:16 - INFO - __main__ - Tokenizing Input ...
05/17/2022 12:22:16 - INFO - __main__ - Tokenizing Output ...
05/17/2022 12:22:16 - INFO - __main__ - Loaded 64 examples from dev data
05/17/2022 12:22:23 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 12:22:23 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 12:22:23 - INFO - __main__ - Starting training!
05/17/2022 12:22:24 - INFO - __main__ - Step 10 Global step 10 Train loss 8.97 on epoch=2
05/17/2022 12:22:26 - INFO - __main__ - Step 20 Global step 20 Train loss 9.08 on epoch=4
05/17/2022 12:22:27 - INFO - __main__ - Step 30 Global step 30 Train loss 8.92 on epoch=7
05/17/2022 12:22:29 - INFO - __main__ - Step 40 Global step 40 Train loss 8.91 on epoch=9
05/17/2022 12:22:31 - INFO - __main__ - Step 50 Global step 50 Train loss 8.90 on epoch=12
05/17/2022 12:22:37 - INFO - __main__ - Global step 50 Train loss 8.96 Classification-F1 0.0 on epoch=12
05/17/2022 12:22:37 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/17/2022 12:22:39 - INFO - __main__ - Step 60 Global step 60 Train loss 8.91 on epoch=14
05/17/2022 12:22:40 - INFO - __main__ - Step 70 Global step 70 Train loss 8.74 on epoch=17
05/17/2022 12:22:42 - INFO - __main__ - Step 80 Global step 80 Train loss 8.79 on epoch=19
05/17/2022 12:22:43 - INFO - __main__ - Step 90 Global step 90 Train loss 8.68 on epoch=22
05/17/2022 12:22:44 - INFO - __main__ - Step 100 Global step 100 Train loss 8.69 on epoch=24
05/17/2022 12:22:54 - INFO - __main__ - Global step 100 Train loss 8.76 Classification-F1 0.0 on epoch=24
05/17/2022 12:22:55 - INFO - __main__ - Step 110 Global step 110 Train loss 8.45 on epoch=27
05/17/2022 12:22:57 - INFO - __main__ - Step 120 Global step 120 Train loss 8.37 on epoch=29
05/17/2022 12:22:58 - INFO - __main__ - Step 130 Global step 130 Train loss 8.14 on epoch=32
05/17/2022 12:23:00 - INFO - __main__ - Step 140 Global step 140 Train loss 7.89 on epoch=34
05/17/2022 12:23:01 - INFO - __main__ - Step 150 Global step 150 Train loss 7.84 on epoch=37
05/17/2022 12:23:15 - INFO - __main__ - Global step 150 Train loss 8.14 Classification-F1 0.0 on epoch=37
05/17/2022 12:23:16 - INFO - __main__ - Step 160 Global step 160 Train loss 7.62 on epoch=39
05/17/2022 12:23:17 - INFO - __main__ - Step 170 Global step 170 Train loss 7.62 on epoch=42
05/17/2022 12:23:19 - INFO - __main__ - Step 180 Global step 180 Train loss 7.44 on epoch=44
05/17/2022 12:23:20 - INFO - __main__ - Step 190 Global step 190 Train loss 7.16 on epoch=47
05/17/2022 12:23:21 - INFO - __main__ - Step 200 Global step 200 Train loss 7.13 on epoch=49
05/17/2022 12:23:37 - INFO - __main__ - Global step 200 Train loss 7.39 Classification-F1 0.0 on epoch=49
05/17/2022 12:23:38 - INFO - __main__ - Step 210 Global step 210 Train loss 6.98 on epoch=52
05/17/2022 12:23:39 - INFO - __main__ - Step 220 Global step 220 Train loss 6.76 on epoch=54
05/17/2022 12:23:41 - INFO - __main__ - Step 230 Global step 230 Train loss 6.90 on epoch=57
05/17/2022 12:23:42 - INFO - __main__ - Step 240 Global step 240 Train loss 6.57 on epoch=59
05/17/2022 12:23:43 - INFO - __main__ - Step 250 Global step 250 Train loss 6.36 on epoch=62
05/17/2022 12:23:51 - INFO - __main__ - Global step 250 Train loss 6.72 Classification-F1 0.0 on epoch=62
05/17/2022 12:23:53 - INFO - __main__ - Step 260 Global step 260 Train loss 6.21 on epoch=64
05/17/2022 12:23:54 - INFO - __main__ - Step 270 Global step 270 Train loss 6.03 on epoch=67
05/17/2022 12:23:55 - INFO - __main__ - Step 280 Global step 280 Train loss 6.04 on epoch=69
05/17/2022 12:23:57 - INFO - __main__ - Step 290 Global step 290 Train loss 5.80 on epoch=72
05/17/2022 12:23:58 - INFO - __main__ - Step 300 Global step 300 Train loss 5.82 on epoch=74
05/17/2022 12:24:06 - INFO - __main__ - Global step 300 Train loss 5.98 Classification-F1 0.0 on epoch=74
05/17/2022 12:24:07 - INFO - __main__ - Step 310 Global step 310 Train loss 5.68 on epoch=77
05/17/2022 12:24:09 - INFO - __main__ - Step 320 Global step 320 Train loss 5.64 on epoch=79
05/17/2022 12:24:10 - INFO - __main__ - Step 330 Global step 330 Train loss 5.50 on epoch=82
05/17/2022 12:24:12 - INFO - __main__ - Step 340 Global step 340 Train loss 5.09 on epoch=84
05/17/2022 12:24:13 - INFO - __main__ - Step 350 Global step 350 Train loss 5.33 on epoch=87
05/17/2022 12:24:20 - INFO - __main__ - Global step 350 Train loss 5.45 Classification-F1 0.0 on epoch=87
05/17/2022 12:24:21 - INFO - __main__ - Step 360 Global step 360 Train loss 5.12 on epoch=89
05/17/2022 12:24:22 - INFO - __main__ - Step 370 Global step 370 Train loss 5.32 on epoch=92
05/17/2022 12:24:24 - INFO - __main__ - Step 380 Global step 380 Train loss 4.80 on epoch=94
05/17/2022 12:24:25 - INFO - __main__ - Step 390 Global step 390 Train loss 4.83 on epoch=97
05/17/2022 12:24:26 - INFO - __main__ - Step 400 Global step 400 Train loss 4.80 on epoch=99
05/17/2022 12:24:45 - INFO - __main__ - Global step 400 Train loss 4.97 Classification-F1 0.0 on epoch=99
05/17/2022 12:24:46 - INFO - __main__ - Step 410 Global step 410 Train loss 4.90 on epoch=102
05/17/2022 12:24:47 - INFO - __main__ - Step 420 Global step 420 Train loss 4.54 on epoch=104
05/17/2022 12:24:49 - INFO - __main__ - Step 430 Global step 430 Train loss 4.63 on epoch=107
05/17/2022 12:24:50 - INFO - __main__ - Step 440 Global step 440 Train loss 4.56 on epoch=109
05/17/2022 12:24:51 - INFO - __main__ - Step 450 Global step 450 Train loss 4.65 on epoch=112
05/17/2022 12:25:02 - INFO - __main__ - Global step 450 Train loss 4.66 Classification-F1 0.0 on epoch=112
05/17/2022 12:25:03 - INFO - __main__ - Step 460 Global step 460 Train loss 4.40 on epoch=114
05/17/2022 12:25:05 - INFO - __main__ - Step 470 Global step 470 Train loss 4.40 on epoch=117
05/17/2022 12:25:06 - INFO - __main__ - Step 480 Global step 480 Train loss 4.19 on epoch=119
05/17/2022 12:25:07 - INFO - __main__ - Step 490 Global step 490 Train loss 4.38 on epoch=122
05/17/2022 12:25:09 - INFO - __main__ - Step 500 Global step 500 Train loss 4.13 on epoch=124
05/17/2022 12:25:15 - INFO - __main__ - Global step 500 Train loss 4.30 Classification-F1 0.0 on epoch=124
05/17/2022 12:25:17 - INFO - __main__ - Step 510 Global step 510 Train loss 4.17 on epoch=127
05/17/2022 12:25:18 - INFO - __main__ - Step 520 Global step 520 Train loss 3.94 on epoch=129
05/17/2022 12:25:20 - INFO - __main__ - Step 530 Global step 530 Train loss 4.09 on epoch=132
05/17/2022 12:25:21 - INFO - __main__ - Step 540 Global step 540 Train loss 3.99 on epoch=134
05/17/2022 12:25:23 - INFO - __main__ - Step 550 Global step 550 Train loss 3.97 on epoch=137
05/17/2022 12:25:38 - INFO - __main__ - Global step 550 Train loss 4.03 Classification-F1 0.020979020979020976 on epoch=137
05/17/2022 12:25:38 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.020979020979020976 on epoch=137, global_step=550
05/17/2022 12:25:39 - INFO - __main__ - Step 560 Global step 560 Train loss 3.69 on epoch=139
05/17/2022 12:25:41 - INFO - __main__ - Step 570 Global step 570 Train loss 3.76 on epoch=142
05/17/2022 12:25:42 - INFO - __main__ - Step 580 Global step 580 Train loss 3.49 on epoch=144
05/17/2022 12:25:44 - INFO - __main__ - Step 590 Global step 590 Train loss 3.64 on epoch=147
05/17/2022 12:25:45 - INFO - __main__ - Step 600 Global step 600 Train loss 4.26 on epoch=149
05/17/2022 12:25:47 - INFO - __main__ - Global step 600 Train loss 3.77 Classification-F1 0.0 on epoch=149
05/17/2022 12:25:48 - INFO - __main__ - Step 610 Global step 610 Train loss 4.69 on epoch=152
05/17/2022 12:25:50 - INFO - __main__ - Step 620 Global step 620 Train loss 4.21 on epoch=154
05/17/2022 12:25:52 - INFO - __main__ - Step 630 Global step 630 Train loss 3.67 on epoch=157
05/17/2022 12:25:53 - INFO - __main__ - Step 640 Global step 640 Train loss 3.44 on epoch=159
05/17/2022 12:25:55 - INFO - __main__ - Step 650 Global step 650 Train loss 3.48 on epoch=162
05/17/2022 12:25:56 - INFO - __main__ - Global step 650 Train loss 3.90 Classification-F1 0.13047619047619047 on epoch=162
05/17/2022 12:25:56 - INFO - __main__ - Saving model with best Classification-F1: 0.020979020979020976 -> 0.13047619047619047 on epoch=162, global_step=650
05/17/2022 12:25:58 - INFO - __main__ - Step 660 Global step 660 Train loss 3.10 on epoch=164
05/17/2022 12:25:59 - INFO - __main__ - Step 670 Global step 670 Train loss 3.32 on epoch=167
05/17/2022 12:26:01 - INFO - __main__ - Step 680 Global step 680 Train loss 3.20 on epoch=169
05/17/2022 12:26:02 - INFO - __main__ - Step 690 Global step 690 Train loss 3.42 on epoch=172
05/17/2022 12:26:04 - INFO - __main__ - Step 700 Global step 700 Train loss 3.16 on epoch=174
05/17/2022 12:26:06 - INFO - __main__ - Global step 700 Train loss 3.24 Classification-F1 0.16601307189542483 on epoch=174
05/17/2022 12:26:06 - INFO - __main__ - Saving model with best Classification-F1: 0.13047619047619047 -> 0.16601307189542483 on epoch=174, global_step=700
05/17/2022 12:26:07 - INFO - __main__ - Step 710 Global step 710 Train loss 3.33 on epoch=177
05/17/2022 12:26:08 - INFO - __main__ - Step 720 Global step 720 Train loss 3.15 on epoch=179
05/17/2022 12:26:10 - INFO - __main__ - Step 730 Global step 730 Train loss 3.04 on epoch=182
05/17/2022 12:26:11 - INFO - __main__ - Step 740 Global step 740 Train loss 2.90 on epoch=184
05/17/2022 12:26:13 - INFO - __main__ - Step 750 Global step 750 Train loss 2.94 on epoch=187
05/17/2022 12:26:13 - INFO - __main__ - Global step 750 Train loss 3.07 Classification-F1 0.13746478873239437 on epoch=187
05/17/2022 12:26:15 - INFO - __main__ - Step 760 Global step 760 Train loss 2.72 on epoch=189
05/17/2022 12:26:16 - INFO - __main__ - Step 770 Global step 770 Train loss 2.93 on epoch=192
05/17/2022 12:26:17 - INFO - __main__ - Step 780 Global step 780 Train loss 2.73 on epoch=194
05/17/2022 12:26:19 - INFO - __main__ - Step 790 Global step 790 Train loss 2.81 on epoch=197
05/17/2022 12:26:20 - INFO - __main__ - Step 800 Global step 800 Train loss 2.53 on epoch=199
05/17/2022 12:26:21 - INFO - __main__ - Global step 800 Train loss 2.74 Classification-F1 0.1 on epoch=199
05/17/2022 12:26:22 - INFO - __main__ - Step 810 Global step 810 Train loss 2.69 on epoch=202
05/17/2022 12:26:24 - INFO - __main__ - Step 820 Global step 820 Train loss 2.53 on epoch=204
05/17/2022 12:26:25 - INFO - __main__ - Step 830 Global step 830 Train loss 2.60 on epoch=207
05/17/2022 12:26:27 - INFO - __main__ - Step 840 Global step 840 Train loss 2.37 on epoch=209
05/17/2022 12:26:28 - INFO - __main__ - Step 850 Global step 850 Train loss 2.49 on epoch=212
05/17/2022 12:26:29 - INFO - __main__ - Global step 850 Train loss 2.54 Classification-F1 0.13067758749069247 on epoch=212
05/17/2022 12:26:30 - INFO - __main__ - Step 860 Global step 860 Train loss 2.36 on epoch=214
05/17/2022 12:26:31 - INFO - __main__ - Step 870 Global step 870 Train loss 2.37 on epoch=217
05/17/2022 12:26:33 - INFO - __main__ - Step 880 Global step 880 Train loss 2.16 on epoch=219
05/17/2022 12:26:34 - INFO - __main__ - Step 890 Global step 890 Train loss 2.19 on epoch=222
05/17/2022 12:26:36 - INFO - __main__ - Step 900 Global step 900 Train loss 2.32 on epoch=224
05/17/2022 12:26:36 - INFO - __main__ - Global step 900 Train loss 2.28 Classification-F1 0.1640625 on epoch=224
05/17/2022 12:26:38 - INFO - __main__ - Step 910 Global step 910 Train loss 2.05 on epoch=227
05/17/2022 12:26:39 - INFO - __main__ - Step 920 Global step 920 Train loss 1.91 on epoch=229
05/17/2022 12:26:41 - INFO - __main__ - Step 930 Global step 930 Train loss 2.12 on epoch=232
05/17/2022 12:26:42 - INFO - __main__ - Step 940 Global step 940 Train loss 2.01 on epoch=234
05/17/2022 12:26:43 - INFO - __main__ - Step 950 Global step 950 Train loss 2.28 on epoch=237
05/17/2022 12:26:44 - INFO - __main__ - Global step 950 Train loss 2.07 Classification-F1 0.10256410256410256 on epoch=237
05/17/2022 12:26:45 - INFO - __main__ - Step 960 Global step 960 Train loss 1.82 on epoch=239
05/17/2022 12:26:47 - INFO - __main__ - Step 970 Global step 970 Train loss 2.24 on epoch=242
05/17/2022 12:26:48 - INFO - __main__ - Step 980 Global step 980 Train loss 1.95 on epoch=244
05/17/2022 12:26:49 - INFO - __main__ - Step 990 Global step 990 Train loss 2.06 on epoch=247
05/17/2022 12:26:51 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.72 on epoch=249
05/17/2022 12:26:51 - INFO - __main__ - Global step 1000 Train loss 1.96 Classification-F1 0.15356265356265356 on epoch=249
05/17/2022 12:26:53 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.75 on epoch=252
05/17/2022 12:26:54 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.88 on epoch=254
05/17/2022 12:26:55 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.84 on epoch=257
05/17/2022 12:26:57 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.83 on epoch=259
05/17/2022 12:26:58 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.79 on epoch=262
05/17/2022 12:26:59 - INFO - __main__ - Global step 1050 Train loss 1.82 Classification-F1 0.11732186732186733 on epoch=262
05/17/2022 12:27:00 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.73 on epoch=264
05/17/2022 12:27:02 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.69 on epoch=267
05/17/2022 12:27:03 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.78 on epoch=269
05/17/2022 12:27:05 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.85 on epoch=272
05/17/2022 12:27:06 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.51 on epoch=274
05/17/2022 12:27:07 - INFO - __main__ - Global step 1100 Train loss 1.71 Classification-F1 0.19628950984883187 on epoch=274
05/17/2022 12:27:07 - INFO - __main__ - Saving model with best Classification-F1: 0.16601307189542483 -> 0.19628950984883187 on epoch=274, global_step=1100
05/17/2022 12:27:08 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.79 on epoch=277
05/17/2022 12:27:10 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.55 on epoch=279
05/17/2022 12:27:11 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.69 on epoch=282
05/17/2022 12:27:12 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.45 on epoch=284
05/17/2022 12:27:14 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.57 on epoch=287
05/17/2022 12:27:14 - INFO - __main__ - Global step 1150 Train loss 1.61 Classification-F1 0.12407862407862408 on epoch=287
05/17/2022 12:27:16 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.58 on epoch=289
05/17/2022 12:27:17 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.54 on epoch=292
05/17/2022 12:27:19 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.41 on epoch=294
05/17/2022 12:27:20 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.45 on epoch=297
05/17/2022 12:27:21 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.41 on epoch=299
05/17/2022 12:27:22 - INFO - __main__ - Global step 1200 Train loss 1.48 Classification-F1 0.19016393442622948 on epoch=299
05/17/2022 12:27:23 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.49 on epoch=302
05/17/2022 12:27:25 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.47 on epoch=304
05/17/2022 12:27:26 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.32 on epoch=307
05/17/2022 12:27:28 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.30 on epoch=309
05/17/2022 12:27:29 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.30 on epoch=312
05/17/2022 12:27:30 - INFO - __main__ - Global step 1250 Train loss 1.38 Classification-F1 0.20956521739130435 on epoch=312
05/17/2022 12:27:30 - INFO - __main__ - Saving model with best Classification-F1: 0.19628950984883187 -> 0.20956521739130435 on epoch=312, global_step=1250
05/17/2022 12:27:31 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.23 on epoch=314
05/17/2022 12:27:33 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.43 on epoch=317
05/17/2022 12:27:34 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.41 on epoch=319
05/17/2022 12:27:36 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.34 on epoch=322
05/17/2022 12:27:37 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.30 on epoch=324
05/17/2022 12:27:38 - INFO - __main__ - Global step 1300 Train loss 1.34 Classification-F1 0.2341430499325236 on epoch=324
05/17/2022 12:27:38 - INFO - __main__ - Saving model with best Classification-F1: 0.20956521739130435 -> 0.2341430499325236 on epoch=324, global_step=1300
05/17/2022 12:27:39 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.31 on epoch=327
05/17/2022 12:27:40 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.35 on epoch=329
05/17/2022 12:27:42 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.31 on epoch=332
05/17/2022 12:27:43 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.20 on epoch=334
05/17/2022 12:27:44 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.29 on epoch=337
05/17/2022 12:27:45 - INFO - __main__ - Global step 1350 Train loss 1.29 Classification-F1 0.12407862407862408 on epoch=337
05/17/2022 12:27:47 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.21 on epoch=339
05/17/2022 12:27:48 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.21 on epoch=342
05/17/2022 12:27:49 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.37 on epoch=344
05/17/2022 12:27:51 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.30 on epoch=347
05/17/2022 12:27:52 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.14 on epoch=349
05/17/2022 12:27:53 - INFO - __main__ - Global step 1400 Train loss 1.25 Classification-F1 0.1 on epoch=349
05/17/2022 12:27:54 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.35 on epoch=352
05/17/2022 12:27:55 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.12 on epoch=354
05/17/2022 12:27:57 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.36 on epoch=357
05/17/2022 12:27:58 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.28 on epoch=359
05/17/2022 12:28:00 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.30 on epoch=362
05/17/2022 12:28:00 - INFO - __main__ - Global step 1450 Train loss 1.28 Classification-F1 0.11585329696394688 on epoch=362
05/17/2022 12:28:02 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.27 on epoch=364
05/17/2022 12:28:03 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.33 on epoch=367
05/17/2022 12:28:04 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.23 on epoch=369
05/17/2022 12:28:06 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.39 on epoch=372
05/17/2022 12:28:07 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.14 on epoch=374
05/17/2022 12:28:08 - INFO - __main__ - Global step 1500 Train loss 1.27 Classification-F1 0.16071428571428573 on epoch=374
05/17/2022 12:28:09 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.21 on epoch=377
05/17/2022 12:28:10 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.22 on epoch=379
05/17/2022 12:28:12 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.11 on epoch=382
05/17/2022 12:28:13 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.25 on epoch=384
05/17/2022 12:28:15 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.40 on epoch=387
05/17/2022 12:28:15 - INFO - __main__ - Global step 1550 Train loss 1.24 Classification-F1 0.1912505726065048 on epoch=387
05/17/2022 12:28:16 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.14 on epoch=389
05/17/2022 12:28:18 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.07 on epoch=392
05/17/2022 12:28:19 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.11 on epoch=394
05/17/2022 12:28:21 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.10 on epoch=397
05/17/2022 12:28:22 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.10 on epoch=399
05/17/2022 12:28:23 - INFO - __main__ - Global step 1600 Train loss 1.10 Classification-F1 0.09493670886075949 on epoch=399
05/17/2022 12:28:24 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.17 on epoch=402
05/17/2022 12:28:25 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.25 on epoch=404
05/17/2022 12:28:27 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.13 on epoch=407
05/17/2022 12:28:28 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.11 on epoch=409
05/17/2022 12:28:29 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.28 on epoch=412
05/17/2022 12:28:30 - INFO - __main__ - Global step 1650 Train loss 1.19 Classification-F1 0.10256410256410256 on epoch=412
05/17/2022 12:28:31 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.13 on epoch=414
05/17/2022 12:28:33 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.17 on epoch=417
05/17/2022 12:28:34 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.13 on epoch=419
05/17/2022 12:28:35 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.21 on epoch=422
05/17/2022 12:28:37 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.13 on epoch=424
05/17/2022 12:28:37 - INFO - __main__ - Global step 1700 Train loss 1.15 Classification-F1 0.09615384615384615 on epoch=424
05/17/2022 12:28:39 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.22 on epoch=427
05/17/2022 12:28:40 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.07 on epoch=429
05/17/2022 12:28:41 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.03 on epoch=432
05/17/2022 12:28:43 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.14 on epoch=434
05/17/2022 12:28:44 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.99 on epoch=437
05/17/2022 12:28:45 - INFO - __main__ - Global step 1750 Train loss 1.09 Classification-F1 0.10126582278481013 on epoch=437
05/17/2022 12:28:46 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.08 on epoch=439
05/17/2022 12:28:47 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.09 on epoch=442
05/17/2022 12:28:49 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.19 on epoch=444
05/17/2022 12:28:50 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.20 on epoch=447
05/17/2022 12:28:52 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.99 on epoch=449
05/17/2022 12:28:52 - INFO - __main__ - Global step 1800 Train loss 1.11 Classification-F1 0.13034188034188032 on epoch=449
05/17/2022 12:28:54 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.14 on epoch=452
05/17/2022 12:28:55 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.00 on epoch=454
05/17/2022 12:28:56 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.15 on epoch=457
05/17/2022 12:28:58 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.09 on epoch=459
05/17/2022 12:28:59 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.33 on epoch=462
05/17/2022 12:29:00 - INFO - __main__ - Global step 1850 Train loss 1.14 Classification-F1 0.1302118933697881 on epoch=462
05/17/2022 12:29:01 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.94 on epoch=464
05/17/2022 12:29:02 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.09 on epoch=467
05/17/2022 12:29:04 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.03 on epoch=469
05/17/2022 12:29:05 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.14 on epoch=472
05/17/2022 12:29:06 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.10 on epoch=474
05/17/2022 12:29:07 - INFO - __main__ - Global step 1900 Train loss 1.06 Classification-F1 0.1 on epoch=474
05/17/2022 12:29:08 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.13 on epoch=477
05/17/2022 12:29:10 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.07 on epoch=479
05/17/2022 12:29:11 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.14 on epoch=482
05/17/2022 12:29:12 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.05 on epoch=484
05/17/2022 12:29:14 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.16 on epoch=487
05/17/2022 12:29:14 - INFO - __main__ - Global step 1950 Train loss 1.11 Classification-F1 0.1 on epoch=487
05/17/2022 12:29:15 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.95 on epoch=489
05/17/2022 12:29:17 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.11 on epoch=492
05/17/2022 12:29:18 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.07 on epoch=494
05/17/2022 12:29:19 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.07 on epoch=497
05/17/2022 12:29:21 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.94 on epoch=499
05/17/2022 12:29:21 - INFO - __main__ - Global step 2000 Train loss 1.03 Classification-F1 0.25748194014447884 on epoch=499
05/17/2022 12:29:21 - INFO - __main__ - Saving model with best Classification-F1: 0.2341430499325236 -> 0.25748194014447884 on epoch=499, global_step=2000
05/17/2022 12:29:23 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.05 on epoch=502
05/17/2022 12:29:24 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.91 on epoch=504
05/17/2022 12:29:25 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.01 on epoch=507
05/17/2022 12:29:27 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.15 on epoch=509
05/17/2022 12:29:28 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.02 on epoch=512
05/17/2022 12:29:29 - INFO - __main__ - Global step 2050 Train loss 1.03 Classification-F1 0.10126582278481013 on epoch=512
05/17/2022 12:29:30 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.04 on epoch=514
05/17/2022 12:29:31 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.07 on epoch=517
05/17/2022 12:29:33 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.06 on epoch=519
05/17/2022 12:29:34 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.08 on epoch=522
05/17/2022 12:29:36 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.19 on epoch=524
05/17/2022 12:29:36 - INFO - __main__ - Global step 2100 Train loss 1.09 Classification-F1 0.1 on epoch=524
05/17/2022 12:29:38 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.04 on epoch=527
05/17/2022 12:29:39 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.90 on epoch=529
05/17/2022 12:29:40 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.06 on epoch=532
05/17/2022 12:29:42 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.14 on epoch=534
05/17/2022 12:29:43 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.04 on epoch=537
05/17/2022 12:29:44 - INFO - __main__ - Global step 2150 Train loss 1.04 Classification-F1 0.10256410256410256 on epoch=537
05/17/2022 12:29:45 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.98 on epoch=539
05/17/2022 12:29:46 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.07 on epoch=542
05/17/2022 12:29:48 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.05 on epoch=544
05/17/2022 12:29:49 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.09 on epoch=547
05/17/2022 12:29:51 - INFO - __main__ - Step 2200 Global step 2200 Train loss 1.05 on epoch=549
05/17/2022 12:29:51 - INFO - __main__ - Global step 2200 Train loss 1.05 Classification-F1 0.13034188034188032 on epoch=549
05/17/2022 12:29:52 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.98 on epoch=552
05/17/2022 12:29:54 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.04 on epoch=554
05/17/2022 12:29:55 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.01 on epoch=557
05/17/2022 12:29:57 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.96 on epoch=559
05/17/2022 12:29:58 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.04 on epoch=562
05/17/2022 12:29:58 - INFO - __main__ - Global step 2250 Train loss 1.00 Classification-F1 0.1 on epoch=562
05/17/2022 12:30:00 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.09 on epoch=564
05/17/2022 12:30:01 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.09 on epoch=567
05/17/2022 12:30:03 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.02 on epoch=569
05/17/2022 12:30:04 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.11 on epoch=572
05/17/2022 12:30:05 - INFO - __main__ - Step 2300 Global step 2300 Train loss 1.01 on epoch=574
05/17/2022 12:30:06 - INFO - __main__ - Global step 2300 Train loss 1.06 Classification-F1 0.10256410256410256 on epoch=574
05/17/2022 12:30:07 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.07 on epoch=577
05/17/2022 12:30:09 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.01 on epoch=579
05/17/2022 12:30:10 - INFO - __main__ - Step 2330 Global step 2330 Train loss 1.14 on epoch=582
05/17/2022 12:30:12 - INFO - __main__ - Step 2340 Global step 2340 Train loss 1.06 on epoch=584
05/17/2022 12:30:13 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.93 on epoch=587
05/17/2022 12:30:14 - INFO - __main__ - Global step 2350 Train loss 1.04 Classification-F1 0.1 on epoch=587
05/17/2022 12:30:15 - INFO - __main__ - Step 2360 Global step 2360 Train loss 1.00 on epoch=589
05/17/2022 12:30:16 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.96 on epoch=592
05/17/2022 12:30:18 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.98 on epoch=594
05/17/2022 12:30:19 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.97 on epoch=597
05/17/2022 12:30:21 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.92 on epoch=599
05/17/2022 12:30:21 - INFO - __main__ - Global step 2400 Train loss 0.97 Classification-F1 0.10126582278481013 on epoch=599
05/17/2022 12:30:23 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.98 on epoch=602
05/17/2022 12:30:24 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.96 on epoch=604
05/17/2022 12:30:25 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.00 on epoch=607
05/17/2022 12:30:27 - INFO - __main__ - Step 2440 Global step 2440 Train loss 1.13 on epoch=609
05/17/2022 12:30:28 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.07 on epoch=612
05/17/2022 12:30:28 - INFO - __main__ - Global step 2450 Train loss 1.03 Classification-F1 0.2361111111111111 on epoch=612
05/17/2022 12:30:30 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.10 on epoch=614
05/17/2022 12:30:31 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.98 on epoch=617
05/17/2022 12:30:33 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.01 on epoch=619
05/17/2022 12:30:34 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.90 on epoch=622
05/17/2022 12:30:36 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.98 on epoch=624
05/17/2022 12:30:36 - INFO - __main__ - Global step 2500 Train loss 0.99 Classification-F1 0.14642857142857144 on epoch=624
05/17/2022 12:30:37 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.96 on epoch=627
05/17/2022 12:30:39 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.99 on epoch=629
05/17/2022 12:30:40 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.03 on epoch=632
05/17/2022 12:30:42 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.91 on epoch=634
05/17/2022 12:30:43 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.87 on epoch=637
05/17/2022 12:30:44 - INFO - __main__ - Global step 2550 Train loss 0.95 Classification-F1 0.12518037518037517 on epoch=637
05/17/2022 12:30:45 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.90 on epoch=639
05/17/2022 12:30:46 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.98 on epoch=642
05/17/2022 12:30:48 - INFO - __main__ - Step 2580 Global step 2580 Train loss 1.00 on epoch=644
05/17/2022 12:30:49 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.00 on epoch=647
05/17/2022 12:30:50 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.93 on epoch=649
05/17/2022 12:30:51 - INFO - __main__ - Global step 2600 Train loss 0.96 Classification-F1 0.2062937062937063 on epoch=649
05/17/2022 12:30:52 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.96 on epoch=652
05/17/2022 12:30:54 - INFO - __main__ - Step 2620 Global step 2620 Train loss 1.02 on epoch=654
05/17/2022 12:30:55 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.97 on epoch=657
05/17/2022 12:30:56 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.93 on epoch=659
05/17/2022 12:30:58 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.79 on epoch=662
05/17/2022 12:30:58 - INFO - __main__ - Global step 2650 Train loss 0.93 Classification-F1 0.17433048550069824 on epoch=662
05/17/2022 12:30:59 - INFO - __main__ - Step 2660 Global step 2660 Train loss 1.04 on epoch=664
05/17/2022 12:31:01 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.97 on epoch=667
05/17/2022 12:31:02 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.94 on epoch=669
05/17/2022 12:31:03 - INFO - __main__ - Step 2690 Global step 2690 Train loss 1.04 on epoch=672
05/17/2022 12:31:05 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.94 on epoch=674
05/17/2022 12:31:05 - INFO - __main__ - Global step 2700 Train loss 0.99 Classification-F1 0.2834440227703985 on epoch=674
05/17/2022 12:31:05 - INFO - __main__ - Saving model with best Classification-F1: 0.25748194014447884 -> 0.2834440227703985 on epoch=674, global_step=2700
05/17/2022 12:31:07 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.97 on epoch=677
05/17/2022 12:31:08 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.99 on epoch=679
05/17/2022 12:31:09 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.90 on epoch=682
05/17/2022 12:31:11 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.96 on epoch=684
05/17/2022 12:31:12 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.89 on epoch=687
05/17/2022 12:31:13 - INFO - __main__ - Global step 2750 Train loss 0.94 Classification-F1 0.26862745098039215 on epoch=687
05/17/2022 12:31:14 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.96 on epoch=689
05/17/2022 12:31:15 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.87 on epoch=692
05/17/2022 12:31:17 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.75 on epoch=694
05/17/2022 12:31:18 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.97 on epoch=697
05/17/2022 12:31:19 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.93 on epoch=699
05/17/2022 12:31:20 - INFO - __main__ - Global step 2800 Train loss 0.90 Classification-F1 0.13034188034188032 on epoch=699
05/17/2022 12:31:21 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.03 on epoch=702
05/17/2022 12:31:23 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.96 on epoch=704
05/17/2022 12:31:24 - INFO - __main__ - Step 2830 Global step 2830 Train loss 1.00 on epoch=707
05/17/2022 12:31:26 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.85 on epoch=709
05/17/2022 12:31:27 - INFO - __main__ - Step 2850 Global step 2850 Train loss 1.00 on epoch=712
05/17/2022 12:31:27 - INFO - __main__ - Global step 2850 Train loss 0.97 Classification-F1 0.24731182795698925 on epoch=712
05/17/2022 12:31:29 - INFO - __main__ - Step 2860 Global step 2860 Train loss 1.00 on epoch=714
05/17/2022 12:31:30 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.95 on epoch=717
05/17/2022 12:31:32 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.98 on epoch=719
05/17/2022 12:31:33 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.96 on epoch=722
05/17/2022 12:31:34 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.00 on epoch=724
05/17/2022 12:31:35 - INFO - __main__ - Global step 2900 Train loss 0.98 Classification-F1 0.2800936768149883 on epoch=724
05/17/2022 12:31:36 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.94 on epoch=727
05/17/2022 12:31:38 - INFO - __main__ - Step 2920 Global step 2920 Train loss 1.13 on epoch=729
05/17/2022 12:31:39 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.90 on epoch=732
05/17/2022 12:31:40 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.92 on epoch=734
05/17/2022 12:31:42 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.92 on epoch=737
05/17/2022 12:31:42 - INFO - __main__ - Global step 2950 Train loss 0.96 Classification-F1 0.18886342415754181 on epoch=737
05/17/2022 12:31:43 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.92 on epoch=739
05/17/2022 12:31:45 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.93 on epoch=742
05/17/2022 12:31:46 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.97 on epoch=744
05/17/2022 12:31:47 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.87 on epoch=747
05/17/2022 12:31:49 - INFO - __main__ - Step 3000 Global step 3000 Train loss 1.07 on epoch=749
05/17/2022 12:31:49 - INFO - __main__ - Global step 3000 Train loss 0.95 Classification-F1 0.1 on epoch=749
05/17/2022 12:31:49 - INFO - __main__ - save last model!
05/17/2022 12:31:49 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/17/2022 12:31:49 - INFO - __main__ - Start tokenizing ... 5509 instances
05/17/2022 12:31:49 - INFO - __main__ - Printing 3 examples
05/17/2022 12:31:49 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/17/2022 12:31:49 - INFO - __main__ - ['others']
05/17/2022 12:31:49 - INFO - __main__ -  [emo] what you like very little things ok
05/17/2022 12:31:49 - INFO - __main__ - ['others']
05/17/2022 12:31:49 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/17/2022 12:31:49 - INFO - __main__ - ['others']
05/17/2022 12:31:49 - INFO - __main__ - Tokenizing Input ...
05/17/2022 12:31:50 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 12:31:50 - INFO - __main__ - Printing 3 examples
05/17/2022 12:31:50 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
05/17/2022 12:31:50 - INFO - __main__ - ['others']
05/17/2022 12:31:50 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
05/17/2022 12:31:50 - INFO - __main__ - ['others']
05/17/2022 12:31:50 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
05/17/2022 12:31:50 - INFO - __main__ - ['others']
05/17/2022 12:31:50 - INFO - __main__ - Tokenizing Input ...
05/17/2022 12:31:50 - INFO - __main__ - Tokenizing Output ...
05/17/2022 12:31:50 - INFO - __main__ - Loaded 64 examples from train data
05/17/2022 12:31:50 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 12:31:50 - INFO - __main__ - Printing 3 examples
05/17/2022 12:31:50 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
05/17/2022 12:31:50 - INFO - __main__ - ['others']
05/17/2022 12:31:50 - INFO - __main__ -  [emo] i did ask now you did tell ms
05/17/2022 12:31:50 - INFO - __main__ - ['others']
05/17/2022 12:31:50 - INFO - __main__ -  [emo] buddy how you tell me your contact no
05/17/2022 12:31:50 - INFO - __main__ - ['others']
05/17/2022 12:31:50 - INFO - __main__ - Tokenizing Input ...
05/17/2022 12:31:50 - INFO - __main__ - Tokenizing Output ...
05/17/2022 12:31:50 - INFO - __main__ - Loaded 64 examples from dev data
05/17/2022 12:31:51 - INFO - __main__ - Tokenizing Output ...
05/17/2022 12:31:57 - INFO - __main__ - Loaded 5509 examples from test data
05/17/2022 12:31:57 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 12:31:57 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 12:31:57 - INFO - __main__ - Starting training!
05/17/2022 12:32:41 - INFO - __main__ - Saved prediction in models/T5-base-reptile-cls2cls-3e-5-2-5000-5e-1-10/singletask-emo/emo_16_13_0.3_8_predictions.txt
05/17/2022 12:32:41 - INFO - __main__ - Classification-F1 on test data: 0.0233
05/17/2022 12:32:41 - INFO - __main__ - prefix=emo_16_13, lr=0.3, bsz=8, dev_performance=0.2834440227703985, test_performance=0.02328239590045721
05/17/2022 12:32:41 - INFO - __main__ - Running ... prefix=emo_16_13, lr=0.2, bsz=8 ...
05/17/2022 12:32:42 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 12:32:42 - INFO - __main__ - Printing 3 examples
05/17/2022 12:32:42 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
05/17/2022 12:32:42 - INFO - __main__ - ['others']
05/17/2022 12:32:42 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
05/17/2022 12:32:42 - INFO - __main__ - ['others']
05/17/2022 12:32:42 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
05/17/2022 12:32:42 - INFO - __main__ - ['others']
05/17/2022 12:32:42 - INFO - __main__ - Tokenizing Input ...
05/17/2022 12:32:43 - INFO - __main__ - Tokenizing Output ...
05/17/2022 12:32:43 - INFO - __main__ - Loaded 64 examples from train data
05/17/2022 12:32:43 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 12:32:43 - INFO - __main__ - Printing 3 examples
05/17/2022 12:32:43 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
05/17/2022 12:32:43 - INFO - __main__ - ['others']
05/17/2022 12:32:43 - INFO - __main__ -  [emo] i did ask now you did tell ms
05/17/2022 12:32:43 - INFO - __main__ - ['others']
05/17/2022 12:32:43 - INFO - __main__ -  [emo] buddy how you tell me your contact no
05/17/2022 12:32:43 - INFO - __main__ - ['others']
05/17/2022 12:32:43 - INFO - __main__ - Tokenizing Input ...
05/17/2022 12:32:43 - INFO - __main__ - Tokenizing Output ...
05/17/2022 12:32:43 - INFO - __main__ - Loaded 64 examples from dev data
05/17/2022 12:32:49 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 12:32:49 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 12:32:49 - INFO - __main__ - Starting training!
05/17/2022 12:32:52 - INFO - __main__ - Step 10 Global step 10 Train loss 8.98 on epoch=2
05/17/2022 12:32:53 - INFO - __main__ - Step 20 Global step 20 Train loss 9.10 on epoch=4
05/17/2022 12:32:55 - INFO - __main__ - Step 30 Global step 30 Train loss 9.06 on epoch=7
05/17/2022 12:32:56 - INFO - __main__ - Step 40 Global step 40 Train loss 8.95 on epoch=9
05/17/2022 12:32:58 - INFO - __main__ - Step 50 Global step 50 Train loss 8.86 on epoch=12
05/17/2022 12:33:04 - INFO - __main__ - Global step 50 Train loss 8.99 Classification-F1 0.0 on epoch=12
05/17/2022 12:33:04 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/17/2022 12:33:05 - INFO - __main__ - Step 60 Global step 60 Train loss 8.82 on epoch=14
05/17/2022 12:33:07 - INFO - __main__ - Step 70 Global step 70 Train loss 8.76 on epoch=17
05/17/2022 12:33:08 - INFO - __main__ - Step 80 Global step 80 Train loss 8.79 on epoch=19
05/17/2022 12:33:10 - INFO - __main__ - Step 90 Global step 90 Train loss 8.70 on epoch=22
05/17/2022 12:33:11 - INFO - __main__ - Step 100 Global step 100 Train loss 8.73 on epoch=24
05/17/2022 12:33:17 - INFO - __main__ - Global step 100 Train loss 8.76 Classification-F1 0.0 on epoch=24
05/17/2022 12:33:18 - INFO - __main__ - Step 110 Global step 110 Train loss 8.74 on epoch=27
05/17/2022 12:33:20 - INFO - __main__ - Step 120 Global step 120 Train loss 8.74 on epoch=29
05/17/2022 12:33:21 - INFO - __main__ - Step 130 Global step 130 Train loss 8.72 on epoch=32
05/17/2022 12:33:22 - INFO - __main__ - Step 140 Global step 140 Train loss 8.69 on epoch=34
05/17/2022 12:33:24 - INFO - __main__ - Step 150 Global step 150 Train loss 8.61 on epoch=37
05/17/2022 12:33:29 - INFO - __main__ - Global step 150 Train loss 8.70 Classification-F1 0.0 on epoch=37
05/17/2022 12:33:31 - INFO - __main__ - Step 160 Global step 160 Train loss 8.63 on epoch=39
05/17/2022 12:33:32 - INFO - __main__ - Step 170 Global step 170 Train loss 8.56 on epoch=42
05/17/2022 12:33:34 - INFO - __main__ - Step 180 Global step 180 Train loss 8.65 on epoch=44
05/17/2022 12:33:35 - INFO - __main__ - Step 190 Global step 190 Train loss 8.54 on epoch=47
05/17/2022 12:33:36 - INFO - __main__ - Step 200 Global step 200 Train loss 8.57 on epoch=49
05/17/2022 12:33:43 - INFO - __main__ - Global step 200 Train loss 8.59 Classification-F1 0.0 on epoch=49
05/17/2022 12:33:45 - INFO - __main__ - Step 210 Global step 210 Train loss 8.51 on epoch=52
05/17/2022 12:33:46 - INFO - __main__ - Step 220 Global step 220 Train loss 8.53 on epoch=54
05/17/2022 12:33:47 - INFO - __main__ - Step 230 Global step 230 Train loss 8.51 on epoch=57
05/17/2022 12:33:49 - INFO - __main__ - Step 240 Global step 240 Train loss 8.54 on epoch=59
05/17/2022 12:33:50 - INFO - __main__ - Step 250 Global step 250 Train loss 8.48 on epoch=62
05/17/2022 12:33:59 - INFO - __main__ - Global step 250 Train loss 8.51 Classification-F1 0.0 on epoch=62
05/17/2022 12:34:01 - INFO - __main__ - Step 260 Global step 260 Train loss 8.39 on epoch=64
05/17/2022 12:34:02 - INFO - __main__ - Step 270 Global step 270 Train loss 8.33 on epoch=67
05/17/2022 12:34:04 - INFO - __main__ - Step 280 Global step 280 Train loss 8.40 on epoch=69
05/17/2022 12:34:05 - INFO - __main__ - Step 290 Global step 290 Train loss 8.25 on epoch=72
05/17/2022 12:34:06 - INFO - __main__ - Step 300 Global step 300 Train loss 8.33 on epoch=74
05/17/2022 12:34:12 - INFO - __main__ - Global step 300 Train loss 8.34 Classification-F1 0.0 on epoch=74
05/17/2022 12:34:14 - INFO - __main__ - Step 310 Global step 310 Train loss 8.25 on epoch=77
05/17/2022 12:34:15 - INFO - __main__ - Step 320 Global step 320 Train loss 8.11 on epoch=79
05/17/2022 12:34:17 - INFO - __main__ - Step 330 Global step 330 Train loss 8.11 on epoch=82
05/17/2022 12:34:18 - INFO - __main__ - Step 340 Global step 340 Train loss 8.04 on epoch=84
05/17/2022 12:34:19 - INFO - __main__ - Step 350 Global step 350 Train loss 7.92 on epoch=87
05/17/2022 12:34:25 - INFO - __main__ - Global step 350 Train loss 8.09 Classification-F1 0.0 on epoch=87
05/17/2022 12:34:26 - INFO - __main__ - Step 360 Global step 360 Train loss 7.98 on epoch=89
05/17/2022 12:34:28 - INFO - __main__ - Step 370 Global step 370 Train loss 7.79 on epoch=92
05/17/2022 12:34:29 - INFO - __main__ - Step 380 Global step 380 Train loss 7.72 on epoch=94
05/17/2022 12:34:31 - INFO - __main__ - Step 390 Global step 390 Train loss 7.63 on epoch=97
05/17/2022 12:34:32 - INFO - __main__ - Step 400 Global step 400 Train loss 7.50 on epoch=99
05/17/2022 12:34:50 - INFO - __main__ - Global step 400 Train loss 7.72 Classification-F1 0.0 on epoch=99
05/17/2022 12:34:51 - INFO - __main__ - Step 410 Global step 410 Train loss 7.50 on epoch=102
05/17/2022 12:34:53 - INFO - __main__ - Step 420 Global step 420 Train loss 7.39 on epoch=104
05/17/2022 12:34:54 - INFO - __main__ - Step 430 Global step 430 Train loss 7.00 on epoch=107
05/17/2022 12:34:55 - INFO - __main__ - Step 440 Global step 440 Train loss 7.25 on epoch=109
05/17/2022 12:34:56 - INFO - __main__ - Step 450 Global step 450 Train loss 7.10 on epoch=112
05/17/2022 12:35:11 - INFO - __main__ - Global step 450 Train loss 7.25 Classification-F1 0.0 on epoch=112
05/17/2022 12:35:12 - INFO - __main__ - Step 460 Global step 460 Train loss 7.02 on epoch=114
05/17/2022 12:35:13 - INFO - __main__ - Step 470 Global step 470 Train loss 7.18 on epoch=117
05/17/2022 12:35:15 - INFO - __main__ - Step 480 Global step 480 Train loss 7.02 on epoch=119
05/17/2022 12:35:16 - INFO - __main__ - Step 490 Global step 490 Train loss 6.95 on epoch=122
05/17/2022 12:35:17 - INFO - __main__ - Step 500 Global step 500 Train loss 6.81 on epoch=124
05/17/2022 12:35:38 - INFO - __main__ - Global step 500 Train loss 7.00 Classification-F1 0.0 on epoch=124
05/17/2022 12:35:39 - INFO - __main__ - Step 510 Global step 510 Train loss 6.78 on epoch=127
05/17/2022 12:35:40 - INFO - __main__ - Step 520 Global step 520 Train loss 6.90 on epoch=129
05/17/2022 12:35:42 - INFO - __main__ - Step 530 Global step 530 Train loss 6.57 on epoch=132
05/17/2022 12:35:43 - INFO - __main__ - Step 540 Global step 540 Train loss 6.42 on epoch=134
05/17/2022 12:35:44 - INFO - __main__ - Step 550 Global step 550 Train loss 6.51 on epoch=137
05/17/2022 12:35:51 - INFO - __main__ - Global step 550 Train loss 6.64 Classification-F1 0.0 on epoch=137
05/17/2022 12:35:53 - INFO - __main__ - Step 560 Global step 560 Train loss 6.35 on epoch=139
05/17/2022 12:35:54 - INFO - __main__ - Step 570 Global step 570 Train loss 6.24 on epoch=142
05/17/2022 12:35:56 - INFO - __main__ - Step 580 Global step 580 Train loss 6.23 on epoch=144
05/17/2022 12:35:57 - INFO - __main__ - Step 590 Global step 590 Train loss 6.28 on epoch=147
05/17/2022 12:35:58 - INFO - __main__ - Step 600 Global step 600 Train loss 6.32 on epoch=149
05/17/2022 12:36:10 - INFO - __main__ - Global step 600 Train loss 6.28 Classification-F1 0.0 on epoch=149
05/17/2022 12:36:11 - INFO - __main__ - Step 610 Global step 610 Train loss 6.03 on epoch=152
05/17/2022 12:36:12 - INFO - __main__ - Step 620 Global step 620 Train loss 5.90 on epoch=154
05/17/2022 12:36:14 - INFO - __main__ - Step 630 Global step 630 Train loss 5.82 on epoch=157
05/17/2022 12:36:15 - INFO - __main__ - Step 640 Global step 640 Train loss 5.72 on epoch=159
05/17/2022 12:36:17 - INFO - __main__ - Step 650 Global step 650 Train loss 5.73 on epoch=162
05/17/2022 12:36:29 - INFO - __main__ - Global step 650 Train loss 5.84 Classification-F1 0.0 on epoch=162
05/17/2022 12:36:30 - INFO - __main__ - Step 660 Global step 660 Train loss 5.56 on epoch=164
05/17/2022 12:36:32 - INFO - __main__ - Step 670 Global step 670 Train loss 5.60 on epoch=167
05/17/2022 12:36:33 - INFO - __main__ - Step 680 Global step 680 Train loss 5.41 on epoch=169
05/17/2022 12:36:34 - INFO - __main__ - Step 690 Global step 690 Train loss 5.33 on epoch=172
05/17/2022 12:36:36 - INFO - __main__ - Step 700 Global step 700 Train loss 5.05 on epoch=174
05/17/2022 12:36:46 - INFO - __main__ - Global step 700 Train loss 5.39 Classification-F1 0.0 on epoch=174
05/17/2022 12:36:47 - INFO - __main__ - Step 710 Global step 710 Train loss 5.07 on epoch=177
05/17/2022 12:36:49 - INFO - __main__ - Step 720 Global step 720 Train loss 5.18 on epoch=179
05/17/2022 12:36:50 - INFO - __main__ - Step 730 Global step 730 Train loss 5.00 on epoch=182
05/17/2022 12:36:52 - INFO - __main__ - Step 740 Global step 740 Train loss 5.00 on epoch=184
05/17/2022 12:36:53 - INFO - __main__ - Step 750 Global step 750 Train loss 4.98 on epoch=187
05/17/2022 12:36:59 - INFO - __main__ - Global step 750 Train loss 5.04 Classification-F1 0.0 on epoch=187
05/17/2022 12:37:01 - INFO - __main__ - Step 760 Global step 760 Train loss 4.95 on epoch=189
05/17/2022 12:37:02 - INFO - __main__ - Step 770 Global step 770 Train loss 4.84 on epoch=192
05/17/2022 12:37:04 - INFO - __main__ - Step 780 Global step 780 Train loss 4.45 on epoch=194
05/17/2022 12:37:05 - INFO - __main__ - Step 790 Global step 790 Train loss 4.60 on epoch=197
05/17/2022 12:37:07 - INFO - __main__ - Step 800 Global step 800 Train loss 4.51 on epoch=199
05/17/2022 12:37:27 - INFO - __main__ - Global step 800 Train loss 4.67 Classification-F1 0.0 on epoch=199
05/17/2022 12:37:28 - INFO - __main__ - Step 810 Global step 810 Train loss 4.60 on epoch=202
05/17/2022 12:37:30 - INFO - __main__ - Step 820 Global step 820 Train loss 4.45 on epoch=204
05/17/2022 12:37:31 - INFO - __main__ - Step 830 Global step 830 Train loss 4.55 on epoch=207
05/17/2022 12:37:33 - INFO - __main__ - Step 840 Global step 840 Train loss 4.42 on epoch=209
05/17/2022 12:37:34 - INFO - __main__ - Step 850 Global step 850 Train loss 4.43 on epoch=212
05/17/2022 12:37:48 - INFO - __main__ - Global step 850 Train loss 4.49 Classification-F1 0.005 on epoch=212
05/17/2022 12:37:48 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.005 on epoch=212, global_step=850
05/17/2022 12:37:50 - INFO - __main__ - Step 860 Global step 860 Train loss 4.21 on epoch=214
05/17/2022 12:37:51 - INFO - __main__ - Step 870 Global step 870 Train loss 4.10 on epoch=217
05/17/2022 12:37:52 - INFO - __main__ - Step 880 Global step 880 Train loss 4.02 on epoch=219
05/17/2022 12:37:54 - INFO - __main__ - Step 890 Global step 890 Train loss 4.26 on epoch=222
05/17/2022 12:37:55 - INFO - __main__ - Step 900 Global step 900 Train loss 3.92 on epoch=224
05/17/2022 12:37:59 - INFO - __main__ - Global step 900 Train loss 4.10 Classification-F1 0.00865800865800866 on epoch=224
05/17/2022 12:37:59 - INFO - __main__ - Saving model with best Classification-F1: 0.005 -> 0.00865800865800866 on epoch=224, global_step=900
05/17/2022 12:38:00 - INFO - __main__ - Step 910 Global step 910 Train loss 4.13 on epoch=227
05/17/2022 12:38:02 - INFO - __main__ - Step 920 Global step 920 Train loss 3.89 on epoch=229
05/17/2022 12:38:03 - INFO - __main__ - Step 930 Global step 930 Train loss 3.90 on epoch=232
05/17/2022 12:38:05 - INFO - __main__ - Step 940 Global step 940 Train loss 3.89 on epoch=234
05/17/2022 12:38:07 - INFO - __main__ - Step 950 Global step 950 Train loss 4.07 on epoch=237
05/17/2022 12:38:11 - INFO - __main__ - Global step 950 Train loss 3.97 Classification-F1 0.013257575757575758 on epoch=237
05/17/2022 12:38:11 - INFO - __main__ - Saving model with best Classification-F1: 0.00865800865800866 -> 0.013257575757575758 on epoch=237, global_step=950
05/17/2022 12:38:12 - INFO - __main__ - Step 960 Global step 960 Train loss 4.10 on epoch=239
05/17/2022 12:38:13 - INFO - __main__ - Step 970 Global step 970 Train loss 4.02 on epoch=242
05/17/2022 12:38:15 - INFO - __main__ - Step 980 Global step 980 Train loss 3.67 on epoch=244
05/17/2022 12:38:16 - INFO - __main__ - Step 990 Global step 990 Train loss 3.92 on epoch=247
05/17/2022 12:38:18 - INFO - __main__ - Step 1000 Global step 1000 Train loss 3.66 on epoch=249
05/17/2022 12:38:22 - INFO - __main__ - Global step 1000 Train loss 3.88 Classification-F1 0.015345268542199489 on epoch=249
05/17/2022 12:38:22 - INFO - __main__ - Saving model with best Classification-F1: 0.013257575757575758 -> 0.015345268542199489 on epoch=249, global_step=1000
05/17/2022 12:38:23 - INFO - __main__ - Step 1010 Global step 1010 Train loss 3.93 on epoch=252
05/17/2022 12:38:25 - INFO - __main__ - Step 1020 Global step 1020 Train loss 3.75 on epoch=254
05/17/2022 12:38:26 - INFO - __main__ - Step 1030 Global step 1030 Train loss 3.82 on epoch=257
05/17/2022 12:38:27 - INFO - __main__ - Step 1040 Global step 1040 Train loss 3.66 on epoch=259
05/17/2022 12:38:29 - INFO - __main__ - Step 1050 Global step 1050 Train loss 3.73 on epoch=262
05/17/2022 12:38:33 - INFO - __main__ - Global step 1050 Train loss 3.78 Classification-F1 0.024038461538461536 on epoch=262
05/17/2022 12:38:33 - INFO - __main__ - Saving model with best Classification-F1: 0.015345268542199489 -> 0.024038461538461536 on epoch=262, global_step=1050
05/17/2022 12:38:34 - INFO - __main__ - Step 1060 Global step 1060 Train loss 3.75 on epoch=264
05/17/2022 12:38:35 - INFO - __main__ - Step 1070 Global step 1070 Train loss 3.60 on epoch=267
05/17/2022 12:38:37 - INFO - __main__ - Step 1080 Global step 1080 Train loss 3.54 on epoch=269
05/17/2022 12:38:38 - INFO - __main__ - Step 1090 Global step 1090 Train loss 3.87 on epoch=272
05/17/2022 12:38:40 - INFO - __main__ - Step 1100 Global step 1100 Train loss 3.50 on epoch=274
05/17/2022 12:38:41 - INFO - __main__ - Global step 1100 Train loss 3.65 Classification-F1 0.1 on epoch=274
05/17/2022 12:38:41 - INFO - __main__ - Saving model with best Classification-F1: 0.024038461538461536 -> 0.1 on epoch=274, global_step=1100
05/17/2022 12:38:43 - INFO - __main__ - Step 1110 Global step 1110 Train loss 3.65 on epoch=277
05/17/2022 12:38:44 - INFO - __main__ - Step 1120 Global step 1120 Train loss 3.48 on epoch=279
05/17/2022 12:38:45 - INFO - __main__ - Step 1130 Global step 1130 Train loss 3.64 on epoch=282
05/17/2022 12:38:47 - INFO - __main__ - Step 1140 Global step 1140 Train loss 3.35 on epoch=284
05/17/2022 12:38:48 - INFO - __main__ - Step 1150 Global step 1150 Train loss 3.44 on epoch=287
05/17/2022 12:38:52 - INFO - __main__ - Global step 1150 Train loss 3.51 Classification-F1 0.07017543859649124 on epoch=287
05/17/2022 12:38:53 - INFO - __main__ - Step 1160 Global step 1160 Train loss 3.32 on epoch=289
05/17/2022 12:38:54 - INFO - __main__ - Step 1170 Global step 1170 Train loss 3.42 on epoch=292
05/17/2022 12:38:56 - INFO - __main__ - Step 1180 Global step 1180 Train loss 3.25 on epoch=294
05/17/2022 12:38:57 - INFO - __main__ - Step 1190 Global step 1190 Train loss 3.34 on epoch=297
05/17/2022 12:38:58 - INFO - __main__ - Step 1200 Global step 1200 Train loss 3.25 on epoch=299
05/17/2022 12:39:00 - INFO - __main__ - Global step 1200 Train loss 3.32 Classification-F1 0.1 on epoch=299
05/17/2022 12:39:01 - INFO - __main__ - Step 1210 Global step 1210 Train loss 3.11 on epoch=302
05/17/2022 12:39:02 - INFO - __main__ - Step 1220 Global step 1220 Train loss 3.31 on epoch=304
05/17/2022 12:39:04 - INFO - __main__ - Step 1230 Global step 1230 Train loss 3.26 on epoch=307
05/17/2022 12:39:05 - INFO - __main__ - Step 1240 Global step 1240 Train loss 3.14 on epoch=309
05/17/2022 12:39:06 - INFO - __main__ - Step 1250 Global step 1250 Train loss 3.31 on epoch=312
05/17/2022 12:39:07 - INFO - __main__ - Global step 1250 Train loss 3.23 Classification-F1 0.10686274509803921 on epoch=312
05/17/2022 12:39:07 - INFO - __main__ - Saving model with best Classification-F1: 0.1 -> 0.10686274509803921 on epoch=312, global_step=1250
05/17/2022 12:39:08 - INFO - __main__ - Step 1260 Global step 1260 Train loss 3.07 on epoch=314
05/17/2022 12:39:10 - INFO - __main__ - Step 1270 Global step 1270 Train loss 3.27 on epoch=317
05/17/2022 12:39:11 - INFO - __main__ - Step 1280 Global step 1280 Train loss 3.01 on epoch=319
05/17/2022 12:39:12 - INFO - __main__ - Step 1290 Global step 1290 Train loss 3.19 on epoch=322
05/17/2022 12:39:14 - INFO - __main__ - Step 1300 Global step 1300 Train loss 2.85 on epoch=324
05/17/2022 12:39:14 - INFO - __main__ - Global step 1300 Train loss 3.08 Classification-F1 0.1 on epoch=324
05/17/2022 12:39:16 - INFO - __main__ - Step 1310 Global step 1310 Train loss 3.16 on epoch=327
05/17/2022 12:39:17 - INFO - __main__ - Step 1320 Global step 1320 Train loss 3.10 on epoch=329
05/17/2022 12:39:19 - INFO - __main__ - Step 1330 Global step 1330 Train loss 3.06 on epoch=332
05/17/2022 12:39:20 - INFO - __main__ - Step 1340 Global step 1340 Train loss 2.89 on epoch=334
05/17/2022 12:39:21 - INFO - __main__ - Step 1350 Global step 1350 Train loss 3.20 on epoch=337
05/17/2022 12:39:22 - INFO - __main__ - Global step 1350 Train loss 3.08 Classification-F1 0.0810126582278481 on epoch=337
05/17/2022 12:39:23 - INFO - __main__ - Step 1360 Global step 1360 Train loss 2.99 on epoch=339
05/17/2022 12:39:25 - INFO - __main__ - Step 1370 Global step 1370 Train loss 2.97 on epoch=342
05/17/2022 12:39:26 - INFO - __main__ - Step 1380 Global step 1380 Train loss 2.75 on epoch=344
05/17/2022 12:39:27 - INFO - __main__ - Step 1390 Global step 1390 Train loss 3.06 on epoch=347
05/17/2022 12:39:29 - INFO - __main__ - Step 1400 Global step 1400 Train loss 2.66 on epoch=349
05/17/2022 12:39:29 - INFO - __main__ - Global step 1400 Train loss 2.89 Classification-F1 0.08108108108108109 on epoch=349
05/17/2022 12:39:31 - INFO - __main__ - Step 1410 Global step 1410 Train loss 2.93 on epoch=352
05/17/2022 12:39:32 - INFO - __main__ - Step 1420 Global step 1420 Train loss 2.55 on epoch=354
05/17/2022 12:39:34 - INFO - __main__ - Step 1430 Global step 1430 Train loss 2.91 on epoch=357
05/17/2022 12:39:35 - INFO - __main__ - Step 1440 Global step 1440 Train loss 2.80 on epoch=359
05/17/2022 12:39:36 - INFO - __main__ - Step 1450 Global step 1450 Train loss 2.83 on epoch=362
05/17/2022 12:39:37 - INFO - __main__ - Global step 1450 Train loss 2.81 Classification-F1 0.1 on epoch=362
05/17/2022 12:39:38 - INFO - __main__ - Step 1460 Global step 1460 Train loss 2.73 on epoch=364
05/17/2022 12:39:40 - INFO - __main__ - Step 1470 Global step 1470 Train loss 2.80 on epoch=367
05/17/2022 12:39:41 - INFO - __main__ - Step 1480 Global step 1480 Train loss 2.66 on epoch=369
05/17/2022 12:39:43 - INFO - __main__ - Step 1490 Global step 1490 Train loss 2.81 on epoch=372
05/17/2022 12:39:44 - INFO - __main__ - Step 1500 Global step 1500 Train loss 2.58 on epoch=374
05/17/2022 12:39:45 - INFO - __main__ - Global step 1500 Train loss 2.72 Classification-F1 0.09493670886075949 on epoch=374
05/17/2022 12:39:46 - INFO - __main__ - Step 1510 Global step 1510 Train loss 2.68 on epoch=377
05/17/2022 12:39:48 - INFO - __main__ - Step 1520 Global step 1520 Train loss 2.57 on epoch=379
05/17/2022 12:39:49 - INFO - __main__ - Step 1530 Global step 1530 Train loss 2.88 on epoch=382
05/17/2022 12:39:51 - INFO - __main__ - Step 1540 Global step 1540 Train loss 2.55 on epoch=384
05/17/2022 12:39:53 - INFO - __main__ - Step 1550 Global step 1550 Train loss 2.62 on epoch=387
05/17/2022 12:39:53 - INFO - __main__ - Global step 1550 Train loss 2.66 Classification-F1 0.06857142857142857 on epoch=387
05/17/2022 12:39:55 - INFO - __main__ - Step 1560 Global step 1560 Train loss 2.56 on epoch=389
05/17/2022 12:39:56 - INFO - __main__ - Step 1570 Global step 1570 Train loss 2.70 on epoch=392
05/17/2022 12:39:57 - INFO - __main__ - Step 1580 Global step 1580 Train loss 2.45 on epoch=394
05/17/2022 12:39:59 - INFO - __main__ - Step 1590 Global step 1590 Train loss 2.48 on epoch=397
05/17/2022 12:40:00 - INFO - __main__ - Step 1600 Global step 1600 Train loss 2.35 on epoch=399
05/17/2022 12:40:01 - INFO - __main__ - Global step 1600 Train loss 2.51 Classification-F1 0.08333333333333333 on epoch=399
05/17/2022 12:40:02 - INFO - __main__ - Step 1610 Global step 1610 Train loss 2.40 on epoch=402
05/17/2022 12:40:04 - INFO - __main__ - Step 1620 Global step 1620 Train loss 2.27 on epoch=404
05/17/2022 12:40:05 - INFO - __main__ - Step 1630 Global step 1630 Train loss 2.58 on epoch=407
05/17/2022 12:40:06 - INFO - __main__ - Step 1640 Global step 1640 Train loss 2.33 on epoch=409
05/17/2022 12:40:08 - INFO - __main__ - Step 1650 Global step 1650 Train loss 2.60 on epoch=412
05/17/2022 12:40:08 - INFO - __main__ - Global step 1650 Train loss 2.43 Classification-F1 0.09615384615384615 on epoch=412
05/17/2022 12:40:10 - INFO - __main__ - Step 1660 Global step 1660 Train loss 2.37 on epoch=414
05/17/2022 12:40:11 - INFO - __main__ - Step 1670 Global step 1670 Train loss 2.39 on epoch=417
05/17/2022 12:40:13 - INFO - __main__ - Step 1680 Global step 1680 Train loss 2.37 on epoch=419
05/17/2022 12:40:14 - INFO - __main__ - Step 1690 Global step 1690 Train loss 2.37 on epoch=422
05/17/2022 12:40:15 - INFO - __main__ - Step 1700 Global step 1700 Train loss 2.21 on epoch=424
05/17/2022 12:40:16 - INFO - __main__ - Global step 1700 Train loss 2.34 Classification-F1 0.08380373425966131 on epoch=424
05/17/2022 12:40:17 - INFO - __main__ - Step 1710 Global step 1710 Train loss 2.48 on epoch=427
05/17/2022 12:40:19 - INFO - __main__ - Step 1720 Global step 1720 Train loss 2.33 on epoch=429
05/17/2022 12:40:20 - INFO - __main__ - Step 1730 Global step 1730 Train loss 2.32 on epoch=432
05/17/2022 12:40:21 - INFO - __main__ - Step 1740 Global step 1740 Train loss 2.31 on epoch=434
05/17/2022 12:40:23 - INFO - __main__ - Step 1750 Global step 1750 Train loss 2.41 on epoch=437
05/17/2022 12:40:23 - INFO - __main__ - Global step 1750 Train loss 2.37 Classification-F1 0.11336032388663966 on epoch=437
05/17/2022 12:40:23 - INFO - __main__ - Saving model with best Classification-F1: 0.10686274509803921 -> 0.11336032388663966 on epoch=437, global_step=1750
05/17/2022 12:40:25 - INFO - __main__ - Step 1760 Global step 1760 Train loss 2.31 on epoch=439
05/17/2022 12:40:26 - INFO - __main__ - Step 1770 Global step 1770 Train loss 2.42 on epoch=442
05/17/2022 12:40:28 - INFO - __main__ - Step 1780 Global step 1780 Train loss 2.26 on epoch=444
05/17/2022 12:40:29 - INFO - __main__ - Step 1790 Global step 1790 Train loss 2.24 on epoch=447
05/17/2022 12:40:30 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.97 on epoch=449
05/17/2022 12:40:31 - INFO - __main__ - Global step 1800 Train loss 2.24 Classification-F1 0.142512077294686 on epoch=449
05/17/2022 12:40:31 - INFO - __main__ - Saving model with best Classification-F1: 0.11336032388663966 -> 0.142512077294686 on epoch=449, global_step=1800
05/17/2022 12:40:32 - INFO - __main__ - Step 1810 Global step 1810 Train loss 2.34 on epoch=452
05/17/2022 12:40:34 - INFO - __main__ - Step 1820 Global step 1820 Train loss 2.02 on epoch=454
05/17/2022 12:40:35 - INFO - __main__ - Step 1830 Global step 1830 Train loss 2.24 on epoch=457
05/17/2022 12:40:36 - INFO - __main__ - Step 1840 Global step 1840 Train loss 2.14 on epoch=459
05/17/2022 12:40:38 - INFO - __main__ - Step 1850 Global step 1850 Train loss 2.29 on epoch=462
05/17/2022 12:40:39 - INFO - __main__ - Global step 1850 Train loss 2.21 Classification-F1 0.1015625 on epoch=462
05/17/2022 12:40:40 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.97 on epoch=464
05/17/2022 12:40:41 - INFO - __main__ - Step 1870 Global step 1870 Train loss 2.20 on epoch=467
05/17/2022 12:40:43 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.91 on epoch=469
05/17/2022 12:40:44 - INFO - __main__ - Step 1890 Global step 1890 Train loss 2.10 on epoch=472
05/17/2022 12:40:46 - INFO - __main__ - Step 1900 Global step 1900 Train loss 2.12 on epoch=474
05/17/2022 12:40:46 - INFO - __main__ - Global step 1900 Train loss 2.06 Classification-F1 0.16366223908918406 on epoch=474
05/17/2022 12:40:46 - INFO - __main__ - Saving model with best Classification-F1: 0.142512077294686 -> 0.16366223908918406 on epoch=474, global_step=1900
05/17/2022 12:40:48 - INFO - __main__ - Step 1910 Global step 1910 Train loss 2.13 on epoch=477
05/17/2022 12:40:49 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.82 on epoch=479
05/17/2022 12:40:51 - INFO - __main__ - Step 1930 Global step 1930 Train loss 2.09 on epoch=482
05/17/2022 12:40:52 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.83 on epoch=484
05/17/2022 12:40:53 - INFO - __main__ - Step 1950 Global step 1950 Train loss 2.08 on epoch=487
05/17/2022 12:40:54 - INFO - __main__ - Global step 1950 Train loss 1.99 Classification-F1 0.08450704225352113 on epoch=487
05/17/2022 12:40:55 - INFO - __main__ - Step 1960 Global step 1960 Train loss 2.05 on epoch=489
05/17/2022 12:40:56 - INFO - __main__ - Step 1970 Global step 1970 Train loss 2.19 on epoch=492
05/17/2022 12:40:58 - INFO - __main__ - Step 1980 Global step 1980 Train loss 2.03 on epoch=494
05/17/2022 12:40:59 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.94 on epoch=497
05/17/2022 12:41:00 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.96 on epoch=499
05/17/2022 12:41:01 - INFO - __main__ - Global step 2000 Train loss 2.03 Classification-F1 0.17036188422400433 on epoch=499
05/17/2022 12:41:01 - INFO - __main__ - Saving model with best Classification-F1: 0.16366223908918406 -> 0.17036188422400433 on epoch=499, global_step=2000
05/17/2022 12:41:03 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.92 on epoch=502
05/17/2022 12:41:04 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.74 on epoch=504
05/17/2022 12:41:05 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.77 on epoch=507
05/17/2022 12:41:07 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.88 on epoch=509
05/17/2022 12:41:08 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.72 on epoch=512
05/17/2022 12:41:09 - INFO - __main__ - Global step 2050 Train loss 1.81 Classification-F1 0.12417582417582418 on epoch=512
05/17/2022 12:41:10 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.86 on epoch=514
05/17/2022 12:41:11 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.85 on epoch=517
05/17/2022 12:41:13 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.81 on epoch=519
05/17/2022 12:41:14 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.80 on epoch=522
05/17/2022 12:41:15 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.65 on epoch=524
05/17/2022 12:41:16 - INFO - __main__ - Global step 2100 Train loss 1.79 Classification-F1 0.08293530178028657 on epoch=524
05/17/2022 12:41:17 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.94 on epoch=527
05/17/2022 12:41:19 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.65 on epoch=529
05/17/2022 12:41:20 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.78 on epoch=532
05/17/2022 12:41:22 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.65 on epoch=534
05/17/2022 12:41:23 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.79 on epoch=537
05/17/2022 12:41:23 - INFO - __main__ - Global step 2150 Train loss 1.76 Classification-F1 0.13657090743274053 on epoch=537
05/17/2022 12:41:25 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.83 on epoch=539
05/17/2022 12:41:26 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.79 on epoch=542
05/17/2022 12:41:28 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.56 on epoch=544
05/17/2022 12:41:29 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.77 on epoch=547
05/17/2022 12:41:30 - INFO - __main__ - Step 2200 Global step 2200 Train loss 1.55 on epoch=549
05/17/2022 12:41:31 - INFO - __main__ - Global step 2200 Train loss 1.70 Classification-F1 0.10843672456575681 on epoch=549
05/17/2022 12:41:32 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.70 on epoch=552
05/17/2022 12:41:34 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.57 on epoch=554
05/17/2022 12:41:35 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.73 on epoch=557
05/17/2022 12:41:37 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.56 on epoch=559
05/17/2022 12:41:38 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.66 on epoch=562
05/17/2022 12:41:38 - INFO - __main__ - Global step 2250 Train loss 1.64 Classification-F1 0.1181716833890747 on epoch=562
05/17/2022 12:41:40 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.58 on epoch=564
05/17/2022 12:41:41 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.56 on epoch=567
05/17/2022 12:41:43 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.45 on epoch=569
05/17/2022 12:41:44 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.59 on epoch=572
05/17/2022 12:41:45 - INFO - __main__ - Step 2300 Global step 2300 Train loss 1.41 on epoch=574
05/17/2022 12:41:46 - INFO - __main__ - Global step 2300 Train loss 1.52 Classification-F1 0.1767857142857143 on epoch=574
05/17/2022 12:41:46 - INFO - __main__ - Saving model with best Classification-F1: 0.17036188422400433 -> 0.1767857142857143 on epoch=574, global_step=2300
05/17/2022 12:41:47 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.52 on epoch=577
05/17/2022 12:41:49 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.62 on epoch=579
05/17/2022 12:41:50 - INFO - __main__ - Step 2330 Global step 2330 Train loss 1.57 on epoch=582
05/17/2022 12:41:52 - INFO - __main__ - Step 2340 Global step 2340 Train loss 1.54 on epoch=584
05/17/2022 12:41:53 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.58 on epoch=587
05/17/2022 12:41:54 - INFO - __main__ - Global step 2350 Train loss 1.57 Classification-F1 0.1347521402927368 on epoch=587
05/17/2022 12:41:55 - INFO - __main__ - Step 2360 Global step 2360 Train loss 1.56 on epoch=589
05/17/2022 12:41:56 - INFO - __main__ - Step 2370 Global step 2370 Train loss 1.49 on epoch=592
05/17/2022 12:41:58 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.49 on epoch=594
05/17/2022 12:41:59 - INFO - __main__ - Step 2390 Global step 2390 Train loss 1.58 on epoch=597
05/17/2022 12:42:01 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.47 on epoch=599
05/17/2022 12:42:01 - INFO - __main__ - Global step 2400 Train loss 1.52 Classification-F1 0.08333333333333333 on epoch=599
05/17/2022 12:42:03 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.49 on epoch=602
05/17/2022 12:42:04 - INFO - __main__ - Step 2420 Global step 2420 Train loss 1.45 on epoch=604
05/17/2022 12:42:05 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.53 on epoch=607
05/17/2022 12:42:07 - INFO - __main__ - Step 2440 Global step 2440 Train loss 1.44 on epoch=609
05/17/2022 12:42:08 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.48 on epoch=612
05/17/2022 12:42:08 - INFO - __main__ - Global step 2450 Train loss 1.48 Classification-F1 0.15054945054945054 on epoch=612
05/17/2022 12:42:10 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.29 on epoch=614
05/17/2022 12:42:11 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.40 on epoch=617
05/17/2022 12:42:13 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.36 on epoch=619
05/17/2022 12:42:14 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.38 on epoch=622
05/17/2022 12:42:15 - INFO - __main__ - Step 2500 Global step 2500 Train loss 1.38 on epoch=624
05/17/2022 12:42:16 - INFO - __main__ - Global step 2500 Train loss 1.36 Classification-F1 0.1468058968058968 on epoch=624
05/17/2022 12:42:17 - INFO - __main__ - Step 2510 Global step 2510 Train loss 1.31 on epoch=627
05/17/2022 12:42:19 - INFO - __main__ - Step 2520 Global step 2520 Train loss 1.33 on epoch=629
05/17/2022 12:42:20 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.37 on epoch=632
05/17/2022 12:42:22 - INFO - __main__ - Step 2540 Global step 2540 Train loss 1.27 on epoch=634
05/17/2022 12:42:23 - INFO - __main__ - Step 2550 Global step 2550 Train loss 1.29 on epoch=637
05/17/2022 12:42:23 - INFO - __main__ - Global step 2550 Train loss 1.31 Classification-F1 0.13034188034188032 on epoch=637
05/17/2022 12:42:25 - INFO - __main__ - Step 2560 Global step 2560 Train loss 1.21 on epoch=639
05/17/2022 12:42:26 - INFO - __main__ - Step 2570 Global step 2570 Train loss 1.41 on epoch=642
05/17/2022 12:42:27 - INFO - __main__ - Step 2580 Global step 2580 Train loss 1.35 on epoch=644
05/17/2022 12:42:29 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.18 on epoch=647
05/17/2022 12:42:30 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.27 on epoch=649
05/17/2022 12:42:31 - INFO - __main__ - Global step 2600 Train loss 1.28 Classification-F1 0.09090909090909091 on epoch=649
05/17/2022 12:42:32 - INFO - __main__ - Step 2610 Global step 2610 Train loss 1.26 on epoch=652
05/17/2022 12:42:34 - INFO - __main__ - Step 2620 Global step 2620 Train loss 1.22 on epoch=654
05/17/2022 12:42:35 - INFO - __main__ - Step 2630 Global step 2630 Train loss 1.43 on epoch=657
05/17/2022 12:42:36 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.35 on epoch=659
05/17/2022 12:42:38 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.32 on epoch=662
05/17/2022 12:42:38 - INFO - __main__ - Global step 2650 Train loss 1.31 Classification-F1 0.1743014200641319 on epoch=662
05/17/2022 12:42:40 - INFO - __main__ - Step 2660 Global step 2660 Train loss 1.35 on epoch=664
05/17/2022 12:42:42 - INFO - __main__ - Step 2670 Global step 2670 Train loss 1.32 on epoch=667
05/17/2022 12:42:43 - INFO - __main__ - Step 2680 Global step 2680 Train loss 1.36 on epoch=669
05/17/2022 12:42:45 - INFO - __main__ - Step 2690 Global step 2690 Train loss 1.49 on epoch=672
05/17/2022 12:42:46 - INFO - __main__ - Step 2700 Global step 2700 Train loss 1.23 on epoch=674
05/17/2022 12:42:47 - INFO - __main__ - Global step 2700 Train loss 1.35 Classification-F1 0.09615384615384615 on epoch=674
05/17/2022 12:42:48 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.27 on epoch=677
05/17/2022 12:42:50 - INFO - __main__ - Step 2720 Global step 2720 Train loss 1.22 on epoch=679
05/17/2022 12:42:51 - INFO - __main__ - Step 2730 Global step 2730 Train loss 1.36 on epoch=682
05/17/2022 12:42:52 - INFO - __main__ - Step 2740 Global step 2740 Train loss 1.33 on epoch=684
05/17/2022 12:42:54 - INFO - __main__ - Step 2750 Global step 2750 Train loss 1.24 on epoch=687
05/17/2022 12:42:54 - INFO - __main__ - Global step 2750 Train loss 1.28 Classification-F1 0.17142857142857143 on epoch=687
05/17/2022 12:42:56 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.23 on epoch=689
05/17/2022 12:42:57 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.38 on epoch=692
05/17/2022 12:42:58 - INFO - __main__ - Step 2780 Global step 2780 Train loss 1.20 on epoch=694
05/17/2022 12:43:00 - INFO - __main__ - Step 2790 Global step 2790 Train loss 1.26 on epoch=697
05/17/2022 12:43:01 - INFO - __main__ - Step 2800 Global step 2800 Train loss 1.19 on epoch=699
05/17/2022 12:43:02 - INFO - __main__ - Global step 2800 Train loss 1.25 Classification-F1 0.1468058968058968 on epoch=699
05/17/2022 12:43:03 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.28 on epoch=702
05/17/2022 12:43:04 - INFO - __main__ - Step 2820 Global step 2820 Train loss 1.13 on epoch=704
05/17/2022 12:43:06 - INFO - __main__ - Step 2830 Global step 2830 Train loss 1.25 on epoch=707
05/17/2022 12:43:07 - INFO - __main__ - Step 2840 Global step 2840 Train loss 1.28 on epoch=709
05/17/2022 12:43:09 - INFO - __main__ - Step 2850 Global step 2850 Train loss 1.28 on epoch=712
05/17/2022 12:43:09 - INFO - __main__ - Global step 2850 Train loss 1.24 Classification-F1 0.14742690058479532 on epoch=712
05/17/2022 12:43:11 - INFO - __main__ - Step 2860 Global step 2860 Train loss 1.26 on epoch=714
05/17/2022 12:43:12 - INFO - __main__ - Step 2870 Global step 2870 Train loss 1.10 on epoch=717
05/17/2022 12:43:13 - INFO - __main__ - Step 2880 Global step 2880 Train loss 1.11 on epoch=719
05/17/2022 12:43:15 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.21 on epoch=722
05/17/2022 12:43:16 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.20 on epoch=724
05/17/2022 12:43:17 - INFO - __main__ - Global step 2900 Train loss 1.17 Classification-F1 0.2207516339869281 on epoch=724
05/17/2022 12:43:17 - INFO - __main__ - Saving model with best Classification-F1: 0.1767857142857143 -> 0.2207516339869281 on epoch=724, global_step=2900
05/17/2022 12:43:18 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.24 on epoch=727
05/17/2022 12:43:19 - INFO - __main__ - Step 2920 Global step 2920 Train loss 1.15 on epoch=729
05/17/2022 12:43:21 - INFO - __main__ - Step 2930 Global step 2930 Train loss 1.34 on epoch=732
05/17/2022 12:43:22 - INFO - __main__ - Step 2940 Global step 2940 Train loss 1.18 on epoch=734
05/17/2022 12:43:24 - INFO - __main__ - Step 2950 Global step 2950 Train loss 1.39 on epoch=737
05/17/2022 12:43:24 - INFO - __main__ - Global step 2950 Train loss 1.26 Classification-F1 0.16691176470588237 on epoch=737
05/17/2022 12:43:25 - INFO - __main__ - Step 2960 Global step 2960 Train loss 1.29 on epoch=739
05/17/2022 12:43:27 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.11 on epoch=742
05/17/2022 12:43:28 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.14 on epoch=744
05/17/2022 12:43:30 - INFO - __main__ - Step 2990 Global step 2990 Train loss 1.27 on epoch=747
05/17/2022 12:43:31 - INFO - __main__ - Step 3000 Global step 3000 Train loss 1.19 on epoch=749
05/17/2022 12:43:32 - INFO - __main__ - Global step 3000 Train loss 1.20 Classification-F1 0.16883484162895923 on epoch=749
05/17/2022 12:43:32 - INFO - __main__ - save last model!
05/17/2022 12:43:32 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/17/2022 12:43:32 - INFO - __main__ - Start tokenizing ... 5509 instances
05/17/2022 12:43:32 - INFO - __main__ - Printing 3 examples
05/17/2022 12:43:32 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/17/2022 12:43:32 - INFO - __main__ - ['others']
05/17/2022 12:43:32 - INFO - __main__ -  [emo] what you like very little things ok
05/17/2022 12:43:32 - INFO - __main__ - ['others']
05/17/2022 12:43:32 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/17/2022 12:43:32 - INFO - __main__ - ['others']
05/17/2022 12:43:32 - INFO - __main__ - Tokenizing Input ...
05/17/2022 12:43:32 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 12:43:32 - INFO - __main__ - Printing 3 examples
05/17/2022 12:43:32 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
05/17/2022 12:43:32 - INFO - __main__ - ['sad']
05/17/2022 12:43:32 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
05/17/2022 12:43:32 - INFO - __main__ - ['sad']
05/17/2022 12:43:32 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
05/17/2022 12:43:32 - INFO - __main__ - ['sad']
05/17/2022 12:43:32 - INFO - __main__ - Tokenizing Input ...
05/17/2022 12:43:32 - INFO - __main__ - Tokenizing Output ...
05/17/2022 12:43:32 - INFO - __main__ - Loaded 64 examples from train data
05/17/2022 12:43:32 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 12:43:32 - INFO - __main__ - Printing 3 examples
05/17/2022 12:43:32 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
05/17/2022 12:43:32 - INFO - __main__ - ['sad']
05/17/2022 12:43:32 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
05/17/2022 12:43:32 - INFO - __main__ - ['sad']
05/17/2022 12:43:32 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
05/17/2022 12:43:32 - INFO - __main__ - ['sad']
05/17/2022 12:43:32 - INFO - __main__ - Tokenizing Input ...
05/17/2022 12:43:32 - INFO - __main__ - Tokenizing Output ...
05/17/2022 12:43:33 - INFO - __main__ - Loaded 64 examples from dev data
05/17/2022 12:43:35 - INFO - __main__ - Tokenizing Output ...
05/17/2022 12:43:39 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 12:43:40 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 12:43:40 - INFO - __main__ - Starting training!
05/17/2022 12:43:41 - INFO - __main__ - Loaded 5509 examples from test data
05/17/2022 12:44:27 - INFO - __main__ - Saved prediction in models/T5-base-reptile-cls2cls-3e-5-2-5000-5e-1-10/singletask-emo/emo_16_13_0.2_8_predictions.txt
05/17/2022 12:44:27 - INFO - __main__ - Classification-F1 on test data: 0.0442
05/17/2022 12:44:27 - INFO - __main__ - prefix=emo_16_13, lr=0.2, bsz=8, dev_performance=0.2207516339869281, test_performance=0.0441566212691054
05/17/2022 12:44:27 - INFO - __main__ - Running ... prefix=emo_16_21, lr=0.5, bsz=8 ...
05/17/2022 12:44:28 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 12:44:28 - INFO - __main__ - Printing 3 examples
05/17/2022 12:44:28 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
05/17/2022 12:44:28 - INFO - __main__ - ['sad']
05/17/2022 12:44:28 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
05/17/2022 12:44:28 - INFO - __main__ - ['sad']
05/17/2022 12:44:28 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
05/17/2022 12:44:28 - INFO - __main__ - ['sad']
05/17/2022 12:44:28 - INFO - __main__ - Tokenizing Input ...
05/17/2022 12:44:28 - INFO - __main__ - Tokenizing Output ...
05/17/2022 12:44:28 - INFO - __main__ - Loaded 64 examples from train data
05/17/2022 12:44:28 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 12:44:28 - INFO - __main__ - Printing 3 examples
05/17/2022 12:44:28 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
05/17/2022 12:44:28 - INFO - __main__ - ['sad']
05/17/2022 12:44:28 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
05/17/2022 12:44:28 - INFO - __main__ - ['sad']
05/17/2022 12:44:28 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
05/17/2022 12:44:28 - INFO - __main__ - ['sad']
05/17/2022 12:44:28 - INFO - __main__ - Tokenizing Input ...
05/17/2022 12:44:28 - INFO - __main__ - Tokenizing Output ...
05/17/2022 12:44:28 - INFO - __main__ - Loaded 64 examples from dev data
05/17/2022 12:44:34 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 12:44:35 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 12:44:35 - INFO - __main__ - Starting training!
05/17/2022 12:44:36 - INFO - __main__ - Step 10 Global step 10 Train loss 8.73 on epoch=2
05/17/2022 12:44:37 - INFO - __main__ - Step 20 Global step 20 Train loss 8.70 on epoch=4
05/17/2022 12:44:39 - INFO - __main__ - Step 30 Global step 30 Train loss 8.64 on epoch=7
05/17/2022 12:44:40 - INFO - __main__ - Step 40 Global step 40 Train loss 8.60 on epoch=9
05/17/2022 12:44:42 - INFO - __main__ - Step 50 Global step 50 Train loss 8.61 on epoch=12
05/17/2022 12:44:47 - INFO - __main__ - Global step 50 Train loss 8.65 Classification-F1 0.0 on epoch=12
05/17/2022 12:44:47 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/17/2022 12:44:49 - INFO - __main__ - Step 60 Global step 60 Train loss 8.55 on epoch=14
05/17/2022 12:44:50 - INFO - __main__ - Step 70 Global step 70 Train loss 8.34 on epoch=17
05/17/2022 12:44:52 - INFO - __main__ - Step 80 Global step 80 Train loss 8.33 on epoch=19
05/17/2022 12:44:53 - INFO - __main__ - Step 90 Global step 90 Train loss 8.27 on epoch=22
05/17/2022 12:44:54 - INFO - __main__ - Step 100 Global step 100 Train loss 8.10 on epoch=24
05/17/2022 12:45:11 - INFO - __main__ - Global step 100 Train loss 8.32 Classification-F1 0.0 on epoch=24
05/17/2022 12:45:12 - INFO - __main__ - Step 110 Global step 110 Train loss 7.92 on epoch=27
05/17/2022 12:45:13 - INFO - __main__ - Step 120 Global step 120 Train loss 7.76 on epoch=29
05/17/2022 12:45:15 - INFO - __main__ - Step 130 Global step 130 Train loss 7.73 on epoch=32
05/17/2022 12:45:16 - INFO - __main__ - Step 140 Global step 140 Train loss 7.58 on epoch=34
05/17/2022 12:45:18 - INFO - __main__ - Step 150 Global step 150 Train loss 7.51 on epoch=37
05/17/2022 12:45:32 - INFO - __main__ - Global step 150 Train loss 7.70 Classification-F1 0.0 on epoch=37
05/17/2022 12:45:34 - INFO - __main__ - Step 160 Global step 160 Train loss 7.31 on epoch=39
05/17/2022 12:45:35 - INFO - __main__ - Step 170 Global step 170 Train loss 7.38 on epoch=42
05/17/2022 12:45:36 - INFO - __main__ - Step 180 Global step 180 Train loss 7.37 on epoch=44
05/17/2022 12:45:38 - INFO - __main__ - Step 190 Global step 190 Train loss 7.24 on epoch=47
05/17/2022 12:45:39 - INFO - __main__ - Step 200 Global step 200 Train loss 7.18 on epoch=49
05/17/2022 12:45:48 - INFO - __main__ - Global step 200 Train loss 7.30 Classification-F1 0.0 on epoch=49
05/17/2022 12:45:50 - INFO - __main__ - Step 210 Global step 210 Train loss 7.15 on epoch=52
05/17/2022 12:45:51 - INFO - __main__ - Step 220 Global step 220 Train loss 6.86 on epoch=54
05/17/2022 12:45:53 - INFO - __main__ - Step 230 Global step 230 Train loss 6.98 on epoch=57
05/17/2022 12:45:54 - INFO - __main__ - Step 240 Global step 240 Train loss 6.73 on epoch=59
05/17/2022 12:45:55 - INFO - __main__ - Step 250 Global step 250 Train loss 6.86 on epoch=62
05/17/2022 12:46:00 - INFO - __main__ - Global step 250 Train loss 6.92 Classification-F1 0.0 on epoch=62
05/17/2022 12:46:01 - INFO - __main__ - Step 260 Global step 260 Train loss 6.53 on epoch=64
05/17/2022 12:46:02 - INFO - __main__ - Step 270 Global step 270 Train loss 6.44 on epoch=67
05/17/2022 12:46:04 - INFO - __main__ - Step 280 Global step 280 Train loss 5.89 on epoch=69
05/17/2022 12:46:05 - INFO - __main__ - Step 290 Global step 290 Train loss 6.02 on epoch=72
05/17/2022 12:46:07 - INFO - __main__ - Step 300 Global step 300 Train loss 5.75 on epoch=74
05/17/2022 12:46:12 - INFO - __main__ - Global step 300 Train loss 6.13 Classification-F1 0.0 on epoch=74
05/17/2022 12:46:13 - INFO - __main__ - Step 310 Global step 310 Train loss 5.72 on epoch=77
05/17/2022 12:46:14 - INFO - __main__ - Step 320 Global step 320 Train loss 5.69 on epoch=79
05/17/2022 12:46:16 - INFO - __main__ - Step 330 Global step 330 Train loss 5.57 on epoch=82
05/17/2022 12:46:17 - INFO - __main__ - Step 340 Global step 340 Train loss 5.24 on epoch=84
05/17/2022 12:46:19 - INFO - __main__ - Step 350 Global step 350 Train loss 5.44 on epoch=87
05/17/2022 12:46:22 - INFO - __main__ - Global step 350 Train loss 5.53 Classification-F1 0.0 on epoch=87
05/17/2022 12:46:24 - INFO - __main__ - Step 360 Global step 360 Train loss 5.12 on epoch=89
05/17/2022 12:46:25 - INFO - __main__ - Step 370 Global step 370 Train loss 5.35 on epoch=92
05/17/2022 12:46:27 - INFO - __main__ - Step 380 Global step 380 Train loss 5.11 on epoch=94
05/17/2022 12:46:29 - INFO - __main__ - Step 390 Global step 390 Train loss 5.10 on epoch=97
05/17/2022 12:46:30 - INFO - __main__ - Step 400 Global step 400 Train loss 4.84 on epoch=99
05/17/2022 12:46:34 - INFO - __main__ - Global step 400 Train loss 5.10 Classification-F1 0.0 on epoch=99
05/17/2022 12:46:36 - INFO - __main__ - Step 410 Global step 410 Train loss 4.77 on epoch=102
05/17/2022 12:46:37 - INFO - __main__ - Step 420 Global step 420 Train loss 4.55 on epoch=104
05/17/2022 12:46:39 - INFO - __main__ - Step 430 Global step 430 Train loss 4.64 on epoch=107
05/17/2022 12:46:41 - INFO - __main__ - Step 440 Global step 440 Train loss 4.38 on epoch=109
05/17/2022 12:46:42 - INFO - __main__ - Step 450 Global step 450 Train loss 4.36 on epoch=112
05/17/2022 12:46:46 - INFO - __main__ - Global step 450 Train loss 4.54 Classification-F1 0.0 on epoch=112
05/17/2022 12:46:47 - INFO - __main__ - Step 460 Global step 460 Train loss 4.12 on epoch=114
05/17/2022 12:46:49 - INFO - __main__ - Step 470 Global step 470 Train loss 4.25 on epoch=117
05/17/2022 12:46:50 - INFO - __main__ - Step 480 Global step 480 Train loss 4.02 on epoch=119
05/17/2022 12:46:52 - INFO - __main__ - Step 490 Global step 490 Train loss 4.16 on epoch=122
05/17/2022 12:46:53 - INFO - __main__ - Step 500 Global step 500 Train loss 3.82 on epoch=124
05/17/2022 12:46:56 - INFO - __main__ - Global step 500 Train loss 4.07 Classification-F1 0.07999999999999999 on epoch=124
05/17/2022 12:46:56 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.07999999999999999 on epoch=124, global_step=500
05/17/2022 12:46:57 - INFO - __main__ - Step 510 Global step 510 Train loss 3.90 on epoch=127
05/17/2022 12:46:59 - INFO - __main__ - Step 520 Global step 520 Train loss 3.85 on epoch=129
05/17/2022 12:47:00 - INFO - __main__ - Step 530 Global step 530 Train loss 3.95 on epoch=132
05/17/2022 12:47:01 - INFO - __main__ - Step 540 Global step 540 Train loss 3.66 on epoch=134
05/17/2022 12:47:02 - INFO - __main__ - Step 550 Global step 550 Train loss 3.58 on epoch=137
05/17/2022 12:47:04 - INFO - __main__ - Global step 550 Train loss 3.79 Classification-F1 0.12447885646217988 on epoch=137
05/17/2022 12:47:04 - INFO - __main__ - Saving model with best Classification-F1: 0.07999999999999999 -> 0.12447885646217988 on epoch=137, global_step=550
05/17/2022 12:47:05 - INFO - __main__ - Step 560 Global step 560 Train loss 3.34 on epoch=139
05/17/2022 12:47:06 - INFO - __main__ - Step 570 Global step 570 Train loss 3.51 on epoch=142
05/17/2022 12:47:08 - INFO - __main__ - Step 580 Global step 580 Train loss 3.22 on epoch=144
05/17/2022 12:47:09 - INFO - __main__ - Step 590 Global step 590 Train loss 3.42 on epoch=147
05/17/2022 12:47:10 - INFO - __main__ - Step 600 Global step 600 Train loss 3.16 on epoch=149
05/17/2022 12:47:12 - INFO - __main__ - Global step 600 Train loss 3.33 Classification-F1 0.09090909090909091 on epoch=149
05/17/2022 12:47:13 - INFO - __main__ - Step 610 Global step 610 Train loss 3.28 on epoch=152
05/17/2022 12:47:15 - INFO - __main__ - Step 620 Global step 620 Train loss 2.91 on epoch=154
05/17/2022 12:47:16 - INFO - __main__ - Step 630 Global step 630 Train loss 2.90 on epoch=157
05/17/2022 12:47:17 - INFO - __main__ - Step 640 Global step 640 Train loss 2.81 on epoch=159
05/17/2022 12:47:19 - INFO - __main__ - Step 650 Global step 650 Train loss 2.68 on epoch=162
05/17/2022 12:47:19 - INFO - __main__ - Global step 650 Train loss 2.92 Classification-F1 0.12447885646217988 on epoch=162
05/17/2022 12:47:20 - INFO - __main__ - Step 660 Global step 660 Train loss 2.58 on epoch=164
05/17/2022 12:47:22 - INFO - __main__ - Step 670 Global step 670 Train loss 2.56 on epoch=167
05/17/2022 12:47:23 - INFO - __main__ - Step 680 Global step 680 Train loss 2.25 on epoch=169
05/17/2022 12:47:24 - INFO - __main__ - Step 690 Global step 690 Train loss 2.59 on epoch=172
05/17/2022 12:47:26 - INFO - __main__ - Step 700 Global step 700 Train loss 2.39 on epoch=174
05/17/2022 12:47:26 - INFO - __main__ - Global step 700 Train loss 2.47 Classification-F1 0.15550351288056208 on epoch=174
05/17/2022 12:47:26 - INFO - __main__ - Saving model with best Classification-F1: 0.12447885646217988 -> 0.15550351288056208 on epoch=174, global_step=700
05/17/2022 12:47:28 - INFO - __main__ - Step 710 Global step 710 Train loss 2.34 on epoch=177
05/17/2022 12:47:29 - INFO - __main__ - Step 720 Global step 720 Train loss 2.24 on epoch=179
05/17/2022 12:47:31 - INFO - __main__ - Step 730 Global step 730 Train loss 2.05 on epoch=182
05/17/2022 12:47:32 - INFO - __main__ - Step 740 Global step 740 Train loss 2.12 on epoch=184
05/17/2022 12:47:33 - INFO - __main__ - Step 750 Global step 750 Train loss 1.85 on epoch=187
05/17/2022 12:47:34 - INFO - __main__ - Global step 750 Train loss 2.12 Classification-F1 0.1 on epoch=187
05/17/2022 12:47:36 - INFO - __main__ - Step 760 Global step 760 Train loss 1.76 on epoch=189
05/17/2022 12:47:37 - INFO - __main__ - Step 770 Global step 770 Train loss 1.86 on epoch=192
05/17/2022 12:47:38 - INFO - __main__ - Step 780 Global step 780 Train loss 1.52 on epoch=194
05/17/2022 12:47:40 - INFO - __main__ - Step 790 Global step 790 Train loss 1.57 on epoch=197
05/17/2022 12:47:41 - INFO - __main__ - Step 800 Global step 800 Train loss 1.46 on epoch=199
05/17/2022 12:47:42 - INFO - __main__ - Global step 800 Train loss 1.63 Classification-F1 0.18859649122807015 on epoch=199
05/17/2022 12:47:42 - INFO - __main__ - Saving model with best Classification-F1: 0.15550351288056208 -> 0.18859649122807015 on epoch=199, global_step=800
05/17/2022 12:47:43 - INFO - __main__ - Step 810 Global step 810 Train loss 1.65 on epoch=202
05/17/2022 12:47:44 - INFO - __main__ - Step 820 Global step 820 Train loss 1.47 on epoch=204
05/17/2022 12:47:46 - INFO - __main__ - Step 830 Global step 830 Train loss 1.52 on epoch=207
05/17/2022 12:47:47 - INFO - __main__ - Step 840 Global step 840 Train loss 1.66 on epoch=209
05/17/2022 12:47:49 - INFO - __main__ - Step 850 Global step 850 Train loss 1.48 on epoch=212
05/17/2022 12:47:49 - INFO - __main__ - Global step 850 Train loss 1.55 Classification-F1 0.20869565217391306 on epoch=212
05/17/2022 12:47:49 - INFO - __main__ - Saving model with best Classification-F1: 0.18859649122807015 -> 0.20869565217391306 on epoch=212, global_step=850
05/17/2022 12:47:51 - INFO - __main__ - Step 860 Global step 860 Train loss 1.35 on epoch=214
05/17/2022 12:47:52 - INFO - __main__ - Step 870 Global step 870 Train loss 1.41 on epoch=217
05/17/2022 12:47:53 - INFO - __main__ - Step 880 Global step 880 Train loss 1.41 on epoch=219
05/17/2022 12:47:55 - INFO - __main__ - Step 890 Global step 890 Train loss 1.47 on epoch=222
05/17/2022 12:47:56 - INFO - __main__ - Step 900 Global step 900 Train loss 1.45 on epoch=224
05/17/2022 12:47:56 - INFO - __main__ - Global step 900 Train loss 1.42 Classification-F1 0.14621798689696247 on epoch=224
05/17/2022 12:47:58 - INFO - __main__ - Step 910 Global step 910 Train loss 1.47 on epoch=227
05/17/2022 12:47:59 - INFO - __main__ - Step 920 Global step 920 Train loss 1.23 on epoch=229
05/17/2022 12:48:00 - INFO - __main__ - Step 930 Global step 930 Train loss 1.40 on epoch=232
05/17/2022 12:48:02 - INFO - __main__ - Step 940 Global step 940 Train loss 1.17 on epoch=234
05/17/2022 12:48:03 - INFO - __main__ - Step 950 Global step 950 Train loss 1.24 on epoch=237
05/17/2022 12:48:04 - INFO - __main__ - Global step 950 Train loss 1.30 Classification-F1 0.1 on epoch=237
05/17/2022 12:48:05 - INFO - __main__ - Step 960 Global step 960 Train loss 1.37 on epoch=239
05/17/2022 12:48:07 - INFO - __main__ - Step 970 Global step 970 Train loss 1.33 on epoch=242
05/17/2022 12:48:08 - INFO - __main__ - Step 980 Global step 980 Train loss 1.36 on epoch=244
05/17/2022 12:48:09 - INFO - __main__ - Step 990 Global step 990 Train loss 1.23 on epoch=247
05/17/2022 12:48:11 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.21 on epoch=249
05/17/2022 12:48:11 - INFO - __main__ - Global step 1000 Train loss 1.30 Classification-F1 0.10126582278481013 on epoch=249
05/17/2022 12:48:13 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.21 on epoch=252
05/17/2022 12:48:14 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.28 on epoch=254
05/17/2022 12:48:15 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.17 on epoch=257
05/17/2022 12:48:17 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.32 on epoch=259
05/17/2022 12:48:18 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.24 on epoch=262
05/17/2022 12:48:18 - INFO - __main__ - Global step 1050 Train loss 1.24 Classification-F1 0.13067758749069247 on epoch=262
05/17/2022 12:48:20 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.20 on epoch=264
05/17/2022 12:48:21 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.21 on epoch=267
05/17/2022 12:48:23 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.19 on epoch=269
05/17/2022 12:48:24 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.22 on epoch=272
05/17/2022 12:48:25 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.17 on epoch=274
05/17/2022 12:48:26 - INFO - __main__ - Global step 1100 Train loss 1.20 Classification-F1 0.18955682316805617 on epoch=274
05/17/2022 12:48:27 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.20 on epoch=277
05/17/2022 12:48:29 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.20 on epoch=279
05/17/2022 12:48:30 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.09 on epoch=282
05/17/2022 12:48:31 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.11 on epoch=284
05/17/2022 12:48:33 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.22 on epoch=287
05/17/2022 12:48:33 - INFO - __main__ - Global step 1150 Train loss 1.17 Classification-F1 0.1 on epoch=287
05/17/2022 12:48:35 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.19 on epoch=289
05/17/2022 12:48:36 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.20 on epoch=292
05/17/2022 12:48:37 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.16 on epoch=294
05/17/2022 12:48:39 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.15 on epoch=297
05/17/2022 12:48:40 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.12 on epoch=299
05/17/2022 12:48:41 - INFO - __main__ - Global step 1200 Train loss 1.16 Classification-F1 0.14350945857795172 on epoch=299
05/17/2022 12:48:42 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.13 on epoch=302
05/17/2022 12:48:43 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.08 on epoch=304
05/17/2022 12:48:45 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.25 on epoch=307
05/17/2022 12:48:46 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.18 on epoch=309
05/17/2022 12:48:47 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.20 on epoch=312
05/17/2022 12:48:48 - INFO - __main__ - Global step 1250 Train loss 1.17 Classification-F1 0.1 on epoch=312
05/17/2022 12:48:49 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.09 on epoch=314
05/17/2022 12:48:50 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.06 on epoch=317
05/17/2022 12:48:52 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.14 on epoch=319
05/17/2022 12:48:53 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.20 on epoch=322
05/17/2022 12:48:54 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.07 on epoch=324
05/17/2022 12:48:55 - INFO - __main__ - Global step 1300 Train loss 1.11 Classification-F1 0.1 on epoch=324
05/17/2022 12:48:56 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.00 on epoch=327
05/17/2022 12:48:58 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.09 on epoch=329
05/17/2022 12:48:59 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.23 on epoch=332
05/17/2022 12:49:00 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.13 on epoch=334
05/17/2022 12:49:02 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.07 on epoch=337
05/17/2022 12:49:02 - INFO - __main__ - Global step 1350 Train loss 1.11 Classification-F1 0.1 on epoch=337
05/17/2022 12:49:04 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.13 on epoch=339
05/17/2022 12:49:05 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.02 on epoch=342
05/17/2022 12:49:06 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.15 on epoch=344
05/17/2022 12:49:08 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.09 on epoch=347
05/17/2022 12:49:09 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.02 on epoch=349
05/17/2022 12:49:09 - INFO - __main__ - Global step 1400 Train loss 1.08 Classification-F1 0.11923076923076922 on epoch=349
05/17/2022 12:49:11 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.96 on epoch=352
05/17/2022 12:49:12 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.07 on epoch=354
05/17/2022 12:49:13 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.12 on epoch=357
05/17/2022 12:49:15 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.18 on epoch=359
05/17/2022 12:49:16 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.08 on epoch=362
05/17/2022 12:49:17 - INFO - __main__ - Global step 1450 Train loss 1.08 Classification-F1 0.1 on epoch=362
05/17/2022 12:49:18 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.03 on epoch=364
05/17/2022 12:49:19 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.07 on epoch=367
05/17/2022 12:49:21 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.99 on epoch=369
05/17/2022 12:49:22 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.11 on epoch=372
05/17/2022 12:49:23 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.08 on epoch=374
05/17/2022 12:49:24 - INFO - __main__ - Global step 1500 Train loss 1.06 Classification-F1 0.1529790660225443 on epoch=374
05/17/2022 12:49:25 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.00 on epoch=377
05/17/2022 12:49:27 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.00 on epoch=379
05/17/2022 12:49:28 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.09 on epoch=382
05/17/2022 12:49:29 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.04 on epoch=384
05/17/2022 12:49:31 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.04 on epoch=387
05/17/2022 12:49:31 - INFO - __main__ - Global step 1550 Train loss 1.04 Classification-F1 0.1 on epoch=387
05/17/2022 12:49:33 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.08 on epoch=389
05/17/2022 12:49:34 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.04 on epoch=392
05/17/2022 12:49:35 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.98 on epoch=394
05/17/2022 12:49:37 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.00 on epoch=397
05/17/2022 12:49:38 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.02 on epoch=399
05/17/2022 12:49:39 - INFO - __main__ - Global step 1600 Train loss 1.02 Classification-F1 0.1 on epoch=399
05/17/2022 12:49:40 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.08 on epoch=402
05/17/2022 12:49:41 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.97 on epoch=404
05/17/2022 12:49:43 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.98 on epoch=407
05/17/2022 12:49:44 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.04 on epoch=409
05/17/2022 12:49:45 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.08 on epoch=412
05/17/2022 12:49:46 - INFO - __main__ - Global step 1650 Train loss 1.03 Classification-F1 0.1 on epoch=412
05/17/2022 12:49:47 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.04 on epoch=414
05/17/2022 12:49:48 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.06 on epoch=417
05/17/2022 12:49:50 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.09 on epoch=419
05/17/2022 12:49:51 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.94 on epoch=422
05/17/2022 12:49:52 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.98 on epoch=424
05/17/2022 12:49:53 - INFO - __main__ - Global step 1700 Train loss 1.02 Classification-F1 0.170995670995671 on epoch=424
05/17/2022 12:49:54 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.03 on epoch=427
05/17/2022 12:49:55 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.95 on epoch=429
05/17/2022 12:49:57 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.98 on epoch=432
05/17/2022 12:49:58 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.89 on epoch=434
05/17/2022 12:50:00 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.96 on epoch=437
05/17/2022 12:50:00 - INFO - __main__ - Global step 1750 Train loss 0.96 Classification-F1 0.1 on epoch=437
05/17/2022 12:50:01 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.06 on epoch=439
05/17/2022 12:50:03 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.08 on epoch=442
05/17/2022 12:50:04 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.96 on epoch=444
05/17/2022 12:50:06 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.96 on epoch=447
05/17/2022 12:50:07 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.04 on epoch=449
05/17/2022 12:50:07 - INFO - __main__ - Global step 1800 Train loss 1.02 Classification-F1 0.11208791208791208 on epoch=449
05/17/2022 12:50:09 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.90 on epoch=452
05/17/2022 12:50:10 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.00 on epoch=454
05/17/2022 12:50:11 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.06 on epoch=457
05/17/2022 12:50:13 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.03 on epoch=459
05/17/2022 12:50:14 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.05 on epoch=462
05/17/2022 12:50:15 - INFO - __main__ - Global step 1850 Train loss 1.01 Classification-F1 0.1458966565349544 on epoch=462
05/17/2022 12:50:16 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.02 on epoch=464
05/17/2022 12:50:17 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.95 on epoch=467
05/17/2022 12:50:18 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.89 on epoch=469
05/17/2022 12:50:20 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.94 on epoch=472
05/17/2022 12:50:21 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.28 on epoch=474
05/17/2022 12:50:22 - INFO - __main__ - Global step 1900 Train loss 1.02 Classification-F1 0.10256410256410256 on epoch=474
05/17/2022 12:50:23 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.17 on epoch=477
05/17/2022 12:50:24 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.97 on epoch=479
05/17/2022 12:50:26 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.05 on epoch=482
05/17/2022 12:50:27 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.98 on epoch=484
05/17/2022 12:50:28 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.95 on epoch=487
05/17/2022 12:50:29 - INFO - __main__ - Global step 1950 Train loss 1.02 Classification-F1 0.1 on epoch=487
05/17/2022 12:50:30 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.05 on epoch=489
05/17/2022 12:50:32 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.29 on epoch=492
05/17/2022 12:50:33 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.24 on epoch=494
05/17/2022 12:50:34 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.15 on epoch=497
05/17/2022 12:50:35 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.10 on epoch=499
05/17/2022 12:50:36 - INFO - __main__ - Global step 2000 Train loss 1.17 Classification-F1 0.2563372941421722 on epoch=499
05/17/2022 12:50:36 - INFO - __main__ - Saving model with best Classification-F1: 0.20869565217391306 -> 0.2563372941421722 on epoch=499, global_step=2000
05/17/2022 12:50:37 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.05 on epoch=502
05/17/2022 12:50:39 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.03 on epoch=504
05/17/2022 12:50:40 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.04 on epoch=507
05/17/2022 12:50:41 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.03 on epoch=509
05/17/2022 12:50:43 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.01 on epoch=512
05/17/2022 12:50:43 - INFO - __main__ - Global step 2050 Train loss 1.03 Classification-F1 0.1 on epoch=512
05/17/2022 12:50:44 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.11 on epoch=514
05/17/2022 12:50:46 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.09 on epoch=517
05/17/2022 12:50:47 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.96 on epoch=519
05/17/2022 12:50:49 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.08 on epoch=522
05/17/2022 12:50:50 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.98 on epoch=524
05/17/2022 12:50:50 - INFO - __main__ - Global step 2100 Train loss 1.04 Classification-F1 0.12407862407862408 on epoch=524
05/17/2022 12:50:52 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.95 on epoch=527
05/17/2022 12:50:53 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.04 on epoch=529
05/17/2022 12:50:54 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.99 on epoch=532
05/17/2022 12:50:55 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.91 on epoch=534
05/17/2022 12:50:57 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.03 on epoch=537
05/17/2022 12:50:57 - INFO - __main__ - Global step 2150 Train loss 0.98 Classification-F1 0.1 on epoch=537
05/17/2022 12:50:59 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.02 on epoch=539
05/17/2022 12:51:00 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.98 on epoch=542
05/17/2022 12:51:01 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.00 on epoch=544
05/17/2022 12:51:03 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.13 on epoch=547
05/17/2022 12:51:04 - INFO - __main__ - Step 2200 Global step 2200 Train loss 1.10 on epoch=549
05/17/2022 12:51:05 - INFO - __main__ - Global step 2200 Train loss 1.05 Classification-F1 0.1 on epoch=549
05/17/2022 12:51:06 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.13 on epoch=552
05/17/2022 12:51:07 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.01 on epoch=554
05/17/2022 12:51:09 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.04 on epoch=557
05/17/2022 12:51:10 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.95 on epoch=559
05/17/2022 12:51:11 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.95 on epoch=562
05/17/2022 12:51:12 - INFO - __main__ - Global step 2250 Train loss 1.01 Classification-F1 0.10256410256410256 on epoch=562
05/17/2022 12:51:13 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.99 on epoch=564
05/17/2022 12:51:15 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.00 on epoch=567
05/17/2022 12:51:16 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.03 on epoch=569
05/17/2022 12:51:17 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.01 on epoch=572
05/17/2022 12:51:19 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.93 on epoch=574
05/17/2022 12:51:19 - INFO - __main__ - Global step 2300 Train loss 0.99 Classification-F1 0.1095890410958904 on epoch=574
05/17/2022 12:51:21 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.96 on epoch=577
05/17/2022 12:51:22 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.94 on epoch=579
05/17/2022 12:51:24 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.97 on epoch=582
05/17/2022 12:51:25 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.99 on epoch=584
05/17/2022 12:51:27 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.90 on epoch=587
05/17/2022 12:51:27 - INFO - __main__ - Global step 2350 Train loss 0.95 Classification-F1 0.1565126050420168 on epoch=587
05/17/2022 12:51:29 - INFO - __main__ - Step 2360 Global step 2360 Train loss 1.07 on epoch=589
05/17/2022 12:51:30 - INFO - __main__ - Step 2370 Global step 2370 Train loss 1.00 on epoch=592
05/17/2022 12:51:32 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.96 on epoch=594
05/17/2022 12:51:34 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.99 on epoch=597
05/17/2022 12:51:35 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.99 on epoch=599
05/17/2022 12:51:36 - INFO - __main__ - Global step 2400 Train loss 1.00 Classification-F1 0.13275613275613274 on epoch=599
05/17/2022 12:51:37 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.07 on epoch=602
05/17/2022 12:51:39 - INFO - __main__ - Step 2420 Global step 2420 Train loss 1.04 on epoch=604
05/17/2022 12:51:40 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.89 on epoch=607
05/17/2022 12:51:42 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.98 on epoch=609
05/17/2022 12:51:43 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.87 on epoch=612
05/17/2022 12:51:44 - INFO - __main__ - Global step 2450 Train loss 0.97 Classification-F1 0.09090909090909091 on epoch=612
05/17/2022 12:51:45 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.88 on epoch=614
05/17/2022 12:51:46 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.97 on epoch=617
05/17/2022 12:51:48 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.88 on epoch=619
05/17/2022 12:51:49 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.00 on epoch=622
05/17/2022 12:51:51 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.99 on epoch=624
05/17/2022 12:51:52 - INFO - __main__ - Global step 2500 Train loss 0.95 Classification-F1 0.09999999999999999 on epoch=624
05/17/2022 12:51:53 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.96 on epoch=627
05/17/2022 12:51:54 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.95 on epoch=629
05/17/2022 12:51:56 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.95 on epoch=632
05/17/2022 12:51:57 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.92 on epoch=634
05/17/2022 12:51:59 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.93 on epoch=637
05/17/2022 12:51:59 - INFO - __main__ - Global step 2550 Train loss 0.94 Classification-F1 0.11666666666666667 on epoch=637
05/17/2022 12:52:00 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.90 on epoch=639
05/17/2022 12:52:02 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.93 on epoch=642
05/17/2022 12:52:03 - INFO - __main__ - Step 2580 Global step 2580 Train loss 1.00 on epoch=644
05/17/2022 12:52:05 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.02 on epoch=647
05/17/2022 12:52:06 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.86 on epoch=649
05/17/2022 12:52:06 - INFO - __main__ - Global step 2600 Train loss 0.94 Classification-F1 0.11330409356725146 on epoch=649
05/17/2022 12:52:08 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.95 on epoch=652
05/17/2022 12:52:09 - INFO - __main__ - Step 2620 Global step 2620 Train loss 1.02 on epoch=654
05/17/2022 12:52:10 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.93 on epoch=657
05/17/2022 12:52:12 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.94 on epoch=659
05/17/2022 12:52:13 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.03 on epoch=662
05/17/2022 12:52:14 - INFO - __main__ - Global step 2650 Train loss 0.98 Classification-F1 0.1 on epoch=662
05/17/2022 12:52:15 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.90 on epoch=664
05/17/2022 12:52:16 - INFO - __main__ - Step 2670 Global step 2670 Train loss 1.04 on epoch=667
05/17/2022 12:52:18 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.99 on epoch=669
05/17/2022 12:52:19 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.89 on epoch=672
05/17/2022 12:52:20 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.98 on epoch=674
05/17/2022 12:52:21 - INFO - __main__ - Global step 2700 Train loss 0.96 Classification-F1 0.15897435897435896 on epoch=674
05/17/2022 12:52:22 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.92 on epoch=677
05/17/2022 12:52:23 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.99 on epoch=679
05/17/2022 12:52:25 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.94 on epoch=682
05/17/2022 12:52:26 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.88 on epoch=684
05/17/2022 12:52:27 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.94 on epoch=687
05/17/2022 12:52:28 - INFO - __main__ - Global step 2750 Train loss 0.93 Classification-F1 0.18679549114331723 on epoch=687
05/17/2022 12:52:29 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.88 on epoch=689
05/17/2022 12:52:31 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.97 on epoch=692
05/17/2022 12:52:32 - INFO - __main__ - Step 2780 Global step 2780 Train loss 1.10 on epoch=694
05/17/2022 12:52:33 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.97 on epoch=697
05/17/2022 12:52:35 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.89 on epoch=699
05/17/2022 12:52:35 - INFO - __main__ - Global step 2800 Train loss 0.96 Classification-F1 0.12407862407862408 on epoch=699
05/17/2022 12:52:37 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.90 on epoch=702
05/17/2022 12:52:38 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.86 on epoch=704
05/17/2022 12:52:39 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.89 on epoch=707
05/17/2022 12:52:40 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.97 on epoch=709
05/17/2022 12:52:42 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.86 on epoch=712
05/17/2022 12:52:42 - INFO - __main__ - Global step 2850 Train loss 0.90 Classification-F1 0.13130252100840337 on epoch=712
05/17/2022 12:52:44 - INFO - __main__ - Step 2860 Global step 2860 Train loss 1.00 on epoch=714
05/17/2022 12:52:45 - INFO - __main__ - Step 2870 Global step 2870 Train loss 1.00 on epoch=717
05/17/2022 12:52:46 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.99 on epoch=719
05/17/2022 12:52:48 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.97 on epoch=722
05/17/2022 12:52:49 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.88 on epoch=724
05/17/2022 12:52:49 - INFO - __main__ - Global step 2900 Train loss 0.97 Classification-F1 0.1238095238095238 on epoch=724
05/17/2022 12:52:51 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.90 on epoch=727
05/17/2022 12:52:52 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.95 on epoch=729
05/17/2022 12:52:53 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.96 on epoch=732
05/17/2022 12:52:55 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.89 on epoch=734
05/17/2022 12:52:56 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.99 on epoch=737
05/17/2022 12:52:57 - INFO - __main__ - Global step 2950 Train loss 0.94 Classification-F1 0.17573529411764705 on epoch=737
05/17/2022 12:52:58 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.94 on epoch=739
05/17/2022 12:52:59 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.97 on epoch=742
05/17/2022 12:53:01 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.94 on epoch=744
05/17/2022 12:53:02 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.95 on epoch=747
05/17/2022 12:53:03 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.90 on epoch=749
05/17/2022 12:53:04 - INFO - __main__ - Global step 3000 Train loss 0.94 Classification-F1 0.1 on epoch=749
05/17/2022 12:53:04 - INFO - __main__ - save last model!
05/17/2022 12:53:04 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/17/2022 12:53:04 - INFO - __main__ - Start tokenizing ... 5509 instances
05/17/2022 12:53:04 - INFO - __main__ - Printing 3 examples
05/17/2022 12:53:04 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/17/2022 12:53:04 - INFO - __main__ - ['others']
05/17/2022 12:53:04 - INFO - __main__ -  [emo] what you like very little things ok
05/17/2022 12:53:04 - INFO - __main__ - ['others']
05/17/2022 12:53:04 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/17/2022 12:53:04 - INFO - __main__ - ['others']
05/17/2022 12:53:04 - INFO - __main__ - Tokenizing Input ...
05/17/2022 12:53:04 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 12:53:04 - INFO - __main__ - Printing 3 examples
05/17/2022 12:53:04 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
05/17/2022 12:53:04 - INFO - __main__ - ['sad']
05/17/2022 12:53:04 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
05/17/2022 12:53:04 - INFO - __main__ - ['sad']
05/17/2022 12:53:04 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
05/17/2022 12:53:04 - INFO - __main__ - ['sad']
05/17/2022 12:53:04 - INFO - __main__ - Tokenizing Input ...
05/17/2022 12:53:04 - INFO - __main__ - Tokenizing Output ...
05/17/2022 12:53:05 - INFO - __main__ - Loaded 64 examples from train data
05/17/2022 12:53:05 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 12:53:05 - INFO - __main__ - Printing 3 examples
05/17/2022 12:53:05 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
05/17/2022 12:53:05 - INFO - __main__ - ['sad']
05/17/2022 12:53:05 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
05/17/2022 12:53:05 - INFO - __main__ - ['sad']
05/17/2022 12:53:05 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
05/17/2022 12:53:05 - INFO - __main__ - ['sad']
05/17/2022 12:53:05 - INFO - __main__ - Tokenizing Input ...
05/17/2022 12:53:05 - INFO - __main__ - Tokenizing Output ...
05/17/2022 12:53:05 - INFO - __main__ - Loaded 64 examples from dev data
05/17/2022 12:53:06 - INFO - __main__ - Tokenizing Output ...
05/17/2022 12:53:11 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 12:53:11 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 12:53:11 - INFO - __main__ - Starting training!
05/17/2022 12:53:11 - INFO - __main__ - Loaded 5509 examples from test data
05/17/2022 12:53:56 - INFO - __main__ - Saved prediction in models/T5-base-reptile-cls2cls-3e-5-2-5000-5e-1-10/singletask-emo/emo_16_21_0.5_8_predictions.txt
05/17/2022 12:53:56 - INFO - __main__ - Classification-F1 on test data: 0.0216
05/17/2022 12:53:56 - INFO - __main__ - prefix=emo_16_21, lr=0.5, bsz=8, dev_performance=0.2563372941421722, test_performance=0.021644645340751043
05/17/2022 12:53:56 - INFO - __main__ - Running ... prefix=emo_16_21, lr=0.4, bsz=8 ...
05/17/2022 12:53:57 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 12:53:57 - INFO - __main__ - Printing 3 examples
05/17/2022 12:53:57 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
05/17/2022 12:53:57 - INFO - __main__ - ['sad']
05/17/2022 12:53:57 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
05/17/2022 12:53:57 - INFO - __main__ - ['sad']
05/17/2022 12:53:57 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
05/17/2022 12:53:57 - INFO - __main__ - ['sad']
05/17/2022 12:53:57 - INFO - __main__ - Tokenizing Input ...
05/17/2022 12:53:57 - INFO - __main__ - Tokenizing Output ...
05/17/2022 12:53:57 - INFO - __main__ - Loaded 64 examples from train data
05/17/2022 12:53:57 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 12:53:57 - INFO - __main__ - Printing 3 examples
05/17/2022 12:53:57 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
05/17/2022 12:53:57 - INFO - __main__ - ['sad']
05/17/2022 12:53:57 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
05/17/2022 12:53:57 - INFO - __main__ - ['sad']
05/17/2022 12:53:57 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
05/17/2022 12:53:57 - INFO - __main__ - ['sad']
05/17/2022 12:53:57 - INFO - __main__ - Tokenizing Input ...
05/17/2022 12:53:57 - INFO - __main__ - Tokenizing Output ...
05/17/2022 12:53:57 - INFO - __main__ - Loaded 64 examples from dev data
05/17/2022 12:54:03 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 12:54:03 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 12:54:03 - INFO - __main__ - Starting training!
05/17/2022 12:54:05 - INFO - __main__ - Step 10 Global step 10 Train loss 8.76 on epoch=2
05/17/2022 12:54:06 - INFO - __main__ - Step 20 Global step 20 Train loss 8.69 on epoch=4
05/17/2022 12:54:08 - INFO - __main__ - Step 30 Global step 30 Train loss 8.64 on epoch=7
05/17/2022 12:54:09 - INFO - __main__ - Step 40 Global step 40 Train loss 8.71 on epoch=9
05/17/2022 12:54:10 - INFO - __main__ - Step 50 Global step 50 Train loss 8.57 on epoch=12
05/17/2022 12:54:19 - INFO - __main__ - Global step 50 Train loss 8.68 Classification-F1 0.0 on epoch=12
05/17/2022 12:54:19 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/17/2022 12:54:20 - INFO - __main__ - Step 60 Global step 60 Train loss 8.55 on epoch=14
05/17/2022 12:54:22 - INFO - __main__ - Step 70 Global step 70 Train loss 8.42 on epoch=17
05/17/2022 12:54:23 - INFO - __main__ - Step 80 Global step 80 Train loss 8.39 on epoch=19
05/17/2022 12:54:24 - INFO - __main__ - Step 90 Global step 90 Train loss 8.43 on epoch=22
05/17/2022 12:54:26 - INFO - __main__ - Step 100 Global step 100 Train loss 8.32 on epoch=24
05/17/2022 12:54:33 - INFO - __main__ - Global step 100 Train loss 8.42 Classification-F1 0.0 on epoch=24
05/17/2022 12:54:34 - INFO - __main__ - Step 110 Global step 110 Train loss 8.24 on epoch=27
05/17/2022 12:54:36 - INFO - __main__ - Step 120 Global step 120 Train loss 8.28 on epoch=29
05/17/2022 12:54:37 - INFO - __main__ - Step 130 Global step 130 Train loss 8.05 on epoch=32
05/17/2022 12:54:39 - INFO - __main__ - Step 140 Global step 140 Train loss 8.18 on epoch=34
05/17/2022 12:54:40 - INFO - __main__ - Step 150 Global step 150 Train loss 7.95 on epoch=37
05/17/2022 12:54:56 - INFO - __main__ - Global step 150 Train loss 8.14 Classification-F1 0.0 on epoch=37
05/17/2022 12:54:57 - INFO - __main__ - Step 160 Global step 160 Train loss 7.95 on epoch=39
05/17/2022 12:54:58 - INFO - __main__ - Step 170 Global step 170 Train loss 7.92 on epoch=42
05/17/2022 12:55:00 - INFO - __main__ - Step 180 Global step 180 Train loss 7.93 on epoch=44
05/17/2022 12:55:01 - INFO - __main__ - Step 190 Global step 190 Train loss 7.79 on epoch=47
05/17/2022 12:55:03 - INFO - __main__ - Step 200 Global step 200 Train loss 7.73 on epoch=49
05/17/2022 12:55:14 - INFO - __main__ - Global step 200 Train loss 7.86 Classification-F1 0.0 on epoch=49
05/17/2022 12:55:16 - INFO - __main__ - Step 210 Global step 210 Train loss 7.73 on epoch=52
05/17/2022 12:55:17 - INFO - __main__ - Step 220 Global step 220 Train loss 7.50 on epoch=54
05/17/2022 12:55:18 - INFO - __main__ - Step 230 Global step 230 Train loss 7.47 on epoch=57
05/17/2022 12:55:20 - INFO - __main__ - Step 240 Global step 240 Train loss 7.31 on epoch=59
05/17/2022 12:55:21 - INFO - __main__ - Step 250 Global step 250 Train loss 7.33 on epoch=62
05/17/2022 12:55:27 - INFO - __main__ - Global step 250 Train loss 7.47 Classification-F1 0.0 on epoch=62
05/17/2022 12:55:29 - INFO - __main__ - Step 260 Global step 260 Train loss 7.17 on epoch=64
05/17/2022 12:55:30 - INFO - __main__ - Step 270 Global step 270 Train loss 7.17 on epoch=67
05/17/2022 12:55:32 - INFO - __main__ - Step 280 Global step 280 Train loss 6.95 on epoch=69
05/17/2022 12:55:33 - INFO - __main__ - Step 290 Global step 290 Train loss 7.00 on epoch=72
05/17/2022 12:55:34 - INFO - __main__ - Step 300 Global step 300 Train loss 6.85 on epoch=74
05/17/2022 12:55:47 - INFO - __main__ - Global step 300 Train loss 7.03 Classification-F1 0.0 on epoch=74
05/17/2022 12:55:48 - INFO - __main__ - Step 310 Global step 310 Train loss 6.74 on epoch=77
05/17/2022 12:55:50 - INFO - __main__ - Step 320 Global step 320 Train loss 6.64 on epoch=79
05/17/2022 12:55:51 - INFO - __main__ - Step 330 Global step 330 Train loss 6.70 on epoch=82
05/17/2022 12:55:52 - INFO - __main__ - Step 340 Global step 340 Train loss 6.40 on epoch=84
05/17/2022 12:55:54 - INFO - __main__ - Step 350 Global step 350 Train loss 6.59 on epoch=87
05/17/2022 12:56:00 - INFO - __main__ - Global step 350 Train loss 6.61 Classification-F1 0.0 on epoch=87
05/17/2022 12:56:01 - INFO - __main__ - Step 360 Global step 360 Train loss 6.40 on epoch=89
05/17/2022 12:56:02 - INFO - __main__ - Step 370 Global step 370 Train loss 6.33 on epoch=92
05/17/2022 12:56:04 - INFO - __main__ - Step 380 Global step 380 Train loss 6.11 on epoch=94
05/17/2022 12:56:05 - INFO - __main__ - Step 390 Global step 390 Train loss 6.18 on epoch=97
05/17/2022 12:56:07 - INFO - __main__ - Step 400 Global step 400 Train loss 6.09 on epoch=99
05/17/2022 12:56:13 - INFO - __main__ - Global step 400 Train loss 6.22 Classification-F1 0.0 on epoch=99
05/17/2022 12:56:15 - INFO - __main__ - Step 410 Global step 410 Train loss 5.99 on epoch=102
05/17/2022 12:56:16 - INFO - __main__ - Step 420 Global step 420 Train loss 5.79 on epoch=104
05/17/2022 12:56:18 - INFO - __main__ - Step 430 Global step 430 Train loss 5.82 on epoch=107
05/17/2022 12:56:19 - INFO - __main__ - Step 440 Global step 440 Train loss 5.60 on epoch=109
05/17/2022 12:56:20 - INFO - __main__ - Step 450 Global step 450 Train loss 5.57 on epoch=112
05/17/2022 12:56:25 - INFO - __main__ - Global step 450 Train loss 5.75 Classification-F1 0.0 on epoch=112
05/17/2022 12:56:26 - INFO - __main__ - Step 460 Global step 460 Train loss 5.48 on epoch=114
05/17/2022 12:56:27 - INFO - __main__ - Step 470 Global step 470 Train loss 5.35 on epoch=117
05/17/2022 12:56:29 - INFO - __main__ - Step 480 Global step 480 Train loss 4.97 on epoch=119
05/17/2022 12:56:30 - INFO - __main__ - Step 490 Global step 490 Train loss 5.00 on epoch=122
05/17/2022 12:56:32 - INFO - __main__ - Step 500 Global step 500 Train loss 5.05 on epoch=124
05/17/2022 12:56:39 - INFO - __main__ - Global step 500 Train loss 5.17 Classification-F1 0.0 on epoch=124
05/17/2022 12:56:40 - INFO - __main__ - Step 510 Global step 510 Train loss 5.03 on epoch=127
05/17/2022 12:56:42 - INFO - __main__ - Step 520 Global step 520 Train loss 4.75 on epoch=129
05/17/2022 12:56:43 - INFO - __main__ - Step 530 Global step 530 Train loss 4.58 on epoch=132
05/17/2022 12:56:45 - INFO - __main__ - Step 540 Global step 540 Train loss 4.48 on epoch=134
05/17/2022 12:56:46 - INFO - __main__ - Step 550 Global step 550 Train loss 4.54 on epoch=137
05/17/2022 12:56:48 - INFO - __main__ - Global step 550 Train loss 4.68 Classification-F1 0.07692307692307691 on epoch=137
05/17/2022 12:56:48 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.07692307692307691 on epoch=137, global_step=550
05/17/2022 12:56:50 - INFO - __main__ - Step 560 Global step 560 Train loss 4.19 on epoch=139
05/17/2022 12:56:51 - INFO - __main__ - Step 570 Global step 570 Train loss 4.28 on epoch=142
05/17/2022 12:56:52 - INFO - __main__ - Step 580 Global step 580 Train loss 4.17 on epoch=144
05/17/2022 12:56:54 - INFO - __main__ - Step 590 Global step 590 Train loss 4.08 on epoch=147
05/17/2022 12:56:55 - INFO - __main__ - Step 600 Global step 600 Train loss 3.98 on epoch=149
05/17/2022 12:56:57 - INFO - __main__ - Global step 600 Train loss 4.14 Classification-F1 0.1 on epoch=149
05/17/2022 12:56:57 - INFO - __main__ - Saving model with best Classification-F1: 0.07692307692307691 -> 0.1 on epoch=149, global_step=600
05/17/2022 12:56:58 - INFO - __main__ - Step 610 Global step 610 Train loss 3.98 on epoch=152
05/17/2022 12:56:59 - INFO - __main__ - Step 620 Global step 620 Train loss 3.76 on epoch=154
05/17/2022 12:57:01 - INFO - __main__ - Step 630 Global step 630 Train loss 3.83 on epoch=157
05/17/2022 12:57:02 - INFO - __main__ - Step 640 Global step 640 Train loss 3.62 on epoch=159
05/17/2022 12:57:03 - INFO - __main__ - Step 650 Global step 650 Train loss 3.68 on epoch=162
05/17/2022 12:57:04 - INFO - __main__ - Global step 650 Train loss 3.77 Classification-F1 0.1 on epoch=162
05/17/2022 12:57:06 - INFO - __main__ - Step 660 Global step 660 Train loss 3.62 on epoch=164
05/17/2022 12:57:07 - INFO - __main__ - Step 670 Global step 670 Train loss 3.51 on epoch=167
05/17/2022 12:57:09 - INFO - __main__ - Step 680 Global step 680 Train loss 3.50 on epoch=169
05/17/2022 12:57:10 - INFO - __main__ - Step 690 Global step 690 Train loss 3.87 on epoch=172
05/17/2022 12:57:12 - INFO - __main__ - Step 700 Global step 700 Train loss 3.40 on epoch=174
05/17/2022 12:57:13 - INFO - __main__ - Global step 700 Train loss 3.58 Classification-F1 0.1 on epoch=174
05/17/2022 12:57:14 - INFO - __main__ - Step 710 Global step 710 Train loss 3.58 on epoch=177
05/17/2022 12:57:16 - INFO - __main__ - Step 720 Global step 720 Train loss 3.30 on epoch=179
05/17/2022 12:57:17 - INFO - __main__ - Step 730 Global step 730 Train loss 3.44 on epoch=182
05/17/2022 12:57:18 - INFO - __main__ - Step 740 Global step 740 Train loss 3.27 on epoch=184
05/17/2022 12:57:20 - INFO - __main__ - Step 750 Global step 750 Train loss 3.32 on epoch=187
05/17/2022 12:57:20 - INFO - __main__ - Global step 750 Train loss 3.38 Classification-F1 0.1 on epoch=187
05/17/2022 12:57:22 - INFO - __main__ - Step 760 Global step 760 Train loss 3.22 on epoch=189
05/17/2022 12:57:23 - INFO - __main__ - Step 770 Global step 770 Train loss 3.25 on epoch=192
05/17/2022 12:57:25 - INFO - __main__ - Step 780 Global step 780 Train loss 3.24 on epoch=194
05/17/2022 12:57:26 - INFO - __main__ - Step 790 Global step 790 Train loss 3.36 on epoch=197
05/17/2022 12:57:28 - INFO - __main__ - Step 800 Global step 800 Train loss 3.06 on epoch=199
05/17/2022 12:57:28 - INFO - __main__ - Global step 800 Train loss 3.23 Classification-F1 0.1 on epoch=199
05/17/2022 12:57:30 - INFO - __main__ - Step 810 Global step 810 Train loss 2.98 on epoch=202
05/17/2022 12:57:31 - INFO - __main__ - Step 820 Global step 820 Train loss 3.03 on epoch=204
05/17/2022 12:57:32 - INFO - __main__ - Step 830 Global step 830 Train loss 3.20 on epoch=207
05/17/2022 12:57:34 - INFO - __main__ - Step 840 Global step 840 Train loss 2.72 on epoch=209
05/17/2022 12:57:35 - INFO - __main__ - Step 850 Global step 850 Train loss 2.84 on epoch=212
05/17/2022 12:57:36 - INFO - __main__ - Global step 850 Train loss 2.95 Classification-F1 0.1 on epoch=212
05/17/2022 12:57:37 - INFO - __main__ - Step 860 Global step 860 Train loss 2.70 on epoch=214
05/17/2022 12:57:38 - INFO - __main__ - Step 870 Global step 870 Train loss 2.66 on epoch=217
05/17/2022 12:57:40 - INFO - __main__ - Step 880 Global step 880 Train loss 2.51 on epoch=219
05/17/2022 12:57:41 - INFO - __main__ - Step 890 Global step 890 Train loss 2.47 on epoch=222
05/17/2022 12:57:43 - INFO - __main__ - Step 900 Global step 900 Train loss 2.48 on epoch=224
05/17/2022 12:57:43 - INFO - __main__ - Global step 900 Train loss 2.56 Classification-F1 0.10126582278481013 on epoch=224
05/17/2022 12:57:43 - INFO - __main__ - Saving model with best Classification-F1: 0.1 -> 0.10126582278481013 on epoch=224, global_step=900
05/17/2022 12:57:45 - INFO - __main__ - Step 910 Global step 910 Train loss 2.77 on epoch=227
05/17/2022 12:57:46 - INFO - __main__ - Step 920 Global step 920 Train loss 2.22 on epoch=229
05/17/2022 12:57:47 - INFO - __main__ - Step 930 Global step 930 Train loss 2.22 on epoch=232
05/17/2022 12:57:49 - INFO - __main__ - Step 940 Global step 940 Train loss 2.07 on epoch=234
05/17/2022 12:57:50 - INFO - __main__ - Step 950 Global step 950 Train loss 2.13 on epoch=237
05/17/2022 12:57:51 - INFO - __main__ - Global step 950 Train loss 2.28 Classification-F1 0.1 on epoch=237
05/17/2022 12:57:52 - INFO - __main__ - Step 960 Global step 960 Train loss 1.98 on epoch=239
05/17/2022 12:57:53 - INFO - __main__ - Step 970 Global step 970 Train loss 1.98 on epoch=242
05/17/2022 12:57:55 - INFO - __main__ - Step 980 Global step 980 Train loss 1.81 on epoch=244
05/17/2022 12:57:56 - INFO - __main__ - Step 990 Global step 990 Train loss 1.93 on epoch=247
05/17/2022 12:57:58 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.99 on epoch=249
05/17/2022 12:57:58 - INFO - __main__ - Global step 1000 Train loss 1.94 Classification-F1 0.1 on epoch=249
05/17/2022 12:58:00 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.79 on epoch=252
05/17/2022 12:58:01 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.74 on epoch=254
05/17/2022 12:58:02 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.79 on epoch=257
05/17/2022 12:58:04 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.85 on epoch=259
05/17/2022 12:58:05 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.63 on epoch=262
05/17/2022 12:58:06 - INFO - __main__ - Global step 1050 Train loss 1.76 Classification-F1 0.10256410256410256 on epoch=262
05/17/2022 12:58:06 - INFO - __main__ - Saving model with best Classification-F1: 0.10126582278481013 -> 0.10256410256410256 on epoch=262, global_step=1050
05/17/2022 12:58:07 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.70 on epoch=264
05/17/2022 12:58:08 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.80 on epoch=267
05/17/2022 12:58:10 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.63 on epoch=269
05/17/2022 12:58:11 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.54 on epoch=272
05/17/2022 12:58:13 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.56 on epoch=274
05/17/2022 12:58:14 - INFO - __main__ - Global step 1100 Train loss 1.65 Classification-F1 0.17267605633802818 on epoch=274
05/17/2022 12:58:14 - INFO - __main__ - Saving model with best Classification-F1: 0.10256410256410256 -> 0.17267605633802818 on epoch=274, global_step=1100
05/17/2022 12:58:15 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.56 on epoch=277
05/17/2022 12:58:16 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.51 on epoch=279
05/17/2022 12:58:18 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.41 on epoch=282
05/17/2022 12:58:19 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.46 on epoch=284
05/17/2022 12:58:21 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.71 on epoch=287
05/17/2022 12:58:21 - INFO - __main__ - Global step 1150 Train loss 1.53 Classification-F1 0.1 on epoch=287
05/17/2022 12:58:23 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.42 on epoch=289
05/17/2022 12:58:24 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.61 on epoch=292
05/17/2022 12:58:26 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.41 on epoch=294
05/17/2022 12:58:27 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.32 on epoch=297
05/17/2022 12:58:28 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.36 on epoch=299
05/17/2022 12:58:29 - INFO - __main__ - Global step 1200 Train loss 1.42 Classification-F1 0.1 on epoch=299
05/17/2022 12:58:30 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.43 on epoch=302
05/17/2022 12:58:32 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.37 on epoch=304
05/17/2022 12:58:33 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.22 on epoch=307
05/17/2022 12:58:35 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.45 on epoch=309
05/17/2022 12:58:36 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.40 on epoch=312
05/17/2022 12:58:37 - INFO - __main__ - Global step 1250 Train loss 1.37 Classification-F1 0.13034188034188032 on epoch=312
05/17/2022 12:58:38 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.27 on epoch=314
05/17/2022 12:58:39 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.34 on epoch=317
05/17/2022 12:58:41 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.33 on epoch=319
05/17/2022 12:58:42 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.26 on epoch=322
05/17/2022 12:58:44 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.38 on epoch=324
05/17/2022 12:58:44 - INFO - __main__ - Global step 1300 Train loss 1.32 Classification-F1 0.09493670886075949 on epoch=324
05/17/2022 12:58:46 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.37 on epoch=327
05/17/2022 12:58:48 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.26 on epoch=329
05/17/2022 12:58:49 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.41 on epoch=332
05/17/2022 12:58:50 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.32 on epoch=334
05/17/2022 12:58:52 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.29 on epoch=337
05/17/2022 12:58:52 - INFO - __main__ - Global step 1350 Train loss 1.33 Classification-F1 0.15356265356265356 on epoch=337
05/17/2022 12:58:54 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.30 on epoch=339
05/17/2022 12:58:55 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.29 on epoch=342
05/17/2022 12:58:56 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.21 on epoch=344
05/17/2022 12:58:58 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.28 on epoch=347
05/17/2022 12:58:59 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.31 on epoch=349
05/17/2022 12:59:00 - INFO - __main__ - Global step 1400 Train loss 1.28 Classification-F1 0.13333333333333333 on epoch=349
05/17/2022 12:59:01 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.26 on epoch=352
05/17/2022 12:59:03 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.24 on epoch=354
05/17/2022 12:59:04 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.36 on epoch=357
05/17/2022 12:59:05 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.31 on epoch=359
05/17/2022 12:59:07 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.24 on epoch=362
05/17/2022 12:59:07 - INFO - __main__ - Global step 1450 Train loss 1.28 Classification-F1 0.0974025974025974 on epoch=362
05/17/2022 12:59:09 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.12 on epoch=364
05/17/2022 12:59:10 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.14 on epoch=367
05/17/2022 12:59:11 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.21 on epoch=369
05/17/2022 12:59:13 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.25 on epoch=372
05/17/2022 12:59:14 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.13 on epoch=374
05/17/2022 12:59:15 - INFO - __main__ - Global step 1500 Train loss 1.17 Classification-F1 0.14642305712815235 on epoch=374
05/17/2022 12:59:16 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.26 on epoch=377
05/17/2022 12:59:18 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.11 on epoch=379
05/17/2022 12:59:19 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.29 on epoch=382
05/17/2022 12:59:20 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.22 on epoch=384
05/17/2022 12:59:22 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.13 on epoch=387
05/17/2022 12:59:22 - INFO - __main__ - Global step 1550 Train loss 1.20 Classification-F1 0.13047619047619047 on epoch=387
05/17/2022 12:59:24 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.28 on epoch=389
05/17/2022 12:59:25 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.26 on epoch=392
05/17/2022 12:59:26 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.17 on epoch=394
05/17/2022 12:59:28 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.18 on epoch=397
05/17/2022 12:59:29 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.13 on epoch=399
05/17/2022 12:59:30 - INFO - __main__ - Global step 1600 Train loss 1.20 Classification-F1 0.13936867182846935 on epoch=399
05/17/2022 12:59:31 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.18 on epoch=402
05/17/2022 12:59:33 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.17 on epoch=404
05/17/2022 12:59:34 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.16 on epoch=407
05/17/2022 12:59:36 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.11 on epoch=409
05/17/2022 12:59:37 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.10 on epoch=412
05/17/2022 12:59:38 - INFO - __main__ - Global step 1650 Train loss 1.15 Classification-F1 0.15211640211640212 on epoch=412
05/17/2022 12:59:39 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.23 on epoch=414
05/17/2022 12:59:40 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.18 on epoch=417
05/17/2022 12:59:42 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.20 on epoch=419
05/17/2022 12:59:43 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.25 on epoch=422
05/17/2022 12:59:45 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.12 on epoch=424
05/17/2022 12:59:45 - INFO - __main__ - Global step 1700 Train loss 1.20 Classification-F1 0.1388888888888889 on epoch=424
05/17/2022 12:59:46 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.13 on epoch=427
05/17/2022 12:59:48 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.11 on epoch=429
05/17/2022 12:59:49 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.35 on epoch=432
05/17/2022 12:59:51 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.09 on epoch=434
05/17/2022 12:59:52 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.07 on epoch=437
05/17/2022 12:59:52 - INFO - __main__ - Global step 1750 Train loss 1.15 Classification-F1 0.16993464052287582 on epoch=437
05/17/2022 12:59:54 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.13 on epoch=439
05/17/2022 12:59:55 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.11 on epoch=442
05/17/2022 12:59:57 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.12 on epoch=444
05/17/2022 12:59:58 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.06 on epoch=447
05/17/2022 12:59:59 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.10 on epoch=449
05/17/2022 13:00:00 - INFO - __main__ - Global step 1800 Train loss 1.10 Classification-F1 0.17480643240023822 on epoch=449
05/17/2022 13:00:00 - INFO - __main__ - Saving model with best Classification-F1: 0.17267605633802818 -> 0.17480643240023822 on epoch=449, global_step=1800
05/17/2022 13:00:01 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.18 on epoch=452
05/17/2022 13:00:03 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.18 on epoch=454
05/17/2022 13:00:04 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.06 on epoch=457
05/17/2022 13:00:06 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.09 on epoch=459
05/17/2022 13:00:07 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.12 on epoch=462
05/17/2022 13:00:07 - INFO - __main__ - Global step 1850 Train loss 1.13 Classification-F1 0.14095238095238094 on epoch=462
05/17/2022 13:00:09 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.13 on epoch=464
05/17/2022 13:00:10 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.21 on epoch=467
05/17/2022 13:00:12 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.19 on epoch=469
05/17/2022 13:00:13 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.17 on epoch=472
05/17/2022 13:00:15 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.17 on epoch=474
05/17/2022 13:00:15 - INFO - __main__ - Global step 1900 Train loss 1.17 Classification-F1 0.1875 on epoch=474
05/17/2022 13:00:15 - INFO - __main__ - Saving model with best Classification-F1: 0.17480643240023822 -> 0.1875 on epoch=474, global_step=1900
05/17/2022 13:00:17 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.09 on epoch=477
05/17/2022 13:00:18 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.15 on epoch=479
05/17/2022 13:00:20 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.08 on epoch=482
05/17/2022 13:00:21 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.05 on epoch=484
05/17/2022 13:00:23 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.01 on epoch=487
05/17/2022 13:00:23 - INFO - __main__ - Global step 1950 Train loss 1.08 Classification-F1 0.19445676274944568 on epoch=487
05/17/2022 13:00:23 - INFO - __main__ - Saving model with best Classification-F1: 0.1875 -> 0.19445676274944568 on epoch=487, global_step=1950
05/17/2022 13:00:25 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.21 on epoch=489
05/17/2022 13:00:26 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.05 on epoch=492
05/17/2022 13:00:27 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.07 on epoch=494
05/17/2022 13:00:29 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.06 on epoch=497
05/17/2022 13:00:30 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.08 on epoch=499
05/17/2022 13:00:31 - INFO - __main__ - Global step 2000 Train loss 1.09 Classification-F1 0.1081081081081081 on epoch=499
05/17/2022 13:00:32 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.18 on epoch=502
05/17/2022 13:00:33 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.08 on epoch=504
05/17/2022 13:00:35 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.03 on epoch=507
05/17/2022 13:00:36 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.11 on epoch=509
05/17/2022 13:00:38 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.08 on epoch=512
05/17/2022 13:00:38 - INFO - __main__ - Global step 2050 Train loss 1.10 Classification-F1 0.13067758749069247 on epoch=512
05/17/2022 13:00:40 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.12 on epoch=514
05/17/2022 13:00:41 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.03 on epoch=517
05/17/2022 13:00:43 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.11 on epoch=519
05/17/2022 13:00:44 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.09 on epoch=522
05/17/2022 13:00:45 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.96 on epoch=524
05/17/2022 13:00:46 - INFO - __main__ - Global step 2100 Train loss 1.06 Classification-F1 0.1955535390199637 on epoch=524
05/17/2022 13:00:46 - INFO - __main__ - Saving model with best Classification-F1: 0.19445676274944568 -> 0.1955535390199637 on epoch=524, global_step=2100
05/17/2022 13:00:47 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.11 on epoch=527
05/17/2022 13:00:49 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.08 on epoch=529
05/17/2022 13:00:50 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.06 on epoch=532
05/17/2022 13:00:51 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.06 on epoch=534
05/17/2022 13:00:53 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.04 on epoch=537
05/17/2022 13:00:53 - INFO - __main__ - Global step 2150 Train loss 1.07 Classification-F1 0.1 on epoch=537
05/17/2022 13:00:55 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.01 on epoch=539
05/17/2022 13:00:56 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.15 on epoch=542
05/17/2022 13:00:57 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.05 on epoch=544
05/17/2022 13:00:59 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.04 on epoch=547
05/17/2022 13:01:00 - INFO - __main__ - Step 2200 Global step 2200 Train loss 1.17 on epoch=549
05/17/2022 13:01:01 - INFO - __main__ - Global step 2200 Train loss 1.08 Classification-F1 0.1611111111111111 on epoch=549
05/17/2022 13:01:02 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.07 on epoch=552
05/17/2022 13:01:03 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.13 on epoch=554
05/17/2022 13:01:05 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.04 on epoch=557
05/17/2022 13:01:06 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.09 on epoch=559
05/17/2022 13:01:07 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.98 on epoch=562
05/17/2022 13:01:08 - INFO - __main__ - Global step 2250 Train loss 1.06 Classification-F1 0.13859154929577466 on epoch=562
05/17/2022 13:01:09 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.04 on epoch=564
05/17/2022 13:01:11 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.11 on epoch=567
05/17/2022 13:01:12 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.94 on epoch=569
05/17/2022 13:01:13 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.04 on epoch=572
05/17/2022 13:01:15 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.97 on epoch=574
05/17/2022 13:01:15 - INFO - __main__ - Global step 2300 Train loss 1.02 Classification-F1 0.15859154929577468 on epoch=574
05/17/2022 13:01:17 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.17 on epoch=577
05/17/2022 13:01:18 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.07 on epoch=579
05/17/2022 13:01:19 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.98 on epoch=582
05/17/2022 13:01:21 - INFO - __main__ - Step 2340 Global step 2340 Train loss 1.10 on epoch=584
05/17/2022 13:01:22 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.19 on epoch=587
05/17/2022 13:01:23 - INFO - __main__ - Global step 2350 Train loss 1.10 Classification-F1 0.12499999999999999 on epoch=587
05/17/2022 13:01:24 - INFO - __main__ - Step 2360 Global step 2360 Train loss 1.05 on epoch=589
05/17/2022 13:01:26 - INFO - __main__ - Step 2370 Global step 2370 Train loss 1.06 on epoch=592
05/17/2022 13:01:27 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.96 on epoch=594
05/17/2022 13:01:28 - INFO - __main__ - Step 2390 Global step 2390 Train loss 1.02 on epoch=597
05/17/2022 13:01:30 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.25 on epoch=599
05/17/2022 13:01:30 - INFO - __main__ - Global step 2400 Train loss 1.07 Classification-F1 0.147459165154265 on epoch=599
05/17/2022 13:01:32 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.09 on epoch=602
05/17/2022 13:01:33 - INFO - __main__ - Step 2420 Global step 2420 Train loss 1.06 on epoch=604
05/17/2022 13:01:34 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.03 on epoch=607
05/17/2022 13:01:36 - INFO - __main__ - Step 2440 Global step 2440 Train loss 1.03 on epoch=609
05/17/2022 13:01:37 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.05 on epoch=612
05/17/2022 13:01:38 - INFO - __main__ - Global step 2450 Train loss 1.05 Classification-F1 0.203125 on epoch=612
05/17/2022 13:01:38 - INFO - __main__ - Saving model with best Classification-F1: 0.1955535390199637 -> 0.203125 on epoch=612, global_step=2450
05/17/2022 13:01:39 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.07 on epoch=614
05/17/2022 13:01:41 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.95 on epoch=617
05/17/2022 13:01:42 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.09 on epoch=619
05/17/2022 13:01:44 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.86 on epoch=622
05/17/2022 13:01:45 - INFO - __main__ - Step 2500 Global step 2500 Train loss 1.00 on epoch=624
05/17/2022 13:01:46 - INFO - __main__ - Global step 2500 Train loss 0.99 Classification-F1 0.19956521739130434 on epoch=624
05/17/2022 13:01:47 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.95 on epoch=627
05/17/2022 13:01:48 - INFO - __main__ - Step 2520 Global step 2520 Train loss 1.01 on epoch=629
05/17/2022 13:01:50 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.92 on epoch=632
05/17/2022 13:01:51 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.96 on epoch=634
05/17/2022 13:01:52 - INFO - __main__ - Step 2550 Global step 2550 Train loss 1.03 on epoch=637
05/17/2022 13:01:53 - INFO - __main__ - Global step 2550 Train loss 0.97 Classification-F1 0.10450704225352113 on epoch=637
05/17/2022 13:01:54 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.89 on epoch=639
05/17/2022 13:01:56 - INFO - __main__ - Step 2570 Global step 2570 Train loss 1.04 on epoch=642
05/17/2022 13:01:57 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.96 on epoch=644
05/17/2022 13:01:59 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.92 on epoch=647
05/17/2022 13:02:00 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.04 on epoch=649
05/17/2022 13:02:01 - INFO - __main__ - Global step 2600 Train loss 0.97 Classification-F1 0.13123993558776167 on epoch=649
05/17/2022 13:02:02 - INFO - __main__ - Step 2610 Global step 2610 Train loss 1.01 on epoch=652
05/17/2022 13:02:04 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.90 on epoch=654
05/17/2022 13:02:05 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.94 on epoch=657
05/17/2022 13:02:06 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.05 on epoch=659
05/17/2022 13:02:08 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.09 on epoch=662
05/17/2022 13:02:08 - INFO - __main__ - Global step 2650 Train loss 1.00 Classification-F1 0.13482414242292662 on epoch=662
05/17/2022 13:02:10 - INFO - __main__ - Step 2660 Global step 2660 Train loss 1.09 on epoch=664
05/17/2022 13:02:11 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.92 on epoch=667
05/17/2022 13:02:13 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.99 on epoch=669
05/17/2022 13:02:14 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.99 on epoch=672
05/17/2022 13:02:16 - INFO - __main__ - Step 2700 Global step 2700 Train loss 1.02 on epoch=674
05/17/2022 13:02:16 - INFO - __main__ - Global step 2700 Train loss 1.00 Classification-F1 0.1 on epoch=674
05/17/2022 13:02:18 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.02 on epoch=677
05/17/2022 13:02:19 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.97 on epoch=679
05/17/2022 13:02:20 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.91 on epoch=682
05/17/2022 13:02:22 - INFO - __main__ - Step 2740 Global step 2740 Train loss 1.14 on epoch=684
05/17/2022 13:02:23 - INFO - __main__ - Step 2750 Global step 2750 Train loss 1.01 on epoch=687
05/17/2022 13:02:24 - INFO - __main__ - Global step 2750 Train loss 1.01 Classification-F1 0.1 on epoch=687
05/17/2022 13:02:25 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.93 on epoch=689
05/17/2022 13:02:26 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.03 on epoch=692
05/17/2022 13:02:28 - INFO - __main__ - Step 2780 Global step 2780 Train loss 1.01 on epoch=694
05/17/2022 13:02:29 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.98 on epoch=697
05/17/2022 13:02:31 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.93 on epoch=699
05/17/2022 13:02:31 - INFO - __main__ - Global step 2800 Train loss 0.98 Classification-F1 0.13034188034188032 on epoch=699
05/17/2022 13:02:33 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.03 on epoch=702
05/17/2022 13:02:34 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.98 on epoch=704
05/17/2022 13:02:36 - INFO - __main__ - Step 2830 Global step 2830 Train loss 1.01 on epoch=707
05/17/2022 13:02:37 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.95 on epoch=709
05/17/2022 13:02:38 - INFO - __main__ - Step 2850 Global step 2850 Train loss 1.06 on epoch=712
05/17/2022 13:02:39 - INFO - __main__ - Global step 2850 Train loss 1.01 Classification-F1 0.11732186732186733 on epoch=712
05/17/2022 13:02:41 - INFO - __main__ - Step 2860 Global step 2860 Train loss 1.05 on epoch=714
05/17/2022 13:02:42 - INFO - __main__ - Step 2870 Global step 2870 Train loss 1.12 on epoch=717
05/17/2022 13:02:44 - INFO - __main__ - Step 2880 Global step 2880 Train loss 1.06 on epoch=719
05/17/2022 13:02:45 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.02 on epoch=722
05/17/2022 13:02:47 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.96 on epoch=724
05/17/2022 13:02:47 - INFO - __main__ - Global step 2900 Train loss 1.04 Classification-F1 0.09493670886075949 on epoch=724
05/17/2022 13:02:49 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.87 on epoch=727
05/17/2022 13:02:50 - INFO - __main__ - Step 2920 Global step 2920 Train loss 1.03 on epoch=729
05/17/2022 13:02:52 - INFO - __main__ - Step 2930 Global step 2930 Train loss 1.01 on epoch=732
05/17/2022 13:02:53 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.98 on epoch=734
05/17/2022 13:02:55 - INFO - __main__ - Step 2950 Global step 2950 Train loss 1.01 on epoch=737
05/17/2022 13:02:55 - INFO - __main__ - Global step 2950 Train loss 0.98 Classification-F1 0.12450704225352113 on epoch=737
05/17/2022 13:02:56 - INFO - __main__ - Step 2960 Global step 2960 Train loss 1.02 on epoch=739
05/17/2022 13:02:58 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.97 on epoch=742
05/17/2022 13:02:59 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.91 on epoch=744
05/17/2022 13:03:00 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.98 on epoch=747
05/17/2022 13:03:02 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.94 on epoch=749
05/17/2022 13:03:02 - INFO - __main__ - Global step 3000 Train loss 0.96 Classification-F1 0.19068450849202268 on epoch=749
05/17/2022 13:03:02 - INFO - __main__ - save last model!
05/17/2022 13:03:02 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/17/2022 13:03:02 - INFO - __main__ - Start tokenizing ... 5509 instances
05/17/2022 13:03:02 - INFO - __main__ - Printing 3 examples
05/17/2022 13:03:02 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/17/2022 13:03:02 - INFO - __main__ - ['others']
05/17/2022 13:03:02 - INFO - __main__ -  [emo] what you like very little things ok
05/17/2022 13:03:02 - INFO - __main__ - ['others']
05/17/2022 13:03:02 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/17/2022 13:03:02 - INFO - __main__ - ['others']
05/17/2022 13:03:02 - INFO - __main__ - Tokenizing Input ...
05/17/2022 13:03:03 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 13:03:03 - INFO - __main__ - Printing 3 examples
05/17/2022 13:03:03 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
05/17/2022 13:03:03 - INFO - __main__ - ['sad']
05/17/2022 13:03:03 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
05/17/2022 13:03:03 - INFO - __main__ - ['sad']
05/17/2022 13:03:03 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
05/17/2022 13:03:03 - INFO - __main__ - ['sad']
05/17/2022 13:03:03 - INFO - __main__ - Tokenizing Input ...
05/17/2022 13:03:03 - INFO - __main__ - Tokenizing Output ...
05/17/2022 13:03:03 - INFO - __main__ - Loaded 64 examples from train data
05/17/2022 13:03:03 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 13:03:03 - INFO - __main__ - Printing 3 examples
05/17/2022 13:03:03 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
05/17/2022 13:03:03 - INFO - __main__ - ['sad']
05/17/2022 13:03:03 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
05/17/2022 13:03:03 - INFO - __main__ - ['sad']
05/17/2022 13:03:03 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
05/17/2022 13:03:03 - INFO - __main__ - ['sad']
05/17/2022 13:03:03 - INFO - __main__ - Tokenizing Input ...
05/17/2022 13:03:03 - INFO - __main__ - Tokenizing Output ...
05/17/2022 13:03:03 - INFO - __main__ - Loaded 64 examples from dev data
05/17/2022 13:03:05 - INFO - __main__ - Tokenizing Output ...
05/17/2022 13:03:08 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 13:03:09 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 13:03:09 - INFO - __main__ - Starting training!
05/17/2022 13:03:10 - INFO - __main__ - Loaded 5509 examples from test data
05/17/2022 13:03:57 - INFO - __main__ - Saved prediction in models/T5-base-reptile-cls2cls-3e-5-2-5000-5e-1-10/singletask-emo/emo_16_21_0.4_8_predictions.txt
05/17/2022 13:03:57 - INFO - __main__ - Classification-F1 on test data: 0.0451
05/17/2022 13:03:57 - INFO - __main__ - prefix=emo_16_21, lr=0.4, bsz=8, dev_performance=0.203125, test_performance=0.045132300137508366
05/17/2022 13:03:57 - INFO - __main__ - Running ... prefix=emo_16_21, lr=0.3, bsz=8 ...
05/17/2022 13:03:58 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 13:03:58 - INFO - __main__ - Printing 3 examples
05/17/2022 13:03:58 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
05/17/2022 13:03:58 - INFO - __main__ - ['sad']
05/17/2022 13:03:58 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
05/17/2022 13:03:58 - INFO - __main__ - ['sad']
05/17/2022 13:03:58 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
05/17/2022 13:03:58 - INFO - __main__ - ['sad']
05/17/2022 13:03:58 - INFO - __main__ - Tokenizing Input ...
05/17/2022 13:03:58 - INFO - __main__ - Tokenizing Output ...
05/17/2022 13:03:58 - INFO - __main__ - Loaded 64 examples from train data
05/17/2022 13:03:58 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 13:03:58 - INFO - __main__ - Printing 3 examples
05/17/2022 13:03:58 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
05/17/2022 13:03:58 - INFO - __main__ - ['sad']
05/17/2022 13:03:58 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
05/17/2022 13:03:58 - INFO - __main__ - ['sad']
05/17/2022 13:03:58 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
05/17/2022 13:03:58 - INFO - __main__ - ['sad']
05/17/2022 13:03:58 - INFO - __main__ - Tokenizing Input ...
05/17/2022 13:03:58 - INFO - __main__ - Tokenizing Output ...
05/17/2022 13:03:58 - INFO - __main__ - Loaded 64 examples from dev data
05/17/2022 13:04:05 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 13:04:05 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 13:04:05 - INFO - __main__ - Starting training!
05/17/2022 13:04:07 - INFO - __main__ - Step 10 Global step 10 Train loss 8.78 on epoch=2
05/17/2022 13:04:08 - INFO - __main__ - Step 20 Global step 20 Train loss 8.77 on epoch=4
05/17/2022 13:04:10 - INFO - __main__ - Step 30 Global step 30 Train loss 8.76 on epoch=7
05/17/2022 13:04:11 - INFO - __main__ - Step 40 Global step 40 Train loss 8.67 on epoch=9
05/17/2022 13:04:13 - INFO - __main__ - Step 50 Global step 50 Train loss 8.55 on epoch=12
05/17/2022 13:04:19 - INFO - __main__ - Global step 50 Train loss 8.71 Classification-F1 0.0 on epoch=12
05/17/2022 13:04:19 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/17/2022 13:04:21 - INFO - __main__ - Step 60 Global step 60 Train loss 8.51 on epoch=14
05/17/2022 13:04:22 - INFO - __main__ - Step 70 Global step 70 Train loss 8.40 on epoch=17
05/17/2022 13:04:23 - INFO - __main__ - Step 80 Global step 80 Train loss 8.55 on epoch=19
05/17/2022 13:04:25 - INFO - __main__ - Step 90 Global step 90 Train loss 8.37 on epoch=22
05/17/2022 13:04:26 - INFO - __main__ - Step 100 Global step 100 Train loss 8.44 on epoch=24
05/17/2022 13:04:32 - INFO - __main__ - Global step 100 Train loss 8.45 Classification-F1 0.0 on epoch=24
05/17/2022 13:04:33 - INFO - __main__ - Step 110 Global step 110 Train loss 8.34 on epoch=27
05/17/2022 13:04:34 - INFO - __main__ - Step 120 Global step 120 Train loss 8.34 on epoch=29
05/17/2022 13:04:35 - INFO - __main__ - Step 130 Global step 130 Train loss 8.16 on epoch=32
05/17/2022 13:04:37 - INFO - __main__ - Step 140 Global step 140 Train loss 8.14 on epoch=34
05/17/2022 13:04:38 - INFO - __main__ - Step 150 Global step 150 Train loss 8.13 on epoch=37
05/17/2022 13:04:50 - INFO - __main__ - Global step 150 Train loss 8.22 Classification-F1 0.0 on epoch=37
05/17/2022 13:04:51 - INFO - __main__ - Step 160 Global step 160 Train loss 8.11 on epoch=39
05/17/2022 13:04:53 - INFO - __main__ - Step 170 Global step 170 Train loss 7.97 on epoch=42
05/17/2022 13:04:54 - INFO - __main__ - Step 180 Global step 180 Train loss 7.87 on epoch=44
05/17/2022 13:04:55 - INFO - __main__ - Step 190 Global step 190 Train loss 7.77 on epoch=47
05/17/2022 13:04:57 - INFO - __main__ - Step 200 Global step 200 Train loss 7.71 on epoch=49
05/17/2022 13:05:02 - INFO - __main__ - Global step 200 Train loss 7.89 Classification-F1 0.0 on epoch=49
05/17/2022 13:05:03 - INFO - __main__ - Step 210 Global step 210 Train loss 7.53 on epoch=52
05/17/2022 13:05:04 - INFO - __main__ - Step 220 Global step 220 Train loss 7.58 on epoch=54
05/17/2022 13:05:06 - INFO - __main__ - Step 230 Global step 230 Train loss 7.40 on epoch=57
05/17/2022 13:05:07 - INFO - __main__ - Step 240 Global step 240 Train loss 7.23 on epoch=59
05/17/2022 13:05:08 - INFO - __main__ - Step 250 Global step 250 Train loss 7.21 on epoch=62
05/17/2022 13:05:10 - INFO - __main__ - Global step 250 Train loss 7.39 Classification-F1 0.0 on epoch=62
05/17/2022 13:05:12 - INFO - __main__ - Step 260 Global step 260 Train loss 7.08 on epoch=64
05/17/2022 13:05:13 - INFO - __main__ - Step 270 Global step 270 Train loss 7.10 on epoch=67
05/17/2022 13:05:14 - INFO - __main__ - Step 280 Global step 280 Train loss 6.91 on epoch=69
05/17/2022 13:05:16 - INFO - __main__ - Step 290 Global step 290 Train loss 6.85 on epoch=72
05/17/2022 13:05:17 - INFO - __main__ - Step 300 Global step 300 Train loss 6.81 on epoch=74
05/17/2022 13:05:19 - INFO - __main__ - Global step 300 Train loss 6.95 Classification-F1 0.0 on epoch=74
05/17/2022 13:05:20 - INFO - __main__ - Step 310 Global step 310 Train loss 6.63 on epoch=77
05/17/2022 13:05:22 - INFO - __main__ - Step 320 Global step 320 Train loss 6.56 on epoch=79
05/17/2022 13:05:23 - INFO - __main__ - Step 330 Global step 330 Train loss 6.53 on epoch=82
05/17/2022 13:05:24 - INFO - __main__ - Step 340 Global step 340 Train loss 6.59 on epoch=84
05/17/2022 13:05:26 - INFO - __main__ - Step 350 Global step 350 Train loss 6.32 on epoch=87
05/17/2022 13:05:27 - INFO - __main__ - Global step 350 Train loss 6.53 Classification-F1 0.0 on epoch=87
05/17/2022 13:05:28 - INFO - __main__ - Step 360 Global step 360 Train loss 6.21 on epoch=89
05/17/2022 13:05:30 - INFO - __main__ - Step 370 Global step 370 Train loss 6.35 on epoch=92
05/17/2022 13:05:31 - INFO - __main__ - Step 380 Global step 380 Train loss 6.05 on epoch=94
05/17/2022 13:05:33 - INFO - __main__ - Step 390 Global step 390 Train loss 6.23 on epoch=97
05/17/2022 13:05:34 - INFO - __main__ - Step 400 Global step 400 Train loss 5.86 on epoch=99
05/17/2022 13:05:37 - INFO - __main__ - Global step 400 Train loss 6.14 Classification-F1 0.0 on epoch=99
05/17/2022 13:05:38 - INFO - __main__ - Step 410 Global step 410 Train loss 5.86 on epoch=102
05/17/2022 13:05:40 - INFO - __main__ - Step 420 Global step 420 Train loss 5.69 on epoch=104
05/17/2022 13:05:41 - INFO - __main__ - Step 430 Global step 430 Train loss 5.70 on epoch=107
05/17/2022 13:05:42 - INFO - __main__ - Step 440 Global step 440 Train loss 5.58 on epoch=109
05/17/2022 13:05:44 - INFO - __main__ - Step 450 Global step 450 Train loss 5.59 on epoch=112
05/17/2022 13:05:48 - INFO - __main__ - Global step 450 Train loss 5.68 Classification-F1 0.0 on epoch=112
05/17/2022 13:05:49 - INFO - __main__ - Step 460 Global step 460 Train loss 5.42 on epoch=114
05/17/2022 13:05:51 - INFO - __main__ - Step 470 Global step 470 Train loss 5.33 on epoch=117
05/17/2022 13:05:52 - INFO - __main__ - Step 480 Global step 480 Train loss 5.26 on epoch=119
05/17/2022 13:05:54 - INFO - __main__ - Step 490 Global step 490 Train loss 5.27 on epoch=122
05/17/2022 13:05:55 - INFO - __main__ - Step 500 Global step 500 Train loss 4.93 on epoch=124
05/17/2022 13:06:01 - INFO - __main__ - Global step 500 Train loss 5.24 Classification-F1 0.0 on epoch=124
05/17/2022 13:06:02 - INFO - __main__ - Step 510 Global step 510 Train loss 5.15 on epoch=127
05/17/2022 13:06:04 - INFO - __main__ - Step 520 Global step 520 Train loss 4.93 on epoch=129
05/17/2022 13:06:05 - INFO - __main__ - Step 530 Global step 530 Train loss 4.96 on epoch=132
05/17/2022 13:06:06 - INFO - __main__ - Step 540 Global step 540 Train loss 4.76 on epoch=134
05/17/2022 13:06:08 - INFO - __main__ - Step 550 Global step 550 Train loss 4.97 on epoch=137
05/17/2022 13:06:16 - INFO - __main__ - Global step 550 Train loss 4.95 Classification-F1 0.0 on epoch=137
05/17/2022 13:06:18 - INFO - __main__ - Step 560 Global step 560 Train loss 4.66 on epoch=139
05/17/2022 13:06:19 - INFO - __main__ - Step 570 Global step 570 Train loss 4.84 on epoch=142
05/17/2022 13:06:21 - INFO - __main__ - Step 580 Global step 580 Train loss 4.61 on epoch=144
05/17/2022 13:06:22 - INFO - __main__ - Step 590 Global step 590 Train loss 4.54 on epoch=147
05/17/2022 13:06:24 - INFO - __main__ - Step 600 Global step 600 Train loss 4.41 on epoch=149
05/17/2022 13:06:32 - INFO - __main__ - Global step 600 Train loss 4.61 Classification-F1 0.0 on epoch=149
05/17/2022 13:06:34 - INFO - __main__ - Step 610 Global step 610 Train loss 4.38 on epoch=152
05/17/2022 13:06:35 - INFO - __main__ - Step 620 Global step 620 Train loss 4.18 on epoch=154
05/17/2022 13:06:36 - INFO - __main__ - Step 630 Global step 630 Train loss 4.34 on epoch=157
05/17/2022 13:06:38 - INFO - __main__ - Step 640 Global step 640 Train loss 4.19 on epoch=159
05/17/2022 13:06:39 - INFO - __main__ - Step 650 Global step 650 Train loss 4.36 on epoch=162
05/17/2022 13:06:46 - INFO - __main__ - Global step 650 Train loss 4.29 Classification-F1 0.0 on epoch=162
05/17/2022 13:06:47 - INFO - __main__ - Step 660 Global step 660 Train loss 4.07 on epoch=164
05/17/2022 13:06:48 - INFO - __main__ - Step 670 Global step 670 Train loss 4.00 on epoch=167
05/17/2022 13:06:50 - INFO - __main__ - Step 680 Global step 680 Train loss 3.89 on epoch=169
05/17/2022 13:06:51 - INFO - __main__ - Step 690 Global step 690 Train loss 3.86 on epoch=172
05/17/2022 13:06:52 - INFO - __main__ - Step 700 Global step 700 Train loss 3.97 on epoch=174
05/17/2022 13:06:58 - INFO - __main__ - Global step 700 Train loss 3.96 Classification-F1 0.021739130434782608 on epoch=174
05/17/2022 13:06:58 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.021739130434782608 on epoch=174, global_step=700
05/17/2022 13:06:59 - INFO - __main__ - Step 710 Global step 710 Train loss 3.99 on epoch=177
05/17/2022 13:07:01 - INFO - __main__ - Step 720 Global step 720 Train loss 3.85 on epoch=179
05/17/2022 13:07:02 - INFO - __main__ - Step 730 Global step 730 Train loss 3.98 on epoch=182
05/17/2022 13:07:04 - INFO - __main__ - Step 740 Global step 740 Train loss 3.81 on epoch=184
05/17/2022 13:07:05 - INFO - __main__ - Step 750 Global step 750 Train loss 3.85 on epoch=187
05/17/2022 13:07:09 - INFO - __main__ - Global step 750 Train loss 3.90 Classification-F1 0.07207207207207207 on epoch=187
05/17/2022 13:07:09 - INFO - __main__ - Saving model with best Classification-F1: 0.021739130434782608 -> 0.07207207207207207 on epoch=187, global_step=750
05/17/2022 13:07:10 - INFO - __main__ - Step 760 Global step 760 Train loss 3.59 on epoch=189
05/17/2022 13:07:12 - INFO - __main__ - Step 770 Global step 770 Train loss 3.52 on epoch=192
05/17/2022 13:07:13 - INFO - __main__ - Step 780 Global step 780 Train loss 3.45 on epoch=194
05/17/2022 13:07:14 - INFO - __main__ - Step 790 Global step 790 Train loss 3.62 on epoch=197
05/17/2022 13:07:16 - INFO - __main__ - Step 800 Global step 800 Train loss 3.30 on epoch=199
05/17/2022 13:07:19 - INFO - __main__ - Global step 800 Train loss 3.50 Classification-F1 0.11047619047619046 on epoch=199
05/17/2022 13:07:19 - INFO - __main__ - Saving model with best Classification-F1: 0.07207207207207207 -> 0.11047619047619046 on epoch=199, global_step=800
05/17/2022 13:07:21 - INFO - __main__ - Step 810 Global step 810 Train loss 3.42 on epoch=202
05/17/2022 13:07:22 - INFO - __main__ - Step 820 Global step 820 Train loss 3.33 on epoch=204
05/17/2022 13:07:23 - INFO - __main__ - Step 830 Global step 830 Train loss 3.29 on epoch=207
05/17/2022 13:07:25 - INFO - __main__ - Step 840 Global step 840 Train loss 3.32 on epoch=209
05/17/2022 13:07:26 - INFO - __main__ - Step 850 Global step 850 Train loss 3.25 on epoch=212
05/17/2022 13:07:27 - INFO - __main__ - Global step 850 Train loss 3.32 Classification-F1 0.13067758749069247 on epoch=212
05/17/2022 13:07:27 - INFO - __main__ - Saving model with best Classification-F1: 0.11047619047619046 -> 0.13067758749069247 on epoch=212, global_step=850
05/17/2022 13:07:28 - INFO - __main__ - Step 860 Global step 860 Train loss 3.03 on epoch=214
05/17/2022 13:07:30 - INFO - __main__ - Step 870 Global step 870 Train loss 3.05 on epoch=217
05/17/2022 13:07:31 - INFO - __main__ - Step 880 Global step 880 Train loss 2.87 on epoch=219
05/17/2022 13:07:33 - INFO - __main__ - Step 890 Global step 890 Train loss 3.27 on epoch=222
05/17/2022 13:07:34 - INFO - __main__ - Step 900 Global step 900 Train loss 3.08 on epoch=224
05/17/2022 13:07:35 - INFO - __main__ - Global step 900 Train loss 3.06 Classification-F1 0.15607940446650126 on epoch=224
05/17/2022 13:07:35 - INFO - __main__ - Saving model with best Classification-F1: 0.13067758749069247 -> 0.15607940446650126 on epoch=224, global_step=900
05/17/2022 13:07:37 - INFO - __main__ - Step 910 Global step 910 Train loss 2.94 on epoch=227
05/17/2022 13:07:38 - INFO - __main__ - Step 920 Global step 920 Train loss 2.82 on epoch=229
05/17/2022 13:07:39 - INFO - __main__ - Step 930 Global step 930 Train loss 2.79 on epoch=232
05/17/2022 13:07:41 - INFO - __main__ - Step 940 Global step 940 Train loss 2.75 on epoch=234
05/17/2022 13:07:42 - INFO - __main__ - Step 950 Global step 950 Train loss 2.81 on epoch=237
05/17/2022 13:07:43 - INFO - __main__ - Global step 950 Train loss 2.82 Classification-F1 0.1302118933697881 on epoch=237
05/17/2022 13:07:44 - INFO - __main__ - Step 960 Global step 960 Train loss 2.50 on epoch=239
05/17/2022 13:07:46 - INFO - __main__ - Step 970 Global step 970 Train loss 2.57 on epoch=242
05/17/2022 13:07:47 - INFO - __main__ - Step 980 Global step 980 Train loss 2.38 on epoch=244
05/17/2022 13:07:49 - INFO - __main__ - Step 990 Global step 990 Train loss 2.35 on epoch=247
05/17/2022 13:07:50 - INFO - __main__ - Step 1000 Global step 1000 Train loss 2.24 on epoch=249
05/17/2022 13:07:51 - INFO - __main__ - Global step 1000 Train loss 2.41 Classification-F1 0.1 on epoch=249
05/17/2022 13:07:52 - INFO - __main__ - Step 1010 Global step 1010 Train loss 2.34 on epoch=252
05/17/2022 13:07:54 - INFO - __main__ - Step 1020 Global step 1020 Train loss 2.13 on epoch=254
05/17/2022 13:07:55 - INFO - __main__ - Step 1030 Global step 1030 Train loss 2.05 on epoch=257
05/17/2022 13:07:57 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.83 on epoch=259
05/17/2022 13:07:58 - INFO - __main__ - Step 1050 Global step 1050 Train loss 2.12 on epoch=262
05/17/2022 13:07:59 - INFO - __main__ - Global step 1050 Train loss 2.09 Classification-F1 0.1 on epoch=262
05/17/2022 13:08:00 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.90 on epoch=264
05/17/2022 13:08:01 - INFO - __main__ - Step 1070 Global step 1070 Train loss 2.19 on epoch=267
05/17/2022 13:08:03 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.99 on epoch=269
05/17/2022 13:08:04 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.86 on epoch=272
05/17/2022 13:08:06 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.73 on epoch=274
05/17/2022 13:08:06 - INFO - __main__ - Global step 1100 Train loss 1.93 Classification-F1 0.13067758749069247 on epoch=274
05/17/2022 13:08:08 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.89 on epoch=277
05/17/2022 13:08:09 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.79 on epoch=279
05/17/2022 13:08:11 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.65 on epoch=282
05/17/2022 13:08:12 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.70 on epoch=284
05/17/2022 13:08:14 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.73 on epoch=287
05/17/2022 13:08:14 - INFO - __main__ - Global step 1150 Train loss 1.75 Classification-F1 0.10126582278481013 on epoch=287
05/17/2022 13:08:16 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.75 on epoch=289
05/17/2022 13:08:17 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.51 on epoch=292
05/17/2022 13:08:19 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.50 on epoch=294
05/17/2022 13:08:20 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.55 on epoch=297
05/17/2022 13:08:22 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.51 on epoch=299
05/17/2022 13:08:22 - INFO - __main__ - Global step 1200 Train loss 1.56 Classification-F1 0.1 on epoch=299
05/17/2022 13:08:24 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.50 on epoch=302
05/17/2022 13:08:25 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.40 on epoch=304
05/17/2022 13:08:27 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.45 on epoch=307
05/17/2022 13:08:28 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.50 on epoch=309
05/17/2022 13:08:29 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.56 on epoch=312
05/17/2022 13:08:30 - INFO - __main__ - Global step 1250 Train loss 1.48 Classification-F1 0.18648558014755195 on epoch=312
05/17/2022 13:08:30 - INFO - __main__ - Saving model with best Classification-F1: 0.15607940446650126 -> 0.18648558014755195 on epoch=312, global_step=1250
05/17/2022 13:08:31 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.49 on epoch=314
05/17/2022 13:08:33 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.38 on epoch=317
05/17/2022 13:08:34 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.59 on epoch=319
05/17/2022 13:08:35 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.40 on epoch=322
05/17/2022 13:08:37 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.46 on epoch=324
05/17/2022 13:08:37 - INFO - __main__ - Global step 1300 Train loss 1.47 Classification-F1 0.21560846560846564 on epoch=324
05/17/2022 13:08:37 - INFO - __main__ - Saving model with best Classification-F1: 0.18648558014755195 -> 0.21560846560846564 on epoch=324, global_step=1300
05/17/2022 13:08:39 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.39 on epoch=327
05/17/2022 13:08:40 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.17 on epoch=329
05/17/2022 13:08:41 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.45 on epoch=332
05/17/2022 13:08:43 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.47 on epoch=334
05/17/2022 13:08:44 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.36 on epoch=337
05/17/2022 13:08:45 - INFO - __main__ - Global step 1350 Train loss 1.37 Classification-F1 0.20842379504993486 on epoch=337
05/17/2022 13:08:46 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.40 on epoch=339
05/17/2022 13:08:47 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.45 on epoch=342
05/17/2022 13:08:49 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.30 on epoch=344
05/17/2022 13:08:50 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.40 on epoch=347
05/17/2022 13:08:52 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.23 on epoch=349
05/17/2022 13:08:52 - INFO - __main__ - Global step 1400 Train loss 1.36 Classification-F1 0.16630481980026052 on epoch=349
05/17/2022 13:08:54 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.46 on epoch=352
05/17/2022 13:08:55 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.18 on epoch=354
05/17/2022 13:08:56 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.26 on epoch=357
05/17/2022 13:08:58 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.36 on epoch=359
05/17/2022 13:08:59 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.25 on epoch=362
05/17/2022 13:09:00 - INFO - __main__ - Global step 1450 Train loss 1.30 Classification-F1 0.17937915742793792 on epoch=362
05/17/2022 13:09:01 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.26 on epoch=364
05/17/2022 13:09:03 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.38 on epoch=367
05/17/2022 13:09:04 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.19 on epoch=369
05/17/2022 13:09:05 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.27 on epoch=372
05/17/2022 13:09:07 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.37 on epoch=374
05/17/2022 13:09:07 - INFO - __main__ - Global step 1500 Train loss 1.29 Classification-F1 0.1237183868762816 on epoch=374
05/17/2022 13:09:09 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.28 on epoch=377
05/17/2022 13:09:10 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.15 on epoch=379
05/17/2022 13:09:12 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.30 on epoch=382
05/17/2022 13:09:13 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.25 on epoch=384
05/17/2022 13:09:15 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.19 on epoch=387
05/17/2022 13:09:15 - INFO - __main__ - Global step 1550 Train loss 1.23 Classification-F1 0.1 on epoch=387
05/17/2022 13:09:17 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.31 on epoch=389
05/17/2022 13:09:18 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.32 on epoch=392
05/17/2022 13:09:19 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.21 on epoch=394
05/17/2022 13:09:21 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.30 on epoch=397
05/17/2022 13:09:22 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.41 on epoch=399
05/17/2022 13:09:23 - INFO - __main__ - Global step 1600 Train loss 1.31 Classification-F1 0.15295815295815296 on epoch=399
05/17/2022 13:09:24 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.08 on epoch=402
05/17/2022 13:09:26 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.20 on epoch=404
05/17/2022 13:09:27 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.34 on epoch=407
05/17/2022 13:09:29 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.10 on epoch=409
05/17/2022 13:09:30 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.17 on epoch=412
05/17/2022 13:09:31 - INFO - __main__ - Global step 1650 Train loss 1.18 Classification-F1 0.1 on epoch=412
05/17/2022 13:09:32 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.14 on epoch=414
05/17/2022 13:09:33 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.23 on epoch=417
05/17/2022 13:09:35 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.18 on epoch=419
05/17/2022 13:09:36 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.22 on epoch=422
05/17/2022 13:09:38 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.18 on epoch=424
05/17/2022 13:09:38 - INFO - __main__ - Global step 1700 Train loss 1.19 Classification-F1 0.1 on epoch=424
05/17/2022 13:09:40 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.32 on epoch=427
05/17/2022 13:09:41 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.17 on epoch=429
05/17/2022 13:09:42 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.25 on epoch=432
05/17/2022 13:09:44 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.22 on epoch=434
05/17/2022 13:09:45 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.08 on epoch=437
05/17/2022 13:09:46 - INFO - __main__ - Global step 1750 Train loss 1.20 Classification-F1 0.1 on epoch=437
05/17/2022 13:09:47 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.10 on epoch=439
05/17/2022 13:09:48 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.30 on epoch=442
05/17/2022 13:09:50 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.10 on epoch=444
05/17/2022 13:09:51 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.24 on epoch=447
05/17/2022 13:09:53 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.17 on epoch=449
05/17/2022 13:09:53 - INFO - __main__ - Global step 1800 Train loss 1.18 Classification-F1 0.10126582278481013 on epoch=449
05/17/2022 13:09:55 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.01 on epoch=452
05/17/2022 13:09:56 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.17 on epoch=454
05/17/2022 13:09:57 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.15 on epoch=457
05/17/2022 13:09:59 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.15 on epoch=459
05/17/2022 13:10:00 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.14 on epoch=462
05/17/2022 13:10:01 - INFO - __main__ - Global step 1850 Train loss 1.12 Classification-F1 0.1 on epoch=462
05/17/2022 13:10:02 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.08 on epoch=464
05/17/2022 13:10:04 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.22 on epoch=467
05/17/2022 13:10:05 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.18 on epoch=469
05/17/2022 13:10:06 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.16 on epoch=472
05/17/2022 13:10:08 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.16 on epoch=474
05/17/2022 13:10:08 - INFO - __main__ - Global step 1900 Train loss 1.16 Classification-F1 0.17809523809523808 on epoch=474
05/17/2022 13:10:10 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.15 on epoch=477
05/17/2022 13:10:11 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.23 on epoch=479
05/17/2022 13:10:12 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.17 on epoch=482
05/17/2022 13:10:14 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.03 on epoch=484
05/17/2022 13:10:15 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.10 on epoch=487
05/17/2022 13:10:16 - INFO - __main__ - Global step 1950 Train loss 1.14 Classification-F1 0.1825396825396825 on epoch=487
05/17/2022 13:10:17 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.05 on epoch=489
05/17/2022 13:10:19 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.19 on epoch=492
05/17/2022 13:10:20 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.12 on epoch=494
05/17/2022 13:10:22 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.04 on epoch=497
05/17/2022 13:10:23 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.16 on epoch=499
05/17/2022 13:10:23 - INFO - __main__ - Global step 2000 Train loss 1.11 Classification-F1 0.13067758749069247 on epoch=499
05/17/2022 13:10:25 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.02 on epoch=502
05/17/2022 13:10:26 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.20 on epoch=504
05/17/2022 13:10:28 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.12 on epoch=507
05/17/2022 13:10:29 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.18 on epoch=509
05/17/2022 13:10:31 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.18 on epoch=512
05/17/2022 13:10:31 - INFO - __main__ - Global step 2050 Train loss 1.14 Classification-F1 0.1238095238095238 on epoch=512
05/17/2022 13:10:32 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.08 on epoch=514
05/17/2022 13:10:34 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.08 on epoch=517
05/17/2022 13:10:35 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.09 on epoch=519
05/17/2022 13:10:37 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.12 on epoch=522
05/17/2022 13:10:38 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.05 on epoch=524
05/17/2022 13:10:39 - INFO - __main__ - Global step 2100 Train loss 1.09 Classification-F1 0.1134453781512605 on epoch=524
05/17/2022 13:10:40 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.07 on epoch=527
05/17/2022 13:10:42 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.93 on epoch=529
05/17/2022 13:10:43 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.99 on epoch=532
05/17/2022 13:10:44 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.11 on epoch=534
05/17/2022 13:10:46 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.06 on epoch=537
05/17/2022 13:10:47 - INFO - __main__ - Global step 2150 Train loss 1.03 Classification-F1 0.131328171530673 on epoch=537
05/17/2022 13:10:48 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.06 on epoch=539
05/17/2022 13:10:49 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.18 on epoch=542
05/17/2022 13:10:51 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.98 on epoch=544
05/17/2022 13:10:52 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.14 on epoch=547
05/17/2022 13:10:53 - INFO - __main__ - Step 2200 Global step 2200 Train loss 1.01 on epoch=549
05/17/2022 13:10:54 - INFO - __main__ - Global step 2200 Train loss 1.07 Classification-F1 0.11805555555555555 on epoch=549
05/17/2022 13:10:55 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.07 on epoch=552
05/17/2022 13:10:57 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.11 on epoch=554
05/17/2022 13:10:58 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.11 on epoch=557
05/17/2022 13:11:00 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.05 on epoch=559
05/17/2022 13:11:01 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.02 on epoch=562
05/17/2022 13:11:01 - INFO - __main__ - Global step 2250 Train loss 1.07 Classification-F1 0.1500341763499658 on epoch=562
05/17/2022 13:11:03 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.04 on epoch=564
05/17/2022 13:11:04 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.14 on epoch=567
05/17/2022 13:11:06 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.11 on epoch=569
05/17/2022 13:11:07 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.18 on epoch=572
05/17/2022 13:11:09 - INFO - __main__ - Step 2300 Global step 2300 Train loss 1.06 on epoch=574
05/17/2022 13:11:09 - INFO - __main__ - Global step 2300 Train loss 1.10 Classification-F1 0.17424242424242425 on epoch=574
05/17/2022 13:11:10 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.08 on epoch=577
05/17/2022 13:11:12 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.07 on epoch=579
05/17/2022 13:11:13 - INFO - __main__ - Step 2330 Global step 2330 Train loss 1.08 on epoch=582
05/17/2022 13:11:15 - INFO - __main__ - Step 2340 Global step 2340 Train loss 1.08 on epoch=584
05/17/2022 13:11:16 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.06 on epoch=587
05/17/2022 13:11:17 - INFO - __main__ - Global step 2350 Train loss 1.08 Classification-F1 0.09493670886075949 on epoch=587
05/17/2022 13:11:18 - INFO - __main__ - Step 2360 Global step 2360 Train loss 1.08 on epoch=589
05/17/2022 13:11:20 - INFO - __main__ - Step 2370 Global step 2370 Train loss 1.13 on epoch=592
05/17/2022 13:11:22 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.04 on epoch=594
05/17/2022 13:11:23 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.91 on epoch=597
05/17/2022 13:11:24 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.04 on epoch=599
05/17/2022 13:11:25 - INFO - __main__ - Global step 2400 Train loss 1.04 Classification-F1 0.10135135135135136 on epoch=599
05/17/2022 13:11:26 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.12 on epoch=602
05/17/2022 13:11:28 - INFO - __main__ - Step 2420 Global step 2420 Train loss 1.05 on epoch=604
05/17/2022 13:11:29 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.09 on epoch=607
05/17/2022 13:11:31 - INFO - __main__ - Step 2440 Global step 2440 Train loss 1.08 on epoch=609
05/17/2022 13:11:32 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.05 on epoch=612
05/17/2022 13:11:33 - INFO - __main__ - Global step 2450 Train loss 1.08 Classification-F1 0.09615384615384615 on epoch=612
05/17/2022 13:11:34 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.02 on epoch=614
05/17/2022 13:11:35 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.09 on epoch=617
05/17/2022 13:11:37 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.97 on epoch=619
05/17/2022 13:11:38 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.00 on epoch=622
05/17/2022 13:11:40 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.90 on epoch=624
05/17/2022 13:11:40 - INFO - __main__ - Global step 2500 Train loss 1.00 Classification-F1 0.09493670886075949 on epoch=624
05/17/2022 13:11:42 - INFO - __main__ - Step 2510 Global step 2510 Train loss 1.03 on epoch=627
05/17/2022 13:11:43 - INFO - __main__ - Step 2520 Global step 2520 Train loss 1.09 on epoch=629
05/17/2022 13:11:44 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.03 on epoch=632
05/17/2022 13:11:46 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.97 on epoch=634
05/17/2022 13:11:47 - INFO - __main__ - Step 2550 Global step 2550 Train loss 1.04 on epoch=637
05/17/2022 13:11:48 - INFO - __main__ - Global step 2550 Train loss 1.03 Classification-F1 0.15584415584415584 on epoch=637
05/17/2022 13:11:49 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.94 on epoch=639
05/17/2022 13:11:50 - INFO - __main__ - Step 2570 Global step 2570 Train loss 1.10 on epoch=642
05/17/2022 13:11:52 - INFO - __main__ - Step 2580 Global step 2580 Train loss 1.08 on epoch=644
05/17/2022 13:11:53 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.09 on epoch=647
05/17/2022 13:11:55 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.87 on epoch=649
05/17/2022 13:11:55 - INFO - __main__ - Global step 2600 Train loss 1.02 Classification-F1 0.13034188034188032 on epoch=649
05/17/2022 13:11:56 - INFO - __main__ - Step 2610 Global step 2610 Train loss 1.05 on epoch=652
05/17/2022 13:11:58 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.98 on epoch=654
05/17/2022 13:11:59 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.99 on epoch=657
05/17/2022 13:12:01 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.00 on epoch=659
05/17/2022 13:12:02 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.01 on epoch=662
05/17/2022 13:12:03 - INFO - __main__ - Global step 2650 Train loss 1.01 Classification-F1 0.11078022632519356 on epoch=662
05/17/2022 13:12:04 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.98 on epoch=664
05/17/2022 13:12:05 - INFO - __main__ - Step 2670 Global step 2670 Train loss 1.02 on epoch=667
05/17/2022 13:12:07 - INFO - __main__ - Step 2680 Global step 2680 Train loss 1.05 on epoch=669
05/17/2022 13:12:08 - INFO - __main__ - Step 2690 Global step 2690 Train loss 1.09 on epoch=672
05/17/2022 13:12:10 - INFO - __main__ - Step 2700 Global step 2700 Train loss 1.05 on epoch=674
05/17/2022 13:12:10 - INFO - __main__ - Global step 2700 Train loss 1.04 Classification-F1 0.21286031042128603 on epoch=674
05/17/2022 13:12:12 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.01 on epoch=677
05/17/2022 13:12:13 - INFO - __main__ - Step 2720 Global step 2720 Train loss 1.11 on epoch=679
05/17/2022 13:12:14 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.96 on epoch=682
05/17/2022 13:12:16 - INFO - __main__ - Step 2740 Global step 2740 Train loss 1.09 on epoch=684
05/17/2022 13:12:17 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.93 on epoch=687
05/17/2022 13:12:18 - INFO - __main__ - Global step 2750 Train loss 1.02 Classification-F1 0.1 on epoch=687
05/17/2022 13:12:19 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.03 on epoch=689
05/17/2022 13:12:21 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.00 on epoch=692
05/17/2022 13:12:22 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.93 on epoch=694
05/17/2022 13:12:23 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.97 on epoch=697
05/17/2022 13:12:25 - INFO - __main__ - Step 2800 Global step 2800 Train loss 1.05 on epoch=699
05/17/2022 13:12:25 - INFO - __main__ - Global step 2800 Train loss 0.99 Classification-F1 0.23444444444444448 on epoch=699
05/17/2022 13:12:26 - INFO - __main__ - Saving model with best Classification-F1: 0.21560846560846564 -> 0.23444444444444448 on epoch=699, global_step=2800
05/17/2022 13:12:27 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.03 on epoch=702
05/17/2022 13:12:28 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.99 on epoch=704
05/17/2022 13:12:30 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.98 on epoch=707
05/17/2022 13:12:31 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.96 on epoch=709
05/17/2022 13:12:32 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.95 on epoch=712
05/17/2022 13:12:33 - INFO - __main__ - Global step 2850 Train loss 0.98 Classification-F1 0.18218623481781374 on epoch=712
05/17/2022 13:12:34 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.98 on epoch=714
05/17/2022 13:12:35 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.98 on epoch=717
05/17/2022 13:12:37 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.94 on epoch=719
05/17/2022 13:12:38 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.05 on epoch=722
05/17/2022 13:12:40 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.00 on epoch=724
05/17/2022 13:12:40 - INFO - __main__ - Global step 2900 Train loss 0.99 Classification-F1 0.13333333333333333 on epoch=724
05/17/2022 13:12:42 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.02 on epoch=727
05/17/2022 13:12:43 - INFO - __main__ - Step 2920 Global step 2920 Train loss 1.05 on epoch=729
05/17/2022 13:12:45 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.96 on epoch=732
05/17/2022 13:12:46 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.94 on epoch=734
05/17/2022 13:12:47 - INFO - __main__ - Step 2950 Global step 2950 Train loss 1.04 on epoch=737
05/17/2022 13:12:48 - INFO - __main__ - Global step 2950 Train loss 1.00 Classification-F1 0.19778549717759447 on epoch=737
05/17/2022 13:12:49 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.93 on epoch=739
05/17/2022 13:12:50 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.04 on epoch=742
05/17/2022 13:12:52 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.96 on epoch=744
05/17/2022 13:12:54 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.93 on epoch=747
05/17/2022 13:12:55 - INFO - __main__ - Step 3000 Global step 3000 Train loss 1.05 on epoch=749
05/17/2022 13:12:55 - INFO - __main__ - Global step 3000 Train loss 0.98 Classification-F1 0.11805555555555555 on epoch=749
05/17/2022 13:12:55 - INFO - __main__ - save last model!
05/17/2022 13:12:55 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/17/2022 13:12:55 - INFO - __main__ - Start tokenizing ... 5509 instances
05/17/2022 13:12:55 - INFO - __main__ - Printing 3 examples
05/17/2022 13:12:55 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/17/2022 13:12:55 - INFO - __main__ - ['others']
05/17/2022 13:12:55 - INFO - __main__ -  [emo] what you like very little things ok
05/17/2022 13:12:55 - INFO - __main__ - ['others']
05/17/2022 13:12:55 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/17/2022 13:12:55 - INFO - __main__ - ['others']
05/17/2022 13:12:55 - INFO - __main__ - Tokenizing Input ...
05/17/2022 13:12:56 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 13:12:56 - INFO - __main__ - Printing 3 examples
05/17/2022 13:12:56 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
05/17/2022 13:12:56 - INFO - __main__ - ['sad']
05/17/2022 13:12:56 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
05/17/2022 13:12:56 - INFO - __main__ - ['sad']
05/17/2022 13:12:56 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
05/17/2022 13:12:56 - INFO - __main__ - ['sad']
05/17/2022 13:12:56 - INFO - __main__ - Tokenizing Input ...
05/17/2022 13:12:56 - INFO - __main__ - Tokenizing Output ...
05/17/2022 13:12:56 - INFO - __main__ - Loaded 64 examples from train data
05/17/2022 13:12:56 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 13:12:56 - INFO - __main__ - Printing 3 examples
05/17/2022 13:12:56 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
05/17/2022 13:12:56 - INFO - __main__ - ['sad']
05/17/2022 13:12:56 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
05/17/2022 13:12:56 - INFO - __main__ - ['sad']
05/17/2022 13:12:56 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
05/17/2022 13:12:56 - INFO - __main__ - ['sad']
05/17/2022 13:12:56 - INFO - __main__ - Tokenizing Input ...
05/17/2022 13:12:56 - INFO - __main__ - Tokenizing Output ...
05/17/2022 13:12:56 - INFO - __main__ - Loaded 64 examples from dev data
05/17/2022 13:12:58 - INFO - __main__ - Tokenizing Output ...
05/17/2022 13:13:03 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 13:13:03 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 13:13:03 - INFO - __main__ - Starting training!
05/17/2022 13:13:05 - INFO - __main__ - Loaded 5509 examples from test data
05/17/2022 13:13:54 - INFO - __main__ - Saved prediction in models/T5-base-reptile-cls2cls-3e-5-2-5000-5e-1-10/singletask-emo/emo_16_21_0.3_8_predictions.txt
05/17/2022 13:13:54 - INFO - __main__ - Classification-F1 on test data: 0.2180
05/17/2022 13:13:54 - INFO - __main__ - prefix=emo_16_21, lr=0.3, bsz=8, dev_performance=0.23444444444444448, test_performance=0.21803137791957744
05/17/2022 13:13:54 - INFO - __main__ - Running ... prefix=emo_16_21, lr=0.2, bsz=8 ...
05/17/2022 13:13:55 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 13:13:55 - INFO - __main__ - Printing 3 examples
05/17/2022 13:13:55 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
05/17/2022 13:13:55 - INFO - __main__ - ['sad']
05/17/2022 13:13:55 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
05/17/2022 13:13:55 - INFO - __main__ - ['sad']
05/17/2022 13:13:55 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
05/17/2022 13:13:55 - INFO - __main__ - ['sad']
05/17/2022 13:13:55 - INFO - __main__ - Tokenizing Input ...
05/17/2022 13:13:55 - INFO - __main__ - Tokenizing Output ...
05/17/2022 13:13:55 - INFO - __main__ - Loaded 64 examples from train data
05/17/2022 13:13:55 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 13:13:55 - INFO - __main__ - Printing 3 examples
05/17/2022 13:13:55 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
05/17/2022 13:13:55 - INFO - __main__ - ['sad']
05/17/2022 13:13:55 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
05/17/2022 13:13:55 - INFO - __main__ - ['sad']
05/17/2022 13:13:55 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
05/17/2022 13:13:55 - INFO - __main__ - ['sad']
05/17/2022 13:13:55 - INFO - __main__ - Tokenizing Input ...
05/17/2022 13:13:55 - INFO - __main__ - Tokenizing Output ...
05/17/2022 13:13:55 - INFO - __main__ - Loaded 64 examples from dev data
05/17/2022 13:14:01 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 13:14:01 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 13:14:01 - INFO - __main__ - Starting training!
05/17/2022 13:14:03 - INFO - __main__ - Step 10 Global step 10 Train loss 8.76 on epoch=2
05/17/2022 13:14:04 - INFO - __main__ - Step 20 Global step 20 Train loss 8.77 on epoch=4
05/17/2022 13:14:05 - INFO - __main__ - Step 30 Global step 30 Train loss 8.71 on epoch=7
05/17/2022 13:14:07 - INFO - __main__ - Step 40 Global step 40 Train loss 8.69 on epoch=9
05/17/2022 13:14:08 - INFO - __main__ - Step 50 Global step 50 Train loss 8.67 on epoch=12
05/17/2022 13:14:14 - INFO - __main__ - Global step 50 Train loss 8.72 Classification-F1 0.0 on epoch=12
05/17/2022 13:14:15 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/17/2022 13:14:16 - INFO - __main__ - Step 60 Global step 60 Train loss 8.59 on epoch=14
05/17/2022 13:14:17 - INFO - __main__ - Step 70 Global step 70 Train loss 8.45 on epoch=17
05/17/2022 13:14:19 - INFO - __main__ - Step 80 Global step 80 Train loss 8.57 on epoch=19
05/17/2022 13:14:20 - INFO - __main__ - Step 90 Global step 90 Train loss 8.54 on epoch=22
05/17/2022 13:14:22 - INFO - __main__ - Step 100 Global step 100 Train loss 8.58 on epoch=24
05/17/2022 13:14:27 - INFO - __main__ - Global step 100 Train loss 8.55 Classification-F1 0.0 on epoch=24
05/17/2022 13:14:28 - INFO - __main__ - Step 110 Global step 110 Train loss 8.53 on epoch=27
05/17/2022 13:14:30 - INFO - __main__ - Step 120 Global step 120 Train loss 8.50 on epoch=29
05/17/2022 13:14:31 - INFO - __main__ - Step 130 Global step 130 Train loss 8.39 on epoch=32
05/17/2022 13:14:32 - INFO - __main__ - Step 140 Global step 140 Train loss 8.45 on epoch=34
05/17/2022 13:14:34 - INFO - __main__ - Step 150 Global step 150 Train loss 8.43 on epoch=37
05/17/2022 13:14:41 - INFO - __main__ - Global step 150 Train loss 8.46 Classification-F1 0.0 on epoch=37
05/17/2022 13:14:42 - INFO - __main__ - Step 160 Global step 160 Train loss 8.46 on epoch=39
05/17/2022 13:14:44 - INFO - __main__ - Step 170 Global step 170 Train loss 8.38 on epoch=42
05/17/2022 13:14:45 - INFO - __main__ - Step 180 Global step 180 Train loss 8.23 on epoch=44
05/17/2022 13:14:46 - INFO - __main__ - Step 190 Global step 190 Train loss 8.25 on epoch=47
05/17/2022 13:14:48 - INFO - __main__ - Step 200 Global step 200 Train loss 8.27 on epoch=49
05/17/2022 13:14:54 - INFO - __main__ - Global step 200 Train loss 8.32 Classification-F1 0.0 on epoch=49
05/17/2022 13:14:55 - INFO - __main__ - Step 210 Global step 210 Train loss 8.24 on epoch=52
05/17/2022 13:14:57 - INFO - __main__ - Step 220 Global step 220 Train loss 8.25 on epoch=54
05/17/2022 13:14:58 - INFO - __main__ - Step 230 Global step 230 Train loss 8.18 on epoch=57
05/17/2022 13:14:59 - INFO - __main__ - Step 240 Global step 240 Train loss 8.11 on epoch=59
05/17/2022 13:15:01 - INFO - __main__ - Step 250 Global step 250 Train loss 8.08 on epoch=62
05/17/2022 13:15:08 - INFO - __main__ - Global step 250 Train loss 8.17 Classification-F1 0.0 on epoch=62
05/17/2022 13:15:10 - INFO - __main__ - Step 260 Global step 260 Train loss 8.04 on epoch=64
05/17/2022 13:15:11 - INFO - __main__ - Step 270 Global step 270 Train loss 8.07 on epoch=67
05/17/2022 13:15:13 - INFO - __main__ - Step 280 Global step 280 Train loss 8.06 on epoch=69
05/17/2022 13:15:14 - INFO - __main__ - Step 290 Global step 290 Train loss 8.06 on epoch=72
05/17/2022 13:15:15 - INFO - __main__ - Step 300 Global step 300 Train loss 7.87 on epoch=74
05/17/2022 13:15:24 - INFO - __main__ - Global step 300 Train loss 8.02 Classification-F1 0.0 on epoch=74
05/17/2022 13:15:25 - INFO - __main__ - Step 310 Global step 310 Train loss 7.75 on epoch=77
05/17/2022 13:15:27 - INFO - __main__ - Step 320 Global step 320 Train loss 7.81 on epoch=79
05/17/2022 13:15:28 - INFO - __main__ - Step 330 Global step 330 Train loss 7.83 on epoch=82
05/17/2022 13:15:30 - INFO - __main__ - Step 340 Global step 340 Train loss 7.70 on epoch=84
05/17/2022 13:15:31 - INFO - __main__ - Step 350 Global step 350 Train loss 7.69 on epoch=87
05/17/2022 13:15:40 - INFO - __main__ - Global step 350 Train loss 7.75 Classification-F1 0.0 on epoch=87
05/17/2022 13:15:42 - INFO - __main__ - Step 360 Global step 360 Train loss 7.52 on epoch=89
05/17/2022 13:15:43 - INFO - __main__ - Step 370 Global step 370 Train loss 7.58 on epoch=92
05/17/2022 13:15:44 - INFO - __main__ - Step 380 Global step 380 Train loss 7.60 on epoch=94
05/17/2022 13:15:46 - INFO - __main__ - Step 390 Global step 390 Train loss 7.48 on epoch=97
05/17/2022 13:15:47 - INFO - __main__ - Step 400 Global step 400 Train loss 7.48 on epoch=99
05/17/2022 13:16:00 - INFO - __main__ - Global step 400 Train loss 7.53 Classification-F1 0.0 on epoch=99
05/17/2022 13:16:01 - INFO - __main__ - Step 410 Global step 410 Train loss 7.36 on epoch=102
05/17/2022 13:16:03 - INFO - __main__ - Step 420 Global step 420 Train loss 7.29 on epoch=104
05/17/2022 13:16:04 - INFO - __main__ - Step 430 Global step 430 Train loss 7.10 on epoch=107
05/17/2022 13:16:05 - INFO - __main__ - Step 440 Global step 440 Train loss 7.22 on epoch=109
05/17/2022 13:16:07 - INFO - __main__ - Step 450 Global step 450 Train loss 7.27 on epoch=112
05/17/2022 13:16:10 - INFO - __main__ - Global step 450 Train loss 7.25 Classification-F1 0.0 on epoch=112
05/17/2022 13:16:11 - INFO - __main__ - Step 460 Global step 460 Train loss 7.09 on epoch=114
05/17/2022 13:16:13 - INFO - __main__ - Step 470 Global step 470 Train loss 7.09 on epoch=117
05/17/2022 13:16:14 - INFO - __main__ - Step 480 Global step 480 Train loss 7.04 on epoch=119
05/17/2022 13:16:15 - INFO - __main__ - Step 490 Global step 490 Train loss 7.13 on epoch=122
05/17/2022 13:16:17 - INFO - __main__ - Step 500 Global step 500 Train loss 6.98 on epoch=124
05/17/2022 13:16:21 - INFO - __main__ - Global step 500 Train loss 7.07 Classification-F1 0.0 on epoch=124
05/17/2022 13:16:23 - INFO - __main__ - Step 510 Global step 510 Train loss 6.96 on epoch=127
05/17/2022 13:16:24 - INFO - __main__ - Step 520 Global step 520 Train loss 6.91 on epoch=129
05/17/2022 13:16:25 - INFO - __main__ - Step 530 Global step 530 Train loss 6.83 on epoch=132
05/17/2022 13:16:27 - INFO - __main__ - Step 540 Global step 540 Train loss 6.89 on epoch=134
05/17/2022 13:16:29 - INFO - __main__ - Step 550 Global step 550 Train loss 6.67 on epoch=137
05/17/2022 13:16:34 - INFO - __main__ - Global step 550 Train loss 6.85 Classification-F1 0.0 on epoch=137
05/17/2022 13:16:35 - INFO - __main__ - Step 560 Global step 560 Train loss 6.69 on epoch=139
05/17/2022 13:16:37 - INFO - __main__ - Step 570 Global step 570 Train loss 6.67 on epoch=142
05/17/2022 13:16:38 - INFO - __main__ - Step 580 Global step 580 Train loss 6.66 on epoch=144
05/17/2022 13:16:40 - INFO - __main__ - Step 590 Global step 590 Train loss 6.76 on epoch=147
05/17/2022 13:16:41 - INFO - __main__ - Step 600 Global step 600 Train loss 6.51 on epoch=149
05/17/2022 13:16:51 - INFO - __main__ - Global step 600 Train loss 6.66 Classification-F1 0.0 on epoch=149
05/17/2022 13:16:53 - INFO - __main__ - Step 610 Global step 610 Train loss 6.50 on epoch=152
05/17/2022 13:16:54 - INFO - __main__ - Step 620 Global step 620 Train loss 6.57 on epoch=154
05/17/2022 13:16:55 - INFO - __main__ - Step 630 Global step 630 Train loss 6.45 on epoch=157
05/17/2022 13:16:57 - INFO - __main__ - Step 640 Global step 640 Train loss 6.44 on epoch=159
05/17/2022 13:16:58 - INFO - __main__ - Step 650 Global step 650 Train loss 6.47 on epoch=162
05/17/2022 13:17:02 - INFO - __main__ - Global step 650 Train loss 6.49 Classification-F1 0.0 on epoch=162
05/17/2022 13:17:04 - INFO - __main__ - Step 660 Global step 660 Train loss 6.32 on epoch=164
05/17/2022 13:17:05 - INFO - __main__ - Step 670 Global step 670 Train loss 6.37 on epoch=167
05/17/2022 13:17:07 - INFO - __main__ - Step 680 Global step 680 Train loss 6.17 on epoch=169
05/17/2022 13:17:08 - INFO - __main__ - Step 690 Global step 690 Train loss 6.27 on epoch=172
05/17/2022 13:17:10 - INFO - __main__ - Step 700 Global step 700 Train loss 6.16 on epoch=174
05/17/2022 13:17:19 - INFO - __main__ - Global step 700 Train loss 6.26 Classification-F1 0.0 on epoch=174
05/17/2022 13:17:20 - INFO - __main__ - Step 710 Global step 710 Train loss 6.22 on epoch=177
05/17/2022 13:17:22 - INFO - __main__ - Step 720 Global step 720 Train loss 5.96 on epoch=179
05/17/2022 13:17:24 - INFO - __main__ - Step 730 Global step 730 Train loss 6.03 on epoch=182
05/17/2022 13:17:25 - INFO - __main__ - Step 740 Global step 740 Train loss 6.03 on epoch=184
05/17/2022 13:17:26 - INFO - __main__ - Step 750 Global step 750 Train loss 6.22 on epoch=187
05/17/2022 13:17:33 - INFO - __main__ - Global step 750 Train loss 6.09 Classification-F1 0.0 on epoch=187
05/17/2022 13:17:35 - INFO - __main__ - Step 760 Global step 760 Train loss 6.08 on epoch=189
05/17/2022 13:17:36 - INFO - __main__ - Step 770 Global step 770 Train loss 6.08 on epoch=192
05/17/2022 13:17:38 - INFO - __main__ - Step 780 Global step 780 Train loss 5.97 on epoch=194
05/17/2022 13:17:39 - INFO - __main__ - Step 790 Global step 790 Train loss 5.81 on epoch=197
05/17/2022 13:17:40 - INFO - __main__ - Step 800 Global step 800 Train loss 5.55 on epoch=199
05/17/2022 13:17:47 - INFO - __main__ - Global step 800 Train loss 5.90 Classification-F1 0.0 on epoch=199
05/17/2022 13:17:49 - INFO - __main__ - Step 810 Global step 810 Train loss 5.74 on epoch=202
05/17/2022 13:17:50 - INFO - __main__ - Step 820 Global step 820 Train loss 5.68 on epoch=204
05/17/2022 13:17:51 - INFO - __main__ - Step 830 Global step 830 Train loss 5.80 on epoch=207
05/17/2022 13:17:53 - INFO - __main__ - Step 840 Global step 840 Train loss 5.66 on epoch=209
05/17/2022 13:17:54 - INFO - __main__ - Step 850 Global step 850 Train loss 5.66 on epoch=212
05/17/2022 13:17:59 - INFO - __main__ - Global step 850 Train loss 5.71 Classification-F1 0.0 on epoch=212
05/17/2022 13:18:00 - INFO - __main__ - Step 860 Global step 860 Train loss 5.78 on epoch=214
05/17/2022 13:18:02 - INFO - __main__ - Step 870 Global step 870 Train loss 5.78 on epoch=217
05/17/2022 13:18:03 - INFO - __main__ - Step 880 Global step 880 Train loss 5.35 on epoch=219
05/17/2022 13:18:04 - INFO - __main__ - Step 890 Global step 890 Train loss 5.50 on epoch=222
05/17/2022 13:18:06 - INFO - __main__ - Step 900 Global step 900 Train loss 5.55 on epoch=224
05/17/2022 13:18:14 - INFO - __main__ - Global step 900 Train loss 5.59 Classification-F1 0.0 on epoch=224
05/17/2022 13:18:16 - INFO - __main__ - Step 910 Global step 910 Train loss 5.47 on epoch=227
05/17/2022 13:18:17 - INFO - __main__ - Step 920 Global step 920 Train loss 5.38 on epoch=229
05/17/2022 13:18:18 - INFO - __main__ - Step 930 Global step 930 Train loss 5.46 on epoch=232
05/17/2022 13:18:20 - INFO - __main__ - Step 940 Global step 940 Train loss 5.24 on epoch=234
05/17/2022 13:18:21 - INFO - __main__ - Step 950 Global step 950 Train loss 5.33 on epoch=237
05/17/2022 13:18:31 - INFO - __main__ - Global step 950 Train loss 5.38 Classification-F1 0.0 on epoch=237
05/17/2022 13:18:33 - INFO - __main__ - Step 960 Global step 960 Train loss 5.28 on epoch=239
05/17/2022 13:18:34 - INFO - __main__ - Step 970 Global step 970 Train loss 5.30 on epoch=242
05/17/2022 13:18:35 - INFO - __main__ - Step 980 Global step 980 Train loss 4.98 on epoch=244
05/17/2022 13:18:37 - INFO - __main__ - Step 990 Global step 990 Train loss 5.12 on epoch=247
05/17/2022 13:18:38 - INFO - __main__ - Step 1000 Global step 1000 Train loss 5.03 on epoch=249
05/17/2022 13:18:49 - INFO - __main__ - Global step 1000 Train loss 5.14 Classification-F1 0.0 on epoch=249
05/17/2022 13:18:50 - INFO - __main__ - Step 1010 Global step 1010 Train loss 5.06 on epoch=252
05/17/2022 13:18:52 - INFO - __main__ - Step 1020 Global step 1020 Train loss 4.89 on epoch=254
05/17/2022 13:18:53 - INFO - __main__ - Step 1030 Global step 1030 Train loss 5.12 on epoch=257
05/17/2022 13:18:55 - INFO - __main__ - Step 1040 Global step 1040 Train loss 5.03 on epoch=259
05/17/2022 13:18:56 - INFO - __main__ - Step 1050 Global step 1050 Train loss 4.94 on epoch=262
05/17/2022 13:19:06 - INFO - __main__ - Global step 1050 Train loss 5.01 Classification-F1 0.0 on epoch=262
05/17/2022 13:19:07 - INFO - __main__ - Step 1060 Global step 1060 Train loss 4.87 on epoch=264
05/17/2022 13:19:09 - INFO - __main__ - Step 1070 Global step 1070 Train loss 4.75 on epoch=267
05/17/2022 13:19:11 - INFO - __main__ - Step 1080 Global step 1080 Train loss 4.75 on epoch=269
05/17/2022 13:19:12 - INFO - __main__ - Step 1090 Global step 1090 Train loss 4.74 on epoch=272
05/17/2022 13:19:14 - INFO - __main__ - Step 1100 Global step 1100 Train loss 4.64 on epoch=274
05/17/2022 13:19:30 - INFO - __main__ - Global step 1100 Train loss 4.75 Classification-F1 0.0 on epoch=274
05/17/2022 13:19:31 - INFO - __main__ - Step 1110 Global step 1110 Train loss 4.84 on epoch=277
05/17/2022 13:19:32 - INFO - __main__ - Step 1120 Global step 1120 Train loss 4.58 on epoch=279
05/17/2022 13:19:34 - INFO - __main__ - Step 1130 Global step 1130 Train loss 4.67 on epoch=282
05/17/2022 13:19:35 - INFO - __main__ - Step 1140 Global step 1140 Train loss 4.42 on epoch=284
05/17/2022 13:19:36 - INFO - __main__ - Step 1150 Global step 1150 Train loss 4.70 on epoch=287
05/17/2022 13:19:56 - INFO - __main__ - Global step 1150 Train loss 4.64 Classification-F1 0.0 on epoch=287
05/17/2022 13:19:58 - INFO - __main__ - Step 1160 Global step 1160 Train loss 4.55 on epoch=289
05/17/2022 13:19:59 - INFO - __main__ - Step 1170 Global step 1170 Train loss 4.65 on epoch=292
05/17/2022 13:20:00 - INFO - __main__ - Step 1180 Global step 1180 Train loss 4.36 on epoch=294
05/17/2022 13:20:02 - INFO - __main__ - Step 1190 Global step 1190 Train loss 4.50 on epoch=297
05/17/2022 13:20:03 - INFO - __main__ - Step 1200 Global step 1200 Train loss 4.45 on epoch=299
05/17/2022 13:20:11 - INFO - __main__ - Global step 1200 Train loss 4.50 Classification-F1 0.0 on epoch=299
05/17/2022 13:20:12 - INFO - __main__ - Step 1210 Global step 1210 Train loss 4.48 on epoch=302
05/17/2022 13:20:14 - INFO - __main__ - Step 1220 Global step 1220 Train loss 4.42 on epoch=304
05/17/2022 13:20:15 - INFO - __main__ - Step 1230 Global step 1230 Train loss 4.24 on epoch=307
05/17/2022 13:20:16 - INFO - __main__ - Step 1240 Global step 1240 Train loss 4.31 on epoch=309
05/17/2022 13:20:18 - INFO - __main__ - Step 1250 Global step 1250 Train loss 4.37 on epoch=312
05/17/2022 13:20:24 - INFO - __main__ - Global step 1250 Train loss 4.36 Classification-F1 0.0 on epoch=312
05/17/2022 13:20:25 - INFO - __main__ - Step 1260 Global step 1260 Train loss 4.07 on epoch=314
05/17/2022 13:20:27 - INFO - __main__ - Step 1270 Global step 1270 Train loss 4.28 on epoch=317
05/17/2022 13:20:28 - INFO - __main__ - Step 1280 Global step 1280 Train loss 4.21 on epoch=319
05/17/2022 13:20:29 - INFO - __main__ - Step 1290 Global step 1290 Train loss 4.11 on epoch=322
05/17/2022 13:20:31 - INFO - __main__ - Step 1300 Global step 1300 Train loss 4.06 on epoch=324
05/17/2022 13:20:39 - INFO - __main__ - Global step 1300 Train loss 4.15 Classification-F1 0.0 on epoch=324
05/17/2022 13:20:40 - INFO - __main__ - Step 1310 Global step 1310 Train loss 4.19 on epoch=327
05/17/2022 13:20:42 - INFO - __main__ - Step 1320 Global step 1320 Train loss 4.10 on epoch=329
05/17/2022 13:20:43 - INFO - __main__ - Step 1330 Global step 1330 Train loss 4.21 on epoch=332
05/17/2022 13:20:44 - INFO - __main__ - Step 1340 Global step 1340 Train loss 4.13 on epoch=334
05/17/2022 13:20:46 - INFO - __main__ - Step 1350 Global step 1350 Train loss 3.99 on epoch=337
05/17/2022 13:20:56 - INFO - __main__ - Global step 1350 Train loss 4.13 Classification-F1 0.0 on epoch=337
05/17/2022 13:20:57 - INFO - __main__ - Step 1360 Global step 1360 Train loss 3.89 on epoch=339
05/17/2022 13:20:58 - INFO - __main__ - Step 1370 Global step 1370 Train loss 4.09 on epoch=342
05/17/2022 13:20:59 - INFO - __main__ - Step 1380 Global step 1380 Train loss 3.97 on epoch=344
05/17/2022 13:21:01 - INFO - __main__ - Step 1390 Global step 1390 Train loss 3.97 on epoch=347
05/17/2022 13:21:02 - INFO - __main__ - Step 1400 Global step 1400 Train loss 3.58 on epoch=349
05/17/2022 13:21:07 - INFO - __main__ - Global step 1400 Train loss 3.90 Classification-F1 0.0 on epoch=349
05/17/2022 13:21:08 - INFO - __main__ - Step 1410 Global step 1410 Train loss 3.80 on epoch=352
05/17/2022 13:21:10 - INFO - __main__ - Step 1420 Global step 1420 Train loss 3.82 on epoch=354
05/17/2022 13:21:12 - INFO - __main__ - Step 1430 Global step 1430 Train loss 3.89 on epoch=357
05/17/2022 13:21:13 - INFO - __main__ - Step 1440 Global step 1440 Train loss 3.79 on epoch=359
05/17/2022 13:21:15 - INFO - __main__ - Step 1450 Global step 1450 Train loss 3.70 on epoch=362
05/17/2022 13:21:16 - INFO - __main__ - Global step 1450 Train loss 3.80 Classification-F1 0.03636363636363636 on epoch=362
05/17/2022 13:21:16 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.03636363636363636 on epoch=362, global_step=1450
05/17/2022 13:21:17 - INFO - __main__ - Step 1460 Global step 1460 Train loss 3.63 on epoch=364
05/17/2022 13:21:19 - INFO - __main__ - Step 1470 Global step 1470 Train loss 3.66 on epoch=367
05/17/2022 13:21:20 - INFO - __main__ - Step 1480 Global step 1480 Train loss 3.57 on epoch=369
05/17/2022 13:21:22 - INFO - __main__ - Step 1490 Global step 1490 Train loss 3.64 on epoch=372
05/17/2022 13:21:23 - INFO - __main__ - Step 1500 Global step 1500 Train loss 3.66 on epoch=374
05/17/2022 13:21:24 - INFO - __main__ - Global step 1500 Train loss 3.63 Classification-F1 0.07792207792207792 on epoch=374
05/17/2022 13:21:24 - INFO - __main__ - Saving model with best Classification-F1: 0.03636363636363636 -> 0.07792207792207792 on epoch=374, global_step=1500
05/17/2022 13:21:26 - INFO - __main__ - Step 1510 Global step 1510 Train loss 3.52 on epoch=377
05/17/2022 13:21:28 - INFO - __main__ - Step 1520 Global step 1520 Train loss 3.51 on epoch=379
05/17/2022 13:21:29 - INFO - __main__ - Step 1530 Global step 1530 Train loss 3.75 on epoch=382
05/17/2022 13:21:31 - INFO - __main__ - Step 1540 Global step 1540 Train loss 3.55 on epoch=384
05/17/2022 13:21:32 - INFO - __main__ - Step 1550 Global step 1550 Train loss 3.55 on epoch=387
05/17/2022 13:21:34 - INFO - __main__ - Global step 1550 Train loss 3.58 Classification-F1 0.0810126582278481 on epoch=387
05/17/2022 13:21:34 - INFO - __main__ - Saving model with best Classification-F1: 0.07792207792207792 -> 0.0810126582278481 on epoch=387, global_step=1550
05/17/2022 13:21:36 - INFO - __main__ - Step 1560 Global step 1560 Train loss 3.46 on epoch=389
05/17/2022 13:21:37 - INFO - __main__ - Step 1570 Global step 1570 Train loss 3.47 on epoch=392
05/17/2022 13:21:38 - INFO - __main__ - Step 1580 Global step 1580 Train loss 3.31 on epoch=394
05/17/2022 13:21:40 - INFO - __main__ - Step 1590 Global step 1590 Train loss 3.39 on epoch=397
05/17/2022 13:21:41 - INFO - __main__ - Step 1600 Global step 1600 Train loss 3.49 on epoch=399
05/17/2022 13:21:42 - INFO - __main__ - Global step 1600 Train loss 3.42 Classification-F1 0.15526315789473685 on epoch=399
05/17/2022 13:21:42 - INFO - __main__ - Saving model with best Classification-F1: 0.0810126582278481 -> 0.15526315789473685 on epoch=399, global_step=1600
05/17/2022 13:21:44 - INFO - __main__ - Step 1610 Global step 1610 Train loss 3.44 on epoch=402
05/17/2022 13:21:45 - INFO - __main__ - Step 1620 Global step 1620 Train loss 3.31 on epoch=404
05/17/2022 13:21:46 - INFO - __main__ - Step 1630 Global step 1630 Train loss 3.36 on epoch=407
05/17/2022 13:21:48 - INFO - __main__ - Step 1640 Global step 1640 Train loss 3.25 on epoch=409
05/17/2022 13:21:49 - INFO - __main__ - Step 1650 Global step 1650 Train loss 3.18 on epoch=412
05/17/2022 13:21:50 - INFO - __main__ - Global step 1650 Train loss 3.31 Classification-F1 0.1 on epoch=412
05/17/2022 13:21:51 - INFO - __main__ - Step 1660 Global step 1660 Train loss 3.06 on epoch=414
05/17/2022 13:21:53 - INFO - __main__ - Step 1670 Global step 1670 Train loss 3.24 on epoch=417
05/17/2022 13:21:54 - INFO - __main__ - Step 1680 Global step 1680 Train loss 2.97 on epoch=419
05/17/2022 13:21:55 - INFO - __main__ - Step 1690 Global step 1690 Train loss 3.13 on epoch=422
05/17/2022 13:21:57 - INFO - __main__ - Step 1700 Global step 1700 Train loss 2.97 on epoch=424
05/17/2022 13:21:57 - INFO - __main__ - Global step 1700 Train loss 3.07 Classification-F1 0.1 on epoch=424
05/17/2022 13:21:59 - INFO - __main__ - Step 1710 Global step 1710 Train loss 3.00 on epoch=427
05/17/2022 13:22:00 - INFO - __main__ - Step 1720 Global step 1720 Train loss 2.70 on epoch=429
05/17/2022 13:22:01 - INFO - __main__ - Step 1730 Global step 1730 Train loss 2.86 on epoch=432
05/17/2022 13:22:03 - INFO - __main__ - Step 1740 Global step 1740 Train loss 2.78 on epoch=434
05/17/2022 13:22:04 - INFO - __main__ - Step 1750 Global step 1750 Train loss 2.77 on epoch=437
05/17/2022 13:22:05 - INFO - __main__ - Global step 1750 Train loss 2.82 Classification-F1 0.1 on epoch=437
05/17/2022 13:22:06 - INFO - __main__ - Step 1760 Global step 1760 Train loss 2.64 on epoch=439
05/17/2022 13:22:08 - INFO - __main__ - Step 1770 Global step 1770 Train loss 2.69 on epoch=442
05/17/2022 13:22:09 - INFO - __main__ - Step 1780 Global step 1780 Train loss 2.59 on epoch=444
05/17/2022 13:22:11 - INFO - __main__ - Step 1790 Global step 1790 Train loss 2.61 on epoch=447
05/17/2022 13:22:12 - INFO - __main__ - Step 1800 Global step 1800 Train loss 2.64 on epoch=449
05/17/2022 13:22:13 - INFO - __main__ - Global step 1800 Train loss 2.63 Classification-F1 0.1 on epoch=449
05/17/2022 13:22:14 - INFO - __main__ - Step 1810 Global step 1810 Train loss 2.73 on epoch=452
05/17/2022 13:22:16 - INFO - __main__ - Step 1820 Global step 1820 Train loss 2.45 on epoch=454
05/17/2022 13:22:17 - INFO - __main__ - Step 1830 Global step 1830 Train loss 2.73 on epoch=457
05/17/2022 13:22:18 - INFO - __main__ - Step 1840 Global step 1840 Train loss 2.37 on epoch=459
05/17/2022 13:22:20 - INFO - __main__ - Step 1850 Global step 1850 Train loss 2.44 on epoch=462
05/17/2022 13:22:21 - INFO - __main__ - Global step 1850 Train loss 2.54 Classification-F1 0.1 on epoch=462
05/17/2022 13:22:22 - INFO - __main__ - Step 1860 Global step 1860 Train loss 2.28 on epoch=464
05/17/2022 13:22:23 - INFO - __main__ - Step 1870 Global step 1870 Train loss 2.39 on epoch=467
05/17/2022 13:22:25 - INFO - __main__ - Step 1880 Global step 1880 Train loss 2.34 on epoch=469
05/17/2022 13:22:26 - INFO - __main__ - Step 1890 Global step 1890 Train loss 2.24 on epoch=472
05/17/2022 13:22:27 - INFO - __main__ - Step 1900 Global step 1900 Train loss 2.19 on epoch=474
05/17/2022 13:22:28 - INFO - __main__ - Global step 1900 Train loss 2.29 Classification-F1 0.1 on epoch=474
05/17/2022 13:22:29 - INFO - __main__ - Step 1910 Global step 1910 Train loss 2.42 on epoch=477
05/17/2022 13:22:31 - INFO - __main__ - Step 1920 Global step 1920 Train loss 2.21 on epoch=479
05/17/2022 13:22:32 - INFO - __main__ - Step 1930 Global step 1930 Train loss 2.11 on epoch=482
05/17/2022 13:22:33 - INFO - __main__ - Step 1940 Global step 1940 Train loss 2.22 on epoch=484
05/17/2022 13:22:35 - INFO - __main__ - Step 1950 Global step 1950 Train loss 2.17 on epoch=487
05/17/2022 13:22:36 - INFO - __main__ - Global step 1950 Train loss 2.23 Classification-F1 0.1 on epoch=487
05/17/2022 13:22:37 - INFO - __main__ - Step 1960 Global step 1960 Train loss 2.27 on epoch=489
05/17/2022 13:22:39 - INFO - __main__ - Step 1970 Global step 1970 Train loss 2.12 on epoch=492
05/17/2022 13:22:40 - INFO - __main__ - Step 1980 Global step 1980 Train loss 2.13 on epoch=494
05/17/2022 13:22:42 - INFO - __main__ - Step 1990 Global step 1990 Train loss 2.19 on epoch=497
05/17/2022 13:22:43 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.90 on epoch=499
05/17/2022 13:22:44 - INFO - __main__ - Global step 2000 Train loss 2.12 Classification-F1 0.1 on epoch=499
05/17/2022 13:22:45 - INFO - __main__ - Step 2010 Global step 2010 Train loss 2.08 on epoch=502
05/17/2022 13:22:47 - INFO - __main__ - Step 2020 Global step 2020 Train loss 2.09 on epoch=504
05/17/2022 13:22:48 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.98 on epoch=507
05/17/2022 13:22:50 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.77 on epoch=509
05/17/2022 13:22:51 - INFO - __main__ - Step 2050 Global step 2050 Train loss 2.13 on epoch=512
05/17/2022 13:22:52 - INFO - __main__ - Global step 2050 Train loss 2.01 Classification-F1 0.09615384615384615 on epoch=512
05/17/2022 13:22:53 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.82 on epoch=514
05/17/2022 13:22:55 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.94 on epoch=517
05/17/2022 13:22:56 - INFO - __main__ - Step 2080 Global step 2080 Train loss 2.00 on epoch=519
05/17/2022 13:22:57 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.80 on epoch=522
05/17/2022 13:22:59 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.89 on epoch=524
05/17/2022 13:22:59 - INFO - __main__ - Global step 2100 Train loss 1.89 Classification-F1 0.13034188034188032 on epoch=524
05/17/2022 13:23:01 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.87 on epoch=527
05/17/2022 13:23:02 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.93 on epoch=529
05/17/2022 13:23:03 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.81 on epoch=532
05/17/2022 13:23:05 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.77 on epoch=534
05/17/2022 13:23:06 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.82 on epoch=537
05/17/2022 13:23:07 - INFO - __main__ - Global step 2150 Train loss 1.84 Classification-F1 0.19408369408369408 on epoch=537
05/17/2022 13:23:07 - INFO - __main__ - Saving model with best Classification-F1: 0.15526315789473685 -> 0.19408369408369408 on epoch=537, global_step=2150
05/17/2022 13:23:08 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.80 on epoch=539
05/17/2022 13:23:10 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.81 on epoch=542
05/17/2022 13:23:11 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.89 on epoch=544
05/17/2022 13:23:12 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.76 on epoch=547
05/17/2022 13:23:14 - INFO - __main__ - Step 2200 Global step 2200 Train loss 1.70 on epoch=549
05/17/2022 13:23:14 - INFO - __main__ - Global step 2200 Train loss 1.79 Classification-F1 0.13083538083538082 on epoch=549
05/17/2022 13:23:16 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.82 on epoch=552
05/17/2022 13:23:17 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.80 on epoch=554
05/17/2022 13:23:19 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.75 on epoch=557
05/17/2022 13:23:20 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.61 on epoch=559
05/17/2022 13:23:21 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.62 on epoch=562
05/17/2022 13:23:22 - INFO - __main__ - Global step 2250 Train loss 1.72 Classification-F1 0.14210526315789473 on epoch=562
05/17/2022 13:23:23 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.69 on epoch=564
05/17/2022 13:23:25 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.78 on epoch=567
05/17/2022 13:23:26 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.51 on epoch=569
05/17/2022 13:23:28 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.53 on epoch=572
05/17/2022 13:23:29 - INFO - __main__ - Step 2300 Global step 2300 Train loss 1.55 on epoch=574
05/17/2022 13:23:30 - INFO - __main__ - Global step 2300 Train loss 1.61 Classification-F1 0.18749999999999997 on epoch=574
05/17/2022 13:23:31 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.68 on epoch=577
05/17/2022 13:23:32 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.39 on epoch=579
05/17/2022 13:23:34 - INFO - __main__ - Step 2330 Global step 2330 Train loss 1.52 on epoch=582
05/17/2022 13:23:35 - INFO - __main__ - Step 2340 Global step 2340 Train loss 1.54 on epoch=584
05/17/2022 13:23:37 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.57 on epoch=587
05/17/2022 13:23:37 - INFO - __main__ - Global step 2350 Train loss 1.54 Classification-F1 0.1743478260869565 on epoch=587
05/17/2022 13:23:39 - INFO - __main__ - Step 2360 Global step 2360 Train loss 1.51 on epoch=589
05/17/2022 13:23:40 - INFO - __main__ - Step 2370 Global step 2370 Train loss 1.52 on epoch=592
05/17/2022 13:23:41 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.42 on epoch=594
05/17/2022 13:23:43 - INFO - __main__ - Step 2390 Global step 2390 Train loss 1.49 on epoch=597
05/17/2022 13:23:44 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.56 on epoch=599
05/17/2022 13:23:45 - INFO - __main__ - Global step 2400 Train loss 1.50 Classification-F1 0.17695652173913046 on epoch=599
05/17/2022 13:23:46 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.40 on epoch=602
05/17/2022 13:23:47 - INFO - __main__ - Step 2420 Global step 2420 Train loss 1.38 on epoch=604
05/17/2022 13:23:49 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.42 on epoch=607
05/17/2022 13:23:50 - INFO - __main__ - Step 2440 Global step 2440 Train loss 1.30 on epoch=609
05/17/2022 13:23:52 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.50 on epoch=612
05/17/2022 13:23:52 - INFO - __main__ - Global step 2450 Train loss 1.40 Classification-F1 0.1547202797202797 on epoch=612
05/17/2022 13:23:54 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.42 on epoch=614
05/17/2022 13:23:55 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.47 on epoch=617
05/17/2022 13:23:56 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.58 on epoch=619
05/17/2022 13:23:58 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.37 on epoch=622
05/17/2022 13:23:59 - INFO - __main__ - Step 2500 Global step 2500 Train loss 1.35 on epoch=624
05/17/2022 13:24:00 - INFO - __main__ - Global step 2500 Train loss 1.44 Classification-F1 0.15559772296015179 on epoch=624
05/17/2022 13:24:01 - INFO - __main__ - Step 2510 Global step 2510 Train loss 1.56 on epoch=627
05/17/2022 13:24:02 - INFO - __main__ - Step 2520 Global step 2520 Train loss 1.53 on epoch=629
05/17/2022 13:24:04 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.36 on epoch=632
05/17/2022 13:24:05 - INFO - __main__ - Step 2540 Global step 2540 Train loss 1.42 on epoch=634
05/17/2022 13:24:07 - INFO - __main__ - Step 2550 Global step 2550 Train loss 1.42 on epoch=637
05/17/2022 13:24:07 - INFO - __main__ - Global step 2550 Train loss 1.46 Classification-F1 0.13381369016984046 on epoch=637
05/17/2022 13:24:08 - INFO - __main__ - Step 2560 Global step 2560 Train loss 1.47 on epoch=639
05/17/2022 13:24:10 - INFO - __main__ - Step 2570 Global step 2570 Train loss 1.27 on epoch=642
05/17/2022 13:24:11 - INFO - __main__ - Step 2580 Global step 2580 Train loss 1.44 on epoch=644
05/17/2022 13:24:13 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.33 on epoch=647
05/17/2022 13:24:14 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.40 on epoch=649
05/17/2022 13:24:14 - INFO - __main__ - Global step 2600 Train loss 1.38 Classification-F1 0.09701492537313432 on epoch=649
05/17/2022 13:24:16 - INFO - __main__ - Step 2610 Global step 2610 Train loss 1.36 on epoch=652
05/17/2022 13:24:17 - INFO - __main__ - Step 2620 Global step 2620 Train loss 1.17 on epoch=654
05/17/2022 13:24:19 - INFO - __main__ - Step 2630 Global step 2630 Train loss 1.30 on epoch=657
05/17/2022 13:24:20 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.39 on epoch=659
05/17/2022 13:24:21 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.26 on epoch=662
05/17/2022 13:24:22 - INFO - __main__ - Global step 2650 Train loss 1.30 Classification-F1 0.1803030303030303 on epoch=662
05/17/2022 13:24:23 - INFO - __main__ - Step 2660 Global step 2660 Train loss 1.23 on epoch=664
05/17/2022 13:24:25 - INFO - __main__ - Step 2670 Global step 2670 Train loss 1.36 on epoch=667
05/17/2022 13:24:26 - INFO - __main__ - Step 2680 Global step 2680 Train loss 1.25 on epoch=669
05/17/2022 13:24:27 - INFO - __main__ - Step 2690 Global step 2690 Train loss 1.28 on epoch=672
05/17/2022 13:24:29 - INFO - __main__ - Step 2700 Global step 2700 Train loss 1.22 on epoch=674
05/17/2022 13:24:29 - INFO - __main__ - Global step 2700 Train loss 1.27 Classification-F1 0.203125 on epoch=674
05/17/2022 13:24:29 - INFO - __main__ - Saving model with best Classification-F1: 0.19408369408369408 -> 0.203125 on epoch=674, global_step=2700
05/17/2022 13:24:31 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.16 on epoch=677
05/17/2022 13:24:32 - INFO - __main__ - Step 2720 Global step 2720 Train loss 1.17 on epoch=679
05/17/2022 13:24:34 - INFO - __main__ - Step 2730 Global step 2730 Train loss 1.34 on epoch=682
05/17/2022 13:24:35 - INFO - __main__ - Step 2740 Global step 2740 Train loss 1.16 on epoch=684
05/17/2022 13:24:36 - INFO - __main__ - Step 2750 Global step 2750 Train loss 1.34 on epoch=687
05/17/2022 13:24:37 - INFO - __main__ - Global step 2750 Train loss 1.23 Classification-F1 0.13034188034188032 on epoch=687
05/17/2022 13:24:38 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.28 on epoch=689
05/17/2022 13:24:40 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.37 on epoch=692
05/17/2022 13:24:41 - INFO - __main__ - Step 2780 Global step 2780 Train loss 1.28 on epoch=694
05/17/2022 13:24:43 - INFO - __main__ - Step 2790 Global step 2790 Train loss 1.36 on epoch=697
05/17/2022 13:24:44 - INFO - __main__ - Step 2800 Global step 2800 Train loss 1.39 on epoch=699
05/17/2022 13:24:45 - INFO - __main__ - Global step 2800 Train loss 1.34 Classification-F1 0.15211640211640212 on epoch=699
05/17/2022 13:24:46 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.34 on epoch=702
05/17/2022 13:24:47 - INFO - __main__ - Step 2820 Global step 2820 Train loss 1.29 on epoch=704
05/17/2022 13:24:48 - INFO - __main__ - Step 2830 Global step 2830 Train loss 1.18 on epoch=707
05/17/2022 13:24:50 - INFO - __main__ - Step 2840 Global step 2840 Train loss 1.18 on epoch=709
05/17/2022 13:24:51 - INFO - __main__ - Step 2850 Global step 2850 Train loss 1.22 on epoch=712
05/17/2022 13:24:52 - INFO - __main__ - Global step 2850 Train loss 1.24 Classification-F1 0.19956521739130434 on epoch=712
05/17/2022 13:24:53 - INFO - __main__ - Step 2860 Global step 2860 Train loss 1.29 on epoch=714
05/17/2022 13:24:55 - INFO - __main__ - Step 2870 Global step 2870 Train loss 1.19 on epoch=717
05/17/2022 13:24:56 - INFO - __main__ - Step 2880 Global step 2880 Train loss 1.14 on epoch=719
05/17/2022 13:24:58 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.17 on epoch=722
05/17/2022 13:24:59 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.26 on epoch=724
05/17/2022 13:25:00 - INFO - __main__ - Global step 2900 Train loss 1.21 Classification-F1 0.17831215970961886 on epoch=724
05/17/2022 13:25:01 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.10 on epoch=727
05/17/2022 13:25:02 - INFO - __main__ - Step 2920 Global step 2920 Train loss 1.02 on epoch=729
05/17/2022 13:25:04 - INFO - __main__ - Step 2930 Global step 2930 Train loss 1.26 on epoch=732
05/17/2022 13:25:05 - INFO - __main__ - Step 2940 Global step 2940 Train loss 1.13 on epoch=734
05/17/2022 13:25:07 - INFO - __main__ - Step 2950 Global step 2950 Train loss 1.18 on epoch=737
05/17/2022 13:25:07 - INFO - __main__ - Global step 2950 Train loss 1.14 Classification-F1 0.11714285714285715 on epoch=737
05/17/2022 13:25:09 - INFO - __main__ - Step 2960 Global step 2960 Train loss 1.22 on epoch=739
05/17/2022 13:25:10 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.30 on epoch=742
05/17/2022 13:25:11 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.18 on epoch=744
05/17/2022 13:25:13 - INFO - __main__ - Step 2990 Global step 2990 Train loss 1.35 on epoch=747
05/17/2022 13:25:14 - INFO - __main__ - Step 3000 Global step 3000 Train loss 1.23 on epoch=749
05/17/2022 13:25:15 - INFO - __main__ - Global step 3000 Train loss 1.26 Classification-F1 0.16428571428571428 on epoch=749
05/17/2022 13:25:15 - INFO - __main__ - save last model!
05/17/2022 13:25:15 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/17/2022 13:25:15 - INFO - __main__ - Start tokenizing ... 5509 instances
05/17/2022 13:25:15 - INFO - __main__ - Printing 3 examples
05/17/2022 13:25:15 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/17/2022 13:25:15 - INFO - __main__ - ['others']
05/17/2022 13:25:15 - INFO - __main__ -  [emo] what you like very little things ok
05/17/2022 13:25:15 - INFO - __main__ - ['others']
05/17/2022 13:25:15 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/17/2022 13:25:15 - INFO - __main__ - ['others']
05/17/2022 13:25:15 - INFO - __main__ - Tokenizing Input ...
05/17/2022 13:25:15 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 13:25:15 - INFO - __main__ - Printing 3 examples
05/17/2022 13:25:15 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
05/17/2022 13:25:15 - INFO - __main__ - ['happy']
05/17/2022 13:25:15 - INFO - __main__ -  [emo] your right i'm always right i am impressed
05/17/2022 13:25:15 - INFO - __main__ - ['happy']
05/17/2022 13:25:15 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
05/17/2022 13:25:15 - INFO - __main__ - ['happy']
05/17/2022 13:25:15 - INFO - __main__ - Tokenizing Input ...
05/17/2022 13:25:15 - INFO - __main__ - Tokenizing Output ...
05/17/2022 13:25:15 - INFO - __main__ - Loaded 64 examples from train data
05/17/2022 13:25:15 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 13:25:15 - INFO - __main__ - Printing 3 examples
05/17/2022 13:25:15 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
05/17/2022 13:25:15 - INFO - __main__ - ['happy']
05/17/2022 13:25:15 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
05/17/2022 13:25:15 - INFO - __main__ - ['happy']
05/17/2022 13:25:15 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
05/17/2022 13:25:15 - INFO - __main__ - ['happy']
05/17/2022 13:25:15 - INFO - __main__ - Tokenizing Input ...
05/17/2022 13:25:15 - INFO - __main__ - Tokenizing Output ...
05/17/2022 13:25:16 - INFO - __main__ - Loaded 64 examples from dev data
05/17/2022 13:25:17 - INFO - __main__ - Tokenizing Output ...
05/17/2022 13:25:22 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 13:25:22 - INFO - __main__ - Loaded 5509 examples from test data
05/17/2022 13:25:22 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 13:25:22 - INFO - __main__ - Starting training!
05/17/2022 13:26:06 - INFO - __main__ - Saved prediction in models/T5-base-reptile-cls2cls-3e-5-2-5000-5e-1-10/singletask-emo/emo_16_21_0.2_8_predictions.txt
05/17/2022 13:26:06 - INFO - __main__ - Classification-F1 on test data: 0.0381
05/17/2022 13:26:06 - INFO - __main__ - prefix=emo_16_21, lr=0.2, bsz=8, dev_performance=0.203125, test_performance=0.038122977484098014
05/17/2022 13:26:06 - INFO - __main__ - Running ... prefix=emo_16_42, lr=0.5, bsz=8 ...
05/17/2022 13:26:07 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 13:26:07 - INFO - __main__ - Printing 3 examples
05/17/2022 13:26:07 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
05/17/2022 13:26:07 - INFO - __main__ - ['happy']
05/17/2022 13:26:07 - INFO - __main__ -  [emo] your right i'm always right i am impressed
05/17/2022 13:26:07 - INFO - __main__ - ['happy']
05/17/2022 13:26:07 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
05/17/2022 13:26:07 - INFO - __main__ - ['happy']
05/17/2022 13:26:07 - INFO - __main__ - Tokenizing Input ...
05/17/2022 13:26:07 - INFO - __main__ - Tokenizing Output ...
05/17/2022 13:26:07 - INFO - __main__ - Loaded 64 examples from train data
05/17/2022 13:26:07 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 13:26:07 - INFO - __main__ - Printing 3 examples
05/17/2022 13:26:07 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
05/17/2022 13:26:07 - INFO - __main__ - ['happy']
05/17/2022 13:26:07 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
05/17/2022 13:26:07 - INFO - __main__ - ['happy']
05/17/2022 13:26:07 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
05/17/2022 13:26:07 - INFO - __main__ - ['happy']
05/17/2022 13:26:07 - INFO - __main__ - Tokenizing Input ...
05/17/2022 13:26:07 - INFO - __main__ - Tokenizing Output ...
05/17/2022 13:26:08 - INFO - __main__ - Loaded 64 examples from dev data
05/17/2022 13:26:14 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 13:26:14 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 13:26:14 - INFO - __main__ - Starting training!
05/17/2022 13:26:16 - INFO - __main__ - Step 10 Global step 10 Train loss 8.94 on epoch=2
05/17/2022 13:26:17 - INFO - __main__ - Step 20 Global step 20 Train loss 8.94 on epoch=4
05/17/2022 13:26:19 - INFO - __main__ - Step 30 Global step 30 Train loss 8.83 on epoch=7
05/17/2022 13:26:20 - INFO - __main__ - Step 40 Global step 40 Train loss 8.71 on epoch=9
05/17/2022 13:26:21 - INFO - __main__ - Step 50 Global step 50 Train loss 8.75 on epoch=12
05/17/2022 13:26:32 - INFO - __main__ - Global step 50 Train loss 8.83 Classification-F1 0.0 on epoch=12
05/17/2022 13:26:32 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/17/2022 13:26:33 - INFO - __main__ - Step 60 Global step 60 Train loss 8.64 on epoch=14
05/17/2022 13:26:35 - INFO - __main__ - Step 70 Global step 70 Train loss 8.71 on epoch=17
05/17/2022 13:26:36 - INFO - __main__ - Step 80 Global step 80 Train loss 8.55 on epoch=19
05/17/2022 13:26:38 - INFO - __main__ - Step 90 Global step 90 Train loss 8.27 on epoch=22
05/17/2022 13:26:39 - INFO - __main__ - Step 100 Global step 100 Train loss 8.18 on epoch=24
05/17/2022 13:26:47 - INFO - __main__ - Global step 100 Train loss 8.47 Classification-F1 0.0 on epoch=24
05/17/2022 13:26:48 - INFO - __main__ - Step 110 Global step 110 Train loss 8.12 on epoch=27
05/17/2022 13:26:50 - INFO - __main__ - Step 120 Global step 120 Train loss 7.96 on epoch=29
05/17/2022 13:26:51 - INFO - __main__ - Step 130 Global step 130 Train loss 7.83 on epoch=32
05/17/2022 13:26:52 - INFO - __main__ - Step 140 Global step 140 Train loss 7.54 on epoch=34
05/17/2022 13:26:53 - INFO - __main__ - Step 150 Global step 150 Train loss 7.25 on epoch=37
05/17/2022 13:26:59 - INFO - __main__ - Global step 150 Train loss 7.74 Classification-F1 0.0 on epoch=37
05/17/2022 13:27:01 - INFO - __main__ - Step 160 Global step 160 Train loss 7.21 on epoch=39
05/17/2022 13:27:02 - INFO - __main__ - Step 170 Global step 170 Train loss 6.99 on epoch=42
05/17/2022 13:27:03 - INFO - __main__ - Step 180 Global step 180 Train loss 7.00 on epoch=44
05/17/2022 13:27:05 - INFO - __main__ - Step 190 Global step 190 Train loss 6.95 on epoch=47
05/17/2022 13:27:06 - INFO - __main__ - Step 200 Global step 200 Train loss 6.71 on epoch=49
05/17/2022 13:27:13 - INFO - __main__ - Global step 200 Train loss 6.97 Classification-F1 0.0 on epoch=49
05/17/2022 13:27:14 - INFO - __main__ - Step 210 Global step 210 Train loss 6.48 on epoch=52
05/17/2022 13:27:15 - INFO - __main__ - Step 220 Global step 220 Train loss 6.41 on epoch=54
05/17/2022 13:27:17 - INFO - __main__ - Step 230 Global step 230 Train loss 6.21 on epoch=57
05/17/2022 13:27:18 - INFO - __main__ - Step 240 Global step 240 Train loss 5.93 on epoch=59
05/17/2022 13:27:19 - INFO - __main__ - Step 250 Global step 250 Train loss 5.71 on epoch=62
05/17/2022 13:27:24 - INFO - __main__ - Global step 250 Train loss 6.15 Classification-F1 0.0 on epoch=62
05/17/2022 13:27:26 - INFO - __main__ - Step 260 Global step 260 Train loss 5.60 on epoch=64
05/17/2022 13:27:27 - INFO - __main__ - Step 270 Global step 270 Train loss 5.47 on epoch=67
05/17/2022 13:27:28 - INFO - __main__ - Step 280 Global step 280 Train loss 5.40 on epoch=69
05/17/2022 13:27:30 - INFO - __main__ - Step 290 Global step 290 Train loss 5.20 on epoch=72
05/17/2022 13:27:31 - INFO - __main__ - Step 300 Global step 300 Train loss 5.25 on epoch=74
05/17/2022 13:27:42 - INFO - __main__ - Global step 300 Train loss 5.38 Classification-F1 0.0 on epoch=74
05/17/2022 13:27:43 - INFO - __main__ - Step 310 Global step 310 Train loss 5.17 on epoch=77
05/17/2022 13:27:44 - INFO - __main__ - Step 320 Global step 320 Train loss 5.05 on epoch=79
05/17/2022 13:27:46 - INFO - __main__ - Step 330 Global step 330 Train loss 4.85 on epoch=82
05/17/2022 13:27:47 - INFO - __main__ - Step 340 Global step 340 Train loss 4.75 on epoch=84
05/17/2022 13:27:48 - INFO - __main__ - Step 350 Global step 350 Train loss 4.42 on epoch=87
05/17/2022 13:27:53 - INFO - __main__ - Global step 350 Train loss 4.85 Classification-F1 0.0 on epoch=87
05/17/2022 13:27:55 - INFO - __main__ - Step 360 Global step 360 Train loss 4.46 on epoch=89
05/17/2022 13:27:56 - INFO - __main__ - Step 370 Global step 370 Train loss 4.32 on epoch=92
05/17/2022 13:27:57 - INFO - __main__ - Step 380 Global step 380 Train loss 4.32 on epoch=94
05/17/2022 13:27:59 - INFO - __main__ - Step 390 Global step 390 Train loss 4.30 on epoch=97
05/17/2022 13:28:00 - INFO - __main__ - Step 400 Global step 400 Train loss 4.18 on epoch=99
05/17/2022 13:28:02 - INFO - __main__ - Global step 400 Train loss 4.32 Classification-F1 0.0 on epoch=99
05/17/2022 13:28:04 - INFO - __main__ - Step 410 Global step 410 Train loss 4.02 on epoch=102
05/17/2022 13:28:05 - INFO - __main__ - Step 420 Global step 420 Train loss 3.92 on epoch=104
05/17/2022 13:28:06 - INFO - __main__ - Step 430 Global step 430 Train loss 3.81 on epoch=107
05/17/2022 13:28:08 - INFO - __main__ - Step 440 Global step 440 Train loss 3.80 on epoch=109
05/17/2022 13:28:09 - INFO - __main__ - Step 450 Global step 450 Train loss 3.91 on epoch=112
05/17/2022 13:28:10 - INFO - __main__ - Global step 450 Train loss 3.89 Classification-F1 0.08648901355773725 on epoch=112
05/17/2022 13:28:10 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.08648901355773725 on epoch=112, global_step=450
05/17/2022 13:28:12 - INFO - __main__ - Step 460 Global step 460 Train loss 3.94 on epoch=114
05/17/2022 13:28:13 - INFO - __main__ - Step 470 Global step 470 Train loss 3.78 on epoch=117
05/17/2022 13:28:14 - INFO - __main__ - Step 480 Global step 480 Train loss 3.63 on epoch=119
05/17/2022 13:28:15 - INFO - __main__ - Step 490 Global step 490 Train loss 3.26 on epoch=122
05/17/2022 13:28:17 - INFO - __main__ - Step 500 Global step 500 Train loss 3.48 on epoch=124
05/17/2022 13:28:20 - INFO - __main__ - Global step 500 Train loss 3.62 Classification-F1 0.17344312918167784 on epoch=124
05/17/2022 13:28:20 - INFO - __main__ - Saving model with best Classification-F1: 0.08648901355773725 -> 0.17344312918167784 on epoch=124, global_step=500
05/17/2022 13:28:21 - INFO - __main__ - Step 510 Global step 510 Train loss 3.29 on epoch=127
05/17/2022 13:28:23 - INFO - __main__ - Step 520 Global step 520 Train loss 3.36 on epoch=129
05/17/2022 13:28:24 - INFO - __main__ - Step 530 Global step 530 Train loss 3.17 on epoch=132
05/17/2022 13:28:26 - INFO - __main__ - Step 540 Global step 540 Train loss 3.19 on epoch=134
05/17/2022 13:28:27 - INFO - __main__ - Step 550 Global step 550 Train loss 3.18 on epoch=137
05/17/2022 13:28:34 - INFO - __main__ - Global step 550 Train loss 3.24 Classification-F1 0.1 on epoch=137
05/17/2022 13:28:35 - INFO - __main__ - Step 560 Global step 560 Train loss 3.11 on epoch=139
05/17/2022 13:28:37 - INFO - __main__ - Step 570 Global step 570 Train loss 2.99 on epoch=142
05/17/2022 13:28:38 - INFO - __main__ - Step 580 Global step 580 Train loss 2.89 on epoch=144
05/17/2022 13:28:39 - INFO - __main__ - Step 590 Global step 590 Train loss 2.87 on epoch=147
05/17/2022 13:28:40 - INFO - __main__ - Step 600 Global step 600 Train loss 2.87 on epoch=149
05/17/2022 13:28:43 - INFO - __main__ - Global step 600 Train loss 2.95 Classification-F1 0.12394957983193278 on epoch=149
05/17/2022 13:28:44 - INFO - __main__ - Step 610 Global step 610 Train loss 2.85 on epoch=152
05/17/2022 13:28:45 - INFO - __main__ - Step 620 Global step 620 Train loss 2.93 on epoch=154
05/17/2022 13:28:47 - INFO - __main__ - Step 630 Global step 630 Train loss 2.68 on epoch=157
05/17/2022 13:28:48 - INFO - __main__ - Step 640 Global step 640 Train loss 2.67 on epoch=159
05/17/2022 13:28:49 - INFO - __main__ - Step 650 Global step 650 Train loss 2.46 on epoch=162
05/17/2022 13:28:50 - INFO - __main__ - Global step 650 Train loss 2.72 Classification-F1 0.13911007025761124 on epoch=162
05/17/2022 13:28:51 - INFO - __main__ - Step 660 Global step 660 Train loss 2.67 on epoch=164
05/17/2022 13:28:52 - INFO - __main__ - Step 670 Global step 670 Train loss 2.48 on epoch=167
05/17/2022 13:28:53 - INFO - __main__ - Step 680 Global step 680 Train loss 2.46 on epoch=169
05/17/2022 13:28:55 - INFO - __main__ - Step 690 Global step 690 Train loss 2.20 on epoch=172
05/17/2022 13:28:56 - INFO - __main__ - Step 700 Global step 700 Train loss 2.30 on epoch=174
05/17/2022 13:28:57 - INFO - __main__ - Global step 700 Train loss 2.42 Classification-F1 0.1581196581196581 on epoch=174
05/17/2022 13:28:58 - INFO - __main__ - Step 710 Global step 710 Train loss 2.25 on epoch=177
05/17/2022 13:29:00 - INFO - __main__ - Step 720 Global step 720 Train loss 2.20 on epoch=179
05/17/2022 13:29:01 - INFO - __main__ - Step 730 Global step 730 Train loss 2.12 on epoch=182
05/17/2022 13:29:02 - INFO - __main__ - Step 740 Global step 740 Train loss 2.34 on epoch=184
05/17/2022 13:29:04 - INFO - __main__ - Step 750 Global step 750 Train loss 1.91 on epoch=187
05/17/2022 13:29:08 - INFO - __main__ - Global step 750 Train loss 2.16 Classification-F1 0.10126582278481013 on epoch=187
05/17/2022 13:29:10 - INFO - __main__ - Step 760 Global step 760 Train loss 1.98 on epoch=189
05/17/2022 13:29:11 - INFO - __main__ - Step 770 Global step 770 Train loss 1.87 on epoch=192
05/17/2022 13:29:12 - INFO - __main__ - Step 780 Global step 780 Train loss 1.87 on epoch=194
05/17/2022 13:29:14 - INFO - __main__ - Step 790 Global step 790 Train loss 1.84 on epoch=197
05/17/2022 13:29:15 - INFO - __main__ - Step 800 Global step 800 Train loss 1.82 on epoch=199
05/17/2022 13:29:18 - INFO - __main__ - Global step 800 Train loss 1.88 Classification-F1 0.12394957983193278 on epoch=199
05/17/2022 13:29:19 - INFO - __main__ - Step 810 Global step 810 Train loss 1.88 on epoch=202
05/17/2022 13:29:20 - INFO - __main__ - Step 820 Global step 820 Train loss 1.71 on epoch=204
05/17/2022 13:29:22 - INFO - __main__ - Step 830 Global step 830 Train loss 1.58 on epoch=207
05/17/2022 13:29:23 - INFO - __main__ - Step 840 Global step 840 Train loss 1.70 on epoch=209
05/17/2022 13:29:24 - INFO - __main__ - Step 850 Global step 850 Train loss 1.70 on epoch=212
05/17/2022 13:29:26 - INFO - __main__ - Global step 850 Train loss 1.71 Classification-F1 0.10126582278481013 on epoch=212
05/17/2022 13:29:27 - INFO - __main__ - Step 860 Global step 860 Train loss 1.45 on epoch=214
05/17/2022 13:29:29 - INFO - __main__ - Step 870 Global step 870 Train loss 1.45 on epoch=217
05/17/2022 13:29:30 - INFO - __main__ - Step 880 Global step 880 Train loss 1.43 on epoch=219
05/17/2022 13:29:32 - INFO - __main__ - Step 890 Global step 890 Train loss 1.40 on epoch=222
05/17/2022 13:29:33 - INFO - __main__ - Step 900 Global step 900 Train loss 1.48 on epoch=224
05/17/2022 13:29:34 - INFO - __main__ - Global step 900 Train loss 1.44 Classification-F1 0.09493670886075949 on epoch=224
05/17/2022 13:29:35 - INFO - __main__ - Step 910 Global step 910 Train loss 1.46 on epoch=227
05/17/2022 13:29:36 - INFO - __main__ - Step 920 Global step 920 Train loss 1.57 on epoch=229
05/17/2022 13:29:37 - INFO - __main__ - Step 930 Global step 930 Train loss 1.35 on epoch=232
05/17/2022 13:29:39 - INFO - __main__ - Step 940 Global step 940 Train loss 1.46 on epoch=234
05/17/2022 13:29:40 - INFO - __main__ - Step 950 Global step 950 Train loss 1.35 on epoch=237
05/17/2022 13:29:41 - INFO - __main__ - Global step 950 Train loss 1.44 Classification-F1 0.11705989110707803 on epoch=237
05/17/2022 13:29:42 - INFO - __main__ - Step 960 Global step 960 Train loss 1.42 on epoch=239
05/17/2022 13:29:43 - INFO - __main__ - Step 970 Global step 970 Train loss 1.28 on epoch=242
05/17/2022 13:29:45 - INFO - __main__ - Step 980 Global step 980 Train loss 1.43 on epoch=244
05/17/2022 13:29:46 - INFO - __main__ - Step 990 Global step 990 Train loss 1.41 on epoch=247
05/17/2022 13:29:47 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.31 on epoch=249
05/17/2022 13:29:48 - INFO - __main__ - Global step 1000 Train loss 1.37 Classification-F1 0.13997113997113997 on epoch=249
05/17/2022 13:29:49 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.34 on epoch=252
05/17/2022 13:29:50 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.35 on epoch=254
05/17/2022 13:29:52 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.23 on epoch=257
05/17/2022 13:29:53 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.26 on epoch=259
05/17/2022 13:29:54 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.26 on epoch=262
05/17/2022 13:29:55 - INFO - __main__ - Global step 1050 Train loss 1.29 Classification-F1 0.09090909090909091 on epoch=262
05/17/2022 13:29:56 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.23 on epoch=264
05/17/2022 13:29:57 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.28 on epoch=267
05/17/2022 13:29:59 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.27 on epoch=269
05/17/2022 13:30:00 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.37 on epoch=272
05/17/2022 13:30:01 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.19 on epoch=274
05/17/2022 13:30:02 - INFO - __main__ - Global step 1100 Train loss 1.27 Classification-F1 0.0974025974025974 on epoch=274
05/17/2022 13:30:03 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.23 on epoch=277
05/17/2022 13:30:05 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.31 on epoch=279
05/17/2022 13:30:06 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.32 on epoch=282
05/17/2022 13:30:07 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.27 on epoch=284
05/17/2022 13:30:09 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.09 on epoch=287
05/17/2022 13:30:09 - INFO - __main__ - Global step 1150 Train loss 1.24 Classification-F1 0.14621798689696247 on epoch=287
05/17/2022 13:30:10 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.27 on epoch=289
05/17/2022 13:30:12 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.05 on epoch=292
05/17/2022 13:30:13 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.19 on epoch=294
05/17/2022 13:30:14 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.18 on epoch=297
05/17/2022 13:30:16 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.25 on epoch=299
05/17/2022 13:30:16 - INFO - __main__ - Global step 1200 Train loss 1.19 Classification-F1 0.09615384615384615 on epoch=299
05/17/2022 13:30:18 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.22 on epoch=302
05/17/2022 13:30:19 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.09 on epoch=304
05/17/2022 13:30:20 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.24 on epoch=307
05/17/2022 13:30:22 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.12 on epoch=309
05/17/2022 13:30:23 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.12 on epoch=312
05/17/2022 13:30:24 - INFO - __main__ - Global step 1250 Train loss 1.16 Classification-F1 0.18277599633531835 on epoch=312
05/17/2022 13:30:24 - INFO - __main__ - Saving model with best Classification-F1: 0.17344312918167784 -> 0.18277599633531835 on epoch=312, global_step=1250
05/17/2022 13:30:25 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.12 on epoch=314
05/17/2022 13:30:26 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.14 on epoch=317
05/17/2022 13:30:28 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.10 on epoch=319
05/17/2022 13:30:29 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.05 on epoch=322
05/17/2022 13:30:30 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.12 on epoch=324
05/17/2022 13:30:31 - INFO - __main__ - Global step 1300 Train loss 1.10 Classification-F1 0.2065573770491803 on epoch=324
05/17/2022 13:30:31 - INFO - __main__ - Saving model with best Classification-F1: 0.18277599633531835 -> 0.2065573770491803 on epoch=324, global_step=1300
05/17/2022 13:30:32 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.03 on epoch=327
05/17/2022 13:30:34 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.01 on epoch=329
05/17/2022 13:30:35 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.13 on epoch=332
05/17/2022 13:30:37 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.01 on epoch=334
05/17/2022 13:30:38 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.17 on epoch=337
05/17/2022 13:30:38 - INFO - __main__ - Global step 1350 Train loss 1.07 Classification-F1 0.16470588235294115 on epoch=337
05/17/2022 13:30:40 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.11 on epoch=339
05/17/2022 13:30:41 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.13 on epoch=342
05/17/2022 13:30:42 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.14 on epoch=344
05/17/2022 13:30:44 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.10 on epoch=347
05/17/2022 13:30:45 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.05 on epoch=349
05/17/2022 13:30:46 - INFO - __main__ - Global step 1400 Train loss 1.10 Classification-F1 0.1237183868762816 on epoch=349
05/17/2022 13:30:47 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.25 on epoch=352
05/17/2022 13:30:48 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.01 on epoch=354
05/17/2022 13:30:50 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.09 on epoch=357
05/17/2022 13:30:51 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.03 on epoch=359
05/17/2022 13:30:52 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.98 on epoch=362
05/17/2022 13:30:53 - INFO - __main__ - Global step 1450 Train loss 1.07 Classification-F1 0.18055555555555555 on epoch=362
05/17/2022 13:30:54 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.96 on epoch=364
05/17/2022 13:30:55 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.98 on epoch=367
05/17/2022 13:30:57 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.04 on epoch=369
05/17/2022 13:30:58 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.06 on epoch=372
05/17/2022 13:30:59 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.04 on epoch=374
05/17/2022 13:31:00 - INFO - __main__ - Global step 1500 Train loss 1.02 Classification-F1 0.1 on epoch=374
05/17/2022 13:31:01 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.07 on epoch=377
05/17/2022 13:31:03 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.05 on epoch=379
05/17/2022 13:31:04 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.97 on epoch=382
05/17/2022 13:31:06 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.05 on epoch=384
05/17/2022 13:31:07 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.06 on epoch=387
05/17/2022 13:31:08 - INFO - __main__ - Global step 1550 Train loss 1.04 Classification-F1 0.1565276828434723 on epoch=387
05/17/2022 13:31:09 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.97 on epoch=389
05/17/2022 13:31:11 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.08 on epoch=392
05/17/2022 13:31:12 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.10 on epoch=394
05/17/2022 13:31:13 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.06 on epoch=397
05/17/2022 13:31:15 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.00 on epoch=399
05/17/2022 13:31:15 - INFO - __main__ - Global step 1600 Train loss 1.04 Classification-F1 0.12407862407862408 on epoch=399
05/17/2022 13:31:17 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.10 on epoch=402
05/17/2022 13:31:18 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.07 on epoch=404
05/17/2022 13:31:19 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.02 on epoch=407
05/17/2022 13:31:21 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.01 on epoch=409
05/17/2022 13:31:22 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.03 on epoch=412
05/17/2022 13:31:23 - INFO - __main__ - Global step 1650 Train loss 1.05 Classification-F1 0.1 on epoch=412
05/17/2022 13:31:24 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.98 on epoch=414
05/17/2022 13:31:25 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.93 on epoch=417
05/17/2022 13:31:27 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.87 on epoch=419
05/17/2022 13:31:28 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.06 on epoch=422
05/17/2022 13:31:29 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.00 on epoch=424
05/17/2022 13:31:30 - INFO - __main__ - Global step 1700 Train loss 0.97 Classification-F1 0.1 on epoch=424
05/17/2022 13:31:31 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.94 on epoch=427
05/17/2022 13:31:33 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.02 on epoch=429
05/17/2022 13:31:34 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.97 on epoch=432
05/17/2022 13:31:35 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.95 on epoch=434
05/17/2022 13:31:36 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.93 on epoch=437
05/17/2022 13:31:37 - INFO - __main__ - Global step 1750 Train loss 0.96 Classification-F1 0.10256410256410256 on epoch=437
05/17/2022 13:31:38 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.00 on epoch=439
05/17/2022 13:31:40 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.02 on epoch=442
05/17/2022 13:31:41 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.93 on epoch=444
05/17/2022 13:31:42 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.97 on epoch=447
05/17/2022 13:31:44 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.01 on epoch=449
05/17/2022 13:31:44 - INFO - __main__ - Global step 1800 Train loss 0.99 Classification-F1 0.13197586726998492 on epoch=449
05/17/2022 13:31:46 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.94 on epoch=452
05/17/2022 13:31:47 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.00 on epoch=454
05/17/2022 13:31:49 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.94 on epoch=457
05/17/2022 13:31:50 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.99 on epoch=459
05/17/2022 13:31:51 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.98 on epoch=462
05/17/2022 13:31:52 - INFO - __main__ - Global step 1850 Train loss 0.97 Classification-F1 0.1 on epoch=462
05/17/2022 13:31:53 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.96 on epoch=464
05/17/2022 13:31:54 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.06 on epoch=467
05/17/2022 13:31:56 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.97 on epoch=469
05/17/2022 13:31:57 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.02 on epoch=472
05/17/2022 13:31:58 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.04 on epoch=474
05/17/2022 13:31:59 - INFO - __main__ - Global step 1900 Train loss 1.01 Classification-F1 0.18407494145199066 on epoch=474
05/17/2022 13:32:00 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.98 on epoch=477
05/17/2022 13:32:02 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.01 on epoch=479
05/17/2022 13:32:03 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.96 on epoch=482
05/17/2022 13:32:04 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.01 on epoch=484
05/17/2022 13:32:06 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.08 on epoch=487
05/17/2022 13:32:06 - INFO - __main__ - Global step 1950 Train loss 1.01 Classification-F1 0.1 on epoch=487
05/17/2022 13:32:08 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.92 on epoch=489
05/17/2022 13:32:09 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.95 on epoch=492
05/17/2022 13:32:11 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.04 on epoch=494
05/17/2022 13:32:12 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.06 on epoch=497
05/17/2022 13:32:13 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.96 on epoch=499
05/17/2022 13:32:14 - INFO - __main__ - Global step 2000 Train loss 0.99 Classification-F1 0.1 on epoch=499
05/17/2022 13:32:15 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.97 on epoch=502
05/17/2022 13:32:17 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.97 on epoch=504
05/17/2022 13:32:18 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.90 on epoch=507
05/17/2022 13:32:19 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.96 on epoch=509
05/17/2022 13:32:21 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.13 on epoch=512
05/17/2022 13:32:21 - INFO - __main__ - Global step 2050 Train loss 0.98 Classification-F1 0.07971014492753624 on epoch=512
05/17/2022 13:32:23 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.90 on epoch=514
05/17/2022 13:32:24 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.90 on epoch=517
05/17/2022 13:32:25 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.93 on epoch=519
05/17/2022 13:32:27 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.01 on epoch=522
05/17/2022 13:32:28 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.05 on epoch=524
05/17/2022 13:32:28 - INFO - __main__ - Global step 2100 Train loss 0.96 Classification-F1 0.25396825396825395 on epoch=524
05/17/2022 13:32:28 - INFO - __main__ - Saving model with best Classification-F1: 0.2065573770491803 -> 0.25396825396825395 on epoch=524, global_step=2100
05/17/2022 13:32:30 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.01 on epoch=527
05/17/2022 13:32:31 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.99 on epoch=529
05/17/2022 13:32:32 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.85 on epoch=532
05/17/2022 13:32:34 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.88 on epoch=534
05/17/2022 13:32:35 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.08 on epoch=537
05/17/2022 13:32:36 - INFO - __main__ - Global step 2150 Train loss 0.96 Classification-F1 0.1 on epoch=537
05/17/2022 13:32:37 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.94 on epoch=539
05/17/2022 13:32:38 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.91 on epoch=542
05/17/2022 13:32:40 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.93 on epoch=544
05/17/2022 13:32:41 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.96 on epoch=547
05/17/2022 13:32:42 - INFO - __main__ - Step 2200 Global step 2200 Train loss 1.06 on epoch=549
05/17/2022 13:32:43 - INFO - __main__ - Global step 2200 Train loss 0.96 Classification-F1 0.11552106430155212 on epoch=549
05/17/2022 13:32:44 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.93 on epoch=552
05/17/2022 13:32:46 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.96 on epoch=554
05/17/2022 13:32:47 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.01 on epoch=557
05/17/2022 13:32:48 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.94 on epoch=559
05/17/2022 13:32:50 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.96 on epoch=562
05/17/2022 13:32:50 - INFO - __main__ - Global step 2250 Train loss 0.96 Classification-F1 0.1486842105263158 on epoch=562
05/17/2022 13:32:52 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.99 on epoch=564
05/17/2022 13:32:53 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.94 on epoch=567
05/17/2022 13:32:54 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.85 on epoch=569
05/17/2022 13:32:56 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.99 on epoch=572
05/17/2022 13:32:57 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.93 on epoch=574
05/17/2022 13:32:58 - INFO - __main__ - Global step 2300 Train loss 0.94 Classification-F1 0.14838709677419354 on epoch=574
05/17/2022 13:32:59 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.01 on epoch=577
05/17/2022 13:33:00 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.92 on epoch=579
05/17/2022 13:33:01 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.96 on epoch=582
05/17/2022 13:33:03 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.93 on epoch=584
05/17/2022 13:33:04 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.93 on epoch=587
05/17/2022 13:33:05 - INFO - __main__ - Global step 2350 Train loss 0.95 Classification-F1 0.1 on epoch=587
05/17/2022 13:33:06 - INFO - __main__ - Step 2360 Global step 2360 Train loss 1.02 on epoch=589
05/17/2022 13:33:07 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.93 on epoch=592
05/17/2022 13:33:09 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.01 on epoch=594
05/17/2022 13:33:10 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.94 on epoch=597
05/17/2022 13:33:11 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.87 on epoch=599
05/17/2022 13:33:12 - INFO - __main__ - Global step 2400 Train loss 0.95 Classification-F1 0.1 on epoch=599
05/17/2022 13:33:13 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.97 on epoch=602
05/17/2022 13:33:15 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.94 on epoch=604
05/17/2022 13:33:16 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.90 on epoch=607
05/17/2022 13:33:17 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.95 on epoch=609
05/17/2022 13:33:19 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.00 on epoch=612
05/17/2022 13:33:19 - INFO - __main__ - Global step 2450 Train loss 0.95 Classification-F1 0.23627906976744184 on epoch=612
05/17/2022 13:33:20 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.00 on epoch=614
05/17/2022 13:33:22 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.89 on epoch=617
05/17/2022 13:33:23 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.98 on epoch=619
05/17/2022 13:33:24 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.94 on epoch=622
05/17/2022 13:33:26 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.95 on epoch=624
05/17/2022 13:33:26 - INFO - __main__ - Global step 2500 Train loss 0.95 Classification-F1 0.11714285714285715 on epoch=624
05/17/2022 13:33:28 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.90 on epoch=627
05/17/2022 13:33:29 - INFO - __main__ - Step 2520 Global step 2520 Train loss 1.01 on epoch=629
05/17/2022 13:33:31 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.92 on epoch=632
05/17/2022 13:33:32 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.95 on epoch=634
05/17/2022 13:33:33 - INFO - __main__ - Step 2550 Global step 2550 Train loss 1.00 on epoch=637
05/17/2022 13:33:34 - INFO - __main__ - Global step 2550 Train loss 0.96 Classification-F1 0.13330786860198623 on epoch=637
05/17/2022 13:33:35 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.97 on epoch=639
05/17/2022 13:33:37 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.90 on epoch=642
05/17/2022 13:33:38 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.94 on epoch=644
05/17/2022 13:33:39 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.98 on epoch=647
05/17/2022 13:33:40 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.03 on epoch=649
05/17/2022 13:33:41 - INFO - __main__ - Global step 2600 Train loss 0.96 Classification-F1 0.10126582278481013 on epoch=649
05/17/2022 13:33:42 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.94 on epoch=652
05/17/2022 13:33:44 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.93 on epoch=654
05/17/2022 13:33:45 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.91 on epoch=657
05/17/2022 13:33:46 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.92 on epoch=659
05/17/2022 13:33:48 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.91 on epoch=662
05/17/2022 13:33:48 - INFO - __main__ - Global step 2650 Train loss 0.92 Classification-F1 0.09615384615384615 on epoch=662
05/17/2022 13:33:50 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.89 on epoch=664
05/17/2022 13:33:51 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.91 on epoch=667
05/17/2022 13:33:52 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.90 on epoch=669
05/17/2022 13:33:54 - INFO - __main__ - Step 2690 Global step 2690 Train loss 1.00 on epoch=672
05/17/2022 13:33:55 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.87 on epoch=674
05/17/2022 13:33:56 - INFO - __main__ - Global step 2700 Train loss 0.91 Classification-F1 0.08974358974358974 on epoch=674
05/17/2022 13:33:57 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.93 on epoch=677
05/17/2022 13:33:58 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.85 on epoch=679
05/17/2022 13:34:00 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.96 on epoch=682
05/17/2022 13:34:01 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.97 on epoch=684
05/17/2022 13:34:02 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.90 on epoch=687
05/17/2022 13:34:03 - INFO - __main__ - Global step 2750 Train loss 0.92 Classification-F1 0.1 on epoch=687
05/17/2022 13:34:04 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.93 on epoch=689
05/17/2022 13:34:05 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.90 on epoch=692
05/17/2022 13:34:07 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.87 on epoch=694
05/17/2022 13:34:08 - INFO - __main__ - Step 2790 Global step 2790 Train loss 1.01 on epoch=697
05/17/2022 13:34:09 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.90 on epoch=699
05/17/2022 13:34:10 - INFO - __main__ - Global step 2800 Train loss 0.92 Classification-F1 0.1875814155449414 on epoch=699
05/17/2022 13:34:11 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.90 on epoch=702
05/17/2022 13:34:13 - INFO - __main__ - Step 2820 Global step 2820 Train loss 1.10 on epoch=704
05/17/2022 13:34:14 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.92 on epoch=707
05/17/2022 13:34:15 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.93 on epoch=709
05/17/2022 13:34:17 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.89 on epoch=712
05/17/2022 13:34:17 - INFO - __main__ - Global step 2850 Train loss 0.95 Classification-F1 0.1 on epoch=712
05/17/2022 13:34:18 - INFO - __main__ - Step 2860 Global step 2860 Train loss 1.00 on epoch=714
05/17/2022 13:34:20 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.89 on epoch=717
05/17/2022 13:34:21 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.94 on epoch=719
05/17/2022 13:34:23 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.92 on epoch=722
05/17/2022 13:34:24 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.97 on epoch=724
05/17/2022 13:34:24 - INFO - __main__ - Global step 2900 Train loss 0.94 Classification-F1 0.1115492957746479 on epoch=724
05/17/2022 13:34:26 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.00 on epoch=727
05/17/2022 13:34:28 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.97 on epoch=729
05/17/2022 13:34:29 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.95 on epoch=732
05/17/2022 13:34:31 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.97 on epoch=734
05/17/2022 13:34:32 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.91 on epoch=737
05/17/2022 13:34:33 - INFO - __main__ - Global step 2950 Train loss 0.96 Classification-F1 0.09210526315789473 on epoch=737
05/17/2022 13:34:34 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.99 on epoch=739
05/17/2022 13:34:35 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.03 on epoch=742
05/17/2022 13:34:37 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.99 on epoch=744
05/17/2022 13:34:38 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.91 on epoch=747
05/17/2022 13:34:39 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.86 on epoch=749
05/17/2022 13:34:40 - INFO - __main__ - Global step 3000 Train loss 0.96 Classification-F1 0.0625 on epoch=749
05/17/2022 13:34:40 - INFO - __main__ - save last model!
05/17/2022 13:34:40 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/17/2022 13:34:40 - INFO - __main__ - Start tokenizing ... 5509 instances
05/17/2022 13:34:40 - INFO - __main__ - Printing 3 examples
05/17/2022 13:34:40 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/17/2022 13:34:40 - INFO - __main__ - ['others']
05/17/2022 13:34:40 - INFO - __main__ -  [emo] what you like very little things ok
05/17/2022 13:34:40 - INFO - __main__ - ['others']
05/17/2022 13:34:40 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/17/2022 13:34:40 - INFO - __main__ - ['others']
05/17/2022 13:34:40 - INFO - __main__ - Tokenizing Input ...
05/17/2022 13:34:40 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 13:34:40 - INFO - __main__ - Printing 3 examples
05/17/2022 13:34:40 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
05/17/2022 13:34:40 - INFO - __main__ - ['happy']
05/17/2022 13:34:40 - INFO - __main__ -  [emo] your right i'm always right i am impressed
05/17/2022 13:34:40 - INFO - __main__ - ['happy']
05/17/2022 13:34:40 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
05/17/2022 13:34:40 - INFO - __main__ - ['happy']
05/17/2022 13:34:40 - INFO - __main__ - Tokenizing Input ...
05/17/2022 13:34:40 - INFO - __main__ - Tokenizing Output ...
05/17/2022 13:34:40 - INFO - __main__ - Loaded 64 examples from train data
05/17/2022 13:34:40 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 13:34:40 - INFO - __main__ - Printing 3 examples
05/17/2022 13:34:40 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
05/17/2022 13:34:40 - INFO - __main__ - ['happy']
05/17/2022 13:34:40 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
05/17/2022 13:34:40 - INFO - __main__ - ['happy']
05/17/2022 13:34:40 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
05/17/2022 13:34:40 - INFO - __main__ - ['happy']
05/17/2022 13:34:40 - INFO - __main__ - Tokenizing Input ...
05/17/2022 13:34:40 - INFO - __main__ - Tokenizing Output ...
05/17/2022 13:34:40 - INFO - __main__ - Loaded 64 examples from dev data
05/17/2022 13:34:42 - INFO - __main__ - Tokenizing Output ...
05/17/2022 13:34:46 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 13:34:46 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 13:34:46 - INFO - __main__ - Starting training!
05/17/2022 13:34:47 - INFO - __main__ - Loaded 5509 examples from test data
05/17/2022 13:35:31 - INFO - __main__ - Saved prediction in models/T5-base-reptile-cls2cls-3e-5-2-5000-5e-1-10/singletask-emo/emo_16_42_0.5_8_predictions.txt
05/17/2022 13:35:31 - INFO - __main__ - Classification-F1 on test data: 0.0456
05/17/2022 13:35:31 - INFO - __main__ - prefix=emo_16_42, lr=0.5, bsz=8, dev_performance=0.25396825396825395, test_performance=0.04555459605248868
05/17/2022 13:35:31 - INFO - __main__ - Running ... prefix=emo_16_42, lr=0.4, bsz=8 ...
05/17/2022 13:35:32 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 13:35:32 - INFO - __main__ - Printing 3 examples
05/17/2022 13:35:32 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
05/17/2022 13:35:32 - INFO - __main__ - ['happy']
05/17/2022 13:35:32 - INFO - __main__ -  [emo] your right i'm always right i am impressed
05/17/2022 13:35:32 - INFO - __main__ - ['happy']
05/17/2022 13:35:32 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
05/17/2022 13:35:32 - INFO - __main__ - ['happy']
05/17/2022 13:35:32 - INFO - __main__ - Tokenizing Input ...
05/17/2022 13:35:32 - INFO - __main__ - Tokenizing Output ...
05/17/2022 13:35:32 - INFO - __main__ - Loaded 64 examples from train data
05/17/2022 13:35:32 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 13:35:32 - INFO - __main__ - Printing 3 examples
05/17/2022 13:35:32 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
05/17/2022 13:35:32 - INFO - __main__ - ['happy']
05/17/2022 13:35:32 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
05/17/2022 13:35:32 - INFO - __main__ - ['happy']
05/17/2022 13:35:32 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
05/17/2022 13:35:32 - INFO - __main__ - ['happy']
05/17/2022 13:35:32 - INFO - __main__ - Tokenizing Input ...
05/17/2022 13:35:32 - INFO - __main__ - Tokenizing Output ...
05/17/2022 13:35:32 - INFO - __main__ - Loaded 64 examples from dev data
05/17/2022 13:35:38 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 13:35:38 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 13:35:38 - INFO - __main__ - Starting training!
05/17/2022 13:35:40 - INFO - __main__ - Step 10 Global step 10 Train loss 9.04 on epoch=2
05/17/2022 13:35:41 - INFO - __main__ - Step 20 Global step 20 Train loss 8.93 on epoch=4
05/17/2022 13:35:42 - INFO - __main__ - Step 30 Global step 30 Train loss 8.90 on epoch=7
05/17/2022 13:35:44 - INFO - __main__ - Step 40 Global step 40 Train loss 8.80 on epoch=9
05/17/2022 13:35:45 - INFO - __main__ - Step 50 Global step 50 Train loss 8.67 on epoch=12
05/17/2022 13:35:57 - INFO - __main__ - Global step 50 Train loss 8.87 Classification-F1 0.0 on epoch=12
05/17/2022 13:35:57 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/17/2022 13:35:58 - INFO - __main__ - Step 60 Global step 60 Train loss 8.69 on epoch=14
05/17/2022 13:35:59 - INFO - __main__ - Step 70 Global step 70 Train loss 8.76 on epoch=17
05/17/2022 13:36:01 - INFO - __main__ - Step 80 Global step 80 Train loss 8.64 on epoch=19
05/17/2022 13:36:02 - INFO - __main__ - Step 90 Global step 90 Train loss 8.55 on epoch=22
05/17/2022 13:36:04 - INFO - __main__ - Step 100 Global step 100 Train loss 8.57 on epoch=24
05/17/2022 13:36:15 - INFO - __main__ - Global step 100 Train loss 8.64 Classification-F1 0.0 on epoch=24
05/17/2022 13:36:16 - INFO - __main__ - Step 110 Global step 110 Train loss 8.36 on epoch=27
05/17/2022 13:36:17 - INFO - __main__ - Step 120 Global step 120 Train loss 8.14 on epoch=29
05/17/2022 13:36:19 - INFO - __main__ - Step 130 Global step 130 Train loss 8.00 on epoch=32
05/17/2022 13:36:20 - INFO - __main__ - Step 140 Global step 140 Train loss 7.78 on epoch=34
05/17/2022 13:36:21 - INFO - __main__ - Step 150 Global step 150 Train loss 7.84 on epoch=37
05/17/2022 13:36:26 - INFO - __main__ - Global step 150 Train loss 8.02 Classification-F1 0.0 on epoch=37
05/17/2022 13:36:28 - INFO - __main__ - Step 160 Global step 160 Train loss 7.80 on epoch=39
05/17/2022 13:36:29 - INFO - __main__ - Step 170 Global step 170 Train loss 7.68 on epoch=42
05/17/2022 13:36:31 - INFO - __main__ - Step 180 Global step 180 Train loss 7.58 on epoch=44
05/17/2022 13:36:32 - INFO - __main__ - Step 190 Global step 190 Train loss 7.41 on epoch=47
05/17/2022 13:36:33 - INFO - __main__ - Step 200 Global step 200 Train loss 7.43 on epoch=49
05/17/2022 13:36:35 - INFO - __main__ - Global step 200 Train loss 7.58 Classification-F1 0.0 on epoch=49
05/17/2022 13:36:37 - INFO - __main__ - Step 210 Global step 210 Train loss 7.13 on epoch=52
05/17/2022 13:36:38 - INFO - __main__ - Step 220 Global step 220 Train loss 7.02 on epoch=54
05/17/2022 13:36:39 - INFO - __main__ - Step 230 Global step 230 Train loss 6.87 on epoch=57
05/17/2022 13:36:41 - INFO - __main__ - Step 240 Global step 240 Train loss 6.90 on epoch=59
05/17/2022 13:36:42 - INFO - __main__ - Step 250 Global step 250 Train loss 6.67 on epoch=62
05/17/2022 13:36:46 - INFO - __main__ - Global step 250 Train loss 6.92 Classification-F1 0.0 on epoch=62
05/17/2022 13:36:47 - INFO - __main__ - Step 260 Global step 260 Train loss 6.69 on epoch=64
05/17/2022 13:36:48 - INFO - __main__ - Step 270 Global step 270 Train loss 6.31 on epoch=67
05/17/2022 13:36:50 - INFO - __main__ - Step 280 Global step 280 Train loss 6.24 on epoch=69
05/17/2022 13:36:51 - INFO - __main__ - Step 290 Global step 290 Train loss 6.08 on epoch=72
05/17/2022 13:36:53 - INFO - __main__ - Step 300 Global step 300 Train loss 5.97 on epoch=74
05/17/2022 13:36:58 - INFO - __main__ - Global step 300 Train loss 6.26 Classification-F1 0.0 on epoch=74
05/17/2022 13:37:00 - INFO - __main__ - Step 310 Global step 310 Train loss 5.99 on epoch=77
05/17/2022 13:37:01 - INFO - __main__ - Step 320 Global step 320 Train loss 5.92 on epoch=79
05/17/2022 13:37:02 - INFO - __main__ - Step 330 Global step 330 Train loss 5.73 on epoch=82
05/17/2022 13:37:04 - INFO - __main__ - Step 340 Global step 340 Train loss 5.63 on epoch=84
05/17/2022 13:37:05 - INFO - __main__ - Step 350 Global step 350 Train loss 5.60 on epoch=87
05/17/2022 13:37:11 - INFO - __main__ - Global step 350 Train loss 5.78 Classification-F1 0.0 on epoch=87
05/17/2022 13:37:12 - INFO - __main__ - Step 360 Global step 360 Train loss 5.49 on epoch=89
05/17/2022 13:37:14 - INFO - __main__ - Step 370 Global step 370 Train loss 5.31 on epoch=92
05/17/2022 13:37:15 - INFO - __main__ - Step 380 Global step 380 Train loss 5.31 on epoch=94
05/17/2022 13:37:16 - INFO - __main__ - Step 390 Global step 390 Train loss 5.03 on epoch=97
05/17/2022 13:37:18 - INFO - __main__ - Step 400 Global step 400 Train loss 5.19 on epoch=99
05/17/2022 13:37:22 - INFO - __main__ - Global step 400 Train loss 5.27 Classification-F1 0.0 on epoch=99
05/17/2022 13:37:23 - INFO - __main__ - Step 410 Global step 410 Train loss 5.05 on epoch=102
05/17/2022 13:37:25 - INFO - __main__ - Step 420 Global step 420 Train loss 5.05 on epoch=104
05/17/2022 13:37:26 - INFO - __main__ - Step 430 Global step 430 Train loss 4.79 on epoch=107
05/17/2022 13:37:27 - INFO - __main__ - Step 440 Global step 440 Train loss 4.86 on epoch=109
05/17/2022 13:37:29 - INFO - __main__ - Step 450 Global step 450 Train loss 4.50 on epoch=112
05/17/2022 13:37:33 - INFO - __main__ - Global step 450 Train loss 4.85 Classification-F1 0.0 on epoch=112
05/17/2022 13:37:35 - INFO - __main__ - Step 460 Global step 460 Train loss 4.69 on epoch=114
05/17/2022 13:37:36 - INFO - __main__ - Step 470 Global step 470 Train loss 4.69 on epoch=117
05/17/2022 13:37:38 - INFO - __main__ - Step 480 Global step 480 Train loss 4.58 on epoch=119
05/17/2022 13:37:39 - INFO - __main__ - Step 490 Global step 490 Train loss 4.32 on epoch=122
05/17/2022 13:37:40 - INFO - __main__ - Step 500 Global step 500 Train loss 4.51 on epoch=124
05/17/2022 13:37:46 - INFO - __main__ - Global step 500 Train loss 4.56 Classification-F1 0.0 on epoch=124
05/17/2022 13:37:47 - INFO - __main__ - Step 510 Global step 510 Train loss 4.34 on epoch=127
05/17/2022 13:37:49 - INFO - __main__ - Step 520 Global step 520 Train loss 4.20 on epoch=129
05/17/2022 13:37:50 - INFO - __main__ - Step 530 Global step 530 Train loss 4.14 on epoch=132
05/17/2022 13:37:51 - INFO - __main__ - Step 540 Global step 540 Train loss 4.12 on epoch=134
05/17/2022 13:37:53 - INFO - __main__ - Step 550 Global step 550 Train loss 3.92 on epoch=137
05/17/2022 13:37:57 - INFO - __main__ - Global step 550 Train loss 4.15 Classification-F1 0.014705882352941176 on epoch=137
05/17/2022 13:37:57 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.014705882352941176 on epoch=137, global_step=550
05/17/2022 13:37:58 - INFO - __main__ - Step 560 Global step 560 Train loss 3.88 on epoch=139
05/17/2022 13:38:00 - INFO - __main__ - Step 570 Global step 570 Train loss 3.72 on epoch=142
05/17/2022 13:38:01 - INFO - __main__ - Step 580 Global step 580 Train loss 3.89 on epoch=144
05/17/2022 13:38:02 - INFO - __main__ - Step 590 Global step 590 Train loss 3.58 on epoch=147
05/17/2022 13:38:04 - INFO - __main__ - Step 600 Global step 600 Train loss 3.55 on epoch=149
05/17/2022 13:38:06 - INFO - __main__ - Global step 600 Train loss 3.72 Classification-F1 0.12638146167557932 on epoch=149
05/17/2022 13:38:06 - INFO - __main__ - Saving model with best Classification-F1: 0.014705882352941176 -> 0.12638146167557932 on epoch=149, global_step=600
05/17/2022 13:38:07 - INFO - __main__ - Step 610 Global step 610 Train loss 3.59 on epoch=152
05/17/2022 13:38:09 - INFO - __main__ - Step 620 Global step 620 Train loss 3.53 on epoch=154
05/17/2022 13:38:10 - INFO - __main__ - Step 630 Global step 630 Train loss 3.33 on epoch=157
05/17/2022 13:38:12 - INFO - __main__ - Step 640 Global step 640 Train loss 3.18 on epoch=159
05/17/2022 13:38:13 - INFO - __main__ - Step 650 Global step 650 Train loss 3.17 on epoch=162
05/17/2022 13:38:14 - INFO - __main__ - Global step 650 Train loss 3.36 Classification-F1 0.17712418300653593 on epoch=162
05/17/2022 13:38:14 - INFO - __main__ - Saving model with best Classification-F1: 0.12638146167557932 -> 0.17712418300653593 on epoch=162, global_step=650
05/17/2022 13:38:15 - INFO - __main__ - Step 660 Global step 660 Train loss 2.97 on epoch=164
05/17/2022 13:38:17 - INFO - __main__ - Step 670 Global step 670 Train loss 2.73 on epoch=167
05/17/2022 13:38:18 - INFO - __main__ - Step 680 Global step 680 Train loss 3.04 on epoch=169
05/17/2022 13:38:19 - INFO - __main__ - Step 690 Global step 690 Train loss 2.66 on epoch=172
05/17/2022 13:38:21 - INFO - __main__ - Step 700 Global step 700 Train loss 2.62 on epoch=174
05/17/2022 13:38:21 - INFO - __main__ - Global step 700 Train loss 2.80 Classification-F1 0.14210526315789473 on epoch=174
05/17/2022 13:38:23 - INFO - __main__ - Step 710 Global step 710 Train loss 2.43 on epoch=177
05/17/2022 13:38:24 - INFO - __main__ - Step 720 Global step 720 Train loss 2.30 on epoch=179
05/17/2022 13:38:25 - INFO - __main__ - Step 730 Global step 730 Train loss 2.37 on epoch=182
05/17/2022 13:38:27 - INFO - __main__ - Step 740 Global step 740 Train loss 2.35 on epoch=184
05/17/2022 13:38:28 - INFO - __main__ - Step 750 Global step 750 Train loss 2.21 on epoch=187
05/17/2022 13:38:29 - INFO - __main__ - Global step 750 Train loss 2.33 Classification-F1 0.19285714285714284 on epoch=187
05/17/2022 13:38:29 - INFO - __main__ - Saving model with best Classification-F1: 0.17712418300653593 -> 0.19285714285714284 on epoch=187, global_step=750
05/17/2022 13:38:30 - INFO - __main__ - Step 760 Global step 760 Train loss 2.00 on epoch=189
05/17/2022 13:38:31 - INFO - __main__ - Step 770 Global step 770 Train loss 2.18 on epoch=192
05/17/2022 13:38:33 - INFO - __main__ - Step 780 Global step 780 Train loss 2.06 on epoch=194
05/17/2022 13:38:34 - INFO - __main__ - Step 790 Global step 790 Train loss 2.06 on epoch=197
05/17/2022 13:38:35 - INFO - __main__ - Step 800 Global step 800 Train loss 2.00 on epoch=199
05/17/2022 13:38:36 - INFO - __main__ - Global step 800 Train loss 2.06 Classification-F1 0.13300248138957815 on epoch=199
05/17/2022 13:38:37 - INFO - __main__ - Step 810 Global step 810 Train loss 1.94 on epoch=202
05/17/2022 13:38:39 - INFO - __main__ - Step 820 Global step 820 Train loss 1.94 on epoch=204
05/17/2022 13:38:40 - INFO - __main__ - Step 830 Global step 830 Train loss 1.95 on epoch=207
05/17/2022 13:38:41 - INFO - __main__ - Step 840 Global step 840 Train loss 1.74 on epoch=209
05/17/2022 13:38:43 - INFO - __main__ - Step 850 Global step 850 Train loss 1.73 on epoch=212
05/17/2022 13:38:43 - INFO - __main__ - Global step 850 Train loss 1.86 Classification-F1 0.16666666666666663 on epoch=212
05/17/2022 13:38:45 - INFO - __main__ - Step 860 Global step 860 Train loss 1.87 on epoch=214
05/17/2022 13:38:46 - INFO - __main__ - Step 870 Global step 870 Train loss 1.64 on epoch=217
05/17/2022 13:38:47 - INFO - __main__ - Step 880 Global step 880 Train loss 1.76 on epoch=219
05/17/2022 13:38:49 - INFO - __main__ - Step 890 Global step 890 Train loss 1.83 on epoch=222
05/17/2022 13:38:50 - INFO - __main__ - Step 900 Global step 900 Train loss 1.73 on epoch=224
05/17/2022 13:38:51 - INFO - __main__ - Global step 900 Train loss 1.77 Classification-F1 0.1755366726296959 on epoch=224
05/17/2022 13:38:52 - INFO - __main__ - Step 910 Global step 910 Train loss 1.66 on epoch=227
05/17/2022 13:38:53 - INFO - __main__ - Step 920 Global step 920 Train loss 1.67 on epoch=229
05/17/2022 13:38:55 - INFO - __main__ - Step 930 Global step 930 Train loss 1.76 on epoch=232
05/17/2022 13:38:56 - INFO - __main__ - Step 940 Global step 940 Train loss 1.66 on epoch=234
05/17/2022 13:38:58 - INFO - __main__ - Step 950 Global step 950 Train loss 1.60 on epoch=237
05/17/2022 13:38:58 - INFO - __main__ - Global step 950 Train loss 1.67 Classification-F1 0.17344312918167784 on epoch=237
05/17/2022 13:38:59 - INFO - __main__ - Step 960 Global step 960 Train loss 1.70 on epoch=239
05/17/2022 13:39:01 - INFO - __main__ - Step 970 Global step 970 Train loss 1.65 on epoch=242
05/17/2022 13:39:02 - INFO - __main__ - Step 980 Global step 980 Train loss 1.69 on epoch=244
05/17/2022 13:39:04 - INFO - __main__ - Step 990 Global step 990 Train loss 1.59 on epoch=247
05/17/2022 13:39:05 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.54 on epoch=249
05/17/2022 13:39:06 - INFO - __main__ - Global step 1000 Train loss 1.63 Classification-F1 0.20617715617715618 on epoch=249
05/17/2022 13:39:06 - INFO - __main__ - Saving model with best Classification-F1: 0.19285714285714284 -> 0.20617715617715618 on epoch=249, global_step=1000
05/17/2022 13:39:07 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.61 on epoch=252
05/17/2022 13:39:08 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.68 on epoch=254
05/17/2022 13:39:10 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.62 on epoch=257
05/17/2022 13:39:11 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.60 on epoch=259
05/17/2022 13:39:12 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.43 on epoch=262
05/17/2022 13:39:13 - INFO - __main__ - Global step 1050 Train loss 1.59 Classification-F1 0.17857142857142858 on epoch=262
05/17/2022 13:39:14 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.48 on epoch=264
05/17/2022 13:39:16 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.47 on epoch=267
05/17/2022 13:39:17 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.32 on epoch=269
05/17/2022 13:39:18 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.57 on epoch=272
05/17/2022 13:39:20 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.35 on epoch=274
05/17/2022 13:39:20 - INFO - __main__ - Global step 1100 Train loss 1.44 Classification-F1 0.22059553349875932 on epoch=274
05/17/2022 13:39:20 - INFO - __main__ - Saving model with best Classification-F1: 0.20617715617715618 -> 0.22059553349875932 on epoch=274, global_step=1100
05/17/2022 13:39:22 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.37 on epoch=277
05/17/2022 13:39:23 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.37 on epoch=279
05/17/2022 13:39:24 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.45 on epoch=282
05/17/2022 13:39:26 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.41 on epoch=284
05/17/2022 13:39:27 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.33 on epoch=287
05/17/2022 13:39:28 - INFO - __main__ - Global step 1150 Train loss 1.39 Classification-F1 0.12462006079027355 on epoch=287
05/17/2022 13:39:29 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.40 on epoch=289
05/17/2022 13:39:30 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.42 on epoch=292
05/17/2022 13:39:32 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.44 on epoch=294
05/17/2022 13:39:33 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.33 on epoch=297
05/17/2022 13:39:34 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.35 on epoch=299
05/17/2022 13:39:35 - INFO - __main__ - Global step 1200 Train loss 1.39 Classification-F1 0.07042253521126761 on epoch=299
05/17/2022 13:39:36 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.44 on epoch=302
05/17/2022 13:39:38 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.28 on epoch=304
05/17/2022 13:39:39 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.43 on epoch=307
05/17/2022 13:39:41 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.46 on epoch=309
05/17/2022 13:39:42 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.22 on epoch=312
05/17/2022 13:39:43 - INFO - __main__ - Global step 1250 Train loss 1.37 Classification-F1 0.1 on epoch=312
05/17/2022 13:39:44 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.34 on epoch=314
05/17/2022 13:39:45 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.38 on epoch=317
05/17/2022 13:39:47 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.27 on epoch=319
05/17/2022 13:39:48 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.40 on epoch=322
05/17/2022 13:39:49 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.24 on epoch=324
05/17/2022 13:39:50 - INFO - __main__ - Global step 1300 Train loss 1.33 Classification-F1 0.1 on epoch=324
05/17/2022 13:39:51 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.15 on epoch=327
05/17/2022 13:39:53 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.30 on epoch=329
05/17/2022 13:39:54 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.25 on epoch=332
05/17/2022 13:39:56 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.32 on epoch=334
05/17/2022 13:39:57 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.31 on epoch=337
05/17/2022 13:39:58 - INFO - __main__ - Global step 1350 Train loss 1.27 Classification-F1 0.10126582278481013 on epoch=337
05/17/2022 13:39:59 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.24 on epoch=339
05/17/2022 13:40:01 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.08 on epoch=342
05/17/2022 13:40:02 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.25 on epoch=344
05/17/2022 13:40:03 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.22 on epoch=347
05/17/2022 13:40:05 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.23 on epoch=349
05/17/2022 13:40:05 - INFO - __main__ - Global step 1400 Train loss 1.20 Classification-F1 0.1 on epoch=349
05/17/2022 13:40:07 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.19 on epoch=352
05/17/2022 13:40:08 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.19 on epoch=354
05/17/2022 13:40:09 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.30 on epoch=357
05/17/2022 13:40:11 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.24 on epoch=359
05/17/2022 13:40:12 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.17 on epoch=362
05/17/2022 13:40:13 - INFO - __main__ - Global step 1450 Train loss 1.22 Classification-F1 0.1 on epoch=362
05/17/2022 13:40:14 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.26 on epoch=364
05/17/2022 13:40:16 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.14 on epoch=367
05/17/2022 13:40:17 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.19 on epoch=369
05/17/2022 13:40:19 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.21 on epoch=372
05/17/2022 13:40:20 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.25 on epoch=374
05/17/2022 13:40:21 - INFO - __main__ - Global step 1500 Train loss 1.21 Classification-F1 0.1 on epoch=374
05/17/2022 13:40:22 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.17 on epoch=377
05/17/2022 13:40:23 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.36 on epoch=379
05/17/2022 13:40:25 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.23 on epoch=382
05/17/2022 13:40:26 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.09 on epoch=384
05/17/2022 13:40:28 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.09 on epoch=387
05/17/2022 13:40:28 - INFO - __main__ - Global step 1550 Train loss 1.19 Classification-F1 0.09493670886075949 on epoch=387
05/17/2022 13:40:30 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.16 on epoch=389
05/17/2022 13:40:31 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.00 on epoch=392
05/17/2022 13:40:32 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.19 on epoch=394
05/17/2022 13:40:34 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.21 on epoch=397
05/17/2022 13:40:35 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.11 on epoch=399
05/17/2022 13:40:36 - INFO - __main__ - Global step 1600 Train loss 1.13 Classification-F1 0.1 on epoch=399
05/17/2022 13:40:37 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.17 on epoch=402
05/17/2022 13:40:38 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.26 on epoch=404
05/17/2022 13:40:40 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.01 on epoch=407
05/17/2022 13:40:41 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.23 on epoch=409
05/17/2022 13:40:43 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.15 on epoch=412
05/17/2022 13:40:43 - INFO - __main__ - Global step 1650 Train loss 1.16 Classification-F1 0.1 on epoch=412
05/17/2022 13:40:45 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.17 on epoch=414
05/17/2022 13:40:46 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.22 on epoch=417
05/17/2022 13:40:47 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.11 on epoch=419
05/17/2022 13:40:49 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.01 on epoch=422
05/17/2022 13:40:50 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.13 on epoch=424
05/17/2022 13:40:51 - INFO - __main__ - Global step 1700 Train loss 1.13 Classification-F1 0.1 on epoch=424
05/17/2022 13:40:52 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.20 on epoch=427
05/17/2022 13:40:53 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.05 on epoch=429
05/17/2022 13:40:55 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.13 on epoch=432
05/17/2022 13:40:56 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.21 on epoch=434
05/17/2022 13:40:57 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.19 on epoch=437
05/17/2022 13:40:58 - INFO - __main__ - Global step 1750 Train loss 1.16 Classification-F1 0.10256410256410256 on epoch=437
05/17/2022 13:40:59 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.14 on epoch=439
05/17/2022 13:41:01 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.18 on epoch=442
05/17/2022 13:41:02 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.15 on epoch=444
05/17/2022 13:41:03 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.09 on epoch=447
05/17/2022 13:41:05 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.20 on epoch=449
05/17/2022 13:41:05 - INFO - __main__ - Global step 1800 Train loss 1.15 Classification-F1 0.1 on epoch=449
05/17/2022 13:41:07 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.00 on epoch=452
05/17/2022 13:41:08 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.08 on epoch=454
05/17/2022 13:41:09 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.07 on epoch=457
05/17/2022 13:41:11 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.09 on epoch=459
05/17/2022 13:41:12 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.14 on epoch=462
05/17/2022 13:41:12 - INFO - __main__ - Global step 1850 Train loss 1.08 Classification-F1 0.13026315789473686 on epoch=462
05/17/2022 13:41:14 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.10 on epoch=464
05/17/2022 13:41:15 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.03 on epoch=467
05/17/2022 13:41:17 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.07 on epoch=469
05/17/2022 13:41:18 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.06 on epoch=472
05/17/2022 13:41:19 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.03 on epoch=474
05/17/2022 13:41:20 - INFO - __main__ - Global step 1900 Train loss 1.06 Classification-F1 0.13859154929577466 on epoch=474
05/17/2022 13:41:21 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.08 on epoch=477
05/17/2022 13:41:22 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.10 on epoch=479
05/17/2022 13:41:24 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.04 on epoch=482
05/17/2022 13:41:25 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.03 on epoch=484
05/17/2022 13:41:26 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.12 on epoch=487
05/17/2022 13:41:27 - INFO - __main__ - Global step 1950 Train loss 1.08 Classification-F1 0.13034188034188032 on epoch=487
05/17/2022 13:41:28 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.03 on epoch=489
05/17/2022 13:41:30 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.11 on epoch=492
05/17/2022 13:41:31 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.11 on epoch=494
05/17/2022 13:41:32 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.97 on epoch=497
05/17/2022 13:41:34 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.16 on epoch=499
05/17/2022 13:41:34 - INFO - __main__ - Global step 2000 Train loss 1.08 Classification-F1 0.1 on epoch=499
05/17/2022 13:41:36 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.02 on epoch=502
05/17/2022 13:41:37 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.08 on epoch=504
05/17/2022 13:41:38 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.06 on epoch=507
05/17/2022 13:41:40 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.05 on epoch=509
05/17/2022 13:41:41 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.02 on epoch=512
05/17/2022 13:41:42 - INFO - __main__ - Global step 2050 Train loss 1.05 Classification-F1 0.1 on epoch=512
05/17/2022 13:41:43 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.01 on epoch=514
05/17/2022 13:41:44 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.07 on epoch=517
05/17/2022 13:41:45 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.99 on epoch=519
05/17/2022 13:41:47 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.10 on epoch=522
05/17/2022 13:41:48 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.99 on epoch=524
05/17/2022 13:41:49 - INFO - __main__ - Global step 2100 Train loss 1.03 Classification-F1 0.15356265356265356 on epoch=524
05/17/2022 13:41:50 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.92 on epoch=527
05/17/2022 13:41:51 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.12 on epoch=529
05/17/2022 13:41:53 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.10 on epoch=532
05/17/2022 13:41:55 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.04 on epoch=534
05/17/2022 13:41:56 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.11 on epoch=537
05/17/2022 13:41:56 - INFO - __main__ - Global step 2150 Train loss 1.05 Classification-F1 0.08904109589041095 on epoch=537
05/17/2022 13:41:58 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.02 on epoch=539
05/17/2022 13:41:59 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.10 on epoch=542
05/17/2022 13:42:00 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.14 on epoch=544
05/17/2022 13:42:02 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.03 on epoch=547
05/17/2022 13:42:03 - INFO - __main__ - Step 2200 Global step 2200 Train loss 1.06 on epoch=549
05/17/2022 13:42:04 - INFO - __main__ - Global step 2200 Train loss 1.07 Classification-F1 0.10126582278481013 on epoch=549
05/17/2022 13:42:05 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.98 on epoch=552
05/17/2022 13:42:06 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.06 on epoch=554
05/17/2022 13:42:08 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.05 on epoch=557
05/17/2022 13:42:09 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.96 on epoch=559
05/17/2022 13:42:10 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.08 on epoch=562
05/17/2022 13:42:11 - INFO - __main__ - Global step 2250 Train loss 1.03 Classification-F1 0.1237183868762816 on epoch=562
05/17/2022 13:42:12 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.03 on epoch=564
05/17/2022 13:42:14 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.27 on epoch=567
05/17/2022 13:42:15 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.03 on epoch=569
05/17/2022 13:42:16 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.10 on epoch=572
05/17/2022 13:42:18 - INFO - __main__ - Step 2300 Global step 2300 Train loss 1.07 on epoch=574
05/17/2022 13:42:18 - INFO - __main__ - Global step 2300 Train loss 1.10 Classification-F1 0.2019607843137255 on epoch=574
05/17/2022 13:42:20 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.99 on epoch=577
05/17/2022 13:42:21 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.07 on epoch=579
05/17/2022 13:42:23 - INFO - __main__ - Step 2330 Global step 2330 Train loss 1.07 on epoch=582
05/17/2022 13:42:24 - INFO - __main__ - Step 2340 Global step 2340 Train loss 1.03 on epoch=584
05/17/2022 13:42:26 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.02 on epoch=587
05/17/2022 13:42:26 - INFO - __main__ - Global step 2350 Train loss 1.04 Classification-F1 0.1 on epoch=587
05/17/2022 13:42:28 - INFO - __main__ - Step 2360 Global step 2360 Train loss 1.06 on epoch=589
05/17/2022 13:42:29 - INFO - __main__ - Step 2370 Global step 2370 Train loss 1.05 on epoch=592
05/17/2022 13:42:30 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.97 on epoch=594
05/17/2022 13:42:32 - INFO - __main__ - Step 2390 Global step 2390 Train loss 1.04 on epoch=597
05/17/2022 13:42:33 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.91 on epoch=599
05/17/2022 13:42:34 - INFO - __main__ - Global step 2400 Train loss 1.01 Classification-F1 0.16451612903225807 on epoch=599
05/17/2022 13:42:35 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.90 on epoch=602
05/17/2022 13:42:36 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.91 on epoch=604
05/17/2022 13:42:38 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.97 on epoch=607
05/17/2022 13:42:39 - INFO - __main__ - Step 2440 Global step 2440 Train loss 1.07 on epoch=609
05/17/2022 13:42:41 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.91 on epoch=612
05/17/2022 13:42:41 - INFO - __main__ - Global step 2450 Train loss 0.95 Classification-F1 0.11714285714285715 on epoch=612
05/17/2022 13:42:43 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.07 on epoch=614
05/17/2022 13:42:44 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.96 on epoch=617
05/17/2022 13:42:46 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.00 on epoch=619
05/17/2022 13:42:47 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.95 on epoch=622
05/17/2022 13:42:48 - INFO - __main__ - Step 2500 Global step 2500 Train loss 1.00 on epoch=624
05/17/2022 13:42:49 - INFO - __main__ - Global step 2500 Train loss 1.00 Classification-F1 0.1 on epoch=624
05/17/2022 13:42:50 - INFO - __main__ - Step 2510 Global step 2510 Train loss 1.04 on epoch=627
05/17/2022 13:42:51 - INFO - __main__ - Step 2520 Global step 2520 Train loss 1.06 on epoch=629
05/17/2022 13:42:53 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.12 on epoch=632
05/17/2022 13:42:54 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.95 on epoch=634
05/17/2022 13:42:55 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.93 on epoch=637
05/17/2022 13:42:56 - INFO - __main__ - Global step 2550 Train loss 1.02 Classification-F1 0.1468058968058968 on epoch=637
05/17/2022 13:42:57 - INFO - __main__ - Step 2560 Global step 2560 Train loss 1.02 on epoch=639
05/17/2022 13:42:59 - INFO - __main__ - Step 2570 Global step 2570 Train loss 1.01 on epoch=642
05/17/2022 13:43:00 - INFO - __main__ - Step 2580 Global step 2580 Train loss 1.08 on epoch=644
05/17/2022 13:43:01 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.98 on epoch=647
05/17/2022 13:43:03 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.03 on epoch=649
05/17/2022 13:43:03 - INFO - __main__ - Global step 2600 Train loss 1.02 Classification-F1 0.16402714932126694 on epoch=649
05/17/2022 13:43:05 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.97 on epoch=652
05/17/2022 13:43:06 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.96 on epoch=654
05/17/2022 13:43:07 - INFO - __main__ - Step 2630 Global step 2630 Train loss 1.01 on epoch=657
05/17/2022 13:43:09 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.05 on epoch=659
05/17/2022 13:43:10 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.86 on epoch=662
05/17/2022 13:43:11 - INFO - __main__ - Global step 2650 Train loss 0.97 Classification-F1 0.1 on epoch=662
05/17/2022 13:43:12 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.91 on epoch=664
05/17/2022 13:43:13 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.96 on epoch=667
05/17/2022 13:43:15 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.99 on epoch=669
05/17/2022 13:43:16 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.93 on epoch=672
05/17/2022 13:43:18 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.92 on epoch=674
05/17/2022 13:43:18 - INFO - __main__ - Global step 2700 Train loss 0.94 Classification-F1 0.13034188034188032 on epoch=674
05/17/2022 13:43:20 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.03 on epoch=677
05/17/2022 13:43:22 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.92 on epoch=679
05/17/2022 13:43:23 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.96 on epoch=682
05/17/2022 13:43:24 - INFO - __main__ - Step 2740 Global step 2740 Train loss 1.04 on epoch=684
05/17/2022 13:43:26 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.93 on epoch=687
05/17/2022 13:43:26 - INFO - __main__ - Global step 2750 Train loss 0.97 Classification-F1 0.14621798689696247 on epoch=687
05/17/2022 13:43:28 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.02 on epoch=689
05/17/2022 13:43:29 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.07 on epoch=692
05/17/2022 13:43:31 - INFO - __main__ - Step 2780 Global step 2780 Train loss 1.01 on epoch=694
05/17/2022 13:43:32 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.97 on epoch=697
05/17/2022 13:43:34 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.91 on epoch=699
05/17/2022 13:43:34 - INFO - __main__ - Global step 2800 Train loss 1.00 Classification-F1 0.19445676274944568 on epoch=699
05/17/2022 13:43:36 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.04 on epoch=702
05/17/2022 13:43:37 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.93 on epoch=704
05/17/2022 13:43:39 - INFO - __main__ - Step 2830 Global step 2830 Train loss 1.02 on epoch=707
05/17/2022 13:43:40 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.97 on epoch=709
05/17/2022 13:43:41 - INFO - __main__ - Step 2850 Global step 2850 Train loss 1.03 on epoch=712
05/17/2022 13:43:42 - INFO - __main__ - Global step 2850 Train loss 1.00 Classification-F1 0.13026315789473686 on epoch=712
05/17/2022 13:43:43 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.99 on epoch=714
05/17/2022 13:43:44 - INFO - __main__ - Step 2870 Global step 2870 Train loss 1.04 on epoch=717
05/17/2022 13:43:46 - INFO - __main__ - Step 2880 Global step 2880 Train loss 1.00 on epoch=719
05/17/2022 13:43:47 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.00 on epoch=722
05/17/2022 13:43:48 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.04 on epoch=724
05/17/2022 13:43:49 - INFO - __main__ - Global step 2900 Train loss 1.01 Classification-F1 0.13034188034188032 on epoch=724
05/17/2022 13:43:50 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.91 on epoch=727
05/17/2022 13:43:51 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.97 on epoch=729
05/17/2022 13:43:53 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.92 on epoch=732
05/17/2022 13:43:54 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.96 on epoch=734
05/17/2022 13:43:55 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.95 on epoch=737
05/17/2022 13:43:56 - INFO - __main__ - Global step 2950 Train loss 0.94 Classification-F1 0.1486291486291486 on epoch=737
05/17/2022 13:43:57 - INFO - __main__ - Step 2960 Global step 2960 Train loss 1.04 on epoch=739
05/17/2022 13:43:58 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.97 on epoch=742
05/17/2022 13:43:59 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.97 on epoch=744
05/17/2022 13:44:01 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.97 on epoch=747
05/17/2022 13:44:02 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.91 on epoch=749
05/17/2022 13:44:02 - INFO - __main__ - Global step 3000 Train loss 0.97 Classification-F1 0.1796875 on epoch=749
05/17/2022 13:44:02 - INFO - __main__ - save last model!
05/17/2022 13:44:02 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/17/2022 13:44:02 - INFO - __main__ - Start tokenizing ... 5509 instances
05/17/2022 13:44:02 - INFO - __main__ - Printing 3 examples
05/17/2022 13:44:02 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/17/2022 13:44:02 - INFO - __main__ - ['others']
05/17/2022 13:44:02 - INFO - __main__ -  [emo] what you like very little things ok
05/17/2022 13:44:02 - INFO - __main__ - ['others']
05/17/2022 13:44:02 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/17/2022 13:44:02 - INFO - __main__ - ['others']
05/17/2022 13:44:02 - INFO - __main__ - Tokenizing Input ...
05/17/2022 13:44:03 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 13:44:03 - INFO - __main__ - Printing 3 examples
05/17/2022 13:44:03 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
05/17/2022 13:44:03 - INFO - __main__ - ['happy']
05/17/2022 13:44:03 - INFO - __main__ -  [emo] your right i'm always right i am impressed
05/17/2022 13:44:03 - INFO - __main__ - ['happy']
05/17/2022 13:44:03 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
05/17/2022 13:44:03 - INFO - __main__ - ['happy']
05/17/2022 13:44:03 - INFO - __main__ - Tokenizing Input ...
05/17/2022 13:44:03 - INFO - __main__ - Tokenizing Output ...
05/17/2022 13:44:03 - INFO - __main__ - Loaded 64 examples from train data
05/17/2022 13:44:03 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 13:44:03 - INFO - __main__ - Printing 3 examples
05/17/2022 13:44:03 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
05/17/2022 13:44:03 - INFO - __main__ - ['happy']
05/17/2022 13:44:03 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
05/17/2022 13:44:03 - INFO - __main__ - ['happy']
05/17/2022 13:44:03 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
05/17/2022 13:44:03 - INFO - __main__ - ['happy']
05/17/2022 13:44:03 - INFO - __main__ - Tokenizing Input ...
05/17/2022 13:44:03 - INFO - __main__ - Tokenizing Output ...
05/17/2022 13:44:03 - INFO - __main__ - Loaded 64 examples from dev data
05/17/2022 13:44:05 - INFO - __main__ - Tokenizing Output ...
05/17/2022 13:44:10 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 13:44:10 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 13:44:10 - INFO - __main__ - Starting training!
05/17/2022 13:44:10 - INFO - __main__ - Loaded 5509 examples from test data
05/17/2022 13:44:55 - INFO - __main__ - Saved prediction in models/T5-base-reptile-cls2cls-3e-5-2-5000-5e-1-10/singletask-emo/emo_16_42_0.4_8_predictions.txt
05/17/2022 13:44:55 - INFO - __main__ - Classification-F1 on test data: 0.0431
05/17/2022 13:44:55 - INFO - __main__ - prefix=emo_16_42, lr=0.4, bsz=8, dev_performance=0.22059553349875932, test_performance=0.04313066122127823
05/17/2022 13:44:55 - INFO - __main__ - Running ... prefix=emo_16_42, lr=0.3, bsz=8 ...
05/17/2022 13:44:56 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 13:44:56 - INFO - __main__ - Printing 3 examples
05/17/2022 13:44:56 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
05/17/2022 13:44:56 - INFO - __main__ - ['happy']
05/17/2022 13:44:56 - INFO - __main__ -  [emo] your right i'm always right i am impressed
05/17/2022 13:44:56 - INFO - __main__ - ['happy']
05/17/2022 13:44:56 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
05/17/2022 13:44:56 - INFO - __main__ - ['happy']
05/17/2022 13:44:56 - INFO - __main__ - Tokenizing Input ...
05/17/2022 13:44:56 - INFO - __main__ - Tokenizing Output ...
05/17/2022 13:44:56 - INFO - __main__ - Loaded 64 examples from train data
05/17/2022 13:44:56 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 13:44:56 - INFO - __main__ - Printing 3 examples
05/17/2022 13:44:56 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
05/17/2022 13:44:56 - INFO - __main__ - ['happy']
05/17/2022 13:44:56 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
05/17/2022 13:44:56 - INFO - __main__ - ['happy']
05/17/2022 13:44:56 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
05/17/2022 13:44:56 - INFO - __main__ - ['happy']
05/17/2022 13:44:56 - INFO - __main__ - Tokenizing Input ...
05/17/2022 13:44:56 - INFO - __main__ - Tokenizing Output ...
05/17/2022 13:44:57 - INFO - __main__ - Loaded 64 examples from dev data
05/17/2022 13:45:02 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 13:45:03 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 13:45:03 - INFO - __main__ - Starting training!
05/17/2022 13:45:04 - INFO - __main__ - Step 10 Global step 10 Train loss 9.01 on epoch=2
05/17/2022 13:45:05 - INFO - __main__ - Step 20 Global step 20 Train loss 8.78 on epoch=4
05/17/2022 13:45:07 - INFO - __main__ - Step 30 Global step 30 Train loss 8.96 on epoch=7
05/17/2022 13:45:08 - INFO - __main__ - Step 40 Global step 40 Train loss 8.78 on epoch=9
05/17/2022 13:45:10 - INFO - __main__ - Step 50 Global step 50 Train loss 8.81 on epoch=12
05/17/2022 13:45:15 - INFO - __main__ - Global step 50 Train loss 8.87 Classification-F1 0.0 on epoch=12
05/17/2022 13:45:15 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/17/2022 13:45:16 - INFO - __main__ - Step 60 Global step 60 Train loss 8.74 on epoch=14
05/17/2022 13:45:17 - INFO - __main__ - Step 70 Global step 70 Train loss 8.72 on epoch=17
05/17/2022 13:45:19 - INFO - __main__ - Step 80 Global step 80 Train loss 8.52 on epoch=19
05/17/2022 13:45:20 - INFO - __main__ - Step 90 Global step 90 Train loss 8.63 on epoch=22
05/17/2022 13:45:21 - INFO - __main__ - Step 100 Global step 100 Train loss 8.47 on epoch=24
05/17/2022 13:45:27 - INFO - __main__ - Global step 100 Train loss 8.62 Classification-F1 0.0 on epoch=24
05/17/2022 13:45:28 - INFO - __main__ - Step 110 Global step 110 Train loss 8.49 on epoch=27
05/17/2022 13:45:30 - INFO - __main__ - Step 120 Global step 120 Train loss 8.48 on epoch=29
05/17/2022 13:45:31 - INFO - __main__ - Step 130 Global step 130 Train loss 8.39 on epoch=32
05/17/2022 13:45:33 - INFO - __main__ - Step 140 Global step 140 Train loss 8.19 on epoch=34
05/17/2022 13:45:34 - INFO - __main__ - Step 150 Global step 150 Train loss 8.32 on epoch=37
05/17/2022 13:45:44 - INFO - __main__ - Global step 150 Train loss 8.37 Classification-F1 0.0 on epoch=37
05/17/2022 13:45:45 - INFO - __main__ - Step 160 Global step 160 Train loss 8.10 on epoch=39
05/17/2022 13:45:47 - INFO - __main__ - Step 170 Global step 170 Train loss 8.06 on epoch=42
05/17/2022 13:45:48 - INFO - __main__ - Step 180 Global step 180 Train loss 7.81 on epoch=44
05/17/2022 13:45:49 - INFO - __main__ - Step 190 Global step 190 Train loss 7.77 on epoch=47
05/17/2022 13:45:50 - INFO - __main__ - Step 200 Global step 200 Train loss 7.67 on epoch=49
05/17/2022 13:46:04 - INFO - __main__ - Global step 200 Train loss 7.88 Classification-F1 0.0 on epoch=49
05/17/2022 13:46:05 - INFO - __main__ - Step 210 Global step 210 Train loss 7.47 on epoch=52
05/17/2022 13:46:06 - INFO - __main__ - Step 220 Global step 220 Train loss 7.23 on epoch=54
05/17/2022 13:46:08 - INFO - __main__ - Step 230 Global step 230 Train loss 7.03 on epoch=57
05/17/2022 13:46:09 - INFO - __main__ - Step 240 Global step 240 Train loss 6.99 on epoch=59
05/17/2022 13:46:10 - INFO - __main__ - Step 250 Global step 250 Train loss 6.93 on epoch=62
05/17/2022 13:46:14 - INFO - __main__ - Global step 250 Train loss 7.13 Classification-F1 0.0 on epoch=62
05/17/2022 13:46:16 - INFO - __main__ - Step 260 Global step 260 Train loss 6.87 on epoch=64
05/17/2022 13:46:17 - INFO - __main__ - Step 270 Global step 270 Train loss 6.74 on epoch=67
05/17/2022 13:46:19 - INFO - __main__ - Step 280 Global step 280 Train loss 6.57 on epoch=69
05/17/2022 13:46:20 - INFO - __main__ - Step 290 Global step 290 Train loss 6.58 on epoch=72
05/17/2022 13:46:21 - INFO - __main__ - Step 300 Global step 300 Train loss 6.37 on epoch=74
05/17/2022 13:46:26 - INFO - __main__ - Global step 300 Train loss 6.62 Classification-F1 0.0 on epoch=74
05/17/2022 13:46:27 - INFO - __main__ - Step 310 Global step 310 Train loss 6.33 on epoch=77
05/17/2022 13:46:29 - INFO - __main__ - Step 320 Global step 320 Train loss 6.13 on epoch=79
05/17/2022 13:46:30 - INFO - __main__ - Step 330 Global step 330 Train loss 6.05 on epoch=82
05/17/2022 13:46:31 - INFO - __main__ - Step 340 Global step 340 Train loss 6.00 on epoch=84
05/17/2022 13:46:33 - INFO - __main__ - Step 350 Global step 350 Train loss 5.95 on epoch=87
05/17/2022 13:46:37 - INFO - __main__ - Global step 350 Train loss 6.09 Classification-F1 0.0 on epoch=87
05/17/2022 13:46:38 - INFO - __main__ - Step 360 Global step 360 Train loss 5.92 on epoch=89
05/17/2022 13:46:40 - INFO - __main__ - Step 370 Global step 370 Train loss 5.75 on epoch=92
05/17/2022 13:46:41 - INFO - __main__ - Step 380 Global step 380 Train loss 5.79 on epoch=94
05/17/2022 13:46:42 - INFO - __main__ - Step 390 Global step 390 Train loss 5.55 on epoch=97
05/17/2022 13:46:44 - INFO - __main__ - Step 400 Global step 400 Train loss 5.62 on epoch=99
05/17/2022 13:46:48 - INFO - __main__ - Global step 400 Train loss 5.73 Classification-F1 0.0 on epoch=99
05/17/2022 13:46:49 - INFO - __main__ - Step 410 Global step 410 Train loss 5.33 on epoch=102
05/17/2022 13:46:51 - INFO - __main__ - Step 420 Global step 420 Train loss 5.25 on epoch=104
05/17/2022 13:46:52 - INFO - __main__ - Step 430 Global step 430 Train loss 5.38 on epoch=107
05/17/2022 13:46:53 - INFO - __main__ - Step 440 Global step 440 Train loss 5.34 on epoch=109
05/17/2022 13:46:55 - INFO - __main__ - Step 450 Global step 450 Train loss 5.12 on epoch=112
05/17/2022 13:46:58 - INFO - __main__ - Global step 450 Train loss 5.28 Classification-F1 0.0 on epoch=112
05/17/2022 13:47:00 - INFO - __main__ - Step 460 Global step 460 Train loss 5.17 on epoch=114
05/17/2022 13:47:01 - INFO - __main__ - Step 470 Global step 470 Train loss 5.18 on epoch=117
05/17/2022 13:47:03 - INFO - __main__ - Step 480 Global step 480 Train loss 5.05 on epoch=119
05/17/2022 13:47:04 - INFO - __main__ - Step 490 Global step 490 Train loss 4.96 on epoch=122
05/17/2022 13:47:06 - INFO - __main__ - Step 500 Global step 500 Train loss 4.88 on epoch=124
05/17/2022 13:47:09 - INFO - __main__ - Global step 500 Train loss 5.05 Classification-F1 0.0 on epoch=124
05/17/2022 13:47:11 - INFO - __main__ - Step 510 Global step 510 Train loss 4.90 on epoch=127
05/17/2022 13:47:12 - INFO - __main__ - Step 520 Global step 520 Train loss 4.74 on epoch=129
05/17/2022 13:47:14 - INFO - __main__ - Step 530 Global step 530 Train loss 4.73 on epoch=132
05/17/2022 13:47:15 - INFO - __main__ - Step 540 Global step 540 Train loss 4.74 on epoch=134
05/17/2022 13:47:16 - INFO - __main__ - Step 550 Global step 550 Train loss 4.46 on epoch=137
05/17/2022 13:47:20 - INFO - __main__ - Global step 550 Train loss 4.71 Classification-F1 0.0 on epoch=137
05/17/2022 13:47:22 - INFO - __main__ - Step 560 Global step 560 Train loss 4.57 on epoch=139
05/17/2022 13:47:23 - INFO - __main__ - Step 570 Global step 570 Train loss 4.37 on epoch=142
05/17/2022 13:47:24 - INFO - __main__ - Step 580 Global step 580 Train loss 4.42 on epoch=144
05/17/2022 13:47:26 - INFO - __main__ - Step 590 Global step 590 Train loss 4.26 on epoch=147
05/17/2022 13:47:27 - INFO - __main__ - Step 600 Global step 600 Train loss 4.27 on epoch=149
05/17/2022 13:47:32 - INFO - __main__ - Global step 600 Train loss 4.38 Classification-F1 0.0 on epoch=149
05/17/2022 13:47:33 - INFO - __main__ - Step 610 Global step 610 Train loss 4.22 on epoch=152
05/17/2022 13:47:35 - INFO - __main__ - Step 620 Global step 620 Train loss 4.31 on epoch=154
05/17/2022 13:47:36 - INFO - __main__ - Step 630 Global step 630 Train loss 4.10 on epoch=157
05/17/2022 13:47:38 - INFO - __main__ - Step 640 Global step 640 Train loss 4.05 on epoch=159
05/17/2022 13:47:39 - INFO - __main__ - Step 650 Global step 650 Train loss 4.02 on epoch=162
05/17/2022 13:47:47 - INFO - __main__ - Global step 650 Train loss 4.14 Classification-F1 0.0 on epoch=162
05/17/2022 13:47:48 - INFO - __main__ - Step 660 Global step 660 Train loss 4.21 on epoch=164
05/17/2022 13:47:50 - INFO - __main__ - Step 670 Global step 670 Train loss 4.09 on epoch=167
05/17/2022 13:47:51 - INFO - __main__ - Step 680 Global step 680 Train loss 4.12 on epoch=169
05/17/2022 13:47:52 - INFO - __main__ - Step 690 Global step 690 Train loss 3.71 on epoch=172
05/17/2022 13:47:54 - INFO - __main__ - Step 700 Global step 700 Train loss 3.89 on epoch=174
05/17/2022 13:47:56 - INFO - __main__ - Global step 700 Train loss 4.00 Classification-F1 0.018518518518518517 on epoch=174
05/17/2022 13:47:56 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.018518518518518517 on epoch=174, global_step=700
05/17/2022 13:47:57 - INFO - __main__ - Step 710 Global step 710 Train loss 3.86 on epoch=177
05/17/2022 13:47:58 - INFO - __main__ - Step 720 Global step 720 Train loss 3.97 on epoch=179
05/17/2022 13:48:00 - INFO - __main__ - Step 730 Global step 730 Train loss 3.71 on epoch=182
05/17/2022 13:48:01 - INFO - __main__ - Step 740 Global step 740 Train loss 3.88 on epoch=184
05/17/2022 13:48:03 - INFO - __main__ - Step 750 Global step 750 Train loss 3.78 on epoch=187
05/17/2022 13:48:04 - INFO - __main__ - Global step 750 Train loss 3.84 Classification-F1 0.06769230769230769 on epoch=187
05/17/2022 13:48:04 - INFO - __main__ - Saving model with best Classification-F1: 0.018518518518518517 -> 0.06769230769230769 on epoch=187, global_step=750
05/17/2022 13:48:05 - INFO - __main__ - Step 760 Global step 760 Train loss 3.92 on epoch=189
05/17/2022 13:48:07 - INFO - __main__ - Step 770 Global step 770 Train loss 3.68 on epoch=192
05/17/2022 13:48:08 - INFO - __main__ - Step 780 Global step 780 Train loss 3.71 on epoch=194
05/17/2022 13:48:09 - INFO - __main__ - Step 790 Global step 790 Train loss 3.44 on epoch=197
05/17/2022 13:48:11 - INFO - __main__ - Step 800 Global step 800 Train loss 3.49 on epoch=199
05/17/2022 13:48:13 - INFO - __main__ - Global step 800 Train loss 3.65 Classification-F1 0.07594936708860758 on epoch=199
05/17/2022 13:48:13 - INFO - __main__ - Saving model with best Classification-F1: 0.06769230769230769 -> 0.07594936708860758 on epoch=199, global_step=800
05/17/2022 13:48:14 - INFO - __main__ - Step 810 Global step 810 Train loss 3.54 on epoch=202
05/17/2022 13:48:16 - INFO - __main__ - Step 820 Global step 820 Train loss 3.63 on epoch=204
05/17/2022 13:48:17 - INFO - __main__ - Step 830 Global step 830 Train loss 3.48 on epoch=207
05/17/2022 13:48:19 - INFO - __main__ - Step 840 Global step 840 Train loss 3.41 on epoch=209
05/17/2022 13:48:20 - INFO - __main__ - Step 850 Global step 850 Train loss 3.24 on epoch=212
05/17/2022 13:48:23 - INFO - __main__ - Global step 850 Train loss 3.46 Classification-F1 0.10256410256410256 on epoch=212
05/17/2022 13:48:23 - INFO - __main__ - Saving model with best Classification-F1: 0.07594936708860758 -> 0.10256410256410256 on epoch=212, global_step=850
05/17/2022 13:48:24 - INFO - __main__ - Step 860 Global step 860 Train loss 3.48 on epoch=214
05/17/2022 13:48:25 - INFO - __main__ - Step 870 Global step 870 Train loss 3.19 on epoch=217
05/17/2022 13:48:27 - INFO - __main__ - Step 880 Global step 880 Train loss 3.26 on epoch=219
05/17/2022 13:48:28 - INFO - __main__ - Step 890 Global step 890 Train loss 3.11 on epoch=222
05/17/2022 13:48:29 - INFO - __main__ - Step 900 Global step 900 Train loss 3.36 on epoch=224
05/17/2022 13:48:31 - INFO - __main__ - Global step 900 Train loss 3.28 Classification-F1 0.10126582278481013 on epoch=224
05/17/2022 13:48:32 - INFO - __main__ - Step 910 Global step 910 Train loss 3.08 on epoch=227
05/17/2022 13:48:34 - INFO - __main__ - Step 920 Global step 920 Train loss 3.25 on epoch=229
05/17/2022 13:48:35 - INFO - __main__ - Step 930 Global step 930 Train loss 3.04 on epoch=232
05/17/2022 13:48:37 - INFO - __main__ - Step 940 Global step 940 Train loss 3.03 on epoch=234
05/17/2022 13:48:38 - INFO - __main__ - Step 950 Global step 950 Train loss 2.91 on epoch=237
05/17/2022 13:48:40 - INFO - __main__ - Global step 950 Train loss 3.06 Classification-F1 0.1 on epoch=237
05/17/2022 13:48:41 - INFO - __main__ - Step 960 Global step 960 Train loss 3.04 on epoch=239
05/17/2022 13:48:42 - INFO - __main__ - Step 970 Global step 970 Train loss 2.94 on epoch=242
05/17/2022 13:48:44 - INFO - __main__ - Step 980 Global step 980 Train loss 3.14 on epoch=244
05/17/2022 13:48:45 - INFO - __main__ - Step 990 Global step 990 Train loss 2.91 on epoch=247
05/17/2022 13:48:47 - INFO - __main__ - Step 1000 Global step 1000 Train loss 2.96 on epoch=249
05/17/2022 13:48:48 - INFO - __main__ - Global step 1000 Train loss 3.00 Classification-F1 0.10389610389610389 on epoch=249
05/17/2022 13:48:48 - INFO - __main__ - Saving model with best Classification-F1: 0.10256410256410256 -> 0.10389610389610389 on epoch=249, global_step=1000
05/17/2022 13:48:50 - INFO - __main__ - Step 1010 Global step 1010 Train loss 2.75 on epoch=252
05/17/2022 13:48:51 - INFO - __main__ - Step 1020 Global step 1020 Train loss 2.81 on epoch=254
05/17/2022 13:48:53 - INFO - __main__ - Step 1030 Global step 1030 Train loss 2.68 on epoch=257
05/17/2022 13:48:54 - INFO - __main__ - Step 1040 Global step 1040 Train loss 2.63 on epoch=259
05/17/2022 13:48:56 - INFO - __main__ - Step 1050 Global step 1050 Train loss 2.60 on epoch=262
05/17/2022 13:48:57 - INFO - __main__ - Global step 1050 Train loss 2.69 Classification-F1 0.13067758749069247 on epoch=262
05/17/2022 13:48:57 - INFO - __main__ - Saving model with best Classification-F1: 0.10389610389610389 -> 0.13067758749069247 on epoch=262, global_step=1050
05/17/2022 13:48:58 - INFO - __main__ - Step 1060 Global step 1060 Train loss 2.65 on epoch=264
05/17/2022 13:48:59 - INFO - __main__ - Step 1070 Global step 1070 Train loss 2.39 on epoch=267
05/17/2022 13:49:01 - INFO - __main__ - Step 1080 Global step 1080 Train loss 2.39 on epoch=269
05/17/2022 13:49:02 - INFO - __main__ - Step 1090 Global step 1090 Train loss 2.32 on epoch=272
05/17/2022 13:49:03 - INFO - __main__ - Step 1100 Global step 1100 Train loss 2.31 on epoch=274
05/17/2022 13:49:04 - INFO - __main__ - Global step 1100 Train loss 2.41 Classification-F1 0.13034188034188032 on epoch=274
05/17/2022 13:49:06 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.96 on epoch=277
05/17/2022 13:49:07 - INFO - __main__ - Step 1120 Global step 1120 Train loss 2.20 on epoch=279
05/17/2022 13:49:09 - INFO - __main__ - Step 1130 Global step 1130 Train loss 2.18 on epoch=282
05/17/2022 13:49:10 - INFO - __main__ - Step 1140 Global step 1140 Train loss 2.17 on epoch=284
05/17/2022 13:49:11 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.93 on epoch=287
05/17/2022 13:49:13 - INFO - __main__ - Global step 1150 Train loss 2.09 Classification-F1 0.1 on epoch=287
05/17/2022 13:49:14 - INFO - __main__ - Step 1160 Global step 1160 Train loss 2.03 on epoch=289
05/17/2022 13:49:15 - INFO - __main__ - Step 1170 Global step 1170 Train loss 2.01 on epoch=292
05/17/2022 13:49:17 - INFO - __main__ - Step 1180 Global step 1180 Train loss 2.03 on epoch=294
05/17/2022 13:49:18 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.88 on epoch=297
05/17/2022 13:49:20 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.95 on epoch=299
05/17/2022 13:49:20 - INFO - __main__ - Global step 1200 Train loss 1.98 Classification-F1 0.13034188034188032 on epoch=299
05/17/2022 13:49:22 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.94 on epoch=302
05/17/2022 13:49:23 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.90 on epoch=304
05/17/2022 13:49:25 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.87 on epoch=307
05/17/2022 13:49:26 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.87 on epoch=309
05/17/2022 13:49:28 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.96 on epoch=312
05/17/2022 13:49:28 - INFO - __main__ - Global step 1250 Train loss 1.91 Classification-F1 0.10389610389610389 on epoch=312
05/17/2022 13:49:30 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.94 on epoch=314
05/17/2022 13:49:31 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.71 on epoch=317
05/17/2022 13:49:33 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.81 on epoch=319
05/17/2022 13:49:34 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.73 on epoch=322
05/17/2022 13:49:36 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.74 on epoch=324
05/17/2022 13:49:36 - INFO - __main__ - Global step 1300 Train loss 1.79 Classification-F1 0.1 on epoch=324
05/17/2022 13:49:38 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.69 on epoch=327
05/17/2022 13:49:39 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.77 on epoch=329
05/17/2022 13:49:41 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.67 on epoch=332
05/17/2022 13:49:42 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.54 on epoch=334
05/17/2022 13:49:43 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.55 on epoch=337
05/17/2022 13:49:44 - INFO - __main__ - Global step 1350 Train loss 1.64 Classification-F1 0.1 on epoch=337
05/17/2022 13:49:45 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.76 on epoch=339
05/17/2022 13:49:46 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.48 on epoch=342
05/17/2022 13:49:48 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.59 on epoch=344
05/17/2022 13:49:49 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.60 on epoch=347
05/17/2022 13:49:51 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.59 on epoch=349
05/17/2022 13:49:51 - INFO - __main__ - Global step 1400 Train loss 1.60 Classification-F1 0.1 on epoch=349
05/17/2022 13:49:52 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.56 on epoch=352
05/17/2022 13:49:54 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.51 on epoch=354
05/17/2022 13:49:55 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.54 on epoch=357
05/17/2022 13:49:57 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.57 on epoch=359
05/17/2022 13:49:58 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.61 on epoch=362
05/17/2022 13:49:58 - INFO - __main__ - Global step 1450 Train loss 1.56 Classification-F1 0.1 on epoch=362
05/17/2022 13:50:00 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.54 on epoch=364
05/17/2022 13:50:01 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.47 on epoch=367
05/17/2022 13:50:03 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.42 on epoch=369
05/17/2022 13:50:04 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.36 on epoch=372
05/17/2022 13:50:05 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.40 on epoch=374
05/17/2022 13:50:06 - INFO - __main__ - Global step 1500 Train loss 1.44 Classification-F1 0.1412763767370046 on epoch=374
05/17/2022 13:50:06 - INFO - __main__ - Saving model with best Classification-F1: 0.13067758749069247 -> 0.1412763767370046 on epoch=374, global_step=1500
05/17/2022 13:50:07 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.32 on epoch=377
05/17/2022 13:50:09 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.64 on epoch=379
05/17/2022 13:50:10 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.38 on epoch=382
05/17/2022 13:50:11 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.43 on epoch=384
05/17/2022 13:50:13 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.34 on epoch=387
05/17/2022 13:50:13 - INFO - __main__ - Global step 1550 Train loss 1.42 Classification-F1 0.15211640211640212 on epoch=387
05/17/2022 13:50:14 - INFO - __main__ - Saving model with best Classification-F1: 0.1412763767370046 -> 0.15211640211640212 on epoch=387, global_step=1550
05/17/2022 13:50:15 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.31 on epoch=389
05/17/2022 13:50:17 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.29 on epoch=392
05/17/2022 13:50:18 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.42 on epoch=394
05/17/2022 13:50:20 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.27 on epoch=397
05/17/2022 13:50:21 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.39 on epoch=399
05/17/2022 13:50:22 - INFO - __main__ - Global step 1600 Train loss 1.34 Classification-F1 0.1565276828434723 on epoch=399
05/17/2022 13:50:22 - INFO - __main__ - Saving model with best Classification-F1: 0.15211640211640212 -> 0.1565276828434723 on epoch=399, global_step=1600
05/17/2022 13:50:23 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.37 on epoch=402
05/17/2022 13:50:24 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.36 on epoch=404
05/17/2022 13:50:26 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.41 on epoch=407
05/17/2022 13:50:27 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.34 on epoch=409
05/17/2022 13:50:29 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.28 on epoch=412
05/17/2022 13:50:29 - INFO - __main__ - Global step 1650 Train loss 1.35 Classification-F1 0.14600840336134455 on epoch=412
05/17/2022 13:50:31 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.34 on epoch=414
05/17/2022 13:50:32 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.22 on epoch=417
05/17/2022 13:50:33 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.34 on epoch=419
05/17/2022 13:50:35 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.38 on epoch=422
05/17/2022 13:50:36 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.29 on epoch=424
05/17/2022 13:50:37 - INFO - __main__ - Global step 1700 Train loss 1.31 Classification-F1 0.1 on epoch=424
05/17/2022 13:50:38 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.31 on epoch=427
05/17/2022 13:50:39 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.14 on epoch=429
05/17/2022 13:50:41 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.19 on epoch=432
05/17/2022 13:50:42 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.28 on epoch=434
05/17/2022 13:50:43 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.30 on epoch=437
05/17/2022 13:50:44 - INFO - __main__ - Global step 1750 Train loss 1.24 Classification-F1 0.1 on epoch=437
05/17/2022 13:50:45 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.26 on epoch=439
05/17/2022 13:50:47 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.30 on epoch=442
05/17/2022 13:50:48 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.22 on epoch=444
05/17/2022 13:50:50 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.24 on epoch=447
05/17/2022 13:50:51 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.15 on epoch=449
05/17/2022 13:50:52 - INFO - __main__ - Global step 1800 Train loss 1.23 Classification-F1 0.1 on epoch=449
05/17/2022 13:50:53 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.23 on epoch=452
05/17/2022 13:50:54 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.30 on epoch=454
05/17/2022 13:50:56 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.18 on epoch=457
05/17/2022 13:50:57 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.23 on epoch=459
05/17/2022 13:50:58 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.27 on epoch=462
05/17/2022 13:50:59 - INFO - __main__ - Global step 1850 Train loss 1.24 Classification-F1 0.09493670886075949 on epoch=462
05/17/2022 13:51:00 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.29 on epoch=464
05/17/2022 13:51:02 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.36 on epoch=467
05/17/2022 13:51:03 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.28 on epoch=469
05/17/2022 13:51:04 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.18 on epoch=472
05/17/2022 13:51:06 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.16 on epoch=474
05/17/2022 13:51:06 - INFO - __main__ - Global step 1900 Train loss 1.25 Classification-F1 0.1576923076923077 on epoch=474
05/17/2022 13:51:06 - INFO - __main__ - Saving model with best Classification-F1: 0.1565276828434723 -> 0.1576923076923077 on epoch=474, global_step=1900
05/17/2022 13:51:08 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.15 on epoch=477
05/17/2022 13:51:09 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.17 on epoch=479
05/17/2022 13:51:10 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.28 on epoch=482
05/17/2022 13:51:12 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.20 on epoch=484
05/17/2022 13:51:13 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.07 on epoch=487
05/17/2022 13:51:14 - INFO - __main__ - Global step 1950 Train loss 1.17 Classification-F1 0.1 on epoch=487
05/17/2022 13:51:15 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.16 on epoch=489
05/17/2022 13:51:16 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.18 on epoch=492
05/17/2022 13:51:18 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.21 on epoch=494
05/17/2022 13:51:19 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.29 on epoch=497
05/17/2022 13:51:20 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.17 on epoch=499
05/17/2022 13:51:21 - INFO - __main__ - Global step 2000 Train loss 1.20 Classification-F1 0.13034188034188032 on epoch=499
05/17/2022 13:51:22 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.08 on epoch=502
05/17/2022 13:51:24 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.12 on epoch=504
05/17/2022 13:51:25 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.13 on epoch=507
05/17/2022 13:51:26 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.21 on epoch=509
05/17/2022 13:51:28 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.12 on epoch=512
05/17/2022 13:51:28 - INFO - __main__ - Global step 2050 Train loss 1.13 Classification-F1 0.1 on epoch=512
05/17/2022 13:51:30 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.17 on epoch=514
05/17/2022 13:51:31 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.19 on epoch=517
05/17/2022 13:51:32 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.11 on epoch=519
05/17/2022 13:51:34 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.07 on epoch=522
05/17/2022 13:51:35 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.21 on epoch=524
05/17/2022 13:51:36 - INFO - __main__ - Global step 2100 Train loss 1.15 Classification-F1 0.1 on epoch=524
05/17/2022 13:51:37 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.07 on epoch=527
05/17/2022 13:51:38 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.21 on epoch=529
05/17/2022 13:51:40 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.15 on epoch=532
05/17/2022 13:51:41 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.21 on epoch=534
05/17/2022 13:51:42 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.18 on epoch=537
05/17/2022 13:51:43 - INFO - __main__ - Global step 2150 Train loss 1.16 Classification-F1 0.0974025974025974 on epoch=537
05/17/2022 13:51:44 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.10 on epoch=539
05/17/2022 13:51:46 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.18 on epoch=542
05/17/2022 13:51:47 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.16 on epoch=544
05/17/2022 13:51:48 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.09 on epoch=547
05/17/2022 13:51:50 - INFO - __main__ - Step 2200 Global step 2200 Train loss 1.24 on epoch=549
05/17/2022 13:51:50 - INFO - __main__ - Global step 2200 Train loss 1.15 Classification-F1 0.09493670886075949 on epoch=549
05/17/2022 13:51:51 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.03 on epoch=552
05/17/2022 13:51:53 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.10 on epoch=554
05/17/2022 13:51:54 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.14 on epoch=557
05/17/2022 13:51:55 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.15 on epoch=559
05/17/2022 13:51:57 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.05 on epoch=562
05/17/2022 13:51:57 - INFO - __main__ - Global step 2250 Train loss 1.10 Classification-F1 0.1 on epoch=562
05/17/2022 13:51:59 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.17 on epoch=564
05/17/2022 13:52:00 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.03 on epoch=567
05/17/2022 13:52:01 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.07 on epoch=569
05/17/2022 13:52:03 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.05 on epoch=572
05/17/2022 13:52:04 - INFO - __main__ - Step 2300 Global step 2300 Train loss 1.18 on epoch=574
05/17/2022 13:52:05 - INFO - __main__ - Global step 2300 Train loss 1.10 Classification-F1 0.1 on epoch=574
05/17/2022 13:52:06 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.08 on epoch=577
05/17/2022 13:52:07 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.07 on epoch=579
05/17/2022 13:52:09 - INFO - __main__ - Step 2330 Global step 2330 Train loss 1.15 on epoch=582
05/17/2022 13:52:10 - INFO - __main__ - Step 2340 Global step 2340 Train loss 1.03 on epoch=584
05/17/2022 13:52:12 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.12 on epoch=587
05/17/2022 13:52:12 - INFO - __main__ - Global step 2350 Train loss 1.09 Classification-F1 0.1 on epoch=587
05/17/2022 13:52:13 - INFO - __main__ - Step 2360 Global step 2360 Train loss 1.12 on epoch=589
05/17/2022 13:52:15 - INFO - __main__ - Step 2370 Global step 2370 Train loss 1.10 on epoch=592
05/17/2022 13:52:16 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.07 on epoch=594
05/17/2022 13:52:18 - INFO - __main__ - Step 2390 Global step 2390 Train loss 1.14 on epoch=597
05/17/2022 13:52:19 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.09 on epoch=599
05/17/2022 13:52:20 - INFO - __main__ - Global step 2400 Train loss 1.10 Classification-F1 0.1 on epoch=599
05/17/2022 13:52:21 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.19 on epoch=602
05/17/2022 13:52:22 - INFO - __main__ - Step 2420 Global step 2420 Train loss 1.10 on epoch=604
05/17/2022 13:52:24 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.18 on epoch=607
05/17/2022 13:52:25 - INFO - __main__ - Step 2440 Global step 2440 Train loss 1.20 on epoch=609
05/17/2022 13:52:27 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.01 on epoch=612
05/17/2022 13:52:27 - INFO - __main__ - Global step 2450 Train loss 1.13 Classification-F1 0.1 on epoch=612
05/17/2022 13:52:28 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.98 on epoch=614
05/17/2022 13:52:30 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.08 on epoch=617
05/17/2022 13:52:31 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.12 on epoch=619
05/17/2022 13:52:33 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.03 on epoch=622
05/17/2022 13:52:34 - INFO - __main__ - Step 2500 Global step 2500 Train loss 1.16 on epoch=624
05/17/2022 13:52:35 - INFO - __main__ - Global step 2500 Train loss 1.08 Classification-F1 0.13067758749069247 on epoch=624
05/17/2022 13:52:36 - INFO - __main__ - Step 2510 Global step 2510 Train loss 1.22 on epoch=627
05/17/2022 13:52:37 - INFO - __main__ - Step 2520 Global step 2520 Train loss 1.19 on epoch=629
05/17/2022 13:52:39 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.03 on epoch=632
05/17/2022 13:52:40 - INFO - __main__ - Step 2540 Global step 2540 Train loss 1.09 on epoch=634
05/17/2022 13:52:41 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.95 on epoch=637
05/17/2022 13:52:42 - INFO - __main__ - Global step 2550 Train loss 1.09 Classification-F1 0.1 on epoch=637
05/17/2022 13:52:43 - INFO - __main__ - Step 2560 Global step 2560 Train loss 1.01 on epoch=639
05/17/2022 13:52:45 - INFO - __main__ - Step 2570 Global step 2570 Train loss 1.07 on epoch=642
05/17/2022 13:52:46 - INFO - __main__ - Step 2580 Global step 2580 Train loss 1.16 on epoch=644
05/17/2022 13:52:48 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.11 on epoch=647
05/17/2022 13:52:49 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.02 on epoch=649
05/17/2022 13:52:49 - INFO - __main__ - Global step 2600 Train loss 1.07 Classification-F1 0.1 on epoch=649
05/17/2022 13:52:51 - INFO - __main__ - Step 2610 Global step 2610 Train loss 1.15 on epoch=652
05/17/2022 13:52:52 - INFO - __main__ - Step 2620 Global step 2620 Train loss 1.07 on epoch=654
05/17/2022 13:52:54 - INFO - __main__ - Step 2630 Global step 2630 Train loss 1.05 on epoch=657
05/17/2022 13:52:55 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.04 on epoch=659
05/17/2022 13:52:56 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.13 on epoch=662
05/17/2022 13:52:57 - INFO - __main__ - Global step 2650 Train loss 1.08 Classification-F1 0.1 on epoch=662
05/17/2022 13:52:58 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.99 on epoch=664
05/17/2022 13:53:00 - INFO - __main__ - Step 2670 Global step 2670 Train loss 1.06 on epoch=667
05/17/2022 13:53:01 - INFO - __main__ - Step 2680 Global step 2680 Train loss 1.13 on epoch=669
05/17/2022 13:53:03 - INFO - __main__ - Step 2690 Global step 2690 Train loss 1.00 on epoch=672
05/17/2022 13:53:04 - INFO - __main__ - Step 2700 Global step 2700 Train loss 1.10 on epoch=674
05/17/2022 13:53:05 - INFO - __main__ - Global step 2700 Train loss 1.06 Classification-F1 0.1302118933697881 on epoch=674
05/17/2022 13:53:06 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.13 on epoch=677
05/17/2022 13:53:07 - INFO - __main__ - Step 2720 Global step 2720 Train loss 1.08 on epoch=679
05/17/2022 13:53:09 - INFO - __main__ - Step 2730 Global step 2730 Train loss 1.02 on epoch=682
05/17/2022 13:53:10 - INFO - __main__ - Step 2740 Global step 2740 Train loss 1.04 on epoch=684
05/17/2022 13:53:12 - INFO - __main__ - Step 2750 Global step 2750 Train loss 1.07 on epoch=687
05/17/2022 13:53:12 - INFO - __main__ - Global step 2750 Train loss 1.07 Classification-F1 0.12393162393162392 on epoch=687
05/17/2022 13:53:14 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.08 on epoch=689
05/17/2022 13:53:15 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.16 on epoch=692
05/17/2022 13:53:16 - INFO - __main__ - Step 2780 Global step 2780 Train loss 1.04 on epoch=694
05/17/2022 13:53:18 - INFO - __main__ - Step 2790 Global step 2790 Train loss 1.10 on epoch=697
05/17/2022 13:53:19 - INFO - __main__ - Step 2800 Global step 2800 Train loss 1.09 on epoch=699
05/17/2022 13:53:20 - INFO - __main__ - Global step 2800 Train loss 1.09 Classification-F1 0.1 on epoch=699
05/17/2022 13:53:21 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.05 on epoch=702
05/17/2022 13:53:23 - INFO - __main__ - Step 2820 Global step 2820 Train loss 1.02 on epoch=704
05/17/2022 13:53:24 - INFO - __main__ - Step 2830 Global step 2830 Train loss 1.04 on epoch=707
05/17/2022 13:53:26 - INFO - __main__ - Step 2840 Global step 2840 Train loss 1.05 on epoch=709
05/17/2022 13:53:27 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.99 on epoch=712
05/17/2022 13:53:27 - INFO - __main__ - Global step 2850 Train loss 1.03 Classification-F1 0.1 on epoch=712
05/17/2022 13:53:29 - INFO - __main__ - Step 2860 Global step 2860 Train loss 1.02 on epoch=714
05/17/2022 13:53:30 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.97 on epoch=717
05/17/2022 13:53:32 - INFO - __main__ - Step 2880 Global step 2880 Train loss 1.11 on epoch=719
05/17/2022 13:53:33 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.02 on epoch=722
05/17/2022 13:53:35 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.05 on epoch=724
05/17/2022 13:53:35 - INFO - __main__ - Global step 2900 Train loss 1.03 Classification-F1 0.1 on epoch=724
05/17/2022 13:53:37 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.97 on epoch=727
05/17/2022 13:53:38 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.91 on epoch=729
05/17/2022 13:53:39 - INFO - __main__ - Step 2930 Global step 2930 Train loss 1.02 on epoch=732
05/17/2022 13:53:41 - INFO - __main__ - Step 2940 Global step 2940 Train loss 1.00 on epoch=734
05/17/2022 13:53:42 - INFO - __main__ - Step 2950 Global step 2950 Train loss 1.19 on epoch=737
05/17/2022 13:53:43 - INFO - __main__ - Global step 2950 Train loss 1.02 Classification-F1 0.09493670886075949 on epoch=737
05/17/2022 13:53:44 - INFO - __main__ - Step 2960 Global step 2960 Train loss 1.06 on epoch=739
05/17/2022 13:53:46 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.04 on epoch=742
05/17/2022 13:53:47 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.97 on epoch=744
05/17/2022 13:53:49 - INFO - __main__ - Step 2990 Global step 2990 Train loss 1.06 on epoch=747
05/17/2022 13:53:50 - INFO - __main__ - Step 3000 Global step 3000 Train loss 1.02 on epoch=749
05/17/2022 13:53:51 - INFO - __main__ - Global step 3000 Train loss 1.03 Classification-F1 0.1 on epoch=749
05/17/2022 13:53:51 - INFO - __main__ - save last model!
05/17/2022 13:53:51 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/17/2022 13:53:51 - INFO - __main__ - Start tokenizing ... 5509 instances
05/17/2022 13:53:51 - INFO - __main__ - Printing 3 examples
05/17/2022 13:53:51 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/17/2022 13:53:51 - INFO - __main__ - ['others']
05/17/2022 13:53:51 - INFO - __main__ -  [emo] what you like very little things ok
05/17/2022 13:53:51 - INFO - __main__ - ['others']
05/17/2022 13:53:51 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/17/2022 13:53:51 - INFO - __main__ - ['others']
05/17/2022 13:53:51 - INFO - __main__ - Tokenizing Input ...
05/17/2022 13:53:51 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 13:53:51 - INFO - __main__ - Printing 3 examples
05/17/2022 13:53:51 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
05/17/2022 13:53:51 - INFO - __main__ - ['happy']
05/17/2022 13:53:51 - INFO - __main__ -  [emo] your right i'm always right i am impressed
05/17/2022 13:53:51 - INFO - __main__ - ['happy']
05/17/2022 13:53:51 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
05/17/2022 13:53:51 - INFO - __main__ - ['happy']
05/17/2022 13:53:51 - INFO - __main__ - Tokenizing Input ...
05/17/2022 13:53:51 - INFO - __main__ - Tokenizing Output ...
05/17/2022 13:53:51 - INFO - __main__ - Loaded 64 examples from train data
05/17/2022 13:53:51 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 13:53:51 - INFO - __main__ - Printing 3 examples
05/17/2022 13:53:51 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
05/17/2022 13:53:51 - INFO - __main__ - ['happy']
05/17/2022 13:53:51 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
05/17/2022 13:53:51 - INFO - __main__ - ['happy']
05/17/2022 13:53:51 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
05/17/2022 13:53:51 - INFO - __main__ - ['happy']
05/17/2022 13:53:51 - INFO - __main__ - Tokenizing Input ...
05/17/2022 13:53:51 - INFO - __main__ - Tokenizing Output ...
05/17/2022 13:53:51 - INFO - __main__ - Loaded 64 examples from dev data
05/17/2022 13:53:53 - INFO - __main__ - Tokenizing Output ...
05/17/2022 13:53:57 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 13:53:58 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 13:53:58 - INFO - __main__ - Starting training!
05/17/2022 13:53:58 - INFO - __main__ - Loaded 5509 examples from test data
05/17/2022 13:54:42 - INFO - __main__ - Saved prediction in models/T5-base-reptile-cls2cls-3e-5-2-5000-5e-1-10/singletask-emo/emo_16_42_0.3_8_predictions.txt
05/17/2022 13:54:42 - INFO - __main__ - Classification-F1 on test data: 0.0276
05/17/2022 13:54:42 - INFO - __main__ - prefix=emo_16_42, lr=0.3, bsz=8, dev_performance=0.1576923076923077, test_performance=0.027639781545567232
05/17/2022 13:54:42 - INFO - __main__ - Running ... prefix=emo_16_42, lr=0.2, bsz=8 ...
05/17/2022 13:54:43 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 13:54:43 - INFO - __main__ - Printing 3 examples
05/17/2022 13:54:43 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
05/17/2022 13:54:43 - INFO - __main__ - ['happy']
05/17/2022 13:54:43 - INFO - __main__ -  [emo] your right i'm always right i am impressed
05/17/2022 13:54:43 - INFO - __main__ - ['happy']
05/17/2022 13:54:43 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
05/17/2022 13:54:43 - INFO - __main__ - ['happy']
05/17/2022 13:54:43 - INFO - __main__ - Tokenizing Input ...
05/17/2022 13:54:43 - INFO - __main__ - Tokenizing Output ...
05/17/2022 13:54:43 - INFO - __main__ - Loaded 64 examples from train data
05/17/2022 13:54:43 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 13:54:43 - INFO - __main__ - Printing 3 examples
05/17/2022 13:54:43 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
05/17/2022 13:54:43 - INFO - __main__ - ['happy']
05/17/2022 13:54:43 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
05/17/2022 13:54:43 - INFO - __main__ - ['happy']
05/17/2022 13:54:43 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
05/17/2022 13:54:43 - INFO - __main__ - ['happy']
05/17/2022 13:54:43 - INFO - __main__ - Tokenizing Input ...
05/17/2022 13:54:43 - INFO - __main__ - Tokenizing Output ...
05/17/2022 13:54:43 - INFO - __main__ - Loaded 64 examples from dev data
05/17/2022 13:54:49 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 13:54:49 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 13:54:49 - INFO - __main__ - Starting training!
05/17/2022 13:54:52 - INFO - __main__ - Step 10 Global step 10 Train loss 8.96 on epoch=2
05/17/2022 13:54:53 - INFO - __main__ - Step 20 Global step 20 Train loss 8.89 on epoch=4
05/17/2022 13:54:54 - INFO - __main__ - Step 30 Global step 30 Train loss 8.99 on epoch=7
05/17/2022 13:54:56 - INFO - __main__ - Step 40 Global step 40 Train loss 8.84 on epoch=9
05/17/2022 13:54:57 - INFO - __main__ - Step 50 Global step 50 Train loss 8.97 on epoch=12
05/17/2022 13:55:02 - INFO - __main__ - Global step 50 Train loss 8.93 Classification-F1 0.0 on epoch=12
05/17/2022 13:55:02 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/17/2022 13:55:04 - INFO - __main__ - Step 60 Global step 60 Train loss 8.80 on epoch=14
05/17/2022 13:55:05 - INFO - __main__ - Step 70 Global step 70 Train loss 8.67 on epoch=17
05/17/2022 13:55:06 - INFO - __main__ - Step 80 Global step 80 Train loss 8.78 on epoch=19
05/17/2022 13:55:08 - INFO - __main__ - Step 90 Global step 90 Train loss 8.81 on epoch=22
05/17/2022 13:55:09 - INFO - __main__ - Step 100 Global step 100 Train loss 8.72 on epoch=24
05/17/2022 13:55:18 - INFO - __main__ - Global step 100 Train loss 8.75 Classification-F1 0.0 on epoch=24
05/17/2022 13:55:19 - INFO - __main__ - Step 110 Global step 110 Train loss 8.69 on epoch=27
05/17/2022 13:55:21 - INFO - __main__ - Step 120 Global step 120 Train loss 8.80 on epoch=29
05/17/2022 13:55:22 - INFO - __main__ - Step 130 Global step 130 Train loss 8.64 on epoch=32
05/17/2022 13:55:23 - INFO - __main__ - Step 140 Global step 140 Train loss 8.64 on epoch=34
05/17/2022 13:55:25 - INFO - __main__ - Step 150 Global step 150 Train loss 8.72 on epoch=37
05/17/2022 13:55:29 - INFO - __main__ - Global step 150 Train loss 8.70 Classification-F1 0.0 on epoch=37
05/17/2022 13:55:30 - INFO - __main__ - Step 160 Global step 160 Train loss 8.50 on epoch=39
05/17/2022 13:55:32 - INFO - __main__ - Step 170 Global step 170 Train loss 8.68 on epoch=42
05/17/2022 13:55:33 - INFO - __main__ - Step 180 Global step 180 Train loss 8.51 on epoch=44
05/17/2022 13:55:34 - INFO - __main__ - Step 190 Global step 190 Train loss 8.47 on epoch=47
05/17/2022 13:55:36 - INFO - __main__ - Step 200 Global step 200 Train loss 8.38 on epoch=49
05/17/2022 13:55:43 - INFO - __main__ - Global step 200 Train loss 8.51 Classification-F1 0.0 on epoch=49
05/17/2022 13:55:45 - INFO - __main__ - Step 210 Global step 210 Train loss 8.37 on epoch=52
05/17/2022 13:55:46 - INFO - __main__ - Step 220 Global step 220 Train loss 8.29 on epoch=54
05/17/2022 13:55:47 - INFO - __main__ - Step 230 Global step 230 Train loss 8.35 on epoch=57
05/17/2022 13:55:49 - INFO - __main__ - Step 240 Global step 240 Train loss 8.27 on epoch=59
05/17/2022 13:55:50 - INFO - __main__ - Step 250 Global step 250 Train loss 8.13 on epoch=62
05/17/2022 13:56:05 - INFO - __main__ - Global step 250 Train loss 8.28 Classification-F1 0.0 on epoch=62
05/17/2022 13:56:06 - INFO - __main__ - Step 260 Global step 260 Train loss 7.94 on epoch=64
05/17/2022 13:56:08 - INFO - __main__ - Step 270 Global step 270 Train loss 8.00 on epoch=67
05/17/2022 13:56:09 - INFO - __main__ - Step 280 Global step 280 Train loss 7.77 on epoch=69
05/17/2022 13:56:10 - INFO - __main__ - Step 290 Global step 290 Train loss 7.69 on epoch=72
05/17/2022 13:56:12 - INFO - __main__ - Step 300 Global step 300 Train loss 7.47 on epoch=74
05/17/2022 13:56:22 - INFO - __main__ - Global step 300 Train loss 7.77 Classification-F1 0.0 on epoch=74
05/17/2022 13:56:23 - INFO - __main__ - Step 310 Global step 310 Train loss 7.28 on epoch=77
05/17/2022 13:56:24 - INFO - __main__ - Step 320 Global step 320 Train loss 7.38 on epoch=79
05/17/2022 13:56:26 - INFO - __main__ - Step 330 Global step 330 Train loss 7.38 on epoch=82
05/17/2022 13:56:27 - INFO - __main__ - Step 340 Global step 340 Train loss 7.07 on epoch=84
05/17/2022 13:56:28 - INFO - __main__ - Step 350 Global step 350 Train loss 6.96 on epoch=87
05/17/2022 13:56:32 - INFO - __main__ - Global step 350 Train loss 7.21 Classification-F1 0.0 on epoch=87
05/17/2022 13:56:34 - INFO - __main__ - Step 360 Global step 360 Train loss 6.95 on epoch=89
05/17/2022 13:56:35 - INFO - __main__ - Step 370 Global step 370 Train loss 6.67 on epoch=92
05/17/2022 13:56:36 - INFO - __main__ - Step 380 Global step 380 Train loss 6.54 on epoch=94
05/17/2022 13:56:38 - INFO - __main__ - Step 390 Global step 390 Train loss 6.42 on epoch=97
05/17/2022 13:56:39 - INFO - __main__ - Step 400 Global step 400 Train loss 6.34 on epoch=99
05/17/2022 13:56:45 - INFO - __main__ - Global step 400 Train loss 6.58 Classification-F1 0.0 on epoch=99
05/17/2022 13:56:47 - INFO - __main__ - Step 410 Global step 410 Train loss 6.25 on epoch=102
05/17/2022 13:56:48 - INFO - __main__ - Step 420 Global step 420 Train loss 6.25 on epoch=104
05/17/2022 13:56:50 - INFO - __main__ - Step 430 Global step 430 Train loss 6.12 on epoch=107
05/17/2022 13:56:51 - INFO - __main__ - Step 440 Global step 440 Train loss 6.20 on epoch=109
05/17/2022 13:56:52 - INFO - __main__ - Step 450 Global step 450 Train loss 5.80 on epoch=112
05/17/2022 13:57:02 - INFO - __main__ - Global step 450 Train loss 6.12 Classification-F1 0.0 on epoch=112
05/17/2022 13:57:03 - INFO - __main__ - Step 460 Global step 460 Train loss 5.78 on epoch=114
05/17/2022 13:57:04 - INFO - __main__ - Step 470 Global step 470 Train loss 5.74 on epoch=117
05/17/2022 13:57:06 - INFO - __main__ - Step 480 Global step 480 Train loss 5.83 on epoch=119
05/17/2022 13:57:07 - INFO - __main__ - Step 490 Global step 490 Train loss 5.57 on epoch=122
05/17/2022 13:57:09 - INFO - __main__ - Step 500 Global step 500 Train loss 5.71 on epoch=124
05/17/2022 13:57:14 - INFO - __main__ - Global step 500 Train loss 5.73 Classification-F1 0.0 on epoch=124
05/17/2022 13:57:15 - INFO - __main__ - Step 510 Global step 510 Train loss 5.51 on epoch=127
05/17/2022 13:57:16 - INFO - __main__ - Step 520 Global step 520 Train loss 5.56 on epoch=129
05/17/2022 13:57:18 - INFO - __main__ - Step 530 Global step 530 Train loss 5.65 on epoch=132
05/17/2022 13:57:19 - INFO - __main__ - Step 540 Global step 540 Train loss 5.52 on epoch=134
05/17/2022 13:57:20 - INFO - __main__ - Step 550 Global step 550 Train loss 5.38 on epoch=137
05/17/2022 13:57:26 - INFO - __main__ - Global step 550 Train loss 5.52 Classification-F1 0.0 on epoch=137
05/17/2022 13:57:27 - INFO - __main__ - Step 560 Global step 560 Train loss 5.49 on epoch=139
05/17/2022 13:57:29 - INFO - __main__ - Step 570 Global step 570 Train loss 5.29 on epoch=142
05/17/2022 13:57:30 - INFO - __main__ - Step 580 Global step 580 Train loss 5.44 on epoch=144
05/17/2022 13:57:32 - INFO - __main__ - Step 590 Global step 590 Train loss 5.23 on epoch=147
05/17/2022 13:57:33 - INFO - __main__ - Step 600 Global step 600 Train loss 5.13 on epoch=149
05/17/2022 13:57:41 - INFO - __main__ - Global step 600 Train loss 5.31 Classification-F1 0.0 on epoch=149
05/17/2022 13:57:42 - INFO - __main__ - Step 610 Global step 610 Train loss 5.08 on epoch=152
05/17/2022 13:57:43 - INFO - __main__ - Step 620 Global step 620 Train loss 5.25 on epoch=154
05/17/2022 13:57:45 - INFO - __main__ - Step 630 Global step 630 Train loss 4.86 on epoch=157
05/17/2022 13:57:46 - INFO - __main__ - Step 640 Global step 640 Train loss 5.30 on epoch=159
05/17/2022 13:57:48 - INFO - __main__ - Step 650 Global step 650 Train loss 4.79 on epoch=162
05/17/2022 13:57:53 - INFO - __main__ - Global step 650 Train loss 5.06 Classification-F1 0.0 on epoch=162
05/17/2022 13:57:54 - INFO - __main__ - Step 660 Global step 660 Train loss 5.04 on epoch=164
05/17/2022 13:57:55 - INFO - __main__ - Step 670 Global step 670 Train loss 4.88 on epoch=167
05/17/2022 13:57:57 - INFO - __main__ - Step 680 Global step 680 Train loss 4.78 on epoch=169
05/17/2022 13:57:58 - INFO - __main__ - Step 690 Global step 690 Train loss 4.85 on epoch=172
05/17/2022 13:57:59 - INFO - __main__ - Step 700 Global step 700 Train loss 4.80 on epoch=174
05/17/2022 13:58:06 - INFO - __main__ - Global step 700 Train loss 4.87 Classification-F1 0.0 on epoch=174
05/17/2022 13:58:07 - INFO - __main__ - Step 710 Global step 710 Train loss 4.72 on epoch=177
05/17/2022 13:58:08 - INFO - __main__ - Step 720 Global step 720 Train loss 4.87 on epoch=179
05/17/2022 13:58:10 - INFO - __main__ - Step 730 Global step 730 Train loss 4.59 on epoch=182
05/17/2022 13:58:11 - INFO - __main__ - Step 740 Global step 740 Train loss 4.88 on epoch=184
05/17/2022 13:58:13 - INFO - __main__ - Step 750 Global step 750 Train loss 4.60 on epoch=187
05/17/2022 13:58:23 - INFO - __main__ - Global step 750 Train loss 4.73 Classification-F1 0.0 on epoch=187
05/17/2022 13:58:24 - INFO - __main__ - Step 760 Global step 760 Train loss 4.51 on epoch=189
05/17/2022 13:58:25 - INFO - __main__ - Step 770 Global step 770 Train loss 4.63 on epoch=192
05/17/2022 13:58:27 - INFO - __main__ - Step 780 Global step 780 Train loss 4.55 on epoch=194
05/17/2022 13:58:28 - INFO - __main__ - Step 790 Global step 790 Train loss 4.51 on epoch=197
05/17/2022 13:58:29 - INFO - __main__ - Step 800 Global step 800 Train loss 4.52 on epoch=199
05/17/2022 13:58:37 - INFO - __main__ - Global step 800 Train loss 4.54 Classification-F1 0.0 on epoch=199
05/17/2022 13:58:38 - INFO - __main__ - Step 810 Global step 810 Train loss 4.32 on epoch=202
05/17/2022 13:58:39 - INFO - __main__ - Step 820 Global step 820 Train loss 4.67 on epoch=204
05/17/2022 13:58:41 - INFO - __main__ - Step 830 Global step 830 Train loss 4.42 on epoch=207
05/17/2022 13:58:43 - INFO - __main__ - Step 840 Global step 840 Train loss 4.33 on epoch=209
05/17/2022 13:58:44 - INFO - __main__ - Step 850 Global step 850 Train loss 4.26 on epoch=212
05/17/2022 13:58:55 - INFO - __main__ - Global step 850 Train loss 4.40 Classification-F1 0.0 on epoch=212
05/17/2022 13:58:56 - INFO - __main__ - Step 860 Global step 860 Train loss 4.34 on epoch=214
05/17/2022 13:58:58 - INFO - __main__ - Step 870 Global step 870 Train loss 4.21 on epoch=217
05/17/2022 13:58:59 - INFO - __main__ - Step 880 Global step 880 Train loss 4.27 on epoch=219
05/17/2022 13:59:01 - INFO - __main__ - Step 890 Global step 890 Train loss 4.22 on epoch=222
05/17/2022 13:59:02 - INFO - __main__ - Step 900 Global step 900 Train loss 4.23 on epoch=224
05/17/2022 13:59:08 - INFO - __main__ - Global step 900 Train loss 4.25 Classification-F1 0.0 on epoch=224
05/17/2022 13:59:10 - INFO - __main__ - Step 910 Global step 910 Train loss 4.02 on epoch=227
05/17/2022 13:59:11 - INFO - __main__ - Step 920 Global step 920 Train loss 4.27 on epoch=229
05/17/2022 13:59:12 - INFO - __main__ - Step 930 Global step 930 Train loss 4.12 on epoch=232
05/17/2022 13:59:14 - INFO - __main__ - Step 940 Global step 940 Train loss 4.18 on epoch=234
05/17/2022 13:59:15 - INFO - __main__ - Step 950 Global step 950 Train loss 4.05 on epoch=237
05/17/2022 13:59:22 - INFO - __main__ - Global step 950 Train loss 4.13 Classification-F1 0.01 on epoch=237
05/17/2022 13:59:22 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.01 on epoch=237, global_step=950
05/17/2022 13:59:24 - INFO - __main__ - Step 960 Global step 960 Train loss 3.89 on epoch=239
05/17/2022 13:59:25 - INFO - __main__ - Step 970 Global step 970 Train loss 3.89 on epoch=242
05/17/2022 13:59:27 - INFO - __main__ - Step 980 Global step 980 Train loss 3.92 on epoch=244
05/17/2022 13:59:28 - INFO - __main__ - Step 990 Global step 990 Train loss 4.18 on epoch=247
05/17/2022 13:59:29 - INFO - __main__ - Step 1000 Global step 1000 Train loss 3.89 on epoch=249
05/17/2022 13:59:34 - INFO - __main__ - Global step 1000 Train loss 3.95 Classification-F1 0.04255319148936171 on epoch=249
05/17/2022 13:59:34 - INFO - __main__ - Saving model with best Classification-F1: 0.01 -> 0.04255319148936171 on epoch=249, global_step=1000
05/17/2022 13:59:36 - INFO - __main__ - Step 1010 Global step 1010 Train loss 3.72 on epoch=252
05/17/2022 13:59:37 - INFO - __main__ - Step 1020 Global step 1020 Train loss 4.05 on epoch=254
05/17/2022 13:59:38 - INFO - __main__ - Step 1030 Global step 1030 Train loss 3.73 on epoch=257
05/17/2022 13:59:40 - INFO - __main__ - Step 1040 Global step 1040 Train loss 3.88 on epoch=259
05/17/2022 13:59:41 - INFO - __main__ - Step 1050 Global step 1050 Train loss 3.86 on epoch=262
05/17/2022 13:59:49 - INFO - __main__ - Global step 1050 Train loss 3.85 Classification-F1 0.06666666666666667 on epoch=262
05/17/2022 13:59:49 - INFO - __main__ - Saving model with best Classification-F1: 0.04255319148936171 -> 0.06666666666666667 on epoch=262, global_step=1050
05/17/2022 13:59:50 - INFO - __main__ - Step 1060 Global step 1060 Train loss 3.79 on epoch=264
05/17/2022 13:59:51 - INFO - __main__ - Step 1070 Global step 1070 Train loss 3.68 on epoch=267
05/17/2022 13:59:53 - INFO - __main__ - Step 1080 Global step 1080 Train loss 3.68 on epoch=269
05/17/2022 13:59:54 - INFO - __main__ - Step 1090 Global step 1090 Train loss 3.51 on epoch=272
05/17/2022 13:59:55 - INFO - __main__ - Step 1100 Global step 1100 Train loss 3.80 on epoch=274
05/17/2022 14:00:11 - INFO - __main__ - Global step 1100 Train loss 3.69 Classification-F1 0.1 on epoch=274
05/17/2022 14:00:11 - INFO - __main__ - Saving model with best Classification-F1: 0.06666666666666667 -> 0.1 on epoch=274, global_step=1100
05/17/2022 14:00:12 - INFO - __main__ - Step 1110 Global step 1110 Train loss 3.53 on epoch=277
05/17/2022 14:00:14 - INFO - __main__ - Step 1120 Global step 1120 Train loss 3.56 on epoch=279
05/17/2022 14:00:15 - INFO - __main__ - Step 1130 Global step 1130 Train loss 3.54 on epoch=282
05/17/2022 14:00:17 - INFO - __main__ - Step 1140 Global step 1140 Train loss 3.69 on epoch=284
05/17/2022 14:00:18 - INFO - __main__ - Step 1150 Global step 1150 Train loss 3.44 on epoch=287
05/17/2022 14:00:32 - INFO - __main__ - Global step 1150 Train loss 3.55 Classification-F1 0.0810126582278481 on epoch=287
05/17/2022 14:00:33 - INFO - __main__ - Step 1160 Global step 1160 Train loss 3.64 on epoch=289
05/17/2022 14:00:34 - INFO - __main__ - Step 1170 Global step 1170 Train loss 3.39 on epoch=292
05/17/2022 14:00:36 - INFO - __main__ - Step 1180 Global step 1180 Train loss 3.27 on epoch=294
05/17/2022 14:00:37 - INFO - __main__ - Step 1190 Global step 1190 Train loss 3.38 on epoch=297
05/17/2022 14:00:38 - INFO - __main__ - Step 1200 Global step 1200 Train loss 3.45 on epoch=299
05/17/2022 14:00:47 - INFO - __main__ - Global step 1200 Train loss 3.43 Classification-F1 0.0810126582278481 on epoch=299
05/17/2022 14:00:49 - INFO - __main__ - Step 1210 Global step 1210 Train loss 3.35 on epoch=302
05/17/2022 14:00:50 - INFO - __main__ - Step 1220 Global step 1220 Train loss 3.29 on epoch=304
05/17/2022 14:00:51 - INFO - __main__ - Step 1230 Global step 1230 Train loss 3.18 on epoch=307
05/17/2022 14:00:53 - INFO - __main__ - Step 1240 Global step 1240 Train loss 3.31 on epoch=309
05/17/2022 14:00:54 - INFO - __main__ - Step 1250 Global step 1250 Train loss 3.09 on epoch=312
05/17/2022 14:01:11 - INFO - __main__ - Global step 1250 Train loss 3.24 Classification-F1 0.1 on epoch=312
05/17/2022 14:01:12 - INFO - __main__ - Step 1260 Global step 1260 Train loss 3.29 on epoch=314
05/17/2022 14:01:13 - INFO - __main__ - Step 1270 Global step 1270 Train loss 3.12 on epoch=317
05/17/2022 14:01:15 - INFO - __main__ - Step 1280 Global step 1280 Train loss 3.09 on epoch=319
05/17/2022 14:01:16 - INFO - __main__ - Step 1290 Global step 1290 Train loss 3.07 on epoch=322
05/17/2022 14:01:17 - INFO - __main__ - Step 1300 Global step 1300 Train loss 3.22 on epoch=324
05/17/2022 14:01:36 - INFO - __main__ - Global step 1300 Train loss 3.16 Classification-F1 0.10126582278481013 on epoch=324
05/17/2022 14:01:36 - INFO - __main__ - Saving model with best Classification-F1: 0.1 -> 0.10126582278481013 on epoch=324, global_step=1300
05/17/2022 14:01:37 - INFO - __main__ - Step 1310 Global step 1310 Train loss 2.78 on epoch=327
05/17/2022 14:01:39 - INFO - __main__ - Step 1320 Global step 1320 Train loss 3.06 on epoch=329
05/17/2022 14:01:40 - INFO - __main__ - Step 1330 Global step 1330 Train loss 3.19 on epoch=332
05/17/2022 14:01:42 - INFO - __main__ - Step 1340 Global step 1340 Train loss 3.16 on epoch=334
05/17/2022 14:01:43 - INFO - __main__ - Step 1350 Global step 1350 Train loss 2.85 on epoch=337
05/17/2022 14:01:56 - INFO - __main__ - Global step 1350 Train loss 3.01 Classification-F1 0.10126582278481013 on epoch=337
05/17/2022 14:01:57 - INFO - __main__ - Step 1360 Global step 1360 Train loss 3.03 on epoch=339
05/17/2022 14:01:59 - INFO - __main__ - Step 1370 Global step 1370 Train loss 2.91 on epoch=342
05/17/2022 14:02:01 - INFO - __main__ - Step 1380 Global step 1380 Train loss 2.88 on epoch=344
05/17/2022 14:02:02 - INFO - __main__ - Step 1390 Global step 1390 Train loss 2.77 on epoch=347
05/17/2022 14:02:04 - INFO - __main__ - Step 1400 Global step 1400 Train loss 2.90 on epoch=349
05/17/2022 14:02:13 - INFO - __main__ - Global step 1400 Train loss 2.90 Classification-F1 0.1 on epoch=349
05/17/2022 14:02:15 - INFO - __main__ - Step 1410 Global step 1410 Train loss 2.70 on epoch=352
05/17/2022 14:02:16 - INFO - __main__ - Step 1420 Global step 1420 Train loss 2.90 on epoch=354
05/17/2022 14:02:17 - INFO - __main__ - Step 1430 Global step 1430 Train loss 2.86 on epoch=357
05/17/2022 14:02:19 - INFO - __main__ - Step 1440 Global step 1440 Train loss 2.86 on epoch=359
05/17/2022 14:02:20 - INFO - __main__ - Step 1450 Global step 1450 Train loss 2.69 on epoch=362
05/17/2022 14:02:30 - INFO - __main__ - Global step 1450 Train loss 2.80 Classification-F1 0.1 on epoch=362
05/17/2022 14:02:31 - INFO - __main__ - Step 1460 Global step 1460 Train loss 2.68 on epoch=364
05/17/2022 14:02:33 - INFO - __main__ - Step 1470 Global step 1470 Train loss 2.51 on epoch=367
05/17/2022 14:02:34 - INFO - __main__ - Step 1480 Global step 1480 Train loss 2.61 on epoch=369
05/17/2022 14:02:35 - INFO - __main__ - Step 1490 Global step 1490 Train loss 2.66 on epoch=372
05/17/2022 14:02:36 - INFO - __main__ - Step 1500 Global step 1500 Train loss 2.66 on epoch=374
05/17/2022 14:02:40 - INFO - __main__ - Global step 1500 Train loss 2.62 Classification-F1 0.1 on epoch=374
05/17/2022 14:02:41 - INFO - __main__ - Step 1510 Global step 1510 Train loss 2.49 on epoch=377
05/17/2022 14:02:42 - INFO - __main__ - Step 1520 Global step 1520 Train loss 2.58 on epoch=379
05/17/2022 14:02:44 - INFO - __main__ - Step 1530 Global step 1530 Train loss 2.41 on epoch=382
05/17/2022 14:02:45 - INFO - __main__ - Step 1540 Global step 1540 Train loss 2.56 on epoch=384
05/17/2022 14:02:46 - INFO - __main__ - Step 1550 Global step 1550 Train loss 2.51 on epoch=387
05/17/2022 14:02:47 - INFO - __main__ - Global step 1550 Train loss 2.51 Classification-F1 0.1 on epoch=387
05/17/2022 14:02:48 - INFO - __main__ - Step 1560 Global step 1560 Train loss 2.48 on epoch=389
05/17/2022 14:02:50 - INFO - __main__ - Step 1570 Global step 1570 Train loss 2.45 on epoch=392
05/17/2022 14:02:51 - INFO - __main__ - Step 1580 Global step 1580 Train loss 2.43 on epoch=394
05/17/2022 14:02:52 - INFO - __main__ - Step 1590 Global step 1590 Train loss 2.44 on epoch=397
05/17/2022 14:02:53 - INFO - __main__ - Step 1600 Global step 1600 Train loss 2.47 on epoch=399
05/17/2022 14:02:54 - INFO - __main__ - Global step 1600 Train loss 2.45 Classification-F1 0.1 on epoch=399
05/17/2022 14:02:55 - INFO - __main__ - Step 1610 Global step 1610 Train loss 2.22 on epoch=402
05/17/2022 14:02:57 - INFO - __main__ - Step 1620 Global step 1620 Train loss 2.25 on epoch=404
05/17/2022 14:02:58 - INFO - __main__ - Step 1630 Global step 1630 Train loss 2.12 on epoch=407
05/17/2022 14:02:59 - INFO - __main__ - Step 1640 Global step 1640 Train loss 2.25 on epoch=409
05/17/2022 14:03:01 - INFO - __main__ - Step 1650 Global step 1650 Train loss 2.36 on epoch=412
05/17/2022 14:03:02 - INFO - __main__ - Global step 1650 Train loss 2.24 Classification-F1 0.1 on epoch=412
05/17/2022 14:03:03 - INFO - __main__ - Step 1660 Global step 1660 Train loss 2.24 on epoch=414
05/17/2022 14:03:04 - INFO - __main__ - Step 1670 Global step 1670 Train loss 2.17 on epoch=417
05/17/2022 14:03:06 - INFO - __main__ - Step 1680 Global step 1680 Train loss 2.11 on epoch=419
05/17/2022 14:03:07 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.92 on epoch=422
05/17/2022 14:03:09 - INFO - __main__ - Step 1700 Global step 1700 Train loss 2.05 on epoch=424
05/17/2022 14:03:09 - INFO - __main__ - Global step 1700 Train loss 2.10 Classification-F1 0.1 on epoch=424
05/17/2022 14:03:11 - INFO - __main__ - Step 1710 Global step 1710 Train loss 2.05 on epoch=427
05/17/2022 14:03:13 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.97 on epoch=429
05/17/2022 14:03:14 - INFO - __main__ - Step 1730 Global step 1730 Train loss 2.14 on epoch=432
05/17/2022 14:03:16 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.93 on epoch=434
05/17/2022 14:03:17 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.89 on epoch=437
05/17/2022 14:03:18 - INFO - __main__ - Global step 1750 Train loss 2.00 Classification-F1 0.11762954139368673 on epoch=437
05/17/2022 14:03:18 - INFO - __main__ - Saving model with best Classification-F1: 0.10126582278481013 -> 0.11762954139368673 on epoch=437, global_step=1750
05/17/2022 14:03:19 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.98 on epoch=439
05/17/2022 14:03:21 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.77 on epoch=442
05/17/2022 14:03:22 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.87 on epoch=444
05/17/2022 14:03:24 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.77 on epoch=447
05/17/2022 14:03:25 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.96 on epoch=449
05/17/2022 14:03:26 - INFO - __main__ - Global step 1800 Train loss 1.87 Classification-F1 0.0974025974025974 on epoch=449
05/17/2022 14:03:27 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.85 on epoch=452
05/17/2022 14:03:28 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.63 on epoch=454
05/17/2022 14:03:30 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.77 on epoch=457
05/17/2022 14:03:31 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.62 on epoch=459
05/17/2022 14:03:33 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.80 on epoch=462
05/17/2022 14:03:33 - INFO - __main__ - Global step 1850 Train loss 1.74 Classification-F1 0.10389610389610389 on epoch=462
05/17/2022 14:03:35 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.74 on epoch=464
05/17/2022 14:03:36 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.67 on epoch=467
05/17/2022 14:03:38 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.72 on epoch=469
05/17/2022 14:03:39 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.66 on epoch=472
05/17/2022 14:03:40 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.54 on epoch=474
05/17/2022 14:03:41 - INFO - __main__ - Global step 1900 Train loss 1.67 Classification-F1 0.10126582278481013 on epoch=474
05/17/2022 14:03:42 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.52 on epoch=477
05/17/2022 14:03:44 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.68 on epoch=479
05/17/2022 14:03:45 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.63 on epoch=482
05/17/2022 14:03:46 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.52 on epoch=484
05/17/2022 14:03:48 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.64 on epoch=487
05/17/2022 14:03:48 - INFO - __main__ - Global step 1950 Train loss 1.60 Classification-F1 0.20238095238095238 on epoch=487
05/17/2022 14:03:48 - INFO - __main__ - Saving model with best Classification-F1: 0.11762954139368673 -> 0.20238095238095238 on epoch=487, global_step=1950
05/17/2022 14:03:50 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.66 on epoch=489
05/17/2022 14:03:51 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.67 on epoch=492
05/17/2022 14:03:53 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.65 on epoch=494
05/17/2022 14:03:54 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.43 on epoch=497
05/17/2022 14:03:55 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.48 on epoch=499
05/17/2022 14:03:56 - INFO - __main__ - Global step 2000 Train loss 1.58 Classification-F1 0.09493670886075949 on epoch=499
05/17/2022 14:03:58 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.56 on epoch=502
05/17/2022 14:03:59 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.59 on epoch=504
05/17/2022 14:04:01 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.35 on epoch=507
05/17/2022 14:04:02 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.63 on epoch=509
05/17/2022 14:04:04 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.55 on epoch=512
05/17/2022 14:04:05 - INFO - __main__ - Global step 2050 Train loss 1.54 Classification-F1 0.10126582278481013 on epoch=512
05/17/2022 14:04:06 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.49 on epoch=514
05/17/2022 14:04:08 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.53 on epoch=517
05/17/2022 14:04:09 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.35 on epoch=519
05/17/2022 14:04:11 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.39 on epoch=522
05/17/2022 14:04:12 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.53 on epoch=524
05/17/2022 14:04:13 - INFO - __main__ - Global step 2100 Train loss 1.46 Classification-F1 0.1 on epoch=524
05/17/2022 14:04:14 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.52 on epoch=527
05/17/2022 14:04:16 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.46 on epoch=529
05/17/2022 14:04:18 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.39 on epoch=532
05/17/2022 14:04:19 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.54 on epoch=534
05/17/2022 14:04:21 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.40 on epoch=537
05/17/2022 14:04:21 - INFO - __main__ - Global step 2150 Train loss 1.46 Classification-F1 0.1 on epoch=537
05/17/2022 14:04:23 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.39 on epoch=539
05/17/2022 14:04:24 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.41 on epoch=542
05/17/2022 14:04:26 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.48 on epoch=544
05/17/2022 14:04:27 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.37 on epoch=547
05/17/2022 14:04:29 - INFO - __main__ - Step 2200 Global step 2200 Train loss 1.55 on epoch=549
05/17/2022 14:04:29 - INFO - __main__ - Global step 2200 Train loss 1.44 Classification-F1 0.09090909090909091 on epoch=549
05/17/2022 14:04:31 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.33 on epoch=552
05/17/2022 14:04:32 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.42 on epoch=554
05/17/2022 14:04:33 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.46 on epoch=557
05/17/2022 14:04:35 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.27 on epoch=559
05/17/2022 14:04:36 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.43 on epoch=562
05/17/2022 14:04:37 - INFO - __main__ - Global step 2250 Train loss 1.38 Classification-F1 0.1 on epoch=562
05/17/2022 14:04:38 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.26 on epoch=564
05/17/2022 14:04:40 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.30 on epoch=567
05/17/2022 14:04:41 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.36 on epoch=569
05/17/2022 14:04:43 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.26 on epoch=572
05/17/2022 14:04:44 - INFO - __main__ - Step 2300 Global step 2300 Train loss 1.35 on epoch=574
05/17/2022 14:04:45 - INFO - __main__ - Global step 2300 Train loss 1.31 Classification-F1 0.1 on epoch=574
05/17/2022 14:04:46 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.38 on epoch=577
05/17/2022 14:04:47 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.27 on epoch=579
05/17/2022 14:04:49 - INFO - __main__ - Step 2330 Global step 2330 Train loss 1.35 on epoch=582
05/17/2022 14:04:50 - INFO - __main__ - Step 2340 Global step 2340 Train loss 1.35 on epoch=584
05/17/2022 14:04:52 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.29 on epoch=587
05/17/2022 14:04:52 - INFO - __main__ - Global step 2350 Train loss 1.33 Classification-F1 0.1 on epoch=587
05/17/2022 14:04:54 - INFO - __main__ - Step 2360 Global step 2360 Train loss 1.38 on epoch=589
05/17/2022 14:04:55 - INFO - __main__ - Step 2370 Global step 2370 Train loss 1.21 on epoch=592
05/17/2022 14:04:57 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.29 on epoch=594
05/17/2022 14:04:58 - INFO - __main__ - Step 2390 Global step 2390 Train loss 1.11 on epoch=597
05/17/2022 14:04:59 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.22 on epoch=599
05/17/2022 14:05:00 - INFO - __main__ - Global step 2400 Train loss 1.24 Classification-F1 0.1 on epoch=599
05/17/2022 14:05:01 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.18 on epoch=602
05/17/2022 14:05:03 - INFO - __main__ - Step 2420 Global step 2420 Train loss 1.31 on epoch=604
05/17/2022 14:05:04 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.21 on epoch=607
05/17/2022 14:05:06 - INFO - __main__ - Step 2440 Global step 2440 Train loss 1.25 on epoch=609
05/17/2022 14:05:07 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.35 on epoch=612
05/17/2022 14:05:08 - INFO - __main__ - Global step 2450 Train loss 1.26 Classification-F1 0.1 on epoch=612
05/17/2022 14:05:09 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.36 on epoch=614
05/17/2022 14:05:11 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.20 on epoch=617
05/17/2022 14:05:12 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.25 on epoch=619
05/17/2022 14:05:14 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.28 on epoch=622
05/17/2022 14:05:15 - INFO - __main__ - Step 2500 Global step 2500 Train loss 1.36 on epoch=624
05/17/2022 14:05:16 - INFO - __main__ - Global step 2500 Train loss 1.29 Classification-F1 0.1 on epoch=624
05/17/2022 14:05:17 - INFO - __main__ - Step 2510 Global step 2510 Train loss 1.27 on epoch=627
05/17/2022 14:05:19 - INFO - __main__ - Step 2520 Global step 2520 Train loss 1.37 on epoch=629
05/17/2022 14:05:20 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.26 on epoch=632
05/17/2022 14:05:22 - INFO - __main__ - Step 2540 Global step 2540 Train loss 1.45 on epoch=634
05/17/2022 14:05:23 - INFO - __main__ - Step 2550 Global step 2550 Train loss 1.37 on epoch=637
05/17/2022 14:05:24 - INFO - __main__ - Global step 2550 Train loss 1.35 Classification-F1 0.1 on epoch=637
05/17/2022 14:05:25 - INFO - __main__ - Step 2560 Global step 2560 Train loss 1.30 on epoch=639
05/17/2022 14:05:26 - INFO - __main__ - Step 2570 Global step 2570 Train loss 1.39 on epoch=642
05/17/2022 14:05:28 - INFO - __main__ - Step 2580 Global step 2580 Train loss 1.22 on epoch=644
05/17/2022 14:05:29 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.21 on epoch=647
05/17/2022 14:05:30 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.23 on epoch=649
05/17/2022 14:05:31 - INFO - __main__ - Global step 2600 Train loss 1.27 Classification-F1 0.10126582278481013 on epoch=649
05/17/2022 14:05:32 - INFO - __main__ - Step 2610 Global step 2610 Train loss 1.11 on epoch=652
05/17/2022 14:05:34 - INFO - __main__ - Step 2620 Global step 2620 Train loss 1.21 on epoch=654
05/17/2022 14:05:35 - INFO - __main__ - Step 2630 Global step 2630 Train loss 1.20 on epoch=657
05/17/2022 14:05:37 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.32 on epoch=659
05/17/2022 14:05:38 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.14 on epoch=662
05/17/2022 14:05:39 - INFO - __main__ - Global step 2650 Train loss 1.20 Classification-F1 0.1500341763499658 on epoch=662
05/17/2022 14:05:40 - INFO - __main__ - Step 2660 Global step 2660 Train loss 1.21 on epoch=664
05/17/2022 14:05:42 - INFO - __main__ - Step 2670 Global step 2670 Train loss 1.17 on epoch=667
05/17/2022 14:05:43 - INFO - __main__ - Step 2680 Global step 2680 Train loss 1.26 on epoch=669
05/17/2022 14:05:44 - INFO - __main__ - Step 2690 Global step 2690 Train loss 1.19 on epoch=672
05/17/2022 14:05:46 - INFO - __main__ - Step 2700 Global step 2700 Train loss 1.18 on epoch=674
05/17/2022 14:05:46 - INFO - __main__ - Global step 2700 Train loss 1.20 Classification-F1 0.09493670886075949 on epoch=674
05/17/2022 14:05:48 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.16 on epoch=677
05/17/2022 14:05:49 - INFO - __main__ - Step 2720 Global step 2720 Train loss 1.22 on epoch=679
05/17/2022 14:05:50 - INFO - __main__ - Step 2730 Global step 2730 Train loss 1.22 on epoch=682
05/17/2022 14:05:52 - INFO - __main__ - Step 2740 Global step 2740 Train loss 1.17 on epoch=684
05/17/2022 14:05:53 - INFO - __main__ - Step 2750 Global step 2750 Train loss 1.24 on epoch=687
05/17/2022 14:05:54 - INFO - __main__ - Global step 2750 Train loss 1.21 Classification-F1 0.13067758749069247 on epoch=687
05/17/2022 14:05:55 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.22 on epoch=689
05/17/2022 14:05:57 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.12 on epoch=692
05/17/2022 14:05:58 - INFO - __main__ - Step 2780 Global step 2780 Train loss 1.24 on epoch=694
05/17/2022 14:05:59 - INFO - __main__ - Step 2790 Global step 2790 Train loss 1.27 on epoch=697
05/17/2022 14:06:01 - INFO - __main__ - Step 2800 Global step 2800 Train loss 1.15 on epoch=699
05/17/2022 14:06:01 - INFO - __main__ - Global step 2800 Train loss 1.20 Classification-F1 0.09090909090909091 on epoch=699
05/17/2022 14:06:03 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.14 on epoch=702
05/17/2022 14:06:04 - INFO - __main__ - Step 2820 Global step 2820 Train loss 1.18 on epoch=704
05/17/2022 14:06:06 - INFO - __main__ - Step 2830 Global step 2830 Train loss 1.12 on epoch=707
05/17/2022 14:06:07 - INFO - __main__ - Step 2840 Global step 2840 Train loss 1.09 on epoch=709
05/17/2022 14:06:08 - INFO - __main__ - Step 2850 Global step 2850 Train loss 1.13 on epoch=712
05/17/2022 14:06:09 - INFO - __main__ - Global step 2850 Train loss 1.13 Classification-F1 0.1 on epoch=712
05/17/2022 14:06:10 - INFO - __main__ - Step 2860 Global step 2860 Train loss 1.22 on epoch=714
05/17/2022 14:06:11 - INFO - __main__ - Step 2870 Global step 2870 Train loss 1.16 on epoch=717
05/17/2022 14:06:13 - INFO - __main__ - Step 2880 Global step 2880 Train loss 1.27 on epoch=719
05/17/2022 14:06:14 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.20 on epoch=722
05/17/2022 14:06:16 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.26 on epoch=724
05/17/2022 14:06:16 - INFO - __main__ - Global step 2900 Train loss 1.22 Classification-F1 0.1 on epoch=724
05/17/2022 14:06:18 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.11 on epoch=727
05/17/2022 14:06:19 - INFO - __main__ - Step 2920 Global step 2920 Train loss 1.23 on epoch=729
05/17/2022 14:06:20 - INFO - __main__ - Step 2930 Global step 2930 Train loss 1.19 on epoch=732
05/17/2022 14:06:22 - INFO - __main__ - Step 2940 Global step 2940 Train loss 1.10 on epoch=734
05/17/2022 14:06:23 - INFO - __main__ - Step 2950 Global step 2950 Train loss 1.15 on epoch=737
05/17/2022 14:06:24 - INFO - __main__ - Global step 2950 Train loss 1.15 Classification-F1 0.10126582278481013 on epoch=737
05/17/2022 14:06:25 - INFO - __main__ - Step 2960 Global step 2960 Train loss 1.21 on epoch=739
05/17/2022 14:06:26 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.14 on epoch=742
05/17/2022 14:06:28 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.24 on epoch=744
05/17/2022 14:06:29 - INFO - __main__ - Step 2990 Global step 2990 Train loss 1.11 on epoch=747
05/17/2022 14:06:30 - INFO - __main__ - Step 3000 Global step 3000 Train loss 1.13 on epoch=749
05/17/2022 14:06:31 - INFO - __main__ - Global step 3000 Train loss 1.17 Classification-F1 0.1 on epoch=749
05/17/2022 14:06:31 - INFO - __main__ - save last model!
05/17/2022 14:06:31 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/17/2022 14:06:31 - INFO - __main__ - Start tokenizing ... 5509 instances
05/17/2022 14:06:31 - INFO - __main__ - Printing 3 examples
05/17/2022 14:06:31 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/17/2022 14:06:31 - INFO - __main__ - ['others']
05/17/2022 14:06:31 - INFO - __main__ -  [emo] what you like very little things ok
05/17/2022 14:06:31 - INFO - __main__ - ['others']
05/17/2022 14:06:31 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/17/2022 14:06:31 - INFO - __main__ - ['others']
05/17/2022 14:06:31 - INFO - __main__ - Tokenizing Input ...
05/17/2022 14:06:32 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 14:06:32 - INFO - __main__ - Printing 3 examples
05/17/2022 14:06:32 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
05/17/2022 14:06:32 - INFO - __main__ - ['others']
05/17/2022 14:06:32 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
05/17/2022 14:06:32 - INFO - __main__ - ['others']
05/17/2022 14:06:32 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
05/17/2022 14:06:32 - INFO - __main__ - ['others']
05/17/2022 14:06:32 - INFO - __main__ - Tokenizing Input ...
05/17/2022 14:06:32 - INFO - __main__ - Tokenizing Output ...
05/17/2022 14:06:32 - INFO - __main__ - Loaded 64 examples from train data
05/17/2022 14:06:32 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 14:06:32 - INFO - __main__ - Printing 3 examples
05/17/2022 14:06:32 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
05/17/2022 14:06:32 - INFO - __main__ - ['others']
05/17/2022 14:06:32 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
05/17/2022 14:06:32 - INFO - __main__ - ['others']
05/17/2022 14:06:32 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
05/17/2022 14:06:32 - INFO - __main__ - ['others']
05/17/2022 14:06:32 - INFO - __main__ - Tokenizing Input ...
05/17/2022 14:06:32 - INFO - __main__ - Tokenizing Output ...
05/17/2022 14:06:32 - INFO - __main__ - Loaded 64 examples from dev data
05/17/2022 14:06:34 - INFO - __main__ - Tokenizing Output ...
05/17/2022 14:06:37 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 14:06:37 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 14:06:37 - INFO - __main__ - Starting training!
05/17/2022 14:06:39 - INFO - __main__ - Loaded 5509 examples from test data
05/17/2022 14:07:24 - INFO - __main__ - Saved prediction in models/T5-base-reptile-cls2cls-3e-5-2-5000-5e-1-10/singletask-emo/emo_16_42_0.2_8_predictions.txt
05/17/2022 14:07:24 - INFO - __main__ - Classification-F1 on test data: 0.0217
05/17/2022 14:07:24 - INFO - __main__ - prefix=emo_16_42, lr=0.2, bsz=8, dev_performance=0.20238095238095238, test_performance=0.021720243266724587
05/17/2022 14:07:24 - INFO - __main__ - Running ... prefix=emo_16_87, lr=0.5, bsz=8 ...
05/17/2022 14:07:25 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 14:07:25 - INFO - __main__ - Printing 3 examples
05/17/2022 14:07:25 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
05/17/2022 14:07:25 - INFO - __main__ - ['others']
05/17/2022 14:07:25 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
05/17/2022 14:07:25 - INFO - __main__ - ['others']
05/17/2022 14:07:25 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
05/17/2022 14:07:25 - INFO - __main__ - ['others']
05/17/2022 14:07:25 - INFO - __main__ - Tokenizing Input ...
05/17/2022 14:07:25 - INFO - __main__ - Tokenizing Output ...
05/17/2022 14:07:25 - INFO - __main__ - Loaded 64 examples from train data
05/17/2022 14:07:25 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 14:07:25 - INFO - __main__ - Printing 3 examples
05/17/2022 14:07:25 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
05/17/2022 14:07:25 - INFO - __main__ - ['others']
05/17/2022 14:07:25 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
05/17/2022 14:07:25 - INFO - __main__ - ['others']
05/17/2022 14:07:25 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
05/17/2022 14:07:25 - INFO - __main__ - ['others']
05/17/2022 14:07:25 - INFO - __main__ - Tokenizing Input ...
05/17/2022 14:07:25 - INFO - __main__ - Tokenizing Output ...
05/17/2022 14:07:26 - INFO - __main__ - Loaded 64 examples from dev data
05/17/2022 14:07:31 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 14:07:31 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 14:07:31 - INFO - __main__ - Starting training!
05/17/2022 14:07:33 - INFO - __main__ - Step 10 Global step 10 Train loss 8.97 on epoch=2
05/17/2022 14:07:34 - INFO - __main__ - Step 20 Global step 20 Train loss 8.99 on epoch=4
05/17/2022 14:07:36 - INFO - __main__ - Step 30 Global step 30 Train loss 8.88 on epoch=7
05/17/2022 14:07:37 - INFO - __main__ - Step 40 Global step 40 Train loss 8.85 on epoch=9
05/17/2022 14:07:38 - INFO - __main__ - Step 50 Global step 50 Train loss 8.87 on epoch=12
05/17/2022 14:07:46 - INFO - __main__ - Global step 50 Train loss 8.91 Classification-F1 0.0 on epoch=12
05/17/2022 14:07:46 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/17/2022 14:07:47 - INFO - __main__ - Step 60 Global step 60 Train loss 8.67 on epoch=14
05/17/2022 14:07:49 - INFO - __main__ - Step 70 Global step 70 Train loss 8.67 on epoch=17
05/17/2022 14:07:50 - INFO - __main__ - Step 80 Global step 80 Train loss 8.47 on epoch=19
05/17/2022 14:07:51 - INFO - __main__ - Step 90 Global step 90 Train loss 8.29 on epoch=22
05/17/2022 14:07:53 - INFO - __main__ - Step 100 Global step 100 Train loss 8.11 on epoch=24
05/17/2022 14:08:09 - INFO - __main__ - Global step 100 Train loss 8.44 Classification-F1 0.0 on epoch=24
05/17/2022 14:08:10 - INFO - __main__ - Step 110 Global step 110 Train loss 7.80 on epoch=27
05/17/2022 14:08:12 - INFO - __main__ - Step 120 Global step 120 Train loss 7.72 on epoch=29
05/17/2022 14:08:13 - INFO - __main__ - Step 130 Global step 130 Train loss 7.56 on epoch=32
05/17/2022 14:08:15 - INFO - __main__ - Step 140 Global step 140 Train loss 7.13 on epoch=34
05/17/2022 14:08:16 - INFO - __main__ - Step 150 Global step 150 Train loss 6.91 on epoch=37
05/17/2022 14:08:25 - INFO - __main__ - Global step 150 Train loss 7.42 Classification-F1 0.0 on epoch=37
05/17/2022 14:08:26 - INFO - __main__ - Step 160 Global step 160 Train loss 7.00 on epoch=39
05/17/2022 14:08:27 - INFO - __main__ - Step 170 Global step 170 Train loss 6.59 on epoch=42
05/17/2022 14:08:29 - INFO - __main__ - Step 180 Global step 180 Train loss 6.48 on epoch=44
05/17/2022 14:08:30 - INFO - __main__ - Step 190 Global step 190 Train loss 6.84 on epoch=47
05/17/2022 14:08:31 - INFO - __main__ - Step 200 Global step 200 Train loss 6.66 on epoch=49
05/17/2022 14:08:34 - INFO - __main__ - Global step 200 Train loss 6.71 Classification-F1 0.0 on epoch=49
05/17/2022 14:08:36 - INFO - __main__ - Step 210 Global step 210 Train loss 6.37 on epoch=52
05/17/2022 14:08:37 - INFO - __main__ - Step 220 Global step 220 Train loss 6.03 on epoch=54
05/17/2022 14:08:38 - INFO - __main__ - Step 230 Global step 230 Train loss 6.07 on epoch=57
05/17/2022 14:08:40 - INFO - __main__ - Step 240 Global step 240 Train loss 5.89 on epoch=59
05/17/2022 14:08:41 - INFO - __main__ - Step 250 Global step 250 Train loss 5.99 on epoch=62
05/17/2022 14:08:43 - INFO - __main__ - Global step 250 Train loss 6.07 Classification-F1 0.0 on epoch=62
05/17/2022 14:08:45 - INFO - __main__ - Step 260 Global step 260 Train loss 5.67 on epoch=64
05/17/2022 14:08:46 - INFO - __main__ - Step 270 Global step 270 Train loss 5.90 on epoch=67
05/17/2022 14:08:47 - INFO - __main__ - Step 280 Global step 280 Train loss 5.48 on epoch=69
05/17/2022 14:08:49 - INFO - __main__ - Step 290 Global step 290 Train loss 5.32 on epoch=72
05/17/2022 14:08:50 - INFO - __main__ - Step 300 Global step 300 Train loss 5.11 on epoch=74
05/17/2022 14:08:59 - INFO - __main__ - Global step 300 Train loss 5.50 Classification-F1 0.0 on epoch=74
05/17/2022 14:09:00 - INFO - __main__ - Step 310 Global step 310 Train loss 4.99 on epoch=77
05/17/2022 14:09:01 - INFO - __main__ - Step 320 Global step 320 Train loss 4.79 on epoch=79
05/17/2022 14:09:03 - INFO - __main__ - Step 330 Global step 330 Train loss 4.58 on epoch=82
05/17/2022 14:09:04 - INFO - __main__ - Step 340 Global step 340 Train loss 4.40 on epoch=84
05/17/2022 14:09:06 - INFO - __main__ - Step 350 Global step 350 Train loss 4.74 on epoch=87
05/17/2022 14:09:15 - INFO - __main__ - Global step 350 Train loss 4.70 Classification-F1 0.0 on epoch=87
05/17/2022 14:09:17 - INFO - __main__ - Step 360 Global step 360 Train loss 4.53 on epoch=89
05/17/2022 14:09:18 - INFO - __main__ - Step 370 Global step 370 Train loss 4.38 on epoch=92
05/17/2022 14:09:20 - INFO - __main__ - Step 380 Global step 380 Train loss 4.12 on epoch=94
05/17/2022 14:09:21 - INFO - __main__ - Step 390 Global step 390 Train loss 4.13 on epoch=97
05/17/2022 14:09:23 - INFO - __main__ - Step 400 Global step 400 Train loss 3.85 on epoch=99
05/17/2022 14:09:25 - INFO - __main__ - Global step 400 Train loss 4.20 Classification-F1 0.0 on epoch=99
05/17/2022 14:09:27 - INFO - __main__ - Step 410 Global step 410 Train loss 3.92 on epoch=102
05/17/2022 14:09:28 - INFO - __main__ - Step 420 Global step 420 Train loss 3.58 on epoch=104
05/17/2022 14:09:30 - INFO - __main__ - Step 430 Global step 430 Train loss 3.58 on epoch=107
05/17/2022 14:09:31 - INFO - __main__ - Step 440 Global step 440 Train loss 3.49 on epoch=109
05/17/2022 14:09:33 - INFO - __main__ - Step 450 Global step 450 Train loss 3.47 on epoch=112
05/17/2022 14:09:36 - INFO - __main__ - Global step 450 Train loss 3.61 Classification-F1 0.12519607843137254 on epoch=112
05/17/2022 14:09:36 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.12519607843137254 on epoch=112, global_step=450
05/17/2022 14:09:37 - INFO - __main__ - Step 460 Global step 460 Train loss 3.37 on epoch=114
05/17/2022 14:09:39 - INFO - __main__ - Step 470 Global step 470 Train loss 3.47 on epoch=117
05/17/2022 14:09:40 - INFO - __main__ - Step 480 Global step 480 Train loss 3.08 on epoch=119
05/17/2022 14:09:41 - INFO - __main__ - Step 490 Global step 490 Train loss 3.05 on epoch=122
05/17/2022 14:09:43 - INFO - __main__ - Step 500 Global step 500 Train loss 2.86 on epoch=124
05/17/2022 14:09:43 - INFO - __main__ - Global step 500 Train loss 3.17 Classification-F1 0.1527777777777778 on epoch=124
05/17/2022 14:09:43 - INFO - __main__ - Saving model with best Classification-F1: 0.12519607843137254 -> 0.1527777777777778 on epoch=124, global_step=500
05/17/2022 14:09:45 - INFO - __main__ - Step 510 Global step 510 Train loss 2.93 on epoch=127
05/17/2022 14:09:46 - INFO - __main__ - Step 520 Global step 520 Train loss 2.78 on epoch=129
05/17/2022 14:09:47 - INFO - __main__ - Step 530 Global step 530 Train loss 2.64 on epoch=132
05/17/2022 14:09:49 - INFO - __main__ - Step 540 Global step 540 Train loss 2.73 on epoch=134
05/17/2022 14:09:50 - INFO - __main__ - Step 550 Global step 550 Train loss 2.63 on epoch=137
05/17/2022 14:09:51 - INFO - __main__ - Global step 550 Train loss 2.74 Classification-F1 0.12407862407862408 on epoch=137
05/17/2022 14:09:52 - INFO - __main__ - Step 560 Global step 560 Train loss 2.31 on epoch=139
05/17/2022 14:09:53 - INFO - __main__ - Step 570 Global step 570 Train loss 2.44 on epoch=142
05/17/2022 14:09:55 - INFO - __main__ - Step 580 Global step 580 Train loss 2.08 on epoch=144
05/17/2022 14:09:57 - INFO - __main__ - Step 590 Global step 590 Train loss 2.20 on epoch=147
05/17/2022 14:09:58 - INFO - __main__ - Step 600 Global step 600 Train loss 2.29 on epoch=149
05/17/2022 14:09:59 - INFO - __main__ - Global step 600 Train loss 2.27 Classification-F1 0.1081081081081081 on epoch=149
05/17/2022 14:10:00 - INFO - __main__ - Step 610 Global step 610 Train loss 2.19 on epoch=152
05/17/2022 14:10:02 - INFO - __main__ - Step 620 Global step 620 Train loss 2.12 on epoch=154
05/17/2022 14:10:03 - INFO - __main__ - Step 630 Global step 630 Train loss 2.18 on epoch=157
05/17/2022 14:10:05 - INFO - __main__ - Step 640 Global step 640 Train loss 1.91 on epoch=159
05/17/2022 14:10:06 - INFO - __main__ - Step 650 Global step 650 Train loss 1.95 on epoch=162
05/17/2022 14:10:06 - INFO - __main__ - Global step 650 Train loss 2.07 Classification-F1 0.15521739130434786 on epoch=162
05/17/2022 14:10:06 - INFO - __main__ - Saving model with best Classification-F1: 0.1527777777777778 -> 0.15521739130434786 on epoch=162, global_step=650
05/17/2022 14:10:08 - INFO - __main__ - Step 660 Global step 660 Train loss 1.82 on epoch=164
05/17/2022 14:10:09 - INFO - __main__ - Step 670 Global step 670 Train loss 1.88 on epoch=167
05/17/2022 14:10:11 - INFO - __main__ - Step 680 Global step 680 Train loss 1.83 on epoch=169
05/17/2022 14:10:12 - INFO - __main__ - Step 690 Global step 690 Train loss 1.75 on epoch=172
05/17/2022 14:10:13 - INFO - __main__ - Step 700 Global step 700 Train loss 1.67 on epoch=174
05/17/2022 14:10:14 - INFO - __main__ - Global step 700 Train loss 1.79 Classification-F1 0.1451048951048951 on epoch=174
05/17/2022 14:10:15 - INFO - __main__ - Step 710 Global step 710 Train loss 1.77 on epoch=177
05/17/2022 14:10:16 - INFO - __main__ - Step 720 Global step 720 Train loss 1.58 on epoch=179
05/17/2022 14:10:18 - INFO - __main__ - Step 730 Global step 730 Train loss 1.72 on epoch=182
05/17/2022 14:10:19 - INFO - __main__ - Step 740 Global step 740 Train loss 1.61 on epoch=184
05/17/2022 14:10:20 - INFO - __main__ - Step 750 Global step 750 Train loss 1.57 on epoch=187
05/17/2022 14:10:21 - INFO - __main__ - Global step 750 Train loss 1.65 Classification-F1 0.22026143790849673 on epoch=187
05/17/2022 14:10:21 - INFO - __main__ - Saving model with best Classification-F1: 0.15521739130434786 -> 0.22026143790849673 on epoch=187, global_step=750
05/17/2022 14:10:22 - INFO - __main__ - Step 760 Global step 760 Train loss 1.64 on epoch=189
05/17/2022 14:10:24 - INFO - __main__ - Step 770 Global step 770 Train loss 1.57 on epoch=192
05/17/2022 14:10:25 - INFO - __main__ - Step 780 Global step 780 Train loss 1.64 on epoch=194
05/17/2022 14:10:26 - INFO - __main__ - Step 790 Global step 790 Train loss 1.49 on epoch=197
05/17/2022 14:10:28 - INFO - __main__ - Step 800 Global step 800 Train loss 1.54 on epoch=199
05/17/2022 14:10:28 - INFO - __main__ - Global step 800 Train loss 1.58 Classification-F1 0.16078790655061842 on epoch=199
05/17/2022 14:10:30 - INFO - __main__ - Step 810 Global step 810 Train loss 1.59 on epoch=202
05/17/2022 14:10:31 - INFO - __main__ - Step 820 Global step 820 Train loss 1.48 on epoch=204
05/17/2022 14:10:33 - INFO - __main__ - Step 830 Global step 830 Train loss 1.59 on epoch=207
05/17/2022 14:10:34 - INFO - __main__ - Step 840 Global step 840 Train loss 1.48 on epoch=209
05/17/2022 14:10:35 - INFO - __main__ - Step 850 Global step 850 Train loss 1.40 on epoch=212
05/17/2022 14:10:36 - INFO - __main__ - Global step 850 Train loss 1.51 Classification-F1 0.0974025974025974 on epoch=212
05/17/2022 14:10:37 - INFO - __main__ - Step 860 Global step 860 Train loss 1.39 on epoch=214
05/17/2022 14:10:39 - INFO - __main__ - Step 870 Global step 870 Train loss 1.46 on epoch=217
05/17/2022 14:10:40 - INFO - __main__ - Step 880 Global step 880 Train loss 1.43 on epoch=219
05/17/2022 14:10:41 - INFO - __main__ - Step 890 Global step 890 Train loss 1.42 on epoch=222
05/17/2022 14:10:43 - INFO - __main__ - Step 900 Global step 900 Train loss 1.48 on epoch=224
05/17/2022 14:10:43 - INFO - __main__ - Global step 900 Train loss 1.43 Classification-F1 0.16666666666666669 on epoch=224
05/17/2022 14:10:45 - INFO - __main__ - Step 910 Global step 910 Train loss 1.50 on epoch=227
05/17/2022 14:10:46 - INFO - __main__ - Step 920 Global step 920 Train loss 1.35 on epoch=229
05/17/2022 14:10:47 - INFO - __main__ - Step 930 Global step 930 Train loss 1.28 on epoch=232
05/17/2022 14:10:49 - INFO - __main__ - Step 940 Global step 940 Train loss 1.40 on epoch=234
05/17/2022 14:10:50 - INFO - __main__ - Step 950 Global step 950 Train loss 1.37 on epoch=237
05/17/2022 14:10:51 - INFO - __main__ - Global step 950 Train loss 1.38 Classification-F1 0.180905815748842 on epoch=237
05/17/2022 14:10:52 - INFO - __main__ - Step 960 Global step 960 Train loss 1.18 on epoch=239
05/17/2022 14:10:53 - INFO - __main__ - Step 970 Global step 970 Train loss 1.38 on epoch=242
05/17/2022 14:10:55 - INFO - __main__ - Step 980 Global step 980 Train loss 1.22 on epoch=244
05/17/2022 14:10:56 - INFO - __main__ - Step 990 Global step 990 Train loss 1.35 on epoch=247
05/17/2022 14:10:57 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.25 on epoch=249
05/17/2022 14:10:58 - INFO - __main__ - Global step 1000 Train loss 1.27 Classification-F1 0.2152777777777778 on epoch=249
05/17/2022 14:10:59 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.19 on epoch=252
05/17/2022 14:11:01 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.33 on epoch=254
05/17/2022 14:11:02 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.29 on epoch=257
05/17/2022 14:11:04 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.28 on epoch=259
05/17/2022 14:11:05 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.13 on epoch=262
05/17/2022 14:11:06 - INFO - __main__ - Global step 1050 Train loss 1.24 Classification-F1 0.1476190476190476 on epoch=262
05/17/2022 14:11:07 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.25 on epoch=264
05/17/2022 14:11:08 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.21 on epoch=267
05/17/2022 14:11:10 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.10 on epoch=269
05/17/2022 14:11:11 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.20 on epoch=272
05/17/2022 14:11:12 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.21 on epoch=274
05/17/2022 14:11:13 - INFO - __main__ - Global step 1100 Train loss 1.19 Classification-F1 0.1 on epoch=274
05/17/2022 14:11:14 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.21 on epoch=277
05/17/2022 14:11:16 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.39 on epoch=279
05/17/2022 14:11:17 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.14 on epoch=282
05/17/2022 14:11:19 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.23 on epoch=284
05/17/2022 14:11:20 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.23 on epoch=287
05/17/2022 14:11:20 - INFO - __main__ - Global step 1150 Train loss 1.24 Classification-F1 0.1542857142857143 on epoch=287
05/17/2022 14:11:22 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.14 on epoch=289
05/17/2022 14:11:23 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.34 on epoch=292
05/17/2022 14:11:25 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.15 on epoch=294
05/17/2022 14:11:26 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.09 on epoch=297
05/17/2022 14:11:27 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.16 on epoch=299
05/17/2022 14:11:28 - INFO - __main__ - Global step 1200 Train loss 1.18 Classification-F1 0.13194444444444445 on epoch=299
05/17/2022 14:11:29 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.32 on epoch=302
05/17/2022 14:11:31 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.18 on epoch=304
05/17/2022 14:11:32 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.21 on epoch=307
05/17/2022 14:11:33 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.18 on epoch=309
05/17/2022 14:11:35 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.20 on epoch=312
05/17/2022 14:11:35 - INFO - __main__ - Global step 1250 Train loss 1.22 Classification-F1 0.18607843137254904 on epoch=312
05/17/2022 14:11:37 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.17 on epoch=314
05/17/2022 14:11:38 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.17 on epoch=317
05/17/2022 14:11:39 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.99 on epoch=319
05/17/2022 14:11:41 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.17 on epoch=322
05/17/2022 14:11:42 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.17 on epoch=324
05/17/2022 14:11:43 - INFO - __main__ - Global step 1300 Train loss 1.13 Classification-F1 0.1785516860143726 on epoch=324
05/17/2022 14:11:44 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.10 on epoch=327
05/17/2022 14:11:45 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.14 on epoch=329
05/17/2022 14:11:47 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.13 on epoch=332
05/17/2022 14:11:48 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.14 on epoch=334
05/17/2022 14:11:49 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.11 on epoch=337
05/17/2022 14:11:50 - INFO - __main__ - Global step 1350 Train loss 1.12 Classification-F1 0.1237183868762816 on epoch=337
05/17/2022 14:11:51 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.14 on epoch=339
05/17/2022 14:11:53 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.02 on epoch=342
05/17/2022 14:11:54 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.12 on epoch=344
05/17/2022 14:11:55 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.04 on epoch=347
05/17/2022 14:11:57 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.09 on epoch=349
05/17/2022 14:11:57 - INFO - __main__ - Global step 1400 Train loss 1.08 Classification-F1 0.13067758749069247 on epoch=349
05/17/2022 14:11:59 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.12 on epoch=352
05/17/2022 14:12:00 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.10 on epoch=354
05/17/2022 14:12:01 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.09 on epoch=357
05/17/2022 14:12:03 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.03 on epoch=359
05/17/2022 14:12:04 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.93 on epoch=362
05/17/2022 14:12:05 - INFO - __main__ - Global step 1450 Train loss 1.05 Classification-F1 0.125 on epoch=362
05/17/2022 14:12:06 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.01 on epoch=364
05/17/2022 14:12:07 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.96 on epoch=367
05/17/2022 14:12:09 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.01 on epoch=369
05/17/2022 14:12:10 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.05 on epoch=372
05/17/2022 14:12:12 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.06 on epoch=374
05/17/2022 14:12:12 - INFO - __main__ - Global step 1500 Train loss 1.02 Classification-F1 0.12393162393162392 on epoch=374
05/17/2022 14:12:14 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.04 on epoch=377
05/17/2022 14:12:15 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.09 on epoch=379
05/17/2022 14:12:16 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.99 on epoch=382
05/17/2022 14:12:18 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.95 on epoch=384
05/17/2022 14:12:19 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.14 on epoch=387
05/17/2022 14:12:20 - INFO - __main__ - Global step 1550 Train loss 1.04 Classification-F1 0.1468058968058968 on epoch=387
05/17/2022 14:12:21 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.01 on epoch=389
05/17/2022 14:12:23 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.07 on epoch=392
05/17/2022 14:12:24 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.00 on epoch=394
05/17/2022 14:12:25 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.04 on epoch=397
05/17/2022 14:12:27 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.03 on epoch=399
05/17/2022 14:12:27 - INFO - __main__ - Global step 1600 Train loss 1.03 Classification-F1 0.1 on epoch=399
05/17/2022 14:12:29 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.17 on epoch=402
05/17/2022 14:12:30 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.02 on epoch=404
05/17/2022 14:12:31 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.02 on epoch=407
05/17/2022 14:12:33 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.06 on epoch=409
05/17/2022 14:12:34 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.03 on epoch=412
05/17/2022 14:12:35 - INFO - __main__ - Global step 1650 Train loss 1.06 Classification-F1 0.14285714285714285 on epoch=412
05/17/2022 14:12:36 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.99 on epoch=414
05/17/2022 14:12:37 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.98 on epoch=417
05/17/2022 14:12:38 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.98 on epoch=419
05/17/2022 14:12:40 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.05 on epoch=422
05/17/2022 14:12:41 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.10 on epoch=424
05/17/2022 14:12:42 - INFO - __main__ - Global step 1700 Train loss 1.02 Classification-F1 0.09090909090909091 on epoch=424
05/17/2022 14:12:43 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.03 on epoch=427
05/17/2022 14:12:45 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.13 on epoch=429
05/17/2022 14:12:46 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.18 on epoch=432
05/17/2022 14:12:48 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.94 on epoch=434
05/17/2022 14:12:49 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.90 on epoch=437
05/17/2022 14:12:50 - INFO - __main__ - Global step 1750 Train loss 1.03 Classification-F1 0.09333333333333334 on epoch=437
05/17/2022 14:12:51 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.89 on epoch=439
05/17/2022 14:12:52 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.00 on epoch=442
05/17/2022 14:12:54 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.02 on epoch=444
05/17/2022 14:12:55 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.08 on epoch=447
05/17/2022 14:12:56 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.08 on epoch=449
05/17/2022 14:12:57 - INFO - __main__ - Global step 1800 Train loss 1.01 Classification-F1 0.0974025974025974 on epoch=449
05/17/2022 14:12:58 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.97 on epoch=452
05/17/2022 14:13:00 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.16 on epoch=454
05/17/2022 14:13:01 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.97 on epoch=457
05/17/2022 14:13:02 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.07 on epoch=459
05/17/2022 14:13:04 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.10 on epoch=462
05/17/2022 14:13:04 - INFO - __main__ - Global step 1850 Train loss 1.06 Classification-F1 0.10256410256410256 on epoch=462
05/17/2022 14:13:05 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.03 on epoch=464
05/17/2022 14:13:07 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.97 on epoch=467
05/17/2022 14:13:08 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.97 on epoch=469
05/17/2022 14:13:09 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.00 on epoch=472
05/17/2022 14:13:11 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.97 on epoch=474
05/17/2022 14:13:11 - INFO - __main__ - Global step 1900 Train loss 0.99 Classification-F1 0.20053774017968393 on epoch=474
05/17/2022 14:13:13 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.96 on epoch=477
05/17/2022 14:13:14 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.13 on epoch=479
05/17/2022 14:13:15 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.97 on epoch=482
05/17/2022 14:13:17 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.04 on epoch=484
05/17/2022 14:13:18 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.94 on epoch=487
05/17/2022 14:13:18 - INFO - __main__ - Global step 1950 Train loss 1.01 Classification-F1 0.2269119769119769 on epoch=487
05/17/2022 14:13:18 - INFO - __main__ - Saving model with best Classification-F1: 0.22026143790849673 -> 0.2269119769119769 on epoch=487, global_step=1950
05/17/2022 14:13:20 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.93 on epoch=489
05/17/2022 14:13:21 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.02 on epoch=492
05/17/2022 14:13:23 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.02 on epoch=494
05/17/2022 14:13:24 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.16 on epoch=497
05/17/2022 14:13:25 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.10 on epoch=499
05/17/2022 14:13:26 - INFO - __main__ - Global step 2000 Train loss 1.04 Classification-F1 0.18618266978922718 on epoch=499
05/17/2022 14:13:27 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.01 on epoch=502
05/17/2022 14:13:29 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.98 on epoch=504
05/17/2022 14:13:30 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.11 on epoch=507
05/17/2022 14:13:31 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.01 on epoch=509
05/17/2022 14:13:33 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.07 on epoch=512
05/17/2022 14:13:33 - INFO - __main__ - Global step 2050 Train loss 1.03 Classification-F1 0.18833746898263026 on epoch=512
05/17/2022 14:13:35 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.97 on epoch=514
05/17/2022 14:13:36 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.04 on epoch=517
05/17/2022 14:13:37 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.00 on epoch=519
05/17/2022 14:13:39 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.07 on epoch=522
05/17/2022 14:13:40 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.97 on epoch=524
05/17/2022 14:13:41 - INFO - __main__ - Global step 2100 Train loss 1.01 Classification-F1 0.1597222222222222 on epoch=524
05/17/2022 14:13:42 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.05 on epoch=527
05/17/2022 14:13:43 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.08 on epoch=529
05/17/2022 14:13:45 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.99 on epoch=532
05/17/2022 14:13:46 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.03 on epoch=534
05/17/2022 14:13:48 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.03 on epoch=537
05/17/2022 14:13:48 - INFO - __main__ - Global step 2150 Train loss 1.04 Classification-F1 0.1638655462184874 on epoch=537
05/17/2022 14:13:50 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.96 on epoch=539
05/17/2022 14:13:51 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.03 on epoch=542
05/17/2022 14:13:53 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.90 on epoch=544
05/17/2022 14:13:54 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.05 on epoch=547
05/17/2022 14:13:55 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.91 on epoch=549
05/17/2022 14:13:56 - INFO - __main__ - Global step 2200 Train loss 0.97 Classification-F1 0.09493670886075949 on epoch=549
05/17/2022 14:13:57 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.02 on epoch=552
05/17/2022 14:13:59 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.87 on epoch=554
05/17/2022 14:14:00 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.98 on epoch=557
05/17/2022 14:14:01 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.06 on epoch=559
05/17/2022 14:14:03 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.97 on epoch=562
05/17/2022 14:14:03 - INFO - __main__ - Global step 2250 Train loss 0.98 Classification-F1 0.1782212885154062 on epoch=562
05/17/2022 14:14:05 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.03 on epoch=564
05/17/2022 14:14:06 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.95 on epoch=567
05/17/2022 14:14:07 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.01 on epoch=569
05/17/2022 14:14:09 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.05 on epoch=572
05/17/2022 14:14:10 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.89 on epoch=574
05/17/2022 14:14:11 - INFO - __main__ - Global step 2300 Train loss 0.99 Classification-F1 0.1 on epoch=574
05/17/2022 14:14:12 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.01 on epoch=577
05/17/2022 14:14:14 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.02 on epoch=579
05/17/2022 14:14:15 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.99 on epoch=582
05/17/2022 14:14:16 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.90 on epoch=584
05/17/2022 14:14:18 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.86 on epoch=587
05/17/2022 14:14:18 - INFO - __main__ - Global step 2350 Train loss 0.96 Classification-F1 0.1332923832923833 on epoch=587
05/17/2022 14:14:20 - INFO - __main__ - Step 2360 Global step 2360 Train loss 1.03 on epoch=589
05/17/2022 14:14:21 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.99 on epoch=592
05/17/2022 14:14:23 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.92 on epoch=594
05/17/2022 14:14:24 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.95 on epoch=597
05/17/2022 14:14:26 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.96 on epoch=599
05/17/2022 14:14:26 - INFO - __main__ - Global step 2400 Train loss 0.97 Classification-F1 0.20833333333333331 on epoch=599
05/17/2022 14:14:28 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.00 on epoch=602
05/17/2022 14:14:29 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.97 on epoch=604
05/17/2022 14:14:30 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.93 on epoch=607
05/17/2022 14:14:32 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.97 on epoch=609
05/17/2022 14:14:33 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.90 on epoch=612
05/17/2022 14:14:34 - INFO - __main__ - Global step 2450 Train loss 0.96 Classification-F1 0.1672879776328052 on epoch=612
05/17/2022 14:14:35 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.95 on epoch=614
05/17/2022 14:14:37 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.01 on epoch=617
05/17/2022 14:14:38 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.00 on epoch=619
05/17/2022 14:14:39 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.93 on epoch=622
05/17/2022 14:14:41 - INFO - __main__ - Step 2500 Global step 2500 Train loss 1.02 on epoch=624
05/17/2022 14:14:41 - INFO - __main__ - Global step 2500 Train loss 0.98 Classification-F1 0.12407862407862408 on epoch=624
05/17/2022 14:14:43 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.85 on epoch=627
05/17/2022 14:14:44 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.93 on epoch=629
05/17/2022 14:14:46 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.01 on epoch=632
05/17/2022 14:14:47 - INFO - __main__ - Step 2540 Global step 2540 Train loss 1.02 on epoch=634
05/17/2022 14:14:48 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.98 on epoch=637
05/17/2022 14:14:49 - INFO - __main__ - Global step 2550 Train loss 0.96 Classification-F1 0.09333333333333334 on epoch=637
05/17/2022 14:14:50 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.95 on epoch=639
05/17/2022 14:14:51 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.97 on epoch=642
05/17/2022 14:14:53 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.98 on epoch=644
05/17/2022 14:14:54 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.03 on epoch=647
05/17/2022 14:14:56 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.91 on epoch=649
05/17/2022 14:14:56 - INFO - __main__ - Global step 2600 Train loss 0.97 Classification-F1 0.20980302336234538 on epoch=649
05/17/2022 14:14:58 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.87 on epoch=652
05/17/2022 14:14:59 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.93 on epoch=654
05/17/2022 14:15:00 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.95 on epoch=657
05/17/2022 14:15:02 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.96 on epoch=659
05/17/2022 14:15:03 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.97 on epoch=662
05/17/2022 14:15:04 - INFO - __main__ - Global step 2650 Train loss 0.94 Classification-F1 0.18064516129032257 on epoch=662
05/17/2022 14:15:05 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.90 on epoch=664
05/17/2022 14:15:06 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.88 on epoch=667
05/17/2022 14:15:08 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.91 on epoch=669
05/17/2022 14:15:09 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.99 on epoch=672
05/17/2022 14:15:10 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.99 on epoch=674
05/17/2022 14:15:11 - INFO - __main__ - Global step 2700 Train loss 0.94 Classification-F1 0.21515151515151515 on epoch=674
05/17/2022 14:15:12 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.98 on epoch=677
05/17/2022 14:15:14 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.90 on epoch=679
05/17/2022 14:15:15 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.93 on epoch=682
05/17/2022 14:15:16 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.94 on epoch=684
05/17/2022 14:15:18 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.96 on epoch=687
05/17/2022 14:15:18 - INFO - __main__ - Global step 2750 Train loss 0.94 Classification-F1 0.22675217590471825 on epoch=687
05/17/2022 14:15:20 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.93 on epoch=689
05/17/2022 14:15:21 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.94 on epoch=692
05/17/2022 14:15:22 - INFO - __main__ - Step 2780 Global step 2780 Train loss 1.00 on epoch=694
05/17/2022 14:15:24 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.96 on epoch=697
05/17/2022 14:15:25 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.97 on epoch=699
05/17/2022 14:15:26 - INFO - __main__ - Global step 2800 Train loss 0.96 Classification-F1 0.17831215970961886 on epoch=699
05/17/2022 14:15:27 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.87 on epoch=702
05/17/2022 14:15:28 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.94 on epoch=704
05/17/2022 14:15:29 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.92 on epoch=707
05/17/2022 14:15:31 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.93 on epoch=709
05/17/2022 14:15:32 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.96 on epoch=712
05/17/2022 14:15:33 - INFO - __main__ - Global step 2850 Train loss 0.92 Classification-F1 0.18064516129032257 on epoch=712
05/17/2022 14:15:34 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.92 on epoch=714
05/17/2022 14:15:35 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.88 on epoch=717
05/17/2022 14:15:36 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.87 on epoch=719
05/17/2022 14:15:38 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.94 on epoch=722
05/17/2022 14:15:39 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.93 on epoch=724
05/17/2022 14:15:40 - INFO - __main__ - Global step 2900 Train loss 0.91 Classification-F1 0.09027777777777778 on epoch=724
05/17/2022 14:15:41 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.88 on epoch=727
05/17/2022 14:15:42 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.79 on epoch=729
05/17/2022 14:15:44 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.95 on epoch=732
05/17/2022 14:15:45 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.91 on epoch=734
05/17/2022 14:15:46 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.95 on epoch=737
05/17/2022 14:15:47 - INFO - __main__ - Global step 2950 Train loss 0.89 Classification-F1 0.1796875 on epoch=737
05/17/2022 14:15:48 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.91 on epoch=739
05/17/2022 14:15:49 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.85 on epoch=742
05/17/2022 14:15:51 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.96 on epoch=744
05/17/2022 14:15:52 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.90 on epoch=747
05/17/2022 14:15:53 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.93 on epoch=749
05/17/2022 14:15:54 - INFO - __main__ - Global step 3000 Train loss 0.91 Classification-F1 0.08783783783783784 on epoch=749
05/17/2022 14:15:54 - INFO - __main__ - save last model!
05/17/2022 14:15:54 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/17/2022 14:15:54 - INFO - __main__ - Start tokenizing ... 5509 instances
05/17/2022 14:15:54 - INFO - __main__ - Printing 3 examples
05/17/2022 14:15:54 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/17/2022 14:15:54 - INFO - __main__ - ['others']
05/17/2022 14:15:54 - INFO - __main__ -  [emo] what you like very little things ok
05/17/2022 14:15:54 - INFO - __main__ - ['others']
05/17/2022 14:15:54 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/17/2022 14:15:54 - INFO - __main__ - ['others']
05/17/2022 14:15:54 - INFO - __main__ - Tokenizing Input ...
05/17/2022 14:15:54 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 14:15:54 - INFO - __main__ - Printing 3 examples
05/17/2022 14:15:54 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
05/17/2022 14:15:54 - INFO - __main__ - ['others']
05/17/2022 14:15:54 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
05/17/2022 14:15:54 - INFO - __main__ - ['others']
05/17/2022 14:15:54 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
05/17/2022 14:15:54 - INFO - __main__ - ['others']
05/17/2022 14:15:54 - INFO - __main__ - Tokenizing Input ...
05/17/2022 14:15:54 - INFO - __main__ - Tokenizing Output ...
05/17/2022 14:15:54 - INFO - __main__ - Loaded 64 examples from train data
05/17/2022 14:15:54 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 14:15:54 - INFO - __main__ - Printing 3 examples
05/17/2022 14:15:54 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
05/17/2022 14:15:54 - INFO - __main__ - ['others']
05/17/2022 14:15:54 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
05/17/2022 14:15:54 - INFO - __main__ - ['others']
05/17/2022 14:15:54 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
05/17/2022 14:15:54 - INFO - __main__ - ['others']
05/17/2022 14:15:54 - INFO - __main__ - Tokenizing Input ...
05/17/2022 14:15:54 - INFO - __main__ - Tokenizing Output ...
05/17/2022 14:15:55 - INFO - __main__ - Loaded 64 examples from dev data
05/17/2022 14:15:56 - INFO - __main__ - Tokenizing Output ...
05/17/2022 14:16:00 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 14:16:00 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 14:16:00 - INFO - __main__ - Starting training!
05/17/2022 14:16:01 - INFO - __main__ - Loaded 5509 examples from test data
05/17/2022 14:16:46 - INFO - __main__ - Saved prediction in models/T5-base-reptile-cls2cls-3e-5-2-5000-5e-1-10/singletask-emo/emo_16_87_0.5_8_predictions.txt
05/17/2022 14:16:46 - INFO - __main__ - Classification-F1 on test data: 0.0487
05/17/2022 14:16:46 - INFO - __main__ - prefix=emo_16_87, lr=0.5, bsz=8, dev_performance=0.2269119769119769, test_performance=0.04873826093346512
05/17/2022 14:16:46 - INFO - __main__ - Running ... prefix=emo_16_87, lr=0.4, bsz=8 ...
05/17/2022 14:16:47 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 14:16:47 - INFO - __main__ - Printing 3 examples
05/17/2022 14:16:47 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
05/17/2022 14:16:47 - INFO - __main__ - ['others']
05/17/2022 14:16:47 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
05/17/2022 14:16:47 - INFO - __main__ - ['others']
05/17/2022 14:16:47 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
05/17/2022 14:16:47 - INFO - __main__ - ['others']
05/17/2022 14:16:47 - INFO - __main__ - Tokenizing Input ...
05/17/2022 14:16:47 - INFO - __main__ - Tokenizing Output ...
05/17/2022 14:16:47 - INFO - __main__ - Loaded 64 examples from train data
05/17/2022 14:16:47 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 14:16:47 - INFO - __main__ - Printing 3 examples
05/17/2022 14:16:47 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
05/17/2022 14:16:47 - INFO - __main__ - ['others']
05/17/2022 14:16:47 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
05/17/2022 14:16:47 - INFO - __main__ - ['others']
05/17/2022 14:16:47 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
05/17/2022 14:16:47 - INFO - __main__ - ['others']
05/17/2022 14:16:47 - INFO - __main__ - Tokenizing Input ...
05/17/2022 14:16:47 - INFO - __main__ - Tokenizing Output ...
05/17/2022 14:16:47 - INFO - __main__ - Loaded 64 examples from dev data
05/17/2022 14:16:53 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 14:16:53 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 14:16:53 - INFO - __main__ - Starting training!
05/17/2022 14:16:55 - INFO - __main__ - Step 10 Global step 10 Train loss 9.10 on epoch=2
05/17/2022 14:16:56 - INFO - __main__ - Step 20 Global step 20 Train loss 8.90 on epoch=4
05/17/2022 14:16:57 - INFO - __main__ - Step 30 Global step 30 Train loss 8.92 on epoch=7
05/17/2022 14:16:59 - INFO - __main__ - Step 40 Global step 40 Train loss 8.78 on epoch=9
05/17/2022 14:17:00 - INFO - __main__ - Step 50 Global step 50 Train loss 8.72 on epoch=12
05/17/2022 14:17:10 - INFO - __main__ - Global step 50 Train loss 8.88 Classification-F1 0.0 on epoch=12
05/17/2022 14:17:10 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/17/2022 14:17:11 - INFO - __main__ - Step 60 Global step 60 Train loss 8.70 on epoch=14
05/17/2022 14:17:12 - INFO - __main__ - Step 70 Global step 70 Train loss 8.62 on epoch=17
05/17/2022 14:17:14 - INFO - __main__ - Step 80 Global step 80 Train loss 8.46 on epoch=19
05/17/2022 14:17:15 - INFO - __main__ - Step 90 Global step 90 Train loss 8.42 on epoch=22
05/17/2022 14:17:17 - INFO - __main__ - Step 100 Global step 100 Train loss 8.34 on epoch=24
05/17/2022 14:17:32 - INFO - __main__ - Global step 100 Train loss 8.51 Classification-F1 0.0 on epoch=24
05/17/2022 14:17:33 - INFO - __main__ - Step 110 Global step 110 Train loss 8.27 on epoch=27
05/17/2022 14:17:34 - INFO - __main__ - Step 120 Global step 120 Train loss 8.25 on epoch=29
05/17/2022 14:17:36 - INFO - __main__ - Step 130 Global step 130 Train loss 8.07 on epoch=32
05/17/2022 14:17:37 - INFO - __main__ - Step 140 Global step 140 Train loss 7.97 on epoch=34
05/17/2022 14:17:38 - INFO - __main__ - Step 150 Global step 150 Train loss 7.97 on epoch=37
05/17/2022 14:17:55 - INFO - __main__ - Global step 150 Train loss 8.10 Classification-F1 0.0 on epoch=37
05/17/2022 14:17:56 - INFO - __main__ - Step 160 Global step 160 Train loss 7.68 on epoch=39
05/17/2022 14:17:57 - INFO - __main__ - Step 170 Global step 170 Train loss 7.57 on epoch=42
05/17/2022 14:17:59 - INFO - __main__ - Step 180 Global step 180 Train loss 7.50 on epoch=44
05/17/2022 14:18:00 - INFO - __main__ - Step 190 Global step 190 Train loss 7.35 on epoch=47
05/17/2022 14:18:02 - INFO - __main__ - Step 200 Global step 200 Train loss 7.09 on epoch=49
05/17/2022 14:18:10 - INFO - __main__ - Global step 200 Train loss 7.44 Classification-F1 0.0 on epoch=49
05/17/2022 14:18:11 - INFO - __main__ - Step 210 Global step 210 Train loss 6.81 on epoch=52
05/17/2022 14:18:13 - INFO - __main__ - Step 220 Global step 220 Train loss 6.83 on epoch=54
05/17/2022 14:18:14 - INFO - __main__ - Step 230 Global step 230 Train loss 6.69 on epoch=57
05/17/2022 14:18:15 - INFO - __main__ - Step 240 Global step 240 Train loss 6.39 on epoch=59
05/17/2022 14:18:17 - INFO - __main__ - Step 250 Global step 250 Train loss 6.51 on epoch=62
05/17/2022 14:18:19 - INFO - __main__ - Global step 250 Train loss 6.65 Classification-F1 0.0 on epoch=62
05/17/2022 14:18:20 - INFO - __main__ - Step 260 Global step 260 Train loss 6.22 on epoch=64
05/17/2022 14:18:21 - INFO - __main__ - Step 270 Global step 270 Train loss 6.10 on epoch=67
05/17/2022 14:18:22 - INFO - __main__ - Step 280 Global step 280 Train loss 6.01 on epoch=69
05/17/2022 14:18:24 - INFO - __main__ - Step 290 Global step 290 Train loss 5.79 on epoch=72
05/17/2022 14:18:25 - INFO - __main__ - Step 300 Global step 300 Train loss 5.54 on epoch=74
05/17/2022 14:18:32 - INFO - __main__ - Global step 300 Train loss 5.93 Classification-F1 0.0 on epoch=74
05/17/2022 14:18:33 - INFO - __main__ - Step 310 Global step 310 Train loss 5.57 on epoch=77
05/17/2022 14:18:34 - INFO - __main__ - Step 320 Global step 320 Train loss 5.37 on epoch=79
05/17/2022 14:18:36 - INFO - __main__ - Step 330 Global step 330 Train loss 5.25 on epoch=82
05/17/2022 14:18:37 - INFO - __main__ - Step 340 Global step 340 Train loss 5.20 on epoch=84
05/17/2022 14:18:38 - INFO - __main__ - Step 350 Global step 350 Train loss 5.15 on epoch=87
05/17/2022 14:18:42 - INFO - __main__ - Global step 350 Train loss 5.31 Classification-F1 0.0 on epoch=87
05/17/2022 14:18:43 - INFO - __main__ - Step 360 Global step 360 Train loss 4.89 on epoch=89
05/17/2022 14:18:44 - INFO - __main__ - Step 370 Global step 370 Train loss 4.86 on epoch=92
05/17/2022 14:18:46 - INFO - __main__ - Step 380 Global step 380 Train loss 4.66 on epoch=94
05/17/2022 14:18:47 - INFO - __main__ - Step 390 Global step 390 Train loss 4.64 on epoch=97
05/17/2022 14:18:48 - INFO - __main__ - Step 400 Global step 400 Train loss 4.38 on epoch=99
05/17/2022 14:18:53 - INFO - __main__ - Global step 400 Train loss 4.69 Classification-F1 0.0 on epoch=99
05/17/2022 14:18:55 - INFO - __main__ - Step 410 Global step 410 Train loss 4.30 on epoch=102
05/17/2022 14:18:56 - INFO - __main__ - Step 420 Global step 420 Train loss 4.24 on epoch=104
05/17/2022 14:18:57 - INFO - __main__ - Step 430 Global step 430 Train loss 4.39 on epoch=107
05/17/2022 14:18:59 - INFO - __main__ - Step 440 Global step 440 Train loss 4.08 on epoch=109
05/17/2022 14:19:00 - INFO - __main__ - Step 450 Global step 450 Train loss 4.06 on epoch=112
05/17/2022 14:19:05 - INFO - __main__ - Global step 450 Train loss 4.21 Classification-F1 0.0 on epoch=112
05/17/2022 14:19:07 - INFO - __main__ - Step 460 Global step 460 Train loss 3.78 on epoch=114
05/17/2022 14:19:08 - INFO - __main__ - Step 470 Global step 470 Train loss 3.88 on epoch=117
05/17/2022 14:19:09 - INFO - __main__ - Step 480 Global step 480 Train loss 3.76 on epoch=119
05/17/2022 14:19:11 - INFO - __main__ - Step 490 Global step 490 Train loss 3.74 on epoch=122
05/17/2022 14:19:12 - INFO - __main__ - Step 500 Global step 500 Train loss 3.62 on epoch=124
05/17/2022 14:19:13 - INFO - __main__ - Global step 500 Train loss 3.75 Classification-F1 0.05847953216374269 on epoch=124
05/17/2022 14:19:13 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.05847953216374269 on epoch=124, global_step=500
05/17/2022 14:19:15 - INFO - __main__ - Step 510 Global step 510 Train loss 3.69 on epoch=127
05/17/2022 14:19:16 - INFO - __main__ - Step 520 Global step 520 Train loss 3.67 on epoch=129
05/17/2022 14:19:18 - INFO - __main__ - Step 530 Global step 530 Train loss 3.61 on epoch=132
05/17/2022 14:19:19 - INFO - __main__ - Step 540 Global step 540 Train loss 3.25 on epoch=134
05/17/2022 14:19:21 - INFO - __main__ - Step 550 Global step 550 Train loss 3.41 on epoch=137
05/17/2022 14:19:25 - INFO - __main__ - Global step 550 Train loss 3.52 Classification-F1 0.21061869240895126 on epoch=137
05/17/2022 14:19:26 - INFO - __main__ - Saving model with best Classification-F1: 0.05847953216374269 -> 0.21061869240895126 on epoch=137, global_step=550
05/17/2022 14:19:27 - INFO - __main__ - Step 560 Global step 560 Train loss 3.26 on epoch=139
05/17/2022 14:19:28 - INFO - __main__ - Step 570 Global step 570 Train loss 3.31 on epoch=142
05/17/2022 14:19:30 - INFO - __main__ - Step 580 Global step 580 Train loss 3.07 on epoch=144
05/17/2022 14:19:31 - INFO - __main__ - Step 590 Global step 590 Train loss 3.20 on epoch=147
05/17/2022 14:19:33 - INFO - __main__ - Step 600 Global step 600 Train loss 2.91 on epoch=149
05/17/2022 14:19:35 - INFO - __main__ - Global step 600 Train loss 3.15 Classification-F1 0.10530934620447563 on epoch=149
05/17/2022 14:19:36 - INFO - __main__ - Step 610 Global step 610 Train loss 3.17 on epoch=152
05/17/2022 14:19:37 - INFO - __main__ - Step 620 Global step 620 Train loss 2.98 on epoch=154
05/17/2022 14:19:39 - INFO - __main__ - Step 630 Global step 630 Train loss 3.06 on epoch=157
05/17/2022 14:19:40 - INFO - __main__ - Step 640 Global step 640 Train loss 3.02 on epoch=159
05/17/2022 14:19:41 - INFO - __main__ - Step 650 Global step 650 Train loss 2.99 on epoch=162
05/17/2022 14:19:43 - INFO - __main__ - Global step 650 Train loss 3.05 Classification-F1 0.19999999999999998 on epoch=162
05/17/2022 14:19:45 - INFO - __main__ - Step 660 Global step 660 Train loss 2.63 on epoch=164
05/17/2022 14:19:46 - INFO - __main__ - Step 670 Global step 670 Train loss 2.87 on epoch=167
05/17/2022 14:19:48 - INFO - __main__ - Step 680 Global step 680 Train loss 2.61 on epoch=169
05/17/2022 14:19:49 - INFO - __main__ - Step 690 Global step 690 Train loss 2.72 on epoch=172
05/17/2022 14:19:51 - INFO - __main__ - Step 700 Global step 700 Train loss 2.62 on epoch=174
05/17/2022 14:19:52 - INFO - __main__ - Global step 700 Train loss 2.69 Classification-F1 0.14546244029526703 on epoch=174
05/17/2022 14:19:53 - INFO - __main__ - Step 710 Global step 710 Train loss 2.61 on epoch=177
05/17/2022 14:19:54 - INFO - __main__ - Step 720 Global step 720 Train loss 2.48 on epoch=179
05/17/2022 14:19:56 - INFO - __main__ - Step 730 Global step 730 Train loss 2.63 on epoch=182
05/17/2022 14:19:57 - INFO - __main__ - Step 740 Global step 740 Train loss 2.35 on epoch=184
05/17/2022 14:19:59 - INFO - __main__ - Step 750 Global step 750 Train loss 2.60 on epoch=187
05/17/2022 14:19:59 - INFO - __main__ - Global step 750 Train loss 2.53 Classification-F1 0.12403499742665978 on epoch=187
05/17/2022 14:20:01 - INFO - __main__ - Step 760 Global step 760 Train loss 2.35 on epoch=189
05/17/2022 14:20:02 - INFO - __main__ - Step 770 Global step 770 Train loss 2.35 on epoch=192
05/17/2022 14:20:03 - INFO - __main__ - Step 780 Global step 780 Train loss 2.38 on epoch=194
05/17/2022 14:20:05 - INFO - __main__ - Step 790 Global step 790 Train loss 2.29 on epoch=197
05/17/2022 14:20:06 - INFO - __main__ - Step 800 Global step 800 Train loss 2.15 on epoch=199
05/17/2022 14:20:07 - INFO - __main__ - Global step 800 Train loss 2.30 Classification-F1 0.20784313725490197 on epoch=199
05/17/2022 14:20:08 - INFO - __main__ - Step 810 Global step 810 Train loss 2.17 on epoch=202
05/17/2022 14:20:10 - INFO - __main__ - Step 820 Global step 820 Train loss 2.14 on epoch=204
05/17/2022 14:20:11 - INFO - __main__ - Step 830 Global step 830 Train loss 1.90 on epoch=207
05/17/2022 14:20:13 - INFO - __main__ - Step 840 Global step 840 Train loss 1.98 on epoch=209
05/17/2022 14:20:14 - INFO - __main__ - Step 850 Global step 850 Train loss 2.00 on epoch=212
05/17/2022 14:20:15 - INFO - __main__ - Global step 850 Train loss 2.04 Classification-F1 0.10256410256410256 on epoch=212
05/17/2022 14:20:16 - INFO - __main__ - Step 860 Global step 860 Train loss 1.93 on epoch=214
05/17/2022 14:20:17 - INFO - __main__ - Step 870 Global step 870 Train loss 2.03 on epoch=217
05/17/2022 14:20:19 - INFO - __main__ - Step 880 Global step 880 Train loss 1.99 on epoch=219
05/17/2022 14:20:20 - INFO - __main__ - Step 890 Global step 890 Train loss 1.93 on epoch=222
05/17/2022 14:20:21 - INFO - __main__ - Step 900 Global step 900 Train loss 1.89 on epoch=224
05/17/2022 14:20:22 - INFO - __main__ - Global step 900 Train loss 1.95 Classification-F1 0.1 on epoch=224
05/17/2022 14:20:23 - INFO - __main__ - Step 910 Global step 910 Train loss 1.87 on epoch=227
05/17/2022 14:20:25 - INFO - __main__ - Step 920 Global step 920 Train loss 1.68 on epoch=229
05/17/2022 14:20:26 - INFO - __main__ - Step 930 Global step 930 Train loss 1.84 on epoch=232
05/17/2022 14:20:28 - INFO - __main__ - Step 940 Global step 940 Train loss 1.69 on epoch=234
05/17/2022 14:20:29 - INFO - __main__ - Step 950 Global step 950 Train loss 1.91 on epoch=237
05/17/2022 14:20:30 - INFO - __main__ - Global step 950 Train loss 1.80 Classification-F1 0.10389610389610389 on epoch=237
05/17/2022 14:20:31 - INFO - __main__ - Step 960 Global step 960 Train loss 1.80 on epoch=239
05/17/2022 14:20:33 - INFO - __main__ - Step 970 Global step 970 Train loss 1.80 on epoch=242
05/17/2022 14:20:34 - INFO - __main__ - Step 980 Global step 980 Train loss 1.78 on epoch=244
05/17/2022 14:20:35 - INFO - __main__ - Step 990 Global step 990 Train loss 1.73 on epoch=247
05/17/2022 14:20:37 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.59 on epoch=249
05/17/2022 14:20:37 - INFO - __main__ - Global step 1000 Train loss 1.74 Classification-F1 0.1 on epoch=249
05/17/2022 14:20:39 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.62 on epoch=252
05/17/2022 14:20:40 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.45 on epoch=254
05/17/2022 14:20:42 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.52 on epoch=257
05/17/2022 14:20:43 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.57 on epoch=259
05/17/2022 14:20:44 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.70 on epoch=262
05/17/2022 14:20:45 - INFO - __main__ - Global step 1050 Train loss 1.57 Classification-F1 0.14848484848484847 on epoch=262
05/17/2022 14:20:46 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.60 on epoch=264
05/17/2022 14:20:48 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.52 on epoch=267
05/17/2022 14:20:49 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.60 on epoch=269
05/17/2022 14:20:51 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.46 on epoch=272
05/17/2022 14:20:52 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.50 on epoch=274
05/17/2022 14:20:52 - INFO - __main__ - Global step 1100 Train loss 1.53 Classification-F1 0.20445344129554657 on epoch=274
05/17/2022 14:20:54 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.36 on epoch=277
05/17/2022 14:20:55 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.44 on epoch=279
05/17/2022 14:20:57 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.39 on epoch=282
05/17/2022 14:20:58 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.31 on epoch=284
05/17/2022 14:20:59 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.39 on epoch=287
05/17/2022 14:21:00 - INFO - __main__ - Global step 1150 Train loss 1.38 Classification-F1 0.11687344913151365 on epoch=287
05/17/2022 14:21:01 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.32 on epoch=289
05/17/2022 14:21:03 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.39 on epoch=292
05/17/2022 14:21:04 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.35 on epoch=294
05/17/2022 14:21:06 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.37 on epoch=297
05/17/2022 14:21:07 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.33 on epoch=299
05/17/2022 14:21:08 - INFO - __main__ - Global step 1200 Train loss 1.35 Classification-F1 0.17344312918167784 on epoch=299
05/17/2022 14:21:09 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.41 on epoch=302
05/17/2022 14:21:11 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.19 on epoch=304
05/17/2022 14:21:12 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.33 on epoch=307
05/17/2022 14:21:13 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.37 on epoch=309
05/17/2022 14:21:15 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.44 on epoch=312
05/17/2022 14:21:16 - INFO - __main__ - Global step 1250 Train loss 1.35 Classification-F1 0.1302118933697881 on epoch=312
05/17/2022 14:21:17 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.30 on epoch=314
05/17/2022 14:21:18 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.26 on epoch=317
05/17/2022 14:21:20 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.23 on epoch=319
05/17/2022 14:21:21 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.20 on epoch=322
05/17/2022 14:21:23 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.28 on epoch=324
05/17/2022 14:21:23 - INFO - __main__ - Global step 1300 Train loss 1.25 Classification-F1 0.21256038647342995 on epoch=324
05/17/2022 14:21:23 - INFO - __main__ - Saving model with best Classification-F1: 0.21061869240895126 -> 0.21256038647342995 on epoch=324, global_step=1300
05/17/2022 14:21:25 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.35 on epoch=327
05/17/2022 14:21:26 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.20 on epoch=329
05/17/2022 14:21:27 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.06 on epoch=332
05/17/2022 14:21:29 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.17 on epoch=334
05/17/2022 14:21:30 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.27 on epoch=337
05/17/2022 14:21:31 - INFO - __main__ - Global step 1350 Train loss 1.21 Classification-F1 0.09999999999999999 on epoch=337
05/17/2022 14:21:32 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.06 on epoch=339
05/17/2022 14:21:33 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.29 on epoch=342
05/17/2022 14:21:35 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.07 on epoch=344
05/17/2022 14:21:36 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.14 on epoch=347
05/17/2022 14:21:38 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.20 on epoch=349
05/17/2022 14:21:38 - INFO - __main__ - Global step 1400 Train loss 1.15 Classification-F1 0.1302118933697881 on epoch=349
05/17/2022 14:21:40 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.27 on epoch=352
05/17/2022 14:21:41 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.04 on epoch=354
05/17/2022 14:21:42 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.12 on epoch=357
05/17/2022 14:21:44 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.22 on epoch=359
05/17/2022 14:21:45 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.21 on epoch=362
05/17/2022 14:21:46 - INFO - __main__ - Global step 1450 Train loss 1.17 Classification-F1 0.16110780226325194 on epoch=362
05/17/2022 14:21:47 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.18 on epoch=364
05/17/2022 14:21:48 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.18 on epoch=367
05/17/2022 14:21:50 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.22 on epoch=369
05/17/2022 14:21:51 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.17 on epoch=372
05/17/2022 14:21:53 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.15 on epoch=374
05/17/2022 14:21:53 - INFO - __main__ - Global step 1500 Train loss 1.18 Classification-F1 0.12393162393162392 on epoch=374
05/17/2022 14:21:54 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.15 on epoch=377
05/17/2022 14:21:56 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.17 on epoch=379
05/17/2022 14:21:57 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.05 on epoch=382
05/17/2022 14:21:59 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.15 on epoch=384
05/17/2022 14:22:00 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.12 on epoch=387
05/17/2022 14:22:01 - INFO - __main__ - Global step 1550 Train loss 1.13 Classification-F1 0.15728715728715728 on epoch=387
05/17/2022 14:22:02 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.09 on epoch=389
05/17/2022 14:22:04 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.12 on epoch=392
05/17/2022 14:22:05 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.13 on epoch=394
05/17/2022 14:22:06 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.11 on epoch=397
05/17/2022 14:22:08 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.12 on epoch=399
05/17/2022 14:22:08 - INFO - __main__ - Global step 1600 Train loss 1.11 Classification-F1 0.1542857142857143 on epoch=399
05/17/2022 14:22:10 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.16 on epoch=402
05/17/2022 14:22:11 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.15 on epoch=404
05/17/2022 14:22:13 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.03 on epoch=407
05/17/2022 14:22:14 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.02 on epoch=409
05/17/2022 14:22:15 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.10 on epoch=412
05/17/2022 14:22:16 - INFO - __main__ - Global step 1650 Train loss 1.09 Classification-F1 0.13067758749069247 on epoch=412
05/17/2022 14:22:18 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.17 on epoch=414
05/17/2022 14:22:19 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.06 on epoch=417
05/17/2022 14:22:20 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.11 on epoch=419
05/17/2022 14:22:22 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.08 on epoch=422
05/17/2022 14:22:23 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.22 on epoch=424
05/17/2022 14:22:24 - INFO - __main__ - Global step 1700 Train loss 1.13 Classification-F1 0.1457326892109501 on epoch=424
05/17/2022 14:22:25 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.15 on epoch=427
05/17/2022 14:22:27 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.09 on epoch=429
05/17/2022 14:22:28 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.13 on epoch=432
05/17/2022 14:22:30 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.08 on epoch=434
05/17/2022 14:22:31 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.04 on epoch=437
05/17/2022 14:22:32 - INFO - __main__ - Global step 1750 Train loss 1.10 Classification-F1 0.1581196581196581 on epoch=437
05/17/2022 14:22:33 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.01 on epoch=439
05/17/2022 14:22:34 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.16 on epoch=442
05/17/2022 14:22:36 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.08 on epoch=444
05/17/2022 14:22:37 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.16 on epoch=447
05/17/2022 14:22:39 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.06 on epoch=449
05/17/2022 14:22:39 - INFO - __main__ - Global step 1800 Train loss 1.09 Classification-F1 0.1581196581196581 on epoch=449
05/17/2022 14:22:41 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.05 on epoch=452
05/17/2022 14:22:42 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.22 on epoch=454
05/17/2022 14:22:43 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.10 on epoch=457
05/17/2022 14:22:45 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.04 on epoch=459
05/17/2022 14:22:46 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.05 on epoch=462
05/17/2022 14:22:47 - INFO - __main__ - Global step 1850 Train loss 1.09 Classification-F1 0.13034188034188032 on epoch=462
05/17/2022 14:22:48 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.15 on epoch=464
05/17/2022 14:22:50 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.99 on epoch=467
05/17/2022 14:22:51 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.97 on epoch=469
05/17/2022 14:22:52 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.04 on epoch=472
05/17/2022 14:22:54 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.11 on epoch=474
05/17/2022 14:22:54 - INFO - __main__ - Global step 1900 Train loss 1.05 Classification-F1 0.19068450849202268 on epoch=474
05/17/2022 14:22:56 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.03 on epoch=477
05/17/2022 14:22:57 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.12 on epoch=479
05/17/2022 14:22:58 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.09 on epoch=482
05/17/2022 14:23:00 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.08 on epoch=484
05/17/2022 14:23:01 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.06 on epoch=487
05/17/2022 14:23:02 - INFO - __main__ - Global step 1950 Train loss 1.08 Classification-F1 0.1739766081871345 on epoch=487
05/17/2022 14:23:03 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.09 on epoch=489
05/17/2022 14:23:05 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.16 on epoch=492
05/17/2022 14:23:06 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.04 on epoch=494
05/17/2022 14:23:07 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.04 on epoch=497
05/17/2022 14:23:09 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.03 on epoch=499
05/17/2022 14:23:09 - INFO - __main__ - Global step 2000 Train loss 1.07 Classification-F1 0.1281512605042017 on epoch=499
05/17/2022 14:23:11 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.01 on epoch=502
05/17/2022 14:23:12 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.98 on epoch=504
05/17/2022 14:23:13 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.04 on epoch=507
05/17/2022 14:23:15 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.05 on epoch=509
05/17/2022 14:23:16 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.02 on epoch=512
05/17/2022 14:23:17 - INFO - __main__ - Global step 2050 Train loss 1.02 Classification-F1 0.13166666666666668 on epoch=512
05/17/2022 14:23:18 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.02 on epoch=514
05/17/2022 14:23:20 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.11 on epoch=517
05/17/2022 14:23:21 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.99 on epoch=519
05/17/2022 14:23:23 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.11 on epoch=522
05/17/2022 14:23:24 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.10 on epoch=524
05/17/2022 14:23:25 - INFO - __main__ - Global step 2100 Train loss 1.06 Classification-F1 0.16078790655061842 on epoch=524
05/17/2022 14:23:26 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.11 on epoch=527
05/17/2022 14:23:27 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.03 on epoch=529
05/17/2022 14:23:29 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.07 on epoch=532
05/17/2022 14:23:30 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.06 on epoch=534
05/17/2022 14:23:31 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.01 on epoch=537
05/17/2022 14:23:32 - INFO - __main__ - Global step 2150 Train loss 1.06 Classification-F1 0.10314685314685315 on epoch=537
05/17/2022 14:23:33 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.94 on epoch=539
05/17/2022 14:23:35 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.01 on epoch=542
05/17/2022 14:23:36 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.86 on epoch=544
05/17/2022 14:23:37 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.09 on epoch=547
05/17/2022 14:23:39 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.98 on epoch=549
05/17/2022 14:23:40 - INFO - __main__ - Global step 2200 Train loss 0.97 Classification-F1 0.2531512605042017 on epoch=549
05/17/2022 14:23:40 - INFO - __main__ - Saving model with best Classification-F1: 0.21256038647342995 -> 0.2531512605042017 on epoch=549, global_step=2200
05/17/2022 14:23:41 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.96 on epoch=552
05/17/2022 14:23:42 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.94 on epoch=554
05/17/2022 14:23:44 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.88 on epoch=557
05/17/2022 14:23:45 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.06 on epoch=559
05/17/2022 14:23:46 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.04 on epoch=562
05/17/2022 14:23:47 - INFO - __main__ - Global step 2250 Train loss 0.98 Classification-F1 0.13946869070208728 on epoch=562
05/17/2022 14:23:48 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.06 on epoch=564
05/17/2022 14:23:50 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.04 on epoch=567
05/17/2022 14:23:51 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.99 on epoch=569
05/17/2022 14:23:53 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.03 on epoch=572
05/17/2022 14:23:54 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.96 on epoch=574
05/17/2022 14:23:55 - INFO - __main__ - Global step 2300 Train loss 1.01 Classification-F1 0.19226044226044225 on epoch=574
05/17/2022 14:23:56 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.95 on epoch=577
05/17/2022 14:23:57 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.02 on epoch=579
05/17/2022 14:23:59 - INFO - __main__ - Step 2330 Global step 2330 Train loss 1.03 on epoch=582
05/17/2022 14:24:00 - INFO - __main__ - Step 2340 Global step 2340 Train loss 1.03 on epoch=584
05/17/2022 14:24:02 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.07 on epoch=587
05/17/2022 14:24:02 - INFO - __main__ - Global step 2350 Train loss 1.02 Classification-F1 0.1875 on epoch=587
05/17/2022 14:24:03 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.95 on epoch=589
05/17/2022 14:24:05 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.96 on epoch=592
05/17/2022 14:24:06 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.94 on epoch=594
05/17/2022 14:24:08 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.99 on epoch=597
05/17/2022 14:24:09 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.89 on epoch=599
05/17/2022 14:24:10 - INFO - __main__ - Global step 2400 Train loss 0.94 Classification-F1 0.140625 on epoch=599
05/17/2022 14:24:11 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.94 on epoch=602
05/17/2022 14:24:12 - INFO - __main__ - Step 2420 Global step 2420 Train loss 1.02 on epoch=604
05/17/2022 14:24:14 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.00 on epoch=607
05/17/2022 14:24:15 - INFO - __main__ - Step 2440 Global step 2440 Train loss 1.01 on epoch=609
05/17/2022 14:24:17 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.08 on epoch=612
05/17/2022 14:24:17 - INFO - __main__ - Global step 2450 Train loss 1.01 Classification-F1 0.18679950186799504 on epoch=612
05/17/2022 14:24:19 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.96 on epoch=614
05/17/2022 14:24:20 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.89 on epoch=617
05/17/2022 14:24:21 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.05 on epoch=619
05/17/2022 14:24:23 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.07 on epoch=622
05/17/2022 14:24:24 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.89 on epoch=624
05/17/2022 14:24:25 - INFO - __main__ - Global step 2500 Train loss 0.97 Classification-F1 0.1588235294117647 on epoch=624
05/17/2022 14:24:26 - INFO - __main__ - Step 2510 Global step 2510 Train loss 1.04 on epoch=627
05/17/2022 14:24:27 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.94 on epoch=629
05/17/2022 14:24:29 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.93 on epoch=632
05/17/2022 14:24:30 - INFO - __main__ - Step 2540 Global step 2540 Train loss 1.01 on epoch=634
05/17/2022 14:24:32 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.92 on epoch=637
05/17/2022 14:24:32 - INFO - __main__ - Global step 2550 Train loss 0.97 Classification-F1 0.1797385620915033 on epoch=637
05/17/2022 14:24:34 - INFO - __main__ - Step 2560 Global step 2560 Train loss 1.00 on epoch=639
05/17/2022 14:24:35 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.98 on epoch=642
05/17/2022 14:24:37 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.98 on epoch=644
05/17/2022 14:24:38 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.98 on epoch=647
05/17/2022 14:24:39 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.93 on epoch=649
05/17/2022 14:24:40 - INFO - __main__ - Global step 2600 Train loss 0.98 Classification-F1 0.20132844709115894 on epoch=649
05/17/2022 14:24:41 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.97 on epoch=652
05/17/2022 14:24:43 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.94 on epoch=654
05/17/2022 14:24:44 - INFO - __main__ - Step 2630 Global step 2630 Train loss 1.09 on epoch=657
05/17/2022 14:24:46 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.93 on epoch=659
05/17/2022 14:24:47 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.02 on epoch=662
05/17/2022 14:24:47 - INFO - __main__ - Global step 2650 Train loss 0.99 Classification-F1 0.09090909090909091 on epoch=662
05/17/2022 14:24:49 - INFO - __main__ - Step 2660 Global step 2660 Train loss 1.04 on epoch=664
05/17/2022 14:24:50 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.84 on epoch=667
05/17/2022 14:24:52 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.96 on epoch=669
05/17/2022 14:24:53 - INFO - __main__ - Step 2690 Global step 2690 Train loss 1.01 on epoch=672
05/17/2022 14:24:54 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.98 on epoch=674
05/17/2022 14:24:55 - INFO - __main__ - Global step 2700 Train loss 0.97 Classification-F1 0.13021778584392013 on epoch=674
05/17/2022 14:24:56 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.98 on epoch=677
05/17/2022 14:24:58 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.95 on epoch=679
05/17/2022 14:24:59 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.96 on epoch=682
05/17/2022 14:25:01 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.90 on epoch=684
05/17/2022 14:25:02 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.90 on epoch=687
05/17/2022 14:25:02 - INFO - __main__ - Global step 2750 Train loss 0.94 Classification-F1 0.2127949183303085 on epoch=687
05/17/2022 14:25:04 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.86 on epoch=689
05/17/2022 14:25:05 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.92 on epoch=692
05/17/2022 14:25:07 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.90 on epoch=694
05/17/2022 14:25:08 - INFO - __main__ - Step 2790 Global step 2790 Train loss 1.00 on epoch=697
05/17/2022 14:25:09 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.91 on epoch=699
05/17/2022 14:25:10 - INFO - __main__ - Global step 2800 Train loss 0.92 Classification-F1 0.09722222222222222 on epoch=699
05/17/2022 14:25:11 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.98 on epoch=702
05/17/2022 14:25:13 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.86 on epoch=704
05/17/2022 14:25:14 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.91 on epoch=707
05/17/2022 14:25:16 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.86 on epoch=709
05/17/2022 14:25:17 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.94 on epoch=712
05/17/2022 14:25:18 - INFO - __main__ - Global step 2850 Train loss 0.91 Classification-F1 0.10679361811631496 on epoch=712
05/17/2022 14:25:19 - INFO - __main__ - Step 2860 Global step 2860 Train loss 1.03 on epoch=714
05/17/2022 14:25:20 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.99 on epoch=717
05/17/2022 14:25:22 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.87 on epoch=719
05/17/2022 14:25:23 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.95 on epoch=722
05/17/2022 14:25:25 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.03 on epoch=724
05/17/2022 14:25:25 - INFO - __main__ - Global step 2900 Train loss 0.97 Classification-F1 0.0974025974025974 on epoch=724
05/17/2022 14:25:27 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.95 on epoch=727
05/17/2022 14:25:28 - INFO - __main__ - Step 2920 Global step 2920 Train loss 1.00 on epoch=729
05/17/2022 14:25:29 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.89 on epoch=732
05/17/2022 14:25:31 - INFO - __main__ - Step 2940 Global step 2940 Train loss 1.02 on epoch=734
05/17/2022 14:25:32 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.91 on epoch=737
05/17/2022 14:25:33 - INFO - __main__ - Global step 2950 Train loss 0.95 Classification-F1 0.18969624776652771 on epoch=737
05/17/2022 14:25:34 - INFO - __main__ - Step 2960 Global step 2960 Train loss 1.00 on epoch=739
05/17/2022 14:25:36 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.95 on epoch=742
05/17/2022 14:25:37 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.99 on epoch=744
05/17/2022 14:25:38 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.93 on epoch=747
05/17/2022 14:25:40 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.98 on epoch=749
05/17/2022 14:25:41 - INFO - __main__ - Global step 3000 Train loss 0.97 Classification-F1 0.10126582278481013 on epoch=749
05/17/2022 14:25:41 - INFO - __main__ - save last model!
05/17/2022 14:25:41 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/17/2022 14:25:41 - INFO - __main__ - Start tokenizing ... 5509 instances
05/17/2022 14:25:41 - INFO - __main__ - Printing 3 examples
05/17/2022 14:25:41 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/17/2022 14:25:41 - INFO - __main__ - ['others']
05/17/2022 14:25:41 - INFO - __main__ -  [emo] what you like very little things ok
05/17/2022 14:25:41 - INFO - __main__ - ['others']
05/17/2022 14:25:41 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/17/2022 14:25:41 - INFO - __main__ - ['others']
05/17/2022 14:25:41 - INFO - __main__ - Tokenizing Input ...
05/17/2022 14:25:41 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 14:25:41 - INFO - __main__ - Printing 3 examples
05/17/2022 14:25:41 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
05/17/2022 14:25:41 - INFO - __main__ - ['others']
05/17/2022 14:25:41 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
05/17/2022 14:25:41 - INFO - __main__ - ['others']
05/17/2022 14:25:41 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
05/17/2022 14:25:41 - INFO - __main__ - ['others']
05/17/2022 14:25:41 - INFO - __main__ - Tokenizing Input ...
05/17/2022 14:25:41 - INFO - __main__ - Tokenizing Output ...
05/17/2022 14:25:41 - INFO - __main__ - Loaded 64 examples from train data
05/17/2022 14:25:41 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 14:25:41 - INFO - __main__ - Printing 3 examples
05/17/2022 14:25:41 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
05/17/2022 14:25:41 - INFO - __main__ - ['others']
05/17/2022 14:25:41 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
05/17/2022 14:25:41 - INFO - __main__ - ['others']
05/17/2022 14:25:41 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
05/17/2022 14:25:41 - INFO - __main__ - ['others']
05/17/2022 14:25:41 - INFO - __main__ - Tokenizing Input ...
05/17/2022 14:25:41 - INFO - __main__ - Tokenizing Output ...
05/17/2022 14:25:41 - INFO - __main__ - Loaded 64 examples from dev data
05/17/2022 14:25:44 - INFO - __main__ - Tokenizing Output ...
05/17/2022 14:25:47 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 14:25:47 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 14:25:47 - INFO - __main__ - Starting training!
05/17/2022 14:25:50 - INFO - __main__ - Loaded 5509 examples from test data
05/17/2022 14:26:39 - INFO - __main__ - Saved prediction in models/T5-base-reptile-cls2cls-3e-5-2-5000-5e-1-10/singletask-emo/emo_16_87_0.4_8_predictions.txt
05/17/2022 14:26:39 - INFO - __main__ - Classification-F1 on test data: 0.0378
05/17/2022 14:26:39 - INFO - __main__ - prefix=emo_16_87, lr=0.4, bsz=8, dev_performance=0.2531512605042017, test_performance=0.0377939158695639
05/17/2022 14:26:39 - INFO - __main__ - Running ... prefix=emo_16_87, lr=0.3, bsz=8 ...
05/17/2022 14:26:40 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 14:26:40 - INFO - __main__ - Printing 3 examples
05/17/2022 14:26:40 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
05/17/2022 14:26:40 - INFO - __main__ - ['others']
05/17/2022 14:26:40 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
05/17/2022 14:26:40 - INFO - __main__ - ['others']
05/17/2022 14:26:40 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
05/17/2022 14:26:40 - INFO - __main__ - ['others']
05/17/2022 14:26:40 - INFO - __main__ - Tokenizing Input ...
05/17/2022 14:26:40 - INFO - __main__ - Tokenizing Output ...
05/17/2022 14:26:40 - INFO - __main__ - Loaded 64 examples from train data
05/17/2022 14:26:40 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 14:26:40 - INFO - __main__ - Printing 3 examples
05/17/2022 14:26:40 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
05/17/2022 14:26:40 - INFO - __main__ - ['others']
05/17/2022 14:26:40 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
05/17/2022 14:26:40 - INFO - __main__ - ['others']
05/17/2022 14:26:40 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
05/17/2022 14:26:40 - INFO - __main__ - ['others']
05/17/2022 14:26:40 - INFO - __main__ - Tokenizing Input ...
05/17/2022 14:26:40 - INFO - __main__ - Tokenizing Output ...
05/17/2022 14:26:40 - INFO - __main__ - Loaded 64 examples from dev data
05/17/2022 14:26:47 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 14:26:47 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 14:26:47 - INFO - __main__ - Starting training!
05/17/2022 14:26:50 - INFO - __main__ - Step 10 Global step 10 Train loss 8.85 on epoch=2
05/17/2022 14:26:52 - INFO - __main__ - Step 20 Global step 20 Train loss 8.88 on epoch=4
05/17/2022 14:26:53 - INFO - __main__ - Step 30 Global step 30 Train loss 8.94 on epoch=7
05/17/2022 14:26:54 - INFO - __main__ - Step 40 Global step 40 Train loss 8.88 on epoch=9
05/17/2022 14:26:56 - INFO - __main__ - Step 50 Global step 50 Train loss 8.76 on epoch=12
05/17/2022 14:27:01 - INFO - __main__ - Global step 50 Train loss 8.86 Classification-F1 0.0 on epoch=12
05/17/2022 14:27:01 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/17/2022 14:27:03 - INFO - __main__ - Step 60 Global step 60 Train loss 8.82 on epoch=14
05/17/2022 14:27:04 - INFO - __main__ - Step 70 Global step 70 Train loss 8.75 on epoch=17
05/17/2022 14:27:05 - INFO - __main__ - Step 80 Global step 80 Train loss 8.74 on epoch=19
05/17/2022 14:27:07 - INFO - __main__ - Step 90 Global step 90 Train loss 8.70 on epoch=22
05/17/2022 14:27:08 - INFO - __main__ - Step 100 Global step 100 Train loss 8.72 on epoch=24
05/17/2022 14:27:20 - INFO - __main__ - Global step 100 Train loss 8.74 Classification-F1 0.0 on epoch=24
05/17/2022 14:27:21 - INFO - __main__ - Step 110 Global step 110 Train loss 8.62 on epoch=27
05/17/2022 14:27:23 - INFO - __main__ - Step 120 Global step 120 Train loss 8.53 on epoch=29
05/17/2022 14:27:24 - INFO - __main__ - Step 130 Global step 130 Train loss 8.50 on epoch=32
05/17/2022 14:27:25 - INFO - __main__ - Step 140 Global step 140 Train loss 8.54 on epoch=34
05/17/2022 14:27:27 - INFO - __main__ - Step 150 Global step 150 Train loss 8.45 on epoch=37
05/17/2022 14:27:39 - INFO - __main__ - Global step 150 Train loss 8.53 Classification-F1 0.0 on epoch=37
05/17/2022 14:27:40 - INFO - __main__ - Step 160 Global step 160 Train loss 8.45 on epoch=39
05/17/2022 14:27:41 - INFO - __main__ - Step 170 Global step 170 Train loss 8.34 on epoch=42
05/17/2022 14:27:43 - INFO - __main__ - Step 180 Global step 180 Train loss 8.14 on epoch=44
05/17/2022 14:27:44 - INFO - __main__ - Step 190 Global step 190 Train loss 8.21 on epoch=47
05/17/2022 14:27:46 - INFO - __main__ - Step 200 Global step 200 Train loss 8.13 on epoch=49
05/17/2022 14:27:55 - INFO - __main__ - Global step 200 Train loss 8.25 Classification-F1 0.0 on epoch=49
05/17/2022 14:27:56 - INFO - __main__ - Step 210 Global step 210 Train loss 7.87 on epoch=52
05/17/2022 14:27:58 - INFO - __main__ - Step 220 Global step 220 Train loss 7.62 on epoch=54
05/17/2022 14:27:59 - INFO - __main__ - Step 230 Global step 230 Train loss 7.56 on epoch=57
05/17/2022 14:28:00 - INFO - __main__ - Step 240 Global step 240 Train loss 7.49 on epoch=59
05/17/2022 14:28:02 - INFO - __main__ - Step 250 Global step 250 Train loss 7.18 on epoch=62
05/17/2022 14:28:20 - INFO - __main__ - Global step 250 Train loss 7.54 Classification-F1 0.0 on epoch=62
05/17/2022 14:28:21 - INFO - __main__ - Step 260 Global step 260 Train loss 7.03 on epoch=64
05/17/2022 14:28:23 - INFO - __main__ - Step 270 Global step 270 Train loss 6.72 on epoch=67
05/17/2022 14:28:24 - INFO - __main__ - Step 280 Global step 280 Train loss 6.64 on epoch=69
05/17/2022 14:28:26 - INFO - __main__ - Step 290 Global step 290 Train loss 6.56 on epoch=72
05/17/2022 14:28:28 - INFO - __main__ - Step 300 Global step 300 Train loss 6.54 on epoch=74
05/17/2022 14:28:34 - INFO - __main__ - Global step 300 Train loss 6.70 Classification-F1 0.0 on epoch=74
05/17/2022 14:28:35 - INFO - __main__ - Step 310 Global step 310 Train loss 6.25 on epoch=77
05/17/2022 14:28:37 - INFO - __main__ - Step 320 Global step 320 Train loss 6.20 on epoch=79
05/17/2022 14:28:38 - INFO - __main__ - Step 330 Global step 330 Train loss 5.94 on epoch=82
05/17/2022 14:28:40 - INFO - __main__ - Step 340 Global step 340 Train loss 5.92 on epoch=84
05/17/2022 14:28:41 - INFO - __main__ - Step 350 Global step 350 Train loss 5.82 on epoch=87
05/17/2022 14:28:46 - INFO - __main__ - Global step 350 Train loss 6.02 Classification-F1 0.0 on epoch=87
05/17/2022 14:28:47 - INFO - __main__ - Step 360 Global step 360 Train loss 5.73 on epoch=89
05/17/2022 14:28:49 - INFO - __main__ - Step 370 Global step 370 Train loss 5.58 on epoch=92
05/17/2022 14:28:50 - INFO - __main__ - Step 380 Global step 380 Train loss 5.25 on epoch=94
05/17/2022 14:28:52 - INFO - __main__ - Step 390 Global step 390 Train loss 5.26 on epoch=97
05/17/2022 14:28:53 - INFO - __main__ - Step 400 Global step 400 Train loss 5.17 on epoch=99
05/17/2022 14:28:58 - INFO - __main__ - Global step 400 Train loss 5.40 Classification-F1 0.0 on epoch=99
05/17/2022 14:28:59 - INFO - __main__ - Step 410 Global step 410 Train loss 5.26 on epoch=102
05/17/2022 14:29:01 - INFO - __main__ - Step 420 Global step 420 Train loss 4.96 on epoch=104
05/17/2022 14:29:02 - INFO - __main__ - Step 430 Global step 430 Train loss 4.99 on epoch=107
05/17/2022 14:29:03 - INFO - __main__ - Step 440 Global step 440 Train loss 4.61 on epoch=109
05/17/2022 14:29:05 - INFO - __main__ - Step 450 Global step 450 Train loss 4.67 on epoch=112
05/17/2022 14:29:08 - INFO - __main__ - Global step 450 Train loss 4.90 Classification-F1 0.0 on epoch=112
05/17/2022 14:29:10 - INFO - __main__ - Step 460 Global step 460 Train loss 4.53 on epoch=114
05/17/2022 14:29:11 - INFO - __main__ - Step 470 Global step 470 Train loss 4.45 on epoch=117
05/17/2022 14:29:13 - INFO - __main__ - Step 480 Global step 480 Train loss 4.32 on epoch=119
05/17/2022 14:29:14 - INFO - __main__ - Step 490 Global step 490 Train loss 4.27 on epoch=122
05/17/2022 14:29:16 - INFO - __main__ - Step 500 Global step 500 Train loss 4.07 on epoch=124
05/17/2022 14:29:16 - INFO - __main__ - Global step 500 Train loss 4.33 Classification-F1 0.08596491228070176 on epoch=124
05/17/2022 14:29:17 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.08596491228070176 on epoch=124, global_step=500
05/17/2022 14:29:18 - INFO - __main__ - Step 510 Global step 510 Train loss 3.94 on epoch=127
05/17/2022 14:29:19 - INFO - __main__ - Step 520 Global step 520 Train loss 3.73 on epoch=129
05/17/2022 14:29:21 - INFO - __main__ - Step 530 Global step 530 Train loss 3.90 on epoch=132
05/17/2022 14:29:22 - INFO - __main__ - Step 540 Global step 540 Train loss 3.69 on epoch=134
05/17/2022 14:29:24 - INFO - __main__ - Step 550 Global step 550 Train loss 3.61 on epoch=137
05/17/2022 14:29:24 - INFO - __main__ - Global step 550 Train loss 3.77 Classification-F1 0.07567567567567568 on epoch=137
05/17/2022 14:29:26 - INFO - __main__ - Step 560 Global step 560 Train loss 3.40 on epoch=139
05/17/2022 14:29:27 - INFO - __main__ - Step 570 Global step 570 Train loss 3.55 on epoch=142
05/17/2022 14:29:28 - INFO - __main__ - Step 580 Global step 580 Train loss 3.17 on epoch=144
05/17/2022 14:29:30 - INFO - __main__ - Step 590 Global step 590 Train loss 3.11 on epoch=147
05/17/2022 14:29:31 - INFO - __main__ - Step 600 Global step 600 Train loss 3.19 on epoch=149
05/17/2022 14:29:32 - INFO - __main__ - Global step 600 Train loss 3.28 Classification-F1 0.1343478260869565 on epoch=149
05/17/2022 14:29:32 - INFO - __main__ - Saving model with best Classification-F1: 0.08596491228070176 -> 0.1343478260869565 on epoch=149, global_step=600
05/17/2022 14:29:33 - INFO - __main__ - Step 610 Global step 610 Train loss 3.34 on epoch=152
05/17/2022 14:29:35 - INFO - __main__ - Step 620 Global step 620 Train loss 3.26 on epoch=154
05/17/2022 14:29:36 - INFO - __main__ - Step 630 Global step 630 Train loss 3.12 on epoch=157
05/17/2022 14:29:37 - INFO - __main__ - Step 640 Global step 640 Train loss 2.96 on epoch=159
05/17/2022 14:29:39 - INFO - __main__ - Step 650 Global step 650 Train loss 3.11 on epoch=162
05/17/2022 14:29:39 - INFO - __main__ - Global step 650 Train loss 3.16 Classification-F1 0.17773705909299126 on epoch=162
05/17/2022 14:29:39 - INFO - __main__ - Saving model with best Classification-F1: 0.1343478260869565 -> 0.17773705909299126 on epoch=162, global_step=650
05/17/2022 14:29:41 - INFO - __main__ - Step 660 Global step 660 Train loss 2.89 on epoch=164
05/17/2022 14:29:42 - INFO - __main__ - Step 670 Global step 670 Train loss 3.07 on epoch=167
05/17/2022 14:29:44 - INFO - __main__ - Step 680 Global step 680 Train loss 2.78 on epoch=169
05/17/2022 14:29:45 - INFO - __main__ - Step 690 Global step 690 Train loss 2.96 on epoch=172
05/17/2022 14:29:46 - INFO - __main__ - Step 700 Global step 700 Train loss 2.59 on epoch=174
05/17/2022 14:29:47 - INFO - __main__ - Global step 700 Train loss 2.86 Classification-F1 0.17893217893217894 on epoch=174
05/17/2022 14:29:47 - INFO - __main__ - Saving model with best Classification-F1: 0.17773705909299126 -> 0.17893217893217894 on epoch=174, global_step=700
05/17/2022 14:29:48 - INFO - __main__ - Step 710 Global step 710 Train loss 2.78 on epoch=177
05/17/2022 14:29:50 - INFO - __main__ - Step 720 Global step 720 Train loss 2.59 on epoch=179
05/17/2022 14:29:51 - INFO - __main__ - Step 730 Global step 730 Train loss 2.62 on epoch=182
05/17/2022 14:29:53 - INFO - __main__ - Step 740 Global step 740 Train loss 2.54 on epoch=184
05/17/2022 14:29:54 - INFO - __main__ - Step 750 Global step 750 Train loss 2.65 on epoch=187
05/17/2022 14:29:55 - INFO - __main__ - Global step 750 Train loss 2.64 Classification-F1 0.13381369016984046 on epoch=187
05/17/2022 14:29:56 - INFO - __main__ - Step 760 Global step 760 Train loss 2.57 on epoch=189
05/17/2022 14:29:58 - INFO - __main__ - Step 770 Global step 770 Train loss 2.65 on epoch=192
05/17/2022 14:29:59 - INFO - __main__ - Step 780 Global step 780 Train loss 2.30 on epoch=194
05/17/2022 14:30:00 - INFO - __main__ - Step 790 Global step 790 Train loss 2.64 on epoch=197
05/17/2022 14:30:02 - INFO - __main__ - Step 800 Global step 800 Train loss 2.62 on epoch=199
05/17/2022 14:30:02 - INFO - __main__ - Global step 800 Train loss 2.56 Classification-F1 0.1 on epoch=199
05/17/2022 14:30:04 - INFO - __main__ - Step 810 Global step 810 Train loss 2.65 on epoch=202
05/17/2022 14:30:05 - INFO - __main__ - Step 820 Global step 820 Train loss 2.52 on epoch=204
05/17/2022 14:30:07 - INFO - __main__ - Step 830 Global step 830 Train loss 2.33 on epoch=207
05/17/2022 14:30:08 - INFO - __main__ - Step 840 Global step 840 Train loss 2.07 on epoch=209
05/17/2022 14:30:10 - INFO - __main__ - Step 850 Global step 850 Train loss 2.23 on epoch=212
05/17/2022 14:30:10 - INFO - __main__ - Global step 850 Train loss 2.36 Classification-F1 0.191016333938294 on epoch=212
05/17/2022 14:30:10 - INFO - __main__ - Saving model with best Classification-F1: 0.17893217893217894 -> 0.191016333938294 on epoch=212, global_step=850
05/17/2022 14:30:12 - INFO - __main__ - Step 860 Global step 860 Train loss 2.14 on epoch=214
05/17/2022 14:30:13 - INFO - __main__ - Step 870 Global step 870 Train loss 2.20 on epoch=217
05/17/2022 14:30:15 - INFO - __main__ - Step 880 Global step 880 Train loss 2.07 on epoch=219
05/17/2022 14:30:16 - INFO - __main__ - Step 890 Global step 890 Train loss 2.29 on epoch=222
05/17/2022 14:30:17 - INFO - __main__ - Step 900 Global step 900 Train loss 1.97 on epoch=224
05/17/2022 14:30:18 - INFO - __main__ - Global step 900 Train loss 2.14 Classification-F1 0.1709090909090909 on epoch=224
05/17/2022 14:30:20 - INFO - __main__ - Step 910 Global step 910 Train loss 2.08 on epoch=227
05/17/2022 14:30:21 - INFO - __main__ - Step 920 Global step 920 Train loss 1.96 on epoch=229
05/17/2022 14:30:22 - INFO - __main__ - Step 930 Global step 930 Train loss 1.94 on epoch=232
05/17/2022 14:30:24 - INFO - __main__ - Step 940 Global step 940 Train loss 1.97 on epoch=234
05/17/2022 14:30:25 - INFO - __main__ - Step 950 Global step 950 Train loss 2.00 on epoch=237
05/17/2022 14:30:26 - INFO - __main__ - Global step 950 Train loss 1.99 Classification-F1 0.2433255269320843 on epoch=237
05/17/2022 14:30:26 - INFO - __main__ - Saving model with best Classification-F1: 0.191016333938294 -> 0.2433255269320843 on epoch=237, global_step=950
05/17/2022 14:30:27 - INFO - __main__ - Step 960 Global step 960 Train loss 1.87 on epoch=239
05/17/2022 14:30:29 - INFO - __main__ - Step 970 Global step 970 Train loss 1.91 on epoch=242
05/17/2022 14:30:30 - INFO - __main__ - Step 980 Global step 980 Train loss 1.73 on epoch=244
05/17/2022 14:30:32 - INFO - __main__ - Step 990 Global step 990 Train loss 1.98 on epoch=247
05/17/2022 14:30:33 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.79 on epoch=249
05/17/2022 14:30:34 - INFO - __main__ - Global step 1000 Train loss 1.85 Classification-F1 0.19859154929577466 on epoch=249
05/17/2022 14:30:35 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.82 on epoch=252
05/17/2022 14:30:36 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.82 on epoch=254
05/17/2022 14:30:38 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.85 on epoch=257
05/17/2022 14:30:39 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.75 on epoch=259
05/17/2022 14:30:40 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.76 on epoch=262
05/17/2022 14:30:41 - INFO - __main__ - Global step 1050 Train loss 1.80 Classification-F1 0.09711751662971176 on epoch=262
05/17/2022 14:30:42 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.55 on epoch=264
05/17/2022 14:30:44 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.80 on epoch=267
05/17/2022 14:30:46 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.59 on epoch=269
05/17/2022 14:30:47 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.59 on epoch=272
05/17/2022 14:30:49 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.66 on epoch=274
05/17/2022 14:30:49 - INFO - __main__ - Global step 1100 Train loss 1.64 Classification-F1 0.17142857142857143 on epoch=274
05/17/2022 14:30:51 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.73 on epoch=277
05/17/2022 14:30:52 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.54 on epoch=279
05/17/2022 14:30:54 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.65 on epoch=282
05/17/2022 14:30:55 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.55 on epoch=284
05/17/2022 14:30:57 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.48 on epoch=287
05/17/2022 14:30:57 - INFO - __main__ - Global step 1150 Train loss 1.59 Classification-F1 0.1769230769230769 on epoch=287
05/17/2022 14:30:58 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.36 on epoch=289
05/17/2022 14:31:00 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.47 on epoch=292
05/17/2022 14:31:01 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.51 on epoch=294
05/17/2022 14:31:03 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.50 on epoch=297
05/17/2022 14:31:04 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.43 on epoch=299
05/17/2022 14:31:04 - INFO - __main__ - Global step 1200 Train loss 1.45 Classification-F1 0.1 on epoch=299
05/17/2022 14:31:06 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.46 on epoch=302
05/17/2022 14:31:07 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.32 on epoch=304
05/17/2022 14:31:09 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.58 on epoch=307
05/17/2022 14:31:10 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.35 on epoch=309
05/17/2022 14:31:11 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.51 on epoch=312
05/17/2022 14:31:12 - INFO - __main__ - Global step 1250 Train loss 1.44 Classification-F1 0.13067758749069247 on epoch=312
05/17/2022 14:31:13 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.34 on epoch=314
05/17/2022 14:31:15 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.47 on epoch=317
05/17/2022 14:31:16 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.33 on epoch=319
05/17/2022 14:31:18 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.21 on epoch=322
05/17/2022 14:31:19 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.23 on epoch=324
05/17/2022 14:31:19 - INFO - __main__ - Global step 1300 Train loss 1.32 Classification-F1 0.1 on epoch=324
05/17/2022 14:31:21 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.30 on epoch=327
05/17/2022 14:31:22 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.32 on epoch=329
05/17/2022 14:31:24 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.38 on epoch=332
05/17/2022 14:31:25 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.26 on epoch=334
05/17/2022 14:31:27 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.37 on epoch=337
05/17/2022 14:31:27 - INFO - __main__ - Global step 1350 Train loss 1.33 Classification-F1 0.1 on epoch=337
05/17/2022 14:31:29 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.32 on epoch=339
05/17/2022 14:31:30 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.34 on epoch=342
05/17/2022 14:31:31 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.24 on epoch=344
05/17/2022 14:31:33 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.32 on epoch=347
05/17/2022 14:31:34 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.17 on epoch=349
05/17/2022 14:31:35 - INFO - __main__ - Global step 1400 Train loss 1.28 Classification-F1 0.10256410256410256 on epoch=349
05/17/2022 14:31:36 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.31 on epoch=352
05/17/2022 14:31:37 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.24 on epoch=354
05/17/2022 14:31:39 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.37 on epoch=357
05/17/2022 14:31:40 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.27 on epoch=359
05/17/2022 14:31:42 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.31 on epoch=362
05/17/2022 14:31:42 - INFO - __main__ - Global step 1450 Train loss 1.30 Classification-F1 0.20190476190476192 on epoch=362
05/17/2022 14:31:44 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.13 on epoch=364
05/17/2022 14:31:45 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.24 on epoch=367
05/17/2022 14:31:46 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.24 on epoch=369
05/17/2022 14:31:48 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.28 on epoch=372
05/17/2022 14:31:49 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.29 on epoch=374
05/17/2022 14:31:50 - INFO - __main__ - Global step 1500 Train loss 1.24 Classification-F1 0.1 on epoch=374
05/17/2022 14:31:51 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.49 on epoch=377
05/17/2022 14:31:52 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.31 on epoch=379
05/17/2022 14:31:54 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.22 on epoch=382
05/17/2022 14:31:55 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.14 on epoch=384
05/17/2022 14:31:57 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.22 on epoch=387
05/17/2022 14:31:57 - INFO - __main__ - Global step 1550 Train loss 1.28 Classification-F1 0.1 on epoch=387
05/17/2022 14:31:59 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.25 on epoch=389
05/17/2022 14:32:00 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.15 on epoch=392
05/17/2022 14:32:01 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.23 on epoch=394
05/17/2022 14:32:03 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.22 on epoch=397
05/17/2022 14:32:04 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.16 on epoch=399
05/17/2022 14:32:05 - INFO - __main__ - Global step 1600 Train loss 1.20 Classification-F1 0.1 on epoch=399
05/17/2022 14:32:06 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.12 on epoch=402
05/17/2022 14:32:07 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.19 on epoch=404
05/17/2022 14:32:09 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.25 on epoch=407
05/17/2022 14:32:10 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.08 on epoch=409
05/17/2022 14:32:12 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.11 on epoch=412
05/17/2022 14:32:12 - INFO - __main__ - Global step 1650 Train loss 1.15 Classification-F1 0.1 on epoch=412
05/17/2022 14:32:14 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.26 on epoch=414
05/17/2022 14:32:15 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.21 on epoch=417
05/17/2022 14:32:16 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.08 on epoch=419
05/17/2022 14:32:18 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.26 on epoch=422
05/17/2022 14:32:19 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.13 on epoch=424
05/17/2022 14:32:20 - INFO - __main__ - Global step 1700 Train loss 1.19 Classification-F1 0.25101214574898784 on epoch=424
05/17/2022 14:32:20 - INFO - __main__ - Saving model with best Classification-F1: 0.2433255269320843 -> 0.25101214574898784 on epoch=424, global_step=1700
05/17/2022 14:32:21 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.12 on epoch=427
05/17/2022 14:32:22 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.23 on epoch=429
05/17/2022 14:32:24 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.18 on epoch=432
05/17/2022 14:32:25 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.17 on epoch=434
05/17/2022 14:32:26 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.18 on epoch=437
05/17/2022 14:32:27 - INFO - __main__ - Global step 1750 Train loss 1.18 Classification-F1 0.1 on epoch=437
05/17/2022 14:32:28 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.15 on epoch=439
05/17/2022 14:32:30 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.17 on epoch=442
05/17/2022 14:32:31 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.10 on epoch=444
05/17/2022 14:32:33 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.13 on epoch=447
05/17/2022 14:32:34 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.12 on epoch=449
05/17/2022 14:32:34 - INFO - __main__ - Global step 1800 Train loss 1.13 Classification-F1 0.11772486772486772 on epoch=449
05/17/2022 14:32:36 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.12 on epoch=452
05/17/2022 14:32:37 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.27 on epoch=454
05/17/2022 14:32:39 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.29 on epoch=457
05/17/2022 14:32:40 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.21 on epoch=459
05/17/2022 14:32:41 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.14 on epoch=462
05/17/2022 14:32:42 - INFO - __main__ - Global step 1850 Train loss 1.21 Classification-F1 0.15526315789473685 on epoch=462
05/17/2022 14:32:43 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.14 on epoch=464
05/17/2022 14:32:45 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.17 on epoch=467
05/17/2022 14:32:46 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.09 on epoch=469
05/17/2022 14:32:47 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.13 on epoch=472
05/17/2022 14:32:49 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.08 on epoch=474
05/17/2022 14:32:49 - INFO - __main__ - Global step 1900 Train loss 1.12 Classification-F1 0.19859154929577466 on epoch=474
05/17/2022 14:32:50 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.12 on epoch=477
05/17/2022 14:32:52 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.09 on epoch=479
05/17/2022 14:32:53 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.08 on epoch=482
05/17/2022 14:32:55 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.06 on epoch=484
05/17/2022 14:32:56 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.18 on epoch=487
05/17/2022 14:32:57 - INFO - __main__ - Global step 1950 Train loss 1.10 Classification-F1 0.12518037518037517 on epoch=487
05/17/2022 14:32:58 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.05 on epoch=489
05/17/2022 14:32:59 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.08 on epoch=492
05/17/2022 14:33:01 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.09 on epoch=494
05/17/2022 14:33:02 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.07 on epoch=497
05/17/2022 14:33:03 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.18 on epoch=499
05/17/2022 14:33:04 - INFO - __main__ - Global step 2000 Train loss 1.09 Classification-F1 0.17836812144212524 on epoch=499
05/17/2022 14:33:05 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.08 on epoch=502
05/17/2022 14:33:07 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.03 on epoch=504
05/17/2022 14:33:08 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.06 on epoch=507
05/17/2022 14:33:10 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.19 on epoch=509
05/17/2022 14:33:11 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.24 on epoch=512
05/17/2022 14:33:12 - INFO - __main__ - Global step 2050 Train loss 1.12 Classification-F1 0.15587044534412953 on epoch=512
05/17/2022 14:33:13 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.09 on epoch=514
05/17/2022 14:33:14 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.12 on epoch=517
05/17/2022 14:33:16 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.06 on epoch=519
05/17/2022 14:33:17 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.25 on epoch=522
05/17/2022 14:33:19 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.09 on epoch=524
05/17/2022 14:33:19 - INFO - __main__ - Global step 2100 Train loss 1.12 Classification-F1 0.15490196078431373 on epoch=524
05/17/2022 14:33:21 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.05 on epoch=527
05/17/2022 14:33:22 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.16 on epoch=529
05/17/2022 14:33:23 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.00 on epoch=532
05/17/2022 14:33:25 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.09 on epoch=534
05/17/2022 14:33:26 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.18 on epoch=537
05/17/2022 14:33:27 - INFO - __main__ - Global step 2150 Train loss 1.10 Classification-F1 0.17328042328042326 on epoch=537
05/17/2022 14:33:28 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.97 on epoch=539
05/17/2022 14:33:29 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.12 on epoch=542
05/17/2022 14:33:31 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.17 on epoch=544
05/17/2022 14:33:32 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.16 on epoch=547
05/17/2022 14:33:34 - INFO - __main__ - Step 2200 Global step 2200 Train loss 1.14 on epoch=549
05/17/2022 14:33:34 - INFO - __main__ - Global step 2200 Train loss 1.11 Classification-F1 0.15851775604734944 on epoch=549
05/17/2022 14:33:36 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.17 on epoch=552
05/17/2022 14:33:37 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.06 on epoch=554
05/17/2022 14:33:38 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.15 on epoch=557
05/17/2022 14:33:40 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.03 on epoch=559
05/17/2022 14:33:41 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.12 on epoch=562
05/17/2022 14:33:42 - INFO - __main__ - Global step 2250 Train loss 1.11 Classification-F1 0.1302118933697881 on epoch=562
05/17/2022 14:33:43 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.98 on epoch=564
05/17/2022 14:33:44 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.15 on epoch=567
05/17/2022 14:33:46 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.12 on epoch=569
05/17/2022 14:33:47 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.00 on epoch=572
05/17/2022 14:33:49 - INFO - __main__ - Step 2300 Global step 2300 Train loss 1.09 on epoch=574
05/17/2022 14:33:50 - INFO - __main__ - Global step 2300 Train loss 1.07 Classification-F1 0.1403588195841717 on epoch=574
05/17/2022 14:33:51 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.07 on epoch=577
05/17/2022 14:33:52 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.13 on epoch=579
05/17/2022 14:33:53 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.98 on epoch=582
05/17/2022 14:33:55 - INFO - __main__ - Step 2340 Global step 2340 Train loss 1.08 on epoch=584
05/17/2022 14:33:56 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.05 on epoch=587
05/17/2022 14:33:57 - INFO - __main__ - Global step 2350 Train loss 1.06 Classification-F1 0.12518037518037517 on epoch=587
05/17/2022 14:33:58 - INFO - __main__ - Step 2360 Global step 2360 Train loss 1.05 on epoch=589
05/17/2022 14:34:00 - INFO - __main__ - Step 2370 Global step 2370 Train loss 1.09 on epoch=592
05/17/2022 14:34:01 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.20 on epoch=594
05/17/2022 14:34:03 - INFO - __main__ - Step 2390 Global step 2390 Train loss 1.03 on epoch=597
05/17/2022 14:34:04 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.09 on epoch=599
05/17/2022 14:34:05 - INFO - __main__ - Global step 2400 Train loss 1.09 Classification-F1 0.08974358974358974 on epoch=599
05/17/2022 14:34:06 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.99 on epoch=602
05/17/2022 14:34:07 - INFO - __main__ - Step 2420 Global step 2420 Train loss 1.12 on epoch=604
05/17/2022 14:34:09 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.09 on epoch=607
05/17/2022 14:34:10 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.99 on epoch=609
05/17/2022 14:34:11 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.00 on epoch=612
05/17/2022 14:34:12 - INFO - __main__ - Global step 2450 Train loss 1.04 Classification-F1 0.15526315789473685 on epoch=612
05/17/2022 14:34:13 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.06 on epoch=614
05/17/2022 14:34:15 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.04 on epoch=617
05/17/2022 14:34:16 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.95 on epoch=619
05/17/2022 14:34:17 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.09 on epoch=622
05/17/2022 14:34:18 - INFO - __main__ - Step 2500 Global step 2500 Train loss 1.06 on epoch=624
05/17/2022 14:34:19 - INFO - __main__ - Global step 2500 Train loss 1.04 Classification-F1 0.14141414141414138 on epoch=624
05/17/2022 14:34:20 - INFO - __main__ - Step 2510 Global step 2510 Train loss 1.09 on epoch=627
05/17/2022 14:34:22 - INFO - __main__ - Step 2520 Global step 2520 Train loss 1.01 on epoch=629
05/17/2022 14:34:23 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.18 on epoch=632
05/17/2022 14:34:25 - INFO - __main__ - Step 2540 Global step 2540 Train loss 1.08 on epoch=634
05/17/2022 14:34:26 - INFO - __main__ - Step 2550 Global step 2550 Train loss 1.08 on epoch=637
05/17/2022 14:34:27 - INFO - __main__ - Global step 2550 Train loss 1.09 Classification-F1 0.10126582278481013 on epoch=637
05/17/2022 14:34:28 - INFO - __main__ - Step 2560 Global step 2560 Train loss 1.06 on epoch=639
05/17/2022 14:34:29 - INFO - __main__ - Step 2570 Global step 2570 Train loss 1.06 on epoch=642
05/17/2022 14:34:31 - INFO - __main__ - Step 2580 Global step 2580 Train loss 1.06 on epoch=644
05/17/2022 14:34:32 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.11 on epoch=647
05/17/2022 14:34:34 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.07 on epoch=649
05/17/2022 14:34:34 - INFO - __main__ - Global step 2600 Train loss 1.07 Classification-F1 0.19226044226044225 on epoch=649
05/17/2022 14:34:35 - INFO - __main__ - Step 2610 Global step 2610 Train loss 1.00 on epoch=652
05/17/2022 14:34:37 - INFO - __main__ - Step 2620 Global step 2620 Train loss 1.06 on epoch=654
05/17/2022 14:34:38 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.97 on epoch=657
05/17/2022 14:34:40 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.06 on epoch=659
05/17/2022 14:34:41 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.08 on epoch=662
05/17/2022 14:34:42 - INFO - __main__ - Global step 2650 Train loss 1.03 Classification-F1 0.1 on epoch=662
05/17/2022 14:34:43 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.98 on epoch=664
05/17/2022 14:34:44 - INFO - __main__ - Step 2670 Global step 2670 Train loss 1.07 on epoch=667
05/17/2022 14:34:46 - INFO - __main__ - Step 2680 Global step 2680 Train loss 1.03 on epoch=669
05/17/2022 14:34:47 - INFO - __main__ - Step 2690 Global step 2690 Train loss 1.05 on epoch=672
05/17/2022 14:34:49 - INFO - __main__ - Step 2700 Global step 2700 Train loss 1.06 on epoch=674
05/17/2022 14:34:49 - INFO - __main__ - Global step 2700 Train loss 1.04 Classification-F1 0.1 on epoch=674
05/17/2022 14:34:50 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.12 on epoch=677
05/17/2022 14:34:52 - INFO - __main__ - Step 2720 Global step 2720 Train loss 1.13 on epoch=679
05/17/2022 14:34:53 - INFO - __main__ - Step 2730 Global step 2730 Train loss 1.03 on epoch=682
05/17/2022 14:34:55 - INFO - __main__ - Step 2740 Global step 2740 Train loss 1.04 on epoch=684
05/17/2022 14:34:56 - INFO - __main__ - Step 2750 Global step 2750 Train loss 1.01 on epoch=687
05/17/2022 14:34:57 - INFO - __main__ - Global step 2750 Train loss 1.06 Classification-F1 0.09615384615384615 on epoch=687
05/17/2022 14:34:58 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.97 on epoch=689
05/17/2022 14:35:00 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.01 on epoch=692
05/17/2022 14:35:01 - INFO - __main__ - Step 2780 Global step 2780 Train loss 1.06 on epoch=694
05/17/2022 14:35:03 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.95 on epoch=697
05/17/2022 14:35:04 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.97 on epoch=699
05/17/2022 14:35:04 - INFO - __main__ - Global step 2800 Train loss 0.99 Classification-F1 0.1513157894736842 on epoch=699
05/17/2022 14:35:06 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.03 on epoch=702
05/17/2022 14:35:07 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.97 on epoch=704
05/17/2022 14:35:09 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.95 on epoch=707
05/17/2022 14:35:10 - INFO - __main__ - Step 2840 Global step 2840 Train loss 1.00 on epoch=709
05/17/2022 14:35:12 - INFO - __main__ - Step 2850 Global step 2850 Train loss 1.06 on epoch=712
05/17/2022 14:35:12 - INFO - __main__ - Global step 2850 Train loss 1.00 Classification-F1 0.1 on epoch=712
05/17/2022 14:35:14 - INFO - __main__ - Step 2860 Global step 2860 Train loss 1.11 on epoch=714
05/17/2022 14:35:15 - INFO - __main__ - Step 2870 Global step 2870 Train loss 1.08 on epoch=717
05/17/2022 14:35:16 - INFO - __main__ - Step 2880 Global step 2880 Train loss 1.08 on epoch=719
05/17/2022 14:35:18 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.91 on epoch=722
05/17/2022 14:35:19 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.94 on epoch=724
05/17/2022 14:35:20 - INFO - __main__ - Global step 2900 Train loss 1.02 Classification-F1 0.26129032258064516 on epoch=724
05/17/2022 14:35:20 - INFO - __main__ - Saving model with best Classification-F1: 0.25101214574898784 -> 0.26129032258064516 on epoch=724, global_step=2900
05/17/2022 14:35:21 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.09 on epoch=727
05/17/2022 14:35:22 - INFO - __main__ - Step 2920 Global step 2920 Train loss 1.06 on epoch=729
05/17/2022 14:35:24 - INFO - __main__ - Step 2930 Global step 2930 Train loss 1.04 on epoch=732
05/17/2022 14:35:25 - INFO - __main__ - Step 2940 Global step 2940 Train loss 1.03 on epoch=734
05/17/2022 14:35:27 - INFO - __main__ - Step 2950 Global step 2950 Train loss 1.01 on epoch=737
05/17/2022 14:35:27 - INFO - __main__ - Global step 2950 Train loss 1.05 Classification-F1 0.2361111111111111 on epoch=737
05/17/2022 14:35:29 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.96 on epoch=739
05/17/2022 14:35:30 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.16 on epoch=742
05/17/2022 14:35:31 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.06 on epoch=744
05/17/2022 14:35:33 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.99 on epoch=747
05/17/2022 14:35:34 - INFO - __main__ - Step 3000 Global step 3000 Train loss 1.04 on epoch=749
05/17/2022 14:35:35 - INFO - __main__ - Global step 3000 Train loss 1.04 Classification-F1 0.20190476190476192 on epoch=749
05/17/2022 14:35:35 - INFO - __main__ - save last model!
05/17/2022 14:35:35 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/17/2022 14:35:35 - INFO - __main__ - Start tokenizing ... 5509 instances
05/17/2022 14:35:35 - INFO - __main__ - Printing 3 examples
05/17/2022 14:35:35 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/17/2022 14:35:35 - INFO - __main__ - ['others']
05/17/2022 14:35:35 - INFO - __main__ -  [emo] what you like very little things ok
05/17/2022 14:35:35 - INFO - __main__ - ['others']
05/17/2022 14:35:35 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/17/2022 14:35:35 - INFO - __main__ - ['others']
05/17/2022 14:35:35 - INFO - __main__ - Tokenizing Input ...
05/17/2022 14:35:35 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 14:35:35 - INFO - __main__ - Printing 3 examples
05/17/2022 14:35:35 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
05/17/2022 14:35:35 - INFO - __main__ - ['others']
05/17/2022 14:35:35 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
05/17/2022 14:35:35 - INFO - __main__ - ['others']
05/17/2022 14:35:35 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
05/17/2022 14:35:35 - INFO - __main__ - ['others']
05/17/2022 14:35:35 - INFO - __main__ - Tokenizing Input ...
05/17/2022 14:35:35 - INFO - __main__ - Tokenizing Output ...
05/17/2022 14:35:35 - INFO - __main__ - Loaded 64 examples from train data
05/17/2022 14:35:35 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 14:35:35 - INFO - __main__ - Printing 3 examples
05/17/2022 14:35:35 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
05/17/2022 14:35:35 - INFO - __main__ - ['others']
05/17/2022 14:35:35 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
05/17/2022 14:35:35 - INFO - __main__ - ['others']
05/17/2022 14:35:35 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
05/17/2022 14:35:35 - INFO - __main__ - ['others']
05/17/2022 14:35:35 - INFO - __main__ - Tokenizing Input ...
05/17/2022 14:35:35 - INFO - __main__ - Tokenizing Output ...
05/17/2022 14:35:35 - INFO - __main__ - Loaded 64 examples from dev data
05/17/2022 14:35:37 - INFO - __main__ - Tokenizing Output ...
05/17/2022 14:35:42 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 14:35:42 - INFO - __main__ - Loaded 5509 examples from test data
05/17/2022 14:35:43 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 14:35:43 - INFO - __main__ - Starting training!
05/17/2022 14:36:27 - INFO - __main__ - Saved prediction in models/T5-base-reptile-cls2cls-3e-5-2-5000-5e-1-10/singletask-emo/emo_16_87_0.3_8_predictions.txt
05/17/2022 14:36:27 - INFO - __main__ - Classification-F1 on test data: 0.0325
05/17/2022 14:36:27 - INFO - __main__ - prefix=emo_16_87, lr=0.3, bsz=8, dev_performance=0.26129032258064516, test_performance=0.03254203466969424
05/17/2022 14:36:27 - INFO - __main__ - Running ... prefix=emo_16_87, lr=0.2, bsz=8 ...
05/17/2022 14:36:28 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 14:36:28 - INFO - __main__ - Printing 3 examples
05/17/2022 14:36:28 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
05/17/2022 14:36:28 - INFO - __main__ - ['others']
05/17/2022 14:36:28 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
05/17/2022 14:36:28 - INFO - __main__ - ['others']
05/17/2022 14:36:28 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
05/17/2022 14:36:28 - INFO - __main__ - ['others']
05/17/2022 14:36:28 - INFO - __main__ - Tokenizing Input ...
05/17/2022 14:36:28 - INFO - __main__ - Tokenizing Output ...
05/17/2022 14:36:28 - INFO - __main__ - Loaded 64 examples from train data
05/17/2022 14:36:28 - INFO - __main__ - Start tokenizing ... 64 instances
05/17/2022 14:36:28 - INFO - __main__ - Printing 3 examples
05/17/2022 14:36:28 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
05/17/2022 14:36:28 - INFO - __main__ - ['others']
05/17/2022 14:36:28 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
05/17/2022 14:36:28 - INFO - __main__ - ['others']
05/17/2022 14:36:28 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
05/17/2022 14:36:28 - INFO - __main__ - ['others']
05/17/2022 14:36:28 - INFO - __main__ - Tokenizing Input ...
05/17/2022 14:36:28 - INFO - __main__ - Tokenizing Output ...
05/17/2022 14:36:28 - INFO - __main__ - Loaded 64 examples from dev data
05/17/2022 14:36:35 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 14:36:35 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 14:36:35 - INFO - __main__ - Starting training!
05/17/2022 14:36:36 - INFO - __main__ - Step 10 Global step 10 Train loss 8.81 on epoch=2
05/17/2022 14:36:38 - INFO - __main__ - Step 20 Global step 20 Train loss 8.94 on epoch=4
05/17/2022 14:36:39 - INFO - __main__ - Step 30 Global step 30 Train loss 8.96 on epoch=7
05/17/2022 14:36:41 - INFO - __main__ - Step 40 Global step 40 Train loss 8.92 on epoch=9
05/17/2022 14:36:42 - INFO - __main__ - Step 50 Global step 50 Train loss 9.02 on epoch=12
05/17/2022 14:36:46 - INFO - __main__ - Global step 50 Train loss 8.93 Classification-F1 0.0 on epoch=12
05/17/2022 14:36:46 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/17/2022 14:36:47 - INFO - __main__ - Step 60 Global step 60 Train loss 8.93 on epoch=14
05/17/2022 14:36:48 - INFO - __main__ - Step 70 Global step 70 Train loss 8.86 on epoch=17
05/17/2022 14:36:50 - INFO - __main__ - Step 80 Global step 80 Train loss 8.75 on epoch=19
05/17/2022 14:36:51 - INFO - __main__ - Step 90 Global step 90 Train loss 8.76 on epoch=22
05/17/2022 14:36:52 - INFO - __main__ - Step 100 Global step 100 Train loss 8.76 on epoch=24
05/17/2022 14:36:56 - INFO - __main__ - Global step 100 Train loss 8.81 Classification-F1 0.0 on epoch=24
05/17/2022 14:36:58 - INFO - __main__ - Step 110 Global step 110 Train loss 8.77 on epoch=27
05/17/2022 14:36:59 - INFO - __main__ - Step 120 Global step 120 Train loss 8.68 on epoch=29
05/17/2022 14:37:00 - INFO - __main__ - Step 130 Global step 130 Train loss 8.54 on epoch=32
05/17/2022 14:37:02 - INFO - __main__ - Step 140 Global step 140 Train loss 8.82 on epoch=34
05/17/2022 14:37:03 - INFO - __main__ - Step 150 Global step 150 Train loss 8.63 on epoch=37
05/17/2022 14:37:16 - INFO - __main__ - Global step 150 Train loss 8.69 Classification-F1 0.0 on epoch=37
05/17/2022 14:37:17 - INFO - __main__ - Step 160 Global step 160 Train loss 8.52 on epoch=39
05/17/2022 14:37:19 - INFO - __main__ - Step 170 Global step 170 Train loss 8.61 on epoch=42
05/17/2022 14:37:20 - INFO - __main__ - Step 180 Global step 180 Train loss 8.44 on epoch=44
05/17/2022 14:37:21 - INFO - __main__ - Step 190 Global step 190 Train loss 8.40 on epoch=47
05/17/2022 14:37:23 - INFO - __main__ - Step 200 Global step 200 Train loss 8.30 on epoch=49
05/17/2022 14:37:39 - INFO - __main__ - Global step 200 Train loss 8.46 Classification-F1 0.0 on epoch=49
05/17/2022 14:37:41 - INFO - __main__ - Step 210 Global step 210 Train loss 8.36 on epoch=52
05/17/2022 14:37:42 - INFO - __main__ - Step 220 Global step 220 Train loss 8.22 on epoch=54
05/17/2022 14:37:43 - INFO - __main__ - Step 230 Global step 230 Train loss 8.30 on epoch=57
05/17/2022 14:37:45 - INFO - __main__ - Step 240 Global step 240 Train loss 8.07 on epoch=59
05/17/2022 14:37:46 - INFO - __main__ - Step 250 Global step 250 Train loss 8.06 on epoch=62
05/17/2022 14:38:02 - INFO - __main__ - Global step 250 Train loss 8.20 Classification-F1 0.0 on epoch=62
05/17/2022 14:38:03 - INFO - __main__ - Step 260 Global step 260 Train loss 8.03 on epoch=64
05/17/2022 14:38:05 - INFO - __main__ - Step 270 Global step 270 Train loss 7.93 on epoch=67
05/17/2022 14:38:06 - INFO - __main__ - Step 280 Global step 280 Train loss 7.69 on epoch=69
05/17/2022 14:38:07 - INFO - __main__ - Step 290 Global step 290 Train loss 7.58 on epoch=72
05/17/2022 14:38:09 - INFO - __main__ - Step 300 Global step 300 Train loss 7.53 on epoch=74
05/17/2022 14:38:18 - INFO - __main__ - Global step 300 Train loss 7.75 Classification-F1 0.0 on epoch=74
05/17/2022 14:38:20 - INFO - __main__ - Step 310 Global step 310 Train loss 7.46 on epoch=77
05/17/2022 14:38:21 - INFO - __main__ - Step 320 Global step 320 Train loss 7.28 on epoch=79
05/17/2022 14:38:22 - INFO - __main__ - Step 330 Global step 330 Train loss 7.11 on epoch=82
05/17/2022 14:38:24 - INFO - __main__ - Step 340 Global step 340 Train loss 7.03 on epoch=84
05/17/2022 14:38:25 - INFO - __main__ - Step 350 Global step 350 Train loss 7.00 on epoch=87
05/17/2022 14:38:36 - INFO - __main__ - Global step 350 Train loss 7.18 Classification-F1 0.0 on epoch=87
05/17/2022 14:38:38 - INFO - __main__ - Step 360 Global step 360 Train loss 6.65 on epoch=89
05/17/2022 14:38:39 - INFO - __main__ - Step 370 Global step 370 Train loss 6.70 on epoch=92
05/17/2022 14:38:40 - INFO - __main__ - Step 380 Global step 380 Train loss 6.67 on epoch=94
05/17/2022 14:38:42 - INFO - __main__ - Step 390 Global step 390 Train loss 6.60 on epoch=97
05/17/2022 14:38:43 - INFO - __main__ - Step 400 Global step 400 Train loss 6.51 on epoch=99
05/17/2022 14:38:50 - INFO - __main__ - Global step 400 Train loss 6.63 Classification-F1 0.0 on epoch=99
05/17/2022 14:38:52 - INFO - __main__ - Step 410 Global step 410 Train loss 6.35 on epoch=102
05/17/2022 14:38:53 - INFO - __main__ - Step 420 Global step 420 Train loss 6.03 on epoch=104
05/17/2022 14:38:55 - INFO - __main__ - Step 430 Global step 430 Train loss 6.23 on epoch=107
05/17/2022 14:38:56 - INFO - __main__ - Step 440 Global step 440 Train loss 6.22 on epoch=109
05/17/2022 14:38:57 - INFO - __main__ - Step 450 Global step 450 Train loss 6.09 on epoch=112
05/17/2022 14:39:10 - INFO - __main__ - Global step 450 Train loss 6.18 Classification-F1 0.0 on epoch=112
05/17/2022 14:39:11 - INFO - __main__ - Step 460 Global step 460 Train loss 5.73 on epoch=114
05/17/2022 14:39:13 - INFO - __main__ - Step 470 Global step 470 Train loss 5.98 on epoch=117
05/17/2022 14:39:14 - INFO - __main__ - Step 480 Global step 480 Train loss 5.87 on epoch=119
05/17/2022 14:39:15 - INFO - __main__ - Step 490 Global step 490 Train loss 5.85 on epoch=122
05/17/2022 14:39:17 - INFO - __main__ - Step 500 Global step 500 Train loss 5.77 on epoch=124
05/17/2022 14:39:28 - INFO - __main__ - Global step 500 Train loss 5.84 Classification-F1 0.0 on epoch=124
05/17/2022 14:39:29 - INFO - __main__ - Step 510 Global step 510 Train loss 5.99 on epoch=127
05/17/2022 14:39:30 - INFO - __main__ - Step 520 Global step 520 Train loss 5.60 on epoch=129
05/17/2022 14:39:32 - INFO - __main__ - Step 530 Global step 530 Train loss 5.78 on epoch=132
05/17/2022 14:39:33 - INFO - __main__ - Step 540 Global step 540 Train loss 5.63 on epoch=134
05/17/2022 14:39:35 - INFO - __main__ - Step 550 Global step 550 Train loss 5.50 on epoch=137
05/17/2022 14:39:44 - INFO - __main__ - Global step 550 Train loss 5.70 Classification-F1 0.0 on epoch=137
05/17/2022 14:39:46 - INFO - __main__ - Step 560 Global step 560 Train loss 5.45 on epoch=139
05/17/2022 14:39:47 - INFO - __main__ - Step 570 Global step 570 Train loss 5.50 on epoch=142
05/17/2022 14:39:48 - INFO - __main__ - Step 580 Global step 580 Train loss 5.34 on epoch=144
05/17/2022 14:39:50 - INFO - __main__ - Step 590 Global step 590 Train loss 5.52 on epoch=147
05/17/2022 14:39:51 - INFO - __main__ - Step 600 Global step 600 Train loss 5.51 on epoch=149
05/17/2022 14:40:00 - INFO - __main__ - Global step 600 Train loss 5.47 Classification-F1 0.0 on epoch=149
05/17/2022 14:40:02 - INFO - __main__ - Step 610 Global step 610 Train loss 5.31 on epoch=152
05/17/2022 14:40:03 - INFO - __main__ - Step 620 Global step 620 Train loss 5.22 on epoch=154
05/17/2022 14:40:04 - INFO - __main__ - Step 630 Global step 630 Train loss 5.23 on epoch=157
05/17/2022 14:40:06 - INFO - __main__ - Step 640 Global step 640 Train loss 5.23 on epoch=159
05/17/2022 14:40:07 - INFO - __main__ - Step 650 Global step 650 Train loss 5.09 on epoch=162
05/17/2022 14:40:22 - INFO - __main__ - Global step 650 Train loss 5.22 Classification-F1 0.0 on epoch=162
05/17/2022 14:40:23 - INFO - __main__ - Step 660 Global step 660 Train loss 4.99 on epoch=164
05/17/2022 14:40:25 - INFO - __main__ - Step 670 Global step 670 Train loss 4.84 on epoch=167
05/17/2022 14:40:26 - INFO - __main__ - Step 680 Global step 680 Train loss 4.68 on epoch=169
05/17/2022 14:40:27 - INFO - __main__ - Step 690 Global step 690 Train loss 4.75 on epoch=172
05/17/2022 14:40:29 - INFO - __main__ - Step 700 Global step 700 Train loss 4.45 on epoch=174
05/17/2022 14:40:37 - INFO - __main__ - Global step 700 Train loss 4.74 Classification-F1 0.0 on epoch=174
05/17/2022 14:40:39 - INFO - __main__ - Step 710 Global step 710 Train loss 4.67 on epoch=177
05/17/2022 14:40:40 - INFO - __main__ - Step 720 Global step 720 Train loss 4.36 on epoch=179
05/17/2022 14:40:41 - INFO - __main__ - Step 730 Global step 730 Train loss 4.45 on epoch=182
05/17/2022 14:40:43 - INFO - __main__ - Step 740 Global step 740 Train loss 4.23 on epoch=184
05/17/2022 14:40:44 - INFO - __main__ - Step 750 Global step 750 Train loss 4.04 on epoch=187
05/17/2022 14:40:48 - INFO - __main__ - Global step 750 Train loss 4.35 Classification-F1 0.0 on epoch=187
05/17/2022 14:40:49 - INFO - __main__ - Step 760 Global step 760 Train loss 4.30 on epoch=189
05/17/2022 14:40:50 - INFO - __main__ - Step 770 Global step 770 Train loss 4.32 on epoch=192
05/17/2022 14:40:52 - INFO - __main__ - Step 780 Global step 780 Train loss 4.06 on epoch=194
05/17/2022 14:40:53 - INFO - __main__ - Step 790 Global step 790 Train loss 4.27 on epoch=197
05/17/2022 14:40:54 - INFO - __main__ - Step 800 Global step 800 Train loss 3.95 on epoch=199
05/17/2022 14:40:57 - INFO - __main__ - Global step 800 Train loss 4.18 Classification-F1 0.05185185185185185 on epoch=199
05/17/2022 14:40:57 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.05185185185185185 on epoch=199, global_step=800
05/17/2022 14:40:59 - INFO - __main__ - Step 810 Global step 810 Train loss 3.90 on epoch=202
05/17/2022 14:41:00 - INFO - __main__ - Step 820 Global step 820 Train loss 3.79 on epoch=204
05/17/2022 14:41:02 - INFO - __main__ - Step 830 Global step 830 Train loss 4.14 on epoch=207
05/17/2022 14:41:03 - INFO - __main__ - Step 840 Global step 840 Train loss 3.68 on epoch=209
05/17/2022 14:41:04 - INFO - __main__ - Step 850 Global step 850 Train loss 3.83 on epoch=212
05/17/2022 14:41:06 - INFO - __main__ - Global step 850 Train loss 3.87 Classification-F1 0.08617131062951496 on epoch=212
05/17/2022 14:41:06 - INFO - __main__ - Saving model with best Classification-F1: 0.05185185185185185 -> 0.08617131062951496 on epoch=212, global_step=850
05/17/2022 14:41:08 - INFO - __main__ - Step 860 Global step 860 Train loss 3.78 on epoch=214
05/17/2022 14:41:09 - INFO - __main__ - Step 870 Global step 870 Train loss 3.88 on epoch=217
05/17/2022 14:41:10 - INFO - __main__ - Step 880 Global step 880 Train loss 3.79 on epoch=219
05/17/2022 14:41:12 - INFO - __main__ - Step 890 Global step 890 Train loss 3.84 on epoch=222
05/17/2022 14:41:13 - INFO - __main__ - Step 900 Global step 900 Train loss 3.68 on epoch=224
05/17/2022 14:41:16 - INFO - __main__ - Global step 900 Train loss 3.79 Classification-F1 0.08978328173374613 on epoch=224
05/17/2022 14:41:16 - INFO - __main__ - Saving model with best Classification-F1: 0.08617131062951496 -> 0.08978328173374613 on epoch=224, global_step=900
05/17/2022 14:41:17 - INFO - __main__ - Step 910 Global step 910 Train loss 3.97 on epoch=227
05/17/2022 14:41:18 - INFO - __main__ - Step 920 Global step 920 Train loss 3.54 on epoch=229
05/17/2022 14:41:20 - INFO - __main__ - Step 930 Global step 930 Train loss 3.65 on epoch=232
05/17/2022 14:41:21 - INFO - __main__ - Step 940 Global step 940 Train loss 3.65 on epoch=234
05/17/2022 14:41:23 - INFO - __main__ - Step 950 Global step 950 Train loss 3.48 on epoch=237
05/17/2022 14:41:23 - INFO - __main__ - Global step 950 Train loss 3.66 Classification-F1 0.1581196581196581 on epoch=237
05/17/2022 14:41:23 - INFO - __main__ - Saving model with best Classification-F1: 0.08978328173374613 -> 0.1581196581196581 on epoch=237, global_step=950
05/17/2022 14:41:25 - INFO - __main__ - Step 960 Global step 960 Train loss 3.28 on epoch=239
05/17/2022 14:41:26 - INFO - __main__ - Step 970 Global step 970 Train loss 3.42 on epoch=242
05/17/2022 14:41:28 - INFO - __main__ - Step 980 Global step 980 Train loss 3.30 on epoch=244
05/17/2022 14:41:29 - INFO - __main__ - Step 990 Global step 990 Train loss 3.46 on epoch=247
05/17/2022 14:41:30 - INFO - __main__ - Step 1000 Global step 1000 Train loss 3.42 on epoch=249
05/17/2022 14:41:31 - INFO - __main__ - Global step 1000 Train loss 3.38 Classification-F1 0.17763157894736842 on epoch=249
05/17/2022 14:41:31 - INFO - __main__ - Saving model with best Classification-F1: 0.1581196581196581 -> 0.17763157894736842 on epoch=249, global_step=1000
05/17/2022 14:41:32 - INFO - __main__ - Step 1010 Global step 1010 Train loss 3.14 on epoch=252
05/17/2022 14:41:34 - INFO - __main__ - Step 1020 Global step 1020 Train loss 3.15 on epoch=254
05/17/2022 14:41:35 - INFO - __main__ - Step 1030 Global step 1030 Train loss 3.24 on epoch=257
05/17/2022 14:41:37 - INFO - __main__ - Step 1040 Global step 1040 Train loss 2.96 on epoch=259
05/17/2022 14:41:38 - INFO - __main__ - Step 1050 Global step 1050 Train loss 3.15 on epoch=262
05/17/2022 14:41:39 - INFO - __main__ - Global step 1050 Train loss 3.13 Classification-F1 0.13067758749069247 on epoch=262
05/17/2022 14:41:40 - INFO - __main__ - Step 1060 Global step 1060 Train loss 3.10 on epoch=264
05/17/2022 14:41:41 - INFO - __main__ - Step 1070 Global step 1070 Train loss 3.11 on epoch=267
05/17/2022 14:41:43 - INFO - __main__ - Step 1080 Global step 1080 Train loss 3.09 on epoch=269
05/17/2022 14:41:44 - INFO - __main__ - Step 1090 Global step 1090 Train loss 3.20 on epoch=272
05/17/2022 14:41:46 - INFO - __main__ - Step 1100 Global step 1100 Train loss 2.79 on epoch=274
05/17/2022 14:41:46 - INFO - __main__ - Global step 1100 Train loss 3.06 Classification-F1 0.1237183868762816 on epoch=274
05/17/2022 14:41:48 - INFO - __main__ - Step 1110 Global step 1110 Train loss 3.00 on epoch=277
05/17/2022 14:41:49 - INFO - __main__ - Step 1120 Global step 1120 Train loss 2.84 on epoch=279
05/17/2022 14:41:50 - INFO - __main__ - Step 1130 Global step 1130 Train loss 3.08 on epoch=282
05/17/2022 14:41:52 - INFO - __main__ - Step 1140 Global step 1140 Train loss 2.70 on epoch=284
05/17/2022 14:41:53 - INFO - __main__ - Step 1150 Global step 1150 Train loss 2.85 on epoch=287
05/17/2022 14:41:54 - INFO - __main__ - Global step 1150 Train loss 2.90 Classification-F1 0.1 on epoch=287
05/17/2022 14:41:55 - INFO - __main__ - Step 1160 Global step 1160 Train loss 2.65 on epoch=289
05/17/2022 14:41:57 - INFO - __main__ - Step 1170 Global step 1170 Train loss 2.82 on epoch=292
05/17/2022 14:41:58 - INFO - __main__ - Step 1180 Global step 1180 Train loss 2.59 on epoch=294
05/17/2022 14:41:59 - INFO - __main__ - Step 1190 Global step 1190 Train loss 2.80 on epoch=297
05/17/2022 14:42:01 - INFO - __main__ - Step 1200 Global step 1200 Train loss 2.48 on epoch=299
05/17/2022 14:42:01 - INFO - __main__ - Global step 1200 Train loss 2.67 Classification-F1 0.1 on epoch=299
05/17/2022 14:42:03 - INFO - __main__ - Step 1210 Global step 1210 Train loss 2.78 on epoch=302
05/17/2022 14:42:04 - INFO - __main__ - Step 1220 Global step 1220 Train loss 2.57 on epoch=304
05/17/2022 14:42:05 - INFO - __main__ - Step 1230 Global step 1230 Train loss 2.66 on epoch=307
05/17/2022 14:42:07 - INFO - __main__ - Step 1240 Global step 1240 Train loss 2.65 on epoch=309
05/17/2022 14:42:08 - INFO - __main__ - Step 1250 Global step 1250 Train loss 2.66 on epoch=312
05/17/2022 14:42:09 - INFO - __main__ - Global step 1250 Train loss 2.66 Classification-F1 0.09615384615384615 on epoch=312
05/17/2022 14:42:10 - INFO - __main__ - Step 1260 Global step 1260 Train loss 2.55 on epoch=314
05/17/2022 14:42:12 - INFO - __main__ - Step 1270 Global step 1270 Train loss 2.57 on epoch=317
05/17/2022 14:42:13 - INFO - __main__ - Step 1280 Global step 1280 Train loss 2.40 on epoch=319
05/17/2022 14:42:15 - INFO - __main__ - Step 1290 Global step 1290 Train loss 2.60 on epoch=322
05/17/2022 14:42:16 - INFO - __main__ - Step 1300 Global step 1300 Train loss 2.34 on epoch=324
05/17/2022 14:42:17 - INFO - __main__ - Global step 1300 Train loss 2.49 Classification-F1 0.1 on epoch=324
05/17/2022 14:42:18 - INFO - __main__ - Step 1310 Global step 1310 Train loss 2.48 on epoch=327
05/17/2022 14:42:20 - INFO - __main__ - Step 1320 Global step 1320 Train loss 2.20 on epoch=329
05/17/2022 14:42:22 - INFO - __main__ - Step 1330 Global step 1330 Train loss 2.37 on epoch=332
05/17/2022 14:42:23 - INFO - __main__ - Step 1340 Global step 1340 Train loss 2.15 on epoch=334
05/17/2022 14:42:25 - INFO - __main__ - Step 1350 Global step 1350 Train loss 2.36 on epoch=337
05/17/2022 14:42:25 - INFO - __main__ - Global step 1350 Train loss 2.31 Classification-F1 0.1 on epoch=337
05/17/2022 14:42:27 - INFO - __main__ - Step 1360 Global step 1360 Train loss 2.29 on epoch=339
05/17/2022 14:42:28 - INFO - __main__ - Step 1370 Global step 1370 Train loss 2.25 on epoch=342
05/17/2022 14:42:30 - INFO - __main__ - Step 1380 Global step 1380 Train loss 2.22 on epoch=344
05/17/2022 14:42:31 - INFO - __main__ - Step 1390 Global step 1390 Train loss 2.24 on epoch=347
05/17/2022 14:42:32 - INFO - __main__ - Step 1400 Global step 1400 Train loss 2.01 on epoch=349
05/17/2022 14:42:33 - INFO - __main__ - Global step 1400 Train loss 2.20 Classification-F1 0.09493670886075949 on epoch=349
05/17/2022 14:42:35 - INFO - __main__ - Step 1410 Global step 1410 Train loss 2.16 on epoch=352
05/17/2022 14:42:36 - INFO - __main__ - Step 1420 Global step 1420 Train loss 2.04 on epoch=354
05/17/2022 14:42:37 - INFO - __main__ - Step 1430 Global step 1430 Train loss 2.24 on epoch=357
05/17/2022 14:42:39 - INFO - __main__ - Step 1440 Global step 1440 Train loss 2.02 on epoch=359
05/17/2022 14:42:40 - INFO - __main__ - Step 1450 Global step 1450 Train loss 2.30 on epoch=362
05/17/2022 14:42:41 - INFO - __main__ - Global step 1450 Train loss 2.15 Classification-F1 0.09493670886075949 on epoch=362
05/17/2022 14:42:42 - INFO - __main__ - Step 1460 Global step 1460 Train loss 2.07 on epoch=364
05/17/2022 14:42:43 - INFO - __main__ - Step 1470 Global step 1470 Train loss 2.00 on epoch=367
05/17/2022 14:42:45 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.97 on epoch=369
05/17/2022 14:42:46 - INFO - __main__ - Step 1490 Global step 1490 Train loss 2.20 on epoch=372
05/17/2022 14:42:48 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.87 on epoch=374
05/17/2022 14:42:48 - INFO - __main__ - Global step 1500 Train loss 2.02 Classification-F1 0.1 on epoch=374
05/17/2022 14:42:49 - INFO - __main__ - Step 1510 Global step 1510 Train loss 2.00 on epoch=377
05/17/2022 14:42:51 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.93 on epoch=379
05/17/2022 14:42:52 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.89 on epoch=382
05/17/2022 14:42:54 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.99 on epoch=384
05/17/2022 14:42:55 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.93 on epoch=387
05/17/2022 14:42:56 - INFO - __main__ - Global step 1550 Train loss 1.95 Classification-F1 0.13067758749069247 on epoch=387
05/17/2022 14:42:57 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.78 on epoch=389
05/17/2022 14:42:58 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.85 on epoch=392
05/17/2022 14:43:00 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.84 on epoch=394
05/17/2022 14:43:01 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.94 on epoch=397
05/17/2022 14:43:03 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.66 on epoch=399
05/17/2022 14:43:04 - INFO - __main__ - Global step 1600 Train loss 1.81 Classification-F1 0.1238095238095238 on epoch=399
05/17/2022 14:43:05 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.82 on epoch=402
05/17/2022 14:43:07 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.70 on epoch=404
05/17/2022 14:43:08 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.74 on epoch=407
05/17/2022 14:43:10 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.76 on epoch=409
05/17/2022 14:43:11 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.51 on epoch=412
05/17/2022 14:43:12 - INFO - __main__ - Global step 1650 Train loss 1.71 Classification-F1 0.1237183868762816 on epoch=412
05/17/2022 14:43:13 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.70 on epoch=414
05/17/2022 14:43:15 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.67 on epoch=417
05/17/2022 14:43:16 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.50 on epoch=419
05/17/2022 14:43:18 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.51 on epoch=422
05/17/2022 14:43:19 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.50 on epoch=424
05/17/2022 14:43:20 - INFO - __main__ - Global step 1700 Train loss 1.58 Classification-F1 0.10234192037470727 on epoch=424
05/17/2022 14:43:21 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.61 on epoch=427
05/17/2022 14:43:23 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.52 on epoch=429
05/17/2022 14:43:24 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.40 on epoch=432
05/17/2022 14:43:25 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.55 on epoch=434
05/17/2022 14:43:27 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.48 on epoch=437
05/17/2022 14:43:27 - INFO - __main__ - Global step 1750 Train loss 1.51 Classification-F1 0.1576923076923077 on epoch=437
05/17/2022 14:43:29 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.42 on epoch=439
05/17/2022 14:43:30 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.52 on epoch=442
05/17/2022 14:43:31 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.47 on epoch=444
05/17/2022 14:43:33 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.50 on epoch=447
05/17/2022 14:43:34 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.46 on epoch=449
05/17/2022 14:43:35 - INFO - __main__ - Global step 1800 Train loss 1.48 Classification-F1 0.1500341763499658 on epoch=449
05/17/2022 14:43:36 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.49 on epoch=452
05/17/2022 14:43:38 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.31 on epoch=454
05/17/2022 14:43:39 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.43 on epoch=457
05/17/2022 14:43:40 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.36 on epoch=459
05/17/2022 14:43:42 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.38 on epoch=462
05/17/2022 14:43:42 - INFO - __main__ - Global step 1850 Train loss 1.39 Classification-F1 0.11703296703296702 on epoch=462
05/17/2022 14:43:44 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.33 on epoch=464
05/17/2022 14:43:45 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.28 on epoch=467
05/17/2022 14:43:47 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.37 on epoch=469
05/17/2022 14:43:48 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.56 on epoch=472
05/17/2022 14:43:49 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.26 on epoch=474
05/17/2022 14:43:50 - INFO - __main__ - Global step 1900 Train loss 1.36 Classification-F1 0.08974358974358974 on epoch=474
05/17/2022 14:43:51 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.19 on epoch=477
05/17/2022 14:43:53 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.25 on epoch=479
05/17/2022 14:43:54 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.36 on epoch=482
05/17/2022 14:43:56 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.21 on epoch=484
05/17/2022 14:43:58 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.32 on epoch=487
05/17/2022 14:43:58 - INFO - __main__ - Global step 1950 Train loss 1.27 Classification-F1 0.1486842105263158 on epoch=487
05/17/2022 14:44:00 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.11 on epoch=489
05/17/2022 14:44:01 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.24 on epoch=492
05/17/2022 14:44:03 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.35 on epoch=494
05/17/2022 14:44:04 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.22 on epoch=497
05/17/2022 14:44:06 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.29 on epoch=499
05/17/2022 14:44:06 - INFO - __main__ - Global step 2000 Train loss 1.24 Classification-F1 0.1 on epoch=499
05/17/2022 14:44:08 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.11 on epoch=502
05/17/2022 14:44:09 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.22 on epoch=504
05/17/2022 14:44:11 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.21 on epoch=507
05/17/2022 14:44:12 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.26 on epoch=509
05/17/2022 14:44:13 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.15 on epoch=512
05/17/2022 14:44:14 - INFO - __main__ - Global step 2050 Train loss 1.19 Classification-F1 0.1 on epoch=512
05/17/2022 14:44:15 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.22 on epoch=514
05/17/2022 14:44:17 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.19 on epoch=517
05/17/2022 14:44:18 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.30 on epoch=519
05/17/2022 14:44:19 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.31 on epoch=522
05/17/2022 14:44:21 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.13 on epoch=524
05/17/2022 14:44:21 - INFO - __main__ - Global step 2100 Train loss 1.23 Classification-F1 0.1 on epoch=524
05/17/2022 14:44:23 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.23 on epoch=527
05/17/2022 14:44:24 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.16 on epoch=529
05/17/2022 14:44:26 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.32 on epoch=532
05/17/2022 14:44:27 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.18 on epoch=534
05/17/2022 14:44:28 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.26 on epoch=537
05/17/2022 14:44:29 - INFO - __main__ - Global step 2150 Train loss 1.23 Classification-F1 0.19165085388994307 on epoch=537
05/17/2022 14:44:29 - INFO - __main__ - Saving model with best Classification-F1: 0.17763157894736842 -> 0.19165085388994307 on epoch=537, global_step=2150
05/17/2022 14:44:30 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.26 on epoch=539
05/17/2022 14:44:32 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.33 on epoch=542
05/17/2022 14:44:33 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.31 on epoch=544
05/17/2022 14:44:35 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.16 on epoch=547
05/17/2022 14:44:36 - INFO - __main__ - Step 2200 Global step 2200 Train loss 1.18 on epoch=549
05/17/2022 14:44:37 - INFO - __main__ - Global step 2200 Train loss 1.25 Classification-F1 0.20975609756097563 on epoch=549
05/17/2022 14:44:37 - INFO - __main__ - Saving model with best Classification-F1: 0.19165085388994307 -> 0.20975609756097563 on epoch=549, global_step=2200
05/17/2022 14:44:38 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.30 on epoch=552
05/17/2022 14:44:40 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.30 on epoch=554
05/17/2022 14:44:41 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.21 on epoch=557
05/17/2022 14:44:42 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.12 on epoch=559
05/17/2022 14:44:44 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.19 on epoch=562
05/17/2022 14:44:44 - INFO - __main__ - Global step 2250 Train loss 1.22 Classification-F1 0.17341430499325233 on epoch=562
05/17/2022 14:44:46 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.15 on epoch=564
05/17/2022 14:44:47 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.24 on epoch=567
05/17/2022 14:44:48 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.13 on epoch=569
05/17/2022 14:44:50 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.16 on epoch=572
05/17/2022 14:44:51 - INFO - __main__ - Step 2300 Global step 2300 Train loss 1.15 on epoch=574
05/17/2022 14:44:52 - INFO - __main__ - Global step 2300 Train loss 1.17 Classification-F1 0.20458606313281716 on epoch=574
05/17/2022 14:44:53 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.15 on epoch=577
05/17/2022 14:44:54 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.16 on epoch=579
05/17/2022 14:44:56 - INFO - __main__ - Step 2330 Global step 2330 Train loss 1.14 on epoch=582
05/17/2022 14:44:57 - INFO - __main__ - Step 2340 Global step 2340 Train loss 1.05 on epoch=584
05/17/2022 14:44:59 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.21 on epoch=587
05/17/2022 14:44:59 - INFO - __main__ - Global step 2350 Train loss 1.14 Classification-F1 0.26134301270417426 on epoch=587
05/17/2022 14:44:59 - INFO - __main__ - Saving model with best Classification-F1: 0.20975609756097563 -> 0.26134301270417426 on epoch=587, global_step=2350
05/17/2022 14:45:01 - INFO - __main__ - Step 2360 Global step 2360 Train loss 1.16 on epoch=589
05/17/2022 14:45:02 - INFO - __main__ - Step 2370 Global step 2370 Train loss 1.19 on epoch=592
05/17/2022 14:45:04 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.16 on epoch=594
05/17/2022 14:45:06 - INFO - __main__ - Step 2390 Global step 2390 Train loss 1.18 on epoch=597
05/17/2022 14:45:07 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.22 on epoch=599
05/17/2022 14:45:08 - INFO - __main__ - Global step 2400 Train loss 1.18 Classification-F1 0.16366443643849718 on epoch=599
05/17/2022 14:45:09 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.12 on epoch=602
05/17/2022 14:45:10 - INFO - __main__ - Step 2420 Global step 2420 Train loss 1.23 on epoch=604
05/17/2022 14:45:12 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.22 on epoch=607
05/17/2022 14:45:13 - INFO - __main__ - Step 2440 Global step 2440 Train loss 1.17 on epoch=609
05/17/2022 14:45:14 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.12 on epoch=612
05/17/2022 14:45:15 - INFO - __main__ - Global step 2450 Train loss 1.17 Classification-F1 0.15425848719475876 on epoch=612
05/17/2022 14:45:16 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.06 on epoch=614
05/17/2022 14:45:18 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.00 on epoch=617
05/17/2022 14:45:19 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.08 on epoch=619
05/17/2022 14:45:21 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.10 on epoch=622
05/17/2022 14:45:22 - INFO - __main__ - Step 2500 Global step 2500 Train loss 1.11 on epoch=624
05/17/2022 14:45:22 - INFO - __main__ - Global step 2500 Train loss 1.07 Classification-F1 0.16277641277641278 on epoch=624
05/17/2022 14:45:24 - INFO - __main__ - Step 2510 Global step 2510 Train loss 1.09 on epoch=627
05/17/2022 14:45:25 - INFO - __main__ - Step 2520 Global step 2520 Train loss 1.07 on epoch=629
05/17/2022 14:45:27 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.10 on epoch=632
05/17/2022 14:45:28 - INFO - __main__ - Step 2540 Global step 2540 Train loss 1.10 on epoch=634
05/17/2022 14:45:30 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.99 on epoch=637
05/17/2022 14:45:30 - INFO - __main__ - Global step 2550 Train loss 1.07 Classification-F1 0.09493670886075949 on epoch=637
05/17/2022 14:45:31 - INFO - __main__ - Step 2560 Global step 2560 Train loss 1.15 on epoch=639
05/17/2022 14:45:33 - INFO - __main__ - Step 2570 Global step 2570 Train loss 1.13 on epoch=642
05/17/2022 14:45:34 - INFO - __main__ - Step 2580 Global step 2580 Train loss 1.16 on epoch=644
05/17/2022 14:45:36 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.06 on epoch=647
05/17/2022 14:45:37 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.13 on epoch=649
05/17/2022 14:45:38 - INFO - __main__ - Global step 2600 Train loss 1.13 Classification-F1 0.13067758749069247 on epoch=649
05/17/2022 14:45:39 - INFO - __main__ - Step 2610 Global step 2610 Train loss 1.21 on epoch=652
05/17/2022 14:45:40 - INFO - __main__ - Step 2620 Global step 2620 Train loss 1.24 on epoch=654
05/17/2022 14:45:42 - INFO - __main__ - Step 2630 Global step 2630 Train loss 1.13 on epoch=657
05/17/2022 14:45:43 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.10 on epoch=659
05/17/2022 14:45:44 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.07 on epoch=662
05/17/2022 14:45:45 - INFO - __main__ - Global step 2650 Train loss 1.15 Classification-F1 0.15054945054945054 on epoch=662
05/17/2022 14:45:46 - INFO - __main__ - Step 2660 Global step 2660 Train loss 1.16 on epoch=664
05/17/2022 14:45:48 - INFO - __main__ - Step 2670 Global step 2670 Train loss 1.16 on epoch=667
05/17/2022 14:45:49 - INFO - __main__ - Step 2680 Global step 2680 Train loss 1.07 on epoch=669
05/17/2022 14:45:51 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.98 on epoch=672
05/17/2022 14:45:52 - INFO - __main__ - Step 2700 Global step 2700 Train loss 1.03 on epoch=674
05/17/2022 14:45:52 - INFO - __main__ - Global step 2700 Train loss 1.08 Classification-F1 0.17954911433172302 on epoch=674
05/17/2022 14:45:54 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.20 on epoch=677
05/17/2022 14:45:55 - INFO - __main__ - Step 2720 Global step 2720 Train loss 1.06 on epoch=679
05/17/2022 14:45:57 - INFO - __main__ - Step 2730 Global step 2730 Train loss 1.11 on epoch=682
05/17/2022 14:45:58 - INFO - __main__ - Step 2740 Global step 2740 Train loss 1.13 on epoch=684
05/17/2022 14:45:59 - INFO - __main__ - Step 2750 Global step 2750 Train loss 1.14 on epoch=687
05/17/2022 14:46:00 - INFO - __main__ - Global step 2750 Train loss 1.13 Classification-F1 0.1 on epoch=687
05/17/2022 14:46:01 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.15 on epoch=689
05/17/2022 14:46:03 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.26 on epoch=692
05/17/2022 14:46:04 - INFO - __main__ - Step 2780 Global step 2780 Train loss 1.11 on epoch=694
05/17/2022 14:46:05 - INFO - __main__ - Step 2790 Global step 2790 Train loss 1.11 on epoch=697
05/17/2022 14:46:07 - INFO - __main__ - Step 2800 Global step 2800 Train loss 1.15 on epoch=699
05/17/2022 14:46:07 - INFO - __main__ - Global step 2800 Train loss 1.15 Classification-F1 0.1 on epoch=699
05/17/2022 14:46:09 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.12 on epoch=702
05/17/2022 14:46:10 - INFO - __main__ - Step 2820 Global step 2820 Train loss 1.07 on epoch=704
05/17/2022 14:46:12 - INFO - __main__ - Step 2830 Global step 2830 Train loss 1.19 on epoch=707
05/17/2022 14:46:13 - INFO - __main__ - Step 2840 Global step 2840 Train loss 1.09 on epoch=709
05/17/2022 14:46:14 - INFO - __main__ - Step 2850 Global step 2850 Train loss 1.12 on epoch=712
05/17/2022 14:46:15 - INFO - __main__ - Global step 2850 Train loss 1.12 Classification-F1 0.1 on epoch=712
05/17/2022 14:46:16 - INFO - __main__ - Step 2860 Global step 2860 Train loss 1.12 on epoch=714
05/17/2022 14:46:18 - INFO - __main__ - Step 2870 Global step 2870 Train loss 1.03 on epoch=717
05/17/2022 14:46:19 - INFO - __main__ - Step 2880 Global step 2880 Train loss 1.05 on epoch=719
05/17/2022 14:46:20 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.22 on epoch=722
05/17/2022 14:46:22 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.06 on epoch=724
05/17/2022 14:46:22 - INFO - __main__ - Global step 2900 Train loss 1.09 Classification-F1 0.1 on epoch=724
05/17/2022 14:46:24 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.03 on epoch=727
05/17/2022 14:46:25 - INFO - __main__ - Step 2920 Global step 2920 Train loss 1.17 on epoch=729
05/17/2022 14:46:27 - INFO - __main__ - Step 2930 Global step 2930 Train loss 1.18 on epoch=732
05/17/2022 14:46:28 - INFO - __main__ - Step 2940 Global step 2940 Train loss 1.07 on epoch=734
05/17/2022 14:46:29 - INFO - __main__ - Step 2950 Global step 2950 Train loss 1.06 on epoch=737
05/17/2022 14:46:30 - INFO - __main__ - Global step 2950 Train loss 1.10 Classification-F1 0.1 on epoch=737
05/17/2022 14:46:31 - INFO - __main__ - Step 2960 Global step 2960 Train loss 1.17 on epoch=739
05/17/2022 14:46:33 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.19 on epoch=742
05/17/2022 14:46:34 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.09 on epoch=744
05/17/2022 14:46:35 - INFO - __main__ - Step 2990 Global step 2990 Train loss 1.09 on epoch=747
05/17/2022 14:46:37 - INFO - __main__ - Step 3000 Global step 3000 Train loss 1.05 on epoch=749
05/17/2022 14:46:37 - INFO - __main__ - Global step 3000 Train loss 1.12 Classification-F1 0.10126582278481013 on epoch=749
05/17/2022 14:46:37 - INFO - __main__ - save last model!
05/17/2022 14:46:37 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/17/2022 14:46:37 - INFO - __main__ - Start tokenizing ... 5509 instances
05/17/2022 14:46:37 - INFO - __main__ - Printing 3 examples
05/17/2022 14:46:37 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/17/2022 14:46:37 - INFO - __main__ - ['others']
05/17/2022 14:46:37 - INFO - __main__ -  [emo] what you like very little things ok
05/17/2022 14:46:37 - INFO - __main__ - ['others']
05/17/2022 14:46:37 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/17/2022 14:46:37 - INFO - __main__ - ['others']
05/17/2022 14:46:37 - INFO - __main__ - Tokenizing Input ...
05/17/2022 14:46:40 - INFO - __main__ - Tokenizing Output ...
05/17/2022 14:46:45 - INFO - __main__ - Loaded 5509 examples from test data
05/17/2022 14:47:29 - INFO - __main__ - Saved prediction in models/T5-base-reptile-cls2cls-3e-5-2-5000-5e-1-10/singletask-emo/emo_16_87_0.2_8_predictions.txt
05/17/2022 14:47:29 - INFO - __main__ - Classification-F1 on test data: 0.0284
05/17/2022 14:47:29 - INFO - __main__ - prefix=emo_16_87, lr=0.2, bsz=8, dev_performance=0.26134301270417426, test_performance=0.028374428379406725
05/21/2022 21:18:17 - INFO - __main__ - Namespace(task_dir='data/emo/', task_name='emo', identifier='T5-base-reptile-cls2cls-3e-5-2-5000-5e-1-10', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-base-reptile-cls2cls-3e-5-2-5000-5e-1-10/singletask-emo', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-base-reptile-cls2cls-3e-5-2-5000-5e-1-10/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/base/pytorch_model.bin', model='google/t5-v1_1-base', prompt_number=100, cuda='6,7')
05/21/2022 21:18:17 - INFO - __main__ - models/T5-base-reptile-cls2cls-3e-5-2-5000-5e-1-10/singletask-emo
05/21/2022 21:18:17 - INFO - __main__ - Namespace(task_dir='data/emo/', task_name='emo', identifier='T5-base-reptile-cls2cls-3e-5-2-5000-5e-1-10', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-base-reptile-cls2cls-3e-5-2-5000-5e-1-10/singletask-emo', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-base-reptile-cls2cls-3e-5-2-5000-5e-1-10/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/base/pytorch_model.bin', model='google/t5-v1_1-base', prompt_number=100, cuda='6,7')
05/21/2022 21:18:17 - INFO - __main__ - models/T5-base-reptile-cls2cls-3e-5-2-5000-5e-1-10/singletask-emo
05/21/2022 21:18:19 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
05/21/2022 21:18:19 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
05/21/2022 21:18:19 - INFO - __main__ - args.device: cuda:1
05/21/2022 21:18:19 - INFO - __main__ - args.device: cuda:0
05/21/2022 21:18:19 - INFO - __main__ - Using 2 gpus
05/21/2022 21:18:19 - INFO - __main__ - Using 2 gpus
05/21/2022 21:18:19 - INFO - __main__ - Fine-tuning the following samples: ['emo_16_100', 'emo_16_13', 'emo_16_21', 'emo_16_42', 'emo_16_87']
05/21/2022 21:18:19 - INFO - __main__ - Fine-tuning the following samples: ['emo_16_100', 'emo_16_13', 'emo_16_21', 'emo_16_42', 'emo_16_87']
05/21/2022 21:18:23 - INFO - __main__ - Running ... prefix=emo_16_100, lr=0.5, bsz=8 ...
06/01/2022 02:02:44 - INFO - __main__ - Namespace(task_dir='data/emo/', task_name='emo', identifier='T5-base-reptile-cls2cls-3e-5-2-5000-5e-1-10', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-base-reptile-cls2cls-3e-5-2-5000-5e-1-10/singletask-emo', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-base-reptile-cls2cls-3e-5-2-5000-5e-1-10/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/base/pytorch_model.bin', model='google/t5-v1_1-base', prompt_number=100, cuda='6,7')
06/01/2022 02:02:44 - INFO - __main__ - models/T5-base-reptile-cls2cls-3e-5-2-5000-5e-1-10/singletask-emo
06/01/2022 02:02:44 - INFO - __main__ - Namespace(task_dir='data/emo/', task_name='emo', identifier='T5-base-reptile-cls2cls-3e-5-2-5000-5e-1-10', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-base-reptile-cls2cls-3e-5-2-5000-5e-1-10/singletask-emo', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-base-reptile-cls2cls-3e-5-2-5000-5e-1-10/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/base/pytorch_model.bin', model='google/t5-v1_1-base', prompt_number=100, cuda='6,7')
06/01/2022 02:02:44 - INFO - __main__ - models/T5-base-reptile-cls2cls-3e-5-2-5000-5e-1-10/singletask-emo
06/01/2022 02:02:46 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
06/01/2022 02:02:46 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
06/01/2022 02:02:46 - INFO - __main__ - args.device: cuda:0
06/01/2022 02:02:46 - INFO - __main__ - Using 2 gpus
06/01/2022 02:02:46 - INFO - __main__ - args.device: cuda:1
06/01/2022 02:02:46 - INFO - __main__ - Using 2 gpus
06/01/2022 02:02:46 - INFO - __main__ - Fine-tuning the following samples: ['emo_16_100', 'emo_16_13', 'emo_16_21', 'emo_16_42', 'emo_16_87']
06/01/2022 02:02:46 - INFO - __main__ - Fine-tuning the following samples: ['emo_16_100', 'emo_16_13', 'emo_16_21', 'emo_16_42', 'emo_16_87']
06/01/2022 02:02:50 - INFO - __main__ - Running ... prefix=emo_16_100, lr=0.5, bsz=8 ...
06/01/2022 02:02:51 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 02:02:51 - INFO - __main__ - Printing 3 examples
06/01/2022 02:02:51 - INFO - __main__ -  [emo] how cause yes am listening
06/01/2022 02:02:51 - INFO - __main__ - ['others']
06/01/2022 02:02:51 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/01/2022 02:02:51 - INFO - __main__ - ['others']
06/01/2022 02:02:51 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/01/2022 02:02:51 - INFO - __main__ - ['others']
06/01/2022 02:02:51 - INFO - __main__ - Tokenizing Input ...
06/01/2022 02:02:51 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 02:02:51 - INFO - __main__ - Printing 3 examples
06/01/2022 02:02:51 - INFO - __main__ -  [emo] how cause yes am listening
06/01/2022 02:02:51 - INFO - __main__ - ['others']
06/01/2022 02:02:51 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/01/2022 02:02:51 - INFO - __main__ - ['others']
06/01/2022 02:02:51 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/01/2022 02:02:51 - INFO - __main__ - ['others']
06/01/2022 02:02:51 - INFO - __main__ - Tokenizing Input ...
06/01/2022 02:02:51 - INFO - __main__ - Tokenizing Output ...
06/01/2022 02:02:51 - INFO - __main__ - Tokenizing Output ...
06/01/2022 02:02:51 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 02:02:51 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 02:02:51 - INFO - __main__ - Printing 3 examples
06/01/2022 02:02:51 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
06/01/2022 02:02:51 - INFO - __main__ - ['others']
06/01/2022 02:02:51 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
06/01/2022 02:02:51 - INFO - __main__ - ['others']
06/01/2022 02:02:51 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
06/01/2022 02:02:51 - INFO - __main__ - ['others']
06/01/2022 02:02:51 - INFO - __main__ - Tokenizing Input ...
06/01/2022 02:02:51 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 02:02:51 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 02:02:51 - INFO - __main__ - Printing 3 examples
06/01/2022 02:02:51 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
06/01/2022 02:02:51 - INFO - __main__ - ['others']
06/01/2022 02:02:51 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
06/01/2022 02:02:51 - INFO - __main__ - ['others']
06/01/2022 02:02:51 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
06/01/2022 02:02:51 - INFO - __main__ - ['others']
06/01/2022 02:02:51 - INFO - __main__ - Tokenizing Input ...
06/01/2022 02:02:51 - INFO - __main__ - Tokenizing Output ...
06/01/2022 02:02:51 - INFO - __main__ - Tokenizing Output ...
06/01/2022 02:02:51 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 02:02:51 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 02:02:57 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 02:02:58 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 02:02:58 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/01/2022 02:02:58 - INFO - __main__ - Starting training!
06/01/2022 02:03:03 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/01/2022 02:03:03 - INFO - __main__ - Starting training!
06/01/2022 02:03:05 - INFO - __main__ - Step 10 Global step 10 Train loss 9.02 on epoch=2
06/01/2022 02:03:06 - INFO - __main__ - Step 20 Global step 20 Train loss 8.88 on epoch=4
06/01/2022 02:03:07 - INFO - __main__ - Step 30 Global step 30 Train loss 8.91 on epoch=7
06/01/2022 02:03:09 - INFO - __main__ - Step 40 Global step 40 Train loss 8.82 on epoch=9
06/01/2022 02:03:10 - INFO - __main__ - Step 50 Global step 50 Train loss 8.70 on epoch=12
06/01/2022 02:03:17 - INFO - __main__ - Global step 50 Train loss 8.87 Classification-F1 0.0 on epoch=12
06/01/2022 02:03:17 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
06/01/2022 02:03:18 - INFO - __main__ - Step 60 Global step 60 Train loss 8.77 on epoch=14
06/01/2022 02:03:20 - INFO - __main__ - Step 70 Global step 70 Train loss 8.51 on epoch=17
06/01/2022 02:03:21 - INFO - __main__ - Step 80 Global step 80 Train loss 8.43 on epoch=19
06/01/2022 02:03:22 - INFO - __main__ - Step 90 Global step 90 Train loss 8.12 on epoch=22
06/01/2022 02:03:24 - INFO - __main__ - Step 100 Global step 100 Train loss 7.97 on epoch=24
06/01/2022 02:03:45 - INFO - __main__ - Global step 100 Train loss 8.36 Classification-F1 0.0 on epoch=24
06/01/2022 02:03:47 - INFO - __main__ - Step 110 Global step 110 Train loss 7.58 on epoch=27
06/01/2022 02:03:48 - INFO - __main__ - Step 120 Global step 120 Train loss 7.17 on epoch=29
06/01/2022 02:03:49 - INFO - __main__ - Step 130 Global step 130 Train loss 6.87 on epoch=32
06/01/2022 02:03:51 - INFO - __main__ - Step 140 Global step 140 Train loss 6.64 on epoch=34
06/01/2022 02:03:52 - INFO - __main__ - Step 150 Global step 150 Train loss 6.30 on epoch=37
06/01/2022 02:03:57 - INFO - __main__ - Global step 150 Train loss 6.91 Classification-F1 0.0 on epoch=37
06/01/2022 02:03:58 - INFO - __main__ - Step 160 Global step 160 Train loss 6.17 on epoch=39
06/01/2022 02:04:00 - INFO - __main__ - Step 170 Global step 170 Train loss 5.94 on epoch=42
06/01/2022 02:04:01 - INFO - __main__ - Step 180 Global step 180 Train loss 5.63 on epoch=44
06/01/2022 02:04:02 - INFO - __main__ - Step 190 Global step 190 Train loss 5.67 on epoch=47
06/01/2022 02:04:04 - INFO - __main__ - Step 200 Global step 200 Train loss 5.28 on epoch=49
06/01/2022 02:04:08 - INFO - __main__ - Global step 200 Train loss 5.74 Classification-F1 0.0 on epoch=49
06/01/2022 02:04:10 - INFO - __main__ - Step 210 Global step 210 Train loss 5.47 on epoch=52
06/01/2022 02:04:11 - INFO - __main__ - Step 220 Global step 220 Train loss 5.10 on epoch=54
06/01/2022 02:04:12 - INFO - __main__ - Step 230 Global step 230 Train loss 5.06 on epoch=57
06/01/2022 02:04:13 - INFO - __main__ - Step 240 Global step 240 Train loss 4.88 on epoch=59
06/01/2022 02:04:15 - INFO - __main__ - Step 250 Global step 250 Train loss 5.03 on epoch=62
06/01/2022 02:04:25 - INFO - __main__ - Global step 250 Train loss 5.11 Classification-F1 0.0 on epoch=62
06/01/2022 02:04:26 - INFO - __main__ - Step 260 Global step 260 Train loss 4.62 on epoch=64
06/01/2022 02:04:27 - INFO - __main__ - Step 270 Global step 270 Train loss 4.76 on epoch=67
06/01/2022 02:04:29 - INFO - __main__ - Step 280 Global step 280 Train loss 4.52 on epoch=69
06/01/2022 02:04:30 - INFO - __main__ - Step 290 Global step 290 Train loss 4.51 on epoch=72
06/01/2022 02:04:31 - INFO - __main__ - Step 300 Global step 300 Train loss 4.27 on epoch=74
06/01/2022 02:04:35 - INFO - __main__ - Global step 300 Train loss 4.54 Classification-F1 0.0 on epoch=74
06/01/2022 02:04:36 - INFO - __main__ - Step 310 Global step 310 Train loss 4.47 on epoch=77
06/01/2022 02:04:37 - INFO - __main__ - Step 320 Global step 320 Train loss 4.34 on epoch=79
06/01/2022 02:04:39 - INFO - __main__ - Step 330 Global step 330 Train loss 4.39 on epoch=82
06/01/2022 02:04:40 - INFO - __main__ - Step 340 Global step 340 Train loss 4.23 on epoch=84
06/01/2022 02:04:41 - INFO - __main__ - Step 350 Global step 350 Train loss 4.31 on epoch=87
06/01/2022 02:04:46 - INFO - __main__ - Global step 350 Train loss 4.35 Classification-F1 0.0 on epoch=87
06/01/2022 02:04:48 - INFO - __main__ - Step 360 Global step 360 Train loss 4.10 on epoch=89
06/01/2022 02:04:49 - INFO - __main__ - Step 370 Global step 370 Train loss 4.11 on epoch=92
06/01/2022 02:04:50 - INFO - __main__ - Step 380 Global step 380 Train loss 4.08 on epoch=94
06/01/2022 02:04:52 - INFO - __main__ - Step 390 Global step 390 Train loss 4.08 on epoch=97
06/01/2022 02:04:53 - INFO - __main__ - Step 400 Global step 400 Train loss 3.93 on epoch=99
06/01/2022 02:04:57 - INFO - __main__ - Global step 400 Train loss 4.06 Classification-F1 0.006578947368421052 on epoch=99
06/01/2022 02:04:57 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.006578947368421052 on epoch=99, global_step=400
06/01/2022 02:04:59 - INFO - __main__ - Step 410 Global step 410 Train loss 3.75 on epoch=102
06/01/2022 02:05:00 - INFO - __main__ - Step 420 Global step 420 Train loss 3.71 on epoch=104
06/01/2022 02:05:01 - INFO - __main__ - Step 430 Global step 430 Train loss 3.82 on epoch=107
06/01/2022 02:05:02 - INFO - __main__ - Step 440 Global step 440 Train loss 3.62 on epoch=109
06/01/2022 02:05:04 - INFO - __main__ - Step 450 Global step 450 Train loss 3.80 on epoch=112
06/01/2022 02:05:11 - INFO - __main__ - Global step 450 Train loss 3.74 Classification-F1 0.0 on epoch=112
06/01/2022 02:05:12 - INFO - __main__ - Step 460 Global step 460 Train loss 3.64 on epoch=114
06/01/2022 02:05:13 - INFO - __main__ - Step 470 Global step 470 Train loss 3.62 on epoch=117
06/01/2022 02:05:15 - INFO - __main__ - Step 480 Global step 480 Train loss 3.60 on epoch=119
06/01/2022 02:05:16 - INFO - __main__ - Step 490 Global step 490 Train loss 3.60 on epoch=122
06/01/2022 02:05:17 - INFO - __main__ - Step 500 Global step 500 Train loss 3.55 on epoch=124
06/01/2022 02:05:19 - INFO - __main__ - Global step 500 Train loss 3.60 Classification-F1 0.15277777777777776 on epoch=124
06/01/2022 02:05:19 - INFO - __main__ - Saving model with best Classification-F1: 0.006578947368421052 -> 0.15277777777777776 on epoch=124, global_step=500
06/01/2022 02:05:21 - INFO - __main__ - Step 510 Global step 510 Train loss 3.55 on epoch=127
06/01/2022 02:05:22 - INFO - __main__ - Step 520 Global step 520 Train loss 3.50 on epoch=129
06/01/2022 02:05:23 - INFO - __main__ - Step 530 Global step 530 Train loss 3.42 on epoch=132
06/01/2022 02:05:25 - INFO - __main__ - Step 540 Global step 540 Train loss 3.31 on epoch=134
06/01/2022 02:05:26 - INFO - __main__ - Step 550 Global step 550 Train loss 3.35 on epoch=137
06/01/2022 02:05:37 - INFO - __main__ - Global step 550 Train loss 3.43 Classification-F1 0.09472329472329473 on epoch=137
06/01/2022 02:05:38 - INFO - __main__ - Step 560 Global step 560 Train loss 3.15 on epoch=139
06/01/2022 02:05:39 - INFO - __main__ - Step 570 Global step 570 Train loss 3.30 on epoch=142
06/01/2022 02:05:41 - INFO - __main__ - Step 580 Global step 580 Train loss 3.27 on epoch=144
06/01/2022 02:05:42 - INFO - __main__ - Step 590 Global step 590 Train loss 3.40 on epoch=147
06/01/2022 02:05:43 - INFO - __main__ - Step 600 Global step 600 Train loss 3.27 on epoch=149
06/01/2022 02:05:51 - INFO - __main__ - Global step 600 Train loss 3.28 Classification-F1 0.11377091377091378 on epoch=149
06/01/2022 02:05:52 - INFO - __main__ - Step 610 Global step 610 Train loss 3.13 on epoch=152
06/01/2022 02:05:54 - INFO - __main__ - Step 620 Global step 620 Train loss 2.99 on epoch=154
06/01/2022 02:05:55 - INFO - __main__ - Step 630 Global step 630 Train loss 3.20 on epoch=157
06/01/2022 02:05:56 - INFO - __main__ - Step 640 Global step 640 Train loss 3.00 on epoch=159
06/01/2022 02:05:58 - INFO - __main__ - Step 650 Global step 650 Train loss 3.05 on epoch=162
06/01/2022 02:06:01 - INFO - __main__ - Global step 650 Train loss 3.07 Classification-F1 0.13067758749069247 on epoch=162
06/01/2022 02:06:02 - INFO - __main__ - Step 660 Global step 660 Train loss 3.13 on epoch=164
06/01/2022 02:06:03 - INFO - __main__ - Step 670 Global step 670 Train loss 2.98 on epoch=167
06/01/2022 02:06:05 - INFO - __main__ - Step 680 Global step 680 Train loss 2.92 on epoch=169
06/01/2022 02:06:06 - INFO - __main__ - Step 690 Global step 690 Train loss 2.86 on epoch=172
06/01/2022 02:06:07 - INFO - __main__ - Step 700 Global step 700 Train loss 3.08 on epoch=174
06/01/2022 02:06:11 - INFO - __main__ - Global step 700 Train loss 2.99 Classification-F1 0.1 on epoch=174
06/01/2022 02:06:12 - INFO - __main__ - Step 710 Global step 710 Train loss 2.86 on epoch=177
06/01/2022 02:06:14 - INFO - __main__ - Step 720 Global step 720 Train loss 2.69 on epoch=179
06/01/2022 02:06:15 - INFO - __main__ - Step 730 Global step 730 Train loss 2.60 on epoch=182
06/01/2022 02:06:16 - INFO - __main__ - Step 740 Global step 740 Train loss 2.72 on epoch=184
06/01/2022 02:06:18 - INFO - __main__ - Step 750 Global step 750 Train loss 2.75 on epoch=187
06/01/2022 02:06:19 - INFO - __main__ - Global step 750 Train loss 2.73 Classification-F1 0.09493670886075949 on epoch=187
06/01/2022 02:06:20 - INFO - __main__ - Step 760 Global step 760 Train loss 2.59 on epoch=189
06/01/2022 02:06:21 - INFO - __main__ - Step 770 Global step 770 Train loss 2.58 on epoch=192
06/01/2022 02:06:22 - INFO - __main__ - Step 780 Global step 780 Train loss 2.48 on epoch=194
06/01/2022 02:06:24 - INFO - __main__ - Step 790 Global step 790 Train loss 2.42 on epoch=197
06/01/2022 02:06:25 - INFO - __main__ - Step 800 Global step 800 Train loss 2.35 on epoch=199
06/01/2022 02:06:26 - INFO - __main__ - Global step 800 Train loss 2.49 Classification-F1 0.1484375 on epoch=199
06/01/2022 02:06:27 - INFO - __main__ - Step 810 Global step 810 Train loss 2.39 on epoch=202
06/01/2022 02:06:28 - INFO - __main__ - Step 820 Global step 820 Train loss 2.19 on epoch=204
06/01/2022 02:06:30 - INFO - __main__ - Step 830 Global step 830 Train loss 2.27 on epoch=207
06/01/2022 02:06:31 - INFO - __main__ - Step 840 Global step 840 Train loss 2.00 on epoch=209
06/01/2022 02:06:32 - INFO - __main__ - Step 850 Global step 850 Train loss 2.25 on epoch=212
06/01/2022 02:06:33 - INFO - __main__ - Global step 850 Train loss 2.22 Classification-F1 0.10126582278481013 on epoch=212
06/01/2022 02:06:34 - INFO - __main__ - Step 860 Global step 860 Train loss 2.09 on epoch=214
06/01/2022 02:06:36 - INFO - __main__ - Step 870 Global step 870 Train loss 2.04 on epoch=217
06/01/2022 02:06:37 - INFO - __main__ - Step 880 Global step 880 Train loss 1.79 on epoch=219
06/01/2022 02:06:38 - INFO - __main__ - Step 890 Global step 890 Train loss 1.85 on epoch=222
06/01/2022 02:06:39 - INFO - __main__ - Step 900 Global step 900 Train loss 1.75 on epoch=224
06/01/2022 02:06:40 - INFO - __main__ - Global step 900 Train loss 1.91 Classification-F1 0.10126582278481013 on epoch=224
06/01/2022 02:06:41 - INFO - __main__ - Step 910 Global step 910 Train loss 1.69 on epoch=227
06/01/2022 02:06:42 - INFO - __main__ - Step 920 Global step 920 Train loss 1.67 on epoch=229
06/01/2022 02:06:44 - INFO - __main__ - Step 930 Global step 930 Train loss 1.63 on epoch=232
06/01/2022 02:06:45 - INFO - __main__ - Step 940 Global step 940 Train loss 1.69 on epoch=234
06/01/2022 02:06:46 - INFO - __main__ - Step 950 Global step 950 Train loss 1.71 on epoch=237
06/01/2022 02:06:47 - INFO - __main__ - Global step 950 Train loss 1.68 Classification-F1 0.1575757575757576 on epoch=237
06/01/2022 02:06:47 - INFO - __main__ - Saving model with best Classification-F1: 0.15277777777777776 -> 0.1575757575757576 on epoch=237, global_step=950
06/01/2022 02:06:48 - INFO - __main__ - Step 960 Global step 960 Train loss 1.62 on epoch=239
06/01/2022 02:06:49 - INFO - __main__ - Step 970 Global step 970 Train loss 1.53 on epoch=242
06/01/2022 02:06:51 - INFO - __main__ - Step 980 Global step 980 Train loss 1.49 on epoch=244
06/01/2022 02:06:52 - INFO - __main__ - Step 990 Global step 990 Train loss 1.58 on epoch=247
06/01/2022 02:06:53 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.60 on epoch=249
06/01/2022 02:06:54 - INFO - __main__ - Global step 1000 Train loss 1.56 Classification-F1 0.14915966386554622 on epoch=249
06/01/2022 02:06:55 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.67 on epoch=252
06/01/2022 02:06:56 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.50 on epoch=254
06/01/2022 02:06:57 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.59 on epoch=257
06/01/2022 02:06:59 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.55 on epoch=259
06/01/2022 02:07:00 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.46 on epoch=262
06/01/2022 02:07:00 - INFO - __main__ - Global step 1050 Train loss 1.55 Classification-F1 0.10126582278481013 on epoch=262
06/01/2022 02:07:02 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.34 on epoch=264
06/01/2022 02:07:03 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.42 on epoch=267
06/01/2022 02:07:04 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.47 on epoch=269
06/01/2022 02:07:05 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.54 on epoch=272
06/01/2022 02:07:06 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.52 on epoch=274
06/01/2022 02:07:07 - INFO - __main__ - Global step 1100 Train loss 1.46 Classification-F1 0.16451612903225807 on epoch=274
06/01/2022 02:07:07 - INFO - __main__ - Saving model with best Classification-F1: 0.1575757575757576 -> 0.16451612903225807 on epoch=274, global_step=1100
06/01/2022 02:07:08 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.41 on epoch=277
06/01/2022 02:07:10 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.51 on epoch=279
06/01/2022 02:07:11 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.48 on epoch=282
06/01/2022 02:07:12 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.30 on epoch=284
06/01/2022 02:07:13 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.45 on epoch=287
06/01/2022 02:07:14 - INFO - __main__ - Global step 1150 Train loss 1.43 Classification-F1 0.12447885646217988 on epoch=287
06/01/2022 02:07:15 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.29 on epoch=289
06/01/2022 02:07:16 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.33 on epoch=292
06/01/2022 02:07:18 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.34 on epoch=294
06/01/2022 02:07:19 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.25 on epoch=297
06/01/2022 02:07:20 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.38 on epoch=299
06/01/2022 02:07:21 - INFO - __main__ - Global step 1200 Train loss 1.32 Classification-F1 0.10126582278481013 on epoch=299
06/01/2022 02:07:22 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.17 on epoch=302
06/01/2022 02:07:23 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.25 on epoch=304
06/01/2022 02:07:24 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.15 on epoch=307
06/01/2022 02:07:26 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.19 on epoch=309
06/01/2022 02:07:27 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.28 on epoch=312
06/01/2022 02:07:28 - INFO - __main__ - Global step 1250 Train loss 1.21 Classification-F1 0.1328125 on epoch=312
06/01/2022 02:07:29 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.27 on epoch=314
06/01/2022 02:07:30 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.23 on epoch=317
06/01/2022 02:07:31 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.22 on epoch=319
06/01/2022 02:07:33 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.16 on epoch=322
06/01/2022 02:07:34 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.10 on epoch=324
06/01/2022 02:07:34 - INFO - __main__ - Global step 1300 Train loss 1.20 Classification-F1 0.12447885646217988 on epoch=324
06/01/2022 02:07:36 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.21 on epoch=327
06/01/2022 02:07:37 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.11 on epoch=329
06/01/2022 02:07:38 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.22 on epoch=332
06/01/2022 02:07:40 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.24 on epoch=334
06/01/2022 02:07:41 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.24 on epoch=337
06/01/2022 02:07:41 - INFO - __main__ - Global step 1350 Train loss 1.20 Classification-F1 0.11762954139368673 on epoch=337
06/01/2022 02:07:43 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.08 on epoch=339
06/01/2022 02:07:44 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.17 on epoch=342
06/01/2022 02:07:45 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.09 on epoch=344
06/01/2022 02:07:47 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.21 on epoch=347
06/01/2022 02:07:48 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.08 on epoch=349
06/01/2022 02:07:48 - INFO - __main__ - Global step 1400 Train loss 1.12 Classification-F1 0.1237183868762816 on epoch=349
06/01/2022 02:07:50 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.16 on epoch=352
06/01/2022 02:07:51 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.28 on epoch=354
06/01/2022 02:07:52 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.23 on epoch=357
06/01/2022 02:07:53 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.08 on epoch=359
06/01/2022 02:07:55 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.16 on epoch=362
06/01/2022 02:07:55 - INFO - __main__ - Global step 1450 Train loss 1.18 Classification-F1 0.1855036855036855 on epoch=362
06/01/2022 02:07:55 - INFO - __main__ - Saving model with best Classification-F1: 0.16451612903225807 -> 0.1855036855036855 on epoch=362, global_step=1450
06/01/2022 02:07:57 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.09 on epoch=364
06/01/2022 02:07:58 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.09 on epoch=367
06/01/2022 02:07:59 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.13 on epoch=369
06/01/2022 02:08:00 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.19 on epoch=372
06/01/2022 02:08:02 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.01 on epoch=374
06/01/2022 02:08:02 - INFO - __main__ - Global step 1500 Train loss 1.10 Classification-F1 0.125 on epoch=374
06/01/2022 02:08:03 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.15 on epoch=377
06/01/2022 02:08:05 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.22 on epoch=379
06/01/2022 02:08:06 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.17 on epoch=382
06/01/2022 02:08:07 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.11 on epoch=384
06/01/2022 02:08:09 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.06 on epoch=387
06/01/2022 02:08:09 - INFO - __main__ - Global step 1550 Train loss 1.14 Classification-F1 0.15851775604734944 on epoch=387
06/01/2022 02:08:10 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.02 on epoch=389
06/01/2022 02:08:12 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.24 on epoch=392
06/01/2022 02:08:13 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.11 on epoch=394
06/01/2022 02:08:14 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.08 on epoch=397
06/01/2022 02:08:15 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.11 on epoch=399
06/01/2022 02:08:16 - INFO - __main__ - Global step 1600 Train loss 1.11 Classification-F1 0.1 on epoch=399
06/01/2022 02:08:17 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.05 on epoch=402
06/01/2022 02:08:18 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.11 on epoch=404
06/01/2022 02:08:20 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.03 on epoch=407
06/01/2022 02:08:21 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.04 on epoch=409
06/01/2022 02:08:22 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.19 on epoch=412
06/01/2022 02:08:23 - INFO - __main__ - Global step 1650 Train loss 1.09 Classification-F1 0.2206477732793522 on epoch=412
06/01/2022 02:08:23 - INFO - __main__ - Saving model with best Classification-F1: 0.1855036855036855 -> 0.2206477732793522 on epoch=412, global_step=1650
06/01/2022 02:08:24 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.12 on epoch=414
06/01/2022 02:08:25 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.05 on epoch=417
06/01/2022 02:08:27 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.00 on epoch=419
06/01/2022 02:08:28 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.06 on epoch=422
06/01/2022 02:08:29 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.17 on epoch=424
06/01/2022 02:08:30 - INFO - __main__ - Global step 1700 Train loss 1.08 Classification-F1 0.1576923076923077 on epoch=424
06/01/2022 02:08:31 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.00 on epoch=427
06/01/2022 02:08:32 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.06 on epoch=429
06/01/2022 02:08:34 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.15 on epoch=432
06/01/2022 02:08:35 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.99 on epoch=434
06/01/2022 02:08:36 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.22 on epoch=437
06/01/2022 02:08:37 - INFO - __main__ - Global step 1750 Train loss 1.09 Classification-F1 0.18768328445747798 on epoch=437
06/01/2022 02:08:38 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.02 on epoch=439
06/01/2022 02:08:39 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.02 on epoch=442
06/01/2022 02:08:41 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.94 on epoch=444
06/01/2022 02:08:42 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.06 on epoch=447
06/01/2022 02:08:43 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.98 on epoch=449
06/01/2022 02:08:44 - INFO - __main__ - Global step 1800 Train loss 1.00 Classification-F1 0.14509803921568626 on epoch=449
06/01/2022 02:08:45 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.97 on epoch=452
06/01/2022 02:08:46 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.02 on epoch=454
06/01/2022 02:08:48 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.09 on epoch=457
06/01/2022 02:08:49 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.97 on epoch=459
06/01/2022 02:08:51 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.02 on epoch=462
06/01/2022 02:08:51 - INFO - __main__ - Global step 1850 Train loss 1.02 Classification-F1 0.10256410256410256 on epoch=462
06/01/2022 02:08:52 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.97 on epoch=464
06/01/2022 02:08:54 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.01 on epoch=467
06/01/2022 02:08:55 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.10 on epoch=469
06/01/2022 02:08:56 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.93 on epoch=472
06/01/2022 02:08:58 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.92 on epoch=474
06/01/2022 02:08:58 - INFO - __main__ - Global step 1900 Train loss 0.99 Classification-F1 0.21061869240895126 on epoch=474
06/01/2022 02:09:00 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.12 on epoch=477
06/01/2022 02:09:01 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.92 on epoch=479
06/01/2022 02:09:02 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.05 on epoch=482
06/01/2022 02:09:03 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.93 on epoch=484
06/01/2022 02:09:05 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.00 on epoch=487
06/01/2022 02:09:05 - INFO - __main__ - Global step 1950 Train loss 1.01 Classification-F1 0.20329670329670332 on epoch=487
06/01/2022 02:09:07 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.93 on epoch=489
06/01/2022 02:09:08 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.08 on epoch=492
06/01/2022 02:09:09 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.00 on epoch=494
06/01/2022 02:09:11 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.01 on epoch=497
06/01/2022 02:09:12 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.15 on epoch=499
06/01/2022 02:09:12 - INFO - __main__ - Global step 2000 Train loss 1.04 Classification-F1 0.21862787668258793 on epoch=499
06/01/2022 02:09:14 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.99 on epoch=502
06/01/2022 02:09:15 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.91 on epoch=504
06/01/2022 02:09:16 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.06 on epoch=507
06/01/2022 02:09:18 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.08 on epoch=509
06/01/2022 02:09:19 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.02 on epoch=512
06/01/2022 02:09:20 - INFO - __main__ - Global step 2050 Train loss 1.01 Classification-F1 0.1569691706469822 on epoch=512
06/01/2022 02:09:21 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.06 on epoch=514
06/01/2022 02:09:22 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.06 on epoch=517
06/01/2022 02:09:24 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.98 on epoch=519
06/01/2022 02:09:25 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.99 on epoch=522
06/01/2022 02:09:26 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.99 on epoch=524
06/01/2022 02:09:27 - INFO - __main__ - Global step 2100 Train loss 1.02 Classification-F1 0.17521739130434785 on epoch=524
06/01/2022 02:09:28 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.87 on epoch=527
06/01/2022 02:09:29 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.95 on epoch=529
06/01/2022 02:09:31 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.12 on epoch=532
06/01/2022 02:09:32 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.07 on epoch=534
06/01/2022 02:09:33 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.13 on epoch=537
06/01/2022 02:09:34 - INFO - __main__ - Global step 2150 Train loss 1.03 Classification-F1 0.09615384615384615 on epoch=537
06/01/2022 02:09:35 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.03 on epoch=539
06/01/2022 02:09:36 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.97 on epoch=542
06/01/2022 02:09:38 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.97 on epoch=544
06/01/2022 02:09:39 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.05 on epoch=547
06/01/2022 02:09:40 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.95 on epoch=549
06/01/2022 02:09:41 - INFO - __main__ - Global step 2200 Train loss 0.99 Classification-F1 0.1237183868762816 on epoch=549
06/01/2022 02:09:42 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.00 on epoch=552
06/01/2022 02:09:43 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.97 on epoch=554
06/01/2022 02:09:45 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.00 on epoch=557
06/01/2022 02:09:46 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.89 on epoch=559
06/01/2022 02:09:47 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.00 on epoch=562
06/01/2022 02:09:48 - INFO - __main__ - Global step 2250 Train loss 0.97 Classification-F1 0.13034188034188032 on epoch=562
06/01/2022 02:09:49 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.05 on epoch=564
06/01/2022 02:09:50 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.04 on epoch=567
06/01/2022 02:09:52 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.97 on epoch=569
06/01/2022 02:09:53 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.12 on epoch=572
06/01/2022 02:09:54 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.99 on epoch=574
06/01/2022 02:09:55 - INFO - __main__ - Global step 2300 Train loss 1.03 Classification-F1 0.10389610389610389 on epoch=574
06/01/2022 02:09:56 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.07 on epoch=577
06/01/2022 02:09:57 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.93 on epoch=579
06/01/2022 02:09:58 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.97 on epoch=582
06/01/2022 02:10:00 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.93 on epoch=584
06/01/2022 02:10:01 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.01 on epoch=587
06/01/2022 02:10:02 - INFO - __main__ - Global step 2350 Train loss 0.98 Classification-F1 0.20923520923520922 on epoch=587
06/01/2022 02:10:03 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.93 on epoch=589
06/01/2022 02:10:04 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.92 on epoch=592
06/01/2022 02:10:05 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.02 on epoch=594
06/01/2022 02:10:07 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.98 on epoch=597
06/01/2022 02:10:08 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.03 on epoch=599
06/01/2022 02:10:08 - INFO - __main__ - Global step 2400 Train loss 0.98 Classification-F1 0.20923520923520922 on epoch=599
06/01/2022 02:10:10 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.05 on epoch=602
06/01/2022 02:10:11 - INFO - __main__ - Step 2420 Global step 2420 Train loss 1.04 on epoch=604
06/01/2022 02:10:12 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.96 on epoch=607
06/01/2022 02:10:13 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.86 on epoch=609
06/01/2022 02:10:15 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.90 on epoch=612
06/01/2022 02:10:15 - INFO - __main__ - Global step 2450 Train loss 0.96 Classification-F1 0.1762749445676275 on epoch=612
06/01/2022 02:10:16 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.98 on epoch=614
06/01/2022 02:10:18 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.88 on epoch=617
06/01/2022 02:10:19 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.06 on epoch=619
06/01/2022 02:10:20 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.95 on epoch=622
06/01/2022 02:10:21 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.94 on epoch=624
06/01/2022 02:10:22 - INFO - __main__ - Global step 2500 Train loss 0.96 Classification-F1 0.17552334943639292 on epoch=624
06/01/2022 02:10:23 - INFO - __main__ - Step 2510 Global step 2510 Train loss 1.06 on epoch=627
06/01/2022 02:10:24 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.89 on epoch=629
06/01/2022 02:10:26 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.08 on epoch=632
06/01/2022 02:10:27 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.95 on epoch=634
06/01/2022 02:10:28 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.99 on epoch=637
06/01/2022 02:10:29 - INFO - __main__ - Global step 2550 Train loss 0.99 Classification-F1 0.11859154929577466 on epoch=637
06/01/2022 02:10:30 - INFO - __main__ - Step 2560 Global step 2560 Train loss 1.04 on epoch=639
06/01/2022 02:10:31 - INFO - __main__ - Step 2570 Global step 2570 Train loss 1.00 on epoch=642
06/01/2022 02:10:33 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.89 on epoch=644
06/01/2022 02:10:34 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.01 on epoch=647
06/01/2022 02:10:35 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.99 on epoch=649
06/01/2022 02:10:36 - INFO - __main__ - Global step 2600 Train loss 0.98 Classification-F1 0.1 on epoch=649
06/01/2022 02:10:37 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.98 on epoch=652
06/01/2022 02:10:38 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.92 on epoch=654
06/01/2022 02:10:39 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.98 on epoch=657
06/01/2022 02:10:41 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.93 on epoch=659
06/01/2022 02:10:42 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.12 on epoch=662
06/01/2022 02:10:42 - INFO - __main__ - Global step 2650 Train loss 0.99 Classification-F1 0.10126582278481013 on epoch=662
06/01/2022 02:10:44 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.94 on epoch=664
06/01/2022 02:10:45 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.97 on epoch=667
06/01/2022 02:10:46 - INFO - __main__ - Step 2680 Global step 2680 Train loss 1.02 on epoch=669
06/01/2022 02:10:48 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.91 on epoch=672
06/01/2022 02:10:49 - INFO - __main__ - Step 2700 Global step 2700 Train loss 1.05 on epoch=674
06/01/2022 02:10:49 - INFO - __main__ - Global step 2700 Train loss 0.98 Classification-F1 0.1388888888888889 on epoch=674
06/01/2022 02:10:51 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.01 on epoch=677
06/01/2022 02:10:52 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.94 on epoch=679
06/01/2022 02:10:53 - INFO - __main__ - Step 2730 Global step 2730 Train loss 1.01 on epoch=682
06/01/2022 02:10:54 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.92 on epoch=684
06/01/2022 02:10:56 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.88 on epoch=687
06/01/2022 02:10:56 - INFO - __main__ - Global step 2750 Train loss 0.95 Classification-F1 0.22186932849364793 on epoch=687
06/01/2022 02:10:56 - INFO - __main__ - Saving model with best Classification-F1: 0.2206477732793522 -> 0.22186932849364793 on epoch=687, global_step=2750
06/01/2022 02:10:58 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.92 on epoch=689
06/01/2022 02:10:59 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.92 on epoch=692
06/01/2022 02:11:00 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.98 on epoch=694
06/01/2022 02:11:01 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.91 on epoch=697
06/01/2022 02:11:03 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.91 on epoch=699
06/01/2022 02:11:03 - INFO - __main__ - Global step 2800 Train loss 0.93 Classification-F1 0.13067758749069247 on epoch=699
06/01/2022 02:11:04 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.93 on epoch=702
06/01/2022 02:11:06 - INFO - __main__ - Step 2820 Global step 2820 Train loss 1.01 on epoch=704
06/01/2022 02:11:07 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.97 on epoch=707
06/01/2022 02:11:08 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.95 on epoch=709
06/01/2022 02:11:10 - INFO - __main__ - Step 2850 Global step 2850 Train loss 1.02 on epoch=712
06/01/2022 02:11:10 - INFO - __main__ - Global step 2850 Train loss 0.98 Classification-F1 0.11805555555555555 on epoch=712
06/01/2022 02:11:11 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.92 on epoch=714
06/01/2022 02:11:13 - INFO - __main__ - Step 2870 Global step 2870 Train loss 1.04 on epoch=717
06/01/2022 02:11:14 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.95 on epoch=719
06/01/2022 02:11:15 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.97 on epoch=722
06/01/2022 02:11:17 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.98 on epoch=724
06/01/2022 02:11:17 - INFO - __main__ - Global step 2900 Train loss 0.97 Classification-F1 0.13067758749069247 on epoch=724
06/01/2022 02:11:18 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.04 on epoch=727
06/01/2022 02:11:20 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.93 on epoch=729
06/01/2022 02:11:21 - INFO - __main__ - Step 2930 Global step 2930 Train loss 1.00 on epoch=732
06/01/2022 02:11:22 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.92 on epoch=734
06/01/2022 02:11:23 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.94 on epoch=737
06/01/2022 02:11:24 - INFO - __main__ - Global step 2950 Train loss 0.97 Classification-F1 0.1581196581196581 on epoch=737
06/01/2022 02:11:25 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.94 on epoch=739
06/01/2022 02:11:26 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.95 on epoch=742
06/01/2022 02:11:28 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.81 on epoch=744
06/01/2022 02:11:29 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.98 on epoch=747
06/01/2022 02:11:30 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.93 on epoch=749
06/01/2022 02:11:31 - INFO - __main__ - Global step 3000 Train loss 0.92 Classification-F1 0.1 on epoch=749
06/01/2022 02:11:31 - INFO - __main__ - save last model!
06/01/2022 02:11:31 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/01/2022 02:11:31 - INFO - __main__ - Start tokenizing ... 5509 instances
06/01/2022 02:11:31 - INFO - __main__ - Printing 3 examples
06/01/2022 02:11:31 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/01/2022 02:11:31 - INFO - __main__ - ['others']
06/01/2022 02:11:31 - INFO - __main__ -  [emo] what you like very little things ok
06/01/2022 02:11:31 - INFO - __main__ - ['others']
06/01/2022 02:11:31 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/01/2022 02:11:31 - INFO - __main__ - ['others']
06/01/2022 02:11:31 - INFO - __main__ - Tokenizing Input ...
06/01/2022 02:11:31 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 02:11:31 - INFO - __main__ - Printing 3 examples
06/01/2022 02:11:31 - INFO - __main__ -  [emo] how cause yes am listening
06/01/2022 02:11:31 - INFO - __main__ - ['others']
06/01/2022 02:11:31 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/01/2022 02:11:31 - INFO - __main__ - ['others']
06/01/2022 02:11:31 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/01/2022 02:11:31 - INFO - __main__ - ['others']
06/01/2022 02:11:31 - INFO - __main__ - Tokenizing Input ...
06/01/2022 02:11:31 - INFO - __main__ - Tokenizing Output ...
06/01/2022 02:11:31 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 02:11:31 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 02:11:31 - INFO - __main__ - Printing 3 examples
06/01/2022 02:11:31 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
06/01/2022 02:11:31 - INFO - __main__ - ['others']
06/01/2022 02:11:31 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
06/01/2022 02:11:31 - INFO - __main__ - ['others']
06/01/2022 02:11:31 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
06/01/2022 02:11:31 - INFO - __main__ - ['others']
06/01/2022 02:11:31 - INFO - __main__ - Tokenizing Input ...
06/01/2022 02:11:31 - INFO - __main__ - Tokenizing Output ...
06/01/2022 02:11:32 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 02:11:33 - INFO - __main__ - Tokenizing Output ...
06/01/2022 02:11:38 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 02:11:38 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/01/2022 02:11:38 - INFO - __main__ - Starting training!
06/01/2022 02:11:38 - INFO - __main__ - Loaded 5509 examples from test data
06/01/2022 02:12:22 - INFO - __main__ - Saved prediction in models/T5-base-reptile-cls2cls-3e-5-2-5000-5e-1-10/singletask-emo/emo_16_100_0.5_8_predictions.txt
06/01/2022 02:12:22 - INFO - __main__ - Classification-F1 on test data: 0.0216
06/01/2022 02:12:22 - INFO - __main__ - prefix=emo_16_100, lr=0.5, bsz=8, dev_performance=0.22186932849364793, test_performance=0.021633362293657688
06/01/2022 02:12:22 - INFO - __main__ - Running ... prefix=emo_16_100, lr=0.4, bsz=8 ...
06/01/2022 02:12:23 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 02:12:23 - INFO - __main__ - Printing 3 examples
06/01/2022 02:12:23 - INFO - __main__ -  [emo] how cause yes am listening
06/01/2022 02:12:23 - INFO - __main__ - ['others']
06/01/2022 02:12:23 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/01/2022 02:12:23 - INFO - __main__ - ['others']
06/01/2022 02:12:23 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/01/2022 02:12:23 - INFO - __main__ - ['others']
06/01/2022 02:12:23 - INFO - __main__ - Tokenizing Input ...
06/01/2022 02:12:23 - INFO - __main__ - Tokenizing Output ...
06/01/2022 02:12:23 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 02:12:23 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 02:12:23 - INFO - __main__ - Printing 3 examples
06/01/2022 02:12:23 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
06/01/2022 02:12:23 - INFO - __main__ - ['others']
06/01/2022 02:12:23 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
06/01/2022 02:12:23 - INFO - __main__ - ['others']
06/01/2022 02:12:23 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
06/01/2022 02:12:23 - INFO - __main__ - ['others']
06/01/2022 02:12:23 - INFO - __main__ - Tokenizing Input ...
06/01/2022 02:12:23 - INFO - __main__ - Tokenizing Output ...
06/01/2022 02:12:23 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 02:12:29 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 02:12:29 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/01/2022 02:12:29 - INFO - __main__ - Starting training!
06/01/2022 02:12:31 - INFO - __main__ - Step 10 Global step 10 Train loss 8.94 on epoch=2
06/01/2022 02:12:32 - INFO - __main__ - Step 20 Global step 20 Train loss 8.99 on epoch=4
06/01/2022 02:12:33 - INFO - __main__ - Step 30 Global step 30 Train loss 8.91 on epoch=7
06/01/2022 02:12:34 - INFO - __main__ - Step 40 Global step 40 Train loss 8.93 on epoch=9
06/01/2022 02:12:36 - INFO - __main__ - Step 50 Global step 50 Train loss 8.84 on epoch=12
06/01/2022 02:12:42 - INFO - __main__ - Global step 50 Train loss 8.92 Classification-F1 0.0 on epoch=12
06/01/2022 02:12:42 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
06/01/2022 02:12:43 - INFO - __main__ - Step 60 Global step 60 Train loss 8.89 on epoch=14
06/01/2022 02:12:44 - INFO - __main__ - Step 70 Global step 70 Train loss 8.78 on epoch=17
06/01/2022 02:12:45 - INFO - __main__ - Step 80 Global step 80 Train loss 8.65 on epoch=19
06/01/2022 02:12:47 - INFO - __main__ - Step 90 Global step 90 Train loss 8.67 on epoch=22
06/01/2022 02:12:48 - INFO - __main__ - Step 100 Global step 100 Train loss 8.58 on epoch=24
06/01/2022 02:12:53 - INFO - __main__ - Global step 100 Train loss 8.71 Classification-F1 0.0 on epoch=24
06/01/2022 02:12:54 - INFO - __main__ - Step 110 Global step 110 Train loss 8.55 on epoch=27
06/01/2022 02:12:55 - INFO - __main__ - Step 120 Global step 120 Train loss 8.49 on epoch=29
06/01/2022 02:12:57 - INFO - __main__ - Step 130 Global step 130 Train loss 8.27 on epoch=32
06/01/2022 02:12:58 - INFO - __main__ - Step 140 Global step 140 Train loss 8.08 on epoch=34
06/01/2022 02:12:59 - INFO - __main__ - Step 150 Global step 150 Train loss 8.02 on epoch=37
06/01/2022 02:13:19 - INFO - __main__ - Global step 150 Train loss 8.28 Classification-F1 0.0 on epoch=37
06/01/2022 02:13:20 - INFO - __main__ - Step 160 Global step 160 Train loss 7.86 on epoch=39
06/01/2022 02:13:22 - INFO - __main__ - Step 170 Global step 170 Train loss 7.72 on epoch=42
06/01/2022 02:13:23 - INFO - __main__ - Step 180 Global step 180 Train loss 7.65 on epoch=44
06/01/2022 02:13:24 - INFO - __main__ - Step 190 Global step 190 Train loss 7.34 on epoch=47
06/01/2022 02:13:25 - INFO - __main__ - Step 200 Global step 200 Train loss 7.17 on epoch=49
06/01/2022 02:13:29 - INFO - __main__ - Global step 200 Train loss 7.55 Classification-F1 0.0 on epoch=49
06/01/2022 02:13:30 - INFO - __main__ - Step 210 Global step 210 Train loss 7.08 on epoch=52
06/01/2022 02:13:32 - INFO - __main__ - Step 220 Global step 220 Train loss 7.15 on epoch=54
06/01/2022 02:13:33 - INFO - __main__ - Step 230 Global step 230 Train loss 6.78 on epoch=57
06/01/2022 02:13:34 - INFO - __main__ - Step 240 Global step 240 Train loss 6.61 on epoch=59
06/01/2022 02:13:35 - INFO - __main__ - Step 250 Global step 250 Train loss 6.60 on epoch=62
06/01/2022 02:13:39 - INFO - __main__ - Global step 250 Train loss 6.84 Classification-F1 0.0 on epoch=62
06/01/2022 02:13:40 - INFO - __main__ - Step 260 Global step 260 Train loss 6.37 on epoch=64
06/01/2022 02:13:41 - INFO - __main__ - Step 270 Global step 270 Train loss 6.26 on epoch=67
06/01/2022 02:13:43 - INFO - __main__ - Step 280 Global step 280 Train loss 5.78 on epoch=69
06/01/2022 02:13:44 - INFO - __main__ - Step 290 Global step 290 Train loss 5.84 on epoch=72
06/01/2022 02:13:45 - INFO - __main__ - Step 300 Global step 300 Train loss 5.53 on epoch=74
06/01/2022 02:13:49 - INFO - __main__ - Global step 300 Train loss 5.96 Classification-F1 0.0 on epoch=74
06/01/2022 02:13:50 - INFO - __main__ - Step 310 Global step 310 Train loss 5.37 on epoch=77
06/01/2022 02:13:51 - INFO - __main__ - Step 320 Global step 320 Train loss 5.45 on epoch=79
06/01/2022 02:13:53 - INFO - __main__ - Step 330 Global step 330 Train loss 4.96 on epoch=82
06/01/2022 02:13:54 - INFO - __main__ - Step 340 Global step 340 Train loss 4.90 on epoch=84
06/01/2022 02:13:55 - INFO - __main__ - Step 350 Global step 350 Train loss 4.84 on epoch=87
06/01/2022 02:14:04 - INFO - __main__ - Global step 350 Train loss 5.10 Classification-F1 0.0 on epoch=87
06/01/2022 02:14:05 - INFO - __main__ - Step 360 Global step 360 Train loss 4.57 on epoch=89
06/01/2022 02:14:06 - INFO - __main__ - Step 370 Global step 370 Train loss 4.74 on epoch=92
06/01/2022 02:14:08 - INFO - __main__ - Step 380 Global step 380 Train loss 4.60 on epoch=94
06/01/2022 02:14:09 - INFO - __main__ - Step 390 Global step 390 Train loss 4.73 on epoch=97
06/01/2022 02:14:10 - INFO - __main__ - Step 400 Global step 400 Train loss 4.45 on epoch=99
06/01/2022 02:14:16 - INFO - __main__ - Global step 400 Train loss 4.62 Classification-F1 0.0 on epoch=99
06/01/2022 02:14:17 - INFO - __main__ - Step 410 Global step 410 Train loss 4.43 on epoch=102
06/01/2022 02:14:18 - INFO - __main__ - Step 420 Global step 420 Train loss 4.12 on epoch=104
06/01/2022 02:14:20 - INFO - __main__ - Step 430 Global step 430 Train loss 4.11 on epoch=107
06/01/2022 02:14:21 - INFO - __main__ - Step 440 Global step 440 Train loss 3.99 on epoch=109
06/01/2022 02:14:22 - INFO - __main__ - Step 450 Global step 450 Train loss 4.11 on epoch=112
06/01/2022 02:14:26 - INFO - __main__ - Global step 450 Train loss 4.15 Classification-F1 0.0 on epoch=112
06/01/2022 02:14:28 - INFO - __main__ - Step 460 Global step 460 Train loss 3.70 on epoch=114
06/01/2022 02:14:29 - INFO - __main__ - Step 470 Global step 470 Train loss 3.85 on epoch=117
06/01/2022 02:14:30 - INFO - __main__ - Step 480 Global step 480 Train loss 3.72 on epoch=119
06/01/2022 02:14:31 - INFO - __main__ - Step 490 Global step 490 Train loss 3.64 on epoch=122
06/01/2022 02:14:33 - INFO - __main__ - Step 500 Global step 500 Train loss 3.51 on epoch=124
06/01/2022 02:14:37 - INFO - __main__ - Global step 500 Train loss 3.68 Classification-F1 0.0 on epoch=124
06/01/2022 02:14:38 - INFO - __main__ - Step 510 Global step 510 Train loss 3.48 on epoch=127
06/01/2022 02:14:40 - INFO - __main__ - Step 520 Global step 520 Train loss 3.34 on epoch=129
06/01/2022 02:14:41 - INFO - __main__ - Step 530 Global step 530 Train loss 3.50 on epoch=132
06/01/2022 02:14:42 - INFO - __main__ - Step 540 Global step 540 Train loss 3.38 on epoch=134
06/01/2022 02:14:43 - INFO - __main__ - Step 550 Global step 550 Train loss 3.21 on epoch=137
06/01/2022 02:14:44 - INFO - __main__ - Global step 550 Train loss 3.38 Classification-F1 0.10126582278481013 on epoch=137
06/01/2022 02:14:44 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.10126582278481013 on epoch=137, global_step=550
06/01/2022 02:14:45 - INFO - __main__ - Step 560 Global step 560 Train loss 3.02 on epoch=139
06/01/2022 02:14:47 - INFO - __main__ - Step 570 Global step 570 Train loss 3.33 on epoch=142
06/01/2022 02:14:48 - INFO - __main__ - Step 580 Global step 580 Train loss 2.88 on epoch=144
06/01/2022 02:14:49 - INFO - __main__ - Step 590 Global step 590 Train loss 2.93 on epoch=147
06/01/2022 02:14:50 - INFO - __main__ - Step 600 Global step 600 Train loss 2.80 on epoch=149
06/01/2022 02:14:55 - INFO - __main__ - Global step 600 Train loss 2.99 Classification-F1 0.17857142857142858 on epoch=149
06/01/2022 02:14:55 - INFO - __main__ - Saving model with best Classification-F1: 0.10126582278481013 -> 0.17857142857142858 on epoch=149, global_step=600
06/01/2022 02:14:56 - INFO - __main__ - Step 610 Global step 610 Train loss 2.78 on epoch=152
06/01/2022 02:14:57 - INFO - __main__ - Step 620 Global step 620 Train loss 2.52 on epoch=154
06/01/2022 02:14:58 - INFO - __main__ - Step 630 Global step 630 Train loss 2.82 on epoch=157
06/01/2022 02:15:00 - INFO - __main__ - Step 640 Global step 640 Train loss 2.44 on epoch=159
06/01/2022 02:15:01 - INFO - __main__ - Step 650 Global step 650 Train loss 2.51 on epoch=162
06/01/2022 02:15:01 - INFO - __main__ - Global step 650 Train loss 2.61 Classification-F1 0.18623481781376516 on epoch=162
06/01/2022 02:15:02 - INFO - __main__ - Saving model with best Classification-F1: 0.17857142857142858 -> 0.18623481781376516 on epoch=162, global_step=650
06/01/2022 02:15:03 - INFO - __main__ - Step 660 Global step 660 Train loss 2.39 on epoch=164
06/01/2022 02:15:04 - INFO - __main__ - Step 670 Global step 670 Train loss 2.30 on epoch=167
06/01/2022 02:15:05 - INFO - __main__ - Step 680 Global step 680 Train loss 2.26 on epoch=169
06/01/2022 02:15:06 - INFO - __main__ - Step 690 Global step 690 Train loss 2.32 on epoch=172
06/01/2022 02:15:08 - INFO - __main__ - Step 700 Global step 700 Train loss 2.02 on epoch=174
06/01/2022 02:15:08 - INFO - __main__ - Global step 700 Train loss 2.26 Classification-F1 0.1 on epoch=174
06/01/2022 02:15:09 - INFO - __main__ - Step 710 Global step 710 Train loss 2.26 on epoch=177
06/01/2022 02:15:11 - INFO - __main__ - Step 720 Global step 720 Train loss 2.01 on epoch=179
06/01/2022 02:15:12 - INFO - __main__ - Step 730 Global step 730 Train loss 1.90 on epoch=182
06/01/2022 02:15:13 - INFO - __main__ - Step 740 Global step 740 Train loss 2.00 on epoch=184
06/01/2022 02:15:14 - INFO - __main__ - Step 750 Global step 750 Train loss 1.95 on epoch=187
06/01/2022 02:15:15 - INFO - __main__ - Global step 750 Train loss 2.02 Classification-F1 0.1388888888888889 on epoch=187
06/01/2022 02:15:16 - INFO - __main__ - Step 760 Global step 760 Train loss 1.87 on epoch=189
06/01/2022 02:15:17 - INFO - __main__ - Step 770 Global step 770 Train loss 1.85 on epoch=192
06/01/2022 02:15:19 - INFO - __main__ - Step 780 Global step 780 Train loss 1.66 on epoch=194
06/01/2022 02:15:20 - INFO - __main__ - Step 790 Global step 790 Train loss 1.83 on epoch=197
06/01/2022 02:15:21 - INFO - __main__ - Step 800 Global step 800 Train loss 1.70 on epoch=199
06/01/2022 02:15:22 - INFO - __main__ - Global step 800 Train loss 1.78 Classification-F1 0.09493670886075949 on epoch=199
06/01/2022 02:15:23 - INFO - __main__ - Step 810 Global step 810 Train loss 1.69 on epoch=202
06/01/2022 02:15:24 - INFO - __main__ - Step 820 Global step 820 Train loss 1.78 on epoch=204
06/01/2022 02:15:25 - INFO - __main__ - Step 830 Global step 830 Train loss 1.60 on epoch=207
06/01/2022 02:15:27 - INFO - __main__ - Step 840 Global step 840 Train loss 1.46 on epoch=209
06/01/2022 02:15:28 - INFO - __main__ - Step 850 Global step 850 Train loss 1.59 on epoch=212
06/01/2022 02:15:28 - INFO - __main__ - Global step 850 Train loss 1.62 Classification-F1 0.13034188034188032 on epoch=212
06/01/2022 02:15:29 - INFO - __main__ - Step 860 Global step 860 Train loss 1.62 on epoch=214
06/01/2022 02:15:31 - INFO - __main__ - Step 870 Global step 870 Train loss 1.64 on epoch=217
06/01/2022 02:15:32 - INFO - __main__ - Step 880 Global step 880 Train loss 1.33 on epoch=219
06/01/2022 02:15:33 - INFO - __main__ - Step 890 Global step 890 Train loss 1.33 on epoch=222
06/01/2022 02:15:34 - INFO - __main__ - Step 900 Global step 900 Train loss 1.34 on epoch=224
06/01/2022 02:15:35 - INFO - __main__ - Global step 900 Train loss 1.45 Classification-F1 0.1 on epoch=224
06/01/2022 02:15:36 - INFO - __main__ - Step 910 Global step 910 Train loss 1.30 on epoch=227
06/01/2022 02:15:37 - INFO - __main__ - Step 920 Global step 920 Train loss 1.41 on epoch=229
06/01/2022 02:15:39 - INFO - __main__ - Step 930 Global step 930 Train loss 1.34 on epoch=232
06/01/2022 02:15:40 - INFO - __main__ - Step 940 Global step 940 Train loss 1.39 on epoch=234
06/01/2022 02:15:41 - INFO - __main__ - Step 950 Global step 950 Train loss 1.40 on epoch=237
06/01/2022 02:15:42 - INFO - __main__ - Global step 950 Train loss 1.37 Classification-F1 0.15966386554621848 on epoch=237
06/01/2022 02:15:43 - INFO - __main__ - Step 960 Global step 960 Train loss 1.33 on epoch=239
06/01/2022 02:15:44 - INFO - __main__ - Step 970 Global step 970 Train loss 1.93 on epoch=242
06/01/2022 02:15:45 - INFO - __main__ - Step 980 Global step 980 Train loss 1.27 on epoch=244
06/01/2022 02:15:47 - INFO - __main__ - Step 990 Global step 990 Train loss 1.33 on epoch=247
06/01/2022 02:15:48 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.32 on epoch=249
06/01/2022 02:15:48 - INFO - __main__ - Global step 1000 Train loss 1.44 Classification-F1 0.1 on epoch=249
06/01/2022 02:15:50 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.37 on epoch=252
06/01/2022 02:15:51 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.18 on epoch=254
06/01/2022 02:15:52 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.33 on epoch=257
06/01/2022 02:15:53 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.44 on epoch=259
06/01/2022 02:15:55 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.31 on epoch=262
06/01/2022 02:15:55 - INFO - __main__ - Global step 1050 Train loss 1.33 Classification-F1 0.1569691706469822 on epoch=262
06/01/2022 02:15:56 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.14 on epoch=264
06/01/2022 02:15:58 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.23 on epoch=267
06/01/2022 02:15:59 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.32 on epoch=269
06/01/2022 02:16:00 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.23 on epoch=272
06/01/2022 02:16:01 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.27 on epoch=274
06/01/2022 02:16:02 - INFO - __main__ - Global step 1100 Train loss 1.24 Classification-F1 0.18181818181818182 on epoch=274
06/01/2022 02:16:03 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.19 on epoch=277
06/01/2022 02:16:04 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.15 on epoch=279
06/01/2022 02:16:06 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.13 on epoch=282
06/01/2022 02:16:07 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.25 on epoch=284
06/01/2022 02:16:08 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.20 on epoch=287
06/01/2022 02:16:09 - INFO - __main__ - Global step 1150 Train loss 1.18 Classification-F1 0.12368421052631579 on epoch=287
06/01/2022 02:16:10 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.17 on epoch=289
06/01/2022 02:16:11 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.18 on epoch=292
06/01/2022 02:16:12 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.16 on epoch=294
06/01/2022 02:16:14 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.11 on epoch=297
06/01/2022 02:16:15 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.11 on epoch=299
06/01/2022 02:16:15 - INFO - __main__ - Global step 1200 Train loss 1.15 Classification-F1 0.1883587427065688 on epoch=299
06/01/2022 02:16:15 - INFO - __main__ - Saving model with best Classification-F1: 0.18623481781376516 -> 0.1883587427065688 on epoch=299, global_step=1200
06/01/2022 02:16:17 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.19 on epoch=302
06/01/2022 02:16:18 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.14 on epoch=304
06/01/2022 02:16:19 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.20 on epoch=307
06/01/2022 02:16:20 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.25 on epoch=309
06/01/2022 02:16:22 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.12 on epoch=312
06/01/2022 02:16:22 - INFO - __main__ - Global step 1250 Train loss 1.18 Classification-F1 0.17162540691952458 on epoch=312
06/01/2022 02:16:23 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.14 on epoch=314
06/01/2022 02:16:25 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.11 on epoch=317
06/01/2022 02:16:26 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.16 on epoch=319
06/01/2022 02:16:27 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.18 on epoch=322
06/01/2022 02:16:28 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.22 on epoch=324
06/01/2022 02:16:29 - INFO - __main__ - Global step 1300 Train loss 1.16 Classification-F1 0.13067758749069247 on epoch=324
06/01/2022 02:16:30 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.01 on epoch=327
06/01/2022 02:16:31 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.15 on epoch=329
06/01/2022 02:16:33 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.01 on epoch=332
06/01/2022 02:16:34 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.14 on epoch=334
06/01/2022 02:16:35 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.12 on epoch=337
06/01/2022 02:16:36 - INFO - __main__ - Global step 1350 Train loss 1.09 Classification-F1 0.20189600927305845 on epoch=337
06/01/2022 02:16:36 - INFO - __main__ - Saving model with best Classification-F1: 0.1883587427065688 -> 0.20189600927305845 on epoch=337, global_step=1350
06/01/2022 02:16:37 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.15 on epoch=339
06/01/2022 02:16:38 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.11 on epoch=342
06/01/2022 02:16:39 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.01 on epoch=344
06/01/2022 02:16:41 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.07 on epoch=347
06/01/2022 02:16:42 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.18 on epoch=349
06/01/2022 02:16:42 - INFO - __main__ - Global step 1400 Train loss 1.10 Classification-F1 0.2069069069069069 on epoch=349
06/01/2022 02:16:42 - INFO - __main__ - Saving model with best Classification-F1: 0.20189600927305845 -> 0.2069069069069069 on epoch=349, global_step=1400
06/01/2022 02:16:44 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.13 on epoch=352
06/01/2022 02:16:45 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.98 on epoch=354
06/01/2022 02:16:46 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.14 on epoch=357
06/01/2022 02:16:47 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.96 on epoch=359
06/01/2022 02:16:49 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.13 on epoch=362
06/01/2022 02:16:49 - INFO - __main__ - Global step 1450 Train loss 1.07 Classification-F1 0.28793650793650793 on epoch=362
06/01/2022 02:16:49 - INFO - __main__ - Saving model with best Classification-F1: 0.2069069069069069 -> 0.28793650793650793 on epoch=362, global_step=1450
06/01/2022 02:16:50 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.05 on epoch=364
06/01/2022 02:16:52 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.09 on epoch=367
06/01/2022 02:16:53 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.00 on epoch=369
06/01/2022 02:16:54 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.05 on epoch=372
06/01/2022 02:16:56 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.14 on epoch=374
06/01/2022 02:16:56 - INFO - __main__ - Global step 1500 Train loss 1.07 Classification-F1 0.1 on epoch=374
06/01/2022 02:16:57 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.24 on epoch=377
06/01/2022 02:16:59 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.07 on epoch=379
06/01/2022 02:17:00 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.12 on epoch=382
06/01/2022 02:17:01 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.98 on epoch=384
06/01/2022 02:17:02 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.10 on epoch=387
06/01/2022 02:17:03 - INFO - __main__ - Global step 1550 Train loss 1.10 Classification-F1 0.11732186732186733 on epoch=387
06/01/2022 02:17:04 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.06 on epoch=389
06/01/2022 02:17:05 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.07 on epoch=392
06/01/2022 02:17:07 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.09 on epoch=394
06/01/2022 02:17:08 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.08 on epoch=397
06/01/2022 02:17:09 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.04 on epoch=399
06/01/2022 02:17:10 - INFO - __main__ - Global step 1600 Train loss 1.07 Classification-F1 0.1 on epoch=399
06/01/2022 02:17:11 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.04 on epoch=402
06/01/2022 02:17:12 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.04 on epoch=404
06/01/2022 02:17:14 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.16 on epoch=407
06/01/2022 02:17:15 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.22 on epoch=409
06/01/2022 02:17:16 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.01 on epoch=412
06/01/2022 02:17:16 - INFO - __main__ - Global step 1650 Train loss 1.09 Classification-F1 0.191533180778032 on epoch=412
06/01/2022 02:17:18 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.95 on epoch=414
06/01/2022 02:17:19 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.94 on epoch=417
06/01/2022 02:17:20 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.05 on epoch=419
06/01/2022 02:17:21 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.07 on epoch=422
06/01/2022 02:17:23 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.04 on epoch=424
06/01/2022 02:17:23 - INFO - __main__ - Global step 1700 Train loss 1.01 Classification-F1 0.1769230769230769 on epoch=424
06/01/2022 02:17:24 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.12 on epoch=427
06/01/2022 02:17:26 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.91 on epoch=429
06/01/2022 02:17:27 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.99 on epoch=432
06/01/2022 02:17:28 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.95 on epoch=434
06/01/2022 02:17:29 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.06 on epoch=437
06/01/2022 02:17:30 - INFO - __main__ - Global step 1750 Train loss 1.01 Classification-F1 0.13067758749069247 on epoch=437
06/01/2022 02:17:31 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.05 on epoch=439
06/01/2022 02:17:32 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.02 on epoch=442
06/01/2022 02:17:34 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.08 on epoch=444
06/01/2022 02:17:35 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.90 on epoch=447
06/01/2022 02:17:36 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.05 on epoch=449
06/01/2022 02:17:37 - INFO - __main__ - Global step 1800 Train loss 1.02 Classification-F1 0.1 on epoch=449
06/01/2022 02:17:38 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.16 on epoch=452
06/01/2022 02:17:39 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.03 on epoch=454
06/01/2022 02:17:41 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.97 on epoch=457
06/01/2022 02:17:42 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.06 on epoch=459
06/01/2022 02:17:43 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.03 on epoch=462
06/01/2022 02:17:44 - INFO - __main__ - Global step 1850 Train loss 1.05 Classification-F1 0.12407862407862408 on epoch=462
06/01/2022 02:17:45 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.12 on epoch=464
06/01/2022 02:17:46 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.02 on epoch=467
06/01/2022 02:17:47 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.97 on epoch=469
06/01/2022 02:17:49 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.08 on epoch=472
06/01/2022 02:17:50 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.07 on epoch=474
06/01/2022 02:17:50 - INFO - __main__ - Global step 1900 Train loss 1.05 Classification-F1 0.10126582278481013 on epoch=474
06/01/2022 02:17:52 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.08 on epoch=477
06/01/2022 02:17:53 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.98 on epoch=479
06/01/2022 02:17:54 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.00 on epoch=482
06/01/2022 02:17:55 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.93 on epoch=484
06/01/2022 02:17:57 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.05 on epoch=487
06/01/2022 02:17:57 - INFO - __main__ - Global step 1950 Train loss 1.01 Classification-F1 0.17552334943639292 on epoch=487
06/01/2022 02:17:58 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.97 on epoch=489
06/01/2022 02:18:00 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.91 on epoch=492
06/01/2022 02:18:01 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.06 on epoch=494
06/01/2022 02:18:02 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.08 on epoch=497
06/01/2022 02:18:03 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.09 on epoch=499
06/01/2022 02:18:04 - INFO - __main__ - Global step 2000 Train loss 1.02 Classification-F1 0.1476190476190476 on epoch=499
06/01/2022 02:18:05 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.99 on epoch=502
06/01/2022 02:18:06 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.00 on epoch=504
06/01/2022 02:18:08 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.02 on epoch=507
06/01/2022 02:18:09 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.99 on epoch=509
06/01/2022 02:18:10 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.95 on epoch=512
06/01/2022 02:18:11 - INFO - __main__ - Global step 2050 Train loss 0.99 Classification-F1 0.09868421052631579 on epoch=512
06/01/2022 02:18:12 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.05 on epoch=514
06/01/2022 02:18:13 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.02 on epoch=517
06/01/2022 02:18:15 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.99 on epoch=519
06/01/2022 02:18:16 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.04 on epoch=522
06/01/2022 02:18:17 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.03 on epoch=524
06/01/2022 02:18:18 - INFO - __main__ - Global step 2100 Train loss 1.03 Classification-F1 0.12499999999999999 on epoch=524
06/01/2022 02:18:19 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.90 on epoch=527
06/01/2022 02:18:20 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.03 on epoch=529
06/01/2022 02:18:21 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.05 on epoch=532
06/01/2022 02:18:23 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.96 on epoch=534
06/01/2022 02:18:24 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.90 on epoch=537
06/01/2022 02:18:25 - INFO - __main__ - Global step 2150 Train loss 0.97 Classification-F1 0.20146520146520144 on epoch=537
06/01/2022 02:18:26 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.91 on epoch=539
06/01/2022 02:18:27 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.01 on epoch=542
06/01/2022 02:18:28 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.01 on epoch=544
06/01/2022 02:18:30 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.98 on epoch=547
06/01/2022 02:18:31 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.98 on epoch=549
06/01/2022 02:18:31 - INFO - __main__ - Global step 2200 Train loss 0.98 Classification-F1 0.14583333333333331 on epoch=549
06/01/2022 02:18:33 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.00 on epoch=552
06/01/2022 02:18:34 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.10 on epoch=554
06/01/2022 02:18:35 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.07 on epoch=557
06/01/2022 02:18:37 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.97 on epoch=559
06/01/2022 02:18:38 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.98 on epoch=562
06/01/2022 02:18:38 - INFO - __main__ - Global step 2250 Train loss 1.02 Classification-F1 0.203125 on epoch=562
06/01/2022 02:18:40 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.91 on epoch=564
06/01/2022 02:18:41 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.90 on epoch=567
06/01/2022 02:18:42 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.95 on epoch=569
06/01/2022 02:18:43 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.97 on epoch=572
06/01/2022 02:18:44 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.95 on epoch=574
06/01/2022 02:18:45 - INFO - __main__ - Global step 2300 Train loss 0.94 Classification-F1 0.17517605633802816 on epoch=574
06/01/2022 02:18:46 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.01 on epoch=577
06/01/2022 02:18:47 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.95 on epoch=579
06/01/2022 02:18:49 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.95 on epoch=582
06/01/2022 02:18:50 - INFO - __main__ - Step 2340 Global step 2340 Train loss 1.01 on epoch=584
06/01/2022 02:18:51 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.99 on epoch=587
06/01/2022 02:18:52 - INFO - __main__ - Global step 2350 Train loss 0.98 Classification-F1 0.147459165154265 on epoch=587
06/01/2022 02:18:53 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.88 on epoch=589
06/01/2022 02:18:54 - INFO - __main__ - Step 2370 Global step 2370 Train loss 1.03 on epoch=592
06/01/2022 02:18:56 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.03 on epoch=594
06/01/2022 02:18:57 - INFO - __main__ - Step 2390 Global step 2390 Train loss 1.05 on epoch=597
06/01/2022 02:18:58 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.92 on epoch=599
06/01/2022 02:18:59 - INFO - __main__ - Global step 2400 Train loss 0.98 Classification-F1 0.20867208672086718 on epoch=599
06/01/2022 02:19:00 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.98 on epoch=602
06/01/2022 02:19:01 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.94 on epoch=604
06/01/2022 02:19:02 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.00 on epoch=607
06/01/2022 02:19:04 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.93 on epoch=609
06/01/2022 02:19:05 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.02 on epoch=612
06/01/2022 02:19:05 - INFO - __main__ - Global step 2450 Train loss 0.98 Classification-F1 0.19615384615384615 on epoch=612
06/01/2022 02:19:07 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.93 on epoch=614
06/01/2022 02:19:08 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.97 on epoch=617
06/01/2022 02:19:09 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.86 on epoch=619
06/01/2022 02:19:11 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.93 on epoch=622
06/01/2022 02:19:12 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.84 on epoch=624
06/01/2022 02:19:12 - INFO - __main__ - Global step 2500 Train loss 0.91 Classification-F1 0.19615384615384615 on epoch=624
06/01/2022 02:19:14 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.99 on epoch=627
06/01/2022 02:19:15 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.97 on epoch=629
06/01/2022 02:19:16 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.94 on epoch=632
06/01/2022 02:19:17 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.95 on epoch=634
06/01/2022 02:19:19 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.94 on epoch=637
06/01/2022 02:19:19 - INFO - __main__ - Global step 2550 Train loss 0.96 Classification-F1 0.125 on epoch=637
06/01/2022 02:19:20 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.97 on epoch=639
06/01/2022 02:19:22 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.89 on epoch=642
06/01/2022 02:19:23 - INFO - __main__ - Step 2580 Global step 2580 Train loss 1.04 on epoch=644
06/01/2022 02:19:24 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.03 on epoch=647
06/01/2022 02:19:25 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.98 on epoch=649
06/01/2022 02:19:26 - INFO - __main__ - Global step 2600 Train loss 0.98 Classification-F1 0.15584415584415584 on epoch=649
06/01/2022 02:19:27 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.98 on epoch=652
06/01/2022 02:19:29 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.95 on epoch=654
06/01/2022 02:19:30 - INFO - __main__ - Step 2630 Global step 2630 Train loss 1.03 on epoch=657
06/01/2022 02:19:31 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.90 on epoch=659
06/01/2022 02:19:32 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.01 on epoch=662
06/01/2022 02:19:33 - INFO - __main__ - Global step 2650 Train loss 0.97 Classification-F1 0.16370023419203747 on epoch=662
06/01/2022 02:19:34 - INFO - __main__ - Step 2660 Global step 2660 Train loss 1.01 on epoch=664
06/01/2022 02:19:35 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.94 on epoch=667
06/01/2022 02:19:37 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.93 on epoch=669
06/01/2022 02:19:38 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.93 on epoch=672
06/01/2022 02:19:39 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.89 on epoch=674
06/01/2022 02:19:40 - INFO - __main__ - Global step 2700 Train loss 0.94 Classification-F1 0.1472743930371049 on epoch=674
06/01/2022 02:19:41 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.00 on epoch=677
06/01/2022 02:19:42 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.86 on epoch=679
06/01/2022 02:19:43 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.93 on epoch=682
06/01/2022 02:19:45 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.95 on epoch=684
06/01/2022 02:19:46 - INFO - __main__ - Step 2750 Global step 2750 Train loss 1.03 on epoch=687
06/01/2022 02:19:46 - INFO - __main__ - Global step 2750 Train loss 0.95 Classification-F1 0.2602840909090909 on epoch=687
06/01/2022 02:19:48 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.00 on epoch=689
06/01/2022 02:19:49 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.93 on epoch=692
06/01/2022 02:19:50 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.89 on epoch=694
06/01/2022 02:19:51 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.93 on epoch=697
06/01/2022 02:19:53 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.88 on epoch=699
06/01/2022 02:19:53 - INFO - __main__ - Global step 2800 Train loss 0.93 Classification-F1 0.15526315789473685 on epoch=699
06/01/2022 02:19:54 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.95 on epoch=702
06/01/2022 02:19:56 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.97 on epoch=704
06/01/2022 02:19:57 - INFO - __main__ - Step 2830 Global step 2830 Train loss 1.00 on epoch=707
06/01/2022 02:19:58 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.98 on epoch=709
06/01/2022 02:19:59 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.91 on epoch=712
06/01/2022 02:20:00 - INFO - __main__ - Global step 2850 Train loss 0.96 Classification-F1 0.1 on epoch=712
06/01/2022 02:20:01 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.87 on epoch=714
06/01/2022 02:20:02 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.99 on epoch=717
06/01/2022 02:20:04 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.91 on epoch=719
06/01/2022 02:20:05 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.94 on epoch=722
06/01/2022 02:20:06 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.93 on epoch=724
06/01/2022 02:20:07 - INFO - __main__ - Global step 2900 Train loss 0.93 Classification-F1 0.140625 on epoch=724
06/01/2022 02:20:08 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.00 on epoch=727
06/01/2022 02:20:09 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.93 on epoch=729
06/01/2022 02:20:10 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.95 on epoch=732
06/01/2022 02:20:12 - INFO - __main__ - Step 2940 Global step 2940 Train loss 1.03 on epoch=734
06/01/2022 02:20:13 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.87 on epoch=737
06/01/2022 02:20:13 - INFO - __main__ - Global step 2950 Train loss 0.96 Classification-F1 0.13482414242292662 on epoch=737
06/01/2022 02:20:15 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.90 on epoch=739
06/01/2022 02:20:16 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.90 on epoch=742
06/01/2022 02:20:17 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.87 on epoch=744
06/01/2022 02:20:18 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.93 on epoch=747
06/01/2022 02:20:20 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.93 on epoch=749
06/01/2022 02:20:20 - INFO - __main__ - Global step 3000 Train loss 0.90 Classification-F1 0.17220843672456576 on epoch=749
06/01/2022 02:20:20 - INFO - __main__ - save last model!
06/01/2022 02:20:20 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/01/2022 02:20:20 - INFO - __main__ - Start tokenizing ... 5509 instances
06/01/2022 02:20:20 - INFO - __main__ - Printing 3 examples
06/01/2022 02:20:20 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/01/2022 02:20:20 - INFO - __main__ - ['others']
06/01/2022 02:20:20 - INFO - __main__ -  [emo] what you like very little things ok
06/01/2022 02:20:20 - INFO - __main__ - ['others']
06/01/2022 02:20:20 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/01/2022 02:20:20 - INFO - __main__ - ['others']
06/01/2022 02:20:20 - INFO - __main__ - Tokenizing Input ...
06/01/2022 02:20:21 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 02:20:21 - INFO - __main__ - Printing 3 examples
06/01/2022 02:20:21 - INFO - __main__ -  [emo] how cause yes am listening
06/01/2022 02:20:21 - INFO - __main__ - ['others']
06/01/2022 02:20:21 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/01/2022 02:20:21 - INFO - __main__ - ['others']
06/01/2022 02:20:21 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/01/2022 02:20:21 - INFO - __main__ - ['others']
06/01/2022 02:20:21 - INFO - __main__ - Tokenizing Input ...
06/01/2022 02:20:21 - INFO - __main__ - Tokenizing Output ...
06/01/2022 02:20:21 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 02:20:21 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 02:20:21 - INFO - __main__ - Printing 3 examples
06/01/2022 02:20:21 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
06/01/2022 02:20:21 - INFO - __main__ - ['others']
06/01/2022 02:20:21 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
06/01/2022 02:20:21 - INFO - __main__ - ['others']
06/01/2022 02:20:21 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
06/01/2022 02:20:21 - INFO - __main__ - ['others']
06/01/2022 02:20:21 - INFO - __main__ - Tokenizing Input ...
06/01/2022 02:20:21 - INFO - __main__ - Tokenizing Output ...
06/01/2022 02:20:21 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 02:20:22 - INFO - __main__ - Tokenizing Output ...
06/01/2022 02:20:27 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 02:20:27 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/01/2022 02:20:27 - INFO - __main__ - Starting training!
06/01/2022 02:20:28 - INFO - __main__ - Loaded 5509 examples from test data
06/01/2022 02:21:11 - INFO - __main__ - Saved prediction in models/T5-base-reptile-cls2cls-3e-5-2-5000-5e-1-10/singletask-emo/emo_16_100_0.4_8_predictions.txt
06/01/2022 02:21:11 - INFO - __main__ - Classification-F1 on test data: 0.0455
06/01/2022 02:21:11 - INFO - __main__ - prefix=emo_16_100, lr=0.4, bsz=8, dev_performance=0.28793650793650793, test_performance=0.04551121600250527
06/01/2022 02:21:11 - INFO - __main__ - Running ... prefix=emo_16_100, lr=0.3, bsz=8 ...
06/01/2022 02:21:12 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 02:21:12 - INFO - __main__ - Printing 3 examples
06/01/2022 02:21:12 - INFO - __main__ -  [emo] how cause yes am listening
06/01/2022 02:21:12 - INFO - __main__ - ['others']
06/01/2022 02:21:12 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/01/2022 02:21:12 - INFO - __main__ - ['others']
06/01/2022 02:21:12 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/01/2022 02:21:12 - INFO - __main__ - ['others']
06/01/2022 02:21:12 - INFO - __main__ - Tokenizing Input ...
06/01/2022 02:21:12 - INFO - __main__ - Tokenizing Output ...
06/01/2022 02:21:12 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 02:21:12 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 02:21:12 - INFO - __main__ - Printing 3 examples
06/01/2022 02:21:12 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
06/01/2022 02:21:12 - INFO - __main__ - ['others']
06/01/2022 02:21:12 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
06/01/2022 02:21:12 - INFO - __main__ - ['others']
06/01/2022 02:21:12 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
06/01/2022 02:21:12 - INFO - __main__ - ['others']
06/01/2022 02:21:12 - INFO - __main__ - Tokenizing Input ...
06/01/2022 02:21:12 - INFO - __main__ - Tokenizing Output ...
06/01/2022 02:21:12 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 02:21:18 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 02:21:18 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/01/2022 02:21:18 - INFO - __main__ - Starting training!
06/01/2022 02:21:20 - INFO - __main__ - Step 10 Global step 10 Train loss 9.04 on epoch=2
06/01/2022 02:21:21 - INFO - __main__ - Step 20 Global step 20 Train loss 9.09 on epoch=4
06/01/2022 02:21:22 - INFO - __main__ - Step 30 Global step 30 Train loss 8.98 on epoch=7
06/01/2022 02:21:24 - INFO - __main__ - Step 40 Global step 40 Train loss 9.01 on epoch=9
06/01/2022 02:21:25 - INFO - __main__ - Step 50 Global step 50 Train loss 8.75 on epoch=12
06/01/2022 02:21:30 - INFO - __main__ - Global step 50 Train loss 8.97 Classification-F1 0.0 on epoch=12
06/01/2022 02:21:30 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
06/01/2022 02:21:32 - INFO - __main__ - Step 60 Global step 60 Train loss 8.91 on epoch=14
06/01/2022 02:21:33 - INFO - __main__ - Step 70 Global step 70 Train loss 8.86 on epoch=17
06/01/2022 02:21:34 - INFO - __main__ - Step 80 Global step 80 Train loss 8.85 on epoch=19
06/01/2022 02:21:35 - INFO - __main__ - Step 90 Global step 90 Train loss 8.80 on epoch=22
06/01/2022 02:21:37 - INFO - __main__ - Step 100 Global step 100 Train loss 8.79 on epoch=24
06/01/2022 02:21:44 - INFO - __main__ - Global step 100 Train loss 8.84 Classification-F1 0.0 on epoch=24
06/01/2022 02:21:45 - INFO - __main__ - Step 110 Global step 110 Train loss 8.67 on epoch=27
06/01/2022 02:21:47 - INFO - __main__ - Step 120 Global step 120 Train loss 8.67 on epoch=29
06/01/2022 02:21:48 - INFO - __main__ - Step 130 Global step 130 Train loss 8.55 on epoch=32
06/01/2022 02:21:49 - INFO - __main__ - Step 140 Global step 140 Train loss 8.56 on epoch=34
06/01/2022 02:21:50 - INFO - __main__ - Step 150 Global step 150 Train loss 8.62 on epoch=37
06/01/2022 02:21:57 - INFO - __main__ - Global step 150 Train loss 8.61 Classification-F1 0.0 on epoch=37
06/01/2022 02:21:59 - INFO - __main__ - Step 160 Global step 160 Train loss 8.46 on epoch=39
06/01/2022 02:22:00 - INFO - __main__ - Step 170 Global step 170 Train loss 8.38 on epoch=42
06/01/2022 02:22:01 - INFO - __main__ - Step 180 Global step 180 Train loss 8.27 on epoch=44
06/01/2022 02:22:03 - INFO - __main__ - Step 190 Global step 190 Train loss 8.12 on epoch=47
06/01/2022 02:22:04 - INFO - __main__ - Step 200 Global step 200 Train loss 8.02 on epoch=49
06/01/2022 02:22:16 - INFO - __main__ - Global step 200 Train loss 8.25 Classification-F1 0.0 on epoch=49
06/01/2022 02:22:17 - INFO - __main__ - Step 210 Global step 210 Train loss 8.08 on epoch=52
06/01/2022 02:22:18 - INFO - __main__ - Step 220 Global step 220 Train loss 7.79 on epoch=54
06/01/2022 02:22:20 - INFO - __main__ - Step 230 Global step 230 Train loss 7.63 on epoch=57
06/01/2022 02:22:21 - INFO - __main__ - Step 240 Global step 240 Train loss 7.66 on epoch=59
06/01/2022 02:22:22 - INFO - __main__ - Step 250 Global step 250 Train loss 7.34 on epoch=62
06/01/2022 02:22:35 - INFO - __main__ - Global step 250 Train loss 7.70 Classification-F1 0.0 on epoch=62
06/01/2022 02:22:36 - INFO - __main__ - Step 260 Global step 260 Train loss 7.44 on epoch=64
06/01/2022 02:22:37 - INFO - __main__ - Step 270 Global step 270 Train loss 7.35 on epoch=67
06/01/2022 02:22:38 - INFO - __main__ - Step 280 Global step 280 Train loss 7.19 on epoch=69
06/01/2022 02:22:40 - INFO - __main__ - Step 290 Global step 290 Train loss 7.14 on epoch=72
06/01/2022 02:22:41 - INFO - __main__ - Step 300 Global step 300 Train loss 6.90 on epoch=74
06/01/2022 02:22:49 - INFO - __main__ - Global step 300 Train loss 7.21 Classification-F1 0.0 on epoch=74
06/01/2022 02:22:51 - INFO - __main__ - Step 310 Global step 310 Train loss 6.90 on epoch=77
06/01/2022 02:22:52 - INFO - __main__ - Step 320 Global step 320 Train loss 6.83 on epoch=79
06/01/2022 02:22:54 - INFO - __main__ - Step 330 Global step 330 Train loss 6.69 on epoch=82
06/01/2022 02:22:56 - INFO - __main__ - Step 340 Global step 340 Train loss 6.69 on epoch=84
06/01/2022 02:22:57 - INFO - __main__ - Step 350 Global step 350 Train loss 6.48 on epoch=87
06/01/2022 02:23:02 - INFO - __main__ - Global step 350 Train loss 6.72 Classification-F1 0.0 on epoch=87
06/01/2022 02:23:04 - INFO - __main__ - Step 360 Global step 360 Train loss 6.44 on epoch=89
06/01/2022 02:23:05 - INFO - __main__ - Step 370 Global step 370 Train loss 6.37 on epoch=92
06/01/2022 02:23:06 - INFO - __main__ - Step 380 Global step 380 Train loss 6.28 on epoch=94
06/01/2022 02:23:07 - INFO - __main__ - Step 390 Global step 390 Train loss 6.29 on epoch=97
06/01/2022 02:23:09 - INFO - __main__ - Step 400 Global step 400 Train loss 6.08 on epoch=99
06/01/2022 02:23:12 - INFO - __main__ - Global step 400 Train loss 6.29 Classification-F1 0.0 on epoch=99
06/01/2022 02:23:14 - INFO - __main__ - Step 410 Global step 410 Train loss 5.99 on epoch=102
06/01/2022 02:23:15 - INFO - __main__ - Step 420 Global step 420 Train loss 5.92 on epoch=104
06/01/2022 02:23:16 - INFO - __main__ - Step 430 Global step 430 Train loss 6.04 on epoch=107
06/01/2022 02:23:18 - INFO - __main__ - Step 440 Global step 440 Train loss 5.82 on epoch=109
06/01/2022 02:23:19 - INFO - __main__ - Step 450 Global step 450 Train loss 5.88 on epoch=112
06/01/2022 02:23:24 - INFO - __main__ - Global step 450 Train loss 5.93 Classification-F1 0.0 on epoch=112
06/01/2022 02:23:25 - INFO - __main__ - Step 460 Global step 460 Train loss 5.76 on epoch=114
06/01/2022 02:23:26 - INFO - __main__ - Step 470 Global step 470 Train loss 5.84 on epoch=117
06/01/2022 02:23:27 - INFO - __main__ - Step 480 Global step 480 Train loss 5.54 on epoch=119
06/01/2022 02:23:29 - INFO - __main__ - Step 490 Global step 490 Train loss 5.54 on epoch=122
06/01/2022 02:23:30 - INFO - __main__ - Step 500 Global step 500 Train loss 5.53 on epoch=124
06/01/2022 02:23:34 - INFO - __main__ - Global step 500 Train loss 5.64 Classification-F1 0.0 on epoch=124
06/01/2022 02:23:35 - INFO - __main__ - Step 510 Global step 510 Train loss 5.34 on epoch=127
06/01/2022 02:23:37 - INFO - __main__ - Step 520 Global step 520 Train loss 5.50 on epoch=129
06/01/2022 02:23:38 - INFO - __main__ - Step 530 Global step 530 Train loss 5.14 on epoch=132
06/01/2022 02:23:39 - INFO - __main__ - Step 540 Global step 540 Train loss 5.13 on epoch=134
06/01/2022 02:23:40 - INFO - __main__ - Step 550 Global step 550 Train loss 5.19 on epoch=137
06/01/2022 02:23:45 - INFO - __main__ - Global step 550 Train loss 5.26 Classification-F1 0.0 on epoch=137
06/01/2022 02:23:46 - INFO - __main__ - Step 560 Global step 560 Train loss 5.17 on epoch=139
06/01/2022 02:23:48 - INFO - __main__ - Step 570 Global step 570 Train loss 4.86 on epoch=142
06/01/2022 02:23:49 - INFO - __main__ - Step 580 Global step 580 Train loss 4.92 on epoch=144
06/01/2022 02:23:50 - INFO - __main__ - Step 590 Global step 590 Train loss 4.93 on epoch=147
06/01/2022 02:23:51 - INFO - __main__ - Step 600 Global step 600 Train loss 4.79 on epoch=149
06/01/2022 02:23:56 - INFO - __main__ - Global step 600 Train loss 4.93 Classification-F1 0.0 on epoch=149
06/01/2022 02:23:57 - INFO - __main__ - Step 610 Global step 610 Train loss 4.75 on epoch=152
06/01/2022 02:23:59 - INFO - __main__ - Step 620 Global step 620 Train loss 4.68 on epoch=154
06/01/2022 02:24:00 - INFO - __main__ - Step 630 Global step 630 Train loss 4.85 on epoch=157
06/01/2022 02:24:01 - INFO - __main__ - Step 640 Global step 640 Train loss 4.50 on epoch=159
06/01/2022 02:24:02 - INFO - __main__ - Step 650 Global step 650 Train loss 4.69 on epoch=162
06/01/2022 02:24:07 - INFO - __main__ - Global step 650 Train loss 4.69 Classification-F1 0.0 on epoch=162
06/01/2022 02:24:08 - INFO - __main__ - Step 660 Global step 660 Train loss 4.39 on epoch=164
06/01/2022 02:24:09 - INFO - __main__ - Step 670 Global step 670 Train loss 4.46 on epoch=167
06/01/2022 02:24:10 - INFO - __main__ - Step 680 Global step 680 Train loss 4.35 on epoch=169
06/01/2022 02:24:12 - INFO - __main__ - Step 690 Global step 690 Train loss 4.44 on epoch=172
06/01/2022 02:24:13 - INFO - __main__ - Step 700 Global step 700 Train loss 4.33 on epoch=174
06/01/2022 02:24:17 - INFO - __main__ - Global step 700 Train loss 4.39 Classification-F1 0.0 on epoch=174
06/01/2022 02:24:18 - INFO - __main__ - Step 710 Global step 710 Train loss 4.30 on epoch=177
06/01/2022 02:24:19 - INFO - __main__ - Step 720 Global step 720 Train loss 4.31 on epoch=179
06/01/2022 02:24:20 - INFO - __main__ - Step 730 Global step 730 Train loss 4.13 on epoch=182
06/01/2022 02:24:22 - INFO - __main__ - Step 740 Global step 740 Train loss 4.17 on epoch=184
06/01/2022 02:24:23 - INFO - __main__ - Step 750 Global step 750 Train loss 4.02 on epoch=187
06/01/2022 02:24:26 - INFO - __main__ - Global step 750 Train loss 4.19 Classification-F1 0.0 on epoch=187
06/01/2022 02:24:27 - INFO - __main__ - Step 760 Global step 760 Train loss 3.93 on epoch=189
06/01/2022 02:24:29 - INFO - __main__ - Step 770 Global step 770 Train loss 3.99 on epoch=192
06/01/2022 02:24:30 - INFO - __main__ - Step 780 Global step 780 Train loss 3.67 on epoch=194
06/01/2022 02:24:31 - INFO - __main__ - Step 790 Global step 790 Train loss 4.01 on epoch=197
06/01/2022 02:24:33 - INFO - __main__ - Step 800 Global step 800 Train loss 3.73 on epoch=199
06/01/2022 02:24:35 - INFO - __main__ - Global step 800 Train loss 3.87 Classification-F1 0.0 on epoch=199
06/01/2022 02:24:37 - INFO - __main__ - Step 810 Global step 810 Train loss 3.46 on epoch=202
06/01/2022 02:24:38 - INFO - __main__ - Step 820 Global step 820 Train loss 3.64 on epoch=204
06/01/2022 02:24:39 - INFO - __main__ - Step 830 Global step 830 Train loss 3.57 on epoch=207
06/01/2022 02:24:41 - INFO - __main__ - Step 840 Global step 840 Train loss 3.60 on epoch=209
06/01/2022 02:24:42 - INFO - __main__ - Step 850 Global step 850 Train loss 3.51 on epoch=212
06/01/2022 02:24:43 - INFO - __main__ - Global step 850 Train loss 3.56 Classification-F1 0.06766917293233082 on epoch=212
06/01/2022 02:24:43 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.06766917293233082 on epoch=212, global_step=850
06/01/2022 02:24:44 - INFO - __main__ - Step 860 Global step 860 Train loss 3.33 on epoch=214
06/01/2022 02:24:45 - INFO - __main__ - Step 870 Global step 870 Train loss 3.67 on epoch=217
06/01/2022 02:24:46 - INFO - __main__ - Step 880 Global step 880 Train loss 3.48 on epoch=219
06/01/2022 02:24:48 - INFO - __main__ - Step 890 Global step 890 Train loss 3.38 on epoch=222
06/01/2022 02:24:49 - INFO - __main__ - Step 900 Global step 900 Train loss 3.52 on epoch=224
06/01/2022 02:24:50 - INFO - __main__ - Global step 900 Train loss 3.48 Classification-F1 0.09529411764705882 on epoch=224
06/01/2022 02:24:50 - INFO - __main__ - Saving model with best Classification-F1: 0.06766917293233082 -> 0.09529411764705882 on epoch=224, global_step=900
06/01/2022 02:24:51 - INFO - __main__ - Step 910 Global step 910 Train loss 3.39 on epoch=227
06/01/2022 02:24:52 - INFO - __main__ - Step 920 Global step 920 Train loss 3.20 on epoch=229
06/01/2022 02:24:54 - INFO - __main__ - Step 930 Global step 930 Train loss 2.98 on epoch=232
06/01/2022 02:24:55 - INFO - __main__ - Step 940 Global step 940 Train loss 3.06 on epoch=234
06/01/2022 02:24:56 - INFO - __main__ - Step 950 Global step 950 Train loss 3.27 on epoch=237
06/01/2022 02:24:57 - INFO - __main__ - Global step 950 Train loss 3.18 Classification-F1 0.1111111111111111 on epoch=237
06/01/2022 02:24:57 - INFO - __main__ - Saving model with best Classification-F1: 0.09529411764705882 -> 0.1111111111111111 on epoch=237, global_step=950
06/01/2022 02:24:58 - INFO - __main__ - Step 960 Global step 960 Train loss 2.99 on epoch=239
06/01/2022 02:24:59 - INFO - __main__ - Step 970 Global step 970 Train loss 3.00 on epoch=242
06/01/2022 02:25:01 - INFO - __main__ - Step 980 Global step 980 Train loss 3.00 on epoch=244
06/01/2022 02:25:02 - INFO - __main__ - Step 990 Global step 990 Train loss 2.93 on epoch=247
06/01/2022 02:25:03 - INFO - __main__ - Step 1000 Global step 1000 Train loss 2.74 on epoch=249
06/01/2022 02:25:04 - INFO - __main__ - Global step 1000 Train loss 2.93 Classification-F1 0.14838709677419354 on epoch=249
06/01/2022 02:25:04 - INFO - __main__ - Saving model with best Classification-F1: 0.1111111111111111 -> 0.14838709677419354 on epoch=249, global_step=1000
06/01/2022 02:25:05 - INFO - __main__ - Step 1010 Global step 1010 Train loss 2.90 on epoch=252
06/01/2022 02:25:06 - INFO - __main__ - Step 1020 Global step 1020 Train loss 2.78 on epoch=254
06/01/2022 02:25:08 - INFO - __main__ - Step 1030 Global step 1030 Train loss 2.62 on epoch=257
06/01/2022 02:25:09 - INFO - __main__ - Step 1040 Global step 1040 Train loss 2.52 on epoch=259
06/01/2022 02:25:10 - INFO - __main__ - Step 1050 Global step 1050 Train loss 2.45 on epoch=262
06/01/2022 02:25:11 - INFO - __main__ - Global step 1050 Train loss 2.65 Classification-F1 0.1570048309178744 on epoch=262
06/01/2022 02:25:11 - INFO - __main__ - Saving model with best Classification-F1: 0.14838709677419354 -> 0.1570048309178744 on epoch=262, global_step=1050
06/01/2022 02:25:12 - INFO - __main__ - Step 1060 Global step 1060 Train loss 2.50 on epoch=264
06/01/2022 02:25:13 - INFO - __main__ - Step 1070 Global step 1070 Train loss 2.27 on epoch=267
06/01/2022 02:25:15 - INFO - __main__ - Step 1080 Global step 1080 Train loss 2.27 on epoch=269
06/01/2022 02:25:16 - INFO - __main__ - Step 1090 Global step 1090 Train loss 2.17 on epoch=272
06/01/2022 02:25:17 - INFO - __main__ - Step 1100 Global step 1100 Train loss 2.22 on epoch=274
06/01/2022 02:25:18 - INFO - __main__ - Global step 1100 Train loss 2.29 Classification-F1 0.17744755244755245 on epoch=274
06/01/2022 02:25:18 - INFO - __main__ - Saving model with best Classification-F1: 0.1570048309178744 -> 0.17744755244755245 on epoch=274, global_step=1100
06/01/2022 02:25:19 - INFO - __main__ - Step 1110 Global step 1110 Train loss 2.16 on epoch=277
06/01/2022 02:25:20 - INFO - __main__ - Step 1120 Global step 1120 Train loss 2.17 on epoch=279
06/01/2022 02:25:21 - INFO - __main__ - Step 1130 Global step 1130 Train loss 2.25 on epoch=282
06/01/2022 02:25:23 - INFO - __main__ - Step 1140 Global step 1140 Train loss 2.08 on epoch=284
06/01/2022 02:25:24 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.98 on epoch=287
06/01/2022 02:25:25 - INFO - __main__ - Global step 1150 Train loss 2.13 Classification-F1 0.17328042328042326 on epoch=287
06/01/2022 02:25:26 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.99 on epoch=289
06/01/2022 02:25:27 - INFO - __main__ - Step 1170 Global step 1170 Train loss 2.03 on epoch=292
06/01/2022 02:25:28 - INFO - __main__ - Step 1180 Global step 1180 Train loss 2.00 on epoch=294
06/01/2022 02:25:30 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.69 on epoch=297
06/01/2022 02:25:31 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.69 on epoch=299
06/01/2022 02:25:31 - INFO - __main__ - Global step 1200 Train loss 1.88 Classification-F1 0.10256410256410256 on epoch=299
06/01/2022 02:25:33 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.81 on epoch=302
06/01/2022 02:25:34 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.59 on epoch=304
06/01/2022 02:25:35 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.83 on epoch=307
06/01/2022 02:25:36 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.72 on epoch=309
06/01/2022 02:25:38 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.87 on epoch=312
06/01/2022 02:25:38 - INFO - __main__ - Global step 1250 Train loss 1.76 Classification-F1 0.1 on epoch=312
06/01/2022 02:25:40 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.75 on epoch=314
06/01/2022 02:25:41 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.77 on epoch=317
06/01/2022 02:25:42 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.74 on epoch=319
06/01/2022 02:25:43 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.81 on epoch=322
06/01/2022 02:25:45 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.71 on epoch=324
06/01/2022 02:25:45 - INFO - __main__ - Global step 1300 Train loss 1.76 Classification-F1 0.1769230769230769 on epoch=324
06/01/2022 02:25:46 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.57 on epoch=327
06/01/2022 02:25:48 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.67 on epoch=329
06/01/2022 02:25:49 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.65 on epoch=332
06/01/2022 02:25:50 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.54 on epoch=334
06/01/2022 02:25:52 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.72 on epoch=337
06/01/2022 02:25:52 - INFO - __main__ - Global step 1350 Train loss 1.63 Classification-F1 0.17708333333333331 on epoch=337
06/01/2022 02:25:53 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.50 on epoch=339
06/01/2022 02:25:55 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.59 on epoch=342
06/01/2022 02:25:56 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.71 on epoch=344
06/01/2022 02:25:57 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.60 on epoch=347
06/01/2022 02:25:58 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.68 on epoch=349
06/01/2022 02:25:59 - INFO - __main__ - Global step 1400 Train loss 1.62 Classification-F1 0.1302118933697881 on epoch=349
06/01/2022 02:26:00 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.63 on epoch=352
06/01/2022 02:26:01 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.48 on epoch=354
06/01/2022 02:26:03 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.55 on epoch=357
06/01/2022 02:26:04 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.42 on epoch=359
06/01/2022 02:26:05 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.43 on epoch=362
06/01/2022 02:26:06 - INFO - __main__ - Global step 1450 Train loss 1.50 Classification-F1 0.14621798689696247 on epoch=362
06/01/2022 02:26:07 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.48 on epoch=364
06/01/2022 02:26:08 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.32 on epoch=367
06/01/2022 02:26:10 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.40 on epoch=369
06/01/2022 02:26:11 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.70 on epoch=372
06/01/2022 02:26:12 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.58 on epoch=374
06/01/2022 02:26:13 - INFO - __main__ - Global step 1500 Train loss 1.50 Classification-F1 0.15625 on epoch=374
06/01/2022 02:26:14 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.50 on epoch=377
06/01/2022 02:26:15 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.53 on epoch=379
06/01/2022 02:26:16 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.51 on epoch=382
06/01/2022 02:26:18 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.38 on epoch=384
06/01/2022 02:26:19 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.38 on epoch=387
06/01/2022 02:26:20 - INFO - __main__ - Global step 1550 Train loss 1.46 Classification-F1 0.19859154929577466 on epoch=387
06/01/2022 02:26:20 - INFO - __main__ - Saving model with best Classification-F1: 0.17744755244755245 -> 0.19859154929577466 on epoch=387, global_step=1550
06/01/2022 02:26:21 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.39 on epoch=389
06/01/2022 02:26:22 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.48 on epoch=392
06/01/2022 02:26:23 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.47 on epoch=394
06/01/2022 02:26:25 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.40 on epoch=397
06/01/2022 02:26:26 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.27 on epoch=399
06/01/2022 02:26:26 - INFO - __main__ - Global step 1600 Train loss 1.40 Classification-F1 0.09090909090909091 on epoch=399
06/01/2022 02:26:28 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.25 on epoch=402
06/01/2022 02:26:29 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.32 on epoch=404
06/01/2022 02:26:30 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.31 on epoch=407
06/01/2022 02:26:31 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.49 on epoch=409
06/01/2022 02:26:33 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.35 on epoch=412
06/01/2022 02:26:33 - INFO - __main__ - Global step 1650 Train loss 1.34 Classification-F1 0.1389603705609882 on epoch=412
06/01/2022 02:26:35 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.23 on epoch=414
06/01/2022 02:26:36 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.24 on epoch=417
06/01/2022 02:26:37 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.31 on epoch=419
06/01/2022 02:26:38 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.23 on epoch=422
06/01/2022 02:26:40 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.31 on epoch=424
06/01/2022 02:26:40 - INFO - __main__ - Global step 1700 Train loss 1.26 Classification-F1 0.17694311767260096 on epoch=424
06/01/2022 02:26:42 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.30 on epoch=427
06/01/2022 02:26:43 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.21 on epoch=429
06/01/2022 02:26:44 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.18 on epoch=432
06/01/2022 02:26:45 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.16 on epoch=434
06/01/2022 02:26:47 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.24 on epoch=437
06/01/2022 02:26:47 - INFO - __main__ - Global step 1750 Train loss 1.22 Classification-F1 0.18618266978922718 on epoch=437
06/01/2022 02:26:49 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.12 on epoch=439
06/01/2022 02:26:50 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.15 on epoch=442
06/01/2022 02:26:51 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.10 on epoch=444
06/01/2022 02:26:52 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.31 on epoch=447
06/01/2022 02:26:54 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.07 on epoch=449
06/01/2022 02:26:54 - INFO - __main__ - Global step 1800 Train loss 1.15 Classification-F1 0.16926248282180484 on epoch=449
06/01/2022 02:26:55 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.30 on epoch=452
06/01/2022 02:26:57 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.15 on epoch=454
06/01/2022 02:26:58 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.27 on epoch=457
06/01/2022 02:26:59 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.20 on epoch=459
06/01/2022 02:27:00 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.20 on epoch=462
06/01/2022 02:27:01 - INFO - __main__ - Global step 1850 Train loss 1.22 Classification-F1 0.19493006993006995 on epoch=462
06/01/2022 02:27:02 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.20 on epoch=464
06/01/2022 02:27:03 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.25 on epoch=467
06/01/2022 02:27:05 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.13 on epoch=469
06/01/2022 02:27:06 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.17 on epoch=472
06/01/2022 02:27:07 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.14 on epoch=474
06/01/2022 02:27:08 - INFO - __main__ - Global step 1900 Train loss 1.18 Classification-F1 0.12857142857142856 on epoch=474
06/01/2022 02:27:09 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.32 on epoch=477
06/01/2022 02:27:10 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.15 on epoch=479
06/01/2022 02:27:12 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.17 on epoch=482
06/01/2022 02:27:13 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.05 on epoch=484
06/01/2022 02:27:14 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.25 on epoch=487
06/01/2022 02:27:15 - INFO - __main__ - Global step 1950 Train loss 1.19 Classification-F1 0.27499999999999997 on epoch=487
06/01/2022 02:27:15 - INFO - __main__ - Saving model with best Classification-F1: 0.19859154929577466 -> 0.27499999999999997 on epoch=487, global_step=1950
06/01/2022 02:27:16 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.14 on epoch=489
06/01/2022 02:27:17 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.14 on epoch=492
06/01/2022 02:27:19 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.18 on epoch=494
06/01/2022 02:27:20 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.17 on epoch=497
06/01/2022 02:27:21 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.19 on epoch=499
06/01/2022 02:27:22 - INFO - __main__ - Global step 2000 Train loss 1.16 Classification-F1 0.17295285359801488 on epoch=499
06/01/2022 02:27:23 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.18 on epoch=502
06/01/2022 02:27:24 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.04 on epoch=504
06/01/2022 02:27:26 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.13 on epoch=507
06/01/2022 02:27:27 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.16 on epoch=509
06/01/2022 02:27:28 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.10 on epoch=512
06/01/2022 02:27:29 - INFO - __main__ - Global step 2050 Train loss 1.12 Classification-F1 0.13123993558776167 on epoch=512
06/01/2022 02:27:30 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.13 on epoch=514
06/01/2022 02:27:31 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.12 on epoch=517
06/01/2022 02:27:33 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.02 on epoch=519
06/01/2022 02:27:34 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.06 on epoch=522
06/01/2022 02:27:35 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.05 on epoch=524
06/01/2022 02:27:36 - INFO - __main__ - Global step 2100 Train loss 1.08 Classification-F1 0.1408918406072106 on epoch=524
06/01/2022 02:27:37 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.06 on epoch=527
06/01/2022 02:27:38 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.30 on epoch=529
06/01/2022 02:27:40 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.14 on epoch=532
06/01/2022 02:27:41 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.20 on epoch=534
06/01/2022 02:27:42 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.96 on epoch=537
06/01/2022 02:27:43 - INFO - __main__ - Global step 2150 Train loss 1.13 Classification-F1 0.1796875 on epoch=537
06/01/2022 02:27:44 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.07 on epoch=539
06/01/2022 02:27:45 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.10 on epoch=542
06/01/2022 02:27:46 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.19 on epoch=544
06/01/2022 02:27:48 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.09 on epoch=547
06/01/2022 02:27:49 - INFO - __main__ - Step 2200 Global step 2200 Train loss 1.09 on epoch=549
06/01/2022 02:27:50 - INFO - __main__ - Global step 2200 Train loss 1.11 Classification-F1 0.2093900966183575 on epoch=549
06/01/2022 02:27:51 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.12 on epoch=552
06/01/2022 02:27:52 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.00 on epoch=554
06/01/2022 02:27:53 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.16 on epoch=557
06/01/2022 02:27:55 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.02 on epoch=559
06/01/2022 02:27:56 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.18 on epoch=562
06/01/2022 02:27:57 - INFO - __main__ - Global step 2250 Train loss 1.10 Classification-F1 0.18721318314559865 on epoch=562
06/01/2022 02:27:58 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.92 on epoch=564
06/01/2022 02:27:59 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.13 on epoch=567
06/01/2022 02:28:00 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.07 on epoch=569
06/01/2022 02:28:02 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.02 on epoch=572
06/01/2022 02:28:03 - INFO - __main__ - Step 2300 Global step 2300 Train loss 1.10 on epoch=574
06/01/2022 02:28:03 - INFO - __main__ - Global step 2300 Train loss 1.05 Classification-F1 0.1581196581196581 on epoch=574
06/01/2022 02:28:05 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.14 on epoch=577
06/01/2022 02:28:06 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.04 on epoch=579
06/01/2022 02:28:07 - INFO - __main__ - Step 2330 Global step 2330 Train loss 1.10 on epoch=582
06/01/2022 02:28:09 - INFO - __main__ - Step 2340 Global step 2340 Train loss 1.14 on epoch=584
06/01/2022 02:28:10 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.06 on epoch=587
06/01/2022 02:28:10 - INFO - __main__ - Global step 2350 Train loss 1.10 Classification-F1 0.1527777777777778 on epoch=587
06/01/2022 02:28:12 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.92 on epoch=589
06/01/2022 02:28:13 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.95 on epoch=592
06/01/2022 02:28:14 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.08 on epoch=594
06/01/2022 02:28:15 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.95 on epoch=597
06/01/2022 02:28:17 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.13 on epoch=599
06/01/2022 02:28:17 - INFO - __main__ - Global step 2400 Train loss 1.01 Classification-F1 0.1 on epoch=599
06/01/2022 02:28:18 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.05 on epoch=602
06/01/2022 02:28:20 - INFO - __main__ - Step 2420 Global step 2420 Train loss 1.12 on epoch=604
06/01/2022 02:28:21 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.05 on epoch=607
06/01/2022 02:28:22 - INFO - __main__ - Step 2440 Global step 2440 Train loss 1.03 on epoch=609
06/01/2022 02:28:24 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.23 on epoch=612
06/01/2022 02:28:24 - INFO - __main__ - Global step 2450 Train loss 1.09 Classification-F1 0.1 on epoch=612
06/01/2022 02:28:25 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.98 on epoch=614
06/01/2022 02:28:27 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.14 on epoch=617
06/01/2022 02:28:28 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.14 on epoch=619
06/01/2022 02:28:29 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.10 on epoch=622
06/01/2022 02:28:31 - INFO - __main__ - Step 2500 Global step 2500 Train loss 1.10 on epoch=624
06/01/2022 02:28:31 - INFO - __main__ - Global step 2500 Train loss 1.09 Classification-F1 0.1 on epoch=624
06/01/2022 02:28:32 - INFO - __main__ - Step 2510 Global step 2510 Train loss 1.22 on epoch=627
06/01/2022 02:28:34 - INFO - __main__ - Step 2520 Global step 2520 Train loss 1.13 on epoch=629
06/01/2022 02:28:35 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.19 on epoch=632
06/01/2022 02:28:36 - INFO - __main__ - Step 2540 Global step 2540 Train loss 1.00 on epoch=634
06/01/2022 02:28:37 - INFO - __main__ - Step 2550 Global step 2550 Train loss 1.03 on epoch=637
06/01/2022 02:28:38 - INFO - __main__ - Global step 2550 Train loss 1.12 Classification-F1 0.139087656529517 on epoch=637
06/01/2022 02:28:39 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.97 on epoch=639
06/01/2022 02:28:41 - INFO - __main__ - Step 2570 Global step 2570 Train loss 1.02 on epoch=642
06/01/2022 02:28:42 - INFO - __main__ - Step 2580 Global step 2580 Train loss 1.06 on epoch=644
06/01/2022 02:28:43 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.09 on epoch=647
06/01/2022 02:28:44 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.08 on epoch=649
06/01/2022 02:28:45 - INFO - __main__ - Global step 2600 Train loss 1.04 Classification-F1 0.11056511056511056 on epoch=649
06/01/2022 02:28:46 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.99 on epoch=652
06/01/2022 02:28:47 - INFO - __main__ - Step 2620 Global step 2620 Train loss 1.03 on epoch=654
06/01/2022 02:28:49 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.89 on epoch=657
06/01/2022 02:28:50 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.01 on epoch=659
06/01/2022 02:28:51 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.06 on epoch=662
06/01/2022 02:28:52 - INFO - __main__ - Global step 2650 Train loss 1.00 Classification-F1 0.1 on epoch=662
06/01/2022 02:28:53 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.90 on epoch=664
06/01/2022 02:28:54 - INFO - __main__ - Step 2670 Global step 2670 Train loss 1.00 on epoch=667
06/01/2022 02:28:56 - INFO - __main__ - Step 2680 Global step 2680 Train loss 1.00 on epoch=669
06/01/2022 02:28:57 - INFO - __main__ - Step 2690 Global step 2690 Train loss 1.03 on epoch=672
06/01/2022 02:28:58 - INFO - __main__ - Step 2700 Global step 2700 Train loss 1.08 on epoch=674
06/01/2022 02:28:59 - INFO - __main__ - Global step 2700 Train loss 1.00 Classification-F1 0.1 on epoch=674
06/01/2022 02:29:00 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.98 on epoch=677
06/01/2022 02:29:01 - INFO - __main__ - Step 2720 Global step 2720 Train loss 1.00 on epoch=679
06/01/2022 02:29:02 - INFO - __main__ - Step 2730 Global step 2730 Train loss 1.15 on epoch=682
06/01/2022 02:29:04 - INFO - __main__ - Step 2740 Global step 2740 Train loss 1.02 on epoch=684
06/01/2022 02:29:05 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.93 on epoch=687
06/01/2022 02:29:05 - INFO - __main__ - Global step 2750 Train loss 1.02 Classification-F1 0.10126582278481013 on epoch=687
06/01/2022 02:29:07 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.97 on epoch=689
06/01/2022 02:29:08 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.91 on epoch=692
06/01/2022 02:29:09 - INFO - __main__ - Step 2780 Global step 2780 Train loss 1.00 on epoch=694
06/01/2022 02:29:11 - INFO - __main__ - Step 2790 Global step 2790 Train loss 1.00 on epoch=697
06/01/2022 02:29:12 - INFO - __main__ - Step 2800 Global step 2800 Train loss 1.05 on epoch=699
06/01/2022 02:29:12 - INFO - __main__ - Global step 2800 Train loss 0.99 Classification-F1 0.09493670886075949 on epoch=699
06/01/2022 02:29:14 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.09 on epoch=702
06/01/2022 02:29:15 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.99 on epoch=704
06/01/2022 02:29:16 - INFO - __main__ - Step 2830 Global step 2830 Train loss 1.03 on epoch=707
06/01/2022 02:29:17 - INFO - __main__ - Step 2840 Global step 2840 Train loss 1.00 on epoch=709
06/01/2022 02:29:19 - INFO - __main__ - Step 2850 Global step 2850 Train loss 1.04 on epoch=712
06/01/2022 02:29:19 - INFO - __main__ - Global step 2850 Train loss 1.03 Classification-F1 0.1 on epoch=712
06/01/2022 02:29:21 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.98 on epoch=714
06/01/2022 02:29:22 - INFO - __main__ - Step 2870 Global step 2870 Train loss 1.01 on epoch=717
06/01/2022 02:29:23 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.91 on epoch=719
06/01/2022 02:29:24 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.06 on epoch=722
06/01/2022 02:29:26 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.88 on epoch=724
06/01/2022 02:29:26 - INFO - __main__ - Global step 2900 Train loss 0.97 Classification-F1 0.13936867182846935 on epoch=724
06/01/2022 02:29:28 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.11 on epoch=727
06/01/2022 02:29:29 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.95 on epoch=729
06/01/2022 02:29:31 - INFO - __main__ - Step 2930 Global step 2930 Train loss 1.00 on epoch=732
06/01/2022 02:29:32 - INFO - __main__ - Step 2940 Global step 2940 Train loss 1.05 on epoch=734
06/01/2022 02:29:33 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.92 on epoch=737
06/01/2022 02:29:34 - INFO - __main__ - Global step 2950 Train loss 1.01 Classification-F1 0.1736111111111111 on epoch=737
06/01/2022 02:29:35 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.89 on epoch=739
06/01/2022 02:29:36 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.07 on epoch=742
06/01/2022 02:29:38 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.03 on epoch=744
06/01/2022 02:29:39 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.97 on epoch=747
06/01/2022 02:29:40 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.92 on epoch=749
06/01/2022 02:29:41 - INFO - __main__ - Global step 3000 Train loss 0.98 Classification-F1 0.142512077294686 on epoch=749
06/01/2022 02:29:41 - INFO - __main__ - save last model!
06/01/2022 02:29:41 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/01/2022 02:29:41 - INFO - __main__ - Start tokenizing ... 5509 instances
06/01/2022 02:29:41 - INFO - __main__ - Printing 3 examples
06/01/2022 02:29:41 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/01/2022 02:29:41 - INFO - __main__ - ['others']
06/01/2022 02:29:41 - INFO - __main__ -  [emo] what you like very little things ok
06/01/2022 02:29:41 - INFO - __main__ - ['others']
06/01/2022 02:29:41 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/01/2022 02:29:41 - INFO - __main__ - ['others']
06/01/2022 02:29:41 - INFO - __main__ - Tokenizing Input ...
06/01/2022 02:29:41 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 02:29:41 - INFO - __main__ - Printing 3 examples
06/01/2022 02:29:41 - INFO - __main__ -  [emo] how cause yes am listening
06/01/2022 02:29:41 - INFO - __main__ - ['others']
06/01/2022 02:29:41 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/01/2022 02:29:41 - INFO - __main__ - ['others']
06/01/2022 02:29:41 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/01/2022 02:29:41 - INFO - __main__ - ['others']
06/01/2022 02:29:41 - INFO - __main__ - Tokenizing Input ...
06/01/2022 02:29:41 - INFO - __main__ - Tokenizing Output ...
06/01/2022 02:29:41 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 02:29:41 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 02:29:41 - INFO - __main__ - Printing 3 examples
06/01/2022 02:29:41 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
06/01/2022 02:29:41 - INFO - __main__ - ['others']
06/01/2022 02:29:41 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
06/01/2022 02:29:41 - INFO - __main__ - ['others']
06/01/2022 02:29:41 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
06/01/2022 02:29:41 - INFO - __main__ - ['others']
06/01/2022 02:29:41 - INFO - __main__ - Tokenizing Input ...
06/01/2022 02:29:41 - INFO - __main__ - Tokenizing Output ...
06/01/2022 02:29:41 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 02:29:43 - INFO - __main__ - Tokenizing Output ...
06/01/2022 02:29:47 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 02:29:47 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/01/2022 02:29:47 - INFO - __main__ - Starting training!
06/01/2022 02:29:49 - INFO - __main__ - Loaded 5509 examples from test data
06/01/2022 02:30:33 - INFO - __main__ - Saved prediction in models/T5-base-reptile-cls2cls-3e-5-2-5000-5e-1-10/singletask-emo/emo_16_100_0.3_8_predictions.txt
06/01/2022 02:30:33 - INFO - __main__ - Classification-F1 on test data: 0.0450
06/01/2022 02:30:33 - INFO - __main__ - prefix=emo_16_100, lr=0.3, bsz=8, dev_performance=0.27499999999999997, test_performance=0.044995617606100644
06/01/2022 02:30:33 - INFO - __main__ - Running ... prefix=emo_16_100, lr=0.2, bsz=8 ...
06/01/2022 02:30:34 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 02:30:34 - INFO - __main__ - Printing 3 examples
06/01/2022 02:30:34 - INFO - __main__ -  [emo] how cause yes am listening
06/01/2022 02:30:34 - INFO - __main__ - ['others']
06/01/2022 02:30:34 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/01/2022 02:30:34 - INFO - __main__ - ['others']
06/01/2022 02:30:34 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/01/2022 02:30:34 - INFO - __main__ - ['others']
06/01/2022 02:30:34 - INFO - __main__ - Tokenizing Input ...
06/01/2022 02:30:34 - INFO - __main__ - Tokenizing Output ...
06/01/2022 02:30:34 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 02:30:34 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 02:30:34 - INFO - __main__ - Printing 3 examples
06/01/2022 02:30:34 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
06/01/2022 02:30:34 - INFO - __main__ - ['others']
06/01/2022 02:30:34 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
06/01/2022 02:30:34 - INFO - __main__ - ['others']
06/01/2022 02:30:34 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
06/01/2022 02:30:34 - INFO - __main__ - ['others']
06/01/2022 02:30:34 - INFO - __main__ - Tokenizing Input ...
06/01/2022 02:30:34 - INFO - __main__ - Tokenizing Output ...
06/01/2022 02:30:34 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 02:30:40 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 02:30:40 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/01/2022 02:30:40 - INFO - __main__ - Starting training!
06/01/2022 02:30:42 - INFO - __main__ - Step 10 Global step 10 Train loss 8.97 on epoch=2
06/01/2022 02:30:43 - INFO - __main__ - Step 20 Global step 20 Train loss 9.00 on epoch=4
06/01/2022 02:30:44 - INFO - __main__ - Step 30 Global step 30 Train loss 8.96 on epoch=7
06/01/2022 02:30:46 - INFO - __main__ - Step 40 Global step 40 Train loss 8.96 on epoch=9
06/01/2022 02:30:47 - INFO - __main__ - Step 50 Global step 50 Train loss 8.83 on epoch=12
06/01/2022 02:30:56 - INFO - __main__ - Global step 50 Train loss 8.94 Classification-F1 0.0 on epoch=12
06/01/2022 02:30:56 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
06/01/2022 02:30:58 - INFO - __main__ - Step 60 Global step 60 Train loss 9.06 on epoch=14
06/01/2022 02:30:59 - INFO - __main__ - Step 70 Global step 70 Train loss 8.88 on epoch=17
06/01/2022 02:31:00 - INFO - __main__ - Step 80 Global step 80 Train loss 8.88 on epoch=19
06/01/2022 02:31:02 - INFO - __main__ - Step 90 Global step 90 Train loss 8.87 on epoch=22
06/01/2022 02:31:03 - INFO - __main__ - Step 100 Global step 100 Train loss 8.91 on epoch=24
06/01/2022 02:31:13 - INFO - __main__ - Global step 100 Train loss 8.92 Classification-F1 0.0 on epoch=24
06/01/2022 02:31:15 - INFO - __main__ - Step 110 Global step 110 Train loss 8.76 on epoch=27
06/01/2022 02:31:16 - INFO - __main__ - Step 120 Global step 120 Train loss 8.85 on epoch=29
06/01/2022 02:31:17 - INFO - __main__ - Step 130 Global step 130 Train loss 8.74 on epoch=32
06/01/2022 02:31:18 - INFO - __main__ - Step 140 Global step 140 Train loss 8.63 on epoch=34
06/01/2022 02:31:20 - INFO - __main__ - Step 150 Global step 150 Train loss 8.67 on epoch=37
06/01/2022 02:31:28 - INFO - __main__ - Global step 150 Train loss 8.73 Classification-F1 0.0 on epoch=37
06/01/2022 02:31:29 - INFO - __main__ - Step 160 Global step 160 Train loss 8.65 on epoch=39
06/01/2022 02:31:31 - INFO - __main__ - Step 170 Global step 170 Train loss 8.69 on epoch=42
06/01/2022 02:31:32 - INFO - __main__ - Step 180 Global step 180 Train loss 8.49 on epoch=44
06/01/2022 02:31:33 - INFO - __main__ - Step 190 Global step 190 Train loss 8.36 on epoch=47
06/01/2022 02:31:34 - INFO - __main__ - Step 200 Global step 200 Train loss 8.54 on epoch=49
06/01/2022 02:31:50 - INFO - __main__ - Global step 200 Train loss 8.55 Classification-F1 0.0 on epoch=49
06/01/2022 02:31:51 - INFO - __main__ - Step 210 Global step 210 Train loss 8.25 on epoch=52
06/01/2022 02:31:53 - INFO - __main__ - Step 220 Global step 220 Train loss 8.17 on epoch=54
06/01/2022 02:31:54 - INFO - __main__ - Step 230 Global step 230 Train loss 8.14 on epoch=57
06/01/2022 02:31:55 - INFO - __main__ - Step 240 Global step 240 Train loss 8.02 on epoch=59
06/01/2022 02:31:56 - INFO - __main__ - Step 250 Global step 250 Train loss 7.94 on epoch=62
06/01/2022 02:32:10 - INFO - __main__ - Global step 250 Train loss 8.10 Classification-F1 0.0 on epoch=62
06/01/2022 02:32:11 - INFO - __main__ - Step 260 Global step 260 Train loss 8.06 on epoch=64
06/01/2022 02:32:13 - INFO - __main__ - Step 270 Global step 270 Train loss 7.82 on epoch=67
06/01/2022 02:32:14 - INFO - __main__ - Step 280 Global step 280 Train loss 7.68 on epoch=69
06/01/2022 02:32:15 - INFO - __main__ - Step 290 Global step 290 Train loss 7.73 on epoch=72
06/01/2022 02:32:16 - INFO - __main__ - Step 300 Global step 300 Train loss 7.51 on epoch=74
06/01/2022 02:32:29 - INFO - __main__ - Global step 300 Train loss 7.76 Classification-F1 0.0 on epoch=74
06/01/2022 02:32:31 - INFO - __main__ - Step 310 Global step 310 Train loss 7.58 on epoch=77
06/01/2022 02:32:32 - INFO - __main__ - Step 320 Global step 320 Train loss 7.44 on epoch=79
06/01/2022 02:32:33 - INFO - __main__ - Step 330 Global step 330 Train loss 7.30 on epoch=82
06/01/2022 02:32:35 - INFO - __main__ - Step 340 Global step 340 Train loss 7.29 on epoch=84
06/01/2022 02:32:36 - INFO - __main__ - Step 350 Global step 350 Train loss 7.20 on epoch=87
06/01/2022 02:32:51 - INFO - __main__ - Global step 350 Train loss 7.36 Classification-F1 0.0 on epoch=87
06/01/2022 02:32:52 - INFO - __main__ - Step 360 Global step 360 Train loss 7.14 on epoch=89
06/01/2022 02:32:53 - INFO - __main__ - Step 370 Global step 370 Train loss 6.99 on epoch=92
06/01/2022 02:32:54 - INFO - __main__ - Step 380 Global step 380 Train loss 6.73 on epoch=94
06/01/2022 02:32:56 - INFO - __main__ - Step 390 Global step 390 Train loss 6.70 on epoch=97
06/01/2022 02:32:57 - INFO - __main__ - Step 400 Global step 400 Train loss 6.73 on epoch=99
06/01/2022 02:33:01 - INFO - __main__ - Global step 400 Train loss 6.86 Classification-F1 0.0 on epoch=99
06/01/2022 02:33:02 - INFO - __main__ - Step 410 Global step 410 Train loss 6.61 on epoch=102
06/01/2022 02:33:04 - INFO - __main__ - Step 420 Global step 420 Train loss 6.34 on epoch=104
06/01/2022 02:33:05 - INFO - __main__ - Step 430 Global step 430 Train loss 6.34 on epoch=107
06/01/2022 02:33:07 - INFO - __main__ - Step 440 Global step 440 Train loss 6.18 on epoch=109
06/01/2022 02:33:08 - INFO - __main__ - Step 450 Global step 450 Train loss 6.33 on epoch=112
06/01/2022 02:33:15 - INFO - __main__ - Global step 450 Train loss 6.36 Classification-F1 0.0 on epoch=112
06/01/2022 02:33:17 - INFO - __main__ - Step 460 Global step 460 Train loss 5.99 on epoch=114
06/01/2022 02:33:18 - INFO - __main__ - Step 470 Global step 470 Train loss 6.07 on epoch=117
06/01/2022 02:33:19 - INFO - __main__ - Step 480 Global step 480 Train loss 5.78 on epoch=119
06/01/2022 02:33:20 - INFO - __main__ - Step 490 Global step 490 Train loss 5.92 on epoch=122
06/01/2022 02:33:22 - INFO - __main__ - Step 500 Global step 500 Train loss 5.73 on epoch=124
06/01/2022 02:33:28 - INFO - __main__ - Global step 500 Train loss 5.90 Classification-F1 0.0 on epoch=124
06/01/2022 02:33:29 - INFO - __main__ - Step 510 Global step 510 Train loss 5.83 on epoch=127
06/01/2022 02:33:30 - INFO - __main__ - Step 520 Global step 520 Train loss 5.60 on epoch=129
06/01/2022 02:33:31 - INFO - __main__ - Step 530 Global step 530 Train loss 5.69 on epoch=132
06/01/2022 02:33:33 - INFO - __main__ - Step 540 Global step 540 Train loss 5.61 on epoch=134
06/01/2022 02:33:34 - INFO - __main__ - Step 550 Global step 550 Train loss 5.46 on epoch=137
06/01/2022 02:33:39 - INFO - __main__ - Global step 550 Train loss 5.64 Classification-F1 0.0 on epoch=137
06/01/2022 02:33:40 - INFO - __main__ - Step 560 Global step 560 Train loss 5.33 on epoch=139
06/01/2022 02:33:42 - INFO - __main__ - Step 570 Global step 570 Train loss 5.32 on epoch=142
06/01/2022 02:33:43 - INFO - __main__ - Step 580 Global step 580 Train loss 5.14 on epoch=144
06/01/2022 02:33:44 - INFO - __main__ - Step 590 Global step 590 Train loss 5.52 on epoch=147
06/01/2022 02:33:45 - INFO - __main__ - Step 600 Global step 600 Train loss 5.23 on epoch=149
06/01/2022 02:33:49 - INFO - __main__ - Global step 600 Train loss 5.31 Classification-F1 0.0 on epoch=149
06/01/2022 02:33:51 - INFO - __main__ - Step 610 Global step 610 Train loss 5.21 on epoch=152
06/01/2022 02:33:52 - INFO - __main__ - Step 620 Global step 620 Train loss 4.97 on epoch=154
06/01/2022 02:33:53 - INFO - __main__ - Step 630 Global step 630 Train loss 4.98 on epoch=157
06/01/2022 02:33:54 - INFO - __main__ - Step 640 Global step 640 Train loss 4.94 on epoch=159
06/01/2022 02:33:56 - INFO - __main__ - Step 650 Global step 650 Train loss 5.02 on epoch=162
06/01/2022 02:34:00 - INFO - __main__ - Global step 650 Train loss 5.02 Classification-F1 0.0 on epoch=162
06/01/2022 02:34:01 - INFO - __main__ - Step 660 Global step 660 Train loss 4.68 on epoch=164
06/01/2022 02:34:03 - INFO - __main__ - Step 670 Global step 670 Train loss 4.83 on epoch=167
06/01/2022 02:34:04 - INFO - __main__ - Step 680 Global step 680 Train loss 4.57 on epoch=169
06/01/2022 02:34:05 - INFO - __main__ - Step 690 Global step 690 Train loss 4.70 on epoch=172
06/01/2022 02:34:06 - INFO - __main__ - Step 700 Global step 700 Train loss 4.50 on epoch=174
06/01/2022 02:34:10 - INFO - __main__ - Global step 700 Train loss 4.66 Classification-F1 0.0 on epoch=174
06/01/2022 02:34:12 - INFO - __main__ - Step 710 Global step 710 Train loss 4.54 on epoch=177
06/01/2022 02:34:13 - INFO - __main__ - Step 720 Global step 720 Train loss 4.41 on epoch=179
06/01/2022 02:34:14 - INFO - __main__ - Step 730 Global step 730 Train loss 4.45 on epoch=182
06/01/2022 02:34:15 - INFO - __main__ - Step 740 Global step 740 Train loss 4.21 on epoch=184
06/01/2022 02:34:17 - INFO - __main__ - Step 750 Global step 750 Train loss 4.44 on epoch=187
06/01/2022 02:34:21 - INFO - __main__ - Global step 750 Train loss 4.41 Classification-F1 0.0 on epoch=187
06/01/2022 02:34:22 - INFO - __main__ - Step 760 Global step 760 Train loss 4.14 on epoch=189
06/01/2022 02:34:24 - INFO - __main__ - Step 770 Global step 770 Train loss 4.18 on epoch=192
06/01/2022 02:34:25 - INFO - __main__ - Step 780 Global step 780 Train loss 4.01 on epoch=194
06/01/2022 02:34:26 - INFO - __main__ - Step 790 Global step 790 Train loss 4.27 on epoch=197
06/01/2022 02:34:28 - INFO - __main__ - Step 800 Global step 800 Train loss 4.09 on epoch=199
06/01/2022 02:34:31 - INFO - __main__ - Global step 800 Train loss 4.14 Classification-F1 0.0 on epoch=199
06/01/2022 02:34:33 - INFO - __main__ - Step 810 Global step 810 Train loss 4.00 on epoch=202
06/01/2022 02:34:34 - INFO - __main__ - Step 820 Global step 820 Train loss 3.96 on epoch=204
06/01/2022 02:34:35 - INFO - __main__ - Step 830 Global step 830 Train loss 4.00 on epoch=207
06/01/2022 02:34:36 - INFO - __main__ - Step 840 Global step 840 Train loss 3.81 on epoch=209
06/01/2022 02:34:38 - INFO - __main__ - Step 850 Global step 850 Train loss 4.02 on epoch=212
06/01/2022 02:34:45 - INFO - __main__ - Global step 850 Train loss 3.96 Classification-F1 0.0 on epoch=212
06/01/2022 02:34:46 - INFO - __main__ - Step 860 Global step 860 Train loss 3.80 on epoch=214
06/01/2022 02:34:48 - INFO - __main__ - Step 870 Global step 870 Train loss 3.91 on epoch=217
06/01/2022 02:34:49 - INFO - __main__ - Step 880 Global step 880 Train loss 3.69 on epoch=219
06/01/2022 02:34:50 - INFO - __main__ - Step 890 Global step 890 Train loss 3.68 on epoch=222
06/01/2022 02:34:52 - INFO - __main__ - Step 900 Global step 900 Train loss 3.74 on epoch=224
06/01/2022 02:34:53 - INFO - __main__ - Global step 900 Train loss 3.76 Classification-F1 0.12324324324324323 on epoch=224
06/01/2022 02:34:53 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.12324324324324323 on epoch=224, global_step=900
06/01/2022 02:34:54 - INFO - __main__ - Step 910 Global step 910 Train loss 3.49 on epoch=227
06/01/2022 02:34:55 - INFO - __main__ - Step 920 Global step 920 Train loss 3.54 on epoch=229
06/01/2022 02:34:57 - INFO - __main__ - Step 930 Global step 930 Train loss 3.63 on epoch=232
06/01/2022 02:34:58 - INFO - __main__ - Step 940 Global step 940 Train loss 3.38 on epoch=234
06/01/2022 02:34:59 - INFO - __main__ - Step 950 Global step 950 Train loss 3.39 on epoch=237
06/01/2022 02:35:00 - INFO - __main__ - Global step 950 Train loss 3.49 Classification-F1 0.12368421052631579 on epoch=237
06/01/2022 02:35:00 - INFO - __main__ - Saving model with best Classification-F1: 0.12324324324324323 -> 0.12368421052631579 on epoch=237, global_step=950
06/01/2022 02:35:01 - INFO - __main__ - Step 960 Global step 960 Train loss 3.29 on epoch=239
06/01/2022 02:35:02 - INFO - __main__ - Step 970 Global step 970 Train loss 3.41 on epoch=242
06/01/2022 02:35:04 - INFO - __main__ - Step 980 Global step 980 Train loss 3.32 on epoch=244
06/01/2022 02:35:05 - INFO - __main__ - Step 990 Global step 990 Train loss 3.23 on epoch=247
06/01/2022 02:35:06 - INFO - __main__ - Step 1000 Global step 1000 Train loss 3.13 on epoch=249
06/01/2022 02:35:08 - INFO - __main__ - Global step 1000 Train loss 3.28 Classification-F1 0.1875 on epoch=249
06/01/2022 02:35:08 - INFO - __main__ - Saving model with best Classification-F1: 0.12368421052631579 -> 0.1875 on epoch=249, global_step=1000
06/01/2022 02:35:09 - INFO - __main__ - Step 1010 Global step 1010 Train loss 3.18 on epoch=252
06/01/2022 02:35:10 - INFO - __main__ - Step 1020 Global step 1020 Train loss 3.18 on epoch=254
06/01/2022 02:35:11 - INFO - __main__ - Step 1030 Global step 1030 Train loss 3.09 on epoch=257
06/01/2022 02:35:13 - INFO - __main__ - Step 1040 Global step 1040 Train loss 3.04 on epoch=259
06/01/2022 02:35:14 - INFO - __main__ - Step 1050 Global step 1050 Train loss 3.07 on epoch=262
06/01/2022 02:35:15 - INFO - __main__ - Global step 1050 Train loss 3.11 Classification-F1 0.18614718614718614 on epoch=262
06/01/2022 02:35:16 - INFO - __main__ - Step 1060 Global step 1060 Train loss 2.90 on epoch=264
06/01/2022 02:35:17 - INFO - __main__ - Step 1070 Global step 1070 Train loss 3.13 on epoch=267
06/01/2022 02:35:18 - INFO - __main__ - Step 1080 Global step 1080 Train loss 3.03 on epoch=269
06/01/2022 02:35:20 - INFO - __main__ - Step 1090 Global step 1090 Train loss 2.73 on epoch=272
06/01/2022 02:35:21 - INFO - __main__ - Step 1100 Global step 1100 Train loss 2.79 on epoch=274
06/01/2022 02:35:22 - INFO - __main__ - Global step 1100 Train loss 2.92 Classification-F1 0.11923076923076922 on epoch=274
06/01/2022 02:35:23 - INFO - __main__ - Step 1110 Global step 1110 Train loss 2.77 on epoch=277
06/01/2022 02:35:24 - INFO - __main__ - Step 1120 Global step 1120 Train loss 2.61 on epoch=279
06/01/2022 02:35:25 - INFO - __main__ - Step 1130 Global step 1130 Train loss 2.54 on epoch=282
06/01/2022 02:35:27 - INFO - __main__ - Step 1140 Global step 1140 Train loss 2.72 on epoch=284
06/01/2022 02:35:28 - INFO - __main__ - Step 1150 Global step 1150 Train loss 2.65 on epoch=287
06/01/2022 02:35:33 - INFO - __main__ - Global step 1150 Train loss 2.66 Classification-F1 0.11732186732186733 on epoch=287
06/01/2022 02:35:34 - INFO - __main__ - Step 1160 Global step 1160 Train loss 2.49 on epoch=289
06/01/2022 02:35:35 - INFO - __main__ - Step 1170 Global step 1170 Train loss 2.73 on epoch=292
06/01/2022 02:35:36 - INFO - __main__ - Step 1180 Global step 1180 Train loss 2.44 on epoch=294
06/01/2022 02:35:37 - INFO - __main__ - Step 1190 Global step 1190 Train loss 2.58 on epoch=297
06/01/2022 02:35:39 - INFO - __main__ - Step 1200 Global step 1200 Train loss 2.57 on epoch=299
06/01/2022 02:35:39 - INFO - __main__ - Global step 1200 Train loss 2.56 Classification-F1 0.1 on epoch=299
06/01/2022 02:35:41 - INFO - __main__ - Step 1210 Global step 1210 Train loss 2.43 on epoch=302
06/01/2022 02:35:42 - INFO - __main__ - Step 1220 Global step 1220 Train loss 2.43 on epoch=304
06/01/2022 02:35:43 - INFO - __main__ - Step 1230 Global step 1230 Train loss 2.40 on epoch=307
06/01/2022 02:35:44 - INFO - __main__ - Step 1240 Global step 1240 Train loss 2.26 on epoch=309
06/01/2022 02:35:45 - INFO - __main__ - Step 1250 Global step 1250 Train loss 2.39 on epoch=312
06/01/2022 02:35:46 - INFO - __main__ - Global step 1250 Train loss 2.38 Classification-F1 0.1 on epoch=312
06/01/2022 02:35:47 - INFO - __main__ - Step 1260 Global step 1260 Train loss 2.34 on epoch=314
06/01/2022 02:35:49 - INFO - __main__ - Step 1270 Global step 1270 Train loss 2.27 on epoch=317
06/01/2022 02:35:50 - INFO - __main__ - Step 1280 Global step 1280 Train loss 2.07 on epoch=319
06/01/2022 02:35:51 - INFO - __main__ - Step 1290 Global step 1290 Train loss 2.29 on epoch=322
06/01/2022 02:35:52 - INFO - __main__ - Step 1300 Global step 1300 Train loss 2.24 on epoch=324
06/01/2022 02:35:53 - INFO - __main__ - Global step 1300 Train loss 2.24 Classification-F1 0.1 on epoch=324
06/01/2022 02:35:54 - INFO - __main__ - Step 1310 Global step 1310 Train loss 2.28 on epoch=327
06/01/2022 02:35:55 - INFO - __main__ - Step 1320 Global step 1320 Train loss 2.11 on epoch=329
06/01/2022 02:35:57 - INFO - __main__ - Step 1330 Global step 1330 Train loss 2.08 on epoch=332
06/01/2022 02:35:58 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.98 on epoch=334
06/01/2022 02:35:59 - INFO - __main__ - Step 1350 Global step 1350 Train loss 2.01 on epoch=337
06/01/2022 02:35:59 - INFO - __main__ - Global step 1350 Train loss 2.09 Classification-F1 0.1 on epoch=337
06/01/2022 02:36:01 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.96 on epoch=339
06/01/2022 02:36:02 - INFO - __main__ - Step 1370 Global step 1370 Train loss 2.04 on epoch=342
06/01/2022 02:36:03 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.92 on epoch=344
06/01/2022 02:36:05 - INFO - __main__ - Step 1390 Global step 1390 Train loss 2.04 on epoch=347
06/01/2022 02:36:06 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.78 on epoch=349
06/01/2022 02:36:06 - INFO - __main__ - Global step 1400 Train loss 1.95 Classification-F1 0.1 on epoch=349
06/01/2022 02:36:08 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.92 on epoch=352
06/01/2022 02:36:09 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.89 on epoch=354
06/01/2022 02:36:10 - INFO - __main__ - Step 1430 Global step 1430 Train loss 2.00 on epoch=357
06/01/2022 02:36:11 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.86 on epoch=359
06/01/2022 02:36:12 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.96 on epoch=362
06/01/2022 02:36:13 - INFO - __main__ - Global step 1450 Train loss 1.93 Classification-F1 0.1 on epoch=362
06/01/2022 02:36:14 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.64 on epoch=364
06/01/2022 02:36:15 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.74 on epoch=367
06/01/2022 02:36:17 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.68 on epoch=369
06/01/2022 02:36:18 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.88 on epoch=372
06/01/2022 02:36:19 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.78 on epoch=374
06/01/2022 02:36:20 - INFO - __main__ - Global step 1500 Train loss 1.75 Classification-F1 0.10126582278481013 on epoch=374
06/01/2022 02:36:21 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.80 on epoch=377
06/01/2022 02:36:22 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.85 on epoch=379
06/01/2022 02:36:23 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.79 on epoch=382
06/01/2022 02:36:25 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.69 on epoch=384
06/01/2022 02:36:26 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.68 on epoch=387
06/01/2022 02:36:26 - INFO - __main__ - Global step 1550 Train loss 1.76 Classification-F1 0.10450704225352113 on epoch=387
06/01/2022 02:36:28 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.68 on epoch=389
06/01/2022 02:36:29 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.71 on epoch=392
06/01/2022 02:36:30 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.50 on epoch=394
06/01/2022 02:36:31 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.68 on epoch=397
06/01/2022 02:36:33 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.62 on epoch=399
06/01/2022 02:36:33 - INFO - __main__ - Global step 1600 Train loss 1.64 Classification-F1 0.20417422867513613 on epoch=399
06/01/2022 02:36:33 - INFO - __main__ - Saving model with best Classification-F1: 0.1875 -> 0.20417422867513613 on epoch=399, global_step=1600
06/01/2022 02:36:34 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.62 on epoch=402
06/01/2022 02:36:36 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.40 on epoch=404
06/01/2022 02:36:37 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.48 on epoch=407
06/01/2022 02:36:38 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.59 on epoch=409
06/01/2022 02:36:39 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.58 on epoch=412
06/01/2022 02:36:40 - INFO - __main__ - Global step 1650 Train loss 1.54 Classification-F1 0.161078431372549 on epoch=412
06/01/2022 02:36:41 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.56 on epoch=414
06/01/2022 02:36:42 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.54 on epoch=417
06/01/2022 02:36:44 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.42 on epoch=419
06/01/2022 02:36:45 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.48 on epoch=422
06/01/2022 02:36:46 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.35 on epoch=424
06/01/2022 02:36:47 - INFO - __main__ - Global step 1700 Train loss 1.47 Classification-F1 0.13034188034188032 on epoch=424
06/01/2022 02:36:48 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.28 on epoch=427
06/01/2022 02:36:49 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.34 on epoch=429
06/01/2022 02:36:50 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.39 on epoch=432
06/01/2022 02:36:52 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.44 on epoch=434
06/01/2022 02:36:53 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.35 on epoch=437
06/01/2022 02:36:53 - INFO - __main__ - Global step 1750 Train loss 1.36 Classification-F1 0.22832890218234186 on epoch=437
06/01/2022 02:36:53 - INFO - __main__ - Saving model with best Classification-F1: 0.20417422867513613 -> 0.22832890218234186 on epoch=437, global_step=1750
06/01/2022 02:36:55 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.28 on epoch=439
06/01/2022 02:36:56 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.48 on epoch=442
06/01/2022 02:36:57 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.42 on epoch=444
06/01/2022 02:36:58 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.51 on epoch=447
06/01/2022 02:36:59 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.41 on epoch=449
06/01/2022 02:37:00 - INFO - __main__ - Global step 1800 Train loss 1.42 Classification-F1 0.1302118933697881 on epoch=449
06/01/2022 02:37:01 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.31 on epoch=452
06/01/2022 02:37:02 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.34 on epoch=454
06/01/2022 02:37:04 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.31 on epoch=457
06/01/2022 02:37:05 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.26 on epoch=459
06/01/2022 02:37:06 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.44 on epoch=462
06/01/2022 02:37:07 - INFO - __main__ - Global step 1850 Train loss 1.33 Classification-F1 0.12368421052631579 on epoch=462
06/01/2022 02:37:08 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.34 on epoch=464
06/01/2022 02:37:09 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.26 on epoch=467
06/01/2022 02:37:10 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.31 on epoch=469
06/01/2022 02:37:12 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.47 on epoch=472
06/01/2022 02:37:13 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.20 on epoch=474
06/01/2022 02:37:13 - INFO - __main__ - Global step 1900 Train loss 1.31 Classification-F1 0.09868421052631579 on epoch=474
06/01/2022 02:37:15 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.32 on epoch=477
06/01/2022 02:37:16 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.26 on epoch=479
06/01/2022 02:37:17 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.21 on epoch=482
06/01/2022 02:37:18 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.29 on epoch=484
06/01/2022 02:37:20 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.40 on epoch=487
06/01/2022 02:37:20 - INFO - __main__ - Global step 1950 Train loss 1.30 Classification-F1 0.1500341763499658 on epoch=487
06/01/2022 02:37:21 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.35 on epoch=489
06/01/2022 02:37:23 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.36 on epoch=492
06/01/2022 02:37:24 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.33 on epoch=494
06/01/2022 02:37:25 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.30 on epoch=497
06/01/2022 02:37:26 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.23 on epoch=499
06/01/2022 02:37:27 - INFO - __main__ - Global step 2000 Train loss 1.31 Classification-F1 0.1 on epoch=499
06/01/2022 02:37:28 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.21 on epoch=502
06/01/2022 02:37:29 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.19 on epoch=504
06/01/2022 02:37:31 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.22 on epoch=507
06/01/2022 02:37:32 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.37 on epoch=509
06/01/2022 02:37:33 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.29 on epoch=512
06/01/2022 02:37:34 - INFO - __main__ - Global step 2050 Train loss 1.26 Classification-F1 0.13067758749069247 on epoch=512
06/01/2022 02:37:35 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.24 on epoch=514
06/01/2022 02:37:36 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.27 on epoch=517
06/01/2022 02:37:37 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.19 on epoch=519
06/01/2022 02:37:38 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.26 on epoch=522
06/01/2022 02:37:40 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.07 on epoch=524
06/01/2022 02:37:40 - INFO - __main__ - Global step 2100 Train loss 1.21 Classification-F1 0.10126582278481013 on epoch=524
06/01/2022 02:37:41 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.24 on epoch=527
06/01/2022 02:37:43 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.35 on epoch=529
06/01/2022 02:37:44 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.34 on epoch=532
06/01/2022 02:37:45 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.14 on epoch=534
06/01/2022 02:37:46 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.28 on epoch=537
06/01/2022 02:37:47 - INFO - __main__ - Global step 2150 Train loss 1.27 Classification-F1 0.1581196581196581 on epoch=537
06/01/2022 02:37:48 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.19 on epoch=539
06/01/2022 02:37:49 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.22 on epoch=542
06/01/2022 02:37:51 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.22 on epoch=544
06/01/2022 02:37:52 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.20 on epoch=547
06/01/2022 02:37:53 - INFO - __main__ - Step 2200 Global step 2200 Train loss 1.26 on epoch=549
06/01/2022 02:37:54 - INFO - __main__ - Global step 2200 Train loss 1.22 Classification-F1 0.23941798941798942 on epoch=549
06/01/2022 02:37:54 - INFO - __main__ - Saving model with best Classification-F1: 0.22832890218234186 -> 0.23941798941798942 on epoch=549, global_step=2200
06/01/2022 02:37:55 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.27 on epoch=552
06/01/2022 02:37:56 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.20 on epoch=554
06/01/2022 02:37:57 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.16 on epoch=557
06/01/2022 02:37:59 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.19 on epoch=559
06/01/2022 02:38:00 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.21 on epoch=562
06/01/2022 02:38:00 - INFO - __main__ - Global step 2250 Train loss 1.21 Classification-F1 0.2190620929222753 on epoch=562
06/01/2022 02:38:02 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.08 on epoch=564
06/01/2022 02:38:03 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.15 on epoch=567
06/01/2022 02:38:04 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.30 on epoch=569
06/01/2022 02:38:05 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.27 on epoch=572
06/01/2022 02:38:07 - INFO - __main__ - Step 2300 Global step 2300 Train loss 1.06 on epoch=574
06/01/2022 02:38:07 - INFO - __main__ - Global step 2300 Train loss 1.18 Classification-F1 0.19957983193277312 on epoch=574
06/01/2022 02:38:08 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.37 on epoch=577
06/01/2022 02:38:10 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.11 on epoch=579
06/01/2022 02:38:11 - INFO - __main__ - Step 2330 Global step 2330 Train loss 1.32 on epoch=582
06/01/2022 02:38:12 - INFO - __main__ - Step 2340 Global step 2340 Train loss 1.10 on epoch=584
06/01/2022 02:38:13 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.24 on epoch=587
06/01/2022 02:38:14 - INFO - __main__ - Global step 2350 Train loss 1.23 Classification-F1 0.14777327935222673 on epoch=587
06/01/2022 02:38:15 - INFO - __main__ - Step 2360 Global step 2360 Train loss 1.05 on epoch=589
06/01/2022 02:38:16 - INFO - __main__ - Step 2370 Global step 2370 Train loss 1.22 on epoch=592
06/01/2022 02:38:17 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.05 on epoch=594
06/01/2022 02:38:19 - INFO - __main__ - Step 2390 Global step 2390 Train loss 1.09 on epoch=597
06/01/2022 02:38:20 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.13 on epoch=599
06/01/2022 02:38:20 - INFO - __main__ - Global step 2400 Train loss 1.11 Classification-F1 0.1565349544072948 on epoch=599
06/01/2022 02:38:22 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.25 on epoch=602
06/01/2022 02:38:23 - INFO - __main__ - Step 2420 Global step 2420 Train loss 1.10 on epoch=604
06/01/2022 02:38:24 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.02 on epoch=607
06/01/2022 02:38:25 - INFO - __main__ - Step 2440 Global step 2440 Train loss 1.12 on epoch=609
06/01/2022 02:38:27 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.13 on epoch=612
06/01/2022 02:38:27 - INFO - __main__ - Global step 2450 Train loss 1.13 Classification-F1 0.1 on epoch=612
06/01/2022 02:38:28 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.06 on epoch=614
06/01/2022 02:38:30 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.09 on epoch=617
06/01/2022 02:38:31 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.21 on epoch=619
06/01/2022 02:38:32 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.10 on epoch=622
06/01/2022 02:38:33 - INFO - __main__ - Step 2500 Global step 2500 Train loss 1.22 on epoch=624
06/01/2022 02:38:34 - INFO - __main__ - Global step 2500 Train loss 1.14 Classification-F1 0.1302118933697881 on epoch=624
06/01/2022 02:38:35 - INFO - __main__ - Step 2510 Global step 2510 Train loss 1.31 on epoch=627
06/01/2022 02:38:36 - INFO - __main__ - Step 2520 Global step 2520 Train loss 1.14 on epoch=629
06/01/2022 02:38:37 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.29 on epoch=632
06/01/2022 02:38:39 - INFO - __main__ - Step 2540 Global step 2540 Train loss 1.06 on epoch=634
06/01/2022 02:38:40 - INFO - __main__ - Step 2550 Global step 2550 Train loss 1.20 on epoch=637
06/01/2022 02:38:40 - INFO - __main__ - Global step 2550 Train loss 1.20 Classification-F1 0.09493670886075949 on epoch=637
06/01/2022 02:38:42 - INFO - __main__ - Step 2560 Global step 2560 Train loss 1.17 on epoch=639
06/01/2022 02:38:43 - INFO - __main__ - Step 2570 Global step 2570 Train loss 1.17 on epoch=642
06/01/2022 02:38:44 - INFO - __main__ - Step 2580 Global step 2580 Train loss 1.26 on epoch=644
06/01/2022 02:38:45 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.13 on epoch=647
06/01/2022 02:38:47 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.12 on epoch=649
06/01/2022 02:38:47 - INFO - __main__ - Global step 2600 Train loss 1.17 Classification-F1 0.1 on epoch=649
06/01/2022 02:38:48 - INFO - __main__ - Step 2610 Global step 2610 Train loss 1.19 on epoch=652
06/01/2022 02:38:50 - INFO - __main__ - Step 2620 Global step 2620 Train loss 1.11 on epoch=654
06/01/2022 02:38:51 - INFO - __main__ - Step 2630 Global step 2630 Train loss 1.20 on epoch=657
06/01/2022 02:38:52 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.12 on epoch=659
06/01/2022 02:38:53 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.03 on epoch=662
06/01/2022 02:38:54 - INFO - __main__ - Global step 2650 Train loss 1.13 Classification-F1 0.1 on epoch=662
06/01/2022 02:38:55 - INFO - __main__ - Step 2660 Global step 2660 Train loss 1.12 on epoch=664
06/01/2022 02:38:56 - INFO - __main__ - Step 2670 Global step 2670 Train loss 1.15 on epoch=667
06/01/2022 02:38:57 - INFO - __main__ - Step 2680 Global step 2680 Train loss 1.08 on epoch=669
06/01/2022 02:38:59 - INFO - __main__ - Step 2690 Global step 2690 Train loss 1.06 on epoch=672
06/01/2022 02:39:00 - INFO - __main__ - Step 2700 Global step 2700 Train loss 1.10 on epoch=674
06/01/2022 02:39:00 - INFO - __main__ - Global step 2700 Train loss 1.10 Classification-F1 0.1 on epoch=674
06/01/2022 02:39:02 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.02 on epoch=677
06/01/2022 02:39:03 - INFO - __main__ - Step 2720 Global step 2720 Train loss 1.13 on epoch=679
06/01/2022 02:39:04 - INFO - __main__ - Step 2730 Global step 2730 Train loss 1.14 on epoch=682
06/01/2022 02:39:05 - INFO - __main__ - Step 2740 Global step 2740 Train loss 1.02 on epoch=684
06/01/2022 02:39:07 - INFO - __main__ - Step 2750 Global step 2750 Train loss 1.12 on epoch=687
06/01/2022 02:39:07 - INFO - __main__ - Global step 2750 Train loss 1.09 Classification-F1 0.09615384615384615 on epoch=687
06/01/2022 02:39:08 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.18 on epoch=689
06/01/2022 02:39:09 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.16 on epoch=692
06/01/2022 02:39:11 - INFO - __main__ - Step 2780 Global step 2780 Train loss 1.06 on epoch=694
06/01/2022 02:39:12 - INFO - __main__ - Step 2790 Global step 2790 Train loss 1.08 on epoch=697
06/01/2022 02:39:13 - INFO - __main__ - Step 2800 Global step 2800 Train loss 1.12 on epoch=699
06/01/2022 02:39:14 - INFO - __main__ - Global step 2800 Train loss 1.12 Classification-F1 0.1237183868762816 on epoch=699
06/01/2022 02:39:15 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.20 on epoch=702
06/01/2022 02:39:16 - INFO - __main__ - Step 2820 Global step 2820 Train loss 1.11 on epoch=704
06/01/2022 02:39:17 - INFO - __main__ - Step 2830 Global step 2830 Train loss 1.11 on epoch=707
06/01/2022 02:39:19 - INFO - __main__ - Step 2840 Global step 2840 Train loss 1.00 on epoch=709
06/01/2022 02:39:20 - INFO - __main__ - Step 2850 Global step 2850 Train loss 1.12 on epoch=712
06/01/2022 02:39:20 - INFO - __main__ - Global step 2850 Train loss 1.11 Classification-F1 0.16515151515151516 on epoch=712
06/01/2022 02:39:22 - INFO - __main__ - Step 2860 Global step 2860 Train loss 1.01 on epoch=714
06/01/2022 02:39:23 - INFO - __main__ - Step 2870 Global step 2870 Train loss 1.14 on epoch=717
06/01/2022 02:39:24 - INFO - __main__ - Step 2880 Global step 2880 Train loss 1.19 on epoch=719
06/01/2022 02:39:25 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.25 on epoch=722
06/01/2022 02:39:27 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.05 on epoch=724
06/01/2022 02:39:27 - INFO - __main__ - Global step 2900 Train loss 1.13 Classification-F1 0.18284347231715653 on epoch=724
06/01/2022 02:39:28 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.13 on epoch=727
06/01/2022 02:39:29 - INFO - __main__ - Step 2920 Global step 2920 Train loss 1.09 on epoch=729
06/01/2022 02:39:31 - INFO - __main__ - Step 2930 Global step 2930 Train loss 1.00 on epoch=732
06/01/2022 02:39:32 - INFO - __main__ - Step 2940 Global step 2940 Train loss 1.15 on epoch=734
06/01/2022 02:39:33 - INFO - __main__ - Step 2950 Global step 2950 Train loss 1.06 on epoch=737
06/01/2022 02:39:34 - INFO - __main__ - Global step 2950 Train loss 1.09 Classification-F1 0.23973977889027953 on epoch=737
06/01/2022 02:39:34 - INFO - __main__ - Saving model with best Classification-F1: 0.23941798941798942 -> 0.23973977889027953 on epoch=737, global_step=2950
06/01/2022 02:39:35 - INFO - __main__ - Step 2960 Global step 2960 Train loss 1.04 on epoch=739
06/01/2022 02:39:36 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.07 on epoch=742
06/01/2022 02:39:37 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.13 on epoch=744
06/01/2022 02:39:39 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.99 on epoch=747
06/01/2022 02:39:40 - INFO - __main__ - Step 3000 Global step 3000 Train loss 1.03 on epoch=749
06/01/2022 02:39:40 - INFO - __main__ - Global step 3000 Train loss 1.05 Classification-F1 0.13067758749069247 on epoch=749
06/01/2022 02:39:40 - INFO - __main__ - save last model!
06/01/2022 02:39:40 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/01/2022 02:39:40 - INFO - __main__ - Start tokenizing ... 5509 instances
06/01/2022 02:39:40 - INFO - __main__ - Printing 3 examples
06/01/2022 02:39:40 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/01/2022 02:39:40 - INFO - __main__ - ['others']
06/01/2022 02:39:40 - INFO - __main__ -  [emo] what you like very little things ok
06/01/2022 02:39:40 - INFO - __main__ - ['others']
06/01/2022 02:39:40 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/01/2022 02:39:40 - INFO - __main__ - ['others']
06/01/2022 02:39:40 - INFO - __main__ - Tokenizing Input ...
06/01/2022 02:39:41 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 02:39:41 - INFO - __main__ - Printing 3 examples
06/01/2022 02:39:41 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/01/2022 02:39:41 - INFO - __main__ - ['others']
06/01/2022 02:39:41 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/01/2022 02:39:41 - INFO - __main__ - ['others']
06/01/2022 02:39:41 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/01/2022 02:39:41 - INFO - __main__ - ['others']
06/01/2022 02:39:41 - INFO - __main__ - Tokenizing Input ...
06/01/2022 02:39:41 - INFO - __main__ - Tokenizing Output ...
06/01/2022 02:39:41 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 02:39:41 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 02:39:41 - INFO - __main__ - Printing 3 examples
06/01/2022 02:39:41 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
06/01/2022 02:39:41 - INFO - __main__ - ['others']
06/01/2022 02:39:41 - INFO - __main__ -  [emo] i did ask now you did tell ms
06/01/2022 02:39:41 - INFO - __main__ - ['others']
06/01/2022 02:39:41 - INFO - __main__ -  [emo] buddy how you tell me your contact no
06/01/2022 02:39:41 - INFO - __main__ - ['others']
06/01/2022 02:39:41 - INFO - __main__ - Tokenizing Input ...
06/01/2022 02:39:41 - INFO - __main__ - Tokenizing Output ...
06/01/2022 02:39:41 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 02:39:42 - INFO - __main__ - Tokenizing Output ...
06/01/2022 02:39:47 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 02:39:47 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/01/2022 02:39:47 - INFO - __main__ - Starting training!
06/01/2022 02:39:48 - INFO - __main__ - Loaded 5509 examples from test data
06/01/2022 02:40:31 - INFO - __main__ - Saved prediction in models/T5-base-reptile-cls2cls-3e-5-2-5000-5e-1-10/singletask-emo/emo_16_100_0.2_8_predictions.txt
06/01/2022 02:40:31 - INFO - __main__ - Classification-F1 on test data: 0.0314
06/01/2022 02:40:31 - INFO - __main__ - prefix=emo_16_100, lr=0.2, bsz=8, dev_performance=0.23973977889027953, test_performance=0.031425552753034214
06/01/2022 02:40:31 - INFO - __main__ - Running ... prefix=emo_16_13, lr=0.5, bsz=8 ...
06/01/2022 02:40:32 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 02:40:32 - INFO - __main__ - Printing 3 examples
06/01/2022 02:40:32 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/01/2022 02:40:32 - INFO - __main__ - ['others']
06/01/2022 02:40:32 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/01/2022 02:40:32 - INFO - __main__ - ['others']
06/01/2022 02:40:32 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/01/2022 02:40:32 - INFO - __main__ - ['others']
06/01/2022 02:40:32 - INFO - __main__ - Tokenizing Input ...
06/01/2022 02:40:32 - INFO - __main__ - Tokenizing Output ...
06/01/2022 02:40:32 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 02:40:32 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 02:40:32 - INFO - __main__ - Printing 3 examples
06/01/2022 02:40:32 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
06/01/2022 02:40:32 - INFO - __main__ - ['others']
06/01/2022 02:40:32 - INFO - __main__ -  [emo] i did ask now you did tell ms
06/01/2022 02:40:32 - INFO - __main__ - ['others']
06/01/2022 02:40:32 - INFO - __main__ -  [emo] buddy how you tell me your contact no
06/01/2022 02:40:32 - INFO - __main__ - ['others']
06/01/2022 02:40:32 - INFO - __main__ - Tokenizing Input ...
06/01/2022 02:40:32 - INFO - __main__ - Tokenizing Output ...
06/01/2022 02:40:32 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 02:40:38 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 02:40:38 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/01/2022 02:40:38 - INFO - __main__ - Starting training!
06/01/2022 02:40:40 - INFO - __main__ - Step 10 Global step 10 Train loss 9.02 on epoch=2
06/01/2022 02:40:41 - INFO - __main__ - Step 20 Global step 20 Train loss 8.94 on epoch=4
06/01/2022 02:40:42 - INFO - __main__ - Step 30 Global step 30 Train loss 8.81 on epoch=7
06/01/2022 02:40:43 - INFO - __main__ - Step 40 Global step 40 Train loss 8.91 on epoch=9
06/01/2022 02:40:45 - INFO - __main__ - Step 50 Global step 50 Train loss 8.63 on epoch=12
06/01/2022 02:40:49 - INFO - __main__ - Global step 50 Train loss 8.86 Classification-F1 0.0 on epoch=12
06/01/2022 02:40:49 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
06/01/2022 02:40:51 - INFO - __main__ - Step 60 Global step 60 Train loss 8.60 on epoch=14
06/01/2022 02:40:52 - INFO - __main__ - Step 70 Global step 70 Train loss 8.50 on epoch=17
06/01/2022 02:40:53 - INFO - __main__ - Step 80 Global step 80 Train loss 8.34 on epoch=19
06/01/2022 02:40:54 - INFO - __main__ - Step 90 Global step 90 Train loss 8.16 on epoch=22
06/01/2022 02:40:56 - INFO - __main__ - Step 100 Global step 100 Train loss 8.04 on epoch=24
06/01/2022 02:41:10 - INFO - __main__ - Global step 100 Train loss 8.33 Classification-F1 0.0 on epoch=24
06/01/2022 02:41:12 - INFO - __main__ - Step 110 Global step 110 Train loss 7.73 on epoch=27
06/01/2022 02:41:13 - INFO - __main__ - Step 120 Global step 120 Train loss 7.63 on epoch=29
06/01/2022 02:41:14 - INFO - __main__ - Step 130 Global step 130 Train loss 7.62 on epoch=32
06/01/2022 02:41:15 - INFO - __main__ - Step 140 Global step 140 Train loss 7.33 on epoch=34
06/01/2022 02:41:17 - INFO - __main__ - Step 150 Global step 150 Train loss 7.02 on epoch=37
06/01/2022 02:41:22 - INFO - __main__ - Global step 150 Train loss 7.47 Classification-F1 0.0 on epoch=37
06/01/2022 02:41:23 - INFO - __main__ - Step 160 Global step 160 Train loss 6.82 on epoch=39
06/01/2022 02:41:24 - INFO - __main__ - Step 170 Global step 170 Train loss 6.65 on epoch=42
06/01/2022 02:41:25 - INFO - __main__ - Step 180 Global step 180 Train loss 6.37 on epoch=44
06/01/2022 02:41:27 - INFO - __main__ - Step 190 Global step 190 Train loss 6.41 on epoch=47
06/01/2022 02:41:28 - INFO - __main__ - Step 200 Global step 200 Train loss 6.01 on epoch=49
06/01/2022 02:41:32 - INFO - __main__ - Global step 200 Train loss 6.45 Classification-F1 0.0 on epoch=49
06/01/2022 02:41:33 - INFO - __main__ - Step 210 Global step 210 Train loss 5.89 on epoch=52
06/01/2022 02:41:35 - INFO - __main__ - Step 220 Global step 220 Train loss 5.59 on epoch=54
06/01/2022 02:41:36 - INFO - __main__ - Step 230 Global step 230 Train loss 5.64 on epoch=57
06/01/2022 02:41:37 - INFO - __main__ - Step 240 Global step 240 Train loss 5.42 on epoch=59
06/01/2022 02:41:38 - INFO - __main__ - Step 250 Global step 250 Train loss 5.19 on epoch=62
06/01/2022 02:41:53 - INFO - __main__ - Global step 250 Train loss 5.54 Classification-F1 0.0 on epoch=62
06/01/2022 02:41:54 - INFO - __main__ - Step 260 Global step 260 Train loss 5.14 on epoch=64
06/01/2022 02:41:55 - INFO - __main__ - Step 270 Global step 270 Train loss 4.96 on epoch=67
06/01/2022 02:41:56 - INFO - __main__ - Step 280 Global step 280 Train loss 4.73 on epoch=69
06/01/2022 02:41:58 - INFO - __main__ - Step 290 Global step 290 Train loss 4.82 on epoch=72
06/01/2022 02:41:59 - INFO - __main__ - Step 300 Global step 300 Train loss 4.44 on epoch=74
06/01/2022 02:42:03 - INFO - __main__ - Global step 300 Train loss 4.82 Classification-F1 0.0 on epoch=74
06/01/2022 02:42:05 - INFO - __main__ - Step 310 Global step 310 Train loss 4.50 on epoch=77
06/01/2022 02:42:06 - INFO - __main__ - Step 320 Global step 320 Train loss 4.19 on epoch=79
06/01/2022 02:42:07 - INFO - __main__ - Step 330 Global step 330 Train loss 4.19 on epoch=82
06/01/2022 02:42:08 - INFO - __main__ - Step 340 Global step 340 Train loss 3.96 on epoch=84
06/01/2022 02:42:10 - INFO - __main__ - Step 350 Global step 350 Train loss 3.86 on epoch=87
06/01/2022 02:42:12 - INFO - __main__ - Global step 350 Train loss 4.14 Classification-F1 0.06356356356356356 on epoch=87
06/01/2022 02:42:12 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.06356356356356356 on epoch=87, global_step=350
06/01/2022 02:42:13 - INFO - __main__ - Step 360 Global step 360 Train loss 3.81 on epoch=89
06/01/2022 02:42:14 - INFO - __main__ - Step 370 Global step 370 Train loss 3.89 on epoch=92
06/01/2022 02:42:16 - INFO - __main__ - Step 380 Global step 380 Train loss 3.40 on epoch=94
06/01/2022 02:42:17 - INFO - __main__ - Step 390 Global step 390 Train loss 3.67 on epoch=97
06/01/2022 02:42:18 - INFO - __main__ - Step 400 Global step 400 Train loss 3.34 on epoch=99
06/01/2022 02:42:19 - INFO - __main__ - Global step 400 Train loss 3.62 Classification-F1 0.13434704830053668 on epoch=99
06/01/2022 02:42:19 - INFO - __main__ - Saving model with best Classification-F1: 0.06356356356356356 -> 0.13434704830053668 on epoch=99, global_step=400
06/01/2022 02:42:20 - INFO - __main__ - Step 410 Global step 410 Train loss 3.46 on epoch=102
06/01/2022 02:42:21 - INFO - __main__ - Step 420 Global step 420 Train loss 3.10 on epoch=104
06/01/2022 02:42:23 - INFO - __main__ - Step 430 Global step 430 Train loss 3.11 on epoch=107
06/01/2022 02:42:24 - INFO - __main__ - Step 440 Global step 440 Train loss 2.81 on epoch=109
06/01/2022 02:42:25 - INFO - __main__ - Step 450 Global step 450 Train loss 3.24 on epoch=112
06/01/2022 02:42:26 - INFO - __main__ - Global step 450 Train loss 3.14 Classification-F1 0.17328042328042326 on epoch=112
06/01/2022 02:42:26 - INFO - __main__ - Saving model with best Classification-F1: 0.13434704830053668 -> 0.17328042328042326 on epoch=112, global_step=450
06/01/2022 02:42:27 - INFO - __main__ - Step 460 Global step 460 Train loss 2.95 on epoch=114
06/01/2022 02:42:28 - INFO - __main__ - Step 470 Global step 470 Train loss 2.98 on epoch=117
06/01/2022 02:42:30 - INFO - __main__ - Step 480 Global step 480 Train loss 2.68 on epoch=119
06/01/2022 02:42:31 - INFO - __main__ - Step 490 Global step 490 Train loss 2.77 on epoch=122
06/01/2022 02:42:32 - INFO - __main__ - Step 500 Global step 500 Train loss 2.49 on epoch=124
06/01/2022 02:42:33 - INFO - __main__ - Global step 500 Train loss 2.78 Classification-F1 0.164021164021164 on epoch=124
06/01/2022 02:42:34 - INFO - __main__ - Step 510 Global step 510 Train loss 2.54 on epoch=127
06/01/2022 02:42:35 - INFO - __main__ - Step 520 Global step 520 Train loss 2.53 on epoch=129
06/01/2022 02:42:36 - INFO - __main__ - Step 530 Global step 530 Train loss 2.39 on epoch=132
06/01/2022 02:42:38 - INFO - __main__ - Step 540 Global step 540 Train loss 2.29 on epoch=134
06/01/2022 02:42:39 - INFO - __main__ - Step 550 Global step 550 Train loss 2.29 on epoch=137
06/01/2022 02:42:39 - INFO - __main__ - Global step 550 Train loss 2.41 Classification-F1 0.11859154929577466 on epoch=137
06/01/2022 02:42:41 - INFO - __main__ - Step 560 Global step 560 Train loss 2.10 on epoch=139
06/01/2022 02:42:42 - INFO - __main__ - Step 570 Global step 570 Train loss 2.04 on epoch=142
06/01/2022 02:42:43 - INFO - __main__ - Step 580 Global step 580 Train loss 2.04 on epoch=144
06/01/2022 02:42:45 - INFO - __main__ - Step 590 Global step 590 Train loss 1.96 on epoch=147
06/01/2022 02:42:46 - INFO - __main__ - Step 600 Global step 600 Train loss 1.77 on epoch=149
06/01/2022 02:42:46 - INFO - __main__ - Global step 600 Train loss 1.98 Classification-F1 0.1825396825396825 on epoch=149
06/01/2022 02:42:46 - INFO - __main__ - Saving model with best Classification-F1: 0.17328042328042326 -> 0.1825396825396825 on epoch=149, global_step=600
06/01/2022 02:42:48 - INFO - __main__ - Step 610 Global step 610 Train loss 1.84 on epoch=152
06/01/2022 02:42:49 - INFO - __main__ - Step 620 Global step 620 Train loss 1.77 on epoch=154
06/01/2022 02:42:50 - INFO - __main__ - Step 630 Global step 630 Train loss 1.64 on epoch=157
06/01/2022 02:42:52 - INFO - __main__ - Step 640 Global step 640 Train loss 1.56 on epoch=159
06/01/2022 02:42:53 - INFO - __main__ - Step 650 Global step 650 Train loss 1.61 on epoch=162
06/01/2022 02:42:54 - INFO - __main__ - Global step 650 Train loss 1.68 Classification-F1 0.10126582278481013 on epoch=162
06/01/2022 02:42:55 - INFO - __main__ - Step 660 Global step 660 Train loss 1.57 on epoch=164
06/01/2022 02:42:56 - INFO - __main__ - Step 670 Global step 670 Train loss 1.50 on epoch=167
06/01/2022 02:42:57 - INFO - __main__ - Step 680 Global step 680 Train loss 1.62 on epoch=169
06/01/2022 02:42:58 - INFO - __main__ - Step 690 Global step 690 Train loss 1.61 on epoch=172
06/01/2022 02:43:00 - INFO - __main__ - Step 700 Global step 700 Train loss 1.41 on epoch=174
06/01/2022 02:43:00 - INFO - __main__ - Global step 700 Train loss 1.54 Classification-F1 0.1302118933697881 on epoch=174
06/01/2022 02:43:02 - INFO - __main__ - Step 710 Global step 710 Train loss 1.53 on epoch=177
06/01/2022 02:43:03 - INFO - __main__ - Step 720 Global step 720 Train loss 1.39 on epoch=179
06/01/2022 02:43:04 - INFO - __main__ - Step 730 Global step 730 Train loss 1.52 on epoch=182
06/01/2022 02:43:05 - INFO - __main__ - Step 740 Global step 740 Train loss 1.37 on epoch=184
06/01/2022 02:43:07 - INFO - __main__ - Step 750 Global step 750 Train loss 1.34 on epoch=187
06/01/2022 02:43:07 - INFO - __main__ - Global step 750 Train loss 1.43 Classification-F1 0.16953316953316955 on epoch=187
06/01/2022 02:43:08 - INFO - __main__ - Step 760 Global step 760 Train loss 1.21 on epoch=189
06/01/2022 02:43:10 - INFO - __main__ - Step 770 Global step 770 Train loss 1.27 on epoch=192
06/01/2022 02:43:11 - INFO - __main__ - Step 780 Global step 780 Train loss 1.36 on epoch=194
06/01/2022 02:43:12 - INFO - __main__ - Step 790 Global step 790 Train loss 1.27 on epoch=197
06/01/2022 02:43:13 - INFO - __main__ - Step 800 Global step 800 Train loss 1.10 on epoch=199
06/01/2022 02:43:14 - INFO - __main__ - Global step 800 Train loss 1.24 Classification-F1 0.1 on epoch=199
06/01/2022 02:43:15 - INFO - __main__ - Step 810 Global step 810 Train loss 1.32 on epoch=202
06/01/2022 02:43:16 - INFO - __main__ - Step 820 Global step 820 Train loss 1.29 on epoch=204
06/01/2022 02:43:18 - INFO - __main__ - Step 830 Global step 830 Train loss 1.25 on epoch=207
06/01/2022 02:43:19 - INFO - __main__ - Step 840 Global step 840 Train loss 1.11 on epoch=209
06/01/2022 02:43:20 - INFO - __main__ - Step 850 Global step 850 Train loss 1.19 on epoch=212
06/01/2022 02:43:21 - INFO - __main__ - Global step 850 Train loss 1.23 Classification-F1 0.10126582278481013 on epoch=212
06/01/2022 02:43:22 - INFO - __main__ - Step 860 Global step 860 Train loss 1.23 on epoch=214
06/01/2022 02:43:23 - INFO - __main__ - Step 870 Global step 870 Train loss 1.18 on epoch=217
06/01/2022 02:43:25 - INFO - __main__ - Step 880 Global step 880 Train loss 1.18 on epoch=219
06/01/2022 02:43:26 - INFO - __main__ - Step 890 Global step 890 Train loss 1.13 on epoch=222
06/01/2022 02:43:27 - INFO - __main__ - Step 900 Global step 900 Train loss 1.20 on epoch=224
06/01/2022 02:43:28 - INFO - __main__ - Global step 900 Train loss 1.18 Classification-F1 0.17436974789915968 on epoch=224
06/01/2022 02:43:29 - INFO - __main__ - Step 910 Global step 910 Train loss 1.15 on epoch=227
06/01/2022 02:43:30 - INFO - __main__ - Step 920 Global step 920 Train loss 1.26 on epoch=229
06/01/2022 02:43:31 - INFO - __main__ - Step 930 Global step 930 Train loss 1.25 on epoch=232
06/01/2022 02:43:33 - INFO - __main__ - Step 940 Global step 940 Train loss 1.16 on epoch=234
06/01/2022 02:43:34 - INFO - __main__ - Step 950 Global step 950 Train loss 1.11 on epoch=237
06/01/2022 02:43:34 - INFO - __main__ - Global step 950 Train loss 1.19 Classification-F1 0.12393162393162392 on epoch=237
06/01/2022 02:43:36 - INFO - __main__ - Step 960 Global step 960 Train loss 1.24 on epoch=239
06/01/2022 02:43:37 - INFO - __main__ - Step 970 Global step 970 Train loss 1.14 on epoch=242
06/01/2022 02:43:38 - INFO - __main__ - Step 980 Global step 980 Train loss 1.20 on epoch=244
06/01/2022 02:43:40 - INFO - __main__ - Step 990 Global step 990 Train loss 1.29 on epoch=247
06/01/2022 02:43:41 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.40 on epoch=249
06/01/2022 02:43:41 - INFO - __main__ - Global step 1000 Train loss 1.25 Classification-F1 0.13777777777777778 on epoch=249
06/01/2022 02:43:43 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.09 on epoch=252
06/01/2022 02:43:44 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.13 on epoch=254
06/01/2022 02:43:45 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.12 on epoch=257
06/01/2022 02:43:46 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.11 on epoch=259
06/01/2022 02:43:48 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.26 on epoch=262
06/01/2022 02:43:48 - INFO - __main__ - Global step 1050 Train loss 1.14 Classification-F1 0.1302118933697881 on epoch=262
06/01/2022 02:43:49 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.08 on epoch=264
06/01/2022 02:43:51 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.12 on epoch=267
06/01/2022 02:43:52 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.21 on epoch=269
06/01/2022 02:43:53 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.13 on epoch=272
06/01/2022 02:43:54 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.04 on epoch=274
06/01/2022 02:43:55 - INFO - __main__ - Global step 1100 Train loss 1.11 Classification-F1 0.1 on epoch=274
06/01/2022 02:43:56 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.25 on epoch=277
06/01/2022 02:43:58 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.28 on epoch=279
06/01/2022 02:43:59 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.18 on epoch=282
06/01/2022 02:44:00 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.16 on epoch=284
06/01/2022 02:44:01 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.13 on epoch=287
06/01/2022 02:44:02 - INFO - __main__ - Global step 1150 Train loss 1.20 Classification-F1 0.12368421052631579 on epoch=287
06/01/2022 02:44:03 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.99 on epoch=289
06/01/2022 02:44:04 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.10 on epoch=292
06/01/2022 02:44:06 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.20 on epoch=294
06/01/2022 02:44:07 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.11 on epoch=297
06/01/2022 02:44:08 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.09 on epoch=299
06/01/2022 02:44:09 - INFO - __main__ - Global step 1200 Train loss 1.10 Classification-F1 0.09615384615384615 on epoch=299
06/01/2022 02:44:10 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.15 on epoch=302
06/01/2022 02:44:11 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.06 on epoch=304
06/01/2022 02:44:12 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.04 on epoch=307
06/01/2022 02:44:14 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.11 on epoch=309
06/01/2022 02:44:15 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.28 on epoch=312
06/01/2022 02:44:15 - INFO - __main__ - Global step 1250 Train loss 1.13 Classification-F1 0.1 on epoch=312
06/01/2022 02:44:17 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.07 on epoch=314
06/01/2022 02:44:18 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.13 on epoch=317
06/01/2022 02:44:19 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.08 on epoch=319
06/01/2022 02:44:20 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.00 on epoch=322
06/01/2022 02:44:22 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.06 on epoch=324
06/01/2022 02:44:22 - INFO - __main__ - Global step 1300 Train loss 1.07 Classification-F1 0.1 on epoch=324
06/01/2022 02:44:23 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.15 on epoch=327
06/01/2022 02:44:25 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.21 on epoch=329
06/01/2022 02:44:26 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.00 on epoch=332
06/01/2022 02:44:27 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.01 on epoch=334
06/01/2022 02:44:28 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.19 on epoch=337
06/01/2022 02:44:29 - INFO - __main__ - Global step 1350 Train loss 1.11 Classification-F1 0.09615384615384615 on epoch=337
06/01/2022 02:44:30 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.10 on epoch=339
06/01/2022 02:44:32 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.01 on epoch=342
06/01/2022 02:44:33 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.04 on epoch=344
06/01/2022 02:44:34 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.15 on epoch=347
06/01/2022 02:44:35 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.04 on epoch=349
06/01/2022 02:44:36 - INFO - __main__ - Global step 1400 Train loss 1.07 Classification-F1 0.10126582278481013 on epoch=349
06/01/2022 02:44:37 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.23 on epoch=352
06/01/2022 02:44:38 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.08 on epoch=354
06/01/2022 02:44:40 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.97 on epoch=357
06/01/2022 02:44:41 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.98 on epoch=359
06/01/2022 02:44:42 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.04 on epoch=362
06/01/2022 02:44:43 - INFO - __main__ - Global step 1450 Train loss 1.06 Classification-F1 0.10389610389610389 on epoch=362
06/01/2022 02:44:44 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.02 on epoch=364
06/01/2022 02:44:45 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.09 on epoch=367
06/01/2022 02:44:46 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.07 on epoch=369
06/01/2022 02:44:48 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.03 on epoch=372
06/01/2022 02:44:49 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.08 on epoch=374
06/01/2022 02:44:50 - INFO - __main__ - Global step 1500 Train loss 1.06 Classification-F1 0.1 on epoch=374
06/01/2022 02:44:51 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.06 on epoch=377
06/01/2022 02:44:52 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.94 on epoch=379
06/01/2022 02:44:53 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.11 on epoch=382
06/01/2022 02:44:55 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.09 on epoch=384
06/01/2022 02:44:56 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.96 on epoch=387
06/01/2022 02:44:56 - INFO - __main__ - Global step 1550 Train loss 1.03 Classification-F1 0.10389610389610389 on epoch=387
06/01/2022 02:44:58 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.88 on epoch=389
06/01/2022 02:44:59 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.13 on epoch=392
06/01/2022 02:45:00 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.05 on epoch=394
06/01/2022 02:45:01 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.09 on epoch=397
06/01/2022 02:45:03 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.16 on epoch=399
06/01/2022 02:45:03 - INFO - __main__ - Global step 1600 Train loss 1.06 Classification-F1 0.1 on epoch=399
06/01/2022 02:45:04 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.10 on epoch=402
06/01/2022 02:45:06 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.09 on epoch=404
06/01/2022 02:45:07 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.08 on epoch=407
06/01/2022 02:45:08 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.05 on epoch=409
06/01/2022 02:45:09 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.07 on epoch=412
06/01/2022 02:45:10 - INFO - __main__ - Global step 1650 Train loss 1.08 Classification-F1 0.13034188034188032 on epoch=412
06/01/2022 02:45:11 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.05 on epoch=414
06/01/2022 02:45:13 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.96 on epoch=417
06/01/2022 02:45:14 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.07 on epoch=419
06/01/2022 02:45:15 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.08 on epoch=422
06/01/2022 02:45:16 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.97 on epoch=424
06/01/2022 02:45:17 - INFO - __main__ - Global step 1700 Train loss 1.03 Classification-F1 0.1 on epoch=424
06/01/2022 02:45:18 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.06 on epoch=427
06/01/2022 02:45:19 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.07 on epoch=429
06/01/2022 02:45:21 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.99 on epoch=432
06/01/2022 02:45:22 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.94 on epoch=434
06/01/2022 02:45:23 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.95 on epoch=437
06/01/2022 02:45:24 - INFO - __main__ - Global step 1750 Train loss 1.00 Classification-F1 0.1 on epoch=437
06/01/2022 02:45:25 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.03 on epoch=439
06/01/2022 02:45:26 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.97 on epoch=442
06/01/2022 02:45:28 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.97 on epoch=444
06/01/2022 02:45:29 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.06 on epoch=447
06/01/2022 02:45:30 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.03 on epoch=449
06/01/2022 02:45:31 - INFO - __main__ - Global step 1800 Train loss 1.01 Classification-F1 0.1 on epoch=449
06/01/2022 02:45:32 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.96 on epoch=452
06/01/2022 02:45:33 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.02 on epoch=454
06/01/2022 02:45:34 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.01 on epoch=457
06/01/2022 02:45:36 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.99 on epoch=459
06/01/2022 02:45:37 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.03 on epoch=462
06/01/2022 02:45:37 - INFO - __main__ - Global step 1850 Train loss 1.01 Classification-F1 0.09493670886075949 on epoch=462
06/01/2022 02:45:39 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.01 on epoch=464
06/01/2022 02:45:40 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.01 on epoch=467
06/01/2022 02:45:41 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.04 on epoch=469
06/01/2022 02:45:42 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.06 on epoch=472
06/01/2022 02:45:44 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.97 on epoch=474
06/01/2022 02:45:44 - INFO - __main__ - Global step 1900 Train loss 1.02 Classification-F1 0.13026315789473686 on epoch=474
06/01/2022 02:45:45 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.94 on epoch=477
06/01/2022 02:45:47 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.06 on epoch=479
06/01/2022 02:45:48 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.05 on epoch=482
06/01/2022 02:45:49 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.04 on epoch=484
06/01/2022 02:45:51 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.01 on epoch=487
06/01/2022 02:45:51 - INFO - __main__ - Global step 1950 Train loss 1.02 Classification-F1 0.09615384615384615 on epoch=487
06/01/2022 02:45:52 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.95 on epoch=489
06/01/2022 02:45:54 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.90 on epoch=492
06/01/2022 02:45:55 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.96 on epoch=494
06/01/2022 02:45:56 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.04 on epoch=497
06/01/2022 02:45:57 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.95 on epoch=499
06/01/2022 02:45:58 - INFO - __main__ - Global step 2000 Train loss 0.96 Classification-F1 0.1 on epoch=499
06/01/2022 02:45:59 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.98 on epoch=502
06/01/2022 02:46:00 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.96 on epoch=504
06/01/2022 02:46:02 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.05 on epoch=507
06/01/2022 02:46:03 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.00 on epoch=509
06/01/2022 02:46:04 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.99 on epoch=512
06/01/2022 02:46:05 - INFO - __main__ - Global step 2050 Train loss 0.99 Classification-F1 0.09493670886075949 on epoch=512
06/01/2022 02:46:06 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.01 on epoch=514
06/01/2022 02:46:07 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.01 on epoch=517
06/01/2022 02:46:09 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.07 on epoch=519
06/01/2022 02:46:10 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.01 on epoch=522
06/01/2022 02:46:11 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.07 on epoch=524
06/01/2022 02:46:12 - INFO - __main__ - Global step 2100 Train loss 1.04 Classification-F1 0.12368421052631579 on epoch=524
06/01/2022 02:46:13 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.97 on epoch=527
06/01/2022 02:46:14 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.98 on epoch=529
06/01/2022 02:46:15 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.03 on epoch=532
06/01/2022 02:46:17 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.90 on epoch=534
06/01/2022 02:46:18 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.91 on epoch=537
06/01/2022 02:46:18 - INFO - __main__ - Global step 2150 Train loss 0.96 Classification-F1 0.1623759305210918 on epoch=537
06/01/2022 02:46:20 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.08 on epoch=539
06/01/2022 02:46:21 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.94 on epoch=542
06/01/2022 02:46:22 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.92 on epoch=544
06/01/2022 02:46:23 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.99 on epoch=547
06/01/2022 02:46:25 - INFO - __main__ - Step 2200 Global step 2200 Train loss 1.03 on epoch=549
06/01/2022 02:46:25 - INFO - __main__ - Global step 2200 Train loss 0.99 Classification-F1 0.24441687344913154 on epoch=549
06/01/2022 02:46:25 - INFO - __main__ - Saving model with best Classification-F1: 0.1825396825396825 -> 0.24441687344913154 on epoch=549, global_step=2200
06/01/2022 02:46:26 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.04 on epoch=552
06/01/2022 02:46:28 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.92 on epoch=554
06/01/2022 02:46:29 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.09 on epoch=557
06/01/2022 02:46:30 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.99 on epoch=559
06/01/2022 02:46:31 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.11 on epoch=562
06/01/2022 02:46:32 - INFO - __main__ - Global step 2250 Train loss 1.03 Classification-F1 0.13848631239935588 on epoch=562
06/01/2022 02:46:33 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.94 on epoch=564
06/01/2022 02:46:35 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.93 on epoch=567
06/01/2022 02:46:36 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.01 on epoch=569
06/01/2022 02:46:37 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.95 on epoch=572
06/01/2022 02:46:38 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.91 on epoch=574
06/01/2022 02:46:39 - INFO - __main__ - Global step 2300 Train loss 0.95 Classification-F1 0.1 on epoch=574
06/01/2022 02:46:40 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.95 on epoch=577
06/01/2022 02:46:41 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.90 on epoch=579
06/01/2022 02:46:43 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.94 on epoch=582
06/01/2022 02:46:44 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.95 on epoch=584
06/01/2022 02:46:45 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.91 on epoch=587
06/01/2022 02:46:46 - INFO - __main__ - Global step 2350 Train loss 0.93 Classification-F1 0.2004079254079254 on epoch=587
06/01/2022 02:46:47 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.89 on epoch=589
06/01/2022 02:46:48 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.95 on epoch=592
06/01/2022 02:46:49 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.99 on epoch=594
06/01/2022 02:46:51 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.97 on epoch=597
06/01/2022 02:46:52 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.83 on epoch=599
06/01/2022 02:46:52 - INFO - __main__ - Global step 2400 Train loss 0.93 Classification-F1 0.13067758749069247 on epoch=599
06/01/2022 02:46:54 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.00 on epoch=602
06/01/2022 02:46:55 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.96 on epoch=604
06/01/2022 02:46:56 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.98 on epoch=607
06/01/2022 02:46:57 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.93 on epoch=609
06/01/2022 02:46:59 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.95 on epoch=612
06/01/2022 02:46:59 - INFO - __main__ - Global step 2450 Train loss 0.96 Classification-F1 0.1875 on epoch=612
06/01/2022 02:47:01 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.00 on epoch=614
06/01/2022 02:47:02 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.97 on epoch=617
06/01/2022 02:47:03 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.95 on epoch=619
06/01/2022 02:47:04 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.01 on epoch=622
06/01/2022 02:47:06 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.83 on epoch=624
06/01/2022 02:47:06 - INFO - __main__ - Global step 2500 Train loss 0.95 Classification-F1 0.14004914004914004 on epoch=624
06/01/2022 02:47:07 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.92 on epoch=627
06/01/2022 02:47:09 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.90 on epoch=629
06/01/2022 02:47:10 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.05 on epoch=632
06/01/2022 02:47:11 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.95 on epoch=634
06/01/2022 02:47:12 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.95 on epoch=637
06/01/2022 02:47:13 - INFO - __main__ - Global step 2550 Train loss 0.96 Classification-F1 0.1975609756097561 on epoch=637
06/01/2022 02:47:14 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.97 on epoch=639
06/01/2022 02:47:15 - INFO - __main__ - Step 2570 Global step 2570 Train loss 1.00 on epoch=642
06/01/2022 02:47:17 - INFO - __main__ - Step 2580 Global step 2580 Train loss 1.00 on epoch=644
06/01/2022 02:47:18 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.89 on epoch=647
06/01/2022 02:47:19 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.89 on epoch=649
06/01/2022 02:47:20 - INFO - __main__ - Global step 2600 Train loss 0.95 Classification-F1 0.10256410256410256 on epoch=649
06/01/2022 02:47:21 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.99 on epoch=652
06/01/2022 02:47:22 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.99 on epoch=654
06/01/2022 02:47:23 - INFO - __main__ - Step 2630 Global step 2630 Train loss 1.04 on epoch=657
06/01/2022 02:47:25 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.94 on epoch=659
06/01/2022 02:47:26 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.01 on epoch=662
06/01/2022 02:47:26 - INFO - __main__ - Global step 2650 Train loss 0.99 Classification-F1 0.16110780226325194 on epoch=662
06/01/2022 02:47:28 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.99 on epoch=664
06/01/2022 02:47:29 - INFO - __main__ - Step 2670 Global step 2670 Train loss 1.01 on epoch=667
06/01/2022 02:47:30 - INFO - __main__ - Step 2680 Global step 2680 Train loss 1.03 on epoch=669
06/01/2022 02:47:32 - INFO - __main__ - Step 2690 Global step 2690 Train loss 1.02 on epoch=672
06/01/2022 02:47:33 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.89 on epoch=674
06/01/2022 02:47:33 - INFO - __main__ - Global step 2700 Train loss 0.99 Classification-F1 0.18836850231600616 on epoch=674
06/01/2022 02:47:35 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.91 on epoch=677
06/01/2022 02:47:36 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.89 on epoch=679
06/01/2022 02:47:37 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.96 on epoch=682
06/01/2022 02:47:38 - INFO - __main__ - Step 2740 Global step 2740 Train loss 1.02 on epoch=684
06/01/2022 02:47:40 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.94 on epoch=687
06/01/2022 02:47:40 - INFO - __main__ - Global step 2750 Train loss 0.94 Classification-F1 0.15559772296015179 on epoch=687
06/01/2022 02:47:41 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.93 on epoch=689
06/01/2022 02:47:43 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.05 on epoch=692
06/01/2022 02:47:44 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.99 on epoch=694
06/01/2022 02:47:45 - INFO - __main__ - Step 2790 Global step 2790 Train loss 1.00 on epoch=697
06/01/2022 02:47:46 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.97 on epoch=699
06/01/2022 02:47:47 - INFO - __main__ - Global step 2800 Train loss 0.99 Classification-F1 0.16097560975609757 on epoch=699
06/01/2022 02:47:48 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.07 on epoch=702
06/01/2022 02:47:49 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.99 on epoch=704
06/01/2022 02:47:51 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.94 on epoch=707
06/01/2022 02:47:52 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.95 on epoch=709
06/01/2022 02:47:53 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.92 on epoch=712
06/01/2022 02:47:54 - INFO - __main__ - Global step 2850 Train loss 0.97 Classification-F1 0.14450704225352112 on epoch=712
06/01/2022 02:47:55 - INFO - __main__ - Step 2860 Global step 2860 Train loss 1.01 on epoch=714
06/01/2022 02:47:56 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.86 on epoch=717
06/01/2022 02:47:58 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.98 on epoch=719
06/01/2022 02:47:59 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.90 on epoch=722
06/01/2022 02:48:00 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.86 on epoch=724
06/01/2022 02:48:01 - INFO - __main__ - Global step 2900 Train loss 0.92 Classification-F1 0.10126582278481013 on epoch=724
06/01/2022 02:48:02 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.96 on epoch=727
06/01/2022 02:48:03 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.91 on epoch=729
06/01/2022 02:48:04 - INFO - __main__ - Step 2930 Global step 2930 Train loss 1.08 on epoch=732
06/01/2022 02:48:06 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.95 on epoch=734
06/01/2022 02:48:07 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.98 on epoch=737
06/01/2022 02:48:07 - INFO - __main__ - Global step 2950 Train loss 0.97 Classification-F1 0.1486842105263158 on epoch=737
06/01/2022 02:48:09 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.98 on epoch=739
06/01/2022 02:48:10 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.96 on epoch=742
06/01/2022 02:48:11 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.95 on epoch=744
06/01/2022 02:48:12 - INFO - __main__ - Step 2990 Global step 2990 Train loss 1.04 on epoch=747
06/01/2022 02:48:14 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.94 on epoch=749
06/01/2022 02:48:14 - INFO - __main__ - Global step 3000 Train loss 0.97 Classification-F1 0.1 on epoch=749
06/01/2022 02:48:14 - INFO - __main__ - save last model!
06/01/2022 02:48:14 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/01/2022 02:48:14 - INFO - __main__ - Start tokenizing ... 5509 instances
06/01/2022 02:48:14 - INFO - __main__ - Printing 3 examples
06/01/2022 02:48:14 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/01/2022 02:48:14 - INFO - __main__ - ['others']
06/01/2022 02:48:14 - INFO - __main__ -  [emo] what you like very little things ok
06/01/2022 02:48:14 - INFO - __main__ - ['others']
06/01/2022 02:48:14 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/01/2022 02:48:14 - INFO - __main__ - ['others']
06/01/2022 02:48:14 - INFO - __main__ - Tokenizing Input ...
06/01/2022 02:48:15 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 02:48:15 - INFO - __main__ - Printing 3 examples
06/01/2022 02:48:15 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/01/2022 02:48:15 - INFO - __main__ - ['others']
06/01/2022 02:48:15 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/01/2022 02:48:15 - INFO - __main__ - ['others']
06/01/2022 02:48:15 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/01/2022 02:48:15 - INFO - __main__ - ['others']
06/01/2022 02:48:15 - INFO - __main__ - Tokenizing Input ...
06/01/2022 02:48:15 - INFO - __main__ - Tokenizing Output ...
06/01/2022 02:48:15 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 02:48:15 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 02:48:15 - INFO - __main__ - Printing 3 examples
06/01/2022 02:48:15 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
06/01/2022 02:48:15 - INFO - __main__ - ['others']
06/01/2022 02:48:15 - INFO - __main__ -  [emo] i did ask now you did tell ms
06/01/2022 02:48:15 - INFO - __main__ - ['others']
06/01/2022 02:48:15 - INFO - __main__ -  [emo] buddy how you tell me your contact no
06/01/2022 02:48:15 - INFO - __main__ - ['others']
06/01/2022 02:48:15 - INFO - __main__ - Tokenizing Input ...
06/01/2022 02:48:15 - INFO - __main__ - Tokenizing Output ...
06/01/2022 02:48:15 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 02:48:16 - INFO - __main__ - Tokenizing Output ...
06/01/2022 02:48:20 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 02:48:21 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/01/2022 02:48:21 - INFO - __main__ - Starting training!
06/01/2022 02:48:22 - INFO - __main__ - Loaded 5509 examples from test data
06/01/2022 02:49:06 - INFO - __main__ - Saved prediction in models/T5-base-reptile-cls2cls-3e-5-2-5000-5e-1-10/singletask-emo/emo_16_13_0.5_8_predictions.txt
06/01/2022 02:49:06 - INFO - __main__ - Classification-F1 on test data: 0.0234
06/01/2022 02:49:06 - INFO - __main__ - prefix=emo_16_13, lr=0.5, bsz=8, dev_performance=0.24441687344913154, test_performance=0.023360614581241213
06/01/2022 02:49:06 - INFO - __main__ - Running ... prefix=emo_16_13, lr=0.4, bsz=8 ...
06/01/2022 02:49:07 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 02:49:07 - INFO - __main__ - Printing 3 examples
06/01/2022 02:49:07 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/01/2022 02:49:07 - INFO - __main__ - ['others']
06/01/2022 02:49:07 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/01/2022 02:49:07 - INFO - __main__ - ['others']
06/01/2022 02:49:07 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/01/2022 02:49:07 - INFO - __main__ - ['others']
06/01/2022 02:49:07 - INFO - __main__ - Tokenizing Input ...
06/01/2022 02:49:07 - INFO - __main__ - Tokenizing Output ...
06/01/2022 02:49:08 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 02:49:08 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 02:49:08 - INFO - __main__ - Printing 3 examples
06/01/2022 02:49:08 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
06/01/2022 02:49:08 - INFO - __main__ - ['others']
06/01/2022 02:49:08 - INFO - __main__ -  [emo] i did ask now you did tell ms
06/01/2022 02:49:08 - INFO - __main__ - ['others']
06/01/2022 02:49:08 - INFO - __main__ -  [emo] buddy how you tell me your contact no
06/01/2022 02:49:08 - INFO - __main__ - ['others']
06/01/2022 02:49:08 - INFO - __main__ - Tokenizing Input ...
06/01/2022 02:49:08 - INFO - __main__ - Tokenizing Output ...
06/01/2022 02:49:08 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 02:49:13 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 02:49:13 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/01/2022 02:49:13 - INFO - __main__ - Starting training!
06/01/2022 02:49:15 - INFO - __main__ - Step 10 Global step 10 Train loss 8.93 on epoch=2
06/01/2022 02:49:16 - INFO - __main__ - Step 20 Global step 20 Train loss 8.98 on epoch=4
06/01/2022 02:49:17 - INFO - __main__ - Step 30 Global step 30 Train loss 8.92 on epoch=7
06/01/2022 02:49:19 - INFO - __main__ - Step 40 Global step 40 Train loss 8.76 on epoch=9
06/01/2022 02:49:20 - INFO - __main__ - Step 50 Global step 50 Train loss 8.71 on epoch=12
06/01/2022 02:49:26 - INFO - __main__ - Global step 50 Train loss 8.86 Classification-F1 0.0 on epoch=12
06/01/2022 02:49:26 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
06/01/2022 02:49:27 - INFO - __main__ - Step 60 Global step 60 Train loss 8.67 on epoch=14
06/01/2022 02:49:28 - INFO - __main__ - Step 70 Global step 70 Train loss 8.64 on epoch=17
06/01/2022 02:49:30 - INFO - __main__ - Step 80 Global step 80 Train loss 8.55 on epoch=19
06/01/2022 02:49:31 - INFO - __main__ - Step 90 Global step 90 Train loss 8.25 on epoch=22
06/01/2022 02:49:32 - INFO - __main__ - Step 100 Global step 100 Train loss 8.34 on epoch=24
06/01/2022 02:49:44 - INFO - __main__ - Global step 100 Train loss 8.49 Classification-F1 0.0 on epoch=24
06/01/2022 02:49:46 - INFO - __main__ - Step 110 Global step 110 Train loss 8.02 on epoch=27
06/01/2022 02:49:47 - INFO - __main__ - Step 120 Global step 120 Train loss 7.84 on epoch=29
06/01/2022 02:49:48 - INFO - __main__ - Step 130 Global step 130 Train loss 7.60 on epoch=32
06/01/2022 02:49:49 - INFO - __main__ - Step 140 Global step 140 Train loss 7.31 on epoch=34
06/01/2022 02:49:51 - INFO - __main__ - Step 150 Global step 150 Train loss 7.18 on epoch=37
06/01/2022 02:49:56 - INFO - __main__ - Global step 150 Train loss 7.59 Classification-F1 0.0 on epoch=37
06/01/2022 02:49:57 - INFO - __main__ - Step 160 Global step 160 Train loss 7.07 on epoch=39
06/01/2022 02:49:58 - INFO - __main__ - Step 170 Global step 170 Train loss 6.83 on epoch=42
06/01/2022 02:50:00 - INFO - __main__ - Step 180 Global step 180 Train loss 6.75 on epoch=44
06/01/2022 02:50:01 - INFO - __main__ - Step 190 Global step 190 Train loss 6.53 on epoch=47
06/01/2022 02:50:02 - INFO - __main__ - Step 200 Global step 200 Train loss 6.19 on epoch=49
06/01/2022 02:50:06 - INFO - __main__ - Global step 200 Train loss 6.67 Classification-F1 0.0 on epoch=49
06/01/2022 02:50:07 - INFO - __main__ - Step 210 Global step 210 Train loss 6.08 on epoch=52
06/01/2022 02:50:08 - INFO - __main__ - Step 220 Global step 220 Train loss 5.82 on epoch=54
06/01/2022 02:50:10 - INFO - __main__ - Step 230 Global step 230 Train loss 5.69 on epoch=57
06/01/2022 02:50:11 - INFO - __main__ - Step 240 Global step 240 Train loss 5.41 on epoch=59
06/01/2022 02:50:12 - INFO - __main__ - Step 250 Global step 250 Train loss 5.44 on epoch=62
06/01/2022 02:50:16 - INFO - __main__ - Global step 250 Train loss 5.69 Classification-F1 0.0 on epoch=62
06/01/2022 02:50:18 - INFO - __main__ - Step 260 Global step 260 Train loss 4.91 on epoch=64
06/01/2022 02:50:19 - INFO - __main__ - Step 270 Global step 270 Train loss 4.92 on epoch=67
06/01/2022 02:50:20 - INFO - __main__ - Step 280 Global step 280 Train loss 4.83 on epoch=69
06/01/2022 02:50:21 - INFO - __main__ - Step 290 Global step 290 Train loss 4.92 on epoch=72
06/01/2022 02:50:23 - INFO - __main__ - Step 300 Global step 300 Train loss 4.76 on epoch=74
06/01/2022 02:50:31 - INFO - __main__ - Global step 300 Train loss 4.87 Classification-F1 0.0 on epoch=74
06/01/2022 02:50:33 - INFO - __main__ - Step 310 Global step 310 Train loss 4.86 on epoch=77
06/01/2022 02:50:34 - INFO - __main__ - Step 320 Global step 320 Train loss 4.65 on epoch=79
06/01/2022 02:50:35 - INFO - __main__ - Step 330 Global step 330 Train loss 4.50 on epoch=82
06/01/2022 02:50:36 - INFO - __main__ - Step 340 Global step 340 Train loss 4.37 on epoch=84
06/01/2022 02:50:38 - INFO - __main__ - Step 350 Global step 350 Train loss 4.41 on epoch=87
06/01/2022 02:50:41 - INFO - __main__ - Global step 350 Train loss 4.56 Classification-F1 0.022624434389140274 on epoch=87
06/01/2022 02:50:41 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.022624434389140274 on epoch=87, global_step=350
06/01/2022 02:50:43 - INFO - __main__ - Step 360 Global step 360 Train loss 4.10 on epoch=89
06/01/2022 02:50:44 - INFO - __main__ - Step 370 Global step 370 Train loss 4.38 on epoch=92
06/01/2022 02:50:45 - INFO - __main__ - Step 380 Global step 380 Train loss 4.03 on epoch=94
06/01/2022 02:50:46 - INFO - __main__ - Step 390 Global step 390 Train loss 4.08 on epoch=97
06/01/2022 02:50:48 - INFO - __main__ - Step 400 Global step 400 Train loss 3.78 on epoch=99
06/01/2022 02:50:56 - INFO - __main__ - Global step 400 Train loss 4.07 Classification-F1 0.02934851359898798 on epoch=99
06/01/2022 02:50:56 - INFO - __main__ - Saving model with best Classification-F1: 0.022624434389140274 -> 0.02934851359898798 on epoch=99, global_step=400
06/01/2022 02:50:57 - INFO - __main__ - Step 410 Global step 410 Train loss 4.04 on epoch=102
06/01/2022 02:50:58 - INFO - __main__ - Step 420 Global step 420 Train loss 3.75 on epoch=104
06/01/2022 02:50:59 - INFO - __main__ - Step 430 Global step 430 Train loss 3.93 on epoch=107
06/01/2022 02:51:01 - INFO - __main__ - Step 440 Global step 440 Train loss 3.74 on epoch=109
06/01/2022 02:51:02 - INFO - __main__ - Step 450 Global step 450 Train loss 3.69 on epoch=112
06/01/2022 02:51:07 - INFO - __main__ - Global step 450 Train loss 3.83 Classification-F1 0.0693407960199005 on epoch=112
06/01/2022 02:51:07 - INFO - __main__ - Saving model with best Classification-F1: 0.02934851359898798 -> 0.0693407960199005 on epoch=112, global_step=450
06/01/2022 02:51:09 - INFO - __main__ - Step 460 Global step 460 Train loss 3.52 on epoch=114
06/01/2022 02:51:10 - INFO - __main__ - Step 470 Global step 470 Train loss 3.77 on epoch=117
06/01/2022 02:51:11 - INFO - __main__ - Step 480 Global step 480 Train loss 3.30 on epoch=119
06/01/2022 02:51:12 - INFO - __main__ - Step 490 Global step 490 Train loss 3.50 on epoch=122
06/01/2022 02:51:14 - INFO - __main__ - Step 500 Global step 500 Train loss 3.27 on epoch=124
06/01/2022 02:51:17 - INFO - __main__ - Global step 500 Train loss 3.47 Classification-F1 0.14044687642498857 on epoch=124
06/01/2022 02:51:17 - INFO - __main__ - Saving model with best Classification-F1: 0.0693407960199005 -> 0.14044687642498857 on epoch=124, global_step=500
06/01/2022 02:51:18 - INFO - __main__ - Step 510 Global step 510 Train loss 3.30 on epoch=127
06/01/2022 02:51:20 - INFO - __main__ - Step 520 Global step 520 Train loss 3.22 on epoch=129
06/01/2022 02:51:21 - INFO - __main__ - Step 530 Global step 530 Train loss 3.15 on epoch=132
06/01/2022 02:51:22 - INFO - __main__ - Step 540 Global step 540 Train loss 3.07 on epoch=134
06/01/2022 02:51:23 - INFO - __main__ - Step 550 Global step 550 Train loss 3.01 on epoch=137
06/01/2022 02:51:26 - INFO - __main__ - Global step 550 Train loss 3.15 Classification-F1 0.19973544973544974 on epoch=137
06/01/2022 02:51:26 - INFO - __main__ - Saving model with best Classification-F1: 0.14044687642498857 -> 0.19973544973544974 on epoch=137, global_step=550
06/01/2022 02:51:28 - INFO - __main__ - Step 560 Global step 560 Train loss 2.91 on epoch=139
06/01/2022 02:51:29 - INFO - __main__ - Step 570 Global step 570 Train loss 2.92 on epoch=142
06/01/2022 02:51:30 - INFO - __main__ - Step 580 Global step 580 Train loss 2.78 on epoch=144
06/01/2022 02:51:31 - INFO - __main__ - Step 590 Global step 590 Train loss 2.77 on epoch=147
06/01/2022 02:51:32 - INFO - __main__ - Step 600 Global step 600 Train loss 2.65 on epoch=149
06/01/2022 02:51:37 - INFO - __main__ - Global step 600 Train loss 2.80 Classification-F1 0.10389610389610389 on epoch=149
06/01/2022 02:51:38 - INFO - __main__ - Step 610 Global step 610 Train loss 2.75 on epoch=152
06/01/2022 02:51:40 - INFO - __main__ - Step 620 Global step 620 Train loss 2.58 on epoch=154
06/01/2022 02:51:41 - INFO - __main__ - Step 630 Global step 630 Train loss 2.47 on epoch=157
06/01/2022 02:51:42 - INFO - __main__ - Step 640 Global step 640 Train loss 2.45 on epoch=159
06/01/2022 02:51:43 - INFO - __main__ - Step 650 Global step 650 Train loss 2.61 on epoch=162
06/01/2022 02:51:44 - INFO - __main__ - Global step 650 Train loss 2.57 Classification-F1 0.13067758749069247 on epoch=162
06/01/2022 02:51:46 - INFO - __main__ - Step 660 Global step 660 Train loss 2.27 on epoch=164
06/01/2022 02:51:47 - INFO - __main__ - Step 670 Global step 670 Train loss 2.38 on epoch=167
06/01/2022 02:51:48 - INFO - __main__ - Step 680 Global step 680 Train loss 2.11 on epoch=169
06/01/2022 02:51:49 - INFO - __main__ - Step 690 Global step 690 Train loss 2.19 on epoch=172
06/01/2022 02:51:51 - INFO - __main__ - Step 700 Global step 700 Train loss 1.96 on epoch=174
06/01/2022 02:51:51 - INFO - __main__ - Global step 700 Train loss 2.18 Classification-F1 0.1 on epoch=174
06/01/2022 02:51:52 - INFO - __main__ - Step 710 Global step 710 Train loss 2.06 on epoch=177
06/01/2022 02:51:54 - INFO - __main__ - Step 720 Global step 720 Train loss 2.01 on epoch=179
06/01/2022 02:51:55 - INFO - __main__ - Step 730 Global step 730 Train loss 2.10 on epoch=182
06/01/2022 02:51:56 - INFO - __main__ - Step 740 Global step 740 Train loss 1.82 on epoch=184
06/01/2022 02:51:57 - INFO - __main__ - Step 750 Global step 750 Train loss 1.87 on epoch=187
06/01/2022 02:51:58 - INFO - __main__ - Global step 750 Train loss 1.97 Classification-F1 0.13218954248366013 on epoch=187
06/01/2022 02:51:59 - INFO - __main__ - Step 760 Global step 760 Train loss 1.77 on epoch=189
06/01/2022 02:52:00 - INFO - __main__ - Step 770 Global step 770 Train loss 1.95 on epoch=192
06/01/2022 02:52:02 - INFO - __main__ - Step 780 Global step 780 Train loss 1.76 on epoch=194
06/01/2022 02:52:03 - INFO - __main__ - Step 790 Global step 790 Train loss 1.82 on epoch=197
06/01/2022 02:52:04 - INFO - __main__ - Step 800 Global step 800 Train loss 1.79 on epoch=199
06/01/2022 02:52:05 - INFO - __main__ - Global step 800 Train loss 1.82 Classification-F1 0.11552106430155212 on epoch=199
06/01/2022 02:52:06 - INFO - __main__ - Step 810 Global step 810 Train loss 1.75 on epoch=202
06/01/2022 02:52:07 - INFO - __main__ - Step 820 Global step 820 Train loss 1.58 on epoch=204
06/01/2022 02:52:08 - INFO - __main__ - Step 830 Global step 830 Train loss 1.49 on epoch=207
06/01/2022 02:52:10 - INFO - __main__ - Step 840 Global step 840 Train loss 1.68 on epoch=209
06/01/2022 02:52:11 - INFO - __main__ - Step 850 Global step 850 Train loss 1.44 on epoch=212
06/01/2022 02:52:11 - INFO - __main__ - Global step 850 Train loss 1.59 Classification-F1 0.1 on epoch=212
06/01/2022 02:52:13 - INFO - __main__ - Step 860 Global step 860 Train loss 1.44 on epoch=214
06/01/2022 02:52:14 - INFO - __main__ - Step 870 Global step 870 Train loss 1.50 on epoch=217
06/01/2022 02:52:15 - INFO - __main__ - Step 880 Global step 880 Train loss 1.53 on epoch=219
06/01/2022 02:52:16 - INFO - __main__ - Step 890 Global step 890 Train loss 1.51 on epoch=222
06/01/2022 02:52:17 - INFO - __main__ - Step 900 Global step 900 Train loss 1.42 on epoch=224
06/01/2022 02:52:18 - INFO - __main__ - Global step 900 Train loss 1.48 Classification-F1 0.13123993558776167 on epoch=224
06/01/2022 02:52:19 - INFO - __main__ - Step 910 Global step 910 Train loss 1.29 on epoch=227
06/01/2022 02:52:20 - INFO - __main__ - Step 920 Global step 920 Train loss 1.33 on epoch=229
06/01/2022 02:52:22 - INFO - __main__ - Step 930 Global step 930 Train loss 1.50 on epoch=232
06/01/2022 02:52:23 - INFO - __main__ - Step 940 Global step 940 Train loss 1.47 on epoch=234
06/01/2022 02:52:24 - INFO - __main__ - Step 950 Global step 950 Train loss 1.28 on epoch=237
06/01/2022 02:52:25 - INFO - __main__ - Global step 950 Train loss 1.38 Classification-F1 0.20718262398359094 on epoch=237
06/01/2022 02:52:25 - INFO - __main__ - Saving model with best Classification-F1: 0.19973544973544974 -> 0.20718262398359094 on epoch=237, global_step=950
06/01/2022 02:52:26 - INFO - __main__ - Step 960 Global step 960 Train loss 1.35 on epoch=239
06/01/2022 02:52:27 - INFO - __main__ - Step 970 Global step 970 Train loss 1.46 on epoch=242
06/01/2022 02:52:29 - INFO - __main__ - Step 980 Global step 980 Train loss 1.31 on epoch=244
06/01/2022 02:52:30 - INFO - __main__ - Step 990 Global step 990 Train loss 1.35 on epoch=247
06/01/2022 02:52:31 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.35 on epoch=249
06/01/2022 02:52:32 - INFO - __main__ - Global step 1000 Train loss 1.36 Classification-F1 0.15274725274725276 on epoch=249
06/01/2022 02:52:33 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.23 on epoch=252
06/01/2022 02:52:34 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.28 on epoch=254
06/01/2022 02:52:35 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.30 on epoch=257
06/01/2022 02:52:37 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.33 on epoch=259
06/01/2022 02:52:38 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.25 on epoch=262
06/01/2022 02:52:38 - INFO - __main__ - Global step 1050 Train loss 1.28 Classification-F1 0.13067758749069247 on epoch=262
06/01/2022 02:52:40 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.26 on epoch=264
06/01/2022 02:52:41 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.16 on epoch=267
06/01/2022 02:52:42 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.39 on epoch=269
06/01/2022 02:52:43 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.17 on epoch=272
06/01/2022 02:52:44 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.21 on epoch=274
06/01/2022 02:52:45 - INFO - __main__ - Global step 1100 Train loss 1.24 Classification-F1 0.1581196581196581 on epoch=274
06/01/2022 02:52:46 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.17 on epoch=277
06/01/2022 02:52:47 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.38 on epoch=279
06/01/2022 02:52:49 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.18 on epoch=282
06/01/2022 02:52:50 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.04 on epoch=284
06/01/2022 02:52:51 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.26 on epoch=287
06/01/2022 02:52:52 - INFO - __main__ - Global step 1150 Train loss 1.21 Classification-F1 0.16123642439431912 on epoch=287
06/01/2022 02:52:53 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.15 on epoch=289
06/01/2022 02:52:54 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.15 on epoch=292
06/01/2022 02:52:55 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.22 on epoch=294
06/01/2022 02:52:57 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.32 on epoch=297
06/01/2022 02:52:58 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.21 on epoch=299
06/01/2022 02:52:58 - INFO - __main__ - Global step 1200 Train loss 1.21 Classification-F1 0.1 on epoch=299
06/01/2022 02:53:00 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.13 on epoch=302
06/01/2022 02:53:01 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.17 on epoch=304
06/01/2022 02:53:02 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.22 on epoch=307
06/01/2022 02:53:03 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.05 on epoch=309
06/01/2022 02:53:05 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.20 on epoch=312
06/01/2022 02:53:05 - INFO - __main__ - Global step 1250 Train loss 1.15 Classification-F1 0.13067758749069247 on epoch=312
06/01/2022 02:53:06 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.37 on epoch=314
06/01/2022 02:53:08 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.22 on epoch=317
06/01/2022 02:53:09 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.24 on epoch=319
06/01/2022 02:53:10 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.16 on epoch=322
06/01/2022 02:53:11 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.06 on epoch=324
06/01/2022 02:53:12 - INFO - __main__ - Global step 1300 Train loss 1.21 Classification-F1 0.1 on epoch=324
06/01/2022 02:53:13 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.09 on epoch=327
06/01/2022 02:53:14 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.21 on epoch=329
06/01/2022 02:53:16 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.14 on epoch=332
06/01/2022 02:53:17 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.17 on epoch=334
06/01/2022 02:53:18 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.14 on epoch=337
06/01/2022 02:53:19 - INFO - __main__ - Global step 1350 Train loss 1.15 Classification-F1 0.1 on epoch=337
06/01/2022 02:53:20 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.15 on epoch=339
06/01/2022 02:53:21 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.10 on epoch=342
06/01/2022 02:53:22 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.09 on epoch=344
06/01/2022 02:53:23 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.20 on epoch=347
06/01/2022 02:53:25 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.06 on epoch=349
06/01/2022 02:53:25 - INFO - __main__ - Global step 1400 Train loss 1.12 Classification-F1 0.1 on epoch=349
06/01/2022 02:53:26 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.13 on epoch=352
06/01/2022 02:53:28 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.05 on epoch=354
06/01/2022 02:53:29 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.12 on epoch=357
06/01/2022 02:53:30 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.15 on epoch=359
06/01/2022 02:53:31 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.12 on epoch=362
06/01/2022 02:53:32 - INFO - __main__ - Global step 1450 Train loss 1.11 Classification-F1 0.1 on epoch=362
06/01/2022 02:53:33 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.12 on epoch=364
06/01/2022 02:53:34 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.17 on epoch=367
06/01/2022 02:53:36 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.09 on epoch=369
06/01/2022 02:53:37 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.06 on epoch=372
06/01/2022 02:53:38 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.09 on epoch=374
06/01/2022 02:53:39 - INFO - __main__ - Global step 1500 Train loss 1.10 Classification-F1 0.1 on epoch=374
06/01/2022 02:53:40 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.22 on epoch=377
06/01/2022 02:53:41 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.06 on epoch=379
06/01/2022 02:53:42 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.17 on epoch=382
06/01/2022 02:53:44 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.07 on epoch=384
06/01/2022 02:53:45 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.06 on epoch=387
06/01/2022 02:53:45 - INFO - __main__ - Global step 1550 Train loss 1.12 Classification-F1 0.10126582278481013 on epoch=387
06/01/2022 02:53:47 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.07 on epoch=389
06/01/2022 02:53:48 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.03 on epoch=392
06/01/2022 02:53:49 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.24 on epoch=394
06/01/2022 02:53:50 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.23 on epoch=397
06/01/2022 02:53:52 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.16 on epoch=399
06/01/2022 02:53:52 - INFO - __main__ - Global step 1600 Train loss 1.15 Classification-F1 0.1 on epoch=399
06/01/2022 02:53:53 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.14 on epoch=402
06/01/2022 02:53:55 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.06 on epoch=404
06/01/2022 02:53:56 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.11 on epoch=407
06/01/2022 02:53:57 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.92 on epoch=409
06/01/2022 02:53:58 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.01 on epoch=412
06/01/2022 02:53:59 - INFO - __main__ - Global step 1650 Train loss 1.05 Classification-F1 0.10526315789473685 on epoch=412
06/01/2022 02:54:00 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.07 on epoch=414
06/01/2022 02:54:01 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.97 on epoch=417
06/01/2022 02:54:02 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.14 on epoch=419
06/01/2022 02:54:04 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.00 on epoch=422
06/01/2022 02:54:05 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.12 on epoch=424
06/01/2022 02:54:05 - INFO - __main__ - Global step 1700 Train loss 1.06 Classification-F1 0.1 on epoch=424
06/01/2022 02:54:07 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.05 on epoch=427
06/01/2022 02:54:08 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.09 on epoch=429
06/01/2022 02:54:09 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.07 on epoch=432
06/01/2022 02:54:10 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.14 on epoch=434
06/01/2022 02:54:12 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.13 on epoch=437
06/01/2022 02:54:12 - INFO - __main__ - Global step 1750 Train loss 1.09 Classification-F1 0.13067758749069247 on epoch=437
06/01/2022 02:54:13 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.89 on epoch=439
06/01/2022 02:54:15 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.13 on epoch=442
06/01/2022 02:54:16 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.11 on epoch=444
06/01/2022 02:54:17 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.14 on epoch=447
06/01/2022 02:54:18 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.11 on epoch=449
06/01/2022 02:54:19 - INFO - __main__ - Global step 1800 Train loss 1.07 Classification-F1 0.1 on epoch=449
06/01/2022 02:54:20 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.16 on epoch=452
06/01/2022 02:54:21 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.98 on epoch=454
06/01/2022 02:54:23 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.03 on epoch=457
06/01/2022 02:54:24 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.00 on epoch=459
06/01/2022 02:54:25 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.04 on epoch=462
06/01/2022 02:54:26 - INFO - __main__ - Global step 1850 Train loss 1.04 Classification-F1 0.1 on epoch=462
06/01/2022 02:54:27 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.08 on epoch=464
06/01/2022 02:54:28 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.03 on epoch=467
06/01/2022 02:54:29 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.94 on epoch=469
06/01/2022 02:54:30 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.96 on epoch=472
06/01/2022 02:54:32 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.07 on epoch=474
06/01/2022 02:54:32 - INFO - __main__ - Global step 1900 Train loss 1.01 Classification-F1 0.1 on epoch=474
06/01/2022 02:54:33 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.08 on epoch=477
06/01/2022 02:54:35 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.02 on epoch=479
06/01/2022 02:54:36 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.96 on epoch=482
06/01/2022 02:54:37 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.02 on epoch=484
06/01/2022 02:54:38 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.02 on epoch=487
06/01/2022 02:54:39 - INFO - __main__ - Global step 1950 Train loss 1.02 Classification-F1 0.1 on epoch=487
06/01/2022 02:54:40 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.96 on epoch=489
06/01/2022 02:54:41 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.97 on epoch=492
06/01/2022 02:54:43 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.01 on epoch=494
06/01/2022 02:54:44 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.07 on epoch=497
06/01/2022 02:54:45 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.14 on epoch=499
06/01/2022 02:54:46 - INFO - __main__ - Global step 2000 Train loss 1.03 Classification-F1 0.1 on epoch=499
06/01/2022 02:54:47 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.96 on epoch=502
06/01/2022 02:54:48 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.99 on epoch=504
06/01/2022 02:54:49 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.04 on epoch=507
06/01/2022 02:54:51 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.07 on epoch=509
06/01/2022 02:54:52 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.00 on epoch=512
06/01/2022 02:54:52 - INFO - __main__ - Global step 2050 Train loss 1.01 Classification-F1 0.10256410256410256 on epoch=512
06/01/2022 02:54:54 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.03 on epoch=514
06/01/2022 02:54:55 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.98 on epoch=517
06/01/2022 02:54:56 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.90 on epoch=519
06/01/2022 02:54:57 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.02 on epoch=522
06/01/2022 02:54:59 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.11 on epoch=524
06/01/2022 02:54:59 - INFO - __main__ - Global step 2100 Train loss 1.01 Classification-F1 0.1 on epoch=524
06/01/2022 02:55:00 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.14 on epoch=527
06/01/2022 02:55:02 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.07 on epoch=529
06/01/2022 02:55:03 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.97 on epoch=532
06/01/2022 02:55:04 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.98 on epoch=534
06/01/2022 02:55:05 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.04 on epoch=537
06/01/2022 02:55:06 - INFO - __main__ - Global step 2150 Train loss 1.04 Classification-F1 0.1337028824833703 on epoch=537
06/01/2022 02:55:07 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.99 on epoch=539
06/01/2022 02:55:08 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.99 on epoch=542
06/01/2022 02:55:10 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.05 on epoch=544
06/01/2022 02:55:11 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.13 on epoch=547
06/01/2022 02:55:12 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.98 on epoch=549
06/01/2022 02:55:13 - INFO - __main__ - Global step 2200 Train loss 1.03 Classification-F1 0.10126582278481013 on epoch=549
06/01/2022 02:55:14 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.99 on epoch=552
06/01/2022 02:55:15 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.09 on epoch=554
06/01/2022 02:55:16 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.98 on epoch=557
06/01/2022 02:55:18 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.94 on epoch=559
06/01/2022 02:55:19 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.08 on epoch=562
06/01/2022 02:55:19 - INFO - __main__ - Global step 2250 Train loss 1.02 Classification-F1 0.19740740740740742 on epoch=562
06/01/2022 02:55:21 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.02 on epoch=564
06/01/2022 02:55:22 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.00 on epoch=567
06/01/2022 02:55:23 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.01 on epoch=569
06/01/2022 02:55:24 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.96 on epoch=572
06/01/2022 02:55:26 - INFO - __main__ - Step 2300 Global step 2300 Train loss 1.01 on epoch=574
06/01/2022 02:55:26 - INFO - __main__ - Global step 2300 Train loss 1.00 Classification-F1 0.09493670886075949 on epoch=574
06/01/2022 02:55:27 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.09 on epoch=577
06/01/2022 02:55:29 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.06 on epoch=579
06/01/2022 02:55:30 - INFO - __main__ - Step 2330 Global step 2330 Train loss 1.02 on epoch=582
06/01/2022 02:55:31 - INFO - __main__ - Step 2340 Global step 2340 Train loss 1.00 on epoch=584
06/01/2022 02:55:32 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.96 on epoch=587
06/01/2022 02:55:33 - INFO - __main__ - Global step 2350 Train loss 1.03 Classification-F1 0.1527777777777778 on epoch=587
06/01/2022 02:55:34 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.86 on epoch=589
06/01/2022 02:55:35 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.99 on epoch=592
06/01/2022 02:55:37 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.00 on epoch=594
06/01/2022 02:55:38 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.97 on epoch=597
06/01/2022 02:55:39 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.12 on epoch=599
06/01/2022 02:55:40 - INFO - __main__ - Global step 2400 Train loss 0.99 Classification-F1 0.1426456882846335 on epoch=599
06/01/2022 02:55:41 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.95 on epoch=602
06/01/2022 02:55:42 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.96 on epoch=604
06/01/2022 02:55:43 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.97 on epoch=607
06/01/2022 02:55:45 - INFO - __main__ - Step 2440 Global step 2440 Train loss 1.00 on epoch=609
06/01/2022 02:55:46 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.96 on epoch=612
06/01/2022 02:55:46 - INFO - __main__ - Global step 2450 Train loss 0.97 Classification-F1 0.1 on epoch=612
06/01/2022 02:55:48 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.96 on epoch=614
06/01/2022 02:55:49 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.99 on epoch=617
06/01/2022 02:55:50 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.98 on epoch=619
06/01/2022 02:55:51 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.98 on epoch=622
06/01/2022 02:55:53 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.98 on epoch=624
06/01/2022 02:55:53 - INFO - __main__ - Global step 2500 Train loss 0.97 Classification-F1 0.13034188034188032 on epoch=624
06/01/2022 02:55:54 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.99 on epoch=627
06/01/2022 02:55:56 - INFO - __main__ - Step 2520 Global step 2520 Train loss 1.10 on epoch=629
06/01/2022 02:55:57 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.98 on epoch=632
06/01/2022 02:55:58 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.87 on epoch=634
06/01/2022 02:55:59 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.95 on epoch=637
06/01/2022 02:56:00 - INFO - __main__ - Global step 2550 Train loss 0.98 Classification-F1 0.10416666666666666 on epoch=637
06/01/2022 02:56:01 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.97 on epoch=639
06/01/2022 02:56:02 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.92 on epoch=642
06/01/2022 02:56:04 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.92 on epoch=644
06/01/2022 02:56:05 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.99 on epoch=647
06/01/2022 02:56:06 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.92 on epoch=649
06/01/2022 02:56:07 - INFO - __main__ - Global step 2600 Train loss 0.94 Classification-F1 0.1 on epoch=649
06/01/2022 02:56:08 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.95 on epoch=652
06/01/2022 02:56:09 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.86 on epoch=654
06/01/2022 02:56:10 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.99 on epoch=657
06/01/2022 02:56:12 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.93 on epoch=659
06/01/2022 02:56:13 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.99 on epoch=662
06/01/2022 02:56:13 - INFO - __main__ - Global step 2650 Train loss 0.95 Classification-F1 0.1 on epoch=662
06/01/2022 02:56:15 - INFO - __main__ - Step 2660 Global step 2660 Train loss 1.02 on epoch=664
06/01/2022 02:56:16 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.92 on epoch=667
06/01/2022 02:56:17 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.89 on epoch=669
06/01/2022 02:56:18 - INFO - __main__ - Step 2690 Global step 2690 Train loss 1.07 on epoch=672
06/01/2022 02:56:20 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.94 on epoch=674
06/01/2022 02:56:20 - INFO - __main__ - Global step 2700 Train loss 0.97 Classification-F1 0.1 on epoch=674
06/01/2022 02:56:21 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.93 on epoch=677
06/01/2022 02:56:23 - INFO - __main__ - Step 2720 Global step 2720 Train loss 1.03 on epoch=679
06/01/2022 02:56:24 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.88 on epoch=682
06/01/2022 02:56:25 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.91 on epoch=684
06/01/2022 02:56:26 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.85 on epoch=687
06/01/2022 02:56:27 - INFO - __main__ - Global step 2750 Train loss 0.92 Classification-F1 0.1 on epoch=687
06/01/2022 02:56:28 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.02 on epoch=689
06/01/2022 02:56:29 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.99 on epoch=692
06/01/2022 02:56:31 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.96 on epoch=694
06/01/2022 02:56:32 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.84 on epoch=697
06/01/2022 02:56:33 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.94 on epoch=699
06/01/2022 02:56:34 - INFO - __main__ - Global step 2800 Train loss 0.95 Classification-F1 0.1 on epoch=699
06/01/2022 02:56:35 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.04 on epoch=702
06/01/2022 02:56:36 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.95 on epoch=704
06/01/2022 02:56:37 - INFO - __main__ - Step 2830 Global step 2830 Train loss 1.01 on epoch=707
06/01/2022 02:56:39 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.94 on epoch=709
06/01/2022 02:56:40 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.96 on epoch=712
06/01/2022 02:56:40 - INFO - __main__ - Global step 2850 Train loss 0.98 Classification-F1 0.1 on epoch=712
06/01/2022 02:56:42 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.97 on epoch=714
06/01/2022 02:56:43 - INFO - __main__ - Step 2870 Global step 2870 Train loss 1.01 on epoch=717
06/01/2022 02:56:44 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.95 on epoch=719
06/01/2022 02:56:46 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.05 on epoch=722
06/01/2022 02:56:47 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.96 on epoch=724
06/01/2022 02:56:47 - INFO - __main__ - Global step 2900 Train loss 0.99 Classification-F1 0.1 on epoch=724
06/01/2022 02:56:49 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.05 on epoch=727
06/01/2022 02:56:50 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.98 on epoch=729
06/01/2022 02:56:51 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.91 on epoch=732
06/01/2022 02:56:52 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.97 on epoch=734
06/01/2022 02:56:54 - INFO - __main__ - Step 2950 Global step 2950 Train loss 1.00 on epoch=737
06/01/2022 02:56:54 - INFO - __main__ - Global step 2950 Train loss 0.98 Classification-F1 0.1 on epoch=737
06/01/2022 02:56:55 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.95 on epoch=739
06/01/2022 02:56:57 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.98 on epoch=742
06/01/2022 02:56:58 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.99 on epoch=744
06/01/2022 02:56:59 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.98 on epoch=747
06/01/2022 02:57:00 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.97 on epoch=749
06/01/2022 02:57:01 - INFO - __main__ - Global step 3000 Train loss 0.97 Classification-F1 0.1 on epoch=749
06/01/2022 02:57:01 - INFO - __main__ - save last model!
06/01/2022 02:57:01 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/01/2022 02:57:01 - INFO - __main__ - Start tokenizing ... 5509 instances
06/01/2022 02:57:01 - INFO - __main__ - Printing 3 examples
06/01/2022 02:57:01 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/01/2022 02:57:01 - INFO - __main__ - ['others']
06/01/2022 02:57:01 - INFO - __main__ -  [emo] what you like very little things ok
06/01/2022 02:57:01 - INFO - __main__ - ['others']
06/01/2022 02:57:01 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/01/2022 02:57:01 - INFO - __main__ - ['others']
06/01/2022 02:57:01 - INFO - __main__ - Tokenizing Input ...
06/01/2022 02:57:01 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 02:57:01 - INFO - __main__ - Printing 3 examples
06/01/2022 02:57:01 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/01/2022 02:57:01 - INFO - __main__ - ['others']
06/01/2022 02:57:01 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/01/2022 02:57:01 - INFO - __main__ - ['others']
06/01/2022 02:57:01 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/01/2022 02:57:01 - INFO - __main__ - ['others']
06/01/2022 02:57:01 - INFO - __main__ - Tokenizing Input ...
06/01/2022 02:57:01 - INFO - __main__ - Tokenizing Output ...
06/01/2022 02:57:01 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 02:57:01 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 02:57:01 - INFO - __main__ - Printing 3 examples
06/01/2022 02:57:01 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
06/01/2022 02:57:01 - INFO - __main__ - ['others']
06/01/2022 02:57:01 - INFO - __main__ -  [emo] i did ask now you did tell ms
06/01/2022 02:57:01 - INFO - __main__ - ['others']
06/01/2022 02:57:01 - INFO - __main__ -  [emo] buddy how you tell me your contact no
06/01/2022 02:57:01 - INFO - __main__ - ['others']
06/01/2022 02:57:01 - INFO - __main__ - Tokenizing Input ...
06/01/2022 02:57:01 - INFO - __main__ - Tokenizing Output ...
06/01/2022 02:57:02 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 02:57:03 - INFO - __main__ - Tokenizing Output ...
06/01/2022 02:57:07 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 02:57:08 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/01/2022 02:57:08 - INFO - __main__ - Starting training!
06/01/2022 02:57:08 - INFO - __main__ - Loaded 5509 examples from test data
06/01/2022 02:57:52 - INFO - __main__ - Saved prediction in models/T5-base-reptile-cls2cls-3e-5-2-5000-5e-1-10/singletask-emo/emo_16_13_0.4_8_predictions.txt
06/01/2022 02:57:52 - INFO - __main__ - Classification-F1 on test data: 0.0217
06/01/2022 02:57:53 - INFO - __main__ - prefix=emo_16_13, lr=0.4, bsz=8, dev_performance=0.20718262398359094, test_performance=0.021705157145337734
06/01/2022 02:57:53 - INFO - __main__ - Running ... prefix=emo_16_13, lr=0.3, bsz=8 ...
06/01/2022 02:57:54 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 02:57:54 - INFO - __main__ - Printing 3 examples
06/01/2022 02:57:54 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/01/2022 02:57:54 - INFO - __main__ - ['others']
06/01/2022 02:57:54 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/01/2022 02:57:54 - INFO - __main__ - ['others']
06/01/2022 02:57:54 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/01/2022 02:57:54 - INFO - __main__ - ['others']
06/01/2022 02:57:54 - INFO - __main__ - Tokenizing Input ...
06/01/2022 02:57:54 - INFO - __main__ - Tokenizing Output ...
06/01/2022 02:57:54 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 02:57:54 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 02:57:54 - INFO - __main__ - Printing 3 examples
06/01/2022 02:57:54 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
06/01/2022 02:57:54 - INFO - __main__ - ['others']
06/01/2022 02:57:54 - INFO - __main__ -  [emo] i did ask now you did tell ms
06/01/2022 02:57:54 - INFO - __main__ - ['others']
06/01/2022 02:57:54 - INFO - __main__ -  [emo] buddy how you tell me your contact no
06/01/2022 02:57:54 - INFO - __main__ - ['others']
06/01/2022 02:57:54 - INFO - __main__ - Tokenizing Input ...
06/01/2022 02:57:54 - INFO - __main__ - Tokenizing Output ...
06/01/2022 02:57:54 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 02:57:59 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 02:58:00 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/01/2022 02:58:00 - INFO - __main__ - Starting training!
06/01/2022 02:58:01 - INFO - __main__ - Step 10 Global step 10 Train loss 8.97 on epoch=2
06/01/2022 02:58:02 - INFO - __main__ - Step 20 Global step 20 Train loss 9.08 on epoch=4
06/01/2022 02:58:04 - INFO - __main__ - Step 30 Global step 30 Train loss 8.92 on epoch=7
06/01/2022 02:58:05 - INFO - __main__ - Step 40 Global step 40 Train loss 8.91 on epoch=9
06/01/2022 02:58:06 - INFO - __main__ - Step 50 Global step 50 Train loss 8.90 on epoch=12
06/01/2022 02:58:12 - INFO - __main__ - Global step 50 Train loss 8.96 Classification-F1 0.0 on epoch=12
06/01/2022 02:58:12 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
06/01/2022 02:58:13 - INFO - __main__ - Step 60 Global step 60 Train loss 8.91 on epoch=14
06/01/2022 02:58:15 - INFO - __main__ - Step 70 Global step 70 Train loss 8.74 on epoch=17
06/01/2022 02:58:16 - INFO - __main__ - Step 80 Global step 80 Train loss 8.79 on epoch=19
06/01/2022 02:58:17 - INFO - __main__ - Step 90 Global step 90 Train loss 8.68 on epoch=22
06/01/2022 02:58:18 - INFO - __main__ - Step 100 Global step 100 Train loss 8.69 on epoch=24
06/01/2022 02:58:27 - INFO - __main__ - Global step 100 Train loss 8.76 Classification-F1 0.0 on epoch=24
06/01/2022 02:58:28 - INFO - __main__ - Step 110 Global step 110 Train loss 8.45 on epoch=27
06/01/2022 02:58:30 - INFO - __main__ - Step 120 Global step 120 Train loss 8.37 on epoch=29
06/01/2022 02:58:31 - INFO - __main__ - Step 130 Global step 130 Train loss 8.14 on epoch=32
06/01/2022 02:58:32 - INFO - __main__ - Step 140 Global step 140 Train loss 7.89 on epoch=34
06/01/2022 02:58:33 - INFO - __main__ - Step 150 Global step 150 Train loss 7.84 on epoch=37
06/01/2022 02:58:46 - INFO - __main__ - Global step 150 Train loss 8.14 Classification-F1 0.0 on epoch=37
06/01/2022 02:58:47 - INFO - __main__ - Step 160 Global step 160 Train loss 7.62 on epoch=39
06/01/2022 02:58:49 - INFO - __main__ - Step 170 Global step 170 Train loss 7.62 on epoch=42
06/01/2022 02:58:50 - INFO - __main__ - Step 180 Global step 180 Train loss 7.44 on epoch=44
06/01/2022 02:58:51 - INFO - __main__ - Step 190 Global step 190 Train loss 7.16 on epoch=47
06/01/2022 02:58:52 - INFO - __main__ - Step 200 Global step 200 Train loss 7.13 on epoch=49
06/01/2022 02:59:06 - INFO - __main__ - Global step 200 Train loss 7.39 Classification-F1 0.0 on epoch=49
06/01/2022 02:59:07 - INFO - __main__ - Step 210 Global step 210 Train loss 6.98 on epoch=52
06/01/2022 02:59:08 - INFO - __main__ - Step 220 Global step 220 Train loss 6.76 on epoch=54
06/01/2022 02:59:10 - INFO - __main__ - Step 230 Global step 230 Train loss 6.90 on epoch=57
06/01/2022 02:59:11 - INFO - __main__ - Step 240 Global step 240 Train loss 6.57 on epoch=59
06/01/2022 02:59:12 - INFO - __main__ - Step 250 Global step 250 Train loss 6.36 on epoch=62
06/01/2022 02:59:19 - INFO - __main__ - Global step 250 Train loss 6.72 Classification-F1 0.0 on epoch=62
06/01/2022 02:59:20 - INFO - __main__ - Step 260 Global step 260 Train loss 6.21 on epoch=64
06/01/2022 02:59:21 - INFO - __main__ - Step 270 Global step 270 Train loss 6.03 on epoch=67
06/01/2022 02:59:23 - INFO - __main__ - Step 280 Global step 280 Train loss 6.04 on epoch=69
06/01/2022 02:59:24 - INFO - __main__ - Step 290 Global step 290 Train loss 5.80 on epoch=72
06/01/2022 02:59:25 - INFO - __main__ - Step 300 Global step 300 Train loss 5.82 on epoch=74
06/01/2022 02:59:32 - INFO - __main__ - Global step 300 Train loss 5.98 Classification-F1 0.0 on epoch=74
06/01/2022 02:59:34 - INFO - __main__ - Step 310 Global step 310 Train loss 5.68 on epoch=77
06/01/2022 02:59:35 - INFO - __main__ - Step 320 Global step 320 Train loss 5.64 on epoch=79
06/01/2022 02:59:36 - INFO - __main__ - Step 330 Global step 330 Train loss 5.50 on epoch=82
06/01/2022 02:59:38 - INFO - __main__ - Step 340 Global step 340 Train loss 5.09 on epoch=84
06/01/2022 02:59:39 - INFO - __main__ - Step 350 Global step 350 Train loss 5.33 on epoch=87
06/01/2022 02:59:45 - INFO - __main__ - Global step 350 Train loss 5.45 Classification-F1 0.0 on epoch=87
06/01/2022 02:59:46 - INFO - __main__ - Step 360 Global step 360 Train loss 5.12 on epoch=89
06/01/2022 02:59:47 - INFO - __main__ - Step 370 Global step 370 Train loss 5.32 on epoch=92
06/01/2022 02:59:49 - INFO - __main__ - Step 380 Global step 380 Train loss 4.80 on epoch=94
06/01/2022 02:59:50 - INFO - __main__ - Step 390 Global step 390 Train loss 4.83 on epoch=97
06/01/2022 02:59:51 - INFO - __main__ - Step 400 Global step 400 Train loss 4.80 on epoch=99
06/01/2022 03:00:08 - INFO - __main__ - Global step 400 Train loss 4.97 Classification-F1 0.0 on epoch=99
06/01/2022 03:00:09 - INFO - __main__ - Step 410 Global step 410 Train loss 4.90 on epoch=102
06/01/2022 03:00:10 - INFO - __main__ - Step 420 Global step 420 Train loss 4.54 on epoch=104
06/01/2022 03:00:11 - INFO - __main__ - Step 430 Global step 430 Train loss 4.63 on epoch=107
06/01/2022 03:00:13 - INFO - __main__ - Step 440 Global step 440 Train loss 4.56 on epoch=109
06/01/2022 03:00:14 - INFO - __main__ - Step 450 Global step 450 Train loss 4.65 on epoch=112
06/01/2022 03:00:24 - INFO - __main__ - Global step 450 Train loss 4.66 Classification-F1 0.0 on epoch=112
06/01/2022 03:00:25 - INFO - __main__ - Step 460 Global step 460 Train loss 4.40 on epoch=114
06/01/2022 03:00:26 - INFO - __main__ - Step 470 Global step 470 Train loss 4.40 on epoch=117
06/01/2022 03:00:28 - INFO - __main__ - Step 480 Global step 480 Train loss 4.19 on epoch=119
06/01/2022 03:00:29 - INFO - __main__ - Step 490 Global step 490 Train loss 4.38 on epoch=122
06/01/2022 03:00:30 - INFO - __main__ - Step 500 Global step 500 Train loss 4.13 on epoch=124
06/01/2022 03:00:36 - INFO - __main__ - Global step 500 Train loss 4.30 Classification-F1 0.0 on epoch=124
06/01/2022 03:00:38 - INFO - __main__ - Step 510 Global step 510 Train loss 4.17 on epoch=127
06/01/2022 03:00:39 - INFO - __main__ - Step 520 Global step 520 Train loss 3.94 on epoch=129
06/01/2022 03:00:40 - INFO - __main__ - Step 530 Global step 530 Train loss 4.09 on epoch=132
06/01/2022 03:00:41 - INFO - __main__ - Step 540 Global step 540 Train loss 3.99 on epoch=134
06/01/2022 03:00:43 - INFO - __main__ - Step 550 Global step 550 Train loss 3.97 on epoch=137
06/01/2022 03:00:56 - INFO - __main__ - Global step 550 Train loss 4.03 Classification-F1 0.020979020979020976 on epoch=137
06/01/2022 03:00:56 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.020979020979020976 on epoch=137, global_step=550
06/01/2022 03:00:58 - INFO - __main__ - Step 560 Global step 560 Train loss 3.69 on epoch=139
06/01/2022 03:00:59 - INFO - __main__ - Step 570 Global step 570 Train loss 3.76 on epoch=142
06/01/2022 03:01:00 - INFO - __main__ - Step 580 Global step 580 Train loss 3.49 on epoch=144
06/01/2022 03:01:02 - INFO - __main__ - Step 590 Global step 590 Train loss 3.64 on epoch=147
06/01/2022 03:01:03 - INFO - __main__ - Step 600 Global step 600 Train loss 4.26 on epoch=149
06/01/2022 03:01:05 - INFO - __main__ - Global step 600 Train loss 3.77 Classification-F1 0.0 on epoch=149
06/01/2022 03:01:06 - INFO - __main__ - Step 610 Global step 610 Train loss 4.69 on epoch=152
06/01/2022 03:01:07 - INFO - __main__ - Step 620 Global step 620 Train loss 4.21 on epoch=154
06/01/2022 03:01:08 - INFO - __main__ - Step 630 Global step 630 Train loss 3.67 on epoch=157
06/01/2022 03:01:10 - INFO - __main__ - Step 640 Global step 640 Train loss 3.44 on epoch=159
06/01/2022 03:01:11 - INFO - __main__ - Step 650 Global step 650 Train loss 3.48 on epoch=162
06/01/2022 03:01:12 - INFO - __main__ - Global step 650 Train loss 3.90 Classification-F1 0.13047619047619047 on epoch=162
06/01/2022 03:01:12 - INFO - __main__ - Saving model with best Classification-F1: 0.020979020979020976 -> 0.13047619047619047 on epoch=162, global_step=650
06/01/2022 03:01:14 - INFO - __main__ - Step 660 Global step 660 Train loss 3.10 on epoch=164
06/01/2022 03:01:15 - INFO - __main__ - Step 670 Global step 670 Train loss 3.32 on epoch=167
06/01/2022 03:01:16 - INFO - __main__ - Step 680 Global step 680 Train loss 3.20 on epoch=169
06/01/2022 03:01:18 - INFO - __main__ - Step 690 Global step 690 Train loss 3.42 on epoch=172
06/01/2022 03:01:19 - INFO - __main__ - Step 700 Global step 700 Train loss 3.16 on epoch=174
06/01/2022 03:01:21 - INFO - __main__ - Global step 700 Train loss 3.24 Classification-F1 0.16601307189542483 on epoch=174
06/01/2022 03:01:21 - INFO - __main__ - Saving model with best Classification-F1: 0.13047619047619047 -> 0.16601307189542483 on epoch=174, global_step=700
06/01/2022 03:01:22 - INFO - __main__ - Step 710 Global step 710 Train loss 3.33 on epoch=177
06/01/2022 03:01:23 - INFO - __main__ - Step 720 Global step 720 Train loss 3.15 on epoch=179
06/01/2022 03:01:24 - INFO - __main__ - Step 730 Global step 730 Train loss 3.04 on epoch=182
06/01/2022 03:01:26 - INFO - __main__ - Step 740 Global step 740 Train loss 2.90 on epoch=184
06/01/2022 03:01:27 - INFO - __main__ - Step 750 Global step 750 Train loss 2.94 on epoch=187
06/01/2022 03:01:28 - INFO - __main__ - Global step 750 Train loss 3.07 Classification-F1 0.13746478873239437 on epoch=187
06/01/2022 03:01:29 - INFO - __main__ - Step 760 Global step 760 Train loss 2.72 on epoch=189
06/01/2022 03:01:30 - INFO - __main__ - Step 770 Global step 770 Train loss 2.93 on epoch=192
06/01/2022 03:01:31 - INFO - __main__ - Step 780 Global step 780 Train loss 2.73 on epoch=194
06/01/2022 03:01:33 - INFO - __main__ - Step 790 Global step 790 Train loss 2.81 on epoch=197
06/01/2022 03:01:34 - INFO - __main__ - Step 800 Global step 800 Train loss 2.53 on epoch=199
06/01/2022 03:01:35 - INFO - __main__ - Global step 800 Train loss 2.74 Classification-F1 0.1 on epoch=199
06/01/2022 03:01:36 - INFO - __main__ - Step 810 Global step 810 Train loss 2.69 on epoch=202
06/01/2022 03:01:37 - INFO - __main__ - Step 820 Global step 820 Train loss 2.53 on epoch=204
06/01/2022 03:01:39 - INFO - __main__ - Step 830 Global step 830 Train loss 2.60 on epoch=207
06/01/2022 03:01:40 - INFO - __main__ - Step 840 Global step 840 Train loss 2.37 on epoch=209
06/01/2022 03:01:41 - INFO - __main__ - Step 850 Global step 850 Train loss 2.49 on epoch=212
06/01/2022 03:01:42 - INFO - __main__ - Global step 850 Train loss 2.54 Classification-F1 0.13067758749069247 on epoch=212
06/01/2022 03:01:43 - INFO - __main__ - Step 860 Global step 860 Train loss 2.36 on epoch=214
06/01/2022 03:01:44 - INFO - __main__ - Step 870 Global step 870 Train loss 2.37 on epoch=217
06/01/2022 03:01:46 - INFO - __main__ - Step 880 Global step 880 Train loss 2.16 on epoch=219
06/01/2022 03:01:47 - INFO - __main__ - Step 890 Global step 890 Train loss 2.19 on epoch=222
06/01/2022 03:01:48 - INFO - __main__ - Step 900 Global step 900 Train loss 2.32 on epoch=224
06/01/2022 03:01:49 - INFO - __main__ - Global step 900 Train loss 2.28 Classification-F1 0.1640625 on epoch=224
06/01/2022 03:01:50 - INFO - __main__ - Step 910 Global step 910 Train loss 2.05 on epoch=227
06/01/2022 03:01:51 - INFO - __main__ - Step 920 Global step 920 Train loss 1.91 on epoch=229
06/01/2022 03:01:53 - INFO - __main__ - Step 930 Global step 930 Train loss 2.12 on epoch=232
06/01/2022 03:01:54 - INFO - __main__ - Step 940 Global step 940 Train loss 2.01 on epoch=234
06/01/2022 03:01:55 - INFO - __main__ - Step 950 Global step 950 Train loss 2.28 on epoch=237
06/01/2022 03:01:56 - INFO - __main__ - Global step 950 Train loss 2.07 Classification-F1 0.10256410256410256 on epoch=237
06/01/2022 03:01:57 - INFO - __main__ - Step 960 Global step 960 Train loss 1.82 on epoch=239
06/01/2022 03:01:58 - INFO - __main__ - Step 970 Global step 970 Train loss 2.24 on epoch=242
06/01/2022 03:02:00 - INFO - __main__ - Step 980 Global step 980 Train loss 1.95 on epoch=244
06/01/2022 03:02:01 - INFO - __main__ - Step 990 Global step 990 Train loss 2.06 on epoch=247
06/01/2022 03:02:02 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.72 on epoch=249
06/01/2022 03:02:03 - INFO - __main__ - Global step 1000 Train loss 1.96 Classification-F1 0.15356265356265356 on epoch=249
06/01/2022 03:02:04 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.75 on epoch=252
06/01/2022 03:02:05 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.88 on epoch=254
06/01/2022 03:02:07 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.84 on epoch=257
06/01/2022 03:02:08 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.83 on epoch=259
06/01/2022 03:02:09 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.79 on epoch=262
06/01/2022 03:02:10 - INFO - __main__ - Global step 1050 Train loss 1.82 Classification-F1 0.11732186732186733 on epoch=262
06/01/2022 03:02:11 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.73 on epoch=264
06/01/2022 03:02:12 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.69 on epoch=267
06/01/2022 03:02:14 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.78 on epoch=269
06/01/2022 03:02:15 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.85 on epoch=272
06/01/2022 03:02:16 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.51 on epoch=274
06/01/2022 03:02:17 - INFO - __main__ - Global step 1100 Train loss 1.71 Classification-F1 0.19628950984883187 on epoch=274
06/01/2022 03:02:17 - INFO - __main__ - Saving model with best Classification-F1: 0.16601307189542483 -> 0.19628950984883187 on epoch=274, global_step=1100
06/01/2022 03:02:18 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.79 on epoch=277
06/01/2022 03:02:19 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.55 on epoch=279
06/01/2022 03:02:21 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.69 on epoch=282
06/01/2022 03:02:22 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.45 on epoch=284
06/01/2022 03:02:23 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.57 on epoch=287
06/01/2022 03:02:24 - INFO - __main__ - Global step 1150 Train loss 1.61 Classification-F1 0.12407862407862408 on epoch=287
06/01/2022 03:02:25 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.58 on epoch=289
06/01/2022 03:02:26 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.54 on epoch=292
06/01/2022 03:02:28 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.41 on epoch=294
06/01/2022 03:02:29 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.45 on epoch=297
06/01/2022 03:02:30 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.41 on epoch=299
06/01/2022 03:02:31 - INFO - __main__ - Global step 1200 Train loss 1.48 Classification-F1 0.19016393442622948 on epoch=299
06/01/2022 03:02:32 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.49 on epoch=302
06/01/2022 03:02:33 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.47 on epoch=304
06/01/2022 03:02:35 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.32 on epoch=307
06/01/2022 03:02:36 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.30 on epoch=309
06/01/2022 03:02:37 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.30 on epoch=312
06/01/2022 03:02:38 - INFO - __main__ - Global step 1250 Train loss 1.38 Classification-F1 0.20956521739130435 on epoch=312
06/01/2022 03:02:38 - INFO - __main__ - Saving model with best Classification-F1: 0.19628950984883187 -> 0.20956521739130435 on epoch=312, global_step=1250
06/01/2022 03:02:39 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.23 on epoch=314
06/01/2022 03:02:40 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.43 on epoch=317
06/01/2022 03:02:42 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.41 on epoch=319
06/01/2022 03:02:43 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.34 on epoch=322
06/01/2022 03:02:44 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.30 on epoch=324
06/01/2022 03:02:45 - INFO - __main__ - Global step 1300 Train loss 1.34 Classification-F1 0.2341430499325236 on epoch=324
06/01/2022 03:02:45 - INFO - __main__ - Saving model with best Classification-F1: 0.20956521739130435 -> 0.2341430499325236 on epoch=324, global_step=1300
06/01/2022 03:02:46 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.31 on epoch=327
06/01/2022 03:02:48 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.35 on epoch=329
06/01/2022 03:02:49 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.31 on epoch=332
06/01/2022 03:02:50 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.20 on epoch=334
06/01/2022 03:02:51 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.29 on epoch=337
06/01/2022 03:02:52 - INFO - __main__ - Global step 1350 Train loss 1.29 Classification-F1 0.12407862407862408 on epoch=337
06/01/2022 03:02:53 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.21 on epoch=339
06/01/2022 03:02:55 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.21 on epoch=342
06/01/2022 03:02:56 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.37 on epoch=344
06/01/2022 03:02:57 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.30 on epoch=347
06/01/2022 03:02:58 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.14 on epoch=349
06/01/2022 03:02:59 - INFO - __main__ - Global step 1400 Train loss 1.25 Classification-F1 0.1 on epoch=349
06/01/2022 03:03:00 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.35 on epoch=352
06/01/2022 03:03:02 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.12 on epoch=354
06/01/2022 03:03:03 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.36 on epoch=357
06/01/2022 03:03:04 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.28 on epoch=359
06/01/2022 03:03:06 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.30 on epoch=362
06/01/2022 03:03:06 - INFO - __main__ - Global step 1450 Train loss 1.28 Classification-F1 0.11585329696394688 on epoch=362
06/01/2022 03:03:07 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.27 on epoch=364
06/01/2022 03:03:09 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.33 on epoch=367
06/01/2022 03:03:10 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.23 on epoch=369
06/01/2022 03:03:11 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.39 on epoch=372
06/01/2022 03:03:12 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.14 on epoch=374
06/01/2022 03:03:13 - INFO - __main__ - Global step 1500 Train loss 1.27 Classification-F1 0.16071428571428573 on epoch=374
06/01/2022 03:03:14 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.21 on epoch=377
06/01/2022 03:03:16 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.22 on epoch=379
06/01/2022 03:03:17 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.11 on epoch=382
06/01/2022 03:03:18 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.25 on epoch=384
06/01/2022 03:03:19 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.40 on epoch=387
06/01/2022 03:03:20 - INFO - __main__ - Global step 1550 Train loss 1.24 Classification-F1 0.1912505726065048 on epoch=387
06/01/2022 03:03:21 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.14 on epoch=389
06/01/2022 03:03:23 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.07 on epoch=392
06/01/2022 03:03:24 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.11 on epoch=394
06/01/2022 03:03:25 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.10 on epoch=397
06/01/2022 03:03:26 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.10 on epoch=399
06/01/2022 03:03:27 - INFO - __main__ - Global step 1600 Train loss 1.10 Classification-F1 0.09493670886075949 on epoch=399
06/01/2022 03:03:28 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.17 on epoch=402
06/01/2022 03:03:30 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.25 on epoch=404
06/01/2022 03:03:31 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.13 on epoch=407
06/01/2022 03:03:32 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.11 on epoch=409
06/01/2022 03:03:33 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.28 on epoch=412
06/01/2022 03:03:34 - INFO - __main__ - Global step 1650 Train loss 1.19 Classification-F1 0.10256410256410256 on epoch=412
06/01/2022 03:03:35 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.13 on epoch=414
06/01/2022 03:03:37 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.17 on epoch=417
06/01/2022 03:03:38 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.13 on epoch=419
06/01/2022 03:03:39 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.21 on epoch=422
06/01/2022 03:03:40 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.13 on epoch=424
06/01/2022 03:03:41 - INFO - __main__ - Global step 1700 Train loss 1.15 Classification-F1 0.09615384615384615 on epoch=424
06/01/2022 03:03:42 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.22 on epoch=427
06/01/2022 03:03:44 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.07 on epoch=429
06/01/2022 03:03:45 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.03 on epoch=432
06/01/2022 03:03:46 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.14 on epoch=434
06/01/2022 03:03:48 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.99 on epoch=437
06/01/2022 03:03:48 - INFO - __main__ - Global step 1750 Train loss 1.09 Classification-F1 0.10126582278481013 on epoch=437
06/01/2022 03:03:49 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.08 on epoch=439
06/01/2022 03:03:51 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.09 on epoch=442
06/01/2022 03:03:52 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.19 on epoch=444
06/01/2022 03:03:53 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.20 on epoch=447
06/01/2022 03:03:55 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.99 on epoch=449
06/01/2022 03:03:55 - INFO - __main__ - Global step 1800 Train loss 1.11 Classification-F1 0.13034188034188032 on epoch=449
06/01/2022 03:03:56 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.14 on epoch=452
06/01/2022 03:03:58 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.00 on epoch=454
06/01/2022 03:03:59 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.15 on epoch=457
06/01/2022 03:04:00 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.09 on epoch=459
06/01/2022 03:04:02 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.33 on epoch=462
06/01/2022 03:04:02 - INFO - __main__ - Global step 1850 Train loss 1.14 Classification-F1 0.1302118933697881 on epoch=462
06/01/2022 03:04:03 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.94 on epoch=464
06/01/2022 03:04:05 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.09 on epoch=467
06/01/2022 03:04:06 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.03 on epoch=469
06/01/2022 03:04:07 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.14 on epoch=472
06/01/2022 03:04:09 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.10 on epoch=474
06/01/2022 03:04:09 - INFO - __main__ - Global step 1900 Train loss 1.06 Classification-F1 0.1 on epoch=474
06/01/2022 03:04:11 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.13 on epoch=477
06/01/2022 03:04:12 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.07 on epoch=479
06/01/2022 03:04:13 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.14 on epoch=482
06/01/2022 03:04:14 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.05 on epoch=484
06/01/2022 03:04:16 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.16 on epoch=487
06/01/2022 03:04:16 - INFO - __main__ - Global step 1950 Train loss 1.11 Classification-F1 0.1 on epoch=487
06/01/2022 03:04:18 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.95 on epoch=489
06/01/2022 03:04:19 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.11 on epoch=492
06/01/2022 03:04:20 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.07 on epoch=494
06/01/2022 03:04:21 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.07 on epoch=497
06/01/2022 03:04:23 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.94 on epoch=499
06/01/2022 03:04:23 - INFO - __main__ - Global step 2000 Train loss 1.03 Classification-F1 0.25748194014447884 on epoch=499
06/01/2022 03:04:23 - INFO - __main__ - Saving model with best Classification-F1: 0.2341430499325236 -> 0.25748194014447884 on epoch=499, global_step=2000
06/01/2022 03:04:25 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.05 on epoch=502
06/01/2022 03:04:26 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.91 on epoch=504
06/01/2022 03:04:27 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.01 on epoch=507
06/01/2022 03:04:29 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.15 on epoch=509
06/01/2022 03:04:30 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.02 on epoch=512
06/01/2022 03:04:30 - INFO - __main__ - Global step 2050 Train loss 1.03 Classification-F1 0.10126582278481013 on epoch=512
06/01/2022 03:04:32 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.04 on epoch=514
06/01/2022 03:04:33 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.07 on epoch=517
06/01/2022 03:04:34 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.06 on epoch=519
06/01/2022 03:04:36 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.08 on epoch=522
06/01/2022 03:04:37 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.19 on epoch=524
06/01/2022 03:04:37 - INFO - __main__ - Global step 2100 Train loss 1.09 Classification-F1 0.1 on epoch=524
06/01/2022 03:04:39 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.04 on epoch=527
06/01/2022 03:04:40 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.90 on epoch=529
06/01/2022 03:04:41 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.06 on epoch=532
06/01/2022 03:04:43 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.14 on epoch=534
06/01/2022 03:04:44 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.04 on epoch=537
06/01/2022 03:04:44 - INFO - __main__ - Global step 2150 Train loss 1.04 Classification-F1 0.10256410256410256 on epoch=537
06/01/2022 03:04:46 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.98 on epoch=539
06/01/2022 03:04:47 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.07 on epoch=542
06/01/2022 03:04:48 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.05 on epoch=544
06/01/2022 03:04:50 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.09 on epoch=547
06/01/2022 03:04:51 - INFO - __main__ - Step 2200 Global step 2200 Train loss 1.05 on epoch=549
06/01/2022 03:04:51 - INFO - __main__ - Global step 2200 Train loss 1.05 Classification-F1 0.13034188034188032 on epoch=549
06/01/2022 03:04:53 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.98 on epoch=552
06/01/2022 03:04:54 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.04 on epoch=554
06/01/2022 03:04:55 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.01 on epoch=557
06/01/2022 03:04:57 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.96 on epoch=559
06/01/2022 03:04:58 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.04 on epoch=562
06/01/2022 03:04:58 - INFO - __main__ - Global step 2250 Train loss 1.00 Classification-F1 0.1 on epoch=562
06/01/2022 03:05:00 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.09 on epoch=564
06/01/2022 03:05:01 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.09 on epoch=567
06/01/2022 03:05:02 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.02 on epoch=569
06/01/2022 03:05:04 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.11 on epoch=572
06/01/2022 03:05:05 - INFO - __main__ - Step 2300 Global step 2300 Train loss 1.01 on epoch=574
06/01/2022 03:05:06 - INFO - __main__ - Global step 2300 Train loss 1.06 Classification-F1 0.10256410256410256 on epoch=574
06/01/2022 03:05:07 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.07 on epoch=577
06/01/2022 03:05:08 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.01 on epoch=579
06/01/2022 03:05:09 - INFO - __main__ - Step 2330 Global step 2330 Train loss 1.14 on epoch=582
06/01/2022 03:05:11 - INFO - __main__ - Step 2340 Global step 2340 Train loss 1.06 on epoch=584
06/01/2022 03:05:12 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.93 on epoch=587
06/01/2022 03:05:13 - INFO - __main__ - Global step 2350 Train loss 1.04 Classification-F1 0.1 on epoch=587
06/01/2022 03:05:14 - INFO - __main__ - Step 2360 Global step 2360 Train loss 1.00 on epoch=589
06/01/2022 03:05:15 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.96 on epoch=592
06/01/2022 03:05:17 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.98 on epoch=594
06/01/2022 03:05:18 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.97 on epoch=597
06/01/2022 03:05:19 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.92 on epoch=599
06/01/2022 03:05:20 - INFO - __main__ - Global step 2400 Train loss 0.97 Classification-F1 0.10126582278481013 on epoch=599
06/01/2022 03:05:21 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.98 on epoch=602
06/01/2022 03:05:22 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.96 on epoch=604
06/01/2022 03:05:24 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.00 on epoch=607
06/01/2022 03:05:25 - INFO - __main__ - Step 2440 Global step 2440 Train loss 1.13 on epoch=609
06/01/2022 03:05:26 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.07 on epoch=612
06/01/2022 03:05:27 - INFO - __main__ - Global step 2450 Train loss 1.03 Classification-F1 0.2361111111111111 on epoch=612
06/01/2022 03:05:28 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.10 on epoch=614
06/01/2022 03:05:29 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.98 on epoch=617
06/01/2022 03:05:31 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.01 on epoch=619
06/01/2022 03:05:32 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.90 on epoch=622
06/01/2022 03:05:33 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.98 on epoch=624
06/01/2022 03:05:34 - INFO - __main__ - Global step 2500 Train loss 0.99 Classification-F1 0.14642857142857144 on epoch=624
06/01/2022 03:05:35 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.96 on epoch=627
06/01/2022 03:05:36 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.99 on epoch=629
06/01/2022 03:05:38 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.03 on epoch=632
06/01/2022 03:05:39 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.91 on epoch=634
06/01/2022 03:05:40 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.87 on epoch=637
06/01/2022 03:05:41 - INFO - __main__ - Global step 2550 Train loss 0.95 Classification-F1 0.12518037518037517 on epoch=637
06/01/2022 03:05:42 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.90 on epoch=639
06/01/2022 03:05:43 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.98 on epoch=642
06/01/2022 03:05:45 - INFO - __main__ - Step 2580 Global step 2580 Train loss 1.00 on epoch=644
06/01/2022 03:05:46 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.00 on epoch=647
06/01/2022 03:05:47 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.93 on epoch=649
06/01/2022 03:05:48 - INFO - __main__ - Global step 2600 Train loss 0.96 Classification-F1 0.2062937062937063 on epoch=649
06/01/2022 03:05:49 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.96 on epoch=652
06/01/2022 03:05:51 - INFO - __main__ - Step 2620 Global step 2620 Train loss 1.02 on epoch=654
06/01/2022 03:05:52 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.97 on epoch=657
06/01/2022 03:05:53 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.93 on epoch=659
06/01/2022 03:05:55 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.79 on epoch=662
06/01/2022 03:05:55 - INFO - __main__ - Global step 2650 Train loss 0.93 Classification-F1 0.17433048550069824 on epoch=662
06/01/2022 03:05:56 - INFO - __main__ - Step 2660 Global step 2660 Train loss 1.04 on epoch=664
06/01/2022 03:05:58 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.97 on epoch=667
06/01/2022 03:05:59 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.94 on epoch=669
06/01/2022 03:06:00 - INFO - __main__ - Step 2690 Global step 2690 Train loss 1.04 on epoch=672
06/01/2022 03:06:02 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.94 on epoch=674
06/01/2022 03:06:02 - INFO - __main__ - Global step 2700 Train loss 0.99 Classification-F1 0.2834440227703985 on epoch=674
06/01/2022 03:06:02 - INFO - __main__ - Saving model with best Classification-F1: 0.25748194014447884 -> 0.2834440227703985 on epoch=674, global_step=2700
06/01/2022 03:06:04 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.97 on epoch=677
06/01/2022 03:06:05 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.99 on epoch=679
06/01/2022 03:06:06 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.90 on epoch=682
06/01/2022 03:06:07 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.96 on epoch=684
06/01/2022 03:06:09 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.89 on epoch=687
06/01/2022 03:06:09 - INFO - __main__ - Global step 2750 Train loss 0.94 Classification-F1 0.26862745098039215 on epoch=687
06/01/2022 03:06:11 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.96 on epoch=689
06/01/2022 03:06:12 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.87 on epoch=692
06/01/2022 03:06:13 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.75 on epoch=694
06/01/2022 03:06:15 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.97 on epoch=697
06/01/2022 03:06:16 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.93 on epoch=699
06/01/2022 03:06:16 - INFO - __main__ - Global step 2800 Train loss 0.90 Classification-F1 0.13034188034188032 on epoch=699
06/01/2022 03:06:18 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.03 on epoch=702
06/01/2022 03:06:19 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.96 on epoch=704
06/01/2022 03:06:20 - INFO - __main__ - Step 2830 Global step 2830 Train loss 1.00 on epoch=707
06/01/2022 03:06:22 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.85 on epoch=709
06/01/2022 03:06:23 - INFO - __main__ - Step 2850 Global step 2850 Train loss 1.00 on epoch=712
06/01/2022 03:06:23 - INFO - __main__ - Global step 2850 Train loss 0.97 Classification-F1 0.24731182795698925 on epoch=712
06/01/2022 03:06:25 - INFO - __main__ - Step 2860 Global step 2860 Train loss 1.00 on epoch=714
06/01/2022 03:06:26 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.95 on epoch=717
06/01/2022 03:06:27 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.98 on epoch=719
06/01/2022 03:06:29 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.96 on epoch=722
06/01/2022 03:06:30 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.00 on epoch=724
06/01/2022 03:06:31 - INFO - __main__ - Global step 2900 Train loss 0.98 Classification-F1 0.2800936768149883 on epoch=724
06/01/2022 03:06:32 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.94 on epoch=727
06/01/2022 03:06:33 - INFO - __main__ - Step 2920 Global step 2920 Train loss 1.13 on epoch=729
06/01/2022 03:06:34 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.90 on epoch=732
06/01/2022 03:06:36 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.92 on epoch=734
06/01/2022 03:06:37 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.92 on epoch=737
06/01/2022 03:06:38 - INFO - __main__ - Global step 2950 Train loss 0.96 Classification-F1 0.18886342415754181 on epoch=737
06/01/2022 03:06:39 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.92 on epoch=739
06/01/2022 03:06:40 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.93 on epoch=742
06/01/2022 03:06:42 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.97 on epoch=744
06/01/2022 03:06:43 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.87 on epoch=747
06/01/2022 03:06:44 - INFO - __main__ - Step 3000 Global step 3000 Train loss 1.07 on epoch=749
06/01/2022 03:06:45 - INFO - __main__ - Global step 3000 Train loss 0.95 Classification-F1 0.1 on epoch=749
06/01/2022 03:06:45 - INFO - __main__ - save last model!
06/01/2022 03:06:45 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/01/2022 03:06:45 - INFO - __main__ - Start tokenizing ... 5509 instances
06/01/2022 03:06:45 - INFO - __main__ - Printing 3 examples
06/01/2022 03:06:45 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/01/2022 03:06:45 - INFO - __main__ - ['others']
06/01/2022 03:06:45 - INFO - __main__ -  [emo] what you like very little things ok
06/01/2022 03:06:45 - INFO - __main__ - ['others']
06/01/2022 03:06:45 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/01/2022 03:06:45 - INFO - __main__ - ['others']
06/01/2022 03:06:45 - INFO - __main__ - Tokenizing Input ...
06/01/2022 03:06:45 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 03:06:45 - INFO - __main__ - Printing 3 examples
06/01/2022 03:06:45 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/01/2022 03:06:45 - INFO - __main__ - ['others']
06/01/2022 03:06:45 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/01/2022 03:06:45 - INFO - __main__ - ['others']
06/01/2022 03:06:45 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/01/2022 03:06:45 - INFO - __main__ - ['others']
06/01/2022 03:06:45 - INFO - __main__ - Tokenizing Input ...
06/01/2022 03:06:45 - INFO - __main__ - Tokenizing Output ...
06/01/2022 03:06:45 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 03:06:45 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 03:06:45 - INFO - __main__ - Printing 3 examples
06/01/2022 03:06:45 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
06/01/2022 03:06:45 - INFO - __main__ - ['others']
06/01/2022 03:06:45 - INFO - __main__ -  [emo] i did ask now you did tell ms
06/01/2022 03:06:45 - INFO - __main__ - ['others']
06/01/2022 03:06:45 - INFO - __main__ -  [emo] buddy how you tell me your contact no
06/01/2022 03:06:45 - INFO - __main__ - ['others']
06/01/2022 03:06:45 - INFO - __main__ - Tokenizing Input ...
06/01/2022 03:06:45 - INFO - __main__ - Tokenizing Output ...
06/01/2022 03:06:46 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 03:06:47 - INFO - __main__ - Tokenizing Output ...
06/01/2022 03:06:51 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 03:06:51 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/01/2022 03:06:51 - INFO - __main__ - Starting training!
06/01/2022 03:06:52 - INFO - __main__ - Loaded 5509 examples from test data
06/01/2022 03:07:36 - INFO - __main__ - Saved prediction in models/T5-base-reptile-cls2cls-3e-5-2-5000-5e-1-10/singletask-emo/emo_16_13_0.3_8_predictions.txt
06/01/2022 03:07:36 - INFO - __main__ - Classification-F1 on test data: 0.0233
06/01/2022 03:07:36 - INFO - __main__ - prefix=emo_16_13, lr=0.3, bsz=8, dev_performance=0.2834440227703985, test_performance=0.02328239590045721
06/01/2022 03:07:36 - INFO - __main__ - Running ... prefix=emo_16_13, lr=0.2, bsz=8 ...
06/01/2022 03:07:37 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 03:07:37 - INFO - __main__ - Printing 3 examples
06/01/2022 03:07:37 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/01/2022 03:07:37 - INFO - __main__ - ['others']
06/01/2022 03:07:37 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/01/2022 03:07:37 - INFO - __main__ - ['others']
06/01/2022 03:07:37 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/01/2022 03:07:37 - INFO - __main__ - ['others']
06/01/2022 03:07:37 - INFO - __main__ - Tokenizing Input ...
06/01/2022 03:07:37 - INFO - __main__ - Tokenizing Output ...
06/01/2022 03:07:37 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 03:07:37 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 03:07:37 - INFO - __main__ - Printing 3 examples
06/01/2022 03:07:37 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
06/01/2022 03:07:37 - INFO - __main__ - ['others']
06/01/2022 03:07:37 - INFO - __main__ -  [emo] i did ask now you did tell ms
06/01/2022 03:07:37 - INFO - __main__ - ['others']
06/01/2022 03:07:37 - INFO - __main__ -  [emo] buddy how you tell me your contact no
06/01/2022 03:07:37 - INFO - __main__ - ['others']
06/01/2022 03:07:37 - INFO - __main__ - Tokenizing Input ...
06/01/2022 03:07:37 - INFO - __main__ - Tokenizing Output ...
06/01/2022 03:07:37 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 03:07:43 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 03:07:43 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/01/2022 03:07:43 - INFO - __main__ - Starting training!
06/01/2022 03:07:44 - INFO - __main__ - Step 10 Global step 10 Train loss 8.98 on epoch=2
06/01/2022 03:07:45 - INFO - __main__ - Step 20 Global step 20 Train loss 9.10 on epoch=4
06/01/2022 03:07:47 - INFO - __main__ - Step 30 Global step 30 Train loss 9.06 on epoch=7
06/01/2022 03:07:48 - INFO - __main__ - Step 40 Global step 40 Train loss 8.95 on epoch=9
06/01/2022 03:07:49 - INFO - __main__ - Step 50 Global step 50 Train loss 8.86 on epoch=12
06/01/2022 03:07:55 - INFO - __main__ - Global step 50 Train loss 8.99 Classification-F1 0.0 on epoch=12
06/01/2022 03:07:55 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
06/01/2022 03:07:56 - INFO - __main__ - Step 60 Global step 60 Train loss 8.82 on epoch=14
06/01/2022 03:07:57 - INFO - __main__ - Step 70 Global step 70 Train loss 8.76 on epoch=17
06/01/2022 03:07:58 - INFO - __main__ - Step 80 Global step 80 Train loss 8.79 on epoch=19
06/01/2022 03:08:00 - INFO - __main__ - Step 90 Global step 90 Train loss 8.70 on epoch=22
06/01/2022 03:08:01 - INFO - __main__ - Step 100 Global step 100 Train loss 8.73 on epoch=24
06/01/2022 03:08:06 - INFO - __main__ - Global step 100 Train loss 8.76 Classification-F1 0.0 on epoch=24
06/01/2022 03:08:08 - INFO - __main__ - Step 110 Global step 110 Train loss 8.74 on epoch=27
06/01/2022 03:08:09 - INFO - __main__ - Step 120 Global step 120 Train loss 8.74 on epoch=29
06/01/2022 03:08:10 - INFO - __main__ - Step 130 Global step 130 Train loss 8.72 on epoch=32
06/01/2022 03:08:11 - INFO - __main__ - Step 140 Global step 140 Train loss 8.69 on epoch=34
06/01/2022 03:08:12 - INFO - __main__ - Step 150 Global step 150 Train loss 8.61 on epoch=37
06/01/2022 03:08:17 - INFO - __main__ - Global step 150 Train loss 8.70 Classification-F1 0.0 on epoch=37
06/01/2022 03:08:19 - INFO - __main__ - Step 160 Global step 160 Train loss 8.63 on epoch=39
06/01/2022 03:08:20 - INFO - __main__ - Step 170 Global step 170 Train loss 8.56 on epoch=42
06/01/2022 03:08:21 - INFO - __main__ - Step 180 Global step 180 Train loss 8.65 on epoch=44
06/01/2022 03:08:22 - INFO - __main__ - Step 190 Global step 190 Train loss 8.54 on epoch=47
06/01/2022 03:08:23 - INFO - __main__ - Step 200 Global step 200 Train loss 8.57 on epoch=49
06/01/2022 03:08:30 - INFO - __main__ - Global step 200 Train loss 8.59 Classification-F1 0.0 on epoch=49
06/01/2022 03:08:31 - INFO - __main__ - Step 210 Global step 210 Train loss 8.51 on epoch=52
06/01/2022 03:08:32 - INFO - __main__ - Step 220 Global step 220 Train loss 8.53 on epoch=54
06/01/2022 03:08:33 - INFO - __main__ - Step 230 Global step 230 Train loss 8.51 on epoch=57
06/01/2022 03:08:35 - INFO - __main__ - Step 240 Global step 240 Train loss 8.54 on epoch=59
06/01/2022 03:08:36 - INFO - __main__ - Step 250 Global step 250 Train loss 8.48 on epoch=62
06/01/2022 03:08:44 - INFO - __main__ - Global step 250 Train loss 8.51 Classification-F1 0.0 on epoch=62
06/01/2022 03:08:46 - INFO - __main__ - Step 260 Global step 260 Train loss 8.39 on epoch=64
06/01/2022 03:08:47 - INFO - __main__ - Step 270 Global step 270 Train loss 8.33 on epoch=67
06/01/2022 03:08:48 - INFO - __main__ - Step 280 Global step 280 Train loss 8.40 on epoch=69
06/01/2022 03:08:49 - INFO - __main__ - Step 290 Global step 290 Train loss 8.25 on epoch=72
06/01/2022 03:08:51 - INFO - __main__ - Step 300 Global step 300 Train loss 8.33 on epoch=74
06/01/2022 03:08:56 - INFO - __main__ - Global step 300 Train loss 8.34 Classification-F1 0.0 on epoch=74
06/01/2022 03:08:57 - INFO - __main__ - Step 310 Global step 310 Train loss 8.25 on epoch=77
06/01/2022 03:08:58 - INFO - __main__ - Step 320 Global step 320 Train loss 8.11 on epoch=79
06/01/2022 03:09:00 - INFO - __main__ - Step 330 Global step 330 Train loss 8.11 on epoch=82
06/01/2022 03:09:01 - INFO - __main__ - Step 340 Global step 340 Train loss 8.04 on epoch=84
06/01/2022 03:09:02 - INFO - __main__ - Step 350 Global step 350 Train loss 7.92 on epoch=87
06/01/2022 03:09:07 - INFO - __main__ - Global step 350 Train loss 8.09 Classification-F1 0.0 on epoch=87
06/01/2022 03:09:09 - INFO - __main__ - Step 360 Global step 360 Train loss 7.98 on epoch=89
06/01/2022 03:09:10 - INFO - __main__ - Step 370 Global step 370 Train loss 7.79 on epoch=92
06/01/2022 03:09:11 - INFO - __main__ - Step 380 Global step 380 Train loss 7.72 on epoch=94
06/01/2022 03:09:12 - INFO - __main__ - Step 390 Global step 390 Train loss 7.63 on epoch=97
06/01/2022 03:09:14 - INFO - __main__ - Step 400 Global step 400 Train loss 7.50 on epoch=99
06/01/2022 03:09:32 - INFO - __main__ - Global step 400 Train loss 7.72 Classification-F1 0.0 on epoch=99
06/01/2022 03:09:33 - INFO - __main__ - Step 410 Global step 410 Train loss 7.50 on epoch=102
06/01/2022 03:09:34 - INFO - __main__ - Step 420 Global step 420 Train loss 7.39 on epoch=104
06/01/2022 03:09:35 - INFO - __main__ - Step 430 Global step 430 Train loss 7.00 on epoch=107
06/01/2022 03:09:37 - INFO - __main__ - Step 440 Global step 440 Train loss 7.25 on epoch=109
06/01/2022 03:09:38 - INFO - __main__ - Step 450 Global step 450 Train loss 7.10 on epoch=112
06/01/2022 03:09:51 - INFO - __main__ - Global step 450 Train loss 7.25 Classification-F1 0.0 on epoch=112
06/01/2022 03:09:52 - INFO - __main__ - Step 460 Global step 460 Train loss 7.02 on epoch=114
06/01/2022 03:09:53 - INFO - __main__ - Step 470 Global step 470 Train loss 7.18 on epoch=117
06/01/2022 03:09:55 - INFO - __main__ - Step 480 Global step 480 Train loss 7.02 on epoch=119
06/01/2022 03:09:56 - INFO - __main__ - Step 490 Global step 490 Train loss 6.95 on epoch=122
06/01/2022 03:09:57 - INFO - __main__ - Step 500 Global step 500 Train loss 6.81 on epoch=124
06/01/2022 03:10:15 - INFO - __main__ - Global step 500 Train loss 7.00 Classification-F1 0.0 on epoch=124
06/01/2022 03:10:16 - INFO - __main__ - Step 510 Global step 510 Train loss 6.78 on epoch=127
06/01/2022 03:10:18 - INFO - __main__ - Step 520 Global step 520 Train loss 6.90 on epoch=129
06/01/2022 03:10:19 - INFO - __main__ - Step 530 Global step 530 Train loss 6.57 on epoch=132
06/01/2022 03:10:20 - INFO - __main__ - Step 540 Global step 540 Train loss 6.42 on epoch=134
06/01/2022 03:10:21 - INFO - __main__ - Step 550 Global step 550 Train loss 6.51 on epoch=137
06/01/2022 03:10:27 - INFO - __main__ - Global step 550 Train loss 6.64 Classification-F1 0.0 on epoch=137
06/01/2022 03:10:28 - INFO - __main__ - Step 560 Global step 560 Train loss 6.35 on epoch=139
06/01/2022 03:10:30 - INFO - __main__ - Step 570 Global step 570 Train loss 6.24 on epoch=142
06/01/2022 03:10:31 - INFO - __main__ - Step 580 Global step 580 Train loss 6.23 on epoch=144
06/01/2022 03:10:32 - INFO - __main__ - Step 590 Global step 590 Train loss 6.28 on epoch=147
06/01/2022 03:10:33 - INFO - __main__ - Step 600 Global step 600 Train loss 6.32 on epoch=149
06/01/2022 03:10:45 - INFO - __main__ - Global step 600 Train loss 6.28 Classification-F1 0.0 on epoch=149
06/01/2022 03:10:46 - INFO - __main__ - Step 610 Global step 610 Train loss 6.03 on epoch=152
06/01/2022 03:10:47 - INFO - __main__ - Step 620 Global step 620 Train loss 5.90 on epoch=154
06/01/2022 03:10:49 - INFO - __main__ - Step 630 Global step 630 Train loss 5.82 on epoch=157
06/01/2022 03:10:50 - INFO - __main__ - Step 640 Global step 640 Train loss 5.72 on epoch=159
06/01/2022 03:10:51 - INFO - __main__ - Step 650 Global step 650 Train loss 5.73 on epoch=162
06/01/2022 03:11:03 - INFO - __main__ - Global step 650 Train loss 5.84 Classification-F1 0.0 on epoch=162
06/01/2022 03:11:05 - INFO - __main__ - Step 660 Global step 660 Train loss 5.56 on epoch=164
06/01/2022 03:11:06 - INFO - __main__ - Step 670 Global step 670 Train loss 5.60 on epoch=167
06/01/2022 03:11:07 - INFO - __main__ - Step 680 Global step 680 Train loss 5.41 on epoch=169
06/01/2022 03:11:08 - INFO - __main__ - Step 690 Global step 690 Train loss 5.33 on epoch=172
06/01/2022 03:11:10 - INFO - __main__ - Step 700 Global step 700 Train loss 5.05 on epoch=174
06/01/2022 03:11:20 - INFO - __main__ - Global step 700 Train loss 5.39 Classification-F1 0.0 on epoch=174
06/01/2022 03:11:21 - INFO - __main__ - Step 710 Global step 710 Train loss 5.07 on epoch=177
06/01/2022 03:11:23 - INFO - __main__ - Step 720 Global step 720 Train loss 5.18 on epoch=179
06/01/2022 03:11:24 - INFO - __main__ - Step 730 Global step 730 Train loss 5.00 on epoch=182
06/01/2022 03:11:25 - INFO - __main__ - Step 740 Global step 740 Train loss 5.00 on epoch=184
06/01/2022 03:11:26 - INFO - __main__ - Step 750 Global step 750 Train loss 4.98 on epoch=187
06/01/2022 03:11:33 - INFO - __main__ - Global step 750 Train loss 5.04 Classification-F1 0.0 on epoch=187
06/01/2022 03:11:34 - INFO - __main__ - Step 760 Global step 760 Train loss 4.95 on epoch=189
06/01/2022 03:11:35 - INFO - __main__ - Step 770 Global step 770 Train loss 4.84 on epoch=192
06/01/2022 03:11:36 - INFO - __main__ - Step 780 Global step 780 Train loss 4.45 on epoch=194
06/01/2022 03:11:37 - INFO - __main__ - Step 790 Global step 790 Train loss 4.60 on epoch=197
06/01/2022 03:11:39 - INFO - __main__ - Step 800 Global step 800 Train loss 4.51 on epoch=199
06/01/2022 03:12:00 - INFO - __main__ - Global step 800 Train loss 4.67 Classification-F1 0.0 on epoch=199
06/01/2022 03:12:01 - INFO - __main__ - Step 810 Global step 810 Train loss 4.60 on epoch=202
06/01/2022 03:12:02 - INFO - __main__ - Step 820 Global step 820 Train loss 4.45 on epoch=204
06/01/2022 03:12:03 - INFO - __main__ - Step 830 Global step 830 Train loss 4.55 on epoch=207
06/01/2022 03:12:05 - INFO - __main__ - Step 840 Global step 840 Train loss 4.42 on epoch=209
06/01/2022 03:12:06 - INFO - __main__ - Step 850 Global step 850 Train loss 4.43 on epoch=212
06/01/2022 03:12:20 - INFO - __main__ - Global step 850 Train loss 4.49 Classification-F1 0.005 on epoch=212
06/01/2022 03:12:20 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.005 on epoch=212, global_step=850
06/01/2022 03:12:22 - INFO - __main__ - Step 860 Global step 860 Train loss 4.21 on epoch=214
06/01/2022 03:12:23 - INFO - __main__ - Step 870 Global step 870 Train loss 4.10 on epoch=217
06/01/2022 03:12:24 - INFO - __main__ - Step 880 Global step 880 Train loss 4.02 on epoch=219
06/01/2022 03:12:25 - INFO - __main__ - Step 890 Global step 890 Train loss 4.26 on epoch=222
06/01/2022 03:12:27 - INFO - __main__ - Step 900 Global step 900 Train loss 3.92 on epoch=224
06/01/2022 03:12:30 - INFO - __main__ - Global step 900 Train loss 4.10 Classification-F1 0.00865800865800866 on epoch=224
06/01/2022 03:12:30 - INFO - __main__ - Saving model with best Classification-F1: 0.005 -> 0.00865800865800866 on epoch=224, global_step=900
06/01/2022 03:12:32 - INFO - __main__ - Step 910 Global step 910 Train loss 4.13 on epoch=227
06/01/2022 03:12:33 - INFO - __main__ - Step 920 Global step 920 Train loss 3.89 on epoch=229
06/01/2022 03:12:34 - INFO - __main__ - Step 930 Global step 930 Train loss 3.90 on epoch=232
06/01/2022 03:12:35 - INFO - __main__ - Step 940 Global step 940 Train loss 3.89 on epoch=234
06/01/2022 03:12:37 - INFO - __main__ - Step 950 Global step 950 Train loss 4.07 on epoch=237
06/01/2022 03:12:40 - INFO - __main__ - Global step 950 Train loss 3.97 Classification-F1 0.013257575757575758 on epoch=237
06/01/2022 03:12:40 - INFO - __main__ - Saving model with best Classification-F1: 0.00865800865800866 -> 0.013257575757575758 on epoch=237, global_step=950
06/01/2022 03:12:42 - INFO - __main__ - Step 960 Global step 960 Train loss 4.10 on epoch=239
06/01/2022 03:12:43 - INFO - __main__ - Step 970 Global step 970 Train loss 4.02 on epoch=242
06/01/2022 03:12:44 - INFO - __main__ - Step 980 Global step 980 Train loss 3.67 on epoch=244
06/01/2022 03:12:45 - INFO - __main__ - Step 990 Global step 990 Train loss 3.92 on epoch=247
06/01/2022 03:12:47 - INFO - __main__ - Step 1000 Global step 1000 Train loss 3.66 on epoch=249
06/01/2022 03:12:51 - INFO - __main__ - Global step 1000 Train loss 3.88 Classification-F1 0.015345268542199489 on epoch=249
06/01/2022 03:12:51 - INFO - __main__ - Saving model with best Classification-F1: 0.013257575757575758 -> 0.015345268542199489 on epoch=249, global_step=1000
06/01/2022 03:12:53 - INFO - __main__ - Step 1010 Global step 1010 Train loss 3.93 on epoch=252
06/01/2022 03:12:54 - INFO - __main__ - Step 1020 Global step 1020 Train loss 3.75 on epoch=254
06/01/2022 03:12:55 - INFO - __main__ - Step 1030 Global step 1030 Train loss 3.82 on epoch=257
06/01/2022 03:12:56 - INFO - __main__ - Step 1040 Global step 1040 Train loss 3.66 on epoch=259
06/01/2022 03:12:57 - INFO - __main__ - Step 1050 Global step 1050 Train loss 3.73 on epoch=262
06/01/2022 03:13:01 - INFO - __main__ - Global step 1050 Train loss 3.78 Classification-F1 0.024038461538461536 on epoch=262
06/01/2022 03:13:01 - INFO - __main__ - Saving model with best Classification-F1: 0.015345268542199489 -> 0.024038461538461536 on epoch=262, global_step=1050
06/01/2022 03:13:03 - INFO - __main__ - Step 1060 Global step 1060 Train loss 3.75 on epoch=264
06/01/2022 03:13:04 - INFO - __main__ - Step 1070 Global step 1070 Train loss 3.60 on epoch=267
06/01/2022 03:13:05 - INFO - __main__ - Step 1080 Global step 1080 Train loss 3.54 on epoch=269
06/01/2022 03:13:06 - INFO - __main__ - Step 1090 Global step 1090 Train loss 3.87 on epoch=272
06/01/2022 03:13:08 - INFO - __main__ - Step 1100 Global step 1100 Train loss 3.50 on epoch=274
06/01/2022 03:13:09 - INFO - __main__ - Global step 1100 Train loss 3.65 Classification-F1 0.1 on epoch=274
06/01/2022 03:13:09 - INFO - __main__ - Saving model with best Classification-F1: 0.024038461538461536 -> 0.1 on epoch=274, global_step=1100
06/01/2022 03:13:10 - INFO - __main__ - Step 1110 Global step 1110 Train loss 3.65 on epoch=277
06/01/2022 03:13:12 - INFO - __main__ - Step 1120 Global step 1120 Train loss 3.48 on epoch=279
06/01/2022 03:13:13 - INFO - __main__ - Step 1130 Global step 1130 Train loss 3.64 on epoch=282
06/01/2022 03:13:14 - INFO - __main__ - Step 1140 Global step 1140 Train loss 3.35 on epoch=284
06/01/2022 03:13:15 - INFO - __main__ - Step 1150 Global step 1150 Train loss 3.44 on epoch=287
06/01/2022 03:13:19 - INFO - __main__ - Global step 1150 Train loss 3.51 Classification-F1 0.07017543859649124 on epoch=287
06/01/2022 03:13:20 - INFO - __main__ - Step 1160 Global step 1160 Train loss 3.32 on epoch=289
06/01/2022 03:13:21 - INFO - __main__ - Step 1170 Global step 1170 Train loss 3.42 on epoch=292
06/01/2022 03:13:23 - INFO - __main__ - Step 1180 Global step 1180 Train loss 3.25 on epoch=294
06/01/2022 03:13:24 - INFO - __main__ - Step 1190 Global step 1190 Train loss 3.34 on epoch=297
06/01/2022 03:13:25 - INFO - __main__ - Step 1200 Global step 1200 Train loss 3.25 on epoch=299
06/01/2022 03:13:26 - INFO - __main__ - Global step 1200 Train loss 3.32 Classification-F1 0.1 on epoch=299
06/01/2022 03:13:28 - INFO - __main__ - Step 1210 Global step 1210 Train loss 3.11 on epoch=302
06/01/2022 03:13:29 - INFO - __main__ - Step 1220 Global step 1220 Train loss 3.31 on epoch=304
06/01/2022 03:13:30 - INFO - __main__ - Step 1230 Global step 1230 Train loss 3.26 on epoch=307
06/01/2022 03:13:31 - INFO - __main__ - Step 1240 Global step 1240 Train loss 3.14 on epoch=309
06/01/2022 03:13:33 - INFO - __main__ - Step 1250 Global step 1250 Train loss 3.31 on epoch=312
06/01/2022 03:13:33 - INFO - __main__ - Global step 1250 Train loss 3.23 Classification-F1 0.10686274509803921 on epoch=312
06/01/2022 03:13:33 - INFO - __main__ - Saving model with best Classification-F1: 0.1 -> 0.10686274509803921 on epoch=312, global_step=1250
06/01/2022 03:13:34 - INFO - __main__ - Step 1260 Global step 1260 Train loss 3.07 on epoch=314
06/01/2022 03:13:36 - INFO - __main__ - Step 1270 Global step 1270 Train loss 3.27 on epoch=317
06/01/2022 03:13:37 - INFO - __main__ - Step 1280 Global step 1280 Train loss 3.01 on epoch=319
06/01/2022 03:13:38 - INFO - __main__ - Step 1290 Global step 1290 Train loss 3.19 on epoch=322
06/01/2022 03:13:39 - INFO - __main__ - Step 1300 Global step 1300 Train loss 2.85 on epoch=324
06/01/2022 03:13:40 - INFO - __main__ - Global step 1300 Train loss 3.08 Classification-F1 0.1 on epoch=324
06/01/2022 03:13:41 - INFO - __main__ - Step 1310 Global step 1310 Train loss 3.16 on epoch=327
06/01/2022 03:13:43 - INFO - __main__ - Step 1320 Global step 1320 Train loss 3.10 on epoch=329
06/01/2022 03:13:44 - INFO - __main__ - Step 1330 Global step 1330 Train loss 3.06 on epoch=332
06/01/2022 03:13:45 - INFO - __main__ - Step 1340 Global step 1340 Train loss 2.89 on epoch=334
06/01/2022 03:13:46 - INFO - __main__ - Step 1350 Global step 1350 Train loss 3.20 on epoch=337
06/01/2022 03:13:47 - INFO - __main__ - Global step 1350 Train loss 3.08 Classification-F1 0.0810126582278481 on epoch=337
06/01/2022 03:13:48 - INFO - __main__ - Step 1360 Global step 1360 Train loss 2.99 on epoch=339
06/01/2022 03:13:49 - INFO - __main__ - Step 1370 Global step 1370 Train loss 2.97 on epoch=342
06/01/2022 03:13:51 - INFO - __main__ - Step 1380 Global step 1380 Train loss 2.75 on epoch=344
06/01/2022 03:13:52 - INFO - __main__ - Step 1390 Global step 1390 Train loss 3.06 on epoch=347
06/01/2022 03:13:53 - INFO - __main__ - Step 1400 Global step 1400 Train loss 2.66 on epoch=349
06/01/2022 03:13:54 - INFO - __main__ - Global step 1400 Train loss 2.89 Classification-F1 0.08108108108108109 on epoch=349
06/01/2022 03:13:55 - INFO - __main__ - Step 1410 Global step 1410 Train loss 2.93 on epoch=352
06/01/2022 03:13:56 - INFO - __main__ - Step 1420 Global step 1420 Train loss 2.55 on epoch=354
06/01/2022 03:13:57 - INFO - __main__ - Step 1430 Global step 1430 Train loss 2.91 on epoch=357
06/01/2022 03:13:59 - INFO - __main__ - Step 1440 Global step 1440 Train loss 2.80 on epoch=359
06/01/2022 03:14:00 - INFO - __main__ - Step 1450 Global step 1450 Train loss 2.83 on epoch=362
06/01/2022 03:14:00 - INFO - __main__ - Global step 1450 Train loss 2.81 Classification-F1 0.1 on epoch=362
06/01/2022 03:14:02 - INFO - __main__ - Step 1460 Global step 1460 Train loss 2.73 on epoch=364
06/01/2022 03:14:03 - INFO - __main__ - Step 1470 Global step 1470 Train loss 2.80 on epoch=367
06/01/2022 03:14:04 - INFO - __main__ - Step 1480 Global step 1480 Train loss 2.66 on epoch=369
06/01/2022 03:14:05 - INFO - __main__ - Step 1490 Global step 1490 Train loss 2.81 on epoch=372
06/01/2022 03:14:07 - INFO - __main__ - Step 1500 Global step 1500 Train loss 2.58 on epoch=374
06/01/2022 03:14:07 - INFO - __main__ - Global step 1500 Train loss 2.72 Classification-F1 0.09493670886075949 on epoch=374
06/01/2022 03:14:08 - INFO - __main__ - Step 1510 Global step 1510 Train loss 2.68 on epoch=377
06/01/2022 03:14:10 - INFO - __main__ - Step 1520 Global step 1520 Train loss 2.57 on epoch=379
06/01/2022 03:14:11 - INFO - __main__ - Step 1530 Global step 1530 Train loss 2.88 on epoch=382
06/01/2022 03:14:12 - INFO - __main__ - Step 1540 Global step 1540 Train loss 2.55 on epoch=384
06/01/2022 03:14:13 - INFO - __main__ - Step 1550 Global step 1550 Train loss 2.62 on epoch=387
06/01/2022 03:14:14 - INFO - __main__ - Global step 1550 Train loss 2.66 Classification-F1 0.06857142857142857 on epoch=387
06/01/2022 03:14:15 - INFO - __main__ - Step 1560 Global step 1560 Train loss 2.56 on epoch=389
06/01/2022 03:14:16 - INFO - __main__ - Step 1570 Global step 1570 Train loss 2.70 on epoch=392
06/01/2022 03:14:18 - INFO - __main__ - Step 1580 Global step 1580 Train loss 2.45 on epoch=394
06/01/2022 03:14:19 - INFO - __main__ - Step 1590 Global step 1590 Train loss 2.48 on epoch=397
06/01/2022 03:14:20 - INFO - __main__ - Step 1600 Global step 1600 Train loss 2.35 on epoch=399
06/01/2022 03:14:21 - INFO - __main__ - Global step 1600 Train loss 2.51 Classification-F1 0.08333333333333333 on epoch=399
06/01/2022 03:14:22 - INFO - __main__ - Step 1610 Global step 1610 Train loss 2.40 on epoch=402
06/01/2022 03:14:23 - INFO - __main__ - Step 1620 Global step 1620 Train loss 2.27 on epoch=404
06/01/2022 03:14:24 - INFO - __main__ - Step 1630 Global step 1630 Train loss 2.58 on epoch=407
06/01/2022 03:14:26 - INFO - __main__ - Step 1640 Global step 1640 Train loss 2.33 on epoch=409
06/01/2022 03:14:27 - INFO - __main__ - Step 1650 Global step 1650 Train loss 2.60 on epoch=412
06/01/2022 03:14:28 - INFO - __main__ - Global step 1650 Train loss 2.43 Classification-F1 0.09615384615384615 on epoch=412
06/01/2022 03:14:29 - INFO - __main__ - Step 1660 Global step 1660 Train loss 2.37 on epoch=414
06/01/2022 03:14:30 - INFO - __main__ - Step 1670 Global step 1670 Train loss 2.39 on epoch=417
06/01/2022 03:14:31 - INFO - __main__ - Step 1680 Global step 1680 Train loss 2.37 on epoch=419
06/01/2022 03:14:33 - INFO - __main__ - Step 1690 Global step 1690 Train loss 2.37 on epoch=422
06/01/2022 03:14:34 - INFO - __main__ - Step 1700 Global step 1700 Train loss 2.21 on epoch=424
06/01/2022 03:14:34 - INFO - __main__ - Global step 1700 Train loss 2.34 Classification-F1 0.08380373425966131 on epoch=424
06/01/2022 03:14:36 - INFO - __main__ - Step 1710 Global step 1710 Train loss 2.48 on epoch=427
06/01/2022 03:14:37 - INFO - __main__ - Step 1720 Global step 1720 Train loss 2.33 on epoch=429
06/01/2022 03:14:38 - INFO - __main__ - Step 1730 Global step 1730 Train loss 2.32 on epoch=432
06/01/2022 03:14:39 - INFO - __main__ - Step 1740 Global step 1740 Train loss 2.31 on epoch=434
06/01/2022 03:14:41 - INFO - __main__ - Step 1750 Global step 1750 Train loss 2.41 on epoch=437
06/01/2022 03:14:41 - INFO - __main__ - Global step 1750 Train loss 2.37 Classification-F1 0.11336032388663966 on epoch=437
06/01/2022 03:14:41 - INFO - __main__ - Saving model with best Classification-F1: 0.10686274509803921 -> 0.11336032388663966 on epoch=437, global_step=1750
06/01/2022 03:14:42 - INFO - __main__ - Step 1760 Global step 1760 Train loss 2.31 on epoch=439
06/01/2022 03:14:44 - INFO - __main__ - Step 1770 Global step 1770 Train loss 2.42 on epoch=442
06/01/2022 03:14:45 - INFO - __main__ - Step 1780 Global step 1780 Train loss 2.26 on epoch=444
06/01/2022 03:14:46 - INFO - __main__ - Step 1790 Global step 1790 Train loss 2.24 on epoch=447
06/01/2022 03:14:47 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.97 on epoch=449
06/01/2022 03:14:48 - INFO - __main__ - Global step 1800 Train loss 2.24 Classification-F1 0.142512077294686 on epoch=449
06/01/2022 03:14:48 - INFO - __main__ - Saving model with best Classification-F1: 0.11336032388663966 -> 0.142512077294686 on epoch=449, global_step=1800
06/01/2022 03:14:49 - INFO - __main__ - Step 1810 Global step 1810 Train loss 2.34 on epoch=452
06/01/2022 03:14:50 - INFO - __main__ - Step 1820 Global step 1820 Train loss 2.02 on epoch=454
06/01/2022 03:14:52 - INFO - __main__ - Step 1830 Global step 1830 Train loss 2.24 on epoch=457
06/01/2022 03:14:53 - INFO - __main__ - Step 1840 Global step 1840 Train loss 2.14 on epoch=459
06/01/2022 03:14:54 - INFO - __main__ - Step 1850 Global step 1850 Train loss 2.29 on epoch=462
06/01/2022 03:14:55 - INFO - __main__ - Global step 1850 Train loss 2.21 Classification-F1 0.1015625 on epoch=462
06/01/2022 03:14:56 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.97 on epoch=464
06/01/2022 03:14:57 - INFO - __main__ - Step 1870 Global step 1870 Train loss 2.20 on epoch=467
06/01/2022 03:14:58 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.91 on epoch=469
06/01/2022 03:15:00 - INFO - __main__ - Step 1890 Global step 1890 Train loss 2.10 on epoch=472
06/01/2022 03:15:01 - INFO - __main__ - Step 1900 Global step 1900 Train loss 2.12 on epoch=474
06/01/2022 03:15:01 - INFO - __main__ - Global step 1900 Train loss 2.06 Classification-F1 0.16366223908918406 on epoch=474
06/01/2022 03:15:02 - INFO - __main__ - Saving model with best Classification-F1: 0.142512077294686 -> 0.16366223908918406 on epoch=474, global_step=1900
06/01/2022 03:15:03 - INFO - __main__ - Step 1910 Global step 1910 Train loss 2.13 on epoch=477
06/01/2022 03:15:04 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.82 on epoch=479
06/01/2022 03:15:05 - INFO - __main__ - Step 1930 Global step 1930 Train loss 2.09 on epoch=482
06/01/2022 03:15:07 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.83 on epoch=484
06/01/2022 03:15:08 - INFO - __main__ - Step 1950 Global step 1950 Train loss 2.08 on epoch=487
06/01/2022 03:15:08 - INFO - __main__ - Global step 1950 Train loss 1.99 Classification-F1 0.08450704225352113 on epoch=487
06/01/2022 03:15:10 - INFO - __main__ - Step 1960 Global step 1960 Train loss 2.05 on epoch=489
06/01/2022 03:15:11 - INFO - __main__ - Step 1970 Global step 1970 Train loss 2.19 on epoch=492
06/01/2022 03:15:12 - INFO - __main__ - Step 1980 Global step 1980 Train loss 2.03 on epoch=494
06/01/2022 03:15:13 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.94 on epoch=497
06/01/2022 03:15:15 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.96 on epoch=499
06/01/2022 03:15:15 - INFO - __main__ - Global step 2000 Train loss 2.03 Classification-F1 0.17036188422400433 on epoch=499
06/01/2022 03:15:15 - INFO - __main__ - Saving model with best Classification-F1: 0.16366223908918406 -> 0.17036188422400433 on epoch=499, global_step=2000
06/01/2022 03:15:16 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.92 on epoch=502
06/01/2022 03:15:18 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.74 on epoch=504
06/01/2022 03:15:19 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.77 on epoch=507
06/01/2022 03:15:20 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.88 on epoch=509
06/01/2022 03:15:21 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.72 on epoch=512
06/01/2022 03:15:22 - INFO - __main__ - Global step 2050 Train loss 1.81 Classification-F1 0.12417582417582418 on epoch=512
06/01/2022 03:15:23 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.86 on epoch=514
06/01/2022 03:15:24 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.85 on epoch=517
06/01/2022 03:15:26 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.81 on epoch=519
06/01/2022 03:15:27 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.80 on epoch=522
06/01/2022 03:15:28 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.65 on epoch=524
06/01/2022 03:15:29 - INFO - __main__ - Global step 2100 Train loss 1.79 Classification-F1 0.08293530178028657 on epoch=524
06/01/2022 03:15:30 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.94 on epoch=527
06/01/2022 03:15:31 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.65 on epoch=529
06/01/2022 03:15:32 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.78 on epoch=532
06/01/2022 03:15:33 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.65 on epoch=534
06/01/2022 03:15:35 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.79 on epoch=537
06/01/2022 03:15:35 - INFO - __main__ - Global step 2150 Train loss 1.76 Classification-F1 0.13657090743274053 on epoch=537
06/01/2022 03:15:36 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.83 on epoch=539
06/01/2022 03:15:38 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.79 on epoch=542
06/01/2022 03:15:39 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.56 on epoch=544
06/01/2022 03:15:40 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.77 on epoch=547
06/01/2022 03:15:41 - INFO - __main__ - Step 2200 Global step 2200 Train loss 1.55 on epoch=549
06/01/2022 03:15:42 - INFO - __main__ - Global step 2200 Train loss 1.70 Classification-F1 0.10843672456575681 on epoch=549
06/01/2022 03:15:43 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.70 on epoch=552
06/01/2022 03:15:44 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.57 on epoch=554
06/01/2022 03:15:46 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.73 on epoch=557
06/01/2022 03:15:47 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.56 on epoch=559
06/01/2022 03:15:48 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.66 on epoch=562
06/01/2022 03:15:49 - INFO - __main__ - Global step 2250 Train loss 1.64 Classification-F1 0.1181716833890747 on epoch=562
06/01/2022 03:15:50 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.58 on epoch=564
06/01/2022 03:15:51 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.56 on epoch=567
06/01/2022 03:15:52 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.45 on epoch=569
06/01/2022 03:15:54 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.59 on epoch=572
06/01/2022 03:15:55 - INFO - __main__ - Step 2300 Global step 2300 Train loss 1.41 on epoch=574
06/01/2022 03:15:55 - INFO - __main__ - Global step 2300 Train loss 1.52 Classification-F1 0.1767857142857143 on epoch=574
06/01/2022 03:15:55 - INFO - __main__ - Saving model with best Classification-F1: 0.17036188422400433 -> 0.1767857142857143 on epoch=574, global_step=2300
06/01/2022 03:15:57 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.52 on epoch=577
06/01/2022 03:15:58 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.62 on epoch=579
06/01/2022 03:15:59 - INFO - __main__ - Step 2330 Global step 2330 Train loss 1.57 on epoch=582
06/01/2022 03:16:00 - INFO - __main__ - Step 2340 Global step 2340 Train loss 1.54 on epoch=584
06/01/2022 03:16:02 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.58 on epoch=587
06/01/2022 03:16:02 - INFO - __main__ - Global step 2350 Train loss 1.57 Classification-F1 0.1347521402927368 on epoch=587
06/01/2022 03:16:03 - INFO - __main__ - Step 2360 Global step 2360 Train loss 1.56 on epoch=589
06/01/2022 03:16:05 - INFO - __main__ - Step 2370 Global step 2370 Train loss 1.49 on epoch=592
06/01/2022 03:16:06 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.49 on epoch=594
06/01/2022 03:16:07 - INFO - __main__ - Step 2390 Global step 2390 Train loss 1.58 on epoch=597
06/01/2022 03:16:08 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.47 on epoch=599
06/01/2022 03:16:09 - INFO - __main__ - Global step 2400 Train loss 1.52 Classification-F1 0.08333333333333333 on epoch=599
06/01/2022 03:16:10 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.49 on epoch=602
06/01/2022 03:16:11 - INFO - __main__ - Step 2420 Global step 2420 Train loss 1.45 on epoch=604
06/01/2022 03:16:13 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.53 on epoch=607
06/01/2022 03:16:14 - INFO - __main__ - Step 2440 Global step 2440 Train loss 1.44 on epoch=609
06/01/2022 03:16:15 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.48 on epoch=612
06/01/2022 03:16:16 - INFO - __main__ - Global step 2450 Train loss 1.48 Classification-F1 0.15054945054945054 on epoch=612
06/01/2022 03:16:17 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.29 on epoch=614
06/01/2022 03:16:18 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.40 on epoch=617
06/01/2022 03:16:19 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.36 on epoch=619
06/01/2022 03:16:21 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.38 on epoch=622
06/01/2022 03:16:22 - INFO - __main__ - Step 2500 Global step 2500 Train loss 1.38 on epoch=624
06/01/2022 03:16:22 - INFO - __main__ - Global step 2500 Train loss 1.36 Classification-F1 0.1468058968058968 on epoch=624
06/01/2022 03:16:24 - INFO - __main__ - Step 2510 Global step 2510 Train loss 1.31 on epoch=627
06/01/2022 03:16:25 - INFO - __main__ - Step 2520 Global step 2520 Train loss 1.33 on epoch=629
06/01/2022 03:16:26 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.37 on epoch=632
06/01/2022 03:16:28 - INFO - __main__ - Step 2540 Global step 2540 Train loss 1.27 on epoch=634
06/01/2022 03:16:29 - INFO - __main__ - Step 2550 Global step 2550 Train loss 1.29 on epoch=637
06/01/2022 03:16:29 - INFO - __main__ - Global step 2550 Train loss 1.31 Classification-F1 0.13034188034188032 on epoch=637
06/01/2022 03:16:31 - INFO - __main__ - Step 2560 Global step 2560 Train loss 1.21 on epoch=639
06/01/2022 03:16:32 - INFO - __main__ - Step 2570 Global step 2570 Train loss 1.41 on epoch=642
06/01/2022 03:16:33 - INFO - __main__ - Step 2580 Global step 2580 Train loss 1.35 on epoch=644
06/01/2022 03:16:34 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.18 on epoch=647
06/01/2022 03:16:36 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.27 on epoch=649
06/01/2022 03:16:36 - INFO - __main__ - Global step 2600 Train loss 1.28 Classification-F1 0.09090909090909091 on epoch=649
06/01/2022 03:16:37 - INFO - __main__ - Step 2610 Global step 2610 Train loss 1.26 on epoch=652
06/01/2022 03:16:39 - INFO - __main__ - Step 2620 Global step 2620 Train loss 1.22 on epoch=654
06/01/2022 03:16:40 - INFO - __main__ - Step 2630 Global step 2630 Train loss 1.43 on epoch=657
06/01/2022 03:16:41 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.35 on epoch=659
06/01/2022 03:16:42 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.32 on epoch=662
06/01/2022 03:16:43 - INFO - __main__ - Global step 2650 Train loss 1.31 Classification-F1 0.1743014200641319 on epoch=662
06/01/2022 03:16:44 - INFO - __main__ - Step 2660 Global step 2660 Train loss 1.35 on epoch=664
06/01/2022 03:16:45 - INFO - __main__ - Step 2670 Global step 2670 Train loss 1.32 on epoch=667
06/01/2022 03:16:47 - INFO - __main__ - Step 2680 Global step 2680 Train loss 1.36 on epoch=669
06/01/2022 03:16:48 - INFO - __main__ - Step 2690 Global step 2690 Train loss 1.49 on epoch=672
06/01/2022 03:16:49 - INFO - __main__ - Step 2700 Global step 2700 Train loss 1.23 on epoch=674
06/01/2022 03:16:50 - INFO - __main__ - Global step 2700 Train loss 1.35 Classification-F1 0.09615384615384615 on epoch=674
06/01/2022 03:16:51 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.27 on epoch=677
06/01/2022 03:16:52 - INFO - __main__ - Step 2720 Global step 2720 Train loss 1.22 on epoch=679
06/01/2022 03:16:53 - INFO - __main__ - Step 2730 Global step 2730 Train loss 1.36 on epoch=682
06/01/2022 03:16:55 - INFO - __main__ - Step 2740 Global step 2740 Train loss 1.33 on epoch=684
06/01/2022 03:16:56 - INFO - __main__ - Step 2750 Global step 2750 Train loss 1.24 on epoch=687
06/01/2022 03:16:56 - INFO - __main__ - Global step 2750 Train loss 1.28 Classification-F1 0.17142857142857143 on epoch=687
06/01/2022 03:16:58 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.23 on epoch=689
06/01/2022 03:16:59 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.38 on epoch=692
06/01/2022 03:17:00 - INFO - __main__ - Step 2780 Global step 2780 Train loss 1.20 on epoch=694
06/01/2022 03:17:01 - INFO - __main__ - Step 2790 Global step 2790 Train loss 1.26 on epoch=697
06/01/2022 03:17:03 - INFO - __main__ - Step 2800 Global step 2800 Train loss 1.19 on epoch=699
06/01/2022 03:17:03 - INFO - __main__ - Global step 2800 Train loss 1.25 Classification-F1 0.1468058968058968 on epoch=699
06/01/2022 03:17:04 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.28 on epoch=702
06/01/2022 03:17:06 - INFO - __main__ - Step 2820 Global step 2820 Train loss 1.13 on epoch=704
06/01/2022 03:17:07 - INFO - __main__ - Step 2830 Global step 2830 Train loss 1.25 on epoch=707
06/01/2022 03:17:08 - INFO - __main__ - Step 2840 Global step 2840 Train loss 1.28 on epoch=709
06/01/2022 03:17:09 - INFO - __main__ - Step 2850 Global step 2850 Train loss 1.28 on epoch=712
06/01/2022 03:17:10 - INFO - __main__ - Global step 2850 Train loss 1.24 Classification-F1 0.14742690058479532 on epoch=712
06/01/2022 03:17:11 - INFO - __main__ - Step 2860 Global step 2860 Train loss 1.26 on epoch=714
06/01/2022 03:17:12 - INFO - __main__ - Step 2870 Global step 2870 Train loss 1.10 on epoch=717
06/01/2022 03:17:14 - INFO - __main__ - Step 2880 Global step 2880 Train loss 1.11 on epoch=719
06/01/2022 03:17:15 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.21 on epoch=722
06/01/2022 03:17:16 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.20 on epoch=724
06/01/2022 03:17:17 - INFO - __main__ - Global step 2900 Train loss 1.17 Classification-F1 0.2207516339869281 on epoch=724
06/01/2022 03:17:17 - INFO - __main__ - Saving model with best Classification-F1: 0.1767857142857143 -> 0.2207516339869281 on epoch=724, global_step=2900
06/01/2022 03:17:18 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.24 on epoch=727
06/01/2022 03:17:19 - INFO - __main__ - Step 2920 Global step 2920 Train loss 1.15 on epoch=729
06/01/2022 03:17:20 - INFO - __main__ - Step 2930 Global step 2930 Train loss 1.34 on epoch=732
06/01/2022 03:17:22 - INFO - __main__ - Step 2940 Global step 2940 Train loss 1.18 on epoch=734
06/01/2022 03:17:23 - INFO - __main__ - Step 2950 Global step 2950 Train loss 1.39 on epoch=737
06/01/2022 03:17:23 - INFO - __main__ - Global step 2950 Train loss 1.26 Classification-F1 0.16691176470588237 on epoch=737
06/01/2022 03:17:25 - INFO - __main__ - Step 2960 Global step 2960 Train loss 1.29 on epoch=739
06/01/2022 03:17:26 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.11 on epoch=742
06/01/2022 03:17:27 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.14 on epoch=744
06/01/2022 03:17:28 - INFO - __main__ - Step 2990 Global step 2990 Train loss 1.27 on epoch=747
06/01/2022 03:17:30 - INFO - __main__ - Step 3000 Global step 3000 Train loss 1.19 on epoch=749
06/01/2022 03:17:30 - INFO - __main__ - Global step 3000 Train loss 1.20 Classification-F1 0.16883484162895923 on epoch=749
06/01/2022 03:17:30 - INFO - __main__ - save last model!
06/01/2022 03:17:30 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/01/2022 03:17:30 - INFO - __main__ - Start tokenizing ... 5509 instances
06/01/2022 03:17:30 - INFO - __main__ - Printing 3 examples
06/01/2022 03:17:30 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/01/2022 03:17:30 - INFO - __main__ - ['others']
06/01/2022 03:17:30 - INFO - __main__ -  [emo] what you like very little things ok
06/01/2022 03:17:30 - INFO - __main__ - ['others']
06/01/2022 03:17:30 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/01/2022 03:17:30 - INFO - __main__ - ['others']
06/01/2022 03:17:30 - INFO - __main__ - Tokenizing Input ...
06/01/2022 03:17:31 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 03:17:31 - INFO - __main__ - Printing 3 examples
06/01/2022 03:17:31 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/01/2022 03:17:31 - INFO - __main__ - ['sad']
06/01/2022 03:17:31 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/01/2022 03:17:31 - INFO - __main__ - ['sad']
06/01/2022 03:17:31 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/01/2022 03:17:31 - INFO - __main__ - ['sad']
06/01/2022 03:17:31 - INFO - __main__ - Tokenizing Input ...
06/01/2022 03:17:31 - INFO - __main__ - Tokenizing Output ...
06/01/2022 03:17:31 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 03:17:31 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 03:17:31 - INFO - __main__ - Printing 3 examples
06/01/2022 03:17:31 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
06/01/2022 03:17:31 - INFO - __main__ - ['sad']
06/01/2022 03:17:31 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
06/01/2022 03:17:31 - INFO - __main__ - ['sad']
06/01/2022 03:17:31 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
06/01/2022 03:17:31 - INFO - __main__ - ['sad']
06/01/2022 03:17:31 - INFO - __main__ - Tokenizing Input ...
06/01/2022 03:17:31 - INFO - __main__ - Tokenizing Output ...
06/01/2022 03:17:31 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 03:17:32 - INFO - __main__ - Tokenizing Output ...
06/01/2022 03:17:37 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 03:17:37 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/01/2022 03:17:37 - INFO - __main__ - Starting training!
06/01/2022 03:17:38 - INFO - __main__ - Loaded 5509 examples from test data
06/01/2022 03:18:21 - INFO - __main__ - Saved prediction in models/T5-base-reptile-cls2cls-3e-5-2-5000-5e-1-10/singletask-emo/emo_16_13_0.2_8_predictions.txt
06/01/2022 03:18:21 - INFO - __main__ - Classification-F1 on test data: 0.0442
06/01/2022 03:18:22 - INFO - __main__ - prefix=emo_16_13, lr=0.2, bsz=8, dev_performance=0.2207516339869281, test_performance=0.0441566212691054
06/01/2022 03:18:22 - INFO - __main__ - Running ... prefix=emo_16_21, lr=0.5, bsz=8 ...
06/01/2022 03:18:22 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 03:18:22 - INFO - __main__ - Printing 3 examples
06/01/2022 03:18:22 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/01/2022 03:18:22 - INFO - __main__ - ['sad']
06/01/2022 03:18:22 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/01/2022 03:18:22 - INFO - __main__ - ['sad']
06/01/2022 03:18:22 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/01/2022 03:18:22 - INFO - __main__ - ['sad']
06/01/2022 03:18:22 - INFO - __main__ - Tokenizing Input ...
06/01/2022 03:18:22 - INFO - __main__ - Tokenizing Output ...
06/01/2022 03:18:23 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 03:18:23 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 03:18:23 - INFO - __main__ - Printing 3 examples
06/01/2022 03:18:23 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
06/01/2022 03:18:23 - INFO - __main__ - ['sad']
06/01/2022 03:18:23 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
06/01/2022 03:18:23 - INFO - __main__ - ['sad']
06/01/2022 03:18:23 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
06/01/2022 03:18:23 - INFO - __main__ - ['sad']
06/01/2022 03:18:23 - INFO - __main__ - Tokenizing Input ...
06/01/2022 03:18:23 - INFO - __main__ - Tokenizing Output ...
06/01/2022 03:18:23 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 03:18:28 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 03:18:29 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/01/2022 03:18:29 - INFO - __main__ - Starting training!
06/01/2022 03:18:30 - INFO - __main__ - Step 10 Global step 10 Train loss 8.73 on epoch=2
06/01/2022 03:18:31 - INFO - __main__ - Step 20 Global step 20 Train loss 8.70 on epoch=4
06/01/2022 03:18:32 - INFO - __main__ - Step 30 Global step 30 Train loss 8.64 on epoch=7
06/01/2022 03:18:34 - INFO - __main__ - Step 40 Global step 40 Train loss 8.60 on epoch=9
06/01/2022 03:18:35 - INFO - __main__ - Step 50 Global step 50 Train loss 8.61 on epoch=12
06/01/2022 03:18:40 - INFO - __main__ - Global step 50 Train loss 8.65 Classification-F1 0.0 on epoch=12
06/01/2022 03:18:40 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
06/01/2022 03:18:42 - INFO - __main__ - Step 60 Global step 60 Train loss 8.55 on epoch=14
06/01/2022 03:18:43 - INFO - __main__ - Step 70 Global step 70 Train loss 8.34 on epoch=17
06/01/2022 03:18:44 - INFO - __main__ - Step 80 Global step 80 Train loss 8.33 on epoch=19
06/01/2022 03:18:46 - INFO - __main__ - Step 90 Global step 90 Train loss 8.27 on epoch=22
06/01/2022 03:18:47 - INFO - __main__ - Step 100 Global step 100 Train loss 8.10 on epoch=24
06/01/2022 03:19:02 - INFO - __main__ - Global step 100 Train loss 8.32 Classification-F1 0.0 on epoch=24
06/01/2022 03:19:04 - INFO - __main__ - Step 110 Global step 110 Train loss 7.92 on epoch=27
06/01/2022 03:19:05 - INFO - __main__ - Step 120 Global step 120 Train loss 7.76 on epoch=29
06/01/2022 03:19:06 - INFO - __main__ - Step 130 Global step 130 Train loss 7.73 on epoch=32
06/01/2022 03:19:07 - INFO - __main__ - Step 140 Global step 140 Train loss 7.58 on epoch=34
06/01/2022 03:19:09 - INFO - __main__ - Step 150 Global step 150 Train loss 7.51 on epoch=37
06/01/2022 03:19:23 - INFO - __main__ - Global step 150 Train loss 7.70 Classification-F1 0.0 on epoch=37
06/01/2022 03:19:24 - INFO - __main__ - Step 160 Global step 160 Train loss 7.31 on epoch=39
06/01/2022 03:19:25 - INFO - __main__ - Step 170 Global step 170 Train loss 7.38 on epoch=42
06/01/2022 03:19:27 - INFO - __main__ - Step 180 Global step 180 Train loss 7.37 on epoch=44
06/01/2022 03:19:28 - INFO - __main__ - Step 190 Global step 190 Train loss 7.24 on epoch=47
06/01/2022 03:19:29 - INFO - __main__ - Step 200 Global step 200 Train loss 7.18 on epoch=49
06/01/2022 03:19:37 - INFO - __main__ - Global step 200 Train loss 7.30 Classification-F1 0.0 on epoch=49
06/01/2022 03:19:39 - INFO - __main__ - Step 210 Global step 210 Train loss 7.15 on epoch=52
06/01/2022 03:19:40 - INFO - __main__ - Step 220 Global step 220 Train loss 6.86 on epoch=54
06/01/2022 03:19:41 - INFO - __main__ - Step 230 Global step 230 Train loss 6.98 on epoch=57
06/01/2022 03:19:42 - INFO - __main__ - Step 240 Global step 240 Train loss 6.73 on epoch=59
06/01/2022 03:19:44 - INFO - __main__ - Step 250 Global step 250 Train loss 6.86 on epoch=62
06/01/2022 03:19:48 - INFO - __main__ - Global step 250 Train loss 6.92 Classification-F1 0.0 on epoch=62
06/01/2022 03:19:49 - INFO - __main__ - Step 260 Global step 260 Train loss 6.53 on epoch=64
06/01/2022 03:19:50 - INFO - __main__ - Step 270 Global step 270 Train loss 6.44 on epoch=67
06/01/2022 03:19:52 - INFO - __main__ - Step 280 Global step 280 Train loss 5.89 on epoch=69
06/01/2022 03:19:53 - INFO - __main__ - Step 290 Global step 290 Train loss 6.02 on epoch=72
06/01/2022 03:19:54 - INFO - __main__ - Step 300 Global step 300 Train loss 5.75 on epoch=74
06/01/2022 03:19:59 - INFO - __main__ - Global step 300 Train loss 6.13 Classification-F1 0.0 on epoch=74
06/01/2022 03:20:00 - INFO - __main__ - Step 310 Global step 310 Train loss 5.72 on epoch=77
06/01/2022 03:20:02 - INFO - __main__ - Step 320 Global step 320 Train loss 5.69 on epoch=79
06/01/2022 03:20:03 - INFO - __main__ - Step 330 Global step 330 Train loss 5.57 on epoch=82
06/01/2022 03:20:04 - INFO - __main__ - Step 340 Global step 340 Train loss 5.24 on epoch=84
06/01/2022 03:20:05 - INFO - __main__ - Step 350 Global step 350 Train loss 5.44 on epoch=87
06/01/2022 03:20:09 - INFO - __main__ - Global step 350 Train loss 5.53 Classification-F1 0.0 on epoch=87
06/01/2022 03:20:10 - INFO - __main__ - Step 360 Global step 360 Train loss 5.12 on epoch=89
06/01/2022 03:20:11 - INFO - __main__ - Step 370 Global step 370 Train loss 5.35 on epoch=92
06/01/2022 03:20:13 - INFO - __main__ - Step 380 Global step 380 Train loss 5.11 on epoch=94
06/01/2022 03:20:14 - INFO - __main__ - Step 390 Global step 390 Train loss 5.10 on epoch=97
06/01/2022 03:20:15 - INFO - __main__ - Step 400 Global step 400 Train loss 4.84 on epoch=99
06/01/2022 03:20:19 - INFO - __main__ - Global step 400 Train loss 5.10 Classification-F1 0.0 on epoch=99
06/01/2022 03:20:20 - INFO - __main__ - Step 410 Global step 410 Train loss 4.77 on epoch=102
06/01/2022 03:20:21 - INFO - __main__ - Step 420 Global step 420 Train loss 4.55 on epoch=104
06/01/2022 03:20:23 - INFO - __main__ - Step 430 Global step 430 Train loss 4.64 on epoch=107
06/01/2022 03:20:24 - INFO - __main__ - Step 440 Global step 440 Train loss 4.38 on epoch=109
06/01/2022 03:20:25 - INFO - __main__ - Step 450 Global step 450 Train loss 4.36 on epoch=112
06/01/2022 03:20:29 - INFO - __main__ - Global step 450 Train loss 4.54 Classification-F1 0.0 on epoch=112
06/01/2022 03:20:30 - INFO - __main__ - Step 460 Global step 460 Train loss 4.12 on epoch=114
06/01/2022 03:20:31 - INFO - __main__ - Step 470 Global step 470 Train loss 4.25 on epoch=117
06/01/2022 03:20:32 - INFO - __main__ - Step 480 Global step 480 Train loss 4.02 on epoch=119
06/01/2022 03:20:34 - INFO - __main__ - Step 490 Global step 490 Train loss 4.16 on epoch=122
06/01/2022 03:20:35 - INFO - __main__ - Step 500 Global step 500 Train loss 3.82 on epoch=124
06/01/2022 03:20:38 - INFO - __main__ - Global step 500 Train loss 4.07 Classification-F1 0.07999999999999999 on epoch=124
06/01/2022 03:20:38 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.07999999999999999 on epoch=124, global_step=500
06/01/2022 03:20:39 - INFO - __main__ - Step 510 Global step 510 Train loss 3.90 on epoch=127
06/01/2022 03:20:40 - INFO - __main__ - Step 520 Global step 520 Train loss 3.85 on epoch=129
06/01/2022 03:20:41 - INFO - __main__ - Step 530 Global step 530 Train loss 3.95 on epoch=132
06/01/2022 03:20:43 - INFO - __main__ - Step 540 Global step 540 Train loss 3.66 on epoch=134
06/01/2022 03:20:44 - INFO - __main__ - Step 550 Global step 550 Train loss 3.58 on epoch=137
06/01/2022 03:20:45 - INFO - __main__ - Global step 550 Train loss 3.79 Classification-F1 0.12447885646217988 on epoch=137
06/01/2022 03:20:45 - INFO - __main__ - Saving model with best Classification-F1: 0.07999999999999999 -> 0.12447885646217988 on epoch=137, global_step=550
06/01/2022 03:20:46 - INFO - __main__ - Step 560 Global step 560 Train loss 3.34 on epoch=139
06/01/2022 03:20:48 - INFO - __main__ - Step 570 Global step 570 Train loss 3.51 on epoch=142
06/01/2022 03:20:49 - INFO - __main__ - Step 580 Global step 580 Train loss 3.22 on epoch=144
06/01/2022 03:20:50 - INFO - __main__ - Step 590 Global step 590 Train loss 3.42 on epoch=147
06/01/2022 03:20:52 - INFO - __main__ - Step 600 Global step 600 Train loss 3.16 on epoch=149
06/01/2022 03:20:53 - INFO - __main__ - Global step 600 Train loss 3.33 Classification-F1 0.09090909090909091 on epoch=149
06/01/2022 03:20:54 - INFO - __main__ - Step 610 Global step 610 Train loss 3.28 on epoch=152
06/01/2022 03:20:56 - INFO - __main__ - Step 620 Global step 620 Train loss 2.91 on epoch=154
06/01/2022 03:20:57 - INFO - __main__ - Step 630 Global step 630 Train loss 2.90 on epoch=157
06/01/2022 03:20:58 - INFO - __main__ - Step 640 Global step 640 Train loss 2.81 on epoch=159
06/01/2022 03:21:00 - INFO - __main__ - Step 650 Global step 650 Train loss 2.68 on epoch=162
06/01/2022 03:21:00 - INFO - __main__ - Global step 650 Train loss 2.92 Classification-F1 0.12447885646217988 on epoch=162
06/01/2022 03:21:01 - INFO - __main__ - Step 660 Global step 660 Train loss 2.58 on epoch=164
06/01/2022 03:21:03 - INFO - __main__ - Step 670 Global step 670 Train loss 2.56 on epoch=167
06/01/2022 03:21:04 - INFO - __main__ - Step 680 Global step 680 Train loss 2.25 on epoch=169
06/01/2022 03:21:05 - INFO - __main__ - Step 690 Global step 690 Train loss 2.59 on epoch=172
06/01/2022 03:21:06 - INFO - __main__ - Step 700 Global step 700 Train loss 2.39 on epoch=174
06/01/2022 03:21:07 - INFO - __main__ - Global step 700 Train loss 2.47 Classification-F1 0.15550351288056208 on epoch=174
06/01/2022 03:21:07 - INFO - __main__ - Saving model with best Classification-F1: 0.12447885646217988 -> 0.15550351288056208 on epoch=174, global_step=700
06/01/2022 03:21:08 - INFO - __main__ - Step 710 Global step 710 Train loss 2.34 on epoch=177
06/01/2022 03:21:09 - INFO - __main__ - Step 720 Global step 720 Train loss 2.24 on epoch=179
06/01/2022 03:21:11 - INFO - __main__ - Step 730 Global step 730 Train loss 2.05 on epoch=182
06/01/2022 03:21:12 - INFO - __main__ - Step 740 Global step 740 Train loss 2.12 on epoch=184
06/01/2022 03:21:13 - INFO - __main__ - Step 750 Global step 750 Train loss 1.85 on epoch=187
06/01/2022 03:21:14 - INFO - __main__ - Global step 750 Train loss 2.12 Classification-F1 0.1 on epoch=187
06/01/2022 03:21:15 - INFO - __main__ - Step 760 Global step 760 Train loss 1.76 on epoch=189
06/01/2022 03:21:17 - INFO - __main__ - Step 770 Global step 770 Train loss 1.86 on epoch=192
06/01/2022 03:21:18 - INFO - __main__ - Step 780 Global step 780 Train loss 1.52 on epoch=194
06/01/2022 03:21:19 - INFO - __main__ - Step 790 Global step 790 Train loss 1.57 on epoch=197
06/01/2022 03:21:21 - INFO - __main__ - Step 800 Global step 800 Train loss 1.46 on epoch=199
06/01/2022 03:21:21 - INFO - __main__ - Global step 800 Train loss 1.63 Classification-F1 0.18859649122807015 on epoch=199
06/01/2022 03:21:21 - INFO - __main__ - Saving model with best Classification-F1: 0.15550351288056208 -> 0.18859649122807015 on epoch=199, global_step=800
06/01/2022 03:21:23 - INFO - __main__ - Step 810 Global step 810 Train loss 1.65 on epoch=202
06/01/2022 03:21:24 - INFO - __main__ - Step 820 Global step 820 Train loss 1.47 on epoch=204
06/01/2022 03:21:25 - INFO - __main__ - Step 830 Global step 830 Train loss 1.52 on epoch=207
06/01/2022 03:21:26 - INFO - __main__ - Step 840 Global step 840 Train loss 1.66 on epoch=209
06/01/2022 03:21:28 - INFO - __main__ - Step 850 Global step 850 Train loss 1.48 on epoch=212
06/01/2022 03:21:28 - INFO - __main__ - Global step 850 Train loss 1.55 Classification-F1 0.20869565217391306 on epoch=212
06/01/2022 03:21:28 - INFO - __main__ - Saving model with best Classification-F1: 0.18859649122807015 -> 0.20869565217391306 on epoch=212, global_step=850
06/01/2022 03:21:30 - INFO - __main__ - Step 860 Global step 860 Train loss 1.35 on epoch=214
06/01/2022 03:21:31 - INFO - __main__ - Step 870 Global step 870 Train loss 1.41 on epoch=217
06/01/2022 03:21:32 - INFO - __main__ - Step 880 Global step 880 Train loss 1.41 on epoch=219
06/01/2022 03:21:34 - INFO - __main__ - Step 890 Global step 890 Train loss 1.47 on epoch=222
06/01/2022 03:21:35 - INFO - __main__ - Step 900 Global step 900 Train loss 1.45 on epoch=224
06/01/2022 03:21:35 - INFO - __main__ - Global step 900 Train loss 1.42 Classification-F1 0.14621798689696247 on epoch=224
06/01/2022 03:21:37 - INFO - __main__ - Step 910 Global step 910 Train loss 1.47 on epoch=227
06/01/2022 03:21:38 - INFO - __main__ - Step 920 Global step 920 Train loss 1.23 on epoch=229
06/01/2022 03:21:39 - INFO - __main__ - Step 930 Global step 930 Train loss 1.40 on epoch=232
06/01/2022 03:21:41 - INFO - __main__ - Step 940 Global step 940 Train loss 1.17 on epoch=234
06/01/2022 03:21:42 - INFO - __main__ - Step 950 Global step 950 Train loss 1.24 on epoch=237
06/01/2022 03:21:42 - INFO - __main__ - Global step 950 Train loss 1.30 Classification-F1 0.1 on epoch=237
06/01/2022 03:21:44 - INFO - __main__ - Step 960 Global step 960 Train loss 1.37 on epoch=239
06/01/2022 03:21:45 - INFO - __main__ - Step 970 Global step 970 Train loss 1.33 on epoch=242
06/01/2022 03:21:46 - INFO - __main__ - Step 980 Global step 980 Train loss 1.36 on epoch=244
06/01/2022 03:21:47 - INFO - __main__ - Step 990 Global step 990 Train loss 1.23 on epoch=247
06/01/2022 03:21:49 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.21 on epoch=249
06/01/2022 03:21:49 - INFO - __main__ - Global step 1000 Train loss 1.30 Classification-F1 0.10126582278481013 on epoch=249
06/01/2022 03:21:51 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.21 on epoch=252
06/01/2022 03:21:52 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.28 on epoch=254
06/01/2022 03:21:53 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.17 on epoch=257
06/01/2022 03:21:54 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.32 on epoch=259
06/01/2022 03:21:56 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.24 on epoch=262
06/01/2022 03:21:56 - INFO - __main__ - Global step 1050 Train loss 1.24 Classification-F1 0.13067758749069247 on epoch=262
06/01/2022 03:21:58 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.20 on epoch=264
06/01/2022 03:21:59 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.21 on epoch=267
06/01/2022 03:22:00 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.19 on epoch=269
06/01/2022 03:22:01 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.22 on epoch=272
06/01/2022 03:22:03 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.17 on epoch=274
06/01/2022 03:22:03 - INFO - __main__ - Global step 1100 Train loss 1.20 Classification-F1 0.18955682316805617 on epoch=274
06/01/2022 03:22:05 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.20 on epoch=277
06/01/2022 03:22:06 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.20 on epoch=279
06/01/2022 03:22:07 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.09 on epoch=282
06/01/2022 03:22:08 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.11 on epoch=284
06/01/2022 03:22:10 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.22 on epoch=287
06/01/2022 03:22:11 - INFO - __main__ - Global step 1150 Train loss 1.17 Classification-F1 0.1 on epoch=287
06/01/2022 03:22:12 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.19 on epoch=289
06/01/2022 03:22:13 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.20 on epoch=292
06/01/2022 03:22:14 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.16 on epoch=294
06/01/2022 03:22:16 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.15 on epoch=297
06/01/2022 03:22:17 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.12 on epoch=299
06/01/2022 03:22:18 - INFO - __main__ - Global step 1200 Train loss 1.16 Classification-F1 0.14350945857795172 on epoch=299
06/01/2022 03:22:19 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.13 on epoch=302
06/01/2022 03:22:20 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.08 on epoch=304
06/01/2022 03:22:21 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.25 on epoch=307
06/01/2022 03:22:23 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.18 on epoch=309
06/01/2022 03:22:24 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.20 on epoch=312
06/01/2022 03:22:24 - INFO - __main__ - Global step 1250 Train loss 1.17 Classification-F1 0.1 on epoch=312
06/01/2022 03:22:26 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.09 on epoch=314
06/01/2022 03:22:27 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.06 on epoch=317
06/01/2022 03:22:28 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.14 on epoch=319
06/01/2022 03:22:30 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.20 on epoch=322
06/01/2022 03:22:31 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.07 on epoch=324
06/01/2022 03:22:31 - INFO - __main__ - Global step 1300 Train loss 1.11 Classification-F1 0.1 on epoch=324
06/01/2022 03:22:33 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.00 on epoch=327
06/01/2022 03:22:34 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.09 on epoch=329
06/01/2022 03:22:35 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.23 on epoch=332
06/01/2022 03:22:37 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.13 on epoch=334
06/01/2022 03:22:38 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.07 on epoch=337
06/01/2022 03:22:38 - INFO - __main__ - Global step 1350 Train loss 1.11 Classification-F1 0.1 on epoch=337
06/01/2022 03:22:40 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.13 on epoch=339
06/01/2022 03:22:41 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.02 on epoch=342
06/01/2022 03:22:42 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.15 on epoch=344
06/01/2022 03:22:43 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.09 on epoch=347
06/01/2022 03:22:45 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.02 on epoch=349
06/01/2022 03:22:45 - INFO - __main__ - Global step 1400 Train loss 1.08 Classification-F1 0.11923076923076922 on epoch=349
06/01/2022 03:22:47 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.96 on epoch=352
06/01/2022 03:22:48 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.07 on epoch=354
06/01/2022 03:22:49 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.12 on epoch=357
06/01/2022 03:22:50 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.18 on epoch=359
06/01/2022 03:22:52 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.08 on epoch=362
06/01/2022 03:22:52 - INFO - __main__ - Global step 1450 Train loss 1.08 Classification-F1 0.1 on epoch=362
06/01/2022 03:22:54 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.03 on epoch=364
06/01/2022 03:22:55 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.07 on epoch=367
06/01/2022 03:22:56 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.99 on epoch=369
06/01/2022 03:22:57 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.11 on epoch=372
06/01/2022 03:22:59 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.08 on epoch=374
06/01/2022 03:22:59 - INFO - __main__ - Global step 1500 Train loss 1.06 Classification-F1 0.1529790660225443 on epoch=374
06/01/2022 03:23:01 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.00 on epoch=377
06/01/2022 03:23:02 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.00 on epoch=379
06/01/2022 03:23:03 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.09 on epoch=382
06/01/2022 03:23:04 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.04 on epoch=384
06/01/2022 03:23:06 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.04 on epoch=387
06/01/2022 03:23:06 - INFO - __main__ - Global step 1550 Train loss 1.04 Classification-F1 0.1 on epoch=387
06/01/2022 03:23:08 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.08 on epoch=389
06/01/2022 03:23:09 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.04 on epoch=392
06/01/2022 03:23:10 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.98 on epoch=394
06/01/2022 03:23:11 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.00 on epoch=397
06/01/2022 03:23:13 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.02 on epoch=399
06/01/2022 03:23:13 - INFO - __main__ - Global step 1600 Train loss 1.02 Classification-F1 0.1 on epoch=399
06/01/2022 03:23:15 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.08 on epoch=402
06/01/2022 03:23:16 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.97 on epoch=404
06/01/2022 03:23:17 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.98 on epoch=407
06/01/2022 03:23:18 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.04 on epoch=409
06/01/2022 03:23:20 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.08 on epoch=412
06/01/2022 03:23:20 - INFO - __main__ - Global step 1650 Train loss 1.03 Classification-F1 0.1 on epoch=412
06/01/2022 03:23:22 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.04 on epoch=414
06/01/2022 03:23:23 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.06 on epoch=417
06/01/2022 03:23:24 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.09 on epoch=419
06/01/2022 03:23:25 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.94 on epoch=422
06/01/2022 03:23:27 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.98 on epoch=424
06/01/2022 03:23:27 - INFO - __main__ - Global step 1700 Train loss 1.02 Classification-F1 0.170995670995671 on epoch=424
06/01/2022 03:23:29 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.03 on epoch=427
06/01/2022 03:23:30 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.95 on epoch=429
06/01/2022 03:23:31 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.98 on epoch=432
06/01/2022 03:23:32 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.89 on epoch=434
06/01/2022 03:23:34 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.96 on epoch=437
06/01/2022 03:23:34 - INFO - __main__ - Global step 1750 Train loss 0.96 Classification-F1 0.1 on epoch=437
06/01/2022 03:23:36 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.06 on epoch=439
06/01/2022 03:23:37 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.08 on epoch=442
06/01/2022 03:23:38 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.96 on epoch=444
06/01/2022 03:23:39 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.96 on epoch=447
06/01/2022 03:23:41 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.04 on epoch=449
06/01/2022 03:23:41 - INFO - __main__ - Global step 1800 Train loss 1.02 Classification-F1 0.11208791208791208 on epoch=449
06/01/2022 03:23:43 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.90 on epoch=452
06/01/2022 03:23:44 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.00 on epoch=454
06/01/2022 03:23:45 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.06 on epoch=457
06/01/2022 03:23:46 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.03 on epoch=459
06/01/2022 03:23:48 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.05 on epoch=462
06/01/2022 03:23:48 - INFO - __main__ - Global step 1850 Train loss 1.01 Classification-F1 0.1458966565349544 on epoch=462
06/01/2022 03:23:49 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.02 on epoch=464
06/01/2022 03:23:51 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.95 on epoch=467
06/01/2022 03:23:52 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.89 on epoch=469
06/01/2022 03:23:53 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.94 on epoch=472
06/01/2022 03:23:55 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.28 on epoch=474
06/01/2022 03:23:55 - INFO - __main__ - Global step 1900 Train loss 1.02 Classification-F1 0.10256410256410256 on epoch=474
06/01/2022 03:23:56 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.17 on epoch=477
06/01/2022 03:23:58 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.97 on epoch=479
06/01/2022 03:23:59 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.05 on epoch=482
06/01/2022 03:24:00 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.98 on epoch=484
06/01/2022 03:24:02 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.95 on epoch=487
06/01/2022 03:24:02 - INFO - __main__ - Global step 1950 Train loss 1.02 Classification-F1 0.1 on epoch=487
06/01/2022 03:24:03 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.05 on epoch=489
06/01/2022 03:24:05 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.29 on epoch=492
06/01/2022 03:24:06 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.24 on epoch=494
06/01/2022 03:24:07 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.15 on epoch=497
06/01/2022 03:24:09 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.10 on epoch=499
06/01/2022 03:24:09 - INFO - __main__ - Global step 2000 Train loss 1.17 Classification-F1 0.2563372941421722 on epoch=499
06/01/2022 03:24:09 - INFO - __main__ - Saving model with best Classification-F1: 0.20869565217391306 -> 0.2563372941421722 on epoch=499, global_step=2000
06/01/2022 03:24:11 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.05 on epoch=502
06/01/2022 03:24:12 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.03 on epoch=504
06/01/2022 03:24:13 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.04 on epoch=507
06/01/2022 03:24:14 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.03 on epoch=509
06/01/2022 03:24:16 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.01 on epoch=512
06/01/2022 03:24:16 - INFO - __main__ - Global step 2050 Train loss 1.03 Classification-F1 0.1 on epoch=512
06/01/2022 03:24:18 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.11 on epoch=514
06/01/2022 03:24:19 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.09 on epoch=517
06/01/2022 03:24:20 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.96 on epoch=519
06/01/2022 03:24:22 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.08 on epoch=522
06/01/2022 03:24:23 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.98 on epoch=524
06/01/2022 03:24:23 - INFO - __main__ - Global step 2100 Train loss 1.04 Classification-F1 0.12407862407862408 on epoch=524
06/01/2022 03:24:25 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.95 on epoch=527
06/01/2022 03:24:26 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.04 on epoch=529
06/01/2022 03:24:27 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.99 on epoch=532
06/01/2022 03:24:29 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.91 on epoch=534
06/01/2022 03:24:30 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.03 on epoch=537
06/01/2022 03:24:30 - INFO - __main__ - Global step 2150 Train loss 0.98 Classification-F1 0.1 on epoch=537
06/01/2022 03:24:32 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.02 on epoch=539
06/01/2022 03:24:33 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.98 on epoch=542
06/01/2022 03:24:34 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.00 on epoch=544
06/01/2022 03:24:36 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.13 on epoch=547
06/01/2022 03:24:37 - INFO - __main__ - Step 2200 Global step 2200 Train loss 1.10 on epoch=549
06/01/2022 03:24:37 - INFO - __main__ - Global step 2200 Train loss 1.05 Classification-F1 0.1 on epoch=549
06/01/2022 03:24:39 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.13 on epoch=552
06/01/2022 03:24:40 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.01 on epoch=554
06/01/2022 03:24:41 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.04 on epoch=557
06/01/2022 03:24:43 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.95 on epoch=559
06/01/2022 03:24:44 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.95 on epoch=562
06/01/2022 03:24:44 - INFO - __main__ - Global step 2250 Train loss 1.01 Classification-F1 0.10256410256410256 on epoch=562
06/01/2022 03:24:46 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.99 on epoch=564
06/01/2022 03:24:47 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.00 on epoch=567
06/01/2022 03:24:48 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.03 on epoch=569
06/01/2022 03:24:50 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.01 on epoch=572
06/01/2022 03:24:51 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.93 on epoch=574
06/01/2022 03:24:51 - INFO - __main__ - Global step 2300 Train loss 0.99 Classification-F1 0.1095890410958904 on epoch=574
06/01/2022 03:24:53 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.96 on epoch=577
06/01/2022 03:24:54 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.94 on epoch=579
06/01/2022 03:24:55 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.97 on epoch=582
06/01/2022 03:24:57 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.99 on epoch=584
06/01/2022 03:24:58 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.90 on epoch=587
06/01/2022 03:24:58 - INFO - __main__ - Global step 2350 Train loss 0.95 Classification-F1 0.1565126050420168 on epoch=587
06/01/2022 03:25:00 - INFO - __main__ - Step 2360 Global step 2360 Train loss 1.07 on epoch=589
06/01/2022 03:25:01 - INFO - __main__ - Step 2370 Global step 2370 Train loss 1.00 on epoch=592
06/01/2022 03:25:02 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.96 on epoch=594
06/01/2022 03:25:04 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.99 on epoch=597
06/01/2022 03:25:05 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.99 on epoch=599
06/01/2022 03:25:05 - INFO - __main__ - Global step 2400 Train loss 1.00 Classification-F1 0.13275613275613274 on epoch=599
06/01/2022 03:25:07 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.07 on epoch=602
06/01/2022 03:25:08 - INFO - __main__ - Step 2420 Global step 2420 Train loss 1.04 on epoch=604
06/01/2022 03:25:09 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.89 on epoch=607
06/01/2022 03:25:11 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.98 on epoch=609
06/01/2022 03:25:12 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.87 on epoch=612
06/01/2022 03:25:12 - INFO - __main__ - Global step 2450 Train loss 0.97 Classification-F1 0.09090909090909091 on epoch=612
06/01/2022 03:25:14 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.88 on epoch=614
06/01/2022 03:25:15 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.97 on epoch=617
06/01/2022 03:25:16 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.88 on epoch=619
06/01/2022 03:25:18 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.00 on epoch=622
06/01/2022 03:25:19 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.99 on epoch=624
06/01/2022 03:25:19 - INFO - __main__ - Global step 2500 Train loss 0.95 Classification-F1 0.09999999999999999 on epoch=624
06/01/2022 03:25:21 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.96 on epoch=627
06/01/2022 03:25:22 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.95 on epoch=629
06/01/2022 03:25:23 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.95 on epoch=632
06/01/2022 03:25:25 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.92 on epoch=634
06/01/2022 03:25:26 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.93 on epoch=637
06/01/2022 03:25:26 - INFO - __main__ - Global step 2550 Train loss 0.94 Classification-F1 0.11666666666666667 on epoch=637
06/01/2022 03:25:28 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.90 on epoch=639
06/01/2022 03:25:29 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.93 on epoch=642
06/01/2022 03:25:30 - INFO - __main__ - Step 2580 Global step 2580 Train loss 1.00 on epoch=644
06/01/2022 03:25:32 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.02 on epoch=647
06/01/2022 03:25:33 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.86 on epoch=649
06/01/2022 03:25:33 - INFO - __main__ - Global step 2600 Train loss 0.94 Classification-F1 0.11330409356725146 on epoch=649
06/01/2022 03:25:35 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.95 on epoch=652
06/01/2022 03:25:36 - INFO - __main__ - Step 2620 Global step 2620 Train loss 1.02 on epoch=654
06/01/2022 03:25:37 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.93 on epoch=657
06/01/2022 03:25:39 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.94 on epoch=659
06/01/2022 03:25:40 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.03 on epoch=662
06/01/2022 03:25:40 - INFO - __main__ - Global step 2650 Train loss 0.98 Classification-F1 0.1 on epoch=662
06/01/2022 03:25:42 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.90 on epoch=664
06/01/2022 03:25:43 - INFO - __main__ - Step 2670 Global step 2670 Train loss 1.04 on epoch=667
06/01/2022 03:25:44 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.99 on epoch=669
06/01/2022 03:25:46 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.89 on epoch=672
06/01/2022 03:25:47 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.98 on epoch=674
06/01/2022 03:25:47 - INFO - __main__ - Global step 2700 Train loss 0.96 Classification-F1 0.15897435897435896 on epoch=674
06/01/2022 03:25:49 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.92 on epoch=677
06/01/2022 03:25:50 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.99 on epoch=679
06/01/2022 03:25:51 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.94 on epoch=682
06/01/2022 03:25:53 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.88 on epoch=684
06/01/2022 03:25:54 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.94 on epoch=687
06/01/2022 03:25:54 - INFO - __main__ - Global step 2750 Train loss 0.93 Classification-F1 0.18679549114331723 on epoch=687
06/01/2022 03:25:56 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.88 on epoch=689
06/01/2022 03:25:57 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.97 on epoch=692
06/01/2022 03:25:58 - INFO - __main__ - Step 2780 Global step 2780 Train loss 1.10 on epoch=694
06/01/2022 03:26:00 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.97 on epoch=697
06/01/2022 03:26:01 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.89 on epoch=699
06/01/2022 03:26:02 - INFO - __main__ - Global step 2800 Train loss 0.96 Classification-F1 0.12407862407862408 on epoch=699
06/01/2022 03:26:03 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.90 on epoch=702
06/01/2022 03:26:04 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.86 on epoch=704
06/01/2022 03:26:05 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.89 on epoch=707
06/01/2022 03:26:07 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.97 on epoch=709
06/01/2022 03:26:08 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.86 on epoch=712
06/01/2022 03:26:09 - INFO - __main__ - Global step 2850 Train loss 0.90 Classification-F1 0.13130252100840337 on epoch=712
06/01/2022 03:26:10 - INFO - __main__ - Step 2860 Global step 2860 Train loss 1.00 on epoch=714
06/01/2022 03:26:11 - INFO - __main__ - Step 2870 Global step 2870 Train loss 1.00 on epoch=717
06/01/2022 03:26:12 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.99 on epoch=719
06/01/2022 03:26:14 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.97 on epoch=722
06/01/2022 03:26:15 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.88 on epoch=724
06/01/2022 03:26:16 - INFO - __main__ - Global step 2900 Train loss 0.97 Classification-F1 0.1238095238095238 on epoch=724
06/01/2022 03:26:17 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.90 on epoch=727
06/01/2022 03:26:18 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.95 on epoch=729
06/01/2022 03:26:20 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.96 on epoch=732
06/01/2022 03:26:21 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.89 on epoch=734
06/01/2022 03:26:22 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.99 on epoch=737
06/01/2022 03:26:23 - INFO - __main__ - Global step 2950 Train loss 0.94 Classification-F1 0.17573529411764705 on epoch=737
06/01/2022 03:26:24 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.94 on epoch=739
06/01/2022 03:26:25 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.97 on epoch=742
06/01/2022 03:26:27 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.94 on epoch=744
06/01/2022 03:26:28 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.95 on epoch=747
06/01/2022 03:26:29 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.90 on epoch=749
06/01/2022 03:26:30 - INFO - __main__ - Global step 3000 Train loss 0.94 Classification-F1 0.1 on epoch=749
06/01/2022 03:26:30 - INFO - __main__ - save last model!
06/01/2022 03:26:30 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/01/2022 03:26:30 - INFO - __main__ - Start tokenizing ... 5509 instances
06/01/2022 03:26:30 - INFO - __main__ - Printing 3 examples
06/01/2022 03:26:30 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/01/2022 03:26:30 - INFO - __main__ - ['others']
06/01/2022 03:26:30 - INFO - __main__ -  [emo] what you like very little things ok
06/01/2022 03:26:30 - INFO - __main__ - ['others']
06/01/2022 03:26:30 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/01/2022 03:26:30 - INFO - __main__ - ['others']
06/01/2022 03:26:30 - INFO - __main__ - Tokenizing Input ...
06/01/2022 03:26:30 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 03:26:30 - INFO - __main__ - Printing 3 examples
06/01/2022 03:26:30 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/01/2022 03:26:30 - INFO - __main__ - ['sad']
06/01/2022 03:26:30 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/01/2022 03:26:30 - INFO - __main__ - ['sad']
06/01/2022 03:26:30 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/01/2022 03:26:30 - INFO - __main__ - ['sad']
06/01/2022 03:26:30 - INFO - __main__ - Tokenizing Input ...
06/01/2022 03:26:30 - INFO - __main__ - Tokenizing Output ...
06/01/2022 03:26:30 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 03:26:30 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 03:26:30 - INFO - __main__ - Printing 3 examples
06/01/2022 03:26:30 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
06/01/2022 03:26:30 - INFO - __main__ - ['sad']
06/01/2022 03:26:30 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
06/01/2022 03:26:30 - INFO - __main__ - ['sad']
06/01/2022 03:26:30 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
06/01/2022 03:26:30 - INFO - __main__ - ['sad']
06/01/2022 03:26:30 - INFO - __main__ - Tokenizing Input ...
06/01/2022 03:26:30 - INFO - __main__ - Tokenizing Output ...
06/01/2022 03:26:31 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 03:26:32 - INFO - __main__ - Tokenizing Output ...
06/01/2022 03:26:36 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 03:26:36 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/01/2022 03:26:36 - INFO - __main__ - Starting training!
06/01/2022 03:26:37 - INFO - __main__ - Loaded 5509 examples from test data
06/01/2022 03:27:20 - INFO - __main__ - Saved prediction in models/T5-base-reptile-cls2cls-3e-5-2-5000-5e-1-10/singletask-emo/emo_16_21_0.5_8_predictions.txt
06/01/2022 03:27:20 - INFO - __main__ - Classification-F1 on test data: 0.0216
06/01/2022 03:27:21 - INFO - __main__ - prefix=emo_16_21, lr=0.5, bsz=8, dev_performance=0.2563372941421722, test_performance=0.021644645340751043
06/01/2022 03:27:21 - INFO - __main__ - Running ... prefix=emo_16_21, lr=0.4, bsz=8 ...
06/01/2022 03:27:22 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 03:27:22 - INFO - __main__ - Printing 3 examples
06/01/2022 03:27:22 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/01/2022 03:27:22 - INFO - __main__ - ['sad']
06/01/2022 03:27:22 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/01/2022 03:27:22 - INFO - __main__ - ['sad']
06/01/2022 03:27:22 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/01/2022 03:27:22 - INFO - __main__ - ['sad']
06/01/2022 03:27:22 - INFO - __main__ - Tokenizing Input ...
06/01/2022 03:27:22 - INFO - __main__ - Tokenizing Output ...
06/01/2022 03:27:22 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 03:27:22 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 03:27:22 - INFO - __main__ - Printing 3 examples
06/01/2022 03:27:22 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
06/01/2022 03:27:22 - INFO - __main__ - ['sad']
06/01/2022 03:27:22 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
06/01/2022 03:27:22 - INFO - __main__ - ['sad']
06/01/2022 03:27:22 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
06/01/2022 03:27:22 - INFO - __main__ - ['sad']
06/01/2022 03:27:22 - INFO - __main__ - Tokenizing Input ...
06/01/2022 03:27:22 - INFO - __main__ - Tokenizing Output ...
06/01/2022 03:27:22 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 03:27:27 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 03:27:28 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/01/2022 03:27:28 - INFO - __main__ - Starting training!
06/01/2022 03:27:29 - INFO - __main__ - Step 10 Global step 10 Train loss 8.76 on epoch=2
06/01/2022 03:27:30 - INFO - __main__ - Step 20 Global step 20 Train loss 8.69 on epoch=4
06/01/2022 03:27:32 - INFO - __main__ - Step 30 Global step 30 Train loss 8.64 on epoch=7
06/01/2022 03:27:33 - INFO - __main__ - Step 40 Global step 40 Train loss 8.71 on epoch=9
06/01/2022 03:27:34 - INFO - __main__ - Step 50 Global step 50 Train loss 8.57 on epoch=12
06/01/2022 03:27:42 - INFO - __main__ - Global step 50 Train loss 8.68 Classification-F1 0.0 on epoch=12
06/01/2022 03:27:43 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
06/01/2022 03:27:44 - INFO - __main__ - Step 60 Global step 60 Train loss 8.55 on epoch=14
06/01/2022 03:27:45 - INFO - __main__ - Step 70 Global step 70 Train loss 8.42 on epoch=17
06/01/2022 03:27:47 - INFO - __main__ - Step 80 Global step 80 Train loss 8.39 on epoch=19
06/01/2022 03:27:48 - INFO - __main__ - Step 90 Global step 90 Train loss 8.43 on epoch=22
06/01/2022 03:27:49 - INFO - __main__ - Step 100 Global step 100 Train loss 8.32 on epoch=24
06/01/2022 03:27:56 - INFO - __main__ - Global step 100 Train loss 8.42 Classification-F1 0.0 on epoch=24
06/01/2022 03:27:58 - INFO - __main__ - Step 110 Global step 110 Train loss 8.24 on epoch=27
06/01/2022 03:27:59 - INFO - __main__ - Step 120 Global step 120 Train loss 8.28 on epoch=29
06/01/2022 03:28:00 - INFO - __main__ - Step 130 Global step 130 Train loss 8.05 on epoch=32
06/01/2022 03:28:01 - INFO - __main__ - Step 140 Global step 140 Train loss 8.18 on epoch=34
06/01/2022 03:28:03 - INFO - __main__ - Step 150 Global step 150 Train loss 7.95 on epoch=37
06/01/2022 03:28:17 - INFO - __main__ - Global step 150 Train loss 8.14 Classification-F1 0.0 on epoch=37
06/01/2022 03:28:18 - INFO - __main__ - Step 160 Global step 160 Train loss 7.95 on epoch=39
06/01/2022 03:28:20 - INFO - __main__ - Step 170 Global step 170 Train loss 7.92 on epoch=42
06/01/2022 03:28:21 - INFO - __main__ - Step 180 Global step 180 Train loss 7.93 on epoch=44
06/01/2022 03:28:22 - INFO - __main__ - Step 190 Global step 190 Train loss 7.79 on epoch=47
06/01/2022 03:28:23 - INFO - __main__ - Step 200 Global step 200 Train loss 7.73 on epoch=49
06/01/2022 03:28:34 - INFO - __main__ - Global step 200 Train loss 7.86 Classification-F1 0.0 on epoch=49
06/01/2022 03:28:36 - INFO - __main__ - Step 210 Global step 210 Train loss 7.73 on epoch=52
06/01/2022 03:28:37 - INFO - __main__ - Step 220 Global step 220 Train loss 7.50 on epoch=54
06/01/2022 03:28:38 - INFO - __main__ - Step 230 Global step 230 Train loss 7.47 on epoch=57
06/01/2022 03:28:40 - INFO - __main__ - Step 240 Global step 240 Train loss 7.31 on epoch=59
06/01/2022 03:28:41 - INFO - __main__ - Step 250 Global step 250 Train loss 7.33 on epoch=62
06/01/2022 03:28:47 - INFO - __main__ - Global step 250 Train loss 7.47 Classification-F1 0.0 on epoch=62
06/01/2022 03:28:48 - INFO - __main__ - Step 260 Global step 260 Train loss 7.17 on epoch=64
06/01/2022 03:28:49 - INFO - __main__ - Step 270 Global step 270 Train loss 7.17 on epoch=67
06/01/2022 03:28:51 - INFO - __main__ - Step 280 Global step 280 Train loss 6.95 on epoch=69
06/01/2022 03:28:52 - INFO - __main__ - Step 290 Global step 290 Train loss 7.00 on epoch=72
06/01/2022 03:28:53 - INFO - __main__ - Step 300 Global step 300 Train loss 6.85 on epoch=74
06/01/2022 03:29:04 - INFO - __main__ - Global step 300 Train loss 7.03 Classification-F1 0.0 on epoch=74
06/01/2022 03:29:06 - INFO - __main__ - Step 310 Global step 310 Train loss 6.74 on epoch=77
06/01/2022 03:29:07 - INFO - __main__ - Step 320 Global step 320 Train loss 6.64 on epoch=79
06/01/2022 03:29:08 - INFO - __main__ - Step 330 Global step 330 Train loss 6.70 on epoch=82
06/01/2022 03:29:10 - INFO - __main__ - Step 340 Global step 340 Train loss 6.40 on epoch=84
06/01/2022 03:29:11 - INFO - __main__ - Step 350 Global step 350 Train loss 6.59 on epoch=87
06/01/2022 03:29:17 - INFO - __main__ - Global step 350 Train loss 6.61 Classification-F1 0.0 on epoch=87
06/01/2022 03:29:18 - INFO - __main__ - Step 360 Global step 360 Train loss 6.40 on epoch=89
06/01/2022 03:29:19 - INFO - __main__ - Step 370 Global step 370 Train loss 6.33 on epoch=92
06/01/2022 03:29:21 - INFO - __main__ - Step 380 Global step 380 Train loss 6.11 on epoch=94
06/01/2022 03:29:22 - INFO - __main__ - Step 390 Global step 390 Train loss 6.18 on epoch=97
06/01/2022 03:29:23 - INFO - __main__ - Step 400 Global step 400 Train loss 6.09 on epoch=99
06/01/2022 03:29:30 - INFO - __main__ - Global step 400 Train loss 6.22 Classification-F1 0.0 on epoch=99
06/01/2022 03:29:31 - INFO - __main__ - Step 410 Global step 410 Train loss 5.99 on epoch=102
06/01/2022 03:29:32 - INFO - __main__ - Step 420 Global step 420 Train loss 5.79 on epoch=104
06/01/2022 03:29:33 - INFO - __main__ - Step 430 Global step 430 Train loss 5.82 on epoch=107
06/01/2022 03:29:35 - INFO - __main__ - Step 440 Global step 440 Train loss 5.60 on epoch=109
06/01/2022 03:29:36 - INFO - __main__ - Step 450 Global step 450 Train loss 5.57 on epoch=112
06/01/2022 03:29:41 - INFO - __main__ - Global step 450 Train loss 5.75 Classification-F1 0.0 on epoch=112
06/01/2022 03:29:42 - INFO - __main__ - Step 460 Global step 460 Train loss 5.48 on epoch=114
06/01/2022 03:29:43 - INFO - __main__ - Step 470 Global step 470 Train loss 5.35 on epoch=117
06/01/2022 03:29:44 - INFO - __main__ - Step 480 Global step 480 Train loss 4.97 on epoch=119
06/01/2022 03:29:46 - INFO - __main__ - Step 490 Global step 490 Train loss 5.00 on epoch=122
06/01/2022 03:29:47 - INFO - __main__ - Step 500 Global step 500 Train loss 5.05 on epoch=124
06/01/2022 03:29:53 - INFO - __main__ - Global step 500 Train loss 5.17 Classification-F1 0.0 on epoch=124
06/01/2022 03:29:55 - INFO - __main__ - Step 510 Global step 510 Train loss 5.03 on epoch=127
06/01/2022 03:29:56 - INFO - __main__ - Step 520 Global step 520 Train loss 4.75 on epoch=129
06/01/2022 03:29:57 - INFO - __main__ - Step 530 Global step 530 Train loss 4.58 on epoch=132
06/01/2022 03:29:59 - INFO - __main__ - Step 540 Global step 540 Train loss 4.48 on epoch=134
06/01/2022 03:30:00 - INFO - __main__ - Step 550 Global step 550 Train loss 4.54 on epoch=137
06/01/2022 03:30:02 - INFO - __main__ - Global step 550 Train loss 4.68 Classification-F1 0.07692307692307691 on epoch=137
06/01/2022 03:30:02 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.07692307692307691 on epoch=137, global_step=550
06/01/2022 03:30:03 - INFO - __main__ - Step 560 Global step 560 Train loss 4.19 on epoch=139
06/01/2022 03:30:04 - INFO - __main__ - Step 570 Global step 570 Train loss 4.28 on epoch=142
06/01/2022 03:30:06 - INFO - __main__ - Step 580 Global step 580 Train loss 4.17 on epoch=144
06/01/2022 03:30:07 - INFO - __main__ - Step 590 Global step 590 Train loss 4.08 on epoch=147
06/01/2022 03:30:08 - INFO - __main__ - Step 600 Global step 600 Train loss 3.98 on epoch=149
06/01/2022 03:30:10 - INFO - __main__ - Global step 600 Train loss 4.14 Classification-F1 0.1 on epoch=149
06/01/2022 03:30:10 - INFO - __main__ - Saving model with best Classification-F1: 0.07692307692307691 -> 0.1 on epoch=149, global_step=600
06/01/2022 03:30:11 - INFO - __main__ - Step 610 Global step 610 Train loss 3.98 on epoch=152
06/01/2022 03:30:12 - INFO - __main__ - Step 620 Global step 620 Train loss 3.76 on epoch=154
06/01/2022 03:30:13 - INFO - __main__ - Step 630 Global step 630 Train loss 3.83 on epoch=157
06/01/2022 03:30:15 - INFO - __main__ - Step 640 Global step 640 Train loss 3.62 on epoch=159
06/01/2022 03:30:16 - INFO - __main__ - Step 650 Global step 650 Train loss 3.68 on epoch=162
06/01/2022 03:30:17 - INFO - __main__ - Global step 650 Train loss 3.77 Classification-F1 0.1 on epoch=162
06/01/2022 03:30:18 - INFO - __main__ - Step 660 Global step 660 Train loss 3.62 on epoch=164
06/01/2022 03:30:20 - INFO - __main__ - Step 670 Global step 670 Train loss 3.51 on epoch=167
06/01/2022 03:30:21 - INFO - __main__ - Step 680 Global step 680 Train loss 3.50 on epoch=169
06/01/2022 03:30:22 - INFO - __main__ - Step 690 Global step 690 Train loss 3.87 on epoch=172
06/01/2022 03:30:24 - INFO - __main__ - Step 700 Global step 700 Train loss 3.40 on epoch=174
06/01/2022 03:30:24 - INFO - __main__ - Global step 700 Train loss 3.58 Classification-F1 0.1 on epoch=174
06/01/2022 03:30:26 - INFO - __main__ - Step 710 Global step 710 Train loss 3.58 on epoch=177
06/01/2022 03:30:27 - INFO - __main__ - Step 720 Global step 720 Train loss 3.30 on epoch=179
06/01/2022 03:30:28 - INFO - __main__ - Step 730 Global step 730 Train loss 3.44 on epoch=182
06/01/2022 03:30:30 - INFO - __main__ - Step 740 Global step 740 Train loss 3.27 on epoch=184
06/01/2022 03:30:31 - INFO - __main__ - Step 750 Global step 750 Train loss 3.32 on epoch=187
06/01/2022 03:30:32 - INFO - __main__ - Global step 750 Train loss 3.38 Classification-F1 0.1 on epoch=187
06/01/2022 03:30:33 - INFO - __main__ - Step 760 Global step 760 Train loss 3.22 on epoch=189
06/01/2022 03:30:34 - INFO - __main__ - Step 770 Global step 770 Train loss 3.25 on epoch=192
06/01/2022 03:30:35 - INFO - __main__ - Step 780 Global step 780 Train loss 3.24 on epoch=194
06/01/2022 03:30:37 - INFO - __main__ - Step 790 Global step 790 Train loss 3.36 on epoch=197
06/01/2022 03:30:38 - INFO - __main__ - Step 800 Global step 800 Train loss 3.06 on epoch=199
06/01/2022 03:30:39 - INFO - __main__ - Global step 800 Train loss 3.23 Classification-F1 0.1 on epoch=199
06/01/2022 03:30:40 - INFO - __main__ - Step 810 Global step 810 Train loss 2.98 on epoch=202
06/01/2022 03:30:41 - INFO - __main__ - Step 820 Global step 820 Train loss 3.03 on epoch=204
06/01/2022 03:30:42 - INFO - __main__ - Step 830 Global step 830 Train loss 3.20 on epoch=207
06/01/2022 03:30:44 - INFO - __main__ - Step 840 Global step 840 Train loss 2.72 on epoch=209
06/01/2022 03:30:45 - INFO - __main__ - Step 850 Global step 850 Train loss 2.84 on epoch=212
06/01/2022 03:30:45 - INFO - __main__ - Global step 850 Train loss 2.95 Classification-F1 0.1 on epoch=212
06/01/2022 03:30:47 - INFO - __main__ - Step 860 Global step 860 Train loss 2.70 on epoch=214
06/01/2022 03:30:48 - INFO - __main__ - Step 870 Global step 870 Train loss 2.66 on epoch=217
06/01/2022 03:30:49 - INFO - __main__ - Step 880 Global step 880 Train loss 2.51 on epoch=219
06/01/2022 03:30:51 - INFO - __main__ - Step 890 Global step 890 Train loss 2.47 on epoch=222
06/01/2022 03:30:52 - INFO - __main__ - Step 900 Global step 900 Train loss 2.48 on epoch=224
06/01/2022 03:30:53 - INFO - __main__ - Global step 900 Train loss 2.56 Classification-F1 0.10126582278481013 on epoch=224
06/01/2022 03:30:53 - INFO - __main__ - Saving model with best Classification-F1: 0.1 -> 0.10126582278481013 on epoch=224, global_step=900
06/01/2022 03:30:54 - INFO - __main__ - Step 910 Global step 910 Train loss 2.77 on epoch=227
06/01/2022 03:30:55 - INFO - __main__ - Step 920 Global step 920 Train loss 2.22 on epoch=229
06/01/2022 03:30:56 - INFO - __main__ - Step 930 Global step 930 Train loss 2.22 on epoch=232
06/01/2022 03:30:58 - INFO - __main__ - Step 940 Global step 940 Train loss 2.07 on epoch=234
06/01/2022 03:30:59 - INFO - __main__ - Step 950 Global step 950 Train loss 2.13 on epoch=237
06/01/2022 03:31:00 - INFO - __main__ - Global step 950 Train loss 2.28 Classification-F1 0.1 on epoch=237
06/01/2022 03:31:01 - INFO - __main__ - Step 960 Global step 960 Train loss 1.98 on epoch=239
06/01/2022 03:31:02 - INFO - __main__ - Step 970 Global step 970 Train loss 1.98 on epoch=242
06/01/2022 03:31:04 - INFO - __main__ - Step 980 Global step 980 Train loss 1.81 on epoch=244
06/01/2022 03:31:05 - INFO - __main__ - Step 990 Global step 990 Train loss 1.93 on epoch=247
06/01/2022 03:31:06 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.99 on epoch=249
06/01/2022 03:31:07 - INFO - __main__ - Global step 1000 Train loss 1.94 Classification-F1 0.1 on epoch=249
06/01/2022 03:31:08 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.79 on epoch=252
06/01/2022 03:31:09 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.74 on epoch=254
06/01/2022 03:31:11 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.79 on epoch=257
06/01/2022 03:31:12 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.85 on epoch=259
06/01/2022 03:31:13 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.63 on epoch=262
06/01/2022 03:31:14 - INFO - __main__ - Global step 1050 Train loss 1.76 Classification-F1 0.10256410256410256 on epoch=262
06/01/2022 03:31:14 - INFO - __main__ - Saving model with best Classification-F1: 0.10126582278481013 -> 0.10256410256410256 on epoch=262, global_step=1050
06/01/2022 03:31:15 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.70 on epoch=264
06/01/2022 03:31:16 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.80 on epoch=267
06/01/2022 03:31:18 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.63 on epoch=269
06/01/2022 03:31:19 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.54 on epoch=272
06/01/2022 03:31:20 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.56 on epoch=274
06/01/2022 03:31:21 - INFO - __main__ - Global step 1100 Train loss 1.65 Classification-F1 0.17267605633802818 on epoch=274
06/01/2022 03:31:21 - INFO - __main__ - Saving model with best Classification-F1: 0.10256410256410256 -> 0.17267605633802818 on epoch=274, global_step=1100
06/01/2022 03:31:22 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.56 on epoch=277
06/01/2022 03:31:23 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.51 on epoch=279
06/01/2022 03:31:25 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.41 on epoch=282
06/01/2022 03:31:26 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.46 on epoch=284
06/01/2022 03:31:27 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.71 on epoch=287
06/01/2022 03:31:28 - INFO - __main__ - Global step 1150 Train loss 1.53 Classification-F1 0.1 on epoch=287
06/01/2022 03:31:29 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.42 on epoch=289
06/01/2022 03:31:30 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.61 on epoch=292
06/01/2022 03:31:32 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.41 on epoch=294
06/01/2022 03:31:33 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.32 on epoch=297
06/01/2022 03:31:34 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.36 on epoch=299
06/01/2022 03:31:35 - INFO - __main__ - Global step 1200 Train loss 1.42 Classification-F1 0.1 on epoch=299
06/01/2022 03:31:36 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.43 on epoch=302
06/01/2022 03:31:37 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.37 on epoch=304
06/01/2022 03:31:39 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.22 on epoch=307
06/01/2022 03:31:40 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.45 on epoch=309
06/01/2022 03:31:41 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.40 on epoch=312
06/01/2022 03:31:42 - INFO - __main__ - Global step 1250 Train loss 1.37 Classification-F1 0.13034188034188032 on epoch=312
06/01/2022 03:31:43 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.27 on epoch=314
06/01/2022 03:31:44 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.34 on epoch=317
06/01/2022 03:31:46 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.33 on epoch=319
06/01/2022 03:31:47 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.26 on epoch=322
06/01/2022 03:31:49 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.38 on epoch=324
06/01/2022 03:31:49 - INFO - __main__ - Global step 1300 Train loss 1.32 Classification-F1 0.09493670886075949 on epoch=324
06/01/2022 03:31:50 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.37 on epoch=327
06/01/2022 03:31:52 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.26 on epoch=329
06/01/2022 03:31:53 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.41 on epoch=332
06/01/2022 03:31:54 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.32 on epoch=334
06/01/2022 03:31:56 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.29 on epoch=337
06/01/2022 03:31:56 - INFO - __main__ - Global step 1350 Train loss 1.33 Classification-F1 0.15356265356265356 on epoch=337
06/01/2022 03:31:57 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.30 on epoch=339
06/01/2022 03:31:59 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.29 on epoch=342
06/01/2022 03:32:00 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.21 on epoch=344
06/01/2022 03:32:01 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.28 on epoch=347
06/01/2022 03:32:03 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.31 on epoch=349
06/01/2022 03:32:03 - INFO - __main__ - Global step 1400 Train loss 1.28 Classification-F1 0.13333333333333333 on epoch=349
06/01/2022 03:32:04 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.26 on epoch=352
06/01/2022 03:32:06 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.24 on epoch=354
06/01/2022 03:32:07 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.36 on epoch=357
06/01/2022 03:32:08 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.31 on epoch=359
06/01/2022 03:32:10 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.24 on epoch=362
06/01/2022 03:32:10 - INFO - __main__ - Global step 1450 Train loss 1.28 Classification-F1 0.0974025974025974 on epoch=362
06/01/2022 03:32:11 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.12 on epoch=364
06/01/2022 03:32:13 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.14 on epoch=367
06/01/2022 03:32:14 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.21 on epoch=369
06/01/2022 03:32:15 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.25 on epoch=372
06/01/2022 03:32:17 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.13 on epoch=374
06/01/2022 03:32:17 - INFO - __main__ - Global step 1500 Train loss 1.17 Classification-F1 0.14642305712815235 on epoch=374
06/01/2022 03:32:19 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.26 on epoch=377
06/01/2022 03:32:20 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.11 on epoch=379
06/01/2022 03:32:21 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.29 on epoch=382
06/01/2022 03:32:22 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.22 on epoch=384
06/01/2022 03:32:24 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.13 on epoch=387
06/01/2022 03:32:24 - INFO - __main__ - Global step 1550 Train loss 1.20 Classification-F1 0.13047619047619047 on epoch=387
06/01/2022 03:32:26 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.28 on epoch=389
06/01/2022 03:32:27 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.26 on epoch=392
06/01/2022 03:32:28 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.17 on epoch=394
06/01/2022 03:32:30 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.18 on epoch=397
06/01/2022 03:32:31 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.13 on epoch=399
06/01/2022 03:32:31 - INFO - __main__ - Global step 1600 Train loss 1.20 Classification-F1 0.13936867182846935 on epoch=399
06/01/2022 03:32:33 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.18 on epoch=402
06/01/2022 03:32:34 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.17 on epoch=404
06/01/2022 03:32:35 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.16 on epoch=407
06/01/2022 03:32:37 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.11 on epoch=409
06/01/2022 03:32:38 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.10 on epoch=412
06/01/2022 03:32:38 - INFO - __main__ - Global step 1650 Train loss 1.15 Classification-F1 0.15211640211640212 on epoch=412
06/01/2022 03:32:40 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.23 on epoch=414
06/01/2022 03:32:41 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.18 on epoch=417
06/01/2022 03:32:42 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.20 on epoch=419
06/01/2022 03:32:44 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.25 on epoch=422
06/01/2022 03:32:45 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.12 on epoch=424
06/01/2022 03:32:45 - INFO - __main__ - Global step 1700 Train loss 1.20 Classification-F1 0.1388888888888889 on epoch=424
06/01/2022 03:32:47 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.13 on epoch=427
06/01/2022 03:32:48 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.11 on epoch=429
06/01/2022 03:32:49 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.35 on epoch=432
06/01/2022 03:32:51 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.09 on epoch=434
06/01/2022 03:32:52 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.07 on epoch=437
06/01/2022 03:32:52 - INFO - __main__ - Global step 1750 Train loss 1.15 Classification-F1 0.16993464052287582 on epoch=437
06/01/2022 03:32:54 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.13 on epoch=439
06/01/2022 03:32:55 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.11 on epoch=442
06/01/2022 03:32:56 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.12 on epoch=444
06/01/2022 03:32:58 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.06 on epoch=447
06/01/2022 03:32:59 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.10 on epoch=449
06/01/2022 03:33:00 - INFO - __main__ - Global step 1800 Train loss 1.10 Classification-F1 0.17480643240023822 on epoch=449
06/01/2022 03:33:00 - INFO - __main__ - Saving model with best Classification-F1: 0.17267605633802818 -> 0.17480643240023822 on epoch=449, global_step=1800
06/01/2022 03:33:01 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.18 on epoch=452
06/01/2022 03:33:02 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.18 on epoch=454
06/01/2022 03:33:03 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.06 on epoch=457
06/01/2022 03:33:05 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.09 on epoch=459
06/01/2022 03:33:06 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.12 on epoch=462
06/01/2022 03:33:07 - INFO - __main__ - Global step 1850 Train loss 1.13 Classification-F1 0.14095238095238094 on epoch=462
06/01/2022 03:33:08 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.13 on epoch=464
06/01/2022 03:33:09 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.21 on epoch=467
06/01/2022 03:33:10 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.19 on epoch=469
06/01/2022 03:33:12 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.17 on epoch=472
06/01/2022 03:33:13 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.17 on epoch=474
06/01/2022 03:33:14 - INFO - __main__ - Global step 1900 Train loss 1.17 Classification-F1 0.1875 on epoch=474
06/01/2022 03:33:14 - INFO - __main__ - Saving model with best Classification-F1: 0.17480643240023822 -> 0.1875 on epoch=474, global_step=1900
06/01/2022 03:33:15 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.09 on epoch=477
06/01/2022 03:33:16 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.15 on epoch=479
06/01/2022 03:33:18 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.08 on epoch=482
06/01/2022 03:33:19 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.05 on epoch=484
06/01/2022 03:33:20 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.01 on epoch=487
06/01/2022 03:33:21 - INFO - __main__ - Global step 1950 Train loss 1.08 Classification-F1 0.19445676274944568 on epoch=487
06/01/2022 03:33:21 - INFO - __main__ - Saving model with best Classification-F1: 0.1875 -> 0.19445676274944568 on epoch=487, global_step=1950
06/01/2022 03:33:22 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.21 on epoch=489
06/01/2022 03:33:23 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.05 on epoch=492
06/01/2022 03:33:25 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.07 on epoch=494
06/01/2022 03:33:26 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.06 on epoch=497
06/01/2022 03:33:27 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.08 on epoch=499
06/01/2022 03:33:28 - INFO - __main__ - Global step 2000 Train loss 1.09 Classification-F1 0.1081081081081081 on epoch=499
06/01/2022 03:33:29 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.18 on epoch=502
06/01/2022 03:33:30 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.08 on epoch=504
06/01/2022 03:33:32 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.03 on epoch=507
06/01/2022 03:33:33 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.11 on epoch=509
06/01/2022 03:33:34 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.08 on epoch=512
06/01/2022 03:33:35 - INFO - __main__ - Global step 2050 Train loss 1.10 Classification-F1 0.13067758749069247 on epoch=512
06/01/2022 03:33:36 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.12 on epoch=514
06/01/2022 03:33:37 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.03 on epoch=517
06/01/2022 03:33:39 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.11 on epoch=519
06/01/2022 03:33:40 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.09 on epoch=522
06/01/2022 03:33:41 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.96 on epoch=524
06/01/2022 03:33:42 - INFO - __main__ - Global step 2100 Train loss 1.06 Classification-F1 0.1955535390199637 on epoch=524
06/01/2022 03:33:42 - INFO - __main__ - Saving model with best Classification-F1: 0.19445676274944568 -> 0.1955535390199637 on epoch=524, global_step=2100
06/01/2022 03:33:43 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.11 on epoch=527
06/01/2022 03:33:44 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.08 on epoch=529
06/01/2022 03:33:46 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.06 on epoch=532
06/01/2022 03:33:47 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.06 on epoch=534
06/01/2022 03:33:48 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.04 on epoch=537
06/01/2022 03:33:49 - INFO - __main__ - Global step 2150 Train loss 1.07 Classification-F1 0.1 on epoch=537
06/01/2022 03:33:50 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.01 on epoch=539
06/01/2022 03:33:51 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.15 on epoch=542
06/01/2022 03:33:53 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.05 on epoch=544
06/01/2022 03:33:54 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.04 on epoch=547
06/01/2022 03:33:55 - INFO - __main__ - Step 2200 Global step 2200 Train loss 1.17 on epoch=549
06/01/2022 03:33:56 - INFO - __main__ - Global step 2200 Train loss 1.08 Classification-F1 0.1611111111111111 on epoch=549
06/01/2022 03:33:57 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.07 on epoch=552
06/01/2022 03:33:58 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.13 on epoch=554
06/01/2022 03:34:00 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.04 on epoch=557
06/01/2022 03:34:01 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.09 on epoch=559
06/01/2022 03:34:02 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.98 on epoch=562
06/01/2022 03:34:03 - INFO - __main__ - Global step 2250 Train loss 1.06 Classification-F1 0.13859154929577466 on epoch=562
06/01/2022 03:34:04 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.04 on epoch=564
06/01/2022 03:34:05 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.11 on epoch=567
06/01/2022 03:34:06 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.94 on epoch=569
06/01/2022 03:34:08 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.04 on epoch=572
06/01/2022 03:34:09 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.97 on epoch=574
06/01/2022 03:34:10 - INFO - __main__ - Global step 2300 Train loss 1.02 Classification-F1 0.15859154929577468 on epoch=574
06/01/2022 03:34:11 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.17 on epoch=577
06/01/2022 03:34:12 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.07 on epoch=579
06/01/2022 03:34:13 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.98 on epoch=582
06/01/2022 03:34:15 - INFO - __main__ - Step 2340 Global step 2340 Train loss 1.10 on epoch=584
06/01/2022 03:34:16 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.19 on epoch=587
06/01/2022 03:34:17 - INFO - __main__ - Global step 2350 Train loss 1.10 Classification-F1 0.12499999999999999 on epoch=587
06/01/2022 03:34:18 - INFO - __main__ - Step 2360 Global step 2360 Train loss 1.05 on epoch=589
06/01/2022 03:34:19 - INFO - __main__ - Step 2370 Global step 2370 Train loss 1.06 on epoch=592
06/01/2022 03:34:21 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.96 on epoch=594
06/01/2022 03:34:22 - INFO - __main__ - Step 2390 Global step 2390 Train loss 1.02 on epoch=597
06/01/2022 03:34:23 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.25 on epoch=599
06/01/2022 03:34:24 - INFO - __main__ - Global step 2400 Train loss 1.07 Classification-F1 0.147459165154265 on epoch=599
06/01/2022 03:34:25 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.09 on epoch=602
06/01/2022 03:34:26 - INFO - __main__ - Step 2420 Global step 2420 Train loss 1.06 on epoch=604
06/01/2022 03:34:28 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.03 on epoch=607
06/01/2022 03:34:29 - INFO - __main__ - Step 2440 Global step 2440 Train loss 1.03 on epoch=609
06/01/2022 03:34:30 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.05 on epoch=612
06/01/2022 03:34:31 - INFO - __main__ - Global step 2450 Train loss 1.05 Classification-F1 0.203125 on epoch=612
06/01/2022 03:34:31 - INFO - __main__ - Saving model with best Classification-F1: 0.1955535390199637 -> 0.203125 on epoch=612, global_step=2450
06/01/2022 03:34:32 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.07 on epoch=614
06/01/2022 03:34:33 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.95 on epoch=617
06/01/2022 03:34:35 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.09 on epoch=619
06/01/2022 03:34:36 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.86 on epoch=622
06/01/2022 03:34:37 - INFO - __main__ - Step 2500 Global step 2500 Train loss 1.00 on epoch=624
06/01/2022 03:34:38 - INFO - __main__ - Global step 2500 Train loss 0.99 Classification-F1 0.19956521739130434 on epoch=624
06/01/2022 03:34:39 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.95 on epoch=627
06/01/2022 03:34:40 - INFO - __main__ - Step 2520 Global step 2520 Train loss 1.01 on epoch=629
06/01/2022 03:34:42 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.92 on epoch=632
06/01/2022 03:34:43 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.96 on epoch=634
06/01/2022 03:34:44 - INFO - __main__ - Step 2550 Global step 2550 Train loss 1.03 on epoch=637
06/01/2022 03:34:45 - INFO - __main__ - Global step 2550 Train loss 0.97 Classification-F1 0.10450704225352113 on epoch=637
06/01/2022 03:34:46 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.89 on epoch=639
06/01/2022 03:34:47 - INFO - __main__ - Step 2570 Global step 2570 Train loss 1.04 on epoch=642
06/01/2022 03:34:49 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.96 on epoch=644
06/01/2022 03:34:50 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.92 on epoch=647
06/01/2022 03:34:51 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.04 on epoch=649
06/01/2022 03:34:52 - INFO - __main__ - Global step 2600 Train loss 0.97 Classification-F1 0.13123993558776167 on epoch=649
06/01/2022 03:34:53 - INFO - __main__ - Step 2610 Global step 2610 Train loss 1.01 on epoch=652
06/01/2022 03:34:54 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.90 on epoch=654
06/01/2022 03:34:56 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.94 on epoch=657
06/01/2022 03:34:57 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.05 on epoch=659
06/01/2022 03:34:58 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.09 on epoch=662
06/01/2022 03:34:59 - INFO - __main__ - Global step 2650 Train loss 1.00 Classification-F1 0.13482414242292662 on epoch=662
06/01/2022 03:35:00 - INFO - __main__ - Step 2660 Global step 2660 Train loss 1.09 on epoch=664
06/01/2022 03:35:01 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.92 on epoch=667
06/01/2022 03:35:03 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.99 on epoch=669
06/01/2022 03:35:04 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.99 on epoch=672
06/01/2022 03:35:05 - INFO - __main__ - Step 2700 Global step 2700 Train loss 1.02 on epoch=674
06/01/2022 03:35:06 - INFO - __main__ - Global step 2700 Train loss 1.00 Classification-F1 0.1 on epoch=674
06/01/2022 03:35:07 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.02 on epoch=677
06/01/2022 03:35:08 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.97 on epoch=679
06/01/2022 03:35:10 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.91 on epoch=682
06/01/2022 03:35:11 - INFO - __main__ - Step 2740 Global step 2740 Train loss 1.14 on epoch=684
06/01/2022 03:35:12 - INFO - __main__ - Step 2750 Global step 2750 Train loss 1.01 on epoch=687
06/01/2022 03:35:13 - INFO - __main__ - Global step 2750 Train loss 1.01 Classification-F1 0.1 on epoch=687
06/01/2022 03:35:14 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.93 on epoch=689
06/01/2022 03:35:15 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.03 on epoch=692
06/01/2022 03:35:17 - INFO - __main__ - Step 2780 Global step 2780 Train loss 1.01 on epoch=694
06/01/2022 03:35:18 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.98 on epoch=697
06/01/2022 03:35:19 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.93 on epoch=699
06/01/2022 03:35:20 - INFO - __main__ - Global step 2800 Train loss 0.98 Classification-F1 0.13034188034188032 on epoch=699
06/01/2022 03:35:21 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.03 on epoch=702
06/01/2022 03:35:23 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.98 on epoch=704
06/01/2022 03:35:24 - INFO - __main__ - Step 2830 Global step 2830 Train loss 1.01 on epoch=707
06/01/2022 03:35:25 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.95 on epoch=709
06/01/2022 03:35:26 - INFO - __main__ - Step 2850 Global step 2850 Train loss 1.06 on epoch=712
06/01/2022 03:35:27 - INFO - __main__ - Global step 2850 Train loss 1.01 Classification-F1 0.11732186732186733 on epoch=712
06/01/2022 03:35:28 - INFO - __main__ - Step 2860 Global step 2860 Train loss 1.05 on epoch=714
06/01/2022 03:35:30 - INFO - __main__ - Step 2870 Global step 2870 Train loss 1.12 on epoch=717
06/01/2022 03:35:31 - INFO - __main__ - Step 2880 Global step 2880 Train loss 1.06 on epoch=719
06/01/2022 03:35:32 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.02 on epoch=722
06/01/2022 03:35:34 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.96 on epoch=724
06/01/2022 03:35:34 - INFO - __main__ - Global step 2900 Train loss 1.04 Classification-F1 0.09493670886075949 on epoch=724
06/01/2022 03:35:35 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.87 on epoch=727
06/01/2022 03:35:37 - INFO - __main__ - Step 2920 Global step 2920 Train loss 1.03 on epoch=729
06/01/2022 03:35:38 - INFO - __main__ - Step 2930 Global step 2930 Train loss 1.01 on epoch=732
06/01/2022 03:35:39 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.98 on epoch=734
06/01/2022 03:35:41 - INFO - __main__ - Step 2950 Global step 2950 Train loss 1.01 on epoch=737
06/01/2022 03:35:41 - INFO - __main__ - Global step 2950 Train loss 0.98 Classification-F1 0.12450704225352113 on epoch=737
06/01/2022 03:35:43 - INFO - __main__ - Step 2960 Global step 2960 Train loss 1.02 on epoch=739
06/01/2022 03:35:44 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.97 on epoch=742
06/01/2022 03:35:45 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.91 on epoch=744
06/01/2022 03:35:46 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.98 on epoch=747
06/01/2022 03:35:48 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.94 on epoch=749
06/01/2022 03:35:48 - INFO - __main__ - Global step 3000 Train loss 0.96 Classification-F1 0.19068450849202268 on epoch=749
06/01/2022 03:35:48 - INFO - __main__ - save last model!
06/01/2022 03:35:48 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/01/2022 03:35:48 - INFO - __main__ - Start tokenizing ... 5509 instances
06/01/2022 03:35:48 - INFO - __main__ - Printing 3 examples
06/01/2022 03:35:48 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/01/2022 03:35:48 - INFO - __main__ - ['others']
06/01/2022 03:35:48 - INFO - __main__ -  [emo] what you like very little things ok
06/01/2022 03:35:48 - INFO - __main__ - ['others']
06/01/2022 03:35:48 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/01/2022 03:35:48 - INFO - __main__ - ['others']
06/01/2022 03:35:48 - INFO - __main__ - Tokenizing Input ...
06/01/2022 03:35:49 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 03:35:49 - INFO - __main__ - Printing 3 examples
06/01/2022 03:35:49 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/01/2022 03:35:49 - INFO - __main__ - ['sad']
06/01/2022 03:35:49 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/01/2022 03:35:49 - INFO - __main__ - ['sad']
06/01/2022 03:35:49 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/01/2022 03:35:49 - INFO - __main__ - ['sad']
06/01/2022 03:35:49 - INFO - __main__ - Tokenizing Input ...
06/01/2022 03:35:49 - INFO - __main__ - Tokenizing Output ...
06/01/2022 03:35:49 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 03:35:49 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 03:35:49 - INFO - __main__ - Printing 3 examples
06/01/2022 03:35:49 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
06/01/2022 03:35:49 - INFO - __main__ - ['sad']
06/01/2022 03:35:49 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
06/01/2022 03:35:49 - INFO - __main__ - ['sad']
06/01/2022 03:35:49 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
06/01/2022 03:35:49 - INFO - __main__ - ['sad']
06/01/2022 03:35:49 - INFO - __main__ - Tokenizing Input ...
06/01/2022 03:35:49 - INFO - __main__ - Tokenizing Output ...
06/01/2022 03:35:49 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 03:35:51 - INFO - __main__ - Tokenizing Output ...
06/01/2022 03:35:55 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 03:35:55 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/01/2022 03:35:55 - INFO - __main__ - Starting training!
06/01/2022 03:35:56 - INFO - __main__ - Loaded 5509 examples from test data
06/01/2022 03:36:40 - INFO - __main__ - Saved prediction in models/T5-base-reptile-cls2cls-3e-5-2-5000-5e-1-10/singletask-emo/emo_16_21_0.4_8_predictions.txt
06/01/2022 03:36:40 - INFO - __main__ - Classification-F1 on test data: 0.0451
06/01/2022 03:36:40 - INFO - __main__ - prefix=emo_16_21, lr=0.4, bsz=8, dev_performance=0.203125, test_performance=0.045132300137508366
06/01/2022 03:36:40 - INFO - __main__ - Running ... prefix=emo_16_21, lr=0.3, bsz=8 ...
06/01/2022 03:36:41 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 03:36:41 - INFO - __main__ - Printing 3 examples
06/01/2022 03:36:41 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/01/2022 03:36:41 - INFO - __main__ - ['sad']
06/01/2022 03:36:41 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/01/2022 03:36:41 - INFO - __main__ - ['sad']
06/01/2022 03:36:41 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/01/2022 03:36:41 - INFO - __main__ - ['sad']
06/01/2022 03:36:41 - INFO - __main__ - Tokenizing Input ...
06/01/2022 03:36:41 - INFO - __main__ - Tokenizing Output ...
06/01/2022 03:36:41 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 03:36:41 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 03:36:41 - INFO - __main__ - Printing 3 examples
06/01/2022 03:36:41 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
06/01/2022 03:36:41 - INFO - __main__ - ['sad']
06/01/2022 03:36:41 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
06/01/2022 03:36:41 - INFO - __main__ - ['sad']
06/01/2022 03:36:41 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
06/01/2022 03:36:41 - INFO - __main__ - ['sad']
06/01/2022 03:36:41 - INFO - __main__ - Tokenizing Input ...
06/01/2022 03:36:41 - INFO - __main__ - Tokenizing Output ...
06/01/2022 03:36:41 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 03:36:47 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 03:36:47 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/01/2022 03:36:47 - INFO - __main__ - Starting training!
06/01/2022 03:36:49 - INFO - __main__ - Step 10 Global step 10 Train loss 8.78 on epoch=2
06/01/2022 03:36:50 - INFO - __main__ - Step 20 Global step 20 Train loss 8.77 on epoch=4
06/01/2022 03:36:51 - INFO - __main__ - Step 30 Global step 30 Train loss 8.76 on epoch=7
06/01/2022 03:36:53 - INFO - __main__ - Step 40 Global step 40 Train loss 8.67 on epoch=9
06/01/2022 03:36:54 - INFO - __main__ - Step 50 Global step 50 Train loss 8.55 on epoch=12
06/01/2022 03:36:59 - INFO - __main__ - Global step 50 Train loss 8.71 Classification-F1 0.0 on epoch=12
06/01/2022 03:36:59 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
06/01/2022 03:37:01 - INFO - __main__ - Step 60 Global step 60 Train loss 8.51 on epoch=14
06/01/2022 03:37:02 - INFO - __main__ - Step 70 Global step 70 Train loss 8.40 on epoch=17
06/01/2022 03:37:03 - INFO - __main__ - Step 80 Global step 80 Train loss 8.55 on epoch=19
06/01/2022 03:37:04 - INFO - __main__ - Step 90 Global step 90 Train loss 8.37 on epoch=22
06/01/2022 03:37:06 - INFO - __main__ - Step 100 Global step 100 Train loss 8.44 on epoch=24
06/01/2022 03:37:11 - INFO - __main__ - Global step 100 Train loss 8.45 Classification-F1 0.0 on epoch=24
06/01/2022 03:37:12 - INFO - __main__ - Step 110 Global step 110 Train loss 8.34 on epoch=27
06/01/2022 03:37:13 - INFO - __main__ - Step 120 Global step 120 Train loss 8.34 on epoch=29
06/01/2022 03:37:14 - INFO - __main__ - Step 130 Global step 130 Train loss 8.16 on epoch=32
06/01/2022 03:37:16 - INFO - __main__ - Step 140 Global step 140 Train loss 8.14 on epoch=34
06/01/2022 03:37:17 - INFO - __main__ - Step 150 Global step 150 Train loss 8.13 on epoch=37
06/01/2022 03:37:29 - INFO - __main__ - Global step 150 Train loss 8.22 Classification-F1 0.0 on epoch=37
06/01/2022 03:37:30 - INFO - __main__ - Step 160 Global step 160 Train loss 8.11 on epoch=39
06/01/2022 03:37:31 - INFO - __main__ - Step 170 Global step 170 Train loss 7.97 on epoch=42
06/01/2022 03:37:32 - INFO - __main__ - Step 180 Global step 180 Train loss 7.87 on epoch=44
06/01/2022 03:37:34 - INFO - __main__ - Step 190 Global step 190 Train loss 7.77 on epoch=47
06/01/2022 03:37:35 - INFO - __main__ - Step 200 Global step 200 Train loss 7.71 on epoch=49
06/01/2022 03:37:40 - INFO - __main__ - Global step 200 Train loss 7.89 Classification-F1 0.0 on epoch=49
06/01/2022 03:37:41 - INFO - __main__ - Step 210 Global step 210 Train loss 7.53 on epoch=52
06/01/2022 03:37:42 - INFO - __main__ - Step 220 Global step 220 Train loss 7.58 on epoch=54
06/01/2022 03:37:44 - INFO - __main__ - Step 230 Global step 230 Train loss 7.40 on epoch=57
06/01/2022 03:37:45 - INFO - __main__ - Step 240 Global step 240 Train loss 7.23 on epoch=59
06/01/2022 03:37:46 - INFO - __main__ - Step 250 Global step 250 Train loss 7.21 on epoch=62
06/01/2022 03:37:48 - INFO - __main__ - Global step 250 Train loss 7.39 Classification-F1 0.0 on epoch=62
06/01/2022 03:37:49 - INFO - __main__ - Step 260 Global step 260 Train loss 7.08 on epoch=64
06/01/2022 03:37:51 - INFO - __main__ - Step 270 Global step 270 Train loss 7.10 on epoch=67
06/01/2022 03:37:52 - INFO - __main__ - Step 280 Global step 280 Train loss 6.91 on epoch=69
06/01/2022 03:37:53 - INFO - __main__ - Step 290 Global step 290 Train loss 6.85 on epoch=72
06/01/2022 03:37:55 - INFO - __main__ - Step 300 Global step 300 Train loss 6.81 on epoch=74
06/01/2022 03:37:56 - INFO - __main__ - Global step 300 Train loss 6.95 Classification-F1 0.0 on epoch=74
06/01/2022 03:37:58 - INFO - __main__ - Step 310 Global step 310 Train loss 6.63 on epoch=77
06/01/2022 03:37:59 - INFO - __main__ - Step 320 Global step 320 Train loss 6.56 on epoch=79
06/01/2022 03:38:00 - INFO - __main__ - Step 330 Global step 330 Train loss 6.53 on epoch=82
06/01/2022 03:38:02 - INFO - __main__ - Step 340 Global step 340 Train loss 6.59 on epoch=84
06/01/2022 03:38:03 - INFO - __main__ - Step 350 Global step 350 Train loss 6.32 on epoch=87
06/01/2022 03:38:04 - INFO - __main__ - Global step 350 Train loss 6.53 Classification-F1 0.0 on epoch=87
06/01/2022 03:38:05 - INFO - __main__ - Step 360 Global step 360 Train loss 6.21 on epoch=89
06/01/2022 03:38:07 - INFO - __main__ - Step 370 Global step 370 Train loss 6.35 on epoch=92
06/01/2022 03:38:08 - INFO - __main__ - Step 380 Global step 380 Train loss 6.05 on epoch=94
06/01/2022 03:38:09 - INFO - __main__ - Step 390 Global step 390 Train loss 6.23 on epoch=97
06/01/2022 03:38:11 - INFO - __main__ - Step 400 Global step 400 Train loss 5.86 on epoch=99
06/01/2022 03:38:13 - INFO - __main__ - Global step 400 Train loss 6.14 Classification-F1 0.0 on epoch=99
06/01/2022 03:38:15 - INFO - __main__ - Step 410 Global step 410 Train loss 5.86 on epoch=102
06/01/2022 03:38:16 - INFO - __main__ - Step 420 Global step 420 Train loss 5.69 on epoch=104
06/01/2022 03:38:17 - INFO - __main__ - Step 430 Global step 430 Train loss 5.70 on epoch=107
06/01/2022 03:38:18 - INFO - __main__ - Step 440 Global step 440 Train loss 5.58 on epoch=109
06/01/2022 03:38:20 - INFO - __main__ - Step 450 Global step 450 Train loss 5.59 on epoch=112
06/01/2022 03:38:23 - INFO - __main__ - Global step 450 Train loss 5.68 Classification-F1 0.0 on epoch=112
06/01/2022 03:38:25 - INFO - __main__ - Step 460 Global step 460 Train loss 5.42 on epoch=114
06/01/2022 03:38:26 - INFO - __main__ - Step 470 Global step 470 Train loss 5.33 on epoch=117
06/01/2022 03:38:27 - INFO - __main__ - Step 480 Global step 480 Train loss 5.26 on epoch=119
06/01/2022 03:38:29 - INFO - __main__ - Step 490 Global step 490 Train loss 5.27 on epoch=122
06/01/2022 03:38:30 - INFO - __main__ - Step 500 Global step 500 Train loss 4.93 on epoch=124
06/01/2022 03:38:35 - INFO - __main__ - Global step 500 Train loss 5.24 Classification-F1 0.0 on epoch=124
06/01/2022 03:38:36 - INFO - __main__ - Step 510 Global step 510 Train loss 5.15 on epoch=127
06/01/2022 03:38:37 - INFO - __main__ - Step 520 Global step 520 Train loss 4.93 on epoch=129
06/01/2022 03:38:39 - INFO - __main__ - Step 530 Global step 530 Train loss 4.96 on epoch=132
06/01/2022 03:38:40 - INFO - __main__ - Step 540 Global step 540 Train loss 4.76 on epoch=134
06/01/2022 03:38:41 - INFO - __main__ - Step 550 Global step 550 Train loss 4.97 on epoch=137
06/01/2022 03:38:49 - INFO - __main__ - Global step 550 Train loss 4.95 Classification-F1 0.0 on epoch=137
06/01/2022 03:38:51 - INFO - __main__ - Step 560 Global step 560 Train loss 4.66 on epoch=139
06/01/2022 03:38:52 - INFO - __main__ - Step 570 Global step 570 Train loss 4.84 on epoch=142
06/01/2022 03:38:53 - INFO - __main__ - Step 580 Global step 580 Train loss 4.61 on epoch=144
06/01/2022 03:38:55 - INFO - __main__ - Step 590 Global step 590 Train loss 4.54 on epoch=147
06/01/2022 03:38:56 - INFO - __main__ - Step 600 Global step 600 Train loss 4.41 on epoch=149
06/01/2022 03:39:04 - INFO - __main__ - Global step 600 Train loss 4.61 Classification-F1 0.0 on epoch=149
06/01/2022 03:39:05 - INFO - __main__ - Step 610 Global step 610 Train loss 4.38 on epoch=152
06/01/2022 03:39:06 - INFO - __main__ - Step 620 Global step 620 Train loss 4.18 on epoch=154
06/01/2022 03:39:08 - INFO - __main__ - Step 630 Global step 630 Train loss 4.34 on epoch=157
06/01/2022 03:39:09 - INFO - __main__ - Step 640 Global step 640 Train loss 4.19 on epoch=159
06/01/2022 03:39:10 - INFO - __main__ - Step 650 Global step 650 Train loss 4.36 on epoch=162
06/01/2022 03:39:17 - INFO - __main__ - Global step 650 Train loss 4.29 Classification-F1 0.0 on epoch=162
06/01/2022 03:39:18 - INFO - __main__ - Step 660 Global step 660 Train loss 4.07 on epoch=164
06/01/2022 03:39:19 - INFO - __main__ - Step 670 Global step 670 Train loss 4.00 on epoch=167
06/01/2022 03:39:20 - INFO - __main__ - Step 680 Global step 680 Train loss 3.89 on epoch=169
06/01/2022 03:39:22 - INFO - __main__ - Step 690 Global step 690 Train loss 3.86 on epoch=172
06/01/2022 03:39:23 - INFO - __main__ - Step 700 Global step 700 Train loss 3.97 on epoch=174
06/01/2022 03:39:29 - INFO - __main__ - Global step 700 Train loss 3.96 Classification-F1 0.021739130434782608 on epoch=174
06/01/2022 03:39:29 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.021739130434782608 on epoch=174, global_step=700
06/01/2022 03:39:30 - INFO - __main__ - Step 710 Global step 710 Train loss 3.99 on epoch=177
06/01/2022 03:39:31 - INFO - __main__ - Step 720 Global step 720 Train loss 3.85 on epoch=179
06/01/2022 03:39:32 - INFO - __main__ - Step 730 Global step 730 Train loss 3.98 on epoch=182
06/01/2022 03:39:34 - INFO - __main__ - Step 740 Global step 740 Train loss 3.81 on epoch=184
06/01/2022 03:39:35 - INFO - __main__ - Step 750 Global step 750 Train loss 3.85 on epoch=187
06/01/2022 03:39:38 - INFO - __main__ - Global step 750 Train loss 3.90 Classification-F1 0.07207207207207207 on epoch=187
06/01/2022 03:39:38 - INFO - __main__ - Saving model with best Classification-F1: 0.021739130434782608 -> 0.07207207207207207 on epoch=187, global_step=750
06/01/2022 03:39:40 - INFO - __main__ - Step 760 Global step 760 Train loss 3.59 on epoch=189
06/01/2022 03:39:41 - INFO - __main__ - Step 770 Global step 770 Train loss 3.52 on epoch=192
06/01/2022 03:39:42 - INFO - __main__ - Step 780 Global step 780 Train loss 3.45 on epoch=194
06/01/2022 03:39:44 - INFO - __main__ - Step 790 Global step 790 Train loss 3.62 on epoch=197
06/01/2022 03:39:45 - INFO - __main__ - Step 800 Global step 800 Train loss 3.30 on epoch=199
06/01/2022 03:39:48 - INFO - __main__ - Global step 800 Train loss 3.50 Classification-F1 0.11047619047619046 on epoch=199
06/01/2022 03:39:48 - INFO - __main__ - Saving model with best Classification-F1: 0.07207207207207207 -> 0.11047619047619046 on epoch=199, global_step=800
06/01/2022 03:39:49 - INFO - __main__ - Step 810 Global step 810 Train loss 3.42 on epoch=202
06/01/2022 03:39:51 - INFO - __main__ - Step 820 Global step 820 Train loss 3.33 on epoch=204
06/01/2022 03:39:52 - INFO - __main__ - Step 830 Global step 830 Train loss 3.29 on epoch=207
06/01/2022 03:39:53 - INFO - __main__ - Step 840 Global step 840 Train loss 3.32 on epoch=209
06/01/2022 03:39:54 - INFO - __main__ - Step 850 Global step 850 Train loss 3.25 on epoch=212
06/01/2022 03:39:55 - INFO - __main__ - Global step 850 Train loss 3.32 Classification-F1 0.13067758749069247 on epoch=212
06/01/2022 03:39:55 - INFO - __main__ - Saving model with best Classification-F1: 0.11047619047619046 -> 0.13067758749069247 on epoch=212, global_step=850
06/01/2022 03:39:57 - INFO - __main__ - Step 860 Global step 860 Train loss 3.03 on epoch=214
06/01/2022 03:39:58 - INFO - __main__ - Step 870 Global step 870 Train loss 3.05 on epoch=217
06/01/2022 03:39:59 - INFO - __main__ - Step 880 Global step 880 Train loss 2.87 on epoch=219
06/01/2022 03:40:00 - INFO - __main__ - Step 890 Global step 890 Train loss 3.27 on epoch=222
06/01/2022 03:40:02 - INFO - __main__ - Step 900 Global step 900 Train loss 3.08 on epoch=224
06/01/2022 03:40:03 - INFO - __main__ - Global step 900 Train loss 3.06 Classification-F1 0.15607940446650126 on epoch=224
06/01/2022 03:40:03 - INFO - __main__ - Saving model with best Classification-F1: 0.13067758749069247 -> 0.15607940446650126 on epoch=224, global_step=900
06/01/2022 03:40:04 - INFO - __main__ - Step 910 Global step 910 Train loss 2.94 on epoch=227
06/01/2022 03:40:06 - INFO - __main__ - Step 920 Global step 920 Train loss 2.82 on epoch=229
06/01/2022 03:40:07 - INFO - __main__ - Step 930 Global step 930 Train loss 2.79 on epoch=232
06/01/2022 03:40:08 - INFO - __main__ - Step 940 Global step 940 Train loss 2.75 on epoch=234
06/01/2022 03:40:09 - INFO - __main__ - Step 950 Global step 950 Train loss 2.81 on epoch=237
06/01/2022 03:40:10 - INFO - __main__ - Global step 950 Train loss 2.82 Classification-F1 0.1302118933697881 on epoch=237
06/01/2022 03:40:12 - INFO - __main__ - Step 960 Global step 960 Train loss 2.50 on epoch=239
06/01/2022 03:40:13 - INFO - __main__ - Step 970 Global step 970 Train loss 2.57 on epoch=242
06/01/2022 03:40:14 - INFO - __main__ - Step 980 Global step 980 Train loss 2.38 on epoch=244
06/01/2022 03:40:16 - INFO - __main__ - Step 990 Global step 990 Train loss 2.35 on epoch=247
06/01/2022 03:40:17 - INFO - __main__ - Step 1000 Global step 1000 Train loss 2.24 on epoch=249
06/01/2022 03:40:18 - INFO - __main__ - Global step 1000 Train loss 2.41 Classification-F1 0.1 on epoch=249
06/01/2022 03:40:19 - INFO - __main__ - Step 1010 Global step 1010 Train loss 2.34 on epoch=252
06/01/2022 03:40:20 - INFO - __main__ - Step 1020 Global step 1020 Train loss 2.13 on epoch=254
06/01/2022 03:40:21 - INFO - __main__ - Step 1030 Global step 1030 Train loss 2.05 on epoch=257
06/01/2022 03:40:23 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.83 on epoch=259
06/01/2022 03:40:24 - INFO - __main__ - Step 1050 Global step 1050 Train loss 2.12 on epoch=262
06/01/2022 03:40:25 - INFO - __main__ - Global step 1050 Train loss 2.09 Classification-F1 0.1 on epoch=262
06/01/2022 03:40:26 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.90 on epoch=264
06/01/2022 03:40:27 - INFO - __main__ - Step 1070 Global step 1070 Train loss 2.19 on epoch=267
06/01/2022 03:40:29 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.99 on epoch=269
06/01/2022 03:40:30 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.86 on epoch=272
06/01/2022 03:40:31 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.73 on epoch=274
06/01/2022 03:40:32 - INFO - __main__ - Global step 1100 Train loss 1.93 Classification-F1 0.13067758749069247 on epoch=274
06/01/2022 03:40:33 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.89 on epoch=277
06/01/2022 03:40:34 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.79 on epoch=279
06/01/2022 03:40:36 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.65 on epoch=282
06/01/2022 03:40:37 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.70 on epoch=284
06/01/2022 03:40:38 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.73 on epoch=287
06/01/2022 03:40:39 - INFO - __main__ - Global step 1150 Train loss 1.75 Classification-F1 0.10126582278481013 on epoch=287
06/01/2022 03:40:40 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.75 on epoch=289
06/01/2022 03:40:41 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.51 on epoch=292
06/01/2022 03:40:43 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.50 on epoch=294
06/01/2022 03:40:44 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.55 on epoch=297
06/01/2022 03:40:45 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.51 on epoch=299
06/01/2022 03:40:46 - INFO - __main__ - Global step 1200 Train loss 1.56 Classification-F1 0.1 on epoch=299
06/01/2022 03:40:47 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.50 on epoch=302
06/01/2022 03:40:48 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.40 on epoch=304
06/01/2022 03:40:50 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.45 on epoch=307
06/01/2022 03:40:51 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.50 on epoch=309
06/01/2022 03:40:52 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.56 on epoch=312
06/01/2022 03:40:53 - INFO - __main__ - Global step 1250 Train loss 1.48 Classification-F1 0.18648558014755195 on epoch=312
06/01/2022 03:40:53 - INFO - __main__ - Saving model with best Classification-F1: 0.15607940446650126 -> 0.18648558014755195 on epoch=312, global_step=1250
06/01/2022 03:40:54 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.49 on epoch=314
06/01/2022 03:40:55 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.38 on epoch=317
06/01/2022 03:40:57 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.59 on epoch=319
06/01/2022 03:40:58 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.40 on epoch=322
06/01/2022 03:40:59 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.46 on epoch=324
06/01/2022 03:41:00 - INFO - __main__ - Global step 1300 Train loss 1.47 Classification-F1 0.21560846560846564 on epoch=324
06/01/2022 03:41:00 - INFO - __main__ - Saving model with best Classification-F1: 0.18648558014755195 -> 0.21560846560846564 on epoch=324, global_step=1300
06/01/2022 03:41:01 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.39 on epoch=327
06/01/2022 03:41:02 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.17 on epoch=329
06/01/2022 03:41:04 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.45 on epoch=332
06/01/2022 03:41:05 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.47 on epoch=334
06/01/2022 03:41:06 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.36 on epoch=337
06/01/2022 03:41:07 - INFO - __main__ - Global step 1350 Train loss 1.37 Classification-F1 0.20842379504993486 on epoch=337
06/01/2022 03:41:08 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.40 on epoch=339
06/01/2022 03:41:09 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.45 on epoch=342
06/01/2022 03:41:11 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.30 on epoch=344
06/01/2022 03:41:12 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.40 on epoch=347
06/01/2022 03:41:13 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.23 on epoch=349
06/01/2022 03:41:14 - INFO - __main__ - Global step 1400 Train loss 1.36 Classification-F1 0.16630481980026052 on epoch=349
06/01/2022 03:41:15 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.46 on epoch=352
06/01/2022 03:41:16 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.18 on epoch=354
06/01/2022 03:41:18 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.26 on epoch=357
06/01/2022 03:41:19 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.36 on epoch=359
06/01/2022 03:41:20 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.25 on epoch=362
06/01/2022 03:41:21 - INFO - __main__ - Global step 1450 Train loss 1.30 Classification-F1 0.17937915742793792 on epoch=362
06/01/2022 03:41:22 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.26 on epoch=364
06/01/2022 03:41:23 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.38 on epoch=367
06/01/2022 03:41:25 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.19 on epoch=369
06/01/2022 03:41:26 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.27 on epoch=372
06/01/2022 03:41:27 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.37 on epoch=374
06/01/2022 03:41:28 - INFO - __main__ - Global step 1500 Train loss 1.29 Classification-F1 0.1237183868762816 on epoch=374
06/01/2022 03:41:29 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.28 on epoch=377
06/01/2022 03:41:30 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.15 on epoch=379
06/01/2022 03:41:32 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.30 on epoch=382
06/01/2022 03:41:33 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.25 on epoch=384
06/01/2022 03:41:34 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.19 on epoch=387
06/01/2022 03:41:35 - INFO - __main__ - Global step 1550 Train loss 1.23 Classification-F1 0.1 on epoch=387
06/01/2022 03:41:36 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.31 on epoch=389
06/01/2022 03:41:37 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.32 on epoch=392
06/01/2022 03:41:38 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.21 on epoch=394
06/01/2022 03:41:39 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.30 on epoch=397
06/01/2022 03:41:41 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.41 on epoch=399
06/01/2022 03:41:41 - INFO - __main__ - Global step 1600 Train loss 1.31 Classification-F1 0.15295815295815296 on epoch=399
06/01/2022 03:41:42 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.08 on epoch=402
06/01/2022 03:41:44 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.20 on epoch=404
06/01/2022 03:41:45 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.34 on epoch=407
06/01/2022 03:41:46 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.10 on epoch=409
06/01/2022 03:41:47 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.17 on epoch=412
06/01/2022 03:41:48 - INFO - __main__ - Global step 1650 Train loss 1.18 Classification-F1 0.1 on epoch=412
06/01/2022 03:41:49 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.14 on epoch=414
06/01/2022 03:41:50 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.23 on epoch=417
06/01/2022 03:41:52 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.18 on epoch=419
06/01/2022 03:41:53 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.22 on epoch=422
06/01/2022 03:41:54 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.18 on epoch=424
06/01/2022 03:41:55 - INFO - __main__ - Global step 1700 Train loss 1.19 Classification-F1 0.1 on epoch=424
06/01/2022 03:41:56 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.32 on epoch=427
06/01/2022 03:41:57 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.17 on epoch=429
06/01/2022 03:41:58 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.25 on epoch=432
06/01/2022 03:41:59 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.22 on epoch=434
06/01/2022 03:42:01 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.08 on epoch=437
06/01/2022 03:42:01 - INFO - __main__ - Global step 1750 Train loss 1.20 Classification-F1 0.1 on epoch=437
06/01/2022 03:42:02 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.10 on epoch=439
06/01/2022 03:42:04 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.30 on epoch=442
06/01/2022 03:42:05 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.10 on epoch=444
06/01/2022 03:42:06 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.24 on epoch=447
06/01/2022 03:42:07 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.17 on epoch=449
06/01/2022 03:42:08 - INFO - __main__ - Global step 1800 Train loss 1.18 Classification-F1 0.10126582278481013 on epoch=449
06/01/2022 03:42:09 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.01 on epoch=452
06/01/2022 03:42:10 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.17 on epoch=454
06/01/2022 03:42:11 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.15 on epoch=457
06/01/2022 03:42:13 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.15 on epoch=459
06/01/2022 03:42:14 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.14 on epoch=462
06/01/2022 03:42:14 - INFO - __main__ - Global step 1850 Train loss 1.12 Classification-F1 0.1 on epoch=462
06/01/2022 03:42:16 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.08 on epoch=464
06/01/2022 03:42:17 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.22 on epoch=467
06/01/2022 03:42:18 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.18 on epoch=469
06/01/2022 03:42:19 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.16 on epoch=472
06/01/2022 03:42:21 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.16 on epoch=474
06/01/2022 03:42:21 - INFO - __main__ - Global step 1900 Train loss 1.16 Classification-F1 0.17809523809523808 on epoch=474
06/01/2022 03:42:22 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.15 on epoch=477
06/01/2022 03:42:24 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.23 on epoch=479
06/01/2022 03:42:25 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.17 on epoch=482
06/01/2022 03:42:26 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.03 on epoch=484
06/01/2022 03:42:27 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.10 on epoch=487
06/01/2022 03:42:28 - INFO - __main__ - Global step 1950 Train loss 1.14 Classification-F1 0.1825396825396825 on epoch=487
06/01/2022 03:42:29 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.05 on epoch=489
06/01/2022 03:42:30 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.19 on epoch=492
06/01/2022 03:42:31 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.12 on epoch=494
06/01/2022 03:42:33 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.04 on epoch=497
06/01/2022 03:42:34 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.16 on epoch=499
06/01/2022 03:42:34 - INFO - __main__ - Global step 2000 Train loss 1.11 Classification-F1 0.13067758749069247 on epoch=499
06/01/2022 03:42:36 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.02 on epoch=502
06/01/2022 03:42:37 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.20 on epoch=504
06/01/2022 03:42:38 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.12 on epoch=507
06/01/2022 03:42:39 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.18 on epoch=509
06/01/2022 03:42:41 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.18 on epoch=512
06/01/2022 03:42:41 - INFO - __main__ - Global step 2050 Train loss 1.14 Classification-F1 0.1238095238095238 on epoch=512
06/01/2022 03:42:42 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.08 on epoch=514
06/01/2022 03:42:44 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.08 on epoch=517
06/01/2022 03:42:45 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.09 on epoch=519
06/01/2022 03:42:46 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.12 on epoch=522
06/01/2022 03:42:48 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.05 on epoch=524
06/01/2022 03:42:48 - INFO - __main__ - Global step 2100 Train loss 1.09 Classification-F1 0.1134453781512605 on epoch=524
06/01/2022 03:42:49 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.07 on epoch=527
06/01/2022 03:42:51 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.93 on epoch=529
06/01/2022 03:42:52 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.99 on epoch=532
06/01/2022 03:42:53 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.11 on epoch=534
06/01/2022 03:42:54 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.06 on epoch=537
06/01/2022 03:42:55 - INFO - __main__ - Global step 2150 Train loss 1.03 Classification-F1 0.131328171530673 on epoch=537
06/01/2022 03:42:56 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.06 on epoch=539
06/01/2022 03:42:57 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.18 on epoch=542
06/01/2022 03:42:59 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.98 on epoch=544
06/01/2022 03:43:00 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.14 on epoch=547
06/01/2022 03:43:01 - INFO - __main__ - Step 2200 Global step 2200 Train loss 1.01 on epoch=549
06/01/2022 03:43:02 - INFO - __main__ - Global step 2200 Train loss 1.07 Classification-F1 0.11805555555555555 on epoch=549
06/01/2022 03:43:03 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.07 on epoch=552
06/01/2022 03:43:04 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.11 on epoch=554
06/01/2022 03:43:05 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.11 on epoch=557
06/01/2022 03:43:07 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.05 on epoch=559
06/01/2022 03:43:08 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.02 on epoch=562
06/01/2022 03:43:08 - INFO - __main__ - Global step 2250 Train loss 1.07 Classification-F1 0.1500341763499658 on epoch=562
06/01/2022 03:43:10 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.04 on epoch=564
06/01/2022 03:43:11 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.14 on epoch=567
06/01/2022 03:43:12 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.11 on epoch=569
06/01/2022 03:43:13 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.18 on epoch=572
06/01/2022 03:43:15 - INFO - __main__ - Step 2300 Global step 2300 Train loss 1.06 on epoch=574
06/01/2022 03:43:15 - INFO - __main__ - Global step 2300 Train loss 1.10 Classification-F1 0.17424242424242425 on epoch=574
06/01/2022 03:43:16 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.08 on epoch=577
06/01/2022 03:43:18 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.07 on epoch=579
06/01/2022 03:43:19 - INFO - __main__ - Step 2330 Global step 2330 Train loss 1.08 on epoch=582
06/01/2022 03:43:20 - INFO - __main__ - Step 2340 Global step 2340 Train loss 1.08 on epoch=584
06/01/2022 03:43:21 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.06 on epoch=587
06/01/2022 03:43:22 - INFO - __main__ - Global step 2350 Train loss 1.08 Classification-F1 0.09493670886075949 on epoch=587
06/01/2022 03:43:23 - INFO - __main__ - Step 2360 Global step 2360 Train loss 1.08 on epoch=589
06/01/2022 03:43:25 - INFO - __main__ - Step 2370 Global step 2370 Train loss 1.13 on epoch=592
06/01/2022 03:43:26 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.04 on epoch=594
06/01/2022 03:43:27 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.91 on epoch=597
06/01/2022 03:43:28 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.04 on epoch=599
06/01/2022 03:43:29 - INFO - __main__ - Global step 2400 Train loss 1.04 Classification-F1 0.10135135135135136 on epoch=599
06/01/2022 03:43:30 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.12 on epoch=602
06/01/2022 03:43:31 - INFO - __main__ - Step 2420 Global step 2420 Train loss 1.05 on epoch=604
06/01/2022 03:43:33 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.09 on epoch=607
06/01/2022 03:43:34 - INFO - __main__ - Step 2440 Global step 2440 Train loss 1.08 on epoch=609
06/01/2022 03:43:35 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.05 on epoch=612
06/01/2022 03:43:36 - INFO - __main__ - Global step 2450 Train loss 1.08 Classification-F1 0.09615384615384615 on epoch=612
06/01/2022 03:43:37 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.02 on epoch=614
06/01/2022 03:43:38 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.09 on epoch=617
06/01/2022 03:43:39 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.97 on epoch=619
06/01/2022 03:43:40 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.00 on epoch=622
06/01/2022 03:43:42 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.90 on epoch=624
06/01/2022 03:43:42 - INFO - __main__ - Global step 2500 Train loss 1.00 Classification-F1 0.09493670886075949 on epoch=624
06/01/2022 03:43:43 - INFO - __main__ - Step 2510 Global step 2510 Train loss 1.03 on epoch=627
06/01/2022 03:43:45 - INFO - __main__ - Step 2520 Global step 2520 Train loss 1.09 on epoch=629
06/01/2022 03:43:46 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.03 on epoch=632
06/01/2022 03:43:47 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.97 on epoch=634
06/01/2022 03:43:48 - INFO - __main__ - Step 2550 Global step 2550 Train loss 1.04 on epoch=637
06/01/2022 03:43:49 - INFO - __main__ - Global step 2550 Train loss 1.03 Classification-F1 0.15584415584415584 on epoch=637
06/01/2022 03:43:50 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.94 on epoch=639
06/01/2022 03:43:51 - INFO - __main__ - Step 2570 Global step 2570 Train loss 1.10 on epoch=642
06/01/2022 03:43:53 - INFO - __main__ - Step 2580 Global step 2580 Train loss 1.08 on epoch=644
06/01/2022 03:43:54 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.09 on epoch=647
06/01/2022 03:43:55 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.87 on epoch=649
06/01/2022 03:43:56 - INFO - __main__ - Global step 2600 Train loss 1.02 Classification-F1 0.13034188034188032 on epoch=649
06/01/2022 03:43:57 - INFO - __main__ - Step 2610 Global step 2610 Train loss 1.05 on epoch=652
06/01/2022 03:43:58 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.98 on epoch=654
06/01/2022 03:43:59 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.99 on epoch=657
06/01/2022 03:44:01 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.00 on epoch=659
06/01/2022 03:44:02 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.01 on epoch=662
06/01/2022 03:44:03 - INFO - __main__ - Global step 2650 Train loss 1.01 Classification-F1 0.11078022632519356 on epoch=662
06/01/2022 03:44:04 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.98 on epoch=664
06/01/2022 03:44:05 - INFO - __main__ - Step 2670 Global step 2670 Train loss 1.02 on epoch=667
06/01/2022 03:44:06 - INFO - __main__ - Step 2680 Global step 2680 Train loss 1.05 on epoch=669
06/01/2022 03:44:07 - INFO - __main__ - Step 2690 Global step 2690 Train loss 1.09 on epoch=672
06/01/2022 03:44:09 - INFO - __main__ - Step 2700 Global step 2700 Train loss 1.05 on epoch=674
06/01/2022 03:44:09 - INFO - __main__ - Global step 2700 Train loss 1.04 Classification-F1 0.21286031042128603 on epoch=674
06/01/2022 03:44:11 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.01 on epoch=677
06/01/2022 03:44:12 - INFO - __main__ - Step 2720 Global step 2720 Train loss 1.11 on epoch=679
06/01/2022 03:44:13 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.96 on epoch=682
06/01/2022 03:44:14 - INFO - __main__ - Step 2740 Global step 2740 Train loss 1.09 on epoch=684
06/01/2022 03:44:15 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.93 on epoch=687
06/01/2022 03:44:16 - INFO - __main__ - Global step 2750 Train loss 1.02 Classification-F1 0.1 on epoch=687
06/01/2022 03:44:17 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.03 on epoch=689
06/01/2022 03:44:18 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.00 on epoch=692
06/01/2022 03:44:20 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.93 on epoch=694
06/01/2022 03:44:21 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.97 on epoch=697
06/01/2022 03:44:22 - INFO - __main__ - Step 2800 Global step 2800 Train loss 1.05 on epoch=699
06/01/2022 03:44:23 - INFO - __main__ - Global step 2800 Train loss 0.99 Classification-F1 0.23444444444444448 on epoch=699
06/01/2022 03:44:23 - INFO - __main__ - Saving model with best Classification-F1: 0.21560846560846564 -> 0.23444444444444448 on epoch=699, global_step=2800
06/01/2022 03:44:24 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.03 on epoch=702
06/01/2022 03:44:25 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.99 on epoch=704
06/01/2022 03:44:27 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.98 on epoch=707
06/01/2022 03:44:28 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.96 on epoch=709
06/01/2022 03:44:30 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.95 on epoch=712
06/01/2022 03:44:30 - INFO - __main__ - Global step 2850 Train loss 0.98 Classification-F1 0.18218623481781374 on epoch=712
06/01/2022 03:44:32 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.98 on epoch=714
06/01/2022 03:44:33 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.98 on epoch=717
06/01/2022 03:44:34 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.94 on epoch=719
06/01/2022 03:44:36 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.05 on epoch=722
06/01/2022 03:44:37 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.00 on epoch=724
06/01/2022 03:44:38 - INFO - __main__ - Global step 2900 Train loss 0.99 Classification-F1 0.13333333333333333 on epoch=724
06/01/2022 03:44:39 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.02 on epoch=727
06/01/2022 03:44:41 - INFO - __main__ - Step 2920 Global step 2920 Train loss 1.05 on epoch=729
06/01/2022 03:44:42 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.96 on epoch=732
06/01/2022 03:44:43 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.94 on epoch=734
06/01/2022 03:44:45 - INFO - __main__ - Step 2950 Global step 2950 Train loss 1.04 on epoch=737
06/01/2022 03:44:45 - INFO - __main__ - Global step 2950 Train loss 1.00 Classification-F1 0.19778549717759447 on epoch=737
06/01/2022 03:44:47 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.93 on epoch=739
06/01/2022 03:44:48 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.04 on epoch=742
06/01/2022 03:44:49 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.96 on epoch=744
06/01/2022 03:44:51 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.93 on epoch=747
06/01/2022 03:44:52 - INFO - __main__ - Step 3000 Global step 3000 Train loss 1.05 on epoch=749
06/01/2022 03:44:53 - INFO - __main__ - Global step 3000 Train loss 0.98 Classification-F1 0.11805555555555555 on epoch=749
06/01/2022 03:44:53 - INFO - __main__ - save last model!
06/01/2022 03:44:53 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/01/2022 03:44:53 - INFO - __main__ - Start tokenizing ... 5509 instances
06/01/2022 03:44:53 - INFO - __main__ - Printing 3 examples
06/01/2022 03:44:53 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/01/2022 03:44:53 - INFO - __main__ - ['others']
06/01/2022 03:44:53 - INFO - __main__ -  [emo] what you like very little things ok
06/01/2022 03:44:53 - INFO - __main__ - ['others']
06/01/2022 03:44:53 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/01/2022 03:44:53 - INFO - __main__ - ['others']
06/01/2022 03:44:53 - INFO - __main__ - Tokenizing Input ...
06/01/2022 03:44:53 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 03:44:53 - INFO - __main__ - Printing 3 examples
06/01/2022 03:44:53 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/01/2022 03:44:53 - INFO - __main__ - ['sad']
06/01/2022 03:44:53 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/01/2022 03:44:53 - INFO - __main__ - ['sad']
06/01/2022 03:44:53 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/01/2022 03:44:53 - INFO - __main__ - ['sad']
06/01/2022 03:44:53 - INFO - __main__ - Tokenizing Input ...
06/01/2022 03:44:53 - INFO - __main__ - Tokenizing Output ...
06/01/2022 03:44:53 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 03:44:53 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 03:44:53 - INFO - __main__ - Printing 3 examples
06/01/2022 03:44:53 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
06/01/2022 03:44:53 - INFO - __main__ - ['sad']
06/01/2022 03:44:53 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
06/01/2022 03:44:53 - INFO - __main__ - ['sad']
06/01/2022 03:44:53 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
06/01/2022 03:44:53 - INFO - __main__ - ['sad']
06/01/2022 03:44:53 - INFO - __main__ - Tokenizing Input ...
06/01/2022 03:44:53 - INFO - __main__ - Tokenizing Output ...
06/01/2022 03:44:54 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 03:44:55 - INFO - __main__ - Tokenizing Output ...
06/01/2022 03:44:59 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 03:44:59 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/01/2022 03:44:59 - INFO - __main__ - Starting training!
06/01/2022 03:45:00 - INFO - __main__ - Loaded 5509 examples from test data
06/01/2022 03:45:44 - INFO - __main__ - Saved prediction in models/T5-base-reptile-cls2cls-3e-5-2-5000-5e-1-10/singletask-emo/emo_16_21_0.3_8_predictions.txt
06/01/2022 03:45:44 - INFO - __main__ - Classification-F1 on test data: 0.2180
06/01/2022 03:45:44 - INFO - __main__ - prefix=emo_16_21, lr=0.3, bsz=8, dev_performance=0.23444444444444448, test_performance=0.21803137791957744
06/01/2022 03:45:44 - INFO - __main__ - Running ... prefix=emo_16_21, lr=0.2, bsz=8 ...
06/01/2022 03:45:45 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 03:45:45 - INFO - __main__ - Printing 3 examples
06/01/2022 03:45:45 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/01/2022 03:45:45 - INFO - __main__ - ['sad']
06/01/2022 03:45:45 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/01/2022 03:45:45 - INFO - __main__ - ['sad']
06/01/2022 03:45:45 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/01/2022 03:45:45 - INFO - __main__ - ['sad']
06/01/2022 03:45:45 - INFO - __main__ - Tokenizing Input ...
06/01/2022 03:45:45 - INFO - __main__ - Tokenizing Output ...
06/01/2022 03:45:45 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 03:45:45 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 03:45:45 - INFO - __main__ - Printing 3 examples
06/01/2022 03:45:45 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
06/01/2022 03:45:45 - INFO - __main__ - ['sad']
06/01/2022 03:45:45 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
06/01/2022 03:45:45 - INFO - __main__ - ['sad']
06/01/2022 03:45:45 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
06/01/2022 03:45:45 - INFO - __main__ - ['sad']
06/01/2022 03:45:45 - INFO - __main__ - Tokenizing Input ...
06/01/2022 03:45:45 - INFO - __main__ - Tokenizing Output ...
06/01/2022 03:45:45 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 03:45:51 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 03:45:51 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/01/2022 03:45:51 - INFO - __main__ - Starting training!
06/01/2022 03:45:53 - INFO - __main__ - Step 10 Global step 10 Train loss 8.76 on epoch=2
06/01/2022 03:45:54 - INFO - __main__ - Step 20 Global step 20 Train loss 8.77 on epoch=4
06/01/2022 03:45:55 - INFO - __main__ - Step 30 Global step 30 Train loss 8.71 on epoch=7
06/01/2022 03:45:57 - INFO - __main__ - Step 40 Global step 40 Train loss 8.69 on epoch=9
06/01/2022 03:45:58 - INFO - __main__ - Step 50 Global step 50 Train loss 8.67 on epoch=12
06/01/2022 03:46:04 - INFO - __main__ - Global step 50 Train loss 8.72 Classification-F1 0.0 on epoch=12
06/01/2022 03:46:04 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
06/01/2022 03:46:05 - INFO - __main__ - Step 60 Global step 60 Train loss 8.59 on epoch=14
06/01/2022 03:46:07 - INFO - __main__ - Step 70 Global step 70 Train loss 8.45 on epoch=17
06/01/2022 03:46:08 - INFO - __main__ - Step 80 Global step 80 Train loss 8.57 on epoch=19
06/01/2022 03:46:09 - INFO - __main__ - Step 90 Global step 90 Train loss 8.54 on epoch=22
06/01/2022 03:46:10 - INFO - __main__ - Step 100 Global step 100 Train loss 8.58 on epoch=24
06/01/2022 03:46:15 - INFO - __main__ - Global step 100 Train loss 8.55 Classification-F1 0.0 on epoch=24
06/01/2022 03:46:16 - INFO - __main__ - Step 110 Global step 110 Train loss 8.53 on epoch=27
06/01/2022 03:46:17 - INFO - __main__ - Step 120 Global step 120 Train loss 8.50 on epoch=29
06/01/2022 03:46:19 - INFO - __main__ - Step 130 Global step 130 Train loss 8.39 on epoch=32
06/01/2022 03:46:20 - INFO - __main__ - Step 140 Global step 140 Train loss 8.45 on epoch=34
06/01/2022 03:46:21 - INFO - __main__ - Step 150 Global step 150 Train loss 8.43 on epoch=37
06/01/2022 03:46:28 - INFO - __main__ - Global step 150 Train loss 8.46 Classification-F1 0.0 on epoch=37
06/01/2022 03:46:29 - INFO - __main__ - Step 160 Global step 160 Train loss 8.46 on epoch=39
06/01/2022 03:46:31 - INFO - __main__ - Step 170 Global step 170 Train loss 8.38 on epoch=42
06/01/2022 03:46:32 - INFO - __main__ - Step 180 Global step 180 Train loss 8.23 on epoch=44
06/01/2022 03:46:33 - INFO - __main__ - Step 190 Global step 190 Train loss 8.25 on epoch=47
06/01/2022 03:46:34 - INFO - __main__ - Step 200 Global step 200 Train loss 8.27 on epoch=49
06/01/2022 03:46:40 - INFO - __main__ - Global step 200 Train loss 8.32 Classification-F1 0.0 on epoch=49
06/01/2022 03:46:41 - INFO - __main__ - Step 210 Global step 210 Train loss 8.24 on epoch=52
06/01/2022 03:46:42 - INFO - __main__ - Step 220 Global step 220 Train loss 8.25 on epoch=54
06/01/2022 03:46:44 - INFO - __main__ - Step 230 Global step 230 Train loss 8.18 on epoch=57
06/01/2022 03:46:45 - INFO - __main__ - Step 240 Global step 240 Train loss 8.11 on epoch=59
06/01/2022 03:46:46 - INFO - __main__ - Step 250 Global step 250 Train loss 8.08 on epoch=62
06/01/2022 03:46:54 - INFO - __main__ - Global step 250 Train loss 8.17 Classification-F1 0.0 on epoch=62
06/01/2022 03:46:55 - INFO - __main__ - Step 260 Global step 260 Train loss 8.04 on epoch=64
06/01/2022 03:46:56 - INFO - __main__ - Step 270 Global step 270 Train loss 8.07 on epoch=67
06/01/2022 03:46:57 - INFO - __main__ - Step 280 Global step 280 Train loss 8.06 on epoch=69
06/01/2022 03:46:59 - INFO - __main__ - Step 290 Global step 290 Train loss 8.06 on epoch=72
06/01/2022 03:47:00 - INFO - __main__ - Step 300 Global step 300 Train loss 7.87 on epoch=74
06/01/2022 03:47:09 - INFO - __main__ - Global step 300 Train loss 8.02 Classification-F1 0.0 on epoch=74
06/01/2022 03:47:10 - INFO - __main__ - Step 310 Global step 310 Train loss 7.75 on epoch=77
06/01/2022 03:47:11 - INFO - __main__ - Step 320 Global step 320 Train loss 7.81 on epoch=79
06/01/2022 03:47:13 - INFO - __main__ - Step 330 Global step 330 Train loss 7.83 on epoch=82
06/01/2022 03:47:14 - INFO - __main__ - Step 340 Global step 340 Train loss 7.70 on epoch=84
06/01/2022 03:47:15 - INFO - __main__ - Step 350 Global step 350 Train loss 7.69 on epoch=87
06/01/2022 03:47:25 - INFO - __main__ - Global step 350 Train loss 7.75 Classification-F1 0.0 on epoch=87
06/01/2022 03:47:26 - INFO - __main__ - Step 360 Global step 360 Train loss 7.52 on epoch=89
06/01/2022 03:47:27 - INFO - __main__ - Step 370 Global step 370 Train loss 7.58 on epoch=92
06/01/2022 03:47:28 - INFO - __main__ - Step 380 Global step 380 Train loss 7.60 on epoch=94
06/01/2022 03:47:30 - INFO - __main__ - Step 390 Global step 390 Train loss 7.48 on epoch=97
06/01/2022 03:47:31 - INFO - __main__ - Step 400 Global step 400 Train loss 7.48 on epoch=99
06/01/2022 03:47:44 - INFO - __main__ - Global step 400 Train loss 7.53 Classification-F1 0.0 on epoch=99
06/01/2022 03:47:45 - INFO - __main__ - Step 410 Global step 410 Train loss 7.36 on epoch=102
06/01/2022 03:47:46 - INFO - __main__ - Step 420 Global step 420 Train loss 7.29 on epoch=104
06/01/2022 03:47:48 - INFO - __main__ - Step 430 Global step 430 Train loss 7.10 on epoch=107
06/01/2022 03:47:49 - INFO - __main__ - Step 440 Global step 440 Train loss 7.22 on epoch=109
06/01/2022 03:47:50 - INFO - __main__ - Step 450 Global step 450 Train loss 7.27 on epoch=112
06/01/2022 03:47:53 - INFO - __main__ - Global step 450 Train loss 7.25 Classification-F1 0.0 on epoch=112
06/01/2022 03:47:55 - INFO - __main__ - Step 460 Global step 460 Train loss 7.09 on epoch=114
06/01/2022 03:47:56 - INFO - __main__ - Step 470 Global step 470 Train loss 7.09 on epoch=117
06/01/2022 03:47:57 - INFO - __main__ - Step 480 Global step 480 Train loss 7.04 on epoch=119
06/01/2022 03:47:59 - INFO - __main__ - Step 490 Global step 490 Train loss 7.13 on epoch=122
06/01/2022 03:48:00 - INFO - __main__ - Step 500 Global step 500 Train loss 6.98 on epoch=124
06/01/2022 03:48:04 - INFO - __main__ - Global step 500 Train loss 7.07 Classification-F1 0.0 on epoch=124
06/01/2022 03:48:06 - INFO - __main__ - Step 510 Global step 510 Train loss 6.96 on epoch=127
06/01/2022 03:48:07 - INFO - __main__ - Step 520 Global step 520 Train loss 6.91 on epoch=129
06/01/2022 03:48:08 - INFO - __main__ - Step 530 Global step 530 Train loss 6.83 on epoch=132
06/01/2022 03:48:10 - INFO - __main__ - Step 540 Global step 540 Train loss 6.89 on epoch=134
06/01/2022 03:48:11 - INFO - __main__ - Step 550 Global step 550 Train loss 6.67 on epoch=137
06/01/2022 03:48:16 - INFO - __main__ - Global step 550 Train loss 6.85 Classification-F1 0.0 on epoch=137
06/01/2022 03:48:17 - INFO - __main__ - Step 560 Global step 560 Train loss 6.69 on epoch=139
06/01/2022 03:48:19 - INFO - __main__ - Step 570 Global step 570 Train loss 6.67 on epoch=142
06/01/2022 03:48:20 - INFO - __main__ - Step 580 Global step 580 Train loss 6.66 on epoch=144
06/01/2022 03:48:21 - INFO - __main__ - Step 590 Global step 590 Train loss 6.76 on epoch=147
06/01/2022 03:48:23 - INFO - __main__ - Step 600 Global step 600 Train loss 6.51 on epoch=149
06/01/2022 03:48:32 - INFO - __main__ - Global step 600 Train loss 6.66 Classification-F1 0.0 on epoch=149
06/01/2022 03:48:33 - INFO - __main__ - Step 610 Global step 610 Train loss 6.50 on epoch=152
06/01/2022 03:48:34 - INFO - __main__ - Step 620 Global step 620 Train loss 6.57 on epoch=154
06/01/2022 03:48:35 - INFO - __main__ - Step 630 Global step 630 Train loss 6.45 on epoch=157
06/01/2022 03:48:37 - INFO - __main__ - Step 640 Global step 640 Train loss 6.44 on epoch=159
06/01/2022 03:48:38 - INFO - __main__ - Step 650 Global step 650 Train loss 6.47 on epoch=162
06/01/2022 03:48:42 - INFO - __main__ - Global step 650 Train loss 6.49 Classification-F1 0.0 on epoch=162
06/01/2022 03:48:44 - INFO - __main__ - Step 660 Global step 660 Train loss 6.32 on epoch=164
06/01/2022 03:48:45 - INFO - __main__ - Step 670 Global step 670 Train loss 6.37 on epoch=167
06/01/2022 03:48:46 - INFO - __main__ - Step 680 Global step 680 Train loss 6.17 on epoch=169
06/01/2022 03:48:48 - INFO - __main__ - Step 690 Global step 690 Train loss 6.27 on epoch=172
06/01/2022 03:48:49 - INFO - __main__ - Step 700 Global step 700 Train loss 6.16 on epoch=174
06/01/2022 03:48:58 - INFO - __main__ - Global step 700 Train loss 6.26 Classification-F1 0.0 on epoch=174
06/01/2022 03:48:59 - INFO - __main__ - Step 710 Global step 710 Train loss 6.22 on epoch=177
06/01/2022 03:49:01 - INFO - __main__ - Step 720 Global step 720 Train loss 5.96 on epoch=179
06/01/2022 03:49:02 - INFO - __main__ - Step 730 Global step 730 Train loss 6.03 on epoch=182
06/01/2022 03:49:03 - INFO - __main__ - Step 740 Global step 740 Train loss 6.03 on epoch=184
06/01/2022 03:49:04 - INFO - __main__ - Step 750 Global step 750 Train loss 6.22 on epoch=187
06/01/2022 03:49:11 - INFO - __main__ - Global step 750 Train loss 6.09 Classification-F1 0.0 on epoch=187
06/01/2022 03:49:12 - INFO - __main__ - Step 760 Global step 760 Train loss 6.08 on epoch=189
06/01/2022 03:49:13 - INFO - __main__ - Step 770 Global step 770 Train loss 6.08 on epoch=192
06/01/2022 03:49:14 - INFO - __main__ - Step 780 Global step 780 Train loss 5.97 on epoch=194
06/01/2022 03:49:16 - INFO - __main__ - Step 790 Global step 790 Train loss 5.81 on epoch=197
06/01/2022 03:49:17 - INFO - __main__ - Step 800 Global step 800 Train loss 5.55 on epoch=199
06/01/2022 03:49:23 - INFO - __main__ - Global step 800 Train loss 5.90 Classification-F1 0.0 on epoch=199
06/01/2022 03:49:24 - INFO - __main__ - Step 810 Global step 810 Train loss 5.74 on epoch=202
06/01/2022 03:49:26 - INFO - __main__ - Step 820 Global step 820 Train loss 5.68 on epoch=204
06/01/2022 03:49:27 - INFO - __main__ - Step 830 Global step 830 Train loss 5.80 on epoch=207
06/01/2022 03:49:28 - INFO - __main__ - Step 840 Global step 840 Train loss 5.66 on epoch=209
06/01/2022 03:49:30 - INFO - __main__ - Step 850 Global step 850 Train loss 5.66 on epoch=212
06/01/2022 03:49:34 - INFO - __main__ - Global step 850 Train loss 5.71 Classification-F1 0.0 on epoch=212
06/01/2022 03:49:35 - INFO - __main__ - Step 860 Global step 860 Train loss 5.78 on epoch=214
06/01/2022 03:49:37 - INFO - __main__ - Step 870 Global step 870 Train loss 5.78 on epoch=217
06/01/2022 03:49:38 - INFO - __main__ - Step 880 Global step 880 Train loss 5.35 on epoch=219
06/01/2022 03:49:39 - INFO - __main__ - Step 890 Global step 890 Train loss 5.50 on epoch=222
06/01/2022 03:49:41 - INFO - __main__ - Step 900 Global step 900 Train loss 5.55 on epoch=224
06/01/2022 03:49:49 - INFO - __main__ - Global step 900 Train loss 5.59 Classification-F1 0.0 on epoch=224
06/01/2022 03:49:50 - INFO - __main__ - Step 910 Global step 910 Train loss 5.47 on epoch=227
06/01/2022 03:49:52 - INFO - __main__ - Step 920 Global step 920 Train loss 5.38 on epoch=229
06/01/2022 03:49:53 - INFO - __main__ - Step 930 Global step 930 Train loss 5.46 on epoch=232
06/01/2022 03:49:54 - INFO - __main__ - Step 940 Global step 940 Train loss 5.24 on epoch=234
06/01/2022 03:49:56 - INFO - __main__ - Step 950 Global step 950 Train loss 5.33 on epoch=237
06/01/2022 03:50:06 - INFO - __main__ - Global step 950 Train loss 5.38 Classification-F1 0.0 on epoch=237
06/01/2022 03:50:07 - INFO - __main__ - Step 960 Global step 960 Train loss 5.28 on epoch=239
06/01/2022 03:50:09 - INFO - __main__ - Step 970 Global step 970 Train loss 5.30 on epoch=242
06/01/2022 03:50:10 - INFO - __main__ - Step 980 Global step 980 Train loss 4.98 on epoch=244
06/01/2022 03:50:11 - INFO - __main__ - Step 990 Global step 990 Train loss 5.12 on epoch=247
06/01/2022 03:50:13 - INFO - __main__ - Step 1000 Global step 1000 Train loss 5.03 on epoch=249
06/01/2022 03:50:24 - INFO - __main__ - Global step 1000 Train loss 5.14 Classification-F1 0.0 on epoch=249
06/01/2022 03:50:25 - INFO - __main__ - Step 1010 Global step 1010 Train loss 5.06 on epoch=252
06/01/2022 03:50:26 - INFO - __main__ - Step 1020 Global step 1020 Train loss 4.89 on epoch=254
06/01/2022 03:50:27 - INFO - __main__ - Step 1030 Global step 1030 Train loss 5.12 on epoch=257
06/01/2022 03:50:29 - INFO - __main__ - Step 1040 Global step 1040 Train loss 5.03 on epoch=259
06/01/2022 03:50:30 - INFO - __main__ - Step 1050 Global step 1050 Train loss 4.94 on epoch=262
06/01/2022 03:50:40 - INFO - __main__ - Global step 1050 Train loss 5.01 Classification-F1 0.0 on epoch=262
06/01/2022 03:50:42 - INFO - __main__ - Step 1060 Global step 1060 Train loss 4.87 on epoch=264
06/01/2022 03:50:43 - INFO - __main__ - Step 1070 Global step 1070 Train loss 4.75 on epoch=267
06/01/2022 03:50:44 - INFO - __main__ - Step 1080 Global step 1080 Train loss 4.75 on epoch=269
06/01/2022 03:50:45 - INFO - __main__ - Step 1090 Global step 1090 Train loss 4.74 on epoch=272
06/01/2022 03:50:47 - INFO - __main__ - Step 1100 Global step 1100 Train loss 4.64 on epoch=274
06/01/2022 03:51:01 - INFO - __main__ - Global step 1100 Train loss 4.75 Classification-F1 0.0 on epoch=274
06/01/2022 03:51:02 - INFO - __main__ - Step 1110 Global step 1110 Train loss 4.84 on epoch=277
06/01/2022 03:51:04 - INFO - __main__ - Step 1120 Global step 1120 Train loss 4.58 on epoch=279
06/01/2022 03:51:05 - INFO - __main__ - Step 1130 Global step 1130 Train loss 4.67 on epoch=282
06/01/2022 03:51:06 - INFO - __main__ - Step 1140 Global step 1140 Train loss 4.42 on epoch=284
06/01/2022 03:51:08 - INFO - __main__ - Step 1150 Global step 1150 Train loss 4.70 on epoch=287
06/01/2022 03:51:26 - INFO - __main__ - Global step 1150 Train loss 4.64 Classification-F1 0.0 on epoch=287
06/01/2022 03:51:27 - INFO - __main__ - Step 1160 Global step 1160 Train loss 4.55 on epoch=289
06/01/2022 03:51:28 - INFO - __main__ - Step 1170 Global step 1170 Train loss 4.65 on epoch=292
06/01/2022 03:51:29 - INFO - __main__ - Step 1180 Global step 1180 Train loss 4.36 on epoch=294
06/01/2022 03:51:31 - INFO - __main__ - Step 1190 Global step 1190 Train loss 4.50 on epoch=297
06/01/2022 03:51:32 - INFO - __main__ - Step 1200 Global step 1200 Train loss 4.45 on epoch=299
06/01/2022 03:51:40 - INFO - __main__ - Global step 1200 Train loss 4.50 Classification-F1 0.0 on epoch=299
06/01/2022 03:51:41 - INFO - __main__ - Step 1210 Global step 1210 Train loss 4.48 on epoch=302
06/01/2022 03:51:42 - INFO - __main__ - Step 1220 Global step 1220 Train loss 4.42 on epoch=304
06/01/2022 03:51:44 - INFO - __main__ - Step 1230 Global step 1230 Train loss 4.24 on epoch=307
06/01/2022 03:51:45 - INFO - __main__ - Step 1240 Global step 1240 Train loss 4.31 on epoch=309
06/01/2022 03:51:46 - INFO - __main__ - Step 1250 Global step 1250 Train loss 4.37 on epoch=312
06/01/2022 03:51:52 - INFO - __main__ - Global step 1250 Train loss 4.36 Classification-F1 0.0 on epoch=312
06/01/2022 03:51:53 - INFO - __main__ - Step 1260 Global step 1260 Train loss 4.07 on epoch=314
06/01/2022 03:51:55 - INFO - __main__ - Step 1270 Global step 1270 Train loss 4.28 on epoch=317
06/01/2022 03:51:56 - INFO - __main__ - Step 1280 Global step 1280 Train loss 4.21 on epoch=319
06/01/2022 03:51:57 - INFO - __main__ - Step 1290 Global step 1290 Train loss 4.11 on epoch=322
06/01/2022 03:51:59 - INFO - __main__ - Step 1300 Global step 1300 Train loss 4.06 on epoch=324
06/01/2022 03:52:06 - INFO - __main__ - Global step 1300 Train loss 4.15 Classification-F1 0.0 on epoch=324
06/01/2022 03:52:07 - INFO - __main__ - Step 1310 Global step 1310 Train loss 4.19 on epoch=327
06/01/2022 03:52:09 - INFO - __main__ - Step 1320 Global step 1320 Train loss 4.10 on epoch=329
06/01/2022 03:52:10 - INFO - __main__ - Step 1330 Global step 1330 Train loss 4.21 on epoch=332
06/01/2022 03:52:11 - INFO - __main__ - Step 1340 Global step 1340 Train loss 4.13 on epoch=334
06/01/2022 03:52:12 - INFO - __main__ - Step 1350 Global step 1350 Train loss 3.99 on epoch=337
06/01/2022 03:52:21 - INFO - __main__ - Global step 1350 Train loss 4.13 Classification-F1 0.0 on epoch=337
06/01/2022 03:52:23 - INFO - __main__ - Step 1360 Global step 1360 Train loss 3.89 on epoch=339
06/01/2022 03:52:24 - INFO - __main__ - Step 1370 Global step 1370 Train loss 4.09 on epoch=342
06/01/2022 03:52:25 - INFO - __main__ - Step 1380 Global step 1380 Train loss 3.97 on epoch=344
06/01/2022 03:52:26 - INFO - __main__ - Step 1390 Global step 1390 Train loss 3.97 on epoch=347
06/01/2022 03:52:28 - INFO - __main__ - Step 1400 Global step 1400 Train loss 3.58 on epoch=349
06/01/2022 03:52:32 - INFO - __main__ - Global step 1400 Train loss 3.90 Classification-F1 0.0 on epoch=349
06/01/2022 03:52:34 - INFO - __main__ - Step 1410 Global step 1410 Train loss 3.80 on epoch=352
06/01/2022 03:52:35 - INFO - __main__ - Step 1420 Global step 1420 Train loss 3.82 on epoch=354
06/01/2022 03:52:36 - INFO - __main__ - Step 1430 Global step 1430 Train loss 3.89 on epoch=357
06/01/2022 03:52:38 - INFO - __main__ - Step 1440 Global step 1440 Train loss 3.79 on epoch=359
06/01/2022 03:52:39 - INFO - __main__ - Step 1450 Global step 1450 Train loss 3.70 on epoch=362
06/01/2022 03:52:40 - INFO - __main__ - Global step 1450 Train loss 3.80 Classification-F1 0.03636363636363636 on epoch=362
06/01/2022 03:52:40 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.03636363636363636 on epoch=362, global_step=1450
06/01/2022 03:52:41 - INFO - __main__ - Step 1460 Global step 1460 Train loss 3.63 on epoch=364
06/01/2022 03:52:42 - INFO - __main__ - Step 1470 Global step 1470 Train loss 3.66 on epoch=367
06/01/2022 03:52:44 - INFO - __main__ - Step 1480 Global step 1480 Train loss 3.57 on epoch=369
06/01/2022 03:52:45 - INFO - __main__ - Step 1490 Global step 1490 Train loss 3.64 on epoch=372
06/01/2022 03:52:46 - INFO - __main__ - Step 1500 Global step 1500 Train loss 3.66 on epoch=374
06/01/2022 03:52:47 - INFO - __main__ - Global step 1500 Train loss 3.63 Classification-F1 0.07792207792207792 on epoch=374
06/01/2022 03:52:47 - INFO - __main__ - Saving model with best Classification-F1: 0.03636363636363636 -> 0.07792207792207792 on epoch=374, global_step=1500
06/01/2022 03:52:48 - INFO - __main__ - Step 1510 Global step 1510 Train loss 3.52 on epoch=377
06/01/2022 03:52:50 - INFO - __main__ - Step 1520 Global step 1520 Train loss 3.51 on epoch=379
06/01/2022 03:52:51 - INFO - __main__ - Step 1530 Global step 1530 Train loss 3.75 on epoch=382
06/01/2022 03:52:52 - INFO - __main__ - Step 1540 Global step 1540 Train loss 3.55 on epoch=384
06/01/2022 03:52:53 - INFO - __main__ - Step 1550 Global step 1550 Train loss 3.55 on epoch=387
06/01/2022 03:52:55 - INFO - __main__ - Global step 1550 Train loss 3.58 Classification-F1 0.0810126582278481 on epoch=387
06/01/2022 03:52:55 - INFO - __main__ - Saving model with best Classification-F1: 0.07792207792207792 -> 0.0810126582278481 on epoch=387, global_step=1550
06/01/2022 03:52:57 - INFO - __main__ - Step 1560 Global step 1560 Train loss 3.46 on epoch=389
06/01/2022 03:52:58 - INFO - __main__ - Step 1570 Global step 1570 Train loss 3.47 on epoch=392
06/01/2022 03:52:59 - INFO - __main__ - Step 1580 Global step 1580 Train loss 3.31 on epoch=394
06/01/2022 03:53:00 - INFO - __main__ - Step 1590 Global step 1590 Train loss 3.39 on epoch=397
06/01/2022 03:53:02 - INFO - __main__ - Step 1600 Global step 1600 Train loss 3.49 on epoch=399
06/01/2022 03:53:03 - INFO - __main__ - Global step 1600 Train loss 3.42 Classification-F1 0.15526315789473685 on epoch=399
06/01/2022 03:53:03 - INFO - __main__ - Saving model with best Classification-F1: 0.0810126582278481 -> 0.15526315789473685 on epoch=399, global_step=1600
06/01/2022 03:53:04 - INFO - __main__ - Step 1610 Global step 1610 Train loss 3.44 on epoch=402
06/01/2022 03:53:06 - INFO - __main__ - Step 1620 Global step 1620 Train loss 3.31 on epoch=404
06/01/2022 03:53:07 - INFO - __main__ - Step 1630 Global step 1630 Train loss 3.36 on epoch=407
06/01/2022 03:53:08 - INFO - __main__ - Step 1640 Global step 1640 Train loss 3.25 on epoch=409
06/01/2022 03:53:09 - INFO - __main__ - Step 1650 Global step 1650 Train loss 3.18 on epoch=412
06/01/2022 03:53:10 - INFO - __main__ - Global step 1650 Train loss 3.31 Classification-F1 0.1 on epoch=412
06/01/2022 03:53:11 - INFO - __main__ - Step 1660 Global step 1660 Train loss 3.06 on epoch=414
06/01/2022 03:53:13 - INFO - __main__ - Step 1670 Global step 1670 Train loss 3.24 on epoch=417
06/01/2022 03:53:14 - INFO - __main__ - Step 1680 Global step 1680 Train loss 2.97 on epoch=419
06/01/2022 03:53:15 - INFO - __main__ - Step 1690 Global step 1690 Train loss 3.13 on epoch=422
06/01/2022 03:53:17 - INFO - __main__ - Step 1700 Global step 1700 Train loss 2.97 on epoch=424
06/01/2022 03:53:17 - INFO - __main__ - Global step 1700 Train loss 3.07 Classification-F1 0.1 on epoch=424
06/01/2022 03:53:19 - INFO - __main__ - Step 1710 Global step 1710 Train loss 3.00 on epoch=427
06/01/2022 03:53:20 - INFO - __main__ - Step 1720 Global step 1720 Train loss 2.70 on epoch=429
06/01/2022 03:53:21 - INFO - __main__ - Step 1730 Global step 1730 Train loss 2.86 on epoch=432
06/01/2022 03:53:23 - INFO - __main__ - Step 1740 Global step 1740 Train loss 2.78 on epoch=434
06/01/2022 03:53:24 - INFO - __main__ - Step 1750 Global step 1750 Train loss 2.77 on epoch=437
06/01/2022 03:53:25 - INFO - __main__ - Global step 1750 Train loss 2.82 Classification-F1 0.1 on epoch=437
06/01/2022 03:53:26 - INFO - __main__ - Step 1760 Global step 1760 Train loss 2.64 on epoch=439
06/01/2022 03:53:27 - INFO - __main__ - Step 1770 Global step 1770 Train loss 2.69 on epoch=442
06/01/2022 03:53:28 - INFO - __main__ - Step 1780 Global step 1780 Train loss 2.59 on epoch=444
06/01/2022 03:53:30 - INFO - __main__ - Step 1790 Global step 1790 Train loss 2.61 on epoch=447
06/01/2022 03:53:31 - INFO - __main__ - Step 1800 Global step 1800 Train loss 2.64 on epoch=449
06/01/2022 03:53:32 - INFO - __main__ - Global step 1800 Train loss 2.63 Classification-F1 0.1 on epoch=449
06/01/2022 03:53:33 - INFO - __main__ - Step 1810 Global step 1810 Train loss 2.73 on epoch=452
06/01/2022 03:53:34 - INFO - __main__ - Step 1820 Global step 1820 Train loss 2.45 on epoch=454
06/01/2022 03:53:36 - INFO - __main__ - Step 1830 Global step 1830 Train loss 2.73 on epoch=457
06/01/2022 03:53:37 - INFO - __main__ - Step 1840 Global step 1840 Train loss 2.37 on epoch=459
06/01/2022 03:53:38 - INFO - __main__ - Step 1850 Global step 1850 Train loss 2.44 on epoch=462
06/01/2022 03:53:39 - INFO - __main__ - Global step 1850 Train loss 2.54 Classification-F1 0.1 on epoch=462
06/01/2022 03:53:40 - INFO - __main__ - Step 1860 Global step 1860 Train loss 2.28 on epoch=464
06/01/2022 03:53:42 - INFO - __main__ - Step 1870 Global step 1870 Train loss 2.39 on epoch=467
06/01/2022 03:53:43 - INFO - __main__ - Step 1880 Global step 1880 Train loss 2.34 on epoch=469
06/01/2022 03:53:44 - INFO - __main__ - Step 1890 Global step 1890 Train loss 2.24 on epoch=472
06/01/2022 03:53:45 - INFO - __main__ - Step 1900 Global step 1900 Train loss 2.19 on epoch=474
06/01/2022 03:53:46 - INFO - __main__ - Global step 1900 Train loss 2.29 Classification-F1 0.1 on epoch=474
06/01/2022 03:53:48 - INFO - __main__ - Step 1910 Global step 1910 Train loss 2.42 on epoch=477
06/01/2022 03:53:49 - INFO - __main__ - Step 1920 Global step 1920 Train loss 2.21 on epoch=479
06/01/2022 03:53:50 - INFO - __main__ - Step 1930 Global step 1930 Train loss 2.11 on epoch=482
06/01/2022 03:53:51 - INFO - __main__ - Step 1940 Global step 1940 Train loss 2.22 on epoch=484
06/01/2022 03:53:53 - INFO - __main__ - Step 1950 Global step 1950 Train loss 2.17 on epoch=487
06/01/2022 03:53:53 - INFO - __main__ - Global step 1950 Train loss 2.23 Classification-F1 0.1 on epoch=487
06/01/2022 03:53:55 - INFO - __main__ - Step 1960 Global step 1960 Train loss 2.27 on epoch=489
06/01/2022 03:53:56 - INFO - __main__ - Step 1970 Global step 1970 Train loss 2.12 on epoch=492
06/01/2022 03:53:57 - INFO - __main__ - Step 1980 Global step 1980 Train loss 2.13 on epoch=494
06/01/2022 03:53:59 - INFO - __main__ - Step 1990 Global step 1990 Train loss 2.19 on epoch=497
06/01/2022 03:54:00 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.90 on epoch=499
06/01/2022 03:54:00 - INFO - __main__ - Global step 2000 Train loss 2.12 Classification-F1 0.1 on epoch=499
06/01/2022 03:54:02 - INFO - __main__ - Step 2010 Global step 2010 Train loss 2.08 on epoch=502
06/01/2022 03:54:03 - INFO - __main__ - Step 2020 Global step 2020 Train loss 2.09 on epoch=504
06/01/2022 03:54:04 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.98 on epoch=507
06/01/2022 03:54:06 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.77 on epoch=509
06/01/2022 03:54:07 - INFO - __main__ - Step 2050 Global step 2050 Train loss 2.13 on epoch=512
06/01/2022 03:54:07 - INFO - __main__ - Global step 2050 Train loss 2.01 Classification-F1 0.09615384615384615 on epoch=512
06/01/2022 03:54:09 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.82 on epoch=514
06/01/2022 03:54:10 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.94 on epoch=517
06/01/2022 03:54:11 - INFO - __main__ - Step 2080 Global step 2080 Train loss 2.00 on epoch=519
06/01/2022 03:54:13 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.80 on epoch=522
06/01/2022 03:54:14 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.89 on epoch=524
06/01/2022 03:54:14 - INFO - __main__ - Global step 2100 Train loss 1.89 Classification-F1 0.13034188034188032 on epoch=524
06/01/2022 03:54:16 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.87 on epoch=527
06/01/2022 03:54:17 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.93 on epoch=529
06/01/2022 03:54:18 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.81 on epoch=532
06/01/2022 03:54:20 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.77 on epoch=534
06/01/2022 03:54:21 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.82 on epoch=537
06/01/2022 03:54:21 - INFO - __main__ - Global step 2150 Train loss 1.84 Classification-F1 0.19408369408369408 on epoch=537
06/01/2022 03:54:21 - INFO - __main__ - Saving model with best Classification-F1: 0.15526315789473685 -> 0.19408369408369408 on epoch=537, global_step=2150
06/01/2022 03:54:23 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.80 on epoch=539
06/01/2022 03:54:24 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.81 on epoch=542
06/01/2022 03:54:25 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.89 on epoch=544
06/01/2022 03:54:27 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.76 on epoch=547
06/01/2022 03:54:28 - INFO - __main__ - Step 2200 Global step 2200 Train loss 1.70 on epoch=549
06/01/2022 03:54:29 - INFO - __main__ - Global step 2200 Train loss 1.79 Classification-F1 0.13083538083538082 on epoch=549
06/01/2022 03:54:30 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.82 on epoch=552
06/01/2022 03:54:31 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.80 on epoch=554
06/01/2022 03:54:32 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.75 on epoch=557
06/01/2022 03:54:34 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.61 on epoch=559
06/01/2022 03:54:35 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.62 on epoch=562
06/01/2022 03:54:36 - INFO - __main__ - Global step 2250 Train loss 1.72 Classification-F1 0.14210526315789473 on epoch=562
06/01/2022 03:54:37 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.69 on epoch=564
06/01/2022 03:54:38 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.78 on epoch=567
06/01/2022 03:54:40 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.51 on epoch=569
06/01/2022 03:54:41 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.53 on epoch=572
06/01/2022 03:54:42 - INFO - __main__ - Step 2300 Global step 2300 Train loss 1.55 on epoch=574
06/01/2022 03:54:43 - INFO - __main__ - Global step 2300 Train loss 1.61 Classification-F1 0.18749999999999997 on epoch=574
06/01/2022 03:54:44 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.68 on epoch=577
06/01/2022 03:54:45 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.39 on epoch=579
06/01/2022 03:54:47 - INFO - __main__ - Step 2330 Global step 2330 Train loss 1.52 on epoch=582
06/01/2022 03:54:48 - INFO - __main__ - Step 2340 Global step 2340 Train loss 1.54 on epoch=584
06/01/2022 03:54:49 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.57 on epoch=587
06/01/2022 03:54:50 - INFO - __main__ - Global step 2350 Train loss 1.54 Classification-F1 0.1743478260869565 on epoch=587
06/01/2022 03:54:51 - INFO - __main__ - Step 2360 Global step 2360 Train loss 1.51 on epoch=589
06/01/2022 03:54:52 - INFO - __main__ - Step 2370 Global step 2370 Train loss 1.52 on epoch=592
06/01/2022 03:54:54 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.42 on epoch=594
06/01/2022 03:54:55 - INFO - __main__ - Step 2390 Global step 2390 Train loss 1.49 on epoch=597
06/01/2022 03:54:56 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.56 on epoch=599
06/01/2022 03:54:57 - INFO - __main__ - Global step 2400 Train loss 1.50 Classification-F1 0.17695652173913046 on epoch=599
06/01/2022 03:54:58 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.40 on epoch=602
06/01/2022 03:54:59 - INFO - __main__ - Step 2420 Global step 2420 Train loss 1.38 on epoch=604
06/01/2022 03:55:01 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.42 on epoch=607
06/01/2022 03:55:02 - INFO - __main__ - Step 2440 Global step 2440 Train loss 1.30 on epoch=609
06/01/2022 03:55:03 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.50 on epoch=612
06/01/2022 03:55:04 - INFO - __main__ - Global step 2450 Train loss 1.40 Classification-F1 0.1547202797202797 on epoch=612
06/01/2022 03:55:05 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.42 on epoch=614
06/01/2022 03:55:06 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.47 on epoch=617
06/01/2022 03:55:08 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.58 on epoch=619
06/01/2022 03:55:09 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.37 on epoch=622
06/01/2022 03:55:10 - INFO - __main__ - Step 2500 Global step 2500 Train loss 1.35 on epoch=624
06/01/2022 03:55:11 - INFO - __main__ - Global step 2500 Train loss 1.44 Classification-F1 0.15559772296015179 on epoch=624
06/01/2022 03:55:12 - INFO - __main__ - Step 2510 Global step 2510 Train loss 1.56 on epoch=627
06/01/2022 03:55:13 - INFO - __main__ - Step 2520 Global step 2520 Train loss 1.53 on epoch=629
06/01/2022 03:55:15 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.36 on epoch=632
06/01/2022 03:55:16 - INFO - __main__ - Step 2540 Global step 2540 Train loss 1.42 on epoch=634
06/01/2022 03:55:17 - INFO - __main__ - Step 2550 Global step 2550 Train loss 1.42 on epoch=637
06/01/2022 03:55:18 - INFO - __main__ - Global step 2550 Train loss 1.46 Classification-F1 0.13381369016984046 on epoch=637
06/01/2022 03:55:19 - INFO - __main__ - Step 2560 Global step 2560 Train loss 1.47 on epoch=639
06/01/2022 03:55:21 - INFO - __main__ - Step 2570 Global step 2570 Train loss 1.27 on epoch=642
06/01/2022 03:55:22 - INFO - __main__ - Step 2580 Global step 2580 Train loss 1.44 on epoch=644
06/01/2022 03:55:23 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.33 on epoch=647
06/01/2022 03:55:24 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.40 on epoch=649
06/01/2022 03:55:25 - INFO - __main__ - Global step 2600 Train loss 1.38 Classification-F1 0.09701492537313432 on epoch=649
06/01/2022 03:55:26 - INFO - __main__ - Step 2610 Global step 2610 Train loss 1.36 on epoch=652
06/01/2022 03:55:28 - INFO - __main__ - Step 2620 Global step 2620 Train loss 1.17 on epoch=654
06/01/2022 03:55:29 - INFO - __main__ - Step 2630 Global step 2630 Train loss 1.30 on epoch=657
06/01/2022 03:55:30 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.39 on epoch=659
06/01/2022 03:55:32 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.26 on epoch=662
06/01/2022 03:55:32 - INFO - __main__ - Global step 2650 Train loss 1.30 Classification-F1 0.1803030303030303 on epoch=662
06/01/2022 03:55:34 - INFO - __main__ - Step 2660 Global step 2660 Train loss 1.23 on epoch=664
06/01/2022 03:55:35 - INFO - __main__ - Step 2670 Global step 2670 Train loss 1.36 on epoch=667
06/01/2022 03:55:36 - INFO - __main__ - Step 2680 Global step 2680 Train loss 1.25 on epoch=669
06/01/2022 03:55:38 - INFO - __main__ - Step 2690 Global step 2690 Train loss 1.28 on epoch=672
06/01/2022 03:55:39 - INFO - __main__ - Step 2700 Global step 2700 Train loss 1.22 on epoch=674
06/01/2022 03:55:40 - INFO - __main__ - Global step 2700 Train loss 1.27 Classification-F1 0.203125 on epoch=674
06/01/2022 03:55:40 - INFO - __main__ - Saving model with best Classification-F1: 0.19408369408369408 -> 0.203125 on epoch=674, global_step=2700
06/01/2022 03:55:41 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.16 on epoch=677
06/01/2022 03:55:43 - INFO - __main__ - Step 2720 Global step 2720 Train loss 1.17 on epoch=679
06/01/2022 03:55:44 - INFO - __main__ - Step 2730 Global step 2730 Train loss 1.34 on epoch=682
06/01/2022 03:55:45 - INFO - __main__ - Step 2740 Global step 2740 Train loss 1.16 on epoch=684
06/01/2022 03:55:47 - INFO - __main__ - Step 2750 Global step 2750 Train loss 1.34 on epoch=687
06/01/2022 03:55:47 - INFO - __main__ - Global step 2750 Train loss 1.23 Classification-F1 0.13034188034188032 on epoch=687
06/01/2022 03:55:49 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.28 on epoch=689
06/01/2022 03:55:50 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.37 on epoch=692
06/01/2022 03:55:52 - INFO - __main__ - Step 2780 Global step 2780 Train loss 1.28 on epoch=694
06/01/2022 03:55:53 - INFO - __main__ - Step 2790 Global step 2790 Train loss 1.36 on epoch=697
06/01/2022 03:55:54 - INFO - __main__ - Step 2800 Global step 2800 Train loss 1.39 on epoch=699
06/01/2022 03:55:55 - INFO - __main__ - Global step 2800 Train loss 1.34 Classification-F1 0.15211640211640212 on epoch=699
06/01/2022 03:55:56 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.34 on epoch=702
06/01/2022 03:55:58 - INFO - __main__ - Step 2820 Global step 2820 Train loss 1.29 on epoch=704
06/01/2022 03:55:59 - INFO - __main__ - Step 2830 Global step 2830 Train loss 1.18 on epoch=707
06/01/2022 03:56:00 - INFO - __main__ - Step 2840 Global step 2840 Train loss 1.18 on epoch=709
06/01/2022 03:56:02 - INFO - __main__ - Step 2850 Global step 2850 Train loss 1.22 on epoch=712
06/01/2022 03:56:02 - INFO - __main__ - Global step 2850 Train loss 1.24 Classification-F1 0.19956521739130434 on epoch=712
06/01/2022 03:56:04 - INFO - __main__ - Step 2860 Global step 2860 Train loss 1.29 on epoch=714
06/01/2022 03:56:05 - INFO - __main__ - Step 2870 Global step 2870 Train loss 1.19 on epoch=717
06/01/2022 03:56:07 - INFO - __main__ - Step 2880 Global step 2880 Train loss 1.14 on epoch=719
06/01/2022 03:56:08 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.17 on epoch=722
06/01/2022 03:56:09 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.26 on epoch=724
06/01/2022 03:56:10 - INFO - __main__ - Global step 2900 Train loss 1.21 Classification-F1 0.17831215970961886 on epoch=724
06/01/2022 03:56:11 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.10 on epoch=727
06/01/2022 03:56:13 - INFO - __main__ - Step 2920 Global step 2920 Train loss 1.02 on epoch=729
06/01/2022 03:56:14 - INFO - __main__ - Step 2930 Global step 2930 Train loss 1.26 on epoch=732
06/01/2022 03:56:16 - INFO - __main__ - Step 2940 Global step 2940 Train loss 1.13 on epoch=734
06/01/2022 03:56:17 - INFO - __main__ - Step 2950 Global step 2950 Train loss 1.18 on epoch=737
06/01/2022 03:56:18 - INFO - __main__ - Global step 2950 Train loss 1.14 Classification-F1 0.11714285714285715 on epoch=737
06/01/2022 03:56:19 - INFO - __main__ - Step 2960 Global step 2960 Train loss 1.22 on epoch=739
06/01/2022 03:56:20 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.30 on epoch=742
06/01/2022 03:56:22 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.18 on epoch=744
06/01/2022 03:56:23 - INFO - __main__ - Step 2990 Global step 2990 Train loss 1.35 on epoch=747
06/01/2022 03:56:25 - INFO - __main__ - Step 3000 Global step 3000 Train loss 1.23 on epoch=749
06/01/2022 03:56:25 - INFO - __main__ - Global step 3000 Train loss 1.26 Classification-F1 0.16428571428571428 on epoch=749
06/01/2022 03:56:25 - INFO - __main__ - save last model!
06/01/2022 03:56:25 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/01/2022 03:56:25 - INFO - __main__ - Start tokenizing ... 5509 instances
06/01/2022 03:56:25 - INFO - __main__ - Printing 3 examples
06/01/2022 03:56:25 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/01/2022 03:56:25 - INFO - __main__ - ['others']
06/01/2022 03:56:25 - INFO - __main__ -  [emo] what you like very little things ok
06/01/2022 03:56:25 - INFO - __main__ - ['others']
06/01/2022 03:56:25 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/01/2022 03:56:25 - INFO - __main__ - ['others']
06/01/2022 03:56:25 - INFO - __main__ - Tokenizing Input ...
06/01/2022 03:56:26 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 03:56:26 - INFO - __main__ - Printing 3 examples
06/01/2022 03:56:26 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/01/2022 03:56:26 - INFO - __main__ - ['happy']
06/01/2022 03:56:26 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/01/2022 03:56:26 - INFO - __main__ - ['happy']
06/01/2022 03:56:26 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/01/2022 03:56:26 - INFO - __main__ - ['happy']
06/01/2022 03:56:26 - INFO - __main__ - Tokenizing Input ...
06/01/2022 03:56:26 - INFO - __main__ - Tokenizing Output ...
06/01/2022 03:56:26 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 03:56:26 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 03:56:26 - INFO - __main__ - Printing 3 examples
06/01/2022 03:56:26 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
06/01/2022 03:56:26 - INFO - __main__ - ['happy']
06/01/2022 03:56:26 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
06/01/2022 03:56:26 - INFO - __main__ - ['happy']
06/01/2022 03:56:26 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
06/01/2022 03:56:26 - INFO - __main__ - ['happy']
06/01/2022 03:56:26 - INFO - __main__ - Tokenizing Input ...
06/01/2022 03:56:26 - INFO - __main__ - Tokenizing Output ...
06/01/2022 03:56:26 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 03:56:27 - INFO - __main__ - Tokenizing Output ...
06/01/2022 03:56:32 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 03:56:32 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/01/2022 03:56:32 - INFO - __main__ - Starting training!
06/01/2022 03:56:33 - INFO - __main__ - Loaded 5509 examples from test data
06/01/2022 03:57:17 - INFO - __main__ - Saved prediction in models/T5-base-reptile-cls2cls-3e-5-2-5000-5e-1-10/singletask-emo/emo_16_21_0.2_8_predictions.txt
06/01/2022 03:57:17 - INFO - __main__ - Classification-F1 on test data: 0.0381
06/01/2022 03:57:17 - INFO - __main__ - prefix=emo_16_21, lr=0.2, bsz=8, dev_performance=0.203125, test_performance=0.038122977484098014
06/01/2022 03:57:17 - INFO - __main__ - Running ... prefix=emo_16_42, lr=0.5, bsz=8 ...
06/01/2022 03:57:18 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 03:57:18 - INFO - __main__ - Printing 3 examples
06/01/2022 03:57:18 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/01/2022 03:57:18 - INFO - __main__ - ['happy']
06/01/2022 03:57:18 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/01/2022 03:57:18 - INFO - __main__ - ['happy']
06/01/2022 03:57:18 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/01/2022 03:57:18 - INFO - __main__ - ['happy']
06/01/2022 03:57:18 - INFO - __main__ - Tokenizing Input ...
06/01/2022 03:57:18 - INFO - __main__ - Tokenizing Output ...
06/01/2022 03:57:18 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 03:57:18 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 03:57:18 - INFO - __main__ - Printing 3 examples
06/01/2022 03:57:18 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
06/01/2022 03:57:18 - INFO - __main__ - ['happy']
06/01/2022 03:57:18 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
06/01/2022 03:57:18 - INFO - __main__ - ['happy']
06/01/2022 03:57:18 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
06/01/2022 03:57:18 - INFO - __main__ - ['happy']
06/01/2022 03:57:18 - INFO - __main__ - Tokenizing Input ...
06/01/2022 03:57:18 - INFO - __main__ - Tokenizing Output ...
06/01/2022 03:57:18 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 03:57:24 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 03:57:24 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/01/2022 03:57:24 - INFO - __main__ - Starting training!
06/01/2022 03:57:25 - INFO - __main__ - Step 10 Global step 10 Train loss 8.94 on epoch=2
06/01/2022 03:57:27 - INFO - __main__ - Step 20 Global step 20 Train loss 8.94 on epoch=4
06/01/2022 03:57:29 - INFO - __main__ - Step 30 Global step 30 Train loss 8.83 on epoch=7
06/01/2022 03:57:30 - INFO - __main__ - Step 40 Global step 40 Train loss 8.71 on epoch=9
06/01/2022 03:57:32 - INFO - __main__ - Step 50 Global step 50 Train loss 8.75 on epoch=12
06/01/2022 03:57:42 - INFO - __main__ - Global step 50 Train loss 8.83 Classification-F1 0.0 on epoch=12
06/01/2022 03:57:42 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
06/01/2022 03:57:44 - INFO - __main__ - Step 60 Global step 60 Train loss 8.64 on epoch=14
06/01/2022 03:57:45 - INFO - __main__ - Step 70 Global step 70 Train loss 8.71 on epoch=17
06/01/2022 03:57:47 - INFO - __main__ - Step 80 Global step 80 Train loss 8.55 on epoch=19
06/01/2022 03:57:48 - INFO - __main__ - Step 90 Global step 90 Train loss 8.27 on epoch=22
06/01/2022 03:57:50 - INFO - __main__ - Step 100 Global step 100 Train loss 8.18 on epoch=24
06/01/2022 03:57:58 - INFO - __main__ - Global step 100 Train loss 8.47 Classification-F1 0.0 on epoch=24
06/01/2022 03:57:59 - INFO - __main__ - Step 110 Global step 110 Train loss 8.12 on epoch=27
06/01/2022 03:58:01 - INFO - __main__ - Step 120 Global step 120 Train loss 7.96 on epoch=29
06/01/2022 03:58:02 - INFO - __main__ - Step 130 Global step 130 Train loss 7.83 on epoch=32
06/01/2022 03:58:04 - INFO - __main__ - Step 140 Global step 140 Train loss 7.54 on epoch=34
06/01/2022 03:58:05 - INFO - __main__ - Step 150 Global step 150 Train loss 7.25 on epoch=37
06/01/2022 03:58:10 - INFO - __main__ - Global step 150 Train loss 7.74 Classification-F1 0.0 on epoch=37
06/01/2022 03:58:12 - INFO - __main__ - Step 160 Global step 160 Train loss 7.21 on epoch=39
06/01/2022 03:58:13 - INFO - __main__ - Step 170 Global step 170 Train loss 6.99 on epoch=42
06/01/2022 03:58:14 - INFO - __main__ - Step 180 Global step 180 Train loss 7.00 on epoch=44
06/01/2022 03:58:15 - INFO - __main__ - Step 190 Global step 190 Train loss 6.95 on epoch=47
06/01/2022 03:58:17 - INFO - __main__ - Step 200 Global step 200 Train loss 6.71 on epoch=49
06/01/2022 03:58:23 - INFO - __main__ - Global step 200 Train loss 6.97 Classification-F1 0.0 on epoch=49
06/01/2022 03:58:24 - INFO - __main__ - Step 210 Global step 210 Train loss 6.48 on epoch=52
06/01/2022 03:58:25 - INFO - __main__ - Step 220 Global step 220 Train loss 6.41 on epoch=54
06/01/2022 03:58:27 - INFO - __main__ - Step 230 Global step 230 Train loss 6.21 on epoch=57
06/01/2022 03:58:28 - INFO - __main__ - Step 240 Global step 240 Train loss 5.93 on epoch=59
06/01/2022 03:58:29 - INFO - __main__ - Step 250 Global step 250 Train loss 5.71 on epoch=62
06/01/2022 03:58:34 - INFO - __main__ - Global step 250 Train loss 6.15 Classification-F1 0.0 on epoch=62
06/01/2022 03:58:35 - INFO - __main__ - Step 260 Global step 260 Train loss 5.60 on epoch=64
06/01/2022 03:58:37 - INFO - __main__ - Step 270 Global step 270 Train loss 5.47 on epoch=67
06/01/2022 03:58:38 - INFO - __main__ - Step 280 Global step 280 Train loss 5.40 on epoch=69
06/01/2022 03:58:39 - INFO - __main__ - Step 290 Global step 290 Train loss 5.20 on epoch=72
06/01/2022 03:58:40 - INFO - __main__ - Step 300 Global step 300 Train loss 5.25 on epoch=74
06/01/2022 03:58:50 - INFO - __main__ - Global step 300 Train loss 5.38 Classification-F1 0.0 on epoch=74
06/01/2022 03:58:51 - INFO - __main__ - Step 310 Global step 310 Train loss 5.17 on epoch=77
06/01/2022 03:58:53 - INFO - __main__ - Step 320 Global step 320 Train loss 5.05 on epoch=79
06/01/2022 03:58:54 - INFO - __main__ - Step 330 Global step 330 Train loss 4.85 on epoch=82
06/01/2022 03:58:55 - INFO - __main__ - Step 340 Global step 340 Train loss 4.75 on epoch=84
06/01/2022 03:58:57 - INFO - __main__ - Step 350 Global step 350 Train loss 4.42 on epoch=87
06/01/2022 03:59:01 - INFO - __main__ - Global step 350 Train loss 4.85 Classification-F1 0.0 on epoch=87
06/01/2022 03:59:02 - INFO - __main__ - Step 360 Global step 360 Train loss 4.46 on epoch=89
06/01/2022 03:59:03 - INFO - __main__ - Step 370 Global step 370 Train loss 4.32 on epoch=92
06/01/2022 03:59:05 - INFO - __main__ - Step 380 Global step 380 Train loss 4.32 on epoch=94
06/01/2022 03:59:06 - INFO - __main__ - Step 390 Global step 390 Train loss 4.30 on epoch=97
06/01/2022 03:59:07 - INFO - __main__ - Step 400 Global step 400 Train loss 4.18 on epoch=99
06/01/2022 03:59:09 - INFO - __main__ - Global step 400 Train loss 4.32 Classification-F1 0.0 on epoch=99
06/01/2022 03:59:11 - INFO - __main__ - Step 410 Global step 410 Train loss 4.02 on epoch=102
06/01/2022 03:59:12 - INFO - __main__ - Step 420 Global step 420 Train loss 3.92 on epoch=104
06/01/2022 03:59:13 - INFO - __main__ - Step 430 Global step 430 Train loss 3.81 on epoch=107
06/01/2022 03:59:15 - INFO - __main__ - Step 440 Global step 440 Train loss 3.80 on epoch=109
06/01/2022 03:59:16 - INFO - __main__ - Step 450 Global step 450 Train loss 3.91 on epoch=112
06/01/2022 03:59:17 - INFO - __main__ - Global step 450 Train loss 3.89 Classification-F1 0.08648901355773725 on epoch=112
06/01/2022 03:59:17 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.08648901355773725 on epoch=112, global_step=450
06/01/2022 03:59:18 - INFO - __main__ - Step 460 Global step 460 Train loss 3.94 on epoch=114
06/01/2022 03:59:19 - INFO - __main__ - Step 470 Global step 470 Train loss 3.78 on epoch=117
06/01/2022 03:59:21 - INFO - __main__ - Step 480 Global step 480 Train loss 3.63 on epoch=119
06/01/2022 03:59:22 - INFO - __main__ - Step 490 Global step 490 Train loss 3.26 on epoch=122
06/01/2022 03:59:23 - INFO - __main__ - Step 500 Global step 500 Train loss 3.48 on epoch=124
06/01/2022 03:59:27 - INFO - __main__ - Global step 500 Train loss 3.62 Classification-F1 0.17344312918167784 on epoch=124
06/01/2022 03:59:27 - INFO - __main__ - Saving model with best Classification-F1: 0.08648901355773725 -> 0.17344312918167784 on epoch=124, global_step=500
06/01/2022 03:59:28 - INFO - __main__ - Step 510 Global step 510 Train loss 3.29 on epoch=127
06/01/2022 03:59:29 - INFO - __main__ - Step 520 Global step 520 Train loss 3.36 on epoch=129
06/01/2022 03:59:31 - INFO - __main__ - Step 530 Global step 530 Train loss 3.17 on epoch=132
06/01/2022 03:59:32 - INFO - __main__ - Step 540 Global step 540 Train loss 3.19 on epoch=134
06/01/2022 03:59:33 - INFO - __main__ - Step 550 Global step 550 Train loss 3.18 on epoch=137
06/01/2022 03:59:40 - INFO - __main__ - Global step 550 Train loss 3.24 Classification-F1 0.1 on epoch=137
06/01/2022 03:59:41 - INFO - __main__ - Step 560 Global step 560 Train loss 3.11 on epoch=139
06/01/2022 03:59:43 - INFO - __main__ - Step 570 Global step 570 Train loss 2.99 on epoch=142
06/01/2022 03:59:44 - INFO - __main__ - Step 580 Global step 580 Train loss 2.89 on epoch=144
06/01/2022 03:59:45 - INFO - __main__ - Step 590 Global step 590 Train loss 2.87 on epoch=147
06/01/2022 03:59:46 - INFO - __main__ - Step 600 Global step 600 Train loss 2.87 on epoch=149
06/01/2022 03:59:49 - INFO - __main__ - Global step 600 Train loss 2.95 Classification-F1 0.12394957983193278 on epoch=149
06/01/2022 03:59:50 - INFO - __main__ - Step 610 Global step 610 Train loss 2.85 on epoch=152
06/01/2022 03:59:51 - INFO - __main__ - Step 620 Global step 620 Train loss 2.93 on epoch=154
06/01/2022 03:59:53 - INFO - __main__ - Step 630 Global step 630 Train loss 2.68 on epoch=157
06/01/2022 03:59:54 - INFO - __main__ - Step 640 Global step 640 Train loss 2.67 on epoch=159
06/01/2022 03:59:55 - INFO - __main__ - Step 650 Global step 650 Train loss 2.46 on epoch=162
06/01/2022 03:59:56 - INFO - __main__ - Global step 650 Train loss 2.72 Classification-F1 0.13911007025761124 on epoch=162
06/01/2022 03:59:57 - INFO - __main__ - Step 660 Global step 660 Train loss 2.67 on epoch=164
06/01/2022 03:59:58 - INFO - __main__ - Step 670 Global step 670 Train loss 2.48 on epoch=167
06/01/2022 04:00:00 - INFO - __main__ - Step 680 Global step 680 Train loss 2.46 on epoch=169
06/01/2022 04:00:01 - INFO - __main__ - Step 690 Global step 690 Train loss 2.20 on epoch=172
06/01/2022 04:00:02 - INFO - __main__ - Step 700 Global step 700 Train loss 2.30 on epoch=174
06/01/2022 04:00:04 - INFO - __main__ - Global step 700 Train loss 2.42 Classification-F1 0.1581196581196581 on epoch=174
06/01/2022 04:00:05 - INFO - __main__ - Step 710 Global step 710 Train loss 2.25 on epoch=177
06/01/2022 04:00:06 - INFO - __main__ - Step 720 Global step 720 Train loss 2.20 on epoch=179
06/01/2022 04:00:07 - INFO - __main__ - Step 730 Global step 730 Train loss 2.12 on epoch=182
06/01/2022 04:00:09 - INFO - __main__ - Step 740 Global step 740 Train loss 2.34 on epoch=184
06/01/2022 04:00:10 - INFO - __main__ - Step 750 Global step 750 Train loss 1.91 on epoch=187
06/01/2022 04:00:14 - INFO - __main__ - Global step 750 Train loss 2.16 Classification-F1 0.10126582278481013 on epoch=187
06/01/2022 04:00:16 - INFO - __main__ - Step 760 Global step 760 Train loss 1.98 on epoch=189
06/01/2022 04:00:17 - INFO - __main__ - Step 770 Global step 770 Train loss 1.87 on epoch=192
06/01/2022 04:00:18 - INFO - __main__ - Step 780 Global step 780 Train loss 1.87 on epoch=194
06/01/2022 04:00:19 - INFO - __main__ - Step 790 Global step 790 Train loss 1.84 on epoch=197
06/01/2022 04:00:21 - INFO - __main__ - Step 800 Global step 800 Train loss 1.82 on epoch=199
06/01/2022 04:00:23 - INFO - __main__ - Global step 800 Train loss 1.88 Classification-F1 0.12394957983193278 on epoch=199
06/01/2022 04:00:25 - INFO - __main__ - Step 810 Global step 810 Train loss 1.88 on epoch=202
06/01/2022 04:00:26 - INFO - __main__ - Step 820 Global step 820 Train loss 1.71 on epoch=204
06/01/2022 04:00:27 - INFO - __main__ - Step 830 Global step 830 Train loss 1.58 on epoch=207
06/01/2022 04:00:28 - INFO - __main__ - Step 840 Global step 840 Train loss 1.70 on epoch=209
06/01/2022 04:00:30 - INFO - __main__ - Step 850 Global step 850 Train loss 1.70 on epoch=212
06/01/2022 04:00:31 - INFO - __main__ - Global step 850 Train loss 1.71 Classification-F1 0.10126582278481013 on epoch=212
06/01/2022 04:00:32 - INFO - __main__ - Step 860 Global step 860 Train loss 1.45 on epoch=214
06/01/2022 04:00:34 - INFO - __main__ - Step 870 Global step 870 Train loss 1.45 on epoch=217
06/01/2022 04:00:35 - INFO - __main__ - Step 880 Global step 880 Train loss 1.43 on epoch=219
06/01/2022 04:00:36 - INFO - __main__ - Step 890 Global step 890 Train loss 1.40 on epoch=222
06/01/2022 04:00:38 - INFO - __main__ - Step 900 Global step 900 Train loss 1.48 on epoch=224
06/01/2022 04:00:38 - INFO - __main__ - Global step 900 Train loss 1.44 Classification-F1 0.09493670886075949 on epoch=224
06/01/2022 04:00:39 - INFO - __main__ - Step 910 Global step 910 Train loss 1.46 on epoch=227
06/01/2022 04:00:41 - INFO - __main__ - Step 920 Global step 920 Train loss 1.57 on epoch=229
06/01/2022 04:00:42 - INFO - __main__ - Step 930 Global step 930 Train loss 1.35 on epoch=232
06/01/2022 04:00:43 - INFO - __main__ - Step 940 Global step 940 Train loss 1.46 on epoch=234
06/01/2022 04:00:45 - INFO - __main__ - Step 950 Global step 950 Train loss 1.35 on epoch=237
06/01/2022 04:00:45 - INFO - __main__ - Global step 950 Train loss 1.44 Classification-F1 0.11705989110707803 on epoch=237
06/01/2022 04:00:46 - INFO - __main__ - Step 960 Global step 960 Train loss 1.42 on epoch=239
06/01/2022 04:00:48 - INFO - __main__ - Step 970 Global step 970 Train loss 1.28 on epoch=242
06/01/2022 04:00:49 - INFO - __main__ - Step 980 Global step 980 Train loss 1.43 on epoch=244
06/01/2022 04:00:51 - INFO - __main__ - Step 990 Global step 990 Train loss 1.41 on epoch=247
06/01/2022 04:00:52 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.31 on epoch=249
06/01/2022 04:00:52 - INFO - __main__ - Global step 1000 Train loss 1.37 Classification-F1 0.13997113997113997 on epoch=249
06/01/2022 04:00:54 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.34 on epoch=252
06/01/2022 04:00:55 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.35 on epoch=254
06/01/2022 04:00:56 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.23 on epoch=257
06/01/2022 04:00:58 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.26 on epoch=259
06/01/2022 04:00:59 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.26 on epoch=262
06/01/2022 04:00:59 - INFO - __main__ - Global step 1050 Train loss 1.29 Classification-F1 0.09090909090909091 on epoch=262
06/01/2022 04:01:01 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.23 on epoch=264
06/01/2022 04:01:02 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.28 on epoch=267
06/01/2022 04:01:03 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.27 on epoch=269
06/01/2022 04:01:04 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.37 on epoch=272
06/01/2022 04:01:06 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.19 on epoch=274
06/01/2022 04:01:06 - INFO - __main__ - Global step 1100 Train loss 1.27 Classification-F1 0.0974025974025974 on epoch=274
06/01/2022 04:01:08 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.23 on epoch=277
06/01/2022 04:01:09 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.31 on epoch=279
06/01/2022 04:01:10 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.32 on epoch=282
06/01/2022 04:01:11 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.27 on epoch=284
06/01/2022 04:01:13 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.09 on epoch=287
06/01/2022 04:01:13 - INFO - __main__ - Global step 1150 Train loss 1.24 Classification-F1 0.14621798689696247 on epoch=287
06/01/2022 04:01:15 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.27 on epoch=289
06/01/2022 04:01:16 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.05 on epoch=292
06/01/2022 04:01:17 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.19 on epoch=294
06/01/2022 04:01:18 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.18 on epoch=297
06/01/2022 04:01:20 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.25 on epoch=299
06/01/2022 04:01:20 - INFO - __main__ - Global step 1200 Train loss 1.19 Classification-F1 0.09615384615384615 on epoch=299
06/01/2022 04:01:22 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.22 on epoch=302
06/01/2022 04:01:23 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.09 on epoch=304
06/01/2022 04:01:24 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.24 on epoch=307
06/01/2022 04:01:25 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.12 on epoch=309
06/01/2022 04:01:27 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.12 on epoch=312
06/01/2022 04:01:27 - INFO - __main__ - Global step 1250 Train loss 1.16 Classification-F1 0.18277599633531835 on epoch=312
06/01/2022 04:01:27 - INFO - __main__ - Saving model with best Classification-F1: 0.17344312918167784 -> 0.18277599633531835 on epoch=312, global_step=1250
06/01/2022 04:01:29 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.12 on epoch=314
06/01/2022 04:01:30 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.14 on epoch=317
06/01/2022 04:01:31 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.10 on epoch=319
06/01/2022 04:01:32 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.05 on epoch=322
06/01/2022 04:01:34 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.12 on epoch=324
06/01/2022 04:01:34 - INFO - __main__ - Global step 1300 Train loss 1.10 Classification-F1 0.2065573770491803 on epoch=324
06/01/2022 04:01:34 - INFO - __main__ - Saving model with best Classification-F1: 0.18277599633531835 -> 0.2065573770491803 on epoch=324, global_step=1300
06/01/2022 04:01:36 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.03 on epoch=327
06/01/2022 04:01:37 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.01 on epoch=329
06/01/2022 04:01:38 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.13 on epoch=332
06/01/2022 04:01:40 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.01 on epoch=334
06/01/2022 04:01:41 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.17 on epoch=337
06/01/2022 04:01:41 - INFO - __main__ - Global step 1350 Train loss 1.07 Classification-F1 0.16470588235294115 on epoch=337
06/01/2022 04:01:43 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.11 on epoch=339
06/01/2022 04:01:44 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.13 on epoch=342
06/01/2022 04:01:45 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.14 on epoch=344
06/01/2022 04:01:46 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.10 on epoch=347
06/01/2022 04:01:48 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.05 on epoch=349
06/01/2022 04:01:48 - INFO - __main__ - Global step 1400 Train loss 1.10 Classification-F1 0.1237183868762816 on epoch=349
06/01/2022 04:01:50 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.25 on epoch=352
06/01/2022 04:01:51 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.01 on epoch=354
06/01/2022 04:01:52 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.09 on epoch=357
06/01/2022 04:01:53 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.03 on epoch=359
06/01/2022 04:01:55 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.98 on epoch=362
06/01/2022 04:01:55 - INFO - __main__ - Global step 1450 Train loss 1.07 Classification-F1 0.18055555555555555 on epoch=362
06/01/2022 04:01:57 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.96 on epoch=364
06/01/2022 04:01:58 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.98 on epoch=367
06/01/2022 04:01:59 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.04 on epoch=369
06/01/2022 04:02:00 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.06 on epoch=372
06/01/2022 04:02:02 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.04 on epoch=374
06/01/2022 04:02:02 - INFO - __main__ - Global step 1500 Train loss 1.02 Classification-F1 0.1 on epoch=374
06/01/2022 04:02:04 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.07 on epoch=377
06/01/2022 04:02:05 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.05 on epoch=379
06/01/2022 04:02:06 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.97 on epoch=382
06/01/2022 04:02:07 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.05 on epoch=384
06/01/2022 04:02:09 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.06 on epoch=387
06/01/2022 04:02:09 - INFO - __main__ - Global step 1550 Train loss 1.04 Classification-F1 0.1565276828434723 on epoch=387
06/01/2022 04:02:11 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.97 on epoch=389
06/01/2022 04:02:12 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.08 on epoch=392
06/01/2022 04:02:13 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.10 on epoch=394
06/01/2022 04:02:15 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.06 on epoch=397
06/01/2022 04:02:16 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.00 on epoch=399
06/01/2022 04:02:16 - INFO - __main__ - Global step 1600 Train loss 1.04 Classification-F1 0.12407862407862408 on epoch=399
06/01/2022 04:02:18 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.10 on epoch=402
06/01/2022 04:02:19 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.07 on epoch=404
06/01/2022 04:02:20 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.02 on epoch=407
06/01/2022 04:02:22 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.01 on epoch=409
06/01/2022 04:02:23 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.03 on epoch=412
06/01/2022 04:02:23 - INFO - __main__ - Global step 1650 Train loss 1.05 Classification-F1 0.1 on epoch=412
06/01/2022 04:02:25 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.98 on epoch=414
06/01/2022 04:02:26 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.93 on epoch=417
06/01/2022 04:02:27 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.87 on epoch=419
06/01/2022 04:02:28 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.06 on epoch=422
06/01/2022 04:02:30 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.00 on epoch=424
06/01/2022 04:02:30 - INFO - __main__ - Global step 1700 Train loss 0.97 Classification-F1 0.1 on epoch=424
06/01/2022 04:02:32 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.94 on epoch=427
06/01/2022 04:02:33 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.02 on epoch=429
06/01/2022 04:02:34 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.97 on epoch=432
06/01/2022 04:02:36 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.95 on epoch=434
06/01/2022 04:02:37 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.93 on epoch=437
06/01/2022 04:02:37 - INFO - __main__ - Global step 1750 Train loss 0.96 Classification-F1 0.10256410256410256 on epoch=437
06/01/2022 04:02:39 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.00 on epoch=439
06/01/2022 04:02:40 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.02 on epoch=442
06/01/2022 04:02:41 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.93 on epoch=444
06/01/2022 04:02:43 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.97 on epoch=447
06/01/2022 04:02:44 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.01 on epoch=449
06/01/2022 04:02:44 - INFO - __main__ - Global step 1800 Train loss 0.99 Classification-F1 0.13197586726998492 on epoch=449
06/01/2022 04:02:46 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.94 on epoch=452
06/01/2022 04:02:47 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.00 on epoch=454
06/01/2022 04:02:48 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.94 on epoch=457
06/01/2022 04:02:50 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.99 on epoch=459
06/01/2022 04:02:51 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.98 on epoch=462
06/01/2022 04:02:51 - INFO - __main__ - Global step 1850 Train loss 0.97 Classification-F1 0.1 on epoch=462
06/01/2022 04:02:53 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.96 on epoch=464
06/01/2022 04:02:54 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.06 on epoch=467
06/01/2022 04:02:55 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.97 on epoch=469
06/01/2022 04:02:57 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.02 on epoch=472
06/01/2022 04:02:58 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.04 on epoch=474
06/01/2022 04:02:58 - INFO - __main__ - Global step 1900 Train loss 1.01 Classification-F1 0.18407494145199066 on epoch=474
06/01/2022 04:03:00 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.98 on epoch=477
06/01/2022 04:03:01 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.01 on epoch=479
06/01/2022 04:03:02 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.96 on epoch=482
06/01/2022 04:03:04 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.01 on epoch=484
06/01/2022 04:03:05 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.08 on epoch=487
06/01/2022 04:03:05 - INFO - __main__ - Global step 1950 Train loss 1.01 Classification-F1 0.1 on epoch=487
06/01/2022 04:03:07 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.92 on epoch=489
06/01/2022 04:03:08 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.95 on epoch=492
06/01/2022 04:03:09 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.04 on epoch=494
06/01/2022 04:03:11 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.06 on epoch=497
06/01/2022 04:03:12 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.96 on epoch=499
06/01/2022 04:03:12 - INFO - __main__ - Global step 2000 Train loss 0.99 Classification-F1 0.1 on epoch=499
06/01/2022 04:03:14 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.97 on epoch=502
06/01/2022 04:03:15 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.97 on epoch=504
06/01/2022 04:03:16 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.90 on epoch=507
06/01/2022 04:03:18 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.96 on epoch=509
06/01/2022 04:03:19 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.13 on epoch=512
06/01/2022 04:03:19 - INFO - __main__ - Global step 2050 Train loss 0.98 Classification-F1 0.07971014492753624 on epoch=512
06/01/2022 04:03:21 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.90 on epoch=514
06/01/2022 04:03:22 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.90 on epoch=517
06/01/2022 04:03:23 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.93 on epoch=519
06/01/2022 04:03:25 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.01 on epoch=522
06/01/2022 04:03:26 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.05 on epoch=524
06/01/2022 04:03:26 - INFO - __main__ - Global step 2100 Train loss 0.96 Classification-F1 0.25396825396825395 on epoch=524
06/01/2022 04:03:26 - INFO - __main__ - Saving model with best Classification-F1: 0.2065573770491803 -> 0.25396825396825395 on epoch=524, global_step=2100
06/01/2022 04:03:28 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.01 on epoch=527
06/01/2022 04:03:29 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.99 on epoch=529
06/01/2022 04:03:30 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.85 on epoch=532
06/01/2022 04:03:32 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.88 on epoch=534
06/01/2022 04:03:33 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.08 on epoch=537
06/01/2022 04:03:33 - INFO - __main__ - Global step 2150 Train loss 0.96 Classification-F1 0.1 on epoch=537
06/01/2022 04:03:35 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.94 on epoch=539
06/01/2022 04:03:36 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.91 on epoch=542
06/01/2022 04:03:37 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.93 on epoch=544
06/01/2022 04:03:39 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.96 on epoch=547
06/01/2022 04:03:40 - INFO - __main__ - Step 2200 Global step 2200 Train loss 1.06 on epoch=549
06/01/2022 04:03:40 - INFO - __main__ - Global step 2200 Train loss 0.96 Classification-F1 0.11552106430155212 on epoch=549
06/01/2022 04:03:42 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.93 on epoch=552
06/01/2022 04:03:43 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.96 on epoch=554
06/01/2022 04:03:44 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.01 on epoch=557
06/01/2022 04:03:46 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.94 on epoch=559
06/01/2022 04:03:47 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.96 on epoch=562
06/01/2022 04:03:47 - INFO - __main__ - Global step 2250 Train loss 0.96 Classification-F1 0.1486842105263158 on epoch=562
06/01/2022 04:03:49 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.99 on epoch=564
06/01/2022 04:03:50 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.94 on epoch=567
06/01/2022 04:03:51 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.85 on epoch=569
06/01/2022 04:03:53 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.99 on epoch=572
06/01/2022 04:03:54 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.93 on epoch=574
06/01/2022 04:03:55 - INFO - __main__ - Global step 2300 Train loss 0.94 Classification-F1 0.14838709677419354 on epoch=574
06/01/2022 04:03:56 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.01 on epoch=577
06/01/2022 04:03:57 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.92 on epoch=579
06/01/2022 04:03:58 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.96 on epoch=582
06/01/2022 04:04:00 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.93 on epoch=584
06/01/2022 04:04:01 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.93 on epoch=587
06/01/2022 04:04:02 - INFO - __main__ - Global step 2350 Train loss 0.95 Classification-F1 0.1 on epoch=587
06/01/2022 04:04:03 - INFO - __main__ - Step 2360 Global step 2360 Train loss 1.02 on epoch=589
06/01/2022 04:04:04 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.93 on epoch=592
06/01/2022 04:04:05 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.01 on epoch=594
06/01/2022 04:04:07 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.94 on epoch=597
06/01/2022 04:04:08 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.87 on epoch=599
06/01/2022 04:04:09 - INFO - __main__ - Global step 2400 Train loss 0.95 Classification-F1 0.1 on epoch=599
06/01/2022 04:04:10 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.97 on epoch=602
06/01/2022 04:04:11 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.94 on epoch=604
06/01/2022 04:04:12 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.90 on epoch=607
06/01/2022 04:04:14 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.95 on epoch=609
06/01/2022 04:04:15 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.00 on epoch=612
06/01/2022 04:04:16 - INFO - __main__ - Global step 2450 Train loss 0.95 Classification-F1 0.23627906976744184 on epoch=612
06/01/2022 04:04:17 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.00 on epoch=614
06/01/2022 04:04:18 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.89 on epoch=617
06/01/2022 04:04:19 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.98 on epoch=619
06/01/2022 04:04:21 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.94 on epoch=622
06/01/2022 04:04:22 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.95 on epoch=624
06/01/2022 04:04:23 - INFO - __main__ - Global step 2500 Train loss 0.95 Classification-F1 0.11714285714285715 on epoch=624
06/01/2022 04:04:24 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.90 on epoch=627
06/01/2022 04:04:25 - INFO - __main__ - Step 2520 Global step 2520 Train loss 1.01 on epoch=629
06/01/2022 04:04:26 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.92 on epoch=632
06/01/2022 04:04:28 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.95 on epoch=634
06/01/2022 04:04:29 - INFO - __main__ - Step 2550 Global step 2550 Train loss 1.00 on epoch=637
06/01/2022 04:04:30 - INFO - __main__ - Global step 2550 Train loss 0.96 Classification-F1 0.13330786860198623 on epoch=637
06/01/2022 04:04:31 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.97 on epoch=639
06/01/2022 04:04:32 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.90 on epoch=642
06/01/2022 04:04:34 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.94 on epoch=644
06/01/2022 04:04:35 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.98 on epoch=647
06/01/2022 04:04:36 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.03 on epoch=649
06/01/2022 04:04:37 - INFO - __main__ - Global step 2600 Train loss 0.96 Classification-F1 0.10126582278481013 on epoch=649
06/01/2022 04:04:38 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.94 on epoch=652
06/01/2022 04:04:39 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.93 on epoch=654
06/01/2022 04:04:41 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.91 on epoch=657
06/01/2022 04:04:42 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.92 on epoch=659
06/01/2022 04:04:43 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.91 on epoch=662
06/01/2022 04:04:44 - INFO - __main__ - Global step 2650 Train loss 0.92 Classification-F1 0.09615384615384615 on epoch=662
06/01/2022 04:04:45 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.89 on epoch=664
06/01/2022 04:04:46 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.91 on epoch=667
06/01/2022 04:04:48 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.90 on epoch=669
06/01/2022 04:04:49 - INFO - __main__ - Step 2690 Global step 2690 Train loss 1.00 on epoch=672
06/01/2022 04:04:50 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.87 on epoch=674
06/01/2022 04:04:51 - INFO - __main__ - Global step 2700 Train loss 0.91 Classification-F1 0.08974358974358974 on epoch=674
06/01/2022 04:04:52 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.93 on epoch=677
06/01/2022 04:04:53 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.85 on epoch=679
06/01/2022 04:04:55 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.96 on epoch=682
06/01/2022 04:04:56 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.97 on epoch=684
06/01/2022 04:04:57 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.90 on epoch=687
06/01/2022 04:04:58 - INFO - __main__ - Global step 2750 Train loss 0.92 Classification-F1 0.1 on epoch=687
06/01/2022 04:04:59 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.93 on epoch=689
06/01/2022 04:05:00 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.90 on epoch=692
06/01/2022 04:05:02 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.87 on epoch=694
06/01/2022 04:05:03 - INFO - __main__ - Step 2790 Global step 2790 Train loss 1.01 on epoch=697
06/01/2022 04:05:04 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.90 on epoch=699
06/01/2022 04:05:05 - INFO - __main__ - Global step 2800 Train loss 0.92 Classification-F1 0.1875814155449414 on epoch=699
06/01/2022 04:05:06 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.90 on epoch=702
06/01/2022 04:05:07 - INFO - __main__ - Step 2820 Global step 2820 Train loss 1.10 on epoch=704
06/01/2022 04:05:09 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.92 on epoch=707
06/01/2022 04:05:10 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.93 on epoch=709
06/01/2022 04:05:11 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.89 on epoch=712
06/01/2022 04:05:12 - INFO - __main__ - Global step 2850 Train loss 0.95 Classification-F1 0.1 on epoch=712
06/01/2022 04:05:13 - INFO - __main__ - Step 2860 Global step 2860 Train loss 1.00 on epoch=714
06/01/2022 04:05:14 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.89 on epoch=717
06/01/2022 04:05:16 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.94 on epoch=719
06/01/2022 04:05:17 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.92 on epoch=722
06/01/2022 04:05:18 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.97 on epoch=724
06/01/2022 04:05:19 - INFO - __main__ - Global step 2900 Train loss 0.94 Classification-F1 0.1115492957746479 on epoch=724
06/01/2022 04:05:20 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.00 on epoch=727
06/01/2022 04:05:21 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.97 on epoch=729
06/01/2022 04:05:23 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.95 on epoch=732
06/01/2022 04:05:24 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.97 on epoch=734
06/01/2022 04:05:25 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.91 on epoch=737
06/01/2022 04:05:26 - INFO - __main__ - Global step 2950 Train loss 0.96 Classification-F1 0.09210526315789473 on epoch=737
06/01/2022 04:05:27 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.99 on epoch=739
06/01/2022 04:05:29 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.03 on epoch=742
06/01/2022 04:05:30 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.99 on epoch=744
06/01/2022 04:05:31 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.91 on epoch=747
06/01/2022 04:05:32 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.86 on epoch=749
06/01/2022 04:05:33 - INFO - __main__ - Global step 3000 Train loss 0.96 Classification-F1 0.0625 on epoch=749
06/01/2022 04:05:33 - INFO - __main__ - save last model!
06/01/2022 04:05:33 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/01/2022 04:05:33 - INFO - __main__ - Start tokenizing ... 5509 instances
06/01/2022 04:05:33 - INFO - __main__ - Printing 3 examples
06/01/2022 04:05:33 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/01/2022 04:05:33 - INFO - __main__ - ['others']
06/01/2022 04:05:33 - INFO - __main__ -  [emo] what you like very little things ok
06/01/2022 04:05:33 - INFO - __main__ - ['others']
06/01/2022 04:05:33 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/01/2022 04:05:33 - INFO - __main__ - ['others']
06/01/2022 04:05:33 - INFO - __main__ - Tokenizing Input ...
06/01/2022 04:05:34 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 04:05:34 - INFO - __main__ - Printing 3 examples
06/01/2022 04:05:34 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/01/2022 04:05:34 - INFO - __main__ - ['happy']
06/01/2022 04:05:34 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/01/2022 04:05:34 - INFO - __main__ - ['happy']
06/01/2022 04:05:34 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/01/2022 04:05:34 - INFO - __main__ - ['happy']
06/01/2022 04:05:34 - INFO - __main__ - Tokenizing Input ...
06/01/2022 04:05:34 - INFO - __main__ - Tokenizing Output ...
06/01/2022 04:05:34 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 04:05:34 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 04:05:34 - INFO - __main__ - Printing 3 examples
06/01/2022 04:05:34 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
06/01/2022 04:05:34 - INFO - __main__ - ['happy']
06/01/2022 04:05:34 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
06/01/2022 04:05:34 - INFO - __main__ - ['happy']
06/01/2022 04:05:34 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
06/01/2022 04:05:34 - INFO - __main__ - ['happy']
06/01/2022 04:05:34 - INFO - __main__ - Tokenizing Input ...
06/01/2022 04:05:34 - INFO - __main__ - Tokenizing Output ...
06/01/2022 04:05:34 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 04:05:35 - INFO - __main__ - Tokenizing Output ...
06/01/2022 04:05:39 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 04:05:40 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/01/2022 04:05:40 - INFO - __main__ - Starting training!
06/01/2022 04:05:40 - INFO - __main__ - Loaded 5509 examples from test data
06/01/2022 04:06:25 - INFO - __main__ - Saved prediction in models/T5-base-reptile-cls2cls-3e-5-2-5000-5e-1-10/singletask-emo/emo_16_42_0.5_8_predictions.txt
06/01/2022 04:06:25 - INFO - __main__ - Classification-F1 on test data: 0.0456
06/01/2022 04:06:25 - INFO - __main__ - prefix=emo_16_42, lr=0.5, bsz=8, dev_performance=0.25396825396825395, test_performance=0.04555459605248868
06/01/2022 04:06:25 - INFO - __main__ - Running ... prefix=emo_16_42, lr=0.4, bsz=8 ...
06/01/2022 04:06:26 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 04:06:26 - INFO - __main__ - Printing 3 examples
06/01/2022 04:06:26 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/01/2022 04:06:26 - INFO - __main__ - ['happy']
06/01/2022 04:06:26 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/01/2022 04:06:26 - INFO - __main__ - ['happy']
06/01/2022 04:06:26 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/01/2022 04:06:26 - INFO - __main__ - ['happy']
06/01/2022 04:06:26 - INFO - __main__ - Tokenizing Input ...
06/01/2022 04:06:26 - INFO - __main__ - Tokenizing Output ...
06/01/2022 04:06:26 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 04:06:26 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 04:06:26 - INFO - __main__ - Printing 3 examples
06/01/2022 04:06:26 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
06/01/2022 04:06:26 - INFO - __main__ - ['happy']
06/01/2022 04:06:26 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
06/01/2022 04:06:26 - INFO - __main__ - ['happy']
06/01/2022 04:06:26 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
06/01/2022 04:06:26 - INFO - __main__ - ['happy']
06/01/2022 04:06:26 - INFO - __main__ - Tokenizing Input ...
06/01/2022 04:06:26 - INFO - __main__ - Tokenizing Output ...
06/01/2022 04:06:26 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 04:06:32 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 04:06:32 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/01/2022 04:06:32 - INFO - __main__ - Starting training!
06/01/2022 04:06:33 - INFO - __main__ - Step 10 Global step 10 Train loss 9.04 on epoch=2
06/01/2022 04:06:35 - INFO - __main__ - Step 20 Global step 20 Train loss 8.93 on epoch=4
06/01/2022 04:06:36 - INFO - __main__ - Step 30 Global step 30 Train loss 8.90 on epoch=7
06/01/2022 04:06:37 - INFO - __main__ - Step 40 Global step 40 Train loss 8.80 on epoch=9
06/01/2022 04:06:39 - INFO - __main__ - Step 50 Global step 50 Train loss 8.67 on epoch=12
06/01/2022 04:06:48 - INFO - __main__ - Global step 50 Train loss 8.87 Classification-F1 0.0 on epoch=12
06/01/2022 04:06:48 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
06/01/2022 04:06:50 - INFO - __main__ - Step 60 Global step 60 Train loss 8.69 on epoch=14
06/01/2022 04:06:51 - INFO - __main__ - Step 70 Global step 70 Train loss 8.76 on epoch=17
06/01/2022 04:06:52 - INFO - __main__ - Step 80 Global step 80 Train loss 8.64 on epoch=19
06/01/2022 04:06:53 - INFO - __main__ - Step 90 Global step 90 Train loss 8.55 on epoch=22
06/01/2022 04:06:55 - INFO - __main__ - Step 100 Global step 100 Train loss 8.57 on epoch=24
06/01/2022 04:07:05 - INFO - __main__ - Global step 100 Train loss 8.64 Classification-F1 0.0 on epoch=24
06/01/2022 04:07:06 - INFO - __main__ - Step 110 Global step 110 Train loss 8.36 on epoch=27
06/01/2022 04:07:07 - INFO - __main__ - Step 120 Global step 120 Train loss 8.14 on epoch=29
06/01/2022 04:07:09 - INFO - __main__ - Step 130 Global step 130 Train loss 8.00 on epoch=32
06/01/2022 04:07:10 - INFO - __main__ - Step 140 Global step 140 Train loss 7.78 on epoch=34
06/01/2022 04:07:11 - INFO - __main__ - Step 150 Global step 150 Train loss 7.84 on epoch=37
06/01/2022 04:07:16 - INFO - __main__ - Global step 150 Train loss 8.02 Classification-F1 0.0 on epoch=37
06/01/2022 04:07:18 - INFO - __main__ - Step 160 Global step 160 Train loss 7.80 on epoch=39
06/01/2022 04:07:19 - INFO - __main__ - Step 170 Global step 170 Train loss 7.68 on epoch=42
06/01/2022 04:07:20 - INFO - __main__ - Step 180 Global step 180 Train loss 7.58 on epoch=44
06/01/2022 04:07:22 - INFO - __main__ - Step 190 Global step 190 Train loss 7.41 on epoch=47
06/01/2022 04:07:23 - INFO - __main__ - Step 200 Global step 200 Train loss 7.43 on epoch=49
06/01/2022 04:07:25 - INFO - __main__ - Global step 200 Train loss 7.58 Classification-F1 0.0 on epoch=49
06/01/2022 04:07:26 - INFO - __main__ - Step 210 Global step 210 Train loss 7.13 on epoch=52
06/01/2022 04:07:28 - INFO - __main__ - Step 220 Global step 220 Train loss 7.02 on epoch=54
06/01/2022 04:07:29 - INFO - __main__ - Step 230 Global step 230 Train loss 6.87 on epoch=57
06/01/2022 04:07:30 - INFO - __main__ - Step 240 Global step 240 Train loss 6.90 on epoch=59
06/01/2022 04:07:31 - INFO - __main__ - Step 250 Global step 250 Train loss 6.67 on epoch=62
06/01/2022 04:07:35 - INFO - __main__ - Global step 250 Train loss 6.92 Classification-F1 0.0 on epoch=62
06/01/2022 04:07:36 - INFO - __main__ - Step 260 Global step 260 Train loss 6.69 on epoch=64
06/01/2022 04:07:38 - INFO - __main__ - Step 270 Global step 270 Train loss 6.31 on epoch=67
06/01/2022 04:07:39 - INFO - __main__ - Step 280 Global step 280 Train loss 6.24 on epoch=69
06/01/2022 04:07:40 - INFO - __main__ - Step 290 Global step 290 Train loss 6.08 on epoch=72
06/01/2022 04:07:42 - INFO - __main__ - Step 300 Global step 300 Train loss 5.97 on epoch=74
06/01/2022 04:07:48 - INFO - __main__ - Global step 300 Train loss 6.26 Classification-F1 0.0 on epoch=74
06/01/2022 04:07:49 - INFO - __main__ - Step 310 Global step 310 Train loss 5.99 on epoch=77
06/01/2022 04:07:50 - INFO - __main__ - Step 320 Global step 320 Train loss 5.92 on epoch=79
06/01/2022 04:07:51 - INFO - __main__ - Step 330 Global step 330 Train loss 5.73 on epoch=82
06/01/2022 04:07:53 - INFO - __main__ - Step 340 Global step 340 Train loss 5.63 on epoch=84
06/01/2022 04:07:54 - INFO - __main__ - Step 350 Global step 350 Train loss 5.60 on epoch=87
06/01/2022 04:08:00 - INFO - __main__ - Global step 350 Train loss 5.78 Classification-F1 0.0 on epoch=87
06/01/2022 04:08:01 - INFO - __main__ - Step 360 Global step 360 Train loss 5.49 on epoch=89
06/01/2022 04:08:02 - INFO - __main__ - Step 370 Global step 370 Train loss 5.31 on epoch=92
06/01/2022 04:08:04 - INFO - __main__ - Step 380 Global step 380 Train loss 5.31 on epoch=94
06/01/2022 04:08:05 - INFO - __main__ - Step 390 Global step 390 Train loss 5.03 on epoch=97
06/01/2022 04:08:06 - INFO - __main__ - Step 400 Global step 400 Train loss 5.19 on epoch=99
06/01/2022 04:08:11 - INFO - __main__ - Global step 400 Train loss 5.27 Classification-F1 0.0 on epoch=99
06/01/2022 04:08:12 - INFO - __main__ - Step 410 Global step 410 Train loss 5.05 on epoch=102
06/01/2022 04:08:13 - INFO - __main__ - Step 420 Global step 420 Train loss 5.05 on epoch=104
06/01/2022 04:08:15 - INFO - __main__ - Step 430 Global step 430 Train loss 4.79 on epoch=107
06/01/2022 04:08:16 - INFO - __main__ - Step 440 Global step 440 Train loss 4.86 on epoch=109
06/01/2022 04:08:17 - INFO - __main__ - Step 450 Global step 450 Train loss 4.50 on epoch=112
06/01/2022 04:08:21 - INFO - __main__ - Global step 450 Train loss 4.85 Classification-F1 0.0 on epoch=112
06/01/2022 04:08:23 - INFO - __main__ - Step 460 Global step 460 Train loss 4.69 on epoch=114
06/01/2022 04:08:24 - INFO - __main__ - Step 470 Global step 470 Train loss 4.69 on epoch=117
06/01/2022 04:08:25 - INFO - __main__ - Step 480 Global step 480 Train loss 4.58 on epoch=119
06/01/2022 04:08:27 - INFO - __main__ - Step 490 Global step 490 Train loss 4.32 on epoch=122
06/01/2022 04:08:28 - INFO - __main__ - Step 500 Global step 500 Train loss 4.51 on epoch=124
06/01/2022 04:08:33 - INFO - __main__ - Global step 500 Train loss 4.56 Classification-F1 0.0 on epoch=124
06/01/2022 04:08:34 - INFO - __main__ - Step 510 Global step 510 Train loss 4.34 on epoch=127
06/01/2022 04:08:35 - INFO - __main__ - Step 520 Global step 520 Train loss 4.20 on epoch=129
06/01/2022 04:08:37 - INFO - __main__ - Step 530 Global step 530 Train loss 4.14 on epoch=132
06/01/2022 04:08:38 - INFO - __main__ - Step 540 Global step 540 Train loss 4.12 on epoch=134
06/01/2022 04:08:39 - INFO - __main__ - Step 550 Global step 550 Train loss 3.92 on epoch=137
06/01/2022 04:08:43 - INFO - __main__ - Global step 550 Train loss 4.15 Classification-F1 0.014705882352941176 on epoch=137
06/01/2022 04:08:43 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.014705882352941176 on epoch=137, global_step=550
06/01/2022 04:08:44 - INFO - __main__ - Step 560 Global step 560 Train loss 3.88 on epoch=139
06/01/2022 04:08:46 - INFO - __main__ - Step 570 Global step 570 Train loss 3.72 on epoch=142
06/01/2022 04:08:47 - INFO - __main__ - Step 580 Global step 580 Train loss 3.89 on epoch=144
06/01/2022 04:08:48 - INFO - __main__ - Step 590 Global step 590 Train loss 3.58 on epoch=147
06/01/2022 04:08:50 - INFO - __main__ - Step 600 Global step 600 Train loss 3.55 on epoch=149
06/01/2022 04:08:52 - INFO - __main__ - Global step 600 Train loss 3.72 Classification-F1 0.12638146167557932 on epoch=149
06/01/2022 04:08:52 - INFO - __main__ - Saving model with best Classification-F1: 0.014705882352941176 -> 0.12638146167557932 on epoch=149, global_step=600
06/01/2022 04:08:53 - INFO - __main__ - Step 610 Global step 610 Train loss 3.59 on epoch=152
06/01/2022 04:08:54 - INFO - __main__ - Step 620 Global step 620 Train loss 3.53 on epoch=154
06/01/2022 04:08:55 - INFO - __main__ - Step 630 Global step 630 Train loss 3.33 on epoch=157
06/01/2022 04:08:57 - INFO - __main__ - Step 640 Global step 640 Train loss 3.18 on epoch=159
06/01/2022 04:08:58 - INFO - __main__ - Step 650 Global step 650 Train loss 3.17 on epoch=162
06/01/2022 04:08:59 - INFO - __main__ - Global step 650 Train loss 3.36 Classification-F1 0.17712418300653593 on epoch=162
06/01/2022 04:08:59 - INFO - __main__ - Saving model with best Classification-F1: 0.12638146167557932 -> 0.17712418300653593 on epoch=162, global_step=650
06/01/2022 04:09:00 - INFO - __main__ - Step 660 Global step 660 Train loss 2.97 on epoch=164
06/01/2022 04:09:01 - INFO - __main__ - Step 670 Global step 670 Train loss 2.73 on epoch=167
06/01/2022 04:09:03 - INFO - __main__ - Step 680 Global step 680 Train loss 3.04 on epoch=169
06/01/2022 04:09:04 - INFO - __main__ - Step 690 Global step 690 Train loss 2.66 on epoch=172
06/01/2022 04:09:05 - INFO - __main__ - Step 700 Global step 700 Train loss 2.62 on epoch=174
06/01/2022 04:09:06 - INFO - __main__ - Global step 700 Train loss 2.80 Classification-F1 0.14210526315789473 on epoch=174
06/01/2022 04:09:07 - INFO - __main__ - Step 710 Global step 710 Train loss 2.43 on epoch=177
06/01/2022 04:09:08 - INFO - __main__ - Step 720 Global step 720 Train loss 2.30 on epoch=179
06/01/2022 04:09:10 - INFO - __main__ - Step 730 Global step 730 Train loss 2.37 on epoch=182
06/01/2022 04:09:11 - INFO - __main__ - Step 740 Global step 740 Train loss 2.35 on epoch=184
06/01/2022 04:09:12 - INFO - __main__ - Step 750 Global step 750 Train loss 2.21 on epoch=187
06/01/2022 04:09:13 - INFO - __main__ - Global step 750 Train loss 2.33 Classification-F1 0.19285714285714284 on epoch=187
06/01/2022 04:09:13 - INFO - __main__ - Saving model with best Classification-F1: 0.17712418300653593 -> 0.19285714285714284 on epoch=187, global_step=750
06/01/2022 04:09:14 - INFO - __main__ - Step 760 Global step 760 Train loss 2.00 on epoch=189
06/01/2022 04:09:15 - INFO - __main__ - Step 770 Global step 770 Train loss 2.18 on epoch=192
06/01/2022 04:09:16 - INFO - __main__ - Step 780 Global step 780 Train loss 2.06 on epoch=194
06/01/2022 04:09:18 - INFO - __main__ - Step 790 Global step 790 Train loss 2.06 on epoch=197
06/01/2022 04:09:19 - INFO - __main__ - Step 800 Global step 800 Train loss 2.00 on epoch=199
06/01/2022 04:09:20 - INFO - __main__ - Global step 800 Train loss 2.06 Classification-F1 0.13300248138957815 on epoch=199
06/01/2022 04:09:21 - INFO - __main__ - Step 810 Global step 810 Train loss 1.94 on epoch=202
06/01/2022 04:09:22 - INFO - __main__ - Step 820 Global step 820 Train loss 1.94 on epoch=204
06/01/2022 04:09:23 - INFO - __main__ - Step 830 Global step 830 Train loss 1.95 on epoch=207
06/01/2022 04:09:25 - INFO - __main__ - Step 840 Global step 840 Train loss 1.74 on epoch=209
06/01/2022 04:09:26 - INFO - __main__ - Step 850 Global step 850 Train loss 1.73 on epoch=212
06/01/2022 04:09:27 - INFO - __main__ - Global step 850 Train loss 1.86 Classification-F1 0.16666666666666663 on epoch=212
06/01/2022 04:09:28 - INFO - __main__ - Step 860 Global step 860 Train loss 1.87 on epoch=214
06/01/2022 04:09:29 - INFO - __main__ - Step 870 Global step 870 Train loss 1.64 on epoch=217
06/01/2022 04:09:30 - INFO - __main__ - Step 880 Global step 880 Train loss 1.76 on epoch=219
06/01/2022 04:09:32 - INFO - __main__ - Step 890 Global step 890 Train loss 1.83 on epoch=222
06/01/2022 04:09:33 - INFO - __main__ - Step 900 Global step 900 Train loss 1.73 on epoch=224
06/01/2022 04:09:34 - INFO - __main__ - Global step 900 Train loss 1.77 Classification-F1 0.1755366726296959 on epoch=224
06/01/2022 04:09:35 - INFO - __main__ - Step 910 Global step 910 Train loss 1.66 on epoch=227
06/01/2022 04:09:36 - INFO - __main__ - Step 920 Global step 920 Train loss 1.67 on epoch=229
06/01/2022 04:09:38 - INFO - __main__ - Step 930 Global step 930 Train loss 1.76 on epoch=232
06/01/2022 04:09:39 - INFO - __main__ - Step 940 Global step 940 Train loss 1.66 on epoch=234
06/01/2022 04:09:40 - INFO - __main__ - Step 950 Global step 950 Train loss 1.60 on epoch=237
06/01/2022 04:09:41 - INFO - __main__ - Global step 950 Train loss 1.67 Classification-F1 0.17344312918167784 on epoch=237
06/01/2022 04:09:42 - INFO - __main__ - Step 960 Global step 960 Train loss 1.70 on epoch=239
06/01/2022 04:09:43 - INFO - __main__ - Step 970 Global step 970 Train loss 1.65 on epoch=242
06/01/2022 04:09:45 - INFO - __main__ - Step 980 Global step 980 Train loss 1.69 on epoch=244
06/01/2022 04:09:46 - INFO - __main__ - Step 990 Global step 990 Train loss 1.59 on epoch=247
06/01/2022 04:09:47 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.54 on epoch=249
06/01/2022 04:09:48 - INFO - __main__ - Global step 1000 Train loss 1.63 Classification-F1 0.20617715617715618 on epoch=249
06/01/2022 04:09:48 - INFO - __main__ - Saving model with best Classification-F1: 0.19285714285714284 -> 0.20617715617715618 on epoch=249, global_step=1000
06/01/2022 04:09:49 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.61 on epoch=252
06/01/2022 04:09:50 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.68 on epoch=254
06/01/2022 04:09:52 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.62 on epoch=257
06/01/2022 04:09:53 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.60 on epoch=259
06/01/2022 04:09:54 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.43 on epoch=262
06/01/2022 04:09:55 - INFO - __main__ - Global step 1050 Train loss 1.59 Classification-F1 0.17857142857142858 on epoch=262
06/01/2022 04:09:56 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.48 on epoch=264
06/01/2022 04:09:57 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.47 on epoch=267
06/01/2022 04:09:59 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.32 on epoch=269
06/01/2022 04:10:00 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.57 on epoch=272
06/01/2022 04:10:01 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.35 on epoch=274
06/01/2022 04:10:02 - INFO - __main__ - Global step 1100 Train loss 1.44 Classification-F1 0.22059553349875932 on epoch=274
06/01/2022 04:10:02 - INFO - __main__ - Saving model with best Classification-F1: 0.20617715617715618 -> 0.22059553349875932 on epoch=274, global_step=1100
06/01/2022 04:10:03 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.37 on epoch=277
06/01/2022 04:10:04 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.37 on epoch=279
06/01/2022 04:10:06 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.45 on epoch=282
06/01/2022 04:10:07 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.41 on epoch=284
06/01/2022 04:10:08 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.33 on epoch=287
06/01/2022 04:10:09 - INFO - __main__ - Global step 1150 Train loss 1.39 Classification-F1 0.12462006079027355 on epoch=287
06/01/2022 04:10:10 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.40 on epoch=289
06/01/2022 04:10:11 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.42 on epoch=292
06/01/2022 04:10:12 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.44 on epoch=294
06/01/2022 04:10:14 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.33 on epoch=297
06/01/2022 04:10:15 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.35 on epoch=299
06/01/2022 04:10:15 - INFO - __main__ - Global step 1200 Train loss 1.39 Classification-F1 0.07042253521126761 on epoch=299
06/01/2022 04:10:17 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.44 on epoch=302
06/01/2022 04:10:18 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.28 on epoch=304
06/01/2022 04:10:19 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.43 on epoch=307
06/01/2022 04:10:21 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.46 on epoch=309
06/01/2022 04:10:22 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.22 on epoch=312
06/01/2022 04:10:22 - INFO - __main__ - Global step 1250 Train loss 1.37 Classification-F1 0.1 on epoch=312
06/01/2022 04:10:24 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.34 on epoch=314
06/01/2022 04:10:25 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.38 on epoch=317
06/01/2022 04:10:26 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.27 on epoch=319
06/01/2022 04:10:28 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.40 on epoch=322
06/01/2022 04:10:29 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.24 on epoch=324
06/01/2022 04:10:29 - INFO - __main__ - Global step 1300 Train loss 1.33 Classification-F1 0.1 on epoch=324
06/01/2022 04:10:31 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.15 on epoch=327
06/01/2022 04:10:32 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.30 on epoch=329
06/01/2022 04:10:33 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.25 on epoch=332
06/01/2022 04:10:35 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.32 on epoch=334
06/01/2022 04:10:36 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.31 on epoch=337
06/01/2022 04:10:36 - INFO - __main__ - Global step 1350 Train loss 1.27 Classification-F1 0.10126582278481013 on epoch=337
06/01/2022 04:10:38 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.24 on epoch=339
06/01/2022 04:10:39 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.08 on epoch=342
06/01/2022 04:10:40 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.25 on epoch=344
06/01/2022 04:10:42 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.22 on epoch=347
06/01/2022 04:10:43 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.23 on epoch=349
06/01/2022 04:10:43 - INFO - __main__ - Global step 1400 Train loss 1.20 Classification-F1 0.1 on epoch=349
06/01/2022 04:10:45 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.19 on epoch=352
06/01/2022 04:10:46 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.19 on epoch=354
06/01/2022 04:10:47 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.30 on epoch=357
06/01/2022 04:10:49 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.24 on epoch=359
06/01/2022 04:10:50 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.17 on epoch=362
06/01/2022 04:10:50 - INFO - __main__ - Global step 1450 Train loss 1.22 Classification-F1 0.1 on epoch=362
06/01/2022 04:10:52 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.26 on epoch=364
06/01/2022 04:10:53 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.14 on epoch=367
06/01/2022 04:10:54 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.19 on epoch=369
06/01/2022 04:10:56 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.21 on epoch=372
06/01/2022 04:10:57 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.25 on epoch=374
06/01/2022 04:10:57 - INFO - __main__ - Global step 1500 Train loss 1.21 Classification-F1 0.1 on epoch=374
06/01/2022 04:10:59 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.17 on epoch=377
06/01/2022 04:11:00 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.36 on epoch=379
06/01/2022 04:11:01 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.23 on epoch=382
06/01/2022 04:11:02 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.09 on epoch=384
06/01/2022 04:11:04 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.09 on epoch=387
06/01/2022 04:11:04 - INFO - __main__ - Global step 1550 Train loss 1.19 Classification-F1 0.09493670886075949 on epoch=387
06/01/2022 04:11:06 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.16 on epoch=389
06/01/2022 04:11:07 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.00 on epoch=392
06/01/2022 04:11:08 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.19 on epoch=394
06/01/2022 04:11:09 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.21 on epoch=397
06/01/2022 04:11:11 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.11 on epoch=399
06/01/2022 04:11:11 - INFO - __main__ - Global step 1600 Train loss 1.13 Classification-F1 0.1 on epoch=399
06/01/2022 04:11:13 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.17 on epoch=402
06/01/2022 04:11:14 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.26 on epoch=404
06/01/2022 04:11:15 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.01 on epoch=407
06/01/2022 04:11:16 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.23 on epoch=409
06/01/2022 04:11:18 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.15 on epoch=412
06/01/2022 04:11:18 - INFO - __main__ - Global step 1650 Train loss 1.16 Classification-F1 0.1 on epoch=412
06/01/2022 04:11:20 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.17 on epoch=414
06/01/2022 04:11:21 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.22 on epoch=417
06/01/2022 04:11:22 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.11 on epoch=419
06/01/2022 04:11:23 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.01 on epoch=422
06/01/2022 04:11:25 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.13 on epoch=424
06/01/2022 04:11:25 - INFO - __main__ - Global step 1700 Train loss 1.13 Classification-F1 0.1 on epoch=424
06/01/2022 04:11:27 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.20 on epoch=427
06/01/2022 04:11:28 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.05 on epoch=429
06/01/2022 04:11:29 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.13 on epoch=432
06/01/2022 04:11:30 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.21 on epoch=434
06/01/2022 04:11:32 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.19 on epoch=437
06/01/2022 04:11:32 - INFO - __main__ - Global step 1750 Train loss 1.16 Classification-F1 0.10256410256410256 on epoch=437
06/01/2022 04:11:34 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.14 on epoch=439
06/01/2022 04:11:35 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.18 on epoch=442
06/01/2022 04:11:36 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.15 on epoch=444
06/01/2022 04:11:37 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.09 on epoch=447
06/01/2022 04:11:39 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.20 on epoch=449
06/01/2022 04:11:39 - INFO - __main__ - Global step 1800 Train loss 1.15 Classification-F1 0.1 on epoch=449
06/01/2022 04:11:41 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.00 on epoch=452
06/01/2022 04:11:42 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.08 on epoch=454
06/01/2022 04:11:43 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.07 on epoch=457
06/01/2022 04:11:44 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.09 on epoch=459
06/01/2022 04:11:46 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.14 on epoch=462
06/01/2022 04:11:46 - INFO - __main__ - Global step 1850 Train loss 1.08 Classification-F1 0.13026315789473686 on epoch=462
06/01/2022 04:11:47 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.10 on epoch=464
06/01/2022 04:11:49 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.03 on epoch=467
06/01/2022 04:11:50 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.07 on epoch=469
06/01/2022 04:11:51 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.06 on epoch=472
06/01/2022 04:11:53 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.03 on epoch=474
06/01/2022 04:11:53 - INFO - __main__ - Global step 1900 Train loss 1.06 Classification-F1 0.13859154929577466 on epoch=474
06/01/2022 04:11:54 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.08 on epoch=477
06/01/2022 04:11:56 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.10 on epoch=479
06/01/2022 04:11:57 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.04 on epoch=482
06/01/2022 04:11:58 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.03 on epoch=484
06/01/2022 04:11:59 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.12 on epoch=487
06/01/2022 04:12:00 - INFO - __main__ - Global step 1950 Train loss 1.08 Classification-F1 0.13034188034188032 on epoch=487
06/01/2022 04:12:01 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.03 on epoch=489
06/01/2022 04:12:03 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.11 on epoch=492
06/01/2022 04:12:04 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.11 on epoch=494
06/01/2022 04:12:05 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.97 on epoch=497
06/01/2022 04:12:06 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.16 on epoch=499
06/01/2022 04:12:07 - INFO - __main__ - Global step 2000 Train loss 1.08 Classification-F1 0.1 on epoch=499
06/01/2022 04:12:08 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.02 on epoch=502
06/01/2022 04:12:09 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.08 on epoch=504
06/01/2022 04:12:11 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.06 on epoch=507
06/01/2022 04:12:12 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.05 on epoch=509
06/01/2022 04:12:13 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.02 on epoch=512
06/01/2022 04:12:14 - INFO - __main__ - Global step 2050 Train loss 1.05 Classification-F1 0.1 on epoch=512
06/01/2022 04:12:15 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.01 on epoch=514
06/01/2022 04:12:16 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.07 on epoch=517
06/01/2022 04:12:18 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.99 on epoch=519
06/01/2022 04:12:19 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.10 on epoch=522
06/01/2022 04:12:20 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.99 on epoch=524
06/01/2022 04:12:21 - INFO - __main__ - Global step 2100 Train loss 1.03 Classification-F1 0.15356265356265356 on epoch=524
06/01/2022 04:12:22 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.92 on epoch=527
06/01/2022 04:12:23 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.12 on epoch=529
06/01/2022 04:12:24 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.10 on epoch=532
06/01/2022 04:12:26 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.04 on epoch=534
06/01/2022 04:12:27 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.11 on epoch=537
06/01/2022 04:12:27 - INFO - __main__ - Global step 2150 Train loss 1.05 Classification-F1 0.08904109589041095 on epoch=537
06/01/2022 04:12:29 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.02 on epoch=539
06/01/2022 04:12:30 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.10 on epoch=542
06/01/2022 04:12:31 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.14 on epoch=544
06/01/2022 04:12:33 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.03 on epoch=547
06/01/2022 04:12:34 - INFO - __main__ - Step 2200 Global step 2200 Train loss 1.06 on epoch=549
06/01/2022 04:12:34 - INFO - __main__ - Global step 2200 Train loss 1.07 Classification-F1 0.10126582278481013 on epoch=549
06/01/2022 04:12:36 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.98 on epoch=552
06/01/2022 04:12:37 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.06 on epoch=554
06/01/2022 04:12:38 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.05 on epoch=557
06/01/2022 04:12:39 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.96 on epoch=559
06/01/2022 04:12:41 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.08 on epoch=562
06/01/2022 04:12:41 - INFO - __main__ - Global step 2250 Train loss 1.03 Classification-F1 0.1237183868762816 on epoch=562
06/01/2022 04:12:43 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.03 on epoch=564
06/01/2022 04:12:44 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.27 on epoch=567
06/01/2022 04:12:45 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.03 on epoch=569
06/01/2022 04:12:46 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.10 on epoch=572
06/01/2022 04:12:48 - INFO - __main__ - Step 2300 Global step 2300 Train loss 1.07 on epoch=574
06/01/2022 04:12:48 - INFO - __main__ - Global step 2300 Train loss 1.10 Classification-F1 0.2019607843137255 on epoch=574
06/01/2022 04:12:49 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.99 on epoch=577
06/01/2022 04:12:51 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.07 on epoch=579
06/01/2022 04:12:52 - INFO - __main__ - Step 2330 Global step 2330 Train loss 1.07 on epoch=582
06/01/2022 04:12:53 - INFO - __main__ - Step 2340 Global step 2340 Train loss 1.03 on epoch=584
06/01/2022 04:12:54 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.02 on epoch=587
06/01/2022 04:12:55 - INFO - __main__ - Global step 2350 Train loss 1.04 Classification-F1 0.1 on epoch=587
06/01/2022 04:12:56 - INFO - __main__ - Step 2360 Global step 2360 Train loss 1.06 on epoch=589
06/01/2022 04:12:57 - INFO - __main__ - Step 2370 Global step 2370 Train loss 1.05 on epoch=592
06/01/2022 04:12:59 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.97 on epoch=594
06/01/2022 04:13:00 - INFO - __main__ - Step 2390 Global step 2390 Train loss 1.04 on epoch=597
06/01/2022 04:13:01 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.91 on epoch=599
06/01/2022 04:13:02 - INFO - __main__ - Global step 2400 Train loss 1.01 Classification-F1 0.16451612903225807 on epoch=599
06/01/2022 04:13:03 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.90 on epoch=602
06/01/2022 04:13:04 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.91 on epoch=604
06/01/2022 04:13:06 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.97 on epoch=607
06/01/2022 04:13:07 - INFO - __main__ - Step 2440 Global step 2440 Train loss 1.07 on epoch=609
06/01/2022 04:13:08 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.91 on epoch=612
06/01/2022 04:13:09 - INFO - __main__ - Global step 2450 Train loss 0.95 Classification-F1 0.11714285714285715 on epoch=612
06/01/2022 04:13:10 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.07 on epoch=614
06/01/2022 04:13:11 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.96 on epoch=617
06/01/2022 04:13:13 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.00 on epoch=619
06/01/2022 04:13:14 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.95 on epoch=622
06/01/2022 04:13:15 - INFO - __main__ - Step 2500 Global step 2500 Train loss 1.00 on epoch=624
06/01/2022 04:13:16 - INFO - __main__ - Global step 2500 Train loss 1.00 Classification-F1 0.1 on epoch=624
06/01/2022 04:13:17 - INFO - __main__ - Step 2510 Global step 2510 Train loss 1.04 on epoch=627
06/01/2022 04:13:18 - INFO - __main__ - Step 2520 Global step 2520 Train loss 1.06 on epoch=629
06/01/2022 04:13:19 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.12 on epoch=632
06/01/2022 04:13:21 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.95 on epoch=634
06/01/2022 04:13:22 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.93 on epoch=637
06/01/2022 04:13:23 - INFO - __main__ - Global step 2550 Train loss 1.02 Classification-F1 0.1468058968058968 on epoch=637
06/01/2022 04:13:24 - INFO - __main__ - Step 2560 Global step 2560 Train loss 1.02 on epoch=639
06/01/2022 04:13:25 - INFO - __main__ - Step 2570 Global step 2570 Train loss 1.01 on epoch=642
06/01/2022 04:13:26 - INFO - __main__ - Step 2580 Global step 2580 Train loss 1.08 on epoch=644
06/01/2022 04:13:28 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.98 on epoch=647
06/01/2022 04:13:29 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.03 on epoch=649
06/01/2022 04:13:29 - INFO - __main__ - Global step 2600 Train loss 1.02 Classification-F1 0.16402714932126694 on epoch=649
06/01/2022 04:13:31 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.97 on epoch=652
06/01/2022 04:13:32 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.96 on epoch=654
06/01/2022 04:13:33 - INFO - __main__ - Step 2630 Global step 2630 Train loss 1.01 on epoch=657
06/01/2022 04:13:34 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.05 on epoch=659
06/01/2022 04:13:36 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.86 on epoch=662
06/01/2022 04:13:36 - INFO - __main__ - Global step 2650 Train loss 0.97 Classification-F1 0.1 on epoch=662
06/01/2022 04:13:37 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.91 on epoch=664
06/01/2022 04:13:39 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.96 on epoch=667
06/01/2022 04:13:40 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.99 on epoch=669
06/01/2022 04:13:41 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.93 on epoch=672
06/01/2022 04:13:43 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.92 on epoch=674
06/01/2022 04:13:43 - INFO - __main__ - Global step 2700 Train loss 0.94 Classification-F1 0.13034188034188032 on epoch=674
06/01/2022 04:13:44 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.03 on epoch=677
06/01/2022 04:13:46 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.92 on epoch=679
06/01/2022 04:13:47 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.96 on epoch=682
06/01/2022 04:13:48 - INFO - __main__ - Step 2740 Global step 2740 Train loss 1.04 on epoch=684
06/01/2022 04:13:49 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.93 on epoch=687
06/01/2022 04:13:50 - INFO - __main__ - Global step 2750 Train loss 0.97 Classification-F1 0.14621798689696247 on epoch=687
06/01/2022 04:13:51 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.02 on epoch=689
06/01/2022 04:13:52 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.07 on epoch=692
06/01/2022 04:13:54 - INFO - __main__ - Step 2780 Global step 2780 Train loss 1.01 on epoch=694
06/01/2022 04:13:55 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.97 on epoch=697
06/01/2022 04:13:56 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.91 on epoch=699
06/01/2022 04:13:57 - INFO - __main__ - Global step 2800 Train loss 1.00 Classification-F1 0.19445676274944568 on epoch=699
06/01/2022 04:13:58 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.04 on epoch=702
06/01/2022 04:13:59 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.93 on epoch=704
06/01/2022 04:14:01 - INFO - __main__ - Step 2830 Global step 2830 Train loss 1.02 on epoch=707
06/01/2022 04:14:02 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.97 on epoch=709
06/01/2022 04:14:03 - INFO - __main__ - Step 2850 Global step 2850 Train loss 1.03 on epoch=712
06/01/2022 04:14:04 - INFO - __main__ - Global step 2850 Train loss 1.00 Classification-F1 0.13026315789473686 on epoch=712
06/01/2022 04:14:05 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.99 on epoch=714
06/01/2022 04:14:06 - INFO - __main__ - Step 2870 Global step 2870 Train loss 1.04 on epoch=717
06/01/2022 04:14:08 - INFO - __main__ - Step 2880 Global step 2880 Train loss 1.00 on epoch=719
06/01/2022 04:14:09 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.00 on epoch=722
06/01/2022 04:14:10 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.04 on epoch=724
06/01/2022 04:14:11 - INFO - __main__ - Global step 2900 Train loss 1.01 Classification-F1 0.13034188034188032 on epoch=724
06/01/2022 04:14:12 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.91 on epoch=727
06/01/2022 04:14:13 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.97 on epoch=729
06/01/2022 04:14:14 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.92 on epoch=732
06/01/2022 04:14:16 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.96 on epoch=734
06/01/2022 04:14:17 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.95 on epoch=737
06/01/2022 04:14:17 - INFO - __main__ - Global step 2950 Train loss 0.94 Classification-F1 0.1486291486291486 on epoch=737
06/01/2022 04:14:19 - INFO - __main__ - Step 2960 Global step 2960 Train loss 1.04 on epoch=739
06/01/2022 04:14:20 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.97 on epoch=742
06/01/2022 04:14:21 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.97 on epoch=744
06/01/2022 04:14:22 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.97 on epoch=747
06/01/2022 04:14:24 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.91 on epoch=749
06/01/2022 04:14:24 - INFO - __main__ - Global step 3000 Train loss 0.97 Classification-F1 0.1796875 on epoch=749
06/01/2022 04:14:24 - INFO - __main__ - save last model!
06/01/2022 04:14:24 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/01/2022 04:14:24 - INFO - __main__ - Start tokenizing ... 5509 instances
06/01/2022 04:14:24 - INFO - __main__ - Printing 3 examples
06/01/2022 04:14:24 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/01/2022 04:14:24 - INFO - __main__ - ['others']
06/01/2022 04:14:24 - INFO - __main__ -  [emo] what you like very little things ok
06/01/2022 04:14:24 - INFO - __main__ - ['others']
06/01/2022 04:14:24 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/01/2022 04:14:24 - INFO - __main__ - ['others']
06/01/2022 04:14:24 - INFO - __main__ - Tokenizing Input ...
06/01/2022 04:14:25 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 04:14:25 - INFO - __main__ - Printing 3 examples
06/01/2022 04:14:25 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/01/2022 04:14:25 - INFO - __main__ - ['happy']
06/01/2022 04:14:25 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/01/2022 04:14:25 - INFO - __main__ - ['happy']
06/01/2022 04:14:25 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/01/2022 04:14:25 - INFO - __main__ - ['happy']
06/01/2022 04:14:25 - INFO - __main__ - Tokenizing Input ...
06/01/2022 04:14:25 - INFO - __main__ - Tokenizing Output ...
06/01/2022 04:14:25 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 04:14:25 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 04:14:25 - INFO - __main__ - Printing 3 examples
06/01/2022 04:14:25 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
06/01/2022 04:14:25 - INFO - __main__ - ['happy']
06/01/2022 04:14:25 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
06/01/2022 04:14:25 - INFO - __main__ - ['happy']
06/01/2022 04:14:25 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
06/01/2022 04:14:25 - INFO - __main__ - ['happy']
06/01/2022 04:14:25 - INFO - __main__ - Tokenizing Input ...
06/01/2022 04:14:25 - INFO - __main__ - Tokenizing Output ...
06/01/2022 04:14:25 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 04:14:26 - INFO - __main__ - Tokenizing Output ...
06/01/2022 04:14:31 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 04:14:31 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/01/2022 04:14:31 - INFO - __main__ - Starting training!
06/01/2022 04:14:32 - INFO - __main__ - Loaded 5509 examples from test data
06/01/2022 04:15:16 - INFO - __main__ - Saved prediction in models/T5-base-reptile-cls2cls-3e-5-2-5000-5e-1-10/singletask-emo/emo_16_42_0.4_8_predictions.txt
06/01/2022 04:15:16 - INFO - __main__ - Classification-F1 on test data: 0.0431
06/01/2022 04:15:16 - INFO - __main__ - prefix=emo_16_42, lr=0.4, bsz=8, dev_performance=0.22059553349875932, test_performance=0.04313066122127823
06/01/2022 04:15:16 - INFO - __main__ - Running ... prefix=emo_16_42, lr=0.3, bsz=8 ...
06/01/2022 04:15:17 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 04:15:17 - INFO - __main__ - Printing 3 examples
06/01/2022 04:15:17 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/01/2022 04:15:17 - INFO - __main__ - ['happy']
06/01/2022 04:15:17 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/01/2022 04:15:17 - INFO - __main__ - ['happy']
06/01/2022 04:15:17 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/01/2022 04:15:17 - INFO - __main__ - ['happy']
06/01/2022 04:15:17 - INFO - __main__ - Tokenizing Input ...
06/01/2022 04:15:17 - INFO - __main__ - Tokenizing Output ...
06/01/2022 04:15:17 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 04:15:17 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 04:15:17 - INFO - __main__ - Printing 3 examples
06/01/2022 04:15:17 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
06/01/2022 04:15:17 - INFO - __main__ - ['happy']
06/01/2022 04:15:17 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
06/01/2022 04:15:17 - INFO - __main__ - ['happy']
06/01/2022 04:15:17 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
06/01/2022 04:15:17 - INFO - __main__ - ['happy']
06/01/2022 04:15:17 - INFO - __main__ - Tokenizing Input ...
06/01/2022 04:15:17 - INFO - __main__ - Tokenizing Output ...
06/01/2022 04:15:17 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 04:15:23 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 04:15:23 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/01/2022 04:15:23 - INFO - __main__ - Starting training!
06/01/2022 04:15:24 - INFO - __main__ - Step 10 Global step 10 Train loss 9.01 on epoch=2
06/01/2022 04:15:26 - INFO - __main__ - Step 20 Global step 20 Train loss 8.78 on epoch=4
06/01/2022 04:15:27 - INFO - __main__ - Step 30 Global step 30 Train loss 8.96 on epoch=7
06/01/2022 04:15:28 - INFO - __main__ - Step 40 Global step 40 Train loss 8.78 on epoch=9
06/01/2022 04:15:29 - INFO - __main__ - Step 50 Global step 50 Train loss 8.81 on epoch=12
06/01/2022 04:15:34 - INFO - __main__ - Global step 50 Train loss 8.87 Classification-F1 0.0 on epoch=12
06/01/2022 04:15:34 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
06/01/2022 04:15:36 - INFO - __main__ - Step 60 Global step 60 Train loss 8.74 on epoch=14
06/01/2022 04:15:37 - INFO - __main__ - Step 70 Global step 70 Train loss 8.72 on epoch=17
06/01/2022 04:15:38 - INFO - __main__ - Step 80 Global step 80 Train loss 8.52 on epoch=19
06/01/2022 04:15:39 - INFO - __main__ - Step 90 Global step 90 Train loss 8.63 on epoch=22
06/01/2022 04:15:41 - INFO - __main__ - Step 100 Global step 100 Train loss 8.47 on epoch=24
06/01/2022 04:15:46 - INFO - __main__ - Global step 100 Train loss 8.62 Classification-F1 0.0 on epoch=24
06/01/2022 04:15:47 - INFO - __main__ - Step 110 Global step 110 Train loss 8.49 on epoch=27
06/01/2022 04:15:48 - INFO - __main__ - Step 120 Global step 120 Train loss 8.48 on epoch=29
06/01/2022 04:15:49 - INFO - __main__ - Step 130 Global step 130 Train loss 8.39 on epoch=32
06/01/2022 04:15:51 - INFO - __main__ - Step 140 Global step 140 Train loss 8.19 on epoch=34
06/01/2022 04:15:52 - INFO - __main__ - Step 150 Global step 150 Train loss 8.32 on epoch=37
06/01/2022 04:16:01 - INFO - __main__ - Global step 150 Train loss 8.37 Classification-F1 0.0 on epoch=37
06/01/2022 04:16:03 - INFO - __main__ - Step 160 Global step 160 Train loss 8.10 on epoch=39
06/01/2022 04:16:04 - INFO - __main__ - Step 170 Global step 170 Train loss 8.06 on epoch=42
06/01/2022 04:16:05 - INFO - __main__ - Step 180 Global step 180 Train loss 7.81 on epoch=44
06/01/2022 04:16:06 - INFO - __main__ - Step 190 Global step 190 Train loss 7.77 on epoch=47
06/01/2022 04:16:08 - INFO - __main__ - Step 200 Global step 200 Train loss 7.67 on epoch=49
06/01/2022 04:16:20 - INFO - __main__ - Global step 200 Train loss 7.88 Classification-F1 0.0 on epoch=49
06/01/2022 04:16:21 - INFO - __main__ - Step 210 Global step 210 Train loss 7.47 on epoch=52
06/01/2022 04:16:22 - INFO - __main__ - Step 220 Global step 220 Train loss 7.23 on epoch=54
06/01/2022 04:16:24 - INFO - __main__ - Step 230 Global step 230 Train loss 7.03 on epoch=57
06/01/2022 04:16:25 - INFO - __main__ - Step 240 Global step 240 Train loss 6.99 on epoch=59
06/01/2022 04:16:26 - INFO - __main__ - Step 250 Global step 250 Train loss 6.93 on epoch=62
06/01/2022 04:16:30 - INFO - __main__ - Global step 250 Train loss 7.13 Classification-F1 0.0 on epoch=62
06/01/2022 04:16:31 - INFO - __main__ - Step 260 Global step 260 Train loss 6.87 on epoch=64
06/01/2022 04:16:32 - INFO - __main__ - Step 270 Global step 270 Train loss 6.74 on epoch=67
06/01/2022 04:16:34 - INFO - __main__ - Step 280 Global step 280 Train loss 6.57 on epoch=69
06/01/2022 04:16:35 - INFO - __main__ - Step 290 Global step 290 Train loss 6.58 on epoch=72
06/01/2022 04:16:36 - INFO - __main__ - Step 300 Global step 300 Train loss 6.37 on epoch=74
06/01/2022 04:16:40 - INFO - __main__ - Global step 300 Train loss 6.62 Classification-F1 0.0 on epoch=74
06/01/2022 04:16:41 - INFO - __main__ - Step 310 Global step 310 Train loss 6.33 on epoch=77
06/01/2022 04:16:42 - INFO - __main__ - Step 320 Global step 320 Train loss 6.13 on epoch=79
06/01/2022 04:16:44 - INFO - __main__ - Step 330 Global step 330 Train loss 6.05 on epoch=82
06/01/2022 04:16:45 - INFO - __main__ - Step 340 Global step 340 Train loss 6.00 on epoch=84
06/01/2022 04:16:46 - INFO - __main__ - Step 350 Global step 350 Train loss 5.95 on epoch=87
06/01/2022 04:16:50 - INFO - __main__ - Global step 350 Train loss 6.09 Classification-F1 0.0 on epoch=87
06/01/2022 04:16:52 - INFO - __main__ - Step 360 Global step 360 Train loss 5.92 on epoch=89
06/01/2022 04:16:53 - INFO - __main__ - Step 370 Global step 370 Train loss 5.75 on epoch=92
06/01/2022 04:16:54 - INFO - __main__ - Step 380 Global step 380 Train loss 5.79 on epoch=94
06/01/2022 04:16:55 - INFO - __main__ - Step 390 Global step 390 Train loss 5.55 on epoch=97
06/01/2022 04:16:57 - INFO - __main__ - Step 400 Global step 400 Train loss 5.62 on epoch=99
06/01/2022 04:17:01 - INFO - __main__ - Global step 400 Train loss 5.73 Classification-F1 0.0 on epoch=99
06/01/2022 04:17:02 - INFO - __main__ - Step 410 Global step 410 Train loss 5.33 on epoch=102
06/01/2022 04:17:03 - INFO - __main__ - Step 420 Global step 420 Train loss 5.25 on epoch=104
06/01/2022 04:17:04 - INFO - __main__ - Step 430 Global step 430 Train loss 5.38 on epoch=107
06/01/2022 04:17:06 - INFO - __main__ - Step 440 Global step 440 Train loss 5.34 on epoch=109
06/01/2022 04:17:07 - INFO - __main__ - Step 450 Global step 450 Train loss 5.12 on epoch=112
06/01/2022 04:17:10 - INFO - __main__ - Global step 450 Train loss 5.28 Classification-F1 0.0 on epoch=112
06/01/2022 04:17:12 - INFO - __main__ - Step 460 Global step 460 Train loss 5.17 on epoch=114
06/01/2022 04:17:13 - INFO - __main__ - Step 470 Global step 470 Train loss 5.18 on epoch=117
06/01/2022 04:17:14 - INFO - __main__ - Step 480 Global step 480 Train loss 5.05 on epoch=119
06/01/2022 04:17:16 - INFO - __main__ - Step 490 Global step 490 Train loss 4.96 on epoch=122
06/01/2022 04:17:17 - INFO - __main__ - Step 500 Global step 500 Train loss 4.88 on epoch=124
06/01/2022 04:17:21 - INFO - __main__ - Global step 500 Train loss 5.05 Classification-F1 0.0 on epoch=124
06/01/2022 04:17:22 - INFO - __main__ - Step 510 Global step 510 Train loss 4.90 on epoch=127
06/01/2022 04:17:23 - INFO - __main__ - Step 520 Global step 520 Train loss 4.74 on epoch=129
06/01/2022 04:17:24 - INFO - __main__ - Step 530 Global step 530 Train loss 4.73 on epoch=132
06/01/2022 04:17:26 - INFO - __main__ - Step 540 Global step 540 Train loss 4.74 on epoch=134
06/01/2022 04:17:27 - INFO - __main__ - Step 550 Global step 550 Train loss 4.46 on epoch=137
06/01/2022 04:17:31 - INFO - __main__ - Global step 550 Train loss 4.71 Classification-F1 0.0 on epoch=137
06/01/2022 04:17:32 - INFO - __main__ - Step 560 Global step 560 Train loss 4.57 on epoch=139
06/01/2022 04:17:34 - INFO - __main__ - Step 570 Global step 570 Train loss 4.37 on epoch=142
06/01/2022 04:17:35 - INFO - __main__ - Step 580 Global step 580 Train loss 4.42 on epoch=144
06/01/2022 04:17:36 - INFO - __main__ - Step 590 Global step 590 Train loss 4.26 on epoch=147
06/01/2022 04:17:37 - INFO - __main__ - Step 600 Global step 600 Train loss 4.27 on epoch=149
06/01/2022 04:17:42 - INFO - __main__ - Global step 600 Train loss 4.38 Classification-F1 0.0 on epoch=149
06/01/2022 04:17:44 - INFO - __main__ - Step 610 Global step 610 Train loss 4.22 on epoch=152
06/01/2022 04:17:45 - INFO - __main__ - Step 620 Global step 620 Train loss 4.31 on epoch=154
06/01/2022 04:17:46 - INFO - __main__ - Step 630 Global step 630 Train loss 4.10 on epoch=157
06/01/2022 04:17:47 - INFO - __main__ - Step 640 Global step 640 Train loss 4.05 on epoch=159
06/01/2022 04:17:49 - INFO - __main__ - Step 650 Global step 650 Train loss 4.02 on epoch=162
06/01/2022 04:17:57 - INFO - __main__ - Global step 650 Train loss 4.14 Classification-F1 0.0 on epoch=162
06/01/2022 04:17:58 - INFO - __main__ - Step 660 Global step 660 Train loss 4.21 on epoch=164
06/01/2022 04:17:59 - INFO - __main__ - Step 670 Global step 670 Train loss 4.09 on epoch=167
06/01/2022 04:18:00 - INFO - __main__ - Step 680 Global step 680 Train loss 4.12 on epoch=169
06/01/2022 04:18:02 - INFO - __main__ - Step 690 Global step 690 Train loss 3.71 on epoch=172
06/01/2022 04:18:03 - INFO - __main__ - Step 700 Global step 700 Train loss 3.89 on epoch=174
06/01/2022 04:18:05 - INFO - __main__ - Global step 700 Train loss 4.00 Classification-F1 0.018518518518518517 on epoch=174
06/01/2022 04:18:05 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.018518518518518517 on epoch=174, global_step=700
06/01/2022 04:18:06 - INFO - __main__ - Step 710 Global step 710 Train loss 3.86 on epoch=177
06/01/2022 04:18:07 - INFO - __main__ - Step 720 Global step 720 Train loss 3.97 on epoch=179
06/01/2022 04:18:09 - INFO - __main__ - Step 730 Global step 730 Train loss 3.71 on epoch=182
06/01/2022 04:18:10 - INFO - __main__ - Step 740 Global step 740 Train loss 3.88 on epoch=184
06/01/2022 04:18:11 - INFO - __main__ - Step 750 Global step 750 Train loss 3.78 on epoch=187
06/01/2022 04:18:12 - INFO - __main__ - Global step 750 Train loss 3.84 Classification-F1 0.06769230769230769 on epoch=187
06/01/2022 04:18:12 - INFO - __main__ - Saving model with best Classification-F1: 0.018518518518518517 -> 0.06769230769230769 on epoch=187, global_step=750
06/01/2022 04:18:14 - INFO - __main__ - Step 760 Global step 760 Train loss 3.92 on epoch=189
06/01/2022 04:18:15 - INFO - __main__ - Step 770 Global step 770 Train loss 3.68 on epoch=192
06/01/2022 04:18:16 - INFO - __main__ - Step 780 Global step 780 Train loss 3.71 on epoch=194
06/01/2022 04:18:17 - INFO - __main__ - Step 790 Global step 790 Train loss 3.44 on epoch=197
06/01/2022 04:18:19 - INFO - __main__ - Step 800 Global step 800 Train loss 3.49 on epoch=199
06/01/2022 04:18:21 - INFO - __main__ - Global step 800 Train loss 3.65 Classification-F1 0.07594936708860758 on epoch=199
06/01/2022 04:18:21 - INFO - __main__ - Saving model with best Classification-F1: 0.06769230769230769 -> 0.07594936708860758 on epoch=199, global_step=800
06/01/2022 04:18:22 - INFO - __main__ - Step 810 Global step 810 Train loss 3.54 on epoch=202
06/01/2022 04:18:23 - INFO - __main__ - Step 820 Global step 820 Train loss 3.63 on epoch=204
06/01/2022 04:18:25 - INFO - __main__ - Step 830 Global step 830 Train loss 3.48 on epoch=207
06/01/2022 04:18:26 - INFO - __main__ - Step 840 Global step 840 Train loss 3.41 on epoch=209
06/01/2022 04:18:27 - INFO - __main__ - Step 850 Global step 850 Train loss 3.24 on epoch=212
06/01/2022 04:18:30 - INFO - __main__ - Global step 850 Train loss 3.46 Classification-F1 0.10256410256410256 on epoch=212
06/01/2022 04:18:30 - INFO - __main__ - Saving model with best Classification-F1: 0.07594936708860758 -> 0.10256410256410256 on epoch=212, global_step=850
06/01/2022 04:18:31 - INFO - __main__ - Step 860 Global step 860 Train loss 3.48 on epoch=214
06/01/2022 04:18:32 - INFO - __main__ - Step 870 Global step 870 Train loss 3.19 on epoch=217
06/01/2022 04:18:34 - INFO - __main__ - Step 880 Global step 880 Train loss 3.26 on epoch=219
06/01/2022 04:18:35 - INFO - __main__ - Step 890 Global step 890 Train loss 3.11 on epoch=222
06/01/2022 04:18:36 - INFO - __main__ - Step 900 Global step 900 Train loss 3.36 on epoch=224
06/01/2022 04:18:38 - INFO - __main__ - Global step 900 Train loss 3.28 Classification-F1 0.10126582278481013 on epoch=224
06/01/2022 04:18:39 - INFO - __main__ - Step 910 Global step 910 Train loss 3.08 on epoch=227
06/01/2022 04:18:40 - INFO - __main__ - Step 920 Global step 920 Train loss 3.25 on epoch=229
06/01/2022 04:18:42 - INFO - __main__ - Step 930 Global step 930 Train loss 3.04 on epoch=232
06/01/2022 04:18:43 - INFO - __main__ - Step 940 Global step 940 Train loss 3.03 on epoch=234
06/01/2022 04:18:44 - INFO - __main__ - Step 950 Global step 950 Train loss 2.91 on epoch=237
06/01/2022 04:18:45 - INFO - __main__ - Global step 950 Train loss 3.06 Classification-F1 0.1 on epoch=237
06/01/2022 04:18:46 - INFO - __main__ - Step 960 Global step 960 Train loss 3.04 on epoch=239
06/01/2022 04:18:48 - INFO - __main__ - Step 970 Global step 970 Train loss 2.94 on epoch=242
06/01/2022 04:18:49 - INFO - __main__ - Step 980 Global step 980 Train loss 3.14 on epoch=244
06/01/2022 04:18:50 - INFO - __main__ - Step 990 Global step 990 Train loss 2.91 on epoch=247
06/01/2022 04:18:51 - INFO - __main__ - Step 1000 Global step 1000 Train loss 2.96 on epoch=249
06/01/2022 04:18:53 - INFO - __main__ - Global step 1000 Train loss 3.00 Classification-F1 0.10389610389610389 on epoch=249
06/01/2022 04:18:53 - INFO - __main__ - Saving model with best Classification-F1: 0.10256410256410256 -> 0.10389610389610389 on epoch=249, global_step=1000
06/01/2022 04:18:54 - INFO - __main__ - Step 1010 Global step 1010 Train loss 2.75 on epoch=252
06/01/2022 04:18:55 - INFO - __main__ - Step 1020 Global step 1020 Train loss 2.81 on epoch=254
06/01/2022 04:18:56 - INFO - __main__ - Step 1030 Global step 1030 Train loss 2.68 on epoch=257
06/01/2022 04:18:58 - INFO - __main__ - Step 1040 Global step 1040 Train loss 2.63 on epoch=259
06/01/2022 04:18:59 - INFO - __main__ - Step 1050 Global step 1050 Train loss 2.60 on epoch=262
06/01/2022 04:19:00 - INFO - __main__ - Global step 1050 Train loss 2.69 Classification-F1 0.13067758749069247 on epoch=262
06/01/2022 04:19:00 - INFO - __main__ - Saving model with best Classification-F1: 0.10389610389610389 -> 0.13067758749069247 on epoch=262, global_step=1050
06/01/2022 04:19:01 - INFO - __main__ - Step 1060 Global step 1060 Train loss 2.65 on epoch=264
06/01/2022 04:19:02 - INFO - __main__ - Step 1070 Global step 1070 Train loss 2.39 on epoch=267
06/01/2022 04:19:04 - INFO - __main__ - Step 1080 Global step 1080 Train loss 2.39 on epoch=269
06/01/2022 04:19:05 - INFO - __main__ - Step 1090 Global step 1090 Train loss 2.32 on epoch=272
06/01/2022 04:19:06 - INFO - __main__ - Step 1100 Global step 1100 Train loss 2.31 on epoch=274
06/01/2022 04:19:07 - INFO - __main__ - Global step 1100 Train loss 2.41 Classification-F1 0.13034188034188032 on epoch=274
06/01/2022 04:19:08 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.96 on epoch=277
06/01/2022 04:19:09 - INFO - __main__ - Step 1120 Global step 1120 Train loss 2.20 on epoch=279
06/01/2022 04:19:11 - INFO - __main__ - Step 1130 Global step 1130 Train loss 2.18 on epoch=282
06/01/2022 04:19:12 - INFO - __main__ - Step 1140 Global step 1140 Train loss 2.17 on epoch=284
06/01/2022 04:19:13 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.93 on epoch=287
06/01/2022 04:19:14 - INFO - __main__ - Global step 1150 Train loss 2.09 Classification-F1 0.1 on epoch=287
06/01/2022 04:19:16 - INFO - __main__ - Step 1160 Global step 1160 Train loss 2.03 on epoch=289
06/01/2022 04:19:17 - INFO - __main__ - Step 1170 Global step 1170 Train loss 2.01 on epoch=292
06/01/2022 04:19:18 - INFO - __main__ - Step 1180 Global step 1180 Train loss 2.03 on epoch=294
06/01/2022 04:19:19 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.88 on epoch=297
06/01/2022 04:19:21 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.95 on epoch=299
06/01/2022 04:19:21 - INFO - __main__ - Global step 1200 Train loss 1.98 Classification-F1 0.13034188034188032 on epoch=299
06/01/2022 04:19:22 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.94 on epoch=302
06/01/2022 04:19:24 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.90 on epoch=304
06/01/2022 04:19:25 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.87 on epoch=307
06/01/2022 04:19:26 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.87 on epoch=309
06/01/2022 04:19:27 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.96 on epoch=312
06/01/2022 04:19:28 - INFO - __main__ - Global step 1250 Train loss 1.91 Classification-F1 0.10389610389610389 on epoch=312
06/01/2022 04:19:29 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.94 on epoch=314
06/01/2022 04:19:30 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.71 on epoch=317
06/01/2022 04:19:32 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.81 on epoch=319
06/01/2022 04:19:33 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.73 on epoch=322
06/01/2022 04:19:34 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.74 on epoch=324
06/01/2022 04:19:35 - INFO - __main__ - Global step 1300 Train loss 1.79 Classification-F1 0.1 on epoch=324
06/01/2022 04:19:36 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.69 on epoch=327
06/01/2022 04:19:37 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.77 on epoch=329
06/01/2022 04:19:39 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.67 on epoch=332
06/01/2022 04:19:40 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.54 on epoch=334
06/01/2022 04:19:41 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.55 on epoch=337
06/01/2022 04:19:42 - INFO - __main__ - Global step 1350 Train loss 1.64 Classification-F1 0.1 on epoch=337
06/01/2022 04:19:43 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.76 on epoch=339
06/01/2022 04:19:44 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.48 on epoch=342
06/01/2022 04:19:46 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.59 on epoch=344
06/01/2022 04:19:47 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.60 on epoch=347
06/01/2022 04:19:48 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.59 on epoch=349
06/01/2022 04:19:49 - INFO - __main__ - Global step 1400 Train loss 1.60 Classification-F1 0.1 on epoch=349
06/01/2022 04:19:50 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.56 on epoch=352
06/01/2022 04:19:51 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.51 on epoch=354
06/01/2022 04:19:52 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.54 on epoch=357
06/01/2022 04:19:54 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.57 on epoch=359
06/01/2022 04:19:55 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.61 on epoch=362
06/01/2022 04:19:55 - INFO - __main__ - Global step 1450 Train loss 1.56 Classification-F1 0.1 on epoch=362
06/01/2022 04:19:57 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.54 on epoch=364
06/01/2022 04:19:58 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.47 on epoch=367
06/01/2022 04:19:59 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.42 on epoch=369
06/01/2022 04:20:01 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.36 on epoch=372
06/01/2022 04:20:02 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.40 on epoch=374
06/01/2022 04:20:02 - INFO - __main__ - Global step 1500 Train loss 1.44 Classification-F1 0.1412763767370046 on epoch=374
06/01/2022 04:20:02 - INFO - __main__ - Saving model with best Classification-F1: 0.13067758749069247 -> 0.1412763767370046 on epoch=374, global_step=1500
06/01/2022 04:20:04 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.32 on epoch=377
06/01/2022 04:20:05 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.64 on epoch=379
06/01/2022 04:20:06 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.38 on epoch=382
06/01/2022 04:20:07 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.43 on epoch=384
06/01/2022 04:20:09 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.34 on epoch=387
06/01/2022 04:20:09 - INFO - __main__ - Global step 1550 Train loss 1.42 Classification-F1 0.15211640211640212 on epoch=387
06/01/2022 04:20:09 - INFO - __main__ - Saving model with best Classification-F1: 0.1412763767370046 -> 0.15211640211640212 on epoch=387, global_step=1550
06/01/2022 04:20:10 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.31 on epoch=389
06/01/2022 04:20:12 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.29 on epoch=392
06/01/2022 04:20:13 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.42 on epoch=394
06/01/2022 04:20:14 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.27 on epoch=397
06/01/2022 04:20:16 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.39 on epoch=399
06/01/2022 04:20:16 - INFO - __main__ - Global step 1600 Train loss 1.34 Classification-F1 0.1565276828434723 on epoch=399
06/01/2022 04:20:16 - INFO - __main__ - Saving model with best Classification-F1: 0.15211640211640212 -> 0.1565276828434723 on epoch=399, global_step=1600
06/01/2022 04:20:17 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.37 on epoch=402
06/01/2022 04:20:19 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.36 on epoch=404
06/01/2022 04:20:20 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.41 on epoch=407
06/01/2022 04:20:21 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.34 on epoch=409
06/01/2022 04:20:22 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.28 on epoch=412
06/01/2022 04:20:23 - INFO - __main__ - Global step 1650 Train loss 1.35 Classification-F1 0.14600840336134455 on epoch=412
06/01/2022 04:20:24 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.34 on epoch=414
06/01/2022 04:20:25 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.22 on epoch=417
06/01/2022 04:20:27 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.34 on epoch=419
06/01/2022 04:20:28 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.38 on epoch=422
06/01/2022 04:20:29 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.29 on epoch=424
06/01/2022 04:20:30 - INFO - __main__ - Global step 1700 Train loss 1.31 Classification-F1 0.1 on epoch=424
06/01/2022 04:20:31 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.31 on epoch=427
06/01/2022 04:20:32 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.14 on epoch=429
06/01/2022 04:20:34 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.19 on epoch=432
06/01/2022 04:20:35 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.28 on epoch=434
06/01/2022 04:20:36 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.30 on epoch=437
06/01/2022 04:20:37 - INFO - __main__ - Global step 1750 Train loss 1.24 Classification-F1 0.1 on epoch=437
06/01/2022 04:20:38 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.26 on epoch=439
06/01/2022 04:20:39 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.30 on epoch=442
06/01/2022 04:20:41 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.22 on epoch=444
06/01/2022 04:20:42 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.24 on epoch=447
06/01/2022 04:20:43 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.15 on epoch=449
06/01/2022 04:20:44 - INFO - __main__ - Global step 1800 Train loss 1.23 Classification-F1 0.1 on epoch=449
06/01/2022 04:20:45 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.23 on epoch=452
06/01/2022 04:20:46 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.30 on epoch=454
06/01/2022 04:20:47 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.18 on epoch=457
06/01/2022 04:20:49 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.23 on epoch=459
06/01/2022 04:20:50 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.27 on epoch=462
06/01/2022 04:20:51 - INFO - __main__ - Global step 1850 Train loss 1.24 Classification-F1 0.09493670886075949 on epoch=462
06/01/2022 04:20:52 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.29 on epoch=464
06/01/2022 04:20:53 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.36 on epoch=467
06/01/2022 04:20:54 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.28 on epoch=469
06/01/2022 04:20:56 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.18 on epoch=472
06/01/2022 04:20:57 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.16 on epoch=474
06/01/2022 04:20:57 - INFO - __main__ - Global step 1900 Train loss 1.25 Classification-F1 0.1576923076923077 on epoch=474
06/01/2022 04:20:57 - INFO - __main__ - Saving model with best Classification-F1: 0.1565276828434723 -> 0.1576923076923077 on epoch=474, global_step=1900
06/01/2022 04:20:59 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.15 on epoch=477
06/01/2022 04:21:00 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.17 on epoch=479
06/01/2022 04:21:01 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.28 on epoch=482
06/01/2022 04:21:03 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.20 on epoch=484
06/01/2022 04:21:04 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.07 on epoch=487
06/01/2022 04:21:04 - INFO - __main__ - Global step 1950 Train loss 1.17 Classification-F1 0.1 on epoch=487
06/01/2022 04:21:06 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.16 on epoch=489
06/01/2022 04:21:07 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.18 on epoch=492
06/01/2022 04:21:08 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.21 on epoch=494
06/01/2022 04:21:09 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.29 on epoch=497
06/01/2022 04:21:11 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.17 on epoch=499
06/01/2022 04:21:11 - INFO - __main__ - Global step 2000 Train loss 1.20 Classification-F1 0.13034188034188032 on epoch=499
06/01/2022 04:21:12 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.08 on epoch=502
06/01/2022 04:21:14 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.12 on epoch=504
06/01/2022 04:21:15 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.13 on epoch=507
06/01/2022 04:21:16 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.21 on epoch=509
06/01/2022 04:21:18 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.12 on epoch=512
06/01/2022 04:21:18 - INFO - __main__ - Global step 2050 Train loss 1.13 Classification-F1 0.1 on epoch=512
06/01/2022 04:21:19 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.17 on epoch=514
06/01/2022 04:21:21 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.19 on epoch=517
06/01/2022 04:21:22 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.11 on epoch=519
06/01/2022 04:21:23 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.07 on epoch=522
06/01/2022 04:21:24 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.21 on epoch=524
06/01/2022 04:21:25 - INFO - __main__ - Global step 2100 Train loss 1.15 Classification-F1 0.1 on epoch=524
06/01/2022 04:21:26 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.07 on epoch=527
06/01/2022 04:21:27 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.21 on epoch=529
06/01/2022 04:21:29 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.15 on epoch=532
06/01/2022 04:21:30 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.21 on epoch=534
06/01/2022 04:21:31 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.18 on epoch=537
06/01/2022 04:21:32 - INFO - __main__ - Global step 2150 Train loss 1.16 Classification-F1 0.0974025974025974 on epoch=537
06/01/2022 04:21:33 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.10 on epoch=539
06/01/2022 04:21:34 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.18 on epoch=542
06/01/2022 04:21:36 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.16 on epoch=544
06/01/2022 04:21:37 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.09 on epoch=547
06/01/2022 04:21:38 - INFO - __main__ - Step 2200 Global step 2200 Train loss 1.24 on epoch=549
06/01/2022 04:21:39 - INFO - __main__ - Global step 2200 Train loss 1.15 Classification-F1 0.09493670886075949 on epoch=549
06/01/2022 04:21:40 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.03 on epoch=552
06/01/2022 04:21:41 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.10 on epoch=554
06/01/2022 04:21:43 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.14 on epoch=557
06/01/2022 04:21:44 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.15 on epoch=559
06/01/2022 04:21:45 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.05 on epoch=562
06/01/2022 04:21:46 - INFO - __main__ - Global step 2250 Train loss 1.10 Classification-F1 0.1 on epoch=562
06/01/2022 04:21:47 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.17 on epoch=564
06/01/2022 04:21:48 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.03 on epoch=567
06/01/2022 04:21:49 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.07 on epoch=569
06/01/2022 04:21:51 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.05 on epoch=572
06/01/2022 04:21:52 - INFO - __main__ - Step 2300 Global step 2300 Train loss 1.18 on epoch=574
06/01/2022 04:21:53 - INFO - __main__ - Global step 2300 Train loss 1.10 Classification-F1 0.1 on epoch=574
06/01/2022 04:21:54 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.08 on epoch=577
06/01/2022 04:21:55 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.07 on epoch=579
06/01/2022 04:21:56 - INFO - __main__ - Step 2330 Global step 2330 Train loss 1.15 on epoch=582
06/01/2022 04:21:58 - INFO - __main__ - Step 2340 Global step 2340 Train loss 1.03 on epoch=584
06/01/2022 04:21:59 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.12 on epoch=587
06/01/2022 04:21:59 - INFO - __main__ - Global step 2350 Train loss 1.09 Classification-F1 0.1 on epoch=587
06/01/2022 04:22:01 - INFO - __main__ - Step 2360 Global step 2360 Train loss 1.12 on epoch=589
06/01/2022 04:22:02 - INFO - __main__ - Step 2370 Global step 2370 Train loss 1.10 on epoch=592
06/01/2022 04:22:03 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.07 on epoch=594
06/01/2022 04:22:05 - INFO - __main__ - Step 2390 Global step 2390 Train loss 1.14 on epoch=597
06/01/2022 04:22:06 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.09 on epoch=599
06/01/2022 04:22:06 - INFO - __main__ - Global step 2400 Train loss 1.10 Classification-F1 0.1 on epoch=599
06/01/2022 04:22:08 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.19 on epoch=602
06/01/2022 04:22:09 - INFO - __main__ - Step 2420 Global step 2420 Train loss 1.10 on epoch=604
06/01/2022 04:22:10 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.18 on epoch=607
06/01/2022 04:22:11 - INFO - __main__ - Step 2440 Global step 2440 Train loss 1.20 on epoch=609
06/01/2022 04:22:13 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.01 on epoch=612
06/01/2022 04:22:13 - INFO - __main__ - Global step 2450 Train loss 1.13 Classification-F1 0.1 on epoch=612
06/01/2022 04:22:15 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.98 on epoch=614
06/01/2022 04:22:16 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.08 on epoch=617
06/01/2022 04:22:17 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.12 on epoch=619
06/01/2022 04:22:18 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.03 on epoch=622
06/01/2022 04:22:20 - INFO - __main__ - Step 2500 Global step 2500 Train loss 1.16 on epoch=624
06/01/2022 04:22:20 - INFO - __main__ - Global step 2500 Train loss 1.08 Classification-F1 0.13067758749069247 on epoch=624
06/01/2022 04:22:21 - INFO - __main__ - Step 2510 Global step 2510 Train loss 1.22 on epoch=627
06/01/2022 04:22:23 - INFO - __main__ - Step 2520 Global step 2520 Train loss 1.19 on epoch=629
06/01/2022 04:22:24 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.03 on epoch=632
06/01/2022 04:22:25 - INFO - __main__ - Step 2540 Global step 2540 Train loss 1.09 on epoch=634
06/01/2022 04:22:27 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.95 on epoch=637
06/01/2022 04:22:27 - INFO - __main__ - Global step 2550 Train loss 1.09 Classification-F1 0.1 on epoch=637
06/01/2022 04:22:28 - INFO - __main__ - Step 2560 Global step 2560 Train loss 1.01 on epoch=639
06/01/2022 04:22:30 - INFO - __main__ - Step 2570 Global step 2570 Train loss 1.07 on epoch=642
06/01/2022 04:22:31 - INFO - __main__ - Step 2580 Global step 2580 Train loss 1.16 on epoch=644
06/01/2022 04:22:32 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.11 on epoch=647
06/01/2022 04:22:33 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.02 on epoch=649
06/01/2022 04:22:34 - INFO - __main__ - Global step 2600 Train loss 1.07 Classification-F1 0.1 on epoch=649
06/01/2022 04:22:35 - INFO - __main__ - Step 2610 Global step 2610 Train loss 1.15 on epoch=652
06/01/2022 04:22:36 - INFO - __main__ - Step 2620 Global step 2620 Train loss 1.07 on epoch=654
06/01/2022 04:22:38 - INFO - __main__ - Step 2630 Global step 2630 Train loss 1.05 on epoch=657
06/01/2022 04:22:39 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.04 on epoch=659
06/01/2022 04:22:40 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.13 on epoch=662
06/01/2022 04:22:41 - INFO - __main__ - Global step 2650 Train loss 1.08 Classification-F1 0.1 on epoch=662
06/01/2022 04:22:42 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.99 on epoch=664
06/01/2022 04:22:43 - INFO - __main__ - Step 2670 Global step 2670 Train loss 1.06 on epoch=667
06/01/2022 04:22:45 - INFO - __main__ - Step 2680 Global step 2680 Train loss 1.13 on epoch=669
06/01/2022 04:22:46 - INFO - __main__ - Step 2690 Global step 2690 Train loss 1.00 on epoch=672
06/01/2022 04:22:47 - INFO - __main__ - Step 2700 Global step 2700 Train loss 1.10 on epoch=674
06/01/2022 04:22:48 - INFO - __main__ - Global step 2700 Train loss 1.06 Classification-F1 0.1302118933697881 on epoch=674
06/01/2022 04:22:49 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.13 on epoch=677
06/01/2022 04:22:50 - INFO - __main__ - Step 2720 Global step 2720 Train loss 1.08 on epoch=679
06/01/2022 04:22:52 - INFO - __main__ - Step 2730 Global step 2730 Train loss 1.02 on epoch=682
06/01/2022 04:22:53 - INFO - __main__ - Step 2740 Global step 2740 Train loss 1.04 on epoch=684
06/01/2022 04:22:54 - INFO - __main__ - Step 2750 Global step 2750 Train loss 1.07 on epoch=687
06/01/2022 04:22:55 - INFO - __main__ - Global step 2750 Train loss 1.07 Classification-F1 0.12393162393162392 on epoch=687
06/01/2022 04:22:56 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.08 on epoch=689
06/01/2022 04:22:57 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.16 on epoch=692
06/01/2022 04:22:58 - INFO - __main__ - Step 2780 Global step 2780 Train loss 1.04 on epoch=694
06/01/2022 04:23:00 - INFO - __main__ - Step 2790 Global step 2790 Train loss 1.10 on epoch=697
06/01/2022 04:23:01 - INFO - __main__ - Step 2800 Global step 2800 Train loss 1.09 on epoch=699
06/01/2022 04:23:02 - INFO - __main__ - Global step 2800 Train loss 1.09 Classification-F1 0.1 on epoch=699
06/01/2022 04:23:03 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.05 on epoch=702
06/01/2022 04:23:04 - INFO - __main__ - Step 2820 Global step 2820 Train loss 1.02 on epoch=704
06/01/2022 04:23:05 - INFO - __main__ - Step 2830 Global step 2830 Train loss 1.04 on epoch=707
06/01/2022 04:23:07 - INFO - __main__ - Step 2840 Global step 2840 Train loss 1.05 on epoch=709
06/01/2022 04:23:08 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.99 on epoch=712
06/01/2022 04:23:09 - INFO - __main__ - Global step 2850 Train loss 1.03 Classification-F1 0.1 on epoch=712
06/01/2022 04:23:10 - INFO - __main__ - Step 2860 Global step 2860 Train loss 1.02 on epoch=714
06/01/2022 04:23:11 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.97 on epoch=717
06/01/2022 04:23:12 - INFO - __main__ - Step 2880 Global step 2880 Train loss 1.11 on epoch=719
06/01/2022 04:23:14 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.02 on epoch=722
06/01/2022 04:23:15 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.05 on epoch=724
06/01/2022 04:23:16 - INFO - __main__ - Global step 2900 Train loss 1.03 Classification-F1 0.1 on epoch=724
06/01/2022 04:23:17 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.97 on epoch=727
06/01/2022 04:23:18 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.91 on epoch=729
06/01/2022 04:23:20 - INFO - __main__ - Step 2930 Global step 2930 Train loss 1.02 on epoch=732
06/01/2022 04:23:21 - INFO - __main__ - Step 2940 Global step 2940 Train loss 1.00 on epoch=734
06/01/2022 04:23:22 - INFO - __main__ - Step 2950 Global step 2950 Train loss 1.19 on epoch=737
06/01/2022 04:23:23 - INFO - __main__ - Global step 2950 Train loss 1.02 Classification-F1 0.09493670886075949 on epoch=737
06/01/2022 04:23:24 - INFO - __main__ - Step 2960 Global step 2960 Train loss 1.06 on epoch=739
06/01/2022 04:23:25 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.04 on epoch=742
06/01/2022 04:23:27 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.97 on epoch=744
06/01/2022 04:23:28 - INFO - __main__ - Step 2990 Global step 2990 Train loss 1.06 on epoch=747
06/01/2022 04:23:29 - INFO - __main__ - Step 3000 Global step 3000 Train loss 1.02 on epoch=749
06/01/2022 04:23:30 - INFO - __main__ - Global step 3000 Train loss 1.03 Classification-F1 0.1 on epoch=749
06/01/2022 04:23:30 - INFO - __main__ - save last model!
06/01/2022 04:23:30 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/01/2022 04:23:30 - INFO - __main__ - Start tokenizing ... 5509 instances
06/01/2022 04:23:30 - INFO - __main__ - Printing 3 examples
06/01/2022 04:23:30 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/01/2022 04:23:30 - INFO - __main__ - ['others']
06/01/2022 04:23:30 - INFO - __main__ -  [emo] what you like very little things ok
06/01/2022 04:23:30 - INFO - __main__ - ['others']
06/01/2022 04:23:30 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/01/2022 04:23:30 - INFO - __main__ - ['others']
06/01/2022 04:23:30 - INFO - __main__ - Tokenizing Input ...
06/01/2022 04:23:30 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 04:23:30 - INFO - __main__ - Printing 3 examples
06/01/2022 04:23:30 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/01/2022 04:23:30 - INFO - __main__ - ['happy']
06/01/2022 04:23:30 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/01/2022 04:23:30 - INFO - __main__ - ['happy']
06/01/2022 04:23:30 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/01/2022 04:23:30 - INFO - __main__ - ['happy']
06/01/2022 04:23:30 - INFO - __main__ - Tokenizing Input ...
06/01/2022 04:23:30 - INFO - __main__ - Tokenizing Output ...
06/01/2022 04:23:30 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 04:23:30 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 04:23:30 - INFO - __main__ - Printing 3 examples
06/01/2022 04:23:30 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
06/01/2022 04:23:30 - INFO - __main__ - ['happy']
06/01/2022 04:23:30 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
06/01/2022 04:23:30 - INFO - __main__ - ['happy']
06/01/2022 04:23:30 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
06/01/2022 04:23:30 - INFO - __main__ - ['happy']
06/01/2022 04:23:30 - INFO - __main__ - Tokenizing Input ...
06/01/2022 04:23:30 - INFO - __main__ - Tokenizing Output ...
06/01/2022 04:23:30 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 04:23:32 - INFO - __main__ - Tokenizing Output ...
06/01/2022 04:23:36 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 04:23:36 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/01/2022 04:23:36 - INFO - __main__ - Starting training!
06/01/2022 04:23:37 - INFO - __main__ - Loaded 5509 examples from test data
06/01/2022 04:24:21 - INFO - __main__ - Saved prediction in models/T5-base-reptile-cls2cls-3e-5-2-5000-5e-1-10/singletask-emo/emo_16_42_0.3_8_predictions.txt
06/01/2022 04:24:21 - INFO - __main__ - Classification-F1 on test data: 0.0276
06/01/2022 04:24:21 - INFO - __main__ - prefix=emo_16_42, lr=0.3, bsz=8, dev_performance=0.1576923076923077, test_performance=0.027639781545567232
06/01/2022 04:24:21 - INFO - __main__ - Running ... prefix=emo_16_42, lr=0.2, bsz=8 ...
06/01/2022 04:24:22 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 04:24:22 - INFO - __main__ - Printing 3 examples
06/01/2022 04:24:22 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/01/2022 04:24:22 - INFO - __main__ - ['happy']
06/01/2022 04:24:22 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/01/2022 04:24:22 - INFO - __main__ - ['happy']
06/01/2022 04:24:22 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/01/2022 04:24:22 - INFO - __main__ - ['happy']
06/01/2022 04:24:22 - INFO - __main__ - Tokenizing Input ...
06/01/2022 04:24:22 - INFO - __main__ - Tokenizing Output ...
06/01/2022 04:24:22 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 04:24:22 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 04:24:22 - INFO - __main__ - Printing 3 examples
06/01/2022 04:24:22 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
06/01/2022 04:24:22 - INFO - __main__ - ['happy']
06/01/2022 04:24:22 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
06/01/2022 04:24:22 - INFO - __main__ - ['happy']
06/01/2022 04:24:22 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
06/01/2022 04:24:22 - INFO - __main__ - ['happy']
06/01/2022 04:24:22 - INFO - __main__ - Tokenizing Input ...
06/01/2022 04:24:22 - INFO - __main__ - Tokenizing Output ...
06/01/2022 04:24:23 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 04:24:28 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 04:24:29 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/01/2022 04:24:29 - INFO - __main__ - Starting training!
06/01/2022 04:24:30 - INFO - __main__ - Step 10 Global step 10 Train loss 8.96 on epoch=2
06/01/2022 04:24:31 - INFO - __main__ - Step 20 Global step 20 Train loss 8.89 on epoch=4
06/01/2022 04:24:33 - INFO - __main__ - Step 30 Global step 30 Train loss 8.99 on epoch=7
06/01/2022 04:24:34 - INFO - __main__ - Step 40 Global step 40 Train loss 8.84 on epoch=9
06/01/2022 04:24:35 - INFO - __main__ - Step 50 Global step 50 Train loss 8.97 on epoch=12
06/01/2022 04:24:40 - INFO - __main__ - Global step 50 Train loss 8.93 Classification-F1 0.0 on epoch=12
06/01/2022 04:24:40 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
06/01/2022 04:24:41 - INFO - __main__ - Step 60 Global step 60 Train loss 8.80 on epoch=14
06/01/2022 04:24:42 - INFO - __main__ - Step 70 Global step 70 Train loss 8.67 on epoch=17
06/01/2022 04:24:43 - INFO - __main__ - Step 80 Global step 80 Train loss 8.78 on epoch=19
06/01/2022 04:24:45 - INFO - __main__ - Step 90 Global step 90 Train loss 8.81 on epoch=22
06/01/2022 04:24:46 - INFO - __main__ - Step 100 Global step 100 Train loss 8.72 on epoch=24
06/01/2022 04:24:54 - INFO - __main__ - Global step 100 Train loss 8.75 Classification-F1 0.0 on epoch=24
06/01/2022 04:24:55 - INFO - __main__ - Step 110 Global step 110 Train loss 8.69 on epoch=27
06/01/2022 04:24:57 - INFO - __main__ - Step 120 Global step 120 Train loss 8.80 on epoch=29
06/01/2022 04:24:58 - INFO - __main__ - Step 130 Global step 130 Train loss 8.64 on epoch=32
06/01/2022 04:24:59 - INFO - __main__ - Step 140 Global step 140 Train loss 8.64 on epoch=34
06/01/2022 04:25:01 - INFO - __main__ - Step 150 Global step 150 Train loss 8.72 on epoch=37
06/01/2022 04:25:04 - INFO - __main__ - Global step 150 Train loss 8.70 Classification-F1 0.0 on epoch=37
06/01/2022 04:25:05 - INFO - __main__ - Step 160 Global step 160 Train loss 8.50 on epoch=39
06/01/2022 04:25:07 - INFO - __main__ - Step 170 Global step 170 Train loss 8.68 on epoch=42
06/01/2022 04:25:08 - INFO - __main__ - Step 180 Global step 180 Train loss 8.51 on epoch=44
06/01/2022 04:25:09 - INFO - __main__ - Step 190 Global step 190 Train loss 8.47 on epoch=47
06/01/2022 04:25:10 - INFO - __main__ - Step 200 Global step 200 Train loss 8.38 on epoch=49
06/01/2022 04:25:17 - INFO - __main__ - Global step 200 Train loss 8.51 Classification-F1 0.0 on epoch=49
06/01/2022 04:25:18 - INFO - __main__ - Step 210 Global step 210 Train loss 8.37 on epoch=52
06/01/2022 04:25:20 - INFO - __main__ - Step 220 Global step 220 Train loss 8.29 on epoch=54
06/01/2022 04:25:21 - INFO - __main__ - Step 230 Global step 230 Train loss 8.35 on epoch=57
06/01/2022 04:25:22 - INFO - __main__ - Step 240 Global step 240 Train loss 8.27 on epoch=59
06/01/2022 04:25:24 - INFO - __main__ - Step 250 Global step 250 Train loss 8.13 on epoch=62
06/01/2022 04:25:36 - INFO - __main__ - Global step 250 Train loss 8.28 Classification-F1 0.0 on epoch=62
06/01/2022 04:25:38 - INFO - __main__ - Step 260 Global step 260 Train loss 7.94 on epoch=64
06/01/2022 04:25:39 - INFO - __main__ - Step 270 Global step 270 Train loss 8.00 on epoch=67
06/01/2022 04:25:40 - INFO - __main__ - Step 280 Global step 280 Train loss 7.77 on epoch=69
06/01/2022 04:25:41 - INFO - __main__ - Step 290 Global step 290 Train loss 7.69 on epoch=72
06/01/2022 04:25:43 - INFO - __main__ - Step 300 Global step 300 Train loss 7.47 on epoch=74
06/01/2022 04:25:51 - INFO - __main__ - Global step 300 Train loss 7.77 Classification-F1 0.0 on epoch=74
06/01/2022 04:25:53 - INFO - __main__ - Step 310 Global step 310 Train loss 7.28 on epoch=77
06/01/2022 04:25:54 - INFO - __main__ - Step 320 Global step 320 Train loss 7.38 on epoch=79
06/01/2022 04:25:55 - INFO - __main__ - Step 330 Global step 330 Train loss 7.38 on epoch=82
06/01/2022 04:25:57 - INFO - __main__ - Step 340 Global step 340 Train loss 7.07 on epoch=84
06/01/2022 04:25:58 - INFO - __main__ - Step 350 Global step 350 Train loss 6.96 on epoch=87
06/01/2022 04:26:01 - INFO - __main__ - Global step 350 Train loss 7.21 Classification-F1 0.0 on epoch=87
06/01/2022 04:26:02 - INFO - __main__ - Step 360 Global step 360 Train loss 6.95 on epoch=89
06/01/2022 04:26:04 - INFO - __main__ - Step 370 Global step 370 Train loss 6.67 on epoch=92
06/01/2022 04:26:05 - INFO - __main__ - Step 380 Global step 380 Train loss 6.54 on epoch=94
06/01/2022 04:26:06 - INFO - __main__ - Step 390 Global step 390 Train loss 6.42 on epoch=97
06/01/2022 04:26:08 - INFO - __main__ - Step 400 Global step 400 Train loss 6.34 on epoch=99
06/01/2022 04:26:13 - INFO - __main__ - Global step 400 Train loss 6.58 Classification-F1 0.0 on epoch=99
06/01/2022 04:26:14 - INFO - __main__ - Step 410 Global step 410 Train loss 6.25 on epoch=102
06/01/2022 04:26:15 - INFO - __main__ - Step 420 Global step 420 Train loss 6.25 on epoch=104
06/01/2022 04:26:17 - INFO - __main__ - Step 430 Global step 430 Train loss 6.12 on epoch=107
06/01/2022 04:26:18 - INFO - __main__ - Step 440 Global step 440 Train loss 6.20 on epoch=109
06/01/2022 04:26:19 - INFO - __main__ - Step 450 Global step 450 Train loss 5.80 on epoch=112
06/01/2022 04:26:28 - INFO - __main__ - Global step 450 Train loss 6.12 Classification-F1 0.0 on epoch=112
06/01/2022 04:26:29 - INFO - __main__ - Step 460 Global step 460 Train loss 5.78 on epoch=114
06/01/2022 04:26:30 - INFO - __main__ - Step 470 Global step 470 Train loss 5.74 on epoch=117
06/01/2022 04:26:31 - INFO - __main__ - Step 480 Global step 480 Train loss 5.83 on epoch=119
06/01/2022 04:26:33 - INFO - __main__ - Step 490 Global step 490 Train loss 5.57 on epoch=122
06/01/2022 04:26:34 - INFO - __main__ - Step 500 Global step 500 Train loss 5.71 on epoch=124
06/01/2022 04:26:38 - INFO - __main__ - Global step 500 Train loss 5.73 Classification-F1 0.0 on epoch=124
06/01/2022 04:26:40 - INFO - __main__ - Step 510 Global step 510 Train loss 5.51 on epoch=127
06/01/2022 04:26:41 - INFO - __main__ - Step 520 Global step 520 Train loss 5.56 on epoch=129
06/01/2022 04:26:42 - INFO - __main__ - Step 530 Global step 530 Train loss 5.65 on epoch=132
06/01/2022 04:26:44 - INFO - __main__ - Step 540 Global step 540 Train loss 5.52 on epoch=134
06/01/2022 04:26:45 - INFO - __main__ - Step 550 Global step 550 Train loss 5.38 on epoch=137
06/01/2022 04:26:50 - INFO - __main__ - Global step 550 Train loss 5.52 Classification-F1 0.0 on epoch=137
06/01/2022 04:26:51 - INFO - __main__ - Step 560 Global step 560 Train loss 5.49 on epoch=139
06/01/2022 04:26:52 - INFO - __main__ - Step 570 Global step 570 Train loss 5.29 on epoch=142
06/01/2022 04:26:54 - INFO - __main__ - Step 580 Global step 580 Train loss 5.44 on epoch=144
06/01/2022 04:26:55 - INFO - __main__ - Step 590 Global step 590 Train loss 5.23 on epoch=147
06/01/2022 04:26:56 - INFO - __main__ - Step 600 Global step 600 Train loss 5.13 on epoch=149
06/01/2022 04:27:03 - INFO - __main__ - Global step 600 Train loss 5.31 Classification-F1 0.0 on epoch=149
06/01/2022 04:27:04 - INFO - __main__ - Step 610 Global step 610 Train loss 5.08 on epoch=152
06/01/2022 04:27:06 - INFO - __main__ - Step 620 Global step 620 Train loss 5.25 on epoch=154
06/01/2022 04:27:07 - INFO - __main__ - Step 630 Global step 630 Train loss 4.86 on epoch=157
06/01/2022 04:27:08 - INFO - __main__ - Step 640 Global step 640 Train loss 5.30 on epoch=159
06/01/2022 04:27:10 - INFO - __main__ - Step 650 Global step 650 Train loss 4.79 on epoch=162
06/01/2022 04:27:14 - INFO - __main__ - Global step 650 Train loss 5.06 Classification-F1 0.0 on epoch=162
06/01/2022 04:27:15 - INFO - __main__ - Step 660 Global step 660 Train loss 5.04 on epoch=164
06/01/2022 04:27:16 - INFO - __main__ - Step 670 Global step 670 Train loss 4.88 on epoch=167
06/01/2022 04:27:18 - INFO - __main__ - Step 680 Global step 680 Train loss 4.78 on epoch=169
06/01/2022 04:27:19 - INFO - __main__ - Step 690 Global step 690 Train loss 4.85 on epoch=172
06/01/2022 04:27:20 - INFO - __main__ - Step 700 Global step 700 Train loss 4.80 on epoch=174
06/01/2022 04:27:26 - INFO - __main__ - Global step 700 Train loss 4.87 Classification-F1 0.0 on epoch=174
06/01/2022 04:27:27 - INFO - __main__ - Step 710 Global step 710 Train loss 4.72 on epoch=177
06/01/2022 04:27:28 - INFO - __main__ - Step 720 Global step 720 Train loss 4.87 on epoch=179
06/01/2022 04:27:30 - INFO - __main__ - Step 730 Global step 730 Train loss 4.59 on epoch=182
06/01/2022 04:27:31 - INFO - __main__ - Step 740 Global step 740 Train loss 4.88 on epoch=184
06/01/2022 04:27:32 - INFO - __main__ - Step 750 Global step 750 Train loss 4.60 on epoch=187
06/01/2022 04:27:41 - INFO - __main__ - Global step 750 Train loss 4.73 Classification-F1 0.0 on epoch=187
06/01/2022 04:27:42 - INFO - __main__ - Step 760 Global step 760 Train loss 4.51 on epoch=189
06/01/2022 04:27:44 - INFO - __main__ - Step 770 Global step 770 Train loss 4.63 on epoch=192
06/01/2022 04:27:45 - INFO - __main__ - Step 780 Global step 780 Train loss 4.55 on epoch=194
06/01/2022 04:27:46 - INFO - __main__ - Step 790 Global step 790 Train loss 4.51 on epoch=197
06/01/2022 04:27:47 - INFO - __main__ - Step 800 Global step 800 Train loss 4.52 on epoch=199
06/01/2022 04:27:54 - INFO - __main__ - Global step 800 Train loss 4.54 Classification-F1 0.0 on epoch=199
06/01/2022 04:27:55 - INFO - __main__ - Step 810 Global step 810 Train loss 4.32 on epoch=202
06/01/2022 04:27:56 - INFO - __main__ - Step 820 Global step 820 Train loss 4.67 on epoch=204
06/01/2022 04:27:58 - INFO - __main__ - Step 830 Global step 830 Train loss 4.42 on epoch=207
06/01/2022 04:27:59 - INFO - __main__ - Step 840 Global step 840 Train loss 4.33 on epoch=209
06/01/2022 04:28:00 - INFO - __main__ - Step 850 Global step 850 Train loss 4.26 on epoch=212
06/01/2022 04:28:10 - INFO - __main__ - Global step 850 Train loss 4.40 Classification-F1 0.0 on epoch=212
06/01/2022 04:28:11 - INFO - __main__ - Step 860 Global step 860 Train loss 4.34 on epoch=214
06/01/2022 04:28:13 - INFO - __main__ - Step 870 Global step 870 Train loss 4.21 on epoch=217
06/01/2022 04:28:14 - INFO - __main__ - Step 880 Global step 880 Train loss 4.27 on epoch=219
06/01/2022 04:28:15 - INFO - __main__ - Step 890 Global step 890 Train loss 4.22 on epoch=222
06/01/2022 04:28:16 - INFO - __main__ - Step 900 Global step 900 Train loss 4.23 on epoch=224
06/01/2022 04:28:22 - INFO - __main__ - Global step 900 Train loss 4.25 Classification-F1 0.0 on epoch=224
06/01/2022 04:28:23 - INFO - __main__ - Step 910 Global step 910 Train loss 4.02 on epoch=227
06/01/2022 04:28:24 - INFO - __main__ - Step 920 Global step 920 Train loss 4.27 on epoch=229
06/01/2022 04:28:26 - INFO - __main__ - Step 930 Global step 930 Train loss 4.12 on epoch=232
06/01/2022 04:28:27 - INFO - __main__ - Step 940 Global step 940 Train loss 4.18 on epoch=234
06/01/2022 04:28:28 - INFO - __main__ - Step 950 Global step 950 Train loss 4.05 on epoch=237
06/01/2022 04:28:35 - INFO - __main__ - Global step 950 Train loss 4.13 Classification-F1 0.01 on epoch=237
06/01/2022 04:28:35 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.01 on epoch=237, global_step=950
06/01/2022 04:28:36 - INFO - __main__ - Step 960 Global step 960 Train loss 3.89 on epoch=239
06/01/2022 04:28:38 - INFO - __main__ - Step 970 Global step 970 Train loss 3.89 on epoch=242
06/01/2022 04:28:39 - INFO - __main__ - Step 980 Global step 980 Train loss 3.92 on epoch=244
06/01/2022 04:28:40 - INFO - __main__ - Step 990 Global step 990 Train loss 4.18 on epoch=247
06/01/2022 04:28:41 - INFO - __main__ - Step 1000 Global step 1000 Train loss 3.89 on epoch=249
06/01/2022 04:28:46 - INFO - __main__ - Global step 1000 Train loss 3.95 Classification-F1 0.04255319148936171 on epoch=249
06/01/2022 04:28:46 - INFO - __main__ - Saving model with best Classification-F1: 0.01 -> 0.04255319148936171 on epoch=249, global_step=1000
06/01/2022 04:28:47 - INFO - __main__ - Step 1010 Global step 1010 Train loss 3.72 on epoch=252
06/01/2022 04:28:48 - INFO - __main__ - Step 1020 Global step 1020 Train loss 4.05 on epoch=254
06/01/2022 04:28:50 - INFO - __main__ - Step 1030 Global step 1030 Train loss 3.73 on epoch=257
06/01/2022 04:28:51 - INFO - __main__ - Step 1040 Global step 1040 Train loss 3.88 on epoch=259
06/01/2022 04:28:52 - INFO - __main__ - Step 1050 Global step 1050 Train loss 3.86 on epoch=262
06/01/2022 04:28:59 - INFO - __main__ - Global step 1050 Train loss 3.85 Classification-F1 0.06666666666666667 on epoch=262
06/01/2022 04:28:59 - INFO - __main__ - Saving model with best Classification-F1: 0.04255319148936171 -> 0.06666666666666667 on epoch=262, global_step=1050
06/01/2022 04:29:01 - INFO - __main__ - Step 1060 Global step 1060 Train loss 3.79 on epoch=264
06/01/2022 04:29:02 - INFO - __main__ - Step 1070 Global step 1070 Train loss 3.68 on epoch=267
06/01/2022 04:29:03 - INFO - __main__ - Step 1080 Global step 1080 Train loss 3.68 on epoch=269
06/01/2022 04:29:04 - INFO - __main__ - Step 1090 Global step 1090 Train loss 3.51 on epoch=272
06/01/2022 04:29:06 - INFO - __main__ - Step 1100 Global step 1100 Train loss 3.80 on epoch=274
06/01/2022 04:29:21 - INFO - __main__ - Global step 1100 Train loss 3.69 Classification-F1 0.1 on epoch=274
06/01/2022 04:29:21 - INFO - __main__ - Saving model with best Classification-F1: 0.06666666666666667 -> 0.1 on epoch=274, global_step=1100
06/01/2022 04:29:22 - INFO - __main__ - Step 1110 Global step 1110 Train loss 3.53 on epoch=277
06/01/2022 04:29:24 - INFO - __main__ - Step 1120 Global step 1120 Train loss 3.56 on epoch=279
06/01/2022 04:29:25 - INFO - __main__ - Step 1130 Global step 1130 Train loss 3.54 on epoch=282
06/01/2022 04:29:26 - INFO - __main__ - Step 1140 Global step 1140 Train loss 3.69 on epoch=284
06/01/2022 04:29:28 - INFO - __main__ - Step 1150 Global step 1150 Train loss 3.44 on epoch=287
06/01/2022 04:29:41 - INFO - __main__ - Global step 1150 Train loss 3.55 Classification-F1 0.0810126582278481 on epoch=287
06/01/2022 04:29:42 - INFO - __main__ - Step 1160 Global step 1160 Train loss 3.64 on epoch=289
06/01/2022 04:29:43 - INFO - __main__ - Step 1170 Global step 1170 Train loss 3.39 on epoch=292
06/01/2022 04:29:45 - INFO - __main__ - Step 1180 Global step 1180 Train loss 3.27 on epoch=294
06/01/2022 04:29:46 - INFO - __main__ - Step 1190 Global step 1190 Train loss 3.38 on epoch=297
06/01/2022 04:29:47 - INFO - __main__ - Step 1200 Global step 1200 Train loss 3.45 on epoch=299
06/01/2022 04:29:56 - INFO - __main__ - Global step 1200 Train loss 3.43 Classification-F1 0.0810126582278481 on epoch=299
06/01/2022 04:29:57 - INFO - __main__ - Step 1210 Global step 1210 Train loss 3.35 on epoch=302
06/01/2022 04:29:59 - INFO - __main__ - Step 1220 Global step 1220 Train loss 3.29 on epoch=304
06/01/2022 04:30:00 - INFO - __main__ - Step 1230 Global step 1230 Train loss 3.18 on epoch=307
06/01/2022 04:30:01 - INFO - __main__ - Step 1240 Global step 1240 Train loss 3.31 on epoch=309
06/01/2022 04:30:02 - INFO - __main__ - Step 1250 Global step 1250 Train loss 3.09 on epoch=312
06/01/2022 04:30:19 - INFO - __main__ - Global step 1250 Train loss 3.24 Classification-F1 0.1 on epoch=312
06/01/2022 04:30:20 - INFO - __main__ - Step 1260 Global step 1260 Train loss 3.29 on epoch=314
06/01/2022 04:30:21 - INFO - __main__ - Step 1270 Global step 1270 Train loss 3.12 on epoch=317
06/01/2022 04:30:23 - INFO - __main__ - Step 1280 Global step 1280 Train loss 3.09 on epoch=319
06/01/2022 04:30:24 - INFO - __main__ - Step 1290 Global step 1290 Train loss 3.07 on epoch=322
06/01/2022 04:30:25 - INFO - __main__ - Step 1300 Global step 1300 Train loss 3.22 on epoch=324
06/01/2022 04:30:43 - INFO - __main__ - Global step 1300 Train loss 3.16 Classification-F1 0.10126582278481013 on epoch=324
06/01/2022 04:30:43 - INFO - __main__ - Saving model with best Classification-F1: 0.1 -> 0.10126582278481013 on epoch=324, global_step=1300
06/01/2022 04:30:44 - INFO - __main__ - Step 1310 Global step 1310 Train loss 2.78 on epoch=327
06/01/2022 04:30:46 - INFO - __main__ - Step 1320 Global step 1320 Train loss 3.06 on epoch=329
06/01/2022 04:30:47 - INFO - __main__ - Step 1330 Global step 1330 Train loss 3.19 on epoch=332
06/01/2022 04:30:48 - INFO - __main__ - Step 1340 Global step 1340 Train loss 3.16 on epoch=334
06/01/2022 04:30:49 - INFO - __main__ - Step 1350 Global step 1350 Train loss 2.85 on epoch=337
06/01/2022 04:31:00 - INFO - __main__ - Global step 1350 Train loss 3.01 Classification-F1 0.10126582278481013 on epoch=337
06/01/2022 04:31:01 - INFO - __main__ - Step 1360 Global step 1360 Train loss 3.03 on epoch=339
06/01/2022 04:31:03 - INFO - __main__ - Step 1370 Global step 1370 Train loss 2.91 on epoch=342
06/01/2022 04:31:04 - INFO - __main__ - Step 1380 Global step 1380 Train loss 2.88 on epoch=344
06/01/2022 04:31:05 - INFO - __main__ - Step 1390 Global step 1390 Train loss 2.77 on epoch=347
06/01/2022 04:31:06 - INFO - __main__ - Step 1400 Global step 1400 Train loss 2.90 on epoch=349
06/01/2022 04:31:15 - INFO - __main__ - Global step 1400 Train loss 2.90 Classification-F1 0.1 on epoch=349
06/01/2022 04:31:16 - INFO - __main__ - Step 1410 Global step 1410 Train loss 2.70 on epoch=352
06/01/2022 04:31:18 - INFO - __main__ - Step 1420 Global step 1420 Train loss 2.90 on epoch=354
06/01/2022 04:31:19 - INFO - __main__ - Step 1430 Global step 1430 Train loss 2.86 on epoch=357
06/01/2022 04:31:20 - INFO - __main__ - Step 1440 Global step 1440 Train loss 2.86 on epoch=359
06/01/2022 04:31:21 - INFO - __main__ - Step 1450 Global step 1450 Train loss 2.69 on epoch=362
06/01/2022 04:31:31 - INFO - __main__ - Global step 1450 Train loss 2.80 Classification-F1 0.1 on epoch=362
06/01/2022 04:31:32 - INFO - __main__ - Step 1460 Global step 1460 Train loss 2.68 on epoch=364
06/01/2022 04:31:34 - INFO - __main__ - Step 1470 Global step 1470 Train loss 2.51 on epoch=367
06/01/2022 04:31:35 - INFO - __main__ - Step 1480 Global step 1480 Train loss 2.61 on epoch=369
06/01/2022 04:31:36 - INFO - __main__ - Step 1490 Global step 1490 Train loss 2.66 on epoch=372
06/01/2022 04:31:37 - INFO - __main__ - Step 1500 Global step 1500 Train loss 2.66 on epoch=374
06/01/2022 04:31:41 - INFO - __main__ - Global step 1500 Train loss 2.62 Classification-F1 0.1 on epoch=374
06/01/2022 04:31:42 - INFO - __main__ - Step 1510 Global step 1510 Train loss 2.49 on epoch=377
06/01/2022 04:31:43 - INFO - __main__ - Step 1520 Global step 1520 Train loss 2.58 on epoch=379
06/01/2022 04:31:44 - INFO - __main__ - Step 1530 Global step 1530 Train loss 2.41 on epoch=382
06/01/2022 04:31:45 - INFO - __main__ - Step 1540 Global step 1540 Train loss 2.56 on epoch=384
06/01/2022 04:31:47 - INFO - __main__ - Step 1550 Global step 1550 Train loss 2.51 on epoch=387
06/01/2022 04:31:47 - INFO - __main__ - Global step 1550 Train loss 2.51 Classification-F1 0.1 on epoch=387
06/01/2022 04:31:48 - INFO - __main__ - Step 1560 Global step 1560 Train loss 2.48 on epoch=389
06/01/2022 04:31:50 - INFO - __main__ - Step 1570 Global step 1570 Train loss 2.45 on epoch=392
06/01/2022 04:31:51 - INFO - __main__ - Step 1580 Global step 1580 Train loss 2.43 on epoch=394
06/01/2022 04:31:52 - INFO - __main__ - Step 1590 Global step 1590 Train loss 2.44 on epoch=397
06/01/2022 04:31:53 - INFO - __main__ - Step 1600 Global step 1600 Train loss 2.47 on epoch=399
06/01/2022 04:31:54 - INFO - __main__ - Global step 1600 Train loss 2.45 Classification-F1 0.1 on epoch=399
06/01/2022 04:31:55 - INFO - __main__ - Step 1610 Global step 1610 Train loss 2.22 on epoch=402
06/01/2022 04:31:56 - INFO - __main__ - Step 1620 Global step 1620 Train loss 2.25 on epoch=404
06/01/2022 04:31:58 - INFO - __main__ - Step 1630 Global step 1630 Train loss 2.12 on epoch=407
06/01/2022 04:31:59 - INFO - __main__ - Step 1640 Global step 1640 Train loss 2.25 on epoch=409
06/01/2022 04:32:00 - INFO - __main__ - Step 1650 Global step 1650 Train loss 2.36 on epoch=412
06/01/2022 04:32:01 - INFO - __main__ - Global step 1650 Train loss 2.24 Classification-F1 0.1 on epoch=412
06/01/2022 04:32:02 - INFO - __main__ - Step 1660 Global step 1660 Train loss 2.24 on epoch=414
06/01/2022 04:32:03 - INFO - __main__ - Step 1670 Global step 1670 Train loss 2.17 on epoch=417
06/01/2022 04:32:04 - INFO - __main__ - Step 1680 Global step 1680 Train loss 2.11 on epoch=419
06/01/2022 04:32:06 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.92 on epoch=422
06/01/2022 04:32:07 - INFO - __main__ - Step 1700 Global step 1700 Train loss 2.05 on epoch=424
06/01/2022 04:32:07 - INFO - __main__ - Global step 1700 Train loss 2.10 Classification-F1 0.1 on epoch=424
06/01/2022 04:32:09 - INFO - __main__ - Step 1710 Global step 1710 Train loss 2.05 on epoch=427
06/01/2022 04:32:10 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.97 on epoch=429
06/01/2022 04:32:11 - INFO - __main__ - Step 1730 Global step 1730 Train loss 2.14 on epoch=432
06/01/2022 04:32:12 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.93 on epoch=434
06/01/2022 04:32:13 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.89 on epoch=437
06/01/2022 04:32:14 - INFO - __main__ - Global step 1750 Train loss 2.00 Classification-F1 0.11762954139368673 on epoch=437
06/01/2022 04:32:14 - INFO - __main__ - Saving model with best Classification-F1: 0.10126582278481013 -> 0.11762954139368673 on epoch=437, global_step=1750
06/01/2022 04:32:15 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.98 on epoch=439
06/01/2022 04:32:16 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.77 on epoch=442
06/01/2022 04:32:18 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.87 on epoch=444
06/01/2022 04:32:19 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.77 on epoch=447
06/01/2022 04:32:20 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.96 on epoch=449
06/01/2022 04:32:21 - INFO - __main__ - Global step 1800 Train loss 1.87 Classification-F1 0.0974025974025974 on epoch=449
06/01/2022 04:32:22 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.85 on epoch=452
06/01/2022 04:32:23 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.63 on epoch=454
06/01/2022 04:32:24 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.77 on epoch=457
06/01/2022 04:32:26 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.62 on epoch=459
06/01/2022 04:32:27 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.80 on epoch=462
06/01/2022 04:32:27 - INFO - __main__ - Global step 1850 Train loss 1.74 Classification-F1 0.10389610389610389 on epoch=462
06/01/2022 04:32:29 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.74 on epoch=464
06/01/2022 04:32:30 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.67 on epoch=467
06/01/2022 04:32:31 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.72 on epoch=469
06/01/2022 04:32:32 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.66 on epoch=472
06/01/2022 04:32:34 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.54 on epoch=474
06/01/2022 04:32:34 - INFO - __main__ - Global step 1900 Train loss 1.67 Classification-F1 0.10126582278481013 on epoch=474
06/01/2022 04:32:35 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.52 on epoch=477
06/01/2022 04:32:37 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.68 on epoch=479
06/01/2022 04:32:38 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.63 on epoch=482
06/01/2022 04:32:39 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.52 on epoch=484
06/01/2022 04:32:40 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.64 on epoch=487
06/01/2022 04:32:41 - INFO - __main__ - Global step 1950 Train loss 1.60 Classification-F1 0.20238095238095238 on epoch=487
06/01/2022 04:32:41 - INFO - __main__ - Saving model with best Classification-F1: 0.11762954139368673 -> 0.20238095238095238 on epoch=487, global_step=1950
06/01/2022 04:32:42 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.66 on epoch=489
06/01/2022 04:32:43 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.67 on epoch=492
06/01/2022 04:32:45 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.65 on epoch=494
06/01/2022 04:32:46 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.43 on epoch=497
06/01/2022 04:32:47 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.48 on epoch=499
06/01/2022 04:32:48 - INFO - __main__ - Global step 2000 Train loss 1.58 Classification-F1 0.09493670886075949 on epoch=499
06/01/2022 04:32:49 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.56 on epoch=502
06/01/2022 04:32:50 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.59 on epoch=504
06/01/2022 04:32:51 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.35 on epoch=507
06/01/2022 04:32:53 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.63 on epoch=509
06/01/2022 04:32:54 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.55 on epoch=512
06/01/2022 04:32:54 - INFO - __main__ - Global step 2050 Train loss 1.54 Classification-F1 0.10126582278481013 on epoch=512
06/01/2022 04:32:55 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.49 on epoch=514
06/01/2022 04:32:57 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.53 on epoch=517
06/01/2022 04:32:58 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.35 on epoch=519
06/01/2022 04:32:59 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.39 on epoch=522
06/01/2022 04:33:00 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.53 on epoch=524
06/01/2022 04:33:01 - INFO - __main__ - Global step 2100 Train loss 1.46 Classification-F1 0.1 on epoch=524
06/01/2022 04:33:02 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.52 on epoch=527
06/01/2022 04:33:03 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.46 on epoch=529
06/01/2022 04:33:05 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.39 on epoch=532
06/01/2022 04:33:06 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.54 on epoch=534
06/01/2022 04:33:07 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.40 on epoch=537
06/01/2022 04:33:08 - INFO - __main__ - Global step 2150 Train loss 1.46 Classification-F1 0.1 on epoch=537
06/01/2022 04:33:09 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.39 on epoch=539
06/01/2022 04:33:10 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.41 on epoch=542
06/01/2022 04:33:11 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.48 on epoch=544
06/01/2022 04:33:13 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.37 on epoch=547
06/01/2022 04:33:14 - INFO - __main__ - Step 2200 Global step 2200 Train loss 1.55 on epoch=549
06/01/2022 04:33:14 - INFO - __main__ - Global step 2200 Train loss 1.44 Classification-F1 0.09090909090909091 on epoch=549
06/01/2022 04:33:16 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.33 on epoch=552
06/01/2022 04:33:17 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.42 on epoch=554
06/01/2022 04:33:18 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.46 on epoch=557
06/01/2022 04:33:19 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.27 on epoch=559
06/01/2022 04:33:21 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.43 on epoch=562
06/01/2022 04:33:21 - INFO - __main__ - Global step 2250 Train loss 1.38 Classification-F1 0.1 on epoch=562
06/01/2022 04:33:23 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.26 on epoch=564
06/01/2022 04:33:24 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.30 on epoch=567
06/01/2022 04:33:25 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.36 on epoch=569
06/01/2022 04:33:26 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.26 on epoch=572
06/01/2022 04:33:28 - INFO - __main__ - Step 2300 Global step 2300 Train loss 1.35 on epoch=574
06/01/2022 04:33:28 - INFO - __main__ - Global step 2300 Train loss 1.31 Classification-F1 0.1 on epoch=574
06/01/2022 04:33:29 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.38 on epoch=577
06/01/2022 04:33:31 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.27 on epoch=579
06/01/2022 04:33:32 - INFO - __main__ - Step 2330 Global step 2330 Train loss 1.35 on epoch=582
06/01/2022 04:33:33 - INFO - __main__ - Step 2340 Global step 2340 Train loss 1.35 on epoch=584
06/01/2022 04:33:35 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.29 on epoch=587
06/01/2022 04:33:35 - INFO - __main__ - Global step 2350 Train loss 1.33 Classification-F1 0.1 on epoch=587
06/01/2022 04:33:36 - INFO - __main__ - Step 2360 Global step 2360 Train loss 1.38 on epoch=589
06/01/2022 04:33:38 - INFO - __main__ - Step 2370 Global step 2370 Train loss 1.21 on epoch=592
06/01/2022 04:33:39 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.29 on epoch=594
06/01/2022 04:33:40 - INFO - __main__ - Step 2390 Global step 2390 Train loss 1.11 on epoch=597
06/01/2022 04:33:41 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.22 on epoch=599
06/01/2022 04:33:42 - INFO - __main__ - Global step 2400 Train loss 1.24 Classification-F1 0.1 on epoch=599
06/01/2022 04:33:43 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.18 on epoch=602
06/01/2022 04:33:44 - INFO - __main__ - Step 2420 Global step 2420 Train loss 1.31 on epoch=604
06/01/2022 04:33:46 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.21 on epoch=607
06/01/2022 04:33:47 - INFO - __main__ - Step 2440 Global step 2440 Train loss 1.25 on epoch=609
06/01/2022 04:33:48 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.35 on epoch=612
06/01/2022 04:33:49 - INFO - __main__ - Global step 2450 Train loss 1.26 Classification-F1 0.1 on epoch=612
06/01/2022 04:33:50 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.36 on epoch=614
06/01/2022 04:33:51 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.20 on epoch=617
06/01/2022 04:33:52 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.25 on epoch=619
06/01/2022 04:33:54 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.28 on epoch=622
06/01/2022 04:33:55 - INFO - __main__ - Step 2500 Global step 2500 Train loss 1.36 on epoch=624
06/01/2022 04:33:55 - INFO - __main__ - Global step 2500 Train loss 1.29 Classification-F1 0.1 on epoch=624
06/01/2022 04:33:57 - INFO - __main__ - Step 2510 Global step 2510 Train loss 1.27 on epoch=627
06/01/2022 04:33:58 - INFO - __main__ - Step 2520 Global step 2520 Train loss 1.37 on epoch=629
06/01/2022 04:33:59 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.26 on epoch=632
06/01/2022 04:34:01 - INFO - __main__ - Step 2540 Global step 2540 Train loss 1.45 on epoch=634
06/01/2022 04:34:02 - INFO - __main__ - Step 2550 Global step 2550 Train loss 1.37 on epoch=637
06/01/2022 04:34:02 - INFO - __main__ - Global step 2550 Train loss 1.35 Classification-F1 0.1 on epoch=637
06/01/2022 04:34:04 - INFO - __main__ - Step 2560 Global step 2560 Train loss 1.30 on epoch=639
06/01/2022 04:34:05 - INFO - __main__ - Step 2570 Global step 2570 Train loss 1.39 on epoch=642
06/01/2022 04:34:06 - INFO - __main__ - Step 2580 Global step 2580 Train loss 1.22 on epoch=644
06/01/2022 04:34:07 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.21 on epoch=647
06/01/2022 04:34:09 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.23 on epoch=649
06/01/2022 04:34:09 - INFO - __main__ - Global step 2600 Train loss 1.27 Classification-F1 0.10126582278481013 on epoch=649
06/01/2022 04:34:10 - INFO - __main__ - Step 2610 Global step 2610 Train loss 1.11 on epoch=652
06/01/2022 04:34:12 - INFO - __main__ - Step 2620 Global step 2620 Train loss 1.21 on epoch=654
06/01/2022 04:34:13 - INFO - __main__ - Step 2630 Global step 2630 Train loss 1.20 on epoch=657
06/01/2022 04:34:14 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.32 on epoch=659
06/01/2022 04:34:16 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.14 on epoch=662
06/01/2022 04:34:16 - INFO - __main__ - Global step 2650 Train loss 1.20 Classification-F1 0.1500341763499658 on epoch=662
06/01/2022 04:34:17 - INFO - __main__ - Step 2660 Global step 2660 Train loss 1.21 on epoch=664
06/01/2022 04:34:19 - INFO - __main__ - Step 2670 Global step 2670 Train loss 1.17 on epoch=667
06/01/2022 04:34:20 - INFO - __main__ - Step 2680 Global step 2680 Train loss 1.26 on epoch=669
06/01/2022 04:34:21 - INFO - __main__ - Step 2690 Global step 2690 Train loss 1.19 on epoch=672
06/01/2022 04:34:23 - INFO - __main__ - Step 2700 Global step 2700 Train loss 1.18 on epoch=674
06/01/2022 04:34:23 - INFO - __main__ - Global step 2700 Train loss 1.20 Classification-F1 0.09493670886075949 on epoch=674
06/01/2022 04:34:24 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.16 on epoch=677
06/01/2022 04:34:26 - INFO - __main__ - Step 2720 Global step 2720 Train loss 1.22 on epoch=679
06/01/2022 04:34:27 - INFO - __main__ - Step 2730 Global step 2730 Train loss 1.22 on epoch=682
06/01/2022 04:34:28 - INFO - __main__ - Step 2740 Global step 2740 Train loss 1.17 on epoch=684
06/01/2022 04:34:29 - INFO - __main__ - Step 2750 Global step 2750 Train loss 1.24 on epoch=687
06/01/2022 04:34:30 - INFO - __main__ - Global step 2750 Train loss 1.21 Classification-F1 0.13067758749069247 on epoch=687
06/01/2022 04:34:31 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.22 on epoch=689
06/01/2022 04:34:33 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.12 on epoch=692
06/01/2022 04:34:34 - INFO - __main__ - Step 2780 Global step 2780 Train loss 1.24 on epoch=694
06/01/2022 04:34:35 - INFO - __main__ - Step 2790 Global step 2790 Train loss 1.27 on epoch=697
06/01/2022 04:34:36 - INFO - __main__ - Step 2800 Global step 2800 Train loss 1.15 on epoch=699
06/01/2022 04:34:37 - INFO - __main__ - Global step 2800 Train loss 1.20 Classification-F1 0.09090909090909091 on epoch=699
06/01/2022 04:34:38 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.14 on epoch=702
06/01/2022 04:34:39 - INFO - __main__ - Step 2820 Global step 2820 Train loss 1.18 on epoch=704
06/01/2022 04:34:41 - INFO - __main__ - Step 2830 Global step 2830 Train loss 1.12 on epoch=707
06/01/2022 04:34:42 - INFO - __main__ - Step 2840 Global step 2840 Train loss 1.09 on epoch=709
06/01/2022 04:34:43 - INFO - __main__ - Step 2850 Global step 2850 Train loss 1.13 on epoch=712
06/01/2022 04:34:44 - INFO - __main__ - Global step 2850 Train loss 1.13 Classification-F1 0.1 on epoch=712
06/01/2022 04:34:45 - INFO - __main__ - Step 2860 Global step 2860 Train loss 1.22 on epoch=714
06/01/2022 04:34:46 - INFO - __main__ - Step 2870 Global step 2870 Train loss 1.16 on epoch=717
06/01/2022 04:34:47 - INFO - __main__ - Step 2880 Global step 2880 Train loss 1.27 on epoch=719
06/01/2022 04:34:49 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.20 on epoch=722
06/01/2022 04:34:50 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.26 on epoch=724
06/01/2022 04:34:50 - INFO - __main__ - Global step 2900 Train loss 1.22 Classification-F1 0.1 on epoch=724
06/01/2022 04:34:52 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.11 on epoch=727
06/01/2022 04:34:53 - INFO - __main__ - Step 2920 Global step 2920 Train loss 1.23 on epoch=729
06/01/2022 04:34:54 - INFO - __main__ - Step 2930 Global step 2930 Train loss 1.19 on epoch=732
06/01/2022 04:34:55 - INFO - __main__ - Step 2940 Global step 2940 Train loss 1.10 on epoch=734
06/01/2022 04:34:57 - INFO - __main__ - Step 2950 Global step 2950 Train loss 1.15 on epoch=737
06/01/2022 04:34:57 - INFO - __main__ - Global step 2950 Train loss 1.15 Classification-F1 0.10126582278481013 on epoch=737
06/01/2022 04:34:58 - INFO - __main__ - Step 2960 Global step 2960 Train loss 1.21 on epoch=739
06/01/2022 04:35:00 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.14 on epoch=742
06/01/2022 04:35:01 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.24 on epoch=744
06/01/2022 04:35:02 - INFO - __main__ - Step 2990 Global step 2990 Train loss 1.11 on epoch=747
06/01/2022 04:35:04 - INFO - __main__ - Step 3000 Global step 3000 Train loss 1.13 on epoch=749
06/01/2022 04:35:04 - INFO - __main__ - Global step 3000 Train loss 1.17 Classification-F1 0.1 on epoch=749
06/01/2022 04:35:04 - INFO - __main__ - save last model!
06/01/2022 04:35:04 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/01/2022 04:35:04 - INFO - __main__ - Start tokenizing ... 5509 instances
06/01/2022 04:35:04 - INFO - __main__ - Printing 3 examples
06/01/2022 04:35:04 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/01/2022 04:35:04 - INFO - __main__ - ['others']
06/01/2022 04:35:04 - INFO - __main__ -  [emo] what you like very little things ok
06/01/2022 04:35:04 - INFO - __main__ - ['others']
06/01/2022 04:35:04 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/01/2022 04:35:04 - INFO - __main__ - ['others']
06/01/2022 04:35:04 - INFO - __main__ - Tokenizing Input ...
06/01/2022 04:35:05 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 04:35:05 - INFO - __main__ - Printing 3 examples
06/01/2022 04:35:05 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/01/2022 04:35:05 - INFO - __main__ - ['others']
06/01/2022 04:35:05 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/01/2022 04:35:05 - INFO - __main__ - ['others']
06/01/2022 04:35:05 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/01/2022 04:35:05 - INFO - __main__ - ['others']
06/01/2022 04:35:05 - INFO - __main__ - Tokenizing Input ...
06/01/2022 04:35:05 - INFO - __main__ - Tokenizing Output ...
06/01/2022 04:35:05 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 04:35:05 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 04:35:05 - INFO - __main__ - Printing 3 examples
06/01/2022 04:35:05 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
06/01/2022 04:35:05 - INFO - __main__ - ['others']
06/01/2022 04:35:05 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
06/01/2022 04:35:05 - INFO - __main__ - ['others']
06/01/2022 04:35:05 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
06/01/2022 04:35:05 - INFO - __main__ - ['others']
06/01/2022 04:35:05 - INFO - __main__ - Tokenizing Input ...
06/01/2022 04:35:05 - INFO - __main__ - Tokenizing Output ...
06/01/2022 04:35:05 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 04:35:06 - INFO - __main__ - Tokenizing Output ...
06/01/2022 04:35:10 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 04:35:11 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/01/2022 04:35:11 - INFO - __main__ - Starting training!
06/01/2022 04:35:12 - INFO - __main__ - Loaded 5509 examples from test data
06/01/2022 04:35:55 - INFO - __main__ - Saved prediction in models/T5-base-reptile-cls2cls-3e-5-2-5000-5e-1-10/singletask-emo/emo_16_42_0.2_8_predictions.txt
06/01/2022 04:35:55 - INFO - __main__ - Classification-F1 on test data: 0.0217
06/01/2022 04:35:55 - INFO - __main__ - prefix=emo_16_42, lr=0.2, bsz=8, dev_performance=0.20238095238095238, test_performance=0.021720243266724587
06/01/2022 04:35:55 - INFO - __main__ - Running ... prefix=emo_16_87, lr=0.5, bsz=8 ...
06/01/2022 04:35:56 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 04:35:56 - INFO - __main__ - Printing 3 examples
06/01/2022 04:35:56 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/01/2022 04:35:56 - INFO - __main__ - ['others']
06/01/2022 04:35:56 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/01/2022 04:35:56 - INFO - __main__ - ['others']
06/01/2022 04:35:56 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/01/2022 04:35:56 - INFO - __main__ - ['others']
06/01/2022 04:35:56 - INFO - __main__ - Tokenizing Input ...
06/01/2022 04:35:56 - INFO - __main__ - Tokenizing Output ...
06/01/2022 04:35:57 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 04:35:57 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 04:35:57 - INFO - __main__ - Printing 3 examples
06/01/2022 04:35:57 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
06/01/2022 04:35:57 - INFO - __main__ - ['others']
06/01/2022 04:35:57 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
06/01/2022 04:35:57 - INFO - __main__ - ['others']
06/01/2022 04:35:57 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
06/01/2022 04:35:57 - INFO - __main__ - ['others']
06/01/2022 04:35:57 - INFO - __main__ - Tokenizing Input ...
06/01/2022 04:35:57 - INFO - __main__ - Tokenizing Output ...
06/01/2022 04:35:57 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 04:36:02 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 04:36:03 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/01/2022 04:36:03 - INFO - __main__ - Starting training!
06/01/2022 04:36:04 - INFO - __main__ - Step 10 Global step 10 Train loss 8.97 on epoch=2
06/01/2022 04:36:06 - INFO - __main__ - Step 20 Global step 20 Train loss 8.99 on epoch=4
06/01/2022 04:36:07 - INFO - __main__ - Step 30 Global step 30 Train loss 8.88 on epoch=7
06/01/2022 04:36:08 - INFO - __main__ - Step 40 Global step 40 Train loss 8.85 on epoch=9
06/01/2022 04:36:10 - INFO - __main__ - Step 50 Global step 50 Train loss 8.87 on epoch=12
06/01/2022 04:36:18 - INFO - __main__ - Global step 50 Train loss 8.91 Classification-F1 0.0 on epoch=12
06/01/2022 04:36:18 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
06/01/2022 04:36:19 - INFO - __main__ - Step 60 Global step 60 Train loss 8.67 on epoch=14
06/01/2022 04:36:20 - INFO - __main__ - Step 70 Global step 70 Train loss 8.67 on epoch=17
06/01/2022 04:36:22 - INFO - __main__ - Step 80 Global step 80 Train loss 8.47 on epoch=19
06/01/2022 04:36:23 - INFO - __main__ - Step 90 Global step 90 Train loss 8.29 on epoch=22
06/01/2022 04:36:24 - INFO - __main__ - Step 100 Global step 100 Train loss 8.11 on epoch=24
06/01/2022 04:36:39 - INFO - __main__ - Global step 100 Train loss 8.44 Classification-F1 0.0 on epoch=24
06/01/2022 04:36:41 - INFO - __main__ - Step 110 Global step 110 Train loss 7.80 on epoch=27
06/01/2022 04:36:42 - INFO - __main__ - Step 120 Global step 120 Train loss 7.72 on epoch=29
06/01/2022 04:36:43 - INFO - __main__ - Step 130 Global step 130 Train loss 7.56 on epoch=32
06/01/2022 04:36:45 - INFO - __main__ - Step 140 Global step 140 Train loss 7.13 on epoch=34
06/01/2022 04:36:46 - INFO - __main__ - Step 150 Global step 150 Train loss 6.91 on epoch=37
06/01/2022 04:36:54 - INFO - __main__ - Global step 150 Train loss 7.42 Classification-F1 0.0 on epoch=37
06/01/2022 04:36:56 - INFO - __main__ - Step 160 Global step 160 Train loss 7.00 on epoch=39
06/01/2022 04:36:57 - INFO - __main__ - Step 170 Global step 170 Train loss 6.59 on epoch=42
06/01/2022 04:36:58 - INFO - __main__ - Step 180 Global step 180 Train loss 6.48 on epoch=44
06/01/2022 04:36:59 - INFO - __main__ - Step 190 Global step 190 Train loss 6.84 on epoch=47
06/01/2022 04:37:01 - INFO - __main__ - Step 200 Global step 200 Train loss 6.66 on epoch=49
06/01/2022 04:37:03 - INFO - __main__ - Global step 200 Train loss 6.71 Classification-F1 0.0 on epoch=49
06/01/2022 04:37:04 - INFO - __main__ - Step 210 Global step 210 Train loss 6.37 on epoch=52
06/01/2022 04:37:06 - INFO - __main__ - Step 220 Global step 220 Train loss 6.03 on epoch=54
06/01/2022 04:37:07 - INFO - __main__ - Step 230 Global step 230 Train loss 6.07 on epoch=57
06/01/2022 04:37:08 - INFO - __main__ - Step 240 Global step 240 Train loss 5.89 on epoch=59
06/01/2022 04:37:09 - INFO - __main__ - Step 250 Global step 250 Train loss 5.99 on epoch=62
06/01/2022 04:37:11 - INFO - __main__ - Global step 250 Train loss 6.07 Classification-F1 0.0 on epoch=62
06/01/2022 04:37:13 - INFO - __main__ - Step 260 Global step 260 Train loss 5.67 on epoch=64
06/01/2022 04:37:14 - INFO - __main__ - Step 270 Global step 270 Train loss 5.90 on epoch=67
06/01/2022 04:37:15 - INFO - __main__ - Step 280 Global step 280 Train loss 5.48 on epoch=69
06/01/2022 04:37:16 - INFO - __main__ - Step 290 Global step 290 Train loss 5.32 on epoch=72
06/01/2022 04:37:18 - INFO - __main__ - Step 300 Global step 300 Train loss 5.11 on epoch=74
06/01/2022 04:37:25 - INFO - __main__ - Global step 300 Train loss 5.50 Classification-F1 0.0 on epoch=74
06/01/2022 04:37:27 - INFO - __main__ - Step 310 Global step 310 Train loss 4.99 on epoch=77
06/01/2022 04:37:28 - INFO - __main__ - Step 320 Global step 320 Train loss 4.79 on epoch=79
06/01/2022 04:37:29 - INFO - __main__ - Step 330 Global step 330 Train loss 4.58 on epoch=82
06/01/2022 04:37:30 - INFO - __main__ - Step 340 Global step 340 Train loss 4.40 on epoch=84
06/01/2022 04:37:32 - INFO - __main__ - Step 350 Global step 350 Train loss 4.74 on epoch=87
06/01/2022 04:37:41 - INFO - __main__ - Global step 350 Train loss 4.70 Classification-F1 0.0 on epoch=87
06/01/2022 04:37:43 - INFO - __main__ - Step 360 Global step 360 Train loss 4.53 on epoch=89
06/01/2022 04:37:44 - INFO - __main__ - Step 370 Global step 370 Train loss 4.38 on epoch=92
06/01/2022 04:37:45 - INFO - __main__ - Step 380 Global step 380 Train loss 4.12 on epoch=94
06/01/2022 04:37:46 - INFO - __main__ - Step 390 Global step 390 Train loss 4.13 on epoch=97
06/01/2022 04:37:47 - INFO - __main__ - Step 400 Global step 400 Train loss 3.85 on epoch=99
06/01/2022 04:37:50 - INFO - __main__ - Global step 400 Train loss 4.20 Classification-F1 0.0 on epoch=99
06/01/2022 04:37:51 - INFO - __main__ - Step 410 Global step 410 Train loss 3.92 on epoch=102
06/01/2022 04:37:52 - INFO - __main__ - Step 420 Global step 420 Train loss 3.58 on epoch=104
06/01/2022 04:37:53 - INFO - __main__ - Step 430 Global step 430 Train loss 3.58 on epoch=107
06/01/2022 04:37:55 - INFO - __main__ - Step 440 Global step 440 Train loss 3.49 on epoch=109
06/01/2022 04:37:56 - INFO - __main__ - Step 450 Global step 450 Train loss 3.47 on epoch=112
06/01/2022 04:37:58 - INFO - __main__ - Global step 450 Train loss 3.61 Classification-F1 0.12519607843137254 on epoch=112
06/01/2022 04:37:59 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.12519607843137254 on epoch=112, global_step=450
06/01/2022 04:38:00 - INFO - __main__ - Step 460 Global step 460 Train loss 3.37 on epoch=114
06/01/2022 04:38:01 - INFO - __main__ - Step 470 Global step 470 Train loss 3.47 on epoch=117
06/01/2022 04:38:02 - INFO - __main__ - Step 480 Global step 480 Train loss 3.08 on epoch=119
06/01/2022 04:38:03 - INFO - __main__ - Step 490 Global step 490 Train loss 3.05 on epoch=122
06/01/2022 04:38:05 - INFO - __main__ - Step 500 Global step 500 Train loss 2.86 on epoch=124
06/01/2022 04:38:05 - INFO - __main__ - Global step 500 Train loss 3.17 Classification-F1 0.1527777777777778 on epoch=124
06/01/2022 04:38:05 - INFO - __main__ - Saving model with best Classification-F1: 0.12519607843137254 -> 0.1527777777777778 on epoch=124, global_step=500
06/01/2022 04:38:07 - INFO - __main__ - Step 510 Global step 510 Train loss 2.93 on epoch=127
06/01/2022 04:38:08 - INFO - __main__ - Step 520 Global step 520 Train loss 2.78 on epoch=129
06/01/2022 04:38:09 - INFO - __main__ - Step 530 Global step 530 Train loss 2.64 on epoch=132
06/01/2022 04:38:10 - INFO - __main__ - Step 540 Global step 540 Train loss 2.73 on epoch=134
06/01/2022 04:38:12 - INFO - __main__ - Step 550 Global step 550 Train loss 2.63 on epoch=137
06/01/2022 04:38:12 - INFO - __main__ - Global step 550 Train loss 2.74 Classification-F1 0.12407862407862408 on epoch=137
06/01/2022 04:38:13 - INFO - __main__ - Step 560 Global step 560 Train loss 2.31 on epoch=139
06/01/2022 04:38:15 - INFO - __main__ - Step 570 Global step 570 Train loss 2.44 on epoch=142
06/01/2022 04:38:16 - INFO - __main__ - Step 580 Global step 580 Train loss 2.08 on epoch=144
06/01/2022 04:38:17 - INFO - __main__ - Step 590 Global step 590 Train loss 2.20 on epoch=147
06/01/2022 04:38:18 - INFO - __main__ - Step 600 Global step 600 Train loss 2.29 on epoch=149
06/01/2022 04:38:19 - INFO - __main__ - Global step 600 Train loss 2.27 Classification-F1 0.1081081081081081 on epoch=149
06/01/2022 04:38:20 - INFO - __main__ - Step 610 Global step 610 Train loss 2.19 on epoch=152
06/01/2022 04:38:22 - INFO - __main__ - Step 620 Global step 620 Train loss 2.12 on epoch=154
06/01/2022 04:38:23 - INFO - __main__ - Step 630 Global step 630 Train loss 2.18 on epoch=157
06/01/2022 04:38:24 - INFO - __main__ - Step 640 Global step 640 Train loss 1.91 on epoch=159
06/01/2022 04:38:25 - INFO - __main__ - Step 650 Global step 650 Train loss 1.95 on epoch=162
06/01/2022 04:38:26 - INFO - __main__ - Global step 650 Train loss 2.07 Classification-F1 0.15521739130434786 on epoch=162
06/01/2022 04:38:26 - INFO - __main__ - Saving model with best Classification-F1: 0.1527777777777778 -> 0.15521739130434786 on epoch=162, global_step=650
06/01/2022 04:38:27 - INFO - __main__ - Step 660 Global step 660 Train loss 1.82 on epoch=164
06/01/2022 04:38:28 - INFO - __main__ - Step 670 Global step 670 Train loss 1.88 on epoch=167
06/01/2022 04:38:30 - INFO - __main__ - Step 680 Global step 680 Train loss 1.83 on epoch=169
06/01/2022 04:38:31 - INFO - __main__ - Step 690 Global step 690 Train loss 1.75 on epoch=172
06/01/2022 04:38:32 - INFO - __main__ - Step 700 Global step 700 Train loss 1.67 on epoch=174
06/01/2022 04:38:33 - INFO - __main__ - Global step 700 Train loss 1.79 Classification-F1 0.1451048951048951 on epoch=174
06/01/2022 04:38:34 - INFO - __main__ - Step 710 Global step 710 Train loss 1.77 on epoch=177
06/01/2022 04:38:35 - INFO - __main__ - Step 720 Global step 720 Train loss 1.58 on epoch=179
06/01/2022 04:38:37 - INFO - __main__ - Step 730 Global step 730 Train loss 1.72 on epoch=182
06/01/2022 04:38:38 - INFO - __main__ - Step 740 Global step 740 Train loss 1.61 on epoch=184
06/01/2022 04:38:39 - INFO - __main__ - Step 750 Global step 750 Train loss 1.57 on epoch=187
06/01/2022 04:38:40 - INFO - __main__ - Global step 750 Train loss 1.65 Classification-F1 0.22026143790849673 on epoch=187
06/01/2022 04:38:40 - INFO - __main__ - Saving model with best Classification-F1: 0.15521739130434786 -> 0.22026143790849673 on epoch=187, global_step=750
06/01/2022 04:38:41 - INFO - __main__ - Step 760 Global step 760 Train loss 1.64 on epoch=189
06/01/2022 04:38:42 - INFO - __main__ - Step 770 Global step 770 Train loss 1.57 on epoch=192
06/01/2022 04:38:43 - INFO - __main__ - Step 780 Global step 780 Train loss 1.64 on epoch=194
06/01/2022 04:38:45 - INFO - __main__ - Step 790 Global step 790 Train loss 1.49 on epoch=197
06/01/2022 04:38:46 - INFO - __main__ - Step 800 Global step 800 Train loss 1.54 on epoch=199
06/01/2022 04:38:46 - INFO - __main__ - Global step 800 Train loss 1.58 Classification-F1 0.16078790655061842 on epoch=199
06/01/2022 04:38:48 - INFO - __main__ - Step 810 Global step 810 Train loss 1.59 on epoch=202
06/01/2022 04:38:49 - INFO - __main__ - Step 820 Global step 820 Train loss 1.48 on epoch=204
06/01/2022 04:38:50 - INFO - __main__ - Step 830 Global step 830 Train loss 1.59 on epoch=207
06/01/2022 04:38:51 - INFO - __main__ - Step 840 Global step 840 Train loss 1.48 on epoch=209
06/01/2022 04:38:53 - INFO - __main__ - Step 850 Global step 850 Train loss 1.40 on epoch=212
06/01/2022 04:38:53 - INFO - __main__ - Global step 850 Train loss 1.51 Classification-F1 0.0974025974025974 on epoch=212
06/01/2022 04:38:54 - INFO - __main__ - Step 860 Global step 860 Train loss 1.39 on epoch=214
06/01/2022 04:38:56 - INFO - __main__ - Step 870 Global step 870 Train loss 1.46 on epoch=217
06/01/2022 04:38:57 - INFO - __main__ - Step 880 Global step 880 Train loss 1.43 on epoch=219
06/01/2022 04:38:58 - INFO - __main__ - Step 890 Global step 890 Train loss 1.42 on epoch=222
06/01/2022 04:38:59 - INFO - __main__ - Step 900 Global step 900 Train loss 1.48 on epoch=224
06/01/2022 04:39:00 - INFO - __main__ - Global step 900 Train loss 1.43 Classification-F1 0.16666666666666669 on epoch=224
06/01/2022 04:39:01 - INFO - __main__ - Step 910 Global step 910 Train loss 1.50 on epoch=227
06/01/2022 04:39:02 - INFO - __main__ - Step 920 Global step 920 Train loss 1.35 on epoch=229
06/01/2022 04:39:04 - INFO - __main__ - Step 930 Global step 930 Train loss 1.28 on epoch=232
06/01/2022 04:39:05 - INFO - __main__ - Step 940 Global step 940 Train loss 1.40 on epoch=234
06/01/2022 04:39:06 - INFO - __main__ - Step 950 Global step 950 Train loss 1.37 on epoch=237
06/01/2022 04:39:07 - INFO - __main__ - Global step 950 Train loss 1.38 Classification-F1 0.180905815748842 on epoch=237
06/01/2022 04:39:08 - INFO - __main__ - Step 960 Global step 960 Train loss 1.18 on epoch=239
06/01/2022 04:39:09 - INFO - __main__ - Step 970 Global step 970 Train loss 1.38 on epoch=242
06/01/2022 04:39:11 - INFO - __main__ - Step 980 Global step 980 Train loss 1.22 on epoch=244
06/01/2022 04:39:12 - INFO - __main__ - Step 990 Global step 990 Train loss 1.35 on epoch=247
06/01/2022 04:39:13 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.25 on epoch=249
06/01/2022 04:39:14 - INFO - __main__ - Global step 1000 Train loss 1.27 Classification-F1 0.2152777777777778 on epoch=249
06/01/2022 04:39:15 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.19 on epoch=252
06/01/2022 04:39:16 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.33 on epoch=254
06/01/2022 04:39:17 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.29 on epoch=257
06/01/2022 04:39:19 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.28 on epoch=259
06/01/2022 04:39:20 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.13 on epoch=262
06/01/2022 04:39:21 - INFO - __main__ - Global step 1050 Train loss 1.24 Classification-F1 0.1476190476190476 on epoch=262
06/01/2022 04:39:22 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.25 on epoch=264
06/01/2022 04:39:23 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.21 on epoch=267
06/01/2022 04:39:24 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.10 on epoch=269
06/01/2022 04:39:26 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.20 on epoch=272
06/01/2022 04:39:27 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.21 on epoch=274
06/01/2022 04:39:27 - INFO - __main__ - Global step 1100 Train loss 1.19 Classification-F1 0.1 on epoch=274
06/01/2022 04:39:29 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.21 on epoch=277
06/01/2022 04:39:30 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.39 on epoch=279
06/01/2022 04:39:31 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.14 on epoch=282
06/01/2022 04:39:33 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.23 on epoch=284
06/01/2022 04:39:34 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.23 on epoch=287
06/01/2022 04:39:34 - INFO - __main__ - Global step 1150 Train loss 1.24 Classification-F1 0.1542857142857143 on epoch=287
06/01/2022 04:39:36 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.14 on epoch=289
06/01/2022 04:39:37 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.34 on epoch=292
06/01/2022 04:39:38 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.15 on epoch=294
06/01/2022 04:39:40 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.09 on epoch=297
06/01/2022 04:39:41 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.16 on epoch=299
06/01/2022 04:39:41 - INFO - __main__ - Global step 1200 Train loss 1.18 Classification-F1 0.13194444444444445 on epoch=299
06/01/2022 04:39:43 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.32 on epoch=302
06/01/2022 04:39:44 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.18 on epoch=304
06/01/2022 04:39:45 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.21 on epoch=307
06/01/2022 04:39:46 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.18 on epoch=309
06/01/2022 04:39:48 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.20 on epoch=312
06/01/2022 04:39:48 - INFO - __main__ - Global step 1250 Train loss 1.22 Classification-F1 0.18607843137254904 on epoch=312
06/01/2022 04:39:50 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.17 on epoch=314
06/01/2022 04:39:51 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.17 on epoch=317
06/01/2022 04:39:52 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.99 on epoch=319
06/01/2022 04:39:53 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.17 on epoch=322
06/01/2022 04:39:55 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.17 on epoch=324
06/01/2022 04:39:55 - INFO - __main__ - Global step 1300 Train loss 1.13 Classification-F1 0.1785516860143726 on epoch=324
06/01/2022 04:39:56 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.10 on epoch=327
06/01/2022 04:39:58 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.14 on epoch=329
06/01/2022 04:39:59 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.13 on epoch=332
06/01/2022 04:40:00 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.14 on epoch=334
06/01/2022 04:40:02 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.11 on epoch=337
06/01/2022 04:40:02 - INFO - __main__ - Global step 1350 Train loss 1.12 Classification-F1 0.1237183868762816 on epoch=337
06/01/2022 04:40:03 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.14 on epoch=339
06/01/2022 04:40:05 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.02 on epoch=342
06/01/2022 04:40:06 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.12 on epoch=344
06/01/2022 04:40:07 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.04 on epoch=347
06/01/2022 04:40:09 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.09 on epoch=349
06/01/2022 04:40:09 - INFO - __main__ - Global step 1400 Train loss 1.08 Classification-F1 0.13067758749069247 on epoch=349
06/01/2022 04:40:10 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.12 on epoch=352
06/01/2022 04:40:12 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.10 on epoch=354
06/01/2022 04:40:13 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.09 on epoch=357
06/01/2022 04:40:14 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.03 on epoch=359
06/01/2022 04:40:15 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.93 on epoch=362
06/01/2022 04:40:16 - INFO - __main__ - Global step 1450 Train loss 1.05 Classification-F1 0.125 on epoch=362
06/01/2022 04:40:17 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.01 on epoch=364
06/01/2022 04:40:19 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.96 on epoch=367
06/01/2022 04:40:20 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.01 on epoch=369
06/01/2022 04:40:21 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.05 on epoch=372
06/01/2022 04:40:22 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.06 on epoch=374
06/01/2022 04:40:23 - INFO - __main__ - Global step 1500 Train loss 1.02 Classification-F1 0.12393162393162392 on epoch=374
06/01/2022 04:40:24 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.04 on epoch=377
06/01/2022 04:40:26 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.09 on epoch=379
06/01/2022 04:40:27 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.99 on epoch=382
06/01/2022 04:40:28 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.95 on epoch=384
06/01/2022 04:40:29 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.14 on epoch=387
06/01/2022 04:40:30 - INFO - __main__ - Global step 1550 Train loss 1.04 Classification-F1 0.1468058968058968 on epoch=387
06/01/2022 04:40:31 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.01 on epoch=389
06/01/2022 04:40:32 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.07 on epoch=392
06/01/2022 04:40:34 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.00 on epoch=394
06/01/2022 04:40:35 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.04 on epoch=397
06/01/2022 04:40:36 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.03 on epoch=399
06/01/2022 04:40:37 - INFO - __main__ - Global step 1600 Train loss 1.03 Classification-F1 0.1 on epoch=399
06/01/2022 04:40:38 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.17 on epoch=402
06/01/2022 04:40:39 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.02 on epoch=404
06/01/2022 04:40:41 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.02 on epoch=407
06/01/2022 04:40:42 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.06 on epoch=409
06/01/2022 04:40:43 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.03 on epoch=412
06/01/2022 04:40:44 - INFO - __main__ - Global step 1650 Train loss 1.06 Classification-F1 0.14285714285714285 on epoch=412
06/01/2022 04:40:45 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.99 on epoch=414
06/01/2022 04:40:46 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.98 on epoch=417
06/01/2022 04:40:48 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.98 on epoch=419
06/01/2022 04:40:49 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.05 on epoch=422
06/01/2022 04:40:50 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.10 on epoch=424
06/01/2022 04:40:51 - INFO - __main__ - Global step 1700 Train loss 1.02 Classification-F1 0.09090909090909091 on epoch=424
06/01/2022 04:40:52 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.03 on epoch=427
06/01/2022 04:40:53 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.13 on epoch=429
06/01/2022 04:40:55 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.18 on epoch=432
06/01/2022 04:40:56 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.94 on epoch=434
06/01/2022 04:40:57 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.90 on epoch=437
06/01/2022 04:40:58 - INFO - __main__ - Global step 1750 Train loss 1.03 Classification-F1 0.09333333333333334 on epoch=437
06/01/2022 04:40:59 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.89 on epoch=439
06/01/2022 04:41:00 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.00 on epoch=442
06/01/2022 04:41:01 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.02 on epoch=444
06/01/2022 04:41:03 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.08 on epoch=447
06/01/2022 04:41:04 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.08 on epoch=449
06/01/2022 04:41:04 - INFO - __main__ - Global step 1800 Train loss 1.01 Classification-F1 0.0974025974025974 on epoch=449
06/01/2022 04:41:06 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.97 on epoch=452
06/01/2022 04:41:07 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.16 on epoch=454
06/01/2022 04:41:08 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.97 on epoch=457
06/01/2022 04:41:10 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.07 on epoch=459
06/01/2022 04:41:11 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.10 on epoch=462
06/01/2022 04:41:11 - INFO - __main__ - Global step 1850 Train loss 1.06 Classification-F1 0.10256410256410256 on epoch=462
06/01/2022 04:41:13 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.03 on epoch=464
06/01/2022 04:41:14 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.97 on epoch=467
06/01/2022 04:41:15 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.97 on epoch=469
06/01/2022 04:41:17 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.00 on epoch=472
06/01/2022 04:41:18 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.97 on epoch=474
06/01/2022 04:41:18 - INFO - __main__ - Global step 1900 Train loss 0.99 Classification-F1 0.20053774017968393 on epoch=474
06/01/2022 04:41:20 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.96 on epoch=477
06/01/2022 04:41:21 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.13 on epoch=479
06/01/2022 04:41:22 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.97 on epoch=482
06/01/2022 04:41:23 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.04 on epoch=484
06/01/2022 04:41:25 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.94 on epoch=487
06/01/2022 04:41:25 - INFO - __main__ - Global step 1950 Train loss 1.01 Classification-F1 0.2269119769119769 on epoch=487
06/01/2022 04:41:25 - INFO - __main__ - Saving model with best Classification-F1: 0.22026143790849673 -> 0.2269119769119769 on epoch=487, global_step=1950
06/01/2022 04:41:27 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.93 on epoch=489
06/01/2022 04:41:28 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.02 on epoch=492
06/01/2022 04:41:29 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.02 on epoch=494
06/01/2022 04:41:30 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.16 on epoch=497
06/01/2022 04:41:32 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.10 on epoch=499
06/01/2022 04:41:32 - INFO - __main__ - Global step 2000 Train loss 1.04 Classification-F1 0.18618266978922718 on epoch=499
06/01/2022 04:41:34 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.01 on epoch=502
06/01/2022 04:41:35 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.98 on epoch=504
06/01/2022 04:41:36 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.11 on epoch=507
06/01/2022 04:41:37 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.01 on epoch=509
06/01/2022 04:41:39 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.07 on epoch=512
06/01/2022 04:41:39 - INFO - __main__ - Global step 2050 Train loss 1.03 Classification-F1 0.18833746898263026 on epoch=512
06/01/2022 04:41:40 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.97 on epoch=514
06/01/2022 04:41:42 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.04 on epoch=517
06/01/2022 04:41:43 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.00 on epoch=519
06/01/2022 04:41:44 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.07 on epoch=522
06/01/2022 04:41:45 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.97 on epoch=524
06/01/2022 04:41:46 - INFO - __main__ - Global step 2100 Train loss 1.01 Classification-F1 0.1597222222222222 on epoch=524
06/01/2022 04:41:47 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.05 on epoch=527
06/01/2022 04:41:49 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.08 on epoch=529
06/01/2022 04:41:50 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.99 on epoch=532
06/01/2022 04:41:51 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.03 on epoch=534
06/01/2022 04:41:52 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.03 on epoch=537
06/01/2022 04:41:53 - INFO - __main__ - Global step 2150 Train loss 1.04 Classification-F1 0.1638655462184874 on epoch=537
06/01/2022 04:41:54 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.96 on epoch=539
06/01/2022 04:41:56 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.03 on epoch=542
06/01/2022 04:41:57 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.90 on epoch=544
06/01/2022 04:41:58 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.05 on epoch=547
06/01/2022 04:41:59 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.91 on epoch=549
06/01/2022 04:42:00 - INFO - __main__ - Global step 2200 Train loss 0.97 Classification-F1 0.09493670886075949 on epoch=549
06/01/2022 04:42:01 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.02 on epoch=552
06/01/2022 04:42:02 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.87 on epoch=554
06/01/2022 04:42:04 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.98 on epoch=557
06/01/2022 04:42:05 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.06 on epoch=559
06/01/2022 04:42:06 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.97 on epoch=562
06/01/2022 04:42:07 - INFO - __main__ - Global step 2250 Train loss 0.98 Classification-F1 0.1782212885154062 on epoch=562
06/01/2022 04:42:08 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.03 on epoch=564
06/01/2022 04:42:09 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.95 on epoch=567
06/01/2022 04:42:11 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.01 on epoch=569
06/01/2022 04:42:12 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.05 on epoch=572
06/01/2022 04:42:13 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.89 on epoch=574
06/01/2022 04:42:14 - INFO - __main__ - Global step 2300 Train loss 0.99 Classification-F1 0.1 on epoch=574
06/01/2022 04:42:15 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.01 on epoch=577
06/01/2022 04:42:16 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.02 on epoch=579
06/01/2022 04:42:18 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.99 on epoch=582
06/01/2022 04:42:19 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.90 on epoch=584
06/01/2022 04:42:20 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.86 on epoch=587
06/01/2022 04:42:21 - INFO - __main__ - Global step 2350 Train loss 0.96 Classification-F1 0.1332923832923833 on epoch=587
06/01/2022 04:42:22 - INFO - __main__ - Step 2360 Global step 2360 Train loss 1.03 on epoch=589
06/01/2022 04:42:23 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.99 on epoch=592
06/01/2022 04:42:25 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.92 on epoch=594
06/01/2022 04:42:26 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.95 on epoch=597
06/01/2022 04:42:27 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.96 on epoch=599
06/01/2022 04:42:28 - INFO - __main__ - Global step 2400 Train loss 0.97 Classification-F1 0.20833333333333331 on epoch=599
06/01/2022 04:42:29 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.00 on epoch=602
06/01/2022 04:42:30 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.97 on epoch=604
06/01/2022 04:42:31 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.93 on epoch=607
06/01/2022 04:42:33 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.97 on epoch=609
06/01/2022 04:42:34 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.90 on epoch=612
06/01/2022 04:42:35 - INFO - __main__ - Global step 2450 Train loss 0.96 Classification-F1 0.1672879776328052 on epoch=612
06/01/2022 04:42:36 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.95 on epoch=614
06/01/2022 04:42:37 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.01 on epoch=617
06/01/2022 04:42:38 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.00 on epoch=619
06/01/2022 04:42:40 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.93 on epoch=622
06/01/2022 04:42:41 - INFO - __main__ - Step 2500 Global step 2500 Train loss 1.02 on epoch=624
06/01/2022 04:42:41 - INFO - __main__ - Global step 2500 Train loss 0.98 Classification-F1 0.12407862407862408 on epoch=624
06/01/2022 04:42:43 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.85 on epoch=627
06/01/2022 04:42:44 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.93 on epoch=629
06/01/2022 04:42:45 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.01 on epoch=632
06/01/2022 04:42:47 - INFO - __main__ - Step 2540 Global step 2540 Train loss 1.02 on epoch=634
06/01/2022 04:42:48 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.98 on epoch=637
06/01/2022 04:42:48 - INFO - __main__ - Global step 2550 Train loss 0.96 Classification-F1 0.09333333333333334 on epoch=637
06/01/2022 04:42:50 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.95 on epoch=639
06/01/2022 04:42:51 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.97 on epoch=642
06/01/2022 04:42:52 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.98 on epoch=644
06/01/2022 04:42:53 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.03 on epoch=647
06/01/2022 04:42:55 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.91 on epoch=649
06/01/2022 04:42:55 - INFO - __main__ - Global step 2600 Train loss 0.97 Classification-F1 0.20980302336234538 on epoch=649
06/01/2022 04:42:57 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.87 on epoch=652
06/01/2022 04:42:58 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.93 on epoch=654
06/01/2022 04:42:59 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.95 on epoch=657
06/01/2022 04:43:00 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.96 on epoch=659
06/01/2022 04:43:02 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.97 on epoch=662
06/01/2022 04:43:02 - INFO - __main__ - Global step 2650 Train loss 0.94 Classification-F1 0.18064516129032257 on epoch=662
06/01/2022 04:43:04 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.90 on epoch=664
06/01/2022 04:43:05 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.88 on epoch=667
06/01/2022 04:43:06 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.91 on epoch=669
06/01/2022 04:43:07 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.99 on epoch=672
06/01/2022 04:43:09 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.99 on epoch=674
06/01/2022 04:43:09 - INFO - __main__ - Global step 2700 Train loss 0.94 Classification-F1 0.21515151515151515 on epoch=674
06/01/2022 04:43:10 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.98 on epoch=677
06/01/2022 04:43:12 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.90 on epoch=679
06/01/2022 04:43:13 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.93 on epoch=682
06/01/2022 04:43:14 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.94 on epoch=684
06/01/2022 04:43:16 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.96 on epoch=687
06/01/2022 04:43:16 - INFO - __main__ - Global step 2750 Train loss 0.94 Classification-F1 0.22675217590471825 on epoch=687
06/01/2022 04:43:17 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.93 on epoch=689
06/01/2022 04:43:19 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.94 on epoch=692
06/01/2022 04:43:20 - INFO - __main__ - Step 2780 Global step 2780 Train loss 1.00 on epoch=694
06/01/2022 04:43:21 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.96 on epoch=697
06/01/2022 04:43:23 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.97 on epoch=699
06/01/2022 04:43:23 - INFO - __main__ - Global step 2800 Train loss 0.96 Classification-F1 0.17831215970961886 on epoch=699
06/01/2022 04:43:24 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.87 on epoch=702
06/01/2022 04:43:26 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.94 on epoch=704
06/01/2022 04:43:27 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.92 on epoch=707
06/01/2022 04:43:28 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.93 on epoch=709
06/01/2022 04:43:30 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.96 on epoch=712
06/01/2022 04:43:30 - INFO - __main__ - Global step 2850 Train loss 0.92 Classification-F1 0.18064516129032257 on epoch=712
06/01/2022 04:43:31 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.92 on epoch=714
06/01/2022 04:43:33 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.88 on epoch=717
06/01/2022 04:43:34 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.87 on epoch=719
06/01/2022 04:43:35 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.94 on epoch=722
06/01/2022 04:43:37 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.93 on epoch=724
06/01/2022 04:43:37 - INFO - __main__ - Global step 2900 Train loss 0.91 Classification-F1 0.09027777777777778 on epoch=724
06/01/2022 04:43:38 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.88 on epoch=727
06/01/2022 04:43:40 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.79 on epoch=729
06/01/2022 04:43:41 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.95 on epoch=732
06/01/2022 04:43:42 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.91 on epoch=734
06/01/2022 04:43:44 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.95 on epoch=737
06/01/2022 04:43:44 - INFO - __main__ - Global step 2950 Train loss 0.89 Classification-F1 0.1796875 on epoch=737
06/01/2022 04:43:45 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.91 on epoch=739
06/01/2022 04:43:47 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.85 on epoch=742
06/01/2022 04:43:48 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.96 on epoch=744
06/01/2022 04:43:49 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.90 on epoch=747
06/01/2022 04:43:50 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.93 on epoch=749
06/01/2022 04:43:51 - INFO - __main__ - Global step 3000 Train loss 0.91 Classification-F1 0.08783783783783784 on epoch=749
06/01/2022 04:43:51 - INFO - __main__ - save last model!
06/01/2022 04:43:51 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/01/2022 04:43:51 - INFO - __main__ - Start tokenizing ... 5509 instances
06/01/2022 04:43:51 - INFO - __main__ - Printing 3 examples
06/01/2022 04:43:51 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/01/2022 04:43:51 - INFO - __main__ - ['others']
06/01/2022 04:43:51 - INFO - __main__ -  [emo] what you like very little things ok
06/01/2022 04:43:51 - INFO - __main__ - ['others']
06/01/2022 04:43:51 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/01/2022 04:43:51 - INFO - __main__ - ['others']
06/01/2022 04:43:51 - INFO - __main__ - Tokenizing Input ...
06/01/2022 04:43:51 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 04:43:51 - INFO - __main__ - Printing 3 examples
06/01/2022 04:43:51 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/01/2022 04:43:51 - INFO - __main__ - ['others']
06/01/2022 04:43:51 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/01/2022 04:43:51 - INFO - __main__ - ['others']
06/01/2022 04:43:51 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/01/2022 04:43:51 - INFO - __main__ - ['others']
06/01/2022 04:43:51 - INFO - __main__ - Tokenizing Input ...
06/01/2022 04:43:52 - INFO - __main__ - Tokenizing Output ...
06/01/2022 04:43:52 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 04:43:52 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 04:43:52 - INFO - __main__ - Printing 3 examples
06/01/2022 04:43:52 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
06/01/2022 04:43:52 - INFO - __main__ - ['others']
06/01/2022 04:43:52 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
06/01/2022 04:43:52 - INFO - __main__ - ['others']
06/01/2022 04:43:52 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
06/01/2022 04:43:52 - INFO - __main__ - ['others']
06/01/2022 04:43:52 - INFO - __main__ - Tokenizing Input ...
06/01/2022 04:43:52 - INFO - __main__ - Tokenizing Output ...
06/01/2022 04:43:52 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 04:43:53 - INFO - __main__ - Tokenizing Output ...
06/01/2022 04:43:57 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 04:43:58 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/01/2022 04:43:58 - INFO - __main__ - Starting training!
06/01/2022 04:43:59 - INFO - __main__ - Loaded 5509 examples from test data
06/01/2022 04:44:42 - INFO - __main__ - Saved prediction in models/T5-base-reptile-cls2cls-3e-5-2-5000-5e-1-10/singletask-emo/emo_16_87_0.5_8_predictions.txt
06/01/2022 04:44:42 - INFO - __main__ - Classification-F1 on test data: 0.0487
06/01/2022 04:44:42 - INFO - __main__ - prefix=emo_16_87, lr=0.5, bsz=8, dev_performance=0.2269119769119769, test_performance=0.04873826093346512
06/01/2022 04:44:42 - INFO - __main__ - Running ... prefix=emo_16_87, lr=0.4, bsz=8 ...
06/01/2022 04:44:43 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 04:44:43 - INFO - __main__ - Printing 3 examples
06/01/2022 04:44:43 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/01/2022 04:44:43 - INFO - __main__ - ['others']
06/01/2022 04:44:43 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/01/2022 04:44:43 - INFO - __main__ - ['others']
06/01/2022 04:44:43 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/01/2022 04:44:43 - INFO - __main__ - ['others']
06/01/2022 04:44:43 - INFO - __main__ - Tokenizing Input ...
06/01/2022 04:44:43 - INFO - __main__ - Tokenizing Output ...
06/01/2022 04:44:43 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 04:44:43 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 04:44:43 - INFO - __main__ - Printing 3 examples
06/01/2022 04:44:43 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
06/01/2022 04:44:43 - INFO - __main__ - ['others']
06/01/2022 04:44:43 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
06/01/2022 04:44:43 - INFO - __main__ - ['others']
06/01/2022 04:44:43 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
06/01/2022 04:44:43 - INFO - __main__ - ['others']
06/01/2022 04:44:43 - INFO - __main__ - Tokenizing Input ...
06/01/2022 04:44:43 - INFO - __main__ - Tokenizing Output ...
06/01/2022 04:44:43 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 04:44:49 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 04:44:49 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/01/2022 04:44:49 - INFO - __main__ - Starting training!
06/01/2022 04:44:51 - INFO - __main__ - Step 10 Global step 10 Train loss 9.10 on epoch=2
06/01/2022 04:44:52 - INFO - __main__ - Step 20 Global step 20 Train loss 8.90 on epoch=4
06/01/2022 04:44:53 - INFO - __main__ - Step 30 Global step 30 Train loss 8.92 on epoch=7
06/01/2022 04:44:55 - INFO - __main__ - Step 40 Global step 40 Train loss 8.78 on epoch=9
06/01/2022 04:44:56 - INFO - __main__ - Step 50 Global step 50 Train loss 8.72 on epoch=12
06/01/2022 04:45:06 - INFO - __main__ - Global step 50 Train loss 8.88 Classification-F1 0.0 on epoch=12
06/01/2022 04:45:06 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
06/01/2022 04:45:07 - INFO - __main__ - Step 60 Global step 60 Train loss 8.70 on epoch=14
06/01/2022 04:45:08 - INFO - __main__ - Step 70 Global step 70 Train loss 8.62 on epoch=17
06/01/2022 04:45:10 - INFO - __main__ - Step 80 Global step 80 Train loss 8.46 on epoch=19
06/01/2022 04:45:11 - INFO - __main__ - Step 90 Global step 90 Train loss 8.42 on epoch=22
06/01/2022 04:45:12 - INFO - __main__ - Step 100 Global step 100 Train loss 8.34 on epoch=24
06/01/2022 04:45:27 - INFO - __main__ - Global step 100 Train loss 8.51 Classification-F1 0.0 on epoch=24
06/01/2022 04:45:28 - INFO - __main__ - Step 110 Global step 110 Train loss 8.27 on epoch=27
06/01/2022 04:45:30 - INFO - __main__ - Step 120 Global step 120 Train loss 8.25 on epoch=29
06/01/2022 04:45:31 - INFO - __main__ - Step 130 Global step 130 Train loss 8.07 on epoch=32
06/01/2022 04:45:32 - INFO - __main__ - Step 140 Global step 140 Train loss 7.97 on epoch=34
06/01/2022 04:45:33 - INFO - __main__ - Step 150 Global step 150 Train loss 7.97 on epoch=37
06/01/2022 04:45:50 - INFO - __main__ - Global step 150 Train loss 8.10 Classification-F1 0.0 on epoch=37
06/01/2022 04:45:51 - INFO - __main__ - Step 160 Global step 160 Train loss 7.68 on epoch=39
06/01/2022 04:45:53 - INFO - __main__ - Step 170 Global step 170 Train loss 7.57 on epoch=42
06/01/2022 04:45:54 - INFO - __main__ - Step 180 Global step 180 Train loss 7.50 on epoch=44
06/01/2022 04:45:55 - INFO - __main__ - Step 190 Global step 190 Train loss 7.35 on epoch=47
06/01/2022 04:45:56 - INFO - __main__ - Step 200 Global step 200 Train loss 7.09 on epoch=49
06/01/2022 04:46:05 - INFO - __main__ - Global step 200 Train loss 7.44 Classification-F1 0.0 on epoch=49
06/01/2022 04:46:06 - INFO - __main__ - Step 210 Global step 210 Train loss 6.81 on epoch=52
06/01/2022 04:46:07 - INFO - __main__ - Step 220 Global step 220 Train loss 6.83 on epoch=54
06/01/2022 04:46:09 - INFO - __main__ - Step 230 Global step 230 Train loss 6.69 on epoch=57
06/01/2022 04:46:10 - INFO - __main__ - Step 240 Global step 240 Train loss 6.39 on epoch=59
06/01/2022 04:46:11 - INFO - __main__ - Step 250 Global step 250 Train loss 6.51 on epoch=62
06/01/2022 04:46:13 - INFO - __main__ - Global step 250 Train loss 6.65 Classification-F1 0.0 on epoch=62
06/01/2022 04:46:14 - INFO - __main__ - Step 260 Global step 260 Train loss 6.22 on epoch=64
06/01/2022 04:46:15 - INFO - __main__ - Step 270 Global step 270 Train loss 6.10 on epoch=67
06/01/2022 04:46:17 - INFO - __main__ - Step 280 Global step 280 Train loss 6.01 on epoch=69
06/01/2022 04:46:18 - INFO - __main__ - Step 290 Global step 290 Train loss 5.79 on epoch=72
06/01/2022 04:46:19 - INFO - __main__ - Step 300 Global step 300 Train loss 5.54 on epoch=74
06/01/2022 04:46:26 - INFO - __main__ - Global step 300 Train loss 5.93 Classification-F1 0.0 on epoch=74
06/01/2022 04:46:27 - INFO - __main__ - Step 310 Global step 310 Train loss 5.57 on epoch=77
06/01/2022 04:46:28 - INFO - __main__ - Step 320 Global step 320 Train loss 5.37 on epoch=79
06/01/2022 04:46:29 - INFO - __main__ - Step 330 Global step 330 Train loss 5.25 on epoch=82
06/01/2022 04:46:31 - INFO - __main__ - Step 340 Global step 340 Train loss 5.20 on epoch=84
06/01/2022 04:46:32 - INFO - __main__ - Step 350 Global step 350 Train loss 5.15 on epoch=87
06/01/2022 04:46:35 - INFO - __main__ - Global step 350 Train loss 5.31 Classification-F1 0.0 on epoch=87
06/01/2022 04:46:37 - INFO - __main__ - Step 360 Global step 360 Train loss 4.89 on epoch=89
06/01/2022 04:46:38 - INFO - __main__ - Step 370 Global step 370 Train loss 4.86 on epoch=92
06/01/2022 04:46:39 - INFO - __main__ - Step 380 Global step 380 Train loss 4.66 on epoch=94
06/01/2022 04:46:40 - INFO - __main__ - Step 390 Global step 390 Train loss 4.64 on epoch=97
06/01/2022 04:46:42 - INFO - __main__ - Step 400 Global step 400 Train loss 4.38 on epoch=99
06/01/2022 04:46:47 - INFO - __main__ - Global step 400 Train loss 4.69 Classification-F1 0.0 on epoch=99
06/01/2022 04:46:48 - INFO - __main__ - Step 410 Global step 410 Train loss 4.30 on epoch=102
06/01/2022 04:46:49 - INFO - __main__ - Step 420 Global step 420 Train loss 4.24 on epoch=104
06/01/2022 04:46:51 - INFO - __main__ - Step 430 Global step 430 Train loss 4.39 on epoch=107
06/01/2022 04:46:52 - INFO - __main__ - Step 440 Global step 440 Train loss 4.08 on epoch=109
06/01/2022 04:46:53 - INFO - __main__ - Step 450 Global step 450 Train loss 4.06 on epoch=112
06/01/2022 04:46:57 - INFO - __main__ - Global step 450 Train loss 4.21 Classification-F1 0.0 on epoch=112
06/01/2022 04:46:59 - INFO - __main__ - Step 460 Global step 460 Train loss 3.78 on epoch=114
06/01/2022 04:47:00 - INFO - __main__ - Step 470 Global step 470 Train loss 3.88 on epoch=117
06/01/2022 04:47:01 - INFO - __main__ - Step 480 Global step 480 Train loss 3.76 on epoch=119
06/01/2022 04:47:02 - INFO - __main__ - Step 490 Global step 490 Train loss 3.74 on epoch=122
06/01/2022 04:47:04 - INFO - __main__ - Step 500 Global step 500 Train loss 3.62 on epoch=124
06/01/2022 04:47:05 - INFO - __main__ - Global step 500 Train loss 3.75 Classification-F1 0.05847953216374269 on epoch=124
06/01/2022 04:47:05 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.05847953216374269 on epoch=124, global_step=500
06/01/2022 04:47:06 - INFO - __main__ - Step 510 Global step 510 Train loss 3.69 on epoch=127
06/01/2022 04:47:07 - INFO - __main__ - Step 520 Global step 520 Train loss 3.67 on epoch=129
06/01/2022 04:47:09 - INFO - __main__ - Step 530 Global step 530 Train loss 3.61 on epoch=132
06/01/2022 04:47:10 - INFO - __main__ - Step 540 Global step 540 Train loss 3.25 on epoch=134
06/01/2022 04:47:11 - INFO - __main__ - Step 550 Global step 550 Train loss 3.41 on epoch=137
06/01/2022 04:47:16 - INFO - __main__ - Global step 550 Train loss 3.52 Classification-F1 0.21061869240895126 on epoch=137
06/01/2022 04:47:16 - INFO - __main__ - Saving model with best Classification-F1: 0.05847953216374269 -> 0.21061869240895126 on epoch=137, global_step=550
06/01/2022 04:47:17 - INFO - __main__ - Step 560 Global step 560 Train loss 3.26 on epoch=139
06/01/2022 04:47:18 - INFO - __main__ - Step 570 Global step 570 Train loss 3.31 on epoch=142
06/01/2022 04:47:19 - INFO - __main__ - Step 580 Global step 580 Train loss 3.07 on epoch=144
06/01/2022 04:47:21 - INFO - __main__ - Step 590 Global step 590 Train loss 3.20 on epoch=147
06/01/2022 04:47:22 - INFO - __main__ - Step 600 Global step 600 Train loss 2.91 on epoch=149
06/01/2022 04:47:24 - INFO - __main__ - Global step 600 Train loss 3.15 Classification-F1 0.10530934620447563 on epoch=149
06/01/2022 04:47:25 - INFO - __main__ - Step 610 Global step 610 Train loss 3.17 on epoch=152
06/01/2022 04:47:26 - INFO - __main__ - Step 620 Global step 620 Train loss 2.98 on epoch=154
06/01/2022 04:47:27 - INFO - __main__ - Step 630 Global step 630 Train loss 3.06 on epoch=157
06/01/2022 04:47:28 - INFO - __main__ - Step 640 Global step 640 Train loss 3.02 on epoch=159
06/01/2022 04:47:30 - INFO - __main__ - Step 650 Global step 650 Train loss 2.99 on epoch=162
06/01/2022 04:47:32 - INFO - __main__ - Global step 650 Train loss 3.05 Classification-F1 0.19999999999999998 on epoch=162
06/01/2022 04:47:33 - INFO - __main__ - Step 660 Global step 660 Train loss 2.63 on epoch=164
06/01/2022 04:47:34 - INFO - __main__ - Step 670 Global step 670 Train loss 2.87 on epoch=167
06/01/2022 04:47:35 - INFO - __main__ - Step 680 Global step 680 Train loss 2.61 on epoch=169
06/01/2022 04:47:37 - INFO - __main__ - Step 690 Global step 690 Train loss 2.72 on epoch=172
06/01/2022 04:47:38 - INFO - __main__ - Step 700 Global step 700 Train loss 2.62 on epoch=174
06/01/2022 04:47:38 - INFO - __main__ - Global step 700 Train loss 2.69 Classification-F1 0.14546244029526703 on epoch=174
06/01/2022 04:47:40 - INFO - __main__ - Step 710 Global step 710 Train loss 2.61 on epoch=177
06/01/2022 04:47:41 - INFO - __main__ - Step 720 Global step 720 Train loss 2.48 on epoch=179
06/01/2022 04:47:42 - INFO - __main__ - Step 730 Global step 730 Train loss 2.63 on epoch=182
06/01/2022 04:47:43 - INFO - __main__ - Step 740 Global step 740 Train loss 2.35 on epoch=184
06/01/2022 04:47:44 - INFO - __main__ - Step 750 Global step 750 Train loss 2.60 on epoch=187
06/01/2022 04:47:45 - INFO - __main__ - Global step 750 Train loss 2.53 Classification-F1 0.12403499742665978 on epoch=187
06/01/2022 04:47:46 - INFO - __main__ - Step 760 Global step 760 Train loss 2.35 on epoch=189
06/01/2022 04:47:48 - INFO - __main__ - Step 770 Global step 770 Train loss 2.35 on epoch=192
06/01/2022 04:47:49 - INFO - __main__ - Step 780 Global step 780 Train loss 2.38 on epoch=194
06/01/2022 04:47:50 - INFO - __main__ - Step 790 Global step 790 Train loss 2.29 on epoch=197
06/01/2022 04:47:51 - INFO - __main__ - Step 800 Global step 800 Train loss 2.15 on epoch=199
06/01/2022 04:47:52 - INFO - __main__ - Global step 800 Train loss 2.30 Classification-F1 0.20784313725490197 on epoch=199
06/01/2022 04:47:53 - INFO - __main__ - Step 810 Global step 810 Train loss 2.17 on epoch=202
06/01/2022 04:47:54 - INFO - __main__ - Step 820 Global step 820 Train loss 2.14 on epoch=204
06/01/2022 04:47:56 - INFO - __main__ - Step 830 Global step 830 Train loss 1.90 on epoch=207
06/01/2022 04:47:57 - INFO - __main__ - Step 840 Global step 840 Train loss 1.98 on epoch=209
06/01/2022 04:47:58 - INFO - __main__ - Step 850 Global step 850 Train loss 2.00 on epoch=212
06/01/2022 04:47:59 - INFO - __main__ - Global step 850 Train loss 2.04 Classification-F1 0.10256410256410256 on epoch=212
06/01/2022 04:48:00 - INFO - __main__ - Step 860 Global step 860 Train loss 1.93 on epoch=214
06/01/2022 04:48:01 - INFO - __main__ - Step 870 Global step 870 Train loss 2.03 on epoch=217
06/01/2022 04:48:03 - INFO - __main__ - Step 880 Global step 880 Train loss 1.99 on epoch=219
06/01/2022 04:48:04 - INFO - __main__ - Step 890 Global step 890 Train loss 1.93 on epoch=222
06/01/2022 04:48:05 - INFO - __main__ - Step 900 Global step 900 Train loss 1.89 on epoch=224
06/01/2022 04:48:06 - INFO - __main__ - Global step 900 Train loss 1.95 Classification-F1 0.1 on epoch=224
06/01/2022 04:48:07 - INFO - __main__ - Step 910 Global step 910 Train loss 1.87 on epoch=227
06/01/2022 04:48:08 - INFO - __main__ - Step 920 Global step 920 Train loss 1.68 on epoch=229
06/01/2022 04:48:09 - INFO - __main__ - Step 930 Global step 930 Train loss 1.84 on epoch=232
06/01/2022 04:48:11 - INFO - __main__ - Step 940 Global step 940 Train loss 1.69 on epoch=234
06/01/2022 04:48:12 - INFO - __main__ - Step 950 Global step 950 Train loss 1.91 on epoch=237
06/01/2022 04:48:12 - INFO - __main__ - Global step 950 Train loss 1.80 Classification-F1 0.10389610389610389 on epoch=237
06/01/2022 04:48:14 - INFO - __main__ - Step 960 Global step 960 Train loss 1.80 on epoch=239
06/01/2022 04:48:15 - INFO - __main__ - Step 970 Global step 970 Train loss 1.80 on epoch=242
06/01/2022 04:48:16 - INFO - __main__ - Step 980 Global step 980 Train loss 1.78 on epoch=244
06/01/2022 04:48:17 - INFO - __main__ - Step 990 Global step 990 Train loss 1.73 on epoch=247
06/01/2022 04:48:19 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.59 on epoch=249
06/01/2022 04:48:19 - INFO - __main__ - Global step 1000 Train loss 1.74 Classification-F1 0.1 on epoch=249
06/01/2022 04:48:20 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.62 on epoch=252
06/01/2022 04:48:22 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.45 on epoch=254
06/01/2022 04:48:23 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.52 on epoch=257
06/01/2022 04:48:24 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.57 on epoch=259
06/01/2022 04:48:25 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.70 on epoch=262
06/01/2022 04:48:26 - INFO - __main__ - Global step 1050 Train loss 1.57 Classification-F1 0.14848484848484847 on epoch=262
06/01/2022 04:48:27 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.60 on epoch=264
06/01/2022 04:48:28 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.52 on epoch=267
06/01/2022 04:48:29 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.60 on epoch=269
06/01/2022 04:48:31 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.46 on epoch=272
06/01/2022 04:48:32 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.50 on epoch=274
06/01/2022 04:48:33 - INFO - __main__ - Global step 1100 Train loss 1.53 Classification-F1 0.20445344129554657 on epoch=274
06/01/2022 04:48:34 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.36 on epoch=277
06/01/2022 04:48:35 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.44 on epoch=279
06/01/2022 04:48:36 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.39 on epoch=282
06/01/2022 04:48:38 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.31 on epoch=284
06/01/2022 04:48:39 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.39 on epoch=287
06/01/2022 04:48:39 - INFO - __main__ - Global step 1150 Train loss 1.38 Classification-F1 0.11687344913151365 on epoch=287
06/01/2022 04:48:41 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.32 on epoch=289
06/01/2022 04:48:42 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.39 on epoch=292
06/01/2022 04:48:43 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.35 on epoch=294
06/01/2022 04:48:44 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.37 on epoch=297
06/01/2022 04:48:46 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.33 on epoch=299
06/01/2022 04:48:46 - INFO - __main__ - Global step 1200 Train loss 1.35 Classification-F1 0.17344312918167784 on epoch=299
06/01/2022 04:48:47 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.41 on epoch=302
06/01/2022 04:48:48 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.19 on epoch=304
06/01/2022 04:48:50 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.33 on epoch=307
06/01/2022 04:48:51 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.37 on epoch=309
06/01/2022 04:48:52 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.44 on epoch=312
06/01/2022 04:48:53 - INFO - __main__ - Global step 1250 Train loss 1.35 Classification-F1 0.1302118933697881 on epoch=312
06/01/2022 04:48:54 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.30 on epoch=314
06/01/2022 04:48:55 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.26 on epoch=317
06/01/2022 04:48:56 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.23 on epoch=319
06/01/2022 04:48:58 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.20 on epoch=322
06/01/2022 04:48:59 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.28 on epoch=324
06/01/2022 04:48:59 - INFO - __main__ - Global step 1300 Train loss 1.25 Classification-F1 0.21256038647342995 on epoch=324
06/01/2022 04:48:59 - INFO - __main__ - Saving model with best Classification-F1: 0.21061869240895126 -> 0.21256038647342995 on epoch=324, global_step=1300
06/01/2022 04:49:01 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.35 on epoch=327
06/01/2022 04:49:02 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.20 on epoch=329
06/01/2022 04:49:03 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.06 on epoch=332
06/01/2022 04:49:04 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.17 on epoch=334
06/01/2022 04:49:06 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.27 on epoch=337
06/01/2022 04:49:06 - INFO - __main__ - Global step 1350 Train loss 1.21 Classification-F1 0.09999999999999999 on epoch=337
06/01/2022 04:49:07 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.06 on epoch=339
06/01/2022 04:49:09 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.29 on epoch=342
06/01/2022 04:49:10 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.07 on epoch=344
06/01/2022 04:49:11 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.14 on epoch=347
06/01/2022 04:49:12 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.20 on epoch=349
06/01/2022 04:49:13 - INFO - __main__ - Global step 1400 Train loss 1.15 Classification-F1 0.1302118933697881 on epoch=349
06/01/2022 04:49:14 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.27 on epoch=352
06/01/2022 04:49:15 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.04 on epoch=354
06/01/2022 04:49:17 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.12 on epoch=357
06/01/2022 04:49:18 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.22 on epoch=359
06/01/2022 04:49:19 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.21 on epoch=362
06/01/2022 04:49:20 - INFO - __main__ - Global step 1450 Train loss 1.17 Classification-F1 0.16110780226325194 on epoch=362
06/01/2022 04:49:21 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.18 on epoch=364
06/01/2022 04:49:22 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.18 on epoch=367
06/01/2022 04:49:23 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.22 on epoch=369
06/01/2022 04:49:24 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.17 on epoch=372
06/01/2022 04:49:26 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.15 on epoch=374
06/01/2022 04:49:26 - INFO - __main__ - Global step 1500 Train loss 1.18 Classification-F1 0.12393162393162392 on epoch=374
06/01/2022 04:49:27 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.15 on epoch=377
06/01/2022 04:49:29 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.17 on epoch=379
06/01/2022 04:49:30 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.05 on epoch=382
06/01/2022 04:49:31 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.15 on epoch=384
06/01/2022 04:49:32 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.12 on epoch=387
06/01/2022 04:49:33 - INFO - __main__ - Global step 1550 Train loss 1.13 Classification-F1 0.15728715728715728 on epoch=387
06/01/2022 04:49:34 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.09 on epoch=389
06/01/2022 04:49:35 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.12 on epoch=392
06/01/2022 04:49:37 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.13 on epoch=394
06/01/2022 04:49:38 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.11 on epoch=397
06/01/2022 04:49:39 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.12 on epoch=399
06/01/2022 04:49:40 - INFO - __main__ - Global step 1600 Train loss 1.11 Classification-F1 0.1542857142857143 on epoch=399
06/01/2022 04:49:41 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.16 on epoch=402
06/01/2022 04:49:42 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.15 on epoch=404
06/01/2022 04:49:43 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.03 on epoch=407
06/01/2022 04:49:45 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.02 on epoch=409
06/01/2022 04:49:46 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.10 on epoch=412
06/01/2022 04:49:46 - INFO - __main__ - Global step 1650 Train loss 1.09 Classification-F1 0.13067758749069247 on epoch=412
06/01/2022 04:49:48 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.17 on epoch=414
06/01/2022 04:49:49 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.06 on epoch=417
06/01/2022 04:49:50 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.11 on epoch=419
06/01/2022 04:49:51 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.08 on epoch=422
06/01/2022 04:49:53 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.22 on epoch=424
06/01/2022 04:49:53 - INFO - __main__ - Global step 1700 Train loss 1.13 Classification-F1 0.1457326892109501 on epoch=424
06/01/2022 04:49:54 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.15 on epoch=427
06/01/2022 04:49:55 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.09 on epoch=429
06/01/2022 04:49:57 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.13 on epoch=432
06/01/2022 04:49:58 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.08 on epoch=434
06/01/2022 04:49:59 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.04 on epoch=437
06/01/2022 04:50:00 - INFO - __main__ - Global step 1750 Train loss 1.10 Classification-F1 0.1581196581196581 on epoch=437
06/01/2022 04:50:01 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.01 on epoch=439
06/01/2022 04:50:02 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.16 on epoch=442
06/01/2022 04:50:03 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.08 on epoch=444
06/01/2022 04:50:05 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.16 on epoch=447
06/01/2022 04:50:06 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.06 on epoch=449
06/01/2022 04:50:06 - INFO - __main__ - Global step 1800 Train loss 1.09 Classification-F1 0.1581196581196581 on epoch=449
06/01/2022 04:50:08 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.05 on epoch=452
06/01/2022 04:50:09 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.22 on epoch=454
06/01/2022 04:50:10 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.10 on epoch=457
06/01/2022 04:50:11 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.04 on epoch=459
06/01/2022 04:50:13 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.05 on epoch=462
06/01/2022 04:50:13 - INFO - __main__ - Global step 1850 Train loss 1.09 Classification-F1 0.13034188034188032 on epoch=462
06/01/2022 04:50:14 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.15 on epoch=464
06/01/2022 04:50:16 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.99 on epoch=467
06/01/2022 04:50:17 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.97 on epoch=469
06/01/2022 04:50:18 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.04 on epoch=472
06/01/2022 04:50:19 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.11 on epoch=474
06/01/2022 04:50:20 - INFO - __main__ - Global step 1900 Train loss 1.05 Classification-F1 0.19068450849202268 on epoch=474
06/01/2022 04:50:21 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.03 on epoch=477
06/01/2022 04:50:22 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.12 on epoch=479
06/01/2022 04:50:23 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.09 on epoch=482
06/01/2022 04:50:25 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.08 on epoch=484
06/01/2022 04:50:26 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.06 on epoch=487
06/01/2022 04:50:26 - INFO - __main__ - Global step 1950 Train loss 1.08 Classification-F1 0.1739766081871345 on epoch=487
06/01/2022 04:50:28 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.09 on epoch=489
06/01/2022 04:50:29 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.16 on epoch=492
06/01/2022 04:50:30 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.04 on epoch=494
06/01/2022 04:50:31 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.04 on epoch=497
06/01/2022 04:50:33 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.03 on epoch=499
06/01/2022 04:50:33 - INFO - __main__ - Global step 2000 Train loss 1.07 Classification-F1 0.1281512605042017 on epoch=499
06/01/2022 04:50:34 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.01 on epoch=502
06/01/2022 04:50:36 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.98 on epoch=504
06/01/2022 04:50:37 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.04 on epoch=507
06/01/2022 04:50:38 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.05 on epoch=509
06/01/2022 04:50:39 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.02 on epoch=512
06/01/2022 04:50:40 - INFO - __main__ - Global step 2050 Train loss 1.02 Classification-F1 0.13166666666666668 on epoch=512
06/01/2022 04:50:41 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.02 on epoch=514
06/01/2022 04:50:42 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.11 on epoch=517
06/01/2022 04:50:44 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.99 on epoch=519
06/01/2022 04:50:45 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.11 on epoch=522
06/01/2022 04:50:46 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.10 on epoch=524
06/01/2022 04:50:47 - INFO - __main__ - Global step 2100 Train loss 1.06 Classification-F1 0.16078790655061842 on epoch=524
06/01/2022 04:50:48 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.11 on epoch=527
06/01/2022 04:50:49 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.03 on epoch=529
06/01/2022 04:50:50 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.07 on epoch=532
06/01/2022 04:50:52 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.06 on epoch=534
06/01/2022 04:50:53 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.01 on epoch=537
06/01/2022 04:50:53 - INFO - __main__ - Global step 2150 Train loss 1.06 Classification-F1 0.10314685314685315 on epoch=537
06/01/2022 04:50:55 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.94 on epoch=539
06/01/2022 04:50:56 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.01 on epoch=542
06/01/2022 04:50:57 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.86 on epoch=544
06/01/2022 04:50:58 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.09 on epoch=547
06/01/2022 04:51:00 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.98 on epoch=549
06/01/2022 04:51:00 - INFO - __main__ - Global step 2200 Train loss 0.97 Classification-F1 0.2531512605042017 on epoch=549
06/01/2022 04:51:00 - INFO - __main__ - Saving model with best Classification-F1: 0.21256038647342995 -> 0.2531512605042017 on epoch=549, global_step=2200
06/01/2022 04:51:01 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.96 on epoch=552
06/01/2022 04:51:03 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.94 on epoch=554
06/01/2022 04:51:04 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.88 on epoch=557
06/01/2022 04:51:05 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.06 on epoch=559
06/01/2022 04:51:06 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.04 on epoch=562
06/01/2022 04:51:07 - INFO - __main__ - Global step 2250 Train loss 0.98 Classification-F1 0.13946869070208728 on epoch=562
06/01/2022 04:51:08 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.06 on epoch=564
06/01/2022 04:51:09 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.04 on epoch=567
06/01/2022 04:51:11 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.99 on epoch=569
06/01/2022 04:51:12 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.03 on epoch=572
06/01/2022 04:51:13 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.96 on epoch=574
06/01/2022 04:51:14 - INFO - __main__ - Global step 2300 Train loss 1.01 Classification-F1 0.19226044226044225 on epoch=574
06/01/2022 04:51:15 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.95 on epoch=577
06/01/2022 04:51:16 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.02 on epoch=579
06/01/2022 04:51:17 - INFO - __main__ - Step 2330 Global step 2330 Train loss 1.03 on epoch=582
06/01/2022 04:51:19 - INFO - __main__ - Step 2340 Global step 2340 Train loss 1.03 on epoch=584
06/01/2022 04:51:20 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.07 on epoch=587
06/01/2022 04:51:20 - INFO - __main__ - Global step 2350 Train loss 1.02 Classification-F1 0.1875 on epoch=587
06/01/2022 04:51:22 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.95 on epoch=589
06/01/2022 04:51:23 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.96 on epoch=592
06/01/2022 04:51:24 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.94 on epoch=594
06/01/2022 04:51:25 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.99 on epoch=597
06/01/2022 04:51:26 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.89 on epoch=599
06/01/2022 04:51:27 - INFO - __main__ - Global step 2400 Train loss 0.94 Classification-F1 0.140625 on epoch=599
06/01/2022 04:51:28 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.94 on epoch=602
06/01/2022 04:51:29 - INFO - __main__ - Step 2420 Global step 2420 Train loss 1.02 on epoch=604
06/01/2022 04:51:31 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.00 on epoch=607
06/01/2022 04:51:32 - INFO - __main__ - Step 2440 Global step 2440 Train loss 1.01 on epoch=609
06/01/2022 04:51:33 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.08 on epoch=612
06/01/2022 04:51:34 - INFO - __main__ - Global step 2450 Train loss 1.01 Classification-F1 0.18679950186799504 on epoch=612
06/01/2022 04:51:35 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.96 on epoch=614
06/01/2022 04:51:36 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.89 on epoch=617
06/01/2022 04:51:37 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.05 on epoch=619
06/01/2022 04:51:39 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.07 on epoch=622
06/01/2022 04:51:40 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.89 on epoch=624
06/01/2022 04:51:40 - INFO - __main__ - Global step 2500 Train loss 0.97 Classification-F1 0.1588235294117647 on epoch=624
06/01/2022 04:51:42 - INFO - __main__ - Step 2510 Global step 2510 Train loss 1.04 on epoch=627
06/01/2022 04:51:43 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.94 on epoch=629
06/01/2022 04:51:44 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.93 on epoch=632
06/01/2022 04:51:45 - INFO - __main__ - Step 2540 Global step 2540 Train loss 1.01 on epoch=634
06/01/2022 04:51:47 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.92 on epoch=637
06/01/2022 04:51:47 - INFO - __main__ - Global step 2550 Train loss 0.97 Classification-F1 0.1797385620915033 on epoch=637
06/01/2022 04:51:48 - INFO - __main__ - Step 2560 Global step 2560 Train loss 1.00 on epoch=639
06/01/2022 04:51:50 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.98 on epoch=642
06/01/2022 04:51:51 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.98 on epoch=644
06/01/2022 04:51:52 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.98 on epoch=647
06/01/2022 04:51:53 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.93 on epoch=649
06/01/2022 04:51:54 - INFO - __main__ - Global step 2600 Train loss 0.98 Classification-F1 0.20132844709115894 on epoch=649
06/01/2022 04:51:55 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.97 on epoch=652
06/01/2022 04:51:56 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.94 on epoch=654
06/01/2022 04:51:57 - INFO - __main__ - Step 2630 Global step 2630 Train loss 1.09 on epoch=657
06/01/2022 04:51:59 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.93 on epoch=659
06/01/2022 04:52:00 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.02 on epoch=662
06/01/2022 04:52:00 - INFO - __main__ - Global step 2650 Train loss 0.99 Classification-F1 0.09090909090909091 on epoch=662
06/01/2022 04:52:02 - INFO - __main__ - Step 2660 Global step 2660 Train loss 1.04 on epoch=664
06/01/2022 04:52:03 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.84 on epoch=667
06/01/2022 04:52:04 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.96 on epoch=669
06/01/2022 04:52:05 - INFO - __main__ - Step 2690 Global step 2690 Train loss 1.01 on epoch=672
06/01/2022 04:52:07 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.98 on epoch=674
06/01/2022 04:52:07 - INFO - __main__ - Global step 2700 Train loss 0.97 Classification-F1 0.13021778584392013 on epoch=674
06/01/2022 04:52:08 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.98 on epoch=677
06/01/2022 04:52:10 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.95 on epoch=679
06/01/2022 04:52:11 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.96 on epoch=682
06/01/2022 04:52:12 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.90 on epoch=684
06/01/2022 04:52:13 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.90 on epoch=687
06/01/2022 04:52:14 - INFO - __main__ - Global step 2750 Train loss 0.94 Classification-F1 0.2127949183303085 on epoch=687
06/01/2022 04:52:15 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.86 on epoch=689
06/01/2022 04:52:16 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.92 on epoch=692
06/01/2022 04:52:18 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.90 on epoch=694
06/01/2022 04:52:19 - INFO - __main__ - Step 2790 Global step 2790 Train loss 1.00 on epoch=697
06/01/2022 04:52:20 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.91 on epoch=699
06/01/2022 04:52:21 - INFO - __main__ - Global step 2800 Train loss 0.92 Classification-F1 0.09722222222222222 on epoch=699
06/01/2022 04:52:22 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.98 on epoch=702
06/01/2022 04:52:23 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.86 on epoch=704
06/01/2022 04:52:24 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.91 on epoch=707
06/01/2022 04:52:26 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.86 on epoch=709
06/01/2022 04:52:27 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.94 on epoch=712
06/01/2022 04:52:27 - INFO - __main__ - Global step 2850 Train loss 0.91 Classification-F1 0.10679361811631496 on epoch=712
06/01/2022 04:52:29 - INFO - __main__ - Step 2860 Global step 2860 Train loss 1.03 on epoch=714
06/01/2022 04:52:30 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.99 on epoch=717
06/01/2022 04:52:31 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.87 on epoch=719
06/01/2022 04:52:32 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.95 on epoch=722
06/01/2022 04:52:34 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.03 on epoch=724
06/01/2022 04:52:34 - INFO - __main__ - Global step 2900 Train loss 0.97 Classification-F1 0.0974025974025974 on epoch=724
06/01/2022 04:52:35 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.95 on epoch=727
06/01/2022 04:52:37 - INFO - __main__ - Step 2920 Global step 2920 Train loss 1.00 on epoch=729
06/01/2022 04:52:38 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.89 on epoch=732
06/01/2022 04:52:39 - INFO - __main__ - Step 2940 Global step 2940 Train loss 1.02 on epoch=734
06/01/2022 04:52:40 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.91 on epoch=737
06/01/2022 04:52:41 - INFO - __main__ - Global step 2950 Train loss 0.95 Classification-F1 0.18969624776652771 on epoch=737
06/01/2022 04:52:42 - INFO - __main__ - Step 2960 Global step 2960 Train loss 1.00 on epoch=739
06/01/2022 04:52:43 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.95 on epoch=742
06/01/2022 04:52:45 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.99 on epoch=744
06/01/2022 04:52:46 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.93 on epoch=747
06/01/2022 04:52:47 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.98 on epoch=749
06/01/2022 04:52:48 - INFO - __main__ - Global step 3000 Train loss 0.97 Classification-F1 0.10126582278481013 on epoch=749
06/01/2022 04:52:48 - INFO - __main__ - save last model!
06/01/2022 04:52:48 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/01/2022 04:52:48 - INFO - __main__ - Start tokenizing ... 5509 instances
06/01/2022 04:52:48 - INFO - __main__ - Printing 3 examples
06/01/2022 04:52:48 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/01/2022 04:52:48 - INFO - __main__ - ['others']
06/01/2022 04:52:48 - INFO - __main__ -  [emo] what you like very little things ok
06/01/2022 04:52:48 - INFO - __main__ - ['others']
06/01/2022 04:52:48 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/01/2022 04:52:48 - INFO - __main__ - ['others']
06/01/2022 04:52:48 - INFO - __main__ - Tokenizing Input ...
06/01/2022 04:52:48 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 04:52:48 - INFO - __main__ - Printing 3 examples
06/01/2022 04:52:48 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/01/2022 04:52:48 - INFO - __main__ - ['others']
06/01/2022 04:52:48 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/01/2022 04:52:48 - INFO - __main__ - ['others']
06/01/2022 04:52:48 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/01/2022 04:52:48 - INFO - __main__ - ['others']
06/01/2022 04:52:48 - INFO - __main__ - Tokenizing Input ...
06/01/2022 04:52:48 - INFO - __main__ - Tokenizing Output ...
06/01/2022 04:52:48 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 04:52:48 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 04:52:48 - INFO - __main__ - Printing 3 examples
06/01/2022 04:52:48 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
06/01/2022 04:52:48 - INFO - __main__ - ['others']
06/01/2022 04:52:48 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
06/01/2022 04:52:48 - INFO - __main__ - ['others']
06/01/2022 04:52:48 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
06/01/2022 04:52:48 - INFO - __main__ - ['others']
06/01/2022 04:52:48 - INFO - __main__ - Tokenizing Input ...
06/01/2022 04:52:48 - INFO - __main__ - Tokenizing Output ...
06/01/2022 04:52:48 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 04:52:50 - INFO - __main__ - Tokenizing Output ...
06/01/2022 04:52:54 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 04:52:54 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/01/2022 04:52:54 - INFO - __main__ - Starting training!
06/01/2022 04:52:55 - INFO - __main__ - Loaded 5509 examples from test data
06/01/2022 04:53:39 - INFO - __main__ - Saved prediction in models/T5-base-reptile-cls2cls-3e-5-2-5000-5e-1-10/singletask-emo/emo_16_87_0.4_8_predictions.txt
06/01/2022 04:53:40 - INFO - __main__ - Classification-F1 on test data: 0.0378
06/01/2022 04:53:40 - INFO - __main__ - prefix=emo_16_87, lr=0.4, bsz=8, dev_performance=0.2531512605042017, test_performance=0.0377939158695639
06/01/2022 04:53:40 - INFO - __main__ - Running ... prefix=emo_16_87, lr=0.3, bsz=8 ...
06/01/2022 04:53:41 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 04:53:41 - INFO - __main__ - Printing 3 examples
06/01/2022 04:53:41 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/01/2022 04:53:41 - INFO - __main__ - ['others']
06/01/2022 04:53:41 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/01/2022 04:53:41 - INFO - __main__ - ['others']
06/01/2022 04:53:41 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/01/2022 04:53:41 - INFO - __main__ - ['others']
06/01/2022 04:53:41 - INFO - __main__ - Tokenizing Input ...
06/01/2022 04:53:41 - INFO - __main__ - Tokenizing Output ...
06/01/2022 04:53:41 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 04:53:41 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 04:53:41 - INFO - __main__ - Printing 3 examples
06/01/2022 04:53:41 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
06/01/2022 04:53:41 - INFO - __main__ - ['others']
06/01/2022 04:53:41 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
06/01/2022 04:53:41 - INFO - __main__ - ['others']
06/01/2022 04:53:41 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
06/01/2022 04:53:41 - INFO - __main__ - ['others']
06/01/2022 04:53:41 - INFO - __main__ - Tokenizing Input ...
06/01/2022 04:53:41 - INFO - __main__ - Tokenizing Output ...
06/01/2022 04:53:41 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 04:53:47 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 04:53:47 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/01/2022 04:53:47 - INFO - __main__ - Starting training!
06/01/2022 04:53:48 - INFO - __main__ - Step 10 Global step 10 Train loss 8.85 on epoch=2
06/01/2022 04:53:50 - INFO - __main__ - Step 20 Global step 20 Train loss 8.88 on epoch=4
06/01/2022 04:53:51 - INFO - __main__ - Step 30 Global step 30 Train loss 8.94 on epoch=7
06/01/2022 04:53:52 - INFO - __main__ - Step 40 Global step 40 Train loss 8.88 on epoch=9
06/01/2022 04:53:54 - INFO - __main__ - Step 50 Global step 50 Train loss 8.76 on epoch=12
06/01/2022 04:53:59 - INFO - __main__ - Global step 50 Train loss 8.86 Classification-F1 0.0 on epoch=12
06/01/2022 04:53:59 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
06/01/2022 04:54:00 - INFO - __main__ - Step 60 Global step 60 Train loss 8.82 on epoch=14
06/01/2022 04:54:01 - INFO - __main__ - Step 70 Global step 70 Train loss 8.75 on epoch=17
06/01/2022 04:54:03 - INFO - __main__ - Step 80 Global step 80 Train loss 8.74 on epoch=19
06/01/2022 04:54:04 - INFO - __main__ - Step 90 Global step 90 Train loss 8.70 on epoch=22
06/01/2022 04:54:05 - INFO - __main__ - Step 100 Global step 100 Train loss 8.72 on epoch=24
06/01/2022 04:54:16 - INFO - __main__ - Global step 100 Train loss 8.74 Classification-F1 0.0 on epoch=24
06/01/2022 04:54:18 - INFO - __main__ - Step 110 Global step 110 Train loss 8.62 on epoch=27
06/01/2022 04:54:19 - INFO - __main__ - Step 120 Global step 120 Train loss 8.53 on epoch=29
06/01/2022 04:54:20 - INFO - __main__ - Step 130 Global step 130 Train loss 8.50 on epoch=32
06/01/2022 04:54:22 - INFO - __main__ - Step 140 Global step 140 Train loss 8.54 on epoch=34
06/01/2022 04:54:23 - INFO - __main__ - Step 150 Global step 150 Train loss 8.45 on epoch=37
06/01/2022 04:54:34 - INFO - __main__ - Global step 150 Train loss 8.53 Classification-F1 0.0 on epoch=37
06/01/2022 04:54:36 - INFO - __main__ - Step 160 Global step 160 Train loss 8.45 on epoch=39
06/01/2022 04:54:37 - INFO - __main__ - Step 170 Global step 170 Train loss 8.34 on epoch=42
06/01/2022 04:54:38 - INFO - __main__ - Step 180 Global step 180 Train loss 8.14 on epoch=44
06/01/2022 04:54:39 - INFO - __main__ - Step 190 Global step 190 Train loss 8.21 on epoch=47
06/01/2022 04:54:41 - INFO - __main__ - Step 200 Global step 200 Train loss 8.13 on epoch=49
06/01/2022 04:54:48 - INFO - __main__ - Global step 200 Train loss 8.25 Classification-F1 0.0 on epoch=49
06/01/2022 04:54:50 - INFO - __main__ - Step 210 Global step 210 Train loss 7.87 on epoch=52
06/01/2022 04:54:51 - INFO - __main__ - Step 220 Global step 220 Train loss 7.62 on epoch=54
06/01/2022 04:54:52 - INFO - __main__ - Step 230 Global step 230 Train loss 7.56 on epoch=57
06/01/2022 04:54:54 - INFO - __main__ - Step 240 Global step 240 Train loss 7.49 on epoch=59
06/01/2022 04:54:55 - INFO - __main__ - Step 250 Global step 250 Train loss 7.18 on epoch=62
06/01/2022 04:55:11 - INFO - __main__ - Global step 250 Train loss 7.54 Classification-F1 0.0 on epoch=62
06/01/2022 04:55:12 - INFO - __main__ - Step 260 Global step 260 Train loss 7.03 on epoch=64
06/01/2022 04:55:13 - INFO - __main__ - Step 270 Global step 270 Train loss 6.72 on epoch=67
06/01/2022 04:55:15 - INFO - __main__ - Step 280 Global step 280 Train loss 6.64 on epoch=69
06/01/2022 04:55:16 - INFO - __main__ - Step 290 Global step 290 Train loss 6.56 on epoch=72
06/01/2022 04:55:17 - INFO - __main__ - Step 300 Global step 300 Train loss 6.54 on epoch=74
06/01/2022 04:55:23 - INFO - __main__ - Global step 300 Train loss 6.70 Classification-F1 0.0 on epoch=74
06/01/2022 04:55:24 - INFO - __main__ - Step 310 Global step 310 Train loss 6.25 on epoch=77
06/01/2022 04:55:26 - INFO - __main__ - Step 320 Global step 320 Train loss 6.20 on epoch=79
06/01/2022 04:55:27 - INFO - __main__ - Step 330 Global step 330 Train loss 5.94 on epoch=82
06/01/2022 04:55:28 - INFO - __main__ - Step 340 Global step 340 Train loss 5.92 on epoch=84
06/01/2022 04:55:30 - INFO - __main__ - Step 350 Global step 350 Train loss 5.82 on epoch=87
06/01/2022 04:55:34 - INFO - __main__ - Global step 350 Train loss 6.02 Classification-F1 0.0 on epoch=87
06/01/2022 04:55:36 - INFO - __main__ - Step 360 Global step 360 Train loss 5.73 on epoch=89
06/01/2022 04:55:37 - INFO - __main__ - Step 370 Global step 370 Train loss 5.58 on epoch=92
06/01/2022 04:55:38 - INFO - __main__ - Step 380 Global step 380 Train loss 5.25 on epoch=94
06/01/2022 04:55:39 - INFO - __main__ - Step 390 Global step 390 Train loss 5.26 on epoch=97
06/01/2022 04:55:41 - INFO - __main__ - Step 400 Global step 400 Train loss 5.17 on epoch=99
06/01/2022 04:55:45 - INFO - __main__ - Global step 400 Train loss 5.40 Classification-F1 0.0 on epoch=99
06/01/2022 04:55:46 - INFO - __main__ - Step 410 Global step 410 Train loss 5.26 on epoch=102
06/01/2022 04:55:47 - INFO - __main__ - Step 420 Global step 420 Train loss 4.96 on epoch=104
06/01/2022 04:55:49 - INFO - __main__ - Step 430 Global step 430 Train loss 4.99 on epoch=107
06/01/2022 04:55:50 - INFO - __main__ - Step 440 Global step 440 Train loss 4.61 on epoch=109
06/01/2022 04:55:51 - INFO - __main__ - Step 450 Global step 450 Train loss 4.67 on epoch=112
06/01/2022 04:55:54 - INFO - __main__ - Global step 450 Train loss 4.90 Classification-F1 0.0 on epoch=112
06/01/2022 04:55:56 - INFO - __main__ - Step 460 Global step 460 Train loss 4.53 on epoch=114
06/01/2022 04:55:57 - INFO - __main__ - Step 470 Global step 470 Train loss 4.45 on epoch=117
06/01/2022 04:55:58 - INFO - __main__ - Step 480 Global step 480 Train loss 4.32 on epoch=119
06/01/2022 04:56:00 - INFO - __main__ - Step 490 Global step 490 Train loss 4.27 on epoch=122
06/01/2022 04:56:01 - INFO - __main__ - Step 500 Global step 500 Train loss 4.07 on epoch=124
06/01/2022 04:56:02 - INFO - __main__ - Global step 500 Train loss 4.33 Classification-F1 0.08596491228070176 on epoch=124
06/01/2022 04:56:02 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.08596491228070176 on epoch=124, global_step=500
06/01/2022 04:56:03 - INFO - __main__ - Step 510 Global step 510 Train loss 3.94 on epoch=127
06/01/2022 04:56:04 - INFO - __main__ - Step 520 Global step 520 Train loss 3.73 on epoch=129
06/01/2022 04:56:06 - INFO - __main__ - Step 530 Global step 530 Train loss 3.90 on epoch=132
06/01/2022 04:56:07 - INFO - __main__ - Step 540 Global step 540 Train loss 3.69 on epoch=134
06/01/2022 04:56:08 - INFO - __main__ - Step 550 Global step 550 Train loss 3.61 on epoch=137
06/01/2022 04:56:09 - INFO - __main__ - Global step 550 Train loss 3.77 Classification-F1 0.07567567567567568 on epoch=137
06/01/2022 04:56:10 - INFO - __main__ - Step 560 Global step 560 Train loss 3.40 on epoch=139
06/01/2022 04:56:11 - INFO - __main__ - Step 570 Global step 570 Train loss 3.55 on epoch=142
06/01/2022 04:56:12 - INFO - __main__ - Step 580 Global step 580 Train loss 3.17 on epoch=144
06/01/2022 04:56:14 - INFO - __main__ - Step 590 Global step 590 Train loss 3.11 on epoch=147
06/01/2022 04:56:15 - INFO - __main__ - Step 600 Global step 600 Train loss 3.19 on epoch=149
06/01/2022 04:56:16 - INFO - __main__ - Global step 600 Train loss 3.28 Classification-F1 0.1343478260869565 on epoch=149
06/01/2022 04:56:16 - INFO - __main__ - Saving model with best Classification-F1: 0.08596491228070176 -> 0.1343478260869565 on epoch=149, global_step=600
06/01/2022 04:56:17 - INFO - __main__ - Step 610 Global step 610 Train loss 3.34 on epoch=152
06/01/2022 04:56:18 - INFO - __main__ - Step 620 Global step 620 Train loss 3.26 on epoch=154
06/01/2022 04:56:20 - INFO - __main__ - Step 630 Global step 630 Train loss 3.12 on epoch=157
06/01/2022 04:56:21 - INFO - __main__ - Step 640 Global step 640 Train loss 2.96 on epoch=159
06/01/2022 04:56:22 - INFO - __main__ - Step 650 Global step 650 Train loss 3.11 on epoch=162
06/01/2022 04:56:23 - INFO - __main__ - Global step 650 Train loss 3.16 Classification-F1 0.17773705909299126 on epoch=162
06/01/2022 04:56:23 - INFO - __main__ - Saving model with best Classification-F1: 0.1343478260869565 -> 0.17773705909299126 on epoch=162, global_step=650
06/01/2022 04:56:24 - INFO - __main__ - Step 660 Global step 660 Train loss 2.89 on epoch=164
06/01/2022 04:56:25 - INFO - __main__ - Step 670 Global step 670 Train loss 3.07 on epoch=167
06/01/2022 04:56:27 - INFO - __main__ - Step 680 Global step 680 Train loss 2.78 on epoch=169
06/01/2022 04:56:28 - INFO - __main__ - Step 690 Global step 690 Train loss 2.96 on epoch=172
06/01/2022 04:56:29 - INFO - __main__ - Step 700 Global step 700 Train loss 2.59 on epoch=174
06/01/2022 04:56:30 - INFO - __main__ - Global step 700 Train loss 2.86 Classification-F1 0.17893217893217894 on epoch=174
06/01/2022 04:56:30 - INFO - __main__ - Saving model with best Classification-F1: 0.17773705909299126 -> 0.17893217893217894 on epoch=174, global_step=700
06/01/2022 04:56:31 - INFO - __main__ - Step 710 Global step 710 Train loss 2.78 on epoch=177
06/01/2022 04:56:32 - INFO - __main__ - Step 720 Global step 720 Train loss 2.59 on epoch=179
06/01/2022 04:56:34 - INFO - __main__ - Step 730 Global step 730 Train loss 2.62 on epoch=182
06/01/2022 04:56:35 - INFO - __main__ - Step 740 Global step 740 Train loss 2.54 on epoch=184
06/01/2022 04:56:36 - INFO - __main__ - Step 750 Global step 750 Train loss 2.65 on epoch=187
06/01/2022 04:56:37 - INFO - __main__ - Global step 750 Train loss 2.64 Classification-F1 0.13381369016984046 on epoch=187
06/01/2022 04:56:38 - INFO - __main__ - Step 760 Global step 760 Train loss 2.57 on epoch=189
06/01/2022 04:56:39 - INFO - __main__ - Step 770 Global step 770 Train loss 2.65 on epoch=192
06/01/2022 04:56:41 - INFO - __main__ - Step 780 Global step 780 Train loss 2.30 on epoch=194
06/01/2022 04:56:42 - INFO - __main__ - Step 790 Global step 790 Train loss 2.64 on epoch=197
06/01/2022 04:56:43 - INFO - __main__ - Step 800 Global step 800 Train loss 2.62 on epoch=199
06/01/2022 04:56:44 - INFO - __main__ - Global step 800 Train loss 2.56 Classification-F1 0.1 on epoch=199
06/01/2022 04:56:45 - INFO - __main__ - Step 810 Global step 810 Train loss 2.65 on epoch=202
06/01/2022 04:56:46 - INFO - __main__ - Step 820 Global step 820 Train loss 2.52 on epoch=204
06/01/2022 04:56:48 - INFO - __main__ - Step 830 Global step 830 Train loss 2.33 on epoch=207
06/01/2022 04:56:49 - INFO - __main__ - Step 840 Global step 840 Train loss 2.07 on epoch=209
06/01/2022 04:56:50 - INFO - __main__ - Step 850 Global step 850 Train loss 2.23 on epoch=212
06/01/2022 04:56:51 - INFO - __main__ - Global step 850 Train loss 2.36 Classification-F1 0.191016333938294 on epoch=212
06/01/2022 04:56:51 - INFO - __main__ - Saving model with best Classification-F1: 0.17893217893217894 -> 0.191016333938294 on epoch=212, global_step=850
06/01/2022 04:56:52 - INFO - __main__ - Step 860 Global step 860 Train loss 2.14 on epoch=214
06/01/2022 04:56:53 - INFO - __main__ - Step 870 Global step 870 Train loss 2.20 on epoch=217
06/01/2022 04:56:54 - INFO - __main__ - Step 880 Global step 880 Train loss 2.07 on epoch=219
06/01/2022 04:56:56 - INFO - __main__ - Step 890 Global step 890 Train loss 2.29 on epoch=222
06/01/2022 04:56:57 - INFO - __main__ - Step 900 Global step 900 Train loss 1.97 on epoch=224
06/01/2022 04:56:58 - INFO - __main__ - Global step 900 Train loss 2.14 Classification-F1 0.1709090909090909 on epoch=224
06/01/2022 04:56:59 - INFO - __main__ - Step 910 Global step 910 Train loss 2.08 on epoch=227
06/01/2022 04:57:00 - INFO - __main__ - Step 920 Global step 920 Train loss 1.96 on epoch=229
06/01/2022 04:57:01 - INFO - __main__ - Step 930 Global step 930 Train loss 1.94 on epoch=232
06/01/2022 04:57:03 - INFO - __main__ - Step 940 Global step 940 Train loss 1.97 on epoch=234
06/01/2022 04:57:04 - INFO - __main__ - Step 950 Global step 950 Train loss 2.00 on epoch=237
06/01/2022 04:57:04 - INFO - __main__ - Global step 950 Train loss 1.99 Classification-F1 0.2433255269320843 on epoch=237
06/01/2022 04:57:04 - INFO - __main__ - Saving model with best Classification-F1: 0.191016333938294 -> 0.2433255269320843 on epoch=237, global_step=950
06/01/2022 04:57:06 - INFO - __main__ - Step 960 Global step 960 Train loss 1.87 on epoch=239
06/01/2022 04:57:07 - INFO - __main__ - Step 970 Global step 970 Train loss 1.91 on epoch=242
06/01/2022 04:57:08 - INFO - __main__ - Step 980 Global step 980 Train loss 1.73 on epoch=244
06/01/2022 04:57:10 - INFO - __main__ - Step 990 Global step 990 Train loss 1.98 on epoch=247
06/01/2022 04:57:11 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.79 on epoch=249
06/01/2022 04:57:11 - INFO - __main__ - Global step 1000 Train loss 1.85 Classification-F1 0.19859154929577466 on epoch=249
06/01/2022 04:57:13 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.82 on epoch=252
06/01/2022 04:57:14 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.82 on epoch=254
06/01/2022 04:57:15 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.85 on epoch=257
06/01/2022 04:57:17 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.75 on epoch=259
06/01/2022 04:57:18 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.76 on epoch=262
06/01/2022 04:57:18 - INFO - __main__ - Global step 1050 Train loss 1.80 Classification-F1 0.09711751662971176 on epoch=262
06/01/2022 04:57:20 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.55 on epoch=264
06/01/2022 04:57:21 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.80 on epoch=267
06/01/2022 04:57:22 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.59 on epoch=269
06/01/2022 04:57:24 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.59 on epoch=272
06/01/2022 04:57:25 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.66 on epoch=274
06/01/2022 04:57:25 - INFO - __main__ - Global step 1100 Train loss 1.64 Classification-F1 0.17142857142857143 on epoch=274
06/01/2022 04:57:27 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.73 on epoch=277
06/01/2022 04:57:28 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.54 on epoch=279
06/01/2022 04:57:29 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.65 on epoch=282
06/01/2022 04:57:30 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.55 on epoch=284
06/01/2022 04:57:32 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.48 on epoch=287
06/01/2022 04:57:32 - INFO - __main__ - Global step 1150 Train loss 1.59 Classification-F1 0.1769230769230769 on epoch=287
06/01/2022 04:57:34 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.36 on epoch=289
06/01/2022 04:57:35 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.47 on epoch=292
06/01/2022 04:57:36 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.51 on epoch=294
06/01/2022 04:57:37 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.50 on epoch=297
06/01/2022 04:57:39 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.43 on epoch=299
06/01/2022 04:57:39 - INFO - __main__ - Global step 1200 Train loss 1.45 Classification-F1 0.1 on epoch=299
06/01/2022 04:57:40 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.46 on epoch=302
06/01/2022 04:57:42 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.32 on epoch=304
06/01/2022 04:57:43 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.58 on epoch=307
06/01/2022 04:57:44 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.35 on epoch=309
06/01/2022 04:57:46 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.51 on epoch=312
06/01/2022 04:57:46 - INFO - __main__ - Global step 1250 Train loss 1.44 Classification-F1 0.13067758749069247 on epoch=312
06/01/2022 04:57:47 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.34 on epoch=314
06/01/2022 04:57:49 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.47 on epoch=317
06/01/2022 04:57:50 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.33 on epoch=319
06/01/2022 04:57:51 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.21 on epoch=322
06/01/2022 04:57:53 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.23 on epoch=324
06/01/2022 04:57:53 - INFO - __main__ - Global step 1300 Train loss 1.32 Classification-F1 0.1 on epoch=324
06/01/2022 04:57:54 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.30 on epoch=327
06/01/2022 04:57:56 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.32 on epoch=329
06/01/2022 04:57:57 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.38 on epoch=332
06/01/2022 04:57:58 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.26 on epoch=334
06/01/2022 04:57:59 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.37 on epoch=337
06/01/2022 04:58:00 - INFO - __main__ - Global step 1350 Train loss 1.33 Classification-F1 0.1 on epoch=337
06/01/2022 04:58:01 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.32 on epoch=339
06/01/2022 04:58:03 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.34 on epoch=342
06/01/2022 04:58:04 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.24 on epoch=344
06/01/2022 04:58:05 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.32 on epoch=347
06/01/2022 04:58:06 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.17 on epoch=349
06/01/2022 04:58:07 - INFO - __main__ - Global step 1400 Train loss 1.28 Classification-F1 0.10256410256410256 on epoch=349
06/01/2022 04:58:08 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.31 on epoch=352
06/01/2022 04:58:10 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.24 on epoch=354
06/01/2022 04:58:11 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.37 on epoch=357
06/01/2022 04:58:12 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.27 on epoch=359
06/01/2022 04:58:13 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.31 on epoch=362
06/01/2022 04:58:14 - INFO - __main__ - Global step 1450 Train loss 1.30 Classification-F1 0.20190476190476192 on epoch=362
06/01/2022 04:58:15 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.13 on epoch=364
06/01/2022 04:58:16 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.24 on epoch=367
06/01/2022 04:58:18 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.24 on epoch=369
06/01/2022 04:58:19 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.28 on epoch=372
06/01/2022 04:58:20 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.29 on epoch=374
06/01/2022 04:58:21 - INFO - __main__ - Global step 1500 Train loss 1.24 Classification-F1 0.1 on epoch=374
06/01/2022 04:58:22 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.49 on epoch=377
06/01/2022 04:58:23 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.31 on epoch=379
06/01/2022 04:58:25 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.22 on epoch=382
06/01/2022 04:58:26 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.14 on epoch=384
06/01/2022 04:58:27 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.22 on epoch=387
06/01/2022 04:58:28 - INFO - __main__ - Global step 1550 Train loss 1.28 Classification-F1 0.1 on epoch=387
06/01/2022 04:58:29 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.25 on epoch=389
06/01/2022 04:58:30 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.15 on epoch=392
06/01/2022 04:58:32 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.23 on epoch=394
06/01/2022 04:58:33 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.22 on epoch=397
06/01/2022 04:58:34 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.16 on epoch=399
06/01/2022 04:58:35 - INFO - __main__ - Global step 1600 Train loss 1.20 Classification-F1 0.1 on epoch=399
06/01/2022 04:58:36 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.12 on epoch=402
06/01/2022 04:58:37 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.19 on epoch=404
06/01/2022 04:58:38 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.25 on epoch=407
06/01/2022 04:58:40 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.08 on epoch=409
06/01/2022 04:58:41 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.11 on epoch=412
06/01/2022 04:58:42 - INFO - __main__ - Global step 1650 Train loss 1.15 Classification-F1 0.1 on epoch=412
06/01/2022 04:58:43 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.26 on epoch=414
06/01/2022 04:58:44 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.21 on epoch=417
06/01/2022 04:58:45 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.08 on epoch=419
06/01/2022 04:58:47 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.26 on epoch=422
06/01/2022 04:58:48 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.13 on epoch=424
06/01/2022 04:58:48 - INFO - __main__ - Global step 1700 Train loss 1.19 Classification-F1 0.25101214574898784 on epoch=424
06/01/2022 04:58:48 - INFO - __main__ - Saving model with best Classification-F1: 0.2433255269320843 -> 0.25101214574898784 on epoch=424, global_step=1700
06/01/2022 04:58:50 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.12 on epoch=427
06/01/2022 04:58:51 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.23 on epoch=429
06/01/2022 04:58:52 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.18 on epoch=432
06/01/2022 04:58:54 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.17 on epoch=434
06/01/2022 04:58:55 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.18 on epoch=437
06/01/2022 04:58:55 - INFO - __main__ - Global step 1750 Train loss 1.18 Classification-F1 0.1 on epoch=437
06/01/2022 04:58:57 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.15 on epoch=439
06/01/2022 04:58:58 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.17 on epoch=442
06/01/2022 04:58:59 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.10 on epoch=444
06/01/2022 04:59:01 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.13 on epoch=447
06/01/2022 04:59:02 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.12 on epoch=449
06/01/2022 04:59:02 - INFO - __main__ - Global step 1800 Train loss 1.13 Classification-F1 0.11772486772486772 on epoch=449
06/01/2022 04:59:04 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.12 on epoch=452
06/01/2022 04:59:05 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.27 on epoch=454
06/01/2022 04:59:06 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.29 on epoch=457
06/01/2022 04:59:07 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.21 on epoch=459
06/01/2022 04:59:09 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.14 on epoch=462
06/01/2022 04:59:09 - INFO - __main__ - Global step 1850 Train loss 1.21 Classification-F1 0.15526315789473685 on epoch=462
06/01/2022 04:59:11 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.14 on epoch=464
06/01/2022 04:59:12 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.17 on epoch=467
06/01/2022 04:59:13 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.09 on epoch=469
06/01/2022 04:59:14 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.13 on epoch=472
06/01/2022 04:59:16 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.08 on epoch=474
06/01/2022 04:59:16 - INFO - __main__ - Global step 1900 Train loss 1.12 Classification-F1 0.19859154929577466 on epoch=474
06/01/2022 04:59:17 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.12 on epoch=477
06/01/2022 04:59:19 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.09 on epoch=479
06/01/2022 04:59:20 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.08 on epoch=482
06/01/2022 04:59:21 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.06 on epoch=484
06/01/2022 04:59:23 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.18 on epoch=487
06/01/2022 04:59:23 - INFO - __main__ - Global step 1950 Train loss 1.10 Classification-F1 0.12518037518037517 on epoch=487
06/01/2022 04:59:24 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.05 on epoch=489
06/01/2022 04:59:26 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.08 on epoch=492
06/01/2022 04:59:27 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.09 on epoch=494
06/01/2022 04:59:28 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.07 on epoch=497
06/01/2022 04:59:30 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.18 on epoch=499
06/01/2022 04:59:30 - INFO - __main__ - Global step 2000 Train loss 1.09 Classification-F1 0.17836812144212524 on epoch=499
06/01/2022 04:59:31 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.08 on epoch=502
06/01/2022 04:59:33 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.03 on epoch=504
06/01/2022 04:59:34 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.06 on epoch=507
06/01/2022 04:59:35 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.19 on epoch=509
06/01/2022 04:59:37 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.24 on epoch=512
06/01/2022 04:59:37 - INFO - __main__ - Global step 2050 Train loss 1.12 Classification-F1 0.15587044534412953 on epoch=512
06/01/2022 04:59:38 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.09 on epoch=514
06/01/2022 04:59:40 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.12 on epoch=517
06/01/2022 04:59:41 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.06 on epoch=519
06/01/2022 04:59:42 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.25 on epoch=522
06/01/2022 04:59:44 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.09 on epoch=524
06/01/2022 04:59:44 - INFO - __main__ - Global step 2100 Train loss 1.12 Classification-F1 0.15490196078431373 on epoch=524
06/01/2022 04:59:45 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.05 on epoch=527
06/01/2022 04:59:47 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.16 on epoch=529
06/01/2022 04:59:48 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.00 on epoch=532
06/01/2022 04:59:49 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.09 on epoch=534
06/01/2022 04:59:50 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.18 on epoch=537
06/01/2022 04:59:51 - INFO - __main__ - Global step 2150 Train loss 1.10 Classification-F1 0.17328042328042326 on epoch=537
06/01/2022 04:59:52 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.97 on epoch=539
06/01/2022 04:59:54 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.12 on epoch=542
06/01/2022 04:59:55 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.17 on epoch=544
06/01/2022 04:59:56 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.16 on epoch=547
06/01/2022 04:59:57 - INFO - __main__ - Step 2200 Global step 2200 Train loss 1.14 on epoch=549
06/01/2022 04:59:58 - INFO - __main__ - Global step 2200 Train loss 1.11 Classification-F1 0.15851775604734944 on epoch=549
06/01/2022 04:59:59 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.17 on epoch=552
06/01/2022 05:00:01 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.06 on epoch=554
06/01/2022 05:00:02 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.15 on epoch=557
06/01/2022 05:00:03 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.03 on epoch=559
06/01/2022 05:00:04 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.12 on epoch=562
06/01/2022 05:00:05 - INFO - __main__ - Global step 2250 Train loss 1.11 Classification-F1 0.1302118933697881 on epoch=562
06/01/2022 05:00:06 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.98 on epoch=564
06/01/2022 05:00:08 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.15 on epoch=567
06/01/2022 05:00:09 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.12 on epoch=569
06/01/2022 05:00:10 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.00 on epoch=572
06/01/2022 05:00:11 - INFO - __main__ - Step 2300 Global step 2300 Train loss 1.09 on epoch=574
06/01/2022 05:00:12 - INFO - __main__ - Global step 2300 Train loss 1.07 Classification-F1 0.1403588195841717 on epoch=574
06/01/2022 05:00:13 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.07 on epoch=577
06/01/2022 05:00:14 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.13 on epoch=579
06/01/2022 05:00:16 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.98 on epoch=582
06/01/2022 05:00:17 - INFO - __main__ - Step 2340 Global step 2340 Train loss 1.08 on epoch=584
06/01/2022 05:00:18 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.05 on epoch=587
06/01/2022 05:00:19 - INFO - __main__ - Global step 2350 Train loss 1.06 Classification-F1 0.12518037518037517 on epoch=587
06/01/2022 05:00:20 - INFO - __main__ - Step 2360 Global step 2360 Train loss 1.05 on epoch=589
06/01/2022 05:00:21 - INFO - __main__ - Step 2370 Global step 2370 Train loss 1.09 on epoch=592
06/01/2022 05:00:23 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.20 on epoch=594
06/01/2022 05:00:24 - INFO - __main__ - Step 2390 Global step 2390 Train loss 1.03 on epoch=597
06/01/2022 05:00:25 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.09 on epoch=599
06/01/2022 05:00:26 - INFO - __main__ - Global step 2400 Train loss 1.09 Classification-F1 0.08974358974358974 on epoch=599
06/01/2022 05:00:27 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.99 on epoch=602
06/01/2022 05:00:28 - INFO - __main__ - Step 2420 Global step 2420 Train loss 1.12 on epoch=604
06/01/2022 05:00:30 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.09 on epoch=607
06/01/2022 05:00:31 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.99 on epoch=609
06/01/2022 05:00:32 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.00 on epoch=612
06/01/2022 05:00:33 - INFO - __main__ - Global step 2450 Train loss 1.04 Classification-F1 0.15526315789473685 on epoch=612
06/01/2022 05:00:34 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.06 on epoch=614
06/01/2022 05:00:35 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.04 on epoch=617
06/01/2022 05:00:37 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.95 on epoch=619
06/01/2022 05:00:38 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.09 on epoch=622
06/01/2022 05:00:39 - INFO - __main__ - Step 2500 Global step 2500 Train loss 1.06 on epoch=624
06/01/2022 05:00:40 - INFO - __main__ - Global step 2500 Train loss 1.04 Classification-F1 0.14141414141414138 on epoch=624
06/01/2022 05:00:41 - INFO - __main__ - Step 2510 Global step 2510 Train loss 1.09 on epoch=627
06/01/2022 05:00:42 - INFO - __main__ - Step 2520 Global step 2520 Train loss 1.01 on epoch=629
06/01/2022 05:00:43 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.18 on epoch=632
06/01/2022 05:00:45 - INFO - __main__ - Step 2540 Global step 2540 Train loss 1.08 on epoch=634
06/01/2022 05:00:46 - INFO - __main__ - Step 2550 Global step 2550 Train loss 1.08 on epoch=637
06/01/2022 05:00:47 - INFO - __main__ - Global step 2550 Train loss 1.09 Classification-F1 0.10126582278481013 on epoch=637
06/01/2022 05:00:48 - INFO - __main__ - Step 2560 Global step 2560 Train loss 1.06 on epoch=639
06/01/2022 05:00:49 - INFO - __main__ - Step 2570 Global step 2570 Train loss 1.06 on epoch=642
06/01/2022 05:00:50 - INFO - __main__ - Step 2580 Global step 2580 Train loss 1.06 on epoch=644
06/01/2022 05:00:52 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.11 on epoch=647
06/01/2022 05:00:53 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.07 on epoch=649
06/01/2022 05:00:54 - INFO - __main__ - Global step 2600 Train loss 1.07 Classification-F1 0.19226044226044225 on epoch=649
06/01/2022 05:00:55 - INFO - __main__ - Step 2610 Global step 2610 Train loss 1.00 on epoch=652
06/01/2022 05:00:56 - INFO - __main__ - Step 2620 Global step 2620 Train loss 1.06 on epoch=654
06/01/2022 05:00:57 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.97 on epoch=657
06/01/2022 05:00:59 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.06 on epoch=659
06/01/2022 05:01:00 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.08 on epoch=662
06/01/2022 05:01:00 - INFO - __main__ - Global step 2650 Train loss 1.03 Classification-F1 0.1 on epoch=662
06/01/2022 05:01:02 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.98 on epoch=664
06/01/2022 05:01:03 - INFO - __main__ - Step 2670 Global step 2670 Train loss 1.07 on epoch=667
06/01/2022 05:01:04 - INFO - __main__ - Step 2680 Global step 2680 Train loss 1.03 on epoch=669
06/01/2022 05:01:06 - INFO - __main__ - Step 2690 Global step 2690 Train loss 1.05 on epoch=672
06/01/2022 05:01:07 - INFO - __main__ - Step 2700 Global step 2700 Train loss 1.06 on epoch=674
06/01/2022 05:01:07 - INFO - __main__ - Global step 2700 Train loss 1.04 Classification-F1 0.1 on epoch=674
06/01/2022 05:01:09 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.12 on epoch=677
06/01/2022 05:01:10 - INFO - __main__ - Step 2720 Global step 2720 Train loss 1.13 on epoch=679
06/01/2022 05:01:11 - INFO - __main__ - Step 2730 Global step 2730 Train loss 1.03 on epoch=682
06/01/2022 05:01:13 - INFO - __main__ - Step 2740 Global step 2740 Train loss 1.04 on epoch=684
06/01/2022 05:01:14 - INFO - __main__ - Step 2750 Global step 2750 Train loss 1.01 on epoch=687
06/01/2022 05:01:14 - INFO - __main__ - Global step 2750 Train loss 1.06 Classification-F1 0.09615384615384615 on epoch=687
06/01/2022 05:01:16 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.97 on epoch=689
06/01/2022 05:01:17 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.01 on epoch=692
06/01/2022 05:01:18 - INFO - __main__ - Step 2780 Global step 2780 Train loss 1.06 on epoch=694
06/01/2022 05:01:20 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.95 on epoch=697
06/01/2022 05:01:21 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.97 on epoch=699
06/01/2022 05:01:21 - INFO - __main__ - Global step 2800 Train loss 0.99 Classification-F1 0.1513157894736842 on epoch=699
06/01/2022 05:01:23 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.03 on epoch=702
06/01/2022 05:01:24 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.97 on epoch=704
06/01/2022 05:01:25 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.95 on epoch=707
06/01/2022 05:01:27 - INFO - __main__ - Step 2840 Global step 2840 Train loss 1.00 on epoch=709
06/01/2022 05:01:28 - INFO - __main__ - Step 2850 Global step 2850 Train loss 1.06 on epoch=712
06/01/2022 05:01:28 - INFO - __main__ - Global step 2850 Train loss 1.00 Classification-F1 0.1 on epoch=712
06/01/2022 05:01:30 - INFO - __main__ - Step 2860 Global step 2860 Train loss 1.11 on epoch=714
06/01/2022 05:01:31 - INFO - __main__ - Step 2870 Global step 2870 Train loss 1.08 on epoch=717
06/01/2022 05:01:32 - INFO - __main__ - Step 2880 Global step 2880 Train loss 1.08 on epoch=719
06/01/2022 05:01:33 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.91 on epoch=722
06/01/2022 05:01:35 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.94 on epoch=724
06/01/2022 05:01:35 - INFO - __main__ - Global step 2900 Train loss 1.02 Classification-F1 0.26129032258064516 on epoch=724
06/01/2022 05:01:35 - INFO - __main__ - Saving model with best Classification-F1: 0.25101214574898784 -> 0.26129032258064516 on epoch=724, global_step=2900
06/01/2022 05:01:37 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.09 on epoch=727
06/01/2022 05:01:38 - INFO - __main__ - Step 2920 Global step 2920 Train loss 1.06 on epoch=729
06/01/2022 05:01:39 - INFO - __main__ - Step 2930 Global step 2930 Train loss 1.04 on epoch=732
06/01/2022 05:01:40 - INFO - __main__ - Step 2940 Global step 2940 Train loss 1.03 on epoch=734
06/01/2022 05:01:42 - INFO - __main__ - Step 2950 Global step 2950 Train loss 1.01 on epoch=737
06/01/2022 05:01:42 - INFO - __main__ - Global step 2950 Train loss 1.05 Classification-F1 0.2361111111111111 on epoch=737
06/01/2022 05:01:44 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.96 on epoch=739
06/01/2022 05:01:45 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.16 on epoch=742
06/01/2022 05:01:46 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.06 on epoch=744
06/01/2022 05:01:47 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.99 on epoch=747
06/01/2022 05:01:49 - INFO - __main__ - Step 3000 Global step 3000 Train loss 1.04 on epoch=749
06/01/2022 05:01:49 - INFO - __main__ - Global step 3000 Train loss 1.04 Classification-F1 0.20190476190476192 on epoch=749
06/01/2022 05:01:49 - INFO - __main__ - save last model!
06/01/2022 05:01:49 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/01/2022 05:01:49 - INFO - __main__ - Start tokenizing ... 5509 instances
06/01/2022 05:01:49 - INFO - __main__ - Printing 3 examples
06/01/2022 05:01:49 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/01/2022 05:01:49 - INFO - __main__ - ['others']
06/01/2022 05:01:49 - INFO - __main__ -  [emo] what you like very little things ok
06/01/2022 05:01:49 - INFO - __main__ - ['others']
06/01/2022 05:01:49 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/01/2022 05:01:49 - INFO - __main__ - ['others']
06/01/2022 05:01:49 - INFO - __main__ - Tokenizing Input ...
06/01/2022 05:01:50 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 05:01:50 - INFO - __main__ - Printing 3 examples
06/01/2022 05:01:50 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/01/2022 05:01:50 - INFO - __main__ - ['others']
06/01/2022 05:01:50 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/01/2022 05:01:50 - INFO - __main__ - ['others']
06/01/2022 05:01:50 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/01/2022 05:01:50 - INFO - __main__ - ['others']
06/01/2022 05:01:50 - INFO - __main__ - Tokenizing Input ...
06/01/2022 05:01:50 - INFO - __main__ - Tokenizing Output ...
06/01/2022 05:01:50 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 05:01:50 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 05:01:50 - INFO - __main__ - Printing 3 examples
06/01/2022 05:01:50 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
06/01/2022 05:01:50 - INFO - __main__ - ['others']
06/01/2022 05:01:50 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
06/01/2022 05:01:50 - INFO - __main__ - ['others']
06/01/2022 05:01:50 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
06/01/2022 05:01:50 - INFO - __main__ - ['others']
06/01/2022 05:01:50 - INFO - __main__ - Tokenizing Input ...
06/01/2022 05:01:50 - INFO - __main__ - Tokenizing Output ...
06/01/2022 05:01:50 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 05:01:51 - INFO - __main__ - Tokenizing Output ...
06/01/2022 05:01:56 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 05:01:56 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/01/2022 05:01:56 - INFO - __main__ - Starting training!
06/01/2022 05:01:57 - INFO - __main__ - Loaded 5509 examples from test data
06/01/2022 05:02:40 - INFO - __main__ - Saved prediction in models/T5-base-reptile-cls2cls-3e-5-2-5000-5e-1-10/singletask-emo/emo_16_87_0.3_8_predictions.txt
06/01/2022 05:02:40 - INFO - __main__ - Classification-F1 on test data: 0.0325
06/01/2022 05:02:41 - INFO - __main__ - prefix=emo_16_87, lr=0.3, bsz=8, dev_performance=0.26129032258064516, test_performance=0.03254203466969424
06/01/2022 05:02:41 - INFO - __main__ - Running ... prefix=emo_16_87, lr=0.2, bsz=8 ...
06/01/2022 05:02:42 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 05:02:42 - INFO - __main__ - Printing 3 examples
06/01/2022 05:02:42 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/01/2022 05:02:42 - INFO - __main__ - ['others']
06/01/2022 05:02:42 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/01/2022 05:02:42 - INFO - __main__ - ['others']
06/01/2022 05:02:42 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/01/2022 05:02:42 - INFO - __main__ - ['others']
06/01/2022 05:02:42 - INFO - __main__ - Tokenizing Input ...
06/01/2022 05:02:42 - INFO - __main__ - Tokenizing Output ...
06/01/2022 05:02:42 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 05:02:42 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 05:02:42 - INFO - __main__ - Printing 3 examples
06/01/2022 05:02:42 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
06/01/2022 05:02:42 - INFO - __main__ - ['others']
06/01/2022 05:02:42 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
06/01/2022 05:02:42 - INFO - __main__ - ['others']
06/01/2022 05:02:42 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
06/01/2022 05:02:42 - INFO - __main__ - ['others']
06/01/2022 05:02:42 - INFO - __main__ - Tokenizing Input ...
06/01/2022 05:02:42 - INFO - __main__ - Tokenizing Output ...
06/01/2022 05:02:42 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 05:02:47 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 05:02:48 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/01/2022 05:02:48 - INFO - __main__ - Starting training!
06/01/2022 05:02:49 - INFO - __main__ - Step 10 Global step 10 Train loss 8.81 on epoch=2
06/01/2022 05:02:51 - INFO - __main__ - Step 20 Global step 20 Train loss 8.94 on epoch=4
06/01/2022 05:02:52 - INFO - __main__ - Step 30 Global step 30 Train loss 8.96 on epoch=7
06/01/2022 05:02:53 - INFO - __main__ - Step 40 Global step 40 Train loss 8.92 on epoch=9
06/01/2022 05:02:54 - INFO - __main__ - Step 50 Global step 50 Train loss 9.02 on epoch=12
06/01/2022 05:02:58 - INFO - __main__ - Global step 50 Train loss 8.93 Classification-F1 0.0 on epoch=12
06/01/2022 05:02:58 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
06/01/2022 05:02:59 - INFO - __main__ - Step 60 Global step 60 Train loss 8.93 on epoch=14
06/01/2022 05:03:00 - INFO - __main__ - Step 70 Global step 70 Train loss 8.86 on epoch=17
06/01/2022 05:03:02 - INFO - __main__ - Step 80 Global step 80 Train loss 8.75 on epoch=19
06/01/2022 05:03:03 - INFO - __main__ - Step 90 Global step 90 Train loss 8.76 on epoch=22
06/01/2022 05:03:04 - INFO - __main__ - Step 100 Global step 100 Train loss 8.76 on epoch=24
06/01/2022 05:03:08 - INFO - __main__ - Global step 100 Train loss 8.81 Classification-F1 0.0 on epoch=24
06/01/2022 05:03:09 - INFO - __main__ - Step 110 Global step 110 Train loss 8.77 on epoch=27
06/01/2022 05:03:10 - INFO - __main__ - Step 120 Global step 120 Train loss 8.68 on epoch=29
06/01/2022 05:03:12 - INFO - __main__ - Step 130 Global step 130 Train loss 8.54 on epoch=32
06/01/2022 05:03:13 - INFO - __main__ - Step 140 Global step 140 Train loss 8.82 on epoch=34
06/01/2022 05:03:14 - INFO - __main__ - Step 150 Global step 150 Train loss 8.63 on epoch=37
06/01/2022 05:03:26 - INFO - __main__ - Global step 150 Train loss 8.69 Classification-F1 0.0 on epoch=37
06/01/2022 05:03:27 - INFO - __main__ - Step 160 Global step 160 Train loss 8.52 on epoch=39
06/01/2022 05:03:28 - INFO - __main__ - Step 170 Global step 170 Train loss 8.61 on epoch=42
06/01/2022 05:03:30 - INFO - __main__ - Step 180 Global step 180 Train loss 8.44 on epoch=44
06/01/2022 05:03:31 - INFO - __main__ - Step 190 Global step 190 Train loss 8.40 on epoch=47
06/01/2022 05:03:32 - INFO - __main__ - Step 200 Global step 200 Train loss 8.30 on epoch=49
06/01/2022 05:03:47 - INFO - __main__ - Global step 200 Train loss 8.46 Classification-F1 0.0 on epoch=49
06/01/2022 05:03:48 - INFO - __main__ - Step 210 Global step 210 Train loss 8.36 on epoch=52
06/01/2022 05:03:50 - INFO - __main__ - Step 220 Global step 220 Train loss 8.22 on epoch=54
06/01/2022 05:03:51 - INFO - __main__ - Step 230 Global step 230 Train loss 8.30 on epoch=57
06/01/2022 05:03:52 - INFO - __main__ - Step 240 Global step 240 Train loss 8.07 on epoch=59
06/01/2022 05:03:53 - INFO - __main__ - Step 250 Global step 250 Train loss 8.06 on epoch=62
06/01/2022 05:04:09 - INFO - __main__ - Global step 250 Train loss 8.20 Classification-F1 0.0 on epoch=62
06/01/2022 05:04:10 - INFO - __main__ - Step 260 Global step 260 Train loss 8.03 on epoch=64
06/01/2022 05:04:11 - INFO - __main__ - Step 270 Global step 270 Train loss 7.93 on epoch=67
06/01/2022 05:04:13 - INFO - __main__ - Step 280 Global step 280 Train loss 7.69 on epoch=69
06/01/2022 05:04:14 - INFO - __main__ - Step 290 Global step 290 Train loss 7.58 on epoch=72
06/01/2022 05:04:15 - INFO - __main__ - Step 300 Global step 300 Train loss 7.53 on epoch=74
06/01/2022 05:04:24 - INFO - __main__ - Global step 300 Train loss 7.75 Classification-F1 0.0 on epoch=74
06/01/2022 05:04:25 - INFO - __main__ - Step 310 Global step 310 Train loss 7.46 on epoch=77
06/01/2022 05:04:26 - INFO - __main__ - Step 320 Global step 320 Train loss 7.28 on epoch=79
06/01/2022 05:04:27 - INFO - __main__ - Step 330 Global step 330 Train loss 7.11 on epoch=82
06/01/2022 05:04:29 - INFO - __main__ - Step 340 Global step 340 Train loss 7.03 on epoch=84
06/01/2022 05:04:30 - INFO - __main__ - Step 350 Global step 350 Train loss 7.00 on epoch=87
06/01/2022 05:04:41 - INFO - __main__ - Global step 350 Train loss 7.18 Classification-F1 0.0 on epoch=87
06/01/2022 05:04:42 - INFO - __main__ - Step 360 Global step 360 Train loss 6.65 on epoch=89
06/01/2022 05:04:43 - INFO - __main__ - Step 370 Global step 370 Train loss 6.70 on epoch=92
06/01/2022 05:04:44 - INFO - __main__ - Step 380 Global step 380 Train loss 6.67 on epoch=94
06/01/2022 05:04:46 - INFO - __main__ - Step 390 Global step 390 Train loss 6.60 on epoch=97
06/01/2022 05:04:47 - INFO - __main__ - Step 400 Global step 400 Train loss 6.51 on epoch=99
06/01/2022 05:04:53 - INFO - __main__ - Global step 400 Train loss 6.63 Classification-F1 0.0 on epoch=99
06/01/2022 05:04:55 - INFO - __main__ - Step 410 Global step 410 Train loss 6.35 on epoch=102
06/01/2022 05:04:56 - INFO - __main__ - Step 420 Global step 420 Train loss 6.03 on epoch=104
06/01/2022 05:04:57 - INFO - __main__ - Step 430 Global step 430 Train loss 6.23 on epoch=107
06/01/2022 05:04:59 - INFO - __main__ - Step 440 Global step 440 Train loss 6.22 on epoch=109
06/01/2022 05:05:00 - INFO - __main__ - Step 450 Global step 450 Train loss 6.09 on epoch=112
06/01/2022 05:05:12 - INFO - __main__ - Global step 450 Train loss 6.18 Classification-F1 0.0 on epoch=112
06/01/2022 05:05:13 - INFO - __main__ - Step 460 Global step 460 Train loss 5.73 on epoch=114
06/01/2022 05:05:15 - INFO - __main__ - Step 470 Global step 470 Train loss 5.98 on epoch=117
06/01/2022 05:05:16 - INFO - __main__ - Step 480 Global step 480 Train loss 5.87 on epoch=119
06/01/2022 05:05:17 - INFO - __main__ - Step 490 Global step 490 Train loss 5.85 on epoch=122
06/01/2022 05:05:18 - INFO - __main__ - Step 500 Global step 500 Train loss 5.77 on epoch=124
06/01/2022 05:05:30 - INFO - __main__ - Global step 500 Train loss 5.84 Classification-F1 0.0 on epoch=124
06/01/2022 05:05:31 - INFO - __main__ - Step 510 Global step 510 Train loss 5.99 on epoch=127
06/01/2022 05:05:32 - INFO - __main__ - Step 520 Global step 520 Train loss 5.60 on epoch=129
06/01/2022 05:05:33 - INFO - __main__ - Step 530 Global step 530 Train loss 5.78 on epoch=132
06/01/2022 05:05:35 - INFO - __main__ - Step 540 Global step 540 Train loss 5.63 on epoch=134
06/01/2022 05:05:36 - INFO - __main__ - Step 550 Global step 550 Train loss 5.50 on epoch=137
06/01/2022 05:05:45 - INFO - __main__ - Global step 550 Train loss 5.70 Classification-F1 0.0 on epoch=137
06/01/2022 05:05:47 - INFO - __main__ - Step 560 Global step 560 Train loss 5.45 on epoch=139
06/01/2022 05:05:48 - INFO - __main__ - Step 570 Global step 570 Train loss 5.50 on epoch=142
06/01/2022 05:05:49 - INFO - __main__ - Step 580 Global step 580 Train loss 5.34 on epoch=144
06/01/2022 05:05:51 - INFO - __main__ - Step 590 Global step 590 Train loss 5.52 on epoch=147
06/01/2022 05:05:52 - INFO - __main__ - Step 600 Global step 600 Train loss 5.51 on epoch=149
06/01/2022 05:06:00 - INFO - __main__ - Global step 600 Train loss 5.47 Classification-F1 0.0 on epoch=149
06/01/2022 05:06:02 - INFO - __main__ - Step 610 Global step 610 Train loss 5.31 on epoch=152
06/01/2022 05:06:03 - INFO - __main__ - Step 620 Global step 620 Train loss 5.22 on epoch=154
06/01/2022 05:06:04 - INFO - __main__ - Step 630 Global step 630 Train loss 5.23 on epoch=157
06/01/2022 05:06:05 - INFO - __main__ - Step 640 Global step 640 Train loss 5.23 on epoch=159
06/01/2022 05:06:07 - INFO - __main__ - Step 650 Global step 650 Train loss 5.09 on epoch=162
06/01/2022 05:06:20 - INFO - __main__ - Global step 650 Train loss 5.22 Classification-F1 0.0 on epoch=162
06/01/2022 05:06:22 - INFO - __main__ - Step 660 Global step 660 Train loss 4.99 on epoch=164
06/01/2022 05:06:23 - INFO - __main__ - Step 670 Global step 670 Train loss 4.84 on epoch=167
06/01/2022 05:06:24 - INFO - __main__ - Step 680 Global step 680 Train loss 4.68 on epoch=169
06/01/2022 05:06:25 - INFO - __main__ - Step 690 Global step 690 Train loss 4.75 on epoch=172
06/01/2022 05:06:27 - INFO - __main__ - Step 700 Global step 700 Train loss 4.45 on epoch=174
06/01/2022 05:06:35 - INFO - __main__ - Global step 700 Train loss 4.74 Classification-F1 0.0 on epoch=174
06/01/2022 05:06:37 - INFO - __main__ - Step 710 Global step 710 Train loss 4.67 on epoch=177
06/01/2022 05:06:38 - INFO - __main__ - Step 720 Global step 720 Train loss 4.36 on epoch=179
06/01/2022 05:06:39 - INFO - __main__ - Step 730 Global step 730 Train loss 4.45 on epoch=182
06/01/2022 05:06:41 - INFO - __main__ - Step 740 Global step 740 Train loss 4.23 on epoch=184
06/01/2022 05:06:42 - INFO - __main__ - Step 750 Global step 750 Train loss 4.04 on epoch=187
06/01/2022 05:06:45 - INFO - __main__ - Global step 750 Train loss 4.35 Classification-F1 0.0 on epoch=187
06/01/2022 05:06:47 - INFO - __main__ - Step 760 Global step 760 Train loss 4.30 on epoch=189
06/01/2022 05:06:48 - INFO - __main__ - Step 770 Global step 770 Train loss 4.32 on epoch=192
06/01/2022 05:06:49 - INFO - __main__ - Step 780 Global step 780 Train loss 4.06 on epoch=194
06/01/2022 05:06:51 - INFO - __main__ - Step 790 Global step 790 Train loss 4.27 on epoch=197
06/01/2022 05:06:52 - INFO - __main__ - Step 800 Global step 800 Train loss 3.95 on epoch=199
06/01/2022 05:06:55 - INFO - __main__ - Global step 800 Train loss 4.18 Classification-F1 0.05185185185185185 on epoch=199
06/01/2022 05:06:55 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.05185185185185185 on epoch=199, global_step=800
06/01/2022 05:06:56 - INFO - __main__ - Step 810 Global step 810 Train loss 3.90 on epoch=202
06/01/2022 05:06:57 - INFO - __main__ - Step 820 Global step 820 Train loss 3.79 on epoch=204
06/01/2022 05:06:59 - INFO - __main__ - Step 830 Global step 830 Train loss 4.14 on epoch=207
06/01/2022 05:07:00 - INFO - __main__ - Step 840 Global step 840 Train loss 3.68 on epoch=209
06/01/2022 05:07:01 - INFO - __main__ - Step 850 Global step 850 Train loss 3.83 on epoch=212
06/01/2022 05:07:03 - INFO - __main__ - Global step 850 Train loss 3.87 Classification-F1 0.08617131062951496 on epoch=212
06/01/2022 05:07:03 - INFO - __main__ - Saving model with best Classification-F1: 0.05185185185185185 -> 0.08617131062951496 on epoch=212, global_step=850
06/01/2022 05:07:05 - INFO - __main__ - Step 860 Global step 860 Train loss 3.78 on epoch=214
06/01/2022 05:07:06 - INFO - __main__ - Step 870 Global step 870 Train loss 3.88 on epoch=217
06/01/2022 05:07:07 - INFO - __main__ - Step 880 Global step 880 Train loss 3.79 on epoch=219
06/01/2022 05:07:08 - INFO - __main__ - Step 890 Global step 890 Train loss 3.84 on epoch=222
06/01/2022 05:07:10 - INFO - __main__ - Step 900 Global step 900 Train loss 3.68 on epoch=224
06/01/2022 05:07:12 - INFO - __main__ - Global step 900 Train loss 3.79 Classification-F1 0.08978328173374613 on epoch=224
06/01/2022 05:07:12 - INFO - __main__ - Saving model with best Classification-F1: 0.08617131062951496 -> 0.08978328173374613 on epoch=224, global_step=900
06/01/2022 05:07:14 - INFO - __main__ - Step 910 Global step 910 Train loss 3.97 on epoch=227
06/01/2022 05:07:15 - INFO - __main__ - Step 920 Global step 920 Train loss 3.54 on epoch=229
06/01/2022 05:07:16 - INFO - __main__ - Step 930 Global step 930 Train loss 3.65 on epoch=232
06/01/2022 05:07:18 - INFO - __main__ - Step 940 Global step 940 Train loss 3.65 on epoch=234
06/01/2022 05:07:19 - INFO - __main__ - Step 950 Global step 950 Train loss 3.48 on epoch=237
06/01/2022 05:07:19 - INFO - __main__ - Global step 950 Train loss 3.66 Classification-F1 0.1581196581196581 on epoch=237
06/01/2022 05:07:19 - INFO - __main__ - Saving model with best Classification-F1: 0.08978328173374613 -> 0.1581196581196581 on epoch=237, global_step=950
06/01/2022 05:07:21 - INFO - __main__ - Step 960 Global step 960 Train loss 3.28 on epoch=239
06/01/2022 05:07:22 - INFO - __main__ - Step 970 Global step 970 Train loss 3.42 on epoch=242
06/01/2022 05:07:23 - INFO - __main__ - Step 980 Global step 980 Train loss 3.30 on epoch=244
06/01/2022 05:07:25 - INFO - __main__ - Step 990 Global step 990 Train loss 3.46 on epoch=247
06/01/2022 05:07:26 - INFO - __main__ - Step 1000 Global step 1000 Train loss 3.42 on epoch=249
06/01/2022 05:07:26 - INFO - __main__ - Global step 1000 Train loss 3.38 Classification-F1 0.17763157894736842 on epoch=249
06/01/2022 05:07:26 - INFO - __main__ - Saving model with best Classification-F1: 0.1581196581196581 -> 0.17763157894736842 on epoch=249, global_step=1000
06/01/2022 05:07:28 - INFO - __main__ - Step 1010 Global step 1010 Train loss 3.14 on epoch=252
06/01/2022 05:07:29 - INFO - __main__ - Step 1020 Global step 1020 Train loss 3.15 on epoch=254
06/01/2022 05:07:30 - INFO - __main__ - Step 1030 Global step 1030 Train loss 3.24 on epoch=257
06/01/2022 05:07:32 - INFO - __main__ - Step 1040 Global step 1040 Train loss 2.96 on epoch=259
06/01/2022 05:07:33 - INFO - __main__ - Step 1050 Global step 1050 Train loss 3.15 on epoch=262
06/01/2022 05:07:33 - INFO - __main__ - Global step 1050 Train loss 3.13 Classification-F1 0.13067758749069247 on epoch=262
06/01/2022 05:07:35 - INFO - __main__ - Step 1060 Global step 1060 Train loss 3.10 on epoch=264
06/01/2022 05:07:36 - INFO - __main__ - Step 1070 Global step 1070 Train loss 3.11 on epoch=267
06/01/2022 05:07:37 - INFO - __main__ - Step 1080 Global step 1080 Train loss 3.09 on epoch=269
06/01/2022 05:07:38 - INFO - __main__ - Step 1090 Global step 1090 Train loss 3.20 on epoch=272
06/01/2022 05:07:40 - INFO - __main__ - Step 1100 Global step 1100 Train loss 2.79 on epoch=274
06/01/2022 05:07:40 - INFO - __main__ - Global step 1100 Train loss 3.06 Classification-F1 0.1237183868762816 on epoch=274
06/01/2022 05:07:42 - INFO - __main__ - Step 1110 Global step 1110 Train loss 3.00 on epoch=277
06/01/2022 05:07:43 - INFO - __main__ - Step 1120 Global step 1120 Train loss 2.84 on epoch=279
06/01/2022 05:07:44 - INFO - __main__ - Step 1130 Global step 1130 Train loss 3.08 on epoch=282
06/01/2022 05:07:45 - INFO - __main__ - Step 1140 Global step 1140 Train loss 2.70 on epoch=284
06/01/2022 05:07:47 - INFO - __main__ - Step 1150 Global step 1150 Train loss 2.85 on epoch=287
06/01/2022 05:07:47 - INFO - __main__ - Global step 1150 Train loss 2.90 Classification-F1 0.1 on epoch=287
06/01/2022 05:07:48 - INFO - __main__ - Step 1160 Global step 1160 Train loss 2.65 on epoch=289
06/01/2022 05:07:50 - INFO - __main__ - Step 1170 Global step 1170 Train loss 2.82 on epoch=292
06/01/2022 05:07:51 - INFO - __main__ - Step 1180 Global step 1180 Train loss 2.59 on epoch=294
06/01/2022 05:07:52 - INFO - __main__ - Step 1190 Global step 1190 Train loss 2.80 on epoch=297
06/01/2022 05:07:54 - INFO - __main__ - Step 1200 Global step 1200 Train loss 2.48 on epoch=299
06/01/2022 05:07:54 - INFO - __main__ - Global step 1200 Train loss 2.67 Classification-F1 0.1 on epoch=299
06/01/2022 05:07:55 - INFO - __main__ - Step 1210 Global step 1210 Train loss 2.78 on epoch=302
06/01/2022 05:07:57 - INFO - __main__ - Step 1220 Global step 1220 Train loss 2.57 on epoch=304
06/01/2022 05:07:58 - INFO - __main__ - Step 1230 Global step 1230 Train loss 2.66 on epoch=307
06/01/2022 05:07:59 - INFO - __main__ - Step 1240 Global step 1240 Train loss 2.65 on epoch=309
06/01/2022 05:08:01 - INFO - __main__ - Step 1250 Global step 1250 Train loss 2.66 on epoch=312
06/01/2022 05:08:01 - INFO - __main__ - Global step 1250 Train loss 2.66 Classification-F1 0.09615384615384615 on epoch=312
06/01/2022 05:08:02 - INFO - __main__ - Step 1260 Global step 1260 Train loss 2.55 on epoch=314
06/01/2022 05:08:04 - INFO - __main__ - Step 1270 Global step 1270 Train loss 2.57 on epoch=317
06/01/2022 05:08:05 - INFO - __main__ - Step 1280 Global step 1280 Train loss 2.40 on epoch=319
06/01/2022 05:08:06 - INFO - __main__ - Step 1290 Global step 1290 Train loss 2.60 on epoch=322
06/01/2022 05:08:07 - INFO - __main__ - Step 1300 Global step 1300 Train loss 2.34 on epoch=324
06/01/2022 05:08:08 - INFO - __main__ - Global step 1300 Train loss 2.49 Classification-F1 0.1 on epoch=324
06/01/2022 05:08:09 - INFO - __main__ - Step 1310 Global step 1310 Train loss 2.48 on epoch=327
06/01/2022 05:08:10 - INFO - __main__ - Step 1320 Global step 1320 Train loss 2.20 on epoch=329
06/01/2022 05:08:12 - INFO - __main__ - Step 1330 Global step 1330 Train loss 2.37 on epoch=332
06/01/2022 05:08:13 - INFO - __main__ - Step 1340 Global step 1340 Train loss 2.15 on epoch=334
06/01/2022 05:08:14 - INFO - __main__ - Step 1350 Global step 1350 Train loss 2.36 on epoch=337
06/01/2022 05:08:15 - INFO - __main__ - Global step 1350 Train loss 2.31 Classification-F1 0.1 on epoch=337
06/01/2022 05:08:16 - INFO - __main__ - Step 1360 Global step 1360 Train loss 2.29 on epoch=339
06/01/2022 05:08:17 - INFO - __main__ - Step 1370 Global step 1370 Train loss 2.25 on epoch=342
06/01/2022 05:08:19 - INFO - __main__ - Step 1380 Global step 1380 Train loss 2.22 on epoch=344
06/01/2022 05:08:20 - INFO - __main__ - Step 1390 Global step 1390 Train loss 2.24 on epoch=347
06/01/2022 05:08:21 - INFO - __main__ - Step 1400 Global step 1400 Train loss 2.01 on epoch=349
06/01/2022 05:08:22 - INFO - __main__ - Global step 1400 Train loss 2.20 Classification-F1 0.09493670886075949 on epoch=349
06/01/2022 05:08:23 - INFO - __main__ - Step 1410 Global step 1410 Train loss 2.16 on epoch=352
06/01/2022 05:08:24 - INFO - __main__ - Step 1420 Global step 1420 Train loss 2.04 on epoch=354
06/01/2022 05:08:26 - INFO - __main__ - Step 1430 Global step 1430 Train loss 2.24 on epoch=357
06/01/2022 05:08:27 - INFO - __main__ - Step 1440 Global step 1440 Train loss 2.02 on epoch=359
06/01/2022 05:08:28 - INFO - __main__ - Step 1450 Global step 1450 Train loss 2.30 on epoch=362
06/01/2022 05:08:29 - INFO - __main__ - Global step 1450 Train loss 2.15 Classification-F1 0.09493670886075949 on epoch=362
06/01/2022 05:08:30 - INFO - __main__ - Step 1460 Global step 1460 Train loss 2.07 on epoch=364
06/01/2022 05:08:31 - INFO - __main__ - Step 1470 Global step 1470 Train loss 2.00 on epoch=367
06/01/2022 05:08:33 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.97 on epoch=369
06/01/2022 05:08:34 - INFO - __main__ - Step 1490 Global step 1490 Train loss 2.20 on epoch=372
06/01/2022 05:08:35 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.87 on epoch=374
06/01/2022 05:08:36 - INFO - __main__ - Global step 1500 Train loss 2.02 Classification-F1 0.1 on epoch=374
06/01/2022 05:08:37 - INFO - __main__ - Step 1510 Global step 1510 Train loss 2.00 on epoch=377
06/01/2022 05:08:38 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.93 on epoch=379
06/01/2022 05:08:40 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.89 on epoch=382
06/01/2022 05:08:41 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.99 on epoch=384
06/01/2022 05:08:42 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.93 on epoch=387
06/01/2022 05:08:43 - INFO - __main__ - Global step 1550 Train loss 1.95 Classification-F1 0.13067758749069247 on epoch=387
06/01/2022 05:08:44 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.78 on epoch=389
06/01/2022 05:08:45 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.85 on epoch=392
06/01/2022 05:08:46 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.84 on epoch=394
06/01/2022 05:08:48 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.94 on epoch=397
06/01/2022 05:08:49 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.66 on epoch=399
06/01/2022 05:08:50 - INFO - __main__ - Global step 1600 Train loss 1.81 Classification-F1 0.1238095238095238 on epoch=399
06/01/2022 05:08:51 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.82 on epoch=402
06/01/2022 05:08:52 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.70 on epoch=404
06/01/2022 05:08:53 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.74 on epoch=407
06/01/2022 05:08:55 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.76 on epoch=409
06/01/2022 05:08:56 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.51 on epoch=412
06/01/2022 05:08:56 - INFO - __main__ - Global step 1650 Train loss 1.71 Classification-F1 0.1237183868762816 on epoch=412
06/01/2022 05:08:58 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.70 on epoch=414
06/01/2022 05:08:59 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.67 on epoch=417
06/01/2022 05:09:00 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.50 on epoch=419
06/01/2022 05:09:02 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.51 on epoch=422
06/01/2022 05:09:03 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.50 on epoch=424
06/01/2022 05:09:03 - INFO - __main__ - Global step 1700 Train loss 1.58 Classification-F1 0.10234192037470727 on epoch=424
06/01/2022 05:09:05 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.61 on epoch=427
06/01/2022 05:09:06 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.52 on epoch=429
06/01/2022 05:09:07 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.40 on epoch=432
06/01/2022 05:09:08 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.55 on epoch=434
06/01/2022 05:09:10 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.48 on epoch=437
06/01/2022 05:09:10 - INFO - __main__ - Global step 1750 Train loss 1.51 Classification-F1 0.1576923076923077 on epoch=437
06/01/2022 05:09:12 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.42 on epoch=439
06/01/2022 05:09:13 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.52 on epoch=442
06/01/2022 05:09:14 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.47 on epoch=444
06/01/2022 05:09:15 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.50 on epoch=447
06/01/2022 05:09:17 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.46 on epoch=449
06/01/2022 05:09:17 - INFO - __main__ - Global step 1800 Train loss 1.48 Classification-F1 0.1500341763499658 on epoch=449
06/01/2022 05:09:18 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.49 on epoch=452
06/01/2022 05:09:20 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.31 on epoch=454
06/01/2022 05:09:21 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.43 on epoch=457
06/01/2022 05:09:22 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.36 on epoch=459
06/01/2022 05:09:24 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.38 on epoch=462
06/01/2022 05:09:24 - INFO - __main__ - Global step 1850 Train loss 1.39 Classification-F1 0.11703296703296702 on epoch=462
06/01/2022 05:09:25 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.33 on epoch=464
06/01/2022 05:09:27 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.28 on epoch=467
06/01/2022 05:09:28 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.37 on epoch=469
06/01/2022 05:09:29 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.56 on epoch=472
06/01/2022 05:09:30 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.26 on epoch=474
06/01/2022 05:09:31 - INFO - __main__ - Global step 1900 Train loss 1.36 Classification-F1 0.08974358974358974 on epoch=474
06/01/2022 05:09:32 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.19 on epoch=477
06/01/2022 05:09:34 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.25 on epoch=479
06/01/2022 05:09:35 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.36 on epoch=482
06/01/2022 05:09:36 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.21 on epoch=484
06/01/2022 05:09:37 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.32 on epoch=487
06/01/2022 05:09:38 - INFO - __main__ - Global step 1950 Train loss 1.27 Classification-F1 0.1486842105263158 on epoch=487
06/01/2022 05:09:39 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.11 on epoch=489
06/01/2022 05:09:41 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.24 on epoch=492
06/01/2022 05:09:42 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.35 on epoch=494
06/01/2022 05:09:43 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.22 on epoch=497
06/01/2022 05:09:44 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.29 on epoch=499
06/01/2022 05:09:45 - INFO - __main__ - Global step 2000 Train loss 1.24 Classification-F1 0.1 on epoch=499
06/01/2022 05:09:46 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.11 on epoch=502
06/01/2022 05:09:47 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.22 on epoch=504
06/01/2022 05:09:49 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.21 on epoch=507
06/01/2022 05:09:50 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.26 on epoch=509
06/01/2022 05:09:51 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.15 on epoch=512
06/01/2022 05:09:52 - INFO - __main__ - Global step 2050 Train loss 1.19 Classification-F1 0.1 on epoch=512
06/01/2022 05:09:53 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.22 on epoch=514
06/01/2022 05:09:54 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.19 on epoch=517
06/01/2022 05:09:56 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.30 on epoch=519
06/01/2022 05:09:57 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.31 on epoch=522
06/01/2022 05:09:58 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.13 on epoch=524
06/01/2022 05:09:59 - INFO - __main__ - Global step 2100 Train loss 1.23 Classification-F1 0.1 on epoch=524
06/01/2022 05:10:00 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.23 on epoch=527
06/01/2022 05:10:01 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.16 on epoch=529
06/01/2022 05:10:03 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.32 on epoch=532
06/01/2022 05:10:04 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.18 on epoch=534
06/01/2022 05:10:05 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.26 on epoch=537
06/01/2022 05:10:06 - INFO - __main__ - Global step 2150 Train loss 1.23 Classification-F1 0.19165085388994307 on epoch=537
06/01/2022 05:10:06 - INFO - __main__ - Saving model with best Classification-F1: 0.17763157894736842 -> 0.19165085388994307 on epoch=537, global_step=2150
06/01/2022 05:10:07 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.26 on epoch=539
06/01/2022 05:10:08 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.33 on epoch=542
06/01/2022 05:10:10 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.31 on epoch=544
06/01/2022 05:10:11 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.16 on epoch=547
06/01/2022 05:10:12 - INFO - __main__ - Step 2200 Global step 2200 Train loss 1.18 on epoch=549
06/01/2022 05:10:13 - INFO - __main__ - Global step 2200 Train loss 1.25 Classification-F1 0.20975609756097563 on epoch=549
06/01/2022 05:10:13 - INFO - __main__ - Saving model with best Classification-F1: 0.19165085388994307 -> 0.20975609756097563 on epoch=549, global_step=2200
06/01/2022 05:10:14 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.30 on epoch=552
06/01/2022 05:10:15 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.30 on epoch=554
06/01/2022 05:10:16 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.21 on epoch=557
06/01/2022 05:10:18 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.12 on epoch=559
06/01/2022 05:10:19 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.19 on epoch=562
06/01/2022 05:10:20 - INFO - __main__ - Global step 2250 Train loss 1.22 Classification-F1 0.17341430499325233 on epoch=562
06/01/2022 05:10:21 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.15 on epoch=564
06/01/2022 05:10:22 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.24 on epoch=567
06/01/2022 05:10:23 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.13 on epoch=569
06/01/2022 05:10:25 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.16 on epoch=572
06/01/2022 05:10:26 - INFO - __main__ - Step 2300 Global step 2300 Train loss 1.15 on epoch=574
06/01/2022 05:10:27 - INFO - __main__ - Global step 2300 Train loss 1.17 Classification-F1 0.20458606313281716 on epoch=574
06/01/2022 05:10:28 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.15 on epoch=577
06/01/2022 05:10:29 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.16 on epoch=579
06/01/2022 05:10:30 - INFO - __main__ - Step 2330 Global step 2330 Train loss 1.14 on epoch=582
06/01/2022 05:10:32 - INFO - __main__ - Step 2340 Global step 2340 Train loss 1.05 on epoch=584
06/01/2022 05:10:33 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.21 on epoch=587
06/01/2022 05:10:33 - INFO - __main__ - Global step 2350 Train loss 1.14 Classification-F1 0.26134301270417426 on epoch=587
06/01/2022 05:10:34 - INFO - __main__ - Saving model with best Classification-F1: 0.20975609756097563 -> 0.26134301270417426 on epoch=587, global_step=2350
06/01/2022 05:10:35 - INFO - __main__ - Step 2360 Global step 2360 Train loss 1.16 on epoch=589
06/01/2022 05:10:36 - INFO - __main__ - Step 2370 Global step 2370 Train loss 1.19 on epoch=592
06/01/2022 05:10:37 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.16 on epoch=594
06/01/2022 05:10:39 - INFO - __main__ - Step 2390 Global step 2390 Train loss 1.18 on epoch=597
06/01/2022 05:10:40 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.22 on epoch=599
06/01/2022 05:10:40 - INFO - __main__ - Global step 2400 Train loss 1.18 Classification-F1 0.16366443643849718 on epoch=599
06/01/2022 05:10:42 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.12 on epoch=602
06/01/2022 05:10:43 - INFO - __main__ - Step 2420 Global step 2420 Train loss 1.23 on epoch=604
06/01/2022 05:10:44 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.22 on epoch=607
06/01/2022 05:10:46 - INFO - __main__ - Step 2440 Global step 2440 Train loss 1.17 on epoch=609
06/01/2022 05:10:47 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.12 on epoch=612
06/01/2022 05:10:47 - INFO - __main__ - Global step 2450 Train loss 1.17 Classification-F1 0.15425848719475876 on epoch=612
06/01/2022 05:10:49 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.06 on epoch=614
06/01/2022 05:10:50 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.00 on epoch=617
06/01/2022 05:10:51 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.08 on epoch=619
06/01/2022 05:10:53 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.10 on epoch=622
06/01/2022 05:10:54 - INFO - __main__ - Step 2500 Global step 2500 Train loss 1.11 on epoch=624
06/01/2022 05:10:54 - INFO - __main__ - Global step 2500 Train loss 1.07 Classification-F1 0.16277641277641278 on epoch=624
06/01/2022 05:10:56 - INFO - __main__ - Step 2510 Global step 2510 Train loss 1.09 on epoch=627
06/01/2022 05:10:57 - INFO - __main__ - Step 2520 Global step 2520 Train loss 1.07 on epoch=629
06/01/2022 05:10:58 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.10 on epoch=632
06/01/2022 05:10:59 - INFO - __main__ - Step 2540 Global step 2540 Train loss 1.10 on epoch=634
06/01/2022 05:11:01 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.99 on epoch=637
06/01/2022 05:11:01 - INFO - __main__ - Global step 2550 Train loss 1.07 Classification-F1 0.09493670886075949 on epoch=637
06/01/2022 05:11:02 - INFO - __main__ - Step 2560 Global step 2560 Train loss 1.15 on epoch=639
06/01/2022 05:11:04 - INFO - __main__ - Step 2570 Global step 2570 Train loss 1.13 on epoch=642
06/01/2022 05:11:05 - INFO - __main__ - Step 2580 Global step 2580 Train loss 1.16 on epoch=644
06/01/2022 05:11:06 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.06 on epoch=647
06/01/2022 05:11:08 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.13 on epoch=649
06/01/2022 05:11:08 - INFO - __main__ - Global step 2600 Train loss 1.13 Classification-F1 0.13067758749069247 on epoch=649
06/01/2022 05:11:09 - INFO - __main__ - Step 2610 Global step 2610 Train loss 1.21 on epoch=652
06/01/2022 05:11:11 - INFO - __main__ - Step 2620 Global step 2620 Train loss 1.24 on epoch=654
06/01/2022 05:11:12 - INFO - __main__ - Step 2630 Global step 2630 Train loss 1.13 on epoch=657
06/01/2022 05:11:13 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.10 on epoch=659
06/01/2022 05:11:15 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.07 on epoch=662
06/01/2022 05:11:15 - INFO - __main__ - Global step 2650 Train loss 1.15 Classification-F1 0.15054945054945054 on epoch=662
06/01/2022 05:11:16 - INFO - __main__ - Step 2660 Global step 2660 Train loss 1.16 on epoch=664
06/01/2022 05:11:18 - INFO - __main__ - Step 2670 Global step 2670 Train loss 1.16 on epoch=667
06/01/2022 05:11:19 - INFO - __main__ - Step 2680 Global step 2680 Train loss 1.07 on epoch=669
06/01/2022 05:11:20 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.98 on epoch=672
06/01/2022 05:11:21 - INFO - __main__ - Step 2700 Global step 2700 Train loss 1.03 on epoch=674
06/01/2022 05:11:22 - INFO - __main__ - Global step 2700 Train loss 1.08 Classification-F1 0.17954911433172302 on epoch=674
06/01/2022 05:11:23 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.20 on epoch=677
06/01/2022 05:11:25 - INFO - __main__ - Step 2720 Global step 2720 Train loss 1.06 on epoch=679
06/01/2022 05:11:26 - INFO - __main__ - Step 2730 Global step 2730 Train loss 1.11 on epoch=682
06/01/2022 05:11:27 - INFO - __main__ - Step 2740 Global step 2740 Train loss 1.13 on epoch=684
06/01/2022 05:11:28 - INFO - __main__ - Step 2750 Global step 2750 Train loss 1.14 on epoch=687
06/01/2022 05:11:29 - INFO - __main__ - Global step 2750 Train loss 1.13 Classification-F1 0.1 on epoch=687
06/01/2022 05:11:30 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.15 on epoch=689
06/01/2022 05:11:31 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.26 on epoch=692
06/01/2022 05:11:33 - INFO - __main__ - Step 2780 Global step 2780 Train loss 1.11 on epoch=694
06/01/2022 05:11:34 - INFO - __main__ - Step 2790 Global step 2790 Train loss 1.11 on epoch=697
06/01/2022 05:11:35 - INFO - __main__ - Step 2800 Global step 2800 Train loss 1.15 on epoch=699
06/01/2022 05:11:36 - INFO - __main__ - Global step 2800 Train loss 1.15 Classification-F1 0.1 on epoch=699
06/01/2022 05:11:37 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.12 on epoch=702
06/01/2022 05:11:38 - INFO - __main__ - Step 2820 Global step 2820 Train loss 1.07 on epoch=704
06/01/2022 05:11:40 - INFO - __main__ - Step 2830 Global step 2830 Train loss 1.19 on epoch=707
06/01/2022 05:11:41 - INFO - __main__ - Step 2840 Global step 2840 Train loss 1.09 on epoch=709
06/01/2022 05:11:42 - INFO - __main__ - Step 2850 Global step 2850 Train loss 1.12 on epoch=712
06/01/2022 05:11:43 - INFO - __main__ - Global step 2850 Train loss 1.12 Classification-F1 0.1 on epoch=712
06/01/2022 05:11:44 - INFO - __main__ - Step 2860 Global step 2860 Train loss 1.12 on epoch=714
06/01/2022 05:11:45 - INFO - __main__ - Step 2870 Global step 2870 Train loss 1.03 on epoch=717
06/01/2022 05:11:47 - INFO - __main__ - Step 2880 Global step 2880 Train loss 1.05 on epoch=719
06/01/2022 05:11:48 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.22 on epoch=722
06/01/2022 05:11:49 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.06 on epoch=724
06/01/2022 05:11:50 - INFO - __main__ - Global step 2900 Train loss 1.09 Classification-F1 0.1 on epoch=724
06/01/2022 05:11:51 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.03 on epoch=727
06/01/2022 05:11:52 - INFO - __main__ - Step 2920 Global step 2920 Train loss 1.17 on epoch=729
06/01/2022 05:11:54 - INFO - __main__ - Step 2930 Global step 2930 Train loss 1.18 on epoch=732
06/01/2022 05:11:55 - INFO - __main__ - Step 2940 Global step 2940 Train loss 1.07 on epoch=734
06/01/2022 05:11:56 - INFO - __main__ - Step 2950 Global step 2950 Train loss 1.06 on epoch=737
06/01/2022 05:11:57 - INFO - __main__ - Global step 2950 Train loss 1.10 Classification-F1 0.1 on epoch=737
06/01/2022 05:11:58 - INFO - __main__ - Step 2960 Global step 2960 Train loss 1.17 on epoch=739
06/01/2022 05:11:59 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.19 on epoch=742
06/01/2022 05:12:01 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.09 on epoch=744
06/01/2022 05:12:02 - INFO - __main__ - Step 2990 Global step 2990 Train loss 1.09 on epoch=747
06/01/2022 05:12:03 - INFO - __main__ - Step 3000 Global step 3000 Train loss 1.05 on epoch=749
06/01/2022 05:12:04 - INFO - __main__ - Global step 3000 Train loss 1.12 Classification-F1 0.10126582278481013 on epoch=749
06/01/2022 05:12:04 - INFO - __main__ - save last model!
06/01/2022 05:12:04 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/01/2022 05:12:04 - INFO - __main__ - Start tokenizing ... 5509 instances
06/01/2022 05:12:04 - INFO - __main__ - Printing 3 examples
06/01/2022 05:12:04 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/01/2022 05:12:04 - INFO - __main__ - ['others']
06/01/2022 05:12:04 - INFO - __main__ -  [emo] what you like very little things ok
06/01/2022 05:12:04 - INFO - __main__ - ['others']
06/01/2022 05:12:04 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/01/2022 05:12:04 - INFO - __main__ - ['others']
06/01/2022 05:12:04 - INFO - __main__ - Tokenizing Input ...
06/01/2022 05:12:06 - INFO - __main__ - Tokenizing Output ...
06/01/2022 05:12:11 - INFO - __main__ - Loaded 5509 examples from test data
06/01/2022 05:12:56 - INFO - __main__ - Saved prediction in models/T5-base-reptile-cls2cls-3e-5-2-5000-5e-1-10/singletask-emo/emo_16_87_0.2_8_predictions.txt
06/01/2022 05:12:56 - INFO - __main__ - Classification-F1 on test data: 0.0284
06/01/2022 05:12:56 - INFO - __main__ - prefix=emo_16_87, lr=0.2, bsz=8, dev_performance=0.26134301270417426, test_performance=0.028374428379406725
