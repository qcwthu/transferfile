05/27/2022 21:27:56 - INFO - __main__ - Namespace(task_dir='data_128/dbpedia_14/', task_name='dbpedia_14', identifier='T5-large-multitask-cls2cls-5e-1-4-20-down128shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-multitask-cls2cls-5e-1-4-20-down128shot/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-multitask-cls2cls-5e-1-4-20/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='4,5')
05/27/2022 21:27:56 - INFO - __main__ - models/T5-large-multitask-cls2cls-5e-1-4-20-down128shot/singletask-dbpedia_14
05/27/2022 21:27:56 - INFO - __main__ - Namespace(task_dir='data_128/dbpedia_14/', task_name='dbpedia_14', identifier='T5-large-multitask-cls2cls-5e-1-4-20-down128shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-multitask-cls2cls-5e-1-4-20-down128shot/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-multitask-cls2cls-5e-1-4-20/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='4,5')
05/27/2022 21:27:56 - INFO - __main__ - models/T5-large-multitask-cls2cls-5e-1-4-20-down128shot/singletask-dbpedia_14
05/27/2022 21:27:58 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
05/27/2022 21:27:58 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
05/27/2022 21:27:58 - INFO - __main__ - args.device: cuda:0
05/27/2022 21:27:58 - INFO - __main__ - Using 2 gpus
05/27/2022 21:27:58 - INFO - __main__ - Fine-tuning the following samples: ['dbpedia_14_128_100', 'dbpedia_14_128_13', 'dbpedia_14_128_21', 'dbpedia_14_128_42', 'dbpedia_14_128_87']
05/27/2022 21:27:58 - INFO - __main__ - args.device: cuda:1
05/27/2022 21:27:58 - INFO - __main__ - Using 2 gpus
05/27/2022 21:27:58 - INFO - __main__ - Fine-tuning the following samples: ['dbpedia_14_128_100', 'dbpedia_14_128_13', 'dbpedia_14_128_21', 'dbpedia_14_128_42', 'dbpedia_14_128_87']
05/27/2022 21:28:02 - INFO - __main__ - Running ... prefix=dbpedia_14_128_100, lr=0.5, bsz=8 ...
05/27/2022 21:28:03 - INFO - __main__ - Start tokenizing ... 1792 instances
05/27/2022 21:28:03 - INFO - __main__ - Printing 3 examples
05/27/2022 21:28:03 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/27/2022 21:28:03 - INFO - __main__ - ['Animal']
05/27/2022 21:28:03 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/27/2022 21:28:03 - INFO - __main__ - ['Animal']
05/27/2022 21:28:03 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/27/2022 21:28:03 - INFO - __main__ - ['Animal']
05/27/2022 21:28:03 - INFO - __main__ - Tokenizing Input ...
05/27/2022 21:28:03 - INFO - __main__ - Start tokenizing ... 1792 instances
05/27/2022 21:28:03 - INFO - __main__ - Printing 3 examples
05/27/2022 21:28:03 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/27/2022 21:28:03 - INFO - __main__ - ['Animal']
05/27/2022 21:28:03 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/27/2022 21:28:03 - INFO - __main__ - ['Animal']
05/27/2022 21:28:03 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/27/2022 21:28:03 - INFO - __main__ - ['Animal']
05/27/2022 21:28:03 - INFO - __main__ - Tokenizing Input ...
05/27/2022 21:28:04 - INFO - __main__ - Tokenizing Output ...
05/27/2022 21:28:04 - INFO - __main__ - Tokenizing Output ...
05/27/2022 21:28:06 - INFO - __main__ - Loaded 1792 examples from train data
05/27/2022 21:28:06 - INFO - __main__ - Loaded 1792 examples from train data
05/27/2022 21:28:06 - INFO - __main__ - Start tokenizing ... 1792 instances
05/27/2022 21:28:06 - INFO - __main__ - Start tokenizing ... 1792 instances
05/27/2022 21:28:06 - INFO - __main__ - Printing 3 examples
05/27/2022 21:28:06 - INFO - __main__ -  [dbpedia_14] Palaephatus fusciterminus is a moth of the Palaephatidae family. It is found in the Valdivian forests of southern Argentina and Chile.The length of the forewings is 10-12 mm for males and 10.5-11.5 mm for females. Adults have a buff to brown head and thorax and dark brownish fuscous forewings with a pale buff hindmargin. They are on wing from October to March possibly in multiple generations per year.
05/27/2022 21:28:06 - INFO - __main__ - ['Animal']
05/27/2022 21:28:06 - INFO - __main__ -  [dbpedia_14] Labus is an indomalayan genus of potter wasps.
05/27/2022 21:28:06 - INFO - __main__ - ['Animal']
05/27/2022 21:28:06 - INFO - __main__ -  [dbpedia_14] Trifurcula beirnei is a moth of the Nepticulidae family. It is found in Great Britain Denmark and parts of Germany and Poland Austria the Czech Republic Slovakia and Hungary. It is also found in the Volga and Ural region of Russia.The wingspan is 8–11 mm. Adults are on wing from the end of June to late September.The larvae feed on Genista species including Genista tinctoria Genista germanica and Genista pilosa.
05/27/2022 21:28:06 - INFO - __main__ - ['Animal']
05/27/2022 21:28:06 - INFO - __main__ - Printing 3 examples
05/27/2022 21:28:06 - INFO - __main__ -  [dbpedia_14] Palaephatus fusciterminus is a moth of the Palaephatidae family. It is found in the Valdivian forests of southern Argentina and Chile.The length of the forewings is 10-12 mm for males and 10.5-11.5 mm for females. Adults have a buff to brown head and thorax and dark brownish fuscous forewings with a pale buff hindmargin. They are on wing from October to March possibly in multiple generations per year.
05/27/2022 21:28:06 - INFO - __main__ - ['Animal']
05/27/2022 21:28:06 - INFO - __main__ -  [dbpedia_14] Labus is an indomalayan genus of potter wasps.
05/27/2022 21:28:06 - INFO - __main__ - ['Animal']
05/27/2022 21:28:06 - INFO - __main__ -  [dbpedia_14] Trifurcula beirnei is a moth of the Nepticulidae family. It is found in Great Britain Denmark and parts of Germany and Poland Austria the Czech Republic Slovakia and Hungary. It is also found in the Volga and Ural region of Russia.The wingspan is 8–11 mm. Adults are on wing from the end of June to late September.The larvae feed on Genista species including Genista tinctoria Genista germanica and Genista pilosa.
05/27/2022 21:28:06 - INFO - __main__ - Tokenizing Input ...
05/27/2022 21:28:06 - INFO - __main__ - ['Animal']
05/27/2022 21:28:06 - INFO - __main__ - Tokenizing Input ...
05/27/2022 21:28:07 - INFO - __main__ - Tokenizing Output ...
05/27/2022 21:28:07 - INFO - __main__ - Tokenizing Output ...
05/27/2022 21:28:09 - INFO - __main__ - Loaded 1792 examples from dev data
05/27/2022 21:28:09 - INFO - __main__ - Loaded 1792 examples from dev data
05/27/2022 21:28:27 - INFO - __main__ - load prompt embedding from ckpt
05/27/2022 21:28:27 - INFO - __main__ - load prompt embedding from ckpt
05/27/2022 21:28:28 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/27/2022 21:28:28 - INFO - __main__ - Starting training!
05/27/2022 21:28:32 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/27/2022 21:28:32 - INFO - __main__ - Starting training!
05/27/2022 21:28:36 - INFO - __main__ - Step 10 Global step 10 Train loss 6.83 on epoch=0
05/27/2022 21:28:39 - INFO - __main__ - Step 20 Global step 20 Train loss 4.85 on epoch=0
05/27/2022 21:28:41 - INFO - __main__ - Step 30 Global step 30 Train loss 3.77 on epoch=0
05/27/2022 21:28:44 - INFO - __main__ - Step 40 Global step 40 Train loss 3.43 on epoch=0
05/27/2022 21:28:47 - INFO - __main__ - Step 50 Global step 50 Train loss 2.91 on epoch=0
05/27/2022 21:29:40 - INFO - __main__ - Global step 50 Train loss 4.36 Classification-F1 0.01686720888122576 on epoch=0
05/27/2022 21:29:40 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.01686720888122576 on epoch=0, global_step=50
05/27/2022 21:29:42 - INFO - __main__ - Step 60 Global step 60 Train loss 2.27 on epoch=0
05/27/2022 21:29:45 - INFO - __main__ - Step 70 Global step 70 Train loss 2.19 on epoch=0
05/27/2022 21:29:48 - INFO - __main__ - Step 80 Global step 80 Train loss 2.13 on epoch=0
05/27/2022 21:29:50 - INFO - __main__ - Step 90 Global step 90 Train loss 2.00 on epoch=0
05/27/2022 21:29:53 - INFO - __main__ - Step 100 Global step 100 Train loss 1.77 on epoch=0
05/27/2022 21:30:41 - INFO - __main__ - Global step 100 Train loss 2.07 Classification-F1 0.045527750656908526 on epoch=0
05/27/2022 21:30:41 - INFO - __main__ - Saving model with best Classification-F1: 0.01686720888122576 -> 0.045527750656908526 on epoch=0, global_step=100
05/27/2022 21:30:44 - INFO - __main__ - Step 110 Global step 110 Train loss 1.73 on epoch=0
05/27/2022 21:30:46 - INFO - __main__ - Step 120 Global step 120 Train loss 1.58 on epoch=1
05/27/2022 21:30:49 - INFO - __main__ - Step 130 Global step 130 Train loss 1.44 on epoch=1
05/27/2022 21:30:52 - INFO - __main__ - Step 140 Global step 140 Train loss 1.17 on epoch=1
05/27/2022 21:30:54 - INFO - __main__ - Step 150 Global step 150 Train loss 1.09 on epoch=1
05/27/2022 21:31:40 - INFO - __main__ - Global step 150 Train loss 1.40 Classification-F1 0.1293864402043676 on epoch=1
05/27/2022 21:31:40 - INFO - __main__ - Saving model with best Classification-F1: 0.045527750656908526 -> 0.1293864402043676 on epoch=1, global_step=150
05/27/2022 21:31:43 - INFO - __main__ - Step 160 Global step 160 Train loss 1.07 on epoch=1
05/27/2022 21:31:45 - INFO - __main__ - Step 170 Global step 170 Train loss 0.86 on epoch=1
05/27/2022 21:31:48 - INFO - __main__ - Step 180 Global step 180 Train loss 0.68 on epoch=1
05/27/2022 21:31:51 - INFO - __main__ - Step 190 Global step 190 Train loss 0.67 on epoch=1
05/27/2022 21:31:53 - INFO - __main__ - Step 200 Global step 200 Train loss 0.66 on epoch=1
05/27/2022 21:32:43 - INFO - __main__ - Global step 200 Train loss 0.79 Classification-F1 0.21691294695760582 on epoch=1
05/27/2022 21:32:43 - INFO - __main__ - Saving model with best Classification-F1: 0.1293864402043676 -> 0.21691294695760582 on epoch=1, global_step=200
05/27/2022 21:32:45 - INFO - __main__ - Step 210 Global step 210 Train loss 0.59 on epoch=1
05/27/2022 21:32:48 - INFO - __main__ - Step 220 Global step 220 Train loss 0.53 on epoch=1
05/27/2022 21:32:51 - INFO - __main__ - Step 230 Global step 230 Train loss 0.49 on epoch=2
05/27/2022 21:32:53 - INFO - __main__ - Step 240 Global step 240 Train loss 0.36 on epoch=2
05/27/2022 21:32:56 - INFO - __main__ - Step 250 Global step 250 Train loss 0.55 on epoch=2
05/27/2022 21:33:48 - INFO - __main__ - Global step 250 Train loss 0.51 Classification-F1 0.332112445253596 on epoch=2
05/27/2022 21:33:48 - INFO - __main__ - Saving model with best Classification-F1: 0.21691294695760582 -> 0.332112445253596 on epoch=2, global_step=250
05/27/2022 21:33:51 - INFO - __main__ - Step 260 Global step 260 Train loss 0.44 on epoch=2
05/27/2022 21:33:53 - INFO - __main__ - Step 270 Global step 270 Train loss 0.45 on epoch=2
05/27/2022 21:33:56 - INFO - __main__ - Step 280 Global step 280 Train loss 0.40 on epoch=2
05/27/2022 21:33:59 - INFO - __main__ - Step 290 Global step 290 Train loss 0.29 on epoch=2
05/27/2022 21:34:01 - INFO - __main__ - Step 300 Global step 300 Train loss 0.41 on epoch=2
05/27/2022 21:34:54 - INFO - __main__ - Global step 300 Train loss 0.40 Classification-F1 0.38607967843293134 on epoch=2
05/27/2022 21:34:54 - INFO - __main__ - Saving model with best Classification-F1: 0.332112445253596 -> 0.38607967843293134 on epoch=2, global_step=300
05/27/2022 21:34:57 - INFO - __main__ - Step 310 Global step 310 Train loss 0.28 on epoch=2
05/27/2022 21:34:59 - INFO - __main__ - Step 320 Global step 320 Train loss 0.42 on epoch=2
05/27/2022 21:35:02 - INFO - __main__ - Step 330 Global step 330 Train loss 0.34 on epoch=2
05/27/2022 21:35:04 - INFO - __main__ - Step 340 Global step 340 Train loss 0.26 on epoch=3
05/27/2022 21:35:07 - INFO - __main__ - Step 350 Global step 350 Train loss 0.30 on epoch=3
05/27/2022 21:36:00 - INFO - __main__ - Global step 350 Train loss 0.32 Classification-F1 0.37511532795124647 on epoch=3
05/27/2022 21:36:02 - INFO - __main__ - Step 360 Global step 360 Train loss 0.34 on epoch=3
05/27/2022 21:36:05 - INFO - __main__ - Step 370 Global step 370 Train loss 0.33 on epoch=3
05/27/2022 21:36:07 - INFO - __main__ - Step 380 Global step 380 Train loss 0.27 on epoch=3
05/27/2022 21:36:10 - INFO - __main__ - Step 390 Global step 390 Train loss 0.29 on epoch=3
05/27/2022 21:36:13 - INFO - __main__ - Step 400 Global step 400 Train loss 0.28 on epoch=3
05/27/2022 21:37:05 - INFO - __main__ - Global step 400 Train loss 0.30 Classification-F1 0.42055344395595484 on epoch=3
05/27/2022 21:37:05 - INFO - __main__ - Saving model with best Classification-F1: 0.38607967843293134 -> 0.42055344395595484 on epoch=3, global_step=400
05/27/2022 21:37:08 - INFO - __main__ - Step 410 Global step 410 Train loss 0.23 on epoch=3
05/27/2022 21:37:10 - INFO - __main__ - Step 420 Global step 420 Train loss 0.24 on epoch=3
05/27/2022 21:37:13 - INFO - __main__ - Step 430 Global step 430 Train loss 0.28 on epoch=3
05/27/2022 21:37:16 - INFO - __main__ - Step 440 Global step 440 Train loss 0.21 on epoch=3
05/27/2022 21:37:18 - INFO - __main__ - Step 450 Global step 450 Train loss 0.21 on epoch=4
05/27/2022 21:38:09 - INFO - __main__ - Global step 450 Train loss 0.23 Classification-F1 0.3477667119601576 on epoch=4
05/27/2022 21:38:11 - INFO - __main__ - Step 460 Global step 460 Train loss 0.17 on epoch=4
05/27/2022 21:38:14 - INFO - __main__ - Step 470 Global step 470 Train loss 0.26 on epoch=4
05/27/2022 21:38:17 - INFO - __main__ - Step 480 Global step 480 Train loss 0.22 on epoch=4
05/27/2022 21:38:19 - INFO - __main__ - Step 490 Global step 490 Train loss 0.20 on epoch=4
05/27/2022 21:38:22 - INFO - __main__ - Step 500 Global step 500 Train loss 0.19 on epoch=4
05/27/2022 21:39:13 - INFO - __main__ - Global step 500 Train loss 0.21 Classification-F1 0.4706707274335791 on epoch=4
05/27/2022 21:39:13 - INFO - __main__ - Saving model with best Classification-F1: 0.42055344395595484 -> 0.4706707274335791 on epoch=4, global_step=500
05/27/2022 21:39:16 - INFO - __main__ - Step 510 Global step 510 Train loss 0.19 on epoch=4
05/27/2022 21:39:18 - INFO - __main__ - Step 520 Global step 520 Train loss 0.23 on epoch=4
05/27/2022 21:39:21 - INFO - __main__ - Step 530 Global step 530 Train loss 0.14 on epoch=4
05/27/2022 21:39:24 - INFO - __main__ - Step 540 Global step 540 Train loss 0.23 on epoch=4
05/27/2022 21:39:26 - INFO - __main__ - Step 550 Global step 550 Train loss 0.18 on epoch=4
05/27/2022 21:40:19 - INFO - __main__ - Global step 550 Train loss 0.20 Classification-F1 0.4572228060500731 on epoch=4
05/27/2022 21:40:21 - INFO - __main__ - Step 560 Global step 560 Train loss 0.16 on epoch=4
05/27/2022 21:40:24 - INFO - __main__ - Step 570 Global step 570 Train loss 0.20 on epoch=5
05/27/2022 21:40:26 - INFO - __main__ - Step 580 Global step 580 Train loss 0.16 on epoch=5
05/27/2022 21:40:29 - INFO - __main__ - Step 590 Global step 590 Train loss 0.19 on epoch=5
05/27/2022 21:40:32 - INFO - __main__ - Step 600 Global step 600 Train loss 0.18 on epoch=5
05/27/2022 21:41:22 - INFO - __main__ - Global step 600 Train loss 0.18 Classification-F1 0.44420059201081086 on epoch=5
05/27/2022 21:41:25 - INFO - __main__ - Step 610 Global step 610 Train loss 0.15 on epoch=5
05/27/2022 21:41:28 - INFO - __main__ - Step 620 Global step 620 Train loss 0.15 on epoch=5
05/27/2022 21:41:30 - INFO - __main__ - Step 630 Global step 630 Train loss 0.18 on epoch=5
05/27/2022 21:41:33 - INFO - __main__ - Step 640 Global step 640 Train loss 0.16 on epoch=5
05/27/2022 21:41:36 - INFO - __main__ - Step 650 Global step 650 Train loss 0.28 on epoch=5
05/27/2022 21:42:27 - INFO - __main__ - Global step 650 Train loss 0.18 Classification-F1 0.5508324611301413 on epoch=5
05/27/2022 21:42:27 - INFO - __main__ - Saving model with best Classification-F1: 0.4706707274335791 -> 0.5508324611301413 on epoch=5, global_step=650
05/27/2022 21:42:30 - INFO - __main__ - Step 660 Global step 660 Train loss 0.17 on epoch=5
05/27/2022 21:42:32 - INFO - __main__ - Step 670 Global step 670 Train loss 0.09 on epoch=5
05/27/2022 21:42:35 - INFO - __main__ - Step 680 Global step 680 Train loss 0.11 on epoch=6
05/27/2022 21:42:37 - INFO - __main__ - Step 690 Global step 690 Train loss 0.14 on epoch=6
05/27/2022 21:42:40 - INFO - __main__ - Step 700 Global step 700 Train loss 0.16 on epoch=6
05/27/2022 21:43:31 - INFO - __main__ - Global step 700 Train loss 0.13 Classification-F1 0.56763567906346 on epoch=6
05/27/2022 21:43:31 - INFO - __main__ - Saving model with best Classification-F1: 0.5508324611301413 -> 0.56763567906346 on epoch=6, global_step=700
05/27/2022 21:43:34 - INFO - __main__ - Step 710 Global step 710 Train loss 0.11 on epoch=6
05/27/2022 21:43:36 - INFO - __main__ - Step 720 Global step 720 Train loss 0.13 on epoch=6
05/27/2022 21:43:39 - INFO - __main__ - Step 730 Global step 730 Train loss 0.15 on epoch=6
05/27/2022 21:43:41 - INFO - __main__ - Step 740 Global step 740 Train loss 0.13 on epoch=6
05/27/2022 21:43:44 - INFO - __main__ - Step 750 Global step 750 Train loss 0.15 on epoch=6
05/27/2022 21:44:36 - INFO - __main__ - Global step 750 Train loss 0.14 Classification-F1 0.5788213555547506 on epoch=6
05/27/2022 21:44:36 - INFO - __main__ - Saving model with best Classification-F1: 0.56763567906346 -> 0.5788213555547506 on epoch=6, global_step=750
05/27/2022 21:44:39 - INFO - __main__ - Step 760 Global step 760 Train loss 0.14 on epoch=6
05/27/2022 21:44:41 - INFO - __main__ - Step 770 Global step 770 Train loss 0.15 on epoch=6
05/27/2022 21:44:44 - INFO - __main__ - Step 780 Global step 780 Train loss 0.11 on epoch=6
05/27/2022 21:44:46 - INFO - __main__ - Step 790 Global step 790 Train loss 0.09 on epoch=7
05/27/2022 21:44:49 - INFO - __main__ - Step 800 Global step 800 Train loss 0.12 on epoch=7
05/27/2022 21:45:38 - INFO - __main__ - Global step 800 Train loss 0.12 Classification-F1 0.5228108727373982 on epoch=7
05/27/2022 21:45:41 - INFO - __main__ - Step 810 Global step 810 Train loss 0.19 on epoch=7
05/27/2022 21:45:44 - INFO - __main__ - Step 820 Global step 820 Train loss 0.07 on epoch=7
05/27/2022 21:45:46 - INFO - __main__ - Step 830 Global step 830 Train loss 0.11 on epoch=7
05/27/2022 21:45:49 - INFO - __main__ - Step 840 Global step 840 Train loss 0.09 on epoch=7
05/27/2022 21:45:52 - INFO - __main__ - Step 850 Global step 850 Train loss 0.07 on epoch=7
05/27/2022 21:46:43 - INFO - __main__ - Global step 850 Train loss 0.11 Classification-F1 0.510980954315419 on epoch=7
05/27/2022 21:46:46 - INFO - __main__ - Step 860 Global step 860 Train loss 0.09 on epoch=7
05/27/2022 21:46:48 - INFO - __main__ - Step 870 Global step 870 Train loss 0.11 on epoch=7
05/27/2022 21:46:51 - INFO - __main__ - Step 880 Global step 880 Train loss 0.14 on epoch=7
05/27/2022 21:46:54 - INFO - __main__ - Step 890 Global step 890 Train loss 0.14 on epoch=7
05/27/2022 21:46:56 - INFO - __main__ - Step 900 Global step 900 Train loss 0.10 on epoch=8
05/27/2022 21:47:46 - INFO - __main__ - Global step 900 Train loss 0.12 Classification-F1 0.5523529358387057 on epoch=8
05/27/2022 21:47:49 - INFO - __main__ - Step 910 Global step 910 Train loss 0.09 on epoch=8
05/27/2022 21:47:51 - INFO - __main__ - Step 920 Global step 920 Train loss 0.13 on epoch=8
05/27/2022 21:47:54 - INFO - __main__ - Step 930 Global step 930 Train loss 0.07 on epoch=8
05/27/2022 21:47:57 - INFO - __main__ - Step 940 Global step 940 Train loss 0.11 on epoch=8
05/27/2022 21:47:59 - INFO - __main__ - Step 950 Global step 950 Train loss 0.06 on epoch=8
05/27/2022 21:48:50 - INFO - __main__ - Global step 950 Train loss 0.09 Classification-F1 0.5814104207209851 on epoch=8
05/27/2022 21:48:50 - INFO - __main__ - Saving model with best Classification-F1: 0.5788213555547506 -> 0.5814104207209851 on epoch=8, global_step=950
05/27/2022 21:48:52 - INFO - __main__ - Step 960 Global step 960 Train loss 0.10 on epoch=8
05/27/2022 21:48:55 - INFO - __main__ - Step 970 Global step 970 Train loss 0.08 on epoch=8
05/27/2022 21:48:58 - INFO - __main__ - Step 980 Global step 980 Train loss 0.09 on epoch=8
05/27/2022 21:49:00 - INFO - __main__ - Step 990 Global step 990 Train loss 0.11 on epoch=8
05/27/2022 21:49:03 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.16 on epoch=8
05/27/2022 21:49:52 - INFO - __main__ - Global step 1000 Train loss 0.11 Classification-F1 0.5740312847329695 on epoch=8
05/27/2022 21:49:55 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.09 on epoch=9
05/27/2022 21:49:57 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.07 on epoch=9
05/27/2022 21:50:00 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.07 on epoch=9
05/27/2022 21:50:02 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.16 on epoch=9
05/27/2022 21:50:05 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.09 on epoch=9
05/27/2022 21:50:57 - INFO - __main__ - Global step 1050 Train loss 0.10 Classification-F1 0.5181456503982744 on epoch=9
05/27/2022 21:51:00 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.06 on epoch=9
05/27/2022 21:51:02 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.08 on epoch=9
05/27/2022 21:51:05 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.09 on epoch=9
05/27/2022 21:51:07 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.05 on epoch=9
05/27/2022 21:51:10 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.15 on epoch=9
05/27/2022 21:51:58 - INFO - __main__ - Global step 1100 Train loss 0.09 Classification-F1 0.5468499489710191 on epoch=9
05/27/2022 21:52:00 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.10 on epoch=9
05/27/2022 21:52:03 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.05 on epoch=9
05/27/2022 21:52:06 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.11 on epoch=10
05/27/2022 21:52:08 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.06 on epoch=10
05/27/2022 21:52:11 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.18 on epoch=10
05/27/2022 21:53:00 - INFO - __main__ - Global step 1150 Train loss 0.10 Classification-F1 0.4518258769557903 on epoch=10
05/27/2022 21:53:03 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.10 on epoch=10
05/27/2022 21:53:05 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.05 on epoch=10
05/27/2022 21:53:08 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.03 on epoch=10
05/27/2022 21:53:10 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.07 on epoch=10
05/27/2022 21:53:13 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.07 on epoch=10
05/27/2022 21:54:05 - INFO - __main__ - Global step 1200 Train loss 0.06 Classification-F1 0.5240301133095104 on epoch=10
05/27/2022 21:54:08 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.15 on epoch=10
05/27/2022 21:54:11 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.12 on epoch=10
05/27/2022 21:54:13 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.09 on epoch=10
05/27/2022 21:54:16 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.07 on epoch=11
05/27/2022 21:54:18 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.07 on epoch=11
05/27/2022 21:55:06 - INFO - __main__ - Global step 1250 Train loss 0.10 Classification-F1 0.45490416974854286 on epoch=11
05/27/2022 21:55:09 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.10 on epoch=11
05/27/2022 21:55:11 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.05 on epoch=11
05/27/2022 21:55:14 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.06 on epoch=11
05/27/2022 21:55:17 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.06 on epoch=11
05/27/2022 21:55:19 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.07 on epoch=11
05/27/2022 21:56:10 - INFO - __main__ - Global step 1300 Train loss 0.07 Classification-F1 0.4694692319724687 on epoch=11
05/27/2022 21:56:13 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.04 on epoch=11
05/27/2022 21:56:15 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.15 on epoch=11
05/27/2022 21:56:18 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.15 on epoch=11
05/27/2022 21:56:21 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.08 on epoch=11
05/27/2022 21:56:23 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.04 on epoch=12
05/27/2022 21:57:12 - INFO - __main__ - Global step 1350 Train loss 0.09 Classification-F1 0.46082342681186605 on epoch=12
05/27/2022 21:57:14 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.07 on epoch=12
05/27/2022 21:57:17 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.10 on epoch=12
05/27/2022 21:57:19 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.04 on epoch=12
05/27/2022 21:57:22 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.06 on epoch=12
05/27/2022 21:57:25 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.05 on epoch=12
05/27/2022 21:58:13 - INFO - __main__ - Global step 1400 Train loss 0.07 Classification-F1 0.605411817479949 on epoch=12
05/27/2022 21:58:13 - INFO - __main__ - Saving model with best Classification-F1: 0.5814104207209851 -> 0.605411817479949 on epoch=12, global_step=1400
05/27/2022 21:58:16 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.05 on epoch=12
05/27/2022 21:58:18 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.09 on epoch=12
05/27/2022 21:58:21 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.12 on epoch=12
05/27/2022 21:58:24 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.11 on epoch=12
05/27/2022 21:58:26 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.07 on epoch=12
05/27/2022 21:59:15 - INFO - __main__ - Global step 1450 Train loss 0.09 Classification-F1 0.4055228903360442 on epoch=12
05/27/2022 21:59:17 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.04 on epoch=13
05/27/2022 21:59:20 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.07 on epoch=13
05/27/2022 21:59:22 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.05 on epoch=13
05/27/2022 21:59:25 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.05 on epoch=13
05/27/2022 21:59:28 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.11 on epoch=13
05/27/2022 22:00:17 - INFO - __main__ - Global step 1500 Train loss 0.06 Classification-F1 0.4216067620660063 on epoch=13
05/27/2022 22:00:20 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.06 on epoch=13
05/27/2022 22:00:23 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.10 on epoch=13
05/27/2022 22:00:25 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.06 on epoch=13
05/27/2022 22:00:28 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=13
05/27/2022 22:00:31 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.09 on epoch=13
05/27/2022 22:01:21 - INFO - __main__ - Global step 1550 Train loss 0.07 Classification-F1 0.44159154322148736 on epoch=13
05/27/2022 22:01:23 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.11 on epoch=13
05/27/2022 22:01:26 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.05 on epoch=14
05/27/2022 22:01:29 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.04 on epoch=14
05/27/2022 22:01:31 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.05 on epoch=14
05/27/2022 22:01:34 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.09 on epoch=14
05/27/2022 22:02:23 - INFO - __main__ - Global step 1600 Train loss 0.07 Classification-F1 0.4101319784969611 on epoch=14
05/27/2022 22:02:26 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.06 on epoch=14
05/27/2022 22:02:28 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.04 on epoch=14
05/27/2022 22:02:31 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.04 on epoch=14
05/27/2022 22:02:34 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.11 on epoch=14
05/27/2022 22:02:36 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=14
05/27/2022 22:03:26 - INFO - __main__ - Global step 1650 Train loss 0.06 Classification-F1 0.45837676247213643 on epoch=14
05/27/2022 22:03:29 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.15 on epoch=14
05/27/2022 22:03:32 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.14 on epoch=14
05/27/2022 22:03:34 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.04 on epoch=14
05/27/2022 22:03:37 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.06 on epoch=15
05/27/2022 22:03:39 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=15
05/27/2022 22:04:29 - INFO - __main__ - Global step 1700 Train loss 0.08 Classification-F1 0.4076392852168591 on epoch=15
05/27/2022 22:04:31 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.07 on epoch=15
05/27/2022 22:04:34 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.08 on epoch=15
05/27/2022 22:04:37 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.09 on epoch=15
05/27/2022 22:04:39 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.04 on epoch=15
05/27/2022 22:04:42 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.06 on epoch=15
05/27/2022 22:05:32 - INFO - __main__ - Global step 1750 Train loss 0.07 Classification-F1 0.5032147216191943 on epoch=15
05/27/2022 22:05:34 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.04 on epoch=15
05/27/2022 22:05:37 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.10 on epoch=15
05/27/2022 22:05:40 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.09 on epoch=15
05/27/2022 22:05:42 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.04 on epoch=15
05/27/2022 22:05:45 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.05 on epoch=16
05/27/2022 22:06:34 - INFO - __main__ - Global step 1800 Train loss 0.06 Classification-F1 0.5733193363843553 on epoch=16
05/27/2022 22:06:37 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.05 on epoch=16
05/27/2022 22:06:39 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.09 on epoch=16
05/27/2022 22:06:42 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.05 on epoch=16
05/27/2022 22:06:44 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.10 on epoch=16
05/27/2022 22:06:47 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.05 on epoch=16
05/27/2022 22:07:36 - INFO - __main__ - Global step 1850 Train loss 0.07 Classification-F1 0.5758723958119593 on epoch=16
05/27/2022 22:07:39 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.07 on epoch=16
05/27/2022 22:07:41 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.05 on epoch=16
05/27/2022 22:07:44 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.14 on epoch=16
05/27/2022 22:07:47 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.03 on epoch=16
05/27/2022 22:07:49 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.08 on epoch=16
05/27/2022 22:08:38 - INFO - __main__ - Global step 1900 Train loss 0.08 Classification-F1 0.513979254237647 on epoch=16
05/27/2022 22:08:40 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=17
05/27/2022 22:08:43 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.07 on epoch=17
05/27/2022 22:08:45 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.13 on epoch=17
05/27/2022 22:08:48 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=17
05/27/2022 22:08:51 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.05 on epoch=17
05/27/2022 22:09:39 - INFO - __main__ - Global step 1950 Train loss 0.06 Classification-F1 0.5994663917916618 on epoch=17
05/27/2022 22:09:42 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=17
05/27/2022 22:09:44 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.04 on epoch=17
05/27/2022 22:09:47 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.04 on epoch=17
05/27/2022 22:09:50 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.08 on epoch=17
05/27/2022 22:09:52 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.10 on epoch=17
05/27/2022 22:10:41 - INFO - __main__ - Global step 2000 Train loss 0.06 Classification-F1 0.570391488718985 on epoch=17
05/27/2022 22:10:44 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.08 on epoch=17
05/27/2022 22:10:47 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=18
05/27/2022 22:10:49 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.05 on epoch=18
05/27/2022 22:10:52 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.08 on epoch=18
05/27/2022 22:10:54 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.04 on epoch=18
05/27/2022 22:11:43 - INFO - __main__ - Global step 2050 Train loss 0.05 Classification-F1 0.6645857488452938 on epoch=18
05/27/2022 22:11:43 - INFO - __main__ - Saving model with best Classification-F1: 0.605411817479949 -> 0.6645857488452938 on epoch=18, global_step=2050
05/27/2022 22:11:46 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.05 on epoch=18
05/27/2022 22:11:49 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.03 on epoch=18
05/27/2022 22:11:51 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.04 on epoch=18
05/27/2022 22:11:54 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.06 on epoch=18
05/27/2022 22:11:57 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=18
05/27/2022 22:12:46 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.46866060197658577 on epoch=18
05/27/2022 22:12:49 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.11 on epoch=18
05/27/2022 22:12:51 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.05 on epoch=18
05/27/2022 22:12:54 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=19
05/27/2022 22:12:56 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.04 on epoch=19
05/27/2022 22:12:59 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.03 on epoch=19
05/27/2022 22:13:46 - INFO - __main__ - Global step 2150 Train loss 0.05 Classification-F1 0.6049024475574026 on epoch=19
05/27/2022 22:13:49 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=19
05/27/2022 22:13:52 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.04 on epoch=19
05/27/2022 22:13:54 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=19
05/27/2022 22:13:57 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=19
05/27/2022 22:13:59 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.06 on epoch=19
05/27/2022 22:14:48 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.5806459216648271 on epoch=19
05/27/2022 22:14:50 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=19
05/27/2022 22:14:53 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.13 on epoch=19
05/27/2022 22:14:56 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.07 on epoch=19
05/27/2022 22:14:58 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=19
05/27/2022 22:15:01 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.08 on epoch=20
05/27/2022 22:15:50 - INFO - __main__ - Global step 2250 Train loss 0.06 Classification-F1 0.5818897740072821 on epoch=20
05/27/2022 22:15:52 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=20
05/27/2022 22:15:55 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.08 on epoch=20
05/27/2022 22:15:57 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.07 on epoch=20
05/27/2022 22:16:00 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.03 on epoch=20
05/27/2022 22:16:03 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.06 on epoch=20
05/27/2022 22:16:52 - INFO - __main__ - Global step 2300 Train loss 0.05 Classification-F1 0.5444279206193424 on epoch=20
05/27/2022 22:16:55 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=20
05/27/2022 22:16:57 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=20
05/27/2022 22:17:00 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.05 on epoch=20
05/27/2022 22:17:02 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.08 on epoch=20
05/27/2022 22:17:05 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.04 on epoch=20
05/27/2022 22:17:53 - INFO - __main__ - Global step 2350 Train loss 0.04 Classification-F1 0.5037843240716332 on epoch=20
05/27/2022 22:17:56 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.05 on epoch=21
05/27/2022 22:17:58 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.03 on epoch=21
05/27/2022 22:18:01 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.08 on epoch=21
05/27/2022 22:18:04 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=21
05/27/2022 22:18:06 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.03 on epoch=21
05/27/2022 22:18:54 - INFO - __main__ - Global step 2400 Train loss 0.04 Classification-F1 0.5016575487721294 on epoch=21
05/27/2022 22:18:57 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=21
05/27/2022 22:18:59 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=21
05/27/2022 22:19:02 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=21
05/27/2022 22:19:05 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.05 on epoch=21
05/27/2022 22:19:07 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.04 on epoch=21
05/27/2022 22:19:54 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.7449250987538758 on epoch=21
05/27/2022 22:19:54 - INFO - __main__ - Saving model with best Classification-F1: 0.6645857488452938 -> 0.7449250987538758 on epoch=21, global_step=2450
05/27/2022 22:19:56 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.06 on epoch=21
05/27/2022 22:19:59 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=22
05/27/2022 22:20:02 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.03 on epoch=22
05/27/2022 22:20:04 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.08 on epoch=22
05/27/2022 22:20:07 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=22
05/27/2022 22:20:53 - INFO - __main__ - Global step 2500 Train loss 0.04 Classification-F1 0.5776849127238903 on epoch=22
05/27/2022 22:20:56 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.05 on epoch=22
05/27/2022 22:20:59 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.03 on epoch=22
05/27/2022 22:21:01 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.04 on epoch=22
05/27/2022 22:21:04 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=22
05/27/2022 22:21:06 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.10 on epoch=22
05/27/2022 22:21:53 - INFO - __main__ - Global step 2550 Train loss 0.05 Classification-F1 0.5740364249444837 on epoch=22
05/27/2022 22:21:56 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.07 on epoch=22
05/27/2022 22:21:58 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.09 on epoch=22
05/27/2022 22:22:01 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.04 on epoch=23
05/27/2022 22:22:04 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.09 on epoch=23
05/27/2022 22:22:06 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.04 on epoch=23
05/27/2022 22:22:53 - INFO - __main__ - Global step 2600 Train loss 0.06 Classification-F1 0.5503470128476238 on epoch=23
05/27/2022 22:22:56 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=23
05/27/2022 22:22:58 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.04 on epoch=23
05/27/2022 22:23:01 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=23
05/27/2022 22:23:04 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=23
05/27/2022 22:23:06 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.04 on epoch=23
05/27/2022 22:23:54 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.45326284906990694 on epoch=23
05/27/2022 22:23:57 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=23
05/27/2022 22:24:00 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.04 on epoch=23
05/27/2022 22:24:02 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.06 on epoch=23
05/27/2022 22:24:05 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=24
05/27/2022 22:24:07 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.03 on epoch=24
05/27/2022 22:24:55 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.3523674764536622 on epoch=24
05/27/2022 22:24:57 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.04 on epoch=24
05/27/2022 22:25:00 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.06 on epoch=24
05/27/2022 22:25:03 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=24
05/27/2022 22:25:05 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.03 on epoch=24
05/27/2022 22:25:08 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.06 on epoch=24
05/27/2022 22:25:56 - INFO - __main__ - Global step 2750 Train loss 0.04 Classification-F1 0.35303686790220307 on epoch=24
05/27/2022 22:25:59 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.03 on epoch=24
05/27/2022 22:26:01 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=24
05/27/2022 22:26:04 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.05 on epoch=24
05/27/2022 22:26:06 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.07 on epoch=24
05/27/2022 22:26:09 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.04 on epoch=24
05/27/2022 22:26:57 - INFO - __main__ - Global step 2800 Train loss 0.04 Classification-F1 0.37870343677348306 on epoch=24
05/27/2022 22:27:00 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.04 on epoch=25
05/27/2022 22:27:02 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.04 on epoch=25
05/27/2022 22:27:05 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.06 on epoch=25
05/27/2022 22:27:07 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.06 on epoch=25
05/27/2022 22:27:10 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.04 on epoch=25
05/27/2022 22:27:58 - INFO - __main__ - Global step 2850 Train loss 0.05 Classification-F1 0.33355516710824823 on epoch=25
05/27/2022 22:28:01 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.04 on epoch=25
05/27/2022 22:28:03 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.03 on epoch=25
05/27/2022 22:28:06 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=25
05/27/2022 22:28:09 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.06 on epoch=25
05/27/2022 22:28:11 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.04 on epoch=25
05/27/2022 22:29:00 - INFO - __main__ - Global step 2900 Train loss 0.04 Classification-F1 0.43376003959828807 on epoch=25
05/27/2022 22:29:02 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=25
05/27/2022 22:29:05 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.05 on epoch=26
05/27/2022 22:29:07 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.05 on epoch=26
05/27/2022 22:29:10 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.06 on epoch=26
05/27/2022 22:29:13 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=26
05/27/2022 22:30:02 - INFO - __main__ - Global step 2950 Train loss 0.04 Classification-F1 0.5710455053082285 on epoch=26
05/27/2022 22:30:04 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.04 on epoch=26
05/27/2022 22:30:07 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.03 on epoch=26
05/27/2022 22:30:09 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.04 on epoch=26
05/27/2022 22:30:12 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=26
05/27/2022 22:30:15 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.06 on epoch=26
05/27/2022 22:30:16 - INFO - __main__ - Start tokenizing ... 1792 instances
05/27/2022 22:30:16 - INFO - __main__ - Printing 3 examples
05/27/2022 22:30:16 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/27/2022 22:30:16 - INFO - __main__ - ['Animal']
05/27/2022 22:30:16 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/27/2022 22:30:16 - INFO - __main__ - ['Animal']
05/27/2022 22:30:16 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/27/2022 22:30:16 - INFO - __main__ - ['Animal']
05/27/2022 22:30:16 - INFO - __main__ - Tokenizing Input ...
05/27/2022 22:30:17 - INFO - __main__ - Tokenizing Output ...
05/27/2022 22:30:19 - INFO - __main__ - Loaded 1792 examples from train data
05/27/2022 22:30:19 - INFO - __main__ - Start tokenizing ... 1792 instances
05/27/2022 22:30:19 - INFO - __main__ - Printing 3 examples
05/27/2022 22:30:19 - INFO - __main__ -  [dbpedia_14] Palaephatus fusciterminus is a moth of the Palaephatidae family. It is found in the Valdivian forests of southern Argentina and Chile.The length of the forewings is 10-12 mm for males and 10.5-11.5 mm for females. Adults have a buff to brown head and thorax and dark brownish fuscous forewings with a pale buff hindmargin. They are on wing from October to March possibly in multiple generations per year.
05/27/2022 22:30:19 - INFO - __main__ - ['Animal']
05/27/2022 22:30:19 - INFO - __main__ -  [dbpedia_14] Labus is an indomalayan genus of potter wasps.
05/27/2022 22:30:19 - INFO - __main__ - ['Animal']
05/27/2022 22:30:19 - INFO - __main__ -  [dbpedia_14] Trifurcula beirnei is a moth of the Nepticulidae family. It is found in Great Britain Denmark and parts of Germany and Poland Austria the Czech Republic Slovakia and Hungary. It is also found in the Volga and Ural region of Russia.The wingspan is 8–11 mm. Adults are on wing from the end of June to late September.The larvae feed on Genista species including Genista tinctoria Genista germanica and Genista pilosa.
05/27/2022 22:30:19 - INFO - __main__ - ['Animal']
05/27/2022 22:30:19 - INFO - __main__ - Tokenizing Input ...
05/27/2022 22:30:20 - INFO - __main__ - Tokenizing Output ...
05/27/2022 22:30:21 - INFO - __main__ - Loaded 1792 examples from dev data
05/27/2022 22:30:38 - INFO - __main__ - load prompt embedding from ckpt
05/27/2022 22:30:38 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/27/2022 22:30:39 - INFO - __main__ - Starting training!
05/27/2022 22:31:04 - INFO - __main__ - Global step 3000 Train loss 0.04 Classification-F1 0.488315957035361 on epoch=26
05/27/2022 22:31:04 - INFO - __main__ - save last model!
05/27/2022 22:31:04 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/27/2022 22:31:05 - INFO - __main__ - Start tokenizing ... 3500 instances
05/27/2022 22:31:05 - INFO - __main__ - Printing 3 examples
05/27/2022 22:31:05 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/27/2022 22:31:05 - INFO - __main__ - ['Animal']
05/27/2022 22:31:05 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/27/2022 22:31:05 - INFO - __main__ - ['Animal']
05/27/2022 22:31:05 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/27/2022 22:31:05 - INFO - __main__ - ['Village']
05/27/2022 22:31:05 - INFO - __main__ - Tokenizing Input ...
05/27/2022 22:31:06 - INFO - __main__ - Tokenizing Output ...
05/27/2022 22:31:10 - INFO - __main__ - Loaded 3500 examples from test data
05/27/2022 22:33:01 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down128shot/singletask-dbpedia_14/dbpedia_14_128_100_0.5_8_predictions.txt
05/27/2022 22:33:01 - INFO - __main__ - Classification-F1 on test data: 0.4058
05/27/2022 22:33:02 - INFO - __main__ - prefix=dbpedia_14_128_100, lr=0.5, bsz=8, dev_performance=0.7449250987538758, test_performance=0.4057722000947613
05/27/2022 22:33:02 - INFO - __main__ - Running ... prefix=dbpedia_14_128_100, lr=0.4, bsz=8 ...
05/27/2022 22:33:03 - INFO - __main__ - Start tokenizing ... 1792 instances
05/27/2022 22:33:03 - INFO - __main__ - Printing 3 examples
05/27/2022 22:33:03 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/27/2022 22:33:03 - INFO - __main__ - ['Animal']
05/27/2022 22:33:03 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/27/2022 22:33:03 - INFO - __main__ - ['Animal']
05/27/2022 22:33:03 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/27/2022 22:33:03 - INFO - __main__ - ['Animal']
05/27/2022 22:33:03 - INFO - __main__ - Tokenizing Input ...
05/27/2022 22:33:04 - INFO - __main__ - Tokenizing Output ...
05/27/2022 22:33:06 - INFO - __main__ - Loaded 1792 examples from train data
05/27/2022 22:33:06 - INFO - __main__ - Start tokenizing ... 1792 instances
05/27/2022 22:33:06 - INFO - __main__ - Printing 3 examples
05/27/2022 22:33:06 - INFO - __main__ -  [dbpedia_14] Palaephatus fusciterminus is a moth of the Palaephatidae family. It is found in the Valdivian forests of southern Argentina and Chile.The length of the forewings is 10-12 mm for males and 10.5-11.5 mm for females. Adults have a buff to brown head and thorax and dark brownish fuscous forewings with a pale buff hindmargin. They are on wing from October to March possibly in multiple generations per year.
05/27/2022 22:33:06 - INFO - __main__ - ['Animal']
05/27/2022 22:33:06 - INFO - __main__ -  [dbpedia_14] Labus is an indomalayan genus of potter wasps.
05/27/2022 22:33:06 - INFO - __main__ - ['Animal']
05/27/2022 22:33:06 - INFO - __main__ -  [dbpedia_14] Trifurcula beirnei is a moth of the Nepticulidae family. It is found in Great Britain Denmark and parts of Germany and Poland Austria the Czech Republic Slovakia and Hungary. It is also found in the Volga and Ural region of Russia.The wingspan is 8–11 mm. Adults are on wing from the end of June to late September.The larvae feed on Genista species including Genista tinctoria Genista germanica and Genista pilosa.
05/27/2022 22:33:06 - INFO - __main__ - ['Animal']
05/27/2022 22:33:06 - INFO - __main__ - Tokenizing Input ...
05/27/2022 22:33:06 - INFO - __main__ - Tokenizing Output ...
05/27/2022 22:33:08 - INFO - __main__ - Loaded 1792 examples from dev data
05/27/2022 22:33:27 - INFO - __main__ - load prompt embedding from ckpt
05/27/2022 22:33:27 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/27/2022 22:33:27 - INFO - __main__ - Starting training!
05/27/2022 22:33:31 - INFO - __main__ - Step 10 Global step 10 Train loss 6.99 on epoch=0
05/27/2022 22:33:34 - INFO - __main__ - Step 20 Global step 20 Train loss 4.86 on epoch=0
05/27/2022 22:33:36 - INFO - __main__ - Step 30 Global step 30 Train loss 4.15 on epoch=0
05/27/2022 22:33:39 - INFO - __main__ - Step 40 Global step 40 Train loss 3.74 on epoch=0
05/27/2022 22:33:42 - INFO - __main__ - Step 50 Global step 50 Train loss 3.32 on epoch=0
05/27/2022 22:34:35 - INFO - __main__ - Global step 50 Train loss 4.61 Classification-F1 0.011575218323624807 on epoch=0
05/27/2022 22:34:35 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.011575218323624807 on epoch=0, global_step=50
05/27/2022 22:34:38 - INFO - __main__ - Step 60 Global step 60 Train loss 2.49 on epoch=0
05/27/2022 22:34:41 - INFO - __main__ - Step 70 Global step 70 Train loss 2.41 on epoch=0
05/27/2022 22:34:43 - INFO - __main__ - Step 80 Global step 80 Train loss 2.29 on epoch=0
05/27/2022 22:34:46 - INFO - __main__ - Step 90 Global step 90 Train loss 2.22 on epoch=0
05/27/2022 22:34:48 - INFO - __main__ - Step 100 Global step 100 Train loss 2.03 on epoch=0
05/27/2022 22:35:37 - INFO - __main__ - Global step 100 Train loss 2.29 Classification-F1 0.0342640597285915 on epoch=0
05/27/2022 22:35:37 - INFO - __main__ - Saving model with best Classification-F1: 0.011575218323624807 -> 0.0342640597285915 on epoch=0, global_step=100
05/27/2022 22:35:40 - INFO - __main__ - Step 110 Global step 110 Train loss 2.01 on epoch=0
05/27/2022 22:35:42 - INFO - __main__ - Step 120 Global step 120 Train loss 1.82 on epoch=1
05/27/2022 22:35:45 - INFO - __main__ - Step 130 Global step 130 Train loss 1.71 on epoch=1
05/27/2022 22:35:48 - INFO - __main__ - Step 140 Global step 140 Train loss 1.53 on epoch=1
05/27/2022 22:35:50 - INFO - __main__ - Step 150 Global step 150 Train loss 1.44 on epoch=1
05/27/2022 22:36:35 - INFO - __main__ - Global step 150 Train loss 1.70 Classification-F1 0.07658471526941962 on epoch=1
05/27/2022 22:36:35 - INFO - __main__ - Saving model with best Classification-F1: 0.0342640597285915 -> 0.07658471526941962 on epoch=1, global_step=150
05/27/2022 22:36:38 - INFO - __main__ - Step 160 Global step 160 Train loss 1.32 on epoch=1
05/27/2022 22:36:40 - INFO - __main__ - Step 170 Global step 170 Train loss 1.21 on epoch=1
05/27/2022 22:36:43 - INFO - __main__ - Step 180 Global step 180 Train loss 1.02 on epoch=1
05/27/2022 22:36:46 - INFO - __main__ - Step 190 Global step 190 Train loss 1.02 on epoch=1
05/27/2022 22:36:48 - INFO - __main__ - Step 200 Global step 200 Train loss 1.06 on epoch=1
05/27/2022 22:37:32 - INFO - __main__ - Global step 200 Train loss 1.13 Classification-F1 0.1340297441386144 on epoch=1
05/27/2022 22:37:32 - INFO - __main__ - Saving model with best Classification-F1: 0.07658471526941962 -> 0.1340297441386144 on epoch=1, global_step=200
05/27/2022 22:37:35 - INFO - __main__ - Step 210 Global step 210 Train loss 0.92 on epoch=1
05/27/2022 22:37:37 - INFO - __main__ - Step 220 Global step 220 Train loss 0.79 on epoch=1
05/27/2022 22:37:40 - INFO - __main__ - Step 230 Global step 230 Train loss 0.72 on epoch=2
05/27/2022 22:37:42 - INFO - __main__ - Step 240 Global step 240 Train loss 0.73 on epoch=2
05/27/2022 22:37:45 - INFO - __main__ - Step 250 Global step 250 Train loss 0.65 on epoch=2
05/27/2022 22:38:32 - INFO - __main__ - Global step 250 Train loss 0.76 Classification-F1 0.23230417441210552 on epoch=2
05/27/2022 22:38:32 - INFO - __main__ - Saving model with best Classification-F1: 0.1340297441386144 -> 0.23230417441210552 on epoch=2, global_step=250
05/27/2022 22:38:34 - INFO - __main__ - Step 260 Global step 260 Train loss 0.55 on epoch=2
05/27/2022 22:38:37 - INFO - __main__ - Step 270 Global step 270 Train loss 0.54 on epoch=2
05/27/2022 22:38:40 - INFO - __main__ - Step 280 Global step 280 Train loss 0.49 on epoch=2
05/27/2022 22:38:42 - INFO - __main__ - Step 290 Global step 290 Train loss 0.47 on epoch=2
05/27/2022 22:38:45 - INFO - __main__ - Step 300 Global step 300 Train loss 0.43 on epoch=2
05/27/2022 22:39:35 - INFO - __main__ - Global step 300 Train loss 0.50 Classification-F1 0.28589560558609295 on epoch=2
05/27/2022 22:39:35 - INFO - __main__ - Saving model with best Classification-F1: 0.23230417441210552 -> 0.28589560558609295 on epoch=2, global_step=300
05/27/2022 22:39:38 - INFO - __main__ - Step 310 Global step 310 Train loss 0.49 on epoch=2
05/27/2022 22:39:41 - INFO - __main__ - Step 320 Global step 320 Train loss 0.59 on epoch=2
05/27/2022 22:39:43 - INFO - __main__ - Step 330 Global step 330 Train loss 0.42 on epoch=2
05/27/2022 22:39:46 - INFO - __main__ - Step 340 Global step 340 Train loss 0.39 on epoch=3
05/27/2022 22:39:48 - INFO - __main__ - Step 350 Global step 350 Train loss 0.31 on epoch=3
05/27/2022 22:40:38 - INFO - __main__ - Global step 350 Train loss 0.44 Classification-F1 0.290916465512587 on epoch=3
05/27/2022 22:40:38 - INFO - __main__ - Saving model with best Classification-F1: 0.28589560558609295 -> 0.290916465512587 on epoch=3, global_step=350
05/27/2022 22:40:40 - INFO - __main__ - Step 360 Global step 360 Train loss 0.47 on epoch=3
05/27/2022 22:40:43 - INFO - __main__ - Step 370 Global step 370 Train loss 0.34 on epoch=3
05/27/2022 22:40:46 - INFO - __main__ - Step 380 Global step 380 Train loss 0.41 on epoch=3
05/27/2022 22:40:48 - INFO - __main__ - Step 390 Global step 390 Train loss 0.32 on epoch=3
05/27/2022 22:40:51 - INFO - __main__ - Step 400 Global step 400 Train loss 0.31 on epoch=3
05/27/2022 22:41:41 - INFO - __main__ - Global step 400 Train loss 0.37 Classification-F1 0.3236567841691348 on epoch=3
05/27/2022 22:41:41 - INFO - __main__ - Saving model with best Classification-F1: 0.290916465512587 -> 0.3236567841691348 on epoch=3, global_step=400
05/27/2022 22:41:44 - INFO - __main__ - Step 410 Global step 410 Train loss 0.34 on epoch=3
05/27/2022 22:41:47 - INFO - __main__ - Step 420 Global step 420 Train loss 0.24 on epoch=3
05/27/2022 22:41:49 - INFO - __main__ - Step 430 Global step 430 Train loss 0.35 on epoch=3
05/27/2022 22:41:52 - INFO - __main__ - Step 440 Global step 440 Train loss 0.28 on epoch=3
05/27/2022 22:41:55 - INFO - __main__ - Step 450 Global step 450 Train loss 0.26 on epoch=4
05/27/2022 22:42:45 - INFO - __main__ - Global step 450 Train loss 0.29 Classification-F1 0.3489245675677222 on epoch=4
05/27/2022 22:42:45 - INFO - __main__ - Saving model with best Classification-F1: 0.3236567841691348 -> 0.3489245675677222 on epoch=4, global_step=450
05/27/2022 22:42:47 - INFO - __main__ - Step 460 Global step 460 Train loss 0.29 on epoch=4
05/27/2022 22:42:50 - INFO - __main__ - Step 470 Global step 470 Train loss 0.29 on epoch=4
05/27/2022 22:42:53 - INFO - __main__ - Step 480 Global step 480 Train loss 0.24 on epoch=4
05/27/2022 22:42:55 - INFO - __main__ - Step 490 Global step 490 Train loss 0.28 on epoch=4
05/27/2022 22:42:58 - INFO - __main__ - Step 500 Global step 500 Train loss 0.22 on epoch=4
05/27/2022 22:43:50 - INFO - __main__ - Global step 500 Train loss 0.27 Classification-F1 0.39264684759480484 on epoch=4
05/27/2022 22:43:51 - INFO - __main__ - Saving model with best Classification-F1: 0.3489245675677222 -> 0.39264684759480484 on epoch=4, global_step=500
05/27/2022 22:43:53 - INFO - __main__ - Step 510 Global step 510 Train loss 0.23 on epoch=4
05/27/2022 22:43:56 - INFO - __main__ - Step 520 Global step 520 Train loss 0.27 on epoch=4
05/27/2022 22:43:58 - INFO - __main__ - Step 530 Global step 530 Train loss 0.15 on epoch=4
05/27/2022 22:44:01 - INFO - __main__ - Step 540 Global step 540 Train loss 0.20 on epoch=4
05/27/2022 22:44:04 - INFO - __main__ - Step 550 Global step 550 Train loss 0.25 on epoch=4
05/27/2022 22:44:55 - INFO - __main__ - Global step 550 Train loss 0.22 Classification-F1 0.34916754019886004 on epoch=4
05/27/2022 22:44:57 - INFO - __main__ - Step 560 Global step 560 Train loss 0.23 on epoch=4
05/27/2022 22:45:00 - INFO - __main__ - Step 570 Global step 570 Train loss 0.22 on epoch=5
05/27/2022 22:45:03 - INFO - __main__ - Step 580 Global step 580 Train loss 0.17 on epoch=5
05/27/2022 22:45:05 - INFO - __main__ - Step 590 Global step 590 Train loss 0.24 on epoch=5
05/27/2022 22:45:08 - INFO - __main__ - Step 600 Global step 600 Train loss 0.22 on epoch=5
05/27/2022 22:45:57 - INFO - __main__ - Global step 600 Train loss 0.22 Classification-F1 0.3413623862690234 on epoch=5
05/27/2022 22:45:59 - INFO - __main__ - Step 610 Global step 610 Train loss 0.33 on epoch=5
05/27/2022 22:46:02 - INFO - __main__ - Step 620 Global step 620 Train loss 0.18 on epoch=5
05/27/2022 22:46:05 - INFO - __main__ - Step 630 Global step 630 Train loss 0.24 on epoch=5
05/27/2022 22:46:07 - INFO - __main__ - Step 640 Global step 640 Train loss 0.15 on epoch=5
05/27/2022 22:46:10 - INFO - __main__ - Step 650 Global step 650 Train loss 0.19 on epoch=5
05/27/2022 22:47:01 - INFO - __main__ - Global step 650 Train loss 0.22 Classification-F1 0.45632873077170555 on epoch=5
05/27/2022 22:47:01 - INFO - __main__ - Saving model with best Classification-F1: 0.39264684759480484 -> 0.45632873077170555 on epoch=5, global_step=650
05/27/2022 22:47:04 - INFO - __main__ - Step 660 Global step 660 Train loss 0.17 on epoch=5
05/27/2022 22:47:07 - INFO - __main__ - Step 670 Global step 670 Train loss 0.19 on epoch=5
05/27/2022 22:47:09 - INFO - __main__ - Step 680 Global step 680 Train loss 0.20 on epoch=6
05/27/2022 22:47:12 - INFO - __main__ - Step 690 Global step 690 Train loss 0.15 on epoch=6
05/27/2022 22:47:15 - INFO - __main__ - Step 700 Global step 700 Train loss 0.24 on epoch=6
05/27/2022 22:48:05 - INFO - __main__ - Global step 700 Train loss 0.19 Classification-F1 0.4586366748515421 on epoch=6
05/27/2022 22:48:05 - INFO - __main__ - Saving model with best Classification-F1: 0.45632873077170555 -> 0.4586366748515421 on epoch=6, global_step=700
05/27/2022 22:48:08 - INFO - __main__ - Step 710 Global step 710 Train loss 0.14 on epoch=6
05/27/2022 22:48:11 - INFO - __main__ - Step 720 Global step 720 Train loss 0.16 on epoch=6
05/27/2022 22:48:13 - INFO - __main__ - Step 730 Global step 730 Train loss 0.19 on epoch=6
05/27/2022 22:48:16 - INFO - __main__ - Step 740 Global step 740 Train loss 0.23 on epoch=6
05/27/2022 22:48:19 - INFO - __main__ - Step 750 Global step 750 Train loss 0.17 on epoch=6
05/27/2022 22:49:08 - INFO - __main__ - Global step 750 Train loss 0.18 Classification-F1 0.5011518647220021 on epoch=6
05/27/2022 22:49:08 - INFO - __main__ - Saving model with best Classification-F1: 0.4586366748515421 -> 0.5011518647220021 on epoch=6, global_step=750
05/27/2022 22:49:11 - INFO - __main__ - Step 760 Global step 760 Train loss 0.16 on epoch=6
05/27/2022 22:49:14 - INFO - __main__ - Step 770 Global step 770 Train loss 0.16 on epoch=6
05/27/2022 22:49:16 - INFO - __main__ - Step 780 Global step 780 Train loss 0.14 on epoch=6
05/27/2022 22:49:19 - INFO - __main__ - Step 790 Global step 790 Train loss 0.11 on epoch=7
05/27/2022 22:49:22 - INFO - __main__ - Step 800 Global step 800 Train loss 0.11 on epoch=7
05/27/2022 22:50:11 - INFO - __main__ - Global step 800 Train loss 0.14 Classification-F1 0.40868871738321433 on epoch=7
05/27/2022 22:50:14 - INFO - __main__ - Step 810 Global step 810 Train loss 0.14 on epoch=7
05/27/2022 22:50:16 - INFO - __main__ - Step 820 Global step 820 Train loss 0.10 on epoch=7
05/27/2022 22:50:19 - INFO - __main__ - Step 830 Global step 830 Train loss 0.14 on epoch=7
05/27/2022 22:50:22 - INFO - __main__ - Step 840 Global step 840 Train loss 0.11 on epoch=7
05/27/2022 22:50:24 - INFO - __main__ - Step 850 Global step 850 Train loss 0.18 on epoch=7
05/27/2022 22:51:15 - INFO - __main__ - Global step 850 Train loss 0.14 Classification-F1 0.4586743105518441 on epoch=7
05/27/2022 22:51:18 - INFO - __main__ - Step 860 Global step 860 Train loss 0.15 on epoch=7
05/27/2022 22:51:20 - INFO - __main__ - Step 870 Global step 870 Train loss 0.21 on epoch=7
05/27/2022 22:51:23 - INFO - __main__ - Step 880 Global step 880 Train loss 0.17 on epoch=7
05/27/2022 22:51:26 - INFO - __main__ - Step 890 Global step 890 Train loss 0.17 on epoch=7
05/27/2022 22:51:28 - INFO - __main__ - Step 900 Global step 900 Train loss 0.16 on epoch=8
05/27/2022 22:52:18 - INFO - __main__ - Global step 900 Train loss 0.17 Classification-F1 0.4028080232256332 on epoch=8
05/27/2022 22:52:20 - INFO - __main__ - Step 910 Global step 910 Train loss 0.13 on epoch=8
05/27/2022 22:52:23 - INFO - __main__ - Step 920 Global step 920 Train loss 0.23 on epoch=8
05/27/2022 22:52:26 - INFO - __main__ - Step 930 Global step 930 Train loss 0.09 on epoch=8
05/27/2022 22:52:28 - INFO - __main__ - Step 940 Global step 940 Train loss 0.14 on epoch=8
05/27/2022 22:52:31 - INFO - __main__ - Step 950 Global step 950 Train loss 0.11 on epoch=8
05/27/2022 22:53:22 - INFO - __main__ - Global step 950 Train loss 0.14 Classification-F1 0.4773563828290213 on epoch=8
05/27/2022 22:53:25 - INFO - __main__ - Step 960 Global step 960 Train loss 0.12 on epoch=8
05/27/2022 22:53:28 - INFO - __main__ - Step 970 Global step 970 Train loss 0.16 on epoch=8
05/27/2022 22:53:30 - INFO - __main__ - Step 980 Global step 980 Train loss 0.08 on epoch=8
05/27/2022 22:53:33 - INFO - __main__ - Step 990 Global step 990 Train loss 0.18 on epoch=8
05/27/2022 22:53:35 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.12 on epoch=8
05/27/2022 22:54:26 - INFO - __main__ - Global step 1000 Train loss 0.13 Classification-F1 0.5121036564996851 on epoch=8
05/27/2022 22:54:26 - INFO - __main__ - Saving model with best Classification-F1: 0.5011518647220021 -> 0.5121036564996851 on epoch=8, global_step=1000
05/27/2022 22:54:29 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.10 on epoch=9
05/27/2022 22:54:32 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.09 on epoch=9
05/27/2022 22:54:34 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.14 on epoch=9
05/27/2022 22:54:37 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.11 on epoch=9
05/27/2022 22:54:39 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.10 on epoch=9
05/27/2022 22:55:29 - INFO - __main__ - Global step 1050 Train loss 0.11 Classification-F1 0.49198783922381 on epoch=9
05/27/2022 22:55:32 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.05 on epoch=9
05/27/2022 22:55:35 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.06 on epoch=9
05/27/2022 22:55:37 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.14 on epoch=9
05/27/2022 22:55:40 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.07 on epoch=9
05/27/2022 22:55:42 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.12 on epoch=9
05/27/2022 22:56:33 - INFO - __main__ - Global step 1100 Train loss 0.09 Classification-F1 0.5145179906437584 on epoch=9
05/27/2022 22:56:33 - INFO - __main__ - Saving model with best Classification-F1: 0.5121036564996851 -> 0.5145179906437584 on epoch=9, global_step=1100
05/27/2022 22:56:35 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.11 on epoch=9
05/27/2022 22:56:38 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.09 on epoch=9
05/27/2022 22:56:41 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.14 on epoch=10
05/27/2022 22:56:43 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.06 on epoch=10
05/27/2022 22:56:46 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.19 on epoch=10
05/27/2022 22:57:36 - INFO - __main__ - Global step 1150 Train loss 0.12 Classification-F1 0.5110599604542156 on epoch=10
05/27/2022 22:57:39 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.12 on epoch=10
05/27/2022 22:57:41 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.06 on epoch=10
05/27/2022 22:57:44 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.12 on epoch=10
05/27/2022 22:57:46 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.08 on epoch=10
05/27/2022 22:57:49 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.07 on epoch=10
05/27/2022 22:58:41 - INFO - __main__ - Global step 1200 Train loss 0.09 Classification-F1 0.5036503249906742 on epoch=10
05/27/2022 22:58:43 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.12 on epoch=10
05/27/2022 22:58:46 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.10 on epoch=10
05/27/2022 22:58:49 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.06 on epoch=10
05/27/2022 22:58:51 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.09 on epoch=11
05/27/2022 22:58:54 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.12 on epoch=11
05/27/2022 22:59:44 - INFO - __main__ - Global step 1250 Train loss 0.10 Classification-F1 0.5241448077514216 on epoch=11
05/27/2022 22:59:44 - INFO - __main__ - Saving model with best Classification-F1: 0.5145179906437584 -> 0.5241448077514216 on epoch=11, global_step=1250
05/27/2022 22:59:46 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.13 on epoch=11
05/27/2022 22:59:49 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.06 on epoch=11
05/27/2022 22:59:52 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.11 on epoch=11
05/27/2022 22:59:54 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.05 on epoch=11
05/27/2022 22:59:57 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.08 on epoch=11
05/27/2022 23:00:48 - INFO - __main__ - Global step 1300 Train loss 0.09 Classification-F1 0.6105770508889187 on epoch=11
05/27/2022 23:00:48 - INFO - __main__ - Saving model with best Classification-F1: 0.5241448077514216 -> 0.6105770508889187 on epoch=11, global_step=1300
05/27/2022 23:00:51 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.06 on epoch=11
05/27/2022 23:00:54 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.16 on epoch=11
05/27/2022 23:00:56 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.10 on epoch=11
05/27/2022 23:00:59 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.11 on epoch=11
05/27/2022 23:01:01 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.06 on epoch=12
05/27/2022 23:01:51 - INFO - __main__ - Global step 1350 Train loss 0.10 Classification-F1 0.4933423934680187 on epoch=12
05/27/2022 23:01:54 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.05 on epoch=12
05/27/2022 23:01:57 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.10 on epoch=12
05/27/2022 23:01:59 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.02 on epoch=12
05/27/2022 23:02:02 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.07 on epoch=12
05/27/2022 23:02:04 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.06 on epoch=12
05/27/2022 23:02:55 - INFO - __main__ - Global step 1400 Train loss 0.06 Classification-F1 0.5377380088443465 on epoch=12
05/27/2022 23:02:57 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.09 on epoch=12
05/27/2022 23:03:00 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.06 on epoch=12
05/27/2022 23:03:03 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.10 on epoch=12
05/27/2022 23:03:05 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.08 on epoch=12
05/27/2022 23:03:08 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.06 on epoch=12
05/27/2022 23:03:57 - INFO - __main__ - Global step 1450 Train loss 0.08 Classification-F1 0.5168670707188833 on epoch=12
05/27/2022 23:04:00 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.11 on epoch=13
05/27/2022 23:04:03 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.06 on epoch=13
05/27/2022 23:04:05 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.11 on epoch=13
05/27/2022 23:04:08 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.06 on epoch=13
05/27/2022 23:04:10 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.06 on epoch=13
05/27/2022 23:05:00 - INFO - __main__ - Global step 1500 Train loss 0.08 Classification-F1 0.5163678592690921 on epoch=13
05/27/2022 23:05:03 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.07 on epoch=13
05/27/2022 23:05:05 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.10 on epoch=13
05/27/2022 23:05:08 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.05 on epoch=13
05/27/2022 23:05:11 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.10 on epoch=13
05/27/2022 23:05:13 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.11 on epoch=13
05/27/2022 23:06:03 - INFO - __main__ - Global step 1550 Train loss 0.08 Classification-F1 0.4748887232924285 on epoch=13
05/27/2022 23:06:06 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.09 on epoch=13
05/27/2022 23:06:09 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.05 on epoch=14
05/27/2022 23:06:11 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.05 on epoch=14
05/27/2022 23:06:14 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.06 on epoch=14
05/27/2022 23:06:16 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.08 on epoch=14
05/27/2022 23:07:05 - INFO - __main__ - Global step 1600 Train loss 0.06 Classification-F1 0.491640110984989 on epoch=14
05/27/2022 23:07:08 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.08 on epoch=14
05/27/2022 23:07:10 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.04 on epoch=14
05/27/2022 23:07:13 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.05 on epoch=14
05/27/2022 23:07:16 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.06 on epoch=14
05/27/2022 23:07:18 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.03 on epoch=14
05/27/2022 23:08:07 - INFO - __main__ - Global step 1650 Train loss 0.05 Classification-F1 0.46809976382839286 on epoch=14
05/27/2022 23:08:09 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.12 on epoch=14
05/27/2022 23:08:12 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.12 on epoch=14
05/27/2022 23:08:15 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.07 on epoch=14
05/27/2022 23:08:17 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.04 on epoch=15
05/27/2022 23:08:20 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.06 on epoch=15
05/27/2022 23:09:09 - INFO - __main__ - Global step 1700 Train loss 0.08 Classification-F1 0.4962066856124719 on epoch=15
05/27/2022 23:09:11 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.11 on epoch=15
05/27/2022 23:09:14 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.07 on epoch=15
05/27/2022 23:09:17 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.05 on epoch=15
05/27/2022 23:09:19 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.04 on epoch=15
05/27/2022 23:09:22 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.04 on epoch=15
05/27/2022 23:10:13 - INFO - __main__ - Global step 1750 Train loss 0.06 Classification-F1 0.5809239144606475 on epoch=15
05/27/2022 23:10:15 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.04 on epoch=15
05/27/2022 23:10:18 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.13 on epoch=15
05/27/2022 23:10:20 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.09 on epoch=15
05/27/2022 23:10:23 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.06 on epoch=15
05/27/2022 23:10:26 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=16
05/27/2022 23:11:15 - INFO - __main__ - Global step 1800 Train loss 0.07 Classification-F1 0.5416593208592451 on epoch=16
05/27/2022 23:11:18 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.06 on epoch=16
05/27/2022 23:11:20 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.07 on epoch=16
05/27/2022 23:11:23 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=16
05/27/2022 23:11:26 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.09 on epoch=16
05/27/2022 23:11:28 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=16
05/27/2022 23:12:17 - INFO - __main__ - Global step 1850 Train loss 0.05 Classification-F1 0.522633859449707 on epoch=16
05/27/2022 23:12:20 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.09 on epoch=16
05/27/2022 23:12:23 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.06 on epoch=16
05/27/2022 23:12:25 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.08 on epoch=16
05/27/2022 23:12:28 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.10 on epoch=16
05/27/2022 23:12:31 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.07 on epoch=16
05/27/2022 23:13:20 - INFO - __main__ - Global step 1900 Train loss 0.08 Classification-F1 0.532721260522609 on epoch=16
05/27/2022 23:13:22 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=17
05/27/2022 23:13:25 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.05 on epoch=17
05/27/2022 23:13:28 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.09 on epoch=17
05/27/2022 23:13:30 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.04 on epoch=17
05/27/2022 23:13:33 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.05 on epoch=17
05/27/2022 23:14:22 - INFO - __main__ - Global step 1950 Train loss 0.05 Classification-F1 0.5504286754366472 on epoch=17
05/27/2022 23:14:25 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.04 on epoch=17
05/27/2022 23:14:27 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.07 on epoch=17
05/27/2022 23:14:30 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.06 on epoch=17
05/27/2022 23:14:33 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.10 on epoch=17
05/27/2022 23:14:35 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.03 on epoch=17
05/27/2022 23:15:25 - INFO - __main__ - Global step 2000 Train loss 0.06 Classification-F1 0.596782230543128 on epoch=17
05/27/2022 23:15:27 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.09 on epoch=17
05/27/2022 23:15:30 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=18
05/27/2022 23:15:32 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.04 on epoch=18
05/27/2022 23:15:35 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.15 on epoch=18
05/27/2022 23:15:38 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.05 on epoch=18
05/27/2022 23:16:27 - INFO - __main__ - Global step 2050 Train loss 0.07 Classification-F1 0.49740564802154724 on epoch=18
05/27/2022 23:16:30 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.04 on epoch=18
05/27/2022 23:16:33 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.05 on epoch=18
05/27/2022 23:16:35 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.09 on epoch=18
05/27/2022 23:16:38 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.05 on epoch=18
05/27/2022 23:16:40 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=18
05/27/2022 23:17:29 - INFO - __main__ - Global step 2100 Train loss 0.05 Classification-F1 0.5661877351749863 on epoch=18
05/27/2022 23:17:32 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.10 on epoch=18
05/27/2022 23:17:35 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.07 on epoch=18
05/27/2022 23:17:37 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.05 on epoch=19
05/27/2022 23:17:40 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.05 on epoch=19
05/27/2022 23:17:43 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=19
05/27/2022 23:18:32 - INFO - __main__ - Global step 2150 Train loss 0.06 Classification-F1 0.5701735865331711 on epoch=19
05/27/2022 23:18:35 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.08 on epoch=19
05/27/2022 23:18:37 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.05 on epoch=19
05/27/2022 23:18:40 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=19
05/27/2022 23:18:42 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.05 on epoch=19
05/27/2022 23:18:45 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.04 on epoch=19
05/27/2022 23:19:35 - INFO - __main__ - Global step 2200 Train loss 0.05 Classification-F1 0.6452232947842176 on epoch=19
05/27/2022 23:19:35 - INFO - __main__ - Saving model with best Classification-F1: 0.6105770508889187 -> 0.6452232947842176 on epoch=19, global_step=2200
05/27/2022 23:19:38 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=19
05/27/2022 23:19:40 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.05 on epoch=19
05/27/2022 23:19:43 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.05 on epoch=19
05/27/2022 23:19:46 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.05 on epoch=19
05/27/2022 23:19:48 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.04 on epoch=20
05/27/2022 23:20:38 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.5504915048470589 on epoch=20
05/27/2022 23:20:40 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.03 on epoch=20
05/27/2022 23:20:43 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.06 on epoch=20
05/27/2022 23:20:45 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.06 on epoch=20
05/27/2022 23:20:48 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.04 on epoch=20
05/27/2022 23:20:51 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=20
05/27/2022 23:21:41 - INFO - __main__ - Global step 2300 Train loss 0.05 Classification-F1 0.6441661236572641 on epoch=20
05/27/2022 23:21:44 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.09 on epoch=20
05/27/2022 23:21:46 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=20
05/27/2022 23:21:49 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.09 on epoch=20
05/27/2022 23:21:52 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.11 on epoch=20
05/27/2022 23:21:54 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=20
05/27/2022 23:22:44 - INFO - __main__ - Global step 2350 Train loss 0.07 Classification-F1 0.6394584844511871 on epoch=20
05/27/2022 23:22:47 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=21
05/27/2022 23:22:50 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.05 on epoch=21
05/27/2022 23:22:52 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.10 on epoch=21
05/27/2022 23:22:55 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=21
05/27/2022 23:22:58 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.03 on epoch=21
05/27/2022 23:23:47 - INFO - __main__ - Global step 2400 Train loss 0.05 Classification-F1 0.5384687739239898 on epoch=21
05/27/2022 23:23:50 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.05 on epoch=21
05/27/2022 23:23:52 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.05 on epoch=21
05/27/2022 23:23:55 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=21
05/27/2022 23:23:58 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.04 on epoch=21
05/27/2022 23:24:00 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.08 on epoch=21
05/27/2022 23:24:49 - INFO - __main__ - Global step 2450 Train loss 0.05 Classification-F1 0.5561235098432834 on epoch=21
05/27/2022 23:24:52 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.06 on epoch=21
05/27/2022 23:24:54 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=22
05/27/2022 23:24:57 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.03 on epoch=22
05/27/2022 23:25:00 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.05 on epoch=22
05/27/2022 23:25:02 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=22
05/27/2022 23:25:52 - INFO - __main__ - Global step 2500 Train loss 0.04 Classification-F1 0.45721230525269324 on epoch=22
05/27/2022 23:25:55 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.08 on epoch=22
05/27/2022 23:25:57 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.05 on epoch=22
05/27/2022 23:26:00 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.06 on epoch=22
05/27/2022 23:26:03 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.07 on epoch=22
05/27/2022 23:26:05 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.09 on epoch=22
05/27/2022 23:26:54 - INFO - __main__ - Global step 2550 Train loss 0.07 Classification-F1 0.5527781362858409 on epoch=22
05/27/2022 23:26:57 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.04 on epoch=22
05/27/2022 23:27:00 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.10 on epoch=22
05/27/2022 23:27:02 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=23
05/27/2022 23:27:05 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.03 on epoch=23
05/27/2022 23:27:08 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.07 on epoch=23
05/27/2022 23:27:56 - INFO - __main__ - Global step 2600 Train loss 0.05 Classification-F1 0.5679005292628284 on epoch=23
05/27/2022 23:27:59 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.03 on epoch=23
05/27/2022 23:28:02 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.05 on epoch=23
05/27/2022 23:28:04 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.03 on epoch=23
05/27/2022 23:28:07 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.06 on epoch=23
05/27/2022 23:28:10 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.05 on epoch=23
05/27/2022 23:28:59 - INFO - __main__ - Global step 2650 Train loss 0.04 Classification-F1 0.5654011029961135 on epoch=23
05/27/2022 23:29:02 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.04 on epoch=23
05/27/2022 23:29:04 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.07 on epoch=23
05/27/2022 23:29:07 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.06 on epoch=23
05/27/2022 23:29:10 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=24
05/27/2022 23:29:12 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.06 on epoch=24
05/27/2022 23:30:02 - INFO - __main__ - Global step 2700 Train loss 0.05 Classification-F1 0.5880547043057188 on epoch=24
05/27/2022 23:30:04 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=24
05/27/2022 23:30:07 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.05 on epoch=24
05/27/2022 23:30:10 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.06 on epoch=24
05/27/2022 23:30:12 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.04 on epoch=24
05/27/2022 23:30:15 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.04 on epoch=24
05/27/2022 23:31:04 - INFO - __main__ - Global step 2750 Train loss 0.04 Classification-F1 0.5846956499407042 on epoch=24
05/27/2022 23:31:07 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.04 on epoch=24
05/27/2022 23:31:09 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.03 on epoch=24
05/27/2022 23:31:12 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.08 on epoch=24
05/27/2022 23:31:14 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.06 on epoch=24
05/27/2022 23:31:17 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.03 on epoch=24
05/27/2022 23:32:06 - INFO - __main__ - Global step 2800 Train loss 0.05 Classification-F1 0.5220793446611324 on epoch=24
05/27/2022 23:32:09 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=25
05/27/2022 23:32:11 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=25
05/27/2022 23:32:14 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.06 on epoch=25
05/27/2022 23:32:16 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.05 on epoch=25
05/27/2022 23:32:19 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.03 on epoch=25
05/27/2022 23:33:08 - INFO - __main__ - Global step 2850 Train loss 0.04 Classification-F1 0.4931913437440435 on epoch=25
05/27/2022 23:33:10 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=25
05/27/2022 23:33:13 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.11 on epoch=25
05/27/2022 23:33:16 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=25
05/27/2022 23:33:18 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.09 on epoch=25
05/27/2022 23:33:21 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.04 on epoch=25
05/27/2022 23:34:10 - INFO - __main__ - Global step 2900 Train loss 0.05 Classification-F1 0.5198498760728146 on epoch=25
05/27/2022 23:34:12 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=25
05/27/2022 23:34:15 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=26
05/27/2022 23:34:18 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.07 on epoch=26
05/27/2022 23:34:20 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.04 on epoch=26
05/27/2022 23:34:23 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=26
05/27/2022 23:35:11 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.4099265230638779 on epoch=26
05/27/2022 23:35:14 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.04 on epoch=26
05/27/2022 23:35:17 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.05 on epoch=26
05/27/2022 23:35:19 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.03 on epoch=26
05/27/2022 23:35:22 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=26
05/27/2022 23:35:25 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.10 on epoch=26
05/27/2022 23:35:26 - INFO - __main__ - Start tokenizing ... 1792 instances
05/27/2022 23:35:26 - INFO - __main__ - Printing 3 examples
05/27/2022 23:35:26 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/27/2022 23:35:26 - INFO - __main__ - ['Animal']
05/27/2022 23:35:26 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/27/2022 23:35:26 - INFO - __main__ - ['Animal']
05/27/2022 23:35:26 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/27/2022 23:35:26 - INFO - __main__ - ['Animal']
05/27/2022 23:35:26 - INFO - __main__ - Tokenizing Input ...
05/27/2022 23:35:27 - INFO - __main__ - Tokenizing Output ...
05/27/2022 23:35:29 - INFO - __main__ - Loaded 1792 examples from train data
05/27/2022 23:35:29 - INFO - __main__ - Start tokenizing ... 1792 instances
05/27/2022 23:35:29 - INFO - __main__ - Printing 3 examples
05/27/2022 23:35:29 - INFO - __main__ -  [dbpedia_14] Palaephatus fusciterminus is a moth of the Palaephatidae family. It is found in the Valdivian forests of southern Argentina and Chile.The length of the forewings is 10-12 mm for males and 10.5-11.5 mm for females. Adults have a buff to brown head and thorax and dark brownish fuscous forewings with a pale buff hindmargin. They are on wing from October to March possibly in multiple generations per year.
05/27/2022 23:35:29 - INFO - __main__ - ['Animal']
05/27/2022 23:35:29 - INFO - __main__ -  [dbpedia_14] Labus is an indomalayan genus of potter wasps.
05/27/2022 23:35:29 - INFO - __main__ - ['Animal']
05/27/2022 23:35:29 - INFO - __main__ -  [dbpedia_14] Trifurcula beirnei is a moth of the Nepticulidae family. It is found in Great Britain Denmark and parts of Germany and Poland Austria the Czech Republic Slovakia and Hungary. It is also found in the Volga and Ural region of Russia.The wingspan is 8–11 mm. Adults are on wing from the end of June to late September.The larvae feed on Genista species including Genista tinctoria Genista germanica and Genista pilosa.
05/27/2022 23:35:29 - INFO - __main__ - ['Animal']
05/27/2022 23:35:29 - INFO - __main__ - Tokenizing Input ...
05/27/2022 23:35:30 - INFO - __main__ - Tokenizing Output ...
05/27/2022 23:35:31 - INFO - __main__ - Loaded 1792 examples from dev data
05/27/2022 23:35:47 - INFO - __main__ - load prompt embedding from ckpt
05/27/2022 23:35:47 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/27/2022 23:35:47 - INFO - __main__ - Starting training!
05/27/2022 23:36:15 - INFO - __main__ - Global step 3000 Train loss 0.05 Classification-F1 0.5857144672277552 on epoch=26
05/27/2022 23:36:15 - INFO - __main__ - save last model!
05/27/2022 23:36:15 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/27/2022 23:36:15 - INFO - __main__ - Start tokenizing ... 3500 instances
05/27/2022 23:36:15 - INFO - __main__ - Printing 3 examples
05/27/2022 23:36:15 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/27/2022 23:36:15 - INFO - __main__ - ['Animal']
05/27/2022 23:36:15 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/27/2022 23:36:15 - INFO - __main__ - ['Animal']
05/27/2022 23:36:15 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/27/2022 23:36:15 - INFO - __main__ - ['Village']
05/27/2022 23:36:15 - INFO - __main__ - Tokenizing Input ...
05/27/2022 23:36:17 - INFO - __main__ - Tokenizing Output ...
05/27/2022 23:36:20 - INFO - __main__ - Loaded 3500 examples from test data
05/27/2022 23:38:25 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down128shot/singletask-dbpedia_14/dbpedia_14_128_100_0.4_8_predictions.txt
05/27/2022 23:38:25 - INFO - __main__ - Classification-F1 on test data: 0.4315
05/27/2022 23:38:25 - INFO - __main__ - prefix=dbpedia_14_128_100, lr=0.4, bsz=8, dev_performance=0.6452232947842176, test_performance=0.4315190888702649
05/27/2022 23:38:25 - INFO - __main__ - Running ... prefix=dbpedia_14_128_100, lr=0.3, bsz=8 ...
05/27/2022 23:38:26 - INFO - __main__ - Start tokenizing ... 1792 instances
05/27/2022 23:38:26 - INFO - __main__ - Printing 3 examples
05/27/2022 23:38:26 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/27/2022 23:38:26 - INFO - __main__ - ['Animal']
05/27/2022 23:38:26 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/27/2022 23:38:26 - INFO - __main__ - ['Animal']
05/27/2022 23:38:26 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/27/2022 23:38:26 - INFO - __main__ - ['Animal']
05/27/2022 23:38:26 - INFO - __main__ - Tokenizing Input ...
05/27/2022 23:38:27 - INFO - __main__ - Tokenizing Output ...
05/27/2022 23:38:29 - INFO - __main__ - Loaded 1792 examples from train data
05/27/2022 23:38:29 - INFO - __main__ - Start tokenizing ... 1792 instances
05/27/2022 23:38:29 - INFO - __main__ - Printing 3 examples
05/27/2022 23:38:29 - INFO - __main__ -  [dbpedia_14] Palaephatus fusciterminus is a moth of the Palaephatidae family. It is found in the Valdivian forests of southern Argentina and Chile.The length of the forewings is 10-12 mm for males and 10.5-11.5 mm for females. Adults have a buff to brown head and thorax and dark brownish fuscous forewings with a pale buff hindmargin. They are on wing from October to March possibly in multiple generations per year.
05/27/2022 23:38:29 - INFO - __main__ - ['Animal']
05/27/2022 23:38:29 - INFO - __main__ -  [dbpedia_14] Labus is an indomalayan genus of potter wasps.
05/27/2022 23:38:29 - INFO - __main__ - ['Animal']
05/27/2022 23:38:29 - INFO - __main__ -  [dbpedia_14] Trifurcula beirnei is a moth of the Nepticulidae family. It is found in Great Britain Denmark and parts of Germany and Poland Austria the Czech Republic Slovakia and Hungary. It is also found in the Volga and Ural region of Russia.The wingspan is 8–11 mm. Adults are on wing from the end of June to late September.The larvae feed on Genista species including Genista tinctoria Genista germanica and Genista pilosa.
05/27/2022 23:38:29 - INFO - __main__ - ['Animal']
05/27/2022 23:38:29 - INFO - __main__ - Tokenizing Input ...
05/27/2022 23:38:30 - INFO - __main__ - Tokenizing Output ...
05/27/2022 23:38:32 - INFO - __main__ - Loaded 1792 examples from dev data
05/27/2022 23:38:49 - INFO - __main__ - load prompt embedding from ckpt
05/27/2022 23:38:50 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/27/2022 23:38:50 - INFO - __main__ - Starting training!
05/27/2022 23:38:54 - INFO - __main__ - Step 10 Global step 10 Train loss 7.37 on epoch=0
05/27/2022 23:38:56 - INFO - __main__ - Step 20 Global step 20 Train loss 5.60 on epoch=0
05/27/2022 23:38:59 - INFO - __main__ - Step 30 Global step 30 Train loss 4.52 on epoch=0
05/27/2022 23:39:01 - INFO - __main__ - Step 40 Global step 40 Train loss 4.07 on epoch=0
05/27/2022 23:39:04 - INFO - __main__ - Step 50 Global step 50 Train loss 3.88 on epoch=0
05/27/2022 23:40:00 - INFO - __main__ - Global step 50 Train loss 5.09 Classification-F1 0.00758591541678187 on epoch=0
05/27/2022 23:40:00 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.00758591541678187 on epoch=0, global_step=50
05/27/2022 23:40:02 - INFO - __main__ - Step 60 Global step 60 Train loss 3.20 on epoch=0
05/27/2022 23:40:05 - INFO - __main__ - Step 70 Global step 70 Train loss 3.01 on epoch=0
05/27/2022 23:40:08 - INFO - __main__ - Step 80 Global step 80 Train loss 2.75 on epoch=0
05/27/2022 23:40:10 - INFO - __main__ - Step 90 Global step 90 Train loss 2.76 on epoch=0
05/27/2022 23:40:13 - INFO - __main__ - Step 100 Global step 100 Train loss 2.33 on epoch=0
05/27/2022 23:41:04 - INFO - __main__ - Global step 100 Train loss 2.81 Classification-F1 0.020408312375538723 on epoch=0
05/27/2022 23:41:04 - INFO - __main__ - Saving model with best Classification-F1: 0.00758591541678187 -> 0.020408312375538723 on epoch=0, global_step=100
05/27/2022 23:41:06 - INFO - __main__ - Step 110 Global step 110 Train loss 2.42 on epoch=0
05/27/2022 23:41:09 - INFO - __main__ - Step 120 Global step 120 Train loss 2.33 on epoch=1
05/27/2022 23:41:11 - INFO - __main__ - Step 130 Global step 130 Train loss 2.01 on epoch=1
05/27/2022 23:41:14 - INFO - __main__ - Step 140 Global step 140 Train loss 2.00 on epoch=1
05/27/2022 23:41:16 - INFO - __main__ - Step 150 Global step 150 Train loss 1.75 on epoch=1
05/27/2022 23:42:02 - INFO - __main__ - Global step 150 Train loss 2.10 Classification-F1 0.04158345463891084 on epoch=1
05/27/2022 23:42:02 - INFO - __main__ - Saving model with best Classification-F1: 0.020408312375538723 -> 0.04158345463891084 on epoch=1, global_step=150
05/27/2022 23:42:05 - INFO - __main__ - Step 160 Global step 160 Train loss 1.94 on epoch=1
05/27/2022 23:42:07 - INFO - __main__ - Step 170 Global step 170 Train loss 1.48 on epoch=1
05/27/2022 23:42:10 - INFO - __main__ - Step 180 Global step 180 Train loss 1.47 on epoch=1
05/27/2022 23:42:12 - INFO - __main__ - Step 190 Global step 190 Train loss 1.57 on epoch=1
05/27/2022 23:42:15 - INFO - __main__ - Step 200 Global step 200 Train loss 1.51 on epoch=1
05/27/2022 23:43:00 - INFO - __main__ - Global step 200 Train loss 1.59 Classification-F1 0.0759824722178226 on epoch=1
05/27/2022 23:43:00 - INFO - __main__ - Saving model with best Classification-F1: 0.04158345463891084 -> 0.0759824722178226 on epoch=1, global_step=200
05/27/2022 23:43:03 - INFO - __main__ - Step 210 Global step 210 Train loss 1.43 on epoch=1
05/27/2022 23:43:05 - INFO - __main__ - Step 220 Global step 220 Train loss 1.36 on epoch=1
05/27/2022 23:43:08 - INFO - __main__ - Step 230 Global step 230 Train loss 1.23 on epoch=2
05/27/2022 23:43:10 - INFO - __main__ - Step 240 Global step 240 Train loss 1.17 on epoch=2
05/27/2022 23:43:13 - INFO - __main__ - Step 250 Global step 250 Train loss 1.22 on epoch=2
05/27/2022 23:43:57 - INFO - __main__ - Global step 250 Train loss 1.28 Classification-F1 0.11537147617444478 on epoch=2
05/27/2022 23:43:57 - INFO - __main__ - Saving model with best Classification-F1: 0.0759824722178226 -> 0.11537147617444478 on epoch=2, global_step=250
05/27/2022 23:44:00 - INFO - __main__ - Step 260 Global step 260 Train loss 1.04 on epoch=2
05/27/2022 23:44:03 - INFO - __main__ - Step 270 Global step 270 Train loss 0.96 on epoch=2
05/27/2022 23:44:05 - INFO - __main__ - Step 280 Global step 280 Train loss 0.80 on epoch=2
05/27/2022 23:44:08 - INFO - __main__ - Step 290 Global step 290 Train loss 0.73 on epoch=2
05/27/2022 23:44:10 - INFO - __main__ - Step 300 Global step 300 Train loss 0.79 on epoch=2
05/27/2022 23:44:57 - INFO - __main__ - Global step 300 Train loss 0.86 Classification-F1 0.19915254796511284 on epoch=2
05/27/2022 23:44:57 - INFO - __main__ - Saving model with best Classification-F1: 0.11537147617444478 -> 0.19915254796511284 on epoch=2, global_step=300
05/27/2022 23:45:00 - INFO - __main__ - Step 310 Global step 310 Train loss 0.71 on epoch=2
05/27/2022 23:45:03 - INFO - __main__ - Step 320 Global step 320 Train loss 0.71 on epoch=2
05/27/2022 23:45:05 - INFO - __main__ - Step 330 Global step 330 Train loss 0.71 on epoch=2
05/27/2022 23:45:08 - INFO - __main__ - Step 340 Global step 340 Train loss 0.63 on epoch=3
05/27/2022 23:45:10 - INFO - __main__ - Step 350 Global step 350 Train loss 0.65 on epoch=3
05/27/2022 23:45:59 - INFO - __main__ - Global step 350 Train loss 0.68 Classification-F1 0.22329598890236374 on epoch=3
05/27/2022 23:45:59 - INFO - __main__ - Saving model with best Classification-F1: 0.19915254796511284 -> 0.22329598890236374 on epoch=3, global_step=350
05/27/2022 23:46:02 - INFO - __main__ - Step 360 Global step 360 Train loss 0.68 on epoch=3
05/27/2022 23:46:04 - INFO - __main__ - Step 370 Global step 370 Train loss 0.47 on epoch=3
05/27/2022 23:46:06 - INFO - __main__ - Step 380 Global step 380 Train loss 0.51 on epoch=3
05/27/2022 23:46:09 - INFO - __main__ - Step 390 Global step 390 Train loss 0.43 on epoch=3
05/27/2022 23:46:12 - INFO - __main__ - Step 400 Global step 400 Train loss 0.57 on epoch=3
05/27/2022 23:47:01 - INFO - __main__ - Global step 400 Train loss 0.53 Classification-F1 0.2894473047248277 on epoch=3
05/27/2022 23:47:02 - INFO - __main__ - Saving model with best Classification-F1: 0.22329598890236374 -> 0.2894473047248277 on epoch=3, global_step=400
05/27/2022 23:47:04 - INFO - __main__ - Step 410 Global step 410 Train loss 0.53 on epoch=3
05/27/2022 23:47:07 - INFO - __main__ - Step 420 Global step 420 Train loss 0.42 on epoch=3
05/27/2022 23:47:09 - INFO - __main__ - Step 430 Global step 430 Train loss 0.44 on epoch=3
05/27/2022 23:47:12 - INFO - __main__ - Step 440 Global step 440 Train loss 0.40 on epoch=3
05/27/2022 23:47:14 - INFO - __main__ - Step 450 Global step 450 Train loss 0.41 on epoch=4
05/27/2022 23:48:06 - INFO - __main__ - Global step 450 Train loss 0.44 Classification-F1 0.32122717173287285 on epoch=4
05/27/2022 23:48:06 - INFO - __main__ - Saving model with best Classification-F1: 0.2894473047248277 -> 0.32122717173287285 on epoch=4, global_step=450
05/27/2022 23:48:08 - INFO - __main__ - Step 460 Global step 460 Train loss 0.41 on epoch=4
05/27/2022 23:48:11 - INFO - __main__ - Step 470 Global step 470 Train loss 0.38 on epoch=4
05/27/2022 23:48:13 - INFO - __main__ - Step 480 Global step 480 Train loss 0.34 on epoch=4
05/27/2022 23:48:16 - INFO - __main__ - Step 490 Global step 490 Train loss 0.32 on epoch=4
05/27/2022 23:48:19 - INFO - __main__ - Step 500 Global step 500 Train loss 0.33 on epoch=4
05/27/2022 23:49:10 - INFO - __main__ - Global step 500 Train loss 0.36 Classification-F1 0.31579524706118484 on epoch=4
05/27/2022 23:49:12 - INFO - __main__ - Step 510 Global step 510 Train loss 0.30 on epoch=4
05/27/2022 23:49:15 - INFO - __main__ - Step 520 Global step 520 Train loss 0.30 on epoch=4
05/27/2022 23:49:17 - INFO - __main__ - Step 530 Global step 530 Train loss 0.34 on epoch=4
05/27/2022 23:49:20 - INFO - __main__ - Step 540 Global step 540 Train loss 0.39 on epoch=4
05/27/2022 23:49:22 - INFO - __main__ - Step 550 Global step 550 Train loss 0.31 on epoch=4
05/27/2022 23:50:14 - INFO - __main__ - Global step 550 Train loss 0.33 Classification-F1 0.2930335831484294 on epoch=4
05/27/2022 23:50:16 - INFO - __main__ - Step 560 Global step 560 Train loss 0.29 on epoch=4
05/27/2022 23:50:19 - INFO - __main__ - Step 570 Global step 570 Train loss 0.32 on epoch=5
05/27/2022 23:50:22 - INFO - __main__ - Step 580 Global step 580 Train loss 0.27 on epoch=5
05/27/2022 23:50:24 - INFO - __main__ - Step 590 Global step 590 Train loss 0.27 on epoch=5
05/27/2022 23:50:27 - INFO - __main__ - Step 600 Global step 600 Train loss 0.30 on epoch=5
05/27/2022 23:51:18 - INFO - __main__ - Global step 600 Train loss 0.29 Classification-F1 0.3619353787396323 on epoch=5
05/27/2022 23:51:18 - INFO - __main__ - Saving model with best Classification-F1: 0.32122717173287285 -> 0.3619353787396323 on epoch=5, global_step=600
05/27/2022 23:51:20 - INFO - __main__ - Step 610 Global step 610 Train loss 0.29 on epoch=5
05/27/2022 23:51:23 - INFO - __main__ - Step 620 Global step 620 Train loss 0.26 on epoch=5
05/27/2022 23:51:25 - INFO - __main__ - Step 630 Global step 630 Train loss 0.28 on epoch=5
05/27/2022 23:51:28 - INFO - __main__ - Step 640 Global step 640 Train loss 0.20 on epoch=5
05/27/2022 23:51:31 - INFO - __main__ - Step 650 Global step 650 Train loss 0.31 on epoch=5
05/27/2022 23:52:22 - INFO - __main__ - Global step 650 Train loss 0.27 Classification-F1 0.3682582063486824 on epoch=5
05/27/2022 23:52:22 - INFO - __main__ - Saving model with best Classification-F1: 0.3619353787396323 -> 0.3682582063486824 on epoch=5, global_step=650
05/27/2022 23:52:24 - INFO - __main__ - Step 660 Global step 660 Train loss 0.25 on epoch=5
05/27/2022 23:52:27 - INFO - __main__ - Step 670 Global step 670 Train loss 0.22 on epoch=5
05/27/2022 23:52:30 - INFO - __main__ - Step 680 Global step 680 Train loss 0.20 on epoch=6
05/27/2022 23:52:32 - INFO - __main__ - Step 690 Global step 690 Train loss 0.25 on epoch=6
05/27/2022 23:52:35 - INFO - __main__ - Step 700 Global step 700 Train loss 0.29 on epoch=6
05/27/2022 23:53:25 - INFO - __main__ - Global step 700 Train loss 0.24 Classification-F1 0.3395896324340319 on epoch=6
05/27/2022 23:53:27 - INFO - __main__ - Step 710 Global step 710 Train loss 0.22 on epoch=6
05/27/2022 23:53:30 - INFO - __main__ - Step 720 Global step 720 Train loss 0.21 on epoch=6
05/27/2022 23:53:32 - INFO - __main__ - Step 730 Global step 730 Train loss 0.27 on epoch=6
05/27/2022 23:53:35 - INFO - __main__ - Step 740 Global step 740 Train loss 0.18 on epoch=6
05/27/2022 23:53:37 - INFO - __main__ - Step 750 Global step 750 Train loss 0.23 on epoch=6
05/27/2022 23:54:29 - INFO - __main__ - Global step 750 Train loss 0.22 Classification-F1 0.41781614560364155 on epoch=6
05/27/2022 23:54:29 - INFO - __main__ - Saving model with best Classification-F1: 0.3682582063486824 -> 0.41781614560364155 on epoch=6, global_step=750
05/27/2022 23:54:32 - INFO - __main__ - Step 760 Global step 760 Train loss 0.16 on epoch=6
05/27/2022 23:54:34 - INFO - __main__ - Step 770 Global step 770 Train loss 0.25 on epoch=6
05/27/2022 23:54:37 - INFO - __main__ - Step 780 Global step 780 Train loss 0.21 on epoch=6
05/27/2022 23:54:39 - INFO - __main__ - Step 790 Global step 790 Train loss 0.17 on epoch=7
05/27/2022 23:54:42 - INFO - __main__ - Step 800 Global step 800 Train loss 0.16 on epoch=7
05/27/2022 23:55:32 - INFO - __main__ - Global step 800 Train loss 0.19 Classification-F1 0.4055042234203879 on epoch=7
05/27/2022 23:55:34 - INFO - __main__ - Step 810 Global step 810 Train loss 0.19 on epoch=7
05/27/2022 23:55:37 - INFO - __main__ - Step 820 Global step 820 Train loss 0.11 on epoch=7
05/27/2022 23:55:39 - INFO - __main__ - Step 830 Global step 830 Train loss 0.19 on epoch=7
05/27/2022 23:55:42 - INFO - __main__ - Step 840 Global step 840 Train loss 0.14 on epoch=7
05/27/2022 23:55:44 - INFO - __main__ - Step 850 Global step 850 Train loss 0.16 on epoch=7
05/27/2022 23:56:35 - INFO - __main__ - Global step 850 Train loss 0.16 Classification-F1 0.4137837405689291 on epoch=7
05/27/2022 23:56:37 - INFO - __main__ - Step 860 Global step 860 Train loss 0.19 on epoch=7
05/27/2022 23:56:40 - INFO - __main__ - Step 870 Global step 870 Train loss 0.23 on epoch=7
05/27/2022 23:56:42 - INFO - __main__ - Step 880 Global step 880 Train loss 0.18 on epoch=7
05/27/2022 23:56:45 - INFO - __main__ - Step 890 Global step 890 Train loss 0.20 on epoch=7
05/27/2022 23:56:47 - INFO - __main__ - Step 900 Global step 900 Train loss 0.18 on epoch=8
05/27/2022 23:57:38 - INFO - __main__ - Global step 900 Train loss 0.19 Classification-F1 0.47330705093361564 on epoch=8
05/27/2022 23:57:38 - INFO - __main__ - Saving model with best Classification-F1: 0.41781614560364155 -> 0.47330705093361564 on epoch=8, global_step=900
05/27/2022 23:57:40 - INFO - __main__ - Step 910 Global step 910 Train loss 0.21 on epoch=8
05/27/2022 23:57:43 - INFO - __main__ - Step 920 Global step 920 Train loss 0.21 on epoch=8
05/27/2022 23:57:46 - INFO - __main__ - Step 930 Global step 930 Train loss 0.19 on epoch=8
05/27/2022 23:57:48 - INFO - __main__ - Step 940 Global step 940 Train loss 0.17 on epoch=8
05/27/2022 23:57:51 - INFO - __main__ - Step 950 Global step 950 Train loss 0.12 on epoch=8
05/27/2022 23:58:42 - INFO - __main__ - Global step 950 Train loss 0.18 Classification-F1 0.44311390915474574 on epoch=8
05/27/2022 23:58:45 - INFO - __main__ - Step 960 Global step 960 Train loss 0.15 on epoch=8
05/27/2022 23:58:47 - INFO - __main__ - Step 970 Global step 970 Train loss 0.17 on epoch=8
05/27/2022 23:58:50 - INFO - __main__ - Step 980 Global step 980 Train loss 0.12 on epoch=8
05/27/2022 23:58:52 - INFO - __main__ - Step 990 Global step 990 Train loss 0.20 on epoch=8
05/27/2022 23:58:55 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.21 on epoch=8
05/27/2022 23:59:45 - INFO - __main__ - Global step 1000 Train loss 0.17 Classification-F1 0.44324389791616753 on epoch=8
05/27/2022 23:59:47 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.15 on epoch=9
05/27/2022 23:59:50 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.21 on epoch=9
05/27/2022 23:59:52 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.17 on epoch=9
05/27/2022 23:59:55 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.16 on epoch=9
05/27/2022 23:59:57 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.15 on epoch=9
05/28/2022 00:00:48 - INFO - __main__ - Global step 1050 Train loss 0.17 Classification-F1 0.4293991989410967 on epoch=9
05/28/2022 00:00:51 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.12 on epoch=9
05/28/2022 00:00:54 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.10 on epoch=9
05/28/2022 00:00:57 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.18 on epoch=9
05/28/2022 00:00:59 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.08 on epoch=9
05/28/2022 00:01:02 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.17 on epoch=9
05/28/2022 00:01:52 - INFO - __main__ - Global step 1100 Train loss 0.13 Classification-F1 0.5173171467761695 on epoch=9
05/28/2022 00:01:52 - INFO - __main__ - Saving model with best Classification-F1: 0.47330705093361564 -> 0.5173171467761695 on epoch=9, global_step=1100
05/28/2022 00:01:55 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.18 on epoch=9
05/28/2022 00:01:58 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.13 on epoch=9
05/28/2022 00:02:00 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.08 on epoch=10
05/28/2022 00:02:03 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.13 on epoch=10
05/28/2022 00:02:06 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.21 on epoch=10
05/28/2022 00:02:56 - INFO - __main__ - Global step 1150 Train loss 0.15 Classification-F1 0.547963424987096 on epoch=10
05/28/2022 00:02:56 - INFO - __main__ - Saving model with best Classification-F1: 0.5173171467761695 -> 0.547963424987096 on epoch=10, global_step=1150
05/28/2022 00:02:58 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.17 on epoch=10
05/28/2022 00:03:01 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.11 on epoch=10
05/28/2022 00:03:03 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.09 on epoch=10
05/28/2022 00:03:06 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.21 on epoch=10
05/28/2022 00:03:08 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.11 on epoch=10
05/28/2022 00:03:59 - INFO - __main__ - Global step 1200 Train loss 0.14 Classification-F1 0.4977439063446576 on epoch=10
05/28/2022 00:04:02 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.15 on epoch=10
05/28/2022 00:04:04 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.11 on epoch=10
05/28/2022 00:04:07 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.09 on epoch=10
05/28/2022 00:04:09 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.11 on epoch=11
05/28/2022 00:04:12 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.07 on epoch=11
05/28/2022 00:05:02 - INFO - __main__ - Global step 1250 Train loss 0.10 Classification-F1 0.5895237398284342 on epoch=11
05/28/2022 00:05:02 - INFO - __main__ - Saving model with best Classification-F1: 0.547963424987096 -> 0.5895237398284342 on epoch=11, global_step=1250
05/28/2022 00:05:04 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.17 on epoch=11
05/28/2022 00:05:07 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.06 on epoch=11
05/28/2022 00:05:09 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.13 on epoch=11
05/28/2022 00:05:12 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.11 on epoch=11
05/28/2022 00:05:14 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.13 on epoch=11
05/28/2022 00:06:05 - INFO - __main__ - Global step 1300 Train loss 0.12 Classification-F1 0.5428291986183181 on epoch=11
05/28/2022 00:06:08 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.09 on epoch=11
05/28/2022 00:06:10 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.17 on epoch=11
05/28/2022 00:06:13 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.13 on epoch=11
05/28/2022 00:06:15 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.14 on epoch=11
05/28/2022 00:06:18 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.10 on epoch=12
05/28/2022 00:07:07 - INFO - __main__ - Global step 1350 Train loss 0.13 Classification-F1 0.4768479119112981 on epoch=12
05/28/2022 00:07:10 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.11 on epoch=12
05/28/2022 00:07:13 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.17 on epoch=12
05/28/2022 00:07:15 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.08 on epoch=12
05/28/2022 00:07:18 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.09 on epoch=12
05/28/2022 00:07:20 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.05 on epoch=12
05/28/2022 00:08:10 - INFO - __main__ - Global step 1400 Train loss 0.10 Classification-F1 0.5524066663443827 on epoch=12
05/28/2022 00:08:13 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.15 on epoch=12
05/28/2022 00:08:16 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.16 on epoch=12
05/28/2022 00:08:18 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.16 on epoch=12
05/28/2022 00:08:21 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.15 on epoch=12
05/28/2022 00:08:23 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.11 on epoch=12
05/28/2022 00:09:15 - INFO - __main__ - Global step 1450 Train loss 0.15 Classification-F1 0.5453568586158095 on epoch=12
05/28/2022 00:09:17 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.11 on epoch=13
05/28/2022 00:09:20 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.11 on epoch=13
05/28/2022 00:09:22 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.16 on epoch=13
05/28/2022 00:09:25 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.13 on epoch=13
05/28/2022 00:09:27 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.09 on epoch=13
05/28/2022 00:10:17 - INFO - __main__ - Global step 1500 Train loss 0.12 Classification-F1 0.4996362483708461 on epoch=13
05/28/2022 00:10:20 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.12 on epoch=13
05/28/2022 00:10:22 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.09 on epoch=13
05/28/2022 00:10:25 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.13 on epoch=13
05/28/2022 00:10:27 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=13
05/28/2022 00:10:30 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.12 on epoch=13
05/28/2022 00:11:20 - INFO - __main__ - Global step 1550 Train loss 0.10 Classification-F1 0.5495770242743228 on epoch=13
05/28/2022 00:11:23 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.15 on epoch=13
05/28/2022 00:11:25 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.06 on epoch=14
05/28/2022 00:11:28 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.08 on epoch=14
05/28/2022 00:11:31 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.09 on epoch=14
05/28/2022 00:11:33 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.12 on epoch=14
05/28/2022 00:12:23 - INFO - __main__ - Global step 1600 Train loss 0.10 Classification-F1 0.5259785244743386 on epoch=14
05/28/2022 00:12:25 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.14 on epoch=14
05/28/2022 00:12:28 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.06 on epoch=14
05/28/2022 00:12:30 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.09 on epoch=14
05/28/2022 00:12:33 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.10 on epoch=14
05/28/2022 00:12:35 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.05 on epoch=14
05/28/2022 00:13:25 - INFO - __main__ - Global step 1650 Train loss 0.09 Classification-F1 0.5472110913138006 on epoch=14
05/28/2022 00:13:28 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.16 on epoch=14
05/28/2022 00:13:30 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.09 on epoch=14
05/28/2022 00:13:33 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.08 on epoch=14
05/28/2022 00:13:35 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.08 on epoch=15
05/28/2022 00:13:38 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.09 on epoch=15
05/28/2022 00:14:27 - INFO - __main__ - Global step 1700 Train loss 0.10 Classification-F1 0.5378159506980275 on epoch=15
05/28/2022 00:14:30 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.14 on epoch=15
05/28/2022 00:14:32 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.06 on epoch=15
05/28/2022 00:14:35 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.03 on epoch=15
05/28/2022 00:14:38 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.08 on epoch=15
05/28/2022 00:14:40 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.06 on epoch=15
05/28/2022 00:15:32 - INFO - __main__ - Global step 1750 Train loss 0.07 Classification-F1 0.5012955394589108 on epoch=15
05/28/2022 00:15:34 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.08 on epoch=15
05/28/2022 00:15:37 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.16 on epoch=15
05/28/2022 00:15:39 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.13 on epoch=15
05/28/2022 00:15:42 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.07 on epoch=15
05/28/2022 00:15:44 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.05 on epoch=16
05/28/2022 00:16:34 - INFO - __main__ - Global step 1800 Train loss 0.10 Classification-F1 0.5491852032433798 on epoch=16
05/28/2022 00:16:36 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.08 on epoch=16
05/28/2022 00:16:39 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.09 on epoch=16
05/28/2022 00:16:41 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=16
05/28/2022 00:16:44 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.09 on epoch=16
05/28/2022 00:16:46 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.07 on epoch=16
05/28/2022 00:17:36 - INFO - __main__ - Global step 1850 Train loss 0.07 Classification-F1 0.5182880390685077 on epoch=16
05/28/2022 00:17:38 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.09 on epoch=16
05/28/2022 00:17:41 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.09 on epoch=16
05/28/2022 00:17:43 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.14 on epoch=16
05/28/2022 00:17:46 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.14 on epoch=16
05/28/2022 00:17:49 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.12 on epoch=16
05/28/2022 00:18:38 - INFO - __main__ - Global step 1900 Train loss 0.12 Classification-F1 0.544802703072122 on epoch=16
05/28/2022 00:18:41 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.04 on epoch=17
05/28/2022 00:18:44 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.12 on epoch=17
05/28/2022 00:18:46 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.08 on epoch=17
05/28/2022 00:18:49 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.07 on epoch=17
05/28/2022 00:18:51 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.08 on epoch=17
05/28/2022 00:19:41 - INFO - __main__ - Global step 1950 Train loss 0.08 Classification-F1 0.5274474475257492 on epoch=17
05/28/2022 00:19:44 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.03 on epoch=17
05/28/2022 00:19:46 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.05 on epoch=17
05/28/2022 00:19:49 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.05 on epoch=17
05/28/2022 00:19:52 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.09 on epoch=17
05/28/2022 00:19:54 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.05 on epoch=17
05/28/2022 00:20:46 - INFO - __main__ - Global step 2000 Train loss 0.05 Classification-F1 0.5651411609092886 on epoch=17
05/28/2022 00:20:48 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.10 on epoch=17
05/28/2022 00:20:51 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.05 on epoch=18
05/28/2022 00:20:54 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.07 on epoch=18
05/28/2022 00:20:56 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.08 on epoch=18
05/28/2022 00:20:59 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.08 on epoch=18
05/28/2022 00:21:49 - INFO - __main__ - Global step 2050 Train loss 0.07 Classification-F1 0.465307447034209 on epoch=18
05/28/2022 00:21:52 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.10 on epoch=18
05/28/2022 00:21:55 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.05 on epoch=18
05/28/2022 00:21:57 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.06 on epoch=18
05/28/2022 00:22:00 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.07 on epoch=18
05/28/2022 00:22:02 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.05 on epoch=18
05/28/2022 00:22:53 - INFO - __main__ - Global step 2100 Train loss 0.07 Classification-F1 0.46880105390185584 on epoch=18
05/28/2022 00:22:56 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.10 on epoch=18
05/28/2022 00:22:59 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.08 on epoch=18
05/28/2022 00:23:01 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.07 on epoch=19
05/28/2022 00:23:04 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.04 on epoch=19
05/28/2022 00:23:06 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.08 on epoch=19
05/28/2022 00:23:56 - INFO - __main__ - Global step 2150 Train loss 0.07 Classification-F1 0.4871528459321733 on epoch=19
05/28/2022 00:23:58 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.09 on epoch=19
05/28/2022 00:24:01 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.09 on epoch=19
05/28/2022 00:24:03 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.09 on epoch=19
05/28/2022 00:24:06 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.04 on epoch=19
05/28/2022 00:24:09 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.05 on epoch=19
05/28/2022 00:24:58 - INFO - __main__ - Global step 2200 Train loss 0.07 Classification-F1 0.4490069557365825 on epoch=19
05/28/2022 00:25:01 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.03 on epoch=19
05/28/2022 00:25:03 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.18 on epoch=19
05/28/2022 00:25:06 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.07 on epoch=19
05/28/2022 00:25:08 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.03 on epoch=19
05/28/2022 00:25:11 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.07 on epoch=20
05/28/2022 00:26:01 - INFO - __main__ - Global step 2250 Train loss 0.08 Classification-F1 0.5805167535153118 on epoch=20
05/28/2022 00:26:04 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.05 on epoch=20
05/28/2022 00:26:07 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.09 on epoch=20
05/28/2022 00:26:09 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.09 on epoch=20
05/28/2022 00:26:12 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.04 on epoch=20
05/28/2022 00:26:15 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.06 on epoch=20
05/28/2022 00:27:05 - INFO - __main__ - Global step 2300 Train loss 0.07 Classification-F1 0.5847928736056427 on epoch=20
05/28/2022 00:27:07 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.04 on epoch=20
05/28/2022 00:27:10 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.06 on epoch=20
05/28/2022 00:27:13 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.10 on epoch=20
05/28/2022 00:27:15 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.09 on epoch=20
05/28/2022 00:27:18 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.04 on epoch=20
05/28/2022 00:28:08 - INFO - __main__ - Global step 2350 Train loss 0.07 Classification-F1 0.5780997053369311 on epoch=20
05/28/2022 00:28:10 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=21
05/28/2022 00:28:13 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.06 on epoch=21
05/28/2022 00:28:15 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.08 on epoch=21
05/28/2022 00:28:18 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=21
05/28/2022 00:28:20 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.08 on epoch=21
05/28/2022 00:29:10 - INFO - __main__ - Global step 2400 Train loss 0.05 Classification-F1 0.5284685004168451 on epoch=21
05/28/2022 00:29:13 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.07 on epoch=21
05/28/2022 00:29:16 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.10 on epoch=21
05/28/2022 00:29:18 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.04 on epoch=21
05/28/2022 00:29:21 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.11 on epoch=21
05/28/2022 00:29:23 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=21
05/28/2022 00:30:13 - INFO - __main__ - Global step 2450 Train loss 0.07 Classification-F1 0.5332862036607161 on epoch=21
05/28/2022 00:30:15 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.06 on epoch=21
05/28/2022 00:30:18 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.04 on epoch=22
05/28/2022 00:30:21 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.05 on epoch=22
05/28/2022 00:30:23 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.12 on epoch=22
05/28/2022 00:30:26 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.04 on epoch=22
05/28/2022 00:31:16 - INFO - __main__ - Global step 2500 Train loss 0.06 Classification-F1 0.5063349598091881 on epoch=22
05/28/2022 00:31:18 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.07 on epoch=22
05/28/2022 00:31:21 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.04 on epoch=22
05/28/2022 00:31:23 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.06 on epoch=22
05/28/2022 00:31:26 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=22
05/28/2022 00:31:29 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.08 on epoch=22
05/28/2022 00:32:19 - INFO - __main__ - Global step 2550 Train loss 0.05 Classification-F1 0.5693262517188831 on epoch=22
05/28/2022 00:32:22 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.04 on epoch=22
05/28/2022 00:32:24 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.08 on epoch=22
05/28/2022 00:32:27 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=23
05/28/2022 00:32:29 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.06 on epoch=23
05/28/2022 00:32:32 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.15 on epoch=23
05/28/2022 00:33:22 - INFO - __main__ - Global step 2600 Train loss 0.07 Classification-F1 0.5990607231380147 on epoch=23
05/28/2022 00:33:22 - INFO - __main__ - Saving model with best Classification-F1: 0.5895237398284342 -> 0.5990607231380147 on epoch=23, global_step=2600
05/28/2022 00:33:25 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.03 on epoch=23
05/28/2022 00:33:27 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.07 on epoch=23
05/28/2022 00:33:30 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.04 on epoch=23
05/28/2022 00:33:32 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.05 on epoch=23
05/28/2022 00:33:35 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.05 on epoch=23
05/28/2022 00:34:26 - INFO - __main__ - Global step 2650 Train loss 0.05 Classification-F1 0.5773382160471165 on epoch=23
05/28/2022 00:34:28 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.06 on epoch=23
05/28/2022 00:34:31 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.08 on epoch=23
05/28/2022 00:34:34 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.07 on epoch=23
05/28/2022 00:34:36 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.05 on epoch=24
05/28/2022 00:34:39 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.07 on epoch=24
05/28/2022 00:35:29 - INFO - __main__ - Global step 2700 Train loss 0.07 Classification-F1 0.5323695057603772 on epoch=24
05/28/2022 00:35:32 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.04 on epoch=24
05/28/2022 00:35:34 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.09 on epoch=24
05/28/2022 00:35:37 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.09 on epoch=24
05/28/2022 00:35:39 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.03 on epoch=24
05/28/2022 00:35:42 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.07 on epoch=24
05/28/2022 00:36:32 - INFO - __main__ - Global step 2750 Train loss 0.06 Classification-F1 0.5209423663088083 on epoch=24
05/28/2022 00:36:35 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.06 on epoch=24
05/28/2022 00:36:37 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=24
05/28/2022 00:36:40 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.11 on epoch=24
05/28/2022 00:36:43 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.04 on epoch=24
05/28/2022 00:36:45 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.09 on epoch=24
05/28/2022 00:37:36 - INFO - __main__ - Global step 2800 Train loss 0.06 Classification-F1 0.5146072884761153 on epoch=24
05/28/2022 00:37:38 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.03 on epoch=25
05/28/2022 00:37:41 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.05 on epoch=25
05/28/2022 00:37:43 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.07 on epoch=25
05/28/2022 00:37:46 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.07 on epoch=25
05/28/2022 00:37:48 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=25
05/28/2022 00:38:38 - INFO - __main__ - Global step 2850 Train loss 0.05 Classification-F1 0.5312864012469843 on epoch=25
05/28/2022 00:38:41 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.07 on epoch=25
05/28/2022 00:38:44 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.04 on epoch=25
05/28/2022 00:38:46 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=25
05/28/2022 00:38:49 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.08 on epoch=25
05/28/2022 00:38:51 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.08 on epoch=25
05/28/2022 00:39:42 - INFO - __main__ - Global step 2900 Train loss 0.06 Classification-F1 0.5551928572342502 on epoch=25
05/28/2022 00:39:44 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.04 on epoch=25
05/28/2022 00:39:47 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.03 on epoch=26
05/28/2022 00:39:49 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.04 on epoch=26
05/28/2022 00:39:52 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.08 on epoch=26
05/28/2022 00:39:55 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.03 on epoch=26
05/28/2022 00:40:45 - INFO - __main__ - Global step 2950 Train loss 0.04 Classification-F1 0.5554622650930792 on epoch=26
05/28/2022 00:40:48 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.04 on epoch=26
05/28/2022 00:40:50 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.03 on epoch=26
05/28/2022 00:40:53 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.03 on epoch=26
05/28/2022 00:40:56 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.05 on epoch=26
05/28/2022 00:40:58 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.05 on epoch=26
05/28/2022 00:41:00 - INFO - __main__ - Start tokenizing ... 1792 instances
05/28/2022 00:41:00 - INFO - __main__ - Printing 3 examples
05/28/2022 00:41:00 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/28/2022 00:41:00 - INFO - __main__ - ['Animal']
05/28/2022 00:41:00 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/28/2022 00:41:00 - INFO - __main__ - ['Animal']
05/28/2022 00:41:00 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/28/2022 00:41:00 - INFO - __main__ - ['Animal']
05/28/2022 00:41:00 - INFO - __main__ - Tokenizing Input ...
05/28/2022 00:41:01 - INFO - __main__ - Tokenizing Output ...
05/28/2022 00:41:02 - INFO - __main__ - Loaded 1792 examples from train data
05/28/2022 00:41:02 - INFO - __main__ - Start tokenizing ... 1792 instances
05/28/2022 00:41:02 - INFO - __main__ - Printing 3 examples
05/28/2022 00:41:02 - INFO - __main__ -  [dbpedia_14] Palaephatus fusciterminus is a moth of the Palaephatidae family. It is found in the Valdivian forests of southern Argentina and Chile.The length of the forewings is 10-12 mm for males and 10.5-11.5 mm for females. Adults have a buff to brown head and thorax and dark brownish fuscous forewings with a pale buff hindmargin. They are on wing from October to March possibly in multiple generations per year.
05/28/2022 00:41:02 - INFO - __main__ - ['Animal']
05/28/2022 00:41:02 - INFO - __main__ -  [dbpedia_14] Labus is an indomalayan genus of potter wasps.
05/28/2022 00:41:02 - INFO - __main__ - ['Animal']
05/28/2022 00:41:02 - INFO - __main__ -  [dbpedia_14] Trifurcula beirnei is a moth of the Nepticulidae family. It is found in Great Britain Denmark and parts of Germany and Poland Austria the Czech Republic Slovakia and Hungary. It is also found in the Volga and Ural region of Russia.The wingspan is 8–11 mm. Adults are on wing from the end of June to late September.The larvae feed on Genista species including Genista tinctoria Genista germanica and Genista pilosa.
05/28/2022 00:41:02 - INFO - __main__ - ['Animal']
05/28/2022 00:41:02 - INFO - __main__ - Tokenizing Input ...
05/28/2022 00:41:03 - INFO - __main__ - Tokenizing Output ...
05/28/2022 00:41:05 - INFO - __main__ - Loaded 1792 examples from dev data
05/28/2022 00:41:20 - INFO - __main__ - load prompt embedding from ckpt
05/28/2022 00:41:21 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/28/2022 00:41:21 - INFO - __main__ - Starting training!
05/28/2022 00:41:49 - INFO - __main__ - Global step 3000 Train loss 0.04 Classification-F1 0.6039736430865776 on epoch=26
05/28/2022 00:41:49 - INFO - __main__ - Saving model with best Classification-F1: 0.5990607231380147 -> 0.6039736430865776 on epoch=26, global_step=3000
05/28/2022 00:41:49 - INFO - __main__ - save last model!
05/28/2022 00:41:49 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/28/2022 00:41:49 - INFO - __main__ - Start tokenizing ... 3500 instances
05/28/2022 00:41:49 - INFO - __main__ - Printing 3 examples
05/28/2022 00:41:49 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/28/2022 00:41:49 - INFO - __main__ - ['Animal']
05/28/2022 00:41:49 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/28/2022 00:41:49 - INFO - __main__ - ['Animal']
05/28/2022 00:41:49 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/28/2022 00:41:49 - INFO - __main__ - ['Village']
05/28/2022 00:41:49 - INFO - __main__ - Tokenizing Input ...
05/28/2022 00:41:51 - INFO - __main__ - Tokenizing Output ...
05/28/2022 00:41:54 - INFO - __main__ - Loaded 3500 examples from test data
05/28/2022 00:43:55 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down128shot/singletask-dbpedia_14/dbpedia_14_128_100_0.3_8_predictions.txt
05/28/2022 00:43:55 - INFO - __main__ - Classification-F1 on test data: 0.4901
05/28/2022 00:43:55 - INFO - __main__ - prefix=dbpedia_14_128_100, lr=0.3, bsz=8, dev_performance=0.6039736430865776, test_performance=0.49012098078170185
05/28/2022 00:43:55 - INFO - __main__ - Running ... prefix=dbpedia_14_128_100, lr=0.2, bsz=8 ...
05/28/2022 00:43:56 - INFO - __main__ - Start tokenizing ... 1792 instances
05/28/2022 00:43:56 - INFO - __main__ - Printing 3 examples
05/28/2022 00:43:56 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/28/2022 00:43:56 - INFO - __main__ - ['Animal']
05/28/2022 00:43:56 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/28/2022 00:43:56 - INFO - __main__ - ['Animal']
05/28/2022 00:43:56 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/28/2022 00:43:56 - INFO - __main__ - ['Animal']
05/28/2022 00:43:56 - INFO - __main__ - Tokenizing Input ...
05/28/2022 00:43:57 - INFO - __main__ - Tokenizing Output ...
05/28/2022 00:43:59 - INFO - __main__ - Loaded 1792 examples from train data
05/28/2022 00:43:59 - INFO - __main__ - Start tokenizing ... 1792 instances
05/28/2022 00:43:59 - INFO - __main__ - Printing 3 examples
05/28/2022 00:43:59 - INFO - __main__ -  [dbpedia_14] Palaephatus fusciterminus is a moth of the Palaephatidae family. It is found in the Valdivian forests of southern Argentina and Chile.The length of the forewings is 10-12 mm for males and 10.5-11.5 mm for females. Adults have a buff to brown head and thorax and dark brownish fuscous forewings with a pale buff hindmargin. They are on wing from October to March possibly in multiple generations per year.
05/28/2022 00:43:59 - INFO - __main__ - ['Animal']
05/28/2022 00:43:59 - INFO - __main__ -  [dbpedia_14] Labus is an indomalayan genus of potter wasps.
05/28/2022 00:43:59 - INFO - __main__ - ['Animal']
05/28/2022 00:43:59 - INFO - __main__ -  [dbpedia_14] Trifurcula beirnei is a moth of the Nepticulidae family. It is found in Great Britain Denmark and parts of Germany and Poland Austria the Czech Republic Slovakia and Hungary. It is also found in the Volga and Ural region of Russia.The wingspan is 8–11 mm. Adults are on wing from the end of June to late September.The larvae feed on Genista species including Genista tinctoria Genista germanica and Genista pilosa.
05/28/2022 00:43:59 - INFO - __main__ - ['Animal']
05/28/2022 00:43:59 - INFO - __main__ - Tokenizing Input ...
05/28/2022 00:44:00 - INFO - __main__ - Tokenizing Output ...
05/28/2022 00:44:02 - INFO - __main__ - Loaded 1792 examples from dev data
05/28/2022 00:44:19 - INFO - __main__ - load prompt embedding from ckpt
05/28/2022 00:44:20 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/28/2022 00:44:20 - INFO - __main__ - Starting training!
05/28/2022 00:44:24 - INFO - __main__ - Step 10 Global step 10 Train loss 7.92 on epoch=0
05/28/2022 00:44:26 - INFO - __main__ - Step 20 Global step 20 Train loss 6.01 on epoch=0
05/28/2022 00:44:29 - INFO - __main__ - Step 30 Global step 30 Train loss 4.84 on epoch=0
05/28/2022 00:44:32 - INFO - __main__ - Step 40 Global step 40 Train loss 4.73 on epoch=0
05/28/2022 00:44:34 - INFO - __main__ - Step 50 Global step 50 Train loss 4.40 on epoch=0
05/28/2022 00:45:21 - INFO - __main__ - Global step 50 Train loss 5.58 Classification-F1 0.008879148608379517 on epoch=0
05/28/2022 00:45:21 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.008879148608379517 on epoch=0, global_step=50
05/28/2022 00:45:24 - INFO - __main__ - Step 60 Global step 60 Train loss 3.64 on epoch=0
05/28/2022 00:45:27 - INFO - __main__ - Step 70 Global step 70 Train loss 3.47 on epoch=0
05/28/2022 00:45:29 - INFO - __main__ - Step 80 Global step 80 Train loss 3.33 on epoch=0
05/28/2022 00:45:32 - INFO - __main__ - Step 90 Global step 90 Train loss 3.26 on epoch=0
05/28/2022 00:45:34 - INFO - __main__ - Step 100 Global step 100 Train loss 2.85 on epoch=0
05/28/2022 00:46:28 - INFO - __main__ - Global step 100 Train loss 3.31 Classification-F1 0.012102966102578912 on epoch=0
05/28/2022 00:46:28 - INFO - __main__ - Saving model with best Classification-F1: 0.008879148608379517 -> 0.012102966102578912 on epoch=0, global_step=100
05/28/2022 00:46:30 - INFO - __main__ - Step 110 Global step 110 Train loss 2.94 on epoch=0
05/28/2022 00:46:33 - INFO - __main__ - Step 120 Global step 120 Train loss 2.71 on epoch=1
05/28/2022 00:46:35 - INFO - __main__ - Step 130 Global step 130 Train loss 2.59 on epoch=1
05/28/2022 00:46:38 - INFO - __main__ - Step 140 Global step 140 Train loss 2.40 on epoch=1
05/28/2022 00:46:40 - INFO - __main__ - Step 150 Global step 150 Train loss 2.14 on epoch=1
05/28/2022 00:47:30 - INFO - __main__ - Global step 150 Train loss 2.56 Classification-F1 0.023710442511025245 on epoch=1
05/28/2022 00:47:30 - INFO - __main__ - Saving model with best Classification-F1: 0.012102966102578912 -> 0.023710442511025245 on epoch=1, global_step=150
05/28/2022 00:47:33 - INFO - __main__ - Step 160 Global step 160 Train loss 2.34 on epoch=1
05/28/2022 00:47:35 - INFO - __main__ - Step 170 Global step 170 Train loss 2.07 on epoch=1
05/28/2022 00:47:38 - INFO - __main__ - Step 180 Global step 180 Train loss 1.83 on epoch=1
05/28/2022 00:47:40 - INFO - __main__ - Step 190 Global step 190 Train loss 2.00 on epoch=1
05/28/2022 00:47:43 - INFO - __main__ - Step 200 Global step 200 Train loss 2.06 on epoch=1
05/28/2022 00:48:29 - INFO - __main__ - Global step 200 Train loss 2.06 Classification-F1 0.03929779692705849 on epoch=1
05/28/2022 00:48:29 - INFO - __main__ - Saving model with best Classification-F1: 0.023710442511025245 -> 0.03929779692705849 on epoch=1, global_step=200
05/28/2022 00:48:31 - INFO - __main__ - Step 210 Global step 210 Train loss 1.87 on epoch=1
05/28/2022 00:48:34 - INFO - __main__ - Step 220 Global step 220 Train loss 1.97 on epoch=1
05/28/2022 00:48:36 - INFO - __main__ - Step 230 Global step 230 Train loss 1.79 on epoch=2
05/28/2022 00:48:39 - INFO - __main__ - Step 240 Global step 240 Train loss 1.72 on epoch=2
05/28/2022 00:48:41 - INFO - __main__ - Step 250 Global step 250 Train loss 1.59 on epoch=2
05/28/2022 00:49:27 - INFO - __main__ - Global step 250 Train loss 1.79 Classification-F1 0.06239287234934923 on epoch=2
05/28/2022 00:49:27 - INFO - __main__ - Saving model with best Classification-F1: 0.03929779692705849 -> 0.06239287234934923 on epoch=2, global_step=250
05/28/2022 00:49:30 - INFO - __main__ - Step 260 Global step 260 Train loss 1.45 on epoch=2
05/28/2022 00:49:32 - INFO - __main__ - Step 270 Global step 270 Train loss 1.60 on epoch=2
05/28/2022 00:49:35 - INFO - __main__ - Step 280 Global step 280 Train loss 1.47 on epoch=2
05/28/2022 00:49:37 - INFO - __main__ - Step 290 Global step 290 Train loss 1.19 on epoch=2
05/28/2022 00:49:40 - INFO - __main__ - Step 300 Global step 300 Train loss 1.45 on epoch=2
05/28/2022 00:50:24 - INFO - __main__ - Global step 300 Train loss 1.43 Classification-F1 0.09289961129235168 on epoch=2
05/28/2022 00:50:24 - INFO - __main__ - Saving model with best Classification-F1: 0.06239287234934923 -> 0.09289961129235168 on epoch=2, global_step=300
05/28/2022 00:50:26 - INFO - __main__ - Step 310 Global step 310 Train loss 1.21 on epoch=2
05/28/2022 00:50:29 - INFO - __main__ - Step 320 Global step 320 Train loss 1.29 on epoch=2
05/28/2022 00:50:31 - INFO - __main__ - Step 330 Global step 330 Train loss 1.13 on epoch=2
05/28/2022 00:50:34 - INFO - __main__ - Step 340 Global step 340 Train loss 1.09 on epoch=3
05/28/2022 00:50:37 - INFO - __main__ - Step 350 Global step 350 Train loss 1.00 on epoch=3
05/28/2022 00:51:20 - INFO - __main__ - Global step 350 Train loss 1.15 Classification-F1 0.12016079479071236 on epoch=3
05/28/2022 00:51:20 - INFO - __main__ - Saving model with best Classification-F1: 0.09289961129235168 -> 0.12016079479071236 on epoch=3, global_step=350
05/28/2022 00:51:23 - INFO - __main__ - Step 360 Global step 360 Train loss 1.12 on epoch=3
05/28/2022 00:51:25 - INFO - __main__ - Step 370 Global step 370 Train loss 0.98 on epoch=3
05/28/2022 00:51:28 - INFO - __main__ - Step 380 Global step 380 Train loss 0.94 on epoch=3
05/28/2022 00:51:30 - INFO - __main__ - Step 390 Global step 390 Train loss 0.74 on epoch=3
05/28/2022 00:51:33 - INFO - __main__ - Step 400 Global step 400 Train loss 0.76 on epoch=3
05/28/2022 00:52:17 - INFO - __main__ - Global step 400 Train loss 0.91 Classification-F1 0.15025982033276813 on epoch=3
05/28/2022 00:52:17 - INFO - __main__ - Saving model with best Classification-F1: 0.12016079479071236 -> 0.15025982033276813 on epoch=3, global_step=400
05/28/2022 00:52:20 - INFO - __main__ - Step 410 Global step 410 Train loss 0.83 on epoch=3
05/28/2022 00:52:23 - INFO - __main__ - Step 420 Global step 420 Train loss 0.68 on epoch=3
05/28/2022 00:52:25 - INFO - __main__ - Step 430 Global step 430 Train loss 0.81 on epoch=3
05/28/2022 00:52:28 - INFO - __main__ - Step 440 Global step 440 Train loss 0.69 on epoch=3
05/28/2022 00:52:30 - INFO - __main__ - Step 450 Global step 450 Train loss 0.72 on epoch=4
05/28/2022 00:53:18 - INFO - __main__ - Global step 450 Train loss 0.75 Classification-F1 0.20543302139247416 on epoch=4
05/28/2022 00:53:18 - INFO - __main__ - Saving model with best Classification-F1: 0.15025982033276813 -> 0.20543302139247416 on epoch=4, global_step=450
05/28/2022 00:53:21 - INFO - __main__ - Step 460 Global step 460 Train loss 0.61 on epoch=4
05/28/2022 00:53:24 - INFO - __main__ - Step 470 Global step 470 Train loss 0.70 on epoch=4
05/28/2022 00:53:26 - INFO - __main__ - Step 480 Global step 480 Train loss 0.72 on epoch=4
05/28/2022 00:53:29 - INFO - __main__ - Step 490 Global step 490 Train loss 0.68 on epoch=4
05/28/2022 00:53:31 - INFO - __main__ - Step 500 Global step 500 Train loss 0.54 on epoch=4
05/28/2022 00:54:21 - INFO - __main__ - Global step 500 Train loss 0.65 Classification-F1 0.23884610020670086 on epoch=4
05/28/2022 00:54:21 - INFO - __main__ - Saving model with best Classification-F1: 0.20543302139247416 -> 0.23884610020670086 on epoch=4, global_step=500
05/28/2022 00:54:23 - INFO - __main__ - Step 510 Global step 510 Train loss 0.62 on epoch=4
05/28/2022 00:54:26 - INFO - __main__ - Step 520 Global step 520 Train loss 0.52 on epoch=4
05/28/2022 00:54:28 - INFO - __main__ - Step 530 Global step 530 Train loss 0.50 on epoch=4
05/28/2022 00:54:31 - INFO - __main__ - Step 540 Global step 540 Train loss 0.43 on epoch=4
05/28/2022 00:54:33 - INFO - __main__ - Step 550 Global step 550 Train loss 0.52 on epoch=4
05/28/2022 00:55:24 - INFO - __main__ - Global step 550 Train loss 0.52 Classification-F1 0.2405036881605665 on epoch=4
05/28/2022 00:55:24 - INFO - __main__ - Saving model with best Classification-F1: 0.23884610020670086 -> 0.2405036881605665 on epoch=4, global_step=550
05/28/2022 00:55:26 - INFO - __main__ - Step 560 Global step 560 Train loss 0.44 on epoch=4
05/28/2022 00:55:29 - INFO - __main__ - Step 570 Global step 570 Train loss 0.55 on epoch=5
05/28/2022 00:55:31 - INFO - __main__ - Step 580 Global step 580 Train loss 0.51 on epoch=5
05/28/2022 00:55:34 - INFO - __main__ - Step 590 Global step 590 Train loss 0.49 on epoch=5
05/28/2022 00:55:37 - INFO - __main__ - Step 600 Global step 600 Train loss 0.49 on epoch=5
05/28/2022 00:56:27 - INFO - __main__ - Global step 600 Train loss 0.50 Classification-F1 0.3181563468008762 on epoch=5
05/28/2022 00:56:27 - INFO - __main__ - Saving model with best Classification-F1: 0.2405036881605665 -> 0.3181563468008762 on epoch=5, global_step=600
05/28/2022 00:56:30 - INFO - __main__ - Step 610 Global step 610 Train loss 0.36 on epoch=5
05/28/2022 00:56:33 - INFO - __main__ - Step 620 Global step 620 Train loss 0.33 on epoch=5
05/28/2022 00:56:35 - INFO - __main__ - Step 630 Global step 630 Train loss 0.42 on epoch=5
05/28/2022 00:56:38 - INFO - __main__ - Step 640 Global step 640 Train loss 0.37 on epoch=5
05/28/2022 00:56:40 - INFO - __main__ - Step 650 Global step 650 Train loss 0.42 on epoch=5
05/28/2022 00:57:32 - INFO - __main__ - Global step 650 Train loss 0.38 Classification-F1 0.3421370096128826 on epoch=5
05/28/2022 00:57:32 - INFO - __main__ - Saving model with best Classification-F1: 0.3181563468008762 -> 0.3421370096128826 on epoch=5, global_step=650
05/28/2022 00:57:35 - INFO - __main__ - Step 660 Global step 660 Train loss 0.37 on epoch=5
05/28/2022 00:57:38 - INFO - __main__ - Step 670 Global step 670 Train loss 0.40 on epoch=5
05/28/2022 00:57:40 - INFO - __main__ - Step 680 Global step 680 Train loss 0.38 on epoch=6
05/28/2022 00:57:43 - INFO - __main__ - Step 690 Global step 690 Train loss 0.32 on epoch=6
05/28/2022 00:57:45 - INFO - __main__ - Step 700 Global step 700 Train loss 0.41 on epoch=6
05/28/2022 00:58:37 - INFO - __main__ - Global step 700 Train loss 0.38 Classification-F1 0.3563791582156667 on epoch=6
05/28/2022 00:58:37 - INFO - __main__ - Saving model with best Classification-F1: 0.3421370096128826 -> 0.3563791582156667 on epoch=6, global_step=700
05/28/2022 00:58:40 - INFO - __main__ - Step 710 Global step 710 Train loss 0.34 on epoch=6
05/28/2022 00:58:42 - INFO - __main__ - Step 720 Global step 720 Train loss 0.39 on epoch=6
05/28/2022 00:58:45 - INFO - __main__ - Step 730 Global step 730 Train loss 0.34 on epoch=6
05/28/2022 00:58:48 - INFO - __main__ - Step 740 Global step 740 Train loss 0.35 on epoch=6
05/28/2022 00:58:50 - INFO - __main__ - Step 750 Global step 750 Train loss 0.29 on epoch=6
05/28/2022 00:59:42 - INFO - __main__ - Global step 750 Train loss 0.34 Classification-F1 0.3784884782238477 on epoch=6
05/28/2022 00:59:42 - INFO - __main__ - Saving model with best Classification-F1: 0.3563791582156667 -> 0.3784884782238477 on epoch=6, global_step=750
05/28/2022 00:59:45 - INFO - __main__ - Step 760 Global step 760 Train loss 0.39 on epoch=6
05/28/2022 00:59:48 - INFO - __main__ - Step 770 Global step 770 Train loss 0.32 on epoch=6
05/28/2022 00:59:50 - INFO - __main__ - Step 780 Global step 780 Train loss 0.30 on epoch=6
05/28/2022 00:59:53 - INFO - __main__ - Step 790 Global step 790 Train loss 0.34 on epoch=7
05/28/2022 00:59:55 - INFO - __main__ - Step 800 Global step 800 Train loss 0.32 on epoch=7
05/28/2022 01:00:47 - INFO - __main__ - Global step 800 Train loss 0.33 Classification-F1 0.39529578299262447 on epoch=7
05/28/2022 01:00:47 - INFO - __main__ - Saving model with best Classification-F1: 0.3784884782238477 -> 0.39529578299262447 on epoch=7, global_step=800
05/28/2022 01:00:50 - INFO - __main__ - Step 810 Global step 810 Train loss 0.38 on epoch=7
05/28/2022 01:00:52 - INFO - __main__ - Step 820 Global step 820 Train loss 0.29 on epoch=7
05/28/2022 01:00:55 - INFO - __main__ - Step 830 Global step 830 Train loss 0.30 on epoch=7
05/28/2022 01:00:57 - INFO - __main__ - Step 840 Global step 840 Train loss 0.25 on epoch=7
05/28/2022 01:01:00 - INFO - __main__ - Step 850 Global step 850 Train loss 0.34 on epoch=7
05/28/2022 01:01:53 - INFO - __main__ - Global step 850 Train loss 0.31 Classification-F1 0.41652386478425696 on epoch=7
05/28/2022 01:01:53 - INFO - __main__ - Saving model with best Classification-F1: 0.39529578299262447 -> 0.41652386478425696 on epoch=7, global_step=850
05/28/2022 01:01:56 - INFO - __main__ - Step 860 Global step 860 Train loss 0.29 on epoch=7
05/28/2022 01:01:58 - INFO - __main__ - Step 870 Global step 870 Train loss 0.24 on epoch=7
05/28/2022 01:02:01 - INFO - __main__ - Step 880 Global step 880 Train loss 0.26 on epoch=7
05/28/2022 01:02:03 - INFO - __main__ - Step 890 Global step 890 Train loss 0.32 on epoch=7
05/28/2022 01:02:06 - INFO - __main__ - Step 900 Global step 900 Train loss 0.24 on epoch=8
05/28/2022 01:02:59 - INFO - __main__ - Global step 900 Train loss 0.27 Classification-F1 0.44215935969395936 on epoch=8
05/28/2022 01:02:59 - INFO - __main__ - Saving model with best Classification-F1: 0.41652386478425696 -> 0.44215935969395936 on epoch=8, global_step=900
05/28/2022 01:03:02 - INFO - __main__ - Step 910 Global step 910 Train loss 0.29 on epoch=8
05/28/2022 01:03:04 - INFO - __main__ - Step 920 Global step 920 Train loss 0.24 on epoch=8
05/28/2022 01:03:07 - INFO - __main__ - Step 930 Global step 930 Train loss 0.24 on epoch=8
05/28/2022 01:03:09 - INFO - __main__ - Step 940 Global step 940 Train loss 0.22 on epoch=8
05/28/2022 01:03:12 - INFO - __main__ - Step 950 Global step 950 Train loss 0.23 on epoch=8
05/28/2022 01:04:04 - INFO - __main__ - Global step 950 Train loss 0.24 Classification-F1 0.4069799658970147 on epoch=8
05/28/2022 01:04:06 - INFO - __main__ - Step 960 Global step 960 Train loss 0.23 on epoch=8
05/28/2022 01:04:09 - INFO - __main__ - Step 970 Global step 970 Train loss 0.23 on epoch=8
05/28/2022 01:04:12 - INFO - __main__ - Step 980 Global step 980 Train loss 0.19 on epoch=8
05/28/2022 01:04:14 - INFO - __main__ - Step 990 Global step 990 Train loss 0.27 on epoch=8
05/28/2022 01:04:17 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.26 on epoch=8
05/28/2022 01:05:08 - INFO - __main__ - Global step 1000 Train loss 0.24 Classification-F1 0.4359740795849625 on epoch=8
05/28/2022 01:05:11 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.26 on epoch=9
05/28/2022 01:05:13 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.22 on epoch=9
05/28/2022 01:05:16 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.25 on epoch=9
05/28/2022 01:05:18 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.25 on epoch=9
05/28/2022 01:05:21 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.27 on epoch=9
05/28/2022 01:06:12 - INFO - __main__ - Global step 1050 Train loss 0.25 Classification-F1 0.4841348389742201 on epoch=9
05/28/2022 01:06:12 - INFO - __main__ - Saving model with best Classification-F1: 0.44215935969395936 -> 0.4841348389742201 on epoch=9, global_step=1050
05/28/2022 01:06:14 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.20 on epoch=9
05/28/2022 01:06:17 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.22 on epoch=9
05/28/2022 01:06:20 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.23 on epoch=9
05/28/2022 01:06:22 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.17 on epoch=9
05/28/2022 01:06:25 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.23 on epoch=9
05/28/2022 01:07:16 - INFO - __main__ - Global step 1100 Train loss 0.21 Classification-F1 0.5047564927015641 on epoch=9
05/28/2022 01:07:16 - INFO - __main__ - Saving model with best Classification-F1: 0.4841348389742201 -> 0.5047564927015641 on epoch=9, global_step=1100
05/28/2022 01:07:19 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.24 on epoch=9
05/28/2022 01:07:21 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.14 on epoch=9
05/28/2022 01:07:24 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.20 on epoch=10
05/28/2022 01:07:26 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.28 on epoch=10
05/28/2022 01:07:29 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.30 on epoch=10
05/28/2022 01:08:20 - INFO - __main__ - Global step 1150 Train loss 0.23 Classification-F1 0.5574637592830315 on epoch=10
05/28/2022 01:08:20 - INFO - __main__ - Saving model with best Classification-F1: 0.5047564927015641 -> 0.5574637592830315 on epoch=10, global_step=1150
05/28/2022 01:08:23 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.19 on epoch=10
05/28/2022 01:08:25 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.18 on epoch=10
05/28/2022 01:08:28 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.27 on epoch=10
05/28/2022 01:08:31 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.26 on epoch=10
05/28/2022 01:08:33 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.12 on epoch=10
05/28/2022 01:09:25 - INFO - __main__ - Global step 1200 Train loss 0.20 Classification-F1 0.5585616438854321 on epoch=10
05/28/2022 01:09:25 - INFO - __main__ - Saving model with best Classification-F1: 0.5574637592830315 -> 0.5585616438854321 on epoch=10, global_step=1200
05/28/2022 01:09:27 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.21 on epoch=10
05/28/2022 01:09:30 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.25 on epoch=10
05/28/2022 01:09:32 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.16 on epoch=10
05/28/2022 01:09:35 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.19 on epoch=11
05/28/2022 01:09:38 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.17 on epoch=11
05/28/2022 01:10:29 - INFO - __main__ - Global step 1250 Train loss 0.19 Classification-F1 0.4583334117167199 on epoch=11
05/28/2022 01:10:31 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.29 on epoch=11
05/28/2022 01:10:34 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.15 on epoch=11
05/28/2022 01:10:36 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.20 on epoch=11
05/28/2022 01:10:39 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.17 on epoch=11
05/28/2022 01:10:41 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.19 on epoch=11
05/28/2022 01:11:34 - INFO - __main__ - Global step 1300 Train loss 0.20 Classification-F1 0.5287323015031283 on epoch=11
05/28/2022 01:11:36 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.16 on epoch=11
05/28/2022 01:11:39 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.18 on epoch=11
05/28/2022 01:11:41 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.15 on epoch=11
05/28/2022 01:11:44 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.22 on epoch=11
05/28/2022 01:11:46 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.12 on epoch=12
05/28/2022 01:12:38 - INFO - __main__ - Global step 1350 Train loss 0.17 Classification-F1 0.48209384649854636 on epoch=12
05/28/2022 01:12:40 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.14 on epoch=12
05/28/2022 01:12:43 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.27 on epoch=12
05/28/2022 01:12:45 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.14 on epoch=12
05/28/2022 01:12:48 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.20 on epoch=12
05/28/2022 01:12:50 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.13 on epoch=12
05/28/2022 01:13:42 - INFO - __main__ - Global step 1400 Train loss 0.17 Classification-F1 0.5089005964730723 on epoch=12
05/28/2022 01:13:45 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.14 on epoch=12
05/28/2022 01:13:48 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.14 on epoch=12
05/28/2022 01:13:50 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.14 on epoch=12
05/28/2022 01:13:53 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.16 on epoch=12
05/28/2022 01:13:55 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.20 on epoch=12
05/28/2022 01:14:47 - INFO - __main__ - Global step 1450 Train loss 0.16 Classification-F1 0.5532854713791374 on epoch=12
05/28/2022 01:14:50 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.17 on epoch=13
05/28/2022 01:14:52 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.14 on epoch=13
05/28/2022 01:14:55 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.21 on epoch=13
05/28/2022 01:14:57 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.11 on epoch=13
05/28/2022 01:15:00 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.13 on epoch=13
05/28/2022 01:15:51 - INFO - __main__ - Global step 1500 Train loss 0.15 Classification-F1 0.5116943015315557 on epoch=13
05/28/2022 01:15:54 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.09 on epoch=13
05/28/2022 01:15:56 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.14 on epoch=13
05/28/2022 01:15:59 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.13 on epoch=13
05/28/2022 01:16:01 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.09 on epoch=13
05/28/2022 01:16:04 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.15 on epoch=13
05/28/2022 01:16:57 - INFO - __main__ - Global step 1550 Train loss 0.12 Classification-F1 0.5671477790714965 on epoch=13
05/28/2022 01:16:57 - INFO - __main__ - Saving model with best Classification-F1: 0.5585616438854321 -> 0.5671477790714965 on epoch=13, global_step=1550
05/28/2022 01:17:00 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.17 on epoch=13
05/28/2022 01:17:02 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.09 on epoch=14
05/28/2022 01:17:05 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.12 on epoch=14
05/28/2022 01:17:07 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.12 on epoch=14
05/28/2022 01:17:10 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.16 on epoch=14
05/28/2022 01:18:01 - INFO - __main__ - Global step 1600 Train loss 0.13 Classification-F1 0.5378042774231349 on epoch=14
05/28/2022 01:18:04 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.17 on epoch=14
05/28/2022 01:18:06 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.13 on epoch=14
05/28/2022 01:18:09 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.17 on epoch=14
05/28/2022 01:18:12 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.14 on epoch=14
05/28/2022 01:18:14 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.12 on epoch=14
05/28/2022 01:19:05 - INFO - __main__ - Global step 1650 Train loss 0.15 Classification-F1 0.5932658324130072 on epoch=14
05/28/2022 01:19:05 - INFO - __main__ - Saving model with best Classification-F1: 0.5671477790714965 -> 0.5932658324130072 on epoch=14, global_step=1650
05/28/2022 01:19:08 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.13 on epoch=14
05/28/2022 01:19:11 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.16 on epoch=14
05/28/2022 01:19:13 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.09 on epoch=14
05/28/2022 01:19:16 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.16 on epoch=15
05/28/2022 01:19:18 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.11 on epoch=15
05/28/2022 01:20:09 - INFO - __main__ - Global step 1700 Train loss 0.13 Classification-F1 0.5316189965168895 on epoch=15
05/28/2022 01:20:12 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.13 on epoch=15
05/28/2022 01:20:14 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.18 on epoch=15
05/28/2022 01:20:17 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.10 on epoch=15
05/28/2022 01:20:20 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.12 on epoch=15
05/28/2022 01:20:22 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.11 on epoch=15
05/28/2022 01:21:13 - INFO - __main__ - Global step 1750 Train loss 0.13 Classification-F1 0.5930523356573458 on epoch=15
05/28/2022 01:21:15 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.10 on epoch=15
05/28/2022 01:21:18 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.19 on epoch=15
05/28/2022 01:21:21 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.13 on epoch=15
05/28/2022 01:21:23 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.11 on epoch=15
05/28/2022 01:21:26 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.12 on epoch=16
05/28/2022 01:22:17 - INFO - __main__ - Global step 1800 Train loss 0.13 Classification-F1 0.5594897543238573 on epoch=16
05/28/2022 01:22:19 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.14 on epoch=16
05/28/2022 01:22:22 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.16 on epoch=16
05/28/2022 01:22:25 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.09 on epoch=16
05/28/2022 01:22:27 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.08 on epoch=16
05/28/2022 01:22:30 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.11 on epoch=16
05/28/2022 01:23:22 - INFO - __main__ - Global step 1850 Train loss 0.12 Classification-F1 0.6556102228487081 on epoch=16
05/28/2022 01:23:22 - INFO - __main__ - Saving model with best Classification-F1: 0.5932658324130072 -> 0.6556102228487081 on epoch=16, global_step=1850
05/28/2022 01:23:25 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.11 on epoch=16
05/28/2022 01:23:28 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.07 on epoch=16
05/28/2022 01:23:30 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.17 on epoch=16
05/28/2022 01:23:33 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.11 on epoch=16
05/28/2022 01:23:35 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.11 on epoch=16
05/28/2022 01:24:27 - INFO - __main__ - Global step 1900 Train loss 0.12 Classification-F1 0.5424754495040036 on epoch=16
05/28/2022 01:24:30 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.07 on epoch=17
05/28/2022 01:24:32 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.15 on epoch=17
05/28/2022 01:24:35 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.13 on epoch=17
05/28/2022 01:24:37 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.07 on epoch=17
05/28/2022 01:24:40 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.10 on epoch=17
05/28/2022 01:25:30 - INFO - __main__ - Global step 1950 Train loss 0.10 Classification-F1 0.5332587832195321 on epoch=17
05/28/2022 01:25:33 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.05 on epoch=17
05/28/2022 01:25:36 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.06 on epoch=17
05/28/2022 01:25:38 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.10 on epoch=17
05/28/2022 01:25:41 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.13 on epoch=17
05/28/2022 01:25:43 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.10 on epoch=17
05/28/2022 01:26:35 - INFO - __main__ - Global step 2000 Train loss 0.09 Classification-F1 0.5519745786432899 on epoch=17
05/28/2022 01:26:37 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.15 on epoch=17
05/28/2022 01:26:40 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.08 on epoch=18
05/28/2022 01:26:42 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.15 on epoch=18
05/28/2022 01:26:45 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.12 on epoch=18
05/28/2022 01:26:48 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.11 on epoch=18
05/28/2022 01:27:39 - INFO - __main__ - Global step 2050 Train loss 0.12 Classification-F1 0.6161766053173394 on epoch=18
05/28/2022 01:27:42 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.12 on epoch=18
05/28/2022 01:27:44 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.05 on epoch=18
05/28/2022 01:27:47 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.12 on epoch=18
05/28/2022 01:27:49 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.12 on epoch=18
05/28/2022 01:27:52 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.10 on epoch=18
05/28/2022 01:28:44 - INFO - __main__ - Global step 2100 Train loss 0.10 Classification-F1 0.5950475491387331 on epoch=18
05/28/2022 01:28:47 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.13 on epoch=18
05/28/2022 01:28:49 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.16 on epoch=18
05/28/2022 01:28:52 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.08 on epoch=19
05/28/2022 01:28:55 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.09 on epoch=19
05/28/2022 01:28:57 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.08 on epoch=19
05/28/2022 01:29:47 - INFO - __main__ - Global step 2150 Train loss 0.11 Classification-F1 0.47774338126484805 on epoch=19
05/28/2022 01:29:50 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.11 on epoch=19
05/28/2022 01:29:52 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.16 on epoch=19
05/28/2022 01:29:55 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.08 on epoch=19
05/28/2022 01:29:58 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.10 on epoch=19
05/28/2022 01:30:00 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.12 on epoch=19
05/28/2022 01:30:51 - INFO - __main__ - Global step 2200 Train loss 0.11 Classification-F1 0.541969808620533 on epoch=19
05/28/2022 01:30:54 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.09 on epoch=19
05/28/2022 01:30:56 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.21 on epoch=19
05/28/2022 01:30:59 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.15 on epoch=19
05/28/2022 01:31:02 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.08 on epoch=19
05/28/2022 01:31:04 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.08 on epoch=20
05/28/2022 01:31:56 - INFO - __main__ - Global step 2250 Train loss 0.12 Classification-F1 0.5409845973783728 on epoch=20
05/28/2022 01:31:58 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.06 on epoch=20
05/28/2022 01:32:01 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.11 on epoch=20
05/28/2022 01:32:03 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.08 on epoch=20
05/28/2022 01:32:06 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.06 on epoch=20
05/28/2022 01:32:09 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.09 on epoch=20
05/28/2022 01:33:01 - INFO - __main__ - Global step 2300 Train loss 0.08 Classification-F1 0.5717785706442802 on epoch=20
05/28/2022 01:33:03 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.12 on epoch=20
05/28/2022 01:33:06 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.05 on epoch=20
05/28/2022 01:33:08 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.14 on epoch=20
05/28/2022 01:33:11 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.13 on epoch=20
05/28/2022 01:33:14 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.06 on epoch=20
05/28/2022 01:34:05 - INFO - __main__ - Global step 2350 Train loss 0.10 Classification-F1 0.46605082571821865 on epoch=20
05/28/2022 01:34:08 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.09 on epoch=21
05/28/2022 01:34:10 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.07 on epoch=21
05/28/2022 01:34:13 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.14 on epoch=21
05/28/2022 01:34:15 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.07 on epoch=21
05/28/2022 01:34:18 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.07 on epoch=21
05/28/2022 01:35:09 - INFO - __main__ - Global step 2400 Train loss 0.09 Classification-F1 0.4851462082218879 on epoch=21
05/28/2022 01:35:11 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.09 on epoch=21
05/28/2022 01:35:14 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.11 on epoch=21
05/28/2022 01:35:16 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.08 on epoch=21
05/28/2022 01:35:19 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.13 on epoch=21
05/28/2022 01:35:22 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.11 on epoch=21
05/28/2022 01:36:12 - INFO - __main__ - Global step 2450 Train loss 0.10 Classification-F1 0.44374146202179127 on epoch=21
05/28/2022 01:36:14 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.11 on epoch=21
05/28/2022 01:36:17 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.07 on epoch=22
05/28/2022 01:36:19 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.05 on epoch=22
05/28/2022 01:36:22 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.12 on epoch=22
05/28/2022 01:36:25 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.05 on epoch=22
05/28/2022 01:37:15 - INFO - __main__ - Global step 2500 Train loss 0.08 Classification-F1 0.501796615427189 on epoch=22
05/28/2022 01:37:17 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.10 on epoch=22
05/28/2022 01:37:20 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.07 on epoch=22
05/28/2022 01:37:23 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.09 on epoch=22
05/28/2022 01:37:25 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.06 on epoch=22
05/28/2022 01:37:28 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.14 on epoch=22
05/28/2022 01:38:18 - INFO - __main__ - Global step 2550 Train loss 0.09 Classification-F1 0.4619115173453659 on epoch=22
05/28/2022 01:38:21 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.10 on epoch=22
05/28/2022 01:38:23 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.07 on epoch=22
05/28/2022 01:38:26 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.06 on epoch=23
05/28/2022 01:38:28 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.08 on epoch=23
05/28/2022 01:38:31 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.12 on epoch=23
05/28/2022 01:39:21 - INFO - __main__ - Global step 2600 Train loss 0.09 Classification-F1 0.5025656983501372 on epoch=23
05/28/2022 01:39:23 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.07 on epoch=23
05/28/2022 01:39:26 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.07 on epoch=23
05/28/2022 01:39:29 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.04 on epoch=23
05/28/2022 01:39:31 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.07 on epoch=23
05/28/2022 01:39:34 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.10 on epoch=23
05/28/2022 01:40:24 - INFO - __main__ - Global step 2650 Train loss 0.07 Classification-F1 0.48320562636525327 on epoch=23
05/28/2022 01:40:26 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.04 on epoch=23
05/28/2022 01:40:29 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.11 on epoch=23
05/28/2022 01:40:31 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.11 on epoch=23
05/28/2022 01:40:34 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.06 on epoch=24
05/28/2022 01:40:37 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.09 on epoch=24
05/28/2022 01:41:26 - INFO - __main__ - Global step 2700 Train loss 0.08 Classification-F1 0.4666595499241782 on epoch=24
05/28/2022 01:41:29 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.11 on epoch=24
05/28/2022 01:41:32 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.12 on epoch=24
05/28/2022 01:41:34 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.07 on epoch=24
05/28/2022 01:41:37 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.07 on epoch=24
05/28/2022 01:41:40 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.08 on epoch=24
05/28/2022 01:42:29 - INFO - __main__ - Global step 2750 Train loss 0.09 Classification-F1 0.45157490599105754 on epoch=24
05/28/2022 01:42:32 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.09 on epoch=24
05/28/2022 01:42:35 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.05 on epoch=24
05/28/2022 01:42:37 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.11 on epoch=24
05/28/2022 01:42:40 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.13 on epoch=24
05/28/2022 01:42:43 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.05 on epoch=24
05/28/2022 01:43:32 - INFO - __main__ - Global step 2800 Train loss 0.09 Classification-F1 0.4857249107646551 on epoch=24
05/28/2022 01:43:35 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.06 on epoch=25
05/28/2022 01:43:37 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.07 on epoch=25
05/28/2022 01:43:40 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.09 on epoch=25
05/28/2022 01:43:42 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.06 on epoch=25
05/28/2022 01:43:45 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.06 on epoch=25
05/28/2022 01:44:34 - INFO - __main__ - Global step 2850 Train loss 0.07 Classification-F1 0.5279380814715645 on epoch=25
05/28/2022 01:44:36 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.03 on epoch=25
05/28/2022 01:44:39 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.08 on epoch=25
05/28/2022 01:44:42 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.05 on epoch=25
05/28/2022 01:44:44 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.17 on epoch=25
05/28/2022 01:44:47 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.10 on epoch=25
05/28/2022 01:45:37 - INFO - __main__ - Global step 2900 Train loss 0.08 Classification-F1 0.4632151399767743 on epoch=25
05/28/2022 01:45:39 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.07 on epoch=25
05/28/2022 01:45:42 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.04 on epoch=26
05/28/2022 01:45:44 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.05 on epoch=26
05/28/2022 01:45:47 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.11 on epoch=26
05/28/2022 01:45:50 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.05 on epoch=26
05/28/2022 01:46:39 - INFO - __main__ - Global step 2950 Train loss 0.06 Classification-F1 0.4784055367556179 on epoch=26
05/28/2022 01:46:42 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.10 on epoch=26
05/28/2022 01:46:44 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.11 on epoch=26
05/28/2022 01:46:47 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.07 on epoch=26
05/28/2022 01:46:50 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.05 on epoch=26
05/28/2022 01:46:52 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.11 on epoch=26
05/28/2022 01:46:54 - INFO - __main__ - Start tokenizing ... 1792 instances
05/28/2022 01:46:54 - INFO - __main__ - Printing 3 examples
05/28/2022 01:46:54 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/28/2022 01:46:54 - INFO - __main__ - ['Animal']
05/28/2022 01:46:54 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/28/2022 01:46:54 - INFO - __main__ - ['Animal']
05/28/2022 01:46:54 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
05/28/2022 01:46:54 - INFO - __main__ - ['Animal']
05/28/2022 01:46:54 - INFO - __main__ - Tokenizing Input ...
05/28/2022 01:46:55 - INFO - __main__ - Tokenizing Output ...
05/28/2022 01:46:57 - INFO - __main__ - Loaded 1792 examples from train data
05/28/2022 01:46:57 - INFO - __main__ - Start tokenizing ... 1792 instances
05/28/2022 01:46:57 - INFO - __main__ - Printing 3 examples
05/28/2022 01:46:57 - INFO - __main__ -  [dbpedia_14] The Andaman Treepie (Dendrocitta bayleyi) is a species of bird in the Corvidae family.It is endemic to the Andaman Islands of India.Its natural habitat is subtropical or tropical moist lowland forests. It is threatened by habitat loss.The scientific name commemorates the Anglo-Indian statesman Edward Clive Bayley.
05/28/2022 01:46:57 - INFO - __main__ - ['Animal']
05/28/2022 01:46:57 - INFO - __main__ -  [dbpedia_14] Ethmia tyranthes is a moth in the Ethmiidae family. It is found in the Democratic Republic of Congo.
05/28/2022 01:46:57 - INFO - __main__ - ['Animal']
05/28/2022 01:46:57 - INFO - __main__ -  [dbpedia_14] Van Son’s Brown (Stygionympha vansoni) is a butterfly of the Nymphalidae family. It is found in South Africa in the northern Cape from the Kamiesberg to the Springbok area.The wingspan is 36–38 mm for males and 38–40 mm for females. Adults are on wing from August to October. There is one generation per year.The larvae probably feed on Poaceae grasses.
05/28/2022 01:46:57 - INFO - __main__ - ['Animal']
05/28/2022 01:46:57 - INFO - __main__ - Tokenizing Input ...
05/28/2022 01:46:58 - INFO - __main__ - Tokenizing Output ...
05/28/2022 01:46:59 - INFO - __main__ - Loaded 1792 examples from dev data
05/28/2022 01:47:18 - INFO - __main__ - load prompt embedding from ckpt
05/28/2022 01:47:19 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/28/2022 01:47:19 - INFO - __main__ - Starting training!
05/28/2022 01:47:44 - INFO - __main__ - Global step 3000 Train loss 0.09 Classification-F1 0.555955579224673 on epoch=26
05/28/2022 01:47:44 - INFO - __main__ - save last model!
05/28/2022 01:47:44 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/28/2022 01:47:44 - INFO - __main__ - Start tokenizing ... 3500 instances
05/28/2022 01:47:44 - INFO - __main__ - Printing 3 examples
05/28/2022 01:47:44 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/28/2022 01:47:44 - INFO - __main__ - ['Animal']
05/28/2022 01:47:44 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/28/2022 01:47:44 - INFO - __main__ - ['Animal']
05/28/2022 01:47:44 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/28/2022 01:47:44 - INFO - __main__ - ['Village']
05/28/2022 01:47:44 - INFO - __main__ - Tokenizing Input ...
05/28/2022 01:47:46 - INFO - __main__ - Tokenizing Output ...
05/28/2022 01:47:49 - INFO - __main__ - Loaded 3500 examples from test data
05/28/2022 01:49:47 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down128shot/singletask-dbpedia_14/dbpedia_14_128_100_0.2_8_predictions.txt
05/28/2022 01:49:47 - INFO - __main__ - Classification-F1 on test data: 0.4237
05/28/2022 01:49:47 - INFO - __main__ - prefix=dbpedia_14_128_100, lr=0.2, bsz=8, dev_performance=0.6556102228487081, test_performance=0.42370209208695603
05/28/2022 01:49:47 - INFO - __main__ - Running ... prefix=dbpedia_14_128_13, lr=0.5, bsz=8 ...
05/28/2022 01:49:48 - INFO - __main__ - Start tokenizing ... 1792 instances
05/28/2022 01:49:48 - INFO - __main__ - Printing 3 examples
05/28/2022 01:49:48 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/28/2022 01:49:48 - INFO - __main__ - ['Animal']
05/28/2022 01:49:48 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/28/2022 01:49:48 - INFO - __main__ - ['Animal']
05/28/2022 01:49:48 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
05/28/2022 01:49:48 - INFO - __main__ - ['Animal']
05/28/2022 01:49:48 - INFO - __main__ - Tokenizing Input ...
05/28/2022 01:49:49 - INFO - __main__ - Tokenizing Output ...
05/28/2022 01:49:51 - INFO - __main__ - Loaded 1792 examples from train data
05/28/2022 01:49:51 - INFO - __main__ - Start tokenizing ... 1792 instances
05/28/2022 01:49:51 - INFO - __main__ - Printing 3 examples
05/28/2022 01:49:51 - INFO - __main__ -  [dbpedia_14] The Andaman Treepie (Dendrocitta bayleyi) is a species of bird in the Corvidae family.It is endemic to the Andaman Islands of India.Its natural habitat is subtropical or tropical moist lowland forests. It is threatened by habitat loss.The scientific name commemorates the Anglo-Indian statesman Edward Clive Bayley.
05/28/2022 01:49:51 - INFO - __main__ - ['Animal']
05/28/2022 01:49:51 - INFO - __main__ -  [dbpedia_14] Ethmia tyranthes is a moth in the Ethmiidae family. It is found in the Democratic Republic of Congo.
05/28/2022 01:49:51 - INFO - __main__ - ['Animal']
05/28/2022 01:49:51 - INFO - __main__ -  [dbpedia_14] Van Son’s Brown (Stygionympha vansoni) is a butterfly of the Nymphalidae family. It is found in South Africa in the northern Cape from the Kamiesberg to the Springbok area.The wingspan is 36–38 mm for males and 38–40 mm for females. Adults are on wing from August to October. There is one generation per year.The larvae probably feed on Poaceae grasses.
05/28/2022 01:49:51 - INFO - __main__ - ['Animal']
05/28/2022 01:49:51 - INFO - __main__ - Tokenizing Input ...
05/28/2022 01:49:52 - INFO - __main__ - Tokenizing Output ...
05/28/2022 01:49:53 - INFO - __main__ - Loaded 1792 examples from dev data
05/28/2022 01:50:10 - INFO - __main__ - load prompt embedding from ckpt
05/28/2022 01:50:11 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/28/2022 01:50:11 - INFO - __main__ - Starting training!
05/28/2022 01:50:14 - INFO - __main__ - Step 10 Global step 10 Train loss 6.68 on epoch=0
05/28/2022 01:50:17 - INFO - __main__ - Step 20 Global step 20 Train loss 4.60 on epoch=0
05/28/2022 01:50:20 - INFO - __main__ - Step 30 Global step 30 Train loss 3.83 on epoch=0
05/28/2022 01:50:22 - INFO - __main__ - Step 40 Global step 40 Train loss 2.99 on epoch=0
05/28/2022 01:50:25 - INFO - __main__ - Step 50 Global step 50 Train loss 3.08 on epoch=0
05/28/2022 01:51:15 - INFO - __main__ - Global step 50 Train loss 4.23 Classification-F1 0.016420533770373245 on epoch=0
05/28/2022 01:51:15 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.016420533770373245 on epoch=0, global_step=50
05/28/2022 01:51:18 - INFO - __main__ - Step 60 Global step 60 Train loss 2.60 on epoch=0
05/28/2022 01:51:21 - INFO - __main__ - Step 70 Global step 70 Train loss 2.49 on epoch=0
05/28/2022 01:51:23 - INFO - __main__ - Step 80 Global step 80 Train loss 2.11 on epoch=0
05/28/2022 01:51:26 - INFO - __main__ - Step 90 Global step 90 Train loss 2.04 on epoch=0
05/28/2022 01:51:29 - INFO - __main__ - Step 100 Global step 100 Train loss 1.85 on epoch=0
05/28/2022 01:52:14 - INFO - __main__ - Global step 100 Train loss 2.22 Classification-F1 0.05439020515437523 on epoch=0
05/28/2022 01:52:14 - INFO - __main__ - Saving model with best Classification-F1: 0.016420533770373245 -> 0.05439020515437523 on epoch=0, global_step=100
05/28/2022 01:52:17 - INFO - __main__ - Step 110 Global step 110 Train loss 1.48 on epoch=0
05/28/2022 01:52:19 - INFO - __main__ - Step 120 Global step 120 Train loss 1.51 on epoch=1
05/28/2022 01:52:22 - INFO - __main__ - Step 130 Global step 130 Train loss 1.44 on epoch=1
05/28/2022 01:52:24 - INFO - __main__ - Step 140 Global step 140 Train loss 1.30 on epoch=1
05/28/2022 01:52:27 - INFO - __main__ - Step 150 Global step 150 Train loss 1.12 on epoch=1
05/28/2022 01:53:11 - INFO - __main__ - Global step 150 Train loss 1.37 Classification-F1 0.10427138054772224 on epoch=1
05/28/2022 01:53:11 - INFO - __main__ - Saving model with best Classification-F1: 0.05439020515437523 -> 0.10427138054772224 on epoch=1, global_step=150
05/28/2022 01:53:13 - INFO - __main__ - Step 160 Global step 160 Train loss 1.17 on epoch=1
05/28/2022 01:53:16 - INFO - __main__ - Step 170 Global step 170 Train loss 0.98 on epoch=1
05/28/2022 01:53:18 - INFO - __main__ - Step 180 Global step 180 Train loss 0.96 on epoch=1
05/28/2022 01:53:21 - INFO - __main__ - Step 190 Global step 190 Train loss 0.73 on epoch=1
05/28/2022 01:53:24 - INFO - __main__ - Step 200 Global step 200 Train loss 0.78 on epoch=1
05/28/2022 01:54:10 - INFO - __main__ - Global step 200 Train loss 0.92 Classification-F1 0.21883960941293779 on epoch=1
05/28/2022 01:54:10 - INFO - __main__ - Saving model with best Classification-F1: 0.10427138054772224 -> 0.21883960941293779 on epoch=1, global_step=200
05/28/2022 01:54:13 - INFO - __main__ - Step 210 Global step 210 Train loss 0.77 on epoch=1
05/28/2022 01:54:16 - INFO - __main__ - Step 220 Global step 220 Train loss 0.58 on epoch=1
05/28/2022 01:54:18 - INFO - __main__ - Step 230 Global step 230 Train loss 0.51 on epoch=2
05/28/2022 01:54:21 - INFO - __main__ - Step 240 Global step 240 Train loss 0.49 on epoch=2
05/28/2022 01:54:24 - INFO - __main__ - Step 250 Global step 250 Train loss 0.52 on epoch=2
05/28/2022 01:55:14 - INFO - __main__ - Global step 250 Train loss 0.57 Classification-F1 0.26804447544587395 on epoch=2
05/28/2022 01:55:14 - INFO - __main__ - Saving model with best Classification-F1: 0.21883960941293779 -> 0.26804447544587395 on epoch=2, global_step=250
05/28/2022 01:55:17 - INFO - __main__ - Step 260 Global step 260 Train loss 0.61 on epoch=2
05/28/2022 01:55:19 - INFO - __main__ - Step 270 Global step 270 Train loss 0.44 on epoch=2
05/28/2022 01:55:22 - INFO - __main__ - Step 280 Global step 280 Train loss 0.42 on epoch=2
05/28/2022 01:55:25 - INFO - __main__ - Step 290 Global step 290 Train loss 0.35 on epoch=2
05/28/2022 01:55:27 - INFO - __main__ - Step 300 Global step 300 Train loss 0.38 on epoch=2
05/28/2022 01:56:18 - INFO - __main__ - Global step 300 Train loss 0.44 Classification-F1 0.38309224727482316 on epoch=2
05/28/2022 01:56:18 - INFO - __main__ - Saving model with best Classification-F1: 0.26804447544587395 -> 0.38309224727482316 on epoch=2, global_step=300
05/28/2022 01:56:21 - INFO - __main__ - Step 310 Global step 310 Train loss 0.33 on epoch=2
05/28/2022 01:56:23 - INFO - __main__ - Step 320 Global step 320 Train loss 0.44 on epoch=2
05/28/2022 01:56:26 - INFO - __main__ - Step 330 Global step 330 Train loss 0.38 on epoch=2
05/28/2022 01:56:29 - INFO - __main__ - Step 340 Global step 340 Train loss 0.32 on epoch=3
05/28/2022 01:56:31 - INFO - __main__ - Step 350 Global step 350 Train loss 0.21 on epoch=3
05/28/2022 01:57:23 - INFO - __main__ - Global step 350 Train loss 0.34 Classification-F1 0.3938884702136676 on epoch=3
05/28/2022 01:57:23 - INFO - __main__ - Saving model with best Classification-F1: 0.38309224727482316 -> 0.3938884702136676 on epoch=3, global_step=350
05/28/2022 01:57:26 - INFO - __main__ - Step 360 Global step 360 Train loss 0.30 on epoch=3
05/28/2022 01:57:28 - INFO - __main__ - Step 370 Global step 370 Train loss 0.46 on epoch=3
05/28/2022 01:57:31 - INFO - __main__ - Step 380 Global step 380 Train loss 0.23 on epoch=3
05/28/2022 01:57:33 - INFO - __main__ - Step 390 Global step 390 Train loss 0.27 on epoch=3
05/28/2022 01:57:36 - INFO - __main__ - Step 400 Global step 400 Train loss 0.28 on epoch=3
05/28/2022 01:58:27 - INFO - __main__ - Global step 400 Train loss 0.31 Classification-F1 0.4587560313967259 on epoch=3
05/28/2022 01:58:27 - INFO - __main__ - Saving model with best Classification-F1: 0.3938884702136676 -> 0.4587560313967259 on epoch=3, global_step=400
05/28/2022 01:58:30 - INFO - __main__ - Step 410 Global step 410 Train loss 0.25 on epoch=3
05/28/2022 01:58:33 - INFO - __main__ - Step 420 Global step 420 Train loss 0.33 on epoch=3
05/28/2022 01:58:35 - INFO - __main__ - Step 430 Global step 430 Train loss 0.33 on epoch=3
05/28/2022 01:58:38 - INFO - __main__ - Step 440 Global step 440 Train loss 0.23 on epoch=3
05/28/2022 01:58:41 - INFO - __main__ - Step 450 Global step 450 Train loss 0.23 on epoch=4
05/28/2022 01:59:32 - INFO - __main__ - Global step 450 Train loss 0.27 Classification-F1 0.4606041229307476 on epoch=4
05/28/2022 01:59:32 - INFO - __main__ - Saving model with best Classification-F1: 0.4587560313967259 -> 0.4606041229307476 on epoch=4, global_step=450
05/28/2022 01:59:34 - INFO - __main__ - Step 460 Global step 460 Train loss 0.20 on epoch=4
05/28/2022 01:59:37 - INFO - __main__ - Step 470 Global step 470 Train loss 0.18 on epoch=4
05/28/2022 01:59:40 - INFO - __main__ - Step 480 Global step 480 Train loss 0.41 on epoch=4
05/28/2022 01:59:42 - INFO - __main__ - Step 490 Global step 490 Train loss 0.19 on epoch=4
05/28/2022 01:59:45 - INFO - __main__ - Step 500 Global step 500 Train loss 0.22 on epoch=4
05/28/2022 02:00:36 - INFO - __main__ - Global step 500 Train loss 0.24 Classification-F1 0.48776709376754324 on epoch=4
05/28/2022 02:00:36 - INFO - __main__ - Saving model with best Classification-F1: 0.4606041229307476 -> 0.48776709376754324 on epoch=4, global_step=500
05/28/2022 02:00:39 - INFO - __main__ - Step 510 Global step 510 Train loss 0.20 on epoch=4
05/28/2022 02:00:41 - INFO - __main__ - Step 520 Global step 520 Train loss 0.28 on epoch=4
05/28/2022 02:00:44 - INFO - __main__ - Step 530 Global step 530 Train loss 0.21 on epoch=4
05/28/2022 02:00:46 - INFO - __main__ - Step 540 Global step 540 Train loss 0.32 on epoch=4
05/28/2022 02:00:49 - INFO - __main__ - Step 550 Global step 550 Train loss 0.25 on epoch=4
05/28/2022 02:01:39 - INFO - __main__ - Global step 550 Train loss 0.25 Classification-F1 0.3933020120898313 on epoch=4
05/28/2022 02:01:42 - INFO - __main__ - Step 560 Global step 560 Train loss 0.14 on epoch=4
05/28/2022 02:01:45 - INFO - __main__ - Step 570 Global step 570 Train loss 0.15 on epoch=5
05/28/2022 02:01:47 - INFO - __main__ - Step 580 Global step 580 Train loss 0.14 on epoch=5
05/28/2022 02:01:50 - INFO - __main__ - Step 590 Global step 590 Train loss 0.34 on epoch=5
05/28/2022 02:01:53 - INFO - __main__ - Step 600 Global step 600 Train loss 0.18 on epoch=5
05/28/2022 02:02:43 - INFO - __main__ - Global step 600 Train loss 0.19 Classification-F1 0.4821727153237033 on epoch=5
05/28/2022 02:02:46 - INFO - __main__ - Step 610 Global step 610 Train loss 0.23 on epoch=5
05/28/2022 02:02:49 - INFO - __main__ - Step 620 Global step 620 Train loss 0.14 on epoch=5
05/28/2022 02:02:51 - INFO - __main__ - Step 630 Global step 630 Train loss 0.18 on epoch=5
05/28/2022 02:02:54 - INFO - __main__ - Step 640 Global step 640 Train loss 0.12 on epoch=5
05/28/2022 02:02:57 - INFO - __main__ - Step 650 Global step 650 Train loss 0.14 on epoch=5
05/28/2022 02:03:47 - INFO - __main__ - Global step 650 Train loss 0.16 Classification-F1 0.41228904114830384 on epoch=5
05/28/2022 02:03:49 - INFO - __main__ - Step 660 Global step 660 Train loss 0.19 on epoch=5
05/28/2022 02:03:52 - INFO - __main__ - Step 670 Global step 670 Train loss 0.16 on epoch=5
05/28/2022 02:03:55 - INFO - __main__ - Step 680 Global step 680 Train loss 0.11 on epoch=6
05/28/2022 02:03:58 - INFO - __main__ - Step 690 Global step 690 Train loss 0.11 on epoch=6
05/28/2022 02:04:00 - INFO - __main__ - Step 700 Global step 700 Train loss 0.17 on epoch=6
05/28/2022 02:04:52 - INFO - __main__ - Global step 700 Train loss 0.15 Classification-F1 0.4458135684337555 on epoch=6
05/28/2022 02:04:54 - INFO - __main__ - Step 710 Global step 710 Train loss 0.18 on epoch=6
05/28/2022 02:04:57 - INFO - __main__ - Step 720 Global step 720 Train loss 0.14 on epoch=6
05/28/2022 02:05:00 - INFO - __main__ - Step 730 Global step 730 Train loss 0.12 on epoch=6
05/28/2022 02:05:02 - INFO - __main__ - Step 740 Global step 740 Train loss 0.15 on epoch=6
05/28/2022 02:05:05 - INFO - __main__ - Step 750 Global step 750 Train loss 0.13 on epoch=6
05/28/2022 02:05:56 - INFO - __main__ - Global step 750 Train loss 0.14 Classification-F1 0.4665110406379412 on epoch=6
05/28/2022 02:05:58 - INFO - __main__ - Step 760 Global step 760 Train loss 0.17 on epoch=6
05/28/2022 02:06:01 - INFO - __main__ - Step 770 Global step 770 Train loss 0.17 on epoch=6
05/28/2022 02:06:04 - INFO - __main__ - Step 780 Global step 780 Train loss 0.13 on epoch=6
05/28/2022 02:06:06 - INFO - __main__ - Step 790 Global step 790 Train loss 0.10 on epoch=7
05/28/2022 02:06:09 - INFO - __main__ - Step 800 Global step 800 Train loss 0.09 on epoch=7
05/28/2022 02:07:00 - INFO - __main__ - Global step 800 Train loss 0.13 Classification-F1 0.5071043995093172 on epoch=7
05/28/2022 02:07:00 - INFO - __main__ - Saving model with best Classification-F1: 0.48776709376754324 -> 0.5071043995093172 on epoch=7, global_step=800
05/28/2022 02:07:03 - INFO - __main__ - Step 810 Global step 810 Train loss 0.13 on epoch=7
05/28/2022 02:07:05 - INFO - __main__ - Step 820 Global step 820 Train loss 0.19 on epoch=7
05/28/2022 02:07:08 - INFO - __main__ - Step 830 Global step 830 Train loss 0.11 on epoch=7
05/28/2022 02:07:11 - INFO - __main__ - Step 840 Global step 840 Train loss 0.26 on epoch=7
05/28/2022 02:07:13 - INFO - __main__ - Step 850 Global step 850 Train loss 0.14 on epoch=7
05/28/2022 02:08:07 - INFO - __main__ - Global step 850 Train loss 0.17 Classification-F1 0.48289754486074477 on epoch=7
05/28/2022 02:08:09 - INFO - __main__ - Step 860 Global step 860 Train loss 0.10 on epoch=7
05/28/2022 02:08:12 - INFO - __main__ - Step 870 Global step 870 Train loss 0.11 on epoch=7
05/28/2022 02:08:15 - INFO - __main__ - Step 880 Global step 880 Train loss 0.26 on epoch=7
05/28/2022 02:08:17 - INFO - __main__ - Step 890 Global step 890 Train loss 0.09 on epoch=7
05/28/2022 02:08:20 - INFO - __main__ - Step 900 Global step 900 Train loss 0.11 on epoch=8
05/28/2022 02:09:12 - INFO - __main__ - Global step 900 Train loss 0.13 Classification-F1 0.4531333004559515 on epoch=8
05/28/2022 02:09:15 - INFO - __main__ - Step 910 Global step 910 Train loss 0.08 on epoch=8
05/28/2022 02:09:17 - INFO - __main__ - Step 920 Global step 920 Train loss 0.06 on epoch=8
05/28/2022 02:09:20 - INFO - __main__ - Step 930 Global step 930 Train loss 0.20 on epoch=8
05/28/2022 02:09:23 - INFO - __main__ - Step 940 Global step 940 Train loss 0.09 on epoch=8
05/28/2022 02:09:25 - INFO - __main__ - Step 950 Global step 950 Train loss 0.17 on epoch=8
05/28/2022 02:10:17 - INFO - __main__ - Global step 950 Train loss 0.12 Classification-F1 0.5195852081409803 on epoch=8
05/28/2022 02:10:17 - INFO - __main__ - Saving model with best Classification-F1: 0.5071043995093172 -> 0.5195852081409803 on epoch=8, global_step=950
05/28/2022 02:10:19 - INFO - __main__ - Step 960 Global step 960 Train loss 0.07 on epoch=8
05/28/2022 02:10:22 - INFO - __main__ - Step 970 Global step 970 Train loss 0.11 on epoch=8
05/28/2022 02:10:25 - INFO - __main__ - Step 980 Global step 980 Train loss 0.07 on epoch=8
05/28/2022 02:10:27 - INFO - __main__ - Step 990 Global step 990 Train loss 0.14 on epoch=8
05/28/2022 02:10:30 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.06 on epoch=8
05/28/2022 02:11:23 - INFO - __main__ - Global step 1000 Train loss 0.09 Classification-F1 0.5428207091407825 on epoch=8
05/28/2022 02:11:23 - INFO - __main__ - Saving model with best Classification-F1: 0.5195852081409803 -> 0.5428207091407825 on epoch=8, global_step=1000
05/28/2022 02:11:26 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.14 on epoch=9
05/28/2022 02:11:28 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.09 on epoch=9
05/28/2022 02:11:31 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.05 on epoch=9
05/28/2022 02:11:34 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.18 on epoch=9
05/28/2022 02:11:36 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.09 on epoch=9
05/28/2022 02:12:29 - INFO - __main__ - Global step 1050 Train loss 0.11 Classification-F1 0.586952406070676 on epoch=9
05/28/2022 02:12:29 - INFO - __main__ - Saving model with best Classification-F1: 0.5428207091407825 -> 0.586952406070676 on epoch=9, global_step=1050
05/28/2022 02:12:31 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.13 on epoch=9
05/28/2022 02:12:34 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.06 on epoch=9
05/28/2022 02:12:37 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.12 on epoch=9
05/28/2022 02:12:39 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.06 on epoch=9
05/28/2022 02:12:42 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.18 on epoch=9
05/28/2022 02:13:35 - INFO - __main__ - Global step 1100 Train loss 0.11 Classification-F1 0.5917294140038527 on epoch=9
05/28/2022 02:13:35 - INFO - __main__ - Saving model with best Classification-F1: 0.586952406070676 -> 0.5917294140038527 on epoch=9, global_step=1100
05/28/2022 02:13:38 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.18 on epoch=9
05/28/2022 02:13:41 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.06 on epoch=9
05/28/2022 02:13:43 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.09 on epoch=10
05/28/2022 02:13:46 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.07 on epoch=10
05/28/2022 02:13:49 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.14 on epoch=10
05/28/2022 02:14:45 - INFO - __main__ - Global step 1150 Train loss 0.11 Classification-F1 0.6011381539836987 on epoch=10
05/28/2022 02:14:45 - INFO - __main__ - Saving model with best Classification-F1: 0.5917294140038527 -> 0.6011381539836987 on epoch=10, global_step=1150
05/28/2022 02:14:47 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.05 on epoch=10
05/28/2022 02:14:50 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.08 on epoch=10
05/28/2022 02:14:52 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.09 on epoch=10
05/28/2022 02:14:55 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.06 on epoch=10
05/28/2022 02:14:58 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.06 on epoch=10
05/28/2022 02:15:50 - INFO - __main__ - Global step 1200 Train loss 0.07 Classification-F1 0.5704634739173986 on epoch=10
05/28/2022 02:15:53 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.14 on epoch=10
05/28/2022 02:15:55 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.09 on epoch=10
05/28/2022 02:15:58 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.07 on epoch=10
05/28/2022 02:16:01 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.08 on epoch=11
05/28/2022 02:16:03 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.05 on epoch=11
05/28/2022 02:16:57 - INFO - __main__ - Global step 1250 Train loss 0.09 Classification-F1 0.5505416754178384 on epoch=11
05/28/2022 02:17:00 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.14 on epoch=11
05/28/2022 02:17:03 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.08 on epoch=11
05/28/2022 02:17:05 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.12 on epoch=11
05/28/2022 02:17:08 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.04 on epoch=11
05/28/2022 02:17:10 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.08 on epoch=11
05/28/2022 02:18:05 - INFO - __main__ - Global step 1300 Train loss 0.09 Classification-F1 0.5088045898471586 on epoch=11
05/28/2022 02:18:07 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.09 on epoch=11
05/28/2022 02:18:10 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.10 on epoch=11
05/28/2022 02:18:13 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.12 on epoch=11
05/28/2022 02:18:15 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.15 on epoch=11
05/28/2022 02:18:18 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.05 on epoch=12
05/28/2022 02:19:10 - INFO - __main__ - Global step 1350 Train loss 0.10 Classification-F1 0.6029496556451003 on epoch=12
05/28/2022 02:19:10 - INFO - __main__ - Saving model with best Classification-F1: 0.6011381539836987 -> 0.6029496556451003 on epoch=12, global_step=1350
05/28/2022 02:19:13 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.02 on epoch=12
05/28/2022 02:19:15 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.07 on epoch=12
05/28/2022 02:19:18 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.15 on epoch=12
05/28/2022 02:19:21 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.02 on epoch=12
05/28/2022 02:19:23 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.09 on epoch=12
05/28/2022 02:20:15 - INFO - __main__ - Global step 1400 Train loss 0.07 Classification-F1 0.47226747335767855 on epoch=12
05/28/2022 02:20:18 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.07 on epoch=12
05/28/2022 02:20:20 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.05 on epoch=12
05/28/2022 02:20:23 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.05 on epoch=12
05/28/2022 02:20:26 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.19 on epoch=12
05/28/2022 02:20:29 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.05 on epoch=12
05/28/2022 02:21:22 - INFO - __main__ - Global step 1450 Train loss 0.08 Classification-F1 0.547664750826829 on epoch=12
05/28/2022 02:21:24 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.04 on epoch=13
05/28/2022 02:21:27 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.09 on epoch=13
05/28/2022 02:21:30 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.03 on epoch=13
05/28/2022 02:21:32 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.16 on epoch=13
05/28/2022 02:21:35 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.04 on epoch=13
05/28/2022 02:22:24 - INFO - __main__ - Global step 1500 Train loss 0.07 Classification-F1 0.5393195715135689 on epoch=13
05/28/2022 02:22:27 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.09 on epoch=13
05/28/2022 02:22:30 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.04 on epoch=13
05/28/2022 02:22:32 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.08 on epoch=13
05/28/2022 02:22:35 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.04 on epoch=13
05/28/2022 02:22:37 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.15 on epoch=13
05/28/2022 02:23:28 - INFO - __main__ - Global step 1550 Train loss 0.08 Classification-F1 0.4015706375626057 on epoch=13
05/28/2022 02:23:31 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.09 on epoch=13
05/28/2022 02:23:34 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.06 on epoch=14
05/28/2022 02:23:36 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.03 on epoch=14
05/28/2022 02:23:39 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.02 on epoch=14
05/28/2022 02:23:41 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.20 on epoch=14
05/28/2022 02:24:31 - INFO - __main__ - Global step 1600 Train loss 0.08 Classification-F1 0.4685307091156484 on epoch=14
05/28/2022 02:24:34 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=14
05/28/2022 02:24:36 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.06 on epoch=14
05/28/2022 02:24:39 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.06 on epoch=14
05/28/2022 02:24:42 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.05 on epoch=14
05/28/2022 02:24:44 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.04 on epoch=14
05/28/2022 02:25:35 - INFO - __main__ - Global step 1650 Train loss 0.05 Classification-F1 0.4289923881887505 on epoch=14
05/28/2022 02:25:37 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.07 on epoch=14
05/28/2022 02:25:40 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.07 on epoch=14
05/28/2022 02:25:42 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.07 on epoch=14
05/28/2022 02:25:45 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.02 on epoch=15
05/28/2022 02:25:48 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.07 on epoch=15
05/28/2022 02:26:38 - INFO - __main__ - Global step 1700 Train loss 0.06 Classification-F1 0.42949334888411644 on epoch=15
05/28/2022 02:26:40 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.13 on epoch=15
05/28/2022 02:26:43 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=15
05/28/2022 02:26:46 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.09 on epoch=15
05/28/2022 02:26:48 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.04 on epoch=15
05/28/2022 02:26:51 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.05 on epoch=15
05/28/2022 02:27:42 - INFO - __main__ - Global step 1750 Train loss 0.07 Classification-F1 0.3940035844508677 on epoch=15
05/28/2022 02:27:44 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=15
05/28/2022 02:27:47 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.08 on epoch=15
05/28/2022 02:27:50 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.07 on epoch=15
05/28/2022 02:27:52 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.05 on epoch=15
05/28/2022 02:27:55 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.03 on epoch=16
05/28/2022 02:28:45 - INFO - __main__ - Global step 1800 Train loss 0.05 Classification-F1 0.4494601649231651 on epoch=16
05/28/2022 02:28:48 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.03 on epoch=16
05/28/2022 02:28:50 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.06 on epoch=16
05/28/2022 02:28:53 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.06 on epoch=16
05/28/2022 02:28:56 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.07 on epoch=16
05/28/2022 02:28:58 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.05 on epoch=16
05/28/2022 02:29:47 - INFO - __main__ - Global step 1850 Train loss 0.05 Classification-F1 0.4733484004338506 on epoch=16
05/28/2022 02:29:50 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.03 on epoch=16
05/28/2022 02:29:53 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.05 on epoch=16
05/28/2022 02:29:55 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.06 on epoch=16
05/28/2022 02:29:58 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.07 on epoch=16
05/28/2022 02:30:00 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.09 on epoch=16
05/28/2022 02:30:52 - INFO - __main__ - Global step 1900 Train loss 0.06 Classification-F1 0.43723596861130715 on epoch=16
05/28/2022 02:30:54 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=17
05/28/2022 02:30:57 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=17
05/28/2022 02:30:59 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.08 on epoch=17
05/28/2022 02:31:02 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.09 on epoch=17
05/28/2022 02:31:05 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.04 on epoch=17
05/28/2022 02:31:55 - INFO - __main__ - Global step 1950 Train loss 0.05 Classification-F1 0.48533170732551495 on epoch=17
05/28/2022 02:31:58 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.05 on epoch=17
05/28/2022 02:32:00 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.05 on epoch=17
05/28/2022 02:32:03 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.05 on epoch=17
05/28/2022 02:32:05 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.05 on epoch=17
05/28/2022 02:32:08 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.14 on epoch=17
05/28/2022 02:33:01 - INFO - __main__ - Global step 2000 Train loss 0.07 Classification-F1 0.42855319613502696 on epoch=17
05/28/2022 02:33:04 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.06 on epoch=17
05/28/2022 02:33:06 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.04 on epoch=18
05/28/2022 02:33:09 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.03 on epoch=18
05/28/2022 02:33:11 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=18
05/28/2022 02:33:14 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.17 on epoch=18
05/28/2022 02:34:04 - INFO - __main__ - Global step 2050 Train loss 0.06 Classification-F1 0.38663365192070115 on epoch=18
05/28/2022 02:34:06 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.06 on epoch=18
05/28/2022 02:34:09 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.06 on epoch=18
05/28/2022 02:34:12 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.05 on epoch=18
05/28/2022 02:34:14 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.05 on epoch=18
05/28/2022 02:34:17 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=18
05/28/2022 02:35:06 - INFO - __main__ - Global step 2100 Train loss 0.05 Classification-F1 0.5033392806954206 on epoch=18
05/28/2022 02:35:09 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.11 on epoch=18
05/28/2022 02:35:11 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.04 on epoch=18
05/28/2022 02:35:14 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=19
05/28/2022 02:35:17 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.06 on epoch=19
05/28/2022 02:35:19 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=19
05/28/2022 02:36:09 - INFO - __main__ - Global step 2150 Train loss 0.05 Classification-F1 0.5289370113974736 on epoch=19
05/28/2022 02:36:12 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.09 on epoch=19
05/28/2022 02:36:14 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.05 on epoch=19
05/28/2022 02:36:17 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.06 on epoch=19
05/28/2022 02:36:19 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=19
05/28/2022 02:36:22 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.11 on epoch=19
05/28/2022 02:37:12 - INFO - __main__ - Global step 2200 Train loss 0.07 Classification-F1 0.5502720869344861 on epoch=19
05/28/2022 02:37:14 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=19
05/28/2022 02:37:17 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.10 on epoch=19
05/28/2022 02:37:20 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.06 on epoch=19
05/28/2022 02:37:22 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.03 on epoch=19
05/28/2022 02:37:25 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=20
05/28/2022 02:38:15 - INFO - __main__ - Global step 2250 Train loss 0.05 Classification-F1 0.507601992634766 on epoch=20
05/28/2022 02:38:18 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=20
05/28/2022 02:38:20 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.08 on epoch=20
05/28/2022 02:38:23 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=20
05/28/2022 02:38:25 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.05 on epoch=20
05/28/2022 02:38:28 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.06 on epoch=20
05/28/2022 02:39:17 - INFO - __main__ - Global step 2300 Train loss 0.05 Classification-F1 0.5576052482660501 on epoch=20
05/28/2022 02:39:20 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.04 on epoch=20
05/28/2022 02:39:22 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=20
05/28/2022 02:39:25 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.08 on epoch=20
05/28/2022 02:39:27 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.12 on epoch=20
05/28/2022 02:39:30 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.06 on epoch=20
05/28/2022 02:40:20 - INFO - __main__ - Global step 2350 Train loss 0.06 Classification-F1 0.5999005079589564 on epoch=20
05/28/2022 02:40:22 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.04 on epoch=21
05/28/2022 02:40:25 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.04 on epoch=21
05/28/2022 02:40:28 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.06 on epoch=21
05/28/2022 02:40:30 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=21
05/28/2022 02:40:33 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.03 on epoch=21
05/28/2022 02:41:23 - INFO - __main__ - Global step 2400 Train loss 0.04 Classification-F1 0.54057104301001 on epoch=21
05/28/2022 02:41:25 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.03 on epoch=21
05/28/2022 02:41:28 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.03 on epoch=21
05/28/2022 02:41:30 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=21
05/28/2022 02:41:33 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.07 on epoch=21
05/28/2022 02:41:36 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.06 on epoch=21
05/28/2022 02:42:25 - INFO - __main__ - Global step 2450 Train loss 0.04 Classification-F1 0.6285968374693777 on epoch=21
05/28/2022 02:42:25 - INFO - __main__ - Saving model with best Classification-F1: 0.6029496556451003 -> 0.6285968374693777 on epoch=21, global_step=2450
05/28/2022 02:42:28 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=21
05/28/2022 02:42:30 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=22
05/28/2022 02:42:33 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.04 on epoch=22
05/28/2022 02:42:36 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.07 on epoch=22
05/28/2022 02:42:38 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.05 on epoch=22
05/28/2022 02:43:28 - INFO - __main__ - Global step 2500 Train loss 0.04 Classification-F1 0.6021957619268669 on epoch=22
05/28/2022 02:43:31 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.05 on epoch=22
05/28/2022 02:43:33 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.04 on epoch=22
05/28/2022 02:43:36 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=22
05/28/2022 02:43:39 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=22
05/28/2022 02:43:41 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.05 on epoch=22
05/28/2022 02:44:31 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.5074333197070434 on epoch=22
05/28/2022 02:44:33 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.10 on epoch=22
05/28/2022 02:44:36 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=22
05/28/2022 02:44:39 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.03 on epoch=23
05/28/2022 02:44:41 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.04 on epoch=23
05/28/2022 02:44:44 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=23
05/28/2022 02:45:34 - INFO - __main__ - Global step 2600 Train loss 0.04 Classification-F1 0.48854201238705847 on epoch=23
05/28/2022 02:45:36 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.10 on epoch=23
05/28/2022 02:45:39 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.04 on epoch=23
05/28/2022 02:45:41 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.06 on epoch=23
05/28/2022 02:45:44 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.05 on epoch=23
05/28/2022 02:45:47 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.06 on epoch=23
05/28/2022 02:46:36 - INFO - __main__ - Global step 2650 Train loss 0.06 Classification-F1 0.4565709353902334 on epoch=23
05/28/2022 02:46:39 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=23
05/28/2022 02:46:41 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.11 on epoch=23
05/28/2022 02:46:44 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.03 on epoch=23
05/28/2022 02:46:46 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=24
05/28/2022 02:46:49 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=24
05/28/2022 02:47:39 - INFO - __main__ - Global step 2700 Train loss 0.04 Classification-F1 0.5399957241050481 on epoch=24
05/28/2022 02:47:41 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=24
05/28/2022 02:47:44 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.18 on epoch=24
05/28/2022 02:47:46 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=24
05/28/2022 02:47:49 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.07 on epoch=24
05/28/2022 02:47:51 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.06 on epoch=24
05/28/2022 02:48:43 - INFO - __main__ - Global step 2750 Train loss 0.07 Classification-F1 0.558532189957219 on epoch=24
05/28/2022 02:48:45 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.04 on epoch=24
05/28/2022 02:48:48 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=24
05/28/2022 02:48:51 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.07 on epoch=24
05/28/2022 02:48:53 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.03 on epoch=24
05/28/2022 02:48:56 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.04 on epoch=24
05/28/2022 02:49:46 - INFO - __main__ - Global step 2800 Train loss 0.04 Classification-F1 0.539216361190833 on epoch=24
05/28/2022 02:49:48 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=25
05/28/2022 02:49:51 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=25
05/28/2022 02:49:53 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.04 on epoch=25
05/28/2022 02:49:56 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=25
05/28/2022 02:49:58 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.03 on epoch=25
05/28/2022 02:50:49 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.5341497956181097 on epoch=25
05/28/2022 02:50:52 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=25
05/28/2022 02:50:54 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=25
05/28/2022 02:50:57 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.04 on epoch=25
05/28/2022 02:50:59 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.06 on epoch=25
05/28/2022 02:51:02 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.06 on epoch=25
05/28/2022 02:51:52 - INFO - __main__ - Global step 2900 Train loss 0.04 Classification-F1 0.5388924091853027 on epoch=25
05/28/2022 02:51:55 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=25
05/28/2022 02:51:57 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=26
05/28/2022 02:52:00 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=26
05/28/2022 02:52:02 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.06 on epoch=26
05/28/2022 02:52:05 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=26
05/28/2022 02:52:56 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.5922793525143188 on epoch=26
05/28/2022 02:52:59 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.16 on epoch=26
05/28/2022 02:53:02 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.04 on epoch=26
05/28/2022 02:53:04 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=26
05/28/2022 02:53:07 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.03 on epoch=26
05/28/2022 02:53:09 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.04 on epoch=26
05/28/2022 02:53:11 - INFO - __main__ - Start tokenizing ... 1792 instances
05/28/2022 02:53:11 - INFO - __main__ - Printing 3 examples
05/28/2022 02:53:11 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/28/2022 02:53:11 - INFO - __main__ - ['Animal']
05/28/2022 02:53:11 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/28/2022 02:53:11 - INFO - __main__ - ['Animal']
05/28/2022 02:53:11 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
05/28/2022 02:53:11 - INFO - __main__ - ['Animal']
05/28/2022 02:53:11 - INFO - __main__ - Tokenizing Input ...
05/28/2022 02:53:12 - INFO - __main__ - Tokenizing Output ...
05/28/2022 02:53:14 - INFO - __main__ - Loaded 1792 examples from train data
05/28/2022 02:53:14 - INFO - __main__ - Start tokenizing ... 1792 instances
05/28/2022 02:53:14 - INFO - __main__ - Printing 3 examples
05/28/2022 02:53:14 - INFO - __main__ -  [dbpedia_14] The Andaman Treepie (Dendrocitta bayleyi) is a species of bird in the Corvidae family.It is endemic to the Andaman Islands of India.Its natural habitat is subtropical or tropical moist lowland forests. It is threatened by habitat loss.The scientific name commemorates the Anglo-Indian statesman Edward Clive Bayley.
05/28/2022 02:53:14 - INFO - __main__ - ['Animal']
05/28/2022 02:53:14 - INFO - __main__ -  [dbpedia_14] Ethmia tyranthes is a moth in the Ethmiidae family. It is found in the Democratic Republic of Congo.
05/28/2022 02:53:14 - INFO - __main__ - ['Animal']
05/28/2022 02:53:14 - INFO - __main__ -  [dbpedia_14] Van Son’s Brown (Stygionympha vansoni) is a butterfly of the Nymphalidae family. It is found in South Africa in the northern Cape from the Kamiesberg to the Springbok area.The wingspan is 36–38 mm for males and 38–40 mm for females. Adults are on wing from August to October. There is one generation per year.The larvae probably feed on Poaceae grasses.
05/28/2022 02:53:14 - INFO - __main__ - ['Animal']
05/28/2022 02:53:14 - INFO - __main__ - Tokenizing Input ...
05/28/2022 02:53:15 - INFO - __main__ - Tokenizing Output ...
05/28/2022 02:53:16 - INFO - __main__ - Loaded 1792 examples from dev data
05/28/2022 02:53:32 - INFO - __main__ - load prompt embedding from ckpt
05/28/2022 02:53:32 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/28/2022 02:53:32 - INFO - __main__ - Starting training!
05/28/2022 02:54:00 - INFO - __main__ - Global step 3000 Train loss 0.06 Classification-F1 0.5962290689192903 on epoch=26
05/28/2022 02:54:00 - INFO - __main__ - save last model!
05/28/2022 02:54:00 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/28/2022 02:54:00 - INFO - __main__ - Start tokenizing ... 3500 instances
05/28/2022 02:54:00 - INFO - __main__ - Printing 3 examples
05/28/2022 02:54:00 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/28/2022 02:54:00 - INFO - __main__ - ['Animal']
05/28/2022 02:54:00 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/28/2022 02:54:00 - INFO - __main__ - ['Animal']
05/28/2022 02:54:00 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/28/2022 02:54:00 - INFO - __main__ - ['Village']
05/28/2022 02:54:00 - INFO - __main__ - Tokenizing Input ...
05/28/2022 02:54:02 - INFO - __main__ - Tokenizing Output ...
05/28/2022 02:54:05 - INFO - __main__ - Loaded 3500 examples from test data
05/28/2022 02:56:12 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down128shot/singletask-dbpedia_14/dbpedia_14_128_13_0.5_8_predictions.txt
05/28/2022 02:56:12 - INFO - __main__ - Classification-F1 on test data: 0.4885
05/28/2022 02:56:13 - INFO - __main__ - prefix=dbpedia_14_128_13, lr=0.5, bsz=8, dev_performance=0.6285968374693777, test_performance=0.4884501048574429
05/28/2022 02:56:13 - INFO - __main__ - Running ... prefix=dbpedia_14_128_13, lr=0.4, bsz=8 ...
05/28/2022 02:56:14 - INFO - __main__ - Start tokenizing ... 1792 instances
05/28/2022 02:56:14 - INFO - __main__ - Printing 3 examples
05/28/2022 02:56:14 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/28/2022 02:56:14 - INFO - __main__ - ['Animal']
05/28/2022 02:56:14 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/28/2022 02:56:14 - INFO - __main__ - ['Animal']
05/28/2022 02:56:14 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
05/28/2022 02:56:14 - INFO - __main__ - ['Animal']
05/28/2022 02:56:14 - INFO - __main__ - Tokenizing Input ...
05/28/2022 02:56:15 - INFO - __main__ - Tokenizing Output ...
05/28/2022 02:56:16 - INFO - __main__ - Loaded 1792 examples from train data
05/28/2022 02:56:16 - INFO - __main__ - Start tokenizing ... 1792 instances
05/28/2022 02:56:16 - INFO - __main__ - Printing 3 examples
05/28/2022 02:56:16 - INFO - __main__ -  [dbpedia_14] The Andaman Treepie (Dendrocitta bayleyi) is a species of bird in the Corvidae family.It is endemic to the Andaman Islands of India.Its natural habitat is subtropical or tropical moist lowland forests. It is threatened by habitat loss.The scientific name commemorates the Anglo-Indian statesman Edward Clive Bayley.
05/28/2022 02:56:16 - INFO - __main__ - ['Animal']
05/28/2022 02:56:16 - INFO - __main__ -  [dbpedia_14] Ethmia tyranthes is a moth in the Ethmiidae family. It is found in the Democratic Republic of Congo.
05/28/2022 02:56:16 - INFO - __main__ - ['Animal']
05/28/2022 02:56:16 - INFO - __main__ -  [dbpedia_14] Van Son’s Brown (Stygionympha vansoni) is a butterfly of the Nymphalidae family. It is found in South Africa in the northern Cape from the Kamiesberg to the Springbok area.The wingspan is 36–38 mm for males and 38–40 mm for females. Adults are on wing from August to October. There is one generation per year.The larvae probably feed on Poaceae grasses.
05/28/2022 02:56:16 - INFO - __main__ - ['Animal']
05/28/2022 02:56:16 - INFO - __main__ - Tokenizing Input ...
05/28/2022 02:56:17 - INFO - __main__ - Tokenizing Output ...
05/28/2022 02:56:19 - INFO - __main__ - Loaded 1792 examples from dev data
05/28/2022 02:56:35 - INFO - __main__ - load prompt embedding from ckpt
05/28/2022 02:56:36 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/28/2022 02:56:36 - INFO - __main__ - Starting training!
05/28/2022 02:56:40 - INFO - __main__ - Step 10 Global step 10 Train loss 6.92 on epoch=0
05/28/2022 02:56:42 - INFO - __main__ - Step 20 Global step 20 Train loss 5.04 on epoch=0
05/28/2022 02:56:45 - INFO - __main__ - Step 30 Global step 30 Train loss 4.20 on epoch=0
05/28/2022 02:56:48 - INFO - __main__ - Step 40 Global step 40 Train loss 3.32 on epoch=0
05/28/2022 02:56:50 - INFO - __main__ - Step 50 Global step 50 Train loss 3.39 on epoch=0
05/28/2022 02:57:41 - INFO - __main__ - Global step 50 Train loss 4.57 Classification-F1 0.01261935276635535 on epoch=0
05/28/2022 02:57:41 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.01261935276635535 on epoch=0, global_step=50
05/28/2022 02:57:44 - INFO - __main__ - Step 60 Global step 60 Train loss 2.80 on epoch=0
05/28/2022 02:57:46 - INFO - __main__ - Step 70 Global step 70 Train loss 2.68 on epoch=0
05/28/2022 02:57:49 - INFO - __main__ - Step 80 Global step 80 Train loss 2.35 on epoch=0
05/28/2022 02:57:52 - INFO - __main__ - Step 90 Global step 90 Train loss 2.20 on epoch=0
05/28/2022 02:57:54 - INFO - __main__ - Step 100 Global step 100 Train loss 2.07 on epoch=0
05/28/2022 02:58:41 - INFO - __main__ - Global step 100 Train loss 2.42 Classification-F1 0.035590000247362676 on epoch=0
05/28/2022 02:58:41 - INFO - __main__ - Saving model with best Classification-F1: 0.01261935276635535 -> 0.035590000247362676 on epoch=0, global_step=100
05/28/2022 02:58:44 - INFO - __main__ - Step 110 Global step 110 Train loss 1.87 on epoch=0
05/28/2022 02:58:47 - INFO - __main__ - Step 120 Global step 120 Train loss 1.75 on epoch=1
05/28/2022 02:58:50 - INFO - __main__ - Step 130 Global step 130 Train loss 1.82 on epoch=1
05/28/2022 02:58:52 - INFO - __main__ - Step 140 Global step 140 Train loss 1.57 on epoch=1
05/28/2022 02:58:55 - INFO - __main__ - Step 150 Global step 150 Train loss 1.30 on epoch=1
05/28/2022 02:59:40 - INFO - __main__ - Global step 150 Train loss 1.66 Classification-F1 0.07043563257069017 on epoch=1
05/28/2022 02:59:40 - INFO - __main__ - Saving model with best Classification-F1: 0.035590000247362676 -> 0.07043563257069017 on epoch=1, global_step=150
05/28/2022 02:59:42 - INFO - __main__ - Step 160 Global step 160 Train loss 1.29 on epoch=1
05/28/2022 02:59:45 - INFO - __main__ - Step 170 Global step 170 Train loss 1.26 on epoch=1
05/28/2022 02:59:48 - INFO - __main__ - Step 180 Global step 180 Train loss 1.31 on epoch=1
05/28/2022 02:59:50 - INFO - __main__ - Step 190 Global step 190 Train loss 1.06 on epoch=1
05/28/2022 02:59:53 - INFO - __main__ - Step 200 Global step 200 Train loss 1.03 on epoch=1
05/28/2022 03:00:37 - INFO - __main__ - Global step 200 Train loss 1.19 Classification-F1 0.14519529091686212 on epoch=1
05/28/2022 03:00:37 - INFO - __main__ - Saving model with best Classification-F1: 0.07043563257069017 -> 0.14519529091686212 on epoch=1, global_step=200
05/28/2022 03:00:40 - INFO - __main__ - Step 210 Global step 210 Train loss 0.99 on epoch=1
05/28/2022 03:00:43 - INFO - __main__ - Step 220 Global step 220 Train loss 0.75 on epoch=1
05/28/2022 03:00:45 - INFO - __main__ - Step 230 Global step 230 Train loss 0.80 on epoch=2
05/28/2022 03:00:48 - INFO - __main__ - Step 240 Global step 240 Train loss 0.75 on epoch=2
05/28/2022 03:00:50 - INFO - __main__ - Step 250 Global step 250 Train loss 0.71 on epoch=2
05/28/2022 03:01:40 - INFO - __main__ - Global step 250 Train loss 0.80 Classification-F1 0.2067274591660614 on epoch=2
05/28/2022 03:01:41 - INFO - __main__ - Saving model with best Classification-F1: 0.14519529091686212 -> 0.2067274591660614 on epoch=2, global_step=250
05/28/2022 03:01:43 - INFO - __main__ - Step 260 Global step 260 Train loss 0.82 on epoch=2
05/28/2022 03:01:46 - INFO - __main__ - Step 270 Global step 270 Train loss 0.59 on epoch=2
05/28/2022 03:01:48 - INFO - __main__ - Step 280 Global step 280 Train loss 0.62 on epoch=2
05/28/2022 03:01:51 - INFO - __main__ - Step 290 Global step 290 Train loss 0.53 on epoch=2
05/28/2022 03:01:54 - INFO - __main__ - Step 300 Global step 300 Train loss 0.49 on epoch=2
05/28/2022 03:02:46 - INFO - __main__ - Global step 300 Train loss 0.61 Classification-F1 0.26967807688346124 on epoch=2
05/28/2022 03:02:46 - INFO - __main__ - Saving model with best Classification-F1: 0.2067274591660614 -> 0.26967807688346124 on epoch=2, global_step=300
05/28/2022 03:02:48 - INFO - __main__ - Step 310 Global step 310 Train loss 0.49 on epoch=2
05/28/2022 03:02:51 - INFO - __main__ - Step 320 Global step 320 Train loss 0.61 on epoch=2
05/28/2022 03:02:54 - INFO - __main__ - Step 330 Global step 330 Train loss 0.37 on epoch=2
05/28/2022 03:02:56 - INFO - __main__ - Step 340 Global step 340 Train loss 0.32 on epoch=3
05/28/2022 03:02:59 - INFO - __main__ - Step 350 Global step 350 Train loss 0.36 on epoch=3
05/28/2022 03:03:55 - INFO - __main__ - Global step 350 Train loss 0.43 Classification-F1 0.3218206244609908 on epoch=3
05/28/2022 03:03:55 - INFO - __main__ - Saving model with best Classification-F1: 0.26967807688346124 -> 0.3218206244609908 on epoch=3, global_step=350
05/28/2022 03:03:58 - INFO - __main__ - Step 360 Global step 360 Train loss 0.36 on epoch=3
05/28/2022 03:04:01 - INFO - __main__ - Step 370 Global step 370 Train loss 0.50 on epoch=3
05/28/2022 03:04:03 - INFO - __main__ - Step 380 Global step 380 Train loss 0.28 on epoch=3
05/28/2022 03:04:06 - INFO - __main__ - Step 390 Global step 390 Train loss 0.35 on epoch=3
05/28/2022 03:04:08 - INFO - __main__ - Step 400 Global step 400 Train loss 0.37 on epoch=3
05/28/2022 03:05:03 - INFO - __main__ - Global step 400 Train loss 0.37 Classification-F1 0.39019682422187385 on epoch=3
05/28/2022 03:05:03 - INFO - __main__ - Saving model with best Classification-F1: 0.3218206244609908 -> 0.39019682422187385 on epoch=3, global_step=400
05/28/2022 03:05:05 - INFO - __main__ - Step 410 Global step 410 Train loss 0.41 on epoch=3
05/28/2022 03:05:08 - INFO - __main__ - Step 420 Global step 420 Train loss 0.27 on epoch=3
05/28/2022 03:05:11 - INFO - __main__ - Step 430 Global step 430 Train loss 0.38 on epoch=3
05/28/2022 03:05:13 - INFO - __main__ - Step 440 Global step 440 Train loss 0.33 on epoch=3
05/28/2022 03:05:16 - INFO - __main__ - Step 450 Global step 450 Train loss 0.19 on epoch=4
05/28/2022 03:06:12 - INFO - __main__ - Global step 450 Train loss 0.31 Classification-F1 0.4195823287998556 on epoch=4
05/28/2022 03:06:12 - INFO - __main__ - Saving model with best Classification-F1: 0.39019682422187385 -> 0.4195823287998556 on epoch=4, global_step=450
05/28/2022 03:06:15 - INFO - __main__ - Step 460 Global step 460 Train loss 0.27 on epoch=4
05/28/2022 03:06:17 - INFO - __main__ - Step 470 Global step 470 Train loss 0.21 on epoch=4
05/28/2022 03:06:20 - INFO - __main__ - Step 480 Global step 480 Train loss 0.41 on epoch=4
05/28/2022 03:06:23 - INFO - __main__ - Step 490 Global step 490 Train loss 0.21 on epoch=4
05/28/2022 03:06:25 - INFO - __main__ - Step 500 Global step 500 Train loss 0.41 on epoch=4
05/28/2022 03:07:19 - INFO - __main__ - Global step 500 Train loss 0.30 Classification-F1 0.43479034656534926 on epoch=4
05/28/2022 03:07:19 - INFO - __main__ - Saving model with best Classification-F1: 0.4195823287998556 -> 0.43479034656534926 on epoch=4, global_step=500
05/28/2022 03:07:22 - INFO - __main__ - Step 510 Global step 510 Train loss 0.29 on epoch=4
05/28/2022 03:07:24 - INFO - __main__ - Step 520 Global step 520 Train loss 0.28 on epoch=4
05/28/2022 03:07:27 - INFO - __main__ - Step 530 Global step 530 Train loss 0.19 on epoch=4
05/28/2022 03:07:29 - INFO - __main__ - Step 540 Global step 540 Train loss 0.44 on epoch=4
05/28/2022 03:07:32 - INFO - __main__ - Step 550 Global step 550 Train loss 0.22 on epoch=4
05/28/2022 03:08:27 - INFO - __main__ - Global step 550 Train loss 0.29 Classification-F1 0.4801346286848389 on epoch=4
05/28/2022 03:08:27 - INFO - __main__ - Saving model with best Classification-F1: 0.43479034656534926 -> 0.4801346286848389 on epoch=4, global_step=550
05/28/2022 03:08:30 - INFO - __main__ - Step 560 Global step 560 Train loss 0.22 on epoch=4
05/28/2022 03:08:32 - INFO - __main__ - Step 570 Global step 570 Train loss 0.17 on epoch=5
05/28/2022 03:08:35 - INFO - __main__ - Step 580 Global step 580 Train loss 0.15 on epoch=5
05/28/2022 03:08:38 - INFO - __main__ - Step 590 Global step 590 Train loss 0.27 on epoch=5
05/28/2022 03:08:40 - INFO - __main__ - Step 600 Global step 600 Train loss 0.16 on epoch=5
05/28/2022 03:09:34 - INFO - __main__ - Global step 600 Train loss 0.19 Classification-F1 0.47468713354518594 on epoch=5
05/28/2022 03:09:37 - INFO - __main__ - Step 610 Global step 610 Train loss 0.21 on epoch=5
05/28/2022 03:09:40 - INFO - __main__ - Step 620 Global step 620 Train loss 0.20 on epoch=5
05/28/2022 03:09:42 - INFO - __main__ - Step 630 Global step 630 Train loss 0.16 on epoch=5
05/28/2022 03:09:45 - INFO - __main__ - Step 640 Global step 640 Train loss 0.19 on epoch=5
05/28/2022 03:09:48 - INFO - __main__ - Step 650 Global step 650 Train loss 0.20 on epoch=5
05/28/2022 03:10:41 - INFO - __main__ - Global step 650 Train loss 0.19 Classification-F1 0.5327557190436092 on epoch=5
05/28/2022 03:10:41 - INFO - __main__ - Saving model with best Classification-F1: 0.4801346286848389 -> 0.5327557190436092 on epoch=5, global_step=650
05/28/2022 03:10:43 - INFO - __main__ - Step 660 Global step 660 Train loss 0.19 on epoch=5
05/28/2022 03:10:46 - INFO - __main__ - Step 670 Global step 670 Train loss 0.16 on epoch=5
05/28/2022 03:10:49 - INFO - __main__ - Step 680 Global step 680 Train loss 0.13 on epoch=6
05/28/2022 03:10:51 - INFO - __main__ - Step 690 Global step 690 Train loss 0.15 on epoch=6
05/28/2022 03:10:54 - INFO - __main__ - Step 700 Global step 700 Train loss 0.21 on epoch=6
05/28/2022 03:11:45 - INFO - __main__ - Global step 700 Train loss 0.17 Classification-F1 0.4328125005257677 on epoch=6
05/28/2022 03:11:47 - INFO - __main__ - Step 710 Global step 710 Train loss 0.28 on epoch=6
05/28/2022 03:11:50 - INFO - __main__ - Step 720 Global step 720 Train loss 0.16 on epoch=6
05/28/2022 03:11:53 - INFO - __main__ - Step 730 Global step 730 Train loss 0.17 on epoch=6
05/28/2022 03:11:55 - INFO - __main__ - Step 740 Global step 740 Train loss 0.16 on epoch=6
05/28/2022 03:11:58 - INFO - __main__ - Step 750 Global step 750 Train loss 0.15 on epoch=6
05/28/2022 03:12:50 - INFO - __main__ - Global step 750 Train loss 0.18 Classification-F1 0.538458673324531 on epoch=6
05/28/2022 03:12:50 - INFO - __main__ - Saving model with best Classification-F1: 0.5327557190436092 -> 0.538458673324531 on epoch=6, global_step=750
05/28/2022 03:12:53 - INFO - __main__ - Step 760 Global step 760 Train loss 0.22 on epoch=6
05/28/2022 03:12:55 - INFO - __main__ - Step 770 Global step 770 Train loss 0.19 on epoch=6
05/28/2022 03:12:58 - INFO - __main__ - Step 780 Global step 780 Train loss 0.17 on epoch=6
05/28/2022 03:13:01 - INFO - __main__ - Step 790 Global step 790 Train loss 0.13 on epoch=7
05/28/2022 03:13:04 - INFO - __main__ - Step 800 Global step 800 Train loss 0.12 on epoch=7
05/28/2022 03:13:56 - INFO - __main__ - Global step 800 Train loss 0.17 Classification-F1 0.5218999165171956 on epoch=7
05/28/2022 03:13:59 - INFO - __main__ - Step 810 Global step 810 Train loss 0.18 on epoch=7
05/28/2022 03:14:02 - INFO - __main__ - Step 820 Global step 820 Train loss 0.26 on epoch=7
05/28/2022 03:14:04 - INFO - __main__ - Step 830 Global step 830 Train loss 0.15 on epoch=7
05/28/2022 03:14:07 - INFO - __main__ - Step 840 Global step 840 Train loss 0.13 on epoch=7
05/28/2022 03:14:10 - INFO - __main__ - Step 850 Global step 850 Train loss 0.13 on epoch=7
05/28/2022 03:15:00 - INFO - __main__ - Global step 850 Train loss 0.17 Classification-F1 0.4680817396483095 on epoch=7
05/28/2022 03:15:03 - INFO - __main__ - Step 860 Global step 860 Train loss 0.16 on epoch=7
05/28/2022 03:15:06 - INFO - __main__ - Step 870 Global step 870 Train loss 0.11 on epoch=7
05/28/2022 03:15:09 - INFO - __main__ - Step 880 Global step 880 Train loss 0.28 on epoch=7
05/28/2022 03:15:11 - INFO - __main__ - Step 890 Global step 890 Train loss 0.14 on epoch=7
05/28/2022 03:15:14 - INFO - __main__ - Step 900 Global step 900 Train loss 0.12 on epoch=8
05/28/2022 03:16:06 - INFO - __main__ - Global step 900 Train loss 0.16 Classification-F1 0.4899707703772043 on epoch=8
05/28/2022 03:16:08 - INFO - __main__ - Step 910 Global step 910 Train loss 0.09 on epoch=8
05/28/2022 03:16:11 - INFO - __main__ - Step 920 Global step 920 Train loss 0.13 on epoch=8
05/28/2022 03:16:14 - INFO - __main__ - Step 930 Global step 930 Train loss 0.20 on epoch=8
05/28/2022 03:16:16 - INFO - __main__ - Step 940 Global step 940 Train loss 0.19 on epoch=8
05/28/2022 03:16:19 - INFO - __main__ - Step 950 Global step 950 Train loss 0.14 on epoch=8
05/28/2022 03:17:10 - INFO - __main__ - Global step 950 Train loss 0.15 Classification-F1 0.5557430009616006 on epoch=8
05/28/2022 03:17:10 - INFO - __main__ - Saving model with best Classification-F1: 0.538458673324531 -> 0.5557430009616006 on epoch=8, global_step=950
05/28/2022 03:17:13 - INFO - __main__ - Step 960 Global step 960 Train loss 0.14 on epoch=8
05/28/2022 03:17:16 - INFO - __main__ - Step 970 Global step 970 Train loss 0.09 on epoch=8
05/28/2022 03:17:18 - INFO - __main__ - Step 980 Global step 980 Train loss 0.05 on epoch=8
05/28/2022 03:17:21 - INFO - __main__ - Step 990 Global step 990 Train loss 0.20 on epoch=8
05/28/2022 03:17:24 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.08 on epoch=8
05/28/2022 03:18:15 - INFO - __main__ - Global step 1000 Train loss 0.11 Classification-F1 0.5789371811006155 on epoch=8
05/28/2022 03:18:15 - INFO - __main__ - Saving model with best Classification-F1: 0.5557430009616006 -> 0.5789371811006155 on epoch=8, global_step=1000
05/28/2022 03:18:18 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.05 on epoch=9
05/28/2022 03:18:20 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.09 on epoch=9
05/28/2022 03:18:23 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.07 on epoch=9
05/28/2022 03:18:26 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.17 on epoch=9
05/28/2022 03:18:28 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.10 on epoch=9
05/28/2022 03:19:19 - INFO - __main__ - Global step 1050 Train loss 0.10 Classification-F1 0.5875188441023406 on epoch=9
05/28/2022 03:19:19 - INFO - __main__ - Saving model with best Classification-F1: 0.5789371811006155 -> 0.5875188441023406 on epoch=9, global_step=1050
05/28/2022 03:19:22 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.16 on epoch=9
05/28/2022 03:19:25 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.10 on epoch=9
05/28/2022 03:19:27 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.12 on epoch=9
05/28/2022 03:19:30 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.08 on epoch=9
05/28/2022 03:19:33 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.13 on epoch=9
05/28/2022 03:20:24 - INFO - __main__ - Global step 1100 Train loss 0.12 Classification-F1 0.5572522330532338 on epoch=9
05/28/2022 03:20:27 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.10 on epoch=9
05/28/2022 03:20:29 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.08 on epoch=9
05/28/2022 03:20:32 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.10 on epoch=10
05/28/2022 03:20:35 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.08 on epoch=10
05/28/2022 03:20:37 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.12 on epoch=10
05/28/2022 03:21:29 - INFO - __main__ - Global step 1150 Train loss 0.10 Classification-F1 0.5845074644392018 on epoch=10
05/28/2022 03:21:31 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.08 on epoch=10
05/28/2022 03:21:34 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.14 on epoch=10
05/28/2022 03:21:37 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.09 on epoch=10
05/28/2022 03:21:39 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.12 on epoch=10
05/28/2022 03:21:42 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.07 on epoch=10
05/28/2022 03:22:33 - INFO - __main__ - Global step 1200 Train loss 0.10 Classification-F1 0.5837471106671462 on epoch=10
05/28/2022 03:22:36 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.17 on epoch=10
05/28/2022 03:22:38 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.10 on epoch=10
05/28/2022 03:22:41 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.14 on epoch=10
05/28/2022 03:22:44 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.08 on epoch=11
05/28/2022 03:22:46 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.06 on epoch=11
05/28/2022 03:23:36 - INFO - __main__ - Global step 1250 Train loss 0.11 Classification-F1 0.5646353291572451 on epoch=11
05/28/2022 03:23:39 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.16 on epoch=11
05/28/2022 03:23:41 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.07 on epoch=11
05/28/2022 03:23:44 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.11 on epoch=11
05/28/2022 03:23:46 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.12 on epoch=11
05/28/2022 03:23:49 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.07 on epoch=11
05/28/2022 03:24:40 - INFO - __main__ - Global step 1300 Train loss 0.11 Classification-F1 0.5956650015264731 on epoch=11
05/28/2022 03:24:40 - INFO - __main__ - Saving model with best Classification-F1: 0.5875188441023406 -> 0.5956650015264731 on epoch=11, global_step=1300
05/28/2022 03:24:43 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.12 on epoch=11
05/28/2022 03:24:46 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.11 on epoch=11
05/28/2022 03:24:49 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.14 on epoch=11
05/28/2022 03:24:51 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.10 on epoch=11
05/28/2022 03:24:54 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.04 on epoch=12
05/28/2022 03:25:45 - INFO - __main__ - Global step 1350 Train loss 0.10 Classification-F1 0.5505589011156893 on epoch=12
05/28/2022 03:25:47 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.06 on epoch=12
05/28/2022 03:25:50 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.10 on epoch=12
05/28/2022 03:25:53 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.12 on epoch=12
05/28/2022 03:25:55 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.06 on epoch=12
05/28/2022 03:25:58 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.10 on epoch=12
05/28/2022 03:26:49 - INFO - __main__ - Global step 1400 Train loss 0.09 Classification-F1 0.5286421299179604 on epoch=12
05/28/2022 03:26:52 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.06 on epoch=12
05/28/2022 03:26:54 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.06 on epoch=12
05/28/2022 03:26:57 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.06 on epoch=12
05/28/2022 03:27:00 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.18 on epoch=12
05/28/2022 03:27:03 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.08 on epoch=12
05/28/2022 03:27:52 - INFO - __main__ - Global step 1450 Train loss 0.09 Classification-F1 0.5484104877580956 on epoch=12
05/28/2022 03:27:54 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.07 on epoch=13
05/28/2022 03:27:57 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.05 on epoch=13
05/28/2022 03:28:00 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.05 on epoch=13
05/28/2022 03:28:02 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.13 on epoch=13
05/28/2022 03:28:05 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.09 on epoch=13
05/28/2022 03:28:55 - INFO - __main__ - Global step 1500 Train loss 0.08 Classification-F1 0.6658751049845384 on epoch=13
05/28/2022 03:28:55 - INFO - __main__ - Saving model with best Classification-F1: 0.5956650015264731 -> 0.6658751049845384 on epoch=13, global_step=1500
05/28/2022 03:28:57 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.10 on epoch=13
05/28/2022 03:29:00 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.07 on epoch=13
05/28/2022 03:29:03 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.05 on epoch=13
05/28/2022 03:29:05 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=13
05/28/2022 03:29:08 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.12 on epoch=13
05/28/2022 03:29:57 - INFO - __main__ - Global step 1550 Train loss 0.07 Classification-F1 0.5977685029157359 on epoch=13
05/28/2022 03:30:00 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.08 on epoch=13
05/28/2022 03:30:02 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.05 on epoch=14
05/28/2022 03:30:05 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.09 on epoch=14
05/28/2022 03:30:08 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.03 on epoch=14
05/28/2022 03:30:10 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.17 on epoch=14
05/28/2022 03:31:00 - INFO - __main__ - Global step 1600 Train loss 0.08 Classification-F1 0.5703194650206279 on epoch=14
05/28/2022 03:31:02 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.06 on epoch=14
05/28/2022 03:31:05 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.09 on epoch=14
05/28/2022 03:31:08 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.07 on epoch=14
05/28/2022 03:31:10 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.09 on epoch=14
05/28/2022 03:31:13 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.04 on epoch=14
05/28/2022 03:32:03 - INFO - __main__ - Global step 1650 Train loss 0.07 Classification-F1 0.6262361203801364 on epoch=14
05/28/2022 03:32:06 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.15 on epoch=14
05/28/2022 03:32:08 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.08 on epoch=14
05/28/2022 03:32:11 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.12 on epoch=14
05/28/2022 03:32:14 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.06 on epoch=15
05/28/2022 03:32:16 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=15
05/28/2022 03:33:05 - INFO - __main__ - Global step 1700 Train loss 0.09 Classification-F1 0.6632530174380373 on epoch=15
05/28/2022 03:33:08 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.12 on epoch=15
05/28/2022 03:33:11 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.05 on epoch=15
05/28/2022 03:33:13 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.08 on epoch=15
05/28/2022 03:33:16 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.07 on epoch=15
05/28/2022 03:33:19 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.04 on epoch=15
05/28/2022 03:34:08 - INFO - __main__ - Global step 1750 Train loss 0.07 Classification-F1 0.633304105889005 on epoch=15
05/28/2022 03:34:10 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.08 on epoch=15
05/28/2022 03:34:13 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.09 on epoch=15
05/28/2022 03:34:16 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.05 on epoch=15
05/28/2022 03:34:18 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.09 on epoch=15
05/28/2022 03:34:21 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=16
05/28/2022 03:35:10 - INFO - __main__ - Global step 1800 Train loss 0.07 Classification-F1 0.6520637074629614 on epoch=16
05/28/2022 03:35:13 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.07 on epoch=16
05/28/2022 03:35:16 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.11 on epoch=16
05/28/2022 03:35:18 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.07 on epoch=16
05/28/2022 03:35:21 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.07 on epoch=16
05/28/2022 03:35:24 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.07 on epoch=16
05/28/2022 03:36:13 - INFO - __main__ - Global step 1850 Train loss 0.08 Classification-F1 0.5667692634759129 on epoch=16
05/28/2022 03:36:15 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.04 on epoch=16
05/28/2022 03:36:18 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.04 on epoch=16
05/28/2022 03:36:21 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.07 on epoch=16
05/28/2022 03:36:23 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.06 on epoch=16
05/28/2022 03:36:26 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.07 on epoch=16
05/28/2022 03:37:14 - INFO - __main__ - Global step 1900 Train loss 0.06 Classification-F1 0.6033520288620193 on epoch=16
05/28/2022 03:37:16 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.06 on epoch=17
05/28/2022 03:37:19 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.04 on epoch=17
05/28/2022 03:37:22 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.11 on epoch=17
05/28/2022 03:37:24 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.08 on epoch=17
05/28/2022 03:37:27 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=17
05/28/2022 03:38:15 - INFO - __main__ - Global step 1950 Train loss 0.06 Classification-F1 0.540733392515742 on epoch=17
05/28/2022 03:38:18 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.06 on epoch=17
05/28/2022 03:38:21 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.06 on epoch=17
05/28/2022 03:38:23 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.07 on epoch=17
05/28/2022 03:38:26 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=17
05/28/2022 03:38:29 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.19 on epoch=17
05/28/2022 03:39:17 - INFO - __main__ - Global step 2000 Train loss 0.08 Classification-F1 0.6747013441323838 on epoch=17
05/28/2022 03:39:17 - INFO - __main__ - Saving model with best Classification-F1: 0.6658751049845384 -> 0.6747013441323838 on epoch=17, global_step=2000
05/28/2022 03:39:20 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.03 on epoch=17
05/28/2022 03:39:23 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.05 on epoch=18
05/28/2022 03:39:26 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.03 on epoch=18
05/28/2022 03:39:28 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.03 on epoch=18
05/28/2022 03:39:31 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.13 on epoch=18
05/28/2022 03:40:21 - INFO - __main__ - Global step 2050 Train loss 0.05 Classification-F1 0.5630146396830014 on epoch=18
05/28/2022 03:40:23 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.03 on epoch=18
05/28/2022 03:40:26 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.10 on epoch=18
05/28/2022 03:40:29 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.04 on epoch=18
05/28/2022 03:40:31 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.08 on epoch=18
05/28/2022 03:40:34 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=18
05/28/2022 03:41:23 - INFO - __main__ - Global step 2100 Train loss 0.06 Classification-F1 0.6592719316563862 on epoch=18
05/28/2022 03:41:26 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.13 on epoch=18
05/28/2022 03:41:28 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.07 on epoch=18
05/28/2022 03:41:31 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.05 on epoch=19
05/28/2022 03:41:34 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=19
05/28/2022 03:41:36 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.03 on epoch=19
05/28/2022 03:42:27 - INFO - __main__ - Global step 2150 Train loss 0.06 Classification-F1 0.6751120501678617 on epoch=19
05/28/2022 03:42:27 - INFO - __main__ - Saving model with best Classification-F1: 0.6747013441323838 -> 0.6751120501678617 on epoch=19, global_step=2150
05/28/2022 03:42:30 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.13 on epoch=19
05/28/2022 03:42:32 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=19
05/28/2022 03:42:35 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.07 on epoch=19
05/28/2022 03:42:38 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.07 on epoch=19
05/28/2022 03:42:40 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.03 on epoch=19
05/28/2022 03:43:30 - INFO - __main__ - Global step 2200 Train loss 0.06 Classification-F1 0.5741885007855437 on epoch=19
05/28/2022 03:43:33 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=19
05/28/2022 03:43:35 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.09 on epoch=19
05/28/2022 03:43:38 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.11 on epoch=19
05/28/2022 03:43:41 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=19
05/28/2022 03:43:44 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.04 on epoch=20
05/28/2022 03:44:33 - INFO - __main__ - Global step 2250 Train loss 0.06 Classification-F1 0.6348702488342554 on epoch=20
05/28/2022 03:44:36 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.03 on epoch=20
05/28/2022 03:44:39 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.08 on epoch=20
05/28/2022 03:44:41 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=20
05/28/2022 03:44:44 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.12 on epoch=20
05/28/2022 03:44:46 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.06 on epoch=20
05/28/2022 03:45:38 - INFO - __main__ - Global step 2300 Train loss 0.06 Classification-F1 0.5873003451868829 on epoch=20
05/28/2022 03:45:40 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=20
05/28/2022 03:45:43 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.05 on epoch=20
05/28/2022 03:45:46 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.13 on epoch=20
05/28/2022 03:45:48 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.11 on epoch=20
05/28/2022 03:45:51 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.06 on epoch=20
05/28/2022 03:46:41 - INFO - __main__ - Global step 2350 Train loss 0.08 Classification-F1 0.6429902261332563 on epoch=20
05/28/2022 03:46:43 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=21
05/28/2022 03:46:46 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.04 on epoch=21
05/28/2022 03:46:49 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.15 on epoch=21
05/28/2022 03:46:51 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.05 on epoch=21
05/28/2022 03:46:54 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.08 on epoch=21
05/28/2022 03:47:43 - INFO - __main__ - Global step 2400 Train loss 0.07 Classification-F1 0.6138340534415684 on epoch=21
05/28/2022 03:47:46 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.09 on epoch=21
05/28/2022 03:47:49 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.03 on epoch=21
05/28/2022 03:47:51 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.04 on epoch=21
05/28/2022 03:47:54 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.13 on epoch=21
05/28/2022 03:47:57 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.07 on epoch=21
05/28/2022 03:48:46 - INFO - __main__ - Global step 2450 Train loss 0.07 Classification-F1 0.71315757231093 on epoch=21
05/28/2022 03:48:46 - INFO - __main__ - Saving model with best Classification-F1: 0.6751120501678617 -> 0.71315757231093 on epoch=21, global_step=2450
05/28/2022 03:48:49 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=21
05/28/2022 03:48:51 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.04 on epoch=22
05/28/2022 03:48:54 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.04 on epoch=22
05/28/2022 03:48:57 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.10 on epoch=22
05/28/2022 03:48:59 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.07 on epoch=22
05/28/2022 03:49:49 - INFO - __main__ - Global step 2500 Train loss 0.06 Classification-F1 0.6716725485018754 on epoch=22
05/28/2022 03:49:51 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=22
05/28/2022 03:49:54 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.06 on epoch=22
05/28/2022 03:49:57 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.03 on epoch=22
05/28/2022 03:49:59 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.05 on epoch=22
05/28/2022 03:50:02 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=22
05/28/2022 03:50:50 - INFO - __main__ - Global step 2550 Train loss 0.04 Classification-F1 0.6640854734863142 on epoch=22
05/28/2022 03:50:53 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.14 on epoch=22
05/28/2022 03:50:55 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.05 on epoch=22
05/28/2022 03:50:58 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.04 on epoch=23
05/28/2022 03:51:01 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=23
05/28/2022 03:51:03 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.05 on epoch=23
05/28/2022 03:51:53 - INFO - __main__ - Global step 2600 Train loss 0.06 Classification-F1 0.6798722062610054 on epoch=23
05/28/2022 03:51:56 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.07 on epoch=23
05/28/2022 03:51:58 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.03 on epoch=23
05/28/2022 03:52:01 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.05 on epoch=23
05/28/2022 03:52:03 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.06 on epoch=23
05/28/2022 03:52:06 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.04 on epoch=23
05/28/2022 03:52:55 - INFO - __main__ - Global step 2650 Train loss 0.05 Classification-F1 0.6854851091621879 on epoch=23
05/28/2022 03:52:57 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=23
05/28/2022 03:53:00 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.12 on epoch=23
05/28/2022 03:53:03 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.06 on epoch=23
05/28/2022 03:53:05 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=24
05/28/2022 03:53:08 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=24
05/28/2022 03:53:57 - INFO - __main__ - Global step 2700 Train loss 0.05 Classification-F1 0.6484161310429334 on epoch=24
05/28/2022 03:54:00 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=24
05/28/2022 03:54:02 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.18 on epoch=24
05/28/2022 03:54:05 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.03 on epoch=24
05/28/2022 03:54:08 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.04 on epoch=24
05/28/2022 03:54:10 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.03 on epoch=24
05/28/2022 03:54:59 - INFO - __main__ - Global step 2750 Train loss 0.06 Classification-F1 0.684960835358195 on epoch=24
05/28/2022 03:55:01 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.06 on epoch=24
05/28/2022 03:55:04 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.04 on epoch=24
05/28/2022 03:55:07 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.14 on epoch=24
05/28/2022 03:55:10 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.04 on epoch=24
05/28/2022 03:55:12 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.03 on epoch=24
05/28/2022 03:56:01 - INFO - __main__ - Global step 2800 Train loss 0.06 Classification-F1 0.6469621026037577 on epoch=24
05/28/2022 03:56:04 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.04 on epoch=25
05/28/2022 03:56:06 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.03 on epoch=25
05/28/2022 03:56:09 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.08 on epoch=25
05/28/2022 03:56:12 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=25
05/28/2022 03:56:14 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.06 on epoch=25
05/28/2022 03:57:04 - INFO - __main__ - Global step 2850 Train loss 0.05 Classification-F1 0.6656806709051605 on epoch=25
05/28/2022 03:57:06 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.04 on epoch=25
05/28/2022 03:57:09 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.03 on epoch=25
05/28/2022 03:57:12 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.05 on epoch=25
05/28/2022 03:57:14 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.08 on epoch=25
05/28/2022 03:57:17 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.13 on epoch=25
05/28/2022 03:58:06 - INFO - __main__ - Global step 2900 Train loss 0.06 Classification-F1 0.7107776315519011 on epoch=25
05/28/2022 03:58:08 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.05 on epoch=25
05/28/2022 03:58:11 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=26
05/28/2022 03:58:14 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.04 on epoch=26
05/28/2022 03:58:16 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.12 on epoch=26
05/28/2022 03:58:19 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.03 on epoch=26
05/28/2022 03:59:08 - INFO - __main__ - Global step 2950 Train loss 0.05 Classification-F1 0.6418467981897542 on epoch=26
05/28/2022 03:59:11 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.04 on epoch=26
05/28/2022 03:59:14 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.07 on epoch=26
05/28/2022 03:59:16 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.03 on epoch=26
05/28/2022 03:59:19 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.04 on epoch=26
05/28/2022 03:59:22 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.12 on epoch=26
05/28/2022 03:59:23 - INFO - __main__ - Start tokenizing ... 1792 instances
05/28/2022 03:59:23 - INFO - __main__ - Printing 3 examples
05/28/2022 03:59:23 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/28/2022 03:59:23 - INFO - __main__ - ['Animal']
05/28/2022 03:59:23 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/28/2022 03:59:23 - INFO - __main__ - ['Animal']
05/28/2022 03:59:23 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
05/28/2022 03:59:23 - INFO - __main__ - ['Animal']
05/28/2022 03:59:23 - INFO - __main__ - Tokenizing Input ...
05/28/2022 03:59:24 - INFO - __main__ - Tokenizing Output ...
05/28/2022 03:59:26 - INFO - __main__ - Loaded 1792 examples from train data
05/28/2022 03:59:26 - INFO - __main__ - Start tokenizing ... 1792 instances
05/28/2022 03:59:26 - INFO - __main__ - Printing 3 examples
05/28/2022 03:59:26 - INFO - __main__ -  [dbpedia_14] The Andaman Treepie (Dendrocitta bayleyi) is a species of bird in the Corvidae family.It is endemic to the Andaman Islands of India.Its natural habitat is subtropical or tropical moist lowland forests. It is threatened by habitat loss.The scientific name commemorates the Anglo-Indian statesman Edward Clive Bayley.
05/28/2022 03:59:26 - INFO - __main__ - ['Animal']
05/28/2022 03:59:26 - INFO - __main__ -  [dbpedia_14] Ethmia tyranthes is a moth in the Ethmiidae family. It is found in the Democratic Republic of Congo.
05/28/2022 03:59:26 - INFO - __main__ - ['Animal']
05/28/2022 03:59:26 - INFO - __main__ -  [dbpedia_14] Van Son’s Brown (Stygionympha vansoni) is a butterfly of the Nymphalidae family. It is found in South Africa in the northern Cape from the Kamiesberg to the Springbok area.The wingspan is 36–38 mm for males and 38–40 mm for females. Adults are on wing from August to October. There is one generation per year.The larvae probably feed on Poaceae grasses.
05/28/2022 03:59:26 - INFO - __main__ - ['Animal']
05/28/2022 03:59:26 - INFO - __main__ - Tokenizing Input ...
05/28/2022 03:59:27 - INFO - __main__ - Tokenizing Output ...
05/28/2022 03:59:29 - INFO - __main__ - Loaded 1792 examples from dev data
05/28/2022 03:59:44 - INFO - __main__ - load prompt embedding from ckpt
05/28/2022 03:59:44 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/28/2022 03:59:45 - INFO - __main__ - Starting training!
05/28/2022 04:00:10 - INFO - __main__ - Global step 3000 Train loss 0.06 Classification-F1 0.6328018293762225 on epoch=26
05/28/2022 04:00:10 - INFO - __main__ - save last model!
05/28/2022 04:00:10 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/28/2022 04:00:10 - INFO - __main__ - Start tokenizing ... 3500 instances
05/28/2022 04:00:10 - INFO - __main__ - Printing 3 examples
05/28/2022 04:00:10 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/28/2022 04:00:10 - INFO - __main__ - ['Animal']
05/28/2022 04:00:10 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/28/2022 04:00:10 - INFO - __main__ - ['Animal']
05/28/2022 04:00:10 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/28/2022 04:00:10 - INFO - __main__ - ['Village']
05/28/2022 04:00:10 - INFO - __main__ - Tokenizing Input ...
05/28/2022 04:00:12 - INFO - __main__ - Tokenizing Output ...
05/28/2022 04:00:16 - INFO - __main__ - Loaded 3500 examples from test data
05/28/2022 04:02:16 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down128shot/singletask-dbpedia_14/dbpedia_14_128_13_0.4_8_predictions.txt
05/28/2022 04:02:16 - INFO - __main__ - Classification-F1 on test data: 0.5766
05/28/2022 04:02:16 - INFO - __main__ - prefix=dbpedia_14_128_13, lr=0.4, bsz=8, dev_performance=0.71315757231093, test_performance=0.5766176345590014
05/28/2022 04:02:16 - INFO - __main__ - Running ... prefix=dbpedia_14_128_13, lr=0.3, bsz=8 ...
05/28/2022 04:02:17 - INFO - __main__ - Start tokenizing ... 1792 instances
05/28/2022 04:02:17 - INFO - __main__ - Printing 3 examples
05/28/2022 04:02:17 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/28/2022 04:02:17 - INFO - __main__ - ['Animal']
05/28/2022 04:02:17 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/28/2022 04:02:17 - INFO - __main__ - ['Animal']
05/28/2022 04:02:17 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
05/28/2022 04:02:17 - INFO - __main__ - ['Animal']
05/28/2022 04:02:17 - INFO - __main__ - Tokenizing Input ...
05/28/2022 04:02:18 - INFO - __main__ - Tokenizing Output ...
05/28/2022 04:02:20 - INFO - __main__ - Loaded 1792 examples from train data
05/28/2022 04:02:20 - INFO - __main__ - Start tokenizing ... 1792 instances
05/28/2022 04:02:20 - INFO - __main__ - Printing 3 examples
05/28/2022 04:02:20 - INFO - __main__ -  [dbpedia_14] The Andaman Treepie (Dendrocitta bayleyi) is a species of bird in the Corvidae family.It is endemic to the Andaman Islands of India.Its natural habitat is subtropical or tropical moist lowland forests. It is threatened by habitat loss.The scientific name commemorates the Anglo-Indian statesman Edward Clive Bayley.
05/28/2022 04:02:20 - INFO - __main__ - ['Animal']
05/28/2022 04:02:20 - INFO - __main__ -  [dbpedia_14] Ethmia tyranthes is a moth in the Ethmiidae family. It is found in the Democratic Republic of Congo.
05/28/2022 04:02:20 - INFO - __main__ - ['Animal']
05/28/2022 04:02:20 - INFO - __main__ -  [dbpedia_14] Van Son’s Brown (Stygionympha vansoni) is a butterfly of the Nymphalidae family. It is found in South Africa in the northern Cape from the Kamiesberg to the Springbok area.The wingspan is 36–38 mm for males and 38–40 mm for females. Adults are on wing from August to October. There is one generation per year.The larvae probably feed on Poaceae grasses.
05/28/2022 04:02:20 - INFO - __main__ - ['Animal']
05/28/2022 04:02:20 - INFO - __main__ - Tokenizing Input ...
05/28/2022 04:02:21 - INFO - __main__ - Tokenizing Output ...
05/28/2022 04:02:22 - INFO - __main__ - Loaded 1792 examples from dev data
05/28/2022 04:02:38 - INFO - __main__ - load prompt embedding from ckpt
05/28/2022 04:02:39 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/28/2022 04:02:39 - INFO - __main__ - Starting training!
05/28/2022 04:02:43 - INFO - __main__ - Step 10 Global step 10 Train loss 7.22 on epoch=0
05/28/2022 04:02:46 - INFO - __main__ - Step 20 Global step 20 Train loss 5.49 on epoch=0
05/28/2022 04:02:49 - INFO - __main__ - Step 30 Global step 30 Train loss 4.53 on epoch=0
05/28/2022 04:02:51 - INFO - __main__ - Step 40 Global step 40 Train loss 3.65 on epoch=0
05/28/2022 04:02:54 - INFO - __main__ - Step 50 Global step 50 Train loss 4.05 on epoch=0
05/28/2022 04:03:51 - INFO - __main__ - Global step 50 Train loss 4.99 Classification-F1 0.009059751962359796 on epoch=0
05/28/2022 04:03:51 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.009059751962359796 on epoch=0, global_step=50
05/28/2022 04:03:54 - INFO - __main__ - Step 60 Global step 60 Train loss 3.37 on epoch=0
05/28/2022 04:03:57 - INFO - __main__ - Step 70 Global step 70 Train loss 3.09 on epoch=0
05/28/2022 04:03:59 - INFO - __main__ - Step 80 Global step 80 Train loss 2.73 on epoch=0
05/28/2022 04:04:02 - INFO - __main__ - Step 90 Global step 90 Train loss 2.80 on epoch=0
05/28/2022 04:04:05 - INFO - __main__ - Step 100 Global step 100 Train loss 2.50 on epoch=0
05/28/2022 04:04:55 - INFO - __main__ - Global step 100 Train loss 2.90 Classification-F1 0.02223757720134203 on epoch=0
05/28/2022 04:04:55 - INFO - __main__ - Saving model with best Classification-F1: 0.009059751962359796 -> 0.02223757720134203 on epoch=0, global_step=100
05/28/2022 04:04:58 - INFO - __main__ - Step 110 Global step 110 Train loss 2.24 on epoch=0
05/28/2022 04:05:00 - INFO - __main__ - Step 120 Global step 120 Train loss 2.05 on epoch=1
05/28/2022 04:05:03 - INFO - __main__ - Step 130 Global step 130 Train loss 2.17 on epoch=1
05/28/2022 04:05:05 - INFO - __main__ - Step 140 Global step 140 Train loss 2.03 on epoch=1
05/28/2022 04:05:08 - INFO - __main__ - Step 150 Global step 150 Train loss 1.66 on epoch=1
05/28/2022 04:05:54 - INFO - __main__ - Global step 150 Train loss 2.03 Classification-F1 0.04093515569902046 on epoch=1
05/28/2022 04:05:54 - INFO - __main__ - Saving model with best Classification-F1: 0.02223757720134203 -> 0.04093515569902046 on epoch=1, global_step=150
05/28/2022 04:05:56 - INFO - __main__ - Step 160 Global step 160 Train loss 1.76 on epoch=1
05/28/2022 04:05:59 - INFO - __main__ - Step 170 Global step 170 Train loss 1.73 on epoch=1
05/28/2022 04:06:02 - INFO - __main__ - Step 180 Global step 180 Train loss 1.88 on epoch=1
05/28/2022 04:06:04 - INFO - __main__ - Step 190 Global step 190 Train loss 1.38 on epoch=1
05/28/2022 04:06:07 - INFO - __main__ - Step 200 Global step 200 Train loss 1.59 on epoch=1
05/28/2022 04:06:52 - INFO - __main__ - Global step 200 Train loss 1.67 Classification-F1 0.08010315603187163 on epoch=1
05/28/2022 04:06:52 - INFO - __main__ - Saving model with best Classification-F1: 0.04093515569902046 -> 0.08010315603187163 on epoch=1, global_step=200
05/28/2022 04:06:55 - INFO - __main__ - Step 210 Global step 210 Train loss 1.50 on epoch=1
05/28/2022 04:06:58 - INFO - __main__ - Step 220 Global step 220 Train loss 1.17 on epoch=1
05/28/2022 04:07:00 - INFO - __main__ - Step 230 Global step 230 Train loss 1.28 on epoch=2
05/28/2022 04:07:03 - INFO - __main__ - Step 240 Global step 240 Train loss 1.21 on epoch=2
05/28/2022 04:07:05 - INFO - __main__ - Step 250 Global step 250 Train loss 1.25 on epoch=2
05/28/2022 04:07:49 - INFO - __main__ - Global step 250 Train loss 1.28 Classification-F1 0.11825340557047313 on epoch=2
05/28/2022 04:07:49 - INFO - __main__ - Saving model with best Classification-F1: 0.08010315603187163 -> 0.11825340557047313 on epoch=2, global_step=250
05/28/2022 04:07:52 - INFO - __main__ - Step 260 Global step 260 Train loss 0.97 on epoch=2
05/28/2022 04:07:54 - INFO - __main__ - Step 270 Global step 270 Train loss 0.80 on epoch=2
05/28/2022 04:07:57 - INFO - __main__ - Step 280 Global step 280 Train loss 1.01 on epoch=2
05/28/2022 04:07:59 - INFO - __main__ - Step 290 Global step 290 Train loss 0.90 on epoch=2
05/28/2022 04:08:02 - INFO - __main__ - Step 300 Global step 300 Train loss 0.75 on epoch=2
05/28/2022 04:08:50 - INFO - __main__ - Global step 300 Train loss 0.89 Classification-F1 0.17852432694245704 on epoch=2
05/28/2022 04:08:50 - INFO - __main__ - Saving model with best Classification-F1: 0.11825340557047313 -> 0.17852432694245704 on epoch=2, global_step=300
05/28/2022 04:08:52 - INFO - __main__ - Step 310 Global step 310 Train loss 0.71 on epoch=2
05/28/2022 04:08:55 - INFO - __main__ - Step 320 Global step 320 Train loss 0.81 on epoch=2
05/28/2022 04:08:58 - INFO - __main__ - Step 330 Global step 330 Train loss 0.67 on epoch=2
05/28/2022 04:09:00 - INFO - __main__ - Step 340 Global step 340 Train loss 0.63 on epoch=3
05/28/2022 04:09:03 - INFO - __main__ - Step 350 Global step 350 Train loss 0.58 on epoch=3
05/28/2022 04:09:54 - INFO - __main__ - Global step 350 Train loss 0.68 Classification-F1 0.21712939442377693 on epoch=3
05/28/2022 04:09:54 - INFO - __main__ - Saving model with best Classification-F1: 0.17852432694245704 -> 0.21712939442377693 on epoch=3, global_step=350
05/28/2022 04:09:56 - INFO - __main__ - Step 360 Global step 360 Train loss 0.56 on epoch=3
05/28/2022 04:09:59 - INFO - __main__ - Step 370 Global step 370 Train loss 0.68 on epoch=3
05/28/2022 04:10:02 - INFO - __main__ - Step 380 Global step 380 Train loss 0.45 on epoch=3
05/28/2022 04:10:04 - INFO - __main__ - Step 390 Global step 390 Train loss 0.58 on epoch=3
05/28/2022 04:10:07 - INFO - __main__ - Step 400 Global step 400 Train loss 0.57 on epoch=3
05/28/2022 04:10:59 - INFO - __main__ - Global step 400 Train loss 0.57 Classification-F1 0.2555170549368336 on epoch=3
05/28/2022 04:10:59 - INFO - __main__ - Saving model with best Classification-F1: 0.21712939442377693 -> 0.2555170549368336 on epoch=3, global_step=400
05/28/2022 04:11:01 - INFO - __main__ - Step 410 Global step 410 Train loss 0.50 on epoch=3
05/28/2022 04:11:04 - INFO - __main__ - Step 420 Global step 420 Train loss 0.50 on epoch=3
05/28/2022 04:11:07 - INFO - __main__ - Step 430 Global step 430 Train loss 0.53 on epoch=3
05/28/2022 04:11:09 - INFO - __main__ - Step 440 Global step 440 Train loss 0.38 on epoch=3
05/28/2022 04:11:12 - INFO - __main__ - Step 450 Global step 450 Train loss 0.40 on epoch=4
05/28/2022 04:12:03 - INFO - __main__ - Global step 450 Train loss 0.46 Classification-F1 0.30922250655956657 on epoch=4
05/28/2022 04:12:03 - INFO - __main__ - Saving model with best Classification-F1: 0.2555170549368336 -> 0.30922250655956657 on epoch=4, global_step=450
05/28/2022 04:12:06 - INFO - __main__ - Step 460 Global step 460 Train loss 0.35 on epoch=4
05/28/2022 04:12:09 - INFO - __main__ - Step 470 Global step 470 Train loss 0.37 on epoch=4
05/28/2022 04:12:11 - INFO - __main__ - Step 480 Global step 480 Train loss 0.38 on epoch=4
05/28/2022 04:12:14 - INFO - __main__ - Step 490 Global step 490 Train loss 0.44 on epoch=4
05/28/2022 04:12:17 - INFO - __main__ - Step 500 Global step 500 Train loss 0.40 on epoch=4
05/28/2022 04:13:08 - INFO - __main__ - Global step 500 Train loss 0.39 Classification-F1 0.3600213018293293 on epoch=4
05/28/2022 04:13:08 - INFO - __main__ - Saving model with best Classification-F1: 0.30922250655956657 -> 0.3600213018293293 on epoch=4, global_step=500
05/28/2022 04:13:10 - INFO - __main__ - Step 510 Global step 510 Train loss 0.39 on epoch=4
05/28/2022 04:13:13 - INFO - __main__ - Step 520 Global step 520 Train loss 0.37 on epoch=4
05/28/2022 04:13:16 - INFO - __main__ - Step 530 Global step 530 Train loss 0.36 on epoch=4
05/28/2022 04:13:18 - INFO - __main__ - Step 540 Global step 540 Train loss 0.44 on epoch=4
05/28/2022 04:13:21 - INFO - __main__ - Step 550 Global step 550 Train loss 0.39 on epoch=4
05/28/2022 04:14:13 - INFO - __main__ - Global step 550 Train loss 0.39 Classification-F1 0.3905064557442006 on epoch=4
05/28/2022 04:14:13 - INFO - __main__ - Saving model with best Classification-F1: 0.3600213018293293 -> 0.3905064557442006 on epoch=4, global_step=550
05/28/2022 04:14:16 - INFO - __main__ - Step 560 Global step 560 Train loss 0.26 on epoch=4
05/28/2022 04:14:19 - INFO - __main__ - Step 570 Global step 570 Train loss 0.30 on epoch=5
05/28/2022 04:14:21 - INFO - __main__ - Step 580 Global step 580 Train loss 0.29 on epoch=5
05/28/2022 04:14:24 - INFO - __main__ - Step 590 Global step 590 Train loss 0.44 on epoch=5
05/28/2022 04:14:27 - INFO - __main__ - Step 600 Global step 600 Train loss 0.26 on epoch=5
05/28/2022 04:15:17 - INFO - __main__ - Global step 600 Train loss 0.31 Classification-F1 0.4351785964074174 on epoch=5
05/28/2022 04:15:17 - INFO - __main__ - Saving model with best Classification-F1: 0.3905064557442006 -> 0.4351785964074174 on epoch=5, global_step=600
05/28/2022 04:15:20 - INFO - __main__ - Step 610 Global step 610 Train loss 0.39 on epoch=5
05/28/2022 04:15:22 - INFO - __main__ - Step 620 Global step 620 Train loss 0.36 on epoch=5
05/28/2022 04:15:25 - INFO - __main__ - Step 630 Global step 630 Train loss 0.27 on epoch=5
05/28/2022 04:15:28 - INFO - __main__ - Step 640 Global step 640 Train loss 0.28 on epoch=5
05/28/2022 04:15:30 - INFO - __main__ - Step 650 Global step 650 Train loss 0.30 on epoch=5
05/28/2022 04:16:22 - INFO - __main__ - Global step 650 Train loss 0.32 Classification-F1 0.50563069929392 on epoch=5
05/28/2022 04:16:22 - INFO - __main__ - Saving model with best Classification-F1: 0.4351785964074174 -> 0.50563069929392 on epoch=5, global_step=650
05/28/2022 04:16:25 - INFO - __main__ - Step 660 Global step 660 Train loss 0.27 on epoch=5
05/28/2022 04:16:27 - INFO - __main__ - Step 670 Global step 670 Train loss 0.21 on epoch=5
05/28/2022 04:16:30 - INFO - __main__ - Step 680 Global step 680 Train loss 0.23 on epoch=6
05/28/2022 04:16:33 - INFO - __main__ - Step 690 Global step 690 Train loss 0.22 on epoch=6
05/28/2022 04:16:35 - INFO - __main__ - Step 700 Global step 700 Train loss 0.37 on epoch=6
05/28/2022 04:17:27 - INFO - __main__ - Global step 700 Train loss 0.26 Classification-F1 0.4685019663609285 on epoch=6
05/28/2022 04:17:29 - INFO - __main__ - Step 710 Global step 710 Train loss 0.33 on epoch=6
05/28/2022 04:17:32 - INFO - __main__ - Step 720 Global step 720 Train loss 0.25 on epoch=6
05/28/2022 04:17:35 - INFO - __main__ - Step 730 Global step 730 Train loss 0.28 on epoch=6
05/28/2022 04:17:37 - INFO - __main__ - Step 740 Global step 740 Train loss 0.23 on epoch=6
05/28/2022 04:17:40 - INFO - __main__ - Step 750 Global step 750 Train loss 0.15 on epoch=6
05/28/2022 04:18:31 - INFO - __main__ - Global step 750 Train loss 0.25 Classification-F1 0.4949899936821302 on epoch=6
05/28/2022 04:18:34 - INFO - __main__ - Step 760 Global step 760 Train loss 0.30 on epoch=6
05/28/2022 04:18:36 - INFO - __main__ - Step 770 Global step 770 Train loss 0.18 on epoch=6
05/28/2022 04:18:39 - INFO - __main__ - Step 780 Global step 780 Train loss 0.19 on epoch=6
05/28/2022 04:18:42 - INFO - __main__ - Step 790 Global step 790 Train loss 0.15 on epoch=7
05/28/2022 04:18:44 - INFO - __main__ - Step 800 Global step 800 Train loss 0.18 on epoch=7
05/28/2022 04:19:37 - INFO - __main__ - Global step 800 Train loss 0.20 Classification-F1 0.5257182600052407 on epoch=7
05/28/2022 04:19:37 - INFO - __main__ - Saving model with best Classification-F1: 0.50563069929392 -> 0.5257182600052407 on epoch=7, global_step=800
05/28/2022 04:19:40 - INFO - __main__ - Step 810 Global step 810 Train loss 0.25 on epoch=7
05/28/2022 04:19:42 - INFO - __main__ - Step 820 Global step 820 Train loss 0.27 on epoch=7
05/28/2022 04:19:45 - INFO - __main__ - Step 830 Global step 830 Train loss 0.16 on epoch=7
05/28/2022 04:19:48 - INFO - __main__ - Step 840 Global step 840 Train loss 0.23 on epoch=7
05/28/2022 04:19:50 - INFO - __main__ - Step 850 Global step 850 Train loss 0.16 on epoch=7
05/28/2022 04:20:40 - INFO - __main__ - Global step 850 Train loss 0.22 Classification-F1 0.48356253176606134 on epoch=7
05/28/2022 04:20:43 - INFO - __main__ - Step 860 Global step 860 Train loss 0.18 on epoch=7
05/28/2022 04:20:46 - INFO - __main__ - Step 870 Global step 870 Train loss 0.22 on epoch=7
05/28/2022 04:20:48 - INFO - __main__ - Step 880 Global step 880 Train loss 0.35 on epoch=7
05/28/2022 04:20:51 - INFO - __main__ - Step 890 Global step 890 Train loss 0.20 on epoch=7
05/28/2022 04:20:54 - INFO - __main__ - Step 900 Global step 900 Train loss 0.19 on epoch=8
05/28/2022 04:21:43 - INFO - __main__ - Global step 900 Train loss 0.23 Classification-F1 0.48190783784357194 on epoch=8
05/28/2022 04:21:46 - INFO - __main__ - Step 910 Global step 910 Train loss 0.15 on epoch=8
05/28/2022 04:21:48 - INFO - __main__ - Step 920 Global step 920 Train loss 0.12 on epoch=8
05/28/2022 04:21:51 - INFO - __main__ - Step 930 Global step 930 Train loss 0.25 on epoch=8
05/28/2022 04:21:54 - INFO - __main__ - Step 940 Global step 940 Train loss 0.15 on epoch=8
05/28/2022 04:21:56 - INFO - __main__ - Step 950 Global step 950 Train loss 0.18 on epoch=8
05/28/2022 04:22:46 - INFO - __main__ - Global step 950 Train loss 0.17 Classification-F1 0.5218677819999461 on epoch=8
05/28/2022 04:22:49 - INFO - __main__ - Step 960 Global step 960 Train loss 0.12 on epoch=8
05/28/2022 04:22:51 - INFO - __main__ - Step 970 Global step 970 Train loss 0.26 on epoch=8
05/28/2022 04:22:54 - INFO - __main__ - Step 980 Global step 980 Train loss 0.13 on epoch=8
05/28/2022 04:22:57 - INFO - __main__ - Step 990 Global step 990 Train loss 0.25 on epoch=8
05/28/2022 04:22:59 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.18 on epoch=8
05/28/2022 04:23:49 - INFO - __main__ - Global step 1000 Train loss 0.19 Classification-F1 0.508019559522998 on epoch=8
05/28/2022 04:23:52 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.10 on epoch=9
05/28/2022 04:23:55 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.13 on epoch=9
05/28/2022 04:23:57 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.15 on epoch=9
05/28/2022 04:24:00 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.21 on epoch=9
05/28/2022 04:24:02 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.11 on epoch=9
05/28/2022 04:24:53 - INFO - __main__ - Global step 1050 Train loss 0.14 Classification-F1 0.5837979966358051 on epoch=9
05/28/2022 04:24:53 - INFO - __main__ - Saving model with best Classification-F1: 0.5257182600052407 -> 0.5837979966358051 on epoch=9, global_step=1050
05/28/2022 04:24:55 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.17 on epoch=9
05/28/2022 04:24:58 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.18 on epoch=9
05/28/2022 04:25:01 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.14 on epoch=9
05/28/2022 04:25:03 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.15 on epoch=9
05/28/2022 04:25:06 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.18 on epoch=9
05/28/2022 04:25:55 - INFO - __main__ - Global step 1100 Train loss 0.17 Classification-F1 0.48474992316250476 on epoch=9
05/28/2022 04:25:58 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.22 on epoch=9
05/28/2022 04:26:00 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.15 on epoch=9
05/28/2022 04:26:03 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.16 on epoch=10
05/28/2022 04:26:06 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.09 on epoch=10
05/28/2022 04:26:08 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.23 on epoch=10
05/28/2022 04:26:57 - INFO - __main__ - Global step 1150 Train loss 0.17 Classification-F1 0.5052822479323428 on epoch=10
05/28/2022 04:26:59 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.12 on epoch=10
05/28/2022 04:27:02 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.18 on epoch=10
05/28/2022 04:27:04 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.18 on epoch=10
05/28/2022 04:27:07 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.12 on epoch=10
05/28/2022 04:27:10 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.13 on epoch=10
05/28/2022 04:28:00 - INFO - __main__ - Global step 1200 Train loss 0.15 Classification-F1 0.6008395453270647 on epoch=10
05/28/2022 04:28:01 - INFO - __main__ - Saving model with best Classification-F1: 0.5837979966358051 -> 0.6008395453270647 on epoch=10, global_step=1200
05/28/2022 04:28:03 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.18 on epoch=10
05/28/2022 04:28:06 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.14 on epoch=10
05/28/2022 04:28:09 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.12 on epoch=10
05/28/2022 04:28:11 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.10 on epoch=11
05/28/2022 04:28:14 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.12 on epoch=11
05/28/2022 04:29:05 - INFO - __main__ - Global step 1250 Train loss 0.13 Classification-F1 0.5506490097300493 on epoch=11
05/28/2022 04:29:07 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.15 on epoch=11
05/28/2022 04:29:10 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.15 on epoch=11
05/28/2022 04:29:13 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.16 on epoch=11
05/28/2022 04:29:15 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.09 on epoch=11
05/28/2022 04:29:18 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.11 on epoch=11
05/28/2022 04:30:07 - INFO - __main__ - Global step 1300 Train loss 0.13 Classification-F1 0.5269484120834875 on epoch=11
05/28/2022 04:30:10 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.10 on epoch=11
05/28/2022 04:30:12 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.11 on epoch=11
05/28/2022 04:30:15 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.17 on epoch=11
05/28/2022 04:30:18 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.13 on epoch=11
05/28/2022 04:30:20 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.09 on epoch=12
05/28/2022 04:31:09 - INFO - __main__ - Global step 1350 Train loss 0.12 Classification-F1 0.5286367572303569 on epoch=12
05/28/2022 04:31:12 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.08 on epoch=12
05/28/2022 04:31:15 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.15 on epoch=12
05/28/2022 04:31:17 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.13 on epoch=12
05/28/2022 04:31:20 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.06 on epoch=12
05/28/2022 04:31:22 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.20 on epoch=12
05/28/2022 04:32:11 - INFO - __main__ - Global step 1400 Train loss 0.12 Classification-F1 0.5771795995515704 on epoch=12
05/28/2022 04:32:13 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.10 on epoch=12
05/28/2022 04:32:16 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.10 on epoch=12
05/28/2022 04:32:18 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.12 on epoch=12
05/28/2022 04:32:21 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.16 on epoch=12
05/28/2022 04:32:24 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.15 on epoch=12
05/28/2022 04:33:12 - INFO - __main__ - Global step 1450 Train loss 0.13 Classification-F1 0.5084759125150049 on epoch=12
05/28/2022 04:33:15 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.07 on epoch=13
05/28/2022 04:33:17 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.10 on epoch=13
05/28/2022 04:33:20 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.08 on epoch=13
05/28/2022 04:33:23 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.23 on epoch=13
05/28/2022 04:33:25 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.10 on epoch=13
05/28/2022 04:34:15 - INFO - __main__ - Global step 1500 Train loss 0.12 Classification-F1 0.6156644712295444 on epoch=13
05/28/2022 04:34:15 - INFO - __main__ - Saving model with best Classification-F1: 0.6008395453270647 -> 0.6156644712295444 on epoch=13, global_step=1500
05/28/2022 04:34:17 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.14 on epoch=13
05/28/2022 04:34:20 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.08 on epoch=13
05/28/2022 04:34:23 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.07 on epoch=13
05/28/2022 04:34:25 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.04 on epoch=13
05/28/2022 04:34:28 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.15 on epoch=13
05/28/2022 04:35:18 - INFO - __main__ - Global step 1550 Train loss 0.10 Classification-F1 0.6893674262280092 on epoch=13
05/28/2022 04:35:18 - INFO - __main__ - Saving model with best Classification-F1: 0.6156644712295444 -> 0.6893674262280092 on epoch=13, global_step=1550
05/28/2022 04:35:21 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.07 on epoch=13
05/28/2022 04:35:23 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.06 on epoch=14
05/28/2022 04:35:26 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.08 on epoch=14
05/28/2022 04:35:29 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.07 on epoch=14
05/28/2022 04:35:31 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.23 on epoch=14
05/28/2022 04:36:21 - INFO - __main__ - Global step 1600 Train loss 0.10 Classification-F1 0.6246659277165515 on epoch=14
05/28/2022 04:36:24 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.09 on epoch=14
05/28/2022 04:36:26 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.13 on epoch=14
05/28/2022 04:36:29 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.09 on epoch=14
05/28/2022 04:36:32 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.07 on epoch=14
05/28/2022 04:36:34 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.06 on epoch=14
05/28/2022 04:37:23 - INFO - __main__ - Global step 1650 Train loss 0.09 Classification-F1 0.5709376577533489 on epoch=14
05/28/2022 04:37:25 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.10 on epoch=14
05/28/2022 04:37:28 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.09 on epoch=14
05/28/2022 04:37:31 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.06 on epoch=14
05/28/2022 04:37:33 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.07 on epoch=15
05/28/2022 04:37:36 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=15
05/28/2022 04:38:25 - INFO - __main__ - Global step 1700 Train loss 0.07 Classification-F1 0.530650395444643 on epoch=15
05/28/2022 04:38:27 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.18 on epoch=15
05/28/2022 04:38:30 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.09 on epoch=15
05/28/2022 04:38:33 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.11 on epoch=15
05/28/2022 04:38:35 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.16 on epoch=15
05/28/2022 04:38:38 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.08 on epoch=15
05/28/2022 04:39:27 - INFO - __main__ - Global step 1750 Train loss 0.12 Classification-F1 0.5351076693688476 on epoch=15
05/28/2022 04:39:29 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.06 on epoch=15
05/28/2022 04:39:32 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.15 on epoch=15
05/28/2022 04:39:35 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.10 on epoch=15
05/28/2022 04:39:37 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.07 on epoch=15
05/28/2022 04:39:40 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.06 on epoch=16
05/28/2022 04:40:29 - INFO - __main__ - Global step 1800 Train loss 0.09 Classification-F1 0.6177201183725428 on epoch=16
05/28/2022 04:40:31 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.06 on epoch=16
05/28/2022 04:40:34 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.12 on epoch=16
05/28/2022 04:40:37 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.09 on epoch=16
05/28/2022 04:40:39 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.09 on epoch=16
05/28/2022 04:40:42 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.09 on epoch=16
05/28/2022 04:41:30 - INFO - __main__ - Global step 1850 Train loss 0.09 Classification-F1 0.6158781272470951 on epoch=16
05/28/2022 04:41:33 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.06 on epoch=16
05/28/2022 04:41:35 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.06 on epoch=16
05/28/2022 04:41:38 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.11 on epoch=16
05/28/2022 04:41:41 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.16 on epoch=16
05/28/2022 04:41:43 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.06 on epoch=16
05/28/2022 04:42:31 - INFO - __main__ - Global step 1900 Train loss 0.09 Classification-F1 0.6040818757675026 on epoch=16
05/28/2022 04:42:33 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.05 on epoch=17
05/28/2022 04:42:36 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.05 on epoch=17
05/28/2022 04:42:39 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.09 on epoch=17
05/28/2022 04:42:41 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.12 on epoch=17
05/28/2022 04:42:44 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.04 on epoch=17
05/28/2022 04:43:32 - INFO - __main__ - Global step 1950 Train loss 0.07 Classification-F1 0.5247254268650017 on epoch=17
05/28/2022 04:43:34 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.13 on epoch=17
05/28/2022 04:43:37 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.10 on epoch=17
05/28/2022 04:43:40 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.08 on epoch=17
05/28/2022 04:43:42 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.05 on epoch=17
05/28/2022 04:43:45 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.15 on epoch=17
05/28/2022 04:44:34 - INFO - __main__ - Global step 2000 Train loss 0.10 Classification-F1 0.589076650849076 on epoch=17
05/28/2022 04:44:36 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.08 on epoch=17
05/28/2022 04:44:39 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.05 on epoch=18
05/28/2022 04:44:42 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.02 on epoch=18
05/28/2022 04:44:44 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.07 on epoch=18
05/28/2022 04:44:47 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.16 on epoch=18
05/28/2022 04:45:34 - INFO - __main__ - Global step 2050 Train loss 0.08 Classification-F1 0.5119225961758725 on epoch=18
05/28/2022 04:45:37 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.04 on epoch=18
05/28/2022 04:45:40 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.10 on epoch=18
05/28/2022 04:45:42 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.08 on epoch=18
05/28/2022 04:45:45 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.08 on epoch=18
05/28/2022 04:45:47 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=18
05/28/2022 04:46:35 - INFO - __main__ - Global step 2100 Train loss 0.07 Classification-F1 0.5806936348012086 on epoch=18
05/28/2022 04:46:38 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.18 on epoch=18
05/28/2022 04:46:41 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.06 on epoch=18
05/28/2022 04:46:43 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.07 on epoch=19
05/28/2022 04:46:46 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=19
05/28/2022 04:46:49 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.06 on epoch=19
05/28/2022 04:47:37 - INFO - __main__ - Global step 2150 Train loss 0.08 Classification-F1 0.6173310627613023 on epoch=19
05/28/2022 04:47:39 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.20 on epoch=19
05/28/2022 04:47:42 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.07 on epoch=19
05/28/2022 04:47:44 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.11 on epoch=19
05/28/2022 04:47:47 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.06 on epoch=19
05/28/2022 04:47:50 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.05 on epoch=19
05/28/2022 04:48:38 - INFO - __main__ - Global step 2200 Train loss 0.10 Classification-F1 0.6896457115244472 on epoch=19
05/28/2022 04:48:38 - INFO - __main__ - Saving model with best Classification-F1: 0.6893674262280092 -> 0.6896457115244472 on epoch=19, global_step=2200
05/28/2022 04:48:41 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=19
05/28/2022 04:48:43 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.07 on epoch=19
05/28/2022 04:48:46 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.09 on epoch=19
05/28/2022 04:48:49 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.06 on epoch=19
05/28/2022 04:48:51 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.04 on epoch=20
05/28/2022 04:49:40 - INFO - __main__ - Global step 2250 Train loss 0.06 Classification-F1 0.6122588674416058 on epoch=20
05/28/2022 04:49:43 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.05 on epoch=20
05/28/2022 04:49:45 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.14 on epoch=20
05/28/2022 04:49:48 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.05 on epoch=20
05/28/2022 04:49:51 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.09 on epoch=20
05/28/2022 04:49:53 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.06 on epoch=20
05/28/2022 04:50:41 - INFO - __main__ - Global step 2300 Train loss 0.08 Classification-F1 0.6339099748878076 on epoch=20
05/28/2022 04:50:44 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.04 on epoch=20
05/28/2022 04:50:46 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.04 on epoch=20
05/28/2022 04:50:49 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.09 on epoch=20
05/28/2022 04:50:51 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.10 on epoch=20
05/28/2022 04:50:54 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.04 on epoch=20
05/28/2022 04:51:42 - INFO - __main__ - Global step 2350 Train loss 0.06 Classification-F1 0.6240441190536805 on epoch=20
05/28/2022 04:51:44 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=21
05/28/2022 04:51:47 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=21
05/28/2022 04:51:49 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.10 on epoch=21
05/28/2022 04:51:52 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.08 on epoch=21
05/28/2022 04:51:55 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.04 on epoch=21
05/28/2022 04:52:43 - INFO - __main__ - Global step 2400 Train loss 0.06 Classification-F1 0.6516866787765463 on epoch=21
05/28/2022 04:52:46 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.08 on epoch=21
05/28/2022 04:52:48 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.05 on epoch=21
05/28/2022 04:52:51 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.05 on epoch=21
05/28/2022 04:52:54 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.10 on epoch=21
05/28/2022 04:52:56 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.06 on epoch=21
05/28/2022 04:53:45 - INFO - __main__ - Global step 2450 Train loss 0.07 Classification-F1 0.6900102709931862 on epoch=21
05/28/2022 04:53:45 - INFO - __main__ - Saving model with best Classification-F1: 0.6896457115244472 -> 0.6900102709931862 on epoch=21, global_step=2450
05/28/2022 04:53:48 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.04 on epoch=21
05/28/2022 04:53:50 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=22
05/28/2022 04:53:53 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=22
05/28/2022 04:53:55 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.05 on epoch=22
05/28/2022 04:53:58 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.14 on epoch=22
05/28/2022 04:54:46 - INFO - __main__ - Global step 2500 Train loss 0.05 Classification-F1 0.6160791633009663 on epoch=22
05/28/2022 04:54:49 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.03 on epoch=22
05/28/2022 04:54:51 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.12 on epoch=22
05/28/2022 04:54:54 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.06 on epoch=22
05/28/2022 04:54:57 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.04 on epoch=22
05/28/2022 04:54:59 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=22
05/28/2022 04:55:48 - INFO - __main__ - Global step 2550 Train loss 0.06 Classification-F1 0.6554966206898523 on epoch=22
05/28/2022 04:55:51 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.11 on epoch=22
05/28/2022 04:55:54 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=22
05/28/2022 04:55:56 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.06 on epoch=23
05/28/2022 04:55:59 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=23
05/28/2022 04:56:01 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=23
05/28/2022 04:56:51 - INFO - __main__ - Global step 2600 Train loss 0.05 Classification-F1 0.6172207775021025 on epoch=23
05/28/2022 04:56:53 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.15 on epoch=23
05/28/2022 04:56:56 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.03 on epoch=23
05/28/2022 04:56:59 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.08 on epoch=23
05/28/2022 04:57:01 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=23
05/28/2022 04:57:04 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.04 on epoch=23
05/28/2022 04:57:52 - INFO - __main__ - Global step 2650 Train loss 0.07 Classification-F1 0.6484815562333 on epoch=23
05/28/2022 04:57:55 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=23
05/28/2022 04:57:58 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.14 on epoch=23
05/28/2022 04:58:00 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.08 on epoch=23
05/28/2022 04:58:03 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.03 on epoch=24
05/28/2022 04:58:06 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.04 on epoch=24
05/28/2022 04:58:54 - INFO - __main__ - Global step 2700 Train loss 0.06 Classification-F1 0.6183012820568452 on epoch=24
05/28/2022 04:58:56 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=24
05/28/2022 04:58:59 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.11 on epoch=24
05/28/2022 04:59:01 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.05 on epoch=24
05/28/2022 04:59:04 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.07 on epoch=24
05/28/2022 04:59:07 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.06 on epoch=24
05/28/2022 04:59:54 - INFO - __main__ - Global step 2750 Train loss 0.06 Classification-F1 0.588879426073894 on epoch=24
05/28/2022 04:59:57 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.06 on epoch=24
05/28/2022 04:59:59 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.03 on epoch=24
05/28/2022 05:00:02 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.12 on epoch=24
05/28/2022 05:00:05 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.10 on epoch=24
05/28/2022 05:00:07 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.05 on epoch=24
05/28/2022 05:00:56 - INFO - __main__ - Global step 2800 Train loss 0.07 Classification-F1 0.6240294006854666 on epoch=24
05/28/2022 05:00:59 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=25
05/28/2022 05:01:01 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.06 on epoch=25
05/28/2022 05:01:04 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.11 on epoch=25
05/28/2022 05:01:07 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.03 on epoch=25
05/28/2022 05:01:09 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.08 on epoch=25
05/28/2022 05:01:58 - INFO - __main__ - Global step 2850 Train loss 0.06 Classification-F1 0.6187619619758754 on epoch=25
05/28/2022 05:02:01 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.03 on epoch=25
05/28/2022 05:02:03 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.03 on epoch=25
05/28/2022 05:02:06 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.05 on epoch=25
05/28/2022 05:02:08 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.06 on epoch=25
05/28/2022 05:02:11 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.08 on epoch=25
05/28/2022 05:02:59 - INFO - __main__ - Global step 2900 Train loss 0.05 Classification-F1 0.6413211070729208 on epoch=25
05/28/2022 05:03:01 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=25
05/28/2022 05:03:04 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.05 on epoch=26
05/28/2022 05:03:06 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.04 on epoch=26
05/28/2022 05:03:09 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.17 on epoch=26
05/28/2022 05:03:12 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.09 on epoch=26
05/28/2022 05:04:00 - INFO - __main__ - Global step 2950 Train loss 0.07 Classification-F1 0.6558340599377269 on epoch=26
05/28/2022 05:04:02 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.04 on epoch=26
05/28/2022 05:04:05 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.05 on epoch=26
05/28/2022 05:04:08 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.03 on epoch=26
05/28/2022 05:04:10 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.05 on epoch=26
05/28/2022 05:04:13 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.09 on epoch=26
05/28/2022 05:04:15 - INFO - __main__ - Start tokenizing ... 1792 instances
05/28/2022 05:04:15 - INFO - __main__ - Printing 3 examples
05/28/2022 05:04:15 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/28/2022 05:04:15 - INFO - __main__ - ['Animal']
05/28/2022 05:04:15 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/28/2022 05:04:15 - INFO - __main__ - ['Animal']
05/28/2022 05:04:15 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
05/28/2022 05:04:15 - INFO - __main__ - ['Animal']
05/28/2022 05:04:15 - INFO - __main__ - Tokenizing Input ...
05/28/2022 05:04:15 - INFO - __main__ - Tokenizing Output ...
05/28/2022 05:04:17 - INFO - __main__ - Loaded 1792 examples from train data
05/28/2022 05:04:17 - INFO - __main__ - Start tokenizing ... 1792 instances
05/28/2022 05:04:17 - INFO - __main__ - Printing 3 examples
05/28/2022 05:04:17 - INFO - __main__ -  [dbpedia_14] The Andaman Treepie (Dendrocitta bayleyi) is a species of bird in the Corvidae family.It is endemic to the Andaman Islands of India.Its natural habitat is subtropical or tropical moist lowland forests. It is threatened by habitat loss.The scientific name commemorates the Anglo-Indian statesman Edward Clive Bayley.
05/28/2022 05:04:17 - INFO - __main__ - ['Animal']
05/28/2022 05:04:17 - INFO - __main__ -  [dbpedia_14] Ethmia tyranthes is a moth in the Ethmiidae family. It is found in the Democratic Republic of Congo.
05/28/2022 05:04:17 - INFO - __main__ - ['Animal']
05/28/2022 05:04:17 - INFO - __main__ -  [dbpedia_14] Van Son’s Brown (Stygionympha vansoni) is a butterfly of the Nymphalidae family. It is found in South Africa in the northern Cape from the Kamiesberg to the Springbok area.The wingspan is 36–38 mm for males and 38–40 mm for females. Adults are on wing from August to October. There is one generation per year.The larvae probably feed on Poaceae grasses.
05/28/2022 05:04:17 - INFO - __main__ - ['Animal']
05/28/2022 05:04:17 - INFO - __main__ - Tokenizing Input ...
05/28/2022 05:04:18 - INFO - __main__ - Tokenizing Output ...
05/28/2022 05:04:20 - INFO - __main__ - Loaded 1792 examples from dev data
05/28/2022 05:04:38 - INFO - __main__ - load prompt embedding from ckpt
05/28/2022 05:04:39 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/28/2022 05:04:39 - INFO - __main__ - Starting training!
05/28/2022 05:05:01 - INFO - __main__ - Global step 3000 Train loss 0.05 Classification-F1 0.6752146645807529 on epoch=26
05/28/2022 05:05:01 - INFO - __main__ - save last model!
05/28/2022 05:05:01 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/28/2022 05:05:01 - INFO - __main__ - Start tokenizing ... 3500 instances
05/28/2022 05:05:01 - INFO - __main__ - Printing 3 examples
05/28/2022 05:05:01 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/28/2022 05:05:01 - INFO - __main__ - ['Animal']
05/28/2022 05:05:01 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/28/2022 05:05:01 - INFO - __main__ - ['Animal']
05/28/2022 05:05:01 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/28/2022 05:05:01 - INFO - __main__ - ['Village']
05/28/2022 05:05:01 - INFO - __main__ - Tokenizing Input ...
05/28/2022 05:05:03 - INFO - __main__ - Tokenizing Output ...
05/28/2022 05:05:07 - INFO - __main__ - Loaded 3500 examples from test data
05/28/2022 05:07:10 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down128shot/singletask-dbpedia_14/dbpedia_14_128_13_0.3_8_predictions.txt
05/28/2022 05:07:10 - INFO - __main__ - Classification-F1 on test data: 0.6109
05/28/2022 05:07:10 - INFO - __main__ - prefix=dbpedia_14_128_13, lr=0.3, bsz=8, dev_performance=0.6900102709931862, test_performance=0.6108683704357489
05/28/2022 05:07:10 - INFO - __main__ - Running ... prefix=dbpedia_14_128_13, lr=0.2, bsz=8 ...
05/28/2022 05:07:11 - INFO - __main__ - Start tokenizing ... 1792 instances
05/28/2022 05:07:11 - INFO - __main__ - Printing 3 examples
05/28/2022 05:07:11 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/28/2022 05:07:11 - INFO - __main__ - ['Animal']
05/28/2022 05:07:11 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/28/2022 05:07:11 - INFO - __main__ - ['Animal']
05/28/2022 05:07:11 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
05/28/2022 05:07:11 - INFO - __main__ - ['Animal']
05/28/2022 05:07:11 - INFO - __main__ - Tokenizing Input ...
05/28/2022 05:07:12 - INFO - __main__ - Tokenizing Output ...
05/28/2022 05:07:14 - INFO - __main__ - Loaded 1792 examples from train data
05/28/2022 05:07:14 - INFO - __main__ - Start tokenizing ... 1792 instances
05/28/2022 05:07:14 - INFO - __main__ - Printing 3 examples
05/28/2022 05:07:14 - INFO - __main__ -  [dbpedia_14] The Andaman Treepie (Dendrocitta bayleyi) is a species of bird in the Corvidae family.It is endemic to the Andaman Islands of India.Its natural habitat is subtropical or tropical moist lowland forests. It is threatened by habitat loss.The scientific name commemorates the Anglo-Indian statesman Edward Clive Bayley.
05/28/2022 05:07:14 - INFO - __main__ - ['Animal']
05/28/2022 05:07:14 - INFO - __main__ -  [dbpedia_14] Ethmia tyranthes is a moth in the Ethmiidae family. It is found in the Democratic Republic of Congo.
05/28/2022 05:07:14 - INFO - __main__ - ['Animal']
05/28/2022 05:07:14 - INFO - __main__ -  [dbpedia_14] Van Son’s Brown (Stygionympha vansoni) is a butterfly of the Nymphalidae family. It is found in South Africa in the northern Cape from the Kamiesberg to the Springbok area.The wingspan is 36–38 mm for males and 38–40 mm for females. Adults are on wing from August to October. There is one generation per year.The larvae probably feed on Poaceae grasses.
05/28/2022 05:07:14 - INFO - __main__ - ['Animal']
05/28/2022 05:07:14 - INFO - __main__ - Tokenizing Input ...
05/28/2022 05:07:15 - INFO - __main__ - Tokenizing Output ...
05/28/2022 05:07:17 - INFO - __main__ - Loaded 1792 examples from dev data
05/28/2022 05:07:34 - INFO - __main__ - load prompt embedding from ckpt
05/28/2022 05:07:35 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/28/2022 05:07:35 - INFO - __main__ - Starting training!
05/28/2022 05:07:39 - INFO - __main__ - Step 10 Global step 10 Train loss 7.92 on epoch=0
05/28/2022 05:07:41 - INFO - __main__ - Step 20 Global step 20 Train loss 5.76 on epoch=0
05/28/2022 05:07:44 - INFO - __main__ - Step 30 Global step 30 Train loss 5.13 on epoch=0
05/28/2022 05:07:46 - INFO - __main__ - Step 40 Global step 40 Train loss 4.37 on epoch=0
05/28/2022 05:07:49 - INFO - __main__ - Step 50 Global step 50 Train loss 4.51 on epoch=0
05/28/2022 05:08:40 - INFO - __main__ - Global step 50 Train loss 5.54 Classification-F1 0.006670237319224082 on epoch=0
05/28/2022 05:08:40 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.006670237319224082 on epoch=0, global_step=50
05/28/2022 05:08:43 - INFO - __main__ - Step 60 Global step 60 Train loss 4.11 on epoch=0
05/28/2022 05:08:45 - INFO - __main__ - Step 70 Global step 70 Train loss 3.91 on epoch=0
05/28/2022 05:08:48 - INFO - __main__ - Step 80 Global step 80 Train loss 3.59 on epoch=0
05/28/2022 05:08:51 - INFO - __main__ - Step 90 Global step 90 Train loss 3.45 on epoch=0
05/28/2022 05:08:53 - INFO - __main__ - Step 100 Global step 100 Train loss 3.30 on epoch=0
05/28/2022 05:09:45 - INFO - __main__ - Global step 100 Train loss 3.67 Classification-F1 0.012692266418262436 on epoch=0
05/28/2022 05:09:45 - INFO - __main__ - Saving model with best Classification-F1: 0.006670237319224082 -> 0.012692266418262436 on epoch=0, global_step=100
05/28/2022 05:09:48 - INFO - __main__ - Step 110 Global step 110 Train loss 2.86 on epoch=0
05/28/2022 05:09:50 - INFO - __main__ - Step 120 Global step 120 Train loss 2.70 on epoch=1
05/28/2022 05:09:53 - INFO - __main__ - Step 130 Global step 130 Train loss 2.78 on epoch=1
05/28/2022 05:09:55 - INFO - __main__ - Step 140 Global step 140 Train loss 2.65 on epoch=1
05/28/2022 05:09:58 - INFO - __main__ - Step 150 Global step 150 Train loss 2.17 on epoch=1
05/28/2022 05:10:48 - INFO - __main__ - Global step 150 Train loss 2.63 Classification-F1 0.02396548877938329 on epoch=1
05/28/2022 05:10:48 - INFO - __main__ - Saving model with best Classification-F1: 0.012692266418262436 -> 0.02396548877938329 on epoch=1, global_step=150
05/28/2022 05:10:51 - INFO - __main__ - Step 160 Global step 160 Train loss 2.37 on epoch=1
05/28/2022 05:10:53 - INFO - __main__ - Step 170 Global step 170 Train loss 2.42 on epoch=1
05/28/2022 05:10:56 - INFO - __main__ - Step 180 Global step 180 Train loss 2.27 on epoch=1
05/28/2022 05:10:58 - INFO - __main__ - Step 190 Global step 190 Train loss 1.75 on epoch=1
05/28/2022 05:11:01 - INFO - __main__ - Step 200 Global step 200 Train loss 2.01 on epoch=1
05/28/2022 05:11:46 - INFO - __main__ - Global step 200 Train loss 2.16 Classification-F1 0.03970100213984865 on epoch=1
05/28/2022 05:11:46 - INFO - __main__ - Saving model with best Classification-F1: 0.02396548877938329 -> 0.03970100213984865 on epoch=1, global_step=200
05/28/2022 05:11:48 - INFO - __main__ - Step 210 Global step 210 Train loss 2.09 on epoch=1
05/28/2022 05:11:51 - INFO - __main__ - Step 220 Global step 220 Train loss 1.68 on epoch=1
05/28/2022 05:11:54 - INFO - __main__ - Step 230 Global step 230 Train loss 1.77 on epoch=2
05/28/2022 05:11:56 - INFO - __main__ - Step 240 Global step 240 Train loss 1.75 on epoch=2
05/28/2022 05:11:59 - INFO - __main__ - Step 250 Global step 250 Train loss 1.63 on epoch=2
05/28/2022 05:12:43 - INFO - __main__ - Global step 250 Train loss 1.78 Classification-F1 0.05770600191624381 on epoch=2
05/28/2022 05:12:43 - INFO - __main__ - Saving model with best Classification-F1: 0.03970100213984865 -> 0.05770600191624381 on epoch=2, global_step=250
05/28/2022 05:12:46 - INFO - __main__ - Step 260 Global step 260 Train loss 1.49 on epoch=2
05/28/2022 05:12:49 - INFO - __main__ - Step 270 Global step 270 Train loss 1.51 on epoch=2
05/28/2022 05:12:51 - INFO - __main__ - Step 280 Global step 280 Train loss 1.67 on epoch=2
05/28/2022 05:12:54 - INFO - __main__ - Step 290 Global step 290 Train loss 1.51 on epoch=2
05/28/2022 05:12:56 - INFO - __main__ - Step 300 Global step 300 Train loss 1.31 on epoch=2
05/28/2022 05:13:41 - INFO - __main__ - Global step 300 Train loss 1.50 Classification-F1 0.0867072099374828 on epoch=2
05/28/2022 05:13:41 - INFO - __main__ - Saving model with best Classification-F1: 0.05770600191624381 -> 0.0867072099374828 on epoch=2, global_step=300
05/28/2022 05:13:44 - INFO - __main__ - Step 310 Global step 310 Train loss 1.43 on epoch=2
05/28/2022 05:13:46 - INFO - __main__ - Step 320 Global step 320 Train loss 1.51 on epoch=2
05/28/2022 05:13:49 - INFO - __main__ - Step 330 Global step 330 Train loss 1.11 on epoch=2
05/28/2022 05:13:51 - INFO - __main__ - Step 340 Global step 340 Train loss 1.14 on epoch=3
05/28/2022 05:13:54 - INFO - __main__ - Step 350 Global step 350 Train loss 1.08 on epoch=3
05/28/2022 05:14:38 - INFO - __main__ - Global step 350 Train loss 1.26 Classification-F1 0.1217974590478552 on epoch=3
05/28/2022 05:14:38 - INFO - __main__ - Saving model with best Classification-F1: 0.0867072099374828 -> 0.1217974590478552 on epoch=3, global_step=350
05/28/2022 05:14:41 - INFO - __main__ - Step 360 Global step 360 Train loss 1.03 on epoch=3
05/28/2022 05:14:43 - INFO - __main__ - Step 370 Global step 370 Train loss 1.04 on epoch=3
05/28/2022 05:14:46 - INFO - __main__ - Step 380 Global step 380 Train loss 0.93 on epoch=3
05/28/2022 05:14:48 - INFO - __main__ - Step 390 Global step 390 Train loss 1.08 on epoch=3
05/28/2022 05:14:51 - INFO - __main__ - Step 400 Global step 400 Train loss 0.89 on epoch=3
05/28/2022 05:15:35 - INFO - __main__ - Global step 400 Train loss 0.99 Classification-F1 0.16038562944466278 on epoch=3
05/28/2022 05:15:35 - INFO - __main__ - Saving model with best Classification-F1: 0.1217974590478552 -> 0.16038562944466278 on epoch=3, global_step=400
05/28/2022 05:15:38 - INFO - __main__ - Step 410 Global step 410 Train loss 0.83 on epoch=3
05/28/2022 05:15:41 - INFO - __main__ - Step 420 Global step 420 Train loss 0.95 on epoch=3
05/28/2022 05:15:43 - INFO - __main__ - Step 430 Global step 430 Train loss 0.94 on epoch=3
05/28/2022 05:15:46 - INFO - __main__ - Step 440 Global step 440 Train loss 0.78 on epoch=3
05/28/2022 05:15:48 - INFO - __main__ - Step 450 Global step 450 Train loss 0.67 on epoch=4
05/28/2022 05:16:35 - INFO - __main__ - Global step 450 Train loss 0.84 Classification-F1 0.19460766710604435 on epoch=4
05/28/2022 05:16:35 - INFO - __main__ - Saving model with best Classification-F1: 0.16038562944466278 -> 0.19460766710604435 on epoch=4, global_step=450
05/28/2022 05:16:38 - INFO - __main__ - Step 460 Global step 460 Train loss 0.57 on epoch=4
05/28/2022 05:16:40 - INFO - __main__ - Step 470 Global step 470 Train loss 0.68 on epoch=4
05/28/2022 05:16:43 - INFO - __main__ - Step 480 Global step 480 Train loss 0.76 on epoch=4
05/28/2022 05:16:45 - INFO - __main__ - Step 490 Global step 490 Train loss 0.71 on epoch=4
05/28/2022 05:16:48 - INFO - __main__ - Step 500 Global step 500 Train loss 0.68 on epoch=4
05/28/2022 05:17:37 - INFO - __main__ - Global step 500 Train loss 0.68 Classification-F1 0.21133671075226598 on epoch=4
05/28/2022 05:17:37 - INFO - __main__ - Saving model with best Classification-F1: 0.19460766710604435 -> 0.21133671075226598 on epoch=4, global_step=500
05/28/2022 05:17:40 - INFO - __main__ - Step 510 Global step 510 Train loss 0.68 on epoch=4
05/28/2022 05:17:42 - INFO - __main__ - Step 520 Global step 520 Train loss 0.65 on epoch=4
05/28/2022 05:17:45 - INFO - __main__ - Step 530 Global step 530 Train loss 0.56 on epoch=4
05/28/2022 05:17:47 - INFO - __main__ - Step 540 Global step 540 Train loss 0.63 on epoch=4
05/28/2022 05:17:50 - INFO - __main__ - Step 550 Global step 550 Train loss 0.53 on epoch=4
05/28/2022 05:18:39 - INFO - __main__ - Global step 550 Train loss 0.61 Classification-F1 0.2602933017576376 on epoch=4
05/28/2022 05:18:39 - INFO - __main__ - Saving model with best Classification-F1: 0.21133671075226598 -> 0.2602933017576376 on epoch=4, global_step=550
05/28/2022 05:18:42 - INFO - __main__ - Step 560 Global step 560 Train loss 0.42 on epoch=4
05/28/2022 05:18:44 - INFO - __main__ - Step 570 Global step 570 Train loss 0.52 on epoch=5
05/28/2022 05:18:47 - INFO - __main__ - Step 580 Global step 580 Train loss 0.50 on epoch=5
05/28/2022 05:18:49 - INFO - __main__ - Step 590 Global step 590 Train loss 0.54 on epoch=5
05/28/2022 05:18:52 - INFO - __main__ - Step 600 Global step 600 Train loss 0.39 on epoch=5
05/28/2022 05:19:41 - INFO - __main__ - Global step 600 Train loss 0.47 Classification-F1 0.291664422235132 on epoch=5
05/28/2022 05:19:41 - INFO - __main__ - Saving model with best Classification-F1: 0.2602933017576376 -> 0.291664422235132 on epoch=5, global_step=600
05/28/2022 05:19:43 - INFO - __main__ - Step 610 Global step 610 Train loss 0.47 on epoch=5
05/28/2022 05:19:46 - INFO - __main__ - Step 620 Global step 620 Train loss 0.58 on epoch=5
05/28/2022 05:19:49 - INFO - __main__ - Step 630 Global step 630 Train loss 0.35 on epoch=5
05/28/2022 05:19:51 - INFO - __main__ - Step 640 Global step 640 Train loss 0.49 on epoch=5
05/28/2022 05:19:54 - INFO - __main__ - Step 650 Global step 650 Train loss 0.45 on epoch=5
05/28/2022 05:20:44 - INFO - __main__ - Global step 650 Train loss 0.47 Classification-F1 0.36334565418050596 on epoch=5
05/28/2022 05:20:44 - INFO - __main__ - Saving model with best Classification-F1: 0.291664422235132 -> 0.36334565418050596 on epoch=5, global_step=650
05/28/2022 05:20:46 - INFO - __main__ - Step 660 Global step 660 Train loss 0.39 on epoch=5
05/28/2022 05:20:49 - INFO - __main__ - Step 670 Global step 670 Train loss 0.38 on epoch=5
05/28/2022 05:20:52 - INFO - __main__ - Step 680 Global step 680 Train loss 0.36 on epoch=6
05/28/2022 05:20:54 - INFO - __main__ - Step 690 Global step 690 Train loss 0.42 on epoch=6
05/28/2022 05:20:57 - INFO - __main__ - Step 700 Global step 700 Train loss 0.50 on epoch=6
05/28/2022 05:21:49 - INFO - __main__ - Global step 700 Train loss 0.41 Classification-F1 0.3236803645624687 on epoch=6
05/28/2022 05:21:51 - INFO - __main__ - Step 710 Global step 710 Train loss 0.42 on epoch=6
05/28/2022 05:21:54 - INFO - __main__ - Step 720 Global step 720 Train loss 0.37 on epoch=6
05/28/2022 05:21:56 - INFO - __main__ - Step 730 Global step 730 Train loss 0.42 on epoch=6
05/28/2022 05:21:59 - INFO - __main__ - Step 740 Global step 740 Train loss 0.37 on epoch=6
05/28/2022 05:22:01 - INFO - __main__ - Step 750 Global step 750 Train loss 0.35 on epoch=6
05/28/2022 05:22:53 - INFO - __main__ - Global step 750 Train loss 0.39 Classification-F1 0.4142738805544575 on epoch=6
05/28/2022 05:22:53 - INFO - __main__ - Saving model with best Classification-F1: 0.36334565418050596 -> 0.4142738805544575 on epoch=6, global_step=750
05/28/2022 05:22:56 - INFO - __main__ - Step 760 Global step 760 Train loss 0.40 on epoch=6
05/28/2022 05:22:58 - INFO - __main__ - Step 770 Global step 770 Train loss 0.32 on epoch=6
05/28/2022 05:23:01 - INFO - __main__ - Step 780 Global step 780 Train loss 0.28 on epoch=6
05/28/2022 05:23:03 - INFO - __main__ - Step 790 Global step 790 Train loss 0.31 on epoch=7
05/28/2022 05:23:06 - INFO - __main__ - Step 800 Global step 800 Train loss 0.35 on epoch=7
05/28/2022 05:23:57 - INFO - __main__ - Global step 800 Train loss 0.33 Classification-F1 0.45027267180925756 on epoch=7
05/28/2022 05:23:57 - INFO - __main__ - Saving model with best Classification-F1: 0.4142738805544575 -> 0.45027267180925756 on epoch=7, global_step=800
05/28/2022 05:24:00 - INFO - __main__ - Step 810 Global step 810 Train loss 0.33 on epoch=7
05/28/2022 05:24:02 - INFO - __main__ - Step 820 Global step 820 Train loss 0.38 on epoch=7
05/28/2022 05:24:05 - INFO - __main__ - Step 830 Global step 830 Train loss 0.36 on epoch=7
05/28/2022 05:24:08 - INFO - __main__ - Step 840 Global step 840 Train loss 0.35 on epoch=7
05/28/2022 05:24:10 - INFO - __main__ - Step 850 Global step 850 Train loss 0.26 on epoch=7
05/28/2022 05:25:01 - INFO - __main__ - Global step 850 Train loss 0.34 Classification-F1 0.37663319178181576 on epoch=7
05/28/2022 05:25:04 - INFO - __main__ - Step 860 Global step 860 Train loss 0.30 on epoch=7
05/28/2022 05:25:06 - INFO - __main__ - Step 870 Global step 870 Train loss 0.29 on epoch=7
05/28/2022 05:25:09 - INFO - __main__ - Step 880 Global step 880 Train loss 0.36 on epoch=7
05/28/2022 05:25:12 - INFO - __main__ - Step 890 Global step 890 Train loss 0.24 on epoch=7
05/28/2022 05:25:14 - INFO - __main__ - Step 900 Global step 900 Train loss 0.30 on epoch=8
05/28/2022 05:26:05 - INFO - __main__ - Global step 900 Train loss 0.30 Classification-F1 0.36522082913016674 on epoch=8
05/28/2022 05:26:08 - INFO - __main__ - Step 910 Global step 910 Train loss 0.26 on epoch=8
05/28/2022 05:26:10 - INFO - __main__ - Step 920 Global step 920 Train loss 0.23 on epoch=8
05/28/2022 05:26:13 - INFO - __main__ - Step 930 Global step 930 Train loss 0.44 on epoch=8
05/28/2022 05:26:15 - INFO - __main__ - Step 940 Global step 940 Train loss 0.29 on epoch=8
05/28/2022 05:26:18 - INFO - __main__ - Step 950 Global step 950 Train loss 0.38 on epoch=8
05/28/2022 05:27:09 - INFO - __main__ - Global step 950 Train loss 0.32 Classification-F1 0.4483052280201445 on epoch=8
05/28/2022 05:27:12 - INFO - __main__ - Step 960 Global step 960 Train loss 0.31 on epoch=8
05/28/2022 05:27:15 - INFO - __main__ - Step 970 Global step 970 Train loss 0.32 on epoch=8
05/28/2022 05:27:17 - INFO - __main__ - Step 980 Global step 980 Train loss 0.19 on epoch=8
05/28/2022 05:27:20 - INFO - __main__ - Step 990 Global step 990 Train loss 0.38 on epoch=8
05/28/2022 05:27:22 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.29 on epoch=8
05/28/2022 05:28:15 - INFO - __main__ - Global step 1000 Train loss 0.30 Classification-F1 0.44253603197001695 on epoch=8
05/28/2022 05:28:17 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.22 on epoch=9
05/28/2022 05:28:20 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.25 on epoch=9
05/28/2022 05:28:22 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.29 on epoch=9
05/28/2022 05:28:25 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.32 on epoch=9
05/28/2022 05:28:28 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.21 on epoch=9
05/28/2022 05:29:20 - INFO - __main__ - Global step 1050 Train loss 0.26 Classification-F1 0.5283184434383381 on epoch=9
05/28/2022 05:29:20 - INFO - __main__ - Saving model with best Classification-F1: 0.45027267180925756 -> 0.5283184434383381 on epoch=9, global_step=1050
05/28/2022 05:29:23 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.28 on epoch=9
05/28/2022 05:29:25 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.26 on epoch=9
05/28/2022 05:29:28 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.31 on epoch=9
05/28/2022 05:29:30 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.19 on epoch=9
05/28/2022 05:29:33 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.30 on epoch=9
05/28/2022 05:30:25 - INFO - __main__ - Global step 1100 Train loss 0.27 Classification-F1 0.5519132257879295 on epoch=9
05/28/2022 05:30:25 - INFO - __main__ - Saving model with best Classification-F1: 0.5283184434383381 -> 0.5519132257879295 on epoch=9, global_step=1100
05/28/2022 05:30:28 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.26 on epoch=9
05/28/2022 05:30:30 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.21 on epoch=9
05/28/2022 05:30:33 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.24 on epoch=10
05/28/2022 05:30:35 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.25 on epoch=10
05/28/2022 05:30:38 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.22 on epoch=10
05/28/2022 05:31:29 - INFO - __main__ - Global step 1150 Train loss 0.24 Classification-F1 0.5326231759501009 on epoch=10
05/28/2022 05:31:31 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.15 on epoch=10
05/28/2022 05:31:34 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.29 on epoch=10
05/28/2022 05:31:36 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.26 on epoch=10
05/28/2022 05:31:39 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.24 on epoch=10
05/28/2022 05:31:42 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.20 on epoch=10
05/28/2022 05:32:33 - INFO - __main__ - Global step 1200 Train loss 0.23 Classification-F1 0.5240917566142818 on epoch=10
05/28/2022 05:32:35 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.25 on epoch=10
05/28/2022 05:32:38 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.23 on epoch=10
05/28/2022 05:32:41 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.19 on epoch=10
05/28/2022 05:32:43 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.15 on epoch=11
05/28/2022 05:32:46 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.17 on epoch=11
05/28/2022 05:33:37 - INFO - __main__ - Global step 1250 Train loss 0.20 Classification-F1 0.5478646689536396 on epoch=11
05/28/2022 05:33:40 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.19 on epoch=11
05/28/2022 05:33:42 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.27 on epoch=11
05/28/2022 05:33:45 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.20 on epoch=11
05/28/2022 05:33:47 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.22 on epoch=11
05/28/2022 05:33:50 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.22 on epoch=11
05/28/2022 05:34:42 - INFO - __main__ - Global step 1300 Train loss 0.22 Classification-F1 0.5186291077229607 on epoch=11
05/28/2022 05:34:44 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.16 on epoch=11
05/28/2022 05:34:47 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.23 on epoch=11
05/28/2022 05:34:50 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.24 on epoch=11
05/28/2022 05:34:52 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.16 on epoch=11
05/28/2022 05:34:55 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.19 on epoch=12
05/28/2022 05:35:45 - INFO - __main__ - Global step 1350 Train loss 0.20 Classification-F1 0.6137766413141177 on epoch=12
05/28/2022 05:35:45 - INFO - __main__ - Saving model with best Classification-F1: 0.5519132257879295 -> 0.6137766413141177 on epoch=12, global_step=1350
05/28/2022 05:35:47 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.14 on epoch=12
05/28/2022 05:35:50 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.18 on epoch=12
05/28/2022 05:35:53 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.20 on epoch=12
05/28/2022 05:35:55 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.15 on epoch=12
05/28/2022 05:35:58 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.22 on epoch=12
05/28/2022 05:36:48 - INFO - __main__ - Global step 1400 Train loss 0.18 Classification-F1 0.6142098404200328 on epoch=12
05/28/2022 05:36:48 - INFO - __main__ - Saving model with best Classification-F1: 0.6137766413141177 -> 0.6142098404200328 on epoch=12, global_step=1400
05/28/2022 05:36:50 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.13 on epoch=12
05/28/2022 05:36:53 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.16 on epoch=12
05/28/2022 05:36:56 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.18 on epoch=12
05/28/2022 05:36:58 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.22 on epoch=12
05/28/2022 05:37:01 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.18 on epoch=12
05/28/2022 05:37:52 - INFO - __main__ - Global step 1450 Train loss 0.17 Classification-F1 0.5601837968720532 on epoch=12
05/28/2022 05:37:54 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.13 on epoch=13
05/28/2022 05:37:57 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.15 on epoch=13
05/28/2022 05:37:59 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.15 on epoch=13
05/28/2022 05:38:02 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.22 on epoch=13
05/28/2022 05:38:05 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.16 on epoch=13
05/28/2022 05:38:54 - INFO - __main__ - Global step 1500 Train loss 0.16 Classification-F1 0.5602497461210832 on epoch=13
05/28/2022 05:38:57 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.19 on epoch=13
05/28/2022 05:39:00 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.22 on epoch=13
05/28/2022 05:39:02 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.22 on epoch=13
05/28/2022 05:39:05 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.07 on epoch=13
05/28/2022 05:39:07 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.30 on epoch=13
05/28/2022 05:39:58 - INFO - __main__ - Global step 1550 Train loss 0.20 Classification-F1 0.5869669380699536 on epoch=13
05/28/2022 05:40:01 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.13 on epoch=13
05/28/2022 05:40:03 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.12 on epoch=14
05/28/2022 05:40:06 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.09 on epoch=14
05/28/2022 05:40:08 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.11 on epoch=14
05/28/2022 05:40:11 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.31 on epoch=14
05/28/2022 05:41:01 - INFO - __main__ - Global step 1600 Train loss 0.15 Classification-F1 0.5621803294365587 on epoch=14
05/28/2022 05:41:04 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.10 on epoch=14
05/28/2022 05:41:06 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.20 on epoch=14
05/28/2022 05:41:09 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.12 on epoch=14
05/28/2022 05:41:12 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.19 on epoch=14
05/28/2022 05:41:14 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.12 on epoch=14
05/28/2022 05:42:04 - INFO - __main__ - Global step 1650 Train loss 0.15 Classification-F1 0.5379722082518117 on epoch=14
05/28/2022 05:42:07 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.16 on epoch=14
05/28/2022 05:42:10 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.21 on epoch=14
05/28/2022 05:42:12 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.09 on epoch=14
05/28/2022 05:42:15 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.12 on epoch=15
05/28/2022 05:42:17 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.08 on epoch=15
05/28/2022 05:43:08 - INFO - __main__ - Global step 1700 Train loss 0.13 Classification-F1 0.6160508903640419 on epoch=15
05/28/2022 05:43:08 - INFO - __main__ - Saving model with best Classification-F1: 0.6142098404200328 -> 0.6160508903640419 on epoch=15, global_step=1700
05/28/2022 05:43:10 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.23 on epoch=15
05/28/2022 05:43:13 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.09 on epoch=15
05/28/2022 05:43:15 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.14 on epoch=15
05/28/2022 05:43:18 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.15 on epoch=15
05/28/2022 05:43:21 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.14 on epoch=15
05/28/2022 05:44:10 - INFO - __main__ - Global step 1750 Train loss 0.15 Classification-F1 0.6224778049011137 on epoch=15
05/28/2022 05:44:10 - INFO - __main__ - Saving model with best Classification-F1: 0.6160508903640419 -> 0.6224778049011137 on epoch=15, global_step=1750
05/28/2022 05:44:13 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.11 on epoch=15
05/28/2022 05:44:16 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.17 on epoch=15
05/28/2022 05:44:18 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.13 on epoch=15
05/28/2022 05:44:21 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.15 on epoch=15
05/28/2022 05:44:24 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.09 on epoch=16
05/28/2022 05:45:13 - INFO - __main__ - Global step 1800 Train loss 0.13 Classification-F1 0.6489074077112533 on epoch=16
05/28/2022 05:45:13 - INFO - __main__ - Saving model with best Classification-F1: 0.6224778049011137 -> 0.6489074077112533 on epoch=16, global_step=1800
05/28/2022 05:45:15 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.08 on epoch=16
05/28/2022 05:45:18 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.15 on epoch=16
05/28/2022 05:45:20 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.14 on epoch=16
05/28/2022 05:45:23 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.12 on epoch=16
05/28/2022 05:45:26 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.14 on epoch=16
05/28/2022 05:46:15 - INFO - __main__ - Global step 1850 Train loss 0.13 Classification-F1 0.6110147110697228 on epoch=16
05/28/2022 05:46:17 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.12 on epoch=16
05/28/2022 05:46:20 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.12 on epoch=16
05/28/2022 05:46:22 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.19 on epoch=16
05/28/2022 05:46:25 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.20 on epoch=16
05/28/2022 05:46:28 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.14 on epoch=16
05/28/2022 05:47:17 - INFO - __main__ - Global step 1900 Train loss 0.15 Classification-F1 0.53191305055833 on epoch=16
05/28/2022 05:47:20 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.05 on epoch=17
05/28/2022 05:47:22 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.10 on epoch=17
05/28/2022 05:47:25 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.14 on epoch=17
05/28/2022 05:47:27 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.19 on epoch=17
05/28/2022 05:47:30 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.15 on epoch=17
05/28/2022 05:48:19 - INFO - __main__ - Global step 1950 Train loss 0.13 Classification-F1 0.5335710581217143 on epoch=17
05/28/2022 05:48:22 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.21 on epoch=17
05/28/2022 05:48:24 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.08 on epoch=17
05/28/2022 05:48:27 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.12 on epoch=17
05/28/2022 05:48:29 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.08 on epoch=17
05/28/2022 05:48:32 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.26 on epoch=17
05/28/2022 05:49:22 - INFO - __main__ - Global step 2000 Train loss 0.15 Classification-F1 0.5824257861957737 on epoch=17
05/28/2022 05:49:25 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.19 on epoch=17
05/28/2022 05:49:28 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.06 on epoch=18
05/28/2022 05:49:30 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.08 on epoch=18
05/28/2022 05:49:33 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.06 on epoch=18
05/28/2022 05:49:35 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.27 on epoch=18
05/28/2022 05:50:25 - INFO - __main__ - Global step 2050 Train loss 0.13 Classification-F1 0.5876033220132777 on epoch=18
05/28/2022 05:50:28 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.09 on epoch=18
05/28/2022 05:50:31 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.21 on epoch=18
05/28/2022 05:50:33 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.12 on epoch=18
05/28/2022 05:50:36 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.14 on epoch=18
05/28/2022 05:50:38 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.10 on epoch=18
05/28/2022 05:51:29 - INFO - __main__ - Global step 2100 Train loss 0.13 Classification-F1 0.5928825178940585 on epoch=18
05/28/2022 05:51:32 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.13 on epoch=18
05/28/2022 05:51:34 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.13 on epoch=18
05/28/2022 05:51:37 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.06 on epoch=19
05/28/2022 05:51:39 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.09 on epoch=19
05/28/2022 05:51:42 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.10 on epoch=19
05/28/2022 05:52:33 - INFO - __main__ - Global step 2150 Train loss 0.10 Classification-F1 0.6282593391672682 on epoch=19
05/28/2022 05:52:36 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.25 on epoch=19
05/28/2022 05:52:38 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.10 on epoch=19
05/28/2022 05:52:41 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.17 on epoch=19
05/28/2022 05:52:43 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.11 on epoch=19
05/28/2022 05:52:46 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.17 on epoch=19
05/28/2022 05:53:36 - INFO - __main__ - Global step 2200 Train loss 0.16 Classification-F1 0.6125642776964276 on epoch=19
05/28/2022 05:53:39 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.10 on epoch=19
05/28/2022 05:53:41 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.11 on epoch=19
05/28/2022 05:53:44 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.15 on epoch=19
05/28/2022 05:53:47 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.08 on epoch=19
05/28/2022 05:53:49 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.07 on epoch=20
05/28/2022 05:54:40 - INFO - __main__ - Global step 2250 Train loss 0.10 Classification-F1 0.6250403494667948 on epoch=20
05/28/2022 05:54:42 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.05 on epoch=20
05/28/2022 05:54:45 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.29 on epoch=20
05/28/2022 05:54:48 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.07 on epoch=20
05/28/2022 05:54:50 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.13 on epoch=20
05/28/2022 05:54:53 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.14 on epoch=20
05/28/2022 05:55:42 - INFO - __main__ - Global step 2300 Train loss 0.14 Classification-F1 0.5847099206006168 on epoch=20
05/28/2022 05:55:44 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.07 on epoch=20
05/28/2022 05:55:47 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.08 on epoch=20
05/28/2022 05:55:49 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.13 on epoch=20
05/28/2022 05:55:52 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.08 on epoch=20
05/28/2022 05:55:55 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.12 on epoch=20
05/28/2022 05:56:44 - INFO - __main__ - Global step 2350 Train loss 0.10 Classification-F1 0.5996973522924985 on epoch=20
05/28/2022 05:56:46 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.08 on epoch=21
05/28/2022 05:56:49 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.08 on epoch=21
05/28/2022 05:56:51 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.21 on epoch=21
05/28/2022 05:56:54 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.13 on epoch=21
05/28/2022 05:56:56 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.14 on epoch=21
05/28/2022 05:57:46 - INFO - __main__ - Global step 2400 Train loss 0.13 Classification-F1 0.6719360982650154 on epoch=21
05/28/2022 05:57:46 - INFO - __main__ - Saving model with best Classification-F1: 0.6489074077112533 -> 0.6719360982650154 on epoch=21, global_step=2400
05/28/2022 05:57:49 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.13 on epoch=21
05/28/2022 05:57:51 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.09 on epoch=21
05/28/2022 05:57:54 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.10 on epoch=21
05/28/2022 05:57:56 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.15 on epoch=21
05/28/2022 05:57:59 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.17 on epoch=21
05/28/2022 05:58:48 - INFO - __main__ - Global step 2450 Train loss 0.13 Classification-F1 0.672326413777775 on epoch=21
05/28/2022 05:58:48 - INFO - __main__ - Saving model with best Classification-F1: 0.6719360982650154 -> 0.672326413777775 on epoch=21, global_step=2450
05/28/2022 05:58:51 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.10 on epoch=21
05/28/2022 05:58:54 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.09 on epoch=22
05/28/2022 05:58:56 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.06 on epoch=22
05/28/2022 05:58:59 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.08 on epoch=22
05/28/2022 05:59:02 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.14 on epoch=22
05/28/2022 05:59:51 - INFO - __main__ - Global step 2500 Train loss 0.09 Classification-F1 0.6075409869294196 on epoch=22
05/28/2022 05:59:53 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.06 on epoch=22
05/28/2022 05:59:56 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.13 on epoch=22
05/28/2022 05:59:59 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.08 on epoch=22
05/28/2022 06:00:01 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.09 on epoch=22
05/28/2022 06:00:04 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.14 on epoch=22
05/28/2022 06:00:55 - INFO - __main__ - Global step 2550 Train loss 0.10 Classification-F1 0.6158350065283409 on epoch=22
05/28/2022 06:00:58 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.22 on epoch=22
05/28/2022 06:01:00 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.07 on epoch=22
05/28/2022 06:01:03 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.05 on epoch=23
05/28/2022 06:01:06 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.05 on epoch=23
05/28/2022 06:01:08 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.07 on epoch=23
05/28/2022 06:01:59 - INFO - __main__ - Global step 2600 Train loss 0.09 Classification-F1 0.6498399109588059 on epoch=23
05/28/2022 06:02:01 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.20 on epoch=23
05/28/2022 06:02:04 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.04 on epoch=23
05/28/2022 06:02:06 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.10 on epoch=23
05/28/2022 06:02:09 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.05 on epoch=23
05/28/2022 06:02:12 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.09 on epoch=23
05/28/2022 06:03:01 - INFO - __main__ - Global step 2650 Train loss 0.10 Classification-F1 0.6225161715200267 on epoch=23
05/28/2022 06:03:04 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.07 on epoch=23
05/28/2022 06:03:06 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.15 on epoch=23
05/28/2022 06:03:09 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.11 on epoch=23
05/28/2022 06:03:12 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.05 on epoch=24
05/28/2022 06:03:14 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.06 on epoch=24
05/28/2022 06:04:04 - INFO - __main__ - Global step 2700 Train loss 0.09 Classification-F1 0.6867587156513727 on epoch=24
05/28/2022 06:04:04 - INFO - __main__ - Saving model with best Classification-F1: 0.672326413777775 -> 0.6867587156513727 on epoch=24, global_step=2700
05/28/2022 06:04:07 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.05 on epoch=24
05/28/2022 06:04:09 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.21 on epoch=24
05/28/2022 06:04:12 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.08 on epoch=24
05/28/2022 06:04:15 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.12 on epoch=24
05/28/2022 06:04:17 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.09 on epoch=24
05/28/2022 06:05:06 - INFO - __main__ - Global step 2750 Train loss 0.11 Classification-F1 0.726803936358213 on epoch=24
05/28/2022 06:05:06 - INFO - __main__ - Saving model with best Classification-F1: 0.6867587156513727 -> 0.726803936358213 on epoch=24, global_step=2750
05/28/2022 06:05:09 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.07 on epoch=24
05/28/2022 06:05:12 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.06 on epoch=24
05/28/2022 06:05:14 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.16 on epoch=24
05/28/2022 06:05:17 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.14 on epoch=24
05/28/2022 06:05:20 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.14 on epoch=24
05/28/2022 06:06:09 - INFO - __main__ - Global step 2800 Train loss 0.11 Classification-F1 0.6658515192458784 on epoch=24
05/28/2022 06:06:11 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.05 on epoch=25
05/28/2022 06:06:14 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.08 on epoch=25
05/28/2022 06:06:17 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.13 on epoch=25
05/28/2022 06:06:19 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.07 on epoch=25
05/28/2022 06:06:22 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.14 on epoch=25
05/28/2022 06:07:11 - INFO - __main__ - Global step 2850 Train loss 0.09 Classification-F1 0.6770170883652147 on epoch=25
05/28/2022 06:07:13 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.08 on epoch=25
05/28/2022 06:07:16 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.04 on epoch=25
05/28/2022 06:07:19 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.06 on epoch=25
05/28/2022 06:07:21 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.12 on epoch=25
05/28/2022 06:07:24 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.08 on epoch=25
05/28/2022 06:08:13 - INFO - __main__ - Global step 2900 Train loss 0.07 Classification-F1 0.6669393572624278 on epoch=25
05/28/2022 06:08:15 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.09 on epoch=25
05/28/2022 06:08:18 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.03 on epoch=26
05/28/2022 06:08:21 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.04 on epoch=26
05/28/2022 06:08:23 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.15 on epoch=26
05/28/2022 06:08:26 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.08 on epoch=26
05/28/2022 06:09:14 - INFO - __main__ - Global step 2950 Train loss 0.08 Classification-F1 0.6619432232608431 on epoch=26
05/28/2022 06:09:17 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.05 on epoch=26
05/28/2022 06:09:20 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.06 on epoch=26
05/28/2022 06:09:22 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.04 on epoch=26
05/28/2022 06:09:25 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.04 on epoch=26
05/28/2022 06:09:27 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.13 on epoch=26
05/28/2022 06:09:29 - INFO - __main__ - Start tokenizing ... 1792 instances
05/28/2022 06:09:29 - INFO - __main__ - Printing 3 examples
05/28/2022 06:09:29 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/28/2022 06:09:29 - INFO - __main__ - ['Plant']
05/28/2022 06:09:29 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/28/2022 06:09:29 - INFO - __main__ - ['Plant']
05/28/2022 06:09:29 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/28/2022 06:09:29 - INFO - __main__ - ['Plant']
05/28/2022 06:09:29 - INFO - __main__ - Tokenizing Input ...
05/28/2022 06:09:30 - INFO - __main__ - Tokenizing Output ...
05/28/2022 06:09:32 - INFO - __main__ - Loaded 1792 examples from train data
05/28/2022 06:09:32 - INFO - __main__ - Start tokenizing ... 1792 instances
05/28/2022 06:09:32 - INFO - __main__ - Printing 3 examples
05/28/2022 06:09:32 - INFO - __main__ -  [dbpedia_14] Sabal pumos is a species of flowering plant in the palm tree family Arecaceae. It is native to the dry forests along the Balsas River in central Mexico (Guanajuato Guerrero Jalisco Michoacán Morelos Zacatecas and the State of México). It is threatened by habitat loss.
05/28/2022 06:09:32 - INFO - __main__ - ['Plant']
05/28/2022 06:09:32 - INFO - __main__ -  [dbpedia_14] Bulbophyllum intricatum is a species of orchid in the genus Bulbophyllum.
05/28/2022 06:09:32 - INFO - __main__ - ['Plant']
05/28/2022 06:09:32 - INFO - __main__ -  [dbpedia_14] Gentiana parryi (Parry's Gentian) is a species of the genus Gentiana.
05/28/2022 06:09:32 - INFO - __main__ - ['Plant']
05/28/2022 06:09:32 - INFO - __main__ - Tokenizing Input ...
05/28/2022 06:09:33 - INFO - __main__ - Tokenizing Output ...
05/28/2022 06:09:35 - INFO - __main__ - Loaded 1792 examples from dev data
05/28/2022 06:09:50 - INFO - __main__ - load prompt embedding from ckpt
05/28/2022 06:09:50 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/28/2022 06:09:50 - INFO - __main__ - Starting training!
05/28/2022 06:10:16 - INFO - __main__ - Global step 3000 Train loss 0.07 Classification-F1 0.6194794958845425 on epoch=26
05/28/2022 06:10:16 - INFO - __main__ - save last model!
05/28/2022 06:10:16 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/28/2022 06:10:16 - INFO - __main__ - Start tokenizing ... 3500 instances
05/28/2022 06:10:16 - INFO - __main__ - Printing 3 examples
05/28/2022 06:10:16 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/28/2022 06:10:16 - INFO - __main__ - ['Animal']
05/28/2022 06:10:16 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/28/2022 06:10:16 - INFO - __main__ - ['Animal']
05/28/2022 06:10:16 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/28/2022 06:10:16 - INFO - __main__ - ['Village']
05/28/2022 06:10:16 - INFO - __main__ - Tokenizing Input ...
05/28/2022 06:10:18 - INFO - __main__ - Tokenizing Output ...
05/28/2022 06:10:21 - INFO - __main__ - Loaded 3500 examples from test data
05/28/2022 06:12:20 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down128shot/singletask-dbpedia_14/dbpedia_14_128_13_0.2_8_predictions.txt
05/28/2022 06:12:20 - INFO - __main__ - Classification-F1 on test data: 0.6453
05/28/2022 06:12:21 - INFO - __main__ - prefix=dbpedia_14_128_13, lr=0.2, bsz=8, dev_performance=0.726803936358213, test_performance=0.6453268960255141
05/28/2022 06:12:21 - INFO - __main__ - Running ... prefix=dbpedia_14_128_21, lr=0.5, bsz=8 ...
05/28/2022 06:12:22 - INFO - __main__ - Start tokenizing ... 1792 instances
05/28/2022 06:12:22 - INFO - __main__ - Printing 3 examples
05/28/2022 06:12:22 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/28/2022 06:12:22 - INFO - __main__ - ['Plant']
05/28/2022 06:12:22 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/28/2022 06:12:22 - INFO - __main__ - ['Plant']
05/28/2022 06:12:22 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/28/2022 06:12:22 - INFO - __main__ - ['Plant']
05/28/2022 06:12:22 - INFO - __main__ - Tokenizing Input ...
05/28/2022 06:12:23 - INFO - __main__ - Tokenizing Output ...
05/28/2022 06:12:24 - INFO - __main__ - Loaded 1792 examples from train data
05/28/2022 06:12:24 - INFO - __main__ - Start tokenizing ... 1792 instances
05/28/2022 06:12:24 - INFO - __main__ - Printing 3 examples
05/28/2022 06:12:24 - INFO - __main__ -  [dbpedia_14] Sabal pumos is a species of flowering plant in the palm tree family Arecaceae. It is native to the dry forests along the Balsas River in central Mexico (Guanajuato Guerrero Jalisco Michoacán Morelos Zacatecas and the State of México). It is threatened by habitat loss.
05/28/2022 06:12:24 - INFO - __main__ - ['Plant']
05/28/2022 06:12:24 - INFO - __main__ -  [dbpedia_14] Bulbophyllum intricatum is a species of orchid in the genus Bulbophyllum.
05/28/2022 06:12:24 - INFO - __main__ - ['Plant']
05/28/2022 06:12:24 - INFO - __main__ -  [dbpedia_14] Gentiana parryi (Parry's Gentian) is a species of the genus Gentiana.
05/28/2022 06:12:24 - INFO - __main__ - ['Plant']
05/28/2022 06:12:24 - INFO - __main__ - Tokenizing Input ...
05/28/2022 06:12:25 - INFO - __main__ - Tokenizing Output ...
05/28/2022 06:12:27 - INFO - __main__ - Loaded 1792 examples from dev data
05/28/2022 06:12:45 - INFO - __main__ - load prompt embedding from ckpt
05/28/2022 06:12:46 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/28/2022 06:12:46 - INFO - __main__ - Starting training!
05/28/2022 06:12:50 - INFO - __main__ - Step 10 Global step 10 Train loss 7.96 on epoch=0
05/28/2022 06:12:53 - INFO - __main__ - Step 20 Global step 20 Train loss 4.98 on epoch=0
05/28/2022 06:12:55 - INFO - __main__ - Step 30 Global step 30 Train loss 3.82 on epoch=0
05/28/2022 06:12:58 - INFO - __main__ - Step 40 Global step 40 Train loss 3.38 on epoch=0
05/28/2022 06:13:00 - INFO - __main__ - Step 50 Global step 50 Train loss 3.10 on epoch=0
05/28/2022 06:13:53 - INFO - __main__ - Global step 50 Train loss 4.65 Classification-F1 0.013998052292178598 on epoch=0
05/28/2022 06:13:53 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.013998052292178598 on epoch=0, global_step=50
05/28/2022 06:13:56 - INFO - __main__ - Step 60 Global step 60 Train loss 2.50 on epoch=0
05/28/2022 06:13:59 - INFO - __main__ - Step 70 Global step 70 Train loss 2.20 on epoch=0
05/28/2022 06:14:02 - INFO - __main__ - Step 80 Global step 80 Train loss 2.33 on epoch=0
05/28/2022 06:14:05 - INFO - __main__ - Step 90 Global step 90 Train loss 1.89 on epoch=0
05/28/2022 06:14:07 - INFO - __main__ - Step 100 Global step 100 Train loss 1.43 on epoch=0
05/28/2022 06:14:53 - INFO - __main__ - Global step 100 Train loss 2.07 Classification-F1 0.051628925432937886 on epoch=0
05/28/2022 06:14:53 - INFO - __main__ - Saving model with best Classification-F1: 0.013998052292178598 -> 0.051628925432937886 on epoch=0, global_step=100
05/28/2022 06:14:56 - INFO - __main__ - Step 110 Global step 110 Train loss 1.53 on epoch=0
05/28/2022 06:14:58 - INFO - __main__ - Step 120 Global step 120 Train loss 1.66 on epoch=1
05/28/2022 06:15:01 - INFO - __main__ - Step 130 Global step 130 Train loss 1.38 on epoch=1
05/28/2022 06:15:04 - INFO - __main__ - Step 140 Global step 140 Train loss 1.34 on epoch=1
05/28/2022 06:15:06 - INFO - __main__ - Step 150 Global step 150 Train loss 1.03 on epoch=1
05/28/2022 06:15:50 - INFO - __main__ - Global step 150 Train loss 1.39 Classification-F1 0.11755196569024384 on epoch=1
05/28/2022 06:15:50 - INFO - __main__ - Saving model with best Classification-F1: 0.051628925432937886 -> 0.11755196569024384 on epoch=1, global_step=150
05/28/2022 06:15:53 - INFO - __main__ - Step 160 Global step 160 Train loss 0.96 on epoch=1
05/28/2022 06:15:56 - INFO - __main__ - Step 170 Global step 170 Train loss 0.90 on epoch=1
05/28/2022 06:15:58 - INFO - __main__ - Step 180 Global step 180 Train loss 0.84 on epoch=1
05/28/2022 06:16:01 - INFO - __main__ - Step 190 Global step 190 Train loss 0.72 on epoch=1
05/28/2022 06:16:04 - INFO - __main__ - Step 200 Global step 200 Train loss 0.71 on epoch=1
05/28/2022 06:16:53 - INFO - __main__ - Global step 200 Train loss 0.82 Classification-F1 0.23873353283720428 on epoch=1
05/28/2022 06:16:53 - INFO - __main__ - Saving model with best Classification-F1: 0.11755196569024384 -> 0.23873353283720428 on epoch=1, global_step=200
05/28/2022 06:16:55 - INFO - __main__ - Step 210 Global step 210 Train loss 0.67 on epoch=1
05/28/2022 06:16:58 - INFO - __main__ - Step 220 Global step 220 Train loss 0.64 on epoch=1
05/28/2022 06:17:00 - INFO - __main__ - Step 230 Global step 230 Train loss 0.51 on epoch=2
05/28/2022 06:17:03 - INFO - __main__ - Step 240 Global step 240 Train loss 0.44 on epoch=2
05/28/2022 06:17:06 - INFO - __main__ - Step 250 Global step 250 Train loss 0.47 on epoch=2
05/28/2022 06:17:57 - INFO - __main__ - Global step 250 Train loss 0.55 Classification-F1 0.3017183945075244 on epoch=2
05/28/2022 06:17:57 - INFO - __main__ - Saving model with best Classification-F1: 0.23873353283720428 -> 0.3017183945075244 on epoch=2, global_step=250
05/28/2022 06:17:59 - INFO - __main__ - Step 260 Global step 260 Train loss 0.53 on epoch=2
05/28/2022 06:18:02 - INFO - __main__ - Step 270 Global step 270 Train loss 0.40 on epoch=2
05/28/2022 06:18:04 - INFO - __main__ - Step 280 Global step 280 Train loss 0.49 on epoch=2
05/28/2022 06:18:07 - INFO - __main__ - Step 290 Global step 290 Train loss 0.32 on epoch=2
05/28/2022 06:18:10 - INFO - __main__ - Step 300 Global step 300 Train loss 0.41 on epoch=2
05/28/2022 06:19:00 - INFO - __main__ - Global step 300 Train loss 0.43 Classification-F1 0.3237345328102599 on epoch=2
05/28/2022 06:19:01 - INFO - __main__ - Saving model with best Classification-F1: 0.3017183945075244 -> 0.3237345328102599 on epoch=2, global_step=300
05/28/2022 06:19:03 - INFO - __main__ - Step 310 Global step 310 Train loss 0.39 on epoch=2
05/28/2022 06:19:06 - INFO - __main__ - Step 320 Global step 320 Train loss 0.29 on epoch=2
05/28/2022 06:19:08 - INFO - __main__ - Step 330 Global step 330 Train loss 0.34 on epoch=2
05/28/2022 06:19:11 - INFO - __main__ - Step 340 Global step 340 Train loss 0.37 on epoch=3
05/28/2022 06:19:14 - INFO - __main__ - Step 350 Global step 350 Train loss 0.37 on epoch=3
05/28/2022 06:20:06 - INFO - __main__ - Global step 350 Train loss 0.35 Classification-F1 0.3586340591025846 on epoch=3
05/28/2022 06:20:06 - INFO - __main__ - Saving model with best Classification-F1: 0.3237345328102599 -> 0.3586340591025846 on epoch=3, global_step=350
05/28/2022 06:20:09 - INFO - __main__ - Step 360 Global step 360 Train loss 0.32 on epoch=3
05/28/2022 06:20:11 - INFO - __main__ - Step 370 Global step 370 Train loss 0.37 on epoch=3
05/28/2022 06:20:14 - INFO - __main__ - Step 380 Global step 380 Train loss 0.30 on epoch=3
05/28/2022 06:20:16 - INFO - __main__ - Step 390 Global step 390 Train loss 0.32 on epoch=3
05/28/2022 06:20:19 - INFO - __main__ - Step 400 Global step 400 Train loss 0.22 on epoch=3
05/28/2022 06:21:09 - INFO - __main__ - Global step 400 Train loss 0.31 Classification-F1 0.3583582781763846 on epoch=3
05/28/2022 06:21:12 - INFO - __main__ - Step 410 Global step 410 Train loss 0.27 on epoch=3
05/28/2022 06:21:15 - INFO - __main__ - Step 420 Global step 420 Train loss 0.29 on epoch=3
05/28/2022 06:21:17 - INFO - __main__ - Step 430 Global step 430 Train loss 0.24 on epoch=3
05/28/2022 06:21:20 - INFO - __main__ - Step 440 Global step 440 Train loss 0.24 on epoch=3
05/28/2022 06:21:22 - INFO - __main__ - Step 450 Global step 450 Train loss 0.26 on epoch=4
05/28/2022 06:22:13 - INFO - __main__ - Global step 450 Train loss 0.26 Classification-F1 0.3689439934249983 on epoch=4
05/28/2022 06:22:13 - INFO - __main__ - Saving model with best Classification-F1: 0.3586340591025846 -> 0.3689439934249983 on epoch=4, global_step=450
05/28/2022 06:22:15 - INFO - __main__ - Step 460 Global step 460 Train loss 0.16 on epoch=4
05/28/2022 06:22:18 - INFO - __main__ - Step 470 Global step 470 Train loss 0.25 on epoch=4
05/28/2022 06:22:21 - INFO - __main__ - Step 480 Global step 480 Train loss 0.19 on epoch=4
05/28/2022 06:22:23 - INFO - __main__ - Step 490 Global step 490 Train loss 0.23 on epoch=4
05/28/2022 06:22:26 - INFO - __main__ - Step 500 Global step 500 Train loss 0.26 on epoch=4
05/28/2022 06:23:19 - INFO - __main__ - Global step 500 Train loss 0.22 Classification-F1 0.4576343804584267 on epoch=4
05/28/2022 06:23:19 - INFO - __main__ - Saving model with best Classification-F1: 0.3689439934249983 -> 0.4576343804584267 on epoch=4, global_step=500
05/28/2022 06:23:21 - INFO - __main__ - Step 510 Global step 510 Train loss 0.22 on epoch=4
05/28/2022 06:23:24 - INFO - __main__ - Step 520 Global step 520 Train loss 0.21 on epoch=4
05/28/2022 06:23:26 - INFO - __main__ - Step 530 Global step 530 Train loss 0.13 on epoch=4
05/28/2022 06:23:29 - INFO - __main__ - Step 540 Global step 540 Train loss 0.16 on epoch=4
05/28/2022 06:23:32 - INFO - __main__ - Step 550 Global step 550 Train loss 0.17 on epoch=4
05/28/2022 06:24:23 - INFO - __main__ - Global step 550 Train loss 0.18 Classification-F1 0.4561055560050309 on epoch=4
05/28/2022 06:24:25 - INFO - __main__ - Step 560 Global step 560 Train loss 0.25 on epoch=4
05/28/2022 06:24:28 - INFO - __main__ - Step 570 Global step 570 Train loss 0.16 on epoch=5
05/28/2022 06:24:31 - INFO - __main__ - Step 580 Global step 580 Train loss 0.13 on epoch=5
05/28/2022 06:24:33 - INFO - __main__ - Step 590 Global step 590 Train loss 0.12 on epoch=5
05/28/2022 06:24:36 - INFO - __main__ - Step 600 Global step 600 Train loss 0.16 on epoch=5
05/28/2022 06:25:27 - INFO - __main__ - Global step 600 Train loss 0.16 Classification-F1 0.45727730657434607 on epoch=5
05/28/2022 06:25:29 - INFO - __main__ - Step 610 Global step 610 Train loss 0.16 on epoch=5
05/28/2022 06:25:32 - INFO - __main__ - Step 620 Global step 620 Train loss 0.18 on epoch=5
05/28/2022 06:25:34 - INFO - __main__ - Step 630 Global step 630 Train loss 0.12 on epoch=5
05/28/2022 06:25:37 - INFO - __main__ - Step 640 Global step 640 Train loss 0.11 on epoch=5
05/28/2022 06:25:39 - INFO - __main__ - Step 650 Global step 650 Train loss 0.12 on epoch=5
05/28/2022 06:26:30 - INFO - __main__ - Global step 650 Train loss 0.14 Classification-F1 0.49333111086581355 on epoch=5
05/28/2022 06:26:30 - INFO - __main__ - Saving model with best Classification-F1: 0.4576343804584267 -> 0.49333111086581355 on epoch=5, global_step=650
05/28/2022 06:26:33 - INFO - __main__ - Step 660 Global step 660 Train loss 0.12 on epoch=5
05/28/2022 06:26:35 - INFO - __main__ - Step 670 Global step 670 Train loss 0.11 on epoch=5
05/28/2022 06:26:38 - INFO - __main__ - Step 680 Global step 680 Train loss 0.13 on epoch=6
05/28/2022 06:26:40 - INFO - __main__ - Step 690 Global step 690 Train loss 0.14 on epoch=6
05/28/2022 06:26:43 - INFO - __main__ - Step 700 Global step 700 Train loss 0.20 on epoch=6
05/28/2022 06:27:33 - INFO - __main__ - Global step 700 Train loss 0.14 Classification-F1 0.5441370492467889 on epoch=6
05/28/2022 06:27:34 - INFO - __main__ - Saving model with best Classification-F1: 0.49333111086581355 -> 0.5441370492467889 on epoch=6, global_step=700
05/28/2022 06:27:36 - INFO - __main__ - Step 710 Global step 710 Train loss 0.17 on epoch=6
05/28/2022 06:27:39 - INFO - __main__ - Step 720 Global step 720 Train loss 0.13 on epoch=6
05/28/2022 06:27:41 - INFO - __main__ - Step 730 Global step 730 Train loss 0.12 on epoch=6
05/28/2022 06:27:44 - INFO - __main__ - Step 740 Global step 740 Train loss 0.15 on epoch=6
05/28/2022 06:27:47 - INFO - __main__ - Step 750 Global step 750 Train loss 0.08 on epoch=6
05/28/2022 06:28:36 - INFO - __main__ - Global step 750 Train loss 0.13 Classification-F1 0.5271221557896321 on epoch=6
05/28/2022 06:28:39 - INFO - __main__ - Step 760 Global step 760 Train loss 0.12 on epoch=6
05/28/2022 06:28:41 - INFO - __main__ - Step 770 Global step 770 Train loss 0.10 on epoch=6
05/28/2022 06:28:44 - INFO - __main__ - Step 780 Global step 780 Train loss 0.12 on epoch=6
05/28/2022 06:28:46 - INFO - __main__ - Step 790 Global step 790 Train loss 0.09 on epoch=7
05/28/2022 06:28:49 - INFO - __main__ - Step 800 Global step 800 Train loss 0.06 on epoch=7
05/28/2022 06:29:41 - INFO - __main__ - Global step 800 Train loss 0.10 Classification-F1 0.5511394756000921 on epoch=7
05/28/2022 06:29:41 - INFO - __main__ - Saving model with best Classification-F1: 0.5441370492467889 -> 0.5511394756000921 on epoch=7, global_step=800
05/28/2022 06:29:43 - INFO - __main__ - Step 810 Global step 810 Train loss 0.11 on epoch=7
05/28/2022 06:29:46 - INFO - __main__ - Step 820 Global step 820 Train loss 0.16 on epoch=7
05/28/2022 06:29:48 - INFO - __main__ - Step 830 Global step 830 Train loss 0.10 on epoch=7
05/28/2022 06:29:51 - INFO - __main__ - Step 840 Global step 840 Train loss 0.10 on epoch=7
05/28/2022 06:29:53 - INFO - __main__ - Step 850 Global step 850 Train loss 0.11 on epoch=7
05/28/2022 06:30:44 - INFO - __main__ - Global step 850 Train loss 0.12 Classification-F1 0.5416767413596476 on epoch=7
05/28/2022 06:30:47 - INFO - __main__ - Step 860 Global step 860 Train loss 0.20 on epoch=7
05/28/2022 06:30:50 - INFO - __main__ - Step 870 Global step 870 Train loss 0.10 on epoch=7
05/28/2022 06:30:52 - INFO - __main__ - Step 880 Global step 880 Train loss 0.09 on epoch=7
05/28/2022 06:30:55 - INFO - __main__ - Step 890 Global step 890 Train loss 0.11 on epoch=7
05/28/2022 06:30:57 - INFO - __main__ - Step 900 Global step 900 Train loss 0.14 on epoch=8
05/28/2022 06:31:47 - INFO - __main__ - Global step 900 Train loss 0.13 Classification-F1 0.5427867156820161 on epoch=8
05/28/2022 06:31:50 - INFO - __main__ - Step 910 Global step 910 Train loss 0.08 on epoch=8
05/28/2022 06:31:53 - INFO - __main__ - Step 920 Global step 920 Train loss 0.06 on epoch=8
05/28/2022 06:31:55 - INFO - __main__ - Step 930 Global step 930 Train loss 0.14 on epoch=8
05/28/2022 06:31:58 - INFO - __main__ - Step 940 Global step 940 Train loss 0.10 on epoch=8
05/28/2022 06:32:00 - INFO - __main__ - Step 950 Global step 950 Train loss 0.09 on epoch=8
05/28/2022 06:32:49 - INFO - __main__ - Global step 950 Train loss 0.09 Classification-F1 0.5218246742184138 on epoch=8
05/28/2022 06:32:52 - INFO - __main__ - Step 960 Global step 960 Train loss 0.09 on epoch=8
05/28/2022 06:32:55 - INFO - __main__ - Step 970 Global step 970 Train loss 0.08 on epoch=8
05/28/2022 06:32:58 - INFO - __main__ - Step 980 Global step 980 Train loss 0.06 on epoch=8
05/28/2022 06:33:00 - INFO - __main__ - Step 990 Global step 990 Train loss 0.07 on epoch=8
05/28/2022 06:33:03 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.06 on epoch=8
05/28/2022 06:33:52 - INFO - __main__ - Global step 1000 Train loss 0.07 Classification-F1 0.5216522624453622 on epoch=8
05/28/2022 06:33:54 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.18 on epoch=9
05/28/2022 06:33:57 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.09 on epoch=9
05/28/2022 06:34:00 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.09 on epoch=9
05/28/2022 06:34:02 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.17 on epoch=9
05/28/2022 06:34:05 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.08 on epoch=9
05/28/2022 06:34:54 - INFO - __main__ - Global step 1050 Train loss 0.12 Classification-F1 0.5578630847611092 on epoch=9
05/28/2022 06:34:54 - INFO - __main__ - Saving model with best Classification-F1: 0.5511394756000921 -> 0.5578630847611092 on epoch=9, global_step=1050
05/28/2022 06:34:56 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.12 on epoch=9
05/28/2022 06:34:59 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.09 on epoch=9
05/28/2022 06:35:02 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.07 on epoch=9
05/28/2022 06:35:04 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.06 on epoch=9
05/28/2022 06:35:07 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.07 on epoch=9
05/28/2022 06:35:56 - INFO - __main__ - Global step 1100 Train loss 0.08 Classification-F1 0.5770700606461538 on epoch=9
05/28/2022 06:35:56 - INFO - __main__ - Saving model with best Classification-F1: 0.5578630847611092 -> 0.5770700606461538 on epoch=9, global_step=1100
05/28/2022 06:35:59 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.07 on epoch=9
05/28/2022 06:36:01 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.13 on epoch=9
05/28/2022 06:36:04 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.08 on epoch=10
05/28/2022 06:36:07 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.07 on epoch=10
05/28/2022 06:36:09 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.10 on epoch=10
05/28/2022 06:36:59 - INFO - __main__ - Global step 1150 Train loss 0.09 Classification-F1 0.49649997028216275 on epoch=10
05/28/2022 06:37:01 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.07 on epoch=10
05/28/2022 06:37:04 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.10 on epoch=10
05/28/2022 06:37:06 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.05 on epoch=10
05/28/2022 06:37:09 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.12 on epoch=10
05/28/2022 06:37:12 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.06 on epoch=10
05/28/2022 06:38:01 - INFO - __main__ - Global step 1200 Train loss 0.08 Classification-F1 0.5384947422555826 on epoch=10
05/28/2022 06:38:03 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.14 on epoch=10
05/28/2022 06:38:06 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.08 on epoch=10
05/28/2022 06:38:09 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.08 on epoch=10
05/28/2022 06:38:11 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.07 on epoch=11
05/28/2022 06:38:14 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.03 on epoch=11
05/28/2022 06:39:04 - INFO - __main__ - Global step 1250 Train loss 0.08 Classification-F1 0.6123699232700984 on epoch=11
05/28/2022 06:39:04 - INFO - __main__ - Saving model with best Classification-F1: 0.5770700606461538 -> 0.6123699232700984 on epoch=11, global_step=1250
05/28/2022 06:39:06 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.05 on epoch=11
05/28/2022 06:39:09 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.11 on epoch=11
05/28/2022 06:39:12 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.12 on epoch=11
05/28/2022 06:39:14 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.07 on epoch=11
05/28/2022 06:39:17 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.14 on epoch=11
05/28/2022 06:40:06 - INFO - __main__ - Global step 1300 Train loss 0.10 Classification-F1 0.49384838536045195 on epoch=11
05/28/2022 06:40:08 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.09 on epoch=11
05/28/2022 06:40:11 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.05 on epoch=11
05/28/2022 06:40:14 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.07 on epoch=11
05/28/2022 06:40:16 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.06 on epoch=11
05/28/2022 06:40:19 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.04 on epoch=12
05/28/2022 06:41:08 - INFO - __main__ - Global step 1350 Train loss 0.06 Classification-F1 0.4745244387097562 on epoch=12
05/28/2022 06:41:10 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.02 on epoch=12
05/28/2022 06:41:13 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.07 on epoch=12
05/28/2022 06:41:16 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.07 on epoch=12
05/28/2022 06:41:18 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.07 on epoch=12
05/28/2022 06:41:21 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.11 on epoch=12
05/28/2022 06:42:10 - INFO - __main__ - Global step 1400 Train loss 0.07 Classification-F1 0.5199974571822185 on epoch=12
05/28/2022 06:42:13 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.04 on epoch=12
05/28/2022 06:42:16 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.05 on epoch=12
05/28/2022 06:42:18 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.04 on epoch=12
05/28/2022 06:42:21 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=12
05/28/2022 06:42:24 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.06 on epoch=12
05/28/2022 06:43:14 - INFO - __main__ - Global step 1450 Train loss 0.04 Classification-F1 0.5790422471885375 on epoch=12
05/28/2022 06:43:16 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.07 on epoch=13
05/28/2022 06:43:19 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.02 on epoch=13
05/28/2022 06:43:22 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.04 on epoch=13
05/28/2022 06:43:24 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.15 on epoch=13
05/28/2022 06:43:27 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.05 on epoch=13
05/28/2022 06:44:16 - INFO - __main__ - Global step 1500 Train loss 0.07 Classification-F1 0.5696102363536336 on epoch=13
05/28/2022 06:44:19 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.08 on epoch=13
05/28/2022 06:44:22 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.06 on epoch=13
05/28/2022 06:44:25 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.14 on epoch=13
05/28/2022 06:44:27 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.07 on epoch=13
05/28/2022 06:44:30 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.07 on epoch=13
05/28/2022 06:45:19 - INFO - __main__ - Global step 1550 Train loss 0.08 Classification-F1 0.5035533130616869 on epoch=13
05/28/2022 06:45:21 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.07 on epoch=13
05/28/2022 06:45:24 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.03 on epoch=14
05/28/2022 06:45:27 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.02 on epoch=14
05/28/2022 06:45:29 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.05 on epoch=14
05/28/2022 06:45:32 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.05 on epoch=14
05/28/2022 06:46:21 - INFO - __main__ - Global step 1600 Train loss 0.04 Classification-F1 0.5149877107444039 on epoch=14
05/28/2022 06:46:23 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.06 on epoch=14
05/28/2022 06:46:26 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.13 on epoch=14
05/28/2022 06:46:29 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.05 on epoch=14
05/28/2022 06:46:32 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.07 on epoch=14
05/28/2022 06:46:34 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.04 on epoch=14
05/28/2022 06:47:23 - INFO - __main__ - Global step 1650 Train loss 0.07 Classification-F1 0.5007537378508211 on epoch=14
05/28/2022 06:47:25 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.05 on epoch=14
05/28/2022 06:47:28 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.04 on epoch=14
05/28/2022 06:47:31 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.07 on epoch=14
05/28/2022 06:47:33 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.03 on epoch=15
05/28/2022 06:47:36 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=15
05/28/2022 06:48:25 - INFO - __main__ - Global step 1700 Train loss 0.05 Classification-F1 0.5945974712637092 on epoch=15
05/28/2022 06:48:28 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.05 on epoch=15
05/28/2022 06:48:30 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.04 on epoch=15
05/28/2022 06:48:33 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.07 on epoch=15
05/28/2022 06:48:35 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.04 on epoch=15
05/28/2022 06:48:38 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.06 on epoch=15
05/28/2022 06:49:26 - INFO - __main__ - Global step 1750 Train loss 0.05 Classification-F1 0.6364784525060004 on epoch=15
05/28/2022 06:49:26 - INFO - __main__ - Saving model with best Classification-F1: 0.6123699232700984 -> 0.6364784525060004 on epoch=15, global_step=1750
05/28/2022 06:49:29 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.10 on epoch=15
05/28/2022 06:49:31 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.05 on epoch=15
05/28/2022 06:49:34 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.06 on epoch=15
05/28/2022 06:49:37 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.07 on epoch=15
05/28/2022 06:49:39 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.05 on epoch=16
05/28/2022 06:50:29 - INFO - __main__ - Global step 1800 Train loss 0.06 Classification-F1 0.4946431480421501 on epoch=16
05/28/2022 06:50:32 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=16
05/28/2022 06:50:35 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.05 on epoch=16
05/28/2022 06:50:37 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.06 on epoch=16
05/28/2022 06:50:40 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=16
05/28/2022 06:50:42 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.06 on epoch=16
05/28/2022 06:51:31 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.5517977954723763 on epoch=16
05/28/2022 06:51:33 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.05 on epoch=16
05/28/2022 06:51:36 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.05 on epoch=16
05/28/2022 06:51:39 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.03 on epoch=16
05/28/2022 06:51:41 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.03 on epoch=16
05/28/2022 06:51:44 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.04 on epoch=16
05/28/2022 06:52:33 - INFO - __main__ - Global step 1900 Train loss 0.04 Classification-F1 0.6295745196619451 on epoch=16
05/28/2022 06:52:35 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.04 on epoch=17
05/28/2022 06:52:38 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=17
05/28/2022 06:52:41 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.04 on epoch=17
05/28/2022 06:52:44 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.04 on epoch=17
05/28/2022 06:52:46 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=17
05/28/2022 06:53:34 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.5616999100544086 on epoch=17
05/28/2022 06:53:37 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.07 on epoch=17
05/28/2022 06:53:40 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.06 on epoch=17
05/28/2022 06:53:43 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=17
05/28/2022 06:53:45 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.04 on epoch=17
05/28/2022 06:53:48 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.05 on epoch=17
05/28/2022 06:54:36 - INFO - __main__ - Global step 2000 Train loss 0.05 Classification-F1 0.4855926829564831 on epoch=17
05/28/2022 06:54:39 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.03 on epoch=17
05/28/2022 06:54:41 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.07 on epoch=18
05/28/2022 06:54:44 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.03 on epoch=18
05/28/2022 06:54:47 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=18
05/28/2022 06:54:50 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.05 on epoch=18
05/28/2022 06:55:39 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.4524323923798246 on epoch=18
05/28/2022 06:55:42 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.04 on epoch=18
05/28/2022 06:55:44 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.03 on epoch=18
05/28/2022 06:55:47 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.04 on epoch=18
05/28/2022 06:55:50 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.08 on epoch=18
05/28/2022 06:55:52 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=18
05/28/2022 06:56:41 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.5786007580886902 on epoch=18
05/28/2022 06:56:43 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=18
05/28/2022 06:56:46 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=18
05/28/2022 06:56:49 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=19
05/28/2022 06:56:51 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=19
05/28/2022 06:56:54 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=19
05/28/2022 06:57:42 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.43656853284416386 on epoch=19
05/28/2022 06:57:45 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.03 on epoch=19
05/28/2022 06:57:47 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.05 on epoch=19
05/28/2022 06:57:50 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.07 on epoch=19
05/28/2022 06:57:53 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.08 on epoch=19
05/28/2022 06:57:56 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.05 on epoch=19
05/28/2022 06:58:43 - INFO - __main__ - Global step 2200 Train loss 0.06 Classification-F1 0.5506992555919198 on epoch=19
05/28/2022 06:58:46 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.03 on epoch=19
05/28/2022 06:58:48 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=19
05/28/2022 06:58:51 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.03 on epoch=19
05/28/2022 06:58:54 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.03 on epoch=19
05/28/2022 06:58:56 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.05 on epoch=20
05/28/2022 06:59:45 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.5394623495811796 on epoch=20
05/28/2022 06:59:48 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=20
05/28/2022 06:59:50 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=20
05/28/2022 06:59:53 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=20
05/28/2022 06:59:56 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.07 on epoch=20
05/28/2022 06:59:58 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.04 on epoch=20
05/28/2022 07:00:47 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.4949140064059395 on epoch=20
05/28/2022 07:00:49 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.06 on epoch=20
05/28/2022 07:00:52 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.06 on epoch=20
05/28/2022 07:00:55 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=20
05/28/2022 07:00:58 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.04 on epoch=20
05/28/2022 07:01:00 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.04 on epoch=20
05/28/2022 07:01:49 - INFO - __main__ - Global step 2350 Train loss 0.05 Classification-F1 0.5236893277347306 on epoch=20
05/28/2022 07:01:52 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=21
05/28/2022 07:01:55 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.03 on epoch=21
05/28/2022 07:01:57 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.06 on epoch=21
05/28/2022 07:02:00 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=21
05/28/2022 07:02:03 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=21
05/28/2022 07:02:51 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.45513513498136937 on epoch=21
05/28/2022 07:02:53 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.06 on epoch=21
05/28/2022 07:02:56 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.05 on epoch=21
05/28/2022 07:02:59 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.04 on epoch=21
05/28/2022 07:03:02 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=21
05/28/2022 07:03:04 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=21
05/28/2022 07:03:52 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.4498532286770836 on epoch=21
05/28/2022 07:03:55 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=21
05/28/2022 07:03:57 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=22
05/28/2022 07:04:00 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=22
05/28/2022 07:04:03 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=22
05/28/2022 07:04:05 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.06 on epoch=22
05/28/2022 07:04:54 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.45679408836805696 on epoch=22
05/28/2022 07:04:56 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.03 on epoch=22
05/28/2022 07:04:59 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.09 on epoch=22
05/28/2022 07:05:01 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.03 on epoch=22
05/28/2022 07:05:04 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.03 on epoch=22
05/28/2022 07:05:07 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=22
05/28/2022 07:05:54 - INFO - __main__ - Global step 2550 Train loss 0.04 Classification-F1 0.5867297974266595 on epoch=22
05/28/2022 07:05:57 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=22
05/28/2022 07:06:00 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=22
05/28/2022 07:06:02 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.03 on epoch=23
05/28/2022 07:06:05 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=23
05/28/2022 07:06:08 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=23
05/28/2022 07:06:56 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.7020412832208894 on epoch=23
05/28/2022 07:06:56 - INFO - __main__ - Saving model with best Classification-F1: 0.6364784525060004 -> 0.7020412832208894 on epoch=23, global_step=2600
05/28/2022 07:06:59 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.08 on epoch=23
05/28/2022 07:07:02 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.05 on epoch=23
05/28/2022 07:07:04 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.07 on epoch=23
05/28/2022 07:07:07 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=23
05/28/2022 07:07:10 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.03 on epoch=23
05/28/2022 07:07:58 - INFO - __main__ - Global step 2650 Train loss 0.05 Classification-F1 0.6933684548981389 on epoch=23
05/28/2022 07:08:01 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.04 on epoch=23
05/28/2022 07:08:04 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=23
05/28/2022 07:08:06 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=23
05/28/2022 07:08:09 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=24
05/28/2022 07:08:12 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=24
05/28/2022 07:09:01 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.6156489906600853 on epoch=24
05/28/2022 07:09:04 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=24
05/28/2022 07:09:06 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=24
05/28/2022 07:09:09 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.05 on epoch=24
05/28/2022 07:09:11 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.09 on epoch=24
05/28/2022 07:09:14 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=24
05/28/2022 07:10:02 - INFO - __main__ - Global step 2750 Train loss 0.04 Classification-F1 0.5821810492825134 on epoch=24
05/28/2022 07:10:05 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.03 on epoch=24
05/28/2022 07:10:08 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.03 on epoch=24
05/28/2022 07:10:10 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=24
05/28/2022 07:10:13 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=24
05/28/2022 07:10:15 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=24
05/28/2022 07:11:04 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.45970253487823676 on epoch=24
05/28/2022 07:11:06 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=25
05/28/2022 07:11:09 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=25
05/28/2022 07:11:12 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=25
05/28/2022 07:11:15 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.03 on epoch=25
05/28/2022 07:11:17 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.05 on epoch=25
05/28/2022 07:12:06 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.5754722865037001 on epoch=25
05/28/2022 07:12:09 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.03 on epoch=25
05/28/2022 07:12:11 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.03 on epoch=25
05/28/2022 07:12:14 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=25
05/28/2022 07:12:17 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=25
05/28/2022 07:12:19 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.03 on epoch=25
05/28/2022 07:13:08 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.6646167574646717 on epoch=25
05/28/2022 07:13:11 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.04 on epoch=25
05/28/2022 07:13:14 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=26
05/28/2022 07:13:16 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=26
05/28/2022 07:13:19 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=26
05/28/2022 07:13:22 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=26
05/28/2022 07:14:11 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.6481622446745191 on epoch=26
05/28/2022 07:14:14 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.04 on epoch=26
05/28/2022 07:14:16 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.07 on epoch=26
05/28/2022 07:14:19 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.04 on epoch=26
05/28/2022 07:14:22 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=26
05/28/2022 07:14:24 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=26
05/28/2022 07:14:26 - INFO - __main__ - Start tokenizing ... 1792 instances
05/28/2022 07:14:26 - INFO - __main__ - Printing 3 examples
05/28/2022 07:14:26 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/28/2022 07:14:26 - INFO - __main__ - ['Plant']
05/28/2022 07:14:26 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/28/2022 07:14:26 - INFO - __main__ - ['Plant']
05/28/2022 07:14:26 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/28/2022 07:14:26 - INFO - __main__ - ['Plant']
05/28/2022 07:14:26 - INFO - __main__ - Tokenizing Input ...
05/28/2022 07:14:27 - INFO - __main__ - Tokenizing Output ...
05/28/2022 07:14:28 - INFO - __main__ - Loaded 1792 examples from train data
05/28/2022 07:14:28 - INFO - __main__ - Start tokenizing ... 1792 instances
05/28/2022 07:14:28 - INFO - __main__ - Printing 3 examples
05/28/2022 07:14:28 - INFO - __main__ -  [dbpedia_14] Sabal pumos is a species of flowering plant in the palm tree family Arecaceae. It is native to the dry forests along the Balsas River in central Mexico (Guanajuato Guerrero Jalisco Michoacán Morelos Zacatecas and the State of México). It is threatened by habitat loss.
05/28/2022 07:14:28 - INFO - __main__ - ['Plant']
05/28/2022 07:14:28 - INFO - __main__ -  [dbpedia_14] Bulbophyllum intricatum is a species of orchid in the genus Bulbophyllum.
05/28/2022 07:14:28 - INFO - __main__ - ['Plant']
05/28/2022 07:14:28 - INFO - __main__ -  [dbpedia_14] Gentiana parryi (Parry's Gentian) is a species of the genus Gentiana.
05/28/2022 07:14:28 - INFO - __main__ - ['Plant']
05/28/2022 07:14:28 - INFO - __main__ - Tokenizing Input ...
05/28/2022 07:14:29 - INFO - __main__ - Tokenizing Output ...
05/28/2022 07:14:31 - INFO - __main__ - Loaded 1792 examples from dev data
05/28/2022 07:14:46 - INFO - __main__ - load prompt embedding from ckpt
05/28/2022 07:14:47 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/28/2022 07:14:47 - INFO - __main__ - Starting training!
05/28/2022 07:15:13 - INFO - __main__ - Global step 3000 Train loss 0.04 Classification-F1 0.7044014728166386 on epoch=26
05/28/2022 07:15:13 - INFO - __main__ - Saving model with best Classification-F1: 0.7020412832208894 -> 0.7044014728166386 on epoch=26, global_step=3000
05/28/2022 07:15:13 - INFO - __main__ - save last model!
05/28/2022 07:15:13 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/28/2022 07:15:13 - INFO - __main__ - Start tokenizing ... 3500 instances
05/28/2022 07:15:13 - INFO - __main__ - Printing 3 examples
05/28/2022 07:15:13 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/28/2022 07:15:13 - INFO - __main__ - ['Animal']
05/28/2022 07:15:13 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/28/2022 07:15:13 - INFO - __main__ - ['Animal']
05/28/2022 07:15:13 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/28/2022 07:15:13 - INFO - __main__ - ['Village']
05/28/2022 07:15:13 - INFO - __main__ - Tokenizing Input ...
05/28/2022 07:15:15 - INFO - __main__ - Tokenizing Output ...
05/28/2022 07:15:18 - INFO - __main__ - Loaded 3500 examples from test data
05/28/2022 07:17:19 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down128shot/singletask-dbpedia_14/dbpedia_14_128_21_0.5_8_predictions.txt
05/28/2022 07:17:19 - INFO - __main__ - Classification-F1 on test data: 0.6356
05/28/2022 07:17:20 - INFO - __main__ - prefix=dbpedia_14_128_21, lr=0.5, bsz=8, dev_performance=0.7044014728166386, test_performance=0.635608066437411
05/28/2022 07:17:20 - INFO - __main__ - Running ... prefix=dbpedia_14_128_21, lr=0.4, bsz=8 ...
05/28/2022 07:17:20 - INFO - __main__ - Start tokenizing ... 1792 instances
05/28/2022 07:17:20 - INFO - __main__ - Printing 3 examples
05/28/2022 07:17:20 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/28/2022 07:17:20 - INFO - __main__ - ['Plant']
05/28/2022 07:17:20 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/28/2022 07:17:20 - INFO - __main__ - ['Plant']
05/28/2022 07:17:20 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/28/2022 07:17:20 - INFO - __main__ - ['Plant']
05/28/2022 07:17:20 - INFO - __main__ - Tokenizing Input ...
05/28/2022 07:17:21 - INFO - __main__ - Tokenizing Output ...
05/28/2022 07:17:23 - INFO - __main__ - Loaded 1792 examples from train data
05/28/2022 07:17:23 - INFO - __main__ - Start tokenizing ... 1792 instances
05/28/2022 07:17:23 - INFO - __main__ - Printing 3 examples
05/28/2022 07:17:23 - INFO - __main__ -  [dbpedia_14] Sabal pumos is a species of flowering plant in the palm tree family Arecaceae. It is native to the dry forests along the Balsas River in central Mexico (Guanajuato Guerrero Jalisco Michoacán Morelos Zacatecas and the State of México). It is threatened by habitat loss.
05/28/2022 07:17:23 - INFO - __main__ - ['Plant']
05/28/2022 07:17:23 - INFO - __main__ -  [dbpedia_14] Bulbophyllum intricatum is a species of orchid in the genus Bulbophyllum.
05/28/2022 07:17:23 - INFO - __main__ - ['Plant']
05/28/2022 07:17:23 - INFO - __main__ -  [dbpedia_14] Gentiana parryi (Parry's Gentian) is a species of the genus Gentiana.
05/28/2022 07:17:23 - INFO - __main__ - ['Plant']
05/28/2022 07:17:23 - INFO - __main__ - Tokenizing Input ...
05/28/2022 07:17:24 - INFO - __main__ - Tokenizing Output ...
05/28/2022 07:17:26 - INFO - __main__ - Loaded 1792 examples from dev data
05/28/2022 07:17:44 - INFO - __main__ - load prompt embedding from ckpt
05/28/2022 07:17:44 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/28/2022 07:17:44 - INFO - __main__ - Starting training!
05/28/2022 07:17:48 - INFO - __main__ - Step 10 Global step 10 Train loss 7.40 on epoch=0
05/28/2022 07:17:51 - INFO - __main__ - Step 20 Global step 20 Train loss 5.32 on epoch=0
05/28/2022 07:17:54 - INFO - __main__ - Step 30 Global step 30 Train loss 4.28 on epoch=0
05/28/2022 07:17:56 - INFO - __main__ - Step 40 Global step 40 Train loss 3.90 on epoch=0
05/28/2022 07:17:59 - INFO - __main__ - Step 50 Global step 50 Train loss 3.55 on epoch=0
05/28/2022 07:18:50 - INFO - __main__ - Global step 50 Train loss 4.89 Classification-F1 0.013811928573157032 on epoch=0
05/28/2022 07:18:50 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.013811928573157032 on epoch=0, global_step=50
05/28/2022 07:18:53 - INFO - __main__ - Step 60 Global step 60 Train loss 2.87 on epoch=0
05/28/2022 07:18:55 - INFO - __main__ - Step 70 Global step 70 Train loss 2.48 on epoch=0
05/28/2022 07:18:59 - INFO - __main__ - Step 80 Global step 80 Train loss 2.76 on epoch=0
05/28/2022 07:19:02 - INFO - __main__ - Step 90 Global step 90 Train loss 2.22 on epoch=0
05/28/2022 07:19:04 - INFO - __main__ - Step 100 Global step 100 Train loss 1.75 on epoch=0
05/28/2022 07:19:51 - INFO - __main__ - Global step 100 Train loss 2.41 Classification-F1 0.03366976959494379 on epoch=0
05/28/2022 07:19:51 - INFO - __main__ - Saving model with best Classification-F1: 0.013811928573157032 -> 0.03366976959494379 on epoch=0, global_step=100
05/28/2022 07:19:54 - INFO - __main__ - Step 110 Global step 110 Train loss 1.93 on epoch=0
05/28/2022 07:19:57 - INFO - __main__ - Step 120 Global step 120 Train loss 1.99 on epoch=1
05/28/2022 07:19:59 - INFO - __main__ - Step 130 Global step 130 Train loss 1.74 on epoch=1
05/28/2022 07:20:02 - INFO - __main__ - Step 140 Global step 140 Train loss 1.71 on epoch=1
05/28/2022 07:20:05 - INFO - __main__ - Step 150 Global step 150 Train loss 1.40 on epoch=1
05/28/2022 07:20:49 - INFO - __main__ - Global step 150 Train loss 1.75 Classification-F1 0.07817454113996382 on epoch=1
05/28/2022 07:20:49 - INFO - __main__ - Saving model with best Classification-F1: 0.03366976959494379 -> 0.07817454113996382 on epoch=1, global_step=150
05/28/2022 07:20:51 - INFO - __main__ - Step 160 Global step 160 Train loss 1.34 on epoch=1
05/28/2022 07:20:54 - INFO - __main__ - Step 170 Global step 170 Train loss 1.26 on epoch=1
05/28/2022 07:20:57 - INFO - __main__ - Step 180 Global step 180 Train loss 1.22 on epoch=1
05/28/2022 07:20:59 - INFO - __main__ - Step 190 Global step 190 Train loss 1.12 on epoch=1
05/28/2022 07:21:02 - INFO - __main__ - Step 200 Global step 200 Train loss 1.00 on epoch=1
05/28/2022 07:21:47 - INFO - __main__ - Global step 200 Train loss 1.19 Classification-F1 0.13002372115576374 on epoch=1
05/28/2022 07:21:47 - INFO - __main__ - Saving model with best Classification-F1: 0.07817454113996382 -> 0.13002372115576374 on epoch=1, global_step=200
05/28/2022 07:21:50 - INFO - __main__ - Step 210 Global step 210 Train loss 0.94 on epoch=1
05/28/2022 07:21:52 - INFO - __main__ - Step 220 Global step 220 Train loss 0.79 on epoch=1
05/28/2022 07:21:55 - INFO - __main__ - Step 230 Global step 230 Train loss 0.80 on epoch=2
05/28/2022 07:21:58 - INFO - __main__ - Step 240 Global step 240 Train loss 0.73 on epoch=2
05/28/2022 07:22:00 - INFO - __main__ - Step 250 Global step 250 Train loss 0.71 on epoch=2
05/28/2022 07:22:49 - INFO - __main__ - Global step 250 Train loss 0.79 Classification-F1 0.18134603581600336 on epoch=2
05/28/2022 07:22:49 - INFO - __main__ - Saving model with best Classification-F1: 0.13002372115576374 -> 0.18134603581600336 on epoch=2, global_step=250
05/28/2022 07:22:51 - INFO - __main__ - Step 260 Global step 260 Train loss 0.65 on epoch=2
05/28/2022 07:22:54 - INFO - __main__ - Step 270 Global step 270 Train loss 0.59 on epoch=2
05/28/2022 07:22:56 - INFO - __main__ - Step 280 Global step 280 Train loss 0.60 on epoch=2
05/28/2022 07:22:59 - INFO - __main__ - Step 290 Global step 290 Train loss 0.62 on epoch=2
05/28/2022 07:23:02 - INFO - __main__ - Step 300 Global step 300 Train loss 0.47 on epoch=2
05/28/2022 07:23:54 - INFO - __main__ - Global step 300 Train loss 0.58 Classification-F1 0.24160727321036804 on epoch=2
05/28/2022 07:23:54 - INFO - __main__ - Saving model with best Classification-F1: 0.18134603581600336 -> 0.24160727321036804 on epoch=2, global_step=300
05/28/2022 07:23:56 - INFO - __main__ - Step 310 Global step 310 Train loss 0.60 on epoch=2
05/28/2022 07:23:59 - INFO - __main__ - Step 320 Global step 320 Train loss 0.40 on epoch=2
05/28/2022 07:24:01 - INFO - __main__ - Step 330 Global step 330 Train loss 0.50 on epoch=2
05/28/2022 07:24:04 - INFO - __main__ - Step 340 Global step 340 Train loss 0.42 on epoch=3
05/28/2022 07:24:07 - INFO - __main__ - Step 350 Global step 350 Train loss 0.41 on epoch=3
05/28/2022 07:24:57 - INFO - __main__ - Global step 350 Train loss 0.47 Classification-F1 0.2835024091636522 on epoch=3
05/28/2022 07:24:57 - INFO - __main__ - Saving model with best Classification-F1: 0.24160727321036804 -> 0.2835024091636522 on epoch=3, global_step=350
05/28/2022 07:25:00 - INFO - __main__ - Step 360 Global step 360 Train loss 0.37 on epoch=3
05/28/2022 07:25:02 - INFO - __main__ - Step 370 Global step 370 Train loss 0.49 on epoch=3
05/28/2022 07:25:05 - INFO - __main__ - Step 380 Global step 380 Train loss 0.39 on epoch=3
05/28/2022 07:25:08 - INFO - __main__ - Step 390 Global step 390 Train loss 0.39 on epoch=3
05/28/2022 07:25:10 - INFO - __main__ - Step 400 Global step 400 Train loss 0.35 on epoch=3
05/28/2022 07:26:02 - INFO - __main__ - Global step 400 Train loss 0.40 Classification-F1 0.3992500425395455 on epoch=3
05/28/2022 07:26:02 - INFO - __main__ - Saving model with best Classification-F1: 0.2835024091636522 -> 0.3992500425395455 on epoch=3, global_step=400
05/28/2022 07:26:04 - INFO - __main__ - Step 410 Global step 410 Train loss 0.44 on epoch=3
05/28/2022 07:26:07 - INFO - __main__ - Step 420 Global step 420 Train loss 0.33 on epoch=3
05/28/2022 07:26:10 - INFO - __main__ - Step 430 Global step 430 Train loss 0.35 on epoch=3
05/28/2022 07:26:12 - INFO - __main__ - Step 440 Global step 440 Train loss 0.27 on epoch=3
05/28/2022 07:26:15 - INFO - __main__ - Step 450 Global step 450 Train loss 0.32 on epoch=4
05/28/2022 07:27:07 - INFO - __main__ - Global step 450 Train loss 0.34 Classification-F1 0.42438829366076847 on epoch=4
05/28/2022 07:27:08 - INFO - __main__ - Saving model with best Classification-F1: 0.3992500425395455 -> 0.42438829366076847 on epoch=4, global_step=450
05/28/2022 07:27:10 - INFO - __main__ - Step 460 Global step 460 Train loss 0.31 on epoch=4
05/28/2022 07:27:13 - INFO - __main__ - Step 470 Global step 470 Train loss 0.19 on epoch=4
05/28/2022 07:27:16 - INFO - __main__ - Step 480 Global step 480 Train loss 0.33 on epoch=4
05/28/2022 07:27:18 - INFO - __main__ - Step 490 Global step 490 Train loss 0.28 on epoch=4
05/28/2022 07:27:21 - INFO - __main__ - Step 500 Global step 500 Train loss 0.34 on epoch=4
05/28/2022 07:28:12 - INFO - __main__ - Global step 500 Train loss 0.29 Classification-F1 0.4333762456836104 on epoch=4
05/28/2022 07:28:12 - INFO - __main__ - Saving model with best Classification-F1: 0.42438829366076847 -> 0.4333762456836104 on epoch=4, global_step=500
05/28/2022 07:28:15 - INFO - __main__ - Step 510 Global step 510 Train loss 0.29 on epoch=4
05/28/2022 07:28:18 - INFO - __main__ - Step 520 Global step 520 Train loss 0.24 on epoch=4
05/28/2022 07:28:20 - INFO - __main__ - Step 530 Global step 530 Train loss 0.18 on epoch=4
05/28/2022 07:28:23 - INFO - __main__ - Step 540 Global step 540 Train loss 0.20 on epoch=4
05/28/2022 07:28:25 - INFO - __main__ - Step 550 Global step 550 Train loss 0.21 on epoch=4
05/28/2022 07:29:18 - INFO - __main__ - Global step 550 Train loss 0.22 Classification-F1 0.49992779370528345 on epoch=4
05/28/2022 07:29:18 - INFO - __main__ - Saving model with best Classification-F1: 0.4333762456836104 -> 0.49992779370528345 on epoch=4, global_step=550
05/28/2022 07:29:20 - INFO - __main__ - Step 560 Global step 560 Train loss 0.21 on epoch=4
05/28/2022 07:29:23 - INFO - __main__ - Step 570 Global step 570 Train loss 0.22 on epoch=5
05/28/2022 07:29:26 - INFO - __main__ - Step 580 Global step 580 Train loss 0.23 on epoch=5
05/28/2022 07:29:28 - INFO - __main__ - Step 590 Global step 590 Train loss 0.18 on epoch=5
05/28/2022 07:29:31 - INFO - __main__ - Step 600 Global step 600 Train loss 0.22 on epoch=5
05/28/2022 07:30:22 - INFO - __main__ - Global step 600 Train loss 0.21 Classification-F1 0.4529227224490897 on epoch=5
05/28/2022 07:30:24 - INFO - __main__ - Step 610 Global step 610 Train loss 0.24 on epoch=5
05/28/2022 07:30:27 - INFO - __main__ - Step 620 Global step 620 Train loss 0.17 on epoch=5
05/28/2022 07:30:29 - INFO - __main__ - Step 630 Global step 630 Train loss 0.21 on epoch=5
05/28/2022 07:30:32 - INFO - __main__ - Step 640 Global step 640 Train loss 0.19 on epoch=5
05/28/2022 07:30:34 - INFO - __main__ - Step 650 Global step 650 Train loss 0.14 on epoch=5
05/28/2022 07:31:24 - INFO - __main__ - Global step 650 Train loss 0.19 Classification-F1 0.5117393015904758 on epoch=5
05/28/2022 07:31:24 - INFO - __main__ - Saving model with best Classification-F1: 0.49992779370528345 -> 0.5117393015904758 on epoch=5, global_step=650
05/28/2022 07:31:27 - INFO - __main__ - Step 660 Global step 660 Train loss 0.13 on epoch=5
05/28/2022 07:31:30 - INFO - __main__ - Step 670 Global step 670 Train loss 0.21 on epoch=5
05/28/2022 07:31:32 - INFO - __main__ - Step 680 Global step 680 Train loss 0.18 on epoch=6
05/28/2022 07:31:35 - INFO - __main__ - Step 690 Global step 690 Train loss 0.14 on epoch=6
05/28/2022 07:31:37 - INFO - __main__ - Step 700 Global step 700 Train loss 0.21 on epoch=6
05/28/2022 07:32:28 - INFO - __main__ - Global step 700 Train loss 0.17 Classification-F1 0.5291051096391091 on epoch=6
05/28/2022 07:32:28 - INFO - __main__ - Saving model with best Classification-F1: 0.5117393015904758 -> 0.5291051096391091 on epoch=6, global_step=700
05/28/2022 07:32:30 - INFO - __main__ - Step 710 Global step 710 Train loss 0.28 on epoch=6
05/28/2022 07:32:33 - INFO - __main__ - Step 720 Global step 720 Train loss 0.13 on epoch=6
05/28/2022 07:32:35 - INFO - __main__ - Step 730 Global step 730 Train loss 0.19 on epoch=6
05/28/2022 07:32:38 - INFO - __main__ - Step 740 Global step 740 Train loss 0.16 on epoch=6
05/28/2022 07:32:41 - INFO - __main__ - Step 750 Global step 750 Train loss 0.18 on epoch=6
05/28/2022 07:33:30 - INFO - __main__ - Global step 750 Train loss 0.19 Classification-F1 0.5423422364938706 on epoch=6
05/28/2022 07:33:30 - INFO - __main__ - Saving model with best Classification-F1: 0.5291051096391091 -> 0.5423422364938706 on epoch=6, global_step=750
05/28/2022 07:33:33 - INFO - __main__ - Step 760 Global step 760 Train loss 0.10 on epoch=6
05/28/2022 07:33:36 - INFO - __main__ - Step 770 Global step 770 Train loss 0.15 on epoch=6
05/28/2022 07:33:38 - INFO - __main__ - Step 780 Global step 780 Train loss 0.12 on epoch=6
05/28/2022 07:33:41 - INFO - __main__ - Step 790 Global step 790 Train loss 0.18 on epoch=7
05/28/2022 07:33:44 - INFO - __main__ - Step 800 Global step 800 Train loss 0.11 on epoch=7
05/28/2022 07:34:33 - INFO - __main__ - Global step 800 Train loss 0.13 Classification-F1 0.5633340824793269 on epoch=7
05/28/2022 07:34:33 - INFO - __main__ - Saving model with best Classification-F1: 0.5423422364938706 -> 0.5633340824793269 on epoch=7, global_step=800
05/28/2022 07:34:36 - INFO - __main__ - Step 810 Global step 810 Train loss 0.10 on epoch=7
05/28/2022 07:34:38 - INFO - __main__ - Step 820 Global step 820 Train loss 0.23 on epoch=7
05/28/2022 07:34:41 - INFO - __main__ - Step 830 Global step 830 Train loss 0.16 on epoch=7
05/28/2022 07:34:43 - INFO - __main__ - Step 840 Global step 840 Train loss 0.18 on epoch=7
05/28/2022 07:34:46 - INFO - __main__ - Step 850 Global step 850 Train loss 0.16 on epoch=7
05/28/2022 07:35:36 - INFO - __main__ - Global step 850 Train loss 0.16 Classification-F1 0.5628925842394222 on epoch=7
05/28/2022 07:35:38 - INFO - __main__ - Step 860 Global step 860 Train loss 0.19 on epoch=7
05/28/2022 07:35:41 - INFO - __main__ - Step 870 Global step 870 Train loss 0.10 on epoch=7
05/28/2022 07:35:43 - INFO - __main__ - Step 880 Global step 880 Train loss 0.10 on epoch=7
05/28/2022 07:35:46 - INFO - __main__ - Step 890 Global step 890 Train loss 0.13 on epoch=7
05/28/2022 07:35:49 - INFO - __main__ - Step 900 Global step 900 Train loss 0.13 on epoch=8
05/28/2022 07:36:38 - INFO - __main__ - Global step 900 Train loss 0.13 Classification-F1 0.5622563172788527 on epoch=8
05/28/2022 07:36:41 - INFO - __main__ - Step 910 Global step 910 Train loss 0.11 on epoch=8
05/28/2022 07:36:44 - INFO - __main__ - Step 920 Global step 920 Train loss 0.09 on epoch=8
05/28/2022 07:36:46 - INFO - __main__ - Step 930 Global step 930 Train loss 0.17 on epoch=8
05/28/2022 07:36:49 - INFO - __main__ - Step 940 Global step 940 Train loss 0.10 on epoch=8
05/28/2022 07:36:51 - INFO - __main__ - Step 950 Global step 950 Train loss 0.13 on epoch=8
05/28/2022 07:37:41 - INFO - __main__ - Global step 950 Train loss 0.12 Classification-F1 0.5155857951008914 on epoch=8
05/28/2022 07:37:43 - INFO - __main__ - Step 960 Global step 960 Train loss 0.12 on epoch=8
05/28/2022 07:37:46 - INFO - __main__ - Step 970 Global step 970 Train loss 0.15 on epoch=8
05/28/2022 07:37:49 - INFO - __main__ - Step 980 Global step 980 Train loss 0.12 on epoch=8
05/28/2022 07:37:51 - INFO - __main__ - Step 990 Global step 990 Train loss 0.11 on epoch=8
05/28/2022 07:37:54 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.07 on epoch=8
05/28/2022 07:38:43 - INFO - __main__ - Global step 1000 Train loss 0.12 Classification-F1 0.541944169868346 on epoch=8
05/28/2022 07:38:46 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.07 on epoch=9
05/28/2022 07:38:49 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.10 on epoch=9
05/28/2022 07:38:51 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.06 on epoch=9
05/28/2022 07:38:54 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.13 on epoch=9
05/28/2022 07:38:57 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.15 on epoch=9
05/28/2022 07:39:47 - INFO - __main__ - Global step 1050 Train loss 0.10 Classification-F1 0.6042911241131673 on epoch=9
05/28/2022 07:39:47 - INFO - __main__ - Saving model with best Classification-F1: 0.5633340824793269 -> 0.6042911241131673 on epoch=9, global_step=1050
05/28/2022 07:39:50 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.11 on epoch=9
05/28/2022 07:39:52 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.16 on epoch=9
05/28/2022 07:39:55 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.14 on epoch=9
05/28/2022 07:39:58 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.05 on epoch=9
05/28/2022 07:40:00 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.08 on epoch=9
05/28/2022 07:40:51 - INFO - __main__ - Global step 1100 Train loss 0.11 Classification-F1 0.5514603529598642 on epoch=9
05/28/2022 07:40:54 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.07 on epoch=9
05/28/2022 07:40:57 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.17 on epoch=9
05/28/2022 07:40:59 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.06 on epoch=10
05/28/2022 07:41:02 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.11 on epoch=10
05/28/2022 07:41:05 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.18 on epoch=10
05/28/2022 07:41:55 - INFO - __main__ - Global step 1150 Train loss 0.12 Classification-F1 0.5565941391604055 on epoch=10
05/28/2022 07:41:58 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.07 on epoch=10
05/28/2022 07:42:00 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.11 on epoch=10
05/28/2022 07:42:03 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.12 on epoch=10
05/28/2022 07:42:05 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.07 on epoch=10
05/28/2022 07:42:08 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.06 on epoch=10
05/28/2022 07:42:57 - INFO - __main__ - Global step 1200 Train loss 0.09 Classification-F1 0.5689767624474662 on epoch=10
05/28/2022 07:43:00 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.06 on epoch=10
05/28/2022 07:43:02 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.09 on epoch=10
05/28/2022 07:43:05 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.04 on epoch=10
05/28/2022 07:43:08 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.12 on epoch=11
05/28/2022 07:43:10 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.06 on epoch=11
05/28/2022 07:44:00 - INFO - __main__ - Global step 1250 Train loss 0.07 Classification-F1 0.49974251211681064 on epoch=11
05/28/2022 07:44:03 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.08 on epoch=11
05/28/2022 07:44:05 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.06 on epoch=11
05/28/2022 07:44:08 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.08 on epoch=11
05/28/2022 07:44:10 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.07 on epoch=11
05/28/2022 07:44:13 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.09 on epoch=11
05/28/2022 07:45:04 - INFO - __main__ - Global step 1300 Train loss 0.08 Classification-F1 0.6065140773092489 on epoch=11
05/28/2022 07:45:04 - INFO - __main__ - Saving model with best Classification-F1: 0.6042911241131673 -> 0.6065140773092489 on epoch=11, global_step=1300
05/28/2022 07:45:07 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.07 on epoch=11
05/28/2022 07:45:09 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.09 on epoch=11
05/28/2022 07:45:12 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.10 on epoch=11
05/28/2022 07:45:14 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.10 on epoch=11
05/28/2022 07:45:17 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.11 on epoch=12
05/28/2022 07:46:07 - INFO - __main__ - Global step 1350 Train loss 0.09 Classification-F1 0.5040497072171861 on epoch=12
05/28/2022 07:46:09 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.07 on epoch=12
05/28/2022 07:46:12 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.08 on epoch=12
05/28/2022 07:46:15 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.10 on epoch=12
05/28/2022 07:46:17 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.07 on epoch=12
05/28/2022 07:46:20 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.10 on epoch=12
05/28/2022 07:47:10 - INFO - __main__ - Global step 1400 Train loss 0.08 Classification-F1 0.5805611023127996 on epoch=12
05/28/2022 07:47:12 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.11 on epoch=12
05/28/2022 07:47:15 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.06 on epoch=12
05/28/2022 07:47:18 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.06 on epoch=12
05/28/2022 07:47:20 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.04 on epoch=12
05/28/2022 07:47:23 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.07 on epoch=12
05/28/2022 07:48:13 - INFO - __main__ - Global step 1450 Train loss 0.07 Classification-F1 0.5772078087396705 on epoch=12
05/28/2022 07:48:16 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.14 on epoch=13
05/28/2022 07:48:19 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.06 on epoch=13
05/28/2022 07:48:21 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.03 on epoch=13
05/28/2022 07:48:24 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.10 on epoch=13
05/28/2022 07:48:26 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.07 on epoch=13
05/28/2022 07:49:16 - INFO - __main__ - Global step 1500 Train loss 0.08 Classification-F1 0.5621754260893088 on epoch=13
05/28/2022 07:49:19 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.08 on epoch=13
05/28/2022 07:49:21 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.13 on epoch=13
05/28/2022 07:49:24 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.04 on epoch=13
05/28/2022 07:49:27 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=13
05/28/2022 07:49:29 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.03 on epoch=13
05/28/2022 07:50:19 - INFO - __main__ - Global step 1550 Train loss 0.06 Classification-F1 0.5228496971892044 on epoch=13
05/28/2022 07:50:22 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.04 on epoch=13
05/28/2022 07:50:24 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.11 on epoch=14
05/28/2022 07:50:27 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.02 on epoch=14
05/28/2022 07:50:30 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.03 on epoch=14
05/28/2022 07:50:32 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.05 on epoch=14
05/28/2022 07:51:22 - INFO - __main__ - Global step 1600 Train loss 0.05 Classification-F1 0.5476647954959728 on epoch=14
05/28/2022 07:51:24 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.11 on epoch=14
05/28/2022 07:51:27 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.07 on epoch=14
05/28/2022 07:51:29 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.05 on epoch=14
05/28/2022 07:51:32 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.10 on epoch=14
05/28/2022 07:51:35 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.06 on epoch=14
05/28/2022 07:52:25 - INFO - __main__ - Global step 1650 Train loss 0.08 Classification-F1 0.5257043386360455 on epoch=14
05/28/2022 07:52:27 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.07 on epoch=14
05/28/2022 07:52:30 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.05 on epoch=14
05/28/2022 07:52:33 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.08 on epoch=14
05/28/2022 07:52:35 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.05 on epoch=15
05/28/2022 07:52:38 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.04 on epoch=15
05/28/2022 07:53:28 - INFO - __main__ - Global step 1700 Train loss 0.06 Classification-F1 0.5820106132715316 on epoch=15
05/28/2022 07:53:31 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.05 on epoch=15
05/28/2022 07:53:33 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.09 on epoch=15
05/28/2022 07:53:36 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.10 on epoch=15
05/28/2022 07:53:39 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.07 on epoch=15
05/28/2022 07:53:41 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.04 on epoch=15
05/28/2022 07:54:31 - INFO - __main__ - Global step 1750 Train loss 0.07 Classification-F1 0.5054612639101521 on epoch=15
05/28/2022 07:54:34 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.05 on epoch=15
05/28/2022 07:54:36 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.06 on epoch=15
05/28/2022 07:54:39 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.09 on epoch=15
05/28/2022 07:54:41 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.05 on epoch=15
05/28/2022 07:54:44 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.03 on epoch=16
05/28/2022 07:55:34 - INFO - __main__ - Global step 1800 Train loss 0.06 Classification-F1 0.5009133715618233 on epoch=16
05/28/2022 07:55:36 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.05 on epoch=16
05/28/2022 07:55:39 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.06 on epoch=16
05/28/2022 07:55:41 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.15 on epoch=16
05/28/2022 07:55:44 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.05 on epoch=16
05/28/2022 07:55:47 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.12 on epoch=16
05/28/2022 07:56:36 - INFO - __main__ - Global step 1850 Train loss 0.08 Classification-F1 0.5862204463355847 on epoch=16
05/28/2022 07:56:39 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.09 on epoch=16
05/28/2022 07:56:41 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.07 on epoch=16
05/28/2022 07:56:44 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.05 on epoch=16
05/28/2022 07:56:47 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.06 on epoch=16
05/28/2022 07:56:49 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=16
05/28/2022 07:57:41 - INFO - __main__ - Global step 1900 Train loss 0.06 Classification-F1 0.5666830524046506 on epoch=16
05/28/2022 07:57:43 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.07 on epoch=17
05/28/2022 07:57:46 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.05 on epoch=17
05/28/2022 07:57:48 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.07 on epoch=17
05/28/2022 07:57:51 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.10 on epoch=17
05/28/2022 07:57:54 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.08 on epoch=17
05/28/2022 07:58:43 - INFO - __main__ - Global step 1950 Train loss 0.07 Classification-F1 0.5818630560445854 on epoch=17
05/28/2022 07:58:45 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.10 on epoch=17
05/28/2022 07:58:48 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.04 on epoch=17
05/28/2022 07:58:51 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.05 on epoch=17
05/28/2022 07:58:53 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=17
05/28/2022 07:58:56 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=17
05/28/2022 07:59:46 - INFO - __main__ - Global step 2000 Train loss 0.05 Classification-F1 0.5418803502563635 on epoch=17
05/28/2022 07:59:49 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.05 on epoch=17
05/28/2022 07:59:51 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.07 on epoch=18
05/28/2022 07:59:54 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.02 on epoch=18
05/28/2022 07:59:57 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=18
05/28/2022 07:59:59 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.06 on epoch=18
05/28/2022 08:00:49 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.5170040208405986 on epoch=18
05/28/2022 08:00:52 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.04 on epoch=18
05/28/2022 08:00:54 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.07 on epoch=18
05/28/2022 08:00:57 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.05 on epoch=18
05/28/2022 08:01:00 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.08 on epoch=18
05/28/2022 08:01:02 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.06 on epoch=18
05/28/2022 08:01:52 - INFO - __main__ - Global step 2100 Train loss 0.06 Classification-F1 0.5585809565068827 on epoch=18
05/28/2022 08:01:55 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=18
05/28/2022 08:01:57 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.05 on epoch=18
05/28/2022 08:02:00 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.07 on epoch=19
05/28/2022 08:02:02 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=19
05/28/2022 08:02:05 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.03 on epoch=19
05/28/2022 08:02:55 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.5156317350723619 on epoch=19
05/28/2022 08:02:58 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.06 on epoch=19
05/28/2022 08:03:00 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.05 on epoch=19
05/28/2022 08:03:03 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.09 on epoch=19
05/28/2022 08:03:06 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.07 on epoch=19
05/28/2022 08:03:08 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.07 on epoch=19
05/28/2022 08:03:56 - INFO - __main__ - Global step 2200 Train loss 0.07 Classification-F1 0.5593410908340924 on epoch=19
05/28/2022 08:03:59 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=19
05/28/2022 08:04:01 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=19
05/28/2022 08:04:04 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.03 on epoch=19
05/28/2022 08:04:06 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.03 on epoch=19
05/28/2022 08:04:09 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.07 on epoch=20
05/28/2022 08:04:58 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.5793116514423656 on epoch=20
05/28/2022 08:05:00 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.03 on epoch=20
05/28/2022 08:05:03 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=20
05/28/2022 08:05:06 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.06 on epoch=20
05/28/2022 08:05:08 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.07 on epoch=20
05/28/2022 08:05:11 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=20
05/28/2022 08:05:59 - INFO - __main__ - Global step 2300 Train loss 0.04 Classification-F1 0.5039445691432237 on epoch=20
05/28/2022 08:06:02 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=20
05/28/2022 08:06:05 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=20
05/28/2022 08:06:07 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.04 on epoch=20
05/28/2022 08:06:10 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.06 on epoch=20
05/28/2022 08:06:12 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=20
05/28/2022 08:07:00 - INFO - __main__ - Global step 2350 Train loss 0.04 Classification-F1 0.5164634879596376 on epoch=20
05/28/2022 08:07:03 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=21
05/28/2022 08:07:06 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.03 on epoch=21
05/28/2022 08:07:08 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.03 on epoch=21
05/28/2022 08:07:11 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.06 on epoch=21
05/28/2022 08:07:13 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.05 on epoch=21
05/28/2022 08:08:01 - INFO - __main__ - Global step 2400 Train loss 0.04 Classification-F1 0.4901660275911102 on epoch=21
05/28/2022 08:08:04 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.05 on epoch=21
05/28/2022 08:08:06 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.10 on epoch=21
05/28/2022 08:08:09 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.05 on epoch=21
05/28/2022 08:08:12 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=21
05/28/2022 08:08:14 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.04 on epoch=21
05/28/2022 08:09:03 - INFO - __main__ - Global step 2450 Train loss 0.05 Classification-F1 0.6000984946609741 on epoch=21
05/28/2022 08:09:05 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.04 on epoch=21
05/28/2022 08:09:08 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.06 on epoch=22
05/28/2022 08:09:11 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.06 on epoch=22
05/28/2022 08:09:13 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.04 on epoch=22
05/28/2022 08:09:16 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.04 on epoch=22
05/28/2022 08:10:05 - INFO - __main__ - Global step 2500 Train loss 0.05 Classification-F1 0.6426804034541984 on epoch=22
05/28/2022 08:10:05 - INFO - __main__ - Saving model with best Classification-F1: 0.6065140773092489 -> 0.6426804034541984 on epoch=22, global_step=2500
05/28/2022 08:10:08 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.04 on epoch=22
05/28/2022 08:10:10 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.06 on epoch=22
05/28/2022 08:10:13 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.07 on epoch=22
05/28/2022 08:10:16 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.03 on epoch=22
05/28/2022 08:10:18 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=22
05/28/2022 08:11:08 - INFO - __main__ - Global step 2550 Train loss 0.04 Classification-F1 0.5845009531511585 on epoch=22
05/28/2022 08:11:10 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=22
05/28/2022 08:11:13 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.04 on epoch=22
05/28/2022 08:11:15 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=23
05/28/2022 08:11:18 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=23
05/28/2022 08:11:21 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.04 on epoch=23
05/28/2022 08:12:10 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.562187302594852 on epoch=23
05/28/2022 08:12:12 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.04 on epoch=23
05/28/2022 08:12:15 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.06 on epoch=23
05/28/2022 08:12:17 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.09 on epoch=23
05/28/2022 08:12:20 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.08 on epoch=23
05/28/2022 08:12:23 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.04 on epoch=23
05/28/2022 08:13:10 - INFO - __main__ - Global step 2650 Train loss 0.06 Classification-F1 0.6332072849366871 on epoch=23
05/28/2022 08:13:13 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=23
05/28/2022 08:13:15 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=23
05/28/2022 08:13:18 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.03 on epoch=23
05/28/2022 08:13:20 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=24
05/28/2022 08:13:23 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.05 on epoch=24
05/28/2022 08:14:12 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.6468437931520429 on epoch=24
05/28/2022 08:14:12 - INFO - __main__ - Saving model with best Classification-F1: 0.6426804034541984 -> 0.6468437931520429 on epoch=24, global_step=2700
05/28/2022 08:14:15 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.05 on epoch=24
05/28/2022 08:14:18 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.03 on epoch=24
05/28/2022 08:14:21 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.06 on epoch=24
05/28/2022 08:14:23 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.07 on epoch=24
05/28/2022 08:14:26 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.07 on epoch=24
05/28/2022 08:15:16 - INFO - __main__ - Global step 2750 Train loss 0.06 Classification-F1 0.5930565235182919 on epoch=24
05/28/2022 08:15:19 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.04 on epoch=24
05/28/2022 08:15:21 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=24
05/28/2022 08:15:24 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=24
05/28/2022 08:15:27 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.03 on epoch=24
05/28/2022 08:15:29 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.04 on epoch=24
05/28/2022 08:16:19 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.5617385448034146 on epoch=24
05/28/2022 08:16:22 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.04 on epoch=25
05/28/2022 08:16:25 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=25
05/28/2022 08:16:28 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.04 on epoch=25
05/28/2022 08:16:30 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.06 on epoch=25
05/28/2022 08:16:33 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.04 on epoch=25
05/28/2022 08:17:23 - INFO - __main__ - Global step 2850 Train loss 0.04 Classification-F1 0.5552028825287504 on epoch=25
05/28/2022 08:17:26 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.04 on epoch=25
05/28/2022 08:17:28 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.08 on epoch=25
05/28/2022 08:17:31 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=25
05/28/2022 08:17:34 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.05 on epoch=25
05/28/2022 08:17:37 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.04 on epoch=25
05/28/2022 08:18:27 - INFO - __main__ - Global step 2900 Train loss 0.04 Classification-F1 0.5127432413266163 on epoch=25
05/28/2022 08:18:30 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.07 on epoch=25
05/28/2022 08:18:32 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=26
05/28/2022 08:18:35 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.03 on epoch=26
05/28/2022 08:18:38 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.04 on epoch=26
05/28/2022 08:18:41 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.06 on epoch=26
05/28/2022 08:19:32 - INFO - __main__ - Global step 2950 Train loss 0.04 Classification-F1 0.564054997773989 on epoch=26
05/28/2022 08:19:34 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.03 on epoch=26
05/28/2022 08:19:37 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.09 on epoch=26
05/28/2022 08:19:40 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.04 on epoch=26
05/28/2022 08:19:42 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.04 on epoch=26
05/28/2022 08:19:45 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.04 on epoch=26
05/28/2022 08:19:47 - INFO - __main__ - Start tokenizing ... 1792 instances
05/28/2022 08:19:47 - INFO - __main__ - Printing 3 examples
05/28/2022 08:19:47 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/28/2022 08:19:47 - INFO - __main__ - ['Plant']
05/28/2022 08:19:47 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/28/2022 08:19:47 - INFO - __main__ - ['Plant']
05/28/2022 08:19:47 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/28/2022 08:19:47 - INFO - __main__ - ['Plant']
05/28/2022 08:19:47 - INFO - __main__ - Tokenizing Input ...
05/28/2022 08:19:47 - INFO - __main__ - Tokenizing Output ...
05/28/2022 08:19:49 - INFO - __main__ - Loaded 1792 examples from train data
05/28/2022 08:19:49 - INFO - __main__ - Start tokenizing ... 1792 instances
05/28/2022 08:19:49 - INFO - __main__ - Printing 3 examples
05/28/2022 08:19:49 - INFO - __main__ -  [dbpedia_14] Sabal pumos is a species of flowering plant in the palm tree family Arecaceae. It is native to the dry forests along the Balsas River in central Mexico (Guanajuato Guerrero Jalisco Michoacán Morelos Zacatecas and the State of México). It is threatened by habitat loss.
05/28/2022 08:19:49 - INFO - __main__ - ['Plant']
05/28/2022 08:19:49 - INFO - __main__ -  [dbpedia_14] Bulbophyllum intricatum is a species of orchid in the genus Bulbophyllum.
05/28/2022 08:19:49 - INFO - __main__ - ['Plant']
05/28/2022 08:19:49 - INFO - __main__ -  [dbpedia_14] Gentiana parryi (Parry's Gentian) is a species of the genus Gentiana.
05/28/2022 08:19:49 - INFO - __main__ - ['Plant']
05/28/2022 08:19:49 - INFO - __main__ - Tokenizing Input ...
05/28/2022 08:19:50 - INFO - __main__ - Tokenizing Output ...
05/28/2022 08:19:52 - INFO - __main__ - Loaded 1792 examples from dev data
05/28/2022 08:20:07 - INFO - __main__ - load prompt embedding from ckpt
05/28/2022 08:20:08 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/28/2022 08:20:08 - INFO - __main__ - Starting training!
05/28/2022 08:20:32 - INFO - __main__ - Global step 3000 Train loss 0.05 Classification-F1 0.6373880216607144 on epoch=26
05/28/2022 08:20:32 - INFO - __main__ - save last model!
05/28/2022 08:20:32 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/28/2022 08:20:32 - INFO - __main__ - Start tokenizing ... 3500 instances
05/28/2022 08:20:32 - INFO - __main__ - Printing 3 examples
05/28/2022 08:20:32 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/28/2022 08:20:32 - INFO - __main__ - ['Animal']
05/28/2022 08:20:32 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/28/2022 08:20:32 - INFO - __main__ - ['Animal']
05/28/2022 08:20:32 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/28/2022 08:20:32 - INFO - __main__ - ['Village']
05/28/2022 08:20:32 - INFO - __main__ - Tokenizing Input ...
05/28/2022 08:20:34 - INFO - __main__ - Tokenizing Output ...
05/28/2022 08:20:38 - INFO - __main__ - Loaded 3500 examples from test data
05/28/2022 08:22:34 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down128shot/singletask-dbpedia_14/dbpedia_14_128_21_0.4_8_predictions.txt
05/28/2022 08:22:34 - INFO - __main__ - Classification-F1 on test data: 0.5104
05/28/2022 08:22:34 - INFO - __main__ - prefix=dbpedia_14_128_21, lr=0.4, bsz=8, dev_performance=0.6468437931520429, test_performance=0.5103716159416857
05/28/2022 08:22:34 - INFO - __main__ - Running ... prefix=dbpedia_14_128_21, lr=0.3, bsz=8 ...
05/28/2022 08:22:35 - INFO - __main__ - Start tokenizing ... 1792 instances
05/28/2022 08:22:35 - INFO - __main__ - Printing 3 examples
05/28/2022 08:22:35 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/28/2022 08:22:35 - INFO - __main__ - ['Plant']
05/28/2022 08:22:35 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/28/2022 08:22:35 - INFO - __main__ - ['Plant']
05/28/2022 08:22:35 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/28/2022 08:22:35 - INFO - __main__ - ['Plant']
05/28/2022 08:22:35 - INFO - __main__ - Tokenizing Input ...
05/28/2022 08:22:36 - INFO - __main__ - Tokenizing Output ...
05/28/2022 08:22:37 - INFO - __main__ - Loaded 1792 examples from train data
05/28/2022 08:22:37 - INFO - __main__ - Start tokenizing ... 1792 instances
05/28/2022 08:22:37 - INFO - __main__ - Printing 3 examples
05/28/2022 08:22:37 - INFO - __main__ -  [dbpedia_14] Sabal pumos is a species of flowering plant in the palm tree family Arecaceae. It is native to the dry forests along the Balsas River in central Mexico (Guanajuato Guerrero Jalisco Michoacán Morelos Zacatecas and the State of México). It is threatened by habitat loss.
05/28/2022 08:22:37 - INFO - __main__ - ['Plant']
05/28/2022 08:22:37 - INFO - __main__ -  [dbpedia_14] Bulbophyllum intricatum is a species of orchid in the genus Bulbophyllum.
05/28/2022 08:22:37 - INFO - __main__ - ['Plant']
05/28/2022 08:22:37 - INFO - __main__ -  [dbpedia_14] Gentiana parryi (Parry's Gentian) is a species of the genus Gentiana.
05/28/2022 08:22:37 - INFO - __main__ - ['Plant']
05/28/2022 08:22:37 - INFO - __main__ - Tokenizing Input ...
05/28/2022 08:22:38 - INFO - __main__ - Tokenizing Output ...
05/28/2022 08:22:40 - INFO - __main__ - Loaded 1792 examples from dev data
05/28/2022 08:22:56 - INFO - __main__ - load prompt embedding from ckpt
05/28/2022 08:22:57 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/28/2022 08:22:57 - INFO - __main__ - Starting training!
05/28/2022 08:23:01 - INFO - __main__ - Step 10 Global step 10 Train loss 7.22 on epoch=0
05/28/2022 08:23:04 - INFO - __main__ - Step 20 Global step 20 Train loss 5.32 on epoch=0
05/28/2022 08:23:07 - INFO - __main__ - Step 30 Global step 30 Train loss 4.43 on epoch=0
05/28/2022 08:23:09 - INFO - __main__ - Step 40 Global step 40 Train loss 3.97 on epoch=0
05/28/2022 08:23:12 - INFO - __main__ - Step 50 Global step 50 Train loss 3.82 on epoch=0
05/28/2022 08:24:06 - INFO - __main__ - Global step 50 Train loss 4.95 Classification-F1 0.009957547636959125 on epoch=0
05/28/2022 08:24:07 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.009957547636959125 on epoch=0, global_step=50
05/28/2022 08:24:09 - INFO - __main__ - Step 60 Global step 60 Train loss 3.26 on epoch=0
05/28/2022 08:24:12 - INFO - __main__ - Step 70 Global step 70 Train loss 2.74 on epoch=0
05/28/2022 08:24:15 - INFO - __main__ - Step 80 Global step 80 Train loss 3.13 on epoch=0
05/28/2022 08:24:18 - INFO - __main__ - Step 90 Global step 90 Train loss 2.61 on epoch=0
05/28/2022 08:24:21 - INFO - __main__ - Step 100 Global step 100 Train loss 2.03 on epoch=0
05/28/2022 08:25:11 - INFO - __main__ - Global step 100 Train loss 2.75 Classification-F1 0.021689656974680876 on epoch=0
05/28/2022 08:25:11 - INFO - __main__ - Saving model with best Classification-F1: 0.009957547636959125 -> 0.021689656974680876 on epoch=0, global_step=100
05/28/2022 08:25:14 - INFO - __main__ - Step 110 Global step 110 Train loss 2.06 on epoch=0
05/28/2022 08:25:16 - INFO - __main__ - Step 120 Global step 120 Train loss 2.37 on epoch=1
05/28/2022 08:25:19 - INFO - __main__ - Step 130 Global step 130 Train loss 2.13 on epoch=1
05/28/2022 08:25:22 - INFO - __main__ - Step 140 Global step 140 Train loss 2.10 on epoch=1
05/28/2022 08:25:24 - INFO - __main__ - Step 150 Global step 150 Train loss 1.77 on epoch=1
05/28/2022 08:26:10 - INFO - __main__ - Global step 150 Train loss 2.09 Classification-F1 0.0427569557252912 on epoch=1
05/28/2022 08:26:10 - INFO - __main__ - Saving model with best Classification-F1: 0.021689656974680876 -> 0.0427569557252912 on epoch=1, global_step=150
05/28/2022 08:26:12 - INFO - __main__ - Step 160 Global step 160 Train loss 1.82 on epoch=1
05/28/2022 08:26:15 - INFO - __main__ - Step 170 Global step 170 Train loss 1.75 on epoch=1
05/28/2022 08:26:18 - INFO - __main__ - Step 180 Global step 180 Train loss 1.53 on epoch=1
05/28/2022 08:26:20 - INFO - __main__ - Step 190 Global step 190 Train loss 1.50 on epoch=1
05/28/2022 08:26:23 - INFO - __main__ - Step 200 Global step 200 Train loss 1.53 on epoch=1
05/28/2022 08:27:08 - INFO - __main__ - Global step 200 Train loss 1.63 Classification-F1 0.08719484516485876 on epoch=1
05/28/2022 08:27:08 - INFO - __main__ - Saving model with best Classification-F1: 0.0427569557252912 -> 0.08719484516485876 on epoch=1, global_step=200
05/28/2022 08:27:10 - INFO - __main__ - Step 210 Global step 210 Train loss 1.22 on epoch=1
05/28/2022 08:27:13 - INFO - __main__ - Step 220 Global step 220 Train loss 1.03 on epoch=1
05/28/2022 08:27:15 - INFO - __main__ - Step 230 Global step 230 Train loss 1.21 on epoch=2
05/28/2022 08:27:18 - INFO - __main__ - Step 240 Global step 240 Train loss 1.15 on epoch=2
05/28/2022 08:27:21 - INFO - __main__ - Step 250 Global step 250 Train loss 0.92 on epoch=2
05/28/2022 08:28:06 - INFO - __main__ - Global step 250 Train loss 1.11 Classification-F1 0.1335464574451679 on epoch=2
05/28/2022 08:28:06 - INFO - __main__ - Saving model with best Classification-F1: 0.08719484516485876 -> 0.1335464574451679 on epoch=2, global_step=250
05/28/2022 08:28:09 - INFO - __main__ - Step 260 Global step 260 Train loss 0.90 on epoch=2
05/28/2022 08:28:11 - INFO - __main__ - Step 270 Global step 270 Train loss 0.88 on epoch=2
05/28/2022 08:28:14 - INFO - __main__ - Step 280 Global step 280 Train loss 0.83 on epoch=2
05/28/2022 08:28:16 - INFO - __main__ - Step 290 Global step 290 Train loss 0.77 on epoch=2
05/28/2022 08:28:19 - INFO - __main__ - Step 300 Global step 300 Train loss 0.75 on epoch=2
05/28/2022 08:29:08 - INFO - __main__ - Global step 300 Train loss 0.82 Classification-F1 0.1819926373718859 on epoch=2
05/28/2022 08:29:08 - INFO - __main__ - Saving model with best Classification-F1: 0.1335464574451679 -> 0.1819926373718859 on epoch=2, global_step=300
05/28/2022 08:29:11 - INFO - __main__ - Step 310 Global step 310 Train loss 0.72 on epoch=2
05/28/2022 08:29:13 - INFO - __main__ - Step 320 Global step 320 Train loss 0.66 on epoch=2
05/28/2022 08:29:16 - INFO - __main__ - Step 330 Global step 330 Train loss 0.49 on epoch=2
05/28/2022 08:29:18 - INFO - __main__ - Step 340 Global step 340 Train loss 0.60 on epoch=3
05/28/2022 08:29:21 - INFO - __main__ - Step 350 Global step 350 Train loss 0.66 on epoch=3
05/28/2022 08:30:12 - INFO - __main__ - Global step 350 Train loss 0.63 Classification-F1 0.2661580121692747 on epoch=3
05/28/2022 08:30:12 - INFO - __main__ - Saving model with best Classification-F1: 0.1819926373718859 -> 0.2661580121692747 on epoch=3, global_step=350
05/28/2022 08:30:15 - INFO - __main__ - Step 360 Global step 360 Train loss 0.44 on epoch=3
05/28/2022 08:30:17 - INFO - __main__ - Step 370 Global step 370 Train loss 0.43 on epoch=3
05/28/2022 08:30:20 - INFO - __main__ - Step 380 Global step 380 Train loss 0.46 on epoch=3
05/28/2022 08:30:23 - INFO - __main__ - Step 390 Global step 390 Train loss 0.54 on epoch=3
05/28/2022 08:30:25 - INFO - __main__ - Step 400 Global step 400 Train loss 0.42 on epoch=3
05/28/2022 08:31:17 - INFO - __main__ - Global step 400 Train loss 0.46 Classification-F1 0.2645740115919146 on epoch=3
05/28/2022 08:31:20 - INFO - __main__ - Step 410 Global step 410 Train loss 0.49 on epoch=3
05/28/2022 08:31:22 - INFO - __main__ - Step 420 Global step 420 Train loss 0.44 on epoch=3
05/28/2022 08:31:25 - INFO - __main__ - Step 430 Global step 430 Train loss 0.38 on epoch=3
05/28/2022 08:31:27 - INFO - __main__ - Step 440 Global step 440 Train loss 0.38 on epoch=3
05/28/2022 08:31:30 - INFO - __main__ - Step 450 Global step 450 Train loss 0.44 on epoch=4
05/28/2022 08:32:22 - INFO - __main__ - Global step 450 Train loss 0.43 Classification-F1 0.34401914484412266 on epoch=4
05/28/2022 08:32:22 - INFO - __main__ - Saving model with best Classification-F1: 0.2661580121692747 -> 0.34401914484412266 on epoch=4, global_step=450
05/28/2022 08:32:25 - INFO - __main__ - Step 460 Global step 460 Train loss 0.45 on epoch=4
05/28/2022 08:32:27 - INFO - __main__ - Step 470 Global step 470 Train loss 0.47 on epoch=4
05/28/2022 08:32:30 - INFO - __main__ - Step 480 Global step 480 Train loss 0.33 on epoch=4
05/28/2022 08:32:33 - INFO - __main__ - Step 490 Global step 490 Train loss 0.39 on epoch=4
05/28/2022 08:32:35 - INFO - __main__ - Step 500 Global step 500 Train loss 0.34 on epoch=4
05/28/2022 08:33:26 - INFO - __main__ - Global step 500 Train loss 0.40 Classification-F1 0.33399816590069226 on epoch=4
05/28/2022 08:33:29 - INFO - __main__ - Step 510 Global step 510 Train loss 0.33 on epoch=4
05/28/2022 08:33:32 - INFO - __main__ - Step 520 Global step 520 Train loss 0.40 on epoch=4
05/28/2022 08:33:34 - INFO - __main__ - Step 530 Global step 530 Train loss 0.31 on epoch=4
05/28/2022 08:33:37 - INFO - __main__ - Step 540 Global step 540 Train loss 0.30 on epoch=4
05/28/2022 08:33:39 - INFO - __main__ - Step 550 Global step 550 Train loss 0.37 on epoch=4
05/28/2022 08:34:32 - INFO - __main__ - Global step 550 Train loss 0.34 Classification-F1 0.38987939481899253 on epoch=4
05/28/2022 08:34:32 - INFO - __main__ - Saving model with best Classification-F1: 0.34401914484412266 -> 0.38987939481899253 on epoch=4, global_step=550
05/28/2022 08:34:34 - INFO - __main__ - Step 560 Global step 560 Train loss 0.34 on epoch=4
05/28/2022 08:34:37 - INFO - __main__ - Step 570 Global step 570 Train loss 0.30 on epoch=5
05/28/2022 08:34:40 - INFO - __main__ - Step 580 Global step 580 Train loss 0.25 on epoch=5
05/28/2022 08:34:42 - INFO - __main__ - Step 590 Global step 590 Train loss 0.19 on epoch=5
05/28/2022 08:34:45 - INFO - __main__ - Step 600 Global step 600 Train loss 0.25 on epoch=5
05/28/2022 08:35:35 - INFO - __main__ - Global step 600 Train loss 0.26 Classification-F1 0.3687304051162965 on epoch=5
05/28/2022 08:35:38 - INFO - __main__ - Step 610 Global step 610 Train loss 0.27 on epoch=5
05/28/2022 08:35:40 - INFO - __main__ - Step 620 Global step 620 Train loss 0.35 on epoch=5
05/28/2022 08:35:43 - INFO - __main__ - Step 630 Global step 630 Train loss 0.28 on epoch=5
05/28/2022 08:35:46 - INFO - __main__ - Step 640 Global step 640 Train loss 0.27 on epoch=5
05/28/2022 08:35:48 - INFO - __main__ - Step 650 Global step 650 Train loss 0.25 on epoch=5
05/28/2022 08:36:39 - INFO - __main__ - Global step 650 Train loss 0.28 Classification-F1 0.3651134846317113 on epoch=5
05/28/2022 08:36:42 - INFO - __main__ - Step 660 Global step 660 Train loss 0.25 on epoch=5
05/28/2022 08:36:44 - INFO - __main__ - Step 670 Global step 670 Train loss 0.32 on epoch=5
05/28/2022 08:36:47 - INFO - __main__ - Step 680 Global step 680 Train loss 0.36 on epoch=6
05/28/2022 08:36:50 - INFO - __main__ - Step 690 Global step 690 Train loss 0.24 on epoch=6
05/28/2022 08:36:52 - INFO - __main__ - Step 700 Global step 700 Train loss 0.19 on epoch=6
05/28/2022 08:37:43 - INFO - __main__ - Global step 700 Train loss 0.27 Classification-F1 0.4162478252666214 on epoch=6
05/28/2022 08:37:43 - INFO - __main__ - Saving model with best Classification-F1: 0.38987939481899253 -> 0.4162478252666214 on epoch=6, global_step=700
05/28/2022 08:37:46 - INFO - __main__ - Step 710 Global step 710 Train loss 0.24 on epoch=6
05/28/2022 08:37:49 - INFO - __main__ - Step 720 Global step 720 Train loss 0.16 on epoch=6
05/28/2022 08:37:51 - INFO - __main__ - Step 730 Global step 730 Train loss 0.26 on epoch=6
05/28/2022 08:37:54 - INFO - __main__ - Step 740 Global step 740 Train loss 0.28 on epoch=6
05/28/2022 08:37:57 - INFO - __main__ - Step 750 Global step 750 Train loss 0.27 on epoch=6
05/28/2022 08:38:50 - INFO - __main__ - Global step 750 Train loss 0.24 Classification-F1 0.4376253903590367 on epoch=6
05/28/2022 08:38:50 - INFO - __main__ - Saving model with best Classification-F1: 0.4162478252666214 -> 0.4376253903590367 on epoch=6, global_step=750
05/28/2022 08:38:52 - INFO - __main__ - Step 760 Global step 760 Train loss 0.22 on epoch=6
05/28/2022 08:38:55 - INFO - __main__ - Step 770 Global step 770 Train loss 0.17 on epoch=6
05/28/2022 08:38:58 - INFO - __main__ - Step 780 Global step 780 Train loss 0.22 on epoch=6
05/28/2022 08:39:00 - INFO - __main__ - Step 790 Global step 790 Train loss 0.22 on epoch=7
05/28/2022 08:39:03 - INFO - __main__ - Step 800 Global step 800 Train loss 0.21 on epoch=7
05/28/2022 08:39:56 - INFO - __main__ - Global step 800 Train loss 0.21 Classification-F1 0.4229050659696872 on epoch=7
05/28/2022 08:39:59 - INFO - __main__ - Step 810 Global step 810 Train loss 0.16 on epoch=7
05/28/2022 08:40:01 - INFO - __main__ - Step 820 Global step 820 Train loss 0.20 on epoch=7
05/28/2022 08:40:04 - INFO - __main__ - Step 830 Global step 830 Train loss 0.14 on epoch=7
05/28/2022 08:40:07 - INFO - __main__ - Step 840 Global step 840 Train loss 0.35 on epoch=7
05/28/2022 08:40:09 - INFO - __main__ - Step 850 Global step 850 Train loss 0.22 on epoch=7
05/28/2022 08:41:01 - INFO - __main__ - Global step 850 Train loss 0.22 Classification-F1 0.42065983949069535 on epoch=7
05/28/2022 08:41:03 - INFO - __main__ - Step 860 Global step 860 Train loss 0.24 on epoch=7
05/28/2022 08:41:06 - INFO - __main__ - Step 870 Global step 870 Train loss 0.17 on epoch=7
05/28/2022 08:41:09 - INFO - __main__ - Step 880 Global step 880 Train loss 0.21 on epoch=7
05/28/2022 08:41:11 - INFO - __main__ - Step 890 Global step 890 Train loss 0.15 on epoch=7
05/28/2022 08:41:14 - INFO - __main__ - Step 900 Global step 900 Train loss 0.23 on epoch=8
05/28/2022 08:42:06 - INFO - __main__ - Global step 900 Train loss 0.20 Classification-F1 0.4918510773396789 on epoch=8
05/28/2022 08:42:06 - INFO - __main__ - Saving model with best Classification-F1: 0.4376253903590367 -> 0.4918510773396789 on epoch=8, global_step=900
05/28/2022 08:42:09 - INFO - __main__ - Step 910 Global step 910 Train loss 0.14 on epoch=8
05/28/2022 08:42:12 - INFO - __main__ - Step 920 Global step 920 Train loss 0.09 on epoch=8
05/28/2022 08:42:14 - INFO - __main__ - Step 930 Global step 930 Train loss 0.19 on epoch=8
05/28/2022 08:42:17 - INFO - __main__ - Step 940 Global step 940 Train loss 0.17 on epoch=8
05/28/2022 08:42:19 - INFO - __main__ - Step 950 Global step 950 Train loss 0.16 on epoch=8
05/28/2022 08:43:11 - INFO - __main__ - Global step 950 Train loss 0.15 Classification-F1 0.495640200595911 on epoch=8
05/28/2022 08:43:11 - INFO - __main__ - Saving model with best Classification-F1: 0.4918510773396789 -> 0.495640200595911 on epoch=8, global_step=950
05/28/2022 08:43:13 - INFO - __main__ - Step 960 Global step 960 Train loss 0.18 on epoch=8
05/28/2022 08:43:16 - INFO - __main__ - Step 970 Global step 970 Train loss 0.15 on epoch=8
05/28/2022 08:43:19 - INFO - __main__ - Step 980 Global step 980 Train loss 0.22 on epoch=8
05/28/2022 08:43:21 - INFO - __main__ - Step 990 Global step 990 Train loss 0.12 on epoch=8
05/28/2022 08:43:24 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.11 on epoch=8
05/28/2022 08:44:16 - INFO - __main__ - Global step 1000 Train loss 0.15 Classification-F1 0.45969210559780355 on epoch=8
05/28/2022 08:44:18 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.19 on epoch=9
05/28/2022 08:44:21 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.09 on epoch=9
05/28/2022 08:44:24 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.10 on epoch=9
05/28/2022 08:44:26 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.22 on epoch=9
05/28/2022 08:44:29 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.14 on epoch=9
05/28/2022 08:45:20 - INFO - __main__ - Global step 1050 Train loss 0.15 Classification-F1 0.47734919930510544 on epoch=9
05/28/2022 08:45:22 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.19 on epoch=9
05/28/2022 08:45:25 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.10 on epoch=9
05/28/2022 08:45:28 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.15 on epoch=9
05/28/2022 08:45:30 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.13 on epoch=9
05/28/2022 08:45:33 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.16 on epoch=9
05/28/2022 08:46:24 - INFO - __main__ - Global step 1100 Train loss 0.15 Classification-F1 0.5051237615278658 on epoch=9
05/28/2022 08:46:24 - INFO - __main__ - Saving model with best Classification-F1: 0.495640200595911 -> 0.5051237615278658 on epoch=9, global_step=1100
05/28/2022 08:46:26 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.15 on epoch=9
05/28/2022 08:46:29 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.12 on epoch=9
05/28/2022 08:46:32 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.09 on epoch=10
05/28/2022 08:46:34 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.11 on epoch=10
05/28/2022 08:46:37 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.12 on epoch=10
05/28/2022 08:47:27 - INFO - __main__ - Global step 1150 Train loss 0.12 Classification-F1 0.4789966882303656 on epoch=10
05/28/2022 08:47:30 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.16 on epoch=10
05/28/2022 08:47:32 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.15 on epoch=10
05/28/2022 08:47:35 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.14 on epoch=10
05/28/2022 08:47:38 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.09 on epoch=10
05/28/2022 08:47:40 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.11 on epoch=10
05/28/2022 08:48:31 - INFO - __main__ - Global step 1200 Train loss 0.13 Classification-F1 0.5179302275255969 on epoch=10
05/28/2022 08:48:31 - INFO - __main__ - Saving model with best Classification-F1: 0.5051237615278658 -> 0.5179302275255969 on epoch=10, global_step=1200
05/28/2022 08:48:34 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.10 on epoch=10
05/28/2022 08:48:36 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.15 on epoch=10
05/28/2022 08:48:39 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.15 on epoch=10
05/28/2022 08:48:41 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.09 on epoch=11
05/28/2022 08:48:44 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.12 on epoch=11
05/28/2022 08:49:36 - INFO - __main__ - Global step 1250 Train loss 0.12 Classification-F1 0.5049104419394898 on epoch=11
05/28/2022 08:49:39 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.11 on epoch=11
05/28/2022 08:49:41 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.10 on epoch=11
05/28/2022 08:49:44 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.13 on epoch=11
05/28/2022 08:49:47 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.11 on epoch=11
05/28/2022 08:49:49 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.15 on epoch=11
05/28/2022 08:50:42 - INFO - __main__ - Global step 1300 Train loss 0.12 Classification-F1 0.4858525823661704 on epoch=11
05/28/2022 08:50:44 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.11 on epoch=11
05/28/2022 08:50:47 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.08 on epoch=11
05/28/2022 08:50:49 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.12 on epoch=11
05/28/2022 08:50:52 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.09 on epoch=11
05/28/2022 08:50:55 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.07 on epoch=12
05/28/2022 08:51:46 - INFO - __main__ - Global step 1350 Train loss 0.09 Classification-F1 0.510244439357436 on epoch=12
05/28/2022 08:51:48 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.08 on epoch=12
05/28/2022 08:51:51 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.08 on epoch=12
05/28/2022 08:51:53 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.14 on epoch=12
05/28/2022 08:51:56 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.18 on epoch=12
05/28/2022 08:51:59 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.16 on epoch=12
05/28/2022 08:52:52 - INFO - __main__ - Global step 1400 Train loss 0.13 Classification-F1 0.5332239299052203 on epoch=12
05/28/2022 08:52:52 - INFO - __main__ - Saving model with best Classification-F1: 0.5179302275255969 -> 0.5332239299052203 on epoch=12, global_step=1400
05/28/2022 08:52:55 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.17 on epoch=12
05/28/2022 08:52:57 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.11 on epoch=12
05/28/2022 08:53:00 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.08 on epoch=12
05/28/2022 08:53:02 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.06 on epoch=12
05/28/2022 08:53:05 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.13 on epoch=12
05/28/2022 08:53:58 - INFO - __main__ - Global step 1450 Train loss 0.11 Classification-F1 0.5571589775236377 on epoch=12
05/28/2022 08:53:58 - INFO - __main__ - Saving model with best Classification-F1: 0.5332239299052203 -> 0.5571589775236377 on epoch=12, global_step=1450
05/28/2022 08:54:00 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.13 on epoch=13
05/28/2022 08:54:03 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.12 on epoch=13
05/28/2022 08:54:06 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.06 on epoch=13
05/28/2022 08:54:08 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.12 on epoch=13
05/28/2022 08:54:11 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.10 on epoch=13
05/28/2022 08:55:02 - INFO - __main__ - Global step 1500 Train loss 0.11 Classification-F1 0.5074653069342648 on epoch=13
05/28/2022 08:55:04 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.12 on epoch=13
05/28/2022 08:55:07 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.08 on epoch=13
05/28/2022 08:55:09 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.12 on epoch=13
05/28/2022 08:55:12 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.10 on epoch=13
05/28/2022 08:55:15 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.09 on epoch=13
05/28/2022 08:56:04 - INFO - __main__ - Global step 1550 Train loss 0.10 Classification-F1 0.48530488155015444 on epoch=13
05/28/2022 08:56:07 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.11 on epoch=13
05/28/2022 08:56:09 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.07 on epoch=14
05/28/2022 08:56:12 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.05 on epoch=14
05/28/2022 08:56:15 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.05 on epoch=14
05/28/2022 08:56:17 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.10 on epoch=14
05/28/2022 08:57:06 - INFO - __main__ - Global step 1600 Train loss 0.08 Classification-F1 0.5453452079393296 on epoch=14
05/28/2022 08:57:09 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.09 on epoch=14
05/28/2022 08:57:11 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.09 on epoch=14
05/28/2022 08:57:14 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.08 on epoch=14
05/28/2022 08:57:17 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.07 on epoch=14
05/28/2022 08:57:19 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.06 on epoch=14
05/28/2022 08:58:11 - INFO - __main__ - Global step 1650 Train loss 0.08 Classification-F1 0.5078763787273057 on epoch=14
05/28/2022 08:58:13 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.05 on epoch=14
05/28/2022 08:58:16 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.06 on epoch=14
05/28/2022 08:58:18 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.05 on epoch=14
05/28/2022 08:58:21 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.08 on epoch=15
05/28/2022 08:58:24 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.06 on epoch=15
05/28/2022 08:59:14 - INFO - __main__ - Global step 1700 Train loss 0.06 Classification-F1 0.5637382105768172 on epoch=15
05/28/2022 08:59:14 - INFO - __main__ - Saving model with best Classification-F1: 0.5571589775236377 -> 0.5637382105768172 on epoch=15, global_step=1700
05/28/2022 08:59:17 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.09 on epoch=15
05/28/2022 08:59:20 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.14 on epoch=15
05/28/2022 08:59:22 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.14 on epoch=15
05/28/2022 08:59:25 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.12 on epoch=15
05/28/2022 08:59:27 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.09 on epoch=15
05/28/2022 09:00:18 - INFO - __main__ - Global step 1750 Train loss 0.12 Classification-F1 0.5558667899504594 on epoch=15
05/28/2022 09:00:20 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.04 on epoch=15
05/28/2022 09:00:23 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.09 on epoch=15
05/28/2022 09:00:25 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.08 on epoch=15
05/28/2022 09:00:28 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.08 on epoch=15
05/28/2022 09:00:31 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.08 on epoch=16
05/28/2022 09:01:22 - INFO - __main__ - Global step 1800 Train loss 0.08 Classification-F1 0.5328111850478158 on epoch=16
05/28/2022 09:01:24 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.08 on epoch=16
05/28/2022 09:01:27 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.09 on epoch=16
05/28/2022 09:01:29 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.11 on epoch=16
05/28/2022 09:01:32 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.04 on epoch=16
05/28/2022 09:01:34 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.11 on epoch=16
05/28/2022 09:02:24 - INFO - __main__ - Global step 1850 Train loss 0.09 Classification-F1 0.617625556055521 on epoch=16
05/28/2022 09:02:24 - INFO - __main__ - Saving model with best Classification-F1: 0.5637382105768172 -> 0.617625556055521 on epoch=16, global_step=1850
05/28/2022 09:02:27 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.09 on epoch=16
05/28/2022 09:02:29 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.09 on epoch=16
05/28/2022 09:02:32 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.06 on epoch=16
05/28/2022 09:02:34 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.05 on epoch=16
05/28/2022 09:02:37 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.06 on epoch=16
05/28/2022 09:03:25 - INFO - __main__ - Global step 1900 Train loss 0.07 Classification-F1 0.5477803019787146 on epoch=16
05/28/2022 09:03:28 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.04 on epoch=17
05/28/2022 09:03:31 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.08 on epoch=17
05/28/2022 09:03:33 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.04 on epoch=17
05/28/2022 09:03:36 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.09 on epoch=17
05/28/2022 09:03:38 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.06 on epoch=17
05/28/2022 09:04:27 - INFO - __main__ - Global step 1950 Train loss 0.06 Classification-F1 0.6104757122793936 on epoch=17
05/28/2022 09:04:29 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.11 on epoch=17
05/28/2022 09:04:32 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.05 on epoch=17
05/28/2022 09:04:35 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.06 on epoch=17
05/28/2022 09:04:37 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.06 on epoch=17
05/28/2022 09:04:40 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.04 on epoch=17
05/28/2022 09:05:27 - INFO - __main__ - Global step 2000 Train loss 0.07 Classification-F1 0.529687285114511 on epoch=17
05/28/2022 09:05:30 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.07 on epoch=17
05/28/2022 09:05:33 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.07 on epoch=18
05/28/2022 09:05:35 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.05 on epoch=18
05/28/2022 09:05:38 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.06 on epoch=18
05/28/2022 09:05:40 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.10 on epoch=18
05/28/2022 09:06:28 - INFO - __main__ - Global step 2050 Train loss 0.07 Classification-F1 0.5062616118984726 on epoch=18
05/28/2022 09:06:31 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.05 on epoch=18
05/28/2022 09:06:33 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.09 on epoch=18
05/28/2022 09:06:36 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.09 on epoch=18
05/28/2022 09:06:38 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.08 on epoch=18
05/28/2022 09:06:41 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.05 on epoch=18
05/28/2022 09:07:29 - INFO - __main__ - Global step 2100 Train loss 0.07 Classification-F1 0.4878551715624687 on epoch=18
05/28/2022 09:07:31 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.04 on epoch=18
05/28/2022 09:07:34 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.04 on epoch=18
05/28/2022 09:07:36 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.05 on epoch=19
05/28/2022 09:07:39 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.05 on epoch=19
05/28/2022 09:07:42 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.06 on epoch=19
05/28/2022 09:08:31 - INFO - __main__ - Global step 2150 Train loss 0.05 Classification-F1 0.6205139360727338 on epoch=19
05/28/2022 09:08:31 - INFO - __main__ - Saving model with best Classification-F1: 0.617625556055521 -> 0.6205139360727338 on epoch=19, global_step=2150
05/28/2022 09:08:33 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.10 on epoch=19
05/28/2022 09:08:36 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.04 on epoch=19
05/28/2022 09:08:38 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.05 on epoch=19
05/28/2022 09:08:41 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.05 on epoch=19
05/28/2022 09:08:44 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.07 on epoch=19
05/28/2022 09:09:31 - INFO - __main__ - Global step 2200 Train loss 0.06 Classification-F1 0.5331444348007238 on epoch=19
05/28/2022 09:09:34 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.06 on epoch=19
05/28/2022 09:09:36 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.06 on epoch=19
05/28/2022 09:09:39 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.07 on epoch=19
05/28/2022 09:09:41 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=19
05/28/2022 09:09:44 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.10 on epoch=20
05/28/2022 09:10:33 - INFO - __main__ - Global step 2250 Train loss 0.06 Classification-F1 0.5533756646358509 on epoch=20
05/28/2022 09:10:35 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.04 on epoch=20
05/28/2022 09:10:38 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.04 on epoch=20
05/28/2022 09:10:41 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.07 on epoch=20
05/28/2022 09:10:43 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.09 on epoch=20
05/28/2022 09:10:46 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.09 on epoch=20
05/28/2022 09:11:35 - INFO - __main__ - Global step 2300 Train loss 0.07 Classification-F1 0.5105123571414064 on epoch=20
05/28/2022 09:11:38 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.06 on epoch=20
05/28/2022 09:11:40 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.04 on epoch=20
05/28/2022 09:11:43 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.04 on epoch=20
05/28/2022 09:11:45 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.07 on epoch=20
05/28/2022 09:11:48 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.04 on epoch=20
05/28/2022 09:12:37 - INFO - __main__ - Global step 2350 Train loss 0.05 Classification-F1 0.5598658060467913 on epoch=20
05/28/2022 09:12:39 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.08 on epoch=21
05/28/2022 09:12:42 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.03 on epoch=21
05/28/2022 09:12:45 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.07 on epoch=21
05/28/2022 09:12:47 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.05 on epoch=21
05/28/2022 09:12:50 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.04 on epoch=21
05/28/2022 09:13:39 - INFO - __main__ - Global step 2400 Train loss 0.06 Classification-F1 0.5508062686239811 on epoch=21
05/28/2022 09:13:41 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.07 on epoch=21
05/28/2022 09:13:44 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.05 on epoch=21
05/28/2022 09:13:46 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.07 on epoch=21
05/28/2022 09:13:49 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.07 on epoch=21
05/28/2022 09:13:51 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.04 on epoch=21
05/28/2022 09:14:40 - INFO - __main__ - Global step 2450 Train loss 0.06 Classification-F1 0.6383452232194651 on epoch=21
05/28/2022 09:14:40 - INFO - __main__ - Saving model with best Classification-F1: 0.6205139360727338 -> 0.6383452232194651 on epoch=21, global_step=2450
05/28/2022 09:14:42 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=21
05/28/2022 09:14:45 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.06 on epoch=22
05/28/2022 09:14:48 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=22
05/28/2022 09:14:50 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.04 on epoch=22
05/28/2022 09:14:53 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.09 on epoch=22
05/28/2022 09:15:42 - INFO - __main__ - Global step 2500 Train loss 0.05 Classification-F1 0.6702729272963439 on epoch=22
05/28/2022 09:15:42 - INFO - __main__ - Saving model with best Classification-F1: 0.6383452232194651 -> 0.6702729272963439 on epoch=22, global_step=2500
05/28/2022 09:15:44 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.05 on epoch=22
05/28/2022 09:15:47 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.09 on epoch=22
05/28/2022 09:15:50 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.10 on epoch=22
05/28/2022 09:15:52 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.03 on epoch=22
05/28/2022 09:15:55 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=22
05/28/2022 09:16:44 - INFO - __main__ - Global step 2550 Train loss 0.06 Classification-F1 0.6300303682606248 on epoch=22
05/28/2022 09:16:47 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.04 on epoch=22
05/28/2022 09:16:49 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.04 on epoch=22
05/28/2022 09:16:52 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.06 on epoch=23
05/28/2022 09:16:55 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.03 on epoch=23
05/28/2022 09:16:57 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.04 on epoch=23
05/28/2022 09:17:46 - INFO - __main__ - Global step 2600 Train loss 0.04 Classification-F1 0.6517819570300858 on epoch=23
05/28/2022 09:17:48 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.04 on epoch=23
05/28/2022 09:17:51 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.04 on epoch=23
05/28/2022 09:17:54 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.07 on epoch=23
05/28/2022 09:17:56 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.06 on epoch=23
05/28/2022 09:17:59 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=23
05/28/2022 09:18:46 - INFO - __main__ - Global step 2650 Train loss 0.05 Classification-F1 0.6416092933229892 on epoch=23
05/28/2022 09:18:49 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.05 on epoch=23
05/28/2022 09:18:51 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.03 on epoch=23
05/28/2022 09:18:54 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=23
05/28/2022 09:18:56 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.05 on epoch=24
05/28/2022 09:18:59 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.04 on epoch=24
05/28/2022 09:19:47 - INFO - __main__ - Global step 2700 Train loss 0.04 Classification-F1 0.6862317113485541 on epoch=24
05/28/2022 09:19:47 - INFO - __main__ - Saving model with best Classification-F1: 0.6702729272963439 -> 0.6862317113485541 on epoch=24, global_step=2700
05/28/2022 09:19:50 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.04 on epoch=24
05/28/2022 09:19:52 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.07 on epoch=24
05/28/2022 09:19:55 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.06 on epoch=24
05/28/2022 09:19:58 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.10 on epoch=24
05/28/2022 09:20:00 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.07 on epoch=24
05/28/2022 09:20:47 - INFO - __main__ - Global step 2750 Train loss 0.07 Classification-F1 0.5793283515086952 on epoch=24
05/28/2022 09:20:50 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.06 on epoch=24
05/28/2022 09:20:52 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=24
05/28/2022 09:20:55 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.06 on epoch=24
05/28/2022 09:20:57 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.06 on epoch=24
05/28/2022 09:21:00 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.04 on epoch=24
05/28/2022 09:21:47 - INFO - __main__ - Global step 2800 Train loss 0.05 Classification-F1 0.6081450020040566 on epoch=24
05/28/2022 09:21:50 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.03 on epoch=25
05/28/2022 09:21:53 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.03 on epoch=25
05/28/2022 09:21:55 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.07 on epoch=25
05/28/2022 09:21:58 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.03 on epoch=25
05/28/2022 09:22:00 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.05 on epoch=25
05/28/2022 09:22:48 - INFO - __main__ - Global step 2850 Train loss 0.04 Classification-F1 0.6326296247089472 on epoch=25
05/28/2022 09:22:50 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.07 on epoch=25
05/28/2022 09:22:53 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.06 on epoch=25
05/28/2022 09:22:56 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.04 on epoch=25
05/28/2022 09:22:58 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.03 on epoch=25
05/28/2022 09:23:01 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.04 on epoch=25
05/28/2022 09:23:50 - INFO - __main__ - Global step 2900 Train loss 0.05 Classification-F1 0.6753744152894168 on epoch=25
05/28/2022 09:23:53 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=25
05/28/2022 09:23:56 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.05 on epoch=26
05/28/2022 09:23:58 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.04 on epoch=26
05/28/2022 09:24:01 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.03 on epoch=26
05/28/2022 09:24:04 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.06 on epoch=26
05/28/2022 09:24:54 - INFO - __main__ - Global step 2950 Train loss 0.04 Classification-F1 0.6161334633559448 on epoch=26
05/28/2022 09:24:57 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.04 on epoch=26
05/28/2022 09:25:00 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.09 on epoch=26
05/28/2022 09:25:02 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.05 on epoch=26
05/28/2022 09:25:05 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.06 on epoch=26
05/28/2022 09:25:08 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=26
05/28/2022 09:25:09 - INFO - __main__ - Start tokenizing ... 1792 instances
05/28/2022 09:25:09 - INFO - __main__ - Printing 3 examples
05/28/2022 09:25:09 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/28/2022 09:25:09 - INFO - __main__ - ['Plant']
05/28/2022 09:25:09 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/28/2022 09:25:09 - INFO - __main__ - ['Plant']
05/28/2022 09:25:09 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/28/2022 09:25:09 - INFO - __main__ - ['Plant']
05/28/2022 09:25:09 - INFO - __main__ - Tokenizing Input ...
05/28/2022 09:25:10 - INFO - __main__ - Tokenizing Output ...
05/28/2022 09:25:12 - INFO - __main__ - Loaded 1792 examples from train data
05/28/2022 09:25:12 - INFO - __main__ - Start tokenizing ... 1792 instances
05/28/2022 09:25:12 - INFO - __main__ - Printing 3 examples
05/28/2022 09:25:12 - INFO - __main__ -  [dbpedia_14] Sabal pumos is a species of flowering plant in the palm tree family Arecaceae. It is native to the dry forests along the Balsas River in central Mexico (Guanajuato Guerrero Jalisco Michoacán Morelos Zacatecas and the State of México). It is threatened by habitat loss.
05/28/2022 09:25:12 - INFO - __main__ - ['Plant']
05/28/2022 09:25:12 - INFO - __main__ -  [dbpedia_14] Bulbophyllum intricatum is a species of orchid in the genus Bulbophyllum.
05/28/2022 09:25:12 - INFO - __main__ - ['Plant']
05/28/2022 09:25:12 - INFO - __main__ -  [dbpedia_14] Gentiana parryi (Parry's Gentian) is a species of the genus Gentiana.
05/28/2022 09:25:12 - INFO - __main__ - ['Plant']
05/28/2022 09:25:12 - INFO - __main__ - Tokenizing Input ...
05/28/2022 09:25:13 - INFO - __main__ - Tokenizing Output ...
05/28/2022 09:25:15 - INFO - __main__ - Loaded 1792 examples from dev data
05/28/2022 09:25:33 - INFO - __main__ - load prompt embedding from ckpt
05/28/2022 09:25:34 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/28/2022 09:25:34 - INFO - __main__ - Starting training!
05/28/2022 09:25:58 - INFO - __main__ - Global step 3000 Train loss 0.05 Classification-F1 0.6791772665786132 on epoch=26
05/28/2022 09:25:58 - INFO - __main__ - save last model!
05/28/2022 09:25:58 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/28/2022 09:25:58 - INFO - __main__ - Start tokenizing ... 3500 instances
05/28/2022 09:25:58 - INFO - __main__ - Printing 3 examples
05/28/2022 09:25:58 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/28/2022 09:25:58 - INFO - __main__ - ['Animal']
05/28/2022 09:25:58 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/28/2022 09:25:58 - INFO - __main__ - ['Animal']
05/28/2022 09:25:58 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/28/2022 09:25:58 - INFO - __main__ - ['Village']
05/28/2022 09:25:58 - INFO - __main__ - Tokenizing Input ...
05/28/2022 09:26:00 - INFO - __main__ - Tokenizing Output ...
05/28/2022 09:26:03 - INFO - __main__ - Loaded 3500 examples from test data
05/28/2022 09:28:00 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down128shot/singletask-dbpedia_14/dbpedia_14_128_21_0.3_8_predictions.txt
05/28/2022 09:28:00 - INFO - __main__ - Classification-F1 on test data: 0.5829
05/28/2022 09:28:00 - INFO - __main__ - prefix=dbpedia_14_128_21, lr=0.3, bsz=8, dev_performance=0.6862317113485541, test_performance=0.5828502819338948
05/28/2022 09:28:00 - INFO - __main__ - Running ... prefix=dbpedia_14_128_21, lr=0.2, bsz=8 ...
05/28/2022 09:28:01 - INFO - __main__ - Start tokenizing ... 1792 instances
05/28/2022 09:28:01 - INFO - __main__ - Printing 3 examples
05/28/2022 09:28:01 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/28/2022 09:28:01 - INFO - __main__ - ['Plant']
05/28/2022 09:28:01 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/28/2022 09:28:01 - INFO - __main__ - ['Plant']
05/28/2022 09:28:01 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/28/2022 09:28:01 - INFO - __main__ - ['Plant']
05/28/2022 09:28:01 - INFO - __main__ - Tokenizing Input ...
05/28/2022 09:28:02 - INFO - __main__ - Tokenizing Output ...
05/28/2022 09:28:03 - INFO - __main__ - Loaded 1792 examples from train data
05/28/2022 09:28:03 - INFO - __main__ - Start tokenizing ... 1792 instances
05/28/2022 09:28:03 - INFO - __main__ - Printing 3 examples
05/28/2022 09:28:03 - INFO - __main__ -  [dbpedia_14] Sabal pumos is a species of flowering plant in the palm tree family Arecaceae. It is native to the dry forests along the Balsas River in central Mexico (Guanajuato Guerrero Jalisco Michoacán Morelos Zacatecas and the State of México). It is threatened by habitat loss.
05/28/2022 09:28:03 - INFO - __main__ - ['Plant']
05/28/2022 09:28:03 - INFO - __main__ -  [dbpedia_14] Bulbophyllum intricatum is a species of orchid in the genus Bulbophyllum.
05/28/2022 09:28:03 - INFO - __main__ - ['Plant']
05/28/2022 09:28:03 - INFO - __main__ -  [dbpedia_14] Gentiana parryi (Parry's Gentian) is a species of the genus Gentiana.
05/28/2022 09:28:03 - INFO - __main__ - ['Plant']
05/28/2022 09:28:03 - INFO - __main__ - Tokenizing Input ...
05/28/2022 09:28:04 - INFO - __main__ - Tokenizing Output ...
05/28/2022 09:28:06 - INFO - __main__ - Loaded 1792 examples from dev data
05/28/2022 09:28:24 - INFO - __main__ - load prompt embedding from ckpt
05/28/2022 09:28:25 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/28/2022 09:28:25 - INFO - __main__ - Starting training!
05/28/2022 09:28:28 - INFO - __main__ - Step 10 Global step 10 Train loss 7.79 on epoch=0
05/28/2022 09:28:31 - INFO - __main__ - Step 20 Global step 20 Train loss 6.28 on epoch=0
05/28/2022 09:28:34 - INFO - __main__ - Step 30 Global step 30 Train loss 5.35 on epoch=0
05/28/2022 09:28:37 - INFO - __main__ - Step 40 Global step 40 Train loss 4.71 on epoch=0
05/28/2022 09:28:39 - INFO - __main__ - Step 50 Global step 50 Train loss 4.39 on epoch=0
05/28/2022 09:29:25 - INFO - __main__ - Global step 50 Train loss 5.71 Classification-F1 0.009278242373003625 on epoch=0
05/28/2022 09:29:25 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.009278242373003625 on epoch=0, global_step=50
05/28/2022 09:29:28 - INFO - __main__ - Step 60 Global step 60 Train loss 4.05 on epoch=0
05/28/2022 09:29:31 - INFO - __main__ - Step 70 Global step 70 Train loss 3.75 on epoch=0
05/28/2022 09:29:34 - INFO - __main__ - Step 80 Global step 80 Train loss 3.77 on epoch=0
05/28/2022 09:29:37 - INFO - __main__ - Step 90 Global step 90 Train loss 3.26 on epoch=0
05/28/2022 09:29:39 - INFO - __main__ - Step 100 Global step 100 Train loss 2.57 on epoch=0
05/28/2022 09:30:34 - INFO - __main__ - Global step 100 Train loss 3.48 Classification-F1 0.010165670543321821 on epoch=0
05/28/2022 09:30:34 - INFO - __main__ - Saving model with best Classification-F1: 0.009278242373003625 -> 0.010165670543321821 on epoch=0, global_step=100
05/28/2022 09:30:37 - INFO - __main__ - Step 110 Global step 110 Train loss 2.77 on epoch=0
05/28/2022 09:30:40 - INFO - __main__ - Step 120 Global step 120 Train loss 2.86 on epoch=1
05/28/2022 09:30:42 - INFO - __main__ - Step 130 Global step 130 Train loss 2.69 on epoch=1
05/28/2022 09:30:45 - INFO - __main__ - Step 140 Global step 140 Train loss 2.61 on epoch=1
05/28/2022 09:30:48 - INFO - __main__ - Step 150 Global step 150 Train loss 2.21 on epoch=1
05/28/2022 09:31:39 - INFO - __main__ - Global step 150 Train loss 2.63 Classification-F1 0.021266073905896434 on epoch=1
05/28/2022 09:31:39 - INFO - __main__ - Saving model with best Classification-F1: 0.010165670543321821 -> 0.021266073905896434 on epoch=1, global_step=150
05/28/2022 09:31:41 - INFO - __main__ - Step 160 Global step 160 Train loss 2.55 on epoch=1
05/28/2022 09:31:44 - INFO - __main__ - Step 170 Global step 170 Train loss 2.19 on epoch=1
05/28/2022 09:31:47 - INFO - __main__ - Step 180 Global step 180 Train loss 2.09 on epoch=1
05/28/2022 09:31:49 - INFO - __main__ - Step 190 Global step 190 Train loss 2.07 on epoch=1
05/28/2022 09:31:52 - INFO - __main__ - Step 200 Global step 200 Train loss 2.07 on epoch=1
05/28/2022 09:32:39 - INFO - __main__ - Global step 200 Train loss 2.19 Classification-F1 0.037411829718701814 on epoch=1
05/28/2022 09:32:39 - INFO - __main__ - Saving model with best Classification-F1: 0.021266073905896434 -> 0.037411829718701814 on epoch=1, global_step=200
05/28/2022 09:32:42 - INFO - __main__ - Step 210 Global step 210 Train loss 1.73 on epoch=1
05/28/2022 09:32:44 - INFO - __main__ - Step 220 Global step 220 Train loss 1.75 on epoch=1
05/28/2022 09:32:47 - INFO - __main__ - Step 230 Global step 230 Train loss 1.82 on epoch=2
05/28/2022 09:32:50 - INFO - __main__ - Step 240 Global step 240 Train loss 1.60 on epoch=2
05/28/2022 09:32:52 - INFO - __main__ - Step 250 Global step 250 Train loss 1.72 on epoch=2
05/28/2022 09:33:37 - INFO - __main__ - Global step 250 Train loss 1.72 Classification-F1 0.05942017667303627 on epoch=2
05/28/2022 09:33:37 - INFO - __main__ - Saving model with best Classification-F1: 0.037411829718701814 -> 0.05942017667303627 on epoch=2, global_step=250
05/28/2022 09:33:40 - INFO - __main__ - Step 260 Global step 260 Train loss 1.51 on epoch=2
05/28/2022 09:33:42 - INFO - __main__ - Step 270 Global step 270 Train loss 1.63 on epoch=2
05/28/2022 09:33:45 - INFO - __main__ - Step 280 Global step 280 Train loss 1.56 on epoch=2
05/28/2022 09:33:47 - INFO - __main__ - Step 290 Global step 290 Train loss 1.41 on epoch=2
05/28/2022 09:33:50 - INFO - __main__ - Step 300 Global step 300 Train loss 1.37 on epoch=2
05/28/2022 09:34:35 - INFO - __main__ - Global step 300 Train loss 1.50 Classification-F1 0.08519967143057691 on epoch=2
05/28/2022 09:34:35 - INFO - __main__ - Saving model with best Classification-F1: 0.05942017667303627 -> 0.08519967143057691 on epoch=2, global_step=300
05/28/2022 09:34:37 - INFO - __main__ - Step 310 Global step 310 Train loss 1.43 on epoch=2
05/28/2022 09:34:40 - INFO - __main__ - Step 320 Global step 320 Train loss 1.17 on epoch=2
05/28/2022 09:34:42 - INFO - __main__ - Step 330 Global step 330 Train loss 1.16 on epoch=2
05/28/2022 09:34:45 - INFO - __main__ - Step 340 Global step 340 Train loss 1.21 on epoch=3
05/28/2022 09:34:48 - INFO - __main__ - Step 350 Global step 350 Train loss 1.15 on epoch=3
05/28/2022 09:35:31 - INFO - __main__ - Global step 350 Train loss 1.22 Classification-F1 0.12070971926536239 on epoch=3
05/28/2022 09:35:31 - INFO - __main__ - Saving model with best Classification-F1: 0.08519967143057691 -> 0.12070971926536239 on epoch=3, global_step=350
05/28/2022 09:35:34 - INFO - __main__ - Step 360 Global step 360 Train loss 1.11 on epoch=3
05/28/2022 09:35:37 - INFO - __main__ - Step 370 Global step 370 Train loss 0.93 on epoch=3
05/28/2022 09:35:40 - INFO - __main__ - Step 380 Global step 380 Train loss 1.05 on epoch=3
05/28/2022 09:35:42 - INFO - __main__ - Step 390 Global step 390 Train loss 1.02 on epoch=3
05/28/2022 09:35:45 - INFO - __main__ - Step 400 Global step 400 Train loss 0.94 on epoch=3
05/28/2022 09:36:29 - INFO - __main__ - Global step 400 Train loss 1.01 Classification-F1 0.14183369643081742 on epoch=3
05/28/2022 09:36:29 - INFO - __main__ - Saving model with best Classification-F1: 0.12070971926536239 -> 0.14183369643081742 on epoch=3, global_step=400
05/28/2022 09:36:32 - INFO - __main__ - Step 410 Global step 410 Train loss 0.93 on epoch=3
05/28/2022 09:36:35 - INFO - __main__ - Step 420 Global step 420 Train loss 0.89 on epoch=3
05/28/2022 09:36:37 - INFO - __main__ - Step 430 Global step 430 Train loss 0.75 on epoch=3
05/28/2022 09:36:40 - INFO - __main__ - Step 440 Global step 440 Train loss 0.70 on epoch=3
05/28/2022 09:36:42 - INFO - __main__ - Step 450 Global step 450 Train loss 0.76 on epoch=4
05/28/2022 09:37:30 - INFO - __main__ - Global step 450 Train loss 0.80 Classification-F1 0.1833224682395192 on epoch=4
05/28/2022 09:37:30 - INFO - __main__ - Saving model with best Classification-F1: 0.14183369643081742 -> 0.1833224682395192 on epoch=4, global_step=450
05/28/2022 09:37:32 - INFO - __main__ - Step 460 Global step 460 Train loss 0.69 on epoch=4
05/28/2022 09:37:35 - INFO - __main__ - Step 470 Global step 470 Train loss 0.64 on epoch=4
05/28/2022 09:37:38 - INFO - __main__ - Step 480 Global step 480 Train loss 0.60 on epoch=4
05/28/2022 09:37:40 - INFO - __main__ - Step 490 Global step 490 Train loss 0.62 on epoch=4
05/28/2022 09:37:43 - INFO - __main__ - Step 500 Global step 500 Train loss 0.64 on epoch=4
05/28/2022 09:38:32 - INFO - __main__ - Global step 500 Train loss 0.64 Classification-F1 0.21189797790526047 on epoch=4
05/28/2022 09:38:32 - INFO - __main__ - Saving model with best Classification-F1: 0.1833224682395192 -> 0.21189797790526047 on epoch=4, global_step=500
05/28/2022 09:38:35 - INFO - __main__ - Step 510 Global step 510 Train loss 0.64 on epoch=4
05/28/2022 09:38:38 - INFO - __main__ - Step 520 Global step 520 Train loss 0.60 on epoch=4
05/28/2022 09:38:40 - INFO - __main__ - Step 530 Global step 530 Train loss 0.66 on epoch=4
05/28/2022 09:38:43 - INFO - __main__ - Step 540 Global step 540 Train loss 0.57 on epoch=4
05/28/2022 09:38:46 - INFO - __main__ - Step 550 Global step 550 Train loss 0.45 on epoch=4
05/28/2022 09:39:38 - INFO - __main__ - Global step 550 Train loss 0.58 Classification-F1 0.2761169210178341 on epoch=4
05/28/2022 09:39:38 - INFO - __main__ - Saving model with best Classification-F1: 0.21189797790526047 -> 0.2761169210178341 on epoch=4, global_step=550
05/28/2022 09:39:41 - INFO - __main__ - Step 560 Global step 560 Train loss 0.60 on epoch=4
05/28/2022 09:39:43 - INFO - __main__ - Step 570 Global step 570 Train loss 0.53 on epoch=5
05/28/2022 09:39:46 - INFO - __main__ - Step 580 Global step 580 Train loss 0.52 on epoch=5
05/28/2022 09:39:49 - INFO - __main__ - Step 590 Global step 590 Train loss 0.43 on epoch=5
05/28/2022 09:39:51 - INFO - __main__ - Step 600 Global step 600 Train loss 0.48 on epoch=5
05/28/2022 09:40:44 - INFO - __main__ - Global step 600 Train loss 0.51 Classification-F1 0.2844827857870835 on epoch=5
05/28/2022 09:40:44 - INFO - __main__ - Saving model with best Classification-F1: 0.2761169210178341 -> 0.2844827857870835 on epoch=5, global_step=600
05/28/2022 09:40:47 - INFO - __main__ - Step 610 Global step 610 Train loss 0.47 on epoch=5
05/28/2022 09:40:50 - INFO - __main__ - Step 620 Global step 620 Train loss 0.48 on epoch=5
05/28/2022 09:40:52 - INFO - __main__ - Step 630 Global step 630 Train loss 0.48 on epoch=5
05/28/2022 09:40:55 - INFO - __main__ - Step 640 Global step 640 Train loss 0.48 on epoch=5
05/28/2022 09:40:58 - INFO - __main__ - Step 650 Global step 650 Train loss 0.36 on epoch=5
05/28/2022 09:41:51 - INFO - __main__ - Global step 650 Train loss 0.46 Classification-F1 0.32935360004593955 on epoch=5
05/28/2022 09:41:51 - INFO - __main__ - Saving model with best Classification-F1: 0.2844827857870835 -> 0.32935360004593955 on epoch=5, global_step=650
05/28/2022 09:41:53 - INFO - __main__ - Step 660 Global step 660 Train loss 0.40 on epoch=5
05/28/2022 09:41:56 - INFO - __main__ - Step 670 Global step 670 Train loss 0.32 on epoch=5
05/28/2022 09:41:59 - INFO - __main__ - Step 680 Global step 680 Train loss 0.52 on epoch=6
05/28/2022 09:42:02 - INFO - __main__ - Step 690 Global step 690 Train loss 0.44 on epoch=6
05/28/2022 09:42:04 - INFO - __main__ - Step 700 Global step 700 Train loss 0.42 on epoch=6
05/28/2022 09:42:57 - INFO - __main__ - Global step 700 Train loss 0.42 Classification-F1 0.3446369781659665 on epoch=6
05/28/2022 09:42:57 - INFO - __main__ - Saving model with best Classification-F1: 0.32935360004593955 -> 0.3446369781659665 on epoch=6, global_step=700
05/28/2022 09:43:00 - INFO - __main__ - Step 710 Global step 710 Train loss 0.30 on epoch=6
05/28/2022 09:43:03 - INFO - __main__ - Step 720 Global step 720 Train loss 0.33 on epoch=6
05/28/2022 09:43:05 - INFO - __main__ - Step 730 Global step 730 Train loss 0.45 on epoch=6
05/28/2022 09:43:08 - INFO - __main__ - Step 740 Global step 740 Train loss 0.40 on epoch=6
05/28/2022 09:43:11 - INFO - __main__ - Step 750 Global step 750 Train loss 0.32 on epoch=6
05/28/2022 09:44:04 - INFO - __main__ - Global step 750 Train loss 0.36 Classification-F1 0.37121226911009253 on epoch=6
05/28/2022 09:44:04 - INFO - __main__ - Saving model with best Classification-F1: 0.3446369781659665 -> 0.37121226911009253 on epoch=6, global_step=750
05/28/2022 09:44:07 - INFO - __main__ - Step 760 Global step 760 Train loss 0.38 on epoch=6
05/28/2022 09:44:09 - INFO - __main__ - Step 770 Global step 770 Train loss 0.32 on epoch=6
05/28/2022 09:44:12 - INFO - __main__ - Step 780 Global step 780 Train loss 0.29 on epoch=6
05/28/2022 09:44:14 - INFO - __main__ - Step 790 Global step 790 Train loss 0.40 on epoch=7
05/28/2022 09:44:17 - INFO - __main__ - Step 800 Global step 800 Train loss 0.28 on epoch=7
05/28/2022 09:45:12 - INFO - __main__ - Global step 800 Train loss 0.33 Classification-F1 0.4130042090927838 on epoch=7
05/28/2022 09:45:12 - INFO - __main__ - Saving model with best Classification-F1: 0.37121226911009253 -> 0.4130042090927838 on epoch=7, global_step=800
05/28/2022 09:45:15 - INFO - __main__ - Step 810 Global step 810 Train loss 0.31 on epoch=7
05/28/2022 09:45:17 - INFO - __main__ - Step 820 Global step 820 Train loss 0.38 on epoch=7
05/28/2022 09:45:20 - INFO - __main__ - Step 830 Global step 830 Train loss 0.27 on epoch=7
05/28/2022 09:45:22 - INFO - __main__ - Step 840 Global step 840 Train loss 0.36 on epoch=7
05/28/2022 09:45:25 - INFO - __main__ - Step 850 Global step 850 Train loss 0.32 on epoch=7
05/28/2022 09:46:18 - INFO - __main__ - Global step 850 Train loss 0.33 Classification-F1 0.4093996693996507 on epoch=7
05/28/2022 09:46:20 - INFO - __main__ - Step 860 Global step 860 Train loss 0.47 on epoch=7
05/28/2022 09:46:23 - INFO - __main__ - Step 870 Global step 870 Train loss 0.31 on epoch=7
05/28/2022 09:46:26 - INFO - __main__ - Step 880 Global step 880 Train loss 0.21 on epoch=7
05/28/2022 09:46:28 - INFO - __main__ - Step 890 Global step 890 Train loss 0.24 on epoch=7
05/28/2022 09:46:31 - INFO - __main__ - Step 900 Global step 900 Train loss 0.29 on epoch=8
05/28/2022 09:47:24 - INFO - __main__ - Global step 900 Train loss 0.30 Classification-F1 0.37846196284228634 on epoch=8
05/28/2022 09:47:27 - INFO - __main__ - Step 910 Global step 910 Train loss 0.25 on epoch=8
05/28/2022 09:47:30 - INFO - __main__ - Step 920 Global step 920 Train loss 0.24 on epoch=8
05/28/2022 09:47:32 - INFO - __main__ - Step 930 Global step 930 Train loss 0.22 on epoch=8
05/28/2022 09:47:35 - INFO - __main__ - Step 940 Global step 940 Train loss 0.24 on epoch=8
05/28/2022 09:47:37 - INFO - __main__ - Step 950 Global step 950 Train loss 0.25 on epoch=8
05/28/2022 09:48:30 - INFO - __main__ - Global step 950 Train loss 0.24 Classification-F1 0.4446193327251688 on epoch=8
05/28/2022 09:48:30 - INFO - __main__ - Saving model with best Classification-F1: 0.4130042090927838 -> 0.4446193327251688 on epoch=8, global_step=950
05/28/2022 09:48:33 - INFO - __main__ - Step 960 Global step 960 Train loss 0.26 on epoch=8
05/28/2022 09:48:36 - INFO - __main__ - Step 970 Global step 970 Train loss 0.24 on epoch=8
05/28/2022 09:48:38 - INFO - __main__ - Step 980 Global step 980 Train loss 0.29 on epoch=8
05/28/2022 09:48:41 - INFO - __main__ - Step 990 Global step 990 Train loss 0.25 on epoch=8
05/28/2022 09:48:44 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.22 on epoch=8
05/28/2022 09:49:36 - INFO - __main__ - Global step 1000 Train loss 0.25 Classification-F1 0.49326502183380583 on epoch=8
05/28/2022 09:49:36 - INFO - __main__ - Saving model with best Classification-F1: 0.4446193327251688 -> 0.49326502183380583 on epoch=8, global_step=1000
05/28/2022 09:49:38 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.28 on epoch=9
05/28/2022 09:49:41 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.20 on epoch=9
05/28/2022 09:49:44 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.17 on epoch=9
05/28/2022 09:49:47 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.19 on epoch=9
05/28/2022 09:49:49 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.21 on epoch=9
05/28/2022 09:50:41 - INFO - __main__ - Global step 1050 Train loss 0.21 Classification-F1 0.41088590596222063 on epoch=9
05/28/2022 09:50:44 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.19 on epoch=9
05/28/2022 09:50:46 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.18 on epoch=9
05/28/2022 09:50:49 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.24 on epoch=9
05/28/2022 09:50:52 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.16 on epoch=9
05/28/2022 09:50:54 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.26 on epoch=9
05/28/2022 09:51:46 - INFO - __main__ - Global step 1100 Train loss 0.21 Classification-F1 0.4970559727381114 on epoch=9
05/28/2022 09:51:46 - INFO - __main__ - Saving model with best Classification-F1: 0.49326502183380583 -> 0.4970559727381114 on epoch=9, global_step=1100
05/28/2022 09:51:49 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.21 on epoch=9
05/28/2022 09:51:51 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.27 on epoch=9
05/28/2022 09:51:54 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.24 on epoch=10
05/28/2022 09:51:57 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.19 on epoch=10
05/28/2022 09:51:59 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.19 on epoch=10
05/28/2022 09:52:51 - INFO - __main__ - Global step 1150 Train loss 0.22 Classification-F1 0.5054336247727675 on epoch=10
05/28/2022 09:52:51 - INFO - __main__ - Saving model with best Classification-F1: 0.4970559727381114 -> 0.5054336247727675 on epoch=10, global_step=1150
05/28/2022 09:52:54 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.20 on epoch=10
05/28/2022 09:52:56 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.27 on epoch=10
05/28/2022 09:52:59 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.24 on epoch=10
05/28/2022 09:53:02 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.16 on epoch=10
05/28/2022 09:53:04 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.17 on epoch=10
05/28/2022 09:53:57 - INFO - __main__ - Global step 1200 Train loss 0.21 Classification-F1 0.5161711695958214 on epoch=10
05/28/2022 09:53:57 - INFO - __main__ - Saving model with best Classification-F1: 0.5054336247727675 -> 0.5161711695958214 on epoch=10, global_step=1200
05/28/2022 09:53:59 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.24 on epoch=10
05/28/2022 09:54:02 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.19 on epoch=10
05/28/2022 09:54:05 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.23 on epoch=10
05/28/2022 09:54:07 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.17 on epoch=11
05/28/2022 09:54:10 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.24 on epoch=11
05/28/2022 09:55:03 - INFO - __main__ - Global step 1250 Train loss 0.21 Classification-F1 0.5561437288105883 on epoch=11
05/28/2022 09:55:03 - INFO - __main__ - Saving model with best Classification-F1: 0.5161711695958214 -> 0.5561437288105883 on epoch=11, global_step=1250
05/28/2022 09:55:06 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.19 on epoch=11
05/28/2022 09:55:08 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.22 on epoch=11
05/28/2022 09:55:11 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.17 on epoch=11
05/28/2022 09:55:14 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.18 on epoch=11
05/28/2022 09:55:16 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.23 on epoch=11
05/28/2022 09:56:08 - INFO - __main__ - Global step 1300 Train loss 0.20 Classification-F1 0.5345261524581361 on epoch=11
05/28/2022 09:56:10 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.21 on epoch=11
05/28/2022 09:56:13 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.14 on epoch=11
05/28/2022 09:56:16 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.19 on epoch=11
05/28/2022 09:56:18 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.15 on epoch=11
05/28/2022 09:56:21 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.19 on epoch=12
05/28/2022 09:57:13 - INFO - __main__ - Global step 1350 Train loss 0.18 Classification-F1 0.532753222984972 on epoch=12
05/28/2022 09:57:16 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.16 on epoch=12
05/28/2022 09:57:19 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.11 on epoch=12
05/28/2022 09:57:21 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.29 on epoch=12
05/28/2022 09:57:24 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.15 on epoch=12
05/28/2022 09:57:27 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.29 on epoch=12
05/28/2022 09:58:18 - INFO - __main__ - Global step 1400 Train loss 0.20 Classification-F1 0.5092507387721757 on epoch=12
05/28/2022 09:58:21 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.18 on epoch=12
05/28/2022 09:58:23 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.17 on epoch=12
05/28/2022 09:58:26 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.17 on epoch=12
05/28/2022 09:58:29 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.16 on epoch=12
05/28/2022 09:58:31 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.16 on epoch=12
05/28/2022 09:59:22 - INFO - __main__ - Global step 1450 Train loss 0.17 Classification-F1 0.5125272011694029 on epoch=12
05/28/2022 09:59:25 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.16 on epoch=13
05/28/2022 09:59:28 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.13 on epoch=13
05/28/2022 09:59:30 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.13 on epoch=13
05/28/2022 09:59:33 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.23 on epoch=13
05/28/2022 09:59:36 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.21 on epoch=13
05/28/2022 10:00:25 - INFO - __main__ - Global step 1500 Train loss 0.17 Classification-F1 0.5390504690221082 on epoch=13
05/28/2022 10:00:28 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.18 on epoch=13
05/28/2022 10:00:31 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.15 on epoch=13
05/28/2022 10:00:34 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.15 on epoch=13
05/28/2022 10:00:36 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.13 on epoch=13
05/28/2022 10:00:39 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.20 on epoch=13
05/28/2022 10:01:30 - INFO - __main__ - Global step 1550 Train loss 0.16 Classification-F1 0.5434014178267058 on epoch=13
05/28/2022 10:01:32 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.15 on epoch=13
05/28/2022 10:01:35 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.20 on epoch=14
05/28/2022 10:01:38 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.13 on epoch=14
05/28/2022 10:01:41 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.12 on epoch=14
05/28/2022 10:01:43 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.11 on epoch=14
05/28/2022 10:02:34 - INFO - __main__ - Global step 1600 Train loss 0.14 Classification-F1 0.545296611232496 on epoch=14
05/28/2022 10:02:36 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.14 on epoch=14
05/28/2022 10:02:39 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.11 on epoch=14
05/28/2022 10:02:41 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.13 on epoch=14
05/28/2022 10:02:44 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.18 on epoch=14
05/28/2022 10:02:47 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.13 on epoch=14
05/28/2022 10:03:38 - INFO - __main__ - Global step 1650 Train loss 0.14 Classification-F1 0.5946142690238613 on epoch=14
05/28/2022 10:03:38 - INFO - __main__ - Saving model with best Classification-F1: 0.5561437288105883 -> 0.5946142690238613 on epoch=14, global_step=1650
05/28/2022 10:03:41 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.12 on epoch=14
05/28/2022 10:03:43 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.16 on epoch=14
05/28/2022 10:03:46 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.12 on epoch=14
05/28/2022 10:03:48 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.13 on epoch=15
05/28/2022 10:03:51 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.12 on epoch=15
05/28/2022 10:04:40 - INFO - __main__ - Global step 1700 Train loss 0.13 Classification-F1 0.49951426935205767 on epoch=15
05/28/2022 10:04:43 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.14 on epoch=15
05/28/2022 10:04:45 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.17 on epoch=15
05/28/2022 10:04:48 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.19 on epoch=15
05/28/2022 10:04:51 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.25 on epoch=15
05/28/2022 10:04:53 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.12 on epoch=15
05/28/2022 10:05:43 - INFO - __main__ - Global step 1750 Train loss 0.17 Classification-F1 0.5426931619264801 on epoch=15
05/28/2022 10:05:46 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.10 on epoch=15
05/28/2022 10:05:48 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.18 on epoch=15
05/28/2022 10:05:51 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.11 on epoch=15
05/28/2022 10:05:53 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.09 on epoch=15
05/28/2022 10:05:56 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.10 on epoch=16
05/28/2022 10:06:47 - INFO - __main__ - Global step 1800 Train loss 0.12 Classification-F1 0.5662744611126999 on epoch=16
05/28/2022 10:06:50 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.10 on epoch=16
05/28/2022 10:06:52 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.15 on epoch=16
05/28/2022 10:06:55 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.14 on epoch=16
05/28/2022 10:06:57 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.15 on epoch=16
05/28/2022 10:07:00 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.12 on epoch=16
05/28/2022 10:07:49 - INFO - __main__ - Global step 1850 Train loss 0.13 Classification-F1 0.5697697063490781 on epoch=16
05/28/2022 10:07:52 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.18 on epoch=16
05/28/2022 10:07:55 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.09 on epoch=16
05/28/2022 10:07:57 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.11 on epoch=16
05/28/2022 10:08:00 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.12 on epoch=16
05/28/2022 10:08:03 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.09 on epoch=16
05/28/2022 10:08:53 - INFO - __main__ - Global step 1900 Train loss 0.12 Classification-F1 0.600199191819548 on epoch=16
05/28/2022 10:08:53 - INFO - __main__ - Saving model with best Classification-F1: 0.5946142690238613 -> 0.600199191819548 on epoch=16, global_step=1900
05/28/2022 10:08:56 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.12 on epoch=17
05/28/2022 10:08:59 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.07 on epoch=17
05/28/2022 10:09:01 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.11 on epoch=17
05/28/2022 10:09:04 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.13 on epoch=17
05/28/2022 10:09:06 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.09 on epoch=17
05/28/2022 10:09:57 - INFO - __main__ - Global step 1950 Train loss 0.10 Classification-F1 0.5724595437297282 on epoch=17
05/28/2022 10:09:59 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.14 on epoch=17
05/28/2022 10:10:02 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.12 on epoch=17
05/28/2022 10:10:05 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.16 on epoch=17
05/28/2022 10:10:07 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.15 on epoch=17
05/28/2022 10:10:10 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.09 on epoch=17
05/28/2022 10:11:00 - INFO - __main__ - Global step 2000 Train loss 0.13 Classification-F1 0.572005904562745 on epoch=17
05/28/2022 10:11:02 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.12 on epoch=17
05/28/2022 10:11:05 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.12 on epoch=18
05/28/2022 10:11:08 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.08 on epoch=18
05/28/2022 10:11:10 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.06 on epoch=18
05/28/2022 10:11:13 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.20 on epoch=18
05/28/2022 10:12:02 - INFO - __main__ - Global step 2050 Train loss 0.12 Classification-F1 0.5714555070329191 on epoch=18
05/28/2022 10:12:04 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.18 on epoch=18
05/28/2022 10:12:07 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.09 on epoch=18
05/28/2022 10:12:10 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.12 on epoch=18
05/28/2022 10:12:13 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.13 on epoch=18
05/28/2022 10:12:15 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.09 on epoch=18
05/28/2022 10:13:04 - INFO - __main__ - Global step 2100 Train loss 0.12 Classification-F1 0.5748689653535842 on epoch=18
05/28/2022 10:13:07 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.07 on epoch=18
05/28/2022 10:13:10 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.10 on epoch=18
05/28/2022 10:13:12 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.11 on epoch=19
05/28/2022 10:13:15 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.05 on epoch=19
05/28/2022 10:13:18 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.10 on epoch=19
05/28/2022 10:14:07 - INFO - __main__ - Global step 2150 Train loss 0.09 Classification-F1 0.5280909853591957 on epoch=19
05/28/2022 10:14:09 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.12 on epoch=19
05/28/2022 10:14:12 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.15 on epoch=19
05/28/2022 10:14:15 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.12 on epoch=19
05/28/2022 10:14:17 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.07 on epoch=19
05/28/2022 10:14:20 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.08 on epoch=19
05/28/2022 10:15:09 - INFO - __main__ - Global step 2200 Train loss 0.11 Classification-F1 0.5504244315652973 on epoch=19
05/28/2022 10:15:11 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.13 on epoch=19
05/28/2022 10:15:14 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.07 on epoch=19
05/28/2022 10:15:17 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.11 on epoch=19
05/28/2022 10:15:19 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.06 on epoch=19
05/28/2022 10:15:22 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.08 on epoch=20
05/28/2022 10:16:11 - INFO - __main__ - Global step 2250 Train loss 0.09 Classification-F1 0.6024800424279633 on epoch=20
05/28/2022 10:16:11 - INFO - __main__ - Saving model with best Classification-F1: 0.600199191819548 -> 0.6024800424279633 on epoch=20, global_step=2250
05/28/2022 10:16:14 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.06 on epoch=20
05/28/2022 10:16:17 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.07 on epoch=20
05/28/2022 10:16:19 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.13 on epoch=20
05/28/2022 10:16:22 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.12 on epoch=20
05/28/2022 10:16:24 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.10 on epoch=20
05/28/2022 10:17:13 - INFO - __main__ - Global step 2300 Train loss 0.10 Classification-F1 0.605009075245765 on epoch=20
05/28/2022 10:17:13 - INFO - __main__ - Saving model with best Classification-F1: 0.6024800424279633 -> 0.605009075245765 on epoch=20, global_step=2300
05/28/2022 10:17:16 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.17 on epoch=20
05/28/2022 10:17:19 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.11 on epoch=20
05/28/2022 10:17:21 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.12 on epoch=20
05/28/2022 10:17:24 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.05 on epoch=20
05/28/2022 10:17:27 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.06 on epoch=20
05/28/2022 10:18:16 - INFO - __main__ - Global step 2350 Train loss 0.10 Classification-F1 0.607495365717537 on epoch=20
05/28/2022 10:18:16 - INFO - __main__ - Saving model with best Classification-F1: 0.605009075245765 -> 0.607495365717537 on epoch=20, global_step=2350
05/28/2022 10:18:19 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.11 on epoch=21
05/28/2022 10:18:21 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.09 on epoch=21
05/28/2022 10:18:24 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.09 on epoch=21
05/28/2022 10:18:27 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.14 on epoch=21
05/28/2022 10:18:29 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.04 on epoch=21
05/28/2022 10:19:18 - INFO - __main__ - Global step 2400 Train loss 0.10 Classification-F1 0.6717010844123287 on epoch=21
05/28/2022 10:19:18 - INFO - __main__ - Saving model with best Classification-F1: 0.607495365717537 -> 0.6717010844123287 on epoch=21, global_step=2400
05/28/2022 10:19:21 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.13 on epoch=21
05/28/2022 10:19:24 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.10 on epoch=21
05/28/2022 10:19:26 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.13 on epoch=21
05/28/2022 10:19:29 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.11 on epoch=21
05/28/2022 10:19:32 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.06 on epoch=21
05/28/2022 10:20:21 - INFO - __main__ - Global step 2450 Train loss 0.10 Classification-F1 0.6321687021578876 on epoch=21
05/28/2022 10:20:24 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.07 on epoch=21
05/28/2022 10:20:26 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.12 on epoch=22
05/28/2022 10:20:29 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.12 on epoch=22
05/28/2022 10:20:32 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.06 on epoch=22
05/28/2022 10:20:34 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.11 on epoch=22
05/28/2022 10:21:23 - INFO - __main__ - Global step 2500 Train loss 0.09 Classification-F1 0.6317301256437978 on epoch=22
05/28/2022 10:21:25 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.09 on epoch=22
05/28/2022 10:21:28 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.12 on epoch=22
05/28/2022 10:21:31 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.17 on epoch=22
05/28/2022 10:21:33 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.06 on epoch=22
05/28/2022 10:21:36 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.09 on epoch=22
05/28/2022 10:22:25 - INFO - __main__ - Global step 2550 Train loss 0.10 Classification-F1 0.63830264986189 on epoch=22
05/28/2022 10:22:27 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.08 on epoch=22
05/28/2022 10:22:30 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.14 on epoch=22
05/28/2022 10:22:33 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.09 on epoch=23
05/28/2022 10:22:36 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.05 on epoch=23
05/28/2022 10:22:38 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.06 on epoch=23
05/28/2022 10:23:27 - INFO - __main__ - Global step 2600 Train loss 0.08 Classification-F1 0.6785403532040317 on epoch=23
05/28/2022 10:23:27 - INFO - __main__ - Saving model with best Classification-F1: 0.6717010844123287 -> 0.6785403532040317 on epoch=23, global_step=2600
05/28/2022 10:23:30 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.09 on epoch=23
05/28/2022 10:23:33 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.07 on epoch=23
05/28/2022 10:23:35 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.09 on epoch=23
05/28/2022 10:23:38 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.12 on epoch=23
05/28/2022 10:23:41 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.09 on epoch=23
05/28/2022 10:24:29 - INFO - __main__ - Global step 2650 Train loss 0.09 Classification-F1 0.6402116941340406 on epoch=23
05/28/2022 10:24:32 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.07 on epoch=23
05/28/2022 10:24:35 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.06 on epoch=23
05/28/2022 10:24:37 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.15 on epoch=23
05/28/2022 10:24:40 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.09 on epoch=24
05/28/2022 10:24:43 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.04 on epoch=24
05/28/2022 10:25:31 - INFO - __main__ - Global step 2700 Train loss 0.08 Classification-F1 0.638474506159944 on epoch=24
05/28/2022 10:25:34 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.04 on epoch=24
05/28/2022 10:25:37 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.08 on epoch=24
05/28/2022 10:25:39 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.14 on epoch=24
05/28/2022 10:25:42 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.11 on epoch=24
05/28/2022 10:25:44 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.10 on epoch=24
05/28/2022 10:26:32 - INFO - __main__ - Global step 2750 Train loss 0.09 Classification-F1 0.6698963729225753 on epoch=24
05/28/2022 10:26:35 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.09 on epoch=24
05/28/2022 10:26:38 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.08 on epoch=24
05/28/2022 10:26:40 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.08 on epoch=24
05/28/2022 10:26:43 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.08 on epoch=24
05/28/2022 10:26:46 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.10 on epoch=24
05/28/2022 10:27:34 - INFO - __main__ - Global step 2800 Train loss 0.09 Classification-F1 0.6070075198956616 on epoch=24
05/28/2022 10:27:37 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.06 on epoch=25
05/28/2022 10:27:40 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.10 on epoch=25
05/28/2022 10:27:42 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.09 on epoch=25
05/28/2022 10:27:45 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.06 on epoch=25
05/28/2022 10:27:47 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.16 on epoch=25
05/28/2022 10:28:36 - INFO - __main__ - Global step 2850 Train loss 0.09 Classification-F1 0.6059670600749401 on epoch=25
05/28/2022 10:28:38 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.05 on epoch=25
05/28/2022 10:28:41 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.06 on epoch=25
05/28/2022 10:28:44 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.07 on epoch=25
05/28/2022 10:28:47 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.08 on epoch=25
05/28/2022 10:28:49 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=25
05/28/2022 10:29:37 - INFO - __main__ - Global step 2900 Train loss 0.06 Classification-F1 0.6395224714279271 on epoch=25
05/28/2022 10:29:40 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=25
05/28/2022 10:29:43 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.07 on epoch=26
05/28/2022 10:29:46 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.04 on epoch=26
05/28/2022 10:29:48 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.08 on epoch=26
05/28/2022 10:29:51 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.08 on epoch=26
05/28/2022 10:30:39 - INFO - __main__ - Global step 2950 Train loss 0.06 Classification-F1 0.5566932438026325 on epoch=26
05/28/2022 10:30:41 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.03 on epoch=26
05/28/2022 10:30:44 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.07 on epoch=26
05/28/2022 10:30:47 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.12 on epoch=26
05/28/2022 10:30:50 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.08 on epoch=26
05/28/2022 10:30:52 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.03 on epoch=26
05/28/2022 10:30:54 - INFO - __main__ - Start tokenizing ... 1792 instances
05/28/2022 10:30:54 - INFO - __main__ - Printing 3 examples
05/28/2022 10:30:54 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/28/2022 10:30:54 - INFO - __main__ - ['Company']
05/28/2022 10:30:54 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/28/2022 10:30:54 - INFO - __main__ - ['Company']
05/28/2022 10:30:54 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/28/2022 10:30:54 - INFO - __main__ - ['Company']
05/28/2022 10:30:54 - INFO - __main__ - Tokenizing Input ...
05/28/2022 10:30:55 - INFO - __main__ - Tokenizing Output ...
05/28/2022 10:30:56 - INFO - __main__ - Loaded 1792 examples from train data
05/28/2022 10:30:56 - INFO - __main__ - Start tokenizing ... 1792 instances
05/28/2022 10:30:56 - INFO - __main__ - Printing 3 examples
05/28/2022 10:30:56 - INFO - __main__ -  [dbpedia_14] The Aya Group of Companies commonly referred to as the Aya Group is a business conglomerate based in Uganda.
05/28/2022 10:30:56 - INFO - __main__ - ['Company']
05/28/2022 10:30:56 - INFO - __main__ -  [dbpedia_14] Casengo (founded in 2011) is a Dutch company that provides customer service tools for website and webshop owners available as a SaaS. The Amsterdam-based company was founded by Floris and Thijs van der Veen. Both brothers started off with software named Livecom used mainly by large companies such as Philips and DSM. When they decided to develop customer service software for small businesses Casengo was born.
05/28/2022 10:30:56 - INFO - __main__ - ['Company']
05/28/2022 10:30:56 - INFO - __main__ -  [dbpedia_14] KeySpan Corporation now part of National Grid USA was the fifth largest distributor of natural gas in the United States. KeySpan was formed in 1998 as result of the merger of Brooklyn Union Gas Company (founded 1895 by merging several smaller companies) and Long Island Lighting Company (LILCO).
05/28/2022 10:30:56 - INFO - __main__ - ['Company']
05/28/2022 10:30:56 - INFO - __main__ - Tokenizing Input ...
05/28/2022 10:30:57 - INFO - __main__ - Tokenizing Output ...
05/28/2022 10:30:59 - INFO - __main__ - Loaded 1792 examples from dev data
05/28/2022 10:31:14 - INFO - __main__ - load prompt embedding from ckpt
05/28/2022 10:31:15 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/28/2022 10:31:15 - INFO - __main__ - Starting training!
05/28/2022 10:31:41 - INFO - __main__ - Global step 3000 Train loss 0.07 Classification-F1 0.644329601600427 on epoch=26
05/28/2022 10:31:41 - INFO - __main__ - save last model!
05/28/2022 10:31:41 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/28/2022 10:31:41 - INFO - __main__ - Start tokenizing ... 3500 instances
05/28/2022 10:31:41 - INFO - __main__ - Printing 3 examples
05/28/2022 10:31:41 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/28/2022 10:31:41 - INFO - __main__ - ['Animal']
05/28/2022 10:31:41 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/28/2022 10:31:41 - INFO - __main__ - ['Animal']
05/28/2022 10:31:41 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/28/2022 10:31:41 - INFO - __main__ - ['Village']
05/28/2022 10:31:41 - INFO - __main__ - Tokenizing Input ...
05/28/2022 10:31:43 - INFO - __main__ - Tokenizing Output ...
05/28/2022 10:31:46 - INFO - __main__ - Loaded 3500 examples from test data
05/28/2022 10:33:38 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down128shot/singletask-dbpedia_14/dbpedia_14_128_21_0.2_8_predictions.txt
05/28/2022 10:33:38 - INFO - __main__ - Classification-F1 on test data: 0.6396
05/28/2022 10:33:38 - INFO - __main__ - prefix=dbpedia_14_128_21, lr=0.2, bsz=8, dev_performance=0.6785403532040317, test_performance=0.6395802455490571
05/28/2022 10:33:38 - INFO - __main__ - Running ... prefix=dbpedia_14_128_42, lr=0.5, bsz=8 ...
05/28/2022 10:33:39 - INFO - __main__ - Start tokenizing ... 1792 instances
05/28/2022 10:33:39 - INFO - __main__ - Printing 3 examples
05/28/2022 10:33:39 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/28/2022 10:33:39 - INFO - __main__ - ['Company']
05/28/2022 10:33:39 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/28/2022 10:33:39 - INFO - __main__ - ['Company']
05/28/2022 10:33:39 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/28/2022 10:33:39 - INFO - __main__ - ['Company']
05/28/2022 10:33:39 - INFO - __main__ - Tokenizing Input ...
05/28/2022 10:33:40 - INFO - __main__ - Tokenizing Output ...
05/28/2022 10:33:42 - INFO - __main__ - Loaded 1792 examples from train data
05/28/2022 10:33:42 - INFO - __main__ - Start tokenizing ... 1792 instances
05/28/2022 10:33:42 - INFO - __main__ - Printing 3 examples
05/28/2022 10:33:42 - INFO - __main__ -  [dbpedia_14] The Aya Group of Companies commonly referred to as the Aya Group is a business conglomerate based in Uganda.
05/28/2022 10:33:42 - INFO - __main__ - ['Company']
05/28/2022 10:33:42 - INFO - __main__ -  [dbpedia_14] Casengo (founded in 2011) is a Dutch company that provides customer service tools for website and webshop owners available as a SaaS. The Amsterdam-based company was founded by Floris and Thijs van der Veen. Both brothers started off with software named Livecom used mainly by large companies such as Philips and DSM. When they decided to develop customer service software for small businesses Casengo was born.
05/28/2022 10:33:42 - INFO - __main__ - ['Company']
05/28/2022 10:33:42 - INFO - __main__ -  [dbpedia_14] KeySpan Corporation now part of National Grid USA was the fifth largest distributor of natural gas in the United States. KeySpan was formed in 1998 as result of the merger of Brooklyn Union Gas Company (founded 1895 by merging several smaller companies) and Long Island Lighting Company (LILCO).
05/28/2022 10:33:42 - INFO - __main__ - ['Company']
05/28/2022 10:33:42 - INFO - __main__ - Tokenizing Input ...
05/28/2022 10:33:43 - INFO - __main__ - Tokenizing Output ...
05/28/2022 10:33:45 - INFO - __main__ - Loaded 1792 examples from dev data
05/28/2022 10:34:01 - INFO - __main__ - load prompt embedding from ckpt
05/28/2022 10:34:02 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/28/2022 10:34:02 - INFO - __main__ - Starting training!
05/28/2022 10:34:05 - INFO - __main__ - Step 10 Global step 10 Train loss 6.97 on epoch=0
05/28/2022 10:34:08 - INFO - __main__ - Step 20 Global step 20 Train loss 4.86 on epoch=0
05/28/2022 10:34:11 - INFO - __main__ - Step 30 Global step 30 Train loss 3.90 on epoch=0
05/28/2022 10:34:13 - INFO - __main__ - Step 40 Global step 40 Train loss 3.64 on epoch=0
05/28/2022 10:34:16 - INFO - __main__ - Step 50 Global step 50 Train loss 2.89 on epoch=0
05/28/2022 10:35:08 - INFO - __main__ - Global step 50 Train loss 4.45 Classification-F1 0.013053366618096333 on epoch=0
05/28/2022 10:35:08 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.013053366618096333 on epoch=0, global_step=50
05/28/2022 10:35:11 - INFO - __main__ - Step 60 Global step 60 Train loss 2.43 on epoch=0
05/28/2022 10:35:13 - INFO - __main__ - Step 70 Global step 70 Train loss 2.24 on epoch=0
05/28/2022 10:35:16 - INFO - __main__ - Step 80 Global step 80 Train loss 2.00 on epoch=0
05/28/2022 10:35:18 - INFO - __main__ - Step 90 Global step 90 Train loss 1.87 on epoch=0
05/28/2022 10:35:21 - INFO - __main__ - Step 100 Global step 100 Train loss 1.91 on epoch=0
05/28/2022 10:36:06 - INFO - __main__ - Global step 100 Train loss 2.09 Classification-F1 0.047459962504774224 on epoch=0
05/28/2022 10:36:06 - INFO - __main__ - Saving model with best Classification-F1: 0.013053366618096333 -> 0.047459962504774224 on epoch=0, global_step=100
05/28/2022 10:36:09 - INFO - __main__ - Step 110 Global step 110 Train loss 1.40 on epoch=0
05/28/2022 10:36:12 - INFO - __main__ - Step 120 Global step 120 Train loss 1.59 on epoch=1
05/28/2022 10:36:14 - INFO - __main__ - Step 130 Global step 130 Train loss 1.41 on epoch=1
05/28/2022 10:36:17 - INFO - __main__ - Step 140 Global step 140 Train loss 1.25 on epoch=1
05/28/2022 10:36:19 - INFO - __main__ - Step 150 Global step 150 Train loss 1.23 on epoch=1
05/28/2022 10:37:04 - INFO - __main__ - Global step 150 Train loss 1.37 Classification-F1 0.1123951137734398 on epoch=1
05/28/2022 10:37:04 - INFO - __main__ - Saving model with best Classification-F1: 0.047459962504774224 -> 0.1123951137734398 on epoch=1, global_step=150
05/28/2022 10:37:07 - INFO - __main__ - Step 160 Global step 160 Train loss 1.11 on epoch=1
05/28/2022 10:37:10 - INFO - __main__ - Step 170 Global step 170 Train loss 0.92 on epoch=1
05/28/2022 10:37:12 - INFO - __main__ - Step 180 Global step 180 Train loss 0.67 on epoch=1
05/28/2022 10:37:15 - INFO - __main__ - Step 190 Global step 190 Train loss 0.65 on epoch=1
05/28/2022 10:37:17 - INFO - __main__ - Step 200 Global step 200 Train loss 0.78 on epoch=1
05/28/2022 10:38:04 - INFO - __main__ - Global step 200 Train loss 0.83 Classification-F1 0.1804330227280729 on epoch=1
05/28/2022 10:38:04 - INFO - __main__ - Saving model with best Classification-F1: 0.1123951137734398 -> 0.1804330227280729 on epoch=1, global_step=200
05/28/2022 10:38:07 - INFO - __main__ - Step 210 Global step 210 Train loss 0.75 on epoch=1
05/28/2022 10:38:10 - INFO - __main__ - Step 220 Global step 220 Train loss 0.57 on epoch=1
05/28/2022 10:38:12 - INFO - __main__ - Step 230 Global step 230 Train loss 0.58 on epoch=2
05/28/2022 10:38:15 - INFO - __main__ - Step 240 Global step 240 Train loss 0.47 on epoch=2
05/28/2022 10:38:17 - INFO - __main__ - Step 250 Global step 250 Train loss 0.39 on epoch=2
05/28/2022 10:39:07 - INFO - __main__ - Global step 250 Train loss 0.55 Classification-F1 0.3150364435136145 on epoch=2
05/28/2022 10:39:07 - INFO - __main__ - Saving model with best Classification-F1: 0.1804330227280729 -> 0.3150364435136145 on epoch=2, global_step=250
05/28/2022 10:39:10 - INFO - __main__ - Step 260 Global step 260 Train loss 0.45 on epoch=2
05/28/2022 10:39:12 - INFO - __main__ - Step 270 Global step 270 Train loss 0.40 on epoch=2
05/28/2022 10:39:15 - INFO - __main__ - Step 280 Global step 280 Train loss 0.37 on epoch=2
05/28/2022 10:39:18 - INFO - __main__ - Step 290 Global step 290 Train loss 0.36 on epoch=2
05/28/2022 10:39:20 - INFO - __main__ - Step 300 Global step 300 Train loss 0.30 on epoch=2
05/28/2022 10:40:13 - INFO - __main__ - Global step 300 Train loss 0.38 Classification-F1 0.31611775062856895 on epoch=2
05/28/2022 10:40:13 - INFO - __main__ - Saving model with best Classification-F1: 0.3150364435136145 -> 0.31611775062856895 on epoch=2, global_step=300
05/28/2022 10:40:16 - INFO - __main__ - Step 310 Global step 310 Train loss 0.33 on epoch=2
05/28/2022 10:40:18 - INFO - __main__ - Step 320 Global step 320 Train loss 0.38 on epoch=2
05/28/2022 10:40:21 - INFO - __main__ - Step 330 Global step 330 Train loss 0.39 on epoch=2
05/28/2022 10:40:24 - INFO - __main__ - Step 340 Global step 340 Train loss 0.31 on epoch=3
05/28/2022 10:40:26 - INFO - __main__ - Step 350 Global step 350 Train loss 0.45 on epoch=3
05/28/2022 10:41:18 - INFO - __main__ - Global step 350 Train loss 0.37 Classification-F1 0.3960624904376627 on epoch=3
05/28/2022 10:41:18 - INFO - __main__ - Saving model with best Classification-F1: 0.31611775062856895 -> 0.3960624904376627 on epoch=3, global_step=350
05/28/2022 10:41:21 - INFO - __main__ - Step 360 Global step 360 Train loss 0.30 on epoch=3
05/28/2022 10:41:23 - INFO - __main__ - Step 370 Global step 370 Train loss 0.22 on epoch=3
05/28/2022 10:41:26 - INFO - __main__ - Step 380 Global step 380 Train loss 0.29 on epoch=3
05/28/2022 10:41:28 - INFO - __main__ - Step 390 Global step 390 Train loss 0.22 on epoch=3
05/28/2022 10:41:31 - INFO - __main__ - Step 400 Global step 400 Train loss 0.26 on epoch=3
05/28/2022 10:42:23 - INFO - __main__ - Global step 400 Train loss 0.26 Classification-F1 0.4131457295270237 on epoch=3
05/28/2022 10:42:23 - INFO - __main__ - Saving model with best Classification-F1: 0.3960624904376627 -> 0.4131457295270237 on epoch=3, global_step=400
05/28/2022 10:42:26 - INFO - __main__ - Step 410 Global step 410 Train loss 0.16 on epoch=3
05/28/2022 10:42:29 - INFO - __main__ - Step 420 Global step 420 Train loss 0.28 on epoch=3
05/28/2022 10:42:31 - INFO - __main__ - Step 430 Global step 430 Train loss 0.26 on epoch=3
05/28/2022 10:42:34 - INFO - __main__ - Step 440 Global step 440 Train loss 0.22 on epoch=3
05/28/2022 10:42:36 - INFO - __main__ - Step 450 Global step 450 Train loss 0.24 on epoch=4
05/28/2022 10:43:29 - INFO - __main__ - Global step 450 Train loss 0.23 Classification-F1 0.4236133296431403 on epoch=4
05/28/2022 10:43:29 - INFO - __main__ - Saving model with best Classification-F1: 0.4131457295270237 -> 0.4236133296431403 on epoch=4, global_step=450
05/28/2022 10:43:31 - INFO - __main__ - Step 460 Global step 460 Train loss 0.35 on epoch=4
05/28/2022 10:43:34 - INFO - __main__ - Step 470 Global step 470 Train loss 0.27 on epoch=4
05/28/2022 10:43:37 - INFO - __main__ - Step 480 Global step 480 Train loss 0.24 on epoch=4
05/28/2022 10:43:39 - INFO - __main__ - Step 490 Global step 490 Train loss 0.23 on epoch=4
05/28/2022 10:43:42 - INFO - __main__ - Step 500 Global step 500 Train loss 0.17 on epoch=4
05/28/2022 10:44:33 - INFO - __main__ - Global step 500 Train loss 0.25 Classification-F1 0.39973805445441757 on epoch=4
05/28/2022 10:44:35 - INFO - __main__ - Step 510 Global step 510 Train loss 0.14 on epoch=4
05/28/2022 10:44:38 - INFO - __main__ - Step 520 Global step 520 Train loss 0.20 on epoch=4
05/28/2022 10:44:41 - INFO - __main__ - Step 530 Global step 530 Train loss 0.16 on epoch=4
05/28/2022 10:44:43 - INFO - __main__ - Step 540 Global step 540 Train loss 0.17 on epoch=4
05/28/2022 10:44:46 - INFO - __main__ - Step 550 Global step 550 Train loss 0.21 on epoch=4
05/28/2022 10:45:36 - INFO - __main__ - Global step 550 Train loss 0.17 Classification-F1 0.4749914543662762 on epoch=4
05/28/2022 10:45:37 - INFO - __main__ - Saving model with best Classification-F1: 0.4236133296431403 -> 0.4749914543662762 on epoch=4, global_step=550
05/28/2022 10:45:39 - INFO - __main__ - Step 560 Global step 560 Train loss 0.18 on epoch=4
05/28/2022 10:45:42 - INFO - __main__ - Step 570 Global step 570 Train loss 0.17 on epoch=5
05/28/2022 10:45:44 - INFO - __main__ - Step 580 Global step 580 Train loss 0.21 on epoch=5
05/28/2022 10:45:47 - INFO - __main__ - Step 590 Global step 590 Train loss 0.11 on epoch=5
05/28/2022 10:45:49 - INFO - __main__ - Step 600 Global step 600 Train loss 0.17 on epoch=5
05/28/2022 10:46:42 - INFO - __main__ - Global step 600 Train loss 0.17 Classification-F1 0.4833595209326565 on epoch=5
05/28/2022 10:46:42 - INFO - __main__ - Saving model with best Classification-F1: 0.4749914543662762 -> 0.4833595209326565 on epoch=5, global_step=600
05/28/2022 10:46:44 - INFO - __main__ - Step 610 Global step 610 Train loss 0.18 on epoch=5
05/28/2022 10:46:47 - INFO - __main__ - Step 620 Global step 620 Train loss 0.14 on epoch=5
05/28/2022 10:46:49 - INFO - __main__ - Step 630 Global step 630 Train loss 0.09 on epoch=5
05/28/2022 10:46:52 - INFO - __main__ - Step 640 Global step 640 Train loss 0.10 on epoch=5
05/28/2022 10:46:54 - INFO - __main__ - Step 650 Global step 650 Train loss 0.16 on epoch=5
05/28/2022 10:47:46 - INFO - __main__ - Global step 650 Train loss 0.13 Classification-F1 0.4198391965420106 on epoch=5
05/28/2022 10:47:48 - INFO - __main__ - Step 660 Global step 660 Train loss 0.17 on epoch=5
05/28/2022 10:47:51 - INFO - __main__ - Step 670 Global step 670 Train loss 0.12 on epoch=5
05/28/2022 10:47:53 - INFO - __main__ - Step 680 Global step 680 Train loss 0.10 on epoch=6
05/28/2022 10:47:56 - INFO - __main__ - Step 690 Global step 690 Train loss 0.15 on epoch=6
05/28/2022 10:47:58 - INFO - __main__ - Step 700 Global step 700 Train loss 0.10 on epoch=6
05/28/2022 10:48:50 - INFO - __main__ - Global step 700 Train loss 0.13 Classification-F1 0.4175698572325611 on epoch=6
05/28/2022 10:48:52 - INFO - __main__ - Step 710 Global step 710 Train loss 0.07 on epoch=6
05/28/2022 10:48:55 - INFO - __main__ - Step 720 Global step 720 Train loss 0.14 on epoch=6
05/28/2022 10:48:58 - INFO - __main__ - Step 730 Global step 730 Train loss 0.08 on epoch=6
05/28/2022 10:49:00 - INFO - __main__ - Step 740 Global step 740 Train loss 0.12 on epoch=6
05/28/2022 10:49:03 - INFO - __main__ - Step 750 Global step 750 Train loss 0.09 on epoch=6
05/28/2022 10:49:53 - INFO - __main__ - Global step 750 Train loss 0.10 Classification-F1 0.46184539764165183 on epoch=6
05/28/2022 10:49:56 - INFO - __main__ - Step 760 Global step 760 Train loss 0.14 on epoch=6
05/28/2022 10:49:59 - INFO - __main__ - Step 770 Global step 770 Train loss 0.13 on epoch=6
05/28/2022 10:50:01 - INFO - __main__ - Step 780 Global step 780 Train loss 0.10 on epoch=6
05/28/2022 10:50:04 - INFO - __main__ - Step 790 Global step 790 Train loss 0.10 on epoch=7
05/28/2022 10:50:06 - INFO - __main__ - Step 800 Global step 800 Train loss 0.16 on epoch=7
05/28/2022 10:50:56 - INFO - __main__ - Global step 800 Train loss 0.13 Classification-F1 0.5351991556237552 on epoch=7
05/28/2022 10:50:56 - INFO - __main__ - Saving model with best Classification-F1: 0.4833595209326565 -> 0.5351991556237552 on epoch=7, global_step=800
05/28/2022 10:50:59 - INFO - __main__ - Step 810 Global step 810 Train loss 0.11 on epoch=7
05/28/2022 10:51:01 - INFO - __main__ - Step 820 Global step 820 Train loss 0.07 on epoch=7
05/28/2022 10:51:04 - INFO - __main__ - Step 830 Global step 830 Train loss 0.15 on epoch=7
05/28/2022 10:51:06 - INFO - __main__ - Step 840 Global step 840 Train loss 0.12 on epoch=7
05/28/2022 10:51:09 - INFO - __main__ - Step 850 Global step 850 Train loss 0.08 on epoch=7
05/28/2022 10:51:59 - INFO - __main__ - Global step 850 Train loss 0.11 Classification-F1 0.48440373425316047 on epoch=7
05/28/2022 10:52:02 - INFO - __main__ - Step 860 Global step 860 Train loss 0.07 on epoch=7
05/28/2022 10:52:04 - INFO - __main__ - Step 870 Global step 870 Train loss 0.10 on epoch=7
05/28/2022 10:52:07 - INFO - __main__ - Step 880 Global step 880 Train loss 0.11 on epoch=7
05/28/2022 10:52:10 - INFO - __main__ - Step 890 Global step 890 Train loss 0.07 on epoch=7
05/28/2022 10:52:12 - INFO - __main__ - Step 900 Global step 900 Train loss 0.09 on epoch=8
05/28/2022 10:53:03 - INFO - __main__ - Global step 900 Train loss 0.09 Classification-F1 0.541263279129628 on epoch=8
05/28/2022 10:53:03 - INFO - __main__ - Saving model with best Classification-F1: 0.5351991556237552 -> 0.541263279129628 on epoch=8, global_step=900
05/28/2022 10:53:05 - INFO - __main__ - Step 910 Global step 910 Train loss 0.13 on epoch=8
05/28/2022 10:53:08 - INFO - __main__ - Step 920 Global step 920 Train loss 0.12 on epoch=8
05/28/2022 10:53:10 - INFO - __main__ - Step 930 Global step 930 Train loss 0.07 on epoch=8
05/28/2022 10:53:13 - INFO - __main__ - Step 940 Global step 940 Train loss 0.10 on epoch=8
05/28/2022 10:53:15 - INFO - __main__ - Step 950 Global step 950 Train loss 0.05 on epoch=8
05/28/2022 10:54:06 - INFO - __main__ - Global step 950 Train loss 0.09 Classification-F1 0.5626893932736263 on epoch=8
05/28/2022 10:54:06 - INFO - __main__ - Saving model with best Classification-F1: 0.541263279129628 -> 0.5626893932736263 on epoch=8, global_step=950
05/28/2022 10:54:08 - INFO - __main__ - Step 960 Global step 960 Train loss 0.10 on epoch=8
05/28/2022 10:54:11 - INFO - __main__ - Step 970 Global step 970 Train loss 0.10 on epoch=8
05/28/2022 10:54:14 - INFO - __main__ - Step 980 Global step 980 Train loss 0.08 on epoch=8
05/28/2022 10:54:16 - INFO - __main__ - Step 990 Global step 990 Train loss 0.07 on epoch=8
05/28/2022 10:54:19 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.06 on epoch=8
05/28/2022 10:55:08 - INFO - __main__ - Global step 1000 Train loss 0.08 Classification-F1 0.6134237210928551 on epoch=8
05/28/2022 10:55:08 - INFO - __main__ - Saving model with best Classification-F1: 0.5626893932736263 -> 0.6134237210928551 on epoch=8, global_step=1000
05/28/2022 10:55:11 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.06 on epoch=9
05/28/2022 10:55:14 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.15 on epoch=9
05/28/2022 10:55:16 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.12 on epoch=9
05/28/2022 10:55:19 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.04 on epoch=9
05/28/2022 10:55:21 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.05 on epoch=9
05/28/2022 10:56:11 - INFO - __main__ - Global step 1050 Train loss 0.08 Classification-F1 0.5352746444807771 on epoch=9
05/28/2022 10:56:13 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.08 on epoch=9
05/28/2022 10:56:16 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.05 on epoch=9
05/28/2022 10:56:18 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.07 on epoch=9
05/28/2022 10:56:21 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.06 on epoch=9
05/28/2022 10:56:24 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.11 on epoch=9
05/28/2022 10:57:13 - INFO - __main__ - Global step 1100 Train loss 0.07 Classification-F1 0.5551201827215467 on epoch=9
05/28/2022 10:57:15 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.09 on epoch=9
05/28/2022 10:57:18 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.05 on epoch=9
05/28/2022 10:57:20 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.12 on epoch=10
05/28/2022 10:57:23 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.19 on epoch=10
05/28/2022 10:57:26 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.07 on epoch=10
05/28/2022 10:58:16 - INFO - __main__ - Global step 1150 Train loss 0.10 Classification-F1 0.558871895744359 on epoch=10
05/28/2022 10:58:19 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.06 on epoch=10
05/28/2022 10:58:21 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.06 on epoch=10
05/28/2022 10:58:24 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.11 on epoch=10
05/28/2022 10:58:26 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.07 on epoch=10
05/28/2022 10:58:29 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.05 on epoch=10
05/28/2022 10:59:19 - INFO - __main__ - Global step 1200 Train loss 0.07 Classification-F1 0.47504716491915117 on epoch=10
05/28/2022 10:59:21 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.07 on epoch=10
05/28/2022 10:59:24 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.09 on epoch=10
05/28/2022 10:59:26 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.08 on epoch=10
05/28/2022 10:59:29 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.04 on epoch=11
05/28/2022 10:59:31 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.18 on epoch=11
05/28/2022 11:00:21 - INFO - __main__ - Global step 1250 Train loss 0.09 Classification-F1 0.49190916411646496 on epoch=11
05/28/2022 11:00:24 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.04 on epoch=11
05/28/2022 11:00:26 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.06 on epoch=11
05/28/2022 11:00:29 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.06 on epoch=11
05/28/2022 11:00:32 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.02 on epoch=11
05/28/2022 11:00:34 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.04 on epoch=11
05/28/2022 11:01:23 - INFO - __main__ - Global step 1300 Train loss 0.05 Classification-F1 0.4351244189584072 on epoch=11
05/28/2022 11:01:25 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.04 on epoch=11
05/28/2022 11:01:28 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.09 on epoch=11
05/28/2022 11:01:31 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.06 on epoch=11
05/28/2022 11:01:33 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.07 on epoch=11
05/28/2022 11:01:36 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.05 on epoch=12
05/28/2022 11:02:25 - INFO - __main__ - Global step 1350 Train loss 0.06 Classification-F1 0.49633818073500624 on epoch=12
05/28/2022 11:02:27 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.12 on epoch=12
05/28/2022 11:02:30 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.04 on epoch=12
05/28/2022 11:02:32 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.05 on epoch=12
05/28/2022 11:02:35 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.05 on epoch=12
05/28/2022 11:02:37 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.04 on epoch=12
05/28/2022 11:03:27 - INFO - __main__ - Global step 1400 Train loss 0.06 Classification-F1 0.5379428147000241 on epoch=12
05/28/2022 11:03:29 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.08 on epoch=12
05/28/2022 11:03:32 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.04 on epoch=12
05/28/2022 11:03:34 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.03 on epoch=12
05/28/2022 11:03:37 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.10 on epoch=12
05/28/2022 11:03:40 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.05 on epoch=12
05/28/2022 11:04:28 - INFO - __main__ - Global step 1450 Train loss 0.06 Classification-F1 0.5818431586894776 on epoch=12
05/28/2022 11:04:31 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.05 on epoch=13
05/28/2022 11:04:33 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.11 on epoch=13
05/28/2022 11:04:36 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.03 on epoch=13
05/28/2022 11:04:39 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.06 on epoch=13
05/28/2022 11:04:41 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.07 on epoch=13
05/28/2022 11:05:31 - INFO - __main__ - Global step 1500 Train loss 0.06 Classification-F1 0.5843840230100593 on epoch=13
05/28/2022 11:05:33 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.04 on epoch=13
05/28/2022 11:05:36 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.04 on epoch=13
05/28/2022 11:05:38 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.04 on epoch=13
05/28/2022 11:05:41 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=13
05/28/2022 11:05:43 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.06 on epoch=13
05/28/2022 11:06:32 - INFO - __main__ - Global step 1550 Train loss 0.04 Classification-F1 0.5598126424477722 on epoch=13
05/28/2022 11:06:34 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.03 on epoch=13
05/28/2022 11:06:37 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.07 on epoch=14
05/28/2022 11:06:39 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.08 on epoch=14
05/28/2022 11:06:42 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.04 on epoch=14
05/28/2022 11:06:45 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.04 on epoch=14
05/28/2022 11:07:33 - INFO - __main__ - Global step 1600 Train loss 0.05 Classification-F1 0.5183804077158845 on epoch=14
05/28/2022 11:07:36 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.05 on epoch=14
05/28/2022 11:07:38 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=14
05/28/2022 11:07:41 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.03 on epoch=14
05/28/2022 11:07:44 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.04 on epoch=14
05/28/2022 11:07:46 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.05 on epoch=14
05/28/2022 11:08:35 - INFO - __main__ - Global step 1650 Train loss 0.04 Classification-F1 0.4935729214968485 on epoch=14
05/28/2022 11:08:38 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.10 on epoch=14
05/28/2022 11:08:40 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.04 on epoch=14
05/28/2022 11:08:43 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.03 on epoch=14
05/28/2022 11:08:46 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.04 on epoch=15
05/28/2022 11:08:48 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.15 on epoch=15
05/28/2022 11:09:37 - INFO - __main__ - Global step 1700 Train loss 0.07 Classification-F1 0.5087950783244404 on epoch=15
05/28/2022 11:09:39 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.03 on epoch=15
05/28/2022 11:09:42 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.07 on epoch=15
05/28/2022 11:09:44 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.06 on epoch=15
05/28/2022 11:09:47 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=15
05/28/2022 11:09:50 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.07 on epoch=15
05/28/2022 11:10:38 - INFO - __main__ - Global step 1750 Train loss 0.05 Classification-F1 0.544001888275592 on epoch=15
05/28/2022 11:10:41 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.03 on epoch=15
05/28/2022 11:10:43 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.08 on epoch=15
05/28/2022 11:10:46 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.09 on epoch=15
05/28/2022 11:10:49 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=15
05/28/2022 11:10:51 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.05 on epoch=16
05/28/2022 11:11:40 - INFO - __main__ - Global step 1800 Train loss 0.05 Classification-F1 0.5336804471116346 on epoch=16
05/28/2022 11:11:43 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.08 on epoch=16
05/28/2022 11:11:45 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=16
05/28/2022 11:11:48 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=16
05/28/2022 11:11:50 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.08 on epoch=16
05/28/2022 11:11:53 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=16
05/28/2022 11:12:42 - INFO - __main__ - Global step 1850 Train loss 0.05 Classification-F1 0.5337189742610993 on epoch=16
05/28/2022 11:12:45 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.04 on epoch=16
05/28/2022 11:12:47 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.05 on epoch=16
05/28/2022 11:12:50 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.10 on epoch=16
05/28/2022 11:12:53 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.04 on epoch=16
05/28/2022 11:12:55 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=16
05/28/2022 11:13:45 - INFO - __main__ - Global step 1900 Train loss 0.05 Classification-F1 0.5762591934396141 on epoch=16
05/28/2022 11:13:47 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.04 on epoch=17
05/28/2022 11:13:50 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.15 on epoch=17
05/28/2022 11:13:53 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=17
05/28/2022 11:13:55 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=17
05/28/2022 11:13:58 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.06 on epoch=17
05/28/2022 11:14:46 - INFO - __main__ - Global step 1950 Train loss 0.06 Classification-F1 0.535401239976902 on epoch=17
05/28/2022 11:14:49 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=17
05/28/2022 11:14:51 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.05 on epoch=17
05/28/2022 11:14:54 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=17
05/28/2022 11:14:57 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=17
05/28/2022 11:14:59 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.10 on epoch=17
05/28/2022 11:15:49 - INFO - __main__ - Global step 2000 Train loss 0.05 Classification-F1 0.6230480335976362 on epoch=17
05/28/2022 11:15:49 - INFO - __main__ - Saving model with best Classification-F1: 0.6134237210928551 -> 0.6230480335976362 on epoch=17, global_step=2000
05/28/2022 11:15:51 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.04 on epoch=17
05/28/2022 11:15:54 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=18
05/28/2022 11:15:56 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.10 on epoch=18
05/28/2022 11:15:59 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=18
05/28/2022 11:16:02 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.02 on epoch=18
05/28/2022 11:16:50 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.7188001472443182 on epoch=18
05/28/2022 11:16:51 - INFO - __main__ - Saving model with best Classification-F1: 0.6230480335976362 -> 0.7188001472443182 on epoch=18, global_step=2050
05/28/2022 11:16:53 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.02 on epoch=18
05/28/2022 11:16:56 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=18
05/28/2022 11:16:58 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.04 on epoch=18
05/28/2022 11:17:01 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=18
05/28/2022 11:17:03 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.06 on epoch=18
05/28/2022 11:17:51 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.5542287993864092 on epoch=18
05/28/2022 11:17:54 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.05 on epoch=18
05/28/2022 11:17:56 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.04 on epoch=18
05/28/2022 11:17:59 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=19
05/28/2022 11:18:02 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.07 on epoch=19
05/28/2022 11:18:04 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=19
05/28/2022 11:18:53 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.6083283945333026 on epoch=19
05/28/2022 11:18:56 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=19
05/28/2022 11:18:58 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.04 on epoch=19
05/28/2022 11:19:01 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=19
05/28/2022 11:19:03 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=19
05/28/2022 11:19:06 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.05 on epoch=19
05/28/2022 11:19:54 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.6457543939101755 on epoch=19
05/28/2022 11:19:57 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.03 on epoch=19
05/28/2022 11:20:00 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.08 on epoch=19
05/28/2022 11:20:02 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.04 on epoch=19
05/28/2022 11:20:05 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=19
05/28/2022 11:20:07 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=20
05/28/2022 11:20:56 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.5466132714871423 on epoch=20
05/28/2022 11:20:58 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.07 on epoch=20
05/28/2022 11:21:01 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=20
05/28/2022 11:21:04 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=20
05/28/2022 11:21:06 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.03 on epoch=20
05/28/2022 11:21:09 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=20
05/28/2022 11:21:58 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.596677368371449 on epoch=20
05/28/2022 11:22:00 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=20
05/28/2022 11:22:03 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.04 on epoch=20
05/28/2022 11:22:05 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.04 on epoch=20
05/28/2022 11:22:08 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.05 on epoch=20
05/28/2022 11:22:11 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=20
05/28/2022 11:23:00 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.6571144174374853 on epoch=20
05/28/2022 11:23:02 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=21
05/28/2022 11:23:05 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.08 on epoch=21
05/28/2022 11:23:07 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=21
05/28/2022 11:23:10 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=21
05/28/2022 11:23:13 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.03 on epoch=21
05/28/2022 11:24:02 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.6228241877766693 on epoch=21
05/28/2022 11:24:05 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=21
05/28/2022 11:24:07 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.04 on epoch=21
05/28/2022 11:24:10 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=21
05/28/2022 11:24:13 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.06 on epoch=21
05/28/2022 11:24:15 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=21
05/28/2022 11:25:05 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.6082757959984207 on epoch=21
05/28/2022 11:25:08 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=21
05/28/2022 11:25:11 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=22
05/28/2022 11:25:13 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.05 on epoch=22
05/28/2022 11:25:16 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.04 on epoch=22
05/28/2022 11:25:19 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=22
05/28/2022 11:26:08 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.6221469296039801 on epoch=22
05/28/2022 11:26:11 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=22
05/28/2022 11:26:13 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.04 on epoch=22
05/28/2022 11:26:16 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.04 on epoch=22
05/28/2022 11:26:19 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.03 on epoch=22
05/28/2022 11:26:21 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=22
05/28/2022 11:27:11 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.6012879216357501 on epoch=22
05/28/2022 11:27:14 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.04 on epoch=22
05/28/2022 11:27:17 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=22
05/28/2022 11:27:19 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=23
05/28/2022 11:27:22 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.05 on epoch=23
05/28/2022 11:27:25 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=23
05/28/2022 11:28:17 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.5697243060516988 on epoch=23
05/28/2022 11:28:20 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=23
05/28/2022 11:28:22 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=23
05/28/2022 11:28:25 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.03 on epoch=23
05/28/2022 11:28:28 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.04 on epoch=23
05/28/2022 11:28:31 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=23
05/28/2022 11:29:22 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.5955671812555096 on epoch=23
05/28/2022 11:29:25 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=23
05/28/2022 11:29:27 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.04 on epoch=23
05/28/2022 11:29:30 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=23
05/28/2022 11:29:33 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=24
05/28/2022 11:29:35 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.20 on epoch=24
05/28/2022 11:30:28 - INFO - __main__ - Global step 2700 Train loss 0.06 Classification-F1 0.6996871127263499 on epoch=24
05/28/2022 11:30:31 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=24
05/28/2022 11:30:33 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.03 on epoch=24
05/28/2022 11:30:36 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=24
05/28/2022 11:30:39 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.03 on epoch=24
05/28/2022 11:30:42 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=24
05/28/2022 11:31:33 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.5836131830273141 on epoch=24
05/28/2022 11:31:36 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=24
05/28/2022 11:31:38 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=24
05/28/2022 11:31:41 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.05 on epoch=24
05/28/2022 11:31:44 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=24
05/28/2022 11:31:46 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=24
05/28/2022 11:32:39 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.5884624678323833 on epoch=24
05/28/2022 11:32:41 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=25
05/28/2022 11:32:44 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.10 on epoch=25
05/28/2022 11:32:47 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=25
05/28/2022 11:32:50 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=25
05/28/2022 11:32:52 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.03 on epoch=25
05/28/2022 11:33:44 - INFO - __main__ - Global step 2850 Train loss 0.04 Classification-F1 0.6164040935829302 on epoch=25
05/28/2022 11:33:47 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.04 on epoch=25
05/28/2022 11:33:50 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=25
05/28/2022 11:33:53 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=25
05/28/2022 11:33:55 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=25
05/28/2022 11:33:58 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=25
05/28/2022 11:34:50 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.5627299723878723 on epoch=25
05/28/2022 11:34:53 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=25
05/28/2022 11:34:56 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.04 on epoch=26
05/28/2022 11:34:58 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.07 on epoch=26
05/28/2022 11:35:01 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=26
05/28/2022 11:35:04 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=26
05/28/2022 11:35:57 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.7002985288705749 on epoch=26
05/28/2022 11:36:00 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.03 on epoch=26
05/28/2022 11:36:02 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=26
05/28/2022 11:36:05 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=26
05/28/2022 11:36:08 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=26
05/28/2022 11:36:10 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=26
05/28/2022 11:36:12 - INFO - __main__ - Start tokenizing ... 1792 instances
05/28/2022 11:36:12 - INFO - __main__ - Printing 3 examples
05/28/2022 11:36:12 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/28/2022 11:36:12 - INFO - __main__ - ['Company']
05/28/2022 11:36:12 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/28/2022 11:36:12 - INFO - __main__ - ['Company']
05/28/2022 11:36:12 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/28/2022 11:36:12 - INFO - __main__ - ['Company']
05/28/2022 11:36:12 - INFO - __main__ - Tokenizing Input ...
05/28/2022 11:36:13 - INFO - __main__ - Tokenizing Output ...
05/28/2022 11:36:15 - INFO - __main__ - Loaded 1792 examples from train data
05/28/2022 11:36:15 - INFO - __main__ - Start tokenizing ... 1792 instances
05/28/2022 11:36:15 - INFO - __main__ - Printing 3 examples
05/28/2022 11:36:15 - INFO - __main__ -  [dbpedia_14] The Aya Group of Companies commonly referred to as the Aya Group is a business conglomerate based in Uganda.
05/28/2022 11:36:15 - INFO - __main__ - ['Company']
05/28/2022 11:36:15 - INFO - __main__ -  [dbpedia_14] Casengo (founded in 2011) is a Dutch company that provides customer service tools for website and webshop owners available as a SaaS. The Amsterdam-based company was founded by Floris and Thijs van der Veen. Both brothers started off with software named Livecom used mainly by large companies such as Philips and DSM. When they decided to develop customer service software for small businesses Casengo was born.
05/28/2022 11:36:15 - INFO - __main__ - ['Company']
05/28/2022 11:36:15 - INFO - __main__ -  [dbpedia_14] KeySpan Corporation now part of National Grid USA was the fifth largest distributor of natural gas in the United States. KeySpan was formed in 1998 as result of the merger of Brooklyn Union Gas Company (founded 1895 by merging several smaller companies) and Long Island Lighting Company (LILCO).
05/28/2022 11:36:15 - INFO - __main__ - ['Company']
05/28/2022 11:36:15 - INFO - __main__ - Tokenizing Input ...
05/28/2022 11:36:16 - INFO - __main__ - Tokenizing Output ...
05/28/2022 11:36:17 - INFO - __main__ - Loaded 1792 examples from dev data
05/28/2022 11:36:32 - INFO - __main__ - load prompt embedding from ckpt
05/28/2022 11:36:33 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/28/2022 11:36:33 - INFO - __main__ - Starting training!
05/28/2022 11:37:03 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.6260046917181383 on epoch=26
05/28/2022 11:37:03 - INFO - __main__ - save last model!
05/28/2022 11:37:03 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/28/2022 11:37:03 - INFO - __main__ - Start tokenizing ... 3500 instances
05/28/2022 11:37:03 - INFO - __main__ - Printing 3 examples
05/28/2022 11:37:03 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/28/2022 11:37:03 - INFO - __main__ - ['Animal']
05/28/2022 11:37:03 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/28/2022 11:37:03 - INFO - __main__ - ['Animal']
05/28/2022 11:37:03 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/28/2022 11:37:03 - INFO - __main__ - ['Village']
05/28/2022 11:37:03 - INFO - __main__ - Tokenizing Input ...
05/28/2022 11:37:05 - INFO - __main__ - Tokenizing Output ...
05/28/2022 11:37:09 - INFO - __main__ - Loaded 3500 examples from test data
05/28/2022 11:39:16 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down128shot/singletask-dbpedia_14/dbpedia_14_128_42_0.5_8_predictions.txt
05/28/2022 11:39:16 - INFO - __main__ - Classification-F1 on test data: 0.5035
05/28/2022 11:39:16 - INFO - __main__ - prefix=dbpedia_14_128_42, lr=0.5, bsz=8, dev_performance=0.7188001472443182, test_performance=0.5034571939390393
05/28/2022 11:39:16 - INFO - __main__ - Running ... prefix=dbpedia_14_128_42, lr=0.4, bsz=8 ...
05/28/2022 11:39:17 - INFO - __main__ - Start tokenizing ... 1792 instances
05/28/2022 11:39:17 - INFO - __main__ - Printing 3 examples
05/28/2022 11:39:17 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/28/2022 11:39:17 - INFO - __main__ - ['Company']
05/28/2022 11:39:17 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/28/2022 11:39:17 - INFO - __main__ - ['Company']
05/28/2022 11:39:17 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/28/2022 11:39:17 - INFO - __main__ - ['Company']
05/28/2022 11:39:17 - INFO - __main__ - Tokenizing Input ...
05/28/2022 11:39:18 - INFO - __main__ - Tokenizing Output ...
05/28/2022 11:39:20 - INFO - __main__ - Loaded 1792 examples from train data
05/28/2022 11:39:20 - INFO - __main__ - Start tokenizing ... 1792 instances
05/28/2022 11:39:20 - INFO - __main__ - Printing 3 examples
05/28/2022 11:39:20 - INFO - __main__ -  [dbpedia_14] The Aya Group of Companies commonly referred to as the Aya Group is a business conglomerate based in Uganda.
05/28/2022 11:39:20 - INFO - __main__ - ['Company']
05/28/2022 11:39:20 - INFO - __main__ -  [dbpedia_14] Casengo (founded in 2011) is a Dutch company that provides customer service tools for website and webshop owners available as a SaaS. The Amsterdam-based company was founded by Floris and Thijs van der Veen. Both brothers started off with software named Livecom used mainly by large companies such as Philips and DSM. When they decided to develop customer service software for small businesses Casengo was born.
05/28/2022 11:39:20 - INFO - __main__ - ['Company']
05/28/2022 11:39:20 - INFO - __main__ -  [dbpedia_14] KeySpan Corporation now part of National Grid USA was the fifth largest distributor of natural gas in the United States. KeySpan was formed in 1998 as result of the merger of Brooklyn Union Gas Company (founded 1895 by merging several smaller companies) and Long Island Lighting Company (LILCO).
05/28/2022 11:39:20 - INFO - __main__ - ['Company']
05/28/2022 11:39:20 - INFO - __main__ - Tokenizing Input ...
05/28/2022 11:39:21 - INFO - __main__ - Tokenizing Output ...
05/28/2022 11:39:22 - INFO - __main__ - Loaded 1792 examples from dev data
05/28/2022 11:39:41 - INFO - __main__ - load prompt embedding from ckpt
05/28/2022 11:39:41 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/28/2022 11:39:41 - INFO - __main__ - Starting training!
05/28/2022 11:39:45 - INFO - __main__ - Step 10 Global step 10 Train loss 7.20 on epoch=0
05/28/2022 11:39:47 - INFO - __main__ - Step 20 Global step 20 Train loss 5.18 on epoch=0
05/28/2022 11:39:50 - INFO - __main__ - Step 30 Global step 30 Train loss 4.02 on epoch=0
05/28/2022 11:39:53 - INFO - __main__ - Step 40 Global step 40 Train loss 3.83 on epoch=0
05/28/2022 11:39:55 - INFO - __main__ - Step 50 Global step 50 Train loss 3.20 on epoch=0
05/28/2022 11:40:48 - INFO - __main__ - Global step 50 Train loss 4.69 Classification-F1 0.010392326822390986 on epoch=0
05/28/2022 11:40:48 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.010392326822390986 on epoch=0, global_step=50
05/28/2022 11:40:50 - INFO - __main__ - Step 60 Global step 60 Train loss 2.75 on epoch=0
05/28/2022 11:40:53 - INFO - __main__ - Step 70 Global step 70 Train loss 2.57 on epoch=0
05/28/2022 11:40:56 - INFO - __main__ - Step 80 Global step 80 Train loss 2.15 on epoch=0
05/28/2022 11:40:58 - INFO - __main__ - Step 90 Global step 90 Train loss 2.06 on epoch=0
05/28/2022 11:41:01 - INFO - __main__ - Step 100 Global step 100 Train loss 2.41 on epoch=0
05/28/2022 11:41:50 - INFO - __main__ - Global step 100 Train loss 2.39 Classification-F1 0.03443886431217845 on epoch=0
05/28/2022 11:41:50 - INFO - __main__ - Saving model with best Classification-F1: 0.010392326822390986 -> 0.03443886431217845 on epoch=0, global_step=100
05/28/2022 11:41:52 - INFO - __main__ - Step 110 Global step 110 Train loss 1.50 on epoch=0
05/28/2022 11:41:55 - INFO - __main__ - Step 120 Global step 120 Train loss 1.99 on epoch=1
05/28/2022 11:41:57 - INFO - __main__ - Step 130 Global step 130 Train loss 1.68 on epoch=1
05/28/2022 11:42:00 - INFO - __main__ - Step 140 Global step 140 Train loss 1.39 on epoch=1
05/28/2022 11:42:03 - INFO - __main__ - Step 150 Global step 150 Train loss 1.48 on epoch=1
05/28/2022 11:42:48 - INFO - __main__ - Global step 150 Train loss 1.61 Classification-F1 0.07200854516379997 on epoch=1
05/28/2022 11:42:48 - INFO - __main__ - Saving model with best Classification-F1: 0.03443886431217845 -> 0.07200854516379997 on epoch=1, global_step=150
05/28/2022 11:42:51 - INFO - __main__ - Step 160 Global step 160 Train loss 1.32 on epoch=1
05/28/2022 11:42:53 - INFO - __main__ - Step 170 Global step 170 Train loss 1.28 on epoch=1
05/28/2022 11:42:56 - INFO - __main__ - Step 180 Global step 180 Train loss 1.03 on epoch=1
05/28/2022 11:42:58 - INFO - __main__ - Step 190 Global step 190 Train loss 0.95 on epoch=1
05/28/2022 11:43:01 - INFO - __main__ - Step 200 Global step 200 Train loss 1.08 on epoch=1
05/28/2022 11:43:46 - INFO - __main__ - Global step 200 Train loss 1.13 Classification-F1 0.12213626489664332 on epoch=1
05/28/2022 11:43:46 - INFO - __main__ - Saving model with best Classification-F1: 0.07200854516379997 -> 0.12213626489664332 on epoch=1, global_step=200
05/28/2022 11:43:49 - INFO - __main__ - Step 210 Global step 210 Train loss 0.88 on epoch=1
05/28/2022 11:43:51 - INFO - __main__ - Step 220 Global step 220 Train loss 0.80 on epoch=1
05/28/2022 11:43:54 - INFO - __main__ - Step 230 Global step 230 Train loss 0.81 on epoch=2
05/28/2022 11:43:57 - INFO - __main__ - Step 240 Global step 240 Train loss 0.73 on epoch=2
05/28/2022 11:43:59 - INFO - __main__ - Step 250 Global step 250 Train loss 0.69 on epoch=2
05/28/2022 11:44:50 - INFO - __main__ - Global step 250 Train loss 0.78 Classification-F1 0.1967903870387127 on epoch=2
05/28/2022 11:44:50 - INFO - __main__ - Saving model with best Classification-F1: 0.12213626489664332 -> 0.1967903870387127 on epoch=2, global_step=250
05/28/2022 11:44:53 - INFO - __main__ - Step 260 Global step 260 Train loss 0.56 on epoch=2
05/28/2022 11:44:55 - INFO - __main__ - Step 270 Global step 270 Train loss 0.53 on epoch=2
05/28/2022 11:44:58 - INFO - __main__ - Step 280 Global step 280 Train loss 0.48 on epoch=2
05/28/2022 11:45:00 - INFO - __main__ - Step 290 Global step 290 Train loss 0.49 on epoch=2
05/28/2022 11:45:03 - INFO - __main__ - Step 300 Global step 300 Train loss 0.44 on epoch=2
05/28/2022 11:45:54 - INFO - __main__ - Global step 300 Train loss 0.50 Classification-F1 0.24345200703781103 on epoch=2
05/28/2022 11:45:54 - INFO - __main__ - Saving model with best Classification-F1: 0.1967903870387127 -> 0.24345200703781103 on epoch=2, global_step=300
05/28/2022 11:45:57 - INFO - __main__ - Step 310 Global step 310 Train loss 0.43 on epoch=2
05/28/2022 11:45:59 - INFO - __main__ - Step 320 Global step 320 Train loss 0.50 on epoch=2
05/28/2022 11:46:02 - INFO - __main__ - Step 330 Global step 330 Train loss 0.36 on epoch=2
05/28/2022 11:46:04 - INFO - __main__ - Step 340 Global step 340 Train loss 0.43 on epoch=3
05/28/2022 11:46:07 - INFO - __main__ - Step 350 Global step 350 Train loss 0.41 on epoch=3
05/28/2022 11:47:00 - INFO - __main__ - Global step 350 Train loss 0.43 Classification-F1 0.33244783891919055 on epoch=3
05/28/2022 11:47:00 - INFO - __main__ - Saving model with best Classification-F1: 0.24345200703781103 -> 0.33244783891919055 on epoch=3, global_step=350
05/28/2022 11:47:02 - INFO - __main__ - Step 360 Global step 360 Train loss 0.34 on epoch=3
05/28/2022 11:47:05 - INFO - __main__ - Step 370 Global step 370 Train loss 0.33 on epoch=3
05/28/2022 11:47:07 - INFO - __main__ - Step 380 Global step 380 Train loss 0.49 on epoch=3
05/28/2022 11:47:10 - INFO - __main__ - Step 390 Global step 390 Train loss 0.34 on epoch=3
05/28/2022 11:47:13 - INFO - __main__ - Step 400 Global step 400 Train loss 0.37 on epoch=3
05/28/2022 11:48:04 - INFO - __main__ - Global step 400 Train loss 0.37 Classification-F1 0.35846163737872344 on epoch=3
05/28/2022 11:48:04 - INFO - __main__ - Saving model with best Classification-F1: 0.33244783891919055 -> 0.35846163737872344 on epoch=3, global_step=400
05/28/2022 11:48:07 - INFO - __main__ - Step 410 Global step 410 Train loss 0.26 on epoch=3
05/28/2022 11:48:10 - INFO - __main__ - Step 420 Global step 420 Train loss 0.27 on epoch=3
05/28/2022 11:48:12 - INFO - __main__ - Step 430 Global step 430 Train loss 0.39 on epoch=3
05/28/2022 11:48:15 - INFO - __main__ - Step 440 Global step 440 Train loss 0.34 on epoch=3
05/28/2022 11:48:17 - INFO - __main__ - Step 450 Global step 450 Train loss 0.27 on epoch=4
05/28/2022 11:49:11 - INFO - __main__ - Global step 450 Train loss 0.31 Classification-F1 0.3776762683537497 on epoch=4
05/28/2022 11:49:11 - INFO - __main__ - Saving model with best Classification-F1: 0.35846163737872344 -> 0.3776762683537497 on epoch=4, global_step=450
05/28/2022 11:49:13 - INFO - __main__ - Step 460 Global step 460 Train loss 0.39 on epoch=4
05/28/2022 11:49:16 - INFO - __main__ - Step 470 Global step 470 Train loss 0.25 on epoch=4
05/28/2022 11:49:19 - INFO - __main__ - Step 480 Global step 480 Train loss 0.20 on epoch=4
05/28/2022 11:49:21 - INFO - __main__ - Step 490 Global step 490 Train loss 0.24 on epoch=4
05/28/2022 11:49:24 - INFO - __main__ - Step 500 Global step 500 Train loss 0.22 on epoch=4
05/28/2022 11:50:15 - INFO - __main__ - Global step 500 Train loss 0.26 Classification-F1 0.39835582294528404 on epoch=4
05/28/2022 11:50:15 - INFO - __main__ - Saving model with best Classification-F1: 0.3776762683537497 -> 0.39835582294528404 on epoch=4, global_step=500
05/28/2022 11:50:17 - INFO - __main__ - Step 510 Global step 510 Train loss 0.27 on epoch=4
05/28/2022 11:50:20 - INFO - __main__ - Step 520 Global step 520 Train loss 0.20 on epoch=4
05/28/2022 11:50:22 - INFO - __main__ - Step 530 Global step 530 Train loss 0.22 on epoch=4
05/28/2022 11:50:25 - INFO - __main__ - Step 540 Global step 540 Train loss 0.25 on epoch=4
05/28/2022 11:50:28 - INFO - __main__ - Step 550 Global step 550 Train loss 0.31 on epoch=4
05/28/2022 11:51:20 - INFO - __main__ - Global step 550 Train loss 0.25 Classification-F1 0.4438127709189924 on epoch=4
05/28/2022 11:51:20 - INFO - __main__ - Saving model with best Classification-F1: 0.39835582294528404 -> 0.4438127709189924 on epoch=4, global_step=550
05/28/2022 11:51:23 - INFO - __main__ - Step 560 Global step 560 Train loss 0.17 on epoch=4
05/28/2022 11:51:25 - INFO - __main__ - Step 570 Global step 570 Train loss 0.26 on epoch=5
05/28/2022 11:51:28 - INFO - __main__ - Step 580 Global step 580 Train loss 0.26 on epoch=5
05/28/2022 11:51:30 - INFO - __main__ - Step 590 Global step 590 Train loss 0.14 on epoch=5
05/28/2022 11:51:33 - INFO - __main__ - Step 600 Global step 600 Train loss 0.21 on epoch=5
05/28/2022 11:52:26 - INFO - __main__ - Global step 600 Train loss 0.21 Classification-F1 0.420512609551848 on epoch=5
05/28/2022 11:52:28 - INFO - __main__ - Step 610 Global step 610 Train loss 0.23 on epoch=5
05/28/2022 11:52:31 - INFO - __main__ - Step 620 Global step 620 Train loss 0.19 on epoch=5
05/28/2022 11:52:34 - INFO - __main__ - Step 630 Global step 630 Train loss 0.17 on epoch=5
05/28/2022 11:52:36 - INFO - __main__ - Step 640 Global step 640 Train loss 0.15 on epoch=5
05/28/2022 11:52:39 - INFO - __main__ - Step 650 Global step 650 Train loss 0.21 on epoch=5
05/28/2022 11:53:30 - INFO - __main__ - Global step 650 Train loss 0.19 Classification-F1 0.4800225730989578 on epoch=5
05/28/2022 11:53:30 - INFO - __main__ - Saving model with best Classification-F1: 0.4438127709189924 -> 0.4800225730989578 on epoch=5, global_step=650
05/28/2022 11:53:32 - INFO - __main__ - Step 660 Global step 660 Train loss 0.24 on epoch=5
05/28/2022 11:53:35 - INFO - __main__ - Step 670 Global step 670 Train loss 0.20 on epoch=5
05/28/2022 11:53:38 - INFO - __main__ - Step 680 Global step 680 Train loss 0.16 on epoch=6
05/28/2022 11:53:40 - INFO - __main__ - Step 690 Global step 690 Train loss 0.32 on epoch=6
05/28/2022 11:53:43 - INFO - __main__ - Step 700 Global step 700 Train loss 0.11 on epoch=6
05/28/2022 11:54:34 - INFO - __main__ - Global step 700 Train loss 0.21 Classification-F1 0.44569397083177326 on epoch=6
05/28/2022 11:54:36 - INFO - __main__ - Step 710 Global step 710 Train loss 0.17 on epoch=6
05/28/2022 11:54:39 - INFO - __main__ - Step 720 Global step 720 Train loss 0.12 on epoch=6
05/28/2022 11:54:42 - INFO - __main__ - Step 730 Global step 730 Train loss 0.18 on epoch=6
05/28/2022 11:54:44 - INFO - __main__ - Step 740 Global step 740 Train loss 0.16 on epoch=6
05/28/2022 11:54:47 - INFO - __main__ - Step 750 Global step 750 Train loss 0.14 on epoch=6
05/28/2022 11:55:39 - INFO - __main__ - Global step 750 Train loss 0.15 Classification-F1 0.48731820106578294 on epoch=6
05/28/2022 11:55:39 - INFO - __main__ - Saving model with best Classification-F1: 0.4800225730989578 -> 0.48731820106578294 on epoch=6, global_step=750
05/28/2022 11:55:42 - INFO - __main__ - Step 760 Global step 760 Train loss 0.15 on epoch=6
05/28/2022 11:55:45 - INFO - __main__ - Step 770 Global step 770 Train loss 0.17 on epoch=6
05/28/2022 11:55:47 - INFO - __main__ - Step 780 Global step 780 Train loss 0.15 on epoch=6
05/28/2022 11:55:50 - INFO - __main__ - Step 790 Global step 790 Train loss 0.13 on epoch=7
05/28/2022 11:55:52 - INFO - __main__ - Step 800 Global step 800 Train loss 0.26 on epoch=7
05/28/2022 11:56:44 - INFO - __main__ - Global step 800 Train loss 0.17 Classification-F1 0.4814255387025589 on epoch=7
05/28/2022 11:56:47 - INFO - __main__ - Step 810 Global step 810 Train loss 0.11 on epoch=7
05/28/2022 11:56:49 - INFO - __main__ - Step 820 Global step 820 Train loss 0.09 on epoch=7
05/28/2022 11:56:52 - INFO - __main__ - Step 830 Global step 830 Train loss 0.13 on epoch=7
05/28/2022 11:56:55 - INFO - __main__ - Step 840 Global step 840 Train loss 0.13 on epoch=7
05/28/2022 11:56:57 - INFO - __main__ - Step 850 Global step 850 Train loss 0.13 on epoch=7
05/28/2022 11:57:49 - INFO - __main__ - Global step 850 Train loss 0.12 Classification-F1 0.48413115852065786 on epoch=7
05/28/2022 11:57:52 - INFO - __main__ - Step 860 Global step 860 Train loss 0.13 on epoch=7
05/28/2022 11:57:55 - INFO - __main__ - Step 870 Global step 870 Train loss 0.13 on epoch=7
05/28/2022 11:57:57 - INFO - __main__ - Step 880 Global step 880 Train loss 0.13 on epoch=7
05/28/2022 11:58:00 - INFO - __main__ - Step 890 Global step 890 Train loss 0.12 on epoch=7
05/28/2022 11:58:03 - INFO - __main__ - Step 900 Global step 900 Train loss 0.12 on epoch=8
05/28/2022 11:58:56 - INFO - __main__ - Global step 900 Train loss 0.13 Classification-F1 0.598757868843919 on epoch=8
05/28/2022 11:58:56 - INFO - __main__ - Saving model with best Classification-F1: 0.48731820106578294 -> 0.598757868843919 on epoch=8, global_step=900
05/28/2022 11:58:58 - INFO - __main__ - Step 910 Global step 910 Train loss 0.19 on epoch=8
05/28/2022 11:59:01 - INFO - __main__ - Step 920 Global step 920 Train loss 0.08 on epoch=8
05/28/2022 11:59:04 - INFO - __main__ - Step 930 Global step 930 Train loss 0.07 on epoch=8
05/28/2022 11:59:06 - INFO - __main__ - Step 940 Global step 940 Train loss 0.14 on epoch=8
05/28/2022 11:59:09 - INFO - __main__ - Step 950 Global step 950 Train loss 0.07 on epoch=8
05/28/2022 12:00:01 - INFO - __main__ - Global step 950 Train loss 0.11 Classification-F1 0.6213833336825926 on epoch=8
05/28/2022 12:00:01 - INFO - __main__ - Saving model with best Classification-F1: 0.598757868843919 -> 0.6213833336825926 on epoch=8, global_step=950
05/28/2022 12:00:04 - INFO - __main__ - Step 960 Global step 960 Train loss 0.16 on epoch=8
05/28/2022 12:00:06 - INFO - __main__ - Step 970 Global step 970 Train loss 0.07 on epoch=8
05/28/2022 12:00:09 - INFO - __main__ - Step 980 Global step 980 Train loss 0.09 on epoch=8
05/28/2022 12:00:12 - INFO - __main__ - Step 990 Global step 990 Train loss 0.16 on epoch=8
05/28/2022 12:00:14 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.06 on epoch=8
05/28/2022 12:01:07 - INFO - __main__ - Global step 1000 Train loss 0.11 Classification-F1 0.6895193282342347 on epoch=8
05/28/2022 12:01:07 - INFO - __main__ - Saving model with best Classification-F1: 0.6213833336825926 -> 0.6895193282342347 on epoch=8, global_step=1000
05/28/2022 12:01:09 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.11 on epoch=9
05/28/2022 12:01:12 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.18 on epoch=9
05/28/2022 12:01:15 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.16 on epoch=9
05/28/2022 12:01:17 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.06 on epoch=9
05/28/2022 12:01:20 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.11 on epoch=9
05/28/2022 12:02:12 - INFO - __main__ - Global step 1050 Train loss 0.13 Classification-F1 0.6465516353557215 on epoch=9
05/28/2022 12:02:15 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.12 on epoch=9
05/28/2022 12:02:18 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.07 on epoch=9
05/28/2022 12:02:20 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.08 on epoch=9
05/28/2022 12:02:23 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.07 on epoch=9
05/28/2022 12:02:26 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.11 on epoch=9
05/28/2022 12:03:16 - INFO - __main__ - Global step 1100 Train loss 0.09 Classification-F1 0.5945986056800542 on epoch=9
05/28/2022 12:03:19 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.09 on epoch=9
05/28/2022 12:03:22 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.09 on epoch=9
05/28/2022 12:03:24 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.09 on epoch=10
05/28/2022 12:03:27 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.16 on epoch=10
05/28/2022 12:03:30 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.08 on epoch=10
05/28/2022 12:04:20 - INFO - __main__ - Global step 1150 Train loss 0.10 Classification-F1 0.622602705091621 on epoch=10
05/28/2022 12:04:23 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.08 on epoch=10
05/28/2022 12:04:26 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.08 on epoch=10
05/28/2022 12:04:28 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.07 on epoch=10
05/28/2022 12:04:31 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.08 on epoch=10
05/28/2022 12:04:34 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.08 on epoch=10
05/28/2022 12:05:25 - INFO - __main__ - Global step 1200 Train loss 0.08 Classification-F1 0.5940317435426302 on epoch=10
05/28/2022 12:05:27 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.11 on epoch=10
05/28/2022 12:05:30 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.05 on epoch=10
05/28/2022 12:05:33 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.09 on epoch=10
05/28/2022 12:05:35 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.06 on epoch=11
05/28/2022 12:05:38 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.16 on epoch=11
05/28/2022 12:06:29 - INFO - __main__ - Global step 1250 Train loss 0.09 Classification-F1 0.5458569107503761 on epoch=11
05/28/2022 12:06:32 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.04 on epoch=11
05/28/2022 12:06:35 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.03 on epoch=11
05/28/2022 12:06:37 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.07 on epoch=11
05/28/2022 12:06:40 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.08 on epoch=11
05/28/2022 12:06:43 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.09 on epoch=11
05/28/2022 12:07:34 - INFO - __main__ - Global step 1300 Train loss 0.06 Classification-F1 0.6258008516861614 on epoch=11
05/28/2022 12:07:36 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.07 on epoch=11
05/28/2022 12:07:39 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.12 on epoch=11
05/28/2022 12:07:42 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.07 on epoch=11
05/28/2022 12:07:44 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.07 on epoch=11
05/28/2022 12:07:47 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.06 on epoch=12
05/28/2022 12:08:38 - INFO - __main__ - Global step 1350 Train loss 0.08 Classification-F1 0.5709328528356971 on epoch=12
05/28/2022 12:08:40 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.11 on epoch=12
05/28/2022 12:08:43 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.04 on epoch=12
05/28/2022 12:08:46 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.07 on epoch=12
05/28/2022 12:08:48 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.05 on epoch=12
05/28/2022 12:08:51 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.10 on epoch=12
05/28/2022 12:09:42 - INFO - __main__ - Global step 1400 Train loss 0.07 Classification-F1 0.6048623764991936 on epoch=12
05/28/2022 12:09:44 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.08 on epoch=12
05/28/2022 12:09:47 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.04 on epoch=12
05/28/2022 12:09:50 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.09 on epoch=12
05/28/2022 12:09:52 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.07 on epoch=12
05/28/2022 12:09:55 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.09 on epoch=12
05/28/2022 12:10:45 - INFO - __main__ - Global step 1450 Train loss 0.07 Classification-F1 0.6224668541620538 on epoch=12
05/28/2022 12:10:47 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.07 on epoch=13
05/28/2022 12:10:50 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.18 on epoch=13
05/28/2022 12:10:53 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.07 on epoch=13
05/28/2022 12:10:55 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.06 on epoch=13
05/28/2022 12:10:58 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.08 on epoch=13
05/28/2022 12:11:48 - INFO - __main__ - Global step 1500 Train loss 0.09 Classification-F1 0.7703063996237535 on epoch=13
05/28/2022 12:11:48 - INFO - __main__ - Saving model with best Classification-F1: 0.6895193282342347 -> 0.7703063996237535 on epoch=13, global_step=1500
05/28/2022 12:11:51 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.05 on epoch=13
05/28/2022 12:11:53 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.05 on epoch=13
05/28/2022 12:11:56 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.10 on epoch=13
05/28/2022 12:11:59 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.05 on epoch=13
05/28/2022 12:12:01 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.09 on epoch=13
05/28/2022 12:12:52 - INFO - __main__ - Global step 1550 Train loss 0.07 Classification-F1 0.6061985064023844 on epoch=13
05/28/2022 12:12:55 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.04 on epoch=13
05/28/2022 12:12:58 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.03 on epoch=14
05/28/2022 12:13:00 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.14 on epoch=14
05/28/2022 12:13:03 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.10 on epoch=14
05/28/2022 12:13:05 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.03 on epoch=14
05/28/2022 12:13:53 - INFO - __main__ - Global step 1600 Train loss 0.07 Classification-F1 0.637182295803837 on epoch=14
05/28/2022 12:13:56 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.10 on epoch=14
05/28/2022 12:13:59 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.04 on epoch=14
05/28/2022 12:14:01 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.05 on epoch=14
05/28/2022 12:14:04 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.03 on epoch=14
05/28/2022 12:14:06 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.05 on epoch=14
05/28/2022 12:14:56 - INFO - __main__ - Global step 1650 Train loss 0.05 Classification-F1 0.6395674743376285 on epoch=14
05/28/2022 12:14:59 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.09 on epoch=14
05/28/2022 12:15:01 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.04 on epoch=14
05/28/2022 12:15:04 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.07 on epoch=14
05/28/2022 12:15:07 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.06 on epoch=15
05/28/2022 12:15:09 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.13 on epoch=15
05/28/2022 12:15:59 - INFO - __main__ - Global step 1700 Train loss 0.08 Classification-F1 0.5754211700902641 on epoch=15
05/28/2022 12:16:02 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.05 on epoch=15
05/28/2022 12:16:05 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.04 on epoch=15
05/28/2022 12:16:07 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.03 on epoch=15
05/28/2022 12:16:10 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.04 on epoch=15
05/28/2022 12:16:12 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.05 on epoch=15
05/28/2022 12:17:01 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.5463014908399814 on epoch=15
05/28/2022 12:17:04 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.04 on epoch=15
05/28/2022 12:17:07 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.06 on epoch=15
05/28/2022 12:17:09 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.07 on epoch=15
05/28/2022 12:17:12 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=15
05/28/2022 12:17:14 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.05 on epoch=16
05/28/2022 12:18:04 - INFO - __main__ - Global step 1800 Train loss 0.05 Classification-F1 0.5315186018977415 on epoch=16
05/28/2022 12:18:06 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.07 on epoch=16
05/28/2022 12:18:09 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=16
05/28/2022 12:18:12 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=16
05/28/2022 12:18:14 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.07 on epoch=16
05/28/2022 12:18:17 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=16
05/28/2022 12:19:06 - INFO - __main__ - Global step 1850 Train loss 0.05 Classification-F1 0.6068777394072592 on epoch=16
05/28/2022 12:19:08 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=16
05/28/2022 12:19:11 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.03 on epoch=16
05/28/2022 12:19:13 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.09 on epoch=16
05/28/2022 12:19:16 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.04 on epoch=16
05/28/2022 12:19:19 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.04 on epoch=16
05/28/2022 12:20:08 - INFO - __main__ - Global step 1900 Train loss 0.05 Classification-F1 0.6364408075475614 on epoch=16
05/28/2022 12:20:11 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=17
05/28/2022 12:20:14 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.12 on epoch=17
05/28/2022 12:20:16 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.06 on epoch=17
05/28/2022 12:20:19 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=17
05/28/2022 12:20:21 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.04 on epoch=17
05/28/2022 12:21:11 - INFO - __main__ - Global step 1950 Train loss 0.05 Classification-F1 0.6383451349654632 on epoch=17
05/28/2022 12:21:14 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.03 on epoch=17
05/28/2022 12:21:16 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.06 on epoch=17
05/28/2022 12:21:19 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.04 on epoch=17
05/28/2022 12:21:22 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.05 on epoch=17
05/28/2022 12:21:24 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.05 on epoch=17
05/28/2022 12:22:13 - INFO - __main__ - Global step 2000 Train loss 0.04 Classification-F1 0.717133904190597 on epoch=17
05/28/2022 12:22:16 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.08 on epoch=17
05/28/2022 12:22:18 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.04 on epoch=18
05/28/2022 12:22:21 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.08 on epoch=18
05/28/2022 12:22:24 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.03 on epoch=18
05/28/2022 12:22:26 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.03 on epoch=18
05/28/2022 12:23:16 - INFO - __main__ - Global step 2050 Train loss 0.05 Classification-F1 0.6448293082210281 on epoch=18
05/28/2022 12:23:19 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.04 on epoch=18
05/28/2022 12:23:21 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.03 on epoch=18
05/28/2022 12:23:24 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.04 on epoch=18
05/28/2022 12:23:26 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.04 on epoch=18
05/28/2022 12:23:29 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.04 on epoch=18
05/28/2022 12:24:18 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.7371790313721044 on epoch=18
05/28/2022 12:24:21 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.10 on epoch=18
05/28/2022 12:24:23 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=18
05/28/2022 12:24:26 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.04 on epoch=19
05/28/2022 12:24:29 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.08 on epoch=19
05/28/2022 12:24:31 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.07 on epoch=19
05/28/2022 12:25:20 - INFO - __main__ - Global step 2150 Train loss 0.06 Classification-F1 0.6935146227963184 on epoch=19
05/28/2022 12:25:23 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=19
05/28/2022 12:25:25 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.05 on epoch=19
05/28/2022 12:25:28 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.05 on epoch=19
05/28/2022 12:25:31 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=19
05/28/2022 12:25:33 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.06 on epoch=19
05/28/2022 12:26:22 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.641177687046575 on epoch=19
05/28/2022 12:26:25 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=19
05/28/2022 12:26:28 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.08 on epoch=19
05/28/2022 12:26:30 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.07 on epoch=19
05/28/2022 12:26:33 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=19
05/28/2022 12:26:36 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.03 on epoch=20
05/28/2022 12:27:28 - INFO - __main__ - Global step 2250 Train loss 0.05 Classification-F1 0.6089925091367555 on epoch=20
05/28/2022 12:27:30 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.16 on epoch=20
05/28/2022 12:27:33 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.04 on epoch=20
05/28/2022 12:27:36 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=20
05/28/2022 12:27:38 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=20
05/28/2022 12:27:41 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=20
05/28/2022 12:28:33 - INFO - __main__ - Global step 2300 Train loss 0.05 Classification-F1 0.6074398543510752 on epoch=20
05/28/2022 12:28:36 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.04 on epoch=20
05/28/2022 12:28:38 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=20
05/28/2022 12:28:41 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.05 on epoch=20
05/28/2022 12:28:44 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.07 on epoch=20
05/28/2022 12:28:47 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=20
05/28/2022 12:29:38 - INFO - __main__ - Global step 2350 Train loss 0.04 Classification-F1 0.5744716974093684 on epoch=20
05/28/2022 12:29:40 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=21
05/28/2022 12:29:43 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.09 on epoch=21
05/28/2022 12:29:46 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.04 on epoch=21
05/28/2022 12:29:48 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=21
05/28/2022 12:29:51 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.07 on epoch=21
05/28/2022 12:30:42 - INFO - __main__ - Global step 2400 Train loss 0.05 Classification-F1 0.5228753611106317 on epoch=21
05/28/2022 12:30:45 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.04 on epoch=21
05/28/2022 12:30:47 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=21
05/28/2022 12:30:50 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=21
05/28/2022 12:30:53 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.05 on epoch=21
05/28/2022 12:30:55 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.03 on epoch=21
05/28/2022 12:31:48 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.6576374232566458 on epoch=21
05/28/2022 12:31:50 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=21
05/28/2022 12:31:53 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.05 on epoch=22
05/28/2022 12:31:56 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.07 on epoch=22
05/28/2022 12:31:59 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=22
05/28/2022 12:32:01 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=22
05/28/2022 12:32:54 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.5653899500281204 on epoch=22
05/28/2022 12:32:56 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.03 on epoch=22
05/28/2022 12:32:59 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=22
05/28/2022 12:33:02 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=22
05/28/2022 12:33:04 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=22
05/28/2022 12:33:07 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=22
05/28/2022 12:33:59 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.6174381120965259 on epoch=22
05/28/2022 12:34:02 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.05 on epoch=22
05/28/2022 12:34:04 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.05 on epoch=22
05/28/2022 12:34:07 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=23
05/28/2022 12:34:10 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.12 on epoch=23
05/28/2022 12:34:12 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=23
05/28/2022 12:35:04 - INFO - __main__ - Global step 2600 Train loss 0.05 Classification-F1 0.49514034733268 on epoch=23
05/28/2022 12:35:07 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.03 on epoch=23
05/28/2022 12:35:09 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.03 on epoch=23
05/28/2022 12:35:12 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.03 on epoch=23
05/28/2022 12:35:15 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=23
05/28/2022 12:35:18 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=23
05/28/2022 12:36:09 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.5829318766095395 on epoch=23
05/28/2022 12:36:12 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=23
05/28/2022 12:36:14 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.07 on epoch=23
05/28/2022 12:36:17 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.03 on epoch=23
05/28/2022 12:36:20 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=24
05/28/2022 12:36:22 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.06 on epoch=24
05/28/2022 12:37:14 - INFO - __main__ - Global step 2700 Train loss 0.04 Classification-F1 0.6213727395877157 on epoch=24
05/28/2022 12:37:17 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=24
05/28/2022 12:37:19 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.03 on epoch=24
05/28/2022 12:37:22 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.03 on epoch=24
05/28/2022 12:37:25 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.03 on epoch=24
05/28/2022 12:37:27 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=24
05/28/2022 12:38:19 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.5507835931148259 on epoch=24
05/28/2022 12:38:21 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.06 on epoch=24
05/28/2022 12:38:24 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=24
05/28/2022 12:38:27 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.03 on epoch=24
05/28/2022 12:38:29 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=24
05/28/2022 12:38:32 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=24
05/28/2022 12:39:24 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.5937522445611659 on epoch=24
05/28/2022 12:39:26 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.07 on epoch=25
05/28/2022 12:39:29 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.09 on epoch=25
05/28/2022 12:39:32 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.03 on epoch=25
05/28/2022 12:39:35 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.03 on epoch=25
05/28/2022 12:39:37 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.03 on epoch=25
05/28/2022 12:40:29 - INFO - __main__ - Global step 2850 Train loss 0.05 Classification-F1 0.5502040123591004 on epoch=25
05/28/2022 12:40:32 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=25
05/28/2022 12:40:34 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.06 on epoch=25
05/28/2022 12:40:37 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=25
05/28/2022 12:40:40 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.08 on epoch=25
05/28/2022 12:40:42 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.06 on epoch=25
05/28/2022 12:41:33 - INFO - __main__ - Global step 2900 Train loss 0.05 Classification-F1 0.6184571236132723 on epoch=25
05/28/2022 12:41:36 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=25
05/28/2022 12:41:38 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.03 on epoch=26
05/28/2022 12:41:41 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.06 on epoch=26
05/28/2022 12:41:44 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=26
05/28/2022 12:41:46 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=26
05/28/2022 12:42:38 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.588235926499256 on epoch=26
05/28/2022 12:42:41 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.04 on epoch=26
05/28/2022 12:42:43 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=26
05/28/2022 12:42:46 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.06 on epoch=26
05/28/2022 12:42:49 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=26
05/28/2022 12:42:51 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.05 on epoch=26
05/28/2022 12:42:53 - INFO - __main__ - Start tokenizing ... 1792 instances
05/28/2022 12:42:53 - INFO - __main__ - Printing 3 examples
05/28/2022 12:42:53 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/28/2022 12:42:53 - INFO - __main__ - ['Company']
05/28/2022 12:42:53 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/28/2022 12:42:53 - INFO - __main__ - ['Company']
05/28/2022 12:42:53 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/28/2022 12:42:53 - INFO - __main__ - ['Company']
05/28/2022 12:42:53 - INFO - __main__ - Tokenizing Input ...
05/28/2022 12:42:54 - INFO - __main__ - Tokenizing Output ...
05/28/2022 12:42:56 - INFO - __main__ - Loaded 1792 examples from train data
05/28/2022 12:42:56 - INFO - __main__ - Start tokenizing ... 1792 instances
05/28/2022 12:42:56 - INFO - __main__ - Printing 3 examples
05/28/2022 12:42:56 - INFO - __main__ -  [dbpedia_14] The Aya Group of Companies commonly referred to as the Aya Group is a business conglomerate based in Uganda.
05/28/2022 12:42:56 - INFO - __main__ - ['Company']
05/28/2022 12:42:56 - INFO - __main__ -  [dbpedia_14] Casengo (founded in 2011) is a Dutch company that provides customer service tools for website and webshop owners available as a SaaS. The Amsterdam-based company was founded by Floris and Thijs van der Veen. Both brothers started off with software named Livecom used mainly by large companies such as Philips and DSM. When they decided to develop customer service software for small businesses Casengo was born.
05/28/2022 12:42:56 - INFO - __main__ - ['Company']
05/28/2022 12:42:56 - INFO - __main__ -  [dbpedia_14] KeySpan Corporation now part of National Grid USA was the fifth largest distributor of natural gas in the United States. KeySpan was formed in 1998 as result of the merger of Brooklyn Union Gas Company (founded 1895 by merging several smaller companies) and Long Island Lighting Company (LILCO).
05/28/2022 12:42:56 - INFO - __main__ - ['Company']
05/28/2022 12:42:56 - INFO - __main__ - Tokenizing Input ...
05/28/2022 12:42:57 - INFO - __main__ - Tokenizing Output ...
05/28/2022 12:42:58 - INFO - __main__ - Loaded 1792 examples from dev data
05/28/2022 12:43:13 - INFO - __main__ - load prompt embedding from ckpt
05/28/2022 12:43:14 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/28/2022 12:43:14 - INFO - __main__ - Starting training!
05/28/2022 12:43:42 - INFO - __main__ - Global step 3000 Train loss 0.04 Classification-F1 0.5591344008757939 on epoch=26
05/28/2022 12:43:42 - INFO - __main__ - save last model!
05/28/2022 12:43:42 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/28/2022 12:43:42 - INFO - __main__ - Start tokenizing ... 3500 instances
05/28/2022 12:43:42 - INFO - __main__ - Printing 3 examples
05/28/2022 12:43:42 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/28/2022 12:43:42 - INFO - __main__ - ['Animal']
05/28/2022 12:43:42 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/28/2022 12:43:42 - INFO - __main__ - ['Animal']
05/28/2022 12:43:42 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/28/2022 12:43:42 - INFO - __main__ - ['Village']
05/28/2022 12:43:42 - INFO - __main__ - Tokenizing Input ...
05/28/2022 12:43:44 - INFO - __main__ - Tokenizing Output ...
05/28/2022 12:43:47 - INFO - __main__ - Loaded 3500 examples from test data
05/28/2022 12:45:46 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down128shot/singletask-dbpedia_14/dbpedia_14_128_42_0.4_8_predictions.txt
05/28/2022 12:45:46 - INFO - __main__ - Classification-F1 on test data: 0.5871
05/28/2022 12:45:46 - INFO - __main__ - prefix=dbpedia_14_128_42, lr=0.4, bsz=8, dev_performance=0.7703063996237535, test_performance=0.5870868787652674
05/28/2022 12:45:46 - INFO - __main__ - Running ... prefix=dbpedia_14_128_42, lr=0.3, bsz=8 ...
05/28/2022 12:45:47 - INFO - __main__ - Start tokenizing ... 1792 instances
05/28/2022 12:45:47 - INFO - __main__ - Printing 3 examples
05/28/2022 12:45:47 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/28/2022 12:45:47 - INFO - __main__ - ['Company']
05/28/2022 12:45:47 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/28/2022 12:45:47 - INFO - __main__ - ['Company']
05/28/2022 12:45:47 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/28/2022 12:45:47 - INFO - __main__ - ['Company']
05/28/2022 12:45:47 - INFO - __main__ - Tokenizing Input ...
05/28/2022 12:45:48 - INFO - __main__ - Tokenizing Output ...
05/28/2022 12:45:50 - INFO - __main__ - Loaded 1792 examples from train data
05/28/2022 12:45:50 - INFO - __main__ - Start tokenizing ... 1792 instances
05/28/2022 12:45:50 - INFO - __main__ - Printing 3 examples
05/28/2022 12:45:50 - INFO - __main__ -  [dbpedia_14] The Aya Group of Companies commonly referred to as the Aya Group is a business conglomerate based in Uganda.
05/28/2022 12:45:50 - INFO - __main__ - ['Company']
05/28/2022 12:45:50 - INFO - __main__ -  [dbpedia_14] Casengo (founded in 2011) is a Dutch company that provides customer service tools for website and webshop owners available as a SaaS. The Amsterdam-based company was founded by Floris and Thijs van der Veen. Both brothers started off with software named Livecom used mainly by large companies such as Philips and DSM. When they decided to develop customer service software for small businesses Casengo was born.
05/28/2022 12:45:50 - INFO - __main__ - ['Company']
05/28/2022 12:45:50 - INFO - __main__ -  [dbpedia_14] KeySpan Corporation now part of National Grid USA was the fifth largest distributor of natural gas in the United States. KeySpan was formed in 1998 as result of the merger of Brooklyn Union Gas Company (founded 1895 by merging several smaller companies) and Long Island Lighting Company (LILCO).
05/28/2022 12:45:50 - INFO - __main__ - ['Company']
05/28/2022 12:45:50 - INFO - __main__ - Tokenizing Input ...
05/28/2022 12:45:51 - INFO - __main__ - Tokenizing Output ...
05/28/2022 12:45:52 - INFO - __main__ - Loaded 1792 examples from dev data
05/28/2022 12:46:10 - INFO - __main__ - load prompt embedding from ckpt
05/28/2022 12:46:11 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/28/2022 12:46:11 - INFO - __main__ - Starting training!
05/28/2022 12:46:15 - INFO - __main__ - Step 10 Global step 10 Train loss 7.06 on epoch=0
05/28/2022 12:46:17 - INFO - __main__ - Step 20 Global step 20 Train loss 5.42 on epoch=0
05/28/2022 12:46:20 - INFO - __main__ - Step 30 Global step 30 Train loss 4.66 on epoch=0
05/28/2022 12:46:23 - INFO - __main__ - Step 40 Global step 40 Train loss 4.48 on epoch=0
05/28/2022 12:46:25 - INFO - __main__ - Step 50 Global step 50 Train loss 3.63 on epoch=0
05/28/2022 12:47:21 - INFO - __main__ - Global step 50 Train loss 5.05 Classification-F1 0.006775796896481645 on epoch=0
05/28/2022 12:47:21 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.006775796896481645 on epoch=0, global_step=50
05/28/2022 12:47:24 - INFO - __main__ - Step 60 Global step 60 Train loss 3.27 on epoch=0
05/28/2022 12:47:26 - INFO - __main__ - Step 70 Global step 70 Train loss 3.03 on epoch=0
05/28/2022 12:47:29 - INFO - __main__ - Step 80 Global step 80 Train loss 2.60 on epoch=0
05/28/2022 12:47:31 - INFO - __main__ - Step 90 Global step 90 Train loss 2.41 on epoch=0
05/28/2022 12:47:34 - INFO - __main__ - Step 100 Global step 100 Train loss 2.73 on epoch=0
05/28/2022 12:48:24 - INFO - __main__ - Global step 100 Train loss 2.81 Classification-F1 0.02025894452090945 on epoch=0
05/28/2022 12:48:24 - INFO - __main__ - Saving model with best Classification-F1: 0.006775796896481645 -> 0.02025894452090945 on epoch=0, global_step=100
05/28/2022 12:48:26 - INFO - __main__ - Step 110 Global step 110 Train loss 1.80 on epoch=0
05/28/2022 12:48:29 - INFO - __main__ - Step 120 Global step 120 Train loss 2.37 on epoch=1
05/28/2022 12:48:32 - INFO - __main__ - Step 130 Global step 130 Train loss 2.19 on epoch=1
05/28/2022 12:48:34 - INFO - __main__ - Step 140 Global step 140 Train loss 1.83 on epoch=1
05/28/2022 12:48:37 - INFO - __main__ - Step 150 Global step 150 Train loss 2.00 on epoch=1
05/28/2022 12:49:24 - INFO - __main__ - Global step 150 Train loss 2.04 Classification-F1 0.03966356584821858 on epoch=1
05/28/2022 12:49:24 - INFO - __main__ - Saving model with best Classification-F1: 0.02025894452090945 -> 0.03966356584821858 on epoch=1, global_step=150
05/28/2022 12:49:26 - INFO - __main__ - Step 160 Global step 160 Train loss 1.68 on epoch=1
05/28/2022 12:49:29 - INFO - __main__ - Step 170 Global step 170 Train loss 1.65 on epoch=1
05/28/2022 12:49:32 - INFO - __main__ - Step 180 Global step 180 Train loss 1.49 on epoch=1
05/28/2022 12:49:34 - INFO - __main__ - Step 190 Global step 190 Train loss 1.33 on epoch=1
05/28/2022 12:49:37 - INFO - __main__ - Step 200 Global step 200 Train loss 1.36 on epoch=1
05/28/2022 12:50:21 - INFO - __main__ - Global step 200 Train loss 1.50 Classification-F1 0.07590855895942472 on epoch=1
05/28/2022 12:50:21 - INFO - __main__ - Saving model with best Classification-F1: 0.03966356584821858 -> 0.07590855895942472 on epoch=1, global_step=200
05/28/2022 12:50:24 - INFO - __main__ - Step 210 Global step 210 Train loss 1.55 on epoch=1
05/28/2022 12:50:27 - INFO - __main__ - Step 220 Global step 220 Train loss 1.17 on epoch=1
05/28/2022 12:50:29 - INFO - __main__ - Step 230 Global step 230 Train loss 1.28 on epoch=2
05/28/2022 12:50:32 - INFO - __main__ - Step 240 Global step 240 Train loss 1.20 on epoch=2
05/28/2022 12:50:35 - INFO - __main__ - Step 250 Global step 250 Train loss 0.97 on epoch=2
05/28/2022 12:51:19 - INFO - __main__ - Global step 250 Train loss 1.23 Classification-F1 0.10494486129845255 on epoch=2
05/28/2022 12:51:19 - INFO - __main__ - Saving model with best Classification-F1: 0.07590855895942472 -> 0.10494486129845255 on epoch=2, global_step=250
05/28/2022 12:51:21 - INFO - __main__ - Step 260 Global step 260 Train loss 0.95 on epoch=2
05/28/2022 12:51:24 - INFO - __main__ - Step 270 Global step 270 Train loss 0.93 on epoch=2
05/28/2022 12:51:26 - INFO - __main__ - Step 280 Global step 280 Train loss 0.71 on epoch=2
05/28/2022 12:51:29 - INFO - __main__ - Step 290 Global step 290 Train loss 0.79 on epoch=2
05/28/2022 12:51:32 - INFO - __main__ - Step 300 Global step 300 Train loss 0.70 on epoch=2
05/28/2022 12:52:18 - INFO - __main__ - Global step 300 Train loss 0.82 Classification-F1 0.17024972673322386 on epoch=2
05/28/2022 12:52:18 - INFO - __main__ - Saving model with best Classification-F1: 0.10494486129845255 -> 0.17024972673322386 on epoch=2, global_step=300
05/28/2022 12:52:21 - INFO - __main__ - Step 310 Global step 310 Train loss 0.69 on epoch=2
05/28/2022 12:52:24 - INFO - __main__ - Step 320 Global step 320 Train loss 0.70 on epoch=2
05/28/2022 12:52:26 - INFO - __main__ - Step 330 Global step 330 Train loss 0.53 on epoch=2
05/28/2022 12:52:29 - INFO - __main__ - Step 340 Global step 340 Train loss 0.63 on epoch=3
05/28/2022 12:52:31 - INFO - __main__ - Step 350 Global step 350 Train loss 0.61 on epoch=3
05/28/2022 12:53:22 - INFO - __main__ - Global step 350 Train loss 0.63 Classification-F1 0.21948196087825397 on epoch=3
05/28/2022 12:53:22 - INFO - __main__ - Saving model with best Classification-F1: 0.17024972673322386 -> 0.21948196087825397 on epoch=3, global_step=350
05/28/2022 12:53:24 - INFO - __main__ - Step 360 Global step 360 Train loss 0.57 on epoch=3
05/28/2022 12:53:27 - INFO - __main__ - Step 370 Global step 370 Train loss 0.56 on epoch=3
05/28/2022 12:53:30 - INFO - __main__ - Step 380 Global step 380 Train loss 0.51 on epoch=3
05/28/2022 12:53:32 - INFO - __main__ - Step 390 Global step 390 Train loss 0.44 on epoch=3
05/28/2022 12:53:35 - INFO - __main__ - Step 400 Global step 400 Train loss 0.43 on epoch=3
05/28/2022 12:54:26 - INFO - __main__ - Global step 400 Train loss 0.50 Classification-F1 0.23163891287851424 on epoch=3
05/28/2022 12:54:26 - INFO - __main__ - Saving model with best Classification-F1: 0.21948196087825397 -> 0.23163891287851424 on epoch=3, global_step=400
05/28/2022 12:54:29 - INFO - __main__ - Step 410 Global step 410 Train loss 0.43 on epoch=3
05/28/2022 12:54:32 - INFO - __main__ - Step 420 Global step 420 Train loss 0.33 on epoch=3
05/28/2022 12:54:34 - INFO - __main__ - Step 430 Global step 430 Train loss 0.42 on epoch=3
05/28/2022 12:54:37 - INFO - __main__ - Step 440 Global step 440 Train loss 0.53 on epoch=3
05/28/2022 12:54:39 - INFO - __main__ - Step 450 Global step 450 Train loss 0.37 on epoch=4
05/28/2022 12:55:30 - INFO - __main__ - Global step 450 Train loss 0.42 Classification-F1 0.35412006097510007 on epoch=4
05/28/2022 12:55:30 - INFO - __main__ - Saving model with best Classification-F1: 0.23163891287851424 -> 0.35412006097510007 on epoch=4, global_step=450
05/28/2022 12:55:33 - INFO - __main__ - Step 460 Global step 460 Train loss 0.50 on epoch=4
05/28/2022 12:55:36 - INFO - __main__ - Step 470 Global step 470 Train loss 0.41 on epoch=4
05/28/2022 12:55:38 - INFO - __main__ - Step 480 Global step 480 Train loss 0.30 on epoch=4
05/28/2022 12:55:41 - INFO - __main__ - Step 490 Global step 490 Train loss 0.41 on epoch=4
05/28/2022 12:55:44 - INFO - __main__ - Step 500 Global step 500 Train loss 0.33 on epoch=4
05/28/2022 12:56:35 - INFO - __main__ - Global step 500 Train loss 0.39 Classification-F1 0.3685489614472365 on epoch=4
05/28/2022 12:56:35 - INFO - __main__ - Saving model with best Classification-F1: 0.35412006097510007 -> 0.3685489614472365 on epoch=4, global_step=500
05/28/2022 12:56:38 - INFO - __main__ - Step 510 Global step 510 Train loss 0.30 on epoch=4
05/28/2022 12:56:41 - INFO - __main__ - Step 520 Global step 520 Train loss 0.29 on epoch=4
05/28/2022 12:56:43 - INFO - __main__ - Step 530 Global step 530 Train loss 0.22 on epoch=4
05/28/2022 12:56:46 - INFO - __main__ - Step 540 Global step 540 Train loss 0.26 on epoch=4
05/28/2022 12:56:49 - INFO - __main__ - Step 550 Global step 550 Train loss 0.40 on epoch=4
05/28/2022 12:57:42 - INFO - __main__ - Global step 550 Train loss 0.29 Classification-F1 0.4711831385150769 on epoch=4
05/28/2022 12:57:42 - INFO - __main__ - Saving model with best Classification-F1: 0.3685489614472365 -> 0.4711831385150769 on epoch=4, global_step=550
05/28/2022 12:57:45 - INFO - __main__ - Step 560 Global step 560 Train loss 0.29 on epoch=4
05/28/2022 12:57:47 - INFO - __main__ - Step 570 Global step 570 Train loss 0.27 on epoch=5
05/28/2022 12:57:50 - INFO - __main__ - Step 580 Global step 580 Train loss 0.36 on epoch=5
05/28/2022 12:57:53 - INFO - __main__ - Step 590 Global step 590 Train loss 0.20 on epoch=5
05/28/2022 12:57:55 - INFO - __main__ - Step 600 Global step 600 Train loss 0.27 on epoch=5
05/28/2022 12:58:49 - INFO - __main__ - Global step 600 Train loss 0.28 Classification-F1 0.39275889998868146 on epoch=5
05/28/2022 12:58:52 - INFO - __main__ - Step 610 Global step 610 Train loss 0.27 on epoch=5
05/28/2022 12:58:55 - INFO - __main__ - Step 620 Global step 620 Train loss 0.27 on epoch=5
05/28/2022 12:58:57 - INFO - __main__ - Step 630 Global step 630 Train loss 0.27 on epoch=5
05/28/2022 12:59:00 - INFO - __main__ - Step 640 Global step 640 Train loss 0.20 on epoch=5
05/28/2022 12:59:03 - INFO - __main__ - Step 650 Global step 650 Train loss 0.23 on epoch=5
05/28/2022 12:59:58 - INFO - __main__ - Global step 650 Train loss 0.25 Classification-F1 0.40576427044562274 on epoch=5
05/28/2022 13:00:00 - INFO - __main__ - Step 660 Global step 660 Train loss 0.21 on epoch=5
05/28/2022 13:00:03 - INFO - __main__ - Step 670 Global step 670 Train loss 0.31 on epoch=5
05/28/2022 13:00:06 - INFO - __main__ - Step 680 Global step 680 Train loss 0.29 on epoch=6
05/28/2022 13:00:08 - INFO - __main__ - Step 690 Global step 690 Train loss 0.32 on epoch=6
05/28/2022 13:00:11 - INFO - __main__ - Step 700 Global step 700 Train loss 0.17 on epoch=6
05/28/2022 13:01:05 - INFO - __main__ - Global step 700 Train loss 0.26 Classification-F1 0.434150051409512 on epoch=6
05/28/2022 13:01:07 - INFO - __main__ - Step 710 Global step 710 Train loss 0.21 on epoch=6
05/28/2022 13:01:10 - INFO - __main__ - Step 720 Global step 720 Train loss 0.23 on epoch=6
05/28/2022 13:01:13 - INFO - __main__ - Step 730 Global step 730 Train loss 0.18 on epoch=6
05/28/2022 13:01:16 - INFO - __main__ - Step 740 Global step 740 Train loss 0.22 on epoch=6
05/28/2022 13:01:18 - INFO - __main__ - Step 750 Global step 750 Train loss 0.16 on epoch=6
05/28/2022 13:02:12 - INFO - __main__ - Global step 750 Train loss 0.20 Classification-F1 0.48243471613835737 on epoch=6
05/28/2022 13:02:12 - INFO - __main__ - Saving model with best Classification-F1: 0.4711831385150769 -> 0.48243471613835737 on epoch=6, global_step=750
05/28/2022 13:02:14 - INFO - __main__ - Step 760 Global step 760 Train loss 0.24 on epoch=6
05/28/2022 13:02:17 - INFO - __main__ - Step 770 Global step 770 Train loss 0.21 on epoch=6
05/28/2022 13:02:20 - INFO - __main__ - Step 780 Global step 780 Train loss 0.25 on epoch=6
05/28/2022 13:02:23 - INFO - __main__ - Step 790 Global step 790 Train loss 0.22 on epoch=7
05/28/2022 13:02:25 - INFO - __main__ - Step 800 Global step 800 Train loss 0.22 on epoch=7
05/28/2022 13:03:19 - INFO - __main__ - Global step 800 Train loss 0.23 Classification-F1 0.4887335615064894 on epoch=7
05/28/2022 13:03:19 - INFO - __main__ - Saving model with best Classification-F1: 0.48243471613835737 -> 0.4887335615064894 on epoch=7, global_step=800
05/28/2022 13:03:21 - INFO - __main__ - Step 810 Global step 810 Train loss 0.16 on epoch=7
05/28/2022 13:03:24 - INFO - __main__ - Step 820 Global step 820 Train loss 0.21 on epoch=7
05/28/2022 13:03:27 - INFO - __main__ - Step 830 Global step 830 Train loss 0.24 on epoch=7
05/28/2022 13:03:29 - INFO - __main__ - Step 840 Global step 840 Train loss 0.14 on epoch=7
05/28/2022 13:03:32 - INFO - __main__ - Step 850 Global step 850 Train loss 0.15 on epoch=7
05/28/2022 13:04:25 - INFO - __main__ - Global step 850 Train loss 0.18 Classification-F1 0.5027954781887297 on epoch=7
05/28/2022 13:04:25 - INFO - __main__ - Saving model with best Classification-F1: 0.4887335615064894 -> 0.5027954781887297 on epoch=7, global_step=850
05/28/2022 13:04:27 - INFO - __main__ - Step 860 Global step 860 Train loss 0.16 on epoch=7
05/28/2022 13:04:30 - INFO - __main__ - Step 870 Global step 870 Train loss 0.20 on epoch=7
05/28/2022 13:04:33 - INFO - __main__ - Step 880 Global step 880 Train loss 0.19 on epoch=7
05/28/2022 13:04:36 - INFO - __main__ - Step 890 Global step 890 Train loss 0.13 on epoch=7
05/28/2022 13:04:38 - INFO - __main__ - Step 900 Global step 900 Train loss 0.14 on epoch=8
05/28/2022 13:05:31 - INFO - __main__ - Global step 900 Train loss 0.16 Classification-F1 0.578842917170291 on epoch=8
05/28/2022 13:05:31 - INFO - __main__ - Saving model with best Classification-F1: 0.5027954781887297 -> 0.578842917170291 on epoch=8, global_step=900
05/28/2022 13:05:34 - INFO - __main__ - Step 910 Global step 910 Train loss 0.22 on epoch=8
05/28/2022 13:05:37 - INFO - __main__ - Step 920 Global step 920 Train loss 0.17 on epoch=8
05/28/2022 13:05:39 - INFO - __main__ - Step 930 Global step 930 Train loss 0.10 on epoch=8
05/28/2022 13:05:42 - INFO - __main__ - Step 940 Global step 940 Train loss 0.20 on epoch=8
05/28/2022 13:05:45 - INFO - __main__ - Step 950 Global step 950 Train loss 0.19 on epoch=8
05/28/2022 13:06:40 - INFO - __main__ - Global step 950 Train loss 0.18 Classification-F1 0.5852560789168136 on epoch=8
05/28/2022 13:06:40 - INFO - __main__ - Saving model with best Classification-F1: 0.578842917170291 -> 0.5852560789168136 on epoch=8, global_step=950
05/28/2022 13:06:42 - INFO - __main__ - Step 960 Global step 960 Train loss 0.11 on epoch=8
05/28/2022 13:06:45 - INFO - __main__ - Step 970 Global step 970 Train loss 0.13 on epoch=8
05/28/2022 13:06:48 - INFO - __main__ - Step 980 Global step 980 Train loss 0.12 on epoch=8
05/28/2022 13:06:50 - INFO - __main__ - Step 990 Global step 990 Train loss 0.10 on epoch=8
05/28/2022 13:06:53 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.10 on epoch=8
05/28/2022 13:07:46 - INFO - __main__ - Global step 1000 Train loss 0.11 Classification-F1 0.46503667699048684 on epoch=8
05/28/2022 13:07:49 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.10 on epoch=9
05/28/2022 13:07:52 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.23 on epoch=9
05/28/2022 13:07:54 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.16 on epoch=9
05/28/2022 13:07:57 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.14 on epoch=9
05/28/2022 13:08:00 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.15 on epoch=9
05/28/2022 13:08:54 - INFO - __main__ - Global step 1050 Train loss 0.16 Classification-F1 0.5053025952679344 on epoch=9
05/28/2022 13:08:57 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.08 on epoch=9
05/28/2022 13:08:59 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.07 on epoch=9
05/28/2022 13:09:02 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.11 on epoch=9
05/28/2022 13:09:05 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.10 on epoch=9
05/28/2022 13:09:07 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.10 on epoch=9
05/28/2022 13:10:00 - INFO - __main__ - Global step 1100 Train loss 0.09 Classification-F1 0.4709463909207986 on epoch=9
05/28/2022 13:10:03 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.15 on epoch=9
05/28/2022 13:10:06 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.11 on epoch=9
05/28/2022 13:10:09 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.09 on epoch=10
05/28/2022 13:10:11 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.19 on epoch=10
05/28/2022 13:10:14 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.06 on epoch=10
05/28/2022 13:11:07 - INFO - __main__ - Global step 1150 Train loss 0.12 Classification-F1 0.4870806926965532 on epoch=10
05/28/2022 13:11:10 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.11 on epoch=10
05/28/2022 13:11:12 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.13 on epoch=10
05/28/2022 13:11:15 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.10 on epoch=10
05/28/2022 13:11:18 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.12 on epoch=10
05/28/2022 13:11:20 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.09 on epoch=10
05/28/2022 13:12:13 - INFO - __main__ - Global step 1200 Train loss 0.11 Classification-F1 0.47446423725636955 on epoch=10
05/28/2022 13:12:15 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.14 on epoch=10
05/28/2022 13:12:18 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.12 on epoch=10
05/28/2022 13:12:21 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.15 on epoch=10
05/28/2022 13:12:24 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.16 on epoch=11
05/28/2022 13:12:26 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.11 on epoch=11
05/28/2022 13:13:19 - INFO - __main__ - Global step 1250 Train loss 0.14 Classification-F1 0.4731216915500186 on epoch=11
05/28/2022 13:13:22 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.08 on epoch=11
05/28/2022 13:13:24 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.12 on epoch=11
05/28/2022 13:13:27 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.11 on epoch=11
05/28/2022 13:13:30 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.09 on epoch=11
05/28/2022 13:13:32 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.08 on epoch=11
05/28/2022 13:14:25 - INFO - __main__ - Global step 1300 Train loss 0.10 Classification-F1 0.45795996641233194 on epoch=11
05/28/2022 13:14:28 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.12 on epoch=11
05/28/2022 13:14:31 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.15 on epoch=11
05/28/2022 13:14:33 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.08 on epoch=11
05/28/2022 13:14:36 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.09 on epoch=11
05/28/2022 13:14:39 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.14 on epoch=12
05/28/2022 13:15:31 - INFO - __main__ - Global step 1350 Train loss 0.12 Classification-F1 0.5286859280685855 on epoch=12
05/28/2022 13:15:33 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.14 on epoch=12
05/28/2022 13:15:36 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.09 on epoch=12
05/28/2022 13:15:39 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.06 on epoch=12
05/28/2022 13:15:41 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.11 on epoch=12
05/28/2022 13:15:44 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.07 on epoch=12
05/28/2022 13:16:37 - INFO - __main__ - Global step 1400 Train loss 0.09 Classification-F1 0.5074561743225829 on epoch=12
05/28/2022 13:16:40 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.09 on epoch=12
05/28/2022 13:16:42 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.07 on epoch=12
05/28/2022 13:16:45 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.06 on epoch=12
05/28/2022 13:16:48 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.11 on epoch=12
05/28/2022 13:16:51 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.09 on epoch=12
05/28/2022 13:17:43 - INFO - __main__ - Global step 1450 Train loss 0.08 Classification-F1 0.44653335103607017 on epoch=12
05/28/2022 13:17:45 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.07 on epoch=13
05/28/2022 13:17:48 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.19 on epoch=13
05/28/2022 13:17:51 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.09 on epoch=13
05/28/2022 13:17:54 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.04 on epoch=13
05/28/2022 13:17:56 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.11 on epoch=13
05/28/2022 13:18:47 - INFO - __main__ - Global step 1500 Train loss 0.10 Classification-F1 0.48753656231786374 on epoch=13
05/28/2022 13:18:50 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.06 on epoch=13
05/28/2022 13:18:52 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.13 on epoch=13
05/28/2022 13:18:55 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.05 on epoch=13
05/28/2022 13:18:58 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.04 on epoch=13
05/28/2022 13:19:00 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.13 on epoch=13
05/28/2022 13:19:52 - INFO - __main__ - Global step 1550 Train loss 0.08 Classification-F1 0.5353286424057825 on epoch=13
05/28/2022 13:19:55 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.09 on epoch=13
05/28/2022 13:19:58 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.11 on epoch=14
05/28/2022 13:20:00 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.12 on epoch=14
05/28/2022 13:20:03 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.08 on epoch=14
05/28/2022 13:20:06 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.08 on epoch=14
05/28/2022 13:20:58 - INFO - __main__ - Global step 1600 Train loss 0.10 Classification-F1 0.5452937183250406 on epoch=14
05/28/2022 13:21:00 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.06 on epoch=14
05/28/2022 13:21:03 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.07 on epoch=14
05/28/2022 13:21:06 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.05 on epoch=14
05/28/2022 13:21:08 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.05 on epoch=14
05/28/2022 13:21:11 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.05 on epoch=14
05/28/2022 13:22:02 - INFO - __main__ - Global step 1650 Train loss 0.06 Classification-F1 0.5520343633018904 on epoch=14
05/28/2022 13:22:05 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.12 on epoch=14
05/28/2022 13:22:08 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.08 on epoch=14
05/28/2022 13:22:11 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.05 on epoch=14
05/28/2022 13:22:13 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.09 on epoch=15
05/28/2022 13:22:16 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.12 on epoch=15
05/28/2022 13:23:08 - INFO - __main__ - Global step 1700 Train loss 0.09 Classification-F1 0.5652595262437439 on epoch=15
05/28/2022 13:23:10 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.06 on epoch=15
05/28/2022 13:23:13 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.11 on epoch=15
05/28/2022 13:23:16 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.04 on epoch=15
05/28/2022 13:23:18 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.05 on epoch=15
05/28/2022 13:23:21 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.07 on epoch=15
05/28/2022 13:24:12 - INFO - __main__ - Global step 1750 Train loss 0.07 Classification-F1 0.5585161785391719 on epoch=15
05/28/2022 13:24:15 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.05 on epoch=15
05/28/2022 13:24:18 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.21 on epoch=15
05/28/2022 13:24:20 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.09 on epoch=15
05/28/2022 13:24:23 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.04 on epoch=15
05/28/2022 13:24:25 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.13 on epoch=16
05/28/2022 13:25:15 - INFO - __main__ - Global step 1800 Train loss 0.11 Classification-F1 0.573932888998518 on epoch=16
05/28/2022 13:25:18 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.09 on epoch=16
05/28/2022 13:25:21 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=16
05/28/2022 13:25:23 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.04 on epoch=16
05/28/2022 13:25:26 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.08 on epoch=16
05/28/2022 13:25:29 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.08 on epoch=16
05/28/2022 13:26:20 - INFO - __main__ - Global step 1850 Train loss 0.06 Classification-F1 0.5283515394336756 on epoch=16
05/28/2022 13:26:22 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.07 on epoch=16
05/28/2022 13:26:25 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.05 on epoch=16
05/28/2022 13:26:28 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.12 on epoch=16
05/28/2022 13:26:30 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.06 on epoch=16
05/28/2022 13:26:33 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.05 on epoch=16
05/28/2022 13:27:24 - INFO - __main__ - Global step 1900 Train loss 0.07 Classification-F1 0.5959863161696535 on epoch=16
05/28/2022 13:27:24 - INFO - __main__ - Saving model with best Classification-F1: 0.5852560789168136 -> 0.5959863161696535 on epoch=16, global_step=1900
05/28/2022 13:27:26 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.08 on epoch=17
05/28/2022 13:27:29 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.10 on epoch=17
05/28/2022 13:27:32 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=17
05/28/2022 13:27:34 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.04 on epoch=17
05/28/2022 13:27:37 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.07 on epoch=17
05/28/2022 13:28:26 - INFO - __main__ - Global step 1950 Train loss 0.07 Classification-F1 0.5227326551801735 on epoch=17
05/28/2022 13:28:28 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.05 on epoch=17
05/28/2022 13:28:31 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.09 on epoch=17
05/28/2022 13:28:34 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.05 on epoch=17
05/28/2022 13:28:36 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.05 on epoch=17
05/28/2022 13:28:39 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.09 on epoch=17
05/28/2022 13:29:29 - INFO - __main__ - Global step 2000 Train loss 0.07 Classification-F1 0.5772638898857602 on epoch=17
05/28/2022 13:29:32 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.04 on epoch=17
05/28/2022 13:29:35 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.03 on epoch=18
05/28/2022 13:29:37 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.14 on epoch=18
05/28/2022 13:29:40 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.07 on epoch=18
05/28/2022 13:29:42 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.03 on epoch=18
05/28/2022 13:30:32 - INFO - __main__ - Global step 2050 Train loss 0.06 Classification-F1 0.5389659490722503 on epoch=18
05/28/2022 13:30:35 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.06 on epoch=18
05/28/2022 13:30:37 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.07 on epoch=18
05/28/2022 13:30:40 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.07 on epoch=18
05/28/2022 13:30:43 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.05 on epoch=18
05/28/2022 13:30:45 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.06 on epoch=18
05/28/2022 13:31:35 - INFO - __main__ - Global step 2100 Train loss 0.06 Classification-F1 0.5642523636885864 on epoch=18
05/28/2022 13:31:38 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.08 on epoch=18
05/28/2022 13:31:40 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.04 on epoch=18
05/28/2022 13:31:43 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=19
05/28/2022 13:31:46 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.11 on epoch=19
05/28/2022 13:31:48 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.09 on epoch=19
05/28/2022 13:32:37 - INFO - __main__ - Global step 2150 Train loss 0.07 Classification-F1 0.5606480306391182 on epoch=19
05/28/2022 13:32:40 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.11 on epoch=19
05/28/2022 13:32:42 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.05 on epoch=19
05/28/2022 13:32:45 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=19
05/28/2022 13:32:48 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.05 on epoch=19
05/28/2022 13:32:50 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.07 on epoch=19
05/28/2022 13:33:39 - INFO - __main__ - Global step 2200 Train loss 0.06 Classification-F1 0.5665995406753078 on epoch=19
05/28/2022 13:33:42 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=19
05/28/2022 13:33:44 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.07 on epoch=19
05/28/2022 13:33:47 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.05 on epoch=19
05/28/2022 13:33:50 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.03 on epoch=19
05/28/2022 13:33:52 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.10 on epoch=20
05/28/2022 13:34:41 - INFO - __main__ - Global step 2250 Train loss 0.06 Classification-F1 0.550424619445539 on epoch=20
05/28/2022 13:34:44 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.13 on epoch=20
05/28/2022 13:34:47 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.04 on epoch=20
05/28/2022 13:34:49 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=20
05/28/2022 13:34:52 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.06 on epoch=20
05/28/2022 13:34:55 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=20
05/28/2022 13:35:43 - INFO - __main__ - Global step 2300 Train loss 0.06 Classification-F1 0.5152962336940833 on epoch=20
05/28/2022 13:35:46 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.04 on epoch=20
05/28/2022 13:35:49 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.05 on epoch=20
05/28/2022 13:35:51 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.06 on epoch=20
05/28/2022 13:35:54 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.03 on epoch=20
05/28/2022 13:35:57 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.07 on epoch=20
05/28/2022 13:36:46 - INFO - __main__ - Global step 2350 Train loss 0.05 Classification-F1 0.4928795773949981 on epoch=20
05/28/2022 13:36:48 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.05 on epoch=21
05/28/2022 13:36:51 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.14 on epoch=21
05/28/2022 13:36:54 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.03 on epoch=21
05/28/2022 13:36:56 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=21
05/28/2022 13:36:59 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.06 on epoch=21
05/28/2022 13:37:47 - INFO - __main__ - Global step 2400 Train loss 0.06 Classification-F1 0.452344103055572 on epoch=21
05/28/2022 13:37:50 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.04 on epoch=21
05/28/2022 13:37:53 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.04 on epoch=21
05/28/2022 13:37:55 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=21
05/28/2022 13:37:58 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.11 on epoch=21
05/28/2022 13:38:01 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.04 on epoch=21
05/28/2022 13:38:50 - INFO - __main__ - Global step 2450 Train loss 0.05 Classification-F1 0.50856147798428 on epoch=21
05/28/2022 13:38:53 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.05 on epoch=21
05/28/2022 13:38:55 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=22
05/28/2022 13:38:58 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.14 on epoch=22
05/28/2022 13:39:01 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=22
05/28/2022 13:39:03 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.04 on epoch=22
05/28/2022 13:39:51 - INFO - __main__ - Global step 2500 Train loss 0.05 Classification-F1 0.4715387847963498 on epoch=22
05/28/2022 13:39:54 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.07 on epoch=22
05/28/2022 13:39:57 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.04 on epoch=22
05/28/2022 13:39:59 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=22
05/28/2022 13:40:02 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.04 on epoch=22
05/28/2022 13:40:05 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.08 on epoch=22
05/28/2022 13:40:53 - INFO - __main__ - Global step 2550 Train loss 0.05 Classification-F1 0.4986980922394181 on epoch=22
05/28/2022 13:40:56 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.08 on epoch=22
05/28/2022 13:40:59 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=22
05/28/2022 13:41:01 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.04 on epoch=23
05/28/2022 13:41:04 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.16 on epoch=23
05/28/2022 13:41:07 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=23
05/28/2022 13:41:56 - INFO - __main__ - Global step 2600 Train loss 0.07 Classification-F1 0.4582703823492081 on epoch=23
05/28/2022 13:41:58 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=23
05/28/2022 13:42:01 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.05 on epoch=23
05/28/2022 13:42:04 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=23
05/28/2022 13:42:06 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.04 on epoch=23
05/28/2022 13:42:09 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.03 on epoch=23
05/28/2022 13:42:58 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.5672172868851946 on epoch=23
05/28/2022 13:43:01 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=23
05/28/2022 13:43:03 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.12 on epoch=23
05/28/2022 13:43:06 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.05 on epoch=23
05/28/2022 13:43:08 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.04 on epoch=24
05/28/2022 13:43:11 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.13 on epoch=24
05/28/2022 13:44:00 - INFO - __main__ - Global step 2700 Train loss 0.07 Classification-F1 0.5062165225310247 on epoch=24
05/28/2022 13:44:03 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.05 on epoch=24
05/28/2022 13:44:06 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=24
05/28/2022 13:44:08 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.10 on epoch=24
05/28/2022 13:44:11 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.03 on epoch=24
05/28/2022 13:44:13 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=24
05/28/2022 13:45:02 - INFO - __main__ - Global step 2750 Train loss 0.04 Classification-F1 0.5161394779631024 on epoch=24
05/28/2022 13:45:05 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=24
05/28/2022 13:45:08 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=24
05/28/2022 13:45:10 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.03 on epoch=24
05/28/2022 13:45:13 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.04 on epoch=24
05/28/2022 13:45:15 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=24
05/28/2022 13:46:04 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.5291875607385287 on epoch=24
05/28/2022 13:46:07 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.04 on epoch=25
05/28/2022 13:46:09 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.14 on epoch=25
05/28/2022 13:46:12 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.03 on epoch=25
05/28/2022 13:46:15 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.06 on epoch=25
05/28/2022 13:46:17 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.03 on epoch=25
05/28/2022 13:47:05 - INFO - __main__ - Global step 2850 Train loss 0.06 Classification-F1 0.493596565095558 on epoch=25
05/28/2022 13:47:08 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=25
05/28/2022 13:47:10 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.04 on epoch=25
05/28/2022 13:47:13 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.06 on epoch=25
05/28/2022 13:47:16 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.06 on epoch=25
05/28/2022 13:47:18 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.03 on epoch=25
05/28/2022 13:48:07 - INFO - __main__ - Global step 2900 Train loss 0.04 Classification-F1 0.5124922705959012 on epoch=25
05/28/2022 13:48:09 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.04 on epoch=25
05/28/2022 13:48:12 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.03 on epoch=26
05/28/2022 13:48:15 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.07 on epoch=26
05/28/2022 13:48:17 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=26
05/28/2022 13:48:20 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=26
05/28/2022 13:49:08 - INFO - __main__ - Global step 2950 Train loss 0.04 Classification-F1 0.477541484594396 on epoch=26
05/28/2022 13:49:11 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.05 on epoch=26
05/28/2022 13:49:13 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=26
05/28/2022 13:49:16 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.04 on epoch=26
05/28/2022 13:49:18 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=26
05/28/2022 13:49:21 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.04 on epoch=26
05/28/2022 13:49:23 - INFO - __main__ - Start tokenizing ... 1792 instances
05/28/2022 13:49:23 - INFO - __main__ - Printing 3 examples
05/28/2022 13:49:23 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/28/2022 13:49:23 - INFO - __main__ - ['Company']
05/28/2022 13:49:23 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/28/2022 13:49:23 - INFO - __main__ - ['Company']
05/28/2022 13:49:23 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/28/2022 13:49:23 - INFO - __main__ - ['Company']
05/28/2022 13:49:23 - INFO - __main__ - Tokenizing Input ...
05/28/2022 13:49:23 - INFO - __main__ - Tokenizing Output ...
05/28/2022 13:49:25 - INFO - __main__ - Loaded 1792 examples from train data
05/28/2022 13:49:25 - INFO - __main__ - Start tokenizing ... 1792 instances
05/28/2022 13:49:25 - INFO - __main__ - Printing 3 examples
05/28/2022 13:49:25 - INFO - __main__ -  [dbpedia_14] The Aya Group of Companies commonly referred to as the Aya Group is a business conglomerate based in Uganda.
05/28/2022 13:49:25 - INFO - __main__ - ['Company']
05/28/2022 13:49:25 - INFO - __main__ -  [dbpedia_14] Casengo (founded in 2011) is a Dutch company that provides customer service tools for website and webshop owners available as a SaaS. The Amsterdam-based company was founded by Floris and Thijs van der Veen. Both brothers started off with software named Livecom used mainly by large companies such as Philips and DSM. When they decided to develop customer service software for small businesses Casengo was born.
05/28/2022 13:49:25 - INFO - __main__ - ['Company']
05/28/2022 13:49:25 - INFO - __main__ -  [dbpedia_14] KeySpan Corporation now part of National Grid USA was the fifth largest distributor of natural gas in the United States. KeySpan was formed in 1998 as result of the merger of Brooklyn Union Gas Company (founded 1895 by merging several smaller companies) and Long Island Lighting Company (LILCO).
05/28/2022 13:49:25 - INFO - __main__ - ['Company']
05/28/2022 13:49:25 - INFO - __main__ - Tokenizing Input ...
05/28/2022 13:49:26 - INFO - __main__ - Tokenizing Output ...
05/28/2022 13:49:28 - INFO - __main__ - Loaded 1792 examples from dev data
05/28/2022 13:49:43 - INFO - __main__ - load prompt embedding from ckpt
05/28/2022 13:49:43 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/28/2022 13:49:43 - INFO - __main__ - Starting training!
05/28/2022 13:50:09 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.5084269762948144 on epoch=26
05/28/2022 13:50:09 - INFO - __main__ - save last model!
05/28/2022 13:50:09 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/28/2022 13:50:09 - INFO - __main__ - Start tokenizing ... 3500 instances
05/28/2022 13:50:09 - INFO - __main__ - Printing 3 examples
05/28/2022 13:50:09 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/28/2022 13:50:09 - INFO - __main__ - ['Animal']
05/28/2022 13:50:09 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/28/2022 13:50:09 - INFO - __main__ - ['Animal']
05/28/2022 13:50:09 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/28/2022 13:50:09 - INFO - __main__ - ['Village']
05/28/2022 13:50:09 - INFO - __main__ - Tokenizing Input ...
05/28/2022 13:50:11 - INFO - __main__ - Tokenizing Output ...
05/28/2022 13:50:14 - INFO - __main__ - Loaded 3500 examples from test data
05/28/2022 13:52:13 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down128shot/singletask-dbpedia_14/dbpedia_14_128_42_0.3_8_predictions.txt
05/28/2022 13:52:14 - INFO - __main__ - Classification-F1 on test data: 0.4938
05/28/2022 13:52:14 - INFO - __main__ - prefix=dbpedia_14_128_42, lr=0.3, bsz=8, dev_performance=0.5959863161696535, test_performance=0.49380354132783477
05/28/2022 13:52:14 - INFO - __main__ - Running ... prefix=dbpedia_14_128_42, lr=0.2, bsz=8 ...
05/28/2022 13:52:15 - INFO - __main__ - Start tokenizing ... 1792 instances
05/28/2022 13:52:15 - INFO - __main__ - Printing 3 examples
05/28/2022 13:52:15 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/28/2022 13:52:15 - INFO - __main__ - ['Company']
05/28/2022 13:52:15 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/28/2022 13:52:15 - INFO - __main__ - ['Company']
05/28/2022 13:52:15 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/28/2022 13:52:15 - INFO - __main__ - ['Company']
05/28/2022 13:52:15 - INFO - __main__ - Tokenizing Input ...
05/28/2022 13:52:16 - INFO - __main__ - Tokenizing Output ...
05/28/2022 13:52:18 - INFO - __main__ - Loaded 1792 examples from train data
05/28/2022 13:52:18 - INFO - __main__ - Start tokenizing ... 1792 instances
05/28/2022 13:52:18 - INFO - __main__ - Printing 3 examples
05/28/2022 13:52:18 - INFO - __main__ -  [dbpedia_14] The Aya Group of Companies commonly referred to as the Aya Group is a business conglomerate based in Uganda.
05/28/2022 13:52:18 - INFO - __main__ - ['Company']
05/28/2022 13:52:18 - INFO - __main__ -  [dbpedia_14] Casengo (founded in 2011) is a Dutch company that provides customer service tools for website and webshop owners available as a SaaS. The Amsterdam-based company was founded by Floris and Thijs van der Veen. Both brothers started off with software named Livecom used mainly by large companies such as Philips and DSM. When they decided to develop customer service software for small businesses Casengo was born.
05/28/2022 13:52:18 - INFO - __main__ - ['Company']
05/28/2022 13:52:18 - INFO - __main__ -  [dbpedia_14] KeySpan Corporation now part of National Grid USA was the fifth largest distributor of natural gas in the United States. KeySpan was formed in 1998 as result of the merger of Brooklyn Union Gas Company (founded 1895 by merging several smaller companies) and Long Island Lighting Company (LILCO).
05/28/2022 13:52:18 - INFO - __main__ - ['Company']
05/28/2022 13:52:18 - INFO - __main__ - Tokenizing Input ...
05/28/2022 13:52:19 - INFO - __main__ - Tokenizing Output ...
05/28/2022 13:52:20 - INFO - __main__ - Loaded 1792 examples from dev data
05/28/2022 13:52:36 - INFO - __main__ - load prompt embedding from ckpt
05/28/2022 13:52:37 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/28/2022 13:52:37 - INFO - __main__ - Starting training!
05/28/2022 13:52:41 - INFO - __main__ - Step 10 Global step 10 Train loss 7.72 on epoch=0
05/28/2022 13:52:43 - INFO - __main__ - Step 20 Global step 20 Train loss 6.11 on epoch=0
05/28/2022 13:52:46 - INFO - __main__ - Step 30 Global step 30 Train loss 5.17 on epoch=0
05/28/2022 13:52:49 - INFO - __main__ - Step 40 Global step 40 Train loss 5.03 on epoch=0
05/28/2022 13:52:51 - INFO - __main__ - Step 50 Global step 50 Train loss 4.16 on epoch=0
05/28/2022 13:53:37 - INFO - __main__ - Global step 50 Train loss 5.64 Classification-F1 0.009475372956172966 on epoch=0
05/28/2022 13:53:37 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.009475372956172966 on epoch=0, global_step=50
05/28/2022 13:53:39 - INFO - __main__ - Step 60 Global step 60 Train loss 3.88 on epoch=0
05/28/2022 13:53:42 - INFO - __main__ - Step 70 Global step 70 Train loss 3.66 on epoch=0
05/28/2022 13:53:45 - INFO - __main__ - Step 80 Global step 80 Train loss 3.45 on epoch=0
05/28/2022 13:53:47 - INFO - __main__ - Step 90 Global step 90 Train loss 2.90 on epoch=0
05/28/2022 13:53:50 - INFO - __main__ - Step 100 Global step 100 Train loss 3.31 on epoch=0
05/28/2022 13:54:42 - INFO - __main__ - Global step 100 Train loss 3.44 Classification-F1 0.011154289816870942 on epoch=0
05/28/2022 13:54:42 - INFO - __main__ - Saving model with best Classification-F1: 0.009475372956172966 -> 0.011154289816870942 on epoch=0, global_step=100
05/28/2022 13:54:44 - INFO - __main__ - Step 110 Global step 110 Train loss 2.41 on epoch=0
05/28/2022 13:54:47 - INFO - __main__ - Step 120 Global step 120 Train loss 2.85 on epoch=1
05/28/2022 13:54:49 - INFO - __main__ - Step 130 Global step 130 Train loss 2.81 on epoch=1
05/28/2022 13:54:52 - INFO - __main__ - Step 140 Global step 140 Train loss 2.29 on epoch=1
05/28/2022 13:54:54 - INFO - __main__ - Step 150 Global step 150 Train loss 2.54 on epoch=1
05/28/2022 13:55:44 - INFO - __main__ - Global step 150 Train loss 2.58 Classification-F1 0.02138246755828683 on epoch=1
05/28/2022 13:55:44 - INFO - __main__ - Saving model with best Classification-F1: 0.011154289816870942 -> 0.02138246755828683 on epoch=1, global_step=150
05/28/2022 13:55:47 - INFO - __main__ - Step 160 Global step 160 Train loss 2.15 on epoch=1
05/28/2022 13:55:49 - INFO - __main__ - Step 170 Global step 170 Train loss 2.26 on epoch=1
05/28/2022 13:55:52 - INFO - __main__ - Step 180 Global step 180 Train loss 1.96 on epoch=1
05/28/2022 13:55:54 - INFO - __main__ - Step 190 Global step 190 Train loss 1.84 on epoch=1
05/28/2022 13:55:57 - INFO - __main__ - Step 200 Global step 200 Train loss 1.96 on epoch=1
05/28/2022 13:56:44 - INFO - __main__ - Global step 200 Train loss 2.03 Classification-F1 0.03535295041916535 on epoch=1
05/28/2022 13:56:44 - INFO - __main__ - Saving model with best Classification-F1: 0.02138246755828683 -> 0.03535295041916535 on epoch=1, global_step=200
05/28/2022 13:56:47 - INFO - __main__ - Step 210 Global step 210 Train loss 1.98 on epoch=1
05/28/2022 13:56:49 - INFO - __main__ - Step 220 Global step 220 Train loss 1.60 on epoch=1
05/28/2022 13:56:52 - INFO - __main__ - Step 230 Global step 230 Train loss 1.84 on epoch=2
05/28/2022 13:56:54 - INFO - __main__ - Step 240 Global step 240 Train loss 1.80 on epoch=2
05/28/2022 13:56:57 - INFO - __main__ - Step 250 Global step 250 Train loss 1.53 on epoch=2
05/28/2022 13:57:42 - INFO - __main__ - Global step 250 Train loss 1.75 Classification-F1 0.05302899948509121 on epoch=2
05/28/2022 13:57:42 - INFO - __main__ - Saving model with best Classification-F1: 0.03535295041916535 -> 0.05302899948509121 on epoch=2, global_step=250
05/28/2022 13:57:45 - INFO - __main__ - Step 260 Global step 260 Train loss 1.68 on epoch=2
05/28/2022 13:57:47 - INFO - __main__ - Step 270 Global step 270 Train loss 1.56 on epoch=2
05/28/2022 13:57:50 - INFO - __main__ - Step 280 Global step 280 Train loss 1.28 on epoch=2
05/28/2022 13:57:52 - INFO - __main__ - Step 290 Global step 290 Train loss 1.41 on epoch=2
05/28/2022 13:57:55 - INFO - __main__ - Step 300 Global step 300 Train loss 1.23 on epoch=2
05/28/2022 13:58:39 - INFO - __main__ - Global step 300 Train loss 1.43 Classification-F1 0.07618099689616803 on epoch=2
05/28/2022 13:58:39 - INFO - __main__ - Saving model with best Classification-F1: 0.05302899948509121 -> 0.07618099689616803 on epoch=2, global_step=300
05/28/2022 13:58:42 - INFO - __main__ - Step 310 Global step 310 Train loss 1.18 on epoch=2
05/28/2022 13:58:44 - INFO - __main__ - Step 320 Global step 320 Train loss 1.32 on epoch=2
05/28/2022 13:58:47 - INFO - __main__ - Step 330 Global step 330 Train loss 1.20 on epoch=2
05/28/2022 13:58:49 - INFO - __main__ - Step 340 Global step 340 Train loss 1.04 on epoch=3
05/28/2022 13:58:52 - INFO - __main__ - Step 350 Global step 350 Train loss 1.27 on epoch=3
05/28/2022 13:59:37 - INFO - __main__ - Global step 350 Train loss 1.20 Classification-F1 0.1099551238894375 on epoch=3
05/28/2022 13:59:37 - INFO - __main__ - Saving model with best Classification-F1: 0.07618099689616803 -> 0.1099551238894375 on epoch=3, global_step=350
05/28/2022 13:59:39 - INFO - __main__ - Step 360 Global step 360 Train loss 1.00 on epoch=3
05/28/2022 13:59:42 - INFO - __main__ - Step 370 Global step 370 Train loss 0.98 on epoch=3
05/28/2022 13:59:44 - INFO - __main__ - Step 380 Global step 380 Train loss 1.06 on epoch=3
05/28/2022 13:59:47 - INFO - __main__ - Step 390 Global step 390 Train loss 0.89 on epoch=3
05/28/2022 13:59:49 - INFO - __main__ - Step 400 Global step 400 Train loss 0.82 on epoch=3
05/28/2022 14:00:35 - INFO - __main__ - Global step 400 Train loss 0.95 Classification-F1 0.13438894843625643 on epoch=3
05/28/2022 14:00:35 - INFO - __main__ - Saving model with best Classification-F1: 0.1099551238894375 -> 0.13438894843625643 on epoch=3, global_step=400
05/28/2022 14:00:38 - INFO - __main__ - Step 410 Global step 410 Train loss 0.78 on epoch=3
05/28/2022 14:00:40 - INFO - __main__ - Step 420 Global step 420 Train loss 0.67 on epoch=3
05/28/2022 14:00:43 - INFO - __main__ - Step 430 Global step 430 Train loss 0.82 on epoch=3
05/28/2022 14:00:46 - INFO - __main__ - Step 440 Global step 440 Train loss 0.90 on epoch=3
05/28/2022 14:00:48 - INFO - __main__ - Step 450 Global step 450 Train loss 0.60 on epoch=4
05/28/2022 14:01:37 - INFO - __main__ - Global step 450 Train loss 0.75 Classification-F1 0.18107581545582543 on epoch=4
05/28/2022 14:01:38 - INFO - __main__ - Saving model with best Classification-F1: 0.13438894843625643 -> 0.18107581545582543 on epoch=4, global_step=450
05/28/2022 14:01:40 - INFO - __main__ - Step 460 Global step 460 Train loss 0.76 on epoch=4
05/28/2022 14:01:43 - INFO - __main__ - Step 470 Global step 470 Train loss 0.63 on epoch=4
05/28/2022 14:01:45 - INFO - __main__ - Step 480 Global step 480 Train loss 0.55 on epoch=4
05/28/2022 14:01:48 - INFO - __main__ - Step 490 Global step 490 Train loss 0.65 on epoch=4
05/28/2022 14:01:50 - INFO - __main__ - Step 500 Global step 500 Train loss 0.60 on epoch=4
05/28/2022 14:02:41 - INFO - __main__ - Global step 500 Train loss 0.64 Classification-F1 0.20787684756402602 on epoch=4
05/28/2022 14:02:41 - INFO - __main__ - Saving model with best Classification-F1: 0.18107581545582543 -> 0.20787684756402602 on epoch=4, global_step=500
05/28/2022 14:02:44 - INFO - __main__ - Step 510 Global step 510 Train loss 0.50 on epoch=4
05/28/2022 14:02:46 - INFO - __main__ - Step 520 Global step 520 Train loss 0.56 on epoch=4
05/28/2022 14:02:49 - INFO - __main__ - Step 530 Global step 530 Train loss 0.52 on epoch=4
05/28/2022 14:02:51 - INFO - __main__ - Step 540 Global step 540 Train loss 0.52 on epoch=4
05/28/2022 14:02:54 - INFO - __main__ - Step 550 Global step 550 Train loss 0.56 on epoch=4
05/28/2022 14:03:44 - INFO - __main__ - Global step 550 Train loss 0.53 Classification-F1 0.24232464940394535 on epoch=4
05/28/2022 14:03:44 - INFO - __main__ - Saving model with best Classification-F1: 0.20787684756402602 -> 0.24232464940394535 on epoch=4, global_step=550
05/28/2022 14:03:47 - INFO - __main__ - Step 560 Global step 560 Train loss 0.42 on epoch=4
05/28/2022 14:03:50 - INFO - __main__ - Step 570 Global step 570 Train loss 0.47 on epoch=5
05/28/2022 14:03:52 - INFO - __main__ - Step 580 Global step 580 Train loss 0.53 on epoch=5
05/28/2022 14:03:55 - INFO - __main__ - Step 590 Global step 590 Train loss 0.44 on epoch=5
05/28/2022 14:03:57 - INFO - __main__ - Step 600 Global step 600 Train loss 0.43 on epoch=5
05/28/2022 14:04:48 - INFO - __main__ - Global step 600 Train loss 0.46 Classification-F1 0.2730447226854914 on epoch=5
05/28/2022 14:04:48 - INFO - __main__ - Saving model with best Classification-F1: 0.24232464940394535 -> 0.2730447226854914 on epoch=5, global_step=600
05/28/2022 14:04:50 - INFO - __main__ - Step 610 Global step 610 Train loss 0.39 on epoch=5
05/28/2022 14:04:53 - INFO - __main__ - Step 620 Global step 620 Train loss 0.39 on epoch=5
05/28/2022 14:04:56 - INFO - __main__ - Step 630 Global step 630 Train loss 0.38 on epoch=5
05/28/2022 14:04:58 - INFO - __main__ - Step 640 Global step 640 Train loss 0.32 on epoch=5
05/28/2022 14:05:01 - INFO - __main__ - Step 650 Global step 650 Train loss 0.42 on epoch=5
05/28/2022 14:05:51 - INFO - __main__ - Global step 650 Train loss 0.38 Classification-F1 0.27753846675528304 on epoch=5
05/28/2022 14:05:51 - INFO - __main__ - Saving model with best Classification-F1: 0.2730447226854914 -> 0.27753846675528304 on epoch=5, global_step=650
05/28/2022 14:05:54 - INFO - __main__ - Step 660 Global step 660 Train loss 0.50 on epoch=5
05/28/2022 14:05:56 - INFO - __main__ - Step 670 Global step 670 Train loss 0.27 on epoch=5
05/28/2022 14:05:59 - INFO - __main__ - Step 680 Global step 680 Train loss 0.43 on epoch=6
05/28/2022 14:06:01 - INFO - __main__ - Step 690 Global step 690 Train loss 0.32 on epoch=6
05/28/2022 14:06:04 - INFO - __main__ - Step 700 Global step 700 Train loss 0.29 on epoch=6
05/28/2022 14:06:55 - INFO - __main__ - Global step 700 Train loss 0.36 Classification-F1 0.30801919387062027 on epoch=6
05/28/2022 14:06:55 - INFO - __main__ - Saving model with best Classification-F1: 0.27753846675528304 -> 0.30801919387062027 on epoch=6, global_step=700
05/28/2022 14:06:58 - INFO - __main__ - Step 710 Global step 710 Train loss 0.35 on epoch=6
05/28/2022 14:07:00 - INFO - __main__ - Step 720 Global step 720 Train loss 0.39 on epoch=6
05/28/2022 14:07:03 - INFO - __main__ - Step 730 Global step 730 Train loss 0.35 on epoch=6
05/28/2022 14:07:06 - INFO - __main__ - Step 740 Global step 740 Train loss 0.35 on epoch=6
05/28/2022 14:07:08 - INFO - __main__ - Step 750 Global step 750 Train loss 0.27 on epoch=6
05/28/2022 14:08:00 - INFO - __main__ - Global step 750 Train loss 0.34 Classification-F1 0.3234371036310803 on epoch=6
05/28/2022 14:08:00 - INFO - __main__ - Saving model with best Classification-F1: 0.30801919387062027 -> 0.3234371036310803 on epoch=6, global_step=750
05/28/2022 14:08:02 - INFO - __main__ - Step 760 Global step 760 Train loss 0.38 on epoch=6
05/28/2022 14:08:05 - INFO - __main__ - Step 770 Global step 770 Train loss 0.42 on epoch=6
05/28/2022 14:08:07 - INFO - __main__ - Step 780 Global step 780 Train loss 0.32 on epoch=6
05/28/2022 14:08:10 - INFO - __main__ - Step 790 Global step 790 Train loss 0.34 on epoch=7
05/28/2022 14:08:12 - INFO - __main__ - Step 800 Global step 800 Train loss 0.43 on epoch=7
05/28/2022 14:09:04 - INFO - __main__ - Global step 800 Train loss 0.38 Classification-F1 0.3292713947352259 on epoch=7
05/28/2022 14:09:04 - INFO - __main__ - Saving model with best Classification-F1: 0.3234371036310803 -> 0.3292713947352259 on epoch=7, global_step=800
05/28/2022 14:09:07 - INFO - __main__ - Step 810 Global step 810 Train loss 0.26 on epoch=7
05/28/2022 14:09:09 - INFO - __main__ - Step 820 Global step 820 Train loss 0.25 on epoch=7
05/28/2022 14:09:12 - INFO - __main__ - Step 830 Global step 830 Train loss 0.25 on epoch=7
05/28/2022 14:09:15 - INFO - __main__ - Step 840 Global step 840 Train loss 0.25 on epoch=7
05/28/2022 14:09:17 - INFO - __main__ - Step 850 Global step 850 Train loss 0.19 on epoch=7
05/28/2022 14:10:09 - INFO - __main__ - Global step 850 Train loss 0.24 Classification-F1 0.3238891216862281 on epoch=7
05/28/2022 14:10:11 - INFO - __main__ - Step 860 Global step 860 Train loss 0.25 on epoch=7
05/28/2022 14:10:14 - INFO - __main__ - Step 870 Global step 870 Train loss 0.25 on epoch=7
05/28/2022 14:10:16 - INFO - __main__ - Step 880 Global step 880 Train loss 0.35 on epoch=7
05/28/2022 14:10:19 - INFO - __main__ - Step 890 Global step 890 Train loss 0.32 on epoch=7
05/28/2022 14:10:21 - INFO - __main__ - Step 900 Global step 900 Train loss 0.27 on epoch=8
05/28/2022 14:11:14 - INFO - __main__ - Global step 900 Train loss 0.29 Classification-F1 0.3711240975277649 on epoch=8
05/28/2022 14:11:14 - INFO - __main__ - Saving model with best Classification-F1: 0.3292713947352259 -> 0.3711240975277649 on epoch=8, global_step=900
05/28/2022 14:11:17 - INFO - __main__ - Step 910 Global step 910 Train loss 0.29 on epoch=8
05/28/2022 14:11:20 - INFO - __main__ - Step 920 Global step 920 Train loss 0.19 on epoch=8
05/28/2022 14:11:22 - INFO - __main__ - Step 930 Global step 930 Train loss 0.20 on epoch=8
05/28/2022 14:11:25 - INFO - __main__ - Step 940 Global step 940 Train loss 0.29 on epoch=8
05/28/2022 14:11:27 - INFO - __main__ - Step 950 Global step 950 Train loss 0.22 on epoch=8
05/28/2022 14:12:19 - INFO - __main__ - Global step 950 Train loss 0.24 Classification-F1 0.41323491914274485 on epoch=8
05/28/2022 14:12:19 - INFO - __main__ - Saving model with best Classification-F1: 0.3711240975277649 -> 0.41323491914274485 on epoch=8, global_step=950
05/28/2022 14:12:22 - INFO - __main__ - Step 960 Global step 960 Train loss 0.18 on epoch=8
05/28/2022 14:12:24 - INFO - __main__ - Step 970 Global step 970 Train loss 0.21 on epoch=8
05/28/2022 14:12:27 - INFO - __main__ - Step 980 Global step 980 Train loss 0.22 on epoch=8
05/28/2022 14:12:29 - INFO - __main__ - Step 990 Global step 990 Train loss 0.30 on epoch=8
05/28/2022 14:12:32 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.28 on epoch=8
05/28/2022 14:13:24 - INFO - __main__ - Global step 1000 Train loss 0.24 Classification-F1 0.3684816801011644 on epoch=8
05/28/2022 14:13:27 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.24 on epoch=9
05/28/2022 14:13:29 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.29 on epoch=9
05/28/2022 14:13:32 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.20 on epoch=9
05/28/2022 14:13:34 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.18 on epoch=9
05/28/2022 14:13:37 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.25 on epoch=9
05/28/2022 14:14:27 - INFO - __main__ - Global step 1050 Train loss 0.23 Classification-F1 0.5304885529575444 on epoch=9
05/28/2022 14:14:27 - INFO - __main__ - Saving model with best Classification-F1: 0.41323491914274485 -> 0.5304885529575444 on epoch=9, global_step=1050
05/28/2022 14:14:29 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.24 on epoch=9
05/28/2022 14:14:32 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.15 on epoch=9
05/28/2022 14:14:34 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.19 on epoch=9
05/28/2022 14:14:37 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.20 on epoch=9
05/28/2022 14:14:40 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.16 on epoch=9
05/28/2022 14:15:30 - INFO - __main__ - Global step 1100 Train loss 0.19 Classification-F1 0.3927483919440469 on epoch=9
05/28/2022 14:15:33 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.31 on epoch=9
05/28/2022 14:15:35 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.17 on epoch=9
05/28/2022 14:15:38 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.13 on epoch=10
05/28/2022 14:15:40 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.27 on epoch=10
05/28/2022 14:15:43 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.11 on epoch=10
05/28/2022 14:16:33 - INFO - __main__ - Global step 1150 Train loss 0.20 Classification-F1 0.3956078550287831 on epoch=10
05/28/2022 14:16:35 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.13 on epoch=10
05/28/2022 14:16:38 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.15 on epoch=10
05/28/2022 14:16:41 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.13 on epoch=10
05/28/2022 14:16:43 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.21 on epoch=10
05/28/2022 14:16:46 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.16 on epoch=10
05/28/2022 14:17:36 - INFO - __main__ - Global step 1200 Train loss 0.15 Classification-F1 0.45072765936534104 on epoch=10
05/28/2022 14:17:39 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.18 on epoch=10
05/28/2022 14:17:41 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.27 on epoch=10
05/28/2022 14:17:44 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.13 on epoch=10
05/28/2022 14:17:46 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.20 on epoch=11
05/28/2022 14:17:49 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.31 on epoch=11
05/28/2022 14:18:38 - INFO - __main__ - Global step 1250 Train loss 0.22 Classification-F1 0.4638435789992642 on epoch=11
05/28/2022 14:18:41 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.11 on epoch=11
05/28/2022 14:18:44 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.18 on epoch=11
05/28/2022 14:18:46 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.23 on epoch=11
05/28/2022 14:18:49 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.15 on epoch=11
05/28/2022 14:18:51 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.17 on epoch=11
05/28/2022 14:19:41 - INFO - __main__ - Global step 1300 Train loss 0.17 Classification-F1 0.43396706743998975 on epoch=11
05/28/2022 14:19:44 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.12 on epoch=11
05/28/2022 14:19:46 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.19 on epoch=11
05/28/2022 14:19:49 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.18 on epoch=11
05/28/2022 14:19:52 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.14 on epoch=11
05/28/2022 14:19:54 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.16 on epoch=12
05/28/2022 14:20:44 - INFO - __main__ - Global step 1350 Train loss 0.16 Classification-F1 0.4502610535352154 on epoch=12
05/28/2022 14:20:46 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.23 on epoch=12
05/28/2022 14:20:49 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.16 on epoch=12
05/28/2022 14:20:51 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.16 on epoch=12
05/28/2022 14:20:54 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.19 on epoch=12
05/28/2022 14:20:56 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.13 on epoch=12
05/28/2022 14:21:47 - INFO - __main__ - Global step 1400 Train loss 0.17 Classification-F1 0.4724037369311391 on epoch=12
05/28/2022 14:21:49 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.11 on epoch=12
05/28/2022 14:21:52 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.13 on epoch=12
05/28/2022 14:21:54 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.12 on epoch=12
05/28/2022 14:21:57 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.16 on epoch=12
05/28/2022 14:22:00 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.23 on epoch=12
05/28/2022 14:22:51 - INFO - __main__ - Global step 1450 Train loss 0.15 Classification-F1 0.4550775400918674 on epoch=12
05/28/2022 14:22:53 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.15 on epoch=13
05/28/2022 14:22:56 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.26 on epoch=13
05/28/2022 14:22:59 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.10 on epoch=13
05/28/2022 14:23:01 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.12 on epoch=13
05/28/2022 14:23:04 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.15 on epoch=13
05/28/2022 14:23:55 - INFO - __main__ - Global step 1500 Train loss 0.15 Classification-F1 0.4743642579524454 on epoch=13
05/28/2022 14:23:58 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.13 on epoch=13
05/28/2022 14:24:00 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.18 on epoch=13
05/28/2022 14:24:03 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.13 on epoch=13
05/28/2022 14:24:05 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.11 on epoch=13
05/28/2022 14:24:08 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.18 on epoch=13
05/28/2022 14:24:58 - INFO - __main__ - Global step 1550 Train loss 0.15 Classification-F1 0.47268989860455934 on epoch=13
05/28/2022 14:25:01 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.12 on epoch=13
05/28/2022 14:25:03 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.18 on epoch=14
05/28/2022 14:25:06 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.18 on epoch=14
05/28/2022 14:25:08 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.11 on epoch=14
05/28/2022 14:25:11 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.11 on epoch=14
05/28/2022 14:26:01 - INFO - __main__ - Global step 1600 Train loss 0.14 Classification-F1 0.47716245273439734 on epoch=14
05/28/2022 14:26:03 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.15 on epoch=14
05/28/2022 14:26:06 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.09 on epoch=14
05/28/2022 14:26:08 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.16 on epoch=14
05/28/2022 14:26:11 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.14 on epoch=14
05/28/2022 14:26:14 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.11 on epoch=14
05/28/2022 14:27:04 - INFO - __main__ - Global step 1650 Train loss 0.13 Classification-F1 0.4740128264789798 on epoch=14
05/28/2022 14:27:07 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.18 on epoch=14
05/28/2022 14:27:09 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.19 on epoch=14
05/28/2022 14:27:12 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.11 on epoch=14
05/28/2022 14:27:14 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.10 on epoch=15
05/28/2022 14:27:17 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.20 on epoch=15
05/28/2022 14:28:07 - INFO - __main__ - Global step 1700 Train loss 0.16 Classification-F1 0.5180482174506393 on epoch=15
05/28/2022 14:28:09 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.08 on epoch=15
05/28/2022 14:28:12 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.08 on epoch=15
05/28/2022 14:28:15 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.10 on epoch=15
05/28/2022 14:28:17 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.15 on epoch=15
05/28/2022 14:28:20 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.08 on epoch=15
05/28/2022 14:29:09 - INFO - __main__ - Global step 1750 Train loss 0.10 Classification-F1 0.5195780525689693 on epoch=15
05/28/2022 14:29:12 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.11 on epoch=15
05/28/2022 14:29:14 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.12 on epoch=15
05/28/2022 14:29:17 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.11 on epoch=15
05/28/2022 14:29:19 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.11 on epoch=15
05/28/2022 14:29:22 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.12 on epoch=16
05/28/2022 14:30:12 - INFO - __main__ - Global step 1800 Train loss 0.11 Classification-F1 0.5734978013439683 on epoch=16
05/28/2022 14:30:12 - INFO - __main__ - Saving model with best Classification-F1: 0.5304885529575444 -> 0.5734978013439683 on epoch=16, global_step=1800
05/28/2022 14:30:15 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.13 on epoch=16
05/28/2022 14:30:17 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.08 on epoch=16
05/28/2022 14:30:20 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.06 on epoch=16
05/28/2022 14:30:22 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.11 on epoch=16
05/28/2022 14:30:25 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.09 on epoch=16
05/28/2022 14:31:15 - INFO - __main__ - Global step 1850 Train loss 0.09 Classification-F1 0.5473905477647181 on epoch=16
05/28/2022 14:31:18 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.09 on epoch=16
05/28/2022 14:31:21 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.12 on epoch=16
05/28/2022 14:31:23 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.20 on epoch=16
05/28/2022 14:31:26 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.12 on epoch=16
05/28/2022 14:31:28 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.14 on epoch=16
05/28/2022 14:32:19 - INFO - __main__ - Global step 1900 Train loss 0.13 Classification-F1 0.5495235506598226 on epoch=16
05/28/2022 14:32:21 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.12 on epoch=17
05/28/2022 14:32:24 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.13 on epoch=17
05/28/2022 14:32:27 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.10 on epoch=17
05/28/2022 14:32:29 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.07 on epoch=17
05/28/2022 14:32:32 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.11 on epoch=17
05/28/2022 14:33:23 - INFO - __main__ - Global step 1950 Train loss 0.11 Classification-F1 0.5531373573812188 on epoch=17
05/28/2022 14:33:26 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.06 on epoch=17
05/28/2022 14:33:29 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.07 on epoch=17
05/28/2022 14:33:31 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.12 on epoch=17
05/28/2022 14:33:34 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.05 on epoch=17
05/28/2022 14:33:36 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.16 on epoch=17
05/28/2022 14:34:26 - INFO - __main__ - Global step 2000 Train loss 0.09 Classification-F1 0.5475184164421436 on epoch=17
05/28/2022 14:34:28 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.08 on epoch=17
05/28/2022 14:34:31 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.09 on epoch=18
05/28/2022 14:34:34 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.14 on epoch=18
05/28/2022 14:34:36 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.08 on epoch=18
05/28/2022 14:34:39 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.08 on epoch=18
05/28/2022 14:35:29 - INFO - __main__ - Global step 2050 Train loss 0.10 Classification-F1 0.5781032548029342 on epoch=18
05/28/2022 14:35:29 - INFO - __main__ - Saving model with best Classification-F1: 0.5734978013439683 -> 0.5781032548029342 on epoch=18, global_step=2050
05/28/2022 14:35:32 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.11 on epoch=18
05/28/2022 14:35:34 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.07 on epoch=18
05/28/2022 14:35:37 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.05 on epoch=18
05/28/2022 14:35:40 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.05 on epoch=18
05/28/2022 14:35:42 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.06 on epoch=18
05/28/2022 14:36:32 - INFO - __main__ - Global step 2100 Train loss 0.07 Classification-F1 0.5451693236654992 on epoch=18
05/28/2022 14:36:34 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.12 on epoch=18
05/28/2022 14:36:37 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.07 on epoch=18
05/28/2022 14:36:39 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.06 on epoch=19
05/28/2022 14:36:42 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.13 on epoch=19
05/28/2022 14:36:45 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.12 on epoch=19
05/28/2022 14:37:34 - INFO - __main__ - Global step 2150 Train loss 0.10 Classification-F1 0.5657615422648707 on epoch=19
05/28/2022 14:37:37 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.07 on epoch=19
05/28/2022 14:37:39 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.11 on epoch=19
05/28/2022 14:37:42 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.05 on epoch=19
05/28/2022 14:37:44 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.08 on epoch=19
05/28/2022 14:37:47 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.09 on epoch=19
05/28/2022 14:38:37 - INFO - __main__ - Global step 2200 Train loss 0.08 Classification-F1 0.5694918157793669 on epoch=19
05/28/2022 14:38:40 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.07 on epoch=19
05/28/2022 14:38:42 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.06 on epoch=19
05/28/2022 14:38:45 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.07 on epoch=19
05/28/2022 14:38:48 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.04 on epoch=19
05/28/2022 14:38:50 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.15 on epoch=20
05/28/2022 14:39:39 - INFO - __main__ - Global step 2250 Train loss 0.08 Classification-F1 0.5406644143652993 on epoch=20
05/28/2022 14:39:41 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.12 on epoch=20
05/28/2022 14:39:44 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.04 on epoch=20
05/28/2022 14:39:47 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.07 on epoch=20
05/28/2022 14:39:49 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.09 on epoch=20
05/28/2022 14:39:52 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.05 on epoch=20
05/28/2022 14:40:40 - INFO - __main__ - Global step 2300 Train loss 0.07 Classification-F1 0.5830326644882368 on epoch=20
05/28/2022 14:40:40 - INFO - __main__ - Saving model with best Classification-F1: 0.5781032548029342 -> 0.5830326644882368 on epoch=20, global_step=2300
05/28/2022 14:40:43 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.10 on epoch=20
05/28/2022 14:40:45 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.09 on epoch=20
05/28/2022 14:40:48 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.11 on epoch=20
05/28/2022 14:40:50 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.07 on epoch=20
05/28/2022 14:40:53 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.06 on epoch=20
05/28/2022 14:41:43 - INFO - __main__ - Global step 2350 Train loss 0.09 Classification-F1 0.5528837360882257 on epoch=20
05/28/2022 14:41:45 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.05 on epoch=21
05/28/2022 14:41:48 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.19 on epoch=21
05/28/2022 14:41:51 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.06 on epoch=21
05/28/2022 14:41:53 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.06 on epoch=21
05/28/2022 14:41:56 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.10 on epoch=21
05/28/2022 14:42:45 - INFO - __main__ - Global step 2400 Train loss 0.09 Classification-F1 0.5452672017238782 on epoch=21
05/28/2022 14:42:47 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.05 on epoch=21
05/28/2022 14:42:50 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.07 on epoch=21
05/28/2022 14:42:53 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.04 on epoch=21
05/28/2022 14:42:55 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.09 on epoch=21
05/28/2022 14:42:58 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.04 on epoch=21
05/28/2022 14:43:47 - INFO - __main__ - Global step 2450 Train loss 0.06 Classification-F1 0.530876979085239 on epoch=21
05/28/2022 14:43:50 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.08 on epoch=21
05/28/2022 14:43:52 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.06 on epoch=22
05/28/2022 14:43:55 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.14 on epoch=22
05/28/2022 14:43:58 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.08 on epoch=22
05/28/2022 14:44:00 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.05 on epoch=22
05/28/2022 14:44:49 - INFO - __main__ - Global step 2500 Train loss 0.08 Classification-F1 0.550942677210682 on epoch=22
05/28/2022 14:44:52 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.09 on epoch=22
05/28/2022 14:44:55 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.10 on epoch=22
05/28/2022 14:44:57 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.07 on epoch=22
05/28/2022 14:45:00 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.08 on epoch=22
05/28/2022 14:45:02 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=22
05/28/2022 14:45:51 - INFO - __main__ - Global step 2550 Train loss 0.07 Classification-F1 0.5690325587546365 on epoch=22
05/28/2022 14:45:54 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.14 on epoch=22
05/28/2022 14:45:56 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.05 on epoch=22
05/28/2022 14:45:59 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.11 on epoch=23
05/28/2022 14:46:01 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.21 on epoch=23
05/28/2022 14:46:04 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.06 on epoch=23
05/28/2022 14:46:54 - INFO - __main__ - Global step 2600 Train loss 0.11 Classification-F1 0.5761311099636779 on epoch=23
05/28/2022 14:46:56 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.04 on epoch=23
05/28/2022 14:46:59 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.06 on epoch=23
05/28/2022 14:47:01 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.04 on epoch=23
05/28/2022 14:47:04 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.08 on epoch=23
05/28/2022 14:47:07 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.03 on epoch=23
05/28/2022 14:47:56 - INFO - __main__ - Global step 2650 Train loss 0.05 Classification-F1 0.6093275504387415 on epoch=23
05/28/2022 14:47:56 - INFO - __main__ - Saving model with best Classification-F1: 0.5830326644882368 -> 0.6093275504387415 on epoch=23, global_step=2650
05/28/2022 14:47:59 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.08 on epoch=23
05/28/2022 14:48:01 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.12 on epoch=23
05/28/2022 14:48:04 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.06 on epoch=23
05/28/2022 14:48:07 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.06 on epoch=24
05/28/2022 14:48:09 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.14 on epoch=24
05/28/2022 14:48:59 - INFO - __main__ - Global step 2700 Train loss 0.09 Classification-F1 0.6048511654772837 on epoch=24
05/28/2022 14:49:01 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.07 on epoch=24
05/28/2022 14:49:04 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.04 on epoch=24
05/28/2022 14:49:06 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.09 on epoch=24
05/28/2022 14:49:09 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.07 on epoch=24
05/28/2022 14:49:12 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.05 on epoch=24
05/28/2022 14:50:01 - INFO - __main__ - Global step 2750 Train loss 0.07 Classification-F1 0.5246684200316656 on epoch=24
05/28/2022 14:50:04 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.07 on epoch=24
05/28/2022 14:50:06 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.04 on epoch=24
05/28/2022 14:50:09 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.12 on epoch=24
05/28/2022 14:50:11 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.05 on epoch=24
05/28/2022 14:50:14 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.04 on epoch=24
05/28/2022 14:51:03 - INFO - __main__ - Global step 2800 Train loss 0.06 Classification-F1 0.5750895410157987 on epoch=24
05/28/2022 14:51:06 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.07 on epoch=25
05/28/2022 14:51:09 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.13 on epoch=25
05/28/2022 14:51:11 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=25
05/28/2022 14:51:14 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.08 on epoch=25
05/28/2022 14:51:16 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.06 on epoch=25
05/28/2022 14:52:06 - INFO - __main__ - Global step 2850 Train loss 0.07 Classification-F1 0.6015427261994593 on epoch=25
05/28/2022 14:52:09 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.05 on epoch=25
05/28/2022 14:52:11 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.04 on epoch=25
05/28/2022 14:52:14 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=25
05/28/2022 14:52:16 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.07 on epoch=25
05/28/2022 14:52:19 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.10 on epoch=25
05/28/2022 14:53:08 - INFO - __main__ - Global step 2900 Train loss 0.06 Classification-F1 0.6011365419467934 on epoch=25
05/28/2022 14:53:11 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.12 on epoch=25
05/28/2022 14:53:13 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.11 on epoch=26
05/28/2022 14:53:16 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.09 on epoch=26
05/28/2022 14:53:19 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.05 on epoch=26
05/28/2022 14:53:21 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.05 on epoch=26
05/28/2022 14:54:10 - INFO - __main__ - Global step 2950 Train loss 0.08 Classification-F1 0.5711128569589564 on epoch=26
05/28/2022 14:54:13 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.09 on epoch=26
05/28/2022 14:54:16 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.05 on epoch=26
05/28/2022 14:54:18 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.08 on epoch=26
05/28/2022 14:54:21 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.05 on epoch=26
05/28/2022 14:54:23 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.11 on epoch=26
05/28/2022 14:54:25 - INFO - __main__ - Start tokenizing ... 1792 instances
05/28/2022 14:54:25 - INFO - __main__ - Printing 3 examples
05/28/2022 14:54:25 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
05/28/2022 14:54:25 - INFO - __main__ - ['Film']
05/28/2022 14:54:25 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/28/2022 14:54:25 - INFO - __main__ - ['Film']
05/28/2022 14:54:25 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/28/2022 14:54:25 - INFO - __main__ - ['Film']
05/28/2022 14:54:25 - INFO - __main__ - Tokenizing Input ...
05/28/2022 14:54:26 - INFO - __main__ - Tokenizing Output ...
05/28/2022 14:54:28 - INFO - __main__ - Loaded 1792 examples from train data
05/28/2022 14:54:28 - INFO - __main__ - Start tokenizing ... 1792 instances
05/28/2022 14:54:28 - INFO - __main__ - Printing 3 examples
05/28/2022 14:54:28 - INFO - __main__ -  [dbpedia_14] The Debt is a 2011 American/British drama-thriller film directed by John Madden from a screenplay by Matthew Vaughn Jane Goldman and Peter Straughan. It stars Helen Mirren Sam Worthington Jessica Chastain Ciarán Hinds Tom Wilkinson Marton Csokas and Jesper Christensen. It's a remake of the 2007 Israeli film Ha-Hov directed by Assaf BernsteinOriginally scheduled for a December 2010 release the film was released in the United States on August 31 2011.
05/28/2022 14:54:28 - INFO - __main__ - ['Film']
05/28/2022 14:54:28 - INFO - __main__ -  [dbpedia_14] Naga Bonar Jadi 2 (Naga Bonar Becomes 2) is 2007 comedy film directed by Deddy Mizwar. It is starring Deddy Mizwar Tora Sudiro Lukman Sardi Darius Sinathrya and Michael Muliardo. It is a sequel to the Indonesian film Nagabonar (1987).
05/28/2022 14:54:28 - INFO - __main__ - ['Film']
05/28/2022 14:54:28 - INFO - __main__ -  [dbpedia_14] La Garce is a 1984 French thriller film directed by Christine Pascal and starring Isabelle Huppert.
05/28/2022 14:54:28 - INFO - __main__ - ['Film']
05/28/2022 14:54:28 - INFO - __main__ - Tokenizing Input ...
05/28/2022 14:54:29 - INFO - __main__ - Tokenizing Output ...
05/28/2022 14:54:30 - INFO - __main__ - Loaded 1792 examples from dev data
05/28/2022 14:54:46 - INFO - __main__ - load prompt embedding from ckpt
05/28/2022 14:54:46 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/28/2022 14:54:46 - INFO - __main__ - Starting training!
05/28/2022 14:55:13 - INFO - __main__ - Global step 3000 Train loss 0.08 Classification-F1 0.5037326644288105 on epoch=26
05/28/2022 14:55:13 - INFO - __main__ - save last model!
05/28/2022 14:55:13 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/28/2022 14:55:13 - INFO - __main__ - Start tokenizing ... 3500 instances
05/28/2022 14:55:13 - INFO - __main__ - Printing 3 examples
05/28/2022 14:55:13 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/28/2022 14:55:13 - INFO - __main__ - ['Animal']
05/28/2022 14:55:13 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/28/2022 14:55:13 - INFO - __main__ - ['Animal']
05/28/2022 14:55:13 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/28/2022 14:55:13 - INFO - __main__ - ['Village']
05/28/2022 14:55:13 - INFO - __main__ - Tokenizing Input ...
05/28/2022 14:55:15 - INFO - __main__ - Tokenizing Output ...
05/28/2022 14:55:18 - INFO - __main__ - Loaded 3500 examples from test data
05/28/2022 14:57:16 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down128shot/singletask-dbpedia_14/dbpedia_14_128_42_0.2_8_predictions.txt
05/28/2022 14:57:16 - INFO - __main__ - Classification-F1 on test data: 0.4683
05/28/2022 14:57:16 - INFO - __main__ - prefix=dbpedia_14_128_42, lr=0.2, bsz=8, dev_performance=0.6093275504387415, test_performance=0.46831047230911055
05/28/2022 14:57:16 - INFO - __main__ - Running ... prefix=dbpedia_14_128_87, lr=0.5, bsz=8 ...
05/28/2022 14:57:17 - INFO - __main__ - Start tokenizing ... 1792 instances
05/28/2022 14:57:17 - INFO - __main__ - Printing 3 examples
05/28/2022 14:57:17 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
05/28/2022 14:57:17 - INFO - __main__ - ['Film']
05/28/2022 14:57:17 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/28/2022 14:57:17 - INFO - __main__ - ['Film']
05/28/2022 14:57:17 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/28/2022 14:57:17 - INFO - __main__ - ['Film']
05/28/2022 14:57:17 - INFO - __main__ - Tokenizing Input ...
05/28/2022 14:57:18 - INFO - __main__ - Tokenizing Output ...
05/28/2022 14:57:20 - INFO - __main__ - Loaded 1792 examples from train data
05/28/2022 14:57:20 - INFO - __main__ - Start tokenizing ... 1792 instances
05/28/2022 14:57:20 - INFO - __main__ - Printing 3 examples
05/28/2022 14:57:20 - INFO - __main__ -  [dbpedia_14] The Debt is a 2011 American/British drama-thriller film directed by John Madden from a screenplay by Matthew Vaughn Jane Goldman and Peter Straughan. It stars Helen Mirren Sam Worthington Jessica Chastain Ciarán Hinds Tom Wilkinson Marton Csokas and Jesper Christensen. It's a remake of the 2007 Israeli film Ha-Hov directed by Assaf BernsteinOriginally scheduled for a December 2010 release the film was released in the United States on August 31 2011.
05/28/2022 14:57:20 - INFO - __main__ - ['Film']
05/28/2022 14:57:20 - INFO - __main__ -  [dbpedia_14] Naga Bonar Jadi 2 (Naga Bonar Becomes 2) is 2007 comedy film directed by Deddy Mizwar. It is starring Deddy Mizwar Tora Sudiro Lukman Sardi Darius Sinathrya and Michael Muliardo. It is a sequel to the Indonesian film Nagabonar (1987).
05/28/2022 14:57:20 - INFO - __main__ - ['Film']
05/28/2022 14:57:20 - INFO - __main__ -  [dbpedia_14] La Garce is a 1984 French thriller film directed by Christine Pascal and starring Isabelle Huppert.
05/28/2022 14:57:20 - INFO - __main__ - ['Film']
05/28/2022 14:57:20 - INFO - __main__ - Tokenizing Input ...
05/28/2022 14:57:21 - INFO - __main__ - Tokenizing Output ...
05/28/2022 14:57:23 - INFO - __main__ - Loaded 1792 examples from dev data
05/28/2022 14:57:41 - INFO - __main__ - load prompt embedding from ckpt
05/28/2022 14:57:41 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/28/2022 14:57:41 - INFO - __main__ - Starting training!
05/28/2022 14:57:45 - INFO - __main__ - Step 10 Global step 10 Train loss 6.99 on epoch=0
05/28/2022 14:57:48 - INFO - __main__ - Step 20 Global step 20 Train loss 4.74 on epoch=0
05/28/2022 14:57:50 - INFO - __main__ - Step 30 Global step 30 Train loss 3.62 on epoch=0
05/28/2022 14:57:53 - INFO - __main__ - Step 40 Global step 40 Train loss 2.80 on epoch=0
05/28/2022 14:57:56 - INFO - __main__ - Step 50 Global step 50 Train loss 2.88 on epoch=0
05/28/2022 14:58:47 - INFO - __main__ - Global step 50 Train loss 4.21 Classification-F1 0.015332631613035407 on epoch=0
05/28/2022 14:58:48 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.015332631613035407 on epoch=0, global_step=50
05/28/2022 14:58:50 - INFO - __main__ - Step 60 Global step 60 Train loss 2.30 on epoch=0
05/28/2022 14:58:53 - INFO - __main__ - Step 70 Global step 70 Train loss 2.59 on epoch=0
05/28/2022 14:58:56 - INFO - __main__ - Step 80 Global step 80 Train loss 2.14 on epoch=0
05/28/2022 14:58:58 - INFO - __main__ - Step 90 Global step 90 Train loss 2.15 on epoch=0
05/28/2022 14:59:01 - INFO - __main__ - Step 100 Global step 100 Train loss 1.86 on epoch=0
05/28/2022 14:59:47 - INFO - __main__ - Global step 100 Train loss 2.21 Classification-F1 0.04840433045324307 on epoch=0
05/28/2022 14:59:47 - INFO - __main__ - Saving model with best Classification-F1: 0.015332631613035407 -> 0.04840433045324307 on epoch=0, global_step=100
05/28/2022 14:59:49 - INFO - __main__ - Step 110 Global step 110 Train loss 1.79 on epoch=0
05/28/2022 14:59:52 - INFO - __main__ - Step 120 Global step 120 Train loss 1.42 on epoch=1
05/28/2022 14:59:55 - INFO - __main__ - Step 130 Global step 130 Train loss 1.39 on epoch=1
05/28/2022 14:59:57 - INFO - __main__ - Step 140 Global step 140 Train loss 1.14 on epoch=1
05/28/2022 15:00:00 - INFO - __main__ - Step 150 Global step 150 Train loss 0.95 on epoch=1
05/28/2022 15:00:45 - INFO - __main__ - Global step 150 Train loss 1.34 Classification-F1 0.1173764086549694 on epoch=1
05/28/2022 15:00:45 - INFO - __main__ - Saving model with best Classification-F1: 0.04840433045324307 -> 0.1173764086549694 on epoch=1, global_step=150
05/28/2022 15:00:47 - INFO - __main__ - Step 160 Global step 160 Train loss 0.91 on epoch=1
05/28/2022 15:00:50 - INFO - __main__ - Step 170 Global step 170 Train loss 0.99 on epoch=1
05/28/2022 15:00:52 - INFO - __main__ - Step 180 Global step 180 Train loss 0.81 on epoch=1
05/28/2022 15:00:55 - INFO - __main__ - Step 190 Global step 190 Train loss 0.80 on epoch=1
05/28/2022 15:00:58 - INFO - __main__ - Step 200 Global step 200 Train loss 0.77 on epoch=1
05/28/2022 15:01:48 - INFO - __main__ - Global step 200 Train loss 0.85 Classification-F1 0.204410742179403 on epoch=1
05/28/2022 15:01:48 - INFO - __main__ - Saving model with best Classification-F1: 0.1173764086549694 -> 0.204410742179403 on epoch=1, global_step=200
05/28/2022 15:01:51 - INFO - __main__ - Step 210 Global step 210 Train loss 0.69 on epoch=1
05/28/2022 15:01:53 - INFO - __main__ - Step 220 Global step 220 Train loss 0.62 on epoch=1
05/28/2022 15:01:56 - INFO - __main__ - Step 230 Global step 230 Train loss 0.58 on epoch=2
05/28/2022 15:01:59 - INFO - __main__ - Step 240 Global step 240 Train loss 0.52 on epoch=2
05/28/2022 15:02:01 - INFO - __main__ - Step 250 Global step 250 Train loss 0.54 on epoch=2
05/28/2022 15:02:53 - INFO - __main__ - Global step 250 Train loss 0.59 Classification-F1 0.22933023108088071 on epoch=2
05/28/2022 15:02:53 - INFO - __main__ - Saving model with best Classification-F1: 0.204410742179403 -> 0.22933023108088071 on epoch=2, global_step=250
05/28/2022 15:02:56 - INFO - __main__ - Step 260 Global step 260 Train loss 0.40 on epoch=2
05/28/2022 15:02:58 - INFO - __main__ - Step 270 Global step 270 Train loss 0.39 on epoch=2
05/28/2022 15:03:01 - INFO - __main__ - Step 280 Global step 280 Train loss 0.38 on epoch=2
05/28/2022 15:03:04 - INFO - __main__ - Step 290 Global step 290 Train loss 0.52 on epoch=2
05/28/2022 15:03:06 - INFO - __main__ - Step 300 Global step 300 Train loss 0.44 on epoch=2
05/28/2022 15:03:59 - INFO - __main__ - Global step 300 Train loss 0.43 Classification-F1 0.3838654484809802 on epoch=2
05/28/2022 15:03:59 - INFO - __main__ - Saving model with best Classification-F1: 0.22933023108088071 -> 0.3838654484809802 on epoch=2, global_step=300
05/28/2022 15:04:01 - INFO - __main__ - Step 310 Global step 310 Train loss 0.37 on epoch=2
05/28/2022 15:04:04 - INFO - __main__ - Step 320 Global step 320 Train loss 0.37 on epoch=2
05/28/2022 15:04:07 - INFO - __main__ - Step 330 Global step 330 Train loss 0.39 on epoch=2
05/28/2022 15:04:10 - INFO - __main__ - Step 340 Global step 340 Train loss 0.36 on epoch=3
05/28/2022 15:04:12 - INFO - __main__ - Step 350 Global step 350 Train loss 0.30 on epoch=3
05/28/2022 15:05:07 - INFO - __main__ - Global step 350 Train loss 0.36 Classification-F1 0.39750837117021953 on epoch=3
05/28/2022 15:05:07 - INFO - __main__ - Saving model with best Classification-F1: 0.3838654484809802 -> 0.39750837117021953 on epoch=3, global_step=350
05/28/2022 15:05:10 - INFO - __main__ - Step 360 Global step 360 Train loss 0.29 on epoch=3
05/28/2022 15:05:13 - INFO - __main__ - Step 370 Global step 370 Train loss 0.29 on epoch=3
05/28/2022 15:05:16 - INFO - __main__ - Step 380 Global step 380 Train loss 0.30 on epoch=3
05/28/2022 15:05:18 - INFO - __main__ - Step 390 Global step 390 Train loss 0.25 on epoch=3
05/28/2022 15:05:21 - INFO - __main__ - Step 400 Global step 400 Train loss 0.29 on epoch=3
05/28/2022 15:06:15 - INFO - __main__ - Global step 400 Train loss 0.29 Classification-F1 0.41070796040229357 on epoch=3
05/28/2022 15:06:15 - INFO - __main__ - Saving model with best Classification-F1: 0.39750837117021953 -> 0.41070796040229357 on epoch=3, global_step=400
05/28/2022 15:06:18 - INFO - __main__ - Step 410 Global step 410 Train loss 0.29 on epoch=3
05/28/2022 15:06:21 - INFO - __main__ - Step 420 Global step 420 Train loss 0.26 on epoch=3
05/28/2022 15:06:23 - INFO - __main__ - Step 430 Global step 430 Train loss 0.24 on epoch=3
05/28/2022 15:06:26 - INFO - __main__ - Step 440 Global step 440 Train loss 0.24 on epoch=3
05/28/2022 15:06:29 - INFO - __main__ - Step 450 Global step 450 Train loss 0.28 on epoch=4
05/28/2022 15:07:24 - INFO - __main__ - Global step 450 Train loss 0.26 Classification-F1 0.4578681346843541 on epoch=4
05/28/2022 15:07:24 - INFO - __main__ - Saving model with best Classification-F1: 0.41070796040229357 -> 0.4578681346843541 on epoch=4, global_step=450
05/28/2022 15:07:27 - INFO - __main__ - Step 460 Global step 460 Train loss 0.21 on epoch=4
05/28/2022 15:07:29 - INFO - __main__ - Step 470 Global step 470 Train loss 0.21 on epoch=4
05/28/2022 15:07:32 - INFO - __main__ - Step 480 Global step 480 Train loss 0.24 on epoch=4
05/28/2022 15:07:35 - INFO - __main__ - Step 490 Global step 490 Train loss 0.23 on epoch=4
05/28/2022 15:07:37 - INFO - __main__ - Step 500 Global step 500 Train loss 0.19 on epoch=4
05/28/2022 15:08:32 - INFO - __main__ - Global step 500 Train loss 0.22 Classification-F1 0.43642024510140426 on epoch=4
05/28/2022 15:08:35 - INFO - __main__ - Step 510 Global step 510 Train loss 0.19 on epoch=4
05/28/2022 15:08:38 - INFO - __main__ - Step 520 Global step 520 Train loss 0.19 on epoch=4
05/28/2022 15:08:40 - INFO - __main__ - Step 530 Global step 530 Train loss 0.16 on epoch=4
05/28/2022 15:08:43 - INFO - __main__ - Step 540 Global step 540 Train loss 0.22 on epoch=4
05/28/2022 15:08:46 - INFO - __main__ - Step 550 Global step 550 Train loss 0.24 on epoch=4
05/28/2022 15:09:41 - INFO - __main__ - Global step 550 Train loss 0.20 Classification-F1 0.5209890165570824 on epoch=4
05/28/2022 15:09:41 - INFO - __main__ - Saving model with best Classification-F1: 0.4578681346843541 -> 0.5209890165570824 on epoch=4, global_step=550
05/28/2022 15:09:43 - INFO - __main__ - Step 560 Global step 560 Train loss 0.26 on epoch=4
05/28/2022 15:09:46 - INFO - __main__ - Step 570 Global step 570 Train loss 0.16 on epoch=5
05/28/2022 15:09:49 - INFO - __main__ - Step 580 Global step 580 Train loss 0.16 on epoch=5
05/28/2022 15:09:52 - INFO - __main__ - Step 590 Global step 590 Train loss 0.18 on epoch=5
05/28/2022 15:09:54 - INFO - __main__ - Step 600 Global step 600 Train loss 0.19 on epoch=5
05/28/2022 15:10:50 - INFO - __main__ - Global step 600 Train loss 0.19 Classification-F1 0.4746950940102679 on epoch=5
05/28/2022 15:10:53 - INFO - __main__ - Step 610 Global step 610 Train loss 0.16 on epoch=5
05/28/2022 15:10:56 - INFO - __main__ - Step 620 Global step 620 Train loss 0.16 on epoch=5
05/28/2022 15:10:58 - INFO - __main__ - Step 630 Global step 630 Train loss 0.22 on epoch=5
05/28/2022 15:11:01 - INFO - __main__ - Step 640 Global step 640 Train loss 0.17 on epoch=5
05/28/2022 15:11:04 - INFO - __main__ - Step 650 Global step 650 Train loss 0.15 on epoch=5
05/28/2022 15:11:58 - INFO - __main__ - Global step 650 Train loss 0.17 Classification-F1 0.43461529935499615 on epoch=5
05/28/2022 15:12:00 - INFO - __main__ - Step 660 Global step 660 Train loss 0.16 on epoch=5
05/28/2022 15:12:03 - INFO - __main__ - Step 670 Global step 670 Train loss 0.24 on epoch=5
05/28/2022 15:12:06 - INFO - __main__ - Step 680 Global step 680 Train loss 0.13 on epoch=6
05/28/2022 15:12:08 - INFO - __main__ - Step 690 Global step 690 Train loss 0.17 on epoch=6
05/28/2022 15:12:11 - INFO - __main__ - Step 700 Global step 700 Train loss 0.19 on epoch=6
05/28/2022 15:13:01 - INFO - __main__ - Global step 700 Train loss 0.18 Classification-F1 0.466271430589551 on epoch=6
05/28/2022 15:13:04 - INFO - __main__ - Step 710 Global step 710 Train loss 0.21 on epoch=6
05/28/2022 15:13:06 - INFO - __main__ - Step 720 Global step 720 Train loss 0.21 on epoch=6
05/28/2022 15:13:09 - INFO - __main__ - Step 730 Global step 730 Train loss 0.10 on epoch=6
05/28/2022 15:13:12 - INFO - __main__ - Step 740 Global step 740 Train loss 0.19 on epoch=6
05/28/2022 15:13:14 - INFO - __main__ - Step 750 Global step 750 Train loss 0.13 on epoch=6
05/28/2022 15:14:04 - INFO - __main__ - Global step 750 Train loss 0.17 Classification-F1 0.5204337069982975 on epoch=6
05/28/2022 15:14:07 - INFO - __main__ - Step 760 Global step 760 Train loss 0.10 on epoch=6
05/28/2022 15:14:10 - INFO - __main__ - Step 770 Global step 770 Train loss 0.15 on epoch=6
05/28/2022 15:14:12 - INFO - __main__ - Step 780 Global step 780 Train loss 0.19 on epoch=6
05/28/2022 15:14:15 - INFO - __main__ - Step 790 Global step 790 Train loss 0.11 on epoch=7
05/28/2022 15:14:18 - INFO - __main__ - Step 800 Global step 800 Train loss 0.14 on epoch=7
05/28/2022 15:15:09 - INFO - __main__ - Global step 800 Train loss 0.14 Classification-F1 0.6243025779808884 on epoch=7
05/28/2022 15:15:09 - INFO - __main__ - Saving model with best Classification-F1: 0.5209890165570824 -> 0.6243025779808884 on epoch=7, global_step=800
05/28/2022 15:15:12 - INFO - __main__ - Step 810 Global step 810 Train loss 0.14 on epoch=7
05/28/2022 15:15:15 - INFO - __main__ - Step 820 Global step 820 Train loss 0.08 on epoch=7
05/28/2022 15:15:17 - INFO - __main__ - Step 830 Global step 830 Train loss 0.16 on epoch=7
05/28/2022 15:15:20 - INFO - __main__ - Step 840 Global step 840 Train loss 0.08 on epoch=7
05/28/2022 15:15:23 - INFO - __main__ - Step 850 Global step 850 Train loss 0.08 on epoch=7
05/28/2022 15:16:13 - INFO - __main__ - Global step 850 Train loss 0.11 Classification-F1 0.5999785859948003 on epoch=7
05/28/2022 15:16:16 - INFO - __main__ - Step 860 Global step 860 Train loss 0.12 on epoch=7
05/28/2022 15:16:19 - INFO - __main__ - Step 870 Global step 870 Train loss 0.10 on epoch=7
05/28/2022 15:16:21 - INFO - __main__ - Step 880 Global step 880 Train loss 0.13 on epoch=7
05/28/2022 15:16:24 - INFO - __main__ - Step 890 Global step 890 Train loss 0.08 on epoch=7
05/28/2022 15:16:27 - INFO - __main__ - Step 900 Global step 900 Train loss 0.11 on epoch=8
05/28/2022 15:17:16 - INFO - __main__ - Global step 900 Train loss 0.11 Classification-F1 0.6334890118527913 on epoch=8
05/28/2022 15:17:16 - INFO - __main__ - Saving model with best Classification-F1: 0.6243025779808884 -> 0.6334890118527913 on epoch=8, global_step=900
05/28/2022 15:17:18 - INFO - __main__ - Step 910 Global step 910 Train loss 0.13 on epoch=8
05/28/2022 15:17:21 - INFO - __main__ - Step 920 Global step 920 Train loss 0.12 on epoch=8
05/28/2022 15:17:23 - INFO - __main__ - Step 930 Global step 930 Train loss 0.08 on epoch=8
05/28/2022 15:17:26 - INFO - __main__ - Step 940 Global step 940 Train loss 0.13 on epoch=8
05/28/2022 15:17:29 - INFO - __main__ - Step 950 Global step 950 Train loss 0.08 on epoch=8
05/28/2022 15:18:18 - INFO - __main__ - Global step 950 Train loss 0.11 Classification-F1 0.5789974888679866 on epoch=8
05/28/2022 15:18:21 - INFO - __main__ - Step 960 Global step 960 Train loss 0.05 on epoch=8
05/28/2022 15:18:23 - INFO - __main__ - Step 970 Global step 970 Train loss 0.09 on epoch=8
05/28/2022 15:18:26 - INFO - __main__ - Step 980 Global step 980 Train loss 0.08 on epoch=8
05/28/2022 15:18:29 - INFO - __main__ - Step 990 Global step 990 Train loss 0.11 on epoch=8
05/28/2022 15:18:31 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.11 on epoch=8
05/28/2022 15:19:21 - INFO - __main__ - Global step 1000 Train loss 0.09 Classification-F1 0.5966400783419095 on epoch=8
05/28/2022 15:19:23 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.16 on epoch=9
05/28/2022 15:19:26 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.05 on epoch=9
05/28/2022 15:19:28 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.08 on epoch=9
05/28/2022 15:19:31 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.08 on epoch=9
05/28/2022 15:19:34 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.07 on epoch=9
05/28/2022 15:20:23 - INFO - __main__ - Global step 1050 Train loss 0.09 Classification-F1 0.5766611202395894 on epoch=9
05/28/2022 15:20:26 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.04 on epoch=9
05/28/2022 15:20:28 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.08 on epoch=9
05/28/2022 15:20:31 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.09 on epoch=9
05/28/2022 15:20:34 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.06 on epoch=9
05/28/2022 15:20:36 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.10 on epoch=9
05/28/2022 15:21:26 - INFO - __main__ - Global step 1100 Train loss 0.07 Classification-F1 0.5533359763872674 on epoch=9
05/28/2022 15:21:28 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.07 on epoch=9
05/28/2022 15:21:31 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.09 on epoch=9
05/28/2022 15:21:34 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.09 on epoch=10
05/28/2022 15:21:36 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.12 on epoch=10
05/28/2022 15:21:39 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.05 on epoch=10
05/28/2022 15:22:28 - INFO - __main__ - Global step 1150 Train loss 0.08 Classification-F1 0.5845579842020754 on epoch=10
05/28/2022 15:22:31 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.08 on epoch=10
05/28/2022 15:22:34 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.08 on epoch=10
05/28/2022 15:22:36 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.05 on epoch=10
05/28/2022 15:22:39 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.08 on epoch=10
05/28/2022 15:22:41 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.08 on epoch=10
05/28/2022 15:23:29 - INFO - __main__ - Global step 1200 Train loss 0.07 Classification-F1 0.5476118139270695 on epoch=10
05/28/2022 15:23:32 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.08 on epoch=10
05/28/2022 15:23:34 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.06 on epoch=10
05/28/2022 15:23:37 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.12 on epoch=10
05/28/2022 15:23:40 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.07 on epoch=11
05/28/2022 15:23:42 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.09 on epoch=11
05/28/2022 15:24:32 - INFO - __main__ - Global step 1250 Train loss 0.08 Classification-F1 0.592608413558464 on epoch=11
05/28/2022 15:24:35 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.13 on epoch=11
05/28/2022 15:24:37 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.06 on epoch=11
05/28/2022 15:24:40 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.08 on epoch=11
05/28/2022 15:24:43 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.02 on epoch=11
05/28/2022 15:24:45 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.08 on epoch=11
05/28/2022 15:25:34 - INFO - __main__ - Global step 1300 Train loss 0.07 Classification-F1 0.5578518936042645 on epoch=11
05/28/2022 15:25:36 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.06 on epoch=11
05/28/2022 15:25:39 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.06 on epoch=11
05/28/2022 15:25:42 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.05 on epoch=11
05/28/2022 15:25:44 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.08 on epoch=11
05/28/2022 15:25:47 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.05 on epoch=12
05/28/2022 15:26:37 - INFO - __main__ - Global step 1350 Train loss 0.06 Classification-F1 0.5971934215095401 on epoch=12
05/28/2022 15:26:39 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.06 on epoch=12
05/28/2022 15:26:42 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.09 on epoch=12
05/28/2022 15:26:45 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.03 on epoch=12
05/28/2022 15:26:47 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.07 on epoch=12
05/28/2022 15:26:50 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.04 on epoch=12
05/28/2022 15:27:40 - INFO - __main__ - Global step 1400 Train loss 0.06 Classification-F1 0.6506454009949477 on epoch=12
05/28/2022 15:27:40 - INFO - __main__ - Saving model with best Classification-F1: 0.6334890118527913 -> 0.6506454009949477 on epoch=12, global_step=1400
05/28/2022 15:27:43 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.11 on epoch=12
05/28/2022 15:27:45 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.06 on epoch=12
05/28/2022 15:27:48 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.06 on epoch=12
05/28/2022 15:27:50 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.05 on epoch=12
05/28/2022 15:27:53 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.03 on epoch=12
05/28/2022 15:28:42 - INFO - __main__ - Global step 1450 Train loss 0.06 Classification-F1 0.6235674173575102 on epoch=12
05/28/2022 15:28:44 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.14 on epoch=13
05/28/2022 15:28:47 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.02 on epoch=13
05/28/2022 15:28:49 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.08 on epoch=13
05/28/2022 15:28:52 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.08 on epoch=13
05/28/2022 15:28:55 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.09 on epoch=13
05/28/2022 15:29:43 - INFO - __main__ - Global step 1500 Train loss 0.08 Classification-F1 0.5713788005897404 on epoch=13
05/28/2022 15:29:46 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.05 on epoch=13
05/28/2022 15:29:48 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.06 on epoch=13
05/28/2022 15:29:51 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.05 on epoch=13
05/28/2022 15:29:53 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.05 on epoch=13
05/28/2022 15:29:56 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.05 on epoch=13
05/28/2022 15:30:46 - INFO - __main__ - Global step 1550 Train loss 0.05 Classification-F1 0.6019945685039346 on epoch=13
05/28/2022 15:30:48 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.03 on epoch=13
05/28/2022 15:30:51 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.11 on epoch=14
05/28/2022 15:30:53 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.06 on epoch=14
05/28/2022 15:30:56 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.05 on epoch=14
05/28/2022 15:30:59 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.07 on epoch=14
05/28/2022 15:31:47 - INFO - __main__ - Global step 1600 Train loss 0.06 Classification-F1 0.6507350142226949 on epoch=14
05/28/2022 15:31:47 - INFO - __main__ - Saving model with best Classification-F1: 0.6506454009949477 -> 0.6507350142226949 on epoch=14, global_step=1600
05/28/2022 15:31:50 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.16 on epoch=14
05/28/2022 15:31:53 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.02 on epoch=14
05/28/2022 15:31:55 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.08 on epoch=14
05/28/2022 15:31:58 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.04 on epoch=14
05/28/2022 15:32:00 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.04 on epoch=14
05/28/2022 15:32:49 - INFO - __main__ - Global step 1650 Train loss 0.07 Classification-F1 0.5810316458597196 on epoch=14
05/28/2022 15:32:51 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.06 on epoch=14
05/28/2022 15:32:54 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.03 on epoch=14
05/28/2022 15:32:57 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.16 on epoch=14
05/28/2022 15:32:59 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.05 on epoch=15
05/28/2022 15:33:02 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.09 on epoch=15
05/28/2022 15:33:50 - INFO - __main__ - Global step 1700 Train loss 0.08 Classification-F1 0.6169946813625431 on epoch=15
05/28/2022 15:33:53 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.04 on epoch=15
05/28/2022 15:33:56 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.05 on epoch=15
05/28/2022 15:33:58 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.08 on epoch=15
05/28/2022 15:34:01 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=15
05/28/2022 15:34:03 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=15
05/28/2022 15:34:52 - INFO - __main__ - Global step 1750 Train loss 0.05 Classification-F1 0.5813518868365248 on epoch=15
05/28/2022 15:34:54 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.04 on epoch=15
05/28/2022 15:34:57 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.04 on epoch=15
05/28/2022 15:34:59 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.08 on epoch=15
05/28/2022 15:35:02 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.08 on epoch=15
05/28/2022 15:35:05 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.05 on epoch=16
05/28/2022 15:35:54 - INFO - __main__ - Global step 1800 Train loss 0.06 Classification-F1 0.6116282694720757 on epoch=16
05/28/2022 15:35:56 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.04 on epoch=16
05/28/2022 15:35:59 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.11 on epoch=16
05/28/2022 15:36:02 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.04 on epoch=16
05/28/2022 15:36:04 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.08 on epoch=16
05/28/2022 15:36:07 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=16
05/28/2022 15:36:56 - INFO - __main__ - Global step 1850 Train loss 0.06 Classification-F1 0.6151198651320696 on epoch=16
05/28/2022 15:36:58 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.04 on epoch=16
05/28/2022 15:37:01 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.07 on epoch=16
05/28/2022 15:37:04 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=16
05/28/2022 15:37:06 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=16
05/28/2022 15:37:09 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.06 on epoch=16
05/28/2022 15:37:58 - INFO - __main__ - Global step 1900 Train loss 0.04 Classification-F1 0.6646834545667731 on epoch=16
05/28/2022 15:37:58 - INFO - __main__ - Saving model with best Classification-F1: 0.6507350142226949 -> 0.6646834545667731 on epoch=16, global_step=1900
05/28/2022 15:38:01 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=17
05/28/2022 15:38:04 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.04 on epoch=17
05/28/2022 15:38:06 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.10 on epoch=17
05/28/2022 15:38:09 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=17
05/28/2022 15:38:12 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.08 on epoch=17
05/28/2022 15:39:02 - INFO - __main__ - Global step 1950 Train loss 0.05 Classification-F1 0.7121308859882494 on epoch=17
05/28/2022 15:39:02 - INFO - __main__ - Saving model with best Classification-F1: 0.6646834545667731 -> 0.7121308859882494 on epoch=17, global_step=1950
05/28/2022 15:39:05 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.03 on epoch=17
05/28/2022 15:39:07 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=17
05/28/2022 15:39:10 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.04 on epoch=17
05/28/2022 15:39:12 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.07 on epoch=17
05/28/2022 15:39:15 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.04 on epoch=17
05/28/2022 15:40:05 - INFO - __main__ - Global step 2000 Train loss 0.04 Classification-F1 0.7541414243792204 on epoch=17
05/28/2022 15:40:05 - INFO - __main__ - Saving model with best Classification-F1: 0.7121308859882494 -> 0.7541414243792204 on epoch=17, global_step=2000
05/28/2022 15:40:08 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.05 on epoch=17
05/28/2022 15:40:10 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.07 on epoch=18
05/28/2022 15:40:13 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=18
05/28/2022 15:40:15 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.11 on epoch=18
05/28/2022 15:40:18 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.04 on epoch=18
05/28/2022 15:41:08 - INFO - __main__ - Global step 2050 Train loss 0.06 Classification-F1 0.7124191641524081 on epoch=18
05/28/2022 15:41:10 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.06 on epoch=18
05/28/2022 15:41:13 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=18
05/28/2022 15:41:16 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=18
05/28/2022 15:41:18 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.03 on epoch=18
05/28/2022 15:41:21 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=18
05/28/2022 15:42:10 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.6098890444725582 on epoch=18
05/28/2022 15:42:13 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=18
05/28/2022 15:42:15 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.03 on epoch=18
05/28/2022 15:42:18 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.05 on epoch=19
05/28/2022 15:42:20 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.05 on epoch=19
05/28/2022 15:42:23 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=19
05/28/2022 15:43:12 - INFO - __main__ - Global step 2150 Train loss 0.03 Classification-F1 0.6250167112128062 on epoch=19
05/28/2022 15:43:15 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=19
05/28/2022 15:43:17 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.05 on epoch=19
05/28/2022 15:43:20 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=19
05/28/2022 15:43:22 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=19
05/28/2022 15:43:25 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=19
05/28/2022 15:44:14 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.6326251436140239 on epoch=19
05/28/2022 15:44:17 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=19
05/28/2022 15:44:19 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.04 on epoch=19
05/28/2022 15:44:22 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.03 on epoch=19
05/28/2022 15:44:25 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.09 on epoch=19
05/28/2022 15:44:27 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=20
05/28/2022 15:45:16 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.6047217233899834 on epoch=20
05/28/2022 15:45:19 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.14 on epoch=20
05/28/2022 15:45:22 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=20
05/28/2022 15:45:24 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=20
05/28/2022 15:45:27 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.09 on epoch=20
05/28/2022 15:45:30 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=20
05/28/2022 15:46:19 - INFO - __main__ - Global step 2300 Train loss 0.06 Classification-F1 0.5793971004490357 on epoch=20
05/28/2022 15:46:22 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=20
05/28/2022 15:46:24 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.04 on epoch=20
05/28/2022 15:46:27 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=20
05/28/2022 15:46:29 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=20
05/28/2022 15:46:32 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.11 on epoch=20
05/28/2022 15:47:22 - INFO - __main__ - Global step 2350 Train loss 0.05 Classification-F1 0.6758697147488922 on epoch=20
05/28/2022 15:47:25 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=21
05/28/2022 15:47:28 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=21
05/28/2022 15:47:30 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.07 on epoch=21
05/28/2022 15:47:33 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=21
05/28/2022 15:47:35 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.04 on epoch=21
05/28/2022 15:48:25 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.7057712849672758 on epoch=21
05/28/2022 15:48:28 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.03 on epoch=21
05/28/2022 15:48:30 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=21
05/28/2022 15:48:33 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=21
05/28/2022 15:48:36 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=21
05/28/2022 15:48:38 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.04 on epoch=21
05/28/2022 15:49:27 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.6460876733360128 on epoch=21
05/28/2022 15:49:30 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.09 on epoch=21
05/28/2022 15:49:33 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.05 on epoch=22
05/28/2022 15:49:35 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=22
05/28/2022 15:49:38 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.07 on epoch=22
05/28/2022 15:49:41 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=22
05/28/2022 15:50:30 - INFO - __main__ - Global step 2500 Train loss 0.05 Classification-F1 0.6710743236858231 on epoch=22
05/28/2022 15:50:33 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.04 on epoch=22
05/28/2022 15:50:35 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=22
05/28/2022 15:50:38 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.06 on epoch=22
05/28/2022 15:50:40 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.03 on epoch=22
05/28/2022 15:50:43 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=22
05/28/2022 15:51:32 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.6240328629533672 on epoch=22
05/28/2022 15:51:35 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.03 on epoch=22
05/28/2022 15:51:37 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=22
05/28/2022 15:51:40 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.05 on epoch=23
05/28/2022 15:51:43 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=23
05/28/2022 15:51:45 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.10 on epoch=23
05/28/2022 15:52:35 - INFO - __main__ - Global step 2600 Train loss 0.04 Classification-F1 0.6121604020784233 on epoch=23
05/28/2022 15:52:37 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.05 on epoch=23
05/28/2022 15:52:40 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.07 on epoch=23
05/28/2022 15:52:43 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=23
05/28/2022 15:52:45 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=23
05/28/2022 15:52:48 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=23
05/28/2022 15:53:38 - INFO - __main__ - Global step 2650 Train loss 0.04 Classification-F1 0.7200225728715104 on epoch=23
05/28/2022 15:53:40 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=23
05/28/2022 15:53:43 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.03 on epoch=23
05/28/2022 15:53:46 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=23
05/28/2022 15:53:48 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.08 on epoch=24
05/28/2022 15:53:51 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=24
05/28/2022 15:54:41 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.7506430866855263 on epoch=24
05/28/2022 15:54:43 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.07 on epoch=24
05/28/2022 15:54:46 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=24
05/28/2022 15:54:48 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.04 on epoch=24
05/28/2022 15:54:51 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=24
05/28/2022 15:54:54 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=24
05/28/2022 15:55:45 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.6872526286741165 on epoch=24
05/28/2022 15:55:47 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=24
05/28/2022 15:55:50 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.03 on epoch=24
05/28/2022 15:55:53 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=24
05/28/2022 15:55:55 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=24
05/28/2022 15:55:58 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.04 on epoch=24
05/28/2022 15:56:48 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.6633845818966255 on epoch=24
05/28/2022 15:56:50 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=25
05/28/2022 15:56:53 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.06 on epoch=25
05/28/2022 15:56:56 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=25
05/28/2022 15:56:58 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=25
05/28/2022 15:57:01 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.09 on epoch=25
05/28/2022 15:57:52 - INFO - __main__ - Global step 2850 Train loss 0.04 Classification-F1 0.736195751698137 on epoch=25
05/28/2022 15:57:54 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=25
05/28/2022 15:57:57 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=25
05/28/2022 15:57:59 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=25
05/28/2022 15:58:02 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.05 on epoch=25
05/28/2022 15:58:05 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=25
05/28/2022 15:58:55 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.6762358372635437 on epoch=25
05/28/2022 15:58:58 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.05 on epoch=25
05/28/2022 15:59:00 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=26
05/28/2022 15:59:03 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=26
05/28/2022 15:59:05 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.06 on epoch=26
05/28/2022 15:59:08 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.04 on epoch=26
05/28/2022 15:59:58 - INFO - __main__ - Global step 2950 Train loss 0.04 Classification-F1 0.6608296426491458 on epoch=26
05/28/2022 16:00:01 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.03 on epoch=26
05/28/2022 16:00:03 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=26
05/28/2022 16:00:06 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.03 on epoch=26
05/28/2022 16:00:09 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.03 on epoch=26
05/28/2022 16:00:11 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=26
05/28/2022 16:00:13 - INFO - __main__ - Start tokenizing ... 1792 instances
05/28/2022 16:00:13 - INFO - __main__ - Printing 3 examples
05/28/2022 16:00:13 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
05/28/2022 16:00:13 - INFO - __main__ - ['Film']
05/28/2022 16:00:13 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/28/2022 16:00:13 - INFO - __main__ - ['Film']
05/28/2022 16:00:13 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/28/2022 16:00:13 - INFO - __main__ - ['Film']
05/28/2022 16:00:13 - INFO - __main__ - Tokenizing Input ...
05/28/2022 16:00:14 - INFO - __main__ - Tokenizing Output ...
05/28/2022 16:00:16 - INFO - __main__ - Loaded 1792 examples from train data
05/28/2022 16:00:16 - INFO - __main__ - Start tokenizing ... 1792 instances
05/28/2022 16:00:16 - INFO - __main__ - Printing 3 examples
05/28/2022 16:00:16 - INFO - __main__ -  [dbpedia_14] The Debt is a 2011 American/British drama-thriller film directed by John Madden from a screenplay by Matthew Vaughn Jane Goldman and Peter Straughan. It stars Helen Mirren Sam Worthington Jessica Chastain Ciarán Hinds Tom Wilkinson Marton Csokas and Jesper Christensen. It's a remake of the 2007 Israeli film Ha-Hov directed by Assaf BernsteinOriginally scheduled for a December 2010 release the film was released in the United States on August 31 2011.
05/28/2022 16:00:16 - INFO - __main__ - ['Film']
05/28/2022 16:00:16 - INFO - __main__ -  [dbpedia_14] Naga Bonar Jadi 2 (Naga Bonar Becomes 2) is 2007 comedy film directed by Deddy Mizwar. It is starring Deddy Mizwar Tora Sudiro Lukman Sardi Darius Sinathrya and Michael Muliardo. It is a sequel to the Indonesian film Nagabonar (1987).
05/28/2022 16:00:16 - INFO - __main__ - ['Film']
05/28/2022 16:00:16 - INFO - __main__ -  [dbpedia_14] La Garce is a 1984 French thriller film directed by Christine Pascal and starring Isabelle Huppert.
05/28/2022 16:00:16 - INFO - __main__ - ['Film']
05/28/2022 16:00:16 - INFO - __main__ - Tokenizing Input ...
05/28/2022 16:00:17 - INFO - __main__ - Tokenizing Output ...
05/28/2022 16:00:18 - INFO - __main__ - Loaded 1792 examples from dev data
05/28/2022 16:00:33 - INFO - __main__ - load prompt embedding from ckpt
05/28/2022 16:00:34 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/28/2022 16:00:34 - INFO - __main__ - Starting training!
05/28/2022 16:01:01 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.6028337575557862 on epoch=26
05/28/2022 16:01:01 - INFO - __main__ - save last model!
05/28/2022 16:01:01 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/28/2022 16:01:01 - INFO - __main__ - Start tokenizing ... 3500 instances
05/28/2022 16:01:01 - INFO - __main__ - Printing 3 examples
05/28/2022 16:01:01 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/28/2022 16:01:01 - INFO - __main__ - ['Animal']
05/28/2022 16:01:01 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/28/2022 16:01:01 - INFO - __main__ - ['Animal']
05/28/2022 16:01:01 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/28/2022 16:01:01 - INFO - __main__ - ['Village']
05/28/2022 16:01:01 - INFO - __main__ - Tokenizing Input ...
05/28/2022 16:01:03 - INFO - __main__ - Tokenizing Output ...
05/28/2022 16:01:07 - INFO - __main__ - Loaded 3500 examples from test data
05/28/2022 16:03:12 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down128shot/singletask-dbpedia_14/dbpedia_14_128_87_0.5_8_predictions.txt
05/28/2022 16:03:12 - INFO - __main__ - Classification-F1 on test data: 0.5746
05/28/2022 16:03:12 - INFO - __main__ - prefix=dbpedia_14_128_87, lr=0.5, bsz=8, dev_performance=0.7541414243792204, test_performance=0.5745708590637549
05/28/2022 16:03:12 - INFO - __main__ - Running ... prefix=dbpedia_14_128_87, lr=0.4, bsz=8 ...
05/28/2022 16:03:13 - INFO - __main__ - Start tokenizing ... 1792 instances
05/28/2022 16:03:13 - INFO - __main__ - Printing 3 examples
05/28/2022 16:03:13 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
05/28/2022 16:03:13 - INFO - __main__ - ['Film']
05/28/2022 16:03:13 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/28/2022 16:03:13 - INFO - __main__ - ['Film']
05/28/2022 16:03:13 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/28/2022 16:03:13 - INFO - __main__ - ['Film']
05/28/2022 16:03:13 - INFO - __main__ - Tokenizing Input ...
05/28/2022 16:03:14 - INFO - __main__ - Tokenizing Output ...
05/28/2022 16:03:16 - INFO - __main__ - Loaded 1792 examples from train data
05/28/2022 16:03:16 - INFO - __main__ - Start tokenizing ... 1792 instances
05/28/2022 16:03:16 - INFO - __main__ - Printing 3 examples
05/28/2022 16:03:16 - INFO - __main__ -  [dbpedia_14] The Debt is a 2011 American/British drama-thriller film directed by John Madden from a screenplay by Matthew Vaughn Jane Goldman and Peter Straughan. It stars Helen Mirren Sam Worthington Jessica Chastain Ciarán Hinds Tom Wilkinson Marton Csokas and Jesper Christensen. It's a remake of the 2007 Israeli film Ha-Hov directed by Assaf BernsteinOriginally scheduled for a December 2010 release the film was released in the United States on August 31 2011.
05/28/2022 16:03:16 - INFO - __main__ - ['Film']
05/28/2022 16:03:16 - INFO - __main__ -  [dbpedia_14] Naga Bonar Jadi 2 (Naga Bonar Becomes 2) is 2007 comedy film directed by Deddy Mizwar. It is starring Deddy Mizwar Tora Sudiro Lukman Sardi Darius Sinathrya and Michael Muliardo. It is a sequel to the Indonesian film Nagabonar (1987).
05/28/2022 16:03:16 - INFO - __main__ - ['Film']
05/28/2022 16:03:16 - INFO - __main__ -  [dbpedia_14] La Garce is a 1984 French thriller film directed by Christine Pascal and starring Isabelle Huppert.
05/28/2022 16:03:16 - INFO - __main__ - ['Film']
05/28/2022 16:03:16 - INFO - __main__ - Tokenizing Input ...
05/28/2022 16:03:17 - INFO - __main__ - Tokenizing Output ...
05/28/2022 16:03:19 - INFO - __main__ - Loaded 1792 examples from dev data
05/28/2022 16:03:35 - INFO - __main__ - load prompt embedding from ckpt
05/28/2022 16:03:36 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/28/2022 16:03:36 - INFO - __main__ - Starting training!
05/28/2022 16:03:40 - INFO - __main__ - Step 10 Global step 10 Train loss 7.13 on epoch=0
05/28/2022 16:03:42 - INFO - __main__ - Step 20 Global step 20 Train loss 5.00 on epoch=0
05/28/2022 16:03:45 - INFO - __main__ - Step 30 Global step 30 Train loss 3.84 on epoch=0
05/28/2022 16:03:48 - INFO - __main__ - Step 40 Global step 40 Train loss 2.94 on epoch=0
05/28/2022 16:03:50 - INFO - __main__ - Step 50 Global step 50 Train loss 3.14 on epoch=0
05/28/2022 16:04:41 - INFO - __main__ - Global step 50 Train loss 4.41 Classification-F1 0.013563074367833414 on epoch=0
05/28/2022 16:04:41 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.013563074367833414 on epoch=0, global_step=50
05/28/2022 16:04:43 - INFO - __main__ - Step 60 Global step 60 Train loss 2.71 on epoch=0
05/28/2022 16:04:46 - INFO - __main__ - Step 70 Global step 70 Train loss 2.90 on epoch=0
05/28/2022 16:04:48 - INFO - __main__ - Step 80 Global step 80 Train loss 2.41 on epoch=0
05/28/2022 16:04:51 - INFO - __main__ - Step 90 Global step 90 Train loss 2.33 on epoch=0
05/28/2022 16:04:54 - INFO - __main__ - Step 100 Global step 100 Train loss 2.12 on epoch=0
05/28/2022 16:05:40 - INFO - __main__ - Global step 100 Train loss 2.49 Classification-F1 0.03356044338367993 on epoch=0
05/28/2022 16:05:40 - INFO - __main__ - Saving model with best Classification-F1: 0.013563074367833414 -> 0.03356044338367993 on epoch=0, global_step=100
05/28/2022 16:05:42 - INFO - __main__ - Step 110 Global step 110 Train loss 2.02 on epoch=0
05/28/2022 16:05:45 - INFO - __main__ - Step 120 Global step 120 Train loss 1.85 on epoch=1
05/28/2022 16:05:47 - INFO - __main__ - Step 130 Global step 130 Train loss 1.75 on epoch=1
05/28/2022 16:05:50 - INFO - __main__ - Step 140 Global step 140 Train loss 1.44 on epoch=1
05/28/2022 16:05:53 - INFO - __main__ - Step 150 Global step 150 Train loss 1.08 on epoch=1
05/28/2022 16:06:37 - INFO - __main__ - Global step 150 Train loss 1.63 Classification-F1 0.07400173172319989 on epoch=1
05/28/2022 16:06:37 - INFO - __main__ - Saving model with best Classification-F1: 0.03356044338367993 -> 0.07400173172319989 on epoch=1, global_step=150
05/28/2022 16:06:39 - INFO - __main__ - Step 160 Global step 160 Train loss 1.30 on epoch=1
05/28/2022 16:06:42 - INFO - __main__ - Step 170 Global step 170 Train loss 1.30 on epoch=1
05/28/2022 16:06:45 - INFO - __main__ - Step 180 Global step 180 Train loss 1.34 on epoch=1
05/28/2022 16:06:47 - INFO - __main__ - Step 190 Global step 190 Train loss 1.00 on epoch=1
05/28/2022 16:06:50 - INFO - __main__ - Step 200 Global step 200 Train loss 1.08 on epoch=1
05/28/2022 16:07:34 - INFO - __main__ - Global step 200 Train loss 1.20 Classification-F1 0.15111863796658048 on epoch=1
05/28/2022 16:07:34 - INFO - __main__ - Saving model with best Classification-F1: 0.07400173172319989 -> 0.15111863796658048 on epoch=1, global_step=200
05/28/2022 16:07:37 - INFO - __main__ - Step 210 Global step 210 Train loss 0.90 on epoch=1
05/28/2022 16:07:39 - INFO - __main__ - Step 220 Global step 220 Train loss 0.89 on epoch=1
05/28/2022 16:07:42 - INFO - __main__ - Step 230 Global step 230 Train loss 0.64 on epoch=2
05/28/2022 16:07:44 - INFO - __main__ - Step 240 Global step 240 Train loss 0.80 on epoch=2
05/28/2022 16:07:47 - INFO - __main__ - Step 250 Global step 250 Train loss 0.68 on epoch=2
05/28/2022 16:08:36 - INFO - __main__ - Global step 250 Train loss 0.78 Classification-F1 0.20247409172424563 on epoch=2
05/28/2022 16:08:36 - INFO - __main__ - Saving model with best Classification-F1: 0.15111863796658048 -> 0.20247409172424563 on epoch=2, global_step=250
05/28/2022 16:08:38 - INFO - __main__ - Step 260 Global step 260 Train loss 0.48 on epoch=2
05/28/2022 16:08:41 - INFO - __main__ - Step 270 Global step 270 Train loss 0.53 on epoch=2
05/28/2022 16:08:43 - INFO - __main__ - Step 280 Global step 280 Train loss 0.58 on epoch=2
05/28/2022 16:08:46 - INFO - __main__ - Step 290 Global step 290 Train loss 0.59 on epoch=2
05/28/2022 16:08:49 - INFO - __main__ - Step 300 Global step 300 Train loss 0.44 on epoch=2
05/28/2022 16:09:39 - INFO - __main__ - Global step 300 Train loss 0.52 Classification-F1 0.24357999498952146 on epoch=2
05/28/2022 16:09:39 - INFO - __main__ - Saving model with best Classification-F1: 0.20247409172424563 -> 0.24357999498952146 on epoch=2, global_step=300
05/28/2022 16:09:42 - INFO - __main__ - Step 310 Global step 310 Train loss 0.49 on epoch=2
05/28/2022 16:09:44 - INFO - __main__ - Step 320 Global step 320 Train loss 0.59 on epoch=2
05/28/2022 16:09:47 - INFO - __main__ - Step 330 Global step 330 Train loss 0.53 on epoch=2
05/28/2022 16:09:49 - INFO - __main__ - Step 340 Global step 340 Train loss 0.52 on epoch=3
05/28/2022 16:09:52 - INFO - __main__ - Step 350 Global step 350 Train loss 0.38 on epoch=3
05/28/2022 16:10:45 - INFO - __main__ - Global step 350 Train loss 0.50 Classification-F1 0.2780514924766036 on epoch=3
05/28/2022 16:10:45 - INFO - __main__ - Saving model with best Classification-F1: 0.24357999498952146 -> 0.2780514924766036 on epoch=3, global_step=350
05/28/2022 16:10:47 - INFO - __main__ - Step 360 Global step 360 Train loss 0.46 on epoch=3
05/28/2022 16:10:50 - INFO - __main__ - Step 370 Global step 370 Train loss 0.32 on epoch=3
05/28/2022 16:10:53 - INFO - __main__ - Step 380 Global step 380 Train loss 0.29 on epoch=3
05/28/2022 16:10:55 - INFO - __main__ - Step 390 Global step 390 Train loss 0.34 on epoch=3
05/28/2022 16:10:58 - INFO - __main__ - Step 400 Global step 400 Train loss 0.46 on epoch=3
05/28/2022 16:11:51 - INFO - __main__ - Global step 400 Train loss 0.37 Classification-F1 0.3748247198865115 on epoch=3
05/28/2022 16:11:51 - INFO - __main__ - Saving model with best Classification-F1: 0.2780514924766036 -> 0.3748247198865115 on epoch=3, global_step=400
05/28/2022 16:11:53 - INFO - __main__ - Step 410 Global step 410 Train loss 0.37 on epoch=3
05/28/2022 16:11:56 - INFO - __main__ - Step 420 Global step 420 Train loss 0.27 on epoch=3
05/28/2022 16:11:59 - INFO - __main__ - Step 430 Global step 430 Train loss 0.31 on epoch=3
05/28/2022 16:12:01 - INFO - __main__ - Step 440 Global step 440 Train loss 0.30 on epoch=3
05/28/2022 16:12:04 - INFO - __main__ - Step 450 Global step 450 Train loss 0.33 on epoch=4
05/28/2022 16:12:56 - INFO - __main__ - Global step 450 Train loss 0.32 Classification-F1 0.3489272405498841 on epoch=4
05/28/2022 16:12:59 - INFO - __main__ - Step 460 Global step 460 Train loss 0.27 on epoch=4
05/28/2022 16:13:01 - INFO - __main__ - Step 470 Global step 470 Train loss 0.26 on epoch=4
05/28/2022 16:13:04 - INFO - __main__ - Step 480 Global step 480 Train loss 0.29 on epoch=4
05/28/2022 16:13:06 - INFO - __main__ - Step 490 Global step 490 Train loss 0.30 on epoch=4
05/28/2022 16:13:09 - INFO - __main__ - Step 500 Global step 500 Train loss 0.21 on epoch=4
05/28/2022 16:14:00 - INFO - __main__ - Global step 500 Train loss 0.27 Classification-F1 0.3889106530037077 on epoch=4
05/28/2022 16:14:00 - INFO - __main__ - Saving model with best Classification-F1: 0.3748247198865115 -> 0.3889106530037077 on epoch=4, global_step=500
05/28/2022 16:14:03 - INFO - __main__ - Step 510 Global step 510 Train loss 0.23 on epoch=4
05/28/2022 16:14:05 - INFO - __main__ - Step 520 Global step 520 Train loss 0.26 on epoch=4
05/28/2022 16:14:08 - INFO - __main__ - Step 530 Global step 530 Train loss 0.24 on epoch=4
05/28/2022 16:14:10 - INFO - __main__ - Step 540 Global step 540 Train loss 0.30 on epoch=4
05/28/2022 16:14:13 - INFO - __main__ - Step 550 Global step 550 Train loss 0.19 on epoch=4
05/28/2022 16:15:05 - INFO - __main__ - Global step 550 Train loss 0.24 Classification-F1 0.3946638859168797 on epoch=4
05/28/2022 16:15:05 - INFO - __main__ - Saving model with best Classification-F1: 0.3889106530037077 -> 0.3946638859168797 on epoch=4, global_step=550
05/28/2022 16:15:08 - INFO - __main__ - Step 560 Global step 560 Train loss 0.26 on epoch=4
05/28/2022 16:15:10 - INFO - __main__ - Step 570 Global step 570 Train loss 0.16 on epoch=5
05/28/2022 16:15:13 - INFO - __main__ - Step 580 Global step 580 Train loss 0.35 on epoch=5
05/28/2022 16:15:15 - INFO - __main__ - Step 590 Global step 590 Train loss 0.19 on epoch=5
05/28/2022 16:15:18 - INFO - __main__ - Step 600 Global step 600 Train loss 0.19 on epoch=5
05/28/2022 16:16:09 - INFO - __main__ - Global step 600 Train loss 0.23 Classification-F1 0.44508454205594233 on epoch=5
05/28/2022 16:16:09 - INFO - __main__ - Saving model with best Classification-F1: 0.3946638859168797 -> 0.44508454205594233 on epoch=5, global_step=600
05/28/2022 16:16:11 - INFO - __main__ - Step 610 Global step 610 Train loss 0.25 on epoch=5
05/28/2022 16:16:14 - INFO - __main__ - Step 620 Global step 620 Train loss 0.14 on epoch=5
05/28/2022 16:16:17 - INFO - __main__ - Step 630 Global step 630 Train loss 0.18 on epoch=5
05/28/2022 16:16:19 - INFO - __main__ - Step 640 Global step 640 Train loss 0.24 on epoch=5
05/28/2022 16:16:22 - INFO - __main__ - Step 650 Global step 650 Train loss 0.22 on epoch=5
05/28/2022 16:17:12 - INFO - __main__ - Global step 650 Train loss 0.21 Classification-F1 0.37856825164750313 on epoch=5
05/28/2022 16:17:15 - INFO - __main__ - Step 660 Global step 660 Train loss 0.22 on epoch=5
05/28/2022 16:17:18 - INFO - __main__ - Step 670 Global step 670 Train loss 0.31 on epoch=5
05/28/2022 16:17:20 - INFO - __main__ - Step 680 Global step 680 Train loss 0.17 on epoch=6
05/28/2022 16:17:23 - INFO - __main__ - Step 690 Global step 690 Train loss 0.22 on epoch=6
05/28/2022 16:17:25 - INFO - __main__ - Step 700 Global step 700 Train loss 0.17 on epoch=6
05/28/2022 16:18:18 - INFO - __main__ - Global step 700 Train loss 0.22 Classification-F1 0.48399306388004454 on epoch=6
05/28/2022 16:18:18 - INFO - __main__ - Saving model with best Classification-F1: 0.44508454205594233 -> 0.48399306388004454 on epoch=6, global_step=700
05/28/2022 16:18:21 - INFO - __main__ - Step 710 Global step 710 Train loss 0.10 on epoch=6
05/28/2022 16:18:23 - INFO - __main__ - Step 720 Global step 720 Train loss 0.20 on epoch=6
05/28/2022 16:18:26 - INFO - __main__ - Step 730 Global step 730 Train loss 0.12 on epoch=6
05/28/2022 16:18:29 - INFO - __main__ - Step 740 Global step 740 Train loss 0.21 on epoch=6
05/28/2022 16:18:31 - INFO - __main__ - Step 750 Global step 750 Train loss 0.19 on epoch=6
05/28/2022 16:19:23 - INFO - __main__ - Global step 750 Train loss 0.17 Classification-F1 0.47371172171176046 on epoch=6
05/28/2022 16:19:25 - INFO - __main__ - Step 760 Global step 760 Train loss 0.19 on epoch=6
05/28/2022 16:19:28 - INFO - __main__ - Step 770 Global step 770 Train loss 0.18 on epoch=6
05/28/2022 16:19:31 - INFO - __main__ - Step 780 Global step 780 Train loss 0.18 on epoch=6
05/28/2022 16:19:33 - INFO - __main__ - Step 790 Global step 790 Train loss 0.16 on epoch=7
05/28/2022 16:19:36 - INFO - __main__ - Step 800 Global step 800 Train loss 0.10 on epoch=7
05/28/2022 16:20:28 - INFO - __main__ - Global step 800 Train loss 0.16 Classification-F1 0.5856231529937955 on epoch=7
05/28/2022 16:20:28 - INFO - __main__ - Saving model with best Classification-F1: 0.48399306388004454 -> 0.5856231529937955 on epoch=7, global_step=800
05/28/2022 16:20:31 - INFO - __main__ - Step 810 Global step 810 Train loss 0.15 on epoch=7
05/28/2022 16:20:34 - INFO - __main__ - Step 820 Global step 820 Train loss 0.15 on epoch=7
05/28/2022 16:20:36 - INFO - __main__ - Step 830 Global step 830 Train loss 0.19 on epoch=7
05/28/2022 16:20:39 - INFO - __main__ - Step 840 Global step 840 Train loss 0.10 on epoch=7
05/28/2022 16:20:41 - INFO - __main__ - Step 850 Global step 850 Train loss 0.14 on epoch=7
05/28/2022 16:21:32 - INFO - __main__ - Global step 850 Train loss 0.15 Classification-F1 0.5244768344085509 on epoch=7
05/28/2022 16:21:35 - INFO - __main__ - Step 860 Global step 860 Train loss 0.10 on epoch=7
05/28/2022 16:21:38 - INFO - __main__ - Step 870 Global step 870 Train loss 0.15 on epoch=7
05/28/2022 16:21:40 - INFO - __main__ - Step 880 Global step 880 Train loss 0.16 on epoch=7
05/28/2022 16:21:43 - INFO - __main__ - Step 890 Global step 890 Train loss 0.17 on epoch=7
05/28/2022 16:21:45 - INFO - __main__ - Step 900 Global step 900 Train loss 0.15 on epoch=8
05/28/2022 16:22:36 - INFO - __main__ - Global step 900 Train loss 0.15 Classification-F1 0.454370121099377 on epoch=8
05/28/2022 16:22:38 - INFO - __main__ - Step 910 Global step 910 Train loss 0.11 on epoch=8
05/28/2022 16:22:41 - INFO - __main__ - Step 920 Global step 920 Train loss 0.19 on epoch=8
05/28/2022 16:22:43 - INFO - __main__ - Step 930 Global step 930 Train loss 0.09 on epoch=8
05/28/2022 16:22:46 - INFO - __main__ - Step 940 Global step 940 Train loss 0.16 on epoch=8
05/28/2022 16:22:48 - INFO - __main__ - Step 950 Global step 950 Train loss 0.11 on epoch=8
05/28/2022 16:23:39 - INFO - __main__ - Global step 950 Train loss 0.13 Classification-F1 0.47126508818450374 on epoch=8
05/28/2022 16:23:41 - INFO - __main__ - Step 960 Global step 960 Train loss 0.08 on epoch=8
05/28/2022 16:23:44 - INFO - __main__ - Step 970 Global step 970 Train loss 0.12 on epoch=8
05/28/2022 16:23:46 - INFO - __main__ - Step 980 Global step 980 Train loss 0.09 on epoch=8
05/28/2022 16:23:49 - INFO - __main__ - Step 990 Global step 990 Train loss 0.15 on epoch=8
05/28/2022 16:23:51 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.13 on epoch=8
05/28/2022 16:24:43 - INFO - __main__ - Global step 1000 Train loss 0.12 Classification-F1 0.5344916187014213 on epoch=8
05/28/2022 16:24:45 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.15 on epoch=9
05/28/2022 16:24:48 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.08 on epoch=9
05/28/2022 16:24:50 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.15 on epoch=9
05/28/2022 16:24:53 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.12 on epoch=9
05/28/2022 16:24:56 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.10 on epoch=9
05/28/2022 16:25:48 - INFO - __main__ - Global step 1050 Train loss 0.12 Classification-F1 0.5429179464539838 on epoch=9
05/28/2022 16:25:51 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.13 on epoch=9
05/28/2022 16:25:53 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.12 on epoch=9
05/28/2022 16:25:56 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.11 on epoch=9
05/28/2022 16:25:59 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.08 on epoch=9
05/28/2022 16:26:01 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.10 on epoch=9
05/28/2022 16:26:53 - INFO - __main__ - Global step 1100 Train loss 0.11 Classification-F1 0.6404045850122854 on epoch=9
05/28/2022 16:26:53 - INFO - __main__ - Saving model with best Classification-F1: 0.5856231529937955 -> 0.6404045850122854 on epoch=9, global_step=1100
05/28/2022 16:26:55 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.06 on epoch=9
05/28/2022 16:26:58 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.11 on epoch=9
05/28/2022 16:27:00 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.07 on epoch=10
05/28/2022 16:27:03 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.15 on epoch=10
05/28/2022 16:27:05 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.13 on epoch=10
05/28/2022 16:27:55 - INFO - __main__ - Global step 1150 Train loss 0.10 Classification-F1 0.5861410581057817 on epoch=10
05/28/2022 16:27:58 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.14 on epoch=10
05/28/2022 16:28:01 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.09 on epoch=10
05/28/2022 16:28:03 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.10 on epoch=10
05/28/2022 16:28:06 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.10 on epoch=10
05/28/2022 16:28:08 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.13 on epoch=10
05/28/2022 16:28:58 - INFO - __main__ - Global step 1200 Train loss 0.11 Classification-F1 0.5173547510452484 on epoch=10
05/28/2022 16:29:00 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.11 on epoch=10
05/28/2022 16:29:03 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.07 on epoch=10
05/28/2022 16:29:05 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.17 on epoch=10
05/28/2022 16:29:08 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.08 on epoch=11
05/28/2022 16:29:11 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.12 on epoch=11
05/28/2022 16:30:01 - INFO - __main__ - Global step 1250 Train loss 0.11 Classification-F1 0.5004687959042952 on epoch=11
05/28/2022 16:30:03 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.15 on epoch=11
05/28/2022 16:30:06 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.06 on epoch=11
05/28/2022 16:30:08 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.09 on epoch=11
05/28/2022 16:30:11 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.07 on epoch=11
05/28/2022 16:30:14 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.06 on epoch=11
05/28/2022 16:31:05 - INFO - __main__ - Global step 1300 Train loss 0.08 Classification-F1 0.5010216055153546 on epoch=11
05/28/2022 16:31:08 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.13 on epoch=11
05/28/2022 16:31:10 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.05 on epoch=11
05/28/2022 16:31:13 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.11 on epoch=11
05/28/2022 16:31:15 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.15 on epoch=11
05/28/2022 16:31:18 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.07 on epoch=12
05/28/2022 16:32:11 - INFO - __main__ - Global step 1350 Train loss 0.10 Classification-F1 0.5551560225822633 on epoch=12
05/28/2022 16:32:13 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.04 on epoch=12
05/28/2022 16:32:16 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.16 on epoch=12
05/28/2022 16:32:19 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.08 on epoch=12
05/28/2022 16:32:21 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.07 on epoch=12
05/28/2022 16:32:24 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.04 on epoch=12
05/28/2022 16:33:15 - INFO - __main__ - Global step 1400 Train loss 0.08 Classification-F1 0.521203090347442 on epoch=12
05/28/2022 16:33:18 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.06 on epoch=12
05/28/2022 16:33:20 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.06 on epoch=12
05/28/2022 16:33:23 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.11 on epoch=12
05/28/2022 16:33:25 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.09 on epoch=12
05/28/2022 16:33:28 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.06 on epoch=12
05/28/2022 16:34:19 - INFO - __main__ - Global step 1450 Train loss 0.08 Classification-F1 0.4856136538768641 on epoch=12
05/28/2022 16:34:21 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.13 on epoch=13
05/28/2022 16:34:24 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.11 on epoch=13
05/28/2022 16:34:26 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.11 on epoch=13
05/28/2022 16:34:29 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.07 on epoch=13
05/28/2022 16:34:31 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.12 on epoch=13
05/28/2022 16:35:22 - INFO - __main__ - Global step 1500 Train loss 0.11 Classification-F1 0.4750859681560625 on epoch=13
05/28/2022 16:35:24 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.03 on epoch=13
05/28/2022 16:35:27 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.07 on epoch=13
05/28/2022 16:35:29 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.06 on epoch=13
05/28/2022 16:35:32 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=13
05/28/2022 16:35:34 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.08 on epoch=13
05/28/2022 16:36:25 - INFO - __main__ - Global step 1550 Train loss 0.06 Classification-F1 0.49790320162333496 on epoch=13
05/28/2022 16:36:27 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.06 on epoch=13
05/28/2022 16:36:30 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.13 on epoch=14
05/28/2022 16:36:32 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.08 on epoch=14
05/28/2022 16:36:35 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.14 on epoch=14
05/28/2022 16:36:38 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.04 on epoch=14
05/28/2022 16:37:28 - INFO - __main__ - Global step 1600 Train loss 0.09 Classification-F1 0.5405776013473008 on epoch=14
05/28/2022 16:37:30 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.08 on epoch=14
05/28/2022 16:37:33 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.05 on epoch=14
05/28/2022 16:37:35 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.03 on epoch=14
05/28/2022 16:37:38 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.06 on epoch=14
05/28/2022 16:37:40 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.07 on epoch=14
05/28/2022 16:38:29 - INFO - __main__ - Global step 1650 Train loss 0.06 Classification-F1 0.5131979621050782 on epoch=14
05/28/2022 16:38:32 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.07 on epoch=14
05/28/2022 16:38:35 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.09 on epoch=14
05/28/2022 16:38:37 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.14 on epoch=14
05/28/2022 16:38:40 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.05 on epoch=15
05/28/2022 16:38:42 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.09 on epoch=15
05/28/2022 16:39:32 - INFO - __main__ - Global step 1700 Train loss 0.09 Classification-F1 0.5864647499372206 on epoch=15
05/28/2022 16:39:34 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.04 on epoch=15
05/28/2022 16:39:37 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.04 on epoch=15
05/28/2022 16:39:40 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.11 on epoch=15
05/28/2022 16:39:42 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=15
05/28/2022 16:39:45 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.06 on epoch=15
05/28/2022 16:40:35 - INFO - __main__ - Global step 1750 Train loss 0.06 Classification-F1 0.5361611848843831 on epoch=15
05/28/2022 16:40:38 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.05 on epoch=15
05/28/2022 16:40:40 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.07 on epoch=15
05/28/2022 16:40:43 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.04 on epoch=15
05/28/2022 16:40:45 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.14 on epoch=15
05/28/2022 16:40:48 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=16
05/28/2022 16:41:39 - INFO - __main__ - Global step 1800 Train loss 0.07 Classification-F1 0.4663082807056971 on epoch=16
05/28/2022 16:41:41 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.07 on epoch=16
05/28/2022 16:41:44 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.06 on epoch=16
05/28/2022 16:41:46 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.07 on epoch=16
05/28/2022 16:41:49 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.05 on epoch=16
05/28/2022 16:41:52 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=16
05/28/2022 16:42:43 - INFO - __main__ - Global step 1850 Train loss 0.06 Classification-F1 0.5643474133383942 on epoch=16
05/28/2022 16:42:45 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.06 on epoch=16
05/28/2022 16:42:48 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.09 on epoch=16
05/28/2022 16:42:50 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.04 on epoch=16
05/28/2022 16:42:53 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.03 on epoch=16
05/28/2022 16:42:55 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.08 on epoch=16
05/28/2022 16:43:46 - INFO - __main__ - Global step 1900 Train loss 0.06 Classification-F1 0.48986796813274974 on epoch=16
05/28/2022 16:43:48 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.05 on epoch=17
05/28/2022 16:43:51 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=17
05/28/2022 16:43:53 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.05 on epoch=17
05/28/2022 16:43:56 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.08 on epoch=17
05/28/2022 16:43:58 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.06 on epoch=17
05/28/2022 16:44:48 - INFO - __main__ - Global step 1950 Train loss 0.05 Classification-F1 0.5675305366906997 on epoch=17
05/28/2022 16:44:51 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.05 on epoch=17
05/28/2022 16:44:53 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.04 on epoch=17
05/28/2022 16:44:56 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.05 on epoch=17
05/28/2022 16:44:58 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.04 on epoch=17
05/28/2022 16:45:01 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.08 on epoch=17
05/28/2022 16:45:51 - INFO - __main__ - Global step 2000 Train loss 0.05 Classification-F1 0.5071735142530835 on epoch=17
05/28/2022 16:45:54 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.04 on epoch=17
05/28/2022 16:45:57 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.07 on epoch=18
05/28/2022 16:45:59 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.05 on epoch=18
05/28/2022 16:46:02 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.07 on epoch=18
05/28/2022 16:46:04 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.02 on epoch=18
05/28/2022 16:46:54 - INFO - __main__ - Global step 2050 Train loss 0.05 Classification-F1 0.5207244871071193 on epoch=18
05/28/2022 16:46:57 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.07 on epoch=18
05/28/2022 16:46:59 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.03 on epoch=18
05/28/2022 16:47:02 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.03 on epoch=18
05/28/2022 16:47:04 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.08 on epoch=18
05/28/2022 16:47:07 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.06 on epoch=18
05/28/2022 16:47:57 - INFO - __main__ - Global step 2100 Train loss 0.05 Classification-F1 0.5475598358483004 on epoch=18
05/28/2022 16:47:59 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.03 on epoch=18
05/28/2022 16:48:02 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.04 on epoch=18
05/28/2022 16:48:04 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.07 on epoch=19
05/28/2022 16:48:07 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=19
05/28/2022 16:48:10 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.12 on epoch=19
05/28/2022 16:48:58 - INFO - __main__ - Global step 2150 Train loss 0.06 Classification-F1 0.5108827813225462 on epoch=19
05/28/2022 16:49:01 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=19
05/28/2022 16:49:04 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.07 on epoch=19
05/28/2022 16:49:06 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.05 on epoch=19
05/28/2022 16:49:09 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.05 on epoch=19
05/28/2022 16:49:11 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.05 on epoch=19
05/28/2022 16:50:00 - INFO - __main__ - Global step 2200 Train loss 0.05 Classification-F1 0.4852193051989308 on epoch=19
05/28/2022 16:50:02 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=19
05/28/2022 16:50:05 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=19
05/28/2022 16:50:07 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=19
05/28/2022 16:50:10 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.11 on epoch=19
05/28/2022 16:50:13 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.03 on epoch=20
05/28/2022 16:51:02 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.4722277126474279 on epoch=20
05/28/2022 16:51:04 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.06 on epoch=20
05/28/2022 16:51:07 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.03 on epoch=20
05/28/2022 16:51:09 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.07 on epoch=20
05/28/2022 16:51:12 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.08 on epoch=20
05/28/2022 16:51:14 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=20
05/28/2022 16:52:04 - INFO - __main__ - Global step 2300 Train loss 0.05 Classification-F1 0.5793219339351948 on epoch=20
05/28/2022 16:52:06 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.06 on epoch=20
05/28/2022 16:52:09 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.06 on epoch=20
05/28/2022 16:52:12 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.04 on epoch=20
05/28/2022 16:52:14 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=20
05/28/2022 16:52:17 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.05 on epoch=20
05/28/2022 16:53:06 - INFO - __main__ - Global step 2350 Train loss 0.05 Classification-F1 0.5160618829956082 on epoch=20
05/28/2022 16:53:09 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=21
05/28/2022 16:53:11 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.05 on epoch=21
05/28/2022 16:53:14 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.12 on epoch=21
05/28/2022 16:53:17 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.04 on epoch=21
05/28/2022 16:53:19 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.06 on epoch=21
05/28/2022 16:54:08 - INFO - __main__ - Global step 2400 Train loss 0.06 Classification-F1 0.5719285006095893 on epoch=21
05/28/2022 16:54:11 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=21
05/28/2022 16:54:13 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.05 on epoch=21
05/28/2022 16:54:16 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=21
05/28/2022 16:54:18 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=21
05/28/2022 16:54:21 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=21
05/28/2022 16:55:10 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.5729483520751986 on epoch=21
05/28/2022 16:55:13 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.06 on epoch=21
05/28/2022 16:55:16 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=22
05/28/2022 16:55:18 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.04 on epoch=22
05/28/2022 16:55:21 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.06 on epoch=22
05/28/2022 16:55:23 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.03 on epoch=22
05/28/2022 16:56:14 - INFO - __main__ - Global step 2500 Train loss 0.04 Classification-F1 0.6012701394188862 on epoch=22
05/28/2022 16:56:16 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.04 on epoch=22
05/28/2022 16:56:19 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=22
05/28/2022 16:56:21 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.03 on epoch=22
05/28/2022 16:56:24 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=22
05/28/2022 16:56:26 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.05 on epoch=22
05/28/2022 16:57:16 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.570001420508733 on epoch=22
05/28/2022 16:57:18 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=22
05/28/2022 16:57:21 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.08 on epoch=22
05/28/2022 16:57:24 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.07 on epoch=23
05/28/2022 16:57:26 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.03 on epoch=23
05/28/2022 16:57:29 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.06 on epoch=23
05/28/2022 16:58:17 - INFO - __main__ - Global step 2600 Train loss 0.05 Classification-F1 0.6551621454311831 on epoch=23
05/28/2022 16:58:17 - INFO - __main__ - Saving model with best Classification-F1: 0.6404045850122854 -> 0.6551621454311831 on epoch=23, global_step=2600
05/28/2022 16:58:20 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=23
05/28/2022 16:58:23 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.10 on epoch=23
05/28/2022 16:58:25 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=23
05/28/2022 16:58:28 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=23
05/28/2022 16:58:30 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.04 on epoch=23
05/28/2022 16:59:19 - INFO - __main__ - Global step 2650 Train loss 0.04 Classification-F1 0.6000545762985579 on epoch=23
05/28/2022 16:59:22 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.04 on epoch=23
05/28/2022 16:59:24 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.03 on epoch=23
05/28/2022 16:59:27 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=23
05/28/2022 16:59:29 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.06 on epoch=24
05/28/2022 16:59:32 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.04 on epoch=24
05/28/2022 17:00:21 - INFO - __main__ - Global step 2700 Train loss 0.04 Classification-F1 0.4941575445794552 on epoch=24
05/28/2022 17:00:24 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.05 on epoch=24
05/28/2022 17:00:26 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.04 on epoch=24
05/28/2022 17:00:29 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.06 on epoch=24
05/28/2022 17:00:31 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=24
05/28/2022 17:00:34 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.03 on epoch=24
05/28/2022 17:01:23 - INFO - __main__ - Global step 2750 Train loss 0.04 Classification-F1 0.6094840910675922 on epoch=24
05/28/2022 17:01:26 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.05 on epoch=24
05/28/2022 17:01:28 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.03 on epoch=24
05/28/2022 17:01:31 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.03 on epoch=24
05/28/2022 17:01:33 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.03 on epoch=24
05/28/2022 17:01:36 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.07 on epoch=24
05/28/2022 17:02:25 - INFO - __main__ - Global step 2800 Train loss 0.04 Classification-F1 0.6073371532332428 on epoch=24
05/28/2022 17:02:27 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=25
05/28/2022 17:02:30 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.11 on epoch=25
05/28/2022 17:02:32 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=25
05/28/2022 17:02:35 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.03 on epoch=25
05/28/2022 17:02:38 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.03 on epoch=25
05/28/2022 17:03:27 - INFO - __main__ - Global step 2850 Train loss 0.04 Classification-F1 0.6028482184595497 on epoch=25
05/28/2022 17:03:30 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=25
05/28/2022 17:03:32 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=25
05/28/2022 17:03:35 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.05 on epoch=25
05/28/2022 17:03:37 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=25
05/28/2022 17:03:40 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.05 on epoch=25
05/28/2022 17:04:30 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.6341163782578628 on epoch=25
05/28/2022 17:04:32 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.05 on epoch=25
05/28/2022 17:04:35 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=26
05/28/2022 17:04:37 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=26
05/28/2022 17:04:40 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.04 on epoch=26
05/28/2022 17:04:43 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=26
05/28/2022 17:05:32 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.4199442716861767 on epoch=26
05/28/2022 17:05:34 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.10 on epoch=26
05/28/2022 17:05:37 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=26
05/28/2022 17:05:40 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.03 on epoch=26
05/28/2022 17:05:42 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.06 on epoch=26
05/28/2022 17:05:45 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=26
05/28/2022 17:05:46 - INFO - __main__ - Start tokenizing ... 1792 instances
05/28/2022 17:05:46 - INFO - __main__ - Printing 3 examples
05/28/2022 17:05:46 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
05/28/2022 17:05:46 - INFO - __main__ - ['Film']
05/28/2022 17:05:46 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/28/2022 17:05:46 - INFO - __main__ - ['Film']
05/28/2022 17:05:46 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/28/2022 17:05:46 - INFO - __main__ - ['Film']
05/28/2022 17:05:46 - INFO - __main__ - Tokenizing Input ...
05/28/2022 17:05:47 - INFO - __main__ - Tokenizing Output ...
05/28/2022 17:05:49 - INFO - __main__ - Loaded 1792 examples from train data
05/28/2022 17:05:49 - INFO - __main__ - Start tokenizing ... 1792 instances
05/28/2022 17:05:49 - INFO - __main__ - Printing 3 examples
05/28/2022 17:05:49 - INFO - __main__ -  [dbpedia_14] The Debt is a 2011 American/British drama-thriller film directed by John Madden from a screenplay by Matthew Vaughn Jane Goldman and Peter Straughan. It stars Helen Mirren Sam Worthington Jessica Chastain Ciarán Hinds Tom Wilkinson Marton Csokas and Jesper Christensen. It's a remake of the 2007 Israeli film Ha-Hov directed by Assaf BernsteinOriginally scheduled for a December 2010 release the film was released in the United States on August 31 2011.
05/28/2022 17:05:49 - INFO - __main__ - ['Film']
05/28/2022 17:05:49 - INFO - __main__ -  [dbpedia_14] Naga Bonar Jadi 2 (Naga Bonar Becomes 2) is 2007 comedy film directed by Deddy Mizwar. It is starring Deddy Mizwar Tora Sudiro Lukman Sardi Darius Sinathrya and Michael Muliardo. It is a sequel to the Indonesian film Nagabonar (1987).
05/28/2022 17:05:49 - INFO - __main__ - ['Film']
05/28/2022 17:05:49 - INFO - __main__ -  [dbpedia_14] La Garce is a 1984 French thriller film directed by Christine Pascal and starring Isabelle Huppert.
05/28/2022 17:05:49 - INFO - __main__ - ['Film']
05/28/2022 17:05:49 - INFO - __main__ - Tokenizing Input ...
05/28/2022 17:05:50 - INFO - __main__ - Tokenizing Output ...
05/28/2022 17:05:52 - INFO - __main__ - Loaded 1792 examples from dev data
05/28/2022 17:06:07 - INFO - __main__ - load prompt embedding from ckpt
05/28/2022 17:06:07 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/28/2022 17:06:07 - INFO - __main__ - Starting training!
05/28/2022 17:06:34 - INFO - __main__ - Global step 3000 Train loss 0.04 Classification-F1 0.5722418136759694 on epoch=26
05/28/2022 17:06:34 - INFO - __main__ - save last model!
05/28/2022 17:06:34 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/28/2022 17:06:34 - INFO - __main__ - Start tokenizing ... 3500 instances
05/28/2022 17:06:34 - INFO - __main__ - Printing 3 examples
05/28/2022 17:06:34 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/28/2022 17:06:34 - INFO - __main__ - ['Animal']
05/28/2022 17:06:34 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/28/2022 17:06:34 - INFO - __main__ - ['Animal']
05/28/2022 17:06:34 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/28/2022 17:06:34 - INFO - __main__ - ['Village']
05/28/2022 17:06:34 - INFO - __main__ - Tokenizing Input ...
05/28/2022 17:06:36 - INFO - __main__ - Tokenizing Output ...
05/28/2022 17:06:39 - INFO - __main__ - Loaded 3500 examples from test data
05/28/2022 17:08:44 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down128shot/singletask-dbpedia_14/dbpedia_14_128_87_0.4_8_predictions.txt
05/28/2022 17:08:44 - INFO - __main__ - Classification-F1 on test data: 0.5049
05/28/2022 17:08:45 - INFO - __main__ - prefix=dbpedia_14_128_87, lr=0.4, bsz=8, dev_performance=0.6551621454311831, test_performance=0.5048636988419051
05/28/2022 17:08:45 - INFO - __main__ - Running ... prefix=dbpedia_14_128_87, lr=0.3, bsz=8 ...
05/28/2022 17:08:46 - INFO - __main__ - Start tokenizing ... 1792 instances
05/28/2022 17:08:46 - INFO - __main__ - Printing 3 examples
05/28/2022 17:08:46 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
05/28/2022 17:08:46 - INFO - __main__ - ['Film']
05/28/2022 17:08:46 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/28/2022 17:08:46 - INFO - __main__ - ['Film']
05/28/2022 17:08:46 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/28/2022 17:08:46 - INFO - __main__ - ['Film']
05/28/2022 17:08:46 - INFO - __main__ - Tokenizing Input ...
05/28/2022 17:08:47 - INFO - __main__ - Tokenizing Output ...
05/28/2022 17:08:48 - INFO - __main__ - Loaded 1792 examples from train data
05/28/2022 17:08:48 - INFO - __main__ - Start tokenizing ... 1792 instances
05/28/2022 17:08:48 - INFO - __main__ - Printing 3 examples
05/28/2022 17:08:48 - INFO - __main__ -  [dbpedia_14] The Debt is a 2011 American/British drama-thriller film directed by John Madden from a screenplay by Matthew Vaughn Jane Goldman and Peter Straughan. It stars Helen Mirren Sam Worthington Jessica Chastain Ciarán Hinds Tom Wilkinson Marton Csokas and Jesper Christensen. It's a remake of the 2007 Israeli film Ha-Hov directed by Assaf BernsteinOriginally scheduled for a December 2010 release the film was released in the United States on August 31 2011.
05/28/2022 17:08:48 - INFO - __main__ - ['Film']
05/28/2022 17:08:48 - INFO - __main__ -  [dbpedia_14] Naga Bonar Jadi 2 (Naga Bonar Becomes 2) is 2007 comedy film directed by Deddy Mizwar. It is starring Deddy Mizwar Tora Sudiro Lukman Sardi Darius Sinathrya and Michael Muliardo. It is a sequel to the Indonesian film Nagabonar (1987).
05/28/2022 17:08:48 - INFO - __main__ - ['Film']
05/28/2022 17:08:48 - INFO - __main__ -  [dbpedia_14] La Garce is a 1984 French thriller film directed by Christine Pascal and starring Isabelle Huppert.
05/28/2022 17:08:48 - INFO - __main__ - ['Film']
05/28/2022 17:08:48 - INFO - __main__ - Tokenizing Input ...
05/28/2022 17:08:49 - INFO - __main__ - Tokenizing Output ...
05/28/2022 17:08:51 - INFO - __main__ - Loaded 1792 examples from dev data
05/28/2022 17:09:07 - INFO - __main__ - load prompt embedding from ckpt
05/28/2022 17:09:08 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/28/2022 17:09:08 - INFO - __main__ - Starting training!
05/28/2022 17:09:12 - INFO - __main__ - Step 10 Global step 10 Train loss 7.38 on epoch=0
05/28/2022 17:09:14 - INFO - __main__ - Step 20 Global step 20 Train loss 5.25 on epoch=0
05/28/2022 17:09:17 - INFO - __main__ - Step 30 Global step 30 Train loss 4.47 on epoch=0
05/28/2022 17:09:20 - INFO - __main__ - Step 40 Global step 40 Train loss 3.75 on epoch=0
05/28/2022 17:09:22 - INFO - __main__ - Step 50 Global step 50 Train loss 3.61 on epoch=0
05/28/2022 17:10:12 - INFO - __main__ - Global step 50 Train loss 4.89 Classification-F1 0.010714800436157844 on epoch=0
05/28/2022 17:10:12 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.010714800436157844 on epoch=0, global_step=50
05/28/2022 17:10:15 - INFO - __main__ - Step 60 Global step 60 Train loss 3.20 on epoch=0
05/28/2022 17:10:18 - INFO - __main__ - Step 70 Global step 70 Train loss 3.42 on epoch=0
05/28/2022 17:10:20 - INFO - __main__ - Step 80 Global step 80 Train loss 2.78 on epoch=0
05/28/2022 17:10:23 - INFO - __main__ - Step 90 Global step 90 Train loss 2.78 on epoch=0
05/28/2022 17:10:25 - INFO - __main__ - Step 100 Global step 100 Train loss 2.47 on epoch=0
05/28/2022 17:11:16 - INFO - __main__ - Global step 100 Train loss 2.93 Classification-F1 0.020001943397233535 on epoch=0
05/28/2022 17:11:16 - INFO - __main__ - Saving model with best Classification-F1: 0.010714800436157844 -> 0.020001943397233535 on epoch=0, global_step=100
05/28/2022 17:11:19 - INFO - __main__ - Step 110 Global step 110 Train loss 2.38 on epoch=0
05/28/2022 17:11:21 - INFO - __main__ - Step 120 Global step 120 Train loss 2.16 on epoch=1
05/28/2022 17:11:24 - INFO - __main__ - Step 130 Global step 130 Train loss 2.09 on epoch=1
05/28/2022 17:11:27 - INFO - __main__ - Step 140 Global step 140 Train loss 1.88 on epoch=1
05/28/2022 17:11:29 - INFO - __main__ - Step 150 Global step 150 Train loss 1.48 on epoch=1
05/28/2022 17:12:15 - INFO - __main__ - Global step 150 Train loss 2.00 Classification-F1 0.04074576069837357 on epoch=1
05/28/2022 17:12:15 - INFO - __main__ - Saving model with best Classification-F1: 0.020001943397233535 -> 0.04074576069837357 on epoch=1, global_step=150
05/28/2022 17:12:18 - INFO - __main__ - Step 160 Global step 160 Train loss 1.74 on epoch=1
05/28/2022 17:12:21 - INFO - __main__ - Step 170 Global step 170 Train loss 1.74 on epoch=1
05/28/2022 17:12:23 - INFO - __main__ - Step 180 Global step 180 Train loss 1.72 on epoch=1
05/28/2022 17:12:26 - INFO - __main__ - Step 190 Global step 190 Train loss 1.49 on epoch=1
05/28/2022 17:12:29 - INFO - __main__ - Step 200 Global step 200 Train loss 1.43 on epoch=1
05/28/2022 17:13:13 - INFO - __main__ - Global step 200 Train loss 1.62 Classification-F1 0.08249893805538439 on epoch=1
05/28/2022 17:13:13 - INFO - __main__ - Saving model with best Classification-F1: 0.04074576069837357 -> 0.08249893805538439 on epoch=1, global_step=200
05/28/2022 17:13:15 - INFO - __main__ - Step 210 Global step 210 Train loss 1.42 on epoch=1
05/28/2022 17:13:18 - INFO - __main__ - Step 220 Global step 220 Train loss 1.24 on epoch=1
05/28/2022 17:13:21 - INFO - __main__ - Step 230 Global step 230 Train loss 1.13 on epoch=2
05/28/2022 17:13:23 - INFO - __main__ - Step 240 Global step 240 Train loss 1.21 on epoch=2
05/28/2022 17:13:26 - INFO - __main__ - Step 250 Global step 250 Train loss 0.93 on epoch=2
05/28/2022 17:14:11 - INFO - __main__ - Global step 250 Train loss 1.18 Classification-F1 0.11239287493925444 on epoch=2
05/28/2022 17:14:11 - INFO - __main__ - Saving model with best Classification-F1: 0.08249893805538439 -> 0.11239287493925444 on epoch=2, global_step=250
05/28/2022 17:14:14 - INFO - __main__ - Step 260 Global step 260 Train loss 0.85 on epoch=2
05/28/2022 17:14:17 - INFO - __main__ - Step 270 Global step 270 Train loss 0.90 on epoch=2
05/28/2022 17:14:19 - INFO - __main__ - Step 280 Global step 280 Train loss 0.84 on epoch=2
05/28/2022 17:14:22 - INFO - __main__ - Step 290 Global step 290 Train loss 0.90 on epoch=2
05/28/2022 17:14:24 - INFO - __main__ - Step 300 Global step 300 Train loss 0.81 on epoch=2
05/28/2022 17:15:11 - INFO - __main__ - Global step 300 Train loss 0.86 Classification-F1 0.19652358923206373 on epoch=2
05/28/2022 17:15:11 - INFO - __main__ - Saving model with best Classification-F1: 0.11239287493925444 -> 0.19652358923206373 on epoch=2, global_step=300
05/28/2022 17:15:13 - INFO - __main__ - Step 310 Global step 310 Train loss 0.84 on epoch=2
05/28/2022 17:15:16 - INFO - __main__ - Step 320 Global step 320 Train loss 0.68 on epoch=2
05/28/2022 17:15:19 - INFO - __main__ - Step 330 Global step 330 Train loss 0.69 on epoch=2
05/28/2022 17:15:21 - INFO - __main__ - Step 340 Global step 340 Train loss 0.67 on epoch=3
05/28/2022 17:15:24 - INFO - __main__ - Step 350 Global step 350 Train loss 0.62 on epoch=3
05/28/2022 17:16:14 - INFO - __main__ - Global step 350 Train loss 0.70 Classification-F1 0.1967480621690219 on epoch=3
05/28/2022 17:16:14 - INFO - __main__ - Saving model with best Classification-F1: 0.19652358923206373 -> 0.1967480621690219 on epoch=3, global_step=350
05/28/2022 17:16:17 - INFO - __main__ - Step 360 Global step 360 Train loss 0.57 on epoch=3
05/28/2022 17:16:20 - INFO - __main__ - Step 370 Global step 370 Train loss 0.44 on epoch=3
05/28/2022 17:16:22 - INFO - __main__ - Step 380 Global step 380 Train loss 0.49 on epoch=3
05/28/2022 17:16:25 - INFO - __main__ - Step 390 Global step 390 Train loss 0.52 on epoch=3
05/28/2022 17:16:27 - INFO - __main__ - Step 400 Global step 400 Train loss 0.54 on epoch=3
05/28/2022 17:17:19 - INFO - __main__ - Global step 400 Train loss 0.51 Classification-F1 0.2304334415102041 on epoch=3
05/28/2022 17:17:19 - INFO - __main__ - Saving model with best Classification-F1: 0.1967480621690219 -> 0.2304334415102041 on epoch=3, global_step=400
05/28/2022 17:17:21 - INFO - __main__ - Step 410 Global step 410 Train loss 0.48 on epoch=3
05/28/2022 17:17:24 - INFO - __main__ - Step 420 Global step 420 Train loss 0.49 on epoch=3
05/28/2022 17:17:27 - INFO - __main__ - Step 430 Global step 430 Train loss 0.56 on epoch=3
05/28/2022 17:17:29 - INFO - __main__ - Step 440 Global step 440 Train loss 0.45 on epoch=3
05/28/2022 17:17:32 - INFO - __main__ - Step 450 Global step 450 Train loss 0.51 on epoch=4
05/28/2022 17:18:24 - INFO - __main__ - Global step 450 Train loss 0.50 Classification-F1 0.2927782576803775 on epoch=4
05/28/2022 17:18:24 - INFO - __main__ - Saving model with best Classification-F1: 0.2304334415102041 -> 0.2927782576803775 on epoch=4, global_step=450
05/28/2022 17:18:26 - INFO - __main__ - Step 460 Global step 460 Train loss 0.48 on epoch=4
05/28/2022 17:18:29 - INFO - __main__ - Step 470 Global step 470 Train loss 0.52 on epoch=4
05/28/2022 17:18:32 - INFO - __main__ - Step 480 Global step 480 Train loss 0.39 on epoch=4
05/28/2022 17:18:34 - INFO - __main__ - Step 490 Global step 490 Train loss 0.36 on epoch=4
05/28/2022 17:18:37 - INFO - __main__ - Step 500 Global step 500 Train loss 0.37 on epoch=4
05/28/2022 17:19:28 - INFO - __main__ - Global step 500 Train loss 0.42 Classification-F1 0.2867177908434214 on epoch=4
05/28/2022 17:19:31 - INFO - __main__ - Step 510 Global step 510 Train loss 0.33 on epoch=4
05/28/2022 17:19:33 - INFO - __main__ - Step 520 Global step 520 Train loss 0.37 on epoch=4
05/28/2022 17:19:36 - INFO - __main__ - Step 530 Global step 530 Train loss 0.41 on epoch=4
05/28/2022 17:19:39 - INFO - __main__ - Step 540 Global step 540 Train loss 0.35 on epoch=4
05/28/2022 17:19:41 - INFO - __main__ - Step 550 Global step 550 Train loss 0.45 on epoch=4
05/28/2022 17:20:33 - INFO - __main__ - Global step 550 Train loss 0.38 Classification-F1 0.3965600586764997 on epoch=4
05/28/2022 17:20:33 - INFO - __main__ - Saving model with best Classification-F1: 0.2927782576803775 -> 0.3965600586764997 on epoch=4, global_step=550
05/28/2022 17:20:35 - INFO - __main__ - Step 560 Global step 560 Train loss 0.38 on epoch=4
05/28/2022 17:20:38 - INFO - __main__ - Step 570 Global step 570 Train loss 0.40 on epoch=5
05/28/2022 17:20:41 - INFO - __main__ - Step 580 Global step 580 Train loss 0.33 on epoch=5
05/28/2022 17:20:43 - INFO - __main__ - Step 590 Global step 590 Train loss 0.32 on epoch=5
05/28/2022 17:20:46 - INFO - __main__ - Step 600 Global step 600 Train loss 0.26 on epoch=5
05/28/2022 17:21:38 - INFO - __main__ - Global step 600 Train loss 0.34 Classification-F1 0.419958255445885 on epoch=5
05/28/2022 17:21:38 - INFO - __main__ - Saving model with best Classification-F1: 0.3965600586764997 -> 0.419958255445885 on epoch=5, global_step=600
05/28/2022 17:21:40 - INFO - __main__ - Step 610 Global step 610 Train loss 0.33 on epoch=5
05/28/2022 17:21:43 - INFO - __main__ - Step 620 Global step 620 Train loss 0.29 on epoch=5
05/28/2022 17:21:46 - INFO - __main__ - Step 630 Global step 630 Train loss 0.26 on epoch=5
05/28/2022 17:21:48 - INFO - __main__ - Step 640 Global step 640 Train loss 0.33 on epoch=5
05/28/2022 17:21:51 - INFO - __main__ - Step 650 Global step 650 Train loss 0.28 on epoch=5
05/28/2022 17:22:42 - INFO - __main__ - Global step 650 Train loss 0.30 Classification-F1 0.4604771451715462 on epoch=5
05/28/2022 17:22:42 - INFO - __main__ - Saving model with best Classification-F1: 0.419958255445885 -> 0.4604771451715462 on epoch=5, global_step=650
05/28/2022 17:22:45 - INFO - __main__ - Step 660 Global step 660 Train loss 0.19 on epoch=5
05/28/2022 17:22:48 - INFO - __main__ - Step 670 Global step 670 Train loss 0.45 on epoch=5
05/28/2022 17:22:50 - INFO - __main__ - Step 680 Global step 680 Train loss 0.22 on epoch=6
05/28/2022 17:22:53 - INFO - __main__ - Step 690 Global step 690 Train loss 0.35 on epoch=6
05/28/2022 17:22:56 - INFO - __main__ - Step 700 Global step 700 Train loss 0.18 on epoch=6
05/28/2022 17:23:48 - INFO - __main__ - Global step 700 Train loss 0.28 Classification-F1 0.47450983465374047 on epoch=6
05/28/2022 17:23:48 - INFO - __main__ - Saving model with best Classification-F1: 0.4604771451715462 -> 0.47450983465374047 on epoch=6, global_step=700
05/28/2022 17:23:51 - INFO - __main__ - Step 710 Global step 710 Train loss 0.19 on epoch=6
05/28/2022 17:23:53 - INFO - __main__ - Step 720 Global step 720 Train loss 0.23 on epoch=6
05/28/2022 17:23:56 - INFO - __main__ - Step 730 Global step 730 Train loss 0.21 on epoch=6
05/28/2022 17:23:59 - INFO - __main__ - Step 740 Global step 740 Train loss 0.34 on epoch=6
05/28/2022 17:24:01 - INFO - __main__ - Step 750 Global step 750 Train loss 0.25 on epoch=6
05/28/2022 17:24:54 - INFO - __main__ - Global step 750 Train loss 0.24 Classification-F1 0.4480013123222112 on epoch=6
05/28/2022 17:24:56 - INFO - __main__ - Step 760 Global step 760 Train loss 0.25 on epoch=6
05/28/2022 17:24:59 - INFO - __main__ - Step 770 Global step 770 Train loss 0.25 on epoch=6
05/28/2022 17:25:02 - INFO - __main__ - Step 780 Global step 780 Train loss 0.27 on epoch=6
05/28/2022 17:25:04 - INFO - __main__ - Step 790 Global step 790 Train loss 0.25 on epoch=7
05/28/2022 17:25:07 - INFO - __main__ - Step 800 Global step 800 Train loss 0.17 on epoch=7
05/28/2022 17:26:00 - INFO - __main__ - Global step 800 Train loss 0.24 Classification-F1 0.438892068820884 on epoch=7
05/28/2022 17:26:02 - INFO - __main__ - Step 810 Global step 810 Train loss 0.19 on epoch=7
05/28/2022 17:26:05 - INFO - __main__ - Step 820 Global step 820 Train loss 0.19 on epoch=7
05/28/2022 17:26:08 - INFO - __main__ - Step 830 Global step 830 Train loss 0.25 on epoch=7
05/28/2022 17:26:10 - INFO - __main__ - Step 840 Global step 840 Train loss 0.11 on epoch=7
05/28/2022 17:26:13 - INFO - __main__ - Step 850 Global step 850 Train loss 0.18 on epoch=7
05/28/2022 17:27:07 - INFO - __main__ - Global step 850 Train loss 0.18 Classification-F1 0.5473628926476382 on epoch=7
05/28/2022 17:27:07 - INFO - __main__ - Saving model with best Classification-F1: 0.47450983465374047 -> 0.5473628926476382 on epoch=7, global_step=850
05/28/2022 17:27:09 - INFO - __main__ - Step 860 Global step 860 Train loss 0.19 on epoch=7
05/28/2022 17:27:12 - INFO - __main__ - Step 870 Global step 870 Train loss 0.19 on epoch=7
05/28/2022 17:27:15 - INFO - __main__ - Step 880 Global step 880 Train loss 0.21 on epoch=7
05/28/2022 17:27:17 - INFO - __main__ - Step 890 Global step 890 Train loss 0.23 on epoch=7
05/28/2022 17:27:20 - INFO - __main__ - Step 900 Global step 900 Train loss 0.24 on epoch=8
05/28/2022 17:28:13 - INFO - __main__ - Global step 900 Train loss 0.21 Classification-F1 0.5853215557867537 on epoch=8
05/28/2022 17:28:13 - INFO - __main__ - Saving model with best Classification-F1: 0.5473628926476382 -> 0.5853215557867537 on epoch=8, global_step=900
05/28/2022 17:28:16 - INFO - __main__ - Step 910 Global step 910 Train loss 0.15 on epoch=8
05/28/2022 17:28:18 - INFO - __main__ - Step 920 Global step 920 Train loss 0.22 on epoch=8
05/28/2022 17:28:21 - INFO - __main__ - Step 930 Global step 930 Train loss 0.16 on epoch=8
05/28/2022 17:28:23 - INFO - __main__ - Step 940 Global step 940 Train loss 0.16 on epoch=8
05/28/2022 17:28:26 - INFO - __main__ - Step 950 Global step 950 Train loss 0.16 on epoch=8
05/28/2022 17:29:17 - INFO - __main__ - Global step 950 Train loss 0.17 Classification-F1 0.4954325830177376 on epoch=8
05/28/2022 17:29:20 - INFO - __main__ - Step 960 Global step 960 Train loss 0.17 on epoch=8
05/28/2022 17:29:23 - INFO - __main__ - Step 970 Global step 970 Train loss 0.16 on epoch=8
05/28/2022 17:29:25 - INFO - __main__ - Step 980 Global step 980 Train loss 0.17 on epoch=8
05/28/2022 17:29:28 - INFO - __main__ - Step 990 Global step 990 Train loss 0.17 on epoch=8
05/28/2022 17:29:30 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.18 on epoch=8
05/28/2022 17:30:22 - INFO - __main__ - Global step 1000 Train loss 0.17 Classification-F1 0.49450554360451704 on epoch=8
05/28/2022 17:30:24 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.19 on epoch=9
05/28/2022 17:30:27 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.11 on epoch=9
05/28/2022 17:30:29 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.18 on epoch=9
05/28/2022 17:30:32 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.14 on epoch=9
05/28/2022 17:30:35 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.22 on epoch=9
05/28/2022 17:31:25 - INFO - __main__ - Global step 1050 Train loss 0.17 Classification-F1 0.48994983119910523 on epoch=9
05/28/2022 17:31:28 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.10 on epoch=9
05/28/2022 17:31:30 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.10 on epoch=9
05/28/2022 17:31:33 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.16 on epoch=9
05/28/2022 17:31:35 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.15 on epoch=9
05/28/2022 17:31:38 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.11 on epoch=9
05/28/2022 17:32:30 - INFO - __main__ - Global step 1100 Train loss 0.13 Classification-F1 0.5393453563678108 on epoch=9
05/28/2022 17:32:33 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.06 on epoch=9
05/28/2022 17:32:36 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.24 on epoch=9
05/28/2022 17:32:38 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.14 on epoch=10
05/28/2022 17:32:41 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.18 on epoch=10
05/28/2022 17:32:44 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.11 on epoch=10
05/28/2022 17:33:34 - INFO - __main__ - Global step 1150 Train loss 0.15 Classification-F1 0.5356326582340816 on epoch=10
05/28/2022 17:33:36 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.12 on epoch=10
05/28/2022 17:33:39 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.19 on epoch=10
05/28/2022 17:33:41 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.13 on epoch=10
05/28/2022 17:33:44 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.14 on epoch=10
05/28/2022 17:33:47 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.11 on epoch=10
05/28/2022 17:34:38 - INFO - __main__ - Global step 1200 Train loss 0.14 Classification-F1 0.5685013287482502 on epoch=10
05/28/2022 17:34:41 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.17 on epoch=10
05/28/2022 17:34:44 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.11 on epoch=10
05/28/2022 17:34:46 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.23 on epoch=10
05/28/2022 17:34:49 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.10 on epoch=11
05/28/2022 17:34:52 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.07 on epoch=11
05/28/2022 17:35:43 - INFO - __main__ - Global step 1250 Train loss 0.14 Classification-F1 0.5690498885962808 on epoch=11
05/28/2022 17:35:45 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.12 on epoch=11
05/28/2022 17:35:48 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.12 on epoch=11
05/28/2022 17:35:51 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.14 on epoch=11
05/28/2022 17:35:53 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.10 on epoch=11
05/28/2022 17:35:56 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.14 on epoch=11
05/28/2022 17:36:47 - INFO - __main__ - Global step 1300 Train loss 0.13 Classification-F1 0.6406418110947434 on epoch=11
05/28/2022 17:36:48 - INFO - __main__ - Saving model with best Classification-F1: 0.5853215557867537 -> 0.6406418110947434 on epoch=11, global_step=1300
05/28/2022 17:36:50 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.15 on epoch=11
05/28/2022 17:36:53 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.15 on epoch=11
05/28/2022 17:36:55 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.17 on epoch=11
05/28/2022 17:36:58 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.18 on epoch=11
05/28/2022 17:37:01 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.06 on epoch=12
05/28/2022 17:37:50 - INFO - __main__ - Global step 1350 Train loss 0.14 Classification-F1 0.5188896990442068 on epoch=12
05/28/2022 17:37:53 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.11 on epoch=12
05/28/2022 17:37:56 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.16 on epoch=12
05/28/2022 17:37:58 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.12 on epoch=12
05/28/2022 17:38:01 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.13 on epoch=12
05/28/2022 17:38:04 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.08 on epoch=12
05/28/2022 17:38:54 - INFO - __main__ - Global step 1400 Train loss 0.12 Classification-F1 0.5582860693048223 on epoch=12
05/28/2022 17:38:56 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.11 on epoch=12
05/28/2022 17:38:59 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.08 on epoch=12
05/28/2022 17:39:02 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.15 on epoch=12
05/28/2022 17:39:04 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.08 on epoch=12
05/28/2022 17:39:07 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.09 on epoch=12
05/28/2022 17:39:57 - INFO - __main__ - Global step 1450 Train loss 0.10 Classification-F1 0.5835494346096753 on epoch=12
05/28/2022 17:40:00 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.18 on epoch=13
05/28/2022 17:40:02 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.10 on epoch=13
05/28/2022 17:40:05 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.13 on epoch=13
05/28/2022 17:40:07 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.11 on epoch=13
05/28/2022 17:40:10 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.12 on epoch=13
05/28/2022 17:41:00 - INFO - __main__ - Global step 1500 Train loss 0.13 Classification-F1 0.5406774718822849 on epoch=13
05/28/2022 17:41:03 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.08 on epoch=13
05/28/2022 17:41:05 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.08 on epoch=13
05/28/2022 17:41:08 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.16 on epoch=13
05/28/2022 17:41:11 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.10 on epoch=13
05/28/2022 17:41:13 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.10 on epoch=13
05/28/2022 17:42:03 - INFO - __main__ - Global step 1550 Train loss 0.10 Classification-F1 0.4933766961149001 on epoch=13
05/28/2022 17:42:05 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.09 on epoch=13
05/28/2022 17:42:08 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.09 on epoch=14
05/28/2022 17:42:10 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.06 on epoch=14
05/28/2022 17:42:13 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.15 on epoch=14
05/28/2022 17:42:16 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.05 on epoch=14
05/28/2022 17:43:06 - INFO - __main__ - Global step 1600 Train loss 0.09 Classification-F1 0.6145533316924733 on epoch=14
05/28/2022 17:43:09 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.10 on epoch=14
05/28/2022 17:43:11 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.07 on epoch=14
05/28/2022 17:43:14 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.06 on epoch=14
05/28/2022 17:43:16 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.13 on epoch=14
05/28/2022 17:43:19 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.11 on epoch=14
05/28/2022 17:44:09 - INFO - __main__ - Global step 1650 Train loss 0.09 Classification-F1 0.5004537283987065 on epoch=14
05/28/2022 17:44:11 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.06 on epoch=14
05/28/2022 17:44:14 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.05 on epoch=14
05/28/2022 17:44:16 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.11 on epoch=14
05/28/2022 17:44:19 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.08 on epoch=15
05/28/2022 17:44:21 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.11 on epoch=15
05/28/2022 17:45:12 - INFO - __main__ - Global step 1700 Train loss 0.08 Classification-F1 0.6843747517222989 on epoch=15
05/28/2022 17:45:12 - INFO - __main__ - Saving model with best Classification-F1: 0.6406418110947434 -> 0.6843747517222989 on epoch=15, global_step=1700
05/28/2022 17:45:14 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.06 on epoch=15
05/28/2022 17:45:17 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.11 on epoch=15
05/28/2022 17:45:20 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.10 on epoch=15
05/28/2022 17:45:22 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.08 on epoch=15
05/28/2022 17:45:25 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.09 on epoch=15
05/28/2022 17:46:15 - INFO - __main__ - Global step 1750 Train loss 0.09 Classification-F1 0.7165966159622069 on epoch=15
05/28/2022 17:46:15 - INFO - __main__ - Saving model with best Classification-F1: 0.6843747517222989 -> 0.7165966159622069 on epoch=15, global_step=1750
05/28/2022 17:46:18 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.07 on epoch=15
05/28/2022 17:46:20 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.10 on epoch=15
05/28/2022 17:46:23 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.13 on epoch=15
05/28/2022 17:46:25 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.09 on epoch=15
05/28/2022 17:46:28 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.08 on epoch=16
05/28/2022 17:47:17 - INFO - __main__ - Global step 1800 Train loss 0.10 Classification-F1 0.5168019264693865 on epoch=16
05/28/2022 17:47:19 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.11 on epoch=16
05/28/2022 17:47:22 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.04 on epoch=16
05/28/2022 17:47:25 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.04 on epoch=16
05/28/2022 17:47:27 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.13 on epoch=16
05/28/2022 17:47:30 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.05 on epoch=16
05/28/2022 17:48:20 - INFO - __main__ - Global step 1850 Train loss 0.07 Classification-F1 0.5695352587420871 on epoch=16
05/28/2022 17:48:22 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.07 on epoch=16
05/28/2022 17:48:25 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.05 on epoch=16
05/28/2022 17:48:27 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.11 on epoch=16
05/28/2022 17:48:30 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.08 on epoch=16
05/28/2022 17:48:32 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.09 on epoch=16
05/28/2022 17:49:22 - INFO - __main__ - Global step 1900 Train loss 0.08 Classification-F1 0.6164974050370866 on epoch=16
05/28/2022 17:49:25 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.07 on epoch=17
05/28/2022 17:49:27 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.05 on epoch=17
05/28/2022 17:49:30 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.10 on epoch=17
05/28/2022 17:49:33 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.04 on epoch=17
05/28/2022 17:49:35 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.07 on epoch=17
05/28/2022 17:50:24 - INFO - __main__ - Global step 1950 Train loss 0.07 Classification-F1 0.6477546507640266 on epoch=17
05/28/2022 17:50:27 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.04 on epoch=17
05/28/2022 17:50:29 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.10 on epoch=17
05/28/2022 17:50:32 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.07 on epoch=17
05/28/2022 17:50:35 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.07 on epoch=17
05/28/2022 17:50:37 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.07 on epoch=17
05/28/2022 17:51:25 - INFO - __main__ - Global step 2000 Train loss 0.07 Classification-F1 0.644632435148245 on epoch=17
05/28/2022 17:51:28 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.12 on epoch=17
05/28/2022 17:51:31 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.10 on epoch=18
05/28/2022 17:51:33 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.03 on epoch=18
05/28/2022 17:51:36 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.13 on epoch=18
05/28/2022 17:51:38 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.06 on epoch=18
05/28/2022 17:52:27 - INFO - __main__ - Global step 2050 Train loss 0.09 Classification-F1 0.7998080296983864 on epoch=18
05/28/2022 17:52:27 - INFO - __main__ - Saving model with best Classification-F1: 0.7165966159622069 -> 0.7998080296983864 on epoch=18, global_step=2050
05/28/2022 17:52:30 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.09 on epoch=18
05/28/2022 17:52:32 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.03 on epoch=18
05/28/2022 17:52:35 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.08 on epoch=18
05/28/2022 17:52:37 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.04 on epoch=18
05/28/2022 17:52:40 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.04 on epoch=18
05/28/2022 17:53:28 - INFO - __main__ - Global step 2100 Train loss 0.06 Classification-F1 0.7139035754119831 on epoch=18
05/28/2022 17:53:31 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.08 on epoch=18
05/28/2022 17:53:33 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.06 on epoch=18
05/28/2022 17:53:36 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.08 on epoch=19
05/28/2022 17:53:39 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.09 on epoch=19
05/28/2022 17:53:41 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.09 on epoch=19
05/28/2022 17:54:30 - INFO - __main__ - Global step 2150 Train loss 0.08 Classification-F1 0.7553854717446205 on epoch=19
05/28/2022 17:54:33 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.07 on epoch=19
05/28/2022 17:54:36 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.10 on epoch=19
05/28/2022 17:54:38 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.04 on epoch=19
05/28/2022 17:54:41 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.08 on epoch=19
05/28/2022 17:54:43 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.04 on epoch=19
05/28/2022 17:55:32 - INFO - __main__ - Global step 2200 Train loss 0.07 Classification-F1 0.7643635062108898 on epoch=19
05/28/2022 17:55:35 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.05 on epoch=19
05/28/2022 17:55:38 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.06 on epoch=19
05/28/2022 17:55:40 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.05 on epoch=19
05/28/2022 17:55:43 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.08 on epoch=19
05/28/2022 17:55:45 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.05 on epoch=20
05/28/2022 17:56:34 - INFO - __main__ - Global step 2250 Train loss 0.06 Classification-F1 0.8632226625268993 on epoch=20
05/28/2022 17:56:34 - INFO - __main__ - Saving model with best Classification-F1: 0.7998080296983864 -> 0.8632226625268993 on epoch=20, global_step=2250
05/28/2022 17:56:37 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.08 on epoch=20
05/28/2022 17:56:40 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.09 on epoch=20
05/28/2022 17:56:42 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.04 on epoch=20
05/28/2022 17:56:45 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.07 on epoch=20
05/28/2022 17:56:47 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.05 on epoch=20
05/28/2022 17:57:36 - INFO - __main__ - Global step 2300 Train loss 0.06 Classification-F1 0.7258596793113825 on epoch=20
05/28/2022 17:57:39 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.05 on epoch=20
05/28/2022 17:57:41 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=20
05/28/2022 17:57:44 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.05 on epoch=20
05/28/2022 17:57:47 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.06 on epoch=20
05/28/2022 17:57:49 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.10 on epoch=20
05/28/2022 17:58:37 - INFO - __main__ - Global step 2350 Train loss 0.06 Classification-F1 0.6814653988427356 on epoch=20
05/28/2022 17:58:40 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=21
05/28/2022 17:58:43 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.03 on epoch=21
05/28/2022 17:58:45 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.17 on epoch=21
05/28/2022 17:58:48 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=21
05/28/2022 17:58:50 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.14 on epoch=21
05/28/2022 17:59:39 - INFO - __main__ - Global step 2400 Train loss 0.08 Classification-F1 0.6693028415606436 on epoch=21
05/28/2022 17:59:41 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=21
05/28/2022 17:59:44 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.04 on epoch=21
05/28/2022 17:59:46 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.05 on epoch=21
05/28/2022 17:59:49 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.05 on epoch=21
05/28/2022 17:59:51 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.05 on epoch=21
05/28/2022 18:00:40 - INFO - __main__ - Global step 2450 Train loss 0.04 Classification-F1 0.719002445998188 on epoch=21
05/28/2022 18:00:43 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.12 on epoch=21
05/28/2022 18:00:45 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.05 on epoch=22
05/28/2022 18:00:48 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.07 on epoch=22
05/28/2022 18:00:50 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.15 on epoch=22
05/28/2022 18:00:53 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.03 on epoch=22
05/28/2022 18:01:41 - INFO - __main__ - Global step 2500 Train loss 0.09 Classification-F1 0.6823055681062428 on epoch=22
05/28/2022 18:01:44 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.06 on epoch=22
05/28/2022 18:01:46 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=22
05/28/2022 18:01:49 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.04 on epoch=22
05/28/2022 18:01:52 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.04 on epoch=22
05/28/2022 18:01:54 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=22
05/28/2022 18:02:42 - INFO - __main__ - Global step 2550 Train loss 0.04 Classification-F1 0.7604750482997846 on epoch=22
05/28/2022 18:02:45 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.04 on epoch=22
05/28/2022 18:02:47 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=22
05/28/2022 18:02:50 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.03 on epoch=23
05/28/2022 18:02:53 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.04 on epoch=23
05/28/2022 18:02:55 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.10 on epoch=23
05/28/2022 18:03:44 - INFO - __main__ - Global step 2600 Train loss 0.05 Classification-F1 0.7239231894397672 on epoch=23
05/28/2022 18:03:46 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=23
05/28/2022 18:03:49 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.05 on epoch=23
05/28/2022 18:03:52 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.09 on epoch=23
05/28/2022 18:03:54 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=23
05/28/2022 18:03:57 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.05 on epoch=23
05/28/2022 18:04:45 - INFO - __main__ - Global step 2650 Train loss 0.05 Classification-F1 0.6855235606315606 on epoch=23
05/28/2022 18:04:48 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=23
05/28/2022 18:04:50 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.07 on epoch=23
05/28/2022 18:04:53 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=23
05/28/2022 18:04:56 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.08 on epoch=24
05/28/2022 18:04:58 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.05 on epoch=24
05/28/2022 18:05:47 - INFO - __main__ - Global step 2700 Train loss 0.05 Classification-F1 0.7203264369960166 on epoch=24
05/28/2022 18:05:49 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.09 on epoch=24
05/28/2022 18:05:52 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.05 on epoch=24
05/28/2022 18:05:55 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.09 on epoch=24
05/28/2022 18:05:57 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.04 on epoch=24
05/28/2022 18:06:00 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=24
05/28/2022 18:06:48 - INFO - __main__ - Global step 2750 Train loss 0.06 Classification-F1 0.8077708888347869 on epoch=24
05/28/2022 18:06:51 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.04 on epoch=24
05/28/2022 18:06:53 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.05 on epoch=24
05/28/2022 18:06:56 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.08 on epoch=24
05/28/2022 18:06:58 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=24
05/28/2022 18:07:01 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.07 on epoch=24
05/28/2022 18:07:50 - INFO - __main__ - Global step 2800 Train loss 0.05 Classification-F1 0.7621271945931498 on epoch=24
05/28/2022 18:07:52 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.03 on epoch=25
05/28/2022 18:07:55 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.09 on epoch=25
05/28/2022 18:07:57 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.04 on epoch=25
05/28/2022 18:08:00 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=25
05/28/2022 18:08:02 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.11 on epoch=25
05/28/2022 18:08:51 - INFO - __main__ - Global step 2850 Train loss 0.06 Classification-F1 0.8040048116920326 on epoch=25
05/28/2022 18:08:53 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.06 on epoch=25
05/28/2022 18:08:56 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.04 on epoch=25
05/28/2022 18:08:58 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.06 on epoch=25
05/28/2022 18:09:01 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.05 on epoch=25
05/28/2022 18:09:04 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.04 on epoch=25
05/28/2022 18:09:52 - INFO - __main__ - Global step 2900 Train loss 0.05 Classification-F1 0.8103473279337035 on epoch=25
05/28/2022 18:09:54 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.14 on epoch=25
05/28/2022 18:09:57 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.03 on epoch=26
05/28/2022 18:10:00 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=26
05/28/2022 18:10:02 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.09 on epoch=26
05/28/2022 18:10:05 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=26
05/28/2022 18:10:53 - INFO - __main__ - Global step 2950 Train loss 0.06 Classification-F1 0.8109849116854707 on epoch=26
05/28/2022 18:10:56 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.08 on epoch=26
05/28/2022 18:10:58 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=26
05/28/2022 18:11:01 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.03 on epoch=26
05/28/2022 18:11:03 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.04 on epoch=26
05/28/2022 18:11:06 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.03 on epoch=26
05/28/2022 18:11:07 - INFO - __main__ - Start tokenizing ... 1792 instances
05/28/2022 18:11:07 - INFO - __main__ - Printing 3 examples
05/28/2022 18:11:07 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
05/28/2022 18:11:07 - INFO - __main__ - ['Film']
05/28/2022 18:11:07 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/28/2022 18:11:07 - INFO - __main__ - ['Film']
05/28/2022 18:11:07 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/28/2022 18:11:07 - INFO - __main__ - ['Film']
05/28/2022 18:11:07 - INFO - __main__ - Tokenizing Input ...
05/28/2022 18:11:08 - INFO - __main__ - Tokenizing Output ...
05/28/2022 18:11:10 - INFO - __main__ - Loaded 1792 examples from train data
05/28/2022 18:11:10 - INFO - __main__ - Start tokenizing ... 1792 instances
05/28/2022 18:11:10 - INFO - __main__ - Printing 3 examples
05/28/2022 18:11:10 - INFO - __main__ -  [dbpedia_14] The Debt is a 2011 American/British drama-thriller film directed by John Madden from a screenplay by Matthew Vaughn Jane Goldman and Peter Straughan. It stars Helen Mirren Sam Worthington Jessica Chastain Ciarán Hinds Tom Wilkinson Marton Csokas and Jesper Christensen. It's a remake of the 2007 Israeli film Ha-Hov directed by Assaf BernsteinOriginally scheduled for a December 2010 release the film was released in the United States on August 31 2011.
05/28/2022 18:11:10 - INFO - __main__ - ['Film']
05/28/2022 18:11:10 - INFO - __main__ -  [dbpedia_14] Naga Bonar Jadi 2 (Naga Bonar Becomes 2) is 2007 comedy film directed by Deddy Mizwar. It is starring Deddy Mizwar Tora Sudiro Lukman Sardi Darius Sinathrya and Michael Muliardo. It is a sequel to the Indonesian film Nagabonar (1987).
05/28/2022 18:11:10 - INFO - __main__ - ['Film']
05/28/2022 18:11:10 - INFO - __main__ -  [dbpedia_14] La Garce is a 1984 French thriller film directed by Christine Pascal and starring Isabelle Huppert.
05/28/2022 18:11:10 - INFO - __main__ - ['Film']
05/28/2022 18:11:10 - INFO - __main__ - Tokenizing Input ...
05/28/2022 18:11:11 - INFO - __main__ - Tokenizing Output ...
05/28/2022 18:11:13 - INFO - __main__ - Loaded 1792 examples from dev data
05/28/2022 18:11:31 - INFO - __main__ - load prompt embedding from ckpt
05/28/2022 18:11:32 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/28/2022 18:11:32 - INFO - __main__ - Starting training!
05/28/2022 18:11:54 - INFO - __main__ - Global step 3000 Train loss 0.04 Classification-F1 0.8100901566815532 on epoch=26
05/28/2022 18:11:54 - INFO - __main__ - save last model!
05/28/2022 18:11:54 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/28/2022 18:11:55 - INFO - __main__ - Start tokenizing ... 3500 instances
05/28/2022 18:11:55 - INFO - __main__ - Printing 3 examples
05/28/2022 18:11:55 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/28/2022 18:11:55 - INFO - __main__ - ['Animal']
05/28/2022 18:11:55 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/28/2022 18:11:55 - INFO - __main__ - ['Animal']
05/28/2022 18:11:55 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/28/2022 18:11:55 - INFO - __main__ - ['Village']
05/28/2022 18:11:55 - INFO - __main__ - Tokenizing Input ...
05/28/2022 18:11:56 - INFO - __main__ - Tokenizing Output ...
05/28/2022 18:12:00 - INFO - __main__ - Loaded 3500 examples from test data
05/28/2022 18:14:06 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down128shot/singletask-dbpedia_14/dbpedia_14_128_87_0.3_8_predictions.txt
05/28/2022 18:14:06 - INFO - __main__ - Classification-F1 on test data: 0.6228
05/28/2022 18:14:06 - INFO - __main__ - prefix=dbpedia_14_128_87, lr=0.3, bsz=8, dev_performance=0.8632226625268993, test_performance=0.622810641920562
05/28/2022 18:14:06 - INFO - __main__ - Running ... prefix=dbpedia_14_128_87, lr=0.2, bsz=8 ...
05/28/2022 18:14:07 - INFO - __main__ - Start tokenizing ... 1792 instances
05/28/2022 18:14:07 - INFO - __main__ - Printing 3 examples
05/28/2022 18:14:07 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
05/28/2022 18:14:07 - INFO - __main__ - ['Film']
05/28/2022 18:14:07 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/28/2022 18:14:07 - INFO - __main__ - ['Film']
05/28/2022 18:14:07 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/28/2022 18:14:07 - INFO - __main__ - ['Film']
05/28/2022 18:14:07 - INFO - __main__ - Tokenizing Input ...
05/28/2022 18:14:08 - INFO - __main__ - Tokenizing Output ...
05/28/2022 18:14:10 - INFO - __main__ - Loaded 1792 examples from train data
05/28/2022 18:14:10 - INFO - __main__ - Start tokenizing ... 1792 instances
05/28/2022 18:14:10 - INFO - __main__ - Printing 3 examples
05/28/2022 18:14:10 - INFO - __main__ -  [dbpedia_14] The Debt is a 2011 American/British drama-thriller film directed by John Madden from a screenplay by Matthew Vaughn Jane Goldman and Peter Straughan. It stars Helen Mirren Sam Worthington Jessica Chastain Ciarán Hinds Tom Wilkinson Marton Csokas and Jesper Christensen. It's a remake of the 2007 Israeli film Ha-Hov directed by Assaf BernsteinOriginally scheduled for a December 2010 release the film was released in the United States on August 31 2011.
05/28/2022 18:14:10 - INFO - __main__ - ['Film']
05/28/2022 18:14:10 - INFO - __main__ -  [dbpedia_14] Naga Bonar Jadi 2 (Naga Bonar Becomes 2) is 2007 comedy film directed by Deddy Mizwar. It is starring Deddy Mizwar Tora Sudiro Lukman Sardi Darius Sinathrya and Michael Muliardo. It is a sequel to the Indonesian film Nagabonar (1987).
05/28/2022 18:14:10 - INFO - __main__ - ['Film']
05/28/2022 18:14:10 - INFO - __main__ -  [dbpedia_14] La Garce is a 1984 French thriller film directed by Christine Pascal and starring Isabelle Huppert.
05/28/2022 18:14:10 - INFO - __main__ - ['Film']
05/28/2022 18:14:10 - INFO - __main__ - Tokenizing Input ...
05/28/2022 18:14:11 - INFO - __main__ - Tokenizing Output ...
05/28/2022 18:14:13 - INFO - __main__ - Loaded 1792 examples from dev data
05/28/2022 18:14:29 - INFO - __main__ - load prompt embedding from ckpt
05/28/2022 18:14:30 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/28/2022 18:14:30 - INFO - __main__ - Starting training!
05/28/2022 18:14:33 - INFO - __main__ - Step 10 Global step 10 Train loss 7.77 on epoch=0
05/28/2022 18:14:36 - INFO - __main__ - Step 20 Global step 20 Train loss 6.22 on epoch=0
05/28/2022 18:14:38 - INFO - __main__ - Step 30 Global step 30 Train loss 4.94 on epoch=0
05/28/2022 18:14:41 - INFO - __main__ - Step 40 Global step 40 Train loss 4.16 on epoch=0
05/28/2022 18:14:43 - INFO - __main__ - Step 50 Global step 50 Train loss 4.35 on epoch=0
05/28/2022 18:15:31 - INFO - __main__ - Global step 50 Train loss 5.49 Classification-F1 0.00803437573342691 on epoch=0
05/28/2022 18:15:31 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.00803437573342691 on epoch=0, global_step=50
05/28/2022 18:15:34 - INFO - __main__ - Step 60 Global step 60 Train loss 3.73 on epoch=0
05/28/2022 18:15:36 - INFO - __main__ - Step 70 Global step 70 Train loss 4.06 on epoch=0
05/28/2022 18:15:39 - INFO - __main__ - Step 80 Global step 80 Train loss 3.61 on epoch=0
05/28/2022 18:15:41 - INFO - __main__ - Step 90 Global step 90 Train loss 3.40 on epoch=0
05/28/2022 18:15:44 - INFO - __main__ - Step 100 Global step 100 Train loss 3.15 on epoch=0
05/28/2022 18:16:34 - INFO - __main__ - Global step 100 Train loss 3.59 Classification-F1 0.012259147158929555 on epoch=0
05/28/2022 18:16:34 - INFO - __main__ - Saving model with best Classification-F1: 0.00803437573342691 -> 0.012259147158929555 on epoch=0, global_step=100
05/28/2022 18:16:37 - INFO - __main__ - Step 110 Global step 110 Train loss 3.17 on epoch=0
05/28/2022 18:16:39 - INFO - __main__ - Step 120 Global step 120 Train loss 2.70 on epoch=1
05/28/2022 18:16:42 - INFO - __main__ - Step 130 Global step 130 Train loss 2.71 on epoch=1
05/28/2022 18:16:45 - INFO - __main__ - Step 140 Global step 140 Train loss 2.45 on epoch=1
05/28/2022 18:16:47 - INFO - __main__ - Step 150 Global step 150 Train loss 1.91 on epoch=1
05/28/2022 18:17:37 - INFO - __main__ - Global step 150 Train loss 2.59 Classification-F1 0.023474559684441204 on epoch=1
05/28/2022 18:17:37 - INFO - __main__ - Saving model with best Classification-F1: 0.012259147158929555 -> 0.023474559684441204 on epoch=1, global_step=150
05/28/2022 18:17:39 - INFO - __main__ - Step 160 Global step 160 Train loss 2.27 on epoch=1
05/28/2022 18:17:42 - INFO - __main__ - Step 170 Global step 170 Train loss 2.29 on epoch=1
05/28/2022 18:17:44 - INFO - __main__ - Step 180 Global step 180 Train loss 2.53 on epoch=1
05/28/2022 18:17:47 - INFO - __main__ - Step 190 Global step 190 Train loss 1.95 on epoch=1
05/28/2022 18:17:49 - INFO - __main__ - Step 200 Global step 200 Train loss 2.11 on epoch=1
05/28/2022 18:18:35 - INFO - __main__ - Global step 200 Train loss 2.23 Classification-F1 0.0374470772176789 on epoch=1
05/28/2022 18:18:35 - INFO - __main__ - Saving model with best Classification-F1: 0.023474559684441204 -> 0.0374470772176789 on epoch=1, global_step=200
05/28/2022 18:18:38 - INFO - __main__ - Step 210 Global step 210 Train loss 2.16 on epoch=1
05/28/2022 18:18:41 - INFO - __main__ - Step 220 Global step 220 Train loss 1.95 on epoch=1
05/28/2022 18:18:43 - INFO - __main__ - Step 230 Global step 230 Train loss 1.84 on epoch=2
05/28/2022 18:18:46 - INFO - __main__ - Step 240 Global step 240 Train loss 1.79 on epoch=2
05/28/2022 18:18:48 - INFO - __main__ - Step 250 Global step 250 Train loss 1.56 on epoch=2
05/28/2022 18:19:34 - INFO - __main__ - Global step 250 Train loss 1.86 Classification-F1 0.05420786183926745 on epoch=2
05/28/2022 18:19:34 - INFO - __main__ - Saving model with best Classification-F1: 0.0374470772176789 -> 0.05420786183926745 on epoch=2, global_step=250
05/28/2022 18:19:36 - INFO - __main__ - Step 260 Global step 260 Train loss 1.33 on epoch=2
05/28/2022 18:19:39 - INFO - __main__ - Step 270 Global step 270 Train loss 1.43 on epoch=2
05/28/2022 18:19:41 - INFO - __main__ - Step 280 Global step 280 Train loss 1.51 on epoch=2
05/28/2022 18:19:44 - INFO - __main__ - Step 290 Global step 290 Train loss 1.57 on epoch=2
05/28/2022 18:19:47 - INFO - __main__ - Step 300 Global step 300 Train loss 1.27 on epoch=2
05/28/2022 18:20:31 - INFO - __main__ - Global step 300 Train loss 1.42 Classification-F1 0.07667854589563874 on epoch=2
05/28/2022 18:20:31 - INFO - __main__ - Saving model with best Classification-F1: 0.05420786183926745 -> 0.07667854589563874 on epoch=2, global_step=300
05/28/2022 18:20:33 - INFO - __main__ - Step 310 Global step 310 Train loss 1.44 on epoch=2
05/28/2022 18:20:36 - INFO - __main__ - Step 320 Global step 320 Train loss 1.35 on epoch=2
05/28/2022 18:20:39 - INFO - __main__ - Step 330 Global step 330 Train loss 1.31 on epoch=2
05/28/2022 18:20:41 - INFO - __main__ - Step 340 Global step 340 Train loss 1.22 on epoch=3
05/28/2022 18:20:44 - INFO - __main__ - Step 350 Global step 350 Train loss 1.00 on epoch=3
05/28/2022 18:21:28 - INFO - __main__ - Global step 350 Train loss 1.26 Classification-F1 0.10864646998426851 on epoch=3
05/28/2022 18:21:28 - INFO - __main__ - Saving model with best Classification-F1: 0.07667854589563874 -> 0.10864646998426851 on epoch=3, global_step=350
05/28/2022 18:21:31 - INFO - __main__ - Step 360 Global step 360 Train loss 1.02 on epoch=3
05/28/2022 18:21:34 - INFO - __main__ - Step 370 Global step 370 Train loss 0.88 on epoch=3
05/28/2022 18:21:36 - INFO - __main__ - Step 380 Global step 380 Train loss 0.77 on epoch=3
05/28/2022 18:21:39 - INFO - __main__ - Step 390 Global step 390 Train loss 0.93 on epoch=3
05/28/2022 18:21:41 - INFO - __main__ - Step 400 Global step 400 Train loss 0.95 on epoch=3
05/28/2022 18:22:27 - INFO - __main__ - Global step 400 Train loss 0.91 Classification-F1 0.15168501244331778 on epoch=3
05/28/2022 18:22:27 - INFO - __main__ - Saving model with best Classification-F1: 0.10864646998426851 -> 0.15168501244331778 on epoch=3, global_step=400
05/28/2022 18:22:29 - INFO - __main__ - Step 410 Global step 410 Train loss 0.94 on epoch=3
05/28/2022 18:22:32 - INFO - __main__ - Step 420 Global step 420 Train loss 0.89 on epoch=3
05/28/2022 18:22:35 - INFO - __main__ - Step 430 Global step 430 Train loss 0.82 on epoch=3
05/28/2022 18:22:37 - INFO - __main__ - Step 440 Global step 440 Train loss 0.70 on epoch=3
05/28/2022 18:22:40 - INFO - __main__ - Step 450 Global step 450 Train loss 0.88 on epoch=4
05/28/2022 18:23:28 - INFO - __main__ - Global step 450 Train loss 0.85 Classification-F1 0.18770319867910937 on epoch=4
05/28/2022 18:23:28 - INFO - __main__ - Saving model with best Classification-F1: 0.15168501244331778 -> 0.18770319867910937 on epoch=4, global_step=450
05/28/2022 18:23:31 - INFO - __main__ - Step 460 Global step 460 Train loss 0.80 on epoch=4
05/28/2022 18:23:33 - INFO - __main__ - Step 470 Global step 470 Train loss 0.68 on epoch=4
05/28/2022 18:23:36 - INFO - __main__ - Step 480 Global step 480 Train loss 0.66 on epoch=4
05/28/2022 18:23:38 - INFO - __main__ - Step 490 Global step 490 Train loss 0.53 on epoch=4
05/28/2022 18:23:41 - INFO - __main__ - Step 500 Global step 500 Train loss 0.61 on epoch=4
05/28/2022 18:24:30 - INFO - __main__ - Global step 500 Train loss 0.66 Classification-F1 0.2272878746672021 on epoch=4
05/28/2022 18:24:30 - INFO - __main__ - Saving model with best Classification-F1: 0.18770319867910937 -> 0.2272878746672021 on epoch=4, global_step=500
05/28/2022 18:24:33 - INFO - __main__ - Step 510 Global step 510 Train loss 0.64 on epoch=4
05/28/2022 18:24:35 - INFO - __main__ - Step 520 Global step 520 Train loss 0.58 on epoch=4
05/28/2022 18:24:38 - INFO - __main__ - Step 530 Global step 530 Train loss 0.69 on epoch=4
05/28/2022 18:24:41 - INFO - __main__ - Step 540 Global step 540 Train loss 0.58 on epoch=4
05/28/2022 18:24:43 - INFO - __main__ - Step 550 Global step 550 Train loss 0.54 on epoch=4
05/28/2022 18:25:34 - INFO - __main__ - Global step 550 Train loss 0.61 Classification-F1 0.25431350378833356 on epoch=4
05/28/2022 18:25:34 - INFO - __main__ - Saving model with best Classification-F1: 0.2272878746672021 -> 0.25431350378833356 on epoch=4, global_step=550
05/28/2022 18:25:36 - INFO - __main__ - Step 560 Global step 560 Train loss 0.54 on epoch=4
05/28/2022 18:25:39 - INFO - __main__ - Step 570 Global step 570 Train loss 0.44 on epoch=5
05/28/2022 18:25:42 - INFO - __main__ - Step 580 Global step 580 Train loss 0.58 on epoch=5
05/28/2022 18:25:44 - INFO - __main__ - Step 590 Global step 590 Train loss 0.45 on epoch=5
05/28/2022 18:25:47 - INFO - __main__ - Step 600 Global step 600 Train loss 0.36 on epoch=5
05/28/2022 18:26:36 - INFO - __main__ - Global step 600 Train loss 0.47 Classification-F1 0.2735444514242178 on epoch=5
05/28/2022 18:26:36 - INFO - __main__ - Saving model with best Classification-F1: 0.25431350378833356 -> 0.2735444514242178 on epoch=5, global_step=600
05/28/2022 18:26:39 - INFO - __main__ - Step 610 Global step 610 Train loss 0.49 on epoch=5
05/28/2022 18:26:42 - INFO - __main__ - Step 620 Global step 620 Train loss 0.52 on epoch=5
05/28/2022 18:26:44 - INFO - __main__ - Step 630 Global step 630 Train loss 0.45 on epoch=5
05/28/2022 18:26:47 - INFO - __main__ - Step 640 Global step 640 Train loss 0.48 on epoch=5
05/28/2022 18:26:49 - INFO - __main__ - Step 650 Global step 650 Train loss 0.45 on epoch=5
05/28/2022 18:27:40 - INFO - __main__ - Global step 650 Train loss 0.48 Classification-F1 0.28955423549694015 on epoch=5
05/28/2022 18:27:40 - INFO - __main__ - Saving model with best Classification-F1: 0.2735444514242178 -> 0.28955423549694015 on epoch=5, global_step=650
05/28/2022 18:27:42 - INFO - __main__ - Step 660 Global step 660 Train loss 0.41 on epoch=5
05/28/2022 18:27:45 - INFO - __main__ - Step 670 Global step 670 Train loss 0.45 on epoch=5
05/28/2022 18:27:47 - INFO - __main__ - Step 680 Global step 680 Train loss 0.39 on epoch=6
05/28/2022 18:27:50 - INFO - __main__ - Step 690 Global step 690 Train loss 0.39 on epoch=6
05/28/2022 18:27:53 - INFO - __main__ - Step 700 Global step 700 Train loss 0.36 on epoch=6
05/28/2022 18:28:44 - INFO - __main__ - Global step 700 Train loss 0.40 Classification-F1 0.3318867356829528 on epoch=6
05/28/2022 18:28:44 - INFO - __main__ - Saving model with best Classification-F1: 0.28955423549694015 -> 0.3318867356829528 on epoch=6, global_step=700
05/28/2022 18:28:46 - INFO - __main__ - Step 710 Global step 710 Train loss 0.41 on epoch=6
05/28/2022 18:28:49 - INFO - __main__ - Step 720 Global step 720 Train loss 0.40 on epoch=6
05/28/2022 18:28:51 - INFO - __main__ - Step 730 Global step 730 Train loss 0.40 on epoch=6
05/28/2022 18:28:54 - INFO - __main__ - Step 740 Global step 740 Train loss 0.28 on epoch=6
05/28/2022 18:28:56 - INFO - __main__ - Step 750 Global step 750 Train loss 0.36 on epoch=6
05/28/2022 18:29:48 - INFO - __main__ - Global step 750 Train loss 0.37 Classification-F1 0.3871733777468026 on epoch=6
05/28/2022 18:29:48 - INFO - __main__ - Saving model with best Classification-F1: 0.3318867356829528 -> 0.3871733777468026 on epoch=6, global_step=750
05/28/2022 18:29:50 - INFO - __main__ - Step 760 Global step 760 Train loss 0.38 on epoch=6
05/28/2022 18:29:53 - INFO - __main__ - Step 770 Global step 770 Train loss 0.38 on epoch=6
05/28/2022 18:29:56 - INFO - __main__ - Step 780 Global step 780 Train loss 0.31 on epoch=6
05/28/2022 18:29:59 - INFO - __main__ - Step 790 Global step 790 Train loss 0.32 on epoch=7
05/28/2022 18:30:01 - INFO - __main__ - Step 800 Global step 800 Train loss 0.27 on epoch=7
05/28/2022 18:30:53 - INFO - __main__ - Global step 800 Train loss 0.33 Classification-F1 0.3822123479442472 on epoch=7
05/28/2022 18:30:55 - INFO - __main__ - Step 810 Global step 810 Train loss 0.25 on epoch=7
05/28/2022 18:30:58 - INFO - __main__ - Step 820 Global step 820 Train loss 0.29 on epoch=7
05/28/2022 18:31:00 - INFO - __main__ - Step 830 Global step 830 Train loss 0.37 on epoch=7
05/28/2022 18:31:03 - INFO - __main__ - Step 840 Global step 840 Train loss 0.27 on epoch=7
05/28/2022 18:31:05 - INFO - __main__ - Step 850 Global step 850 Train loss 0.28 on epoch=7
05/28/2022 18:31:56 - INFO - __main__ - Global step 850 Train loss 0.29 Classification-F1 0.3964701352750845 on epoch=7
05/28/2022 18:31:56 - INFO - __main__ - Saving model with best Classification-F1: 0.3871733777468026 -> 0.3964701352750845 on epoch=7, global_step=850
05/28/2022 18:31:59 - INFO - __main__ - Step 860 Global step 860 Train loss 0.23 on epoch=7
05/28/2022 18:32:01 - INFO - __main__ - Step 870 Global step 870 Train loss 0.47 on epoch=7
05/28/2022 18:32:04 - INFO - __main__ - Step 880 Global step 880 Train loss 0.38 on epoch=7
05/28/2022 18:32:06 - INFO - __main__ - Step 890 Global step 890 Train loss 0.27 on epoch=7
05/28/2022 18:32:09 - INFO - __main__ - Step 900 Global step 900 Train loss 0.31 on epoch=8
05/28/2022 18:33:00 - INFO - __main__ - Global step 900 Train loss 0.33 Classification-F1 0.373018056358627 on epoch=8
05/28/2022 18:33:02 - INFO - __main__ - Step 910 Global step 910 Train loss 0.26 on epoch=8
05/28/2022 18:33:05 - INFO - __main__ - Step 920 Global step 920 Train loss 0.32 on epoch=8
05/28/2022 18:33:08 - INFO - __main__ - Step 930 Global step 930 Train loss 0.27 on epoch=8
05/28/2022 18:33:10 - INFO - __main__ - Step 940 Global step 940 Train loss 0.28 on epoch=8
05/28/2022 18:33:13 - INFO - __main__ - Step 950 Global step 950 Train loss 0.30 on epoch=8
05/28/2022 18:34:03 - INFO - __main__ - Global step 950 Train loss 0.28 Classification-F1 0.38158605119613964 on epoch=8
05/28/2022 18:34:06 - INFO - __main__ - Step 960 Global step 960 Train loss 0.29 on epoch=8
05/28/2022 18:34:09 - INFO - __main__ - Step 970 Global step 970 Train loss 0.32 on epoch=8
05/28/2022 18:34:11 - INFO - __main__ - Step 980 Global step 980 Train loss 0.24 on epoch=8
05/28/2022 18:34:14 - INFO - __main__ - Step 990 Global step 990 Train loss 0.29 on epoch=8
05/28/2022 18:34:16 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.23 on epoch=8
05/28/2022 18:35:08 - INFO - __main__ - Global step 1000 Train loss 0.27 Classification-F1 0.43527972607895665 on epoch=8
05/28/2022 18:35:08 - INFO - __main__ - Saving model with best Classification-F1: 0.3964701352750845 -> 0.43527972607895665 on epoch=8, global_step=1000
05/28/2022 18:35:11 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.28 on epoch=9
05/28/2022 18:35:13 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.22 on epoch=9
05/28/2022 18:35:16 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.28 on epoch=9
05/28/2022 18:35:18 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.20 on epoch=9
05/28/2022 18:35:21 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.21 on epoch=9
05/28/2022 18:36:11 - INFO - __main__ - Global step 1050 Train loss 0.24 Classification-F1 0.4549420206312548 on epoch=9
05/28/2022 18:36:11 - INFO - __main__ - Saving model with best Classification-F1: 0.43527972607895665 -> 0.4549420206312548 on epoch=9, global_step=1050
05/28/2022 18:36:13 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.19 on epoch=9
05/28/2022 18:36:16 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.23 on epoch=9
05/28/2022 18:36:19 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.26 on epoch=9
05/28/2022 18:36:21 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.19 on epoch=9
05/28/2022 18:36:24 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.33 on epoch=9
05/28/2022 18:37:14 - INFO - __main__ - Global step 1100 Train loss 0.24 Classification-F1 0.4968840499888458 on epoch=9
05/28/2022 18:37:14 - INFO - __main__ - Saving model with best Classification-F1: 0.4549420206312548 -> 0.4968840499888458 on epoch=9, global_step=1100
05/28/2022 18:37:17 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.19 on epoch=9
05/28/2022 18:37:19 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.25 on epoch=9
05/28/2022 18:37:22 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.17 on epoch=10
05/28/2022 18:37:24 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.29 on epoch=10
05/28/2022 18:37:27 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.15 on epoch=10
05/28/2022 18:38:17 - INFO - __main__ - Global step 1150 Train loss 0.21 Classification-F1 0.44548317891222805 on epoch=10
05/28/2022 18:38:20 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.23 on epoch=10
05/28/2022 18:38:22 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.21 on epoch=10
05/28/2022 18:38:25 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.21 on epoch=10
05/28/2022 18:38:27 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.18 on epoch=10
05/28/2022 18:38:30 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.24 on epoch=10
05/28/2022 18:39:22 - INFO - __main__ - Global step 1200 Train loss 0.21 Classification-F1 0.47062048476595914 on epoch=10
05/28/2022 18:39:25 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.14 on epoch=10
05/28/2022 18:39:28 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.17 on epoch=10
05/28/2022 18:39:30 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.24 on epoch=10
05/28/2022 18:39:33 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.17 on epoch=11
05/28/2022 18:39:35 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.16 on epoch=11
05/28/2022 18:40:27 - INFO - __main__ - Global step 1250 Train loss 0.18 Classification-F1 0.4601501158353133 on epoch=11
05/28/2022 18:40:30 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.13 on epoch=11
05/28/2022 18:40:33 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.18 on epoch=11
05/28/2022 18:40:35 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.16 on epoch=11
05/28/2022 18:40:38 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.13 on epoch=11
05/28/2022 18:40:40 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.21 on epoch=11
05/28/2022 18:41:32 - INFO - __main__ - Global step 1300 Train loss 0.16 Classification-F1 0.4981810996193748 on epoch=11
05/28/2022 18:41:32 - INFO - __main__ - Saving model with best Classification-F1: 0.4968840499888458 -> 0.4981810996193748 on epoch=11, global_step=1300
05/28/2022 18:41:35 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.18 on epoch=11
05/28/2022 18:41:38 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.18 on epoch=11
05/28/2022 18:41:40 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.17 on epoch=11
05/28/2022 18:41:43 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.22 on epoch=11
05/28/2022 18:41:45 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.16 on epoch=12
05/28/2022 18:42:36 - INFO - __main__ - Global step 1350 Train loss 0.18 Classification-F1 0.5119059590132716 on epoch=12
05/28/2022 18:42:36 - INFO - __main__ - Saving model with best Classification-F1: 0.4981810996193748 -> 0.5119059590132716 on epoch=12, global_step=1350
05/28/2022 18:42:38 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.17 on epoch=12
05/28/2022 18:42:41 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.18 on epoch=12
05/28/2022 18:42:43 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.13 on epoch=12
05/28/2022 18:42:46 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.18 on epoch=12
05/28/2022 18:42:48 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.15 on epoch=12
05/28/2022 18:43:39 - INFO - __main__ - Global step 1400 Train loss 0.16 Classification-F1 0.47466316505176825 on epoch=12
05/28/2022 18:43:41 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.18 on epoch=12
05/28/2022 18:43:44 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.14 on epoch=12
05/28/2022 18:43:46 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.13 on epoch=12
05/28/2022 18:43:49 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.18 on epoch=12
05/28/2022 18:43:52 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.19 on epoch=12
05/28/2022 18:44:42 - INFO - __main__ - Global step 1450 Train loss 0.16 Classification-F1 0.4913681744349148 on epoch=12
05/28/2022 18:44:45 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.22 on epoch=13
05/28/2022 18:44:47 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.26 on epoch=13
05/28/2022 18:44:50 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.17 on epoch=13
05/28/2022 18:44:52 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.09 on epoch=13
05/28/2022 18:44:55 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.18 on epoch=13
05/28/2022 18:45:45 - INFO - __main__ - Global step 1500 Train loss 0.18 Classification-F1 0.4635611090086493 on epoch=13
05/28/2022 18:45:48 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.18 on epoch=13
05/28/2022 18:45:51 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.14 on epoch=13
05/28/2022 18:45:53 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.18 on epoch=13
05/28/2022 18:45:56 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.14 on epoch=13
05/28/2022 18:45:58 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.18 on epoch=13
05/28/2022 18:46:50 - INFO - __main__ - Global step 1550 Train loss 0.16 Classification-F1 0.44540242238514893 on epoch=13
05/28/2022 18:46:52 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.16 on epoch=13
05/28/2022 18:46:55 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.19 on epoch=14
05/28/2022 18:46:57 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.16 on epoch=14
05/28/2022 18:47:00 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.19 on epoch=14
05/28/2022 18:47:02 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.13 on epoch=14
05/28/2022 18:47:53 - INFO - __main__ - Global step 1600 Train loss 0.16 Classification-F1 0.47605465464776786 on epoch=14
05/28/2022 18:47:55 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.21 on epoch=14
05/28/2022 18:47:58 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.12 on epoch=14
05/28/2022 18:48:01 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.14 on epoch=14
05/28/2022 18:48:03 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.16 on epoch=14
05/28/2022 18:48:06 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.12 on epoch=14
05/28/2022 18:48:57 - INFO - __main__ - Global step 1650 Train loss 0.15 Classification-F1 0.4768175045019885 on epoch=14
05/28/2022 18:49:00 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.17 on epoch=14
05/28/2022 18:49:02 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.14 on epoch=14
05/28/2022 18:49:05 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.22 on epoch=14
05/28/2022 18:49:07 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.14 on epoch=15
05/28/2022 18:49:10 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.15 on epoch=15
05/28/2022 18:50:01 - INFO - __main__ - Global step 1700 Train loss 0.16 Classification-F1 0.5310450877135182 on epoch=15
05/28/2022 18:50:01 - INFO - __main__ - Saving model with best Classification-F1: 0.5119059590132716 -> 0.5310450877135182 on epoch=15, global_step=1700
05/28/2022 18:50:03 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.07 on epoch=15
05/28/2022 18:50:06 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.08 on epoch=15
05/28/2022 18:50:09 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.20 on epoch=15
05/28/2022 18:50:11 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.11 on epoch=15
05/28/2022 18:50:14 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.12 on epoch=15
05/28/2022 18:51:04 - INFO - __main__ - Global step 1750 Train loss 0.12 Classification-F1 0.473326215880423 on epoch=15
05/28/2022 18:51:07 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.14 on epoch=15
05/28/2022 18:51:09 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.11 on epoch=15
05/28/2022 18:51:12 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.12 on epoch=15
05/28/2022 18:51:15 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.23 on epoch=15
05/28/2022 18:51:17 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.08 on epoch=16
05/28/2022 18:52:08 - INFO - __main__ - Global step 1800 Train loss 0.13 Classification-F1 0.5100830267820794 on epoch=16
05/28/2022 18:52:10 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.12 on epoch=16
05/28/2022 18:52:13 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.15 on epoch=16
05/28/2022 18:52:15 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.12 on epoch=16
05/28/2022 18:52:18 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.09 on epoch=16
05/28/2022 18:52:20 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.10 on epoch=16
05/28/2022 18:53:11 - INFO - __main__ - Global step 1850 Train loss 0.12 Classification-F1 0.5278709051657458 on epoch=16
05/28/2022 18:53:14 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.12 on epoch=16
05/28/2022 18:53:16 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.12 on epoch=16
05/28/2022 18:53:19 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.14 on epoch=16
05/28/2022 18:53:21 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.09 on epoch=16
05/28/2022 18:53:24 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.15 on epoch=16
05/28/2022 18:54:14 - INFO - __main__ - Global step 1900 Train loss 0.12 Classification-F1 0.5109102714870696 on epoch=16
05/28/2022 18:54:17 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.06 on epoch=17
05/28/2022 18:54:19 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.11 on epoch=17
05/28/2022 18:54:22 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.20 on epoch=17
05/28/2022 18:54:24 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.10 on epoch=17
05/28/2022 18:54:27 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.09 on epoch=17
05/28/2022 18:55:17 - INFO - __main__ - Global step 1950 Train loss 0.11 Classification-F1 0.5321477514379458 on epoch=17
05/28/2022 18:55:17 - INFO - __main__ - Saving model with best Classification-F1: 0.5310450877135182 -> 0.5321477514379458 on epoch=17, global_step=1950
05/28/2022 18:55:19 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.10 on epoch=17
05/28/2022 18:55:22 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.14 on epoch=17
05/28/2022 18:55:24 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.12 on epoch=17
05/28/2022 18:55:27 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.09 on epoch=17
05/28/2022 18:55:29 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.13 on epoch=17
05/28/2022 18:56:19 - INFO - __main__ - Global step 2000 Train loss 0.12 Classification-F1 0.5626728263908949 on epoch=17
05/28/2022 18:56:19 - INFO - __main__ - Saving model with best Classification-F1: 0.5321477514379458 -> 0.5626728263908949 on epoch=17, global_step=2000
05/28/2022 18:56:22 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.16 on epoch=17
05/28/2022 18:56:24 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.10 on epoch=18
05/28/2022 18:56:27 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.10 on epoch=18
05/28/2022 18:56:29 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.13 on epoch=18
05/28/2022 18:56:32 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.09 on epoch=18
05/28/2022 18:57:21 - INFO - __main__ - Global step 2050 Train loss 0.12 Classification-F1 0.4983912130309785 on epoch=18
05/28/2022 18:57:24 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.11 on epoch=18
05/28/2022 18:57:27 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.14 on epoch=18
05/28/2022 18:57:29 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.09 on epoch=18
05/28/2022 18:57:32 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.09 on epoch=18
05/28/2022 18:57:34 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.11 on epoch=18
05/28/2022 18:58:24 - INFO - __main__ - Global step 2100 Train loss 0.11 Classification-F1 0.4894397989306165 on epoch=18
05/28/2022 18:58:26 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.12 on epoch=18
05/28/2022 18:58:29 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.15 on epoch=18
05/28/2022 18:58:32 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.12 on epoch=19
05/28/2022 18:58:34 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.09 on epoch=19
05/28/2022 18:58:37 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.17 on epoch=19
05/28/2022 18:59:27 - INFO - __main__ - Global step 2150 Train loss 0.13 Classification-F1 0.5297365153300511 on epoch=19
05/28/2022 18:59:30 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.07 on epoch=19
05/28/2022 18:59:33 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.09 on epoch=19
05/28/2022 18:59:35 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.09 on epoch=19
05/28/2022 18:59:38 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.05 on epoch=19
05/28/2022 18:59:40 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.09 on epoch=19
05/28/2022 19:00:30 - INFO - __main__ - Global step 2200 Train loss 0.08 Classification-F1 0.5566838447977863 on epoch=19
05/28/2022 19:00:33 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.08 on epoch=19
05/28/2022 19:00:35 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.13 on epoch=19
05/28/2022 19:00:38 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.11 on epoch=19
05/28/2022 19:00:41 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.18 on epoch=19
05/28/2022 19:00:43 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.06 on epoch=20
05/28/2022 19:01:33 - INFO - __main__ - Global step 2250 Train loss 0.11 Classification-F1 0.5381648200681406 on epoch=20
05/28/2022 19:01:36 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.10 on epoch=20
05/28/2022 19:01:38 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.08 on epoch=20
05/28/2022 19:01:41 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.16 on epoch=20
05/28/2022 19:01:43 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.10 on epoch=20
05/28/2022 19:01:46 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.07 on epoch=20
05/28/2022 19:02:36 - INFO - __main__ - Global step 2300 Train loss 0.10 Classification-F1 0.5209565914272628 on epoch=20
05/28/2022 19:02:39 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.08 on epoch=20
05/28/2022 19:02:41 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.18 on epoch=20
05/28/2022 19:02:44 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.08 on epoch=20
05/28/2022 19:02:46 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.05 on epoch=20
05/28/2022 19:02:49 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.14 on epoch=20
05/28/2022 19:03:38 - INFO - __main__ - Global step 2350 Train loss 0.11 Classification-F1 0.5226852935813324 on epoch=20
05/28/2022 19:03:41 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.12 on epoch=21
05/28/2022 19:03:43 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.08 on epoch=21
05/28/2022 19:03:46 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.07 on epoch=21
05/28/2022 19:03:48 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.06 on epoch=21
05/28/2022 19:03:51 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.09 on epoch=21
05/28/2022 19:04:40 - INFO - __main__ - Global step 2400 Train loss 0.08 Classification-F1 0.5244040804018489 on epoch=21
05/28/2022 19:04:42 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.07 on epoch=21
05/28/2022 19:04:45 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.07 on epoch=21
05/28/2022 19:04:48 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.13 on epoch=21
05/28/2022 19:04:50 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.09 on epoch=21
05/28/2022 19:04:53 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.08 on epoch=21
05/28/2022 19:05:41 - INFO - __main__ - Global step 2450 Train loss 0.09 Classification-F1 0.5480605106475069 on epoch=21
05/28/2022 19:05:44 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.07 on epoch=21
05/28/2022 19:05:46 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.12 on epoch=22
05/28/2022 19:05:49 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.13 on epoch=22
05/28/2022 19:05:52 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.20 on epoch=22
05/28/2022 19:05:54 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.08 on epoch=22
05/28/2022 19:06:42 - INFO - __main__ - Global step 2500 Train loss 0.12 Classification-F1 0.523069343019486 on epoch=22
05/28/2022 19:06:45 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.13 on epoch=22
05/28/2022 19:06:47 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.04 on epoch=22
05/28/2022 19:06:50 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.06 on epoch=22
05/28/2022 19:06:53 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.08 on epoch=22
05/28/2022 19:06:55 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.06 on epoch=22
05/28/2022 19:07:44 - INFO - __main__ - Global step 2550 Train loss 0.07 Classification-F1 0.5443115902240783 on epoch=22
05/28/2022 19:07:47 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.08 on epoch=22
05/28/2022 19:07:50 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.10 on epoch=22
05/28/2022 19:07:52 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.10 on epoch=23
05/28/2022 19:07:55 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.13 on epoch=23
05/28/2022 19:07:57 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.12 on epoch=23
05/28/2022 19:08:47 - INFO - __main__ - Global step 2600 Train loss 0.10 Classification-F1 0.5671480066872419 on epoch=23
05/28/2022 19:08:47 - INFO - __main__ - Saving model with best Classification-F1: 0.5626728263908949 -> 0.5671480066872419 on epoch=23, global_step=2600
05/28/2022 19:08:50 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.07 on epoch=23
05/28/2022 19:08:52 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.13 on epoch=23
05/28/2022 19:08:55 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.11 on epoch=23
05/28/2022 19:08:58 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.06 on epoch=23
05/28/2022 19:09:00 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.10 on epoch=23
05/28/2022 19:09:49 - INFO - __main__ - Global step 2650 Train loss 0.09 Classification-F1 0.5972229137593017 on epoch=23
05/28/2022 19:09:50 - INFO - __main__ - Saving model with best Classification-F1: 0.5671480066872419 -> 0.5972229137593017 on epoch=23, global_step=2650
05/28/2022 19:09:52 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.06 on epoch=23
05/28/2022 19:09:55 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.06 on epoch=23
05/28/2022 19:09:57 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.10 on epoch=23
05/28/2022 19:10:00 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.07 on epoch=24
05/28/2022 19:10:02 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.08 on epoch=24
05/28/2022 19:10:51 - INFO - __main__ - Global step 2700 Train loss 0.07 Classification-F1 0.5638068894630899 on epoch=24
05/28/2022 19:10:54 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.16 on epoch=24
05/28/2022 19:10:57 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.09 on epoch=24
05/28/2022 19:10:59 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.13 on epoch=24
05/28/2022 19:11:02 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.04 on epoch=24
05/28/2022 19:11:04 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.08 on epoch=24
05/28/2022 19:11:54 - INFO - __main__ - Global step 2750 Train loss 0.10 Classification-F1 0.5716448453532585 on epoch=24
05/28/2022 19:11:56 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.09 on epoch=24
05/28/2022 19:11:59 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.03 on epoch=24
05/28/2022 19:12:01 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.11 on epoch=24
05/28/2022 19:12:04 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=24
05/28/2022 19:12:07 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.14 on epoch=24
05/28/2022 19:12:56 - INFO - __main__ - Global step 2800 Train loss 0.08 Classification-F1 0.5775100803738672 on epoch=24
05/28/2022 19:12:59 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.09 on epoch=25
05/28/2022 19:13:01 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.13 on epoch=25
05/28/2022 19:13:04 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.08 on epoch=25
05/28/2022 19:13:06 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.08 on epoch=25
05/28/2022 19:13:09 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.13 on epoch=25
05/28/2022 19:13:58 - INFO - __main__ - Global step 2850 Train loss 0.10 Classification-F1 0.5756687281824472 on epoch=25
05/28/2022 19:14:01 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.04 on epoch=25
05/28/2022 19:14:03 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.10 on epoch=25
05/28/2022 19:14:06 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.08 on epoch=25
05/28/2022 19:14:08 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.05 on epoch=25
05/28/2022 19:14:11 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.04 on epoch=25
05/28/2022 19:15:00 - INFO - __main__ - Global step 2900 Train loss 0.06 Classification-F1 0.6012945616798653 on epoch=25
05/28/2022 19:15:00 - INFO - __main__ - Saving model with best Classification-F1: 0.5972229137593017 -> 0.6012945616798653 on epoch=25, global_step=2900
05/28/2022 19:15:02 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.11 on epoch=25
05/28/2022 19:15:05 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.07 on epoch=26
05/28/2022 19:15:07 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.05 on epoch=26
05/28/2022 19:15:10 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.08 on epoch=26
05/28/2022 19:15:13 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.07 on epoch=26
05/28/2022 19:16:02 - INFO - __main__ - Global step 2950 Train loss 0.08 Classification-F1 0.6078180488111078 on epoch=26
05/28/2022 19:16:02 - INFO - __main__ - Saving model with best Classification-F1: 0.6012945616798653 -> 0.6078180488111078 on epoch=26, global_step=2950
05/28/2022 19:16:04 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.10 on epoch=26
05/28/2022 19:16:07 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=26
05/28/2022 19:16:10 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.07 on epoch=26
05/28/2022 19:16:12 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.06 on epoch=26
05/28/2022 19:16:15 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.07 on epoch=26
05/28/2022 19:17:04 - INFO - __main__ - Global step 3000 Train loss 0.06 Classification-F1 0.6066567618509874 on epoch=26
05/28/2022 19:17:04 - INFO - __main__ - save last model!
05/28/2022 19:17:04 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/28/2022 19:17:04 - INFO - __main__ - Start tokenizing ... 3500 instances
05/28/2022 19:17:04 - INFO - __main__ - Printing 3 examples
05/28/2022 19:17:04 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/28/2022 19:17:04 - INFO - __main__ - ['Animal']
05/28/2022 19:17:04 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/28/2022 19:17:04 - INFO - __main__ - ['Animal']
05/28/2022 19:17:04 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/28/2022 19:17:04 - INFO - __main__ - ['Village']
05/28/2022 19:17:04 - INFO - __main__ - Tokenizing Input ...
05/28/2022 19:17:06 - INFO - __main__ - Tokenizing Output ...
05/28/2022 19:17:10 - INFO - __main__ - Loaded 3500 examples from test data
05/28/2022 19:19:01 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down128shot/singletask-dbpedia_14/dbpedia_14_128_87_0.2_8_predictions.txt
05/28/2022 19:19:01 - INFO - __main__ - Classification-F1 on test data: 0.4837
05/28/2022 19:19:02 - INFO - __main__ - prefix=dbpedia_14_128_87, lr=0.2, bsz=8, dev_performance=0.6078180488111078, test_performance=0.4837236978066276
