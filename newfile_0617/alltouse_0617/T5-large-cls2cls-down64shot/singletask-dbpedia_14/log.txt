05/22/2022 14:38:12 - INFO - __main__ - Namespace(task_dir='data_64/dbpedia_14/', task_name='dbpedia_14', identifier='T5-large-cls2cls-down64shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-cls2cls-down64shot/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='None', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='6,7')
05/22/2022 14:38:12 - INFO - __main__ - models/T5-large-cls2cls-down64shot/singletask-dbpedia_14
05/22/2022 14:38:12 - INFO - __main__ - Namespace(task_dir='data_64/dbpedia_14/', task_name='dbpedia_14', identifier='T5-large-cls2cls-down64shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-cls2cls-down64shot/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='None', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='6,7')
05/22/2022 14:38:12 - INFO - __main__ - models/T5-large-cls2cls-down64shot/singletask-dbpedia_14
05/22/2022 14:38:14 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
05/22/2022 14:38:14 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
05/22/2022 14:38:14 - INFO - __main__ - args.device: cuda:0
05/22/2022 14:38:14 - INFO - __main__ - args.device: cuda:1
05/22/2022 14:38:14 - INFO - __main__ - Using 2 gpus
05/22/2022 14:38:14 - INFO - __main__ - Using 2 gpus
05/22/2022 14:38:14 - INFO - __main__ - Fine-tuning the following samples: ['dbpedia_14_64_100', 'dbpedia_14_64_13', 'dbpedia_14_64_21', 'dbpedia_14_64_42', 'dbpedia_14_64_87']
05/22/2022 14:38:14 - INFO - __main__ - Fine-tuning the following samples: ['dbpedia_14_64_100', 'dbpedia_14_64_13', 'dbpedia_14_64_21', 'dbpedia_14_64_42', 'dbpedia_14_64_87']
05/22/2022 14:38:18 - INFO - __main__ - Running ... prefix=dbpedia_14_64_100, lr=0.5, bsz=8 ...
05/22/2022 14:38:19 - INFO - __main__ - Start tokenizing ... 896 instances
05/22/2022 14:38:19 - INFO - __main__ - Printing 3 examples
05/22/2022 14:38:19 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/22/2022 14:38:19 - INFO - __main__ - ['Animal']
05/22/2022 14:38:19 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/22/2022 14:38:19 - INFO - __main__ - ['Animal']
05/22/2022 14:38:19 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/22/2022 14:38:19 - INFO - __main__ - ['Animal']
05/22/2022 14:38:19 - INFO - __main__ - Tokenizing Input ...
05/22/2022 14:38:19 - INFO - __main__ - Start tokenizing ... 896 instances
05/22/2022 14:38:19 - INFO - __main__ - Printing 3 examples
05/22/2022 14:38:19 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/22/2022 14:38:19 - INFO - __main__ - ['Animal']
05/22/2022 14:38:19 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/22/2022 14:38:19 - INFO - __main__ - ['Animal']
05/22/2022 14:38:19 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/22/2022 14:38:19 - INFO - __main__ - ['Animal']
05/22/2022 14:38:19 - INFO - __main__ - Tokenizing Input ...
05/22/2022 14:38:20 - INFO - __main__ - Tokenizing Output ...
05/22/2022 14:38:20 - INFO - __main__ - Tokenizing Output ...
05/22/2022 14:38:21 - INFO - __main__ - Loaded 896 examples from train data
05/22/2022 14:38:21 - INFO - __main__ - Start tokenizing ... 896 instances
05/22/2022 14:38:21 - INFO - __main__ - Printing 3 examples
05/22/2022 14:38:21 - INFO - __main__ -  [dbpedia_14] Metareva aenescens is a moth of the Arctiidae family. It was described by Hampson in 1900. It is found in Bolivia.
05/22/2022 14:38:21 - INFO - __main__ - ['Animal']
05/22/2022 14:38:21 - INFO - __main__ -  [dbpedia_14] Xenopipo is a genus of bird in the Pipridae family. It contains the following species: Black Manakin (Xenopipo atronitens) Yellow-headed Manakin (Xenopipo flavicapilla) Green Manakin (Xenopipo holochlora) Jet Manakin (Xenopipo unicolor) Olive Manakin (Xenopipo uniformis)
05/22/2022 14:38:21 - INFO - __main__ - ['Animal']
05/22/2022 14:38:21 - INFO - __main__ -  [dbpedia_14] The Tardy Renia (Renia nemoralis) is a moth of the Noctuidae family. It is found from Illinois to south-eastern Massachusetts south to Florida and Texas.The wingspan is 28-30 mm. There is one generation per year.The larvae feed on organic matter including dead leaves.
05/22/2022 14:38:21 - INFO - __main__ - ['Animal']
05/22/2022 14:38:21 - INFO - __main__ - Tokenizing Input ...
05/22/2022 14:38:21 - INFO - __main__ - Loaded 896 examples from train data
05/22/2022 14:38:21 - INFO - __main__ - Start tokenizing ... 896 instances
05/22/2022 14:38:21 - INFO - __main__ - Printing 3 examples
05/22/2022 14:38:21 - INFO - __main__ -  [dbpedia_14] Metareva aenescens is a moth of the Arctiidae family. It was described by Hampson in 1900. It is found in Bolivia.
05/22/2022 14:38:21 - INFO - __main__ - ['Animal']
05/22/2022 14:38:21 - INFO - __main__ -  [dbpedia_14] Xenopipo is a genus of bird in the Pipridae family. It contains the following species: Black Manakin (Xenopipo atronitens) Yellow-headed Manakin (Xenopipo flavicapilla) Green Manakin (Xenopipo holochlora) Jet Manakin (Xenopipo unicolor) Olive Manakin (Xenopipo uniformis)
05/22/2022 14:38:21 - INFO - __main__ - ['Animal']
05/22/2022 14:38:21 - INFO - __main__ -  [dbpedia_14] The Tardy Renia (Renia nemoralis) is a moth of the Noctuidae family. It is found from Illinois to south-eastern Massachusetts south to Florida and Texas.The wingspan is 28-30 mm. There is one generation per year.The larvae feed on organic matter including dead leaves.
05/22/2022 14:38:21 - INFO - __main__ - ['Animal']
05/22/2022 14:38:21 - INFO - __main__ - Tokenizing Input ...
05/22/2022 14:38:21 - INFO - __main__ - Tokenizing Output ...
05/22/2022 14:38:21 - INFO - __main__ - Tokenizing Output ...
05/22/2022 14:38:22 - INFO - __main__ - Loaded 896 examples from dev data
05/22/2022 14:38:22 - INFO - __main__ - Loaded 896 examples from dev data
05/22/2022 14:38:40 - INFO - __main__ - try to initialize prompt embeddings
05/22/2022 14:38:40 - INFO - __main__ - task name: dbpedia_14
05/22/2022 14:38:40 - INFO - __main__ - try to initialize prompt embeddings
05/22/2022 14:38:40 - INFO - __main__ - task name: dbpedia_14
05/22/2022 14:38:41 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 14:38:41 - INFO - __main__ - Starting training!
05/22/2022 14:38:41 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 14:38:41 - INFO - __main__ - Starting training!
05/22/2022 14:38:44 - INFO - __main__ - Step 10 Global step 10 Train loss 6.60 on epoch=0
05/22/2022 14:38:47 - INFO - __main__ - Step 20 Global step 20 Train loss 4.58 on epoch=0
05/22/2022 14:38:49 - INFO - __main__ - Step 30 Global step 30 Train loss 3.31 on epoch=0
05/22/2022 14:38:52 - INFO - __main__ - Step 40 Global step 40 Train loss 2.58 on epoch=0
05/22/2022 14:38:54 - INFO - __main__ - Step 50 Global step 50 Train loss 2.32 on epoch=0
05/22/2022 14:39:28 - INFO - __main__ - Global step 50 Train loss 3.88 Classification-F1 0.16148512621139857 on epoch=0
05/22/2022 14:39:28 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.16148512621139857 on epoch=0, global_step=50
05/22/2022 14:39:31 - INFO - __main__ - Step 60 Global step 60 Train loss 1.56 on epoch=1
05/22/2022 14:39:33 - INFO - __main__ - Step 70 Global step 70 Train loss 1.23 on epoch=1
05/22/2022 14:39:36 - INFO - __main__ - Step 80 Global step 80 Train loss 1.35 on epoch=1
05/22/2022 14:39:38 - INFO - __main__ - Step 90 Global step 90 Train loss 1.13 on epoch=1
05/22/2022 14:39:41 - INFO - __main__ - Step 100 Global step 100 Train loss 0.92 on epoch=1
05/22/2022 14:40:11 - INFO - __main__ - Global step 100 Train loss 1.24 Classification-F1 0.3215170153624171 on epoch=1
05/22/2022 14:40:11 - INFO - __main__ - Saving model with best Classification-F1: 0.16148512621139857 -> 0.3215170153624171 on epoch=1, global_step=100
05/22/2022 14:40:14 - INFO - __main__ - Step 110 Global step 110 Train loss 0.96 on epoch=1
05/22/2022 14:40:16 - INFO - __main__ - Step 120 Global step 120 Train loss 0.75 on epoch=2
05/22/2022 14:40:19 - INFO - __main__ - Step 130 Global step 130 Train loss 0.75 on epoch=2
05/22/2022 14:40:21 - INFO - __main__ - Step 140 Global step 140 Train loss 0.80 on epoch=2
05/22/2022 14:40:24 - INFO - __main__ - Step 150 Global step 150 Train loss 0.81 on epoch=2
05/22/2022 14:40:52 - INFO - __main__ - Global step 150 Train loss 0.81 Classification-F1 0.42650738456606163 on epoch=2
05/22/2022 14:40:52 - INFO - __main__ - Saving model with best Classification-F1: 0.3215170153624171 -> 0.42650738456606163 on epoch=2, global_step=150
05/22/2022 14:40:55 - INFO - __main__ - Step 160 Global step 160 Train loss 0.88 on epoch=2
05/22/2022 14:40:58 - INFO - __main__ - Step 170 Global step 170 Train loss 0.78 on epoch=3
05/22/2022 14:41:00 - INFO - __main__ - Step 180 Global step 180 Train loss 0.57 on epoch=3
05/22/2022 14:41:03 - INFO - __main__ - Step 190 Global step 190 Train loss 0.57 on epoch=3
05/22/2022 14:41:05 - INFO - __main__ - Step 200 Global step 200 Train loss 0.67 on epoch=3
05/22/2022 14:41:31 - INFO - __main__ - Global step 200 Train loss 0.69 Classification-F1 0.4434288259893152 on epoch=3
05/22/2022 14:41:31 - INFO - __main__ - Saving model with best Classification-F1: 0.42650738456606163 -> 0.4434288259893152 on epoch=3, global_step=200
05/22/2022 14:41:33 - INFO - __main__ - Step 210 Global step 210 Train loss 0.59 on epoch=3
05/22/2022 14:41:36 - INFO - __main__ - Step 220 Global step 220 Train loss 0.73 on epoch=3
05/22/2022 14:41:39 - INFO - __main__ - Step 230 Global step 230 Train loss 0.58 on epoch=4
05/22/2022 14:41:41 - INFO - __main__ - Step 240 Global step 240 Train loss 0.55 on epoch=4
05/22/2022 14:41:44 - INFO - __main__ - Step 250 Global step 250 Train loss 0.60 on epoch=4
05/22/2022 14:42:12 - INFO - __main__ - Global step 250 Train loss 0.61 Classification-F1 0.4098521473209996 on epoch=4
05/22/2022 14:42:15 - INFO - __main__ - Step 260 Global step 260 Train loss 0.59 on epoch=4
05/22/2022 14:42:17 - INFO - __main__ - Step 270 Global step 270 Train loss 0.71 on epoch=4
05/22/2022 14:42:20 - INFO - __main__ - Step 280 Global step 280 Train loss 0.63 on epoch=4
05/22/2022 14:42:23 - INFO - __main__ - Step 290 Global step 290 Train loss 0.44 on epoch=5
05/22/2022 14:42:25 - INFO - __main__ - Step 300 Global step 300 Train loss 0.51 on epoch=5
05/22/2022 14:42:52 - INFO - __main__ - Global step 300 Train loss 0.58 Classification-F1 0.5257452477318418 on epoch=5
05/22/2022 14:42:53 - INFO - __main__ - Saving model with best Classification-F1: 0.4434288259893152 -> 0.5257452477318418 on epoch=5, global_step=300
05/22/2022 14:42:55 - INFO - __main__ - Step 310 Global step 310 Train loss 0.47 on epoch=5
05/22/2022 14:42:58 - INFO - __main__ - Step 320 Global step 320 Train loss 0.48 on epoch=5
05/22/2022 14:43:00 - INFO - __main__ - Step 330 Global step 330 Train loss 0.48 on epoch=5
05/22/2022 14:43:03 - INFO - __main__ - Step 340 Global step 340 Train loss 0.46 on epoch=6
05/22/2022 14:43:05 - INFO - __main__ - Step 350 Global step 350 Train loss 0.40 on epoch=6
05/22/2022 14:43:31 - INFO - __main__ - Global step 350 Train loss 0.46 Classification-F1 0.5005117813957446 on epoch=6
05/22/2022 14:43:34 - INFO - __main__ - Step 360 Global step 360 Train loss 0.40 on epoch=6
05/22/2022 14:43:36 - INFO - __main__ - Step 370 Global step 370 Train loss 0.37 on epoch=6
05/22/2022 14:43:39 - INFO - __main__ - Step 380 Global step 380 Train loss 0.44 on epoch=6
05/22/2022 14:43:42 - INFO - __main__ - Step 390 Global step 390 Train loss 0.51 on epoch=6
05/22/2022 14:43:44 - INFO - __main__ - Step 400 Global step 400 Train loss 0.25 on epoch=7
05/22/2022 14:44:07 - INFO - __main__ - Global step 400 Train loss 0.39 Classification-F1 0.5425114051082525 on epoch=7
05/22/2022 14:44:07 - INFO - __main__ - Saving model with best Classification-F1: 0.5257452477318418 -> 0.5425114051082525 on epoch=7, global_step=400
05/22/2022 14:44:10 - INFO - __main__ - Step 410 Global step 410 Train loss 0.36 on epoch=7
05/22/2022 14:44:13 - INFO - __main__ - Step 420 Global step 420 Train loss 0.41 on epoch=7
05/22/2022 14:44:15 - INFO - __main__ - Step 430 Global step 430 Train loss 0.37 on epoch=7
05/22/2022 14:44:18 - INFO - __main__ - Step 440 Global step 440 Train loss 0.55 on epoch=7
05/22/2022 14:44:20 - INFO - __main__ - Step 450 Global step 450 Train loss 0.27 on epoch=8
05/22/2022 14:44:44 - INFO - __main__ - Global step 450 Train loss 0.39 Classification-F1 0.42109209644932805 on epoch=8
05/22/2022 14:44:46 - INFO - __main__ - Step 460 Global step 460 Train loss 0.29 on epoch=8
05/22/2022 14:44:49 - INFO - __main__ - Step 470 Global step 470 Train loss 0.25 on epoch=8
05/22/2022 14:44:52 - INFO - __main__ - Step 480 Global step 480 Train loss 0.32 on epoch=8
05/22/2022 14:44:54 - INFO - __main__ - Step 490 Global step 490 Train loss 0.37 on epoch=8
05/22/2022 14:44:57 - INFO - __main__ - Step 500 Global step 500 Train loss 0.47 on epoch=8
05/22/2022 14:45:21 - INFO - __main__ - Global step 500 Train loss 0.34 Classification-F1 0.5703595322081367 on epoch=8
05/22/2022 14:45:21 - INFO - __main__ - Saving model with best Classification-F1: 0.5425114051082525 -> 0.5703595322081367 on epoch=8, global_step=500
05/22/2022 14:45:24 - INFO - __main__ - Step 510 Global step 510 Train loss 0.27 on epoch=9
05/22/2022 14:45:26 - INFO - __main__ - Step 520 Global step 520 Train loss 0.23 on epoch=9
05/22/2022 14:45:29 - INFO - __main__ - Step 530 Global step 530 Train loss 0.24 on epoch=9
05/22/2022 14:45:32 - INFO - __main__ - Step 540 Global step 540 Train loss 0.22 on epoch=9
05/22/2022 14:45:34 - INFO - __main__ - Step 550 Global step 550 Train loss 0.25 on epoch=9
05/22/2022 14:45:59 - INFO - __main__ - Global step 550 Train loss 0.24 Classification-F1 0.4130760481354431 on epoch=9
05/22/2022 14:46:02 - INFO - __main__ - Step 560 Global step 560 Train loss 0.21 on epoch=9
05/22/2022 14:46:04 - INFO - __main__ - Step 570 Global step 570 Train loss 0.19 on epoch=10
05/22/2022 14:46:07 - INFO - __main__ - Step 580 Global step 580 Train loss 0.21 on epoch=10
05/22/2022 14:46:10 - INFO - __main__ - Step 590 Global step 590 Train loss 0.21 on epoch=10
05/22/2022 14:46:12 - INFO - __main__ - Step 600 Global step 600 Train loss 0.20 on epoch=10
05/22/2022 14:46:37 - INFO - __main__ - Global step 600 Train loss 0.20 Classification-F1 0.5915891337729907 on epoch=10
05/22/2022 14:46:37 - INFO - __main__ - Saving model with best Classification-F1: 0.5703595322081367 -> 0.5915891337729907 on epoch=10, global_step=600
05/22/2022 14:46:40 - INFO - __main__ - Step 610 Global step 610 Train loss 0.47 on epoch=10
05/22/2022 14:46:42 - INFO - __main__ - Step 620 Global step 620 Train loss 0.17 on epoch=11
05/22/2022 14:46:45 - INFO - __main__ - Step 630 Global step 630 Train loss 0.20 on epoch=11
05/22/2022 14:46:47 - INFO - __main__ - Step 640 Global step 640 Train loss 0.23 on epoch=11
05/22/2022 14:46:50 - INFO - __main__ - Step 650 Global step 650 Train loss 0.24 on epoch=11
05/22/2022 14:47:17 - INFO - __main__ - Global step 650 Train loss 0.26 Classification-F1 0.6209446628267439 on epoch=11
05/22/2022 14:47:17 - INFO - __main__ - Saving model with best Classification-F1: 0.5915891337729907 -> 0.6209446628267439 on epoch=11, global_step=650
05/22/2022 14:47:20 - INFO - __main__ - Step 660 Global step 660 Train loss 0.14 on epoch=11
05/22/2022 14:47:23 - INFO - __main__ - Step 670 Global step 670 Train loss 0.42 on epoch=11
05/22/2022 14:47:25 - INFO - __main__ - Step 680 Global step 680 Train loss 0.16 on epoch=12
05/22/2022 14:47:28 - INFO - __main__ - Step 690 Global step 690 Train loss 0.12 on epoch=12
05/22/2022 14:47:30 - INFO - __main__ - Step 700 Global step 700 Train loss 0.17 on epoch=12
05/22/2022 14:47:58 - INFO - __main__ - Global step 700 Train loss 0.20 Classification-F1 0.518922194589248 on epoch=12
05/22/2022 14:48:00 - INFO - __main__ - Step 710 Global step 710 Train loss 0.16 on epoch=12
05/22/2022 14:48:03 - INFO - __main__ - Step 720 Global step 720 Train loss 0.34 on epoch=12
05/22/2022 14:48:05 - INFO - __main__ - Step 730 Global step 730 Train loss 0.22 on epoch=13
05/22/2022 14:48:08 - INFO - __main__ - Step 740 Global step 740 Train loss 0.13 on epoch=13
05/22/2022 14:48:11 - INFO - __main__ - Step 750 Global step 750 Train loss 0.20 on epoch=13
05/22/2022 14:48:35 - INFO - __main__ - Global step 750 Train loss 0.21 Classification-F1 0.36040570149394546 on epoch=13
05/22/2022 14:48:38 - INFO - __main__ - Step 760 Global step 760 Train loss 0.20 on epoch=13
05/22/2022 14:48:41 - INFO - __main__ - Step 770 Global step 770 Train loss 0.12 on epoch=13
05/22/2022 14:48:43 - INFO - __main__ - Step 780 Global step 780 Train loss 0.35 on epoch=13
05/22/2022 14:48:46 - INFO - __main__ - Step 790 Global step 790 Train loss 0.17 on epoch=14
05/22/2022 14:48:48 - INFO - __main__ - Step 800 Global step 800 Train loss 0.19 on epoch=14
05/22/2022 14:49:12 - INFO - __main__ - Global step 800 Train loss 0.21 Classification-F1 0.48742325663279024 on epoch=14
05/22/2022 14:49:15 - INFO - __main__ - Step 810 Global step 810 Train loss 0.13 on epoch=14
05/22/2022 14:49:18 - INFO - __main__ - Step 820 Global step 820 Train loss 0.15 on epoch=14
05/22/2022 14:49:20 - INFO - __main__ - Step 830 Global step 830 Train loss 0.12 on epoch=14
05/22/2022 14:49:23 - INFO - __main__ - Step 840 Global step 840 Train loss 0.10 on epoch=14
05/22/2022 14:49:26 - INFO - __main__ - Step 850 Global step 850 Train loss 0.17 on epoch=15
05/22/2022 14:49:48 - INFO - __main__ - Global step 850 Train loss 0.14 Classification-F1 0.38969080798900996 on epoch=15
05/22/2022 14:49:51 - INFO - __main__ - Step 860 Global step 860 Train loss 0.09 on epoch=15
05/22/2022 14:49:53 - INFO - __main__ - Step 870 Global step 870 Train loss 0.13 on epoch=15
05/22/2022 14:49:56 - INFO - __main__ - Step 880 Global step 880 Train loss 0.15 on epoch=15
05/22/2022 14:49:58 - INFO - __main__ - Step 890 Global step 890 Train loss 0.39 on epoch=15
05/22/2022 14:50:01 - INFO - __main__ - Step 900 Global step 900 Train loss 0.19 on epoch=16
05/22/2022 14:50:24 - INFO - __main__ - Global step 900 Train loss 0.19 Classification-F1 0.5183053002431403 on epoch=16
05/22/2022 14:50:27 - INFO - __main__ - Step 910 Global step 910 Train loss 0.12 on epoch=16
05/22/2022 14:50:30 - INFO - __main__ - Step 920 Global step 920 Train loss 0.13 on epoch=16
05/22/2022 14:50:32 - INFO - __main__ - Step 930 Global step 930 Train loss 0.12 on epoch=16
05/22/2022 14:50:35 - INFO - __main__ - Step 940 Global step 940 Train loss 0.10 on epoch=16
05/22/2022 14:50:37 - INFO - __main__ - Step 950 Global step 950 Train loss 0.11 on epoch=16
05/22/2022 14:51:00 - INFO - __main__ - Global step 950 Train loss 0.12 Classification-F1 0.6576951984196037 on epoch=16
05/22/2022 14:51:00 - INFO - __main__ - Saving model with best Classification-F1: 0.6209446628267439 -> 0.6576951984196037 on epoch=16, global_step=950
05/22/2022 14:51:03 - INFO - __main__ - Step 960 Global step 960 Train loss 0.13 on epoch=17
05/22/2022 14:51:06 - INFO - __main__ - Step 970 Global step 970 Train loss 0.10 on epoch=17
05/22/2022 14:51:08 - INFO - __main__ - Step 980 Global step 980 Train loss 0.12 on epoch=17
05/22/2022 14:51:11 - INFO - __main__ - Step 990 Global step 990 Train loss 0.11 on epoch=17
05/22/2022 14:51:14 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.12 on epoch=17
05/22/2022 14:51:37 - INFO - __main__ - Global step 1000 Train loss 0.12 Classification-F1 0.5211432965509474 on epoch=17
05/22/2022 14:51:39 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.09 on epoch=18
05/22/2022 14:51:42 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.16 on epoch=18
05/22/2022 14:51:45 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.09 on epoch=18
05/22/2022 14:51:47 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.05 on epoch=18
05/22/2022 14:51:50 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.11 on epoch=18
05/22/2022 14:52:12 - INFO - __main__ - Global step 1050 Train loss 0.10 Classification-F1 0.501745136315204 on epoch=18
05/22/2022 14:52:15 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.06 on epoch=18
05/22/2022 14:52:17 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.10 on epoch=19
05/22/2022 14:52:20 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.18 on epoch=19
05/22/2022 14:52:23 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.07 on epoch=19
05/22/2022 14:52:25 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.15 on epoch=19
05/22/2022 14:52:50 - INFO - __main__ - Global step 1100 Train loss 0.11 Classification-F1 0.5747719731881861 on epoch=19
05/22/2022 14:52:53 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.38 on epoch=19
05/22/2022 14:52:55 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.15 on epoch=19
05/22/2022 14:52:58 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.07 on epoch=20
05/22/2022 14:53:01 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.07 on epoch=20
05/22/2022 14:53:03 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.05 on epoch=20
05/22/2022 14:53:27 - INFO - __main__ - Global step 1150 Train loss 0.14 Classification-F1 0.437073823744084 on epoch=20
05/22/2022 14:53:30 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.11 on epoch=20
05/22/2022 14:53:32 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.14 on epoch=20
05/22/2022 14:53:35 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.07 on epoch=21
05/22/2022 14:53:37 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.05 on epoch=21
05/22/2022 14:53:40 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.06 on epoch=21
05/22/2022 14:54:03 - INFO - __main__ - Global step 1200 Train loss 0.08 Classification-F1 0.4642393117260988 on epoch=21
05/22/2022 14:54:05 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.09 on epoch=21
05/22/2022 14:54:08 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.09 on epoch=21
05/22/2022 14:54:11 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.33 on epoch=21
05/22/2022 14:54:13 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.09 on epoch=22
05/22/2022 14:54:16 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.04 on epoch=22
05/22/2022 14:54:40 - INFO - __main__ - Global step 1250 Train loss 0.13 Classification-F1 0.4347287723412472 on epoch=22
05/22/2022 14:54:42 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.10 on epoch=22
05/22/2022 14:54:45 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.07 on epoch=22
05/22/2022 14:54:48 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.08 on epoch=22
05/22/2022 14:54:50 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.05 on epoch=23
05/22/2022 14:54:53 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.06 on epoch=23
05/22/2022 14:55:16 - INFO - __main__ - Global step 1300 Train loss 0.07 Classification-F1 0.4489026032976656 on epoch=23
05/22/2022 14:55:18 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.04 on epoch=23
05/22/2022 14:55:21 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.08 on epoch=23
05/22/2022 14:55:23 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.15 on epoch=23
05/22/2022 14:55:26 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.04 on epoch=23
05/22/2022 14:55:29 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.07 on epoch=24
05/22/2022 14:55:51 - INFO - __main__ - Global step 1350 Train loss 0.08 Classification-F1 0.4343339886246611 on epoch=24
05/22/2022 14:55:54 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.03 on epoch=24
05/22/2022 14:55:56 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.04 on epoch=24
05/22/2022 14:55:59 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.06 on epoch=24
05/22/2022 14:56:02 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.05 on epoch=24
05/22/2022 14:56:04 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.08 on epoch=24
05/22/2022 14:56:27 - INFO - __main__ - Global step 1400 Train loss 0.05 Classification-F1 0.5152751134916077 on epoch=24
05/22/2022 14:56:30 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.07 on epoch=25
05/22/2022 14:56:32 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.06 on epoch=25
05/22/2022 14:56:35 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.04 on epoch=25
05/22/2022 14:56:37 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.04 on epoch=25
05/22/2022 14:56:40 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.08 on epoch=25
05/22/2022 14:57:03 - INFO - __main__ - Global step 1450 Train loss 0.06 Classification-F1 0.5080652525526509 on epoch=25
05/22/2022 14:57:05 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.07 on epoch=26
05/22/2022 14:57:08 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.10 on epoch=26
05/22/2022 14:57:11 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.12 on epoch=26
05/22/2022 14:57:13 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.08 on epoch=26
05/22/2022 14:57:16 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.08 on epoch=26
05/22/2022 14:57:38 - INFO - __main__ - Global step 1500 Train loss 0.09 Classification-F1 0.47897944139506976 on epoch=26
05/22/2022 14:57:40 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.05 on epoch=26
05/22/2022 14:57:43 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.04 on epoch=27
05/22/2022 14:57:46 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.04 on epoch=27
05/22/2022 14:57:48 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.05 on epoch=27
05/22/2022 14:57:51 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.04 on epoch=27
05/22/2022 14:58:13 - INFO - __main__ - Global step 1550 Train loss 0.04 Classification-F1 0.4826917183278648 on epoch=27
05/22/2022 14:58:15 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.09 on epoch=27
05/22/2022 14:58:18 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.04 on epoch=28
05/22/2022 14:58:21 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.04 on epoch=28
05/22/2022 14:58:23 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.03 on epoch=28
05/22/2022 14:58:26 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.04 on epoch=28
05/22/2022 14:58:48 - INFO - __main__ - Global step 1600 Train loss 0.05 Classification-F1 0.5700933957529837 on epoch=28
05/22/2022 14:58:50 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.04 on epoch=28
05/22/2022 14:58:53 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=28
05/22/2022 14:58:56 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.07 on epoch=29
05/22/2022 14:58:58 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.05 on epoch=29
05/22/2022 14:59:01 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.04 on epoch=29
05/22/2022 14:59:23 - INFO - __main__ - Global step 1650 Train loss 0.05 Classification-F1 0.692716533621052 on epoch=29
05/22/2022 14:59:23 - INFO - __main__ - Saving model with best Classification-F1: 0.6576951984196037 -> 0.692716533621052 on epoch=29, global_step=1650
05/22/2022 14:59:25 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.08 on epoch=29
05/22/2022 14:59:28 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.08 on epoch=29
05/22/2022 14:59:31 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.05 on epoch=29
05/22/2022 14:59:33 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.05 on epoch=30
05/22/2022 14:59:36 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.05 on epoch=30
05/22/2022 14:59:59 - INFO - __main__ - Global step 1700 Train loss 0.06 Classification-F1 0.43594810922741545 on epoch=30
05/22/2022 15:00:01 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.05 on epoch=30
05/22/2022 15:00:04 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.04 on epoch=30
05/22/2022 15:00:07 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.27 on epoch=30
05/22/2022 15:00:09 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.05 on epoch=31
05/22/2022 15:00:12 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=31
05/22/2022 15:00:34 - INFO - __main__ - Global step 1750 Train loss 0.09 Classification-F1 0.4374368479194676 on epoch=31
05/22/2022 15:00:37 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.04 on epoch=31
05/22/2022 15:00:39 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.06 on epoch=31
05/22/2022 15:00:42 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.09 on epoch=31
05/22/2022 15:00:45 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.28 on epoch=31
05/22/2022 15:00:47 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.05 on epoch=32
05/22/2022 15:01:10 - INFO - __main__ - Global step 1800 Train loss 0.10 Classification-F1 0.4276085626002246 on epoch=32
05/22/2022 15:01:12 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=32
05/22/2022 15:01:15 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.05 on epoch=32
05/22/2022 15:01:17 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.04 on epoch=32
05/22/2022 15:01:20 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.11 on epoch=32
05/22/2022 15:01:23 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.04 on epoch=33
05/22/2022 15:01:44 - INFO - __main__ - Global step 1850 Train loss 0.05 Classification-F1 0.41898548468549496 on epoch=33
05/22/2022 15:01:47 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.05 on epoch=33
05/22/2022 15:01:49 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.03 on epoch=33
05/22/2022 15:01:52 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=33
05/22/2022 15:01:55 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.06 on epoch=33
05/22/2022 15:01:57 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.04 on epoch=33
05/22/2022 15:02:19 - INFO - __main__ - Global step 1900 Train loss 0.04 Classification-F1 0.34247608392468243 on epoch=33
05/22/2022 15:02:21 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=34
05/22/2022 15:02:24 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.04 on epoch=34
05/22/2022 15:02:27 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=34
05/22/2022 15:02:29 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=34
05/22/2022 15:02:32 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.06 on epoch=34
05/22/2022 15:02:54 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.5222290019004768 on epoch=34
05/22/2022 15:02:57 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=34
05/22/2022 15:02:59 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.08 on epoch=35
05/22/2022 15:03:02 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=35
05/22/2022 15:03:04 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.04 on epoch=35
05/22/2022 15:03:07 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.04 on epoch=35
05/22/2022 15:03:29 - INFO - __main__ - Global step 2000 Train loss 0.04 Classification-F1 0.5541966196616857 on epoch=35
05/22/2022 15:03:32 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.23 on epoch=35
05/22/2022 15:03:34 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=36
05/22/2022 15:03:37 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=36
05/22/2022 15:03:40 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.05 on epoch=36
05/22/2022 15:03:42 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.02 on epoch=36
05/22/2022 15:04:04 - INFO - __main__ - Global step 2050 Train loss 0.06 Classification-F1 0.5287705715555836 on epoch=36
05/22/2022 15:04:07 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.05 on epoch=36
05/22/2022 15:04:09 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.04 on epoch=36
05/22/2022 15:04:12 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.07 on epoch=37
05/22/2022 15:04:15 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.03 on epoch=37
05/22/2022 15:04:17 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=37
05/22/2022 15:04:39 - INFO - __main__ - Global step 2100 Train loss 0.05 Classification-F1 0.449645628091321 on epoch=37
05/22/2022 15:04:42 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=37
05/22/2022 15:04:45 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.26 on epoch=37
05/22/2022 15:04:47 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=38
05/22/2022 15:04:50 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.07 on epoch=38
05/22/2022 15:04:52 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.03 on epoch=38
05/22/2022 15:05:14 - INFO - __main__ - Global step 2150 Train loss 0.08 Classification-F1 0.5633776151790454 on epoch=38
05/22/2022 15:05:16 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=38
05/22/2022 15:05:19 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.07 on epoch=38
05/22/2022 15:05:22 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.26 on epoch=38
05/22/2022 15:05:24 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.08 on epoch=39
05/22/2022 15:05:27 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=39
05/22/2022 15:05:49 - INFO - __main__ - Global step 2200 Train loss 0.09 Classification-F1 0.44154418278427476 on epoch=39
05/22/2022 15:05:51 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.03 on epoch=39
05/22/2022 15:05:54 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=39
05/22/2022 15:05:56 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.25 on epoch=39
05/22/2022 15:05:59 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.07 on epoch=39
05/22/2022 15:06:02 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.06 on epoch=40
05/22/2022 15:06:24 - INFO - __main__ - Global step 2250 Train loss 0.09 Classification-F1 0.4072047278903894 on epoch=40
05/22/2022 15:06:26 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=40
05/22/2022 15:06:29 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.04 on epoch=40
05/22/2022 15:06:31 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.04 on epoch=40
05/22/2022 15:06:34 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.24 on epoch=40
05/22/2022 15:06:37 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.04 on epoch=41
05/22/2022 15:06:59 - INFO - __main__ - Global step 2300 Train loss 0.07 Classification-F1 0.5964754798710907 on epoch=41
05/22/2022 15:07:01 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=41
05/22/2022 15:07:04 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=41
05/22/2022 15:07:07 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=41
05/22/2022 15:07:09 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.03 on epoch=41
05/22/2022 15:07:12 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.25 on epoch=41
05/22/2022 15:07:34 - INFO - __main__ - Global step 2350 Train loss 0.07 Classification-F1 0.45255365361214295 on epoch=41
05/22/2022 15:07:36 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.08 on epoch=42
05/22/2022 15:07:39 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.06 on epoch=42
05/22/2022 15:07:42 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=42
05/22/2022 15:07:44 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.04 on epoch=42
05/22/2022 15:07:47 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=42
05/22/2022 15:08:09 - INFO - __main__ - Global step 2400 Train loss 0.04 Classification-F1 0.4437479756195756 on epoch=42
05/22/2022 15:08:11 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=43
05/22/2022 15:08:14 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=43
05/22/2022 15:08:16 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=43
05/22/2022 15:08:19 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=43
05/22/2022 15:08:22 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.03 on epoch=43
05/22/2022 15:08:44 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.7005671214583602 on epoch=43
05/22/2022 15:08:44 - INFO - __main__ - Saving model with best Classification-F1: 0.692716533621052 -> 0.7005671214583602 on epoch=43, global_step=2450
05/22/2022 15:08:47 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.02 on epoch=43
05/22/2022 15:08:50 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=44
05/22/2022 15:08:52 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.03 on epoch=44
05/22/2022 15:08:55 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=44
05/22/2022 15:08:57 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=44
05/22/2022 15:09:20 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.5293236386781028 on epoch=44
05/22/2022 15:09:23 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=44
05/22/2022 15:09:25 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=44
05/22/2022 15:09:28 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.03 on epoch=45
05/22/2022 15:09:31 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=45
05/22/2022 15:09:33 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=45
05/22/2022 15:09:55 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.7475291903030691 on epoch=45
05/22/2022 15:09:55 - INFO - __main__ - Saving model with best Classification-F1: 0.7005671214583602 -> 0.7475291903030691 on epoch=45, global_step=2550
05/22/2022 15:09:58 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=45
05/22/2022 15:10:01 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=45
05/22/2022 15:10:03 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.03 on epoch=46
05/22/2022 15:10:06 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.05 on epoch=46
05/22/2022 15:10:08 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=46
05/22/2022 15:10:31 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.6189968534936922 on epoch=46
05/22/2022 15:10:33 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.05 on epoch=46
05/22/2022 15:10:36 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.05 on epoch=46
05/22/2022 15:10:38 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.03 on epoch=46
05/22/2022 15:10:41 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=47
05/22/2022 15:10:44 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.07 on epoch=47
05/22/2022 15:11:06 - INFO - __main__ - Global step 2650 Train loss 0.04 Classification-F1 0.5872249739953547 on epoch=47
05/22/2022 15:11:09 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=47
05/22/2022 15:11:11 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.03 on epoch=47
05/22/2022 15:11:14 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.27 on epoch=47
05/22/2022 15:11:17 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=48
05/22/2022 15:11:19 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=48
05/22/2022 15:11:42 - INFO - __main__ - Global step 2700 Train loss 0.07 Classification-F1 0.5824229131384897 on epoch=48
05/22/2022 15:11:45 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=48
05/22/2022 15:11:47 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=48
05/22/2022 15:11:50 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.08 on epoch=48
05/22/2022 15:11:52 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=48
05/22/2022 15:11:55 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=49
05/22/2022 15:12:17 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.46134454112297196 on epoch=49
05/22/2022 15:12:19 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=49
05/22/2022 15:12:22 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=49
05/22/2022 15:12:25 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.03 on epoch=49
05/22/2022 15:12:27 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=49
05/22/2022 15:12:30 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.04 on epoch=49
05/22/2022 15:12:52 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.6367863609330959 on epoch=49
05/22/2022 15:12:55 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.05 on epoch=50
05/22/2022 15:12:57 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=50
05/22/2022 15:13:00 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.04 on epoch=50
05/22/2022 15:13:03 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.04 on epoch=50
05/22/2022 15:13:05 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.22 on epoch=50
05/22/2022 15:13:28 - INFO - __main__ - Global step 2850 Train loss 0.07 Classification-F1 0.44950348901347276 on epoch=50
05/22/2022 15:13:30 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=51
05/22/2022 15:13:33 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=51
05/22/2022 15:13:36 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.04 on epoch=51
05/22/2022 15:13:38 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=51
05/22/2022 15:13:41 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.05 on epoch=51
05/22/2022 15:14:04 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.6263870959274096 on epoch=51
05/22/2022 15:14:06 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=51
05/22/2022 15:14:09 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=52
05/22/2022 15:14:11 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=52
05/22/2022 15:14:14 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.04 on epoch=52
05/22/2022 15:14:17 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=52
05/22/2022 15:14:39 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.6462581440473212 on epoch=52
05/22/2022 15:14:41 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.26 on epoch=52
05/22/2022 15:14:44 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=53
05/22/2022 15:14:47 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=53
05/22/2022 15:14:49 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.04 on epoch=53
05/22/2022 15:14:52 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=53
05/22/2022 15:14:53 - INFO - __main__ - Start tokenizing ... 896 instances
05/22/2022 15:14:53 - INFO - __main__ - Printing 3 examples
05/22/2022 15:14:53 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/22/2022 15:14:53 - INFO - __main__ - ['Animal']
05/22/2022 15:14:53 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/22/2022 15:14:53 - INFO - __main__ - ['Animal']
05/22/2022 15:14:53 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/22/2022 15:14:53 - INFO - __main__ - ['Animal']
05/22/2022 15:14:53 - INFO - __main__ - Tokenizing Input ...
05/22/2022 15:14:54 - INFO - __main__ - Tokenizing Output ...
05/22/2022 15:14:54 - INFO - __main__ - Loaded 896 examples from train data
05/22/2022 15:14:54 - INFO - __main__ - Start tokenizing ... 896 instances
05/22/2022 15:14:54 - INFO - __main__ - Printing 3 examples
05/22/2022 15:14:54 - INFO - __main__ -  [dbpedia_14] Metareva aenescens is a moth of the Arctiidae family. It was described by Hampson in 1900. It is found in Bolivia.
05/22/2022 15:14:54 - INFO - __main__ - ['Animal']
05/22/2022 15:14:54 - INFO - __main__ -  [dbpedia_14] Xenopipo is a genus of bird in the Pipridae family. It contains the following species: Black Manakin (Xenopipo atronitens) Yellow-headed Manakin (Xenopipo flavicapilla) Green Manakin (Xenopipo holochlora) Jet Manakin (Xenopipo unicolor) Olive Manakin (Xenopipo uniformis)
05/22/2022 15:14:54 - INFO - __main__ - ['Animal']
05/22/2022 15:14:54 - INFO - __main__ -  [dbpedia_14] The Tardy Renia (Renia nemoralis) is a moth of the Noctuidae family. It is found from Illinois to south-eastern Massachusetts south to Florida and Texas.The wingspan is 28-30 mm. There is one generation per year.The larvae feed on organic matter including dead leaves.
05/22/2022 15:14:54 - INFO - __main__ - ['Animal']
05/22/2022 15:14:54 - INFO - __main__ - Tokenizing Input ...
05/22/2022 15:14:55 - INFO - __main__ - Tokenizing Output ...
05/22/2022 15:14:56 - INFO - __main__ - Loaded 896 examples from dev data
05/22/2022 15:15:14 - INFO - __main__ - Global step 3000 Train loss 0.06 Classification-F1 0.5560360417412732 on epoch=53
05/22/2022 15:15:14 - INFO - __main__ - save last model!
05/22/2022 15:15:14 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/22/2022 15:15:14 - INFO - __main__ - Start tokenizing ... 3500 instances
05/22/2022 15:15:14 - INFO - __main__ - Printing 3 examples
05/22/2022 15:15:14 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/22/2022 15:15:14 - INFO - __main__ - ['Animal']
05/22/2022 15:15:14 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/22/2022 15:15:14 - INFO - __main__ - ['Animal']
05/22/2022 15:15:14 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/22/2022 15:15:14 - INFO - __main__ - ['Village']
05/22/2022 15:15:14 - INFO - __main__ - Tokenizing Input ...
05/22/2022 15:15:15 - INFO - __main__ - try to initialize prompt embeddings
05/22/2022 15:15:15 - INFO - __main__ - task name: dbpedia_14
05/22/2022 15:15:16 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 15:15:16 - INFO - __main__ - Starting training!
05/22/2022 15:15:16 - INFO - __main__ - Tokenizing Output ...
05/22/2022 15:15:19 - INFO - __main__ - Loaded 3500 examples from test data
05/22/2022 15:17:23 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down64shot/singletask-dbpedia_14/dbpedia_14_64_100_0.5_8_predictions.txt
05/22/2022 15:17:23 - INFO - __main__ - Classification-F1 on test data: 0.4215
05/22/2022 15:17:23 - INFO - __main__ - prefix=dbpedia_14_64_100, lr=0.5, bsz=8, dev_performance=0.7475291903030691, test_performance=0.421512725959678
05/22/2022 15:17:23 - INFO - __main__ - Running ... prefix=dbpedia_14_64_100, lr=0.4, bsz=8 ...
05/22/2022 15:17:24 - INFO - __main__ - Start tokenizing ... 896 instances
05/22/2022 15:17:24 - INFO - __main__ - Printing 3 examples
05/22/2022 15:17:24 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/22/2022 15:17:24 - INFO - __main__ - ['Animal']
05/22/2022 15:17:24 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/22/2022 15:17:24 - INFO - __main__ - ['Animal']
05/22/2022 15:17:24 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/22/2022 15:17:24 - INFO - __main__ - ['Animal']
05/22/2022 15:17:24 - INFO - __main__ - Tokenizing Input ...
05/22/2022 15:17:25 - INFO - __main__ - Tokenizing Output ...
05/22/2022 15:17:26 - INFO - __main__ - Loaded 896 examples from train data
05/22/2022 15:17:26 - INFO - __main__ - Start tokenizing ... 896 instances
05/22/2022 15:17:26 - INFO - __main__ - Printing 3 examples
05/22/2022 15:17:26 - INFO - __main__ -  [dbpedia_14] Metareva aenescens is a moth of the Arctiidae family. It was described by Hampson in 1900. It is found in Bolivia.
05/22/2022 15:17:26 - INFO - __main__ - ['Animal']
05/22/2022 15:17:26 - INFO - __main__ -  [dbpedia_14] Xenopipo is a genus of bird in the Pipridae family. It contains the following species: Black Manakin (Xenopipo atronitens) Yellow-headed Manakin (Xenopipo flavicapilla) Green Manakin (Xenopipo holochlora) Jet Manakin (Xenopipo unicolor) Olive Manakin (Xenopipo uniformis)
05/22/2022 15:17:26 - INFO - __main__ - ['Animal']
05/22/2022 15:17:26 - INFO - __main__ -  [dbpedia_14] The Tardy Renia (Renia nemoralis) is a moth of the Noctuidae family. It is found from Illinois to south-eastern Massachusetts south to Florida and Texas.The wingspan is 28-30 mm. There is one generation per year.The larvae feed on organic matter including dead leaves.
05/22/2022 15:17:26 - INFO - __main__ - ['Animal']
05/22/2022 15:17:26 - INFO - __main__ - Tokenizing Input ...
05/22/2022 15:17:26 - INFO - __main__ - Tokenizing Output ...
05/22/2022 15:17:27 - INFO - __main__ - Loaded 896 examples from dev data
05/22/2022 15:17:43 - INFO - __main__ - try to initialize prompt embeddings
05/22/2022 15:17:43 - INFO - __main__ - task name: dbpedia_14
05/22/2022 15:17:43 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 15:17:43 - INFO - __main__ - Starting training!
05/22/2022 15:17:46 - INFO - __main__ - Step 10 Global step 10 Train loss 6.94 on epoch=0
05/22/2022 15:17:49 - INFO - __main__ - Step 20 Global step 20 Train loss 5.03 on epoch=0
05/22/2022 15:17:52 - INFO - __main__ - Step 30 Global step 30 Train loss 3.74 on epoch=0
05/22/2022 15:17:54 - INFO - __main__ - Step 40 Global step 40 Train loss 2.72 on epoch=0
05/22/2022 15:17:57 - INFO - __main__ - Step 50 Global step 50 Train loss 2.29 on epoch=0
05/22/2022 15:18:26 - INFO - __main__ - Global step 50 Train loss 4.14 Classification-F1 0.192546771245397 on epoch=0
05/22/2022 15:18:26 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.192546771245397 on epoch=0, global_step=50
05/22/2022 15:18:29 - INFO - __main__ - Step 60 Global step 60 Train loss 1.91 on epoch=1
05/22/2022 15:18:31 - INFO - __main__ - Step 70 Global step 70 Train loss 1.48 on epoch=1
05/22/2022 15:18:34 - INFO - __main__ - Step 80 Global step 80 Train loss 1.23 on epoch=1
05/22/2022 15:18:36 - INFO - __main__ - Step 90 Global step 90 Train loss 1.22 on epoch=1
05/22/2022 15:18:39 - INFO - __main__ - Step 100 Global step 100 Train loss 1.10 on epoch=1
05/22/2022 15:19:08 - INFO - __main__ - Global step 100 Train loss 1.39 Classification-F1 0.24268974068158436 on epoch=1
05/22/2022 15:19:08 - INFO - __main__ - Saving model with best Classification-F1: 0.192546771245397 -> 0.24268974068158436 on epoch=1, global_step=100
05/22/2022 15:19:10 - INFO - __main__ - Step 110 Global step 110 Train loss 1.19 on epoch=1
05/22/2022 15:19:13 - INFO - __main__ - Step 120 Global step 120 Train loss 0.85 on epoch=2
05/22/2022 15:19:15 - INFO - __main__ - Step 130 Global step 130 Train loss 0.94 on epoch=2
05/22/2022 15:19:18 - INFO - __main__ - Step 140 Global step 140 Train loss 0.98 on epoch=2
05/22/2022 15:19:20 - INFO - __main__ - Step 150 Global step 150 Train loss 0.80 on epoch=2
05/22/2022 15:19:48 - INFO - __main__ - Global step 150 Train loss 0.95 Classification-F1 0.3672646647907323 on epoch=2
05/22/2022 15:19:48 - INFO - __main__ - Saving model with best Classification-F1: 0.24268974068158436 -> 0.3672646647907323 on epoch=2, global_step=150
05/22/2022 15:19:51 - INFO - __main__ - Step 160 Global step 160 Train loss 0.84 on epoch=2
05/22/2022 15:19:53 - INFO - __main__ - Step 170 Global step 170 Train loss 0.87 on epoch=3
05/22/2022 15:19:56 - INFO - __main__ - Step 180 Global step 180 Train loss 0.74 on epoch=3
05/22/2022 15:19:59 - INFO - __main__ - Step 190 Global step 190 Train loss 0.73 on epoch=3
05/22/2022 15:20:01 - INFO - __main__ - Step 200 Global step 200 Train loss 0.74 on epoch=3
05/22/2022 15:20:29 - INFO - __main__ - Global step 200 Train loss 0.78 Classification-F1 0.4530933721456423 on epoch=3
05/22/2022 15:20:29 - INFO - __main__ - Saving model with best Classification-F1: 0.3672646647907323 -> 0.4530933721456423 on epoch=3, global_step=200
05/22/2022 15:20:32 - INFO - __main__ - Step 210 Global step 210 Train loss 0.61 on epoch=3
05/22/2022 15:20:34 - INFO - __main__ - Step 220 Global step 220 Train loss 0.67 on epoch=3
05/22/2022 15:20:37 - INFO - __main__ - Step 230 Global step 230 Train loss 0.58 on epoch=4
05/22/2022 15:20:39 - INFO - __main__ - Step 240 Global step 240 Train loss 0.60 on epoch=4
05/22/2022 15:20:42 - INFO - __main__ - Step 250 Global step 250 Train loss 0.57 on epoch=4
05/22/2022 15:21:13 - INFO - __main__ - Global step 250 Train loss 0.61 Classification-F1 0.5452366870450598 on epoch=4
05/22/2022 15:21:13 - INFO - __main__ - Saving model with best Classification-F1: 0.4530933721456423 -> 0.5452366870450598 on epoch=4, global_step=250
05/22/2022 15:21:15 - INFO - __main__ - Step 260 Global step 260 Train loss 0.59 on epoch=4
05/22/2022 15:21:18 - INFO - __main__ - Step 270 Global step 270 Train loss 0.67 on epoch=4
05/22/2022 15:21:20 - INFO - __main__ - Step 280 Global step 280 Train loss 0.53 on epoch=4
05/22/2022 15:21:23 - INFO - __main__ - Step 290 Global step 290 Train loss 0.47 on epoch=5
05/22/2022 15:21:25 - INFO - __main__ - Step 300 Global step 300 Train loss 0.56 on epoch=5
05/22/2022 15:21:51 - INFO - __main__ - Global step 300 Train loss 0.56 Classification-F1 0.5043817432291665 on epoch=5
05/22/2022 15:21:54 - INFO - __main__ - Step 310 Global step 310 Train loss 0.64 on epoch=5
05/22/2022 15:21:56 - INFO - __main__ - Step 320 Global step 320 Train loss 0.46 on epoch=5
05/22/2022 15:21:59 - INFO - __main__ - Step 330 Global step 330 Train loss 0.61 on epoch=5
05/22/2022 15:22:01 - INFO - __main__ - Step 340 Global step 340 Train loss 0.39 on epoch=6
05/22/2022 15:22:04 - INFO - __main__ - Step 350 Global step 350 Train loss 0.50 on epoch=6
05/22/2022 15:22:31 - INFO - __main__ - Global step 350 Train loss 0.52 Classification-F1 0.490160767636357 on epoch=6
05/22/2022 15:22:34 - INFO - __main__ - Step 360 Global step 360 Train loss 0.35 on epoch=6
05/22/2022 15:22:37 - INFO - __main__ - Step 370 Global step 370 Train loss 0.44 on epoch=6
05/22/2022 15:22:39 - INFO - __main__ - Step 380 Global step 380 Train loss 0.44 on epoch=6
05/22/2022 15:22:42 - INFO - __main__ - Step 390 Global step 390 Train loss 0.53 on epoch=6
05/22/2022 15:22:44 - INFO - __main__ - Step 400 Global step 400 Train loss 0.26 on epoch=7
05/22/2022 15:23:10 - INFO - __main__ - Global step 400 Train loss 0.40 Classification-F1 0.6261145217959785 on epoch=7
05/22/2022 15:23:10 - INFO - __main__ - Saving model with best Classification-F1: 0.5452366870450598 -> 0.6261145217959785 on epoch=7, global_step=400
05/22/2022 15:23:13 - INFO - __main__ - Step 410 Global step 410 Train loss 0.39 on epoch=7
05/22/2022 15:23:15 - INFO - __main__ - Step 420 Global step 420 Train loss 0.34 on epoch=7
05/22/2022 15:23:18 - INFO - __main__ - Step 430 Global step 430 Train loss 0.35 on epoch=7
05/22/2022 15:23:20 - INFO - __main__ - Step 440 Global step 440 Train loss 0.50 on epoch=7
05/22/2022 15:23:23 - INFO - __main__ - Step 450 Global step 450 Train loss 0.25 on epoch=8
05/22/2022 15:23:49 - INFO - __main__ - Global step 450 Train loss 0.36 Classification-F1 0.5108346134542875 on epoch=8
05/22/2022 15:23:51 - INFO - __main__ - Step 460 Global step 460 Train loss 0.28 on epoch=8
05/22/2022 15:23:54 - INFO - __main__ - Step 470 Global step 470 Train loss 0.31 on epoch=8
05/22/2022 15:23:56 - INFO - __main__ - Step 480 Global step 480 Train loss 0.34 on epoch=8
05/22/2022 15:23:59 - INFO - __main__ - Step 490 Global step 490 Train loss 0.24 on epoch=8
05/22/2022 15:24:01 - INFO - __main__ - Step 500 Global step 500 Train loss 0.44 on epoch=8
05/22/2022 15:24:27 - INFO - __main__ - Global step 500 Train loss 0.32 Classification-F1 0.5995435001456824 on epoch=8
05/22/2022 15:24:30 - INFO - __main__ - Step 510 Global step 510 Train loss 0.24 on epoch=9
05/22/2022 15:24:32 - INFO - __main__ - Step 520 Global step 520 Train loss 0.24 on epoch=9
05/22/2022 15:24:35 - INFO - __main__ - Step 530 Global step 530 Train loss 0.16 on epoch=9
05/22/2022 15:24:38 - INFO - __main__ - Step 540 Global step 540 Train loss 0.26 on epoch=9
05/22/2022 15:24:40 - INFO - __main__ - Step 550 Global step 550 Train loss 0.43 on epoch=9
05/22/2022 15:25:06 - INFO - __main__ - Global step 550 Train loss 0.26 Classification-F1 0.49327764054875195 on epoch=9
05/22/2022 15:25:09 - INFO - __main__ - Step 560 Global step 560 Train loss 0.20 on epoch=9
05/22/2022 15:25:11 - INFO - __main__ - Step 570 Global step 570 Train loss 0.18 on epoch=10
05/22/2022 15:25:14 - INFO - __main__ - Step 580 Global step 580 Train loss 0.18 on epoch=10
05/22/2022 15:25:16 - INFO - __main__ - Step 590 Global step 590 Train loss 0.19 on epoch=10
05/22/2022 15:25:19 - INFO - __main__ - Step 600 Global step 600 Train loss 0.26 on epoch=10
05/22/2022 15:25:47 - INFO - __main__ - Global step 600 Train loss 0.20 Classification-F1 0.578304660915215 on epoch=10
05/22/2022 15:25:49 - INFO - __main__ - Step 610 Global step 610 Train loss 0.43 on epoch=10
05/22/2022 15:25:52 - INFO - __main__ - Step 620 Global step 620 Train loss 0.17 on epoch=11
05/22/2022 15:25:54 - INFO - __main__ - Step 630 Global step 630 Train loss 0.23 on epoch=11
05/22/2022 15:25:57 - INFO - __main__ - Step 640 Global step 640 Train loss 0.17 on epoch=11
05/22/2022 15:25:59 - INFO - __main__ - Step 650 Global step 650 Train loss 0.20 on epoch=11
05/22/2022 15:26:26 - INFO - __main__ - Global step 650 Train loss 0.24 Classification-F1 0.6532270273394422 on epoch=11
05/22/2022 15:26:26 - INFO - __main__ - Saving model with best Classification-F1: 0.6261145217959785 -> 0.6532270273394422 on epoch=11, global_step=650
05/22/2022 15:26:29 - INFO - __main__ - Step 660 Global step 660 Train loss 0.18 on epoch=11
05/22/2022 15:26:31 - INFO - __main__ - Step 670 Global step 670 Train loss 0.32 on epoch=11
05/22/2022 15:26:34 - INFO - __main__ - Step 680 Global step 680 Train loss 0.17 on epoch=12
05/22/2022 15:26:36 - INFO - __main__ - Step 690 Global step 690 Train loss 0.15 on epoch=12
05/22/2022 15:26:39 - INFO - __main__ - Step 700 Global step 700 Train loss 0.20 on epoch=12
05/22/2022 15:27:06 - INFO - __main__ - Global step 700 Train loss 0.21 Classification-F1 0.558132326253543 on epoch=12
05/22/2022 15:27:08 - INFO - __main__ - Step 710 Global step 710 Train loss 0.19 on epoch=12
05/22/2022 15:27:11 - INFO - __main__ - Step 720 Global step 720 Train loss 0.14 on epoch=12
05/22/2022 15:27:13 - INFO - __main__ - Step 730 Global step 730 Train loss 0.18 on epoch=13
05/22/2022 15:27:16 - INFO - __main__ - Step 740 Global step 740 Train loss 0.11 on epoch=13
05/22/2022 15:27:18 - INFO - __main__ - Step 750 Global step 750 Train loss 0.17 on epoch=13
05/22/2022 15:27:47 - INFO - __main__ - Global step 750 Train loss 0.16 Classification-F1 0.6391382008195234 on epoch=13
05/22/2022 15:27:49 - INFO - __main__ - Step 760 Global step 760 Train loss 0.17 on epoch=13
05/22/2022 15:27:52 - INFO - __main__ - Step 770 Global step 770 Train loss 0.20 on epoch=13
05/22/2022 15:27:54 - INFO - __main__ - Step 780 Global step 780 Train loss 0.17 on epoch=13
05/22/2022 15:27:57 - INFO - __main__ - Step 790 Global step 790 Train loss 0.18 on epoch=14
05/22/2022 15:27:59 - INFO - __main__ - Step 800 Global step 800 Train loss 0.13 on epoch=14
05/22/2022 15:28:28 - INFO - __main__ - Global step 800 Train loss 0.17 Classification-F1 0.5058354328873015 on epoch=14
05/22/2022 15:28:31 - INFO - __main__ - Step 810 Global step 810 Train loss 0.12 on epoch=14
05/22/2022 15:28:33 - INFO - __main__ - Step 820 Global step 820 Train loss 0.19 on epoch=14
05/22/2022 15:28:36 - INFO - __main__ - Step 830 Global step 830 Train loss 0.37 on epoch=14
05/22/2022 15:28:38 - INFO - __main__ - Step 840 Global step 840 Train loss 0.12 on epoch=14
05/22/2022 15:28:41 - INFO - __main__ - Step 850 Global step 850 Train loss 0.14 on epoch=15
05/22/2022 15:29:10 - INFO - __main__ - Global step 850 Train loss 0.19 Classification-F1 0.648192267777862 on epoch=15
05/22/2022 15:29:13 - INFO - __main__ - Step 860 Global step 860 Train loss 0.12 on epoch=15
05/22/2022 15:29:15 - INFO - __main__ - Step 870 Global step 870 Train loss 0.17 on epoch=15
05/22/2022 15:29:18 - INFO - __main__ - Step 880 Global step 880 Train loss 0.13 on epoch=15
05/22/2022 15:29:20 - INFO - __main__ - Step 890 Global step 890 Train loss 0.11 on epoch=15
05/22/2022 15:29:23 - INFO - __main__ - Step 900 Global step 900 Train loss 0.11 on epoch=16
05/22/2022 15:29:50 - INFO - __main__ - Global step 900 Train loss 0.13 Classification-F1 0.5842825447300984 on epoch=16
05/22/2022 15:29:53 - INFO - __main__ - Step 910 Global step 910 Train loss 0.11 on epoch=16
05/22/2022 15:29:56 - INFO - __main__ - Step 920 Global step 920 Train loss 0.14 on epoch=16
05/22/2022 15:29:58 - INFO - __main__ - Step 930 Global step 930 Train loss 0.11 on epoch=16
05/22/2022 15:30:01 - INFO - __main__ - Step 940 Global step 940 Train loss 0.14 on epoch=16
05/22/2022 15:30:03 - INFO - __main__ - Step 950 Global step 950 Train loss 0.15 on epoch=16
05/22/2022 15:30:28 - INFO - __main__ - Global step 950 Train loss 0.13 Classification-F1 0.48779872740303043 on epoch=16
05/22/2022 15:30:30 - INFO - __main__ - Step 960 Global step 960 Train loss 0.12 on epoch=17
05/22/2022 15:30:33 - INFO - __main__ - Step 970 Global step 970 Train loss 0.14 on epoch=17
05/22/2022 15:30:36 - INFO - __main__ - Step 980 Global step 980 Train loss 0.10 on epoch=17
05/22/2022 15:30:38 - INFO - __main__ - Step 990 Global step 990 Train loss 0.13 on epoch=17
05/22/2022 15:30:41 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.13 on epoch=17
05/22/2022 15:31:10 - INFO - __main__ - Global step 1000 Train loss 0.12 Classification-F1 0.3813887336990914 on epoch=17
05/22/2022 15:31:13 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.12 on epoch=18
05/22/2022 15:31:15 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.07 on epoch=18
05/22/2022 15:31:18 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.08 on epoch=18
05/22/2022 15:31:20 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.13 on epoch=18
05/22/2022 15:31:23 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.09 on epoch=18
05/22/2022 15:31:50 - INFO - __main__ - Global step 1050 Train loss 0.10 Classification-F1 0.744508569327087 on epoch=18
05/22/2022 15:31:50 - INFO - __main__ - Saving model with best Classification-F1: 0.6532270273394422 -> 0.744508569327087 on epoch=18, global_step=1050
05/22/2022 15:31:53 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.13 on epoch=18
05/22/2022 15:31:55 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.16 on epoch=19
05/22/2022 15:31:58 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.10 on epoch=19
05/22/2022 15:32:00 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.11 on epoch=19
05/22/2022 15:32:03 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.09 on epoch=19
05/22/2022 15:32:32 - INFO - __main__ - Global step 1100 Train loss 0.12 Classification-F1 0.6109266797129264 on epoch=19
05/22/2022 15:32:35 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.31 on epoch=19
05/22/2022 15:32:37 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.11 on epoch=19
05/22/2022 15:32:40 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.12 on epoch=20
05/22/2022 15:32:42 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.06 on epoch=20
05/22/2022 15:32:45 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.09 on epoch=20
05/22/2022 15:33:13 - INFO - __main__ - Global step 1150 Train loss 0.14 Classification-F1 0.49704265278340465 on epoch=20
05/22/2022 15:33:15 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.14 on epoch=20
05/22/2022 15:33:18 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.13 on epoch=20
05/22/2022 15:33:20 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.11 on epoch=21
05/22/2022 15:33:23 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.08 on epoch=21
05/22/2022 15:33:26 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.04 on epoch=21
05/22/2022 15:33:54 - INFO - __main__ - Global step 1200 Train loss 0.10 Classification-F1 0.5702978424322848 on epoch=21
05/22/2022 15:33:57 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.09 on epoch=21
05/22/2022 15:34:00 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.08 on epoch=21
05/22/2022 15:34:02 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.32 on epoch=21
05/22/2022 15:34:05 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.07 on epoch=22
05/22/2022 15:34:07 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.04 on epoch=22
05/22/2022 15:34:37 - INFO - __main__ - Global step 1250 Train loss 0.12 Classification-F1 0.5662074822992578 on epoch=22
05/22/2022 15:34:39 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.09 on epoch=22
05/22/2022 15:34:42 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.08 on epoch=22
05/22/2022 15:34:44 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.18 on epoch=22
05/22/2022 15:34:47 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.09 on epoch=23
05/22/2022 15:34:49 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.07 on epoch=23
05/22/2022 15:35:14 - INFO - __main__ - Global step 1300 Train loss 0.10 Classification-F1 0.5111599544969233 on epoch=23
05/22/2022 15:35:16 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.08 on epoch=23
05/22/2022 15:35:19 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.14 on epoch=23
05/22/2022 15:35:21 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.11 on epoch=23
05/22/2022 15:35:24 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.10 on epoch=23
05/22/2022 15:35:26 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.08 on epoch=24
05/22/2022 15:35:55 - INFO - __main__ - Global step 1350 Train loss 0.10 Classification-F1 0.49504582502415817 on epoch=24
05/22/2022 15:35:57 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.03 on epoch=24
05/22/2022 15:36:00 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.08 on epoch=24
05/22/2022 15:36:02 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.06 on epoch=24
05/22/2022 15:36:05 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.13 on epoch=24
05/22/2022 15:36:07 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.11 on epoch=24
05/22/2022 15:36:35 - INFO - __main__ - Global step 1400 Train loss 0.08 Classification-F1 0.3948581115141786 on epoch=24
05/22/2022 15:36:38 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.05 on epoch=25
05/22/2022 15:36:40 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.04 on epoch=25
05/22/2022 15:36:43 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.05 on epoch=25
05/22/2022 15:36:46 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.08 on epoch=25
05/22/2022 15:36:48 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.29 on epoch=25
05/22/2022 15:37:14 - INFO - __main__ - Global step 1450 Train loss 0.10 Classification-F1 0.4758897136956323 on epoch=25
05/22/2022 15:37:17 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.08 on epoch=26
05/22/2022 15:37:19 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.04 on epoch=26
05/22/2022 15:37:22 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.06 on epoch=26
05/22/2022 15:37:24 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.06 on epoch=26
05/22/2022 15:37:27 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.07 on epoch=26
05/22/2022 15:37:56 - INFO - __main__ - Global step 1500 Train loss 0.06 Classification-F1 0.5720402802917411 on epoch=26
05/22/2022 15:37:58 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.07 on epoch=26
05/22/2022 15:38:01 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.08 on epoch=27
05/22/2022 15:38:03 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.04 on epoch=27
05/22/2022 15:38:06 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.07 on epoch=27
05/22/2022 15:38:09 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.07 on epoch=27
05/22/2022 15:38:38 - INFO - __main__ - Global step 1550 Train loss 0.07 Classification-F1 0.800680062535647 on epoch=27
05/22/2022 15:38:38 - INFO - __main__ - Saving model with best Classification-F1: 0.744508569327087 -> 0.800680062535647 on epoch=27, global_step=1550
05/22/2022 15:38:41 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.33 on epoch=27
05/22/2022 15:38:43 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.08 on epoch=28
05/22/2022 15:38:46 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.03 on epoch=28
05/22/2022 15:38:48 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.05 on epoch=28
05/22/2022 15:38:51 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.04 on epoch=28
05/22/2022 15:39:21 - INFO - __main__ - Global step 1600 Train loss 0.11 Classification-F1 0.6339374136487246 on epoch=28
05/22/2022 15:39:24 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.08 on epoch=28
05/22/2022 15:39:26 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.07 on epoch=28
05/22/2022 15:39:29 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.03 on epoch=29
05/22/2022 15:39:32 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.08 on epoch=29
05/22/2022 15:39:34 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.05 on epoch=29
05/22/2022 15:40:01 - INFO - __main__ - Global step 1650 Train loss 0.06 Classification-F1 0.7035577571861357 on epoch=29
05/22/2022 15:40:04 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.12 on epoch=29
05/22/2022 15:40:06 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.24 on epoch=29
05/22/2022 15:40:09 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.06 on epoch=29
05/22/2022 15:40:11 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.11 on epoch=30
05/22/2022 15:40:14 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=30
05/22/2022 15:40:42 - INFO - __main__ - Global step 1700 Train loss 0.11 Classification-F1 0.5938732853384442 on epoch=30
05/22/2022 15:40:44 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.10 on epoch=30
05/22/2022 15:40:47 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.08 on epoch=30
05/22/2022 15:40:50 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=30
05/22/2022 15:40:52 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.08 on epoch=31
05/22/2022 15:40:55 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.10 on epoch=31
05/22/2022 15:41:24 - INFO - __main__ - Global step 1750 Train loss 0.07 Classification-F1 0.7064137875851869 on epoch=31
05/22/2022 15:41:27 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.07 on epoch=31
05/22/2022 15:41:29 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.04 on epoch=31
05/22/2022 15:41:32 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.04 on epoch=31
05/22/2022 15:41:34 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.26 on epoch=31
05/22/2022 15:41:37 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.06 on epoch=32
05/22/2022 15:42:01 - INFO - __main__ - Global step 1800 Train loss 0.09 Classification-F1 0.4676497869690893 on epoch=32
05/22/2022 15:42:04 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=32
05/22/2022 15:42:07 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.08 on epoch=32
05/22/2022 15:42:09 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.09 on epoch=32
05/22/2022 15:42:12 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.25 on epoch=32
05/22/2022 15:42:15 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.07 on epoch=33
05/22/2022 15:42:38 - INFO - __main__ - Global step 1850 Train loss 0.10 Classification-F1 0.483793775489575 on epoch=33
05/22/2022 15:42:41 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.05 on epoch=33
05/22/2022 15:42:43 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.04 on epoch=33
05/22/2022 15:42:46 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.04 on epoch=33
05/22/2022 15:42:48 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.05 on epoch=33
05/22/2022 15:42:51 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.06 on epoch=33
05/22/2022 15:43:15 - INFO - __main__ - Global step 1900 Train loss 0.05 Classification-F1 0.40082290943267834 on epoch=33
05/22/2022 15:43:18 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.05 on epoch=34
05/22/2022 15:43:20 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.05 on epoch=34
05/22/2022 15:43:23 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.06 on epoch=34
05/22/2022 15:43:25 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.05 on epoch=34
05/22/2022 15:43:28 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.27 on epoch=34
05/22/2022 15:43:55 - INFO - __main__ - Global step 1950 Train loss 0.10 Classification-F1 0.5343225542340351 on epoch=34
05/22/2022 15:43:58 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.03 on epoch=34
05/22/2022 15:44:00 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.04 on epoch=35
05/22/2022 15:44:03 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=35
05/22/2022 15:44:06 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.06 on epoch=35
05/22/2022 15:44:08 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.06 on epoch=35
05/22/2022 15:44:36 - INFO - __main__ - Global step 2000 Train loss 0.04 Classification-F1 0.526748170719456 on epoch=35
05/22/2022 15:44:39 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.06 on epoch=35
05/22/2022 15:44:42 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.05 on epoch=36
05/22/2022 15:44:44 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.03 on epoch=36
05/22/2022 15:44:47 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=36
05/22/2022 15:44:49 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.06 on epoch=36
05/22/2022 15:45:17 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.669921198532402 on epoch=36
05/22/2022 15:45:19 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.05 on epoch=36
05/22/2022 15:45:22 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.03 on epoch=36
05/22/2022 15:45:24 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.05 on epoch=37
05/22/2022 15:45:27 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.05 on epoch=37
05/22/2022 15:45:30 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.07 on epoch=37
05/22/2022 15:45:59 - INFO - __main__ - Global step 2100 Train loss 0.05 Classification-F1 0.5022861821199708 on epoch=37
05/22/2022 15:46:01 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.06 on epoch=37
05/22/2022 15:46:04 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.08 on epoch=37
05/22/2022 15:46:06 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=38
05/22/2022 15:46:09 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=38
05/22/2022 15:46:12 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.07 on epoch=38
05/22/2022 15:46:39 - INFO - __main__ - Global step 2150 Train loss 0.05 Classification-F1 0.5928895430090706 on epoch=38
05/22/2022 15:46:42 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.05 on epoch=38
05/22/2022 15:46:44 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.04 on epoch=38
05/22/2022 15:46:47 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=38
05/22/2022 15:46:50 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.05 on epoch=39
05/22/2022 15:46:52 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.08 on epoch=39
05/22/2022 15:47:17 - INFO - __main__ - Global step 2200 Train loss 0.05 Classification-F1 0.573414424698543 on epoch=39
05/22/2022 15:47:20 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.03 on epoch=39
05/22/2022 15:47:22 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.08 on epoch=39
05/22/2022 15:47:25 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.06 on epoch=39
05/22/2022 15:47:28 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.03 on epoch=39
05/22/2022 15:47:30 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.14 on epoch=40
05/22/2022 15:47:56 - INFO - __main__ - Global step 2250 Train loss 0.07 Classification-F1 0.41952916956772424 on epoch=40
05/22/2022 15:47:59 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=40
05/22/2022 15:48:01 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=40
05/22/2022 15:48:04 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.06 on epoch=40
05/22/2022 15:48:07 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.08 on epoch=40
05/22/2022 15:48:09 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=41
05/22/2022 15:48:34 - INFO - __main__ - Global step 2300 Train loss 0.04 Classification-F1 0.5221944378548424 on epoch=41
05/22/2022 15:48:37 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.04 on epoch=41
05/22/2022 15:48:39 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.05 on epoch=41
05/22/2022 15:48:42 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.04 on epoch=41
05/22/2022 15:48:44 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.09 on epoch=41
05/22/2022 15:48:47 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=41
05/22/2022 15:49:11 - INFO - __main__ - Global step 2350 Train loss 0.05 Classification-F1 0.5125024011503588 on epoch=41
05/22/2022 15:49:14 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=42
05/22/2022 15:49:16 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=42
05/22/2022 15:49:19 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.13 on epoch=42
05/22/2022 15:49:21 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=42
05/22/2022 15:49:24 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.07 on epoch=42
05/22/2022 15:49:49 - INFO - __main__ - Global step 2400 Train loss 0.05 Classification-F1 0.4982325700534049 on epoch=42
05/22/2022 15:49:51 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.04 on epoch=43
05/22/2022 15:49:54 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=43
05/22/2022 15:49:57 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=43
05/22/2022 15:49:59 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=43
05/22/2022 15:50:02 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.07 on epoch=43
05/22/2022 15:50:25 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.5199181335359226 on epoch=43
05/22/2022 15:50:28 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.08 on epoch=43
05/22/2022 15:50:30 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=44
05/22/2022 15:50:33 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.03 on epoch=44
05/22/2022 15:50:35 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.04 on epoch=44
05/22/2022 15:50:38 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.05 on epoch=44
05/22/2022 15:51:01 - INFO - __main__ - Global step 2500 Train loss 0.04 Classification-F1 0.46978735595771215 on epoch=44
05/22/2022 15:51:04 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.07 on epoch=44
05/22/2022 15:51:07 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.03 on epoch=44
05/22/2022 15:51:09 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.12 on epoch=45
05/22/2022 15:51:12 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=45
05/22/2022 15:51:14 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.04 on epoch=45
05/22/2022 15:51:38 - INFO - __main__ - Global step 2550 Train loss 0.06 Classification-F1 0.48958779033677075 on epoch=45
05/22/2022 15:51:41 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.04 on epoch=45
05/22/2022 15:51:43 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.04 on epoch=45
05/22/2022 15:51:46 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.05 on epoch=46
05/22/2022 15:51:49 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.04 on epoch=46
05/22/2022 15:51:51 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.05 on epoch=46
05/22/2022 15:52:15 - INFO - __main__ - Global step 2600 Train loss 0.04 Classification-F1 0.4994518875682492 on epoch=46
05/22/2022 15:52:17 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.03 on epoch=46
05/22/2022 15:52:20 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.03 on epoch=46
05/22/2022 15:52:23 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.32 on epoch=46
05/22/2022 15:52:25 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=47
05/22/2022 15:52:28 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=47
05/22/2022 15:52:51 - INFO - __main__ - Global step 2650 Train loss 0.09 Classification-F1 0.42845170850475767 on epoch=47
05/22/2022 15:52:54 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=47
05/22/2022 15:52:56 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.04 on epoch=47
05/22/2022 15:52:59 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.27 on epoch=47
05/22/2022 15:53:01 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=48
05/22/2022 15:53:04 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.03 on epoch=48
05/22/2022 15:53:27 - INFO - __main__ - Global step 2700 Train loss 0.08 Classification-F1 0.489938638623872 on epoch=48
05/22/2022 15:53:30 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=48
05/22/2022 15:53:33 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=48
05/22/2022 15:53:35 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=48
05/22/2022 15:53:38 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.03 on epoch=48
05/22/2022 15:53:40 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=49
05/22/2022 15:54:03 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.4762555081862474 on epoch=49
05/22/2022 15:54:05 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.03 on epoch=49
05/22/2022 15:54:08 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.03 on epoch=49
05/22/2022 15:54:10 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=49
05/22/2022 15:54:13 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.05 on epoch=49
05/22/2022 15:54:16 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.04 on epoch=49
05/22/2022 15:54:38 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.5260516655097419 on epoch=49
05/22/2022 15:54:41 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=50
05/22/2022 15:54:44 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=50
05/22/2022 15:54:46 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.04 on epoch=50
05/22/2022 15:54:49 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.03 on epoch=50
05/22/2022 15:54:52 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.03 on epoch=50
05/22/2022 15:55:14 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.4850108935751793 on epoch=50
05/22/2022 15:55:16 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.03 on epoch=51
05/22/2022 15:55:19 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.04 on epoch=51
05/22/2022 15:55:22 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=51
05/22/2022 15:55:24 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.03 on epoch=51
05/22/2022 15:55:27 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.03 on epoch=51
05/22/2022 15:55:50 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.5598293873205041 on epoch=51
05/22/2022 15:55:52 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.04 on epoch=51
05/22/2022 15:55:55 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.05 on epoch=52
05/22/2022 15:55:58 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=52
05/22/2022 15:56:00 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=52
05/22/2022 15:56:03 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.03 on epoch=52
05/22/2022 15:56:26 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.552798059992996 on epoch=52
05/22/2022 15:56:29 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.03 on epoch=52
05/22/2022 15:56:31 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=53
05/22/2022 15:56:34 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.03 on epoch=53
05/22/2022 15:56:36 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=53
05/22/2022 15:56:39 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=53
05/22/2022 15:56:40 - INFO - __main__ - Start tokenizing ... 896 instances
05/22/2022 15:56:40 - INFO - __main__ - Printing 3 examples
05/22/2022 15:56:40 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/22/2022 15:56:40 - INFO - __main__ - ['Animal']
05/22/2022 15:56:40 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/22/2022 15:56:40 - INFO - __main__ - ['Animal']
05/22/2022 15:56:40 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/22/2022 15:56:40 - INFO - __main__ - ['Animal']
05/22/2022 15:56:40 - INFO - __main__ - Tokenizing Input ...
05/22/2022 15:56:41 - INFO - __main__ - Tokenizing Output ...
05/22/2022 15:56:42 - INFO - __main__ - Loaded 896 examples from train data
05/22/2022 15:56:42 - INFO - __main__ - Start tokenizing ... 896 instances
05/22/2022 15:56:42 - INFO - __main__ - Printing 3 examples
05/22/2022 15:56:42 - INFO - __main__ -  [dbpedia_14] Metareva aenescens is a moth of the Arctiidae family. It was described by Hampson in 1900. It is found in Bolivia.
05/22/2022 15:56:42 - INFO - __main__ - ['Animal']
05/22/2022 15:56:42 - INFO - __main__ -  [dbpedia_14] Xenopipo is a genus of bird in the Pipridae family. It contains the following species: Black Manakin (Xenopipo atronitens) Yellow-headed Manakin (Xenopipo flavicapilla) Green Manakin (Xenopipo holochlora) Jet Manakin (Xenopipo unicolor) Olive Manakin (Xenopipo uniformis)
05/22/2022 15:56:42 - INFO - __main__ - ['Animal']
05/22/2022 15:56:42 - INFO - __main__ -  [dbpedia_14] The Tardy Renia (Renia nemoralis) is a moth of the Noctuidae family. It is found from Illinois to south-eastern Massachusetts south to Florida and Texas.The wingspan is 28-30 mm. There is one generation per year.The larvae feed on organic matter including dead leaves.
05/22/2022 15:56:42 - INFO - __main__ - ['Animal']
05/22/2022 15:56:42 - INFO - __main__ - Tokenizing Input ...
05/22/2022 15:56:42 - INFO - __main__ - Tokenizing Output ...
05/22/2022 15:56:43 - INFO - __main__ - Loaded 896 examples from dev data
05/22/2022 15:56:59 - INFO - __main__ - try to initialize prompt embeddings
05/22/2022 15:56:59 - INFO - __main__ - task name: dbpedia_14
05/22/2022 15:56:59 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 15:56:59 - INFO - __main__ - Starting training!
05/22/2022 15:57:02 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.639435631350596 on epoch=53
05/22/2022 15:57:02 - INFO - __main__ - save last model!
05/22/2022 15:57:03 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/22/2022 15:57:03 - INFO - __main__ - Start tokenizing ... 3500 instances
05/22/2022 15:57:03 - INFO - __main__ - Printing 3 examples
05/22/2022 15:57:03 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/22/2022 15:57:03 - INFO - __main__ - ['Animal']
05/22/2022 15:57:03 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/22/2022 15:57:03 - INFO - __main__ - ['Animal']
05/22/2022 15:57:03 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/22/2022 15:57:03 - INFO - __main__ - ['Village']
05/22/2022 15:57:03 - INFO - __main__ - Tokenizing Input ...
05/22/2022 15:57:04 - INFO - __main__ - Tokenizing Output ...
05/22/2022 15:57:08 - INFO - __main__ - Loaded 3500 examples from test data
05/22/2022 15:59:15 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down64shot/singletask-dbpedia_14/dbpedia_14_64_100_0.4_8_predictions.txt
05/22/2022 15:59:15 - INFO - __main__ - Classification-F1 on test data: 0.4533
05/22/2022 15:59:15 - INFO - __main__ - prefix=dbpedia_14_64_100, lr=0.4, bsz=8, dev_performance=0.800680062535647, test_performance=0.45328759414577535
05/22/2022 15:59:15 - INFO - __main__ - Running ... prefix=dbpedia_14_64_100, lr=0.3, bsz=8 ...
05/22/2022 15:59:16 - INFO - __main__ - Start tokenizing ... 896 instances
05/22/2022 15:59:16 - INFO - __main__ - Printing 3 examples
05/22/2022 15:59:16 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/22/2022 15:59:16 - INFO - __main__ - ['Animal']
05/22/2022 15:59:16 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/22/2022 15:59:16 - INFO - __main__ - ['Animal']
05/22/2022 15:59:16 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/22/2022 15:59:16 - INFO - __main__ - ['Animal']
05/22/2022 15:59:16 - INFO - __main__ - Tokenizing Input ...
05/22/2022 15:59:17 - INFO - __main__ - Tokenizing Output ...
05/22/2022 15:59:18 - INFO - __main__ - Loaded 896 examples from train data
05/22/2022 15:59:18 - INFO - __main__ - Start tokenizing ... 896 instances
05/22/2022 15:59:18 - INFO - __main__ - Printing 3 examples
05/22/2022 15:59:18 - INFO - __main__ -  [dbpedia_14] Metareva aenescens is a moth of the Arctiidae family. It was described by Hampson in 1900. It is found in Bolivia.
05/22/2022 15:59:18 - INFO - __main__ - ['Animal']
05/22/2022 15:59:18 - INFO - __main__ -  [dbpedia_14] Xenopipo is a genus of bird in the Pipridae family. It contains the following species: Black Manakin (Xenopipo atronitens) Yellow-headed Manakin (Xenopipo flavicapilla) Green Manakin (Xenopipo holochlora) Jet Manakin (Xenopipo unicolor) Olive Manakin (Xenopipo uniformis)
05/22/2022 15:59:18 - INFO - __main__ - ['Animal']
05/22/2022 15:59:18 - INFO - __main__ -  [dbpedia_14] The Tardy Renia (Renia nemoralis) is a moth of the Noctuidae family. It is found from Illinois to south-eastern Massachusetts south to Florida and Texas.The wingspan is 28-30 mm. There is one generation per year.The larvae feed on organic matter including dead leaves.
05/22/2022 15:59:18 - INFO - __main__ - ['Animal']
05/22/2022 15:59:18 - INFO - __main__ - Tokenizing Input ...
05/22/2022 15:59:18 - INFO - __main__ - Tokenizing Output ...
05/22/2022 15:59:19 - INFO - __main__ - Loaded 896 examples from dev data
05/22/2022 15:59:38 - INFO - __main__ - try to initialize prompt embeddings
05/22/2022 15:59:38 - INFO - __main__ - task name: dbpedia_14
05/22/2022 15:59:39 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 15:59:39 - INFO - __main__ - Starting training!
05/22/2022 15:59:42 - INFO - __main__ - Step 10 Global step 10 Train loss 7.17 on epoch=0
05/22/2022 15:59:44 - INFO - __main__ - Step 20 Global step 20 Train loss 6.02 on epoch=0
05/22/2022 15:59:47 - INFO - __main__ - Step 30 Global step 30 Train loss 4.88 on epoch=0
05/22/2022 15:59:50 - INFO - __main__ - Step 40 Global step 40 Train loss 3.95 on epoch=0
05/22/2022 15:59:52 - INFO - __main__ - Step 50 Global step 50 Train loss 3.49 on epoch=0
05/22/2022 16:00:20 - INFO - __main__ - Global step 50 Train loss 5.10 Classification-F1 0.03919113519117474 on epoch=0
05/22/2022 16:00:20 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.03919113519117474 on epoch=0, global_step=50
05/22/2022 16:00:23 - INFO - __main__ - Step 60 Global step 60 Train loss 2.98 on epoch=1
05/22/2022 16:00:25 - INFO - __main__ - Step 70 Global step 70 Train loss 2.25 on epoch=1
05/22/2022 16:00:28 - INFO - __main__ - Step 80 Global step 80 Train loss 2.03 on epoch=1
05/22/2022 16:00:30 - INFO - __main__ - Step 90 Global step 90 Train loss 1.73 on epoch=1
05/22/2022 16:00:33 - INFO - __main__ - Step 100 Global step 100 Train loss 1.43 on epoch=1
05/22/2022 16:01:03 - INFO - __main__ - Global step 100 Train loss 2.09 Classification-F1 0.23730900015431125 on epoch=1
05/22/2022 16:01:03 - INFO - __main__ - Saving model with best Classification-F1: 0.03919113519117474 -> 0.23730900015431125 on epoch=1, global_step=100
05/22/2022 16:01:06 - INFO - __main__ - Step 110 Global step 110 Train loss 1.56 on epoch=1
05/22/2022 16:01:09 - INFO - __main__ - Step 120 Global step 120 Train loss 1.25 on epoch=2
05/22/2022 16:01:11 - INFO - __main__ - Step 130 Global step 130 Train loss 1.12 on epoch=2
05/22/2022 16:01:14 - INFO - __main__ - Step 140 Global step 140 Train loss 1.08 on epoch=2
05/22/2022 16:01:16 - INFO - __main__ - Step 150 Global step 150 Train loss 0.96 on epoch=2
05/22/2022 16:01:46 - INFO - __main__ - Global step 150 Train loss 1.19 Classification-F1 0.22971707765620253 on epoch=2
05/22/2022 16:01:48 - INFO - __main__ - Step 160 Global step 160 Train loss 1.00 on epoch=2
05/22/2022 16:01:51 - INFO - __main__ - Step 170 Global step 170 Train loss 1.03 on epoch=3
05/22/2022 16:01:54 - INFO - __main__ - Step 180 Global step 180 Train loss 0.88 on epoch=3
05/22/2022 16:01:56 - INFO - __main__ - Step 190 Global step 190 Train loss 0.78 on epoch=3
05/22/2022 16:01:59 - INFO - __main__ - Step 200 Global step 200 Train loss 0.91 on epoch=3
05/22/2022 16:02:24 - INFO - __main__ - Global step 200 Train loss 0.92 Classification-F1 0.3430102879476777 on epoch=3
05/22/2022 16:02:24 - INFO - __main__ - Saving model with best Classification-F1: 0.23730900015431125 -> 0.3430102879476777 on epoch=3, global_step=200
05/22/2022 16:02:27 - INFO - __main__ - Step 210 Global step 210 Train loss 0.85 on epoch=3
05/22/2022 16:02:30 - INFO - __main__ - Step 220 Global step 220 Train loss 0.96 on epoch=3
05/22/2022 16:02:32 - INFO - __main__ - Step 230 Global step 230 Train loss 0.76 on epoch=4
05/22/2022 16:02:35 - INFO - __main__ - Step 240 Global step 240 Train loss 0.65 on epoch=4
05/22/2022 16:02:37 - INFO - __main__ - Step 250 Global step 250 Train loss 0.71 on epoch=4
05/22/2022 16:03:05 - INFO - __main__ - Global step 250 Train loss 0.78 Classification-F1 0.5084042504600075 on epoch=4
05/22/2022 16:03:05 - INFO - __main__ - Saving model with best Classification-F1: 0.3430102879476777 -> 0.5084042504600075 on epoch=4, global_step=250
05/22/2022 16:03:08 - INFO - __main__ - Step 260 Global step 260 Train loss 0.67 on epoch=4
05/22/2022 16:03:10 - INFO - __main__ - Step 270 Global step 270 Train loss 0.69 on epoch=4
05/22/2022 16:03:13 - INFO - __main__ - Step 280 Global step 280 Train loss 0.62 on epoch=4
05/22/2022 16:03:15 - INFO - __main__ - Step 290 Global step 290 Train loss 0.61 on epoch=5
05/22/2022 16:03:18 - INFO - __main__ - Step 300 Global step 300 Train loss 0.67 on epoch=5
05/22/2022 16:03:44 - INFO - __main__ - Global step 300 Train loss 0.65 Classification-F1 0.30201877323226384 on epoch=5
05/22/2022 16:03:47 - INFO - __main__ - Step 310 Global step 310 Train loss 0.74 on epoch=5
05/22/2022 16:03:49 - INFO - __main__ - Step 320 Global step 320 Train loss 0.64 on epoch=5
05/22/2022 16:03:52 - INFO - __main__ - Step 330 Global step 330 Train loss 0.77 on epoch=5
05/22/2022 16:03:54 - INFO - __main__ - Step 340 Global step 340 Train loss 0.59 on epoch=6
05/22/2022 16:03:57 - INFO - __main__ - Step 350 Global step 350 Train loss 0.51 on epoch=6
05/22/2022 16:04:23 - INFO - __main__ - Global step 350 Train loss 0.65 Classification-F1 0.24789275385455195 on epoch=6
05/22/2022 16:04:25 - INFO - __main__ - Step 360 Global step 360 Train loss 0.58 on epoch=6
05/22/2022 16:04:28 - INFO - __main__ - Step 370 Global step 370 Train loss 0.49 on epoch=6
05/22/2022 16:04:30 - INFO - __main__ - Step 380 Global step 380 Train loss 0.51 on epoch=6
05/22/2022 16:04:33 - INFO - __main__ - Step 390 Global step 390 Train loss 0.59 on epoch=6
05/22/2022 16:04:35 - INFO - __main__ - Step 400 Global step 400 Train loss 0.49 on epoch=7
05/22/2022 16:05:03 - INFO - __main__ - Global step 400 Train loss 0.53 Classification-F1 0.32694733803752585 on epoch=7
05/22/2022 16:05:05 - INFO - __main__ - Step 410 Global step 410 Train loss 0.54 on epoch=7
05/22/2022 16:05:08 - INFO - __main__ - Step 420 Global step 420 Train loss 0.53 on epoch=7
05/22/2022 16:05:10 - INFO - __main__ - Step 430 Global step 430 Train loss 0.48 on epoch=7
05/22/2022 16:05:13 - INFO - __main__ - Step 440 Global step 440 Train loss 0.44 on epoch=7
05/22/2022 16:05:15 - INFO - __main__ - Step 450 Global step 450 Train loss 0.46 on epoch=8
05/22/2022 16:05:42 - INFO - __main__ - Global step 450 Train loss 0.49 Classification-F1 0.409318023645988 on epoch=8
05/22/2022 16:05:44 - INFO - __main__ - Step 460 Global step 460 Train loss 0.44 on epoch=8
05/22/2022 16:05:47 - INFO - __main__ - Step 470 Global step 470 Train loss 0.51 on epoch=8
05/22/2022 16:05:50 - INFO - __main__ - Step 480 Global step 480 Train loss 0.40 on epoch=8
05/22/2022 16:05:52 - INFO - __main__ - Step 490 Global step 490 Train loss 0.36 on epoch=8
05/22/2022 16:05:55 - INFO - __main__ - Step 500 Global step 500 Train loss 0.60 on epoch=8
05/22/2022 16:06:20 - INFO - __main__ - Global step 500 Train loss 0.46 Classification-F1 0.4042691106388074 on epoch=8
05/22/2022 16:06:22 - INFO - __main__ - Step 510 Global step 510 Train loss 0.43 on epoch=9
05/22/2022 16:06:25 - INFO - __main__ - Step 520 Global step 520 Train loss 0.43 on epoch=9
05/22/2022 16:06:27 - INFO - __main__ - Step 530 Global step 530 Train loss 0.51 on epoch=9
05/22/2022 16:06:30 - INFO - __main__ - Step 540 Global step 540 Train loss 0.47 on epoch=9
05/22/2022 16:06:32 - INFO - __main__ - Step 550 Global step 550 Train loss 0.41 on epoch=9
05/22/2022 16:06:58 - INFO - __main__ - Global step 550 Train loss 0.45 Classification-F1 0.5535230948726172 on epoch=9
05/22/2022 16:06:58 - INFO - __main__ - Saving model with best Classification-F1: 0.5084042504600075 -> 0.5535230948726172 on epoch=9, global_step=550
05/22/2022 16:07:00 - INFO - __main__ - Step 560 Global step 560 Train loss 0.42 on epoch=9
05/22/2022 16:07:03 - INFO - __main__ - Step 570 Global step 570 Train loss 0.38 on epoch=10
05/22/2022 16:07:05 - INFO - __main__ - Step 580 Global step 580 Train loss 0.40 on epoch=10
05/22/2022 16:07:08 - INFO - __main__ - Step 590 Global step 590 Train loss 0.49 on epoch=10
05/22/2022 16:07:11 - INFO - __main__ - Step 600 Global step 600 Train loss 0.43 on epoch=10
05/22/2022 16:07:36 - INFO - __main__ - Global step 600 Train loss 0.42 Classification-F1 0.5875640146905016 on epoch=10
05/22/2022 16:07:36 - INFO - __main__ - Saving model with best Classification-F1: 0.5535230948726172 -> 0.5875640146905016 on epoch=10, global_step=600
05/22/2022 16:07:39 - INFO - __main__ - Step 610 Global step 610 Train loss 0.58 on epoch=10
05/22/2022 16:07:41 - INFO - __main__ - Step 620 Global step 620 Train loss 0.36 on epoch=11
05/22/2022 16:07:44 - INFO - __main__ - Step 630 Global step 630 Train loss 0.36 on epoch=11
05/22/2022 16:07:46 - INFO - __main__ - Step 640 Global step 640 Train loss 0.45 on epoch=11
05/22/2022 16:07:49 - INFO - __main__ - Step 650 Global step 650 Train loss 0.45 on epoch=11
05/22/2022 16:08:14 - INFO - __main__ - Global step 650 Train loss 0.44 Classification-F1 0.5731824498965574 on epoch=11
05/22/2022 16:08:17 - INFO - __main__ - Step 660 Global step 660 Train loss 0.26 on epoch=11
05/22/2022 16:08:19 - INFO - __main__ - Step 670 Global step 670 Train loss 0.37 on epoch=11
05/22/2022 16:08:22 - INFO - __main__ - Step 680 Global step 680 Train loss 0.36 on epoch=12
05/22/2022 16:08:24 - INFO - __main__ - Step 690 Global step 690 Train loss 0.29 on epoch=12
05/22/2022 16:08:27 - INFO - __main__ - Step 700 Global step 700 Train loss 0.37 on epoch=12
05/22/2022 16:08:53 - INFO - __main__ - Global step 700 Train loss 0.33 Classification-F1 0.6723135519447347 on epoch=12
05/22/2022 16:08:53 - INFO - __main__ - Saving model with best Classification-F1: 0.5875640146905016 -> 0.6723135519447347 on epoch=12, global_step=700
05/22/2022 16:08:55 - INFO - __main__ - Step 710 Global step 710 Train loss 0.33 on epoch=12
05/22/2022 16:08:58 - INFO - __main__ - Step 720 Global step 720 Train loss 0.36 on epoch=12
05/22/2022 16:09:00 - INFO - __main__ - Step 730 Global step 730 Train loss 0.35 on epoch=13
05/22/2022 16:09:03 - INFO - __main__ - Step 740 Global step 740 Train loss 0.27 on epoch=13
05/22/2022 16:09:06 - INFO - __main__ - Step 750 Global step 750 Train loss 0.40 on epoch=13
05/22/2022 16:09:31 - INFO - __main__ - Global step 750 Train loss 0.34 Classification-F1 0.5129999133124646 on epoch=13
05/22/2022 16:09:34 - INFO - __main__ - Step 760 Global step 760 Train loss 0.41 on epoch=13
05/22/2022 16:09:37 - INFO - __main__ - Step 770 Global step 770 Train loss 0.40 on epoch=13
05/22/2022 16:09:39 - INFO - __main__ - Step 780 Global step 780 Train loss 0.53 on epoch=13
05/22/2022 16:09:42 - INFO - __main__ - Step 790 Global step 790 Train loss 0.34 on epoch=14
05/22/2022 16:09:44 - INFO - __main__ - Step 800 Global step 800 Train loss 0.33 on epoch=14
05/22/2022 16:10:10 - INFO - __main__ - Global step 800 Train loss 0.40 Classification-F1 0.6564328115677536 on epoch=14
05/22/2022 16:10:13 - INFO - __main__ - Step 810 Global step 810 Train loss 0.38 on epoch=14
05/22/2022 16:10:15 - INFO - __main__ - Step 820 Global step 820 Train loss 0.37 on epoch=14
05/22/2022 16:10:18 - INFO - __main__ - Step 830 Global step 830 Train loss 0.37 on epoch=14
05/22/2022 16:10:20 - INFO - __main__ - Step 840 Global step 840 Train loss 0.42 on epoch=14
05/22/2022 16:10:23 - INFO - __main__ - Step 850 Global step 850 Train loss 0.26 on epoch=15
05/22/2022 16:10:50 - INFO - __main__ - Global step 850 Train loss 0.36 Classification-F1 0.6230544444130697 on epoch=15
05/22/2022 16:10:52 - INFO - __main__ - Step 860 Global step 860 Train loss 0.23 on epoch=15
05/22/2022 16:10:55 - INFO - __main__ - Step 870 Global step 870 Train loss 0.36 on epoch=15
05/22/2022 16:10:57 - INFO - __main__ - Step 880 Global step 880 Train loss 0.33 on epoch=15
05/22/2022 16:11:00 - INFO - __main__ - Step 890 Global step 890 Train loss 0.50 on epoch=15
05/22/2022 16:11:02 - INFO - __main__ - Step 900 Global step 900 Train loss 0.27 on epoch=16
05/22/2022 16:11:27 - INFO - __main__ - Global step 900 Train loss 0.34 Classification-F1 0.6770180680523072 on epoch=16
05/22/2022 16:11:27 - INFO - __main__ - Saving model with best Classification-F1: 0.6723135519447347 -> 0.6770180680523072 on epoch=16, global_step=900
05/22/2022 16:11:30 - INFO - __main__ - Step 910 Global step 910 Train loss 0.28 on epoch=16
05/22/2022 16:11:32 - INFO - __main__ - Step 920 Global step 920 Train loss 0.27 on epoch=16
05/22/2022 16:11:35 - INFO - __main__ - Step 930 Global step 930 Train loss 0.30 on epoch=16
05/22/2022 16:11:37 - INFO - __main__ - Step 940 Global step 940 Train loss 0.26 on epoch=16
05/22/2022 16:11:40 - INFO - __main__ - Step 950 Global step 950 Train loss 0.27 on epoch=16
05/22/2022 16:12:06 - INFO - __main__ - Global step 950 Train loss 0.28 Classification-F1 0.48149960924366825 on epoch=16
05/22/2022 16:12:08 - INFO - __main__ - Step 960 Global step 960 Train loss 0.28 on epoch=17
05/22/2022 16:12:11 - INFO - __main__ - Step 970 Global step 970 Train loss 0.26 on epoch=17
05/22/2022 16:12:14 - INFO - __main__ - Step 980 Global step 980 Train loss 0.28 on epoch=17
05/22/2022 16:12:16 - INFO - __main__ - Step 990 Global step 990 Train loss 0.22 on epoch=17
05/22/2022 16:12:19 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.45 on epoch=17
05/22/2022 16:12:43 - INFO - __main__ - Global step 1000 Train loss 0.30 Classification-F1 0.4761689582318607 on epoch=17
05/22/2022 16:12:45 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.23 on epoch=18
05/22/2022 16:12:48 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.21 on epoch=18
05/22/2022 16:12:50 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.23 on epoch=18
05/22/2022 16:12:53 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.24 on epoch=18
05/22/2022 16:12:55 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.18 on epoch=18
05/22/2022 16:13:20 - INFO - __main__ - Global step 1050 Train loss 0.22 Classification-F1 0.686942549735311 on epoch=18
05/22/2022 16:13:20 - INFO - __main__ - Saving model with best Classification-F1: 0.6770180680523072 -> 0.686942549735311 on epoch=18, global_step=1050
05/22/2022 16:13:22 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.47 on epoch=18
05/22/2022 16:13:25 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.20 on epoch=19
05/22/2022 16:13:27 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.22 on epoch=19
05/22/2022 16:13:30 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.21 on epoch=19
05/22/2022 16:13:32 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.23 on epoch=19
05/22/2022 16:13:56 - INFO - __main__ - Global step 1100 Train loss 0.27 Classification-F1 0.5371285659783812 on epoch=19
05/22/2022 16:13:59 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.20 on epoch=19
05/22/2022 16:14:02 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.20 on epoch=19
05/22/2022 16:14:04 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.28 on epoch=20
05/22/2022 16:14:07 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.18 on epoch=20
05/22/2022 16:14:09 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.31 on epoch=20
05/22/2022 16:14:33 - INFO - __main__ - Global step 1150 Train loss 0.23 Classification-F1 0.5567337173771175 on epoch=20
05/22/2022 16:14:36 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.20 on epoch=20
05/22/2022 16:14:39 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.21 on epoch=20
05/22/2022 16:14:41 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.16 on epoch=21
05/22/2022 16:14:44 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.16 on epoch=21
05/22/2022 16:14:46 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.27 on epoch=21
05/22/2022 16:15:10 - INFO - __main__ - Global step 1200 Train loss 0.20 Classification-F1 0.5049717466772194 on epoch=21
05/22/2022 16:15:13 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.21 on epoch=21
05/22/2022 16:15:15 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.19 on epoch=21
05/22/2022 16:15:18 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.48 on epoch=21
05/22/2022 16:15:20 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.12 on epoch=22
05/22/2022 16:15:23 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.20 on epoch=22
05/22/2022 16:15:47 - INFO - __main__ - Global step 1250 Train loss 0.24 Classification-F1 0.6214009076175404 on epoch=22
05/22/2022 16:15:50 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.22 on epoch=22
05/22/2022 16:15:52 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.19 on epoch=22
05/22/2022 16:15:55 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.17 on epoch=22
05/22/2022 16:15:57 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.20 on epoch=23
05/22/2022 16:16:00 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.10 on epoch=23
05/22/2022 16:16:24 - INFO - __main__ - Global step 1300 Train loss 0.18 Classification-F1 0.629854257125367 on epoch=23
05/22/2022 16:16:26 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.18 on epoch=23
05/22/2022 16:16:29 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.18 on epoch=23
05/22/2022 16:16:31 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.17 on epoch=23
05/22/2022 16:16:34 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.19 on epoch=23
05/22/2022 16:16:37 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.13 on epoch=24
05/22/2022 16:17:00 - INFO - __main__ - Global step 1350 Train loss 0.17 Classification-F1 0.7033333580499241 on epoch=24
05/22/2022 16:17:00 - INFO - __main__ - Saving model with best Classification-F1: 0.686942549735311 -> 0.7033333580499241 on epoch=24, global_step=1350
05/22/2022 16:17:03 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.14 on epoch=24
05/22/2022 16:17:05 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.18 on epoch=24
05/22/2022 16:17:08 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.22 on epoch=24
05/22/2022 16:17:11 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.19 on epoch=24
05/22/2022 16:17:13 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.13 on epoch=24
05/22/2022 16:17:37 - INFO - __main__ - Global step 1400 Train loss 0.17 Classification-F1 0.5180444613424374 on epoch=24
05/22/2022 16:17:39 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.22 on epoch=25
05/22/2022 16:17:42 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.10 on epoch=25
05/22/2022 16:17:45 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.23 on epoch=25
05/22/2022 16:17:47 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.14 on epoch=25
05/22/2022 16:17:50 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.43 on epoch=25
05/22/2022 16:18:13 - INFO - __main__ - Global step 1450 Train loss 0.23 Classification-F1 0.5316491078762425 on epoch=25
05/22/2022 16:18:16 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.12 on epoch=26
05/22/2022 16:18:19 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.10 on epoch=26
05/22/2022 16:18:21 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.16 on epoch=26
05/22/2022 16:18:24 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.17 on epoch=26
05/22/2022 16:18:26 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.13 on epoch=26
05/22/2022 16:18:50 - INFO - __main__ - Global step 1500 Train loss 0.14 Classification-F1 0.7249383048362092 on epoch=26
05/22/2022 16:18:51 - INFO - __main__ - Saving model with best Classification-F1: 0.7033333580499241 -> 0.7249383048362092 on epoch=26, global_step=1500
05/22/2022 16:18:53 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.33 on epoch=26
05/22/2022 16:18:56 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.16 on epoch=27
05/22/2022 16:18:58 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.14 on epoch=27
05/22/2022 16:19:01 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.14 on epoch=27
05/22/2022 16:19:03 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.11 on epoch=27
05/22/2022 16:19:28 - INFO - __main__ - Global step 1550 Train loss 0.18 Classification-F1 0.7963486984803757 on epoch=27
05/22/2022 16:19:28 - INFO - __main__ - Saving model with best Classification-F1: 0.7249383048362092 -> 0.7963486984803757 on epoch=27, global_step=1550
05/22/2022 16:19:30 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.40 on epoch=27
05/22/2022 16:19:33 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.11 on epoch=28
05/22/2022 16:19:35 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.12 on epoch=28
05/22/2022 16:19:38 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.11 on epoch=28
05/22/2022 16:19:40 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.13 on epoch=28
05/22/2022 16:20:05 - INFO - __main__ - Global step 1600 Train loss 0.17 Classification-F1 0.7395161800996023 on epoch=28
05/22/2022 16:20:08 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.12 on epoch=28
05/22/2022 16:20:10 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.36 on epoch=28
05/22/2022 16:20:13 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.16 on epoch=29
05/22/2022 16:20:15 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.10 on epoch=29
05/22/2022 16:20:18 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.12 on epoch=29
05/22/2022 16:20:41 - INFO - __main__ - Global step 1650 Train loss 0.17 Classification-F1 0.7447852996880431 on epoch=29
05/22/2022 16:20:44 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.12 on epoch=29
05/22/2022 16:20:47 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.37 on epoch=29
05/22/2022 16:20:49 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.12 on epoch=29
05/22/2022 16:20:52 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.10 on epoch=30
05/22/2022 16:20:54 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.12 on epoch=30
05/22/2022 16:21:18 - INFO - __main__ - Global step 1700 Train loss 0.17 Classification-F1 0.7803029621068106 on epoch=30
05/22/2022 16:21:20 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.14 on epoch=30
05/22/2022 16:21:23 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.08 on epoch=30
05/22/2022 16:21:25 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.34 on epoch=30
05/22/2022 16:21:28 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.12 on epoch=31
05/22/2022 16:21:30 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.13 on epoch=31
05/22/2022 16:21:55 - INFO - __main__ - Global step 1750 Train loss 0.16 Classification-F1 0.5533200644658449 on epoch=31
05/22/2022 16:21:58 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.07 on epoch=31
05/22/2022 16:22:00 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.10 on epoch=31
05/22/2022 16:22:03 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.10 on epoch=31
05/22/2022 16:22:05 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.30 on epoch=31
05/22/2022 16:22:08 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.11 on epoch=32
05/22/2022 16:22:32 - INFO - __main__ - Global step 1800 Train loss 0.13 Classification-F1 0.6098211964545708 on epoch=32
05/22/2022 16:22:35 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.13 on epoch=32
05/22/2022 16:22:38 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.09 on epoch=32
05/22/2022 16:22:40 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.07 on epoch=32
05/22/2022 16:22:43 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.35 on epoch=32
05/22/2022 16:22:45 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.10 on epoch=33
05/22/2022 16:23:09 - INFO - __main__ - Global step 1850 Train loss 0.15 Classification-F1 0.7243515051158426 on epoch=33
05/22/2022 16:23:12 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.08 on epoch=33
05/22/2022 16:23:14 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.09 on epoch=33
05/22/2022 16:23:17 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.11 on epoch=33
05/22/2022 16:23:20 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.08 on epoch=33
05/22/2022 16:23:23 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.33 on epoch=33
05/22/2022 16:23:46 - INFO - __main__ - Global step 1900 Train loss 0.14 Classification-F1 0.5002279191159936 on epoch=33
05/22/2022 16:23:49 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.07 on epoch=34
05/22/2022 16:23:52 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.07 on epoch=34
05/22/2022 16:23:54 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.05 on epoch=34
05/22/2022 16:23:57 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.08 on epoch=34
05/22/2022 16:24:00 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.08 on epoch=34
05/22/2022 16:24:23 - INFO - __main__ - Global step 1950 Train loss 0.07 Classification-F1 0.6838027947996351 on epoch=34
05/22/2022 16:24:26 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.11 on epoch=34
05/22/2022 16:24:28 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.07 on epoch=35
05/22/2022 16:24:31 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.04 on epoch=35
05/22/2022 16:24:34 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.08 on epoch=35
05/22/2022 16:24:36 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.07 on epoch=35
05/22/2022 16:25:00 - INFO - __main__ - Global step 2000 Train loss 0.08 Classification-F1 0.6745114470632773 on epoch=35
05/22/2022 16:25:03 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.31 on epoch=35
05/22/2022 16:25:05 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.09 on epoch=36
05/22/2022 16:25:08 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.05 on epoch=36
05/22/2022 16:25:10 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.10 on epoch=36
05/22/2022 16:25:13 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.10 on epoch=36
05/22/2022 16:25:36 - INFO - __main__ - Global step 2050 Train loss 0.13 Classification-F1 0.5980825626778803 on epoch=36
05/22/2022 16:25:38 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.11 on epoch=36
05/22/2022 16:25:41 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.10 on epoch=36
05/22/2022 16:25:44 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.07 on epoch=37
05/22/2022 16:25:46 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.05 on epoch=37
05/22/2022 16:25:49 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.11 on epoch=37
05/22/2022 16:26:12 - INFO - __main__ - Global step 2100 Train loss 0.09 Classification-F1 0.6203126061937855 on epoch=37
05/22/2022 16:26:14 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.04 on epoch=37
05/22/2022 16:26:17 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.09 on epoch=37
05/22/2022 16:26:19 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.04 on epoch=38
05/22/2022 16:26:22 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.10 on epoch=38
05/22/2022 16:26:25 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.07 on epoch=38
05/22/2022 16:26:48 - INFO - __main__ - Global step 2150 Train loss 0.07 Classification-F1 0.6598690979437569 on epoch=38
05/22/2022 16:26:50 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.06 on epoch=38
05/22/2022 16:26:53 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.08 on epoch=38
05/22/2022 16:26:55 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.09 on epoch=38
05/22/2022 16:26:58 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.08 on epoch=39
05/22/2022 16:27:00 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.08 on epoch=39
05/22/2022 16:27:23 - INFO - __main__ - Global step 2200 Train loss 0.08 Classification-F1 0.5876594471875974 on epoch=39
05/22/2022 16:27:26 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=39
05/22/2022 16:27:28 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.07 on epoch=39
05/22/2022 16:27:31 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.28 on epoch=39
05/22/2022 16:27:33 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.08 on epoch=39
05/22/2022 16:27:36 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.18 on epoch=40
05/22/2022 16:27:59 - INFO - __main__ - Global step 2250 Train loss 0.13 Classification-F1 0.5241327951179516 on epoch=40
05/22/2022 16:28:01 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.04 on epoch=40
05/22/2022 16:28:04 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.06 on epoch=40
05/22/2022 16:28:07 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.07 on epoch=40
05/22/2022 16:28:09 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.28 on epoch=40
05/22/2022 16:28:12 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.06 on epoch=41
05/22/2022 16:28:35 - INFO - __main__ - Global step 2300 Train loss 0.10 Classification-F1 0.61167076859744 on epoch=41
05/22/2022 16:28:38 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.04 on epoch=41
05/22/2022 16:28:40 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.04 on epoch=41
05/22/2022 16:28:43 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.04 on epoch=41
05/22/2022 16:28:46 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.04 on epoch=41
05/22/2022 16:28:48 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.24 on epoch=41
05/22/2022 16:29:11 - INFO - __main__ - Global step 2350 Train loss 0.08 Classification-F1 0.6175952064552962 on epoch=41
05/22/2022 16:29:14 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.06 on epoch=42
05/22/2022 16:29:17 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=42
05/22/2022 16:29:19 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.05 on epoch=42
05/22/2022 16:29:22 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.07 on epoch=42
05/22/2022 16:29:24 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.29 on epoch=42
05/22/2022 16:29:47 - INFO - __main__ - Global step 2400 Train loss 0.10 Classification-F1 0.5470641323322678 on epoch=42
05/22/2022 16:29:50 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.04 on epoch=43
05/22/2022 16:29:52 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.11 on epoch=43
05/22/2022 16:29:55 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.06 on epoch=43
05/22/2022 16:29:58 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=43
05/22/2022 16:30:00 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.07 on epoch=43
05/22/2022 16:30:24 - INFO - __main__ - Global step 2450 Train loss 0.06 Classification-F1 0.77420030588865 on epoch=43
05/22/2022 16:30:26 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.04 on epoch=43
05/22/2022 16:30:29 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.05 on epoch=44
05/22/2022 16:30:31 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.08 on epoch=44
05/22/2022 16:30:34 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.04 on epoch=44
05/22/2022 16:30:37 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.04 on epoch=44
05/22/2022 16:31:01 - INFO - __main__ - Global step 2500 Train loss 0.05 Classification-F1 0.6987553486910913 on epoch=44
05/22/2022 16:31:03 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.24 on epoch=44
05/22/2022 16:31:06 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.08 on epoch=44
05/22/2022 16:31:08 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.04 on epoch=45
05/22/2022 16:31:11 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.03 on epoch=45
05/22/2022 16:31:14 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=45
05/22/2022 16:31:37 - INFO - __main__ - Global step 2550 Train loss 0.08 Classification-F1 0.7955659525298497 on epoch=45
05/22/2022 16:31:39 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.08 on epoch=45
05/22/2022 16:31:42 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.23 on epoch=45
05/22/2022 16:31:45 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=46
05/22/2022 16:31:47 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.03 on epoch=46
05/22/2022 16:31:50 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.05 on epoch=46
05/22/2022 16:32:13 - INFO - __main__ - Global step 2600 Train loss 0.08 Classification-F1 0.6944362822150989 on epoch=46
05/22/2022 16:32:15 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.05 on epoch=46
05/22/2022 16:32:18 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.08 on epoch=46
05/22/2022 16:32:21 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.23 on epoch=46
05/22/2022 16:32:23 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.09 on epoch=47
05/22/2022 16:32:26 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.03 on epoch=47
05/22/2022 16:32:50 - INFO - __main__ - Global step 2650 Train loss 0.10 Classification-F1 0.6977413426157297 on epoch=47
05/22/2022 16:32:52 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.06 on epoch=47
05/22/2022 16:32:55 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.03 on epoch=47
05/22/2022 16:32:57 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.32 on epoch=47
05/22/2022 16:33:00 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.03 on epoch=48
05/22/2022 16:33:03 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.06 on epoch=48
05/22/2022 16:33:26 - INFO - __main__ - Global step 2700 Train loss 0.10 Classification-F1 0.6675745676587428 on epoch=48
05/22/2022 16:33:28 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.09 on epoch=48
05/22/2022 16:33:31 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.04 on epoch=48
05/22/2022 16:33:33 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.05 on epoch=48
05/22/2022 16:33:36 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.26 on epoch=48
05/22/2022 16:33:39 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=49
05/22/2022 16:34:01 - INFO - __main__ - Global step 2750 Train loss 0.09 Classification-F1 0.6910753472352246 on epoch=49
05/22/2022 16:34:04 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.05 on epoch=49
05/22/2022 16:34:06 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.04 on epoch=49
05/22/2022 16:34:09 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.05 on epoch=49
05/22/2022 16:34:12 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.07 on epoch=49
05/22/2022 16:34:14 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.05 on epoch=49
05/22/2022 16:34:37 - INFO - __main__ - Global step 2800 Train loss 0.05 Classification-F1 0.7518621768333316 on epoch=49
05/22/2022 16:34:40 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.05 on epoch=50
05/22/2022 16:34:43 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.03 on epoch=50
05/22/2022 16:34:45 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=50
05/22/2022 16:34:48 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.05 on epoch=50
05/22/2022 16:34:51 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.27 on epoch=50
05/22/2022 16:35:13 - INFO - __main__ - Global step 2850 Train loss 0.08 Classification-F1 0.6354165245468152 on epoch=50
05/22/2022 16:35:16 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=51
05/22/2022 16:35:19 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.09 on epoch=51
05/22/2022 16:35:21 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.04 on epoch=51
05/22/2022 16:35:24 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.03 on epoch=51
05/22/2022 16:35:27 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.05 on epoch=51
05/22/2022 16:35:50 - INFO - __main__ - Global step 2900 Train loss 0.05 Classification-F1 0.7455585719264938 on epoch=51
05/22/2022 16:35:52 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.05 on epoch=51
05/22/2022 16:35:55 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.05 on epoch=52
05/22/2022 16:35:58 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=52
05/22/2022 16:36:00 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.05 on epoch=52
05/22/2022 16:36:03 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.04 on epoch=52
05/22/2022 16:36:26 - INFO - __main__ - Global step 2950 Train loss 0.04 Classification-F1 0.6668890359981866 on epoch=52
05/22/2022 16:36:29 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.26 on epoch=52
05/22/2022 16:36:31 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.09 on epoch=53
05/22/2022 16:36:34 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.05 on epoch=53
05/22/2022 16:36:37 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.03 on epoch=53
05/22/2022 16:36:39 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=53
05/22/2022 16:36:41 - INFO - __main__ - Start tokenizing ... 896 instances
05/22/2022 16:36:41 - INFO - __main__ - Printing 3 examples
05/22/2022 16:36:41 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/22/2022 16:36:41 - INFO - __main__ - ['Animal']
05/22/2022 16:36:41 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/22/2022 16:36:41 - INFO - __main__ - ['Animal']
05/22/2022 16:36:41 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/22/2022 16:36:41 - INFO - __main__ - ['Animal']
05/22/2022 16:36:41 - INFO - __main__ - Tokenizing Input ...
05/22/2022 16:36:41 - INFO - __main__ - Tokenizing Output ...
05/22/2022 16:36:42 - INFO - __main__ - Loaded 896 examples from train data
05/22/2022 16:36:42 - INFO - __main__ - Start tokenizing ... 896 instances
05/22/2022 16:36:42 - INFO - __main__ - Printing 3 examples
05/22/2022 16:36:42 - INFO - __main__ -  [dbpedia_14] Metareva aenescens is a moth of the Arctiidae family. It was described by Hampson in 1900. It is found in Bolivia.
05/22/2022 16:36:42 - INFO - __main__ - ['Animal']
05/22/2022 16:36:42 - INFO - __main__ -  [dbpedia_14] Xenopipo is a genus of bird in the Pipridae family. It contains the following species: Black Manakin (Xenopipo atronitens) Yellow-headed Manakin (Xenopipo flavicapilla) Green Manakin (Xenopipo holochlora) Jet Manakin (Xenopipo unicolor) Olive Manakin (Xenopipo uniformis)
05/22/2022 16:36:42 - INFO - __main__ - ['Animal']
05/22/2022 16:36:42 - INFO - __main__ -  [dbpedia_14] The Tardy Renia (Renia nemoralis) is a moth of the Noctuidae family. It is found from Illinois to south-eastern Massachusetts south to Florida and Texas.The wingspan is 28-30 mm. There is one generation per year.The larvae feed on organic matter including dead leaves.
05/22/2022 16:36:42 - INFO - __main__ - ['Animal']
05/22/2022 16:36:42 - INFO - __main__ - Tokenizing Input ...
05/22/2022 16:36:42 - INFO - __main__ - Tokenizing Output ...
05/22/2022 16:36:43 - INFO - __main__ - Loaded 896 examples from dev data
05/22/2022 16:36:59 - INFO - __main__ - try to initialize prompt embeddings
05/22/2022 16:36:59 - INFO - __main__ - task name: dbpedia_14
05/22/2022 16:36:59 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 16:36:59 - INFO - __main__ - Starting training!
05/22/2022 16:37:03 - INFO - __main__ - Global step 3000 Train loss 0.09 Classification-F1 0.7874930087120118 on epoch=53
05/22/2022 16:37:03 - INFO - __main__ - save last model!
05/22/2022 16:37:03 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/22/2022 16:37:03 - INFO - __main__ - Start tokenizing ... 3500 instances
05/22/2022 16:37:03 - INFO - __main__ - Printing 3 examples
05/22/2022 16:37:03 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/22/2022 16:37:03 - INFO - __main__ - ['Animal']
05/22/2022 16:37:03 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/22/2022 16:37:03 - INFO - __main__ - ['Animal']
05/22/2022 16:37:03 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/22/2022 16:37:03 - INFO - __main__ - ['Village']
05/22/2022 16:37:03 - INFO - __main__ - Tokenizing Input ...
05/22/2022 16:37:05 - INFO - __main__ - Tokenizing Output ...
05/22/2022 16:37:08 - INFO - __main__ - Loaded 3500 examples from test data
05/22/2022 16:39:14 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down64shot/singletask-dbpedia_14/dbpedia_14_64_100_0.3_8_predictions.txt
05/22/2022 16:39:14 - INFO - __main__ - Classification-F1 on test data: 0.5172
05/22/2022 16:39:14 - INFO - __main__ - prefix=dbpedia_14_64_100, lr=0.3, bsz=8, dev_performance=0.7963486984803757, test_performance=0.5172337323208839
05/22/2022 16:39:14 - INFO - __main__ - Running ... prefix=dbpedia_14_64_100, lr=0.2, bsz=8 ...
05/22/2022 16:39:15 - INFO - __main__ - Start tokenizing ... 896 instances
05/22/2022 16:39:15 - INFO - __main__ - Printing 3 examples
05/22/2022 16:39:15 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/22/2022 16:39:15 - INFO - __main__ - ['Animal']
05/22/2022 16:39:15 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/22/2022 16:39:15 - INFO - __main__ - ['Animal']
05/22/2022 16:39:15 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/22/2022 16:39:15 - INFO - __main__ - ['Animal']
05/22/2022 16:39:15 - INFO - __main__ - Tokenizing Input ...
05/22/2022 16:39:16 - INFO - __main__ - Tokenizing Output ...
05/22/2022 16:39:17 - INFO - __main__ - Loaded 896 examples from train data
05/22/2022 16:39:17 - INFO - __main__ - Start tokenizing ... 896 instances
05/22/2022 16:39:17 - INFO - __main__ - Printing 3 examples
05/22/2022 16:39:17 - INFO - __main__ -  [dbpedia_14] Metareva aenescens is a moth of the Arctiidae family. It was described by Hampson in 1900. It is found in Bolivia.
05/22/2022 16:39:17 - INFO - __main__ - ['Animal']
05/22/2022 16:39:17 - INFO - __main__ -  [dbpedia_14] Xenopipo is a genus of bird in the Pipridae family. It contains the following species: Black Manakin (Xenopipo atronitens) Yellow-headed Manakin (Xenopipo flavicapilla) Green Manakin (Xenopipo holochlora) Jet Manakin (Xenopipo unicolor) Olive Manakin (Xenopipo uniformis)
05/22/2022 16:39:17 - INFO - __main__ - ['Animal']
05/22/2022 16:39:17 - INFO - __main__ -  [dbpedia_14] The Tardy Renia (Renia nemoralis) is a moth of the Noctuidae family. It is found from Illinois to south-eastern Massachusetts south to Florida and Texas.The wingspan is 28-30 mm. There is one generation per year.The larvae feed on organic matter including dead leaves.
05/22/2022 16:39:17 - INFO - __main__ - ['Animal']
05/22/2022 16:39:17 - INFO - __main__ - Tokenizing Input ...
05/22/2022 16:39:17 - INFO - __main__ - Tokenizing Output ...
05/22/2022 16:39:18 - INFO - __main__ - Loaded 896 examples from dev data
05/22/2022 16:39:37 - INFO - __main__ - try to initialize prompt embeddings
05/22/2022 16:39:37 - INFO - __main__ - task name: dbpedia_14
05/22/2022 16:39:38 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 16:39:38 - INFO - __main__ - Starting training!
05/22/2022 16:39:41 - INFO - __main__ - Step 10 Global step 10 Train loss 7.35 on epoch=0
05/22/2022 16:39:43 - INFO - __main__ - Step 20 Global step 20 Train loss 6.39 on epoch=0
05/22/2022 16:39:46 - INFO - __main__ - Step 30 Global step 30 Train loss 5.79 on epoch=0
05/22/2022 16:39:49 - INFO - __main__ - Step 40 Global step 40 Train loss 4.88 on epoch=0
05/22/2022 16:39:51 - INFO - __main__ - Step 50 Global step 50 Train loss 4.50 on epoch=0
05/22/2022 16:45:44 - INFO - __main__ - Global step 50 Train loss 5.78 Classification-F1 9.184845005740528e-05 on epoch=0
05/22/2022 16:45:44 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 9.184845005740528e-05 on epoch=0, global_step=50
05/22/2022 16:45:46 - INFO - __main__ - Step 60 Global step 60 Train loss 4.08 on epoch=1
05/22/2022 16:45:49 - INFO - __main__ - Step 70 Global step 70 Train loss 3.34 on epoch=1
05/22/2022 16:45:52 - INFO - __main__ - Step 80 Global step 80 Train loss 2.83 on epoch=1
05/22/2022 16:45:54 - INFO - __main__ - Step 90 Global step 90 Train loss 2.70 on epoch=1
05/22/2022 16:45:57 - INFO - __main__ - Step 100 Global step 100 Train loss 2.45 on epoch=1
05/22/2022 16:47:25 - INFO - __main__ - Global step 100 Train loss 3.08 Classification-F1 0.05553065194555529 on epoch=1
05/22/2022 16:47:25 - INFO - __main__ - Saving model with best Classification-F1: 9.184845005740528e-05 -> 0.05553065194555529 on epoch=1, global_step=100
05/22/2022 16:47:27 - INFO - __main__ - Step 110 Global step 110 Train loss 2.33 on epoch=1
05/22/2022 16:47:30 - INFO - __main__ - Step 120 Global step 120 Train loss 1.90 on epoch=2
05/22/2022 16:47:32 - INFO - __main__ - Step 130 Global step 130 Train loss 1.83 on epoch=2
05/22/2022 16:47:35 - INFO - __main__ - Step 140 Global step 140 Train loss 1.69 on epoch=2
05/22/2022 16:47:38 - INFO - __main__ - Step 150 Global step 150 Train loss 1.47 on epoch=2
05/22/2022 16:48:13 - INFO - __main__ - Global step 150 Train loss 1.84 Classification-F1 0.16386234769518576 on epoch=2
05/22/2022 16:48:13 - INFO - __main__ - Saving model with best Classification-F1: 0.05553065194555529 -> 0.16386234769518576 on epoch=2, global_step=150
05/22/2022 16:48:15 - INFO - __main__ - Step 160 Global step 160 Train loss 1.62 on epoch=2
05/22/2022 16:48:18 - INFO - __main__ - Step 170 Global step 170 Train loss 1.49 on epoch=3
05/22/2022 16:48:20 - INFO - __main__ - Step 180 Global step 180 Train loss 1.36 on epoch=3
05/22/2022 16:48:23 - INFO - __main__ - Step 190 Global step 190 Train loss 1.23 on epoch=3
05/22/2022 16:48:25 - INFO - __main__ - Step 200 Global step 200 Train loss 1.24 on epoch=3
05/22/2022 16:48:56 - INFO - __main__ - Global step 200 Train loss 1.39 Classification-F1 0.22953201324082556 on epoch=3
05/22/2022 16:48:56 - INFO - __main__ - Saving model with best Classification-F1: 0.16386234769518576 -> 0.22953201324082556 on epoch=3, global_step=200
05/22/2022 16:48:58 - INFO - __main__ - Step 210 Global step 210 Train loss 1.23 on epoch=3
05/22/2022 16:49:01 - INFO - __main__ - Step 220 Global step 220 Train loss 1.35 on epoch=3
05/22/2022 16:49:03 - INFO - __main__ - Step 230 Global step 230 Train loss 1.14 on epoch=4
05/22/2022 16:49:06 - INFO - __main__ - Step 240 Global step 240 Train loss 1.06 on epoch=4
05/22/2022 16:49:09 - INFO - __main__ - Step 250 Global step 250 Train loss 1.12 on epoch=4
05/22/2022 16:49:37 - INFO - __main__ - Global step 250 Train loss 1.18 Classification-F1 0.32905533917452817 on epoch=4
05/22/2022 16:49:37 - INFO - __main__ - Saving model with best Classification-F1: 0.22953201324082556 -> 0.32905533917452817 on epoch=4, global_step=250
05/22/2022 16:49:40 - INFO - __main__ - Step 260 Global step 260 Train loss 0.96 on epoch=4
05/22/2022 16:49:43 - INFO - __main__ - Step 270 Global step 270 Train loss 1.00 on epoch=4
05/22/2022 16:49:45 - INFO - __main__ - Step 280 Global step 280 Train loss 1.07 on epoch=4
05/22/2022 16:49:48 - INFO - __main__ - Step 290 Global step 290 Train loss 0.89 on epoch=5
05/22/2022 16:49:50 - INFO - __main__ - Step 300 Global step 300 Train loss 0.86 on epoch=5
05/22/2022 16:50:24 - INFO - __main__ - Global step 300 Train loss 0.96 Classification-F1 0.29394935741830397 on epoch=5
05/22/2022 16:50:26 - INFO - __main__ - Step 310 Global step 310 Train loss 0.89 on epoch=5
05/22/2022 16:50:29 - INFO - __main__ - Step 320 Global step 320 Train loss 0.85 on epoch=5
05/22/2022 16:50:32 - INFO - __main__ - Step 330 Global step 330 Train loss 0.87 on epoch=5
05/22/2022 16:50:34 - INFO - __main__ - Step 340 Global step 340 Train loss 0.84 on epoch=6
05/22/2022 16:50:37 - INFO - __main__ - Step 350 Global step 350 Train loss 0.81 on epoch=6
05/22/2022 16:51:04 - INFO - __main__ - Global step 350 Train loss 0.85 Classification-F1 0.43242283384680924 on epoch=6
05/22/2022 16:51:04 - INFO - __main__ - Saving model with best Classification-F1: 0.32905533917452817 -> 0.43242283384680924 on epoch=6, global_step=350
05/22/2022 16:51:07 - INFO - __main__ - Step 360 Global step 360 Train loss 0.74 on epoch=6
05/22/2022 16:51:09 - INFO - __main__ - Step 370 Global step 370 Train loss 0.78 on epoch=6
05/22/2022 16:51:12 - INFO - __main__ - Step 380 Global step 380 Train loss 0.68 on epoch=6
05/22/2022 16:51:15 - INFO - __main__ - Step 390 Global step 390 Train loss 0.93 on epoch=6
05/22/2022 16:51:17 - INFO - __main__ - Step 400 Global step 400 Train loss 0.70 on epoch=7
05/22/2022 16:51:44 - INFO - __main__ - Global step 400 Train loss 0.77 Classification-F1 0.3406151185890279 on epoch=7
05/22/2022 16:51:47 - INFO - __main__ - Step 410 Global step 410 Train loss 0.69 on epoch=7
05/22/2022 16:51:49 - INFO - __main__ - Step 420 Global step 420 Train loss 0.78 on epoch=7
05/22/2022 16:51:52 - INFO - __main__ - Step 430 Global step 430 Train loss 0.58 on epoch=7
05/22/2022 16:51:54 - INFO - __main__ - Step 440 Global step 440 Train loss 0.63 on epoch=7
05/22/2022 16:51:57 - INFO - __main__ - Step 450 Global step 450 Train loss 0.69 on epoch=8
05/22/2022 16:52:25 - INFO - __main__ - Global step 450 Train loss 0.67 Classification-F1 0.39297356917825055 on epoch=8
05/22/2022 16:52:27 - INFO - __main__ - Step 460 Global step 460 Train loss 0.54 on epoch=8
05/22/2022 16:52:30 - INFO - __main__ - Step 470 Global step 470 Train loss 0.59 on epoch=8
05/22/2022 16:52:32 - INFO - __main__ - Step 480 Global step 480 Train loss 0.69 on epoch=8
05/22/2022 16:52:35 - INFO - __main__ - Step 490 Global step 490 Train loss 0.70 on epoch=8
05/22/2022 16:52:38 - INFO - __main__ - Step 500 Global step 500 Train loss 0.73 on epoch=8
05/22/2022 16:53:05 - INFO - __main__ - Global step 500 Train loss 0.65 Classification-F1 0.54951311272484 on epoch=8
05/22/2022 16:53:05 - INFO - __main__ - Saving model with best Classification-F1: 0.43242283384680924 -> 0.54951311272484 on epoch=8, global_step=500
05/22/2022 16:53:08 - INFO - __main__ - Step 510 Global step 510 Train loss 0.52 on epoch=9
05/22/2022 16:53:10 - INFO - __main__ - Step 520 Global step 520 Train loss 0.56 on epoch=9
05/22/2022 16:53:13 - INFO - __main__ - Step 530 Global step 530 Train loss 0.64 on epoch=9
05/22/2022 16:53:15 - INFO - __main__ - Step 540 Global step 540 Train loss 0.50 on epoch=9
05/22/2022 16:53:18 - INFO - __main__ - Step 550 Global step 550 Train loss 0.71 on epoch=9
05/22/2022 16:53:46 - INFO - __main__ - Global step 550 Train loss 0.59 Classification-F1 0.49255020503552405 on epoch=9
05/22/2022 16:53:48 - INFO - __main__ - Step 560 Global step 560 Train loss 0.52 on epoch=9
05/22/2022 16:53:51 - INFO - __main__ - Step 570 Global step 570 Train loss 0.46 on epoch=10
05/22/2022 16:53:53 - INFO - __main__ - Step 580 Global step 580 Train loss 0.47 on epoch=10
05/22/2022 16:53:56 - INFO - __main__ - Step 590 Global step 590 Train loss 0.59 on epoch=10
05/22/2022 16:53:59 - INFO - __main__ - Step 600 Global step 600 Train loss 0.55 on epoch=10
05/22/2022 16:54:28 - INFO - __main__ - Global step 600 Train loss 0.52 Classification-F1 0.5100719787113904 on epoch=10
05/22/2022 16:54:30 - INFO - __main__ - Step 610 Global step 610 Train loss 0.64 on epoch=10
05/22/2022 16:54:33 - INFO - __main__ - Step 620 Global step 620 Train loss 0.53 on epoch=11
05/22/2022 16:54:36 - INFO - __main__ - Step 630 Global step 630 Train loss 0.46 on epoch=11
05/22/2022 16:54:38 - INFO - __main__ - Step 640 Global step 640 Train loss 0.52 on epoch=11
05/22/2022 16:54:41 - INFO - __main__ - Step 650 Global step 650 Train loss 0.55 on epoch=11
05/22/2022 16:55:08 - INFO - __main__ - Global step 650 Train loss 0.54 Classification-F1 0.6399311309414875 on epoch=11
05/22/2022 16:55:08 - INFO - __main__ - Saving model with best Classification-F1: 0.54951311272484 -> 0.6399311309414875 on epoch=11, global_step=650
05/22/2022 16:55:10 - INFO - __main__ - Step 660 Global step 660 Train loss 0.51 on epoch=11
05/22/2022 16:55:13 - INFO - __main__ - Step 670 Global step 670 Train loss 0.50 on epoch=11
05/22/2022 16:55:16 - INFO - __main__ - Step 680 Global step 680 Train loss 0.45 on epoch=12
05/22/2022 16:55:18 - INFO - __main__ - Step 690 Global step 690 Train loss 0.44 on epoch=12
05/22/2022 16:55:21 - INFO - __main__ - Step 700 Global step 700 Train loss 0.52 on epoch=12
05/22/2022 16:55:50 - INFO - __main__ - Global step 700 Train loss 0.48 Classification-F1 0.646881685497657 on epoch=12
05/22/2022 16:55:50 - INFO - __main__ - Saving model with best Classification-F1: 0.6399311309414875 -> 0.646881685497657 on epoch=12, global_step=700
05/22/2022 16:55:52 - INFO - __main__ - Step 710 Global step 710 Train loss 0.46 on epoch=12
05/22/2022 16:55:55 - INFO - __main__ - Step 720 Global step 720 Train loss 0.70 on epoch=12
05/22/2022 16:55:58 - INFO - __main__ - Step 730 Global step 730 Train loss 0.44 on epoch=13
05/22/2022 16:56:00 - INFO - __main__ - Step 740 Global step 740 Train loss 0.32 on epoch=13
05/22/2022 16:56:03 - INFO - __main__ - Step 750 Global step 750 Train loss 0.41 on epoch=13
05/22/2022 16:56:29 - INFO - __main__ - Global step 750 Train loss 0.47 Classification-F1 0.5258039004398569 on epoch=13
05/22/2022 16:56:31 - INFO - __main__ - Step 760 Global step 760 Train loss 0.56 on epoch=13
05/22/2022 16:56:34 - INFO - __main__ - Step 770 Global step 770 Train loss 0.40 on epoch=13
05/22/2022 16:56:36 - INFO - __main__ - Step 780 Global step 780 Train loss 0.60 on epoch=13
05/22/2022 16:56:39 - INFO - __main__ - Step 790 Global step 790 Train loss 0.33 on epoch=14
05/22/2022 16:56:41 - INFO - __main__ - Step 800 Global step 800 Train loss 0.31 on epoch=14
05/22/2022 16:57:08 - INFO - __main__ - Global step 800 Train loss 0.44 Classification-F1 0.7293173933046798 on epoch=14
05/22/2022 16:57:08 - INFO - __main__ - Saving model with best Classification-F1: 0.646881685497657 -> 0.7293173933046798 on epoch=14, global_step=800
05/22/2022 16:57:10 - INFO - __main__ - Step 810 Global step 810 Train loss 0.37 on epoch=14
05/22/2022 16:57:13 - INFO - __main__ - Step 820 Global step 820 Train loss 0.44 on epoch=14
05/22/2022 16:57:16 - INFO - __main__ - Step 830 Global step 830 Train loss 0.40 on epoch=14
05/22/2022 16:57:18 - INFO - __main__ - Step 840 Global step 840 Train loss 0.37 on epoch=14
05/22/2022 16:57:21 - INFO - __main__ - Step 850 Global step 850 Train loss 0.35 on epoch=15
05/22/2022 16:57:47 - INFO - __main__ - Global step 850 Train loss 0.39 Classification-F1 0.6061846431304343 on epoch=15
05/22/2022 16:57:49 - INFO - __main__ - Step 860 Global step 860 Train loss 0.31 on epoch=15
05/22/2022 16:57:52 - INFO - __main__ - Step 870 Global step 870 Train loss 0.35 on epoch=15
05/22/2022 16:57:55 - INFO - __main__ - Step 880 Global step 880 Train loss 0.44 on epoch=15
05/22/2022 16:57:57 - INFO - __main__ - Step 890 Global step 890 Train loss 0.35 on epoch=15
05/22/2022 16:58:00 - INFO - __main__ - Step 900 Global step 900 Train loss 0.29 on epoch=16
05/22/2022 16:58:25 - INFO - __main__ - Global step 900 Train loss 0.34 Classification-F1 0.5774677714283982 on epoch=16
05/22/2022 16:58:27 - INFO - __main__ - Step 910 Global step 910 Train loss 0.29 on epoch=16
05/22/2022 16:58:30 - INFO - __main__ - Step 920 Global step 920 Train loss 0.32 on epoch=16
05/22/2022 16:58:33 - INFO - __main__ - Step 930 Global step 930 Train loss 0.35 on epoch=16
05/22/2022 16:58:35 - INFO - __main__ - Step 940 Global step 940 Train loss 0.27 on epoch=16
05/22/2022 16:58:38 - INFO - __main__ - Step 950 Global step 950 Train loss 0.28 on epoch=16
05/22/2022 16:59:04 - INFO - __main__ - Global step 950 Train loss 0.30 Classification-F1 0.6061462161583021 on epoch=16
05/22/2022 16:59:07 - INFO - __main__ - Step 960 Global step 960 Train loss 0.24 on epoch=17
05/22/2022 16:59:10 - INFO - __main__ - Step 970 Global step 970 Train loss 0.24 on epoch=17
05/22/2022 16:59:12 - INFO - __main__ - Step 980 Global step 980 Train loss 0.32 on epoch=17
05/22/2022 16:59:15 - INFO - __main__ - Step 990 Global step 990 Train loss 0.26 on epoch=17
05/22/2022 16:59:17 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.50 on epoch=17
05/22/2022 16:59:45 - INFO - __main__ - Global step 1000 Train loss 0.31 Classification-F1 0.6719633725418062 on epoch=17
05/22/2022 16:59:47 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.36 on epoch=18
05/22/2022 16:59:50 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.21 on epoch=18
05/22/2022 16:59:52 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.20 on epoch=18
05/22/2022 16:59:55 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.36 on epoch=18
05/22/2022 16:59:58 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.30 on epoch=18
05/22/2022 17:00:23 - INFO - __main__ - Global step 1050 Train loss 0.29 Classification-F1 0.7369601247427624 on epoch=18
05/22/2022 17:00:23 - INFO - __main__ - Saving model with best Classification-F1: 0.7293173933046798 -> 0.7369601247427624 on epoch=18, global_step=1050
05/22/2022 17:00:26 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.42 on epoch=18
05/22/2022 17:00:29 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.20 on epoch=19
05/22/2022 17:00:31 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.31 on epoch=19
05/22/2022 17:00:34 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.20 on epoch=19
05/22/2022 17:00:36 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.27 on epoch=19
05/22/2022 17:01:04 - INFO - __main__ - Global step 1100 Train loss 0.28 Classification-F1 0.6535988447173412 on epoch=19
05/22/2022 17:01:06 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.40 on epoch=19
05/22/2022 17:01:09 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.27 on epoch=19
05/22/2022 17:01:12 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.17 on epoch=20
05/22/2022 17:01:14 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.12 on epoch=20
05/22/2022 17:01:17 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.26 on epoch=20
05/22/2022 17:01:44 - INFO - __main__ - Global step 1150 Train loss 0.24 Classification-F1 0.5855187412731868 on epoch=20
05/22/2022 17:01:47 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.26 on epoch=20
05/22/2022 17:01:49 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.40 on epoch=20
05/22/2022 17:01:52 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.16 on epoch=21
05/22/2022 17:01:55 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.14 on epoch=21
05/22/2022 17:01:57 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.17 on epoch=21
05/22/2022 17:02:22 - INFO - __main__ - Global step 1200 Train loss 0.22 Classification-F1 0.5518401097952659 on epoch=21
05/22/2022 17:02:25 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.21 on epoch=21
05/22/2022 17:02:27 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.17 on epoch=21
05/22/2022 17:02:30 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.37 on epoch=21
05/22/2022 17:02:32 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.21 on epoch=22
05/22/2022 17:02:35 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.18 on epoch=22
05/22/2022 17:03:00 - INFO - __main__ - Global step 1250 Train loss 0.23 Classification-F1 0.5790840785577459 on epoch=22
05/22/2022 17:03:03 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.21 on epoch=22
05/22/2022 17:03:05 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.14 on epoch=22
05/22/2022 17:03:08 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.37 on epoch=22
05/22/2022 17:03:11 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.17 on epoch=23
05/22/2022 17:03:13 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.12 on epoch=23
05/22/2022 17:03:37 - INFO - __main__ - Global step 1300 Train loss 0.20 Classification-F1 0.6060661924439281 on epoch=23
05/22/2022 17:03:40 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.19 on epoch=23
05/22/2022 17:03:43 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.16 on epoch=23
05/22/2022 17:03:45 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.16 on epoch=23
05/22/2022 17:03:48 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.22 on epoch=23
05/22/2022 17:03:50 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.14 on epoch=24
05/22/2022 17:04:14 - INFO - __main__ - Global step 1350 Train loss 0.18 Classification-F1 0.6948619723244425 on epoch=24
05/22/2022 17:04:16 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.13 on epoch=24
05/22/2022 17:04:19 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.07 on epoch=24
05/22/2022 17:04:21 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.12 on epoch=24
05/22/2022 17:04:24 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.38 on epoch=24
05/22/2022 17:04:26 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.10 on epoch=24
05/22/2022 17:04:50 - INFO - __main__ - Global step 1400 Train loss 0.16 Classification-F1 0.789302193746009 on epoch=24
05/22/2022 17:04:50 - INFO - __main__ - Saving model with best Classification-F1: 0.7369601247427624 -> 0.789302193746009 on epoch=24, global_step=1400
05/22/2022 17:04:53 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.12 on epoch=25
05/22/2022 17:04:56 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.13 on epoch=25
05/22/2022 17:04:58 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.12 on epoch=25
05/22/2022 17:05:01 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.14 on epoch=25
05/22/2022 17:05:03 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.39 on epoch=25
05/22/2022 17:05:26 - INFO - __main__ - Global step 1450 Train loss 0.18 Classification-F1 0.6598348644546783 on epoch=25
05/22/2022 17:05:28 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.09 on epoch=26
05/22/2022 17:05:31 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.13 on epoch=26
05/22/2022 17:05:34 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.12 on epoch=26
05/22/2022 17:05:36 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.16 on epoch=26
05/22/2022 17:05:39 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.09 on epoch=26
05/22/2022 17:06:02 - INFO - __main__ - Global step 1500 Train loss 0.12 Classification-F1 0.7506882722379236 on epoch=26
05/22/2022 17:06:04 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.29 on epoch=26
05/22/2022 17:06:07 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.07 on epoch=27
05/22/2022 17:06:09 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.10 on epoch=27
05/22/2022 17:06:12 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.14 on epoch=27
05/22/2022 17:06:15 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.12 on epoch=27
05/22/2022 17:06:38 - INFO - __main__ - Global step 1550 Train loss 0.14 Classification-F1 0.8481051745834602 on epoch=27
05/22/2022 17:06:38 - INFO - __main__ - Saving model with best Classification-F1: 0.789302193746009 -> 0.8481051745834602 on epoch=27, global_step=1550
05/22/2022 17:06:41 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.17 on epoch=27
05/22/2022 17:06:43 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.14 on epoch=28
05/22/2022 17:06:46 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.12 on epoch=28
05/22/2022 17:06:49 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.13 on epoch=28
05/22/2022 17:06:51 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.14 on epoch=28
05/22/2022 17:07:14 - INFO - __main__ - Global step 1600 Train loss 0.14 Classification-F1 0.8527242715944066 on epoch=28
05/22/2022 17:07:14 - INFO - __main__ - Saving model with best Classification-F1: 0.8481051745834602 -> 0.8527242715944066 on epoch=28, global_step=1600
05/22/2022 17:07:17 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.14 on epoch=28
05/22/2022 17:07:19 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.35 on epoch=28
05/22/2022 17:07:22 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.06 on epoch=29
05/22/2022 17:07:25 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.19 on epoch=29
05/22/2022 17:07:27 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.08 on epoch=29
05/22/2022 17:07:49 - INFO - __main__ - Global step 1650 Train loss 0.16 Classification-F1 0.7032510429136366 on epoch=29
05/22/2022 17:07:52 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.10 on epoch=29
05/22/2022 17:07:55 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.32 on epoch=29
05/22/2022 17:07:57 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.12 on epoch=29
05/22/2022 17:08:00 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.05 on epoch=30
05/22/2022 17:08:02 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.10 on epoch=30
05/22/2022 17:08:25 - INFO - __main__ - Global step 1700 Train loss 0.14 Classification-F1 0.6734924383239435 on epoch=30
05/22/2022 17:08:27 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.11 on epoch=30
05/22/2022 17:08:30 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.11 on epoch=30
05/22/2022 17:08:32 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.20 on epoch=30
05/22/2022 17:08:35 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.10 on epoch=31
05/22/2022 17:08:38 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.08 on epoch=31
05/22/2022 17:09:00 - INFO - __main__ - Global step 1750 Train loss 0.12 Classification-F1 0.8503687850373773 on epoch=31
05/22/2022 17:09:03 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.11 on epoch=31
05/22/2022 17:09:05 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.09 on epoch=31
05/22/2022 17:09:08 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.08 on epoch=31
05/22/2022 17:09:10 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.28 on epoch=31
05/22/2022 17:09:13 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.10 on epoch=32
05/22/2022 17:09:35 - INFO - __main__ - Global step 1800 Train loss 0.13 Classification-F1 0.9086357379179596 on epoch=32
05/22/2022 17:09:35 - INFO - __main__ - Saving model with best Classification-F1: 0.8527242715944066 -> 0.9086357379179596 on epoch=32, global_step=1800
05/22/2022 17:09:38 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.03 on epoch=32
05/22/2022 17:09:41 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.14 on epoch=32
05/22/2022 17:09:43 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.08 on epoch=32
05/22/2022 17:09:46 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.34 on epoch=32
05/22/2022 17:09:48 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.10 on epoch=33
05/22/2022 17:10:11 - INFO - __main__ - Global step 1850 Train loss 0.14 Classification-F1 0.902385468233261 on epoch=33
05/22/2022 17:10:14 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.10 on epoch=33
05/22/2022 17:10:16 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.08 on epoch=33
05/22/2022 17:10:19 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.08 on epoch=33
05/22/2022 17:10:21 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.09 on epoch=33
05/22/2022 17:10:24 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.31 on epoch=33
05/22/2022 17:10:47 - INFO - __main__ - Global step 1900 Train loss 0.13 Classification-F1 0.750727845931367 on epoch=33
05/22/2022 17:10:50 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.09 on epoch=34
05/22/2022 17:10:52 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.07 on epoch=34
05/22/2022 17:10:55 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.04 on epoch=34
05/22/2022 17:10:57 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.11 on epoch=34
05/22/2022 17:11:00 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.29 on epoch=34
05/22/2022 17:11:23 - INFO - __main__ - Global step 1950 Train loss 0.12 Classification-F1 0.8549387415659182 on epoch=34
05/22/2022 17:11:26 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.12 on epoch=34
05/22/2022 17:11:29 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.16 on epoch=35
05/22/2022 17:11:31 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.04 on epoch=35
05/22/2022 17:11:34 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.09 on epoch=35
05/22/2022 17:11:36 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.07 on epoch=35
05/22/2022 17:12:00 - INFO - __main__ - Global step 2000 Train loss 0.09 Classification-F1 0.9074066883377256 on epoch=35
05/22/2022 17:12:02 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.32 on epoch=35
05/22/2022 17:12:05 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.06 on epoch=36
05/22/2022 17:12:07 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.07 on epoch=36
05/22/2022 17:12:10 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.08 on epoch=36
05/22/2022 17:12:12 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.09 on epoch=36
05/22/2022 17:12:36 - INFO - __main__ - Global step 2050 Train loss 0.12 Classification-F1 0.799517179985668 on epoch=36
05/22/2022 17:12:38 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.07 on epoch=36
05/22/2022 17:12:41 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.08 on epoch=36
05/22/2022 17:12:43 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.07 on epoch=37
05/22/2022 17:12:46 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.06 on epoch=37
05/22/2022 17:12:49 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.04 on epoch=37
05/22/2022 17:13:12 - INFO - __main__ - Global step 2100 Train loss 0.07 Classification-F1 0.6748670650277749 on epoch=37
05/22/2022 17:13:14 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.10 on epoch=37
05/22/2022 17:13:17 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.11 on epoch=37
05/22/2022 17:13:19 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.08 on epoch=38
05/22/2022 17:13:22 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.07 on epoch=38
05/22/2022 17:13:24 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.08 on epoch=38
05/22/2022 17:13:47 - INFO - __main__ - Global step 2150 Train loss 0.09 Classification-F1 0.9060752013060152 on epoch=38
05/22/2022 17:13:50 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.06 on epoch=38
05/22/2022 17:13:52 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.11 on epoch=38
05/22/2022 17:13:55 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.08 on epoch=38
05/22/2022 17:13:58 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.07 on epoch=39
05/22/2022 17:14:00 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.09 on epoch=39
05/22/2022 17:14:22 - INFO - __main__ - Global step 2200 Train loss 0.08 Classification-F1 0.6708143923326574 on epoch=39
05/22/2022 17:14:25 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.05 on epoch=39
05/22/2022 17:14:28 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.07 on epoch=39
05/22/2022 17:14:30 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.27 on epoch=39
05/22/2022 17:14:33 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.11 on epoch=39
05/22/2022 17:14:36 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.14 on epoch=40
05/22/2022 17:14:58 - INFO - __main__ - Global step 2250 Train loss 0.13 Classification-F1 0.7196522091343209 on epoch=40
05/22/2022 17:15:01 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.06 on epoch=40
05/22/2022 17:15:03 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.06 on epoch=40
05/22/2022 17:15:06 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.07 on epoch=40
05/22/2022 17:15:08 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.24 on epoch=40
05/22/2022 17:15:11 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.07 on epoch=41
05/22/2022 17:15:33 - INFO - __main__ - Global step 2300 Train loss 0.10 Classification-F1 0.7440545722401298 on epoch=41
05/22/2022 17:15:36 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.08 on epoch=41
05/22/2022 17:15:39 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.05 on epoch=41
05/22/2022 17:15:41 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.08 on epoch=41
05/22/2022 17:15:44 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.06 on epoch=41
05/22/2022 17:15:46 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.27 on epoch=41
05/22/2022 17:16:09 - INFO - __main__ - Global step 2350 Train loss 0.11 Classification-F1 0.6368968639841147 on epoch=41
05/22/2022 17:16:11 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.08 on epoch=42
05/22/2022 17:16:14 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.06 on epoch=42
05/22/2022 17:16:17 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.04 on epoch=42
05/22/2022 17:16:19 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.10 on epoch=42
05/22/2022 17:16:22 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.09 on epoch=42
05/22/2022 17:16:44 - INFO - __main__ - Global step 2400 Train loss 0.08 Classification-F1 0.7551641211551203 on epoch=42
05/22/2022 17:16:47 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.07 on epoch=43
05/22/2022 17:16:49 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.04 on epoch=43
05/22/2022 17:16:52 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.06 on epoch=43
05/22/2022 17:16:54 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.09 on epoch=43
05/22/2022 17:16:57 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.10 on epoch=43
05/22/2022 17:17:20 - INFO - __main__ - Global step 2450 Train loss 0.07 Classification-F1 0.7520929972324608 on epoch=43
05/22/2022 17:17:22 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.26 on epoch=43
05/22/2022 17:17:25 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.05 on epoch=44
05/22/2022 17:17:28 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.07 on epoch=44
05/22/2022 17:17:30 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.04 on epoch=44
05/22/2022 17:17:33 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.04 on epoch=44
05/22/2022 17:17:55 - INFO - __main__ - Global step 2500 Train loss 0.09 Classification-F1 0.711086539157962 on epoch=44
05/22/2022 17:17:58 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.26 on epoch=44
05/22/2022 17:18:01 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.10 on epoch=44
05/22/2022 17:18:03 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.06 on epoch=45
05/22/2022 17:18:06 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.07 on epoch=45
05/22/2022 17:18:09 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.07 on epoch=45
05/22/2022 17:18:31 - INFO - __main__ - Global step 2550 Train loss 0.11 Classification-F1 0.7998477390554799 on epoch=45
05/22/2022 17:18:34 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.07 on epoch=45
05/22/2022 17:18:36 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.05 on epoch=45
05/22/2022 17:18:39 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.07 on epoch=46
05/22/2022 17:18:42 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.05 on epoch=46
05/22/2022 17:18:44 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=46
05/22/2022 17:19:07 - INFO - __main__ - Global step 2600 Train loss 0.05 Classification-F1 0.6791907804503989 on epoch=46
05/22/2022 17:19:09 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.03 on epoch=46
05/22/2022 17:19:12 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.04 on epoch=46
05/22/2022 17:19:15 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.23 on epoch=46
05/22/2022 17:19:17 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.06 on epoch=47
05/22/2022 17:19:20 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.03 on epoch=47
05/22/2022 17:19:42 - INFO - __main__ - Global step 2650 Train loss 0.08 Classification-F1 0.5815960434358094 on epoch=47
05/22/2022 17:19:45 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.10 on epoch=47
05/22/2022 17:19:48 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.04 on epoch=47
05/22/2022 17:19:50 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.06 on epoch=47
05/22/2022 17:19:53 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.05 on epoch=48
05/22/2022 17:19:55 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.03 on epoch=48
05/22/2022 17:20:19 - INFO - __main__ - Global step 2700 Train loss 0.06 Classification-F1 0.7159008663675794 on epoch=48
05/22/2022 17:20:21 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=48
05/22/2022 17:20:24 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.04 on epoch=48
05/22/2022 17:20:26 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.10 on epoch=48
05/22/2022 17:20:29 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.05 on epoch=48
05/22/2022 17:20:32 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.08 on epoch=49
05/22/2022 17:20:55 - INFO - __main__ - Global step 2750 Train loss 0.06 Classification-F1 0.788457454866303 on epoch=49
05/22/2022 17:20:57 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.05 on epoch=49
05/22/2022 17:21:00 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.04 on epoch=49
05/22/2022 17:21:03 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.05 on epoch=49
05/22/2022 17:21:05 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.05 on epoch=49
05/22/2022 17:21:08 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.04 on epoch=49
05/22/2022 17:21:31 - INFO - __main__ - Global step 2800 Train loss 0.04 Classification-F1 0.7612282841402682 on epoch=49
05/22/2022 17:21:33 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.05 on epoch=50
05/22/2022 17:21:36 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.03 on epoch=50
05/22/2022 17:21:39 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.05 on epoch=50
05/22/2022 17:21:41 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.08 on epoch=50
05/22/2022 17:21:44 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.28 on epoch=50
05/22/2022 17:22:06 - INFO - __main__ - Global step 2850 Train loss 0.10 Classification-F1 0.7124689440598977 on epoch=50
05/22/2022 17:22:09 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.04 on epoch=51
05/22/2022 17:22:12 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=51
05/22/2022 17:22:14 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.05 on epoch=51
05/22/2022 17:22:17 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.04 on epoch=51
05/22/2022 17:22:20 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=51
05/22/2022 17:22:43 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.8503055135792328 on epoch=51
05/22/2022 17:22:46 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.24 on epoch=51
05/22/2022 17:22:49 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.05 on epoch=52
05/22/2022 17:22:51 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=52
05/22/2022 17:22:54 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.04 on epoch=52
05/22/2022 17:22:56 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=52
05/22/2022 17:23:20 - INFO - __main__ - Global step 2950 Train loss 0.07 Classification-F1 0.9787614048432317 on epoch=52
05/22/2022 17:23:20 - INFO - __main__ - Saving model with best Classification-F1: 0.9086357379179596 -> 0.9787614048432317 on epoch=52, global_step=2950
05/22/2022 17:23:22 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.24 on epoch=52
05/22/2022 17:23:25 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.06 on epoch=53
05/22/2022 17:23:28 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.03 on epoch=53
05/22/2022 17:23:30 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=53
05/22/2022 17:23:33 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.03 on epoch=53
05/22/2022 17:23:34 - INFO - __main__ - Start tokenizing ... 896 instances
05/22/2022 17:23:34 - INFO - __main__ - Printing 3 examples
05/22/2022 17:23:34 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/22/2022 17:23:34 - INFO - __main__ - ['Animal']
05/22/2022 17:23:34 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/22/2022 17:23:34 - INFO - __main__ - ['Animal']
05/22/2022 17:23:34 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
05/22/2022 17:23:34 - INFO - __main__ - ['Animal']
05/22/2022 17:23:34 - INFO - __main__ - Tokenizing Input ...
05/22/2022 17:23:35 - INFO - __main__ - Tokenizing Output ...
05/22/2022 17:23:35 - INFO - __main__ - Loaded 896 examples from train data
05/22/2022 17:23:35 - INFO - __main__ - Start tokenizing ... 896 instances
05/22/2022 17:23:35 - INFO - __main__ - Printing 3 examples
05/22/2022 17:23:35 - INFO - __main__ -  [dbpedia_14] Clarkesvillia is an Upper Ordovician westonocerid genus the differs from Faberoceras in having a more flattened venter and from the later Glyptodendron in having a more ventrally located siphuncle.
05/22/2022 17:23:35 - INFO - __main__ - ['Animal']
05/22/2022 17:23:35 - INFO - __main__ -  [dbpedia_14] Alaena ochracea is a butterfly in the Lycaenidae family. It is found in Malawi (from the southern part of the country to the Shire Highlands). The habitat consists of the fringes of submontane evergreen forests.
05/22/2022 17:23:35 - INFO - __main__ - ['Animal']
05/22/2022 17:23:35 - INFO - __main__ -  [dbpedia_14] Latoia is a genus of moths in the family Limacodidae.
05/22/2022 17:23:35 - INFO - __main__ - ['Animal']
05/22/2022 17:23:35 - INFO - __main__ - Tokenizing Input ...
05/22/2022 17:23:36 - INFO - __main__ - Tokenizing Output ...
05/22/2022 17:23:37 - INFO - __main__ - Loaded 896 examples from dev data
05/22/2022 17:23:52 - INFO - __main__ - try to initialize prompt embeddings
05/22/2022 17:23:52 - INFO - __main__ - task name: dbpedia_14
05/22/2022 17:23:53 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 17:23:53 - INFO - __main__ - Starting training!
05/22/2022 17:23:56 - INFO - __main__ - Global step 3000 Train loss 0.08 Classification-F1 0.9775730651878326 on epoch=53
05/22/2022 17:23:56 - INFO - __main__ - save last model!
05/22/2022 17:23:56 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/22/2022 17:23:56 - INFO - __main__ - Start tokenizing ... 3500 instances
05/22/2022 17:23:56 - INFO - __main__ - Printing 3 examples
05/22/2022 17:23:56 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/22/2022 17:23:56 - INFO - __main__ - ['Animal']
05/22/2022 17:23:56 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/22/2022 17:23:56 - INFO - __main__ - ['Animal']
05/22/2022 17:23:56 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/22/2022 17:23:56 - INFO - __main__ - ['Village']
05/22/2022 17:23:56 - INFO - __main__ - Tokenizing Input ...
05/22/2022 17:23:58 - INFO - __main__ - Tokenizing Output ...
05/22/2022 17:24:01 - INFO - __main__ - Loaded 3500 examples from test data
05/22/2022 17:26:05 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down64shot/singletask-dbpedia_14/dbpedia_14_64_100_0.2_8_predictions.txt
05/22/2022 17:26:05 - INFO - __main__ - Classification-F1 on test data: 0.7208
05/22/2022 17:26:06 - INFO - __main__ - prefix=dbpedia_14_64_100, lr=0.2, bsz=8, dev_performance=0.9787614048432317, test_performance=0.7208407289128334
05/22/2022 17:26:06 - INFO - __main__ - Running ... prefix=dbpedia_14_64_13, lr=0.5, bsz=8 ...
05/22/2022 17:26:07 - INFO - __main__ - Start tokenizing ... 896 instances
05/22/2022 17:26:07 - INFO - __main__ - Printing 3 examples
05/22/2022 17:26:07 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/22/2022 17:26:07 - INFO - __main__ - ['Animal']
05/22/2022 17:26:07 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/22/2022 17:26:07 - INFO - __main__ - ['Animal']
05/22/2022 17:26:07 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
05/22/2022 17:26:07 - INFO - __main__ - ['Animal']
05/22/2022 17:26:07 - INFO - __main__ - Tokenizing Input ...
05/22/2022 17:26:07 - INFO - __main__ - Tokenizing Output ...
05/22/2022 17:26:08 - INFO - __main__ - Loaded 896 examples from train data
05/22/2022 17:26:08 - INFO - __main__ - Start tokenizing ... 896 instances
05/22/2022 17:26:08 - INFO - __main__ - Printing 3 examples
05/22/2022 17:26:08 - INFO - __main__ -  [dbpedia_14] Clarkesvillia is an Upper Ordovician westonocerid genus the differs from Faberoceras in having a more flattened venter and from the later Glyptodendron in having a more ventrally located siphuncle.
05/22/2022 17:26:08 - INFO - __main__ - ['Animal']
05/22/2022 17:26:08 - INFO - __main__ -  [dbpedia_14] Alaena ochracea is a butterfly in the Lycaenidae family. It is found in Malawi (from the southern part of the country to the Shire Highlands). The habitat consists of the fringes of submontane evergreen forests.
05/22/2022 17:26:08 - INFO - __main__ - ['Animal']
05/22/2022 17:26:08 - INFO - __main__ -  [dbpedia_14] Latoia is a genus of moths in the family Limacodidae.
05/22/2022 17:26:08 - INFO - __main__ - ['Animal']
05/22/2022 17:26:08 - INFO - __main__ - Tokenizing Input ...
05/22/2022 17:26:08 - INFO - __main__ - Tokenizing Output ...
05/22/2022 17:26:09 - INFO - __main__ - Loaded 896 examples from dev data
05/22/2022 17:26:25 - INFO - __main__ - try to initialize prompt embeddings
05/22/2022 17:26:25 - INFO - __main__ - task name: dbpedia_14
05/22/2022 17:26:25 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 17:26:25 - INFO - __main__ - Starting training!
05/22/2022 17:26:29 - INFO - __main__ - Step 10 Global step 10 Train loss 6.41 on epoch=0
05/22/2022 17:26:31 - INFO - __main__ - Step 20 Global step 20 Train loss 4.96 on epoch=0
05/22/2022 17:26:34 - INFO - __main__ - Step 30 Global step 30 Train loss 3.18 on epoch=0
05/22/2022 17:26:36 - INFO - __main__ - Step 40 Global step 40 Train loss 2.21 on epoch=0
05/22/2022 17:26:39 - INFO - __main__ - Step 50 Global step 50 Train loss 1.81 on epoch=0
05/22/2022 17:27:16 - INFO - __main__ - Global step 50 Train loss 3.71 Classification-F1 0.16117094357799364 on epoch=0
05/22/2022 17:27:16 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.16117094357799364 on epoch=0, global_step=50
05/22/2022 17:27:18 - INFO - __main__ - Step 60 Global step 60 Train loss 1.41 on epoch=1
05/22/2022 17:27:21 - INFO - __main__ - Step 70 Global step 70 Train loss 1.34 on epoch=1
05/22/2022 17:27:24 - INFO - __main__ - Step 80 Global step 80 Train loss 1.38 on epoch=1
05/22/2022 17:27:26 - INFO - __main__ - Step 90 Global step 90 Train loss 1.16 on epoch=1
05/22/2022 17:27:29 - INFO - __main__ - Step 100 Global step 100 Train loss 0.94 on epoch=1
05/22/2022 17:28:12 - INFO - __main__ - Global step 100 Train loss 1.25 Classification-F1 0.23614358980527092 on epoch=1
05/22/2022 17:28:12 - INFO - __main__ - Saving model with best Classification-F1: 0.16117094357799364 -> 0.23614358980527092 on epoch=1, global_step=100
05/22/2022 17:28:15 - INFO - __main__ - Step 110 Global step 110 Train loss 1.07 on epoch=1
05/22/2022 17:28:17 - INFO - __main__ - Step 120 Global step 120 Train loss 0.81 on epoch=2
05/22/2022 17:28:20 - INFO - __main__ - Step 130 Global step 130 Train loss 1.01 on epoch=2
05/22/2022 17:28:22 - INFO - __main__ - Step 140 Global step 140 Train loss 0.85 on epoch=2
05/22/2022 17:28:25 - INFO - __main__ - Step 150 Global step 150 Train loss 0.90 on epoch=2
05/22/2022 17:29:00 - INFO - __main__ - Global step 150 Train loss 0.93 Classification-F1 0.39724442927856507 on epoch=2
05/22/2022 17:29:00 - INFO - __main__ - Saving model with best Classification-F1: 0.23614358980527092 -> 0.39724442927856507 on epoch=2, global_step=150
05/22/2022 17:29:02 - INFO - __main__ - Step 160 Global step 160 Train loss 0.82 on epoch=2
05/22/2022 17:29:05 - INFO - __main__ - Step 170 Global step 170 Train loss 0.71 on epoch=3
05/22/2022 17:29:07 - INFO - __main__ - Step 180 Global step 180 Train loss 0.71 on epoch=3
05/22/2022 17:29:10 - INFO - __main__ - Step 190 Global step 190 Train loss 0.80 on epoch=3
05/22/2022 17:29:13 - INFO - __main__ - Step 200 Global step 200 Train loss 0.65 on epoch=3
05/22/2022 17:29:39 - INFO - __main__ - Global step 200 Train loss 0.74 Classification-F1 0.5477603391935405 on epoch=3
05/22/2022 17:29:39 - INFO - __main__ - Saving model with best Classification-F1: 0.39724442927856507 -> 0.5477603391935405 on epoch=3, global_step=200
05/22/2022 17:29:41 - INFO - __main__ - Step 210 Global step 210 Train loss 0.52 on epoch=3
05/22/2022 17:29:44 - INFO - __main__ - Step 220 Global step 220 Train loss 0.58 on epoch=3
05/22/2022 17:29:47 - INFO - __main__ - Step 230 Global step 230 Train loss 0.64 on epoch=4
05/22/2022 17:29:49 - INFO - __main__ - Step 240 Global step 240 Train loss 0.61 on epoch=4
05/22/2022 17:29:52 - INFO - __main__ - Step 250 Global step 250 Train loss 0.57 on epoch=4
05/22/2022 17:30:26 - INFO - __main__ - Global step 250 Train loss 0.58 Classification-F1 0.47862790644539127 on epoch=4
05/22/2022 17:30:29 - INFO - __main__ - Step 260 Global step 260 Train loss 0.53 on epoch=4
05/22/2022 17:30:31 - INFO - __main__ - Step 270 Global step 270 Train loss 0.55 on epoch=4
05/22/2022 17:30:34 - INFO - __main__ - Step 280 Global step 280 Train loss 0.46 on epoch=4
05/22/2022 17:30:36 - INFO - __main__ - Step 290 Global step 290 Train loss 0.53 on epoch=5
05/22/2022 17:30:39 - INFO - __main__ - Step 300 Global step 300 Train loss 0.56 on epoch=5
05/22/2022 17:31:05 - INFO - __main__ - Global step 300 Train loss 0.52 Classification-F1 0.5143688783840848 on epoch=5
05/22/2022 17:31:08 - INFO - __main__ - Step 310 Global step 310 Train loss 0.46 on epoch=5
05/22/2022 17:31:10 - INFO - __main__ - Step 320 Global step 320 Train loss 0.36 on epoch=5
05/22/2022 17:31:13 - INFO - __main__ - Step 330 Global step 330 Train loss 0.44 on epoch=5
05/22/2022 17:31:15 - INFO - __main__ - Step 340 Global step 340 Train loss 0.35 on epoch=6
05/22/2022 17:31:18 - INFO - __main__ - Step 350 Global step 350 Train loss 0.41 on epoch=6
05/22/2022 17:31:47 - INFO - __main__ - Global step 350 Train loss 0.41 Classification-F1 0.3688704338181825 on epoch=6
05/22/2022 17:31:49 - INFO - __main__ - Step 360 Global step 360 Train loss 0.44 on epoch=6
05/22/2022 17:31:52 - INFO - __main__ - Step 370 Global step 370 Train loss 0.40 on epoch=6
05/22/2022 17:31:54 - INFO - __main__ - Step 380 Global step 380 Train loss 0.32 on epoch=6
05/22/2022 17:31:57 - INFO - __main__ - Step 390 Global step 390 Train loss 0.33 on epoch=6
05/22/2022 17:31:59 - INFO - __main__ - Step 400 Global step 400 Train loss 0.31 on epoch=7
05/22/2022 17:32:28 - INFO - __main__ - Global step 400 Train loss 0.36 Classification-F1 0.5140026253923072 on epoch=7
05/22/2022 17:32:30 - INFO - __main__ - Step 410 Global step 410 Train loss 0.43 on epoch=7
05/22/2022 17:32:33 - INFO - __main__ - Step 420 Global step 420 Train loss 0.35 on epoch=7
05/22/2022 17:32:35 - INFO - __main__ - Step 430 Global step 430 Train loss 0.28 on epoch=7
05/22/2022 17:32:38 - INFO - __main__ - Step 440 Global step 440 Train loss 0.32 on epoch=7
05/22/2022 17:32:40 - INFO - __main__ - Step 450 Global step 450 Train loss 0.21 on epoch=8
05/22/2022 17:33:07 - INFO - __main__ - Global step 450 Train loss 0.32 Classification-F1 0.5622719448599098 on epoch=8
05/22/2022 17:33:07 - INFO - __main__ - Saving model with best Classification-F1: 0.5477603391935405 -> 0.5622719448599098 on epoch=8, global_step=450
05/22/2022 17:33:10 - INFO - __main__ - Step 460 Global step 460 Train loss 0.31 on epoch=8
05/22/2022 17:33:13 - INFO - __main__ - Step 470 Global step 470 Train loss 0.33 on epoch=8
05/22/2022 17:33:15 - INFO - __main__ - Step 480 Global step 480 Train loss 0.25 on epoch=8
05/22/2022 17:33:18 - INFO - __main__ - Step 490 Global step 490 Train loss 0.22 on epoch=8
05/22/2022 17:33:20 - INFO - __main__ - Step 500 Global step 500 Train loss 0.27 on epoch=8
05/22/2022 17:33:46 - INFO - __main__ - Global step 500 Train loss 0.28 Classification-F1 0.6329868007669144 on epoch=8
05/22/2022 17:33:46 - INFO - __main__ - Saving model with best Classification-F1: 0.5622719448599098 -> 0.6329868007669144 on epoch=8, global_step=500
05/22/2022 17:33:48 - INFO - __main__ - Step 510 Global step 510 Train loss 0.24 on epoch=9
05/22/2022 17:33:51 - INFO - __main__ - Step 520 Global step 520 Train loss 0.28 on epoch=9
05/22/2022 17:33:54 - INFO - __main__ - Step 530 Global step 530 Train loss 0.33 on epoch=9
05/22/2022 17:33:56 - INFO - __main__ - Step 540 Global step 540 Train loss 0.33 on epoch=9
05/22/2022 17:33:59 - INFO - __main__ - Step 550 Global step 550 Train loss 0.20 on epoch=9
05/22/2022 17:34:24 - INFO - __main__ - Global step 550 Train loss 0.27 Classification-F1 0.5092223070750047 on epoch=9
05/22/2022 17:34:26 - INFO - __main__ - Step 560 Global step 560 Train loss 0.13 on epoch=9
05/22/2022 17:34:29 - INFO - __main__ - Step 570 Global step 570 Train loss 0.25 on epoch=10
05/22/2022 17:34:32 - INFO - __main__ - Step 580 Global step 580 Train loss 0.25 on epoch=10
05/22/2022 17:34:34 - INFO - __main__ - Step 590 Global step 590 Train loss 0.26 on epoch=10
05/22/2022 17:34:37 - INFO - __main__ - Step 600 Global step 600 Train loss 0.15 on epoch=10
05/22/2022 17:35:02 - INFO - __main__ - Global step 600 Train loss 0.21 Classification-F1 0.4968199274135587 on epoch=10
05/22/2022 17:35:05 - INFO - __main__ - Step 610 Global step 610 Train loss 0.21 on epoch=10
05/22/2022 17:35:07 - INFO - __main__ - Step 620 Global step 620 Train loss 0.15 on epoch=11
05/22/2022 17:35:10 - INFO - __main__ - Step 630 Global step 630 Train loss 0.20 on epoch=11
05/22/2022 17:35:12 - INFO - __main__ - Step 640 Global step 640 Train loss 0.21 on epoch=11
05/22/2022 17:35:15 - INFO - __main__ - Step 650 Global step 650 Train loss 0.22 on epoch=11
05/22/2022 17:35:43 - INFO - __main__ - Global step 650 Train loss 0.20 Classification-F1 0.5152560292655396 on epoch=11
05/22/2022 17:35:46 - INFO - __main__ - Step 660 Global step 660 Train loss 0.12 on epoch=11
05/22/2022 17:35:48 - INFO - __main__ - Step 670 Global step 670 Train loss 0.17 on epoch=11
05/22/2022 17:35:51 - INFO - __main__ - Step 680 Global step 680 Train loss 0.16 on epoch=12
05/22/2022 17:35:53 - INFO - __main__ - Step 690 Global step 690 Train loss 0.30 on epoch=12
05/22/2022 17:35:56 - INFO - __main__ - Step 700 Global step 700 Train loss 0.17 on epoch=12
05/22/2022 17:36:20 - INFO - __main__ - Global step 700 Train loss 0.19 Classification-F1 0.45830751692512117 on epoch=12
05/22/2022 17:36:23 - INFO - __main__ - Step 710 Global step 710 Train loss 0.11 on epoch=12
05/22/2022 17:36:25 - INFO - __main__ - Step 720 Global step 720 Train loss 0.10 on epoch=12
05/22/2022 17:36:28 - INFO - __main__ - Step 730 Global step 730 Train loss 0.06 on epoch=13
05/22/2022 17:36:31 - INFO - __main__ - Step 740 Global step 740 Train loss 0.16 on epoch=13
05/22/2022 17:36:33 - INFO - __main__ - Step 750 Global step 750 Train loss 0.13 on epoch=13
05/22/2022 17:37:01 - INFO - __main__ - Global step 750 Train loss 0.11 Classification-F1 0.4617347285093179 on epoch=13
05/22/2022 17:37:04 - INFO - __main__ - Step 760 Global step 760 Train loss 0.10 on epoch=13
05/22/2022 17:37:07 - INFO - __main__ - Step 770 Global step 770 Train loss 0.14 on epoch=13
05/22/2022 17:37:09 - INFO - __main__ - Step 780 Global step 780 Train loss 0.10 on epoch=13
05/22/2022 17:37:12 - INFO - __main__ - Step 790 Global step 790 Train loss 0.11 on epoch=14
05/22/2022 17:37:14 - INFO - __main__ - Step 800 Global step 800 Train loss 0.14 on epoch=14
05/22/2022 17:37:44 - INFO - __main__ - Global step 800 Train loss 0.12 Classification-F1 0.6292066104366882 on epoch=14
05/22/2022 17:37:47 - INFO - __main__ - Step 810 Global step 810 Train loss 0.13 on epoch=14
05/22/2022 17:37:49 - INFO - __main__ - Step 820 Global step 820 Train loss 0.12 on epoch=14
05/22/2022 17:37:52 - INFO - __main__ - Step 830 Global step 830 Train loss 0.10 on epoch=14
05/22/2022 17:37:54 - INFO - __main__ - Step 840 Global step 840 Train loss 0.11 on epoch=14
05/22/2022 17:37:57 - INFO - __main__ - Step 850 Global step 850 Train loss 0.19 on epoch=15
05/22/2022 17:38:25 - INFO - __main__ - Global step 850 Train loss 0.13 Classification-F1 0.5306089499736757 on epoch=15
05/22/2022 17:38:27 - INFO - __main__ - Step 860 Global step 860 Train loss 0.17 on epoch=15
05/22/2022 17:38:30 - INFO - __main__ - Step 870 Global step 870 Train loss 0.12 on epoch=15
05/22/2022 17:38:33 - INFO - __main__ - Step 880 Global step 880 Train loss 0.07 on epoch=15
05/22/2022 17:38:35 - INFO - __main__ - Step 890 Global step 890 Train loss 0.09 on epoch=15
05/22/2022 17:38:38 - INFO - __main__ - Step 900 Global step 900 Train loss 0.07 on epoch=16
05/22/2022 17:39:03 - INFO - __main__ - Global step 900 Train loss 0.10 Classification-F1 0.39091008476899436 on epoch=16
05/22/2022 17:39:06 - INFO - __main__ - Step 910 Global step 910 Train loss 0.11 on epoch=16
05/22/2022 17:39:08 - INFO - __main__ - Step 920 Global step 920 Train loss 0.08 on epoch=16
05/22/2022 17:39:11 - INFO - __main__ - Step 930 Global step 930 Train loss 0.09 on epoch=16
05/22/2022 17:39:13 - INFO - __main__ - Step 940 Global step 940 Train loss 0.05 on epoch=16
05/22/2022 17:39:16 - INFO - __main__ - Step 950 Global step 950 Train loss 0.11 on epoch=16
05/22/2022 17:39:45 - INFO - __main__ - Global step 950 Train loss 0.09 Classification-F1 0.47119407623093207 on epoch=16
05/22/2022 17:39:47 - INFO - __main__ - Step 960 Global step 960 Train loss 0.08 on epoch=17
05/22/2022 17:39:50 - INFO - __main__ - Step 970 Global step 970 Train loss 0.10 on epoch=17
05/22/2022 17:39:53 - INFO - __main__ - Step 980 Global step 980 Train loss 0.06 on epoch=17
05/22/2022 17:39:55 - INFO - __main__ - Step 990 Global step 990 Train loss 0.05 on epoch=17
05/22/2022 17:39:58 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.06 on epoch=17
05/22/2022 17:40:30 - INFO - __main__ - Global step 1000 Train loss 0.07 Classification-F1 0.6070929992292443 on epoch=17
05/22/2022 17:40:32 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.06 on epoch=18
05/22/2022 17:40:35 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.07 on epoch=18
05/22/2022 17:40:37 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.07 on epoch=18
05/22/2022 17:40:40 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.08 on epoch=18
05/22/2022 17:40:43 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.05 on epoch=18
05/22/2022 17:41:15 - INFO - __main__ - Global step 1050 Train loss 0.07 Classification-F1 0.573497536613943 on epoch=18
05/22/2022 17:41:18 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.07 on epoch=18
05/22/2022 17:41:20 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.06 on epoch=19
05/22/2022 17:41:23 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.15 on epoch=19
05/22/2022 17:41:26 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.10 on epoch=19
05/22/2022 17:41:28 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.06 on epoch=19
05/22/2022 17:41:53 - INFO - __main__ - Global step 1100 Train loss 0.09 Classification-F1 0.48466146683334294 on epoch=19
05/22/2022 17:41:56 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.03 on epoch=19
05/22/2022 17:41:58 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.02 on epoch=19
05/22/2022 17:42:01 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.13 on epoch=20
05/22/2022 17:42:04 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.10 on epoch=20
05/22/2022 17:42:06 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.04 on epoch=20
05/22/2022 17:42:31 - INFO - __main__ - Global step 1150 Train loss 0.06 Classification-F1 0.6758647705503037 on epoch=20
05/22/2022 17:42:31 - INFO - __main__ - Saving model with best Classification-F1: 0.6329868007669144 -> 0.6758647705503037 on epoch=20, global_step=1150
05/22/2022 17:42:34 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.03 on epoch=20
05/22/2022 17:42:37 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.05 on epoch=20
05/22/2022 17:42:39 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.03 on epoch=21
05/22/2022 17:42:42 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.09 on epoch=21
05/22/2022 17:42:44 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.06 on epoch=21
05/22/2022 17:43:08 - INFO - __main__ - Global step 1200 Train loss 0.05 Classification-F1 0.644035167931325 on epoch=21
05/22/2022 17:43:11 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.05 on epoch=21
05/22/2022 17:43:13 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.07 on epoch=21
05/22/2022 17:43:16 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.06 on epoch=21
05/22/2022 17:43:18 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.03 on epoch=22
05/22/2022 17:43:21 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.07 on epoch=22
05/22/2022 17:43:46 - INFO - __main__ - Global step 1250 Train loss 0.06 Classification-F1 0.7536886543339674 on epoch=22
05/22/2022 17:43:46 - INFO - __main__ - Saving model with best Classification-F1: 0.6758647705503037 -> 0.7536886543339674 on epoch=22, global_step=1250
05/22/2022 17:43:48 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.07 on epoch=22
05/22/2022 17:43:51 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.03 on epoch=22
05/22/2022 17:43:54 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.04 on epoch=22
05/22/2022 17:43:56 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.02 on epoch=23
05/22/2022 17:43:59 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.09 on epoch=23
05/22/2022 17:44:23 - INFO - __main__ - Global step 1300 Train loss 0.05 Classification-F1 0.8082657090224722 on epoch=23
05/22/2022 17:44:23 - INFO - __main__ - Saving model with best Classification-F1: 0.7536886543339674 -> 0.8082657090224722 on epoch=23, global_step=1300
05/22/2022 17:44:26 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.07 on epoch=23
05/22/2022 17:44:29 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.03 on epoch=23
05/22/2022 17:44:31 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.06 on epoch=23
05/22/2022 17:44:34 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.03 on epoch=23
05/22/2022 17:44:36 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=24
05/22/2022 17:45:00 - INFO - __main__ - Global step 1350 Train loss 0.04 Classification-F1 0.7235424449885132 on epoch=24
05/22/2022 17:45:03 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.07 on epoch=24
05/22/2022 17:45:05 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.04 on epoch=24
05/22/2022 17:45:08 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.04 on epoch=24
05/22/2022 17:45:10 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.04 on epoch=24
05/22/2022 17:45:13 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.07 on epoch=24
05/22/2022 17:45:36 - INFO - __main__ - Global step 1400 Train loss 0.05 Classification-F1 0.6763971794707724 on epoch=24
05/22/2022 17:45:38 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.09 on epoch=25
05/22/2022 17:45:41 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.05 on epoch=25
05/22/2022 17:45:43 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.04 on epoch=25
05/22/2022 17:45:46 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.03 on epoch=25
05/22/2022 17:45:49 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=25
05/22/2022 17:46:12 - INFO - __main__ - Global step 1450 Train loss 0.04 Classification-F1 0.534264530818503 on epoch=25
05/22/2022 17:46:14 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=26
05/22/2022 17:46:17 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.10 on epoch=26
05/22/2022 17:46:19 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.04 on epoch=26
05/22/2022 17:46:22 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.04 on epoch=26
05/22/2022 17:46:24 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.03 on epoch=26
05/22/2022 17:46:49 - INFO - __main__ - Global step 1500 Train loss 0.04 Classification-F1 0.6287674528294706 on epoch=26
05/22/2022 17:46:52 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.03 on epoch=26
05/22/2022 17:46:54 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.07 on epoch=27
05/22/2022 17:46:57 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.07 on epoch=27
05/22/2022 17:46:59 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=27
05/22/2022 17:47:02 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.05 on epoch=27
05/22/2022 17:47:25 - INFO - __main__ - Global step 1550 Train loss 0.05 Classification-F1 0.5472774628168843 on epoch=27
05/22/2022 17:47:27 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.04 on epoch=27
05/22/2022 17:47:30 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.04 on epoch=28
05/22/2022 17:47:32 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.05 on epoch=28
05/22/2022 17:47:35 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.04 on epoch=28
05/22/2022 17:47:38 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=28
05/22/2022 17:48:02 - INFO - __main__ - Global step 1600 Train loss 0.04 Classification-F1 0.6091950837532324 on epoch=28
05/22/2022 17:48:05 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.04 on epoch=28
05/22/2022 17:48:07 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.06 on epoch=28
05/22/2022 17:48:10 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.05 on epoch=29
05/22/2022 17:48:12 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.07 on epoch=29
05/22/2022 17:48:15 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.03 on epoch=29
05/22/2022 17:48:39 - INFO - __main__ - Global step 1650 Train loss 0.05 Classification-F1 0.5629643587724021 on epoch=29
05/22/2022 17:48:42 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.07 on epoch=29
05/22/2022 17:48:44 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.03 on epoch=29
05/22/2022 17:48:47 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=29
05/22/2022 17:48:50 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.04 on epoch=30
05/22/2022 17:48:52 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.09 on epoch=30
05/22/2022 17:49:16 - INFO - __main__ - Global step 1700 Train loss 0.05 Classification-F1 0.5273097822622574 on epoch=30
05/22/2022 17:49:19 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.03 on epoch=30
05/22/2022 17:49:22 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.05 on epoch=30
05/22/2022 17:49:24 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.03 on epoch=30
05/22/2022 17:49:27 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.06 on epoch=31
05/22/2022 17:49:29 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.08 on epoch=31
05/22/2022 17:49:53 - INFO - __main__ - Global step 1750 Train loss 0.05 Classification-F1 0.6798907389541903 on epoch=31
05/22/2022 17:49:55 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.05 on epoch=31
05/22/2022 17:49:58 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.03 on epoch=31
05/22/2022 17:50:00 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.04 on epoch=31
05/22/2022 17:50:03 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=31
05/22/2022 17:50:06 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.06 on epoch=32
05/22/2022 17:50:30 - INFO - __main__ - Global step 1800 Train loss 0.04 Classification-F1 0.7598689745369827 on epoch=32
05/22/2022 17:50:33 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.11 on epoch=32
05/22/2022 17:50:35 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=32
05/22/2022 17:50:38 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=32
05/22/2022 17:50:40 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=32
05/22/2022 17:50:43 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=33
05/22/2022 17:51:07 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.7202325187898234 on epoch=33
05/22/2022 17:51:10 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.03 on epoch=33
05/22/2022 17:51:12 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.05 on epoch=33
05/22/2022 17:51:15 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=33
05/22/2022 17:51:18 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=33
05/22/2022 17:51:20 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=33
05/22/2022 17:51:44 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.6367901975045088 on epoch=33
05/22/2022 17:51:46 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=34
05/22/2022 17:51:49 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.05 on epoch=34
05/22/2022 17:51:51 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=34
05/22/2022 17:51:54 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=34
05/22/2022 17:51:57 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=34
05/22/2022 17:52:20 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.6171202424554244 on epoch=34
05/22/2022 17:52:23 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=34
05/22/2022 17:52:25 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=35
05/22/2022 17:52:28 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.05 on epoch=35
05/22/2022 17:52:30 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=35
05/22/2022 17:52:33 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=35
05/22/2022 17:52:56 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.5987513301316927 on epoch=35
05/22/2022 17:52:58 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=35
05/22/2022 17:53:01 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=36
05/22/2022 17:53:04 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.03 on epoch=36
05/22/2022 17:53:06 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=36
05/22/2022 17:53:09 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.03 on epoch=36
05/22/2022 17:53:32 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.5986841592595252 on epoch=36
05/22/2022 17:53:35 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.04 on epoch=36
05/22/2022 17:53:37 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=36
05/22/2022 17:53:40 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=37
05/22/2022 17:53:42 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.05 on epoch=37
05/22/2022 17:53:45 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.04 on epoch=37
05/22/2022 17:54:09 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.5628939649789069 on epoch=37
05/22/2022 17:54:12 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=37
05/22/2022 17:54:14 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.04 on epoch=37
05/22/2022 17:54:17 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=38
05/22/2022 17:54:20 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=38
05/22/2022 17:54:22 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.03 on epoch=38
05/22/2022 17:54:46 - INFO - __main__ - Global step 2150 Train loss 0.03 Classification-F1 0.6026176298269694 on epoch=38
05/22/2022 17:54:48 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=38
05/22/2022 17:54:51 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=38
05/22/2022 17:54:53 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=38
05/22/2022 17:54:56 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=39
05/22/2022 17:54:59 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.08 on epoch=39
05/22/2022 17:55:21 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.501683414258833 on epoch=39
05/22/2022 17:55:24 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.06 on epoch=39
05/22/2022 17:55:27 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=39
05/22/2022 17:55:29 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.03 on epoch=39
05/22/2022 17:55:32 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=39
05/22/2022 17:55:34 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=40
05/22/2022 17:55:58 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.6774967470078808 on epoch=40
05/22/2022 17:56:01 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.04 on epoch=40
05/22/2022 17:56:04 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.04 on epoch=40
05/22/2022 17:56:06 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=40
05/22/2022 17:56:09 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=40
05/22/2022 17:56:12 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=41
05/22/2022 17:56:35 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.765102444316253 on epoch=41
05/22/2022 17:56:37 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.07 on epoch=41
05/22/2022 17:56:40 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=41
05/22/2022 17:56:42 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.04 on epoch=41
05/22/2022 17:56:45 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=41
05/22/2022 17:56:48 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=41
05/22/2022 17:57:11 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.7543047090820815 on epoch=41
05/22/2022 17:57:14 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=42
05/22/2022 17:57:16 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.05 on epoch=42
05/22/2022 17:57:19 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=42
05/22/2022 17:57:22 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.05 on epoch=42
05/22/2022 17:57:24 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=42
05/22/2022 17:57:48 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.7625391119102932 on epoch=42
05/22/2022 17:57:51 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=43
05/22/2022 17:57:53 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.04 on epoch=43
05/22/2022 17:57:56 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.05 on epoch=43
05/22/2022 17:57:58 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=43
05/22/2022 17:58:01 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=43
05/22/2022 17:58:25 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.7521181103206591 on epoch=43
05/22/2022 17:58:28 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=43
05/22/2022 17:58:31 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=44
05/22/2022 17:58:33 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.07 on epoch=44
05/22/2022 17:58:36 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.03 on epoch=44
05/22/2022 17:58:38 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=44
05/22/2022 17:59:03 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.63537628892867 on epoch=44
05/22/2022 17:59:06 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=44
05/22/2022 17:59:08 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=44
05/22/2022 17:59:11 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.05 on epoch=45
05/22/2022 17:59:13 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.04 on epoch=45
05/22/2022 17:59:16 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=45
05/22/2022 17:59:41 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.70875000291603 on epoch=45
05/22/2022 17:59:43 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.04 on epoch=45
05/22/2022 17:59:46 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=45
05/22/2022 17:59:49 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.03 on epoch=46
05/22/2022 17:59:51 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.05 on epoch=46
05/22/2022 17:59:54 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=46
05/22/2022 18:00:18 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.5770266227840432 on epoch=46
05/22/2022 18:00:20 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.03 on epoch=46
05/22/2022 18:00:23 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.03 on epoch=46
05/22/2022 18:00:26 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=46
05/22/2022 18:00:28 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=47
05/22/2022 18:00:31 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.04 on epoch=47
05/22/2022 18:00:55 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.6055810612054646 on epoch=47
05/22/2022 18:00:58 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=47
05/22/2022 18:01:00 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.03 on epoch=47
05/22/2022 18:01:03 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=47
05/22/2022 18:01:05 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=48
05/22/2022 18:01:08 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=48
05/22/2022 18:01:34 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.7223011266482486 on epoch=48
05/22/2022 18:01:36 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.06 on epoch=48
05/22/2022 18:01:39 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=48
05/22/2022 18:01:42 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=48
05/22/2022 18:01:44 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.04 on epoch=48
05/22/2022 18:01:47 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.03 on epoch=49
05/22/2022 18:02:12 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.6533114959848437 on epoch=49
05/22/2022 18:02:15 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.03 on epoch=49
05/22/2022 18:02:18 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.05 on epoch=49
05/22/2022 18:02:20 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.05 on epoch=49
05/22/2022 18:02:23 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.06 on epoch=49
05/22/2022 18:02:25 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=49
05/22/2022 18:02:49 - INFO - __main__ - Global step 2800 Train loss 0.04 Classification-F1 0.6441025264409908 on epoch=49
05/22/2022 18:02:51 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.04 on epoch=50
05/22/2022 18:02:54 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.08 on epoch=50
05/22/2022 18:02:56 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=50
05/22/2022 18:02:59 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=50
05/22/2022 18:03:01 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=50
05/22/2022 18:03:25 - INFO - __main__ - Global step 2850 Train loss 0.03 Classification-F1 0.7205712280955686 on epoch=50
05/22/2022 18:03:28 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=51
05/22/2022 18:03:30 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.03 on epoch=51
05/22/2022 18:03:33 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=51
05/22/2022 18:03:35 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=51
05/22/2022 18:03:38 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=51
05/22/2022 18:04:02 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.7215962925339534 on epoch=51
05/22/2022 18:04:04 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=51
05/22/2022 18:04:07 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=52
05/22/2022 18:04:09 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.05 on epoch=52
05/22/2022 18:04:12 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=52
05/22/2022 18:04:14 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.03 on epoch=52
05/22/2022 18:04:38 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.722703793770538 on epoch=52
05/22/2022 18:04:40 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=52
05/22/2022 18:04:43 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.03 on epoch=53
05/22/2022 18:04:46 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.04 on epoch=53
05/22/2022 18:04:48 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=53
05/22/2022 18:04:51 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=53
05/22/2022 18:04:52 - INFO - __main__ - Start tokenizing ... 896 instances
05/22/2022 18:04:52 - INFO - __main__ - Printing 3 examples
05/22/2022 18:04:52 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/22/2022 18:04:52 - INFO - __main__ - ['Animal']
05/22/2022 18:04:52 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/22/2022 18:04:52 - INFO - __main__ - ['Animal']
05/22/2022 18:04:52 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
05/22/2022 18:04:52 - INFO - __main__ - ['Animal']
05/22/2022 18:04:52 - INFO - __main__ - Tokenizing Input ...
05/22/2022 18:04:53 - INFO - __main__ - Tokenizing Output ...
05/22/2022 18:04:54 - INFO - __main__ - Loaded 896 examples from train data
05/22/2022 18:04:54 - INFO - __main__ - Start tokenizing ... 896 instances
05/22/2022 18:04:54 - INFO - __main__ - Printing 3 examples
05/22/2022 18:04:54 - INFO - __main__ -  [dbpedia_14] Clarkesvillia is an Upper Ordovician westonocerid genus the differs from Faberoceras in having a more flattened venter and from the later Glyptodendron in having a more ventrally located siphuncle.
05/22/2022 18:04:54 - INFO - __main__ - ['Animal']
05/22/2022 18:04:54 - INFO - __main__ -  [dbpedia_14] Alaena ochracea is a butterfly in the Lycaenidae family. It is found in Malawi (from the southern part of the country to the Shire Highlands). The habitat consists of the fringes of submontane evergreen forests.
05/22/2022 18:04:54 - INFO - __main__ - ['Animal']
05/22/2022 18:04:54 - INFO - __main__ -  [dbpedia_14] Latoia is a genus of moths in the family Limacodidae.
05/22/2022 18:04:54 - INFO - __main__ - ['Animal']
05/22/2022 18:04:54 - INFO - __main__ - Tokenizing Input ...
05/22/2022 18:04:54 - INFO - __main__ - Tokenizing Output ...
05/22/2022 18:04:55 - INFO - __main__ - Loaded 896 examples from dev data
05/22/2022 18:05:12 - INFO - __main__ - try to initialize prompt embeddings
05/22/2022 18:05:12 - INFO - __main__ - task name: dbpedia_14
05/22/2022 18:05:13 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 18:05:13 - INFO - __main__ - Starting training!
05/22/2022 18:05:15 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.7660081769717907 on epoch=53
05/22/2022 18:05:15 - INFO - __main__ - save last model!
05/22/2022 18:05:15 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/22/2022 18:05:15 - INFO - __main__ - Start tokenizing ... 3500 instances
05/22/2022 18:05:15 - INFO - __main__ - Printing 3 examples
05/22/2022 18:05:15 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/22/2022 18:05:15 - INFO - __main__ - ['Animal']
05/22/2022 18:05:15 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/22/2022 18:05:15 - INFO - __main__ - ['Animal']
05/22/2022 18:05:15 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/22/2022 18:05:15 - INFO - __main__ - ['Village']
05/22/2022 18:05:15 - INFO - __main__ - Tokenizing Input ...
05/22/2022 18:05:17 - INFO - __main__ - Tokenizing Output ...
05/22/2022 18:05:20 - INFO - __main__ - Loaded 3500 examples from test data
05/22/2022 18:07:25 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down64shot/singletask-dbpedia_14/dbpedia_14_64_13_0.5_8_predictions.txt
05/22/2022 18:07:25 - INFO - __main__ - Classification-F1 on test data: 0.6897
05/22/2022 18:07:25 - INFO - __main__ - prefix=dbpedia_14_64_13, lr=0.5, bsz=8, dev_performance=0.8082657090224722, test_performance=0.6896765765491113
05/22/2022 18:07:25 - INFO - __main__ - Running ... prefix=dbpedia_14_64_13, lr=0.4, bsz=8 ...
05/22/2022 18:07:26 - INFO - __main__ - Start tokenizing ... 896 instances
05/22/2022 18:07:26 - INFO - __main__ - Printing 3 examples
05/22/2022 18:07:26 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/22/2022 18:07:26 - INFO - __main__ - ['Animal']
05/22/2022 18:07:26 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/22/2022 18:07:26 - INFO - __main__ - ['Animal']
05/22/2022 18:07:26 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
05/22/2022 18:07:26 - INFO - __main__ - ['Animal']
05/22/2022 18:07:26 - INFO - __main__ - Tokenizing Input ...
05/22/2022 18:07:27 - INFO - __main__ - Tokenizing Output ...
05/22/2022 18:07:28 - INFO - __main__ - Loaded 896 examples from train data
05/22/2022 18:07:28 - INFO - __main__ - Start tokenizing ... 896 instances
05/22/2022 18:07:28 - INFO - __main__ - Printing 3 examples
05/22/2022 18:07:28 - INFO - __main__ -  [dbpedia_14] Clarkesvillia is an Upper Ordovician westonocerid genus the differs from Faberoceras in having a more flattened venter and from the later Glyptodendron in having a more ventrally located siphuncle.
05/22/2022 18:07:28 - INFO - __main__ - ['Animal']
05/22/2022 18:07:28 - INFO - __main__ -  [dbpedia_14] Alaena ochracea is a butterfly in the Lycaenidae family. It is found in Malawi (from the southern part of the country to the Shire Highlands). The habitat consists of the fringes of submontane evergreen forests.
05/22/2022 18:07:28 - INFO - __main__ - ['Animal']
05/22/2022 18:07:28 - INFO - __main__ -  [dbpedia_14] Latoia is a genus of moths in the family Limacodidae.
05/22/2022 18:07:28 - INFO - __main__ - ['Animal']
05/22/2022 18:07:28 - INFO - __main__ - Tokenizing Input ...
05/22/2022 18:07:28 - INFO - __main__ - Tokenizing Output ...
05/22/2022 18:07:29 - INFO - __main__ - Loaded 896 examples from dev data
05/22/2022 18:07:44 - INFO - __main__ - try to initialize prompt embeddings
05/22/2022 18:07:44 - INFO - __main__ - task name: dbpedia_14
05/22/2022 18:07:45 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 18:07:45 - INFO - __main__ - Starting training!
05/22/2022 18:07:48 - INFO - __main__ - Step 10 Global step 10 Train loss 6.40 on epoch=0
05/22/2022 18:07:51 - INFO - __main__ - Step 20 Global step 20 Train loss 5.30 on epoch=0
05/22/2022 18:07:54 - INFO - __main__ - Step 30 Global step 30 Train loss 3.83 on epoch=0
05/22/2022 18:07:56 - INFO - __main__ - Step 40 Global step 40 Train loss 2.85 on epoch=0
05/22/2022 18:07:59 - INFO - __main__ - Step 50 Global step 50 Train loss 2.26 on epoch=0
05/22/2022 18:08:45 - INFO - __main__ - Global step 50 Train loss 4.13 Classification-F1 0.08425188290441647 on epoch=0
05/22/2022 18:08:45 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.08425188290441647 on epoch=0, global_step=50
05/22/2022 18:08:47 - INFO - __main__ - Step 60 Global step 60 Train loss 1.81 on epoch=1
05/22/2022 18:08:50 - INFO - __main__ - Step 70 Global step 70 Train loss 1.51 on epoch=1
05/22/2022 18:08:52 - INFO - __main__ - Step 80 Global step 80 Train loss 1.29 on epoch=1
05/22/2022 18:08:55 - INFO - __main__ - Step 90 Global step 90 Train loss 1.11 on epoch=1
05/22/2022 18:08:57 - INFO - __main__ - Step 100 Global step 100 Train loss 1.08 on epoch=1
05/22/2022 18:09:59 - INFO - __main__ - Global step 100 Train loss 1.36 Classification-F1 0.15121720220482893 on epoch=1
05/22/2022 18:09:59 - INFO - __main__ - Saving model with best Classification-F1: 0.08425188290441647 -> 0.15121720220482893 on epoch=1, global_step=100
05/22/2022 18:10:01 - INFO - __main__ - Step 110 Global step 110 Train loss 1.05 on epoch=1
05/22/2022 18:10:04 - INFO - __main__ - Step 120 Global step 120 Train loss 0.93 on epoch=2
05/22/2022 18:10:06 - INFO - __main__ - Step 130 Global step 130 Train loss 1.00 on epoch=2
05/22/2022 18:10:09 - INFO - __main__ - Step 140 Global step 140 Train loss 0.91 on epoch=2
05/22/2022 18:10:11 - INFO - __main__ - Step 150 Global step 150 Train loss 0.82 on epoch=2
05/22/2022 18:10:45 - INFO - __main__ - Global step 150 Train loss 0.94 Classification-F1 0.22837401671322757 on epoch=2
05/22/2022 18:10:45 - INFO - __main__ - Saving model with best Classification-F1: 0.15121720220482893 -> 0.22837401671322757 on epoch=2, global_step=150
05/22/2022 18:10:48 - INFO - __main__ - Step 160 Global step 160 Train loss 0.80 on epoch=2
05/22/2022 18:10:50 - INFO - __main__ - Step 170 Global step 170 Train loss 0.72 on epoch=3
05/22/2022 18:10:53 - INFO - __main__ - Step 180 Global step 180 Train loss 0.83 on epoch=3
05/22/2022 18:10:55 - INFO - __main__ - Step 190 Global step 190 Train loss 0.84 on epoch=3
05/22/2022 18:10:58 - INFO - __main__ - Step 200 Global step 200 Train loss 0.82 on epoch=3
05/22/2022 18:11:24 - INFO - __main__ - Global step 200 Train loss 0.80 Classification-F1 0.41430643957339175 on epoch=3
05/22/2022 18:11:24 - INFO - __main__ - Saving model with best Classification-F1: 0.22837401671322757 -> 0.41430643957339175 on epoch=3, global_step=200
05/22/2022 18:11:26 - INFO - __main__ - Step 210 Global step 210 Train loss 0.58 on epoch=3
05/22/2022 18:11:29 - INFO - __main__ - Step 220 Global step 220 Train loss 0.68 on epoch=3
05/22/2022 18:11:31 - INFO - __main__ - Step 230 Global step 230 Train loss 0.64 on epoch=4
05/22/2022 18:11:34 - INFO - __main__ - Step 240 Global step 240 Train loss 0.66 on epoch=4
05/22/2022 18:11:36 - INFO - __main__ - Step 250 Global step 250 Train loss 0.66 on epoch=4
05/22/2022 18:12:06 - INFO - __main__ - Global step 250 Train loss 0.64 Classification-F1 0.3801553140508828 on epoch=4
05/22/2022 18:12:08 - INFO - __main__ - Step 260 Global step 260 Train loss 0.61 on epoch=4
05/22/2022 18:12:11 - INFO - __main__ - Step 270 Global step 270 Train loss 0.57 on epoch=4
05/22/2022 18:12:14 - INFO - __main__ - Step 280 Global step 280 Train loss 0.51 on epoch=4
05/22/2022 18:12:16 - INFO - __main__ - Step 290 Global step 290 Train loss 0.56 on epoch=5
05/22/2022 18:12:19 - INFO - __main__ - Step 300 Global step 300 Train loss 0.58 on epoch=5
05/22/2022 18:12:46 - INFO - __main__ - Global step 300 Train loss 0.57 Classification-F1 0.33928819499421087 on epoch=5
05/22/2022 18:12:48 - INFO - __main__ - Step 310 Global step 310 Train loss 0.53 on epoch=5
05/22/2022 18:12:51 - INFO - __main__ - Step 320 Global step 320 Train loss 0.49 on epoch=5
05/22/2022 18:12:54 - INFO - __main__ - Step 330 Global step 330 Train loss 0.48 on epoch=5
05/22/2022 18:12:56 - INFO - __main__ - Step 340 Global step 340 Train loss 0.41 on epoch=6
05/22/2022 18:12:59 - INFO - __main__ - Step 350 Global step 350 Train loss 0.44 on epoch=6
05/22/2022 18:13:26 - INFO - __main__ - Global step 350 Train loss 0.47 Classification-F1 0.44794282952308406 on epoch=6
05/22/2022 18:13:26 - INFO - __main__ - Saving model with best Classification-F1: 0.41430643957339175 -> 0.44794282952308406 on epoch=6, global_step=350
05/22/2022 18:13:29 - INFO - __main__ - Step 360 Global step 360 Train loss 0.44 on epoch=6
05/22/2022 18:13:31 - INFO - __main__ - Step 370 Global step 370 Train loss 0.57 on epoch=6
05/22/2022 18:13:34 - INFO - __main__ - Step 380 Global step 380 Train loss 0.42 on epoch=6
05/22/2022 18:13:37 - INFO - __main__ - Step 390 Global step 390 Train loss 0.40 on epoch=6
05/22/2022 18:13:39 - INFO - __main__ - Step 400 Global step 400 Train loss 0.34 on epoch=7
05/22/2022 18:14:07 - INFO - __main__ - Global step 400 Train loss 0.43 Classification-F1 0.3958908334739018 on epoch=7
05/22/2022 18:14:10 - INFO - __main__ - Step 410 Global step 410 Train loss 0.49 on epoch=7
05/22/2022 18:14:12 - INFO - __main__ - Step 420 Global step 420 Train loss 0.36 on epoch=7
05/22/2022 18:14:15 - INFO - __main__ - Step 430 Global step 430 Train loss 0.38 on epoch=7
05/22/2022 18:14:18 - INFO - __main__ - Step 440 Global step 440 Train loss 0.41 on epoch=7
05/22/2022 18:14:20 - INFO - __main__ - Step 450 Global step 450 Train loss 0.27 on epoch=8
05/22/2022 18:14:46 - INFO - __main__ - Global step 450 Train loss 0.38 Classification-F1 0.6043303854171952 on epoch=8
05/22/2022 18:14:46 - INFO - __main__ - Saving model with best Classification-F1: 0.44794282952308406 -> 0.6043303854171952 on epoch=8, global_step=450
05/22/2022 18:14:49 - INFO - __main__ - Step 460 Global step 460 Train loss 0.38 on epoch=8
05/22/2022 18:14:51 - INFO - __main__ - Step 470 Global step 470 Train loss 0.37 on epoch=8
05/22/2022 18:14:54 - INFO - __main__ - Step 480 Global step 480 Train loss 0.42 on epoch=8
05/22/2022 18:14:57 - INFO - __main__ - Step 490 Global step 490 Train loss 0.26 on epoch=8
05/22/2022 18:14:59 - INFO - __main__ - Step 500 Global step 500 Train loss 0.25 on epoch=8
05/22/2022 18:15:27 - INFO - __main__ - Global step 500 Train loss 0.34 Classification-F1 0.47194034498246806 on epoch=8
05/22/2022 18:15:29 - INFO - __main__ - Step 510 Global step 510 Train loss 0.30 on epoch=9
05/22/2022 18:15:32 - INFO - __main__ - Step 520 Global step 520 Train loss 0.36 on epoch=9
05/22/2022 18:15:35 - INFO - __main__ - Step 530 Global step 530 Train loss 0.31 on epoch=9
05/22/2022 18:15:37 - INFO - __main__ - Step 540 Global step 540 Train loss 0.25 on epoch=9
05/22/2022 18:15:40 - INFO - __main__ - Step 550 Global step 550 Train loss 0.30 on epoch=9
05/22/2022 18:16:04 - INFO - __main__ - Global step 550 Train loss 0.30 Classification-F1 0.7151260641164906 on epoch=9
05/22/2022 18:16:04 - INFO - __main__ - Saving model with best Classification-F1: 0.6043303854171952 -> 0.7151260641164906 on epoch=9, global_step=550
05/22/2022 18:16:07 - INFO - __main__ - Step 560 Global step 560 Train loss 0.18 on epoch=9
05/22/2022 18:16:10 - INFO - __main__ - Step 570 Global step 570 Train loss 0.23 on epoch=10
05/22/2022 18:16:12 - INFO - __main__ - Step 580 Global step 580 Train loss 0.24 on epoch=10
05/22/2022 18:16:15 - INFO - __main__ - Step 590 Global step 590 Train loss 0.24 on epoch=10
05/22/2022 18:16:17 - INFO - __main__ - Step 600 Global step 600 Train loss 0.16 on epoch=10
05/22/2022 18:16:43 - INFO - __main__ - Global step 600 Train loss 0.21 Classification-F1 0.7303100759486674 on epoch=10
05/22/2022 18:16:43 - INFO - __main__ - Saving model with best Classification-F1: 0.7151260641164906 -> 0.7303100759486674 on epoch=10, global_step=600
05/22/2022 18:16:46 - INFO - __main__ - Step 610 Global step 610 Train loss 0.25 on epoch=10
05/22/2022 18:16:48 - INFO - __main__ - Step 620 Global step 620 Train loss 0.17 on epoch=11
05/22/2022 18:16:51 - INFO - __main__ - Step 630 Global step 630 Train loss 0.26 on epoch=11
05/22/2022 18:16:54 - INFO - __main__ - Step 640 Global step 640 Train loss 0.25 on epoch=11
05/22/2022 18:16:56 - INFO - __main__ - Step 650 Global step 650 Train loss 0.18 on epoch=11
05/22/2022 18:17:24 - INFO - __main__ - Global step 650 Train loss 0.22 Classification-F1 0.5485179222420691 on epoch=11
05/22/2022 18:17:27 - INFO - __main__ - Step 660 Global step 660 Train loss 0.14 on epoch=11
05/22/2022 18:17:29 - INFO - __main__ - Step 670 Global step 670 Train loss 0.15 on epoch=11
05/22/2022 18:17:32 - INFO - __main__ - Step 680 Global step 680 Train loss 0.15 on epoch=12
05/22/2022 18:17:34 - INFO - __main__ - Step 690 Global step 690 Train loss 0.22 on epoch=12
05/22/2022 18:17:37 - INFO - __main__ - Step 700 Global step 700 Train loss 0.10 on epoch=12
05/22/2022 18:18:05 - INFO - __main__ - Global step 700 Train loss 0.15 Classification-F1 0.6146987340618898 on epoch=12
05/22/2022 18:18:07 - INFO - __main__ - Step 710 Global step 710 Train loss 0.16 on epoch=12
05/22/2022 18:18:10 - INFO - __main__ - Step 720 Global step 720 Train loss 0.16 on epoch=12
05/22/2022 18:18:12 - INFO - __main__ - Step 730 Global step 730 Train loss 0.07 on epoch=13
05/22/2022 18:18:15 - INFO - __main__ - Step 740 Global step 740 Train loss 0.19 on epoch=13
05/22/2022 18:18:18 - INFO - __main__ - Step 750 Global step 750 Train loss 0.18 on epoch=13
05/22/2022 18:18:47 - INFO - __main__ - Global step 750 Train loss 0.15 Classification-F1 0.5535086772006664 on epoch=13
05/22/2022 18:18:49 - INFO - __main__ - Step 760 Global step 760 Train loss 0.11 on epoch=13
05/22/2022 18:18:52 - INFO - __main__ - Step 770 Global step 770 Train loss 0.16 on epoch=13
05/22/2022 18:18:54 - INFO - __main__ - Step 780 Global step 780 Train loss 0.11 on epoch=13
05/22/2022 18:18:57 - INFO - __main__ - Step 790 Global step 790 Train loss 0.16 on epoch=14
05/22/2022 18:18:59 - INFO - __main__ - Step 800 Global step 800 Train loss 0.11 on epoch=14
05/22/2022 18:19:31 - INFO - __main__ - Global step 800 Train loss 0.13 Classification-F1 0.6556935151826974 on epoch=14
05/22/2022 18:19:34 - INFO - __main__ - Step 810 Global step 810 Train loss 0.14 on epoch=14
05/22/2022 18:19:36 - INFO - __main__ - Step 820 Global step 820 Train loss 0.15 on epoch=14
05/22/2022 18:19:39 - INFO - __main__ - Step 830 Global step 830 Train loss 0.12 on epoch=14
05/22/2022 18:19:41 - INFO - __main__ - Step 840 Global step 840 Train loss 0.07 on epoch=14
05/22/2022 18:19:44 - INFO - __main__ - Step 850 Global step 850 Train loss 0.18 on epoch=15
05/22/2022 18:20:13 - INFO - __main__ - Global step 850 Train loss 0.13 Classification-F1 0.6321390989221021 on epoch=15
05/22/2022 18:20:16 - INFO - __main__ - Step 860 Global step 860 Train loss 0.18 on epoch=15
05/22/2022 18:20:18 - INFO - __main__ - Step 870 Global step 870 Train loss 0.13 on epoch=15
05/22/2022 18:20:21 - INFO - __main__ - Step 880 Global step 880 Train loss 0.13 on epoch=15
05/22/2022 18:20:24 - INFO - __main__ - Step 890 Global step 890 Train loss 0.09 on epoch=15
05/22/2022 18:20:26 - INFO - __main__ - Step 900 Global step 900 Train loss 0.09 on epoch=16
05/22/2022 18:20:52 - INFO - __main__ - Global step 900 Train loss 0.12 Classification-F1 0.5666869302581451 on epoch=16
05/22/2022 18:20:55 - INFO - __main__ - Step 910 Global step 910 Train loss 0.16 on epoch=16
05/22/2022 18:20:58 - INFO - __main__ - Step 920 Global step 920 Train loss 0.10 on epoch=16
05/22/2022 18:21:00 - INFO - __main__ - Step 930 Global step 930 Train loss 0.18 on epoch=16
05/22/2022 18:21:03 - INFO - __main__ - Step 940 Global step 940 Train loss 0.09 on epoch=16
05/22/2022 18:21:06 - INFO - __main__ - Step 950 Global step 950 Train loss 0.08 on epoch=16
05/22/2022 18:21:33 - INFO - __main__ - Global step 950 Train loss 0.12 Classification-F1 0.5787261546470058 on epoch=16
05/22/2022 18:21:35 - INFO - __main__ - Step 960 Global step 960 Train loss 0.11 on epoch=17
05/22/2022 18:21:38 - INFO - __main__ - Step 970 Global step 970 Train loss 0.21 on epoch=17
05/22/2022 18:21:40 - INFO - __main__ - Step 980 Global step 980 Train loss 0.13 on epoch=17
05/22/2022 18:21:43 - INFO - __main__ - Step 990 Global step 990 Train loss 0.09 on epoch=17
05/22/2022 18:21:46 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.11 on epoch=17
05/22/2022 18:22:09 - INFO - __main__ - Global step 1000 Train loss 0.13 Classification-F1 0.6447278549572365 on epoch=17
05/22/2022 18:22:12 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.07 on epoch=18
05/22/2022 18:22:15 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.10 on epoch=18
05/22/2022 18:22:17 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.11 on epoch=18
05/22/2022 18:22:20 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.08 on epoch=18
05/22/2022 18:22:22 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.10 on epoch=18
05/22/2022 18:22:48 - INFO - __main__ - Global step 1050 Train loss 0.09 Classification-F1 0.7572215809338335 on epoch=18
05/22/2022 18:22:48 - INFO - __main__ - Saving model with best Classification-F1: 0.7303100759486674 -> 0.7572215809338335 on epoch=18, global_step=1050
05/22/2022 18:22:51 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.07 on epoch=18
05/22/2022 18:22:54 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.05 on epoch=19
05/22/2022 18:22:56 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.11 on epoch=19
05/22/2022 18:22:59 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.12 on epoch=19
05/22/2022 18:23:02 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.07 on epoch=19
05/22/2022 18:23:26 - INFO - __main__ - Global step 1100 Train loss 0.08 Classification-F1 0.6660862841571773 on epoch=19
05/22/2022 18:23:28 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.07 on epoch=19
05/22/2022 18:23:31 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.04 on epoch=19
05/22/2022 18:23:34 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.15 on epoch=20
05/22/2022 18:23:36 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.12 on epoch=20
05/22/2022 18:23:39 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.09 on epoch=20
05/22/2022 18:24:07 - INFO - __main__ - Global step 1150 Train loss 0.09 Classification-F1 0.6881986600320629 on epoch=20
05/22/2022 18:24:10 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.11 on epoch=20
05/22/2022 18:24:13 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.05 on epoch=20
05/22/2022 18:24:15 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.07 on epoch=21
05/22/2022 18:24:18 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.09 on epoch=21
05/22/2022 18:24:20 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.03 on epoch=21
05/22/2022 18:24:46 - INFO - __main__ - Global step 1200 Train loss 0.07 Classification-F1 0.5596681232405806 on epoch=21
05/22/2022 18:24:49 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.07 on epoch=21
05/22/2022 18:24:51 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.04 on epoch=21
05/22/2022 18:24:54 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.04 on epoch=21
05/22/2022 18:24:57 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.05 on epoch=22
05/22/2022 18:24:59 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.09 on epoch=22
05/22/2022 18:25:23 - INFO - __main__ - Global step 1250 Train loss 0.06 Classification-F1 0.6376348417740877 on epoch=22
05/22/2022 18:25:26 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.06 on epoch=22
05/22/2022 18:25:28 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.04 on epoch=22
05/22/2022 18:25:31 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.04 on epoch=22
05/22/2022 18:25:34 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.06 on epoch=23
05/22/2022 18:25:36 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.06 on epoch=23
05/22/2022 18:26:01 - INFO - __main__ - Global step 1300 Train loss 0.05 Classification-F1 0.7162515060902013 on epoch=23
05/22/2022 18:26:04 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.05 on epoch=23
05/22/2022 18:26:06 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.04 on epoch=23
05/22/2022 18:26:09 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.10 on epoch=23
05/22/2022 18:26:12 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.04 on epoch=23
05/22/2022 18:26:14 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.04 on epoch=24
05/22/2022 18:26:39 - INFO - __main__ - Global step 1350 Train loss 0.05 Classification-F1 0.6441856399930407 on epoch=24
05/22/2022 18:26:41 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.09 on epoch=24
05/22/2022 18:26:44 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.03 on epoch=24
05/22/2022 18:26:47 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.02 on epoch=24
05/22/2022 18:26:49 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.04 on epoch=24
05/22/2022 18:26:52 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.03 on epoch=24
05/22/2022 18:27:15 - INFO - __main__ - Global step 1400 Train loss 0.04 Classification-F1 0.660069532051312 on epoch=24
05/22/2022 18:27:18 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.07 on epoch=25
05/22/2022 18:27:20 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.08 on epoch=25
05/22/2022 18:27:23 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.06 on epoch=25
05/22/2022 18:27:25 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=25
05/22/2022 18:27:28 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.04 on epoch=25
05/22/2022 18:27:51 - INFO - __main__ - Global step 1450 Train loss 0.05 Classification-F1 0.8087716884078721 on epoch=25
05/22/2022 18:27:51 - INFO - __main__ - Saving model with best Classification-F1: 0.7572215809338335 -> 0.8087716884078721 on epoch=25, global_step=1450
05/22/2022 18:27:53 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.02 on epoch=26
05/22/2022 18:27:56 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.09 on epoch=26
05/22/2022 18:27:59 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.04 on epoch=26
05/22/2022 18:28:01 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.10 on epoch=26
05/22/2022 18:28:04 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.07 on epoch=26
05/22/2022 18:28:28 - INFO - __main__ - Global step 1500 Train loss 0.06 Classification-F1 0.6749878329956817 on epoch=26
05/22/2022 18:28:31 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.05 on epoch=26
05/22/2022 18:28:33 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.03 on epoch=27
05/22/2022 18:28:36 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.08 on epoch=27
05/22/2022 18:28:39 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.07 on epoch=27
05/22/2022 18:28:41 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.04 on epoch=27
05/22/2022 18:29:05 - INFO - __main__ - Global step 1550 Train loss 0.05 Classification-F1 0.7093043209841515 on epoch=27
05/22/2022 18:29:07 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.03 on epoch=27
05/22/2022 18:29:10 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.03 on epoch=28
05/22/2022 18:29:12 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.10 on epoch=28
05/22/2022 18:29:15 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.04 on epoch=28
05/22/2022 18:29:18 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.03 on epoch=28
05/22/2022 18:29:43 - INFO - __main__ - Global step 1600 Train loss 0.05 Classification-F1 0.8050145765830572 on epoch=28
05/22/2022 18:29:45 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.04 on epoch=28
05/22/2022 18:29:48 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=28
05/22/2022 18:29:51 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=29
05/22/2022 18:29:53 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.10 on epoch=29
05/22/2022 18:29:56 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=29
05/22/2022 18:30:20 - INFO - __main__ - Global step 1650 Train loss 0.04 Classification-F1 0.718576925372597 on epoch=29
05/22/2022 18:30:23 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=29
05/22/2022 18:30:26 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.04 on epoch=29
05/22/2022 18:30:28 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.05 on epoch=29
05/22/2022 18:30:31 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.06 on epoch=30
05/22/2022 18:30:33 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.05 on epoch=30
05/22/2022 18:30:57 - INFO - __main__ - Global step 1700 Train loss 0.04 Classification-F1 0.6806343431516956 on epoch=30
05/22/2022 18:31:00 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.05 on epoch=30
05/22/2022 18:31:02 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.02 on epoch=30
05/22/2022 18:31:05 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=30
05/22/2022 18:31:08 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=31
05/22/2022 18:31:10 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.06 on epoch=31
05/22/2022 18:31:33 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.6783506324186367 on epoch=31
05/22/2022 18:31:36 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.04 on epoch=31
05/22/2022 18:31:38 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.04 on epoch=31
05/22/2022 18:31:41 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.07 on epoch=31
05/22/2022 18:31:44 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.03 on epoch=31
05/22/2022 18:31:46 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=32
05/22/2022 18:32:09 - INFO - __main__ - Global step 1800 Train loss 0.04 Classification-F1 0.713778874799428 on epoch=32
05/22/2022 18:32:11 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.08 on epoch=32
05/22/2022 18:32:14 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=32
05/22/2022 18:32:16 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=32
05/22/2022 18:32:19 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.05 on epoch=32
05/22/2022 18:32:22 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.04 on epoch=33
05/22/2022 18:32:44 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.5281022124922352 on epoch=33
05/22/2022 18:32:46 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.06 on epoch=33
05/22/2022 18:32:49 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.05 on epoch=33
05/22/2022 18:32:52 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.03 on epoch=33
05/22/2022 18:32:54 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.04 on epoch=33
05/22/2022 18:32:57 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.04 on epoch=33
05/22/2022 18:33:20 - INFO - __main__ - Global step 1900 Train loss 0.04 Classification-F1 0.7108186857810956 on epoch=33
05/22/2022 18:33:23 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=34
05/22/2022 18:33:25 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.08 on epoch=34
05/22/2022 18:33:28 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=34
05/22/2022 18:33:31 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=34
05/22/2022 18:33:33 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.07 on epoch=34
05/22/2022 18:33:56 - INFO - __main__ - Global step 1950 Train loss 0.04 Classification-F1 0.6023702731999798 on epoch=34
05/22/2022 18:33:58 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.03 on epoch=34
05/22/2022 18:34:01 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.08 on epoch=35
05/22/2022 18:34:04 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.04 on epoch=35
05/22/2022 18:34:06 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=35
05/22/2022 18:34:09 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.04 on epoch=35
05/22/2022 18:34:32 - INFO - __main__ - Global step 2000 Train loss 0.04 Classification-F1 0.6479596641287398 on epoch=35
05/22/2022 18:34:35 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.04 on epoch=35
05/22/2022 18:34:37 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.05 on epoch=36
05/22/2022 18:34:40 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.10 on epoch=36
05/22/2022 18:34:43 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=36
05/22/2022 18:34:45 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.06 on epoch=36
05/22/2022 18:35:08 - INFO - __main__ - Global step 2050 Train loss 0.06 Classification-F1 0.7633451714647117 on epoch=36
05/22/2022 18:35:11 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=36
05/22/2022 18:35:14 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.06 on epoch=36
05/22/2022 18:35:16 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.05 on epoch=37
05/22/2022 18:35:19 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.05 on epoch=37
05/22/2022 18:35:22 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.08 on epoch=37
05/22/2022 18:35:45 - INFO - __main__ - Global step 2100 Train loss 0.05 Classification-F1 0.7601604551473831 on epoch=37
05/22/2022 18:35:48 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=37
05/22/2022 18:35:50 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.04 on epoch=37
05/22/2022 18:35:53 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.04 on epoch=38
05/22/2022 18:35:56 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.04 on epoch=38
05/22/2022 18:35:58 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.06 on epoch=38
05/22/2022 18:36:22 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.7562953497736488 on epoch=38
05/22/2022 18:36:24 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=38
05/22/2022 18:36:27 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.04 on epoch=38
05/22/2022 18:36:29 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=38
05/22/2022 18:36:32 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=39
05/22/2022 18:36:35 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.07 on epoch=39
05/22/2022 18:36:58 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.7971893535929812 on epoch=39
05/22/2022 18:37:00 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=39
05/22/2022 18:37:03 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=39
05/22/2022 18:37:06 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.05 on epoch=39
05/22/2022 18:37:08 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=39
05/22/2022 18:37:11 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.05 on epoch=40
05/22/2022 18:37:34 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.7586580601130541 on epoch=40
05/22/2022 18:37:37 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.06 on epoch=40
05/22/2022 18:37:40 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=40
05/22/2022 18:37:42 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.06 on epoch=40
05/22/2022 18:37:45 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=40
05/22/2022 18:37:48 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=41
05/22/2022 18:38:10 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.6758069537273441 on epoch=41
05/22/2022 18:38:13 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.04 on epoch=41
05/22/2022 18:38:16 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=41
05/22/2022 18:38:18 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=41
05/22/2022 18:38:21 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.04 on epoch=41
05/22/2022 18:38:23 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.04 on epoch=41
05/22/2022 18:38:46 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.7199137828148565 on epoch=41
05/22/2022 18:38:49 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=42
05/22/2022 18:38:52 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.04 on epoch=42
05/22/2022 18:38:54 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.03 on epoch=42
05/22/2022 18:38:57 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=42
05/22/2022 18:38:59 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=42
05/22/2022 18:39:23 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.7257094840359907 on epoch=42
05/22/2022 18:39:26 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=43
05/22/2022 18:39:28 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.04 on epoch=43
05/22/2022 18:39:31 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.08 on epoch=43
05/22/2022 18:39:34 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=43
05/22/2022 18:39:36 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.05 on epoch=43
05/22/2022 18:40:00 - INFO - __main__ - Global step 2450 Train loss 0.04 Classification-F1 0.8517061084791354 on epoch=43
05/22/2022 18:40:00 - INFO - __main__ - Saving model with best Classification-F1: 0.8087716884078721 -> 0.8517061084791354 on epoch=43, global_step=2450
05/22/2022 18:40:02 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=43
05/22/2022 18:40:05 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=44
05/22/2022 18:40:08 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.07 on epoch=44
05/22/2022 18:40:10 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.04 on epoch=44
05/22/2022 18:40:13 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=44
05/22/2022 18:40:36 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.7582043948550732 on epoch=44
05/22/2022 18:40:39 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.05 on epoch=44
05/22/2022 18:40:42 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=44
05/22/2022 18:40:44 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=45
05/22/2022 18:40:47 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.05 on epoch=45
05/22/2022 18:40:49 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=45
05/22/2022 18:41:12 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.6490464969062671 on epoch=45
05/22/2022 18:41:15 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=45
05/22/2022 18:41:18 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.06 on epoch=45
05/22/2022 18:41:20 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.03 on epoch=46
05/22/2022 18:41:23 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.08 on epoch=46
05/22/2022 18:41:25 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=46
05/22/2022 18:41:48 - INFO - __main__ - Global step 2600 Train loss 0.04 Classification-F1 0.7588234211608773 on epoch=46
05/22/2022 18:41:51 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.03 on epoch=46
05/22/2022 18:41:53 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=46
05/22/2022 18:41:56 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=46
05/22/2022 18:41:59 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=47
05/22/2022 18:42:01 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.08 on epoch=47
05/22/2022 18:42:24 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.638424607243331 on epoch=47
05/22/2022 18:42:27 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=47
05/22/2022 18:42:29 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=47
05/22/2022 18:42:32 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.04 on epoch=47
05/22/2022 18:42:35 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=48
05/22/2022 18:42:37 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.09 on epoch=48
05/22/2022 18:43:01 - INFO - __main__ - Global step 2700 Train loss 0.04 Classification-F1 0.6746466325940508 on epoch=48
05/22/2022 18:43:03 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.07 on epoch=48
05/22/2022 18:43:06 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.03 on epoch=48
05/22/2022 18:43:08 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.07 on epoch=48
05/22/2022 18:43:11 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=48
05/22/2022 18:43:14 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.03 on epoch=49
05/22/2022 18:43:36 - INFO - __main__ - Global step 2750 Train loss 0.04 Classification-F1 0.6821542663144349 on epoch=49
05/22/2022 18:43:39 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.03 on epoch=49
05/22/2022 18:43:42 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.05 on epoch=49
05/22/2022 18:43:44 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=49
05/22/2022 18:43:47 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.03 on epoch=49
05/22/2022 18:43:49 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=49
05/22/2022 18:44:12 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.7589058618666789 on epoch=49
05/22/2022 18:44:15 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.03 on epoch=50
05/22/2022 18:44:18 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.06 on epoch=50
05/22/2022 18:44:20 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=50
05/22/2022 18:44:23 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=50
05/22/2022 18:44:26 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=50
05/22/2022 18:44:48 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.752011432312846 on epoch=50
05/22/2022 18:44:51 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=51
05/22/2022 18:44:53 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.08 on epoch=51
05/22/2022 18:44:56 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.05 on epoch=51
05/22/2022 18:44:58 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=51
05/22/2022 18:45:01 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=51
05/22/2022 18:45:24 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.6802920432634462 on epoch=51
05/22/2022 18:45:26 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=51
05/22/2022 18:45:29 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=52
05/22/2022 18:45:32 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.05 on epoch=52
05/22/2022 18:45:34 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=52
05/22/2022 18:45:37 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=52
05/22/2022 18:46:00 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.6949232884660507 on epoch=52
05/22/2022 18:46:03 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=52
05/22/2022 18:46:05 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=53
05/22/2022 18:46:08 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.09 on epoch=53
05/22/2022 18:46:11 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.03 on epoch=53
05/22/2022 18:46:13 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=53
05/22/2022 18:46:15 - INFO - __main__ - Start tokenizing ... 896 instances
05/22/2022 18:46:15 - INFO - __main__ - Printing 3 examples
05/22/2022 18:46:15 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/22/2022 18:46:15 - INFO - __main__ - ['Animal']
05/22/2022 18:46:15 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/22/2022 18:46:15 - INFO - __main__ - ['Animal']
05/22/2022 18:46:15 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
05/22/2022 18:46:15 - INFO - __main__ - ['Animal']
05/22/2022 18:46:15 - INFO - __main__ - Tokenizing Input ...
05/22/2022 18:46:15 - INFO - __main__ - Tokenizing Output ...
05/22/2022 18:46:16 - INFO - __main__ - Loaded 896 examples from train data
05/22/2022 18:46:16 - INFO - __main__ - Start tokenizing ... 896 instances
05/22/2022 18:46:16 - INFO - __main__ - Printing 3 examples
05/22/2022 18:46:16 - INFO - __main__ -  [dbpedia_14] Clarkesvillia is an Upper Ordovician westonocerid genus the differs from Faberoceras in having a more flattened venter and from the later Glyptodendron in having a more ventrally located siphuncle.
05/22/2022 18:46:16 - INFO - __main__ - ['Animal']
05/22/2022 18:46:16 - INFO - __main__ -  [dbpedia_14] Alaena ochracea is a butterfly in the Lycaenidae family. It is found in Malawi (from the southern part of the country to the Shire Highlands). The habitat consists of the fringes of submontane evergreen forests.
05/22/2022 18:46:16 - INFO - __main__ - ['Animal']
05/22/2022 18:46:16 - INFO - __main__ -  [dbpedia_14] Latoia is a genus of moths in the family Limacodidae.
05/22/2022 18:46:16 - INFO - __main__ - ['Animal']
05/22/2022 18:46:16 - INFO - __main__ - Tokenizing Input ...
05/22/2022 18:46:17 - INFO - __main__ - Tokenizing Output ...
05/22/2022 18:46:17 - INFO - __main__ - Loaded 896 examples from dev data
05/22/2022 18:46:35 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.6091099477199264 on epoch=53
05/22/2022 18:46:35 - INFO - __main__ - save last model!
05/22/2022 18:46:35 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/22/2022 18:46:35 - INFO - __main__ - Start tokenizing ... 3500 instances
05/22/2022 18:46:35 - INFO - __main__ - Printing 3 examples
05/22/2022 18:46:35 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/22/2022 18:46:35 - INFO - __main__ - ['Animal']
05/22/2022 18:46:35 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/22/2022 18:46:35 - INFO - __main__ - ['Animal']
05/22/2022 18:46:35 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/22/2022 18:46:35 - INFO - __main__ - ['Village']
05/22/2022 18:46:35 - INFO - __main__ - Tokenizing Input ...
05/22/2022 18:46:36 - INFO - __main__ - try to initialize prompt embeddings
05/22/2022 18:46:36 - INFO - __main__ - task name: dbpedia_14
05/22/2022 18:46:37 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 18:46:37 - INFO - __main__ - Starting training!
05/22/2022 18:46:37 - INFO - __main__ - Tokenizing Output ...
05/22/2022 18:46:41 - INFO - __main__ - Loaded 3500 examples from test data
05/22/2022 18:48:44 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down64shot/singletask-dbpedia_14/dbpedia_14_64_13_0.4_8_predictions.txt
05/22/2022 18:48:44 - INFO - __main__ - Classification-F1 on test data: 0.6110
05/22/2022 18:48:44 - INFO - __main__ - prefix=dbpedia_14_64_13, lr=0.4, bsz=8, dev_performance=0.8517061084791354, test_performance=0.6109754715868151
05/22/2022 18:48:44 - INFO - __main__ - Running ... prefix=dbpedia_14_64_13, lr=0.3, bsz=8 ...
05/22/2022 18:48:45 - INFO - __main__ - Start tokenizing ... 896 instances
05/22/2022 18:48:45 - INFO - __main__ - Printing 3 examples
05/22/2022 18:48:45 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/22/2022 18:48:45 - INFO - __main__ - ['Animal']
05/22/2022 18:48:45 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/22/2022 18:48:45 - INFO - __main__ - ['Animal']
05/22/2022 18:48:45 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
05/22/2022 18:48:45 - INFO - __main__ - ['Animal']
05/22/2022 18:48:45 - INFO - __main__ - Tokenizing Input ...
05/22/2022 18:48:45 - INFO - __main__ - Tokenizing Output ...
05/22/2022 18:48:46 - INFO - __main__ - Loaded 896 examples from train data
05/22/2022 18:48:46 - INFO - __main__ - Start tokenizing ... 896 instances
05/22/2022 18:48:46 - INFO - __main__ - Printing 3 examples
05/22/2022 18:48:46 - INFO - __main__ -  [dbpedia_14] Clarkesvillia is an Upper Ordovician westonocerid genus the differs from Faberoceras in having a more flattened venter and from the later Glyptodendron in having a more ventrally located siphuncle.
05/22/2022 18:48:46 - INFO - __main__ - ['Animal']
05/22/2022 18:48:46 - INFO - __main__ -  [dbpedia_14] Alaena ochracea is a butterfly in the Lycaenidae family. It is found in Malawi (from the southern part of the country to the Shire Highlands). The habitat consists of the fringes of submontane evergreen forests.
05/22/2022 18:48:46 - INFO - __main__ - ['Animal']
05/22/2022 18:48:46 - INFO - __main__ -  [dbpedia_14] Latoia is a genus of moths in the family Limacodidae.
05/22/2022 18:48:46 - INFO - __main__ - ['Animal']
05/22/2022 18:48:46 - INFO - __main__ - Tokenizing Input ...
05/22/2022 18:48:47 - INFO - __main__ - Tokenizing Output ...
05/22/2022 18:48:48 - INFO - __main__ - Loaded 896 examples from dev data
05/22/2022 18:49:06 - INFO - __main__ - try to initialize prompt embeddings
05/22/2022 18:49:06 - INFO - __main__ - task name: dbpedia_14
05/22/2022 18:49:07 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 18:49:07 - INFO - __main__ - Starting training!
05/22/2022 18:49:11 - INFO - __main__ - Step 10 Global step 10 Train loss 6.66 on epoch=0
05/22/2022 18:49:13 - INFO - __main__ - Step 20 Global step 20 Train loss 6.08 on epoch=0
05/22/2022 18:49:16 - INFO - __main__ - Step 30 Global step 30 Train loss 4.57 on epoch=0
05/22/2022 18:49:19 - INFO - __main__ - Step 40 Global step 40 Train loss 3.56 on epoch=0
05/22/2022 18:49:21 - INFO - __main__ - Step 50 Global step 50 Train loss 2.92 on epoch=0
05/22/2022 18:50:29 - INFO - __main__ - Global step 50 Train loss 4.76 Classification-F1 0.025102275614787003 on epoch=0
05/22/2022 18:50:29 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.025102275614787003 on epoch=0, global_step=50
05/22/2022 18:50:32 - INFO - __main__ - Step 60 Global step 60 Train loss 2.41 on epoch=1
05/22/2022 18:50:34 - INFO - __main__ - Step 70 Global step 70 Train loss 1.77 on epoch=1
05/22/2022 18:50:37 - INFO - __main__ - Step 80 Global step 80 Train loss 1.62 on epoch=1
05/22/2022 18:50:40 - INFO - __main__ - Step 90 Global step 90 Train loss 1.28 on epoch=1
05/22/2022 18:50:42 - INFO - __main__ - Step 100 Global step 100 Train loss 1.29 on epoch=1
05/22/2022 18:51:20 - INFO - __main__ - Global step 100 Train loss 1.67 Classification-F1 0.15315825414289252 on epoch=1
05/22/2022 18:51:21 - INFO - __main__ - Saving model with best Classification-F1: 0.025102275614787003 -> 0.15315825414289252 on epoch=1, global_step=100
05/22/2022 18:51:23 - INFO - __main__ - Step 110 Global step 110 Train loss 1.24 on epoch=1
05/22/2022 18:51:26 - INFO - __main__ - Step 120 Global step 120 Train loss 1.09 on epoch=2
05/22/2022 18:51:28 - INFO - __main__ - Step 130 Global step 130 Train loss 1.17 on epoch=2
05/22/2022 18:51:31 - INFO - __main__ - Step 140 Global step 140 Train loss 1.06 on epoch=2
05/22/2022 18:51:33 - INFO - __main__ - Step 150 Global step 150 Train loss 0.94 on epoch=2
05/22/2022 18:52:02 - INFO - __main__ - Global step 150 Train loss 1.10 Classification-F1 0.3559190586765215 on epoch=2
05/22/2022 18:52:02 - INFO - __main__ - Saving model with best Classification-F1: 0.15315825414289252 -> 0.3559190586765215 on epoch=2, global_step=150
05/22/2022 18:52:05 - INFO - __main__ - Step 160 Global step 160 Train loss 0.95 on epoch=2
05/22/2022 18:52:07 - INFO - __main__ - Step 170 Global step 170 Train loss 0.71 on epoch=3
05/22/2022 18:52:10 - INFO - __main__ - Step 180 Global step 180 Train loss 0.86 on epoch=3
05/22/2022 18:52:13 - INFO - __main__ - Step 190 Global step 190 Train loss 0.86 on epoch=3
05/22/2022 18:52:15 - INFO - __main__ - Step 200 Global step 200 Train loss 0.79 on epoch=3
05/22/2022 18:52:45 - INFO - __main__ - Global step 200 Train loss 0.84 Classification-F1 0.38557965112613424 on epoch=3
05/22/2022 18:52:45 - INFO - __main__ - Saving model with best Classification-F1: 0.3559190586765215 -> 0.38557965112613424 on epoch=3, global_step=200
05/22/2022 18:52:47 - INFO - __main__ - Step 210 Global step 210 Train loss 0.70 on epoch=3
05/22/2022 18:52:50 - INFO - __main__ - Step 220 Global step 220 Train loss 0.82 on epoch=3
05/22/2022 18:52:53 - INFO - __main__ - Step 230 Global step 230 Train loss 0.67 on epoch=4
05/22/2022 18:52:55 - INFO - __main__ - Step 240 Global step 240 Train loss 0.74 on epoch=4
05/22/2022 18:52:58 - INFO - __main__ - Step 250 Global step 250 Train loss 0.73 on epoch=4
05/22/2022 18:53:29 - INFO - __main__ - Global step 250 Train loss 0.73 Classification-F1 0.3716221758709549 on epoch=4
05/22/2022 18:53:31 - INFO - __main__ - Step 260 Global step 260 Train loss 0.67 on epoch=4
05/22/2022 18:53:34 - INFO - __main__ - Step 270 Global step 270 Train loss 0.62 on epoch=4
05/22/2022 18:53:37 - INFO - __main__ - Step 280 Global step 280 Train loss 0.54 on epoch=4
05/22/2022 18:53:39 - INFO - __main__ - Step 290 Global step 290 Train loss 0.67 on epoch=5
05/22/2022 18:53:42 - INFO - __main__ - Step 300 Global step 300 Train loss 0.71 on epoch=5
05/22/2022 18:54:09 - INFO - __main__ - Global step 300 Train loss 0.64 Classification-F1 0.5085255070183121 on epoch=5
05/22/2022 18:54:09 - INFO - __main__ - Saving model with best Classification-F1: 0.38557965112613424 -> 0.5085255070183121 on epoch=5, global_step=300
05/22/2022 18:54:11 - INFO - __main__ - Step 310 Global step 310 Train loss 0.63 on epoch=5
05/22/2022 18:54:14 - INFO - __main__ - Step 320 Global step 320 Train loss 0.52 on epoch=5
05/22/2022 18:54:17 - INFO - __main__ - Step 330 Global step 330 Train loss 0.56 on epoch=5
05/22/2022 18:54:19 - INFO - __main__ - Step 340 Global step 340 Train loss 0.52 on epoch=6
05/22/2022 18:54:22 - INFO - __main__ - Step 350 Global step 350 Train loss 0.56 on epoch=6
05/22/2022 18:54:53 - INFO - __main__ - Global step 350 Train loss 0.56 Classification-F1 0.41149130199151834 on epoch=6
05/22/2022 18:54:55 - INFO - __main__ - Step 360 Global step 360 Train loss 0.53 on epoch=6
05/22/2022 18:54:58 - INFO - __main__ - Step 370 Global step 370 Train loss 0.56 on epoch=6
05/22/2022 18:55:01 - INFO - __main__ - Step 380 Global step 380 Train loss 0.44 on epoch=6
05/22/2022 18:55:03 - INFO - __main__ - Step 390 Global step 390 Train loss 0.47 on epoch=6
05/22/2022 18:55:06 - INFO - __main__ - Step 400 Global step 400 Train loss 0.43 on epoch=7
05/22/2022 18:55:35 - INFO - __main__ - Global step 400 Train loss 0.49 Classification-F1 0.47336014282547506 on epoch=7
05/22/2022 18:55:37 - INFO - __main__ - Step 410 Global step 410 Train loss 0.58 on epoch=7
05/22/2022 18:55:40 - INFO - __main__ - Step 420 Global step 420 Train loss 0.49 on epoch=7
05/22/2022 18:55:43 - INFO - __main__ - Step 430 Global step 430 Train loss 0.45 on epoch=7
05/22/2022 18:55:45 - INFO - __main__ - Step 440 Global step 440 Train loss 0.50 on epoch=7
05/22/2022 18:55:48 - INFO - __main__ - Step 450 Global step 450 Train loss 0.40 on epoch=8
05/22/2022 18:56:15 - INFO - __main__ - Global step 450 Train loss 0.48 Classification-F1 0.4758697660200805 on epoch=8
05/22/2022 18:56:18 - INFO - __main__ - Step 460 Global step 460 Train loss 0.46 on epoch=8
05/22/2022 18:56:20 - INFO - __main__ - Step 470 Global step 470 Train loss 0.47 on epoch=8
05/22/2022 18:56:23 - INFO - __main__ - Step 480 Global step 480 Train loss 0.57 on epoch=8
05/22/2022 18:56:26 - INFO - __main__ - Step 490 Global step 490 Train loss 0.42 on epoch=8
05/22/2022 18:56:28 - INFO - __main__ - Step 500 Global step 500 Train loss 0.45 on epoch=8
05/22/2022 18:56:55 - INFO - __main__ - Global step 500 Train loss 0.47 Classification-F1 0.5072810622928426 on epoch=8
05/22/2022 18:56:58 - INFO - __main__ - Step 510 Global step 510 Train loss 0.37 on epoch=9
05/22/2022 18:57:00 - INFO - __main__ - Step 520 Global step 520 Train loss 0.52 on epoch=9
05/22/2022 18:57:03 - INFO - __main__ - Step 530 Global step 530 Train loss 0.39 on epoch=9
05/22/2022 18:57:05 - INFO - __main__ - Step 540 Global step 540 Train loss 0.43 on epoch=9
05/22/2022 18:57:08 - INFO - __main__ - Step 550 Global step 550 Train loss 0.41 on epoch=9
05/22/2022 18:57:33 - INFO - __main__ - Global step 550 Train loss 0.42 Classification-F1 0.5394908333219778 on epoch=9
05/22/2022 18:57:33 - INFO - __main__ - Saving model with best Classification-F1: 0.5085255070183121 -> 0.5394908333219778 on epoch=9, global_step=550
05/22/2022 18:57:36 - INFO - __main__ - Step 560 Global step 560 Train loss 0.35 on epoch=9
05/22/2022 18:57:38 - INFO - __main__ - Step 570 Global step 570 Train loss 0.41 on epoch=10
05/22/2022 18:57:41 - INFO - __main__ - Step 580 Global step 580 Train loss 0.41 on epoch=10
05/22/2022 18:57:44 - INFO - __main__ - Step 590 Global step 590 Train loss 0.38 on epoch=10
05/22/2022 18:57:46 - INFO - __main__ - Step 600 Global step 600 Train loss 0.39 on epoch=10
05/22/2022 18:58:13 - INFO - __main__ - Global step 600 Train loss 0.39 Classification-F1 0.5689610724945816 on epoch=10
05/22/2022 18:58:13 - INFO - __main__ - Saving model with best Classification-F1: 0.5394908333219778 -> 0.5689610724945816 on epoch=10, global_step=600
05/22/2022 18:58:16 - INFO - __main__ - Step 610 Global step 610 Train loss 0.46 on epoch=10
05/22/2022 18:58:18 - INFO - __main__ - Step 620 Global step 620 Train loss 0.33 on epoch=11
05/22/2022 18:58:21 - INFO - __main__ - Step 630 Global step 630 Train loss 0.41 on epoch=11
05/22/2022 18:58:23 - INFO - __main__ - Step 640 Global step 640 Train loss 0.41 on epoch=11
05/22/2022 18:58:26 - INFO - __main__ - Step 650 Global step 650 Train loss 0.42 on epoch=11
05/22/2022 18:58:52 - INFO - __main__ - Global step 650 Train loss 0.41 Classification-F1 0.4968018569322747 on epoch=11
05/22/2022 18:58:55 - INFO - __main__ - Step 660 Global step 660 Train loss 0.34 on epoch=11
05/22/2022 18:58:57 - INFO - __main__ - Step 670 Global step 670 Train loss 0.40 on epoch=11
05/22/2022 18:59:00 - INFO - __main__ - Step 680 Global step 680 Train loss 0.30 on epoch=12
05/22/2022 18:59:03 - INFO - __main__ - Step 690 Global step 690 Train loss 0.46 on epoch=12
05/22/2022 18:59:05 - INFO - __main__ - Step 700 Global step 700 Train loss 0.33 on epoch=12
05/22/2022 18:59:32 - INFO - __main__ - Global step 700 Train loss 0.37 Classification-F1 0.41583596861093625 on epoch=12
05/22/2022 18:59:34 - INFO - __main__ - Step 710 Global step 710 Train loss 0.31 on epoch=12
05/22/2022 18:59:37 - INFO - __main__ - Step 720 Global step 720 Train loss 0.33 on epoch=12
05/22/2022 18:59:39 - INFO - __main__ - Step 730 Global step 730 Train loss 0.25 on epoch=13
05/22/2022 18:59:42 - INFO - __main__ - Step 740 Global step 740 Train loss 0.30 on epoch=13
05/22/2022 18:59:44 - INFO - __main__ - Step 750 Global step 750 Train loss 0.36 on epoch=13
05/22/2022 19:00:11 - INFO - __main__ - Global step 750 Train loss 0.31 Classification-F1 0.527975482726943 on epoch=13
05/22/2022 19:00:14 - INFO - __main__ - Step 760 Global step 760 Train loss 0.36 on epoch=13
05/22/2022 19:00:16 - INFO - __main__ - Step 770 Global step 770 Train loss 0.25 on epoch=13
05/22/2022 19:00:19 - INFO - __main__ - Step 780 Global step 780 Train loss 0.33 on epoch=13
05/22/2022 19:00:21 - INFO - __main__ - Step 790 Global step 790 Train loss 0.30 on epoch=14
05/22/2022 19:00:24 - INFO - __main__ - Step 800 Global step 800 Train loss 0.27 on epoch=14
05/22/2022 19:00:51 - INFO - __main__ - Global step 800 Train loss 0.30 Classification-F1 0.5969135840859952 on epoch=14
05/22/2022 19:00:51 - INFO - __main__ - Saving model with best Classification-F1: 0.5689610724945816 -> 0.5969135840859952 on epoch=14, global_step=800
05/22/2022 19:00:54 - INFO - __main__ - Step 810 Global step 810 Train loss 0.29 on epoch=14
05/22/2022 19:00:56 - INFO - __main__ - Step 820 Global step 820 Train loss 0.33 on epoch=14
05/22/2022 19:00:59 - INFO - __main__ - Step 830 Global step 830 Train loss 0.28 on epoch=14
05/22/2022 19:01:01 - INFO - __main__ - Step 840 Global step 840 Train loss 0.23 on epoch=14
05/22/2022 19:01:04 - INFO - __main__ - Step 850 Global step 850 Train loss 0.27 on epoch=15
05/22/2022 19:01:31 - INFO - __main__ - Global step 850 Train loss 0.28 Classification-F1 0.5297498589015824 on epoch=15
05/22/2022 19:01:34 - INFO - __main__ - Step 860 Global step 860 Train loss 0.35 on epoch=15
05/22/2022 19:01:36 - INFO - __main__ - Step 870 Global step 870 Train loss 0.28 on epoch=15
05/22/2022 19:01:39 - INFO - __main__ - Step 880 Global step 880 Train loss 0.28 on epoch=15
05/22/2022 19:01:41 - INFO - __main__ - Step 890 Global step 890 Train loss 0.26 on epoch=15
05/22/2022 19:01:44 - INFO - __main__ - Step 900 Global step 900 Train loss 0.19 on epoch=16
05/22/2022 19:02:09 - INFO - __main__ - Global step 900 Train loss 0.27 Classification-F1 0.6202111366746192 on epoch=16
05/22/2022 19:02:09 - INFO - __main__ - Saving model with best Classification-F1: 0.5969135840859952 -> 0.6202111366746192 on epoch=16, global_step=900
05/22/2022 19:02:12 - INFO - __main__ - Step 910 Global step 910 Train loss 0.32 on epoch=16
05/22/2022 19:02:15 - INFO - __main__ - Step 920 Global step 920 Train loss 0.28 on epoch=16
05/22/2022 19:02:17 - INFO - __main__ - Step 930 Global step 930 Train loss 0.31 on epoch=16
05/22/2022 19:02:20 - INFO - __main__ - Step 940 Global step 940 Train loss 0.23 on epoch=16
05/22/2022 19:02:22 - INFO - __main__ - Step 950 Global step 950 Train loss 0.21 on epoch=16
05/22/2022 19:02:48 - INFO - __main__ - Global step 950 Train loss 0.27 Classification-F1 0.5470499973361256 on epoch=16
05/22/2022 19:02:50 - INFO - __main__ - Step 960 Global step 960 Train loss 0.20 on epoch=17
05/22/2022 19:02:53 - INFO - __main__ - Step 970 Global step 970 Train loss 0.36 on epoch=17
05/22/2022 19:02:55 - INFO - __main__ - Step 980 Global step 980 Train loss 0.22 on epoch=17
05/22/2022 19:02:58 - INFO - __main__ - Step 990 Global step 990 Train loss 0.25 on epoch=17
05/22/2022 19:03:00 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.19 on epoch=17
05/22/2022 19:03:25 - INFO - __main__ - Global step 1000 Train loss 0.24 Classification-F1 0.5109691888758442 on epoch=17
05/22/2022 19:03:27 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.24 on epoch=18
05/22/2022 19:03:30 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.21 on epoch=18
05/22/2022 19:03:32 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.23 on epoch=18
05/22/2022 19:03:35 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.26 on epoch=18
05/22/2022 19:03:38 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.12 on epoch=18
05/22/2022 19:04:03 - INFO - __main__ - Global step 1050 Train loss 0.21 Classification-F1 0.42141700475346766 on epoch=18
05/22/2022 19:04:06 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.21 on epoch=18
05/22/2022 19:04:09 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.20 on epoch=19
05/22/2022 19:04:11 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.27 on epoch=19
05/22/2022 19:04:14 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.26 on epoch=19
05/22/2022 19:04:16 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.21 on epoch=19
05/22/2022 19:04:41 - INFO - __main__ - Global step 1100 Train loss 0.23 Classification-F1 0.46559697227143576 on epoch=19
05/22/2022 19:04:44 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.23 on epoch=19
05/22/2022 19:04:46 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.10 on epoch=19
05/22/2022 19:04:49 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.24 on epoch=20
05/22/2022 19:04:51 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.25 on epoch=20
05/22/2022 19:04:54 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.19 on epoch=20
05/22/2022 19:05:20 - INFO - __main__ - Global step 1150 Train loss 0.20 Classification-F1 0.5848503991502028 on epoch=20
05/22/2022 19:05:22 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.16 on epoch=20
05/22/2022 19:05:25 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.10 on epoch=20
05/22/2022 19:05:27 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.12 on epoch=21
05/22/2022 19:05:30 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.24 on epoch=21
05/22/2022 19:05:32 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.24 on epoch=21
05/22/2022 19:05:58 - INFO - __main__ - Global step 1200 Train loss 0.17 Classification-F1 0.5174962981314163 on epoch=21
05/22/2022 19:06:00 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.22 on epoch=21
05/22/2022 19:06:03 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.09 on epoch=21
05/22/2022 19:06:06 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.19 on epoch=21
05/22/2022 19:06:08 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.13 on epoch=22
05/22/2022 19:06:11 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.26 on epoch=22
05/22/2022 19:06:35 - INFO - __main__ - Global step 1250 Train loss 0.18 Classification-F1 0.6042378705358719 on epoch=22
05/22/2022 19:06:38 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.19 on epoch=22
05/22/2022 19:06:40 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.18 on epoch=22
05/22/2022 19:06:43 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.13 on epoch=22
05/22/2022 19:06:45 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.16 on epoch=23
05/22/2022 19:06:48 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.24 on epoch=23
05/22/2022 19:07:11 - INFO - __main__ - Global step 1300 Train loss 0.18 Classification-F1 0.5778716951372197 on epoch=23
05/22/2022 19:07:13 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.16 on epoch=23
05/22/2022 19:07:16 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.10 on epoch=23
05/22/2022 19:07:19 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.15 on epoch=23
05/22/2022 19:07:21 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.16 on epoch=23
05/22/2022 19:07:24 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.09 on epoch=24
05/22/2022 19:07:49 - INFO - __main__ - Global step 1350 Train loss 0.13 Classification-F1 0.6424412161210995 on epoch=24
05/22/2022 19:07:49 - INFO - __main__ - Saving model with best Classification-F1: 0.6202111366746192 -> 0.6424412161210995 on epoch=24, global_step=1350
05/22/2022 19:07:51 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.15 on epoch=24
05/22/2022 19:07:54 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.17 on epoch=24
05/22/2022 19:07:56 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.18 on epoch=24
05/22/2022 19:07:59 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.12 on epoch=24
05/22/2022 19:08:01 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.11 on epoch=24
05/22/2022 19:08:25 - INFO - __main__ - Global step 1400 Train loss 0.15 Classification-F1 0.683468079138372 on epoch=24
05/22/2022 19:08:25 - INFO - __main__ - Saving model with best Classification-F1: 0.6424412161210995 -> 0.683468079138372 on epoch=24, global_step=1400
05/22/2022 19:08:28 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.14 on epoch=25
05/22/2022 19:08:30 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.31 on epoch=25
05/22/2022 19:08:33 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.17 on epoch=25
05/22/2022 19:08:35 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.16 on epoch=25
05/22/2022 19:08:38 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.15 on epoch=25
05/22/2022 19:09:01 - INFO - __main__ - Global step 1450 Train loss 0.19 Classification-F1 0.5539916218632974 on epoch=25
05/22/2022 19:09:04 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.11 on epoch=26
05/22/2022 19:09:06 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.12 on epoch=26
05/22/2022 19:09:09 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.13 on epoch=26
05/22/2022 19:09:12 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.10 on epoch=26
05/22/2022 19:09:14 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.09 on epoch=26
05/22/2022 19:09:37 - INFO - __main__ - Global step 1500 Train loss 0.11 Classification-F1 0.45927946160305244 on epoch=26
05/22/2022 19:09:40 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.07 on epoch=26
05/22/2022 19:09:42 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.12 on epoch=27
05/22/2022 19:09:45 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.15 on epoch=27
05/22/2022 19:09:47 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.08 on epoch=27
05/22/2022 19:09:50 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.13 on epoch=27
05/22/2022 19:10:14 - INFO - __main__ - Global step 1550 Train loss 0.11 Classification-F1 0.5966175771532201 on epoch=27
05/22/2022 19:10:16 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.08 on epoch=27
05/22/2022 19:10:19 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.11 on epoch=28
05/22/2022 19:10:21 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.13 on epoch=28
05/22/2022 19:10:24 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.09 on epoch=28
05/22/2022 19:10:27 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.08 on epoch=28
05/22/2022 19:10:51 - INFO - __main__ - Global step 1600 Train loss 0.10 Classification-F1 0.5279694640413949 on epoch=28
05/22/2022 19:10:53 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.08 on epoch=28
05/22/2022 19:10:56 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.10 on epoch=28
05/22/2022 19:10:59 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.09 on epoch=29
05/22/2022 19:11:01 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.14 on epoch=29
05/22/2022 19:11:04 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.10 on epoch=29
05/22/2022 19:11:28 - INFO - __main__ - Global step 1650 Train loss 0.10 Classification-F1 0.4625896138377582 on epoch=29
05/22/2022 19:11:31 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.09 on epoch=29
05/22/2022 19:11:34 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.11 on epoch=29
05/22/2022 19:11:36 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.06 on epoch=29
05/22/2022 19:11:39 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.16 on epoch=30
05/22/2022 19:11:42 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.10 on epoch=30
05/22/2022 19:12:05 - INFO - __main__ - Global step 1700 Train loss 0.11 Classification-F1 0.3916155704405233 on epoch=30
05/22/2022 19:12:08 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.05 on epoch=30
05/22/2022 19:12:11 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.09 on epoch=30
05/22/2022 19:12:13 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.13 on epoch=30
05/22/2022 19:12:16 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.08 on epoch=31
05/22/2022 19:12:18 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.17 on epoch=31
05/22/2022 19:12:41 - INFO - __main__ - Global step 1750 Train loss 0.10 Classification-F1 0.39682494045046507 on epoch=31
05/22/2022 19:12:44 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.06 on epoch=31
05/22/2022 19:12:47 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.08 on epoch=31
05/22/2022 19:12:49 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.03 on epoch=31
05/22/2022 19:12:52 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.11 on epoch=31
05/22/2022 19:12:54 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=32
05/22/2022 19:13:18 - INFO - __main__ - Global step 1800 Train loss 0.07 Classification-F1 0.5058900222201083 on epoch=32
05/22/2022 19:13:21 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.13 on epoch=32
05/22/2022 19:13:23 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.04 on epoch=32
05/22/2022 19:13:26 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=32
05/22/2022 19:13:28 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.11 on epoch=32
05/22/2022 19:13:31 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.09 on epoch=33
05/22/2022 19:13:54 - INFO - __main__ - Global step 1850 Train loss 0.08 Classification-F1 0.5329762058261199 on epoch=33
05/22/2022 19:13:57 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.18 on epoch=33
05/22/2022 19:14:00 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.11 on epoch=33
05/22/2022 19:14:02 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.07 on epoch=33
05/22/2022 19:14:05 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.04 on epoch=33
05/22/2022 19:14:07 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=33
05/22/2022 19:14:30 - INFO - __main__ - Global step 1900 Train loss 0.09 Classification-F1 0.5185963465542553 on epoch=33
05/22/2022 19:14:33 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.07 on epoch=34
05/22/2022 19:14:35 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.10 on epoch=34
05/22/2022 19:14:38 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.10 on epoch=34
05/22/2022 19:14:40 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.06 on epoch=34
05/22/2022 19:14:43 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.09 on epoch=34
05/22/2022 19:15:06 - INFO - __main__ - Global step 1950 Train loss 0.08 Classification-F1 0.4756271484076605 on epoch=34
05/22/2022 19:15:09 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.04 on epoch=34
05/22/2022 19:15:12 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.08 on epoch=35
05/22/2022 19:15:14 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.10 on epoch=35
05/22/2022 19:15:17 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=35
05/22/2022 19:15:19 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.06 on epoch=35
05/22/2022 19:15:42 - INFO - __main__ - Global step 2000 Train loss 0.06 Classification-F1 0.7146623088319646 on epoch=35
05/22/2022 19:15:42 - INFO - __main__ - Saving model with best Classification-F1: 0.683468079138372 -> 0.7146623088319646 on epoch=35, global_step=2000
05/22/2022 19:15:45 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.03 on epoch=35
05/22/2022 19:15:48 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.06 on epoch=36
05/22/2022 19:15:50 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.13 on epoch=36
05/22/2022 19:15:53 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.08 on epoch=36
05/22/2022 19:15:55 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.05 on epoch=36
05/22/2022 19:16:18 - INFO - __main__ - Global step 2050 Train loss 0.07 Classification-F1 0.6303099014328212 on epoch=36
05/22/2022 19:16:21 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.07 on epoch=36
05/22/2022 19:16:24 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.03 on epoch=36
05/22/2022 19:16:26 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=37
05/22/2022 19:16:29 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.07 on epoch=37
05/22/2022 19:16:31 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.06 on epoch=37
05/22/2022 19:16:55 - INFO - __main__ - Global step 2100 Train loss 0.05 Classification-F1 0.6383291545124002 on epoch=37
05/22/2022 19:16:57 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.06 on epoch=37
05/22/2022 19:17:00 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.05 on epoch=37
05/22/2022 19:17:02 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.06 on epoch=38
05/22/2022 19:17:05 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.08 on epoch=38
05/22/2022 19:17:08 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.06 on epoch=38
05/22/2022 19:17:30 - INFO - __main__ - Global step 2150 Train loss 0.06 Classification-F1 0.6463377886604085 on epoch=38
05/22/2022 19:17:33 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.03 on epoch=38
05/22/2022 19:17:36 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.07 on epoch=38
05/22/2022 19:17:38 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.05 on epoch=38
05/22/2022 19:17:41 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=39
05/22/2022 19:17:43 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.10 on epoch=39
05/22/2022 19:18:06 - INFO - __main__ - Global step 2200 Train loss 0.05 Classification-F1 0.5448908735119269 on epoch=39
05/22/2022 19:18:08 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.11 on epoch=39
05/22/2022 19:18:11 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.06 on epoch=39
05/22/2022 19:18:14 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.08 on epoch=39
05/22/2022 19:18:16 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.05 on epoch=39
05/22/2022 19:18:19 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.05 on epoch=40
05/22/2022 19:18:40 - INFO - __main__ - Global step 2250 Train loss 0.07 Classification-F1 0.5523194100407369 on epoch=40
05/22/2022 19:18:43 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.03 on epoch=40
05/22/2022 19:18:45 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.04 on epoch=40
05/22/2022 19:18:48 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.04 on epoch=40
05/22/2022 19:18:51 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=40
05/22/2022 19:18:53 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.04 on epoch=41
05/22/2022 19:19:15 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.507331675958513 on epoch=41
05/22/2022 19:19:18 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.11 on epoch=41
05/22/2022 19:19:20 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=41
05/22/2022 19:19:23 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.04 on epoch=41
05/22/2022 19:19:26 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.03 on epoch=41
05/22/2022 19:19:28 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.04 on epoch=41
05/22/2022 19:19:51 - INFO - __main__ - Global step 2350 Train loss 0.05 Classification-F1 0.5444965442059834 on epoch=41
05/22/2022 19:19:53 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=42
05/22/2022 19:19:56 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.05 on epoch=42
05/22/2022 19:19:58 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.06 on epoch=42
05/22/2022 19:20:01 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.04 on epoch=42
05/22/2022 19:20:04 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.08 on epoch=42
05/22/2022 19:20:27 - INFO - __main__ - Global step 2400 Train loss 0.05 Classification-F1 0.5976511625339108 on epoch=42
05/22/2022 19:20:29 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=43
05/22/2022 19:20:32 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.08 on epoch=43
05/22/2022 19:20:34 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.07 on epoch=43
05/22/2022 19:20:37 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.03 on epoch=43
05/22/2022 19:20:39 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=43
05/22/2022 19:21:02 - INFO - __main__ - Global step 2450 Train loss 0.04 Classification-F1 0.5474808571298194 on epoch=43
05/22/2022 19:21:04 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=43
05/22/2022 19:21:07 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=44
05/22/2022 19:21:10 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.07 on epoch=44
05/22/2022 19:21:12 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.10 on epoch=44
05/22/2022 19:21:15 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.03 on epoch=44
05/22/2022 19:21:37 - INFO - __main__ - Global step 2500 Train loss 0.05 Classification-F1 0.6090946646794841 on epoch=44
05/22/2022 19:21:40 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.05 on epoch=44
05/22/2022 19:21:43 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.03 on epoch=44
05/22/2022 19:21:45 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.06 on epoch=45
05/22/2022 19:21:48 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.04 on epoch=45
05/22/2022 19:21:50 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=45
05/22/2022 19:22:13 - INFO - __main__ - Global step 2550 Train loss 0.04 Classification-F1 0.5226342119653271 on epoch=45
05/22/2022 19:22:16 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.07 on epoch=45
05/22/2022 19:22:18 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=45
05/22/2022 19:22:21 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.05 on epoch=46
05/22/2022 19:22:23 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.05 on epoch=46
05/22/2022 19:22:26 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.07 on epoch=46
05/22/2022 19:22:48 - INFO - __main__ - Global step 2600 Train loss 0.05 Classification-F1 0.5397925304463359 on epoch=46
05/22/2022 19:22:50 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=46
05/22/2022 19:22:53 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=46
05/22/2022 19:22:55 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.04 on epoch=46
05/22/2022 19:22:58 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=47
05/22/2022 19:23:01 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.04 on epoch=47
05/22/2022 19:23:23 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.561910797023116 on epoch=47
05/22/2022 19:23:25 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=47
05/22/2022 19:23:28 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.03 on epoch=47
05/22/2022 19:23:31 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=47
05/22/2022 19:23:33 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=48
05/22/2022 19:23:36 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.04 on epoch=48
05/22/2022 19:23:58 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.5407615115380473 on epoch=48
05/22/2022 19:24:00 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.05 on epoch=48
05/22/2022 19:24:03 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=48
05/22/2022 19:24:05 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.04 on epoch=48
05/22/2022 19:24:08 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.03 on epoch=48
05/22/2022 19:24:10 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.03 on epoch=49
05/22/2022 19:24:33 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.5806286751129566 on epoch=49
05/22/2022 19:24:35 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.08 on epoch=49
05/22/2022 19:24:38 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.08 on epoch=49
05/22/2022 19:24:40 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.07 on epoch=49
05/22/2022 19:24:43 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.05 on epoch=49
05/22/2022 19:24:46 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=49
05/22/2022 19:25:08 - INFO - __main__ - Global step 2800 Train loss 0.06 Classification-F1 0.4873470046198288 on epoch=49
05/22/2022 19:25:11 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.08 on epoch=50
05/22/2022 19:25:13 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.12 on epoch=50
05/22/2022 19:25:16 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.03 on epoch=50
05/22/2022 19:25:19 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.03 on epoch=50
05/22/2022 19:25:21 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.03 on epoch=50
05/22/2022 19:25:44 - INFO - __main__ - Global step 2850 Train loss 0.06 Classification-F1 0.6850627071412672 on epoch=50
05/22/2022 19:25:47 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=51
05/22/2022 19:25:49 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.04 on epoch=51
05/22/2022 19:25:52 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=51
05/22/2022 19:25:54 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=51
05/22/2022 19:25:57 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=51
05/22/2022 19:26:20 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.8622717204074031 on epoch=51
05/22/2022 19:26:20 - INFO - __main__ - Saving model with best Classification-F1: 0.7146623088319646 -> 0.8622717204074031 on epoch=51, global_step=2900
05/22/2022 19:26:23 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=51
05/22/2022 19:26:25 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.03 on epoch=52
05/22/2022 19:26:28 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.09 on epoch=52
05/22/2022 19:26:31 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=52
05/22/2022 19:26:33 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.03 on epoch=52
05/22/2022 19:26:56 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.7251899138118363 on epoch=52
05/22/2022 19:26:59 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=52
05/22/2022 19:27:01 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.04 on epoch=53
05/22/2022 19:27:04 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.05 on epoch=53
05/22/2022 19:27:06 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.12 on epoch=53
05/22/2022 19:27:09 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=53
05/22/2022 19:27:10 - INFO - __main__ - Start tokenizing ... 896 instances
05/22/2022 19:27:10 - INFO - __main__ - Printing 3 examples
05/22/2022 19:27:10 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/22/2022 19:27:10 - INFO - __main__ - ['Animal']
05/22/2022 19:27:10 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/22/2022 19:27:10 - INFO - __main__ - ['Animal']
05/22/2022 19:27:10 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
05/22/2022 19:27:10 - INFO - __main__ - ['Animal']
05/22/2022 19:27:10 - INFO - __main__ - Tokenizing Input ...
05/22/2022 19:27:11 - INFO - __main__ - Tokenizing Output ...
05/22/2022 19:27:12 - INFO - __main__ - Loaded 896 examples from train data
05/22/2022 19:27:12 - INFO - __main__ - Start tokenizing ... 896 instances
05/22/2022 19:27:12 - INFO - __main__ - Printing 3 examples
05/22/2022 19:27:12 - INFO - __main__ -  [dbpedia_14] Clarkesvillia is an Upper Ordovician westonocerid genus the differs from Faberoceras in having a more flattened venter and from the later Glyptodendron in having a more ventrally located siphuncle.
05/22/2022 19:27:12 - INFO - __main__ - ['Animal']
05/22/2022 19:27:12 - INFO - __main__ -  [dbpedia_14] Alaena ochracea is a butterfly in the Lycaenidae family. It is found in Malawi (from the southern part of the country to the Shire Highlands). The habitat consists of the fringes of submontane evergreen forests.
05/22/2022 19:27:12 - INFO - __main__ - ['Animal']
05/22/2022 19:27:12 - INFO - __main__ -  [dbpedia_14] Latoia is a genus of moths in the family Limacodidae.
05/22/2022 19:27:12 - INFO - __main__ - ['Animal']
05/22/2022 19:27:12 - INFO - __main__ - Tokenizing Input ...
05/22/2022 19:27:12 - INFO - __main__ - Tokenizing Output ...
05/22/2022 19:27:13 - INFO - __main__ - Loaded 896 examples from dev data
05/22/2022 19:27:31 - INFO - __main__ - Global step 3000 Train loss 0.05 Classification-F1 0.6503838874865867 on epoch=53
05/22/2022 19:27:31 - INFO - __main__ - save last model!
05/22/2022 19:27:31 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/22/2022 19:27:31 - INFO - __main__ - Start tokenizing ... 3500 instances
05/22/2022 19:27:31 - INFO - __main__ - Printing 3 examples
05/22/2022 19:27:31 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/22/2022 19:27:31 - INFO - __main__ - ['Animal']
05/22/2022 19:27:31 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/22/2022 19:27:31 - INFO - __main__ - ['Animal']
05/22/2022 19:27:31 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/22/2022 19:27:31 - INFO - __main__ - ['Village']
05/22/2022 19:27:31 - INFO - __main__ - Tokenizing Input ...
05/22/2022 19:27:31 - INFO - __main__ - try to initialize prompt embeddings
05/22/2022 19:27:31 - INFO - __main__ - task name: dbpedia_14
05/22/2022 19:27:32 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 19:27:32 - INFO - __main__ - Starting training!
05/22/2022 19:27:33 - INFO - __main__ - Tokenizing Output ...
05/22/2022 19:27:37 - INFO - __main__ - Loaded 3500 examples from test data
05/22/2022 19:29:40 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down64shot/singletask-dbpedia_14/dbpedia_14_64_13_0.3_8_predictions.txt
05/22/2022 19:29:40 - INFO - __main__ - Classification-F1 on test data: 0.6534
05/22/2022 19:29:41 - INFO - __main__ - prefix=dbpedia_14_64_13, lr=0.3, bsz=8, dev_performance=0.8622717204074031, test_performance=0.6533529897099384
05/22/2022 19:29:41 - INFO - __main__ - Running ... prefix=dbpedia_14_64_13, lr=0.2, bsz=8 ...
05/22/2022 19:29:42 - INFO - __main__ - Start tokenizing ... 896 instances
05/22/2022 19:29:42 - INFO - __main__ - Printing 3 examples
05/22/2022 19:29:42 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/22/2022 19:29:42 - INFO - __main__ - ['Animal']
05/22/2022 19:29:42 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/22/2022 19:29:42 - INFO - __main__ - ['Animal']
05/22/2022 19:29:42 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
05/22/2022 19:29:42 - INFO - __main__ - ['Animal']
05/22/2022 19:29:42 - INFO - __main__ - Tokenizing Input ...
05/22/2022 19:29:42 - INFO - __main__ - Tokenizing Output ...
05/22/2022 19:29:43 - INFO - __main__ - Loaded 896 examples from train data
05/22/2022 19:29:43 - INFO - __main__ - Start tokenizing ... 896 instances
05/22/2022 19:29:43 - INFO - __main__ - Printing 3 examples
05/22/2022 19:29:43 - INFO - __main__ -  [dbpedia_14] Clarkesvillia is an Upper Ordovician westonocerid genus the differs from Faberoceras in having a more flattened venter and from the later Glyptodendron in having a more ventrally located siphuncle.
05/22/2022 19:29:43 - INFO - __main__ - ['Animal']
05/22/2022 19:29:43 - INFO - __main__ -  [dbpedia_14] Alaena ochracea is a butterfly in the Lycaenidae family. It is found in Malawi (from the southern part of the country to the Shire Highlands). The habitat consists of the fringes of submontane evergreen forests.
05/22/2022 19:29:43 - INFO - __main__ - ['Animal']
05/22/2022 19:29:43 - INFO - __main__ -  [dbpedia_14] Latoia is a genus of moths in the family Limacodidae.
05/22/2022 19:29:43 - INFO - __main__ - ['Animal']
05/22/2022 19:29:43 - INFO - __main__ - Tokenizing Input ...
05/22/2022 19:29:44 - INFO - __main__ - Tokenizing Output ...
05/22/2022 19:29:45 - INFO - __main__ - Loaded 896 examples from dev data
05/22/2022 19:30:00 - INFO - __main__ - try to initialize prompt embeddings
05/22/2022 19:30:00 - INFO - __main__ - task name: dbpedia_14
05/22/2022 19:30:01 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 19:30:01 - INFO - __main__ - Starting training!
05/22/2022 19:30:04 - INFO - __main__ - Step 10 Global step 10 Train loss 6.80 on epoch=0
05/22/2022 19:30:07 - INFO - __main__ - Step 20 Global step 20 Train loss 6.30 on epoch=0
05/22/2022 19:30:09 - INFO - __main__ - Step 30 Global step 30 Train loss 5.02 on epoch=0
05/22/2022 19:30:12 - INFO - __main__ - Step 40 Global step 40 Train loss 4.14 on epoch=0
05/22/2022 19:30:15 - INFO - __main__ - Step 50 Global step 50 Train loss 3.52 on epoch=0
05/22/2022 19:34:00 - INFO - __main__ - Global step 50 Train loss 5.15 Classification-F1 0.003466746465601126 on epoch=0
05/22/2022 19:34:00 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.003466746465601126 on epoch=0, global_step=50
05/22/2022 19:34:03 - INFO - __main__ - Step 60 Global step 60 Train loss 3.13 on epoch=1
05/22/2022 19:34:06 - INFO - __main__ - Step 70 Global step 70 Train loss 2.37 on epoch=1
05/22/2022 19:34:08 - INFO - __main__ - Step 80 Global step 80 Train loss 2.16 on epoch=1
05/22/2022 19:34:11 - INFO - __main__ - Step 90 Global step 90 Train loss 1.91 on epoch=1
05/22/2022 19:34:13 - INFO - __main__ - Step 100 Global step 100 Train loss 1.73 on epoch=1
05/22/2022 19:35:27 - INFO - __main__ - Global step 100 Train loss 2.26 Classification-F1 0.08283637354799023 on epoch=1
05/22/2022 19:35:27 - INFO - __main__ - Saving model with best Classification-F1: 0.003466746465601126 -> 0.08283637354799023 on epoch=1, global_step=100
05/22/2022 19:35:30 - INFO - __main__ - Step 110 Global step 110 Train loss 1.72 on epoch=1
05/22/2022 19:35:32 - INFO - __main__ - Step 120 Global step 120 Train loss 1.52 on epoch=2
05/22/2022 19:35:35 - INFO - __main__ - Step 130 Global step 130 Train loss 1.48 on epoch=2
05/22/2022 19:35:38 - INFO - __main__ - Step 140 Global step 140 Train loss 1.27 on epoch=2
05/22/2022 19:35:40 - INFO - __main__ - Step 150 Global step 150 Train loss 1.18 on epoch=2
05/22/2022 19:36:28 - INFO - __main__ - Global step 150 Train loss 1.43 Classification-F1 0.20159237140961458 on epoch=2
05/22/2022 19:36:28 - INFO - __main__ - Saving model with best Classification-F1: 0.08283637354799023 -> 0.20159237140961458 on epoch=2, global_step=150
05/22/2022 19:36:30 - INFO - __main__ - Step 160 Global step 160 Train loss 1.19 on epoch=2
05/22/2022 19:36:33 - INFO - __main__ - Step 170 Global step 170 Train loss 1.15 on epoch=3
05/22/2022 19:36:35 - INFO - __main__ - Step 180 Global step 180 Train loss 1.09 on epoch=3
05/22/2022 19:36:38 - INFO - __main__ - Step 190 Global step 190 Train loss 1.14 on epoch=3
05/22/2022 19:36:41 - INFO - __main__ - Step 200 Global step 200 Train loss 1.03 on epoch=3
05/22/2022 19:37:20 - INFO - __main__ - Global step 200 Train loss 1.12 Classification-F1 0.2608474756549533 on epoch=3
05/22/2022 19:37:20 - INFO - __main__ - Saving model with best Classification-F1: 0.20159237140961458 -> 0.2608474756549533 on epoch=3, global_step=200
05/22/2022 19:37:22 - INFO - __main__ - Step 210 Global step 210 Train loss 0.99 on epoch=3
05/22/2022 19:37:25 - INFO - __main__ - Step 220 Global step 220 Train loss 0.92 on epoch=3
05/22/2022 19:37:28 - INFO - __main__ - Step 230 Global step 230 Train loss 0.96 on epoch=4
05/22/2022 19:37:30 - INFO - __main__ - Step 240 Global step 240 Train loss 0.99 on epoch=4
05/22/2022 19:37:33 - INFO - __main__ - Step 250 Global step 250 Train loss 0.88 on epoch=4
05/22/2022 19:38:07 - INFO - __main__ - Global step 250 Train loss 0.95 Classification-F1 0.29654092009468125 on epoch=4
05/22/2022 19:38:07 - INFO - __main__ - Saving model with best Classification-F1: 0.2608474756549533 -> 0.29654092009468125 on epoch=4, global_step=250
05/22/2022 19:38:09 - INFO - __main__ - Step 260 Global step 260 Train loss 0.83 on epoch=4
05/22/2022 19:38:12 - INFO - __main__ - Step 270 Global step 270 Train loss 0.78 on epoch=4
05/22/2022 19:38:15 - INFO - __main__ - Step 280 Global step 280 Train loss 0.79 on epoch=4
05/22/2022 19:38:17 - INFO - __main__ - Step 290 Global step 290 Train loss 0.80 on epoch=5
05/22/2022 19:38:20 - INFO - __main__ - Step 300 Global step 300 Train loss 0.81 on epoch=5
05/22/2022 19:38:53 - INFO - __main__ - Global step 300 Train loss 0.80 Classification-F1 0.37377834441173424 on epoch=5
05/22/2022 19:38:53 - INFO - __main__ - Saving model with best Classification-F1: 0.29654092009468125 -> 0.37377834441173424 on epoch=5, global_step=300
05/22/2022 19:38:56 - INFO - __main__ - Step 310 Global step 310 Train loss 0.80 on epoch=5
05/22/2022 19:38:59 - INFO - __main__ - Step 320 Global step 320 Train loss 0.71 on epoch=5
05/22/2022 19:39:01 - INFO - __main__ - Step 330 Global step 330 Train loss 0.72 on epoch=5
05/22/2022 19:39:04 - INFO - __main__ - Step 340 Global step 340 Train loss 0.78 on epoch=6
05/22/2022 19:39:07 - INFO - __main__ - Step 350 Global step 350 Train loss 0.70 on epoch=6
05/22/2022 19:39:53 - INFO - __main__ - Global step 350 Train loss 0.74 Classification-F1 0.40494734201099575 on epoch=6
05/22/2022 19:39:53 - INFO - __main__ - Saving model with best Classification-F1: 0.37377834441173424 -> 0.40494734201099575 on epoch=6, global_step=350
05/22/2022 19:39:55 - INFO - __main__ - Step 360 Global step 360 Train loss 0.71 on epoch=6
05/22/2022 19:39:58 - INFO - __main__ - Step 370 Global step 370 Train loss 0.74 on epoch=6
05/22/2022 19:40:00 - INFO - __main__ - Step 380 Global step 380 Train loss 0.63 on epoch=6
05/22/2022 19:40:03 - INFO - __main__ - Step 390 Global step 390 Train loss 0.70 on epoch=6
05/22/2022 19:40:06 - INFO - __main__ - Step 400 Global step 400 Train loss 0.57 on epoch=7
05/22/2022 19:40:39 - INFO - __main__ - Global step 400 Train loss 0.67 Classification-F1 0.4219958200509947 on epoch=7
05/22/2022 19:40:39 - INFO - __main__ - Saving model with best Classification-F1: 0.40494734201099575 -> 0.4219958200509947 on epoch=7, global_step=400
05/22/2022 19:40:42 - INFO - __main__ - Step 410 Global step 410 Train loss 0.67 on epoch=7
05/22/2022 19:40:44 - INFO - __main__ - Step 420 Global step 420 Train loss 0.62 on epoch=7
05/22/2022 19:40:47 - INFO - __main__ - Step 430 Global step 430 Train loss 0.62 on epoch=7
05/22/2022 19:40:50 - INFO - __main__ - Step 440 Global step 440 Train loss 0.60 on epoch=7
05/22/2022 19:40:52 - INFO - __main__ - Step 450 Global step 450 Train loss 0.50 on epoch=8
05/22/2022 19:41:21 - INFO - __main__ - Global step 450 Train loss 0.60 Classification-F1 0.39396051508187974 on epoch=8
05/22/2022 19:41:23 - INFO - __main__ - Step 460 Global step 460 Train loss 0.59 on epoch=8
05/22/2022 19:41:26 - INFO - __main__ - Step 470 Global step 470 Train loss 0.67 on epoch=8
05/22/2022 19:41:29 - INFO - __main__ - Step 480 Global step 480 Train loss 0.61 on epoch=8
05/22/2022 19:41:31 - INFO - __main__ - Step 490 Global step 490 Train loss 0.54 on epoch=8
05/22/2022 19:41:34 - INFO - __main__ - Step 500 Global step 500 Train loss 0.59 on epoch=8
05/22/2022 19:42:10 - INFO - __main__ - Global step 500 Train loss 0.60 Classification-F1 0.3469868252157211 on epoch=8
05/22/2022 19:42:13 - INFO - __main__ - Step 510 Global step 510 Train loss 0.58 on epoch=9
05/22/2022 19:42:16 - INFO - __main__ - Step 520 Global step 520 Train loss 0.57 on epoch=9
05/22/2022 19:42:18 - INFO - __main__ - Step 530 Global step 530 Train loss 0.59 on epoch=9
05/22/2022 19:42:21 - INFO - __main__ - Step 540 Global step 540 Train loss 0.55 on epoch=9
05/22/2022 19:42:24 - INFO - __main__ - Step 550 Global step 550 Train loss 0.58 on epoch=9
05/22/2022 19:42:53 - INFO - __main__ - Global step 550 Train loss 0.57 Classification-F1 0.5049374937880029 on epoch=9
05/22/2022 19:42:53 - INFO - __main__ - Saving model with best Classification-F1: 0.4219958200509947 -> 0.5049374937880029 on epoch=9, global_step=550
05/22/2022 19:42:56 - INFO - __main__ - Step 560 Global step 560 Train loss 0.45 on epoch=9
05/22/2022 19:42:58 - INFO - __main__ - Step 570 Global step 570 Train loss 0.54 on epoch=10
05/22/2022 19:43:01 - INFO - __main__ - Step 580 Global step 580 Train loss 0.62 on epoch=10
05/22/2022 19:43:04 - INFO - __main__ - Step 590 Global step 590 Train loss 0.56 on epoch=10
05/22/2022 19:43:06 - INFO - __main__ - Step 600 Global step 600 Train loss 0.40 on epoch=10
05/22/2022 19:43:37 - INFO - __main__ - Global step 600 Train loss 0.51 Classification-F1 0.5915387502152593 on epoch=10
05/22/2022 19:43:37 - INFO - __main__ - Saving model with best Classification-F1: 0.5049374937880029 -> 0.5915387502152593 on epoch=10, global_step=600
05/22/2022 19:43:39 - INFO - __main__ - Step 610 Global step 610 Train loss 0.48 on epoch=10
05/22/2022 19:43:42 - INFO - __main__ - Step 620 Global step 620 Train loss 0.46 on epoch=11
05/22/2022 19:43:44 - INFO - __main__ - Step 630 Global step 630 Train loss 0.52 on epoch=11
05/22/2022 19:43:47 - INFO - __main__ - Step 640 Global step 640 Train loss 0.54 on epoch=11
05/22/2022 19:43:49 - INFO - __main__ - Step 650 Global step 650 Train loss 0.58 on epoch=11
05/22/2022 19:44:18 - INFO - __main__ - Global step 650 Train loss 0.52 Classification-F1 0.6502091578934136 on epoch=11
05/22/2022 19:44:18 - INFO - __main__ - Saving model with best Classification-F1: 0.5915387502152593 -> 0.6502091578934136 on epoch=11, global_step=650
05/22/2022 19:44:21 - INFO - __main__ - Step 660 Global step 660 Train loss 0.36 on epoch=11
05/22/2022 19:44:23 - INFO - __main__ - Step 670 Global step 670 Train loss 0.43 on epoch=11
05/22/2022 19:44:26 - INFO - __main__ - Step 680 Global step 680 Train loss 0.38 on epoch=12
05/22/2022 19:44:28 - INFO - __main__ - Step 690 Global step 690 Train loss 0.51 on epoch=12
05/22/2022 19:44:31 - INFO - __main__ - Step 700 Global step 700 Train loss 0.50 on epoch=12
05/22/2022 19:45:01 - INFO - __main__ - Global step 700 Train loss 0.43 Classification-F1 0.6216144017142224 on epoch=12
05/22/2022 19:45:04 - INFO - __main__ - Step 710 Global step 710 Train loss 0.40 on epoch=12
05/22/2022 19:45:06 - INFO - __main__ - Step 720 Global step 720 Train loss 0.46 on epoch=12
05/22/2022 19:45:09 - INFO - __main__ - Step 730 Global step 730 Train loss 0.37 on epoch=13
05/22/2022 19:45:11 - INFO - __main__ - Step 740 Global step 740 Train loss 0.39 on epoch=13
05/22/2022 19:45:14 - INFO - __main__ - Step 750 Global step 750 Train loss 0.55 on epoch=13
05/22/2022 19:45:44 - INFO - __main__ - Global step 750 Train loss 0.44 Classification-F1 0.674748204988783 on epoch=13
05/22/2022 19:45:44 - INFO - __main__ - Saving model with best Classification-F1: 0.6502091578934136 -> 0.674748204988783 on epoch=13, global_step=750
05/22/2022 19:45:46 - INFO - __main__ - Step 760 Global step 760 Train loss 0.44 on epoch=13
05/22/2022 19:45:49 - INFO - __main__ - Step 770 Global step 770 Train loss 0.32 on epoch=13
05/22/2022 19:45:51 - INFO - __main__ - Step 780 Global step 780 Train loss 0.42 on epoch=13
05/22/2022 19:45:54 - INFO - __main__ - Step 790 Global step 790 Train loss 0.32 on epoch=14
05/22/2022 19:45:56 - INFO - __main__ - Step 800 Global step 800 Train loss 0.36 on epoch=14
05/22/2022 19:46:27 - INFO - __main__ - Global step 800 Train loss 0.37 Classification-F1 0.6471828661706371 on epoch=14
05/22/2022 19:46:30 - INFO - __main__ - Step 810 Global step 810 Train loss 0.42 on epoch=14
05/22/2022 19:46:32 - INFO - __main__ - Step 820 Global step 820 Train loss 0.36 on epoch=14
05/22/2022 19:46:35 - INFO - __main__ - Step 830 Global step 830 Train loss 0.29 on epoch=14
05/22/2022 19:46:37 - INFO - __main__ - Step 840 Global step 840 Train loss 0.31 on epoch=14
05/22/2022 19:46:40 - INFO - __main__ - Step 850 Global step 850 Train loss 0.32 on epoch=15
05/22/2022 19:47:07 - INFO - __main__ - Global step 850 Train loss 0.34 Classification-F1 0.6163554118868814 on epoch=15
05/22/2022 19:47:10 - INFO - __main__ - Step 860 Global step 860 Train loss 0.48 on epoch=15
05/22/2022 19:47:12 - INFO - __main__ - Step 870 Global step 870 Train loss 0.36 on epoch=15
05/22/2022 19:47:15 - INFO - __main__ - Step 880 Global step 880 Train loss 0.28 on epoch=15
05/22/2022 19:47:17 - INFO - __main__ - Step 890 Global step 890 Train loss 0.44 on epoch=15
05/22/2022 19:47:20 - INFO - __main__ - Step 900 Global step 900 Train loss 0.32 on epoch=16
05/22/2022 19:47:46 - INFO - __main__ - Global step 900 Train loss 0.37 Classification-F1 0.6339281592756264 on epoch=16
05/22/2022 19:47:49 - INFO - __main__ - Step 910 Global step 910 Train loss 0.27 on epoch=16
05/22/2022 19:47:51 - INFO - __main__ - Step 920 Global step 920 Train loss 0.34 on epoch=16
05/22/2022 19:47:54 - INFO - __main__ - Step 930 Global step 930 Train loss 0.32 on epoch=16
05/22/2022 19:47:57 - INFO - __main__ - Step 940 Global step 940 Train loss 0.23 on epoch=16
05/22/2022 19:47:59 - INFO - __main__ - Step 950 Global step 950 Train loss 0.32 on epoch=16
05/22/2022 19:48:28 - INFO - __main__ - Global step 950 Train loss 0.30 Classification-F1 0.6989040698785737 on epoch=16
05/22/2022 19:48:28 - INFO - __main__ - Saving model with best Classification-F1: 0.674748204988783 -> 0.6989040698785737 on epoch=16, global_step=950
05/22/2022 19:48:30 - INFO - __main__ - Step 960 Global step 960 Train loss 0.20 on epoch=17
05/22/2022 19:48:33 - INFO - __main__ - Step 970 Global step 970 Train loss 0.33 on epoch=17
05/22/2022 19:48:35 - INFO - __main__ - Step 980 Global step 980 Train loss 0.25 on epoch=17
05/22/2022 19:48:38 - INFO - __main__ - Step 990 Global step 990 Train loss 0.32 on epoch=17
05/22/2022 19:48:40 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.24 on epoch=17
05/22/2022 19:49:07 - INFO - __main__ - Global step 1000 Train loss 0.27 Classification-F1 0.5532255950425887 on epoch=17
05/22/2022 19:49:10 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.21 on epoch=18
05/22/2022 19:49:12 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.30 on epoch=18
05/22/2022 19:49:15 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.33 on epoch=18
05/22/2022 19:49:17 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.27 on epoch=18
05/22/2022 19:49:20 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.23 on epoch=18
05/22/2022 19:49:50 - INFO - __main__ - Global step 1050 Train loss 0.27 Classification-F1 0.5757618842853945 on epoch=18
05/22/2022 19:49:52 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.29 on epoch=18
05/22/2022 19:49:55 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.24 on epoch=19
05/22/2022 19:49:57 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.24 on epoch=19
05/22/2022 19:50:00 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.25 on epoch=19
05/22/2022 19:50:02 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.19 on epoch=19
05/22/2022 19:50:28 - INFO - __main__ - Global step 1100 Train loss 0.24 Classification-F1 0.5917419422549718 on epoch=19
05/22/2022 19:50:31 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.20 on epoch=19
05/22/2022 19:50:33 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.18 on epoch=19
05/22/2022 19:50:36 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.30 on epoch=20
05/22/2022 19:50:39 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.29 on epoch=20
05/22/2022 19:50:41 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.25 on epoch=20
05/22/2022 19:51:08 - INFO - __main__ - Global step 1150 Train loss 0.25 Classification-F1 0.5695454013130086 on epoch=20
05/22/2022 19:51:10 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.21 on epoch=20
05/22/2022 19:51:13 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.22 on epoch=20
05/22/2022 19:51:16 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.17 on epoch=21
05/22/2022 19:51:18 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.16 on epoch=21
05/22/2022 19:51:21 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.21 on epoch=21
05/22/2022 19:51:48 - INFO - __main__ - Global step 1200 Train loss 0.19 Classification-F1 0.49289562743623777 on epoch=21
05/22/2022 19:51:51 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.22 on epoch=21
05/22/2022 19:51:54 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.12 on epoch=21
05/22/2022 19:51:56 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.25 on epoch=21
05/22/2022 19:51:59 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.12 on epoch=22
05/22/2022 19:52:02 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.23 on epoch=22
05/22/2022 19:52:28 - INFO - __main__ - Global step 1250 Train loss 0.19 Classification-F1 0.46919294779744775 on epoch=22
05/22/2022 19:52:30 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.12 on epoch=22
05/22/2022 19:52:33 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.16 on epoch=22
05/22/2022 19:52:36 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.16 on epoch=22
05/22/2022 19:52:38 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.18 on epoch=23
05/22/2022 19:52:41 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.18 on epoch=23
05/22/2022 19:53:12 - INFO - __main__ - Global step 1300 Train loss 0.16 Classification-F1 0.45865206324580476 on epoch=23
05/22/2022 19:53:15 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.20 on epoch=23
05/22/2022 19:53:18 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.17 on epoch=23
05/22/2022 19:53:20 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.10 on epoch=23
05/22/2022 19:53:23 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.18 on epoch=23
05/22/2022 19:53:25 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.17 on epoch=24
05/22/2022 19:53:51 - INFO - __main__ - Global step 1350 Train loss 0.16 Classification-F1 0.6354315240143853 on epoch=24
05/22/2022 19:53:54 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.20 on epoch=24
05/22/2022 19:53:57 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.16 on epoch=24
05/22/2022 19:53:59 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.14 on epoch=24
05/22/2022 19:54:02 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.15 on epoch=24
05/22/2022 19:54:04 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.11 on epoch=24
05/22/2022 19:54:32 - INFO - __main__ - Global step 1400 Train loss 0.15 Classification-F1 0.5777401990961631 on epoch=24
05/22/2022 19:54:34 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.12 on epoch=25
05/22/2022 19:54:37 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.20 on epoch=25
05/22/2022 19:54:39 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.12 on epoch=25
05/22/2022 19:54:42 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.12 on epoch=25
05/22/2022 19:54:45 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.17 on epoch=25
05/22/2022 19:55:13 - INFO - __main__ - Global step 1450 Train loss 0.15 Classification-F1 0.49265240704234764 on epoch=25
05/22/2022 19:55:16 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.09 on epoch=26
05/22/2022 19:55:18 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.14 on epoch=26
05/22/2022 19:55:21 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.20 on epoch=26
05/22/2022 19:55:24 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.10 on epoch=26
05/22/2022 19:55:26 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.12 on epoch=26
05/22/2022 19:55:52 - INFO - __main__ - Global step 1500 Train loss 0.13 Classification-F1 0.5153587002160572 on epoch=26
05/22/2022 19:55:55 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.11 on epoch=26
05/22/2022 19:55:58 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.10 on epoch=27
05/22/2022 19:56:00 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.18 on epoch=27
05/22/2022 19:56:03 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.15 on epoch=27
05/22/2022 19:56:05 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.09 on epoch=27
05/22/2022 19:56:32 - INFO - __main__ - Global step 1550 Train loss 0.13 Classification-F1 0.5809200627793124 on epoch=27
05/22/2022 19:56:35 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.14 on epoch=27
05/22/2022 19:56:37 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.11 on epoch=28
05/22/2022 19:56:40 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.15 on epoch=28
05/22/2022 19:56:43 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.14 on epoch=28
05/22/2022 19:56:45 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.10 on epoch=28
05/22/2022 19:57:11 - INFO - __main__ - Global step 1600 Train loss 0.13 Classification-F1 0.5515716281782482 on epoch=28
05/22/2022 19:57:14 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.09 on epoch=28
05/22/2022 19:57:17 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.13 on epoch=28
05/22/2022 19:57:19 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.07 on epoch=29
05/22/2022 19:57:22 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.15 on epoch=29
05/22/2022 19:57:25 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.16 on epoch=29
05/22/2022 19:57:53 - INFO - __main__ - Global step 1650 Train loss 0.12 Classification-F1 0.5546645783004589 on epoch=29
05/22/2022 19:57:55 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.13 on epoch=29
05/22/2022 19:57:58 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.07 on epoch=29
05/22/2022 19:58:01 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.09 on epoch=29
05/22/2022 19:58:03 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.16 on epoch=30
05/22/2022 19:58:06 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.11 on epoch=30
05/22/2022 19:58:33 - INFO - __main__ - Global step 1700 Train loss 0.11 Classification-F1 0.6128793800256049 on epoch=30
05/22/2022 19:58:35 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.15 on epoch=30
05/22/2022 19:58:38 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.09 on epoch=30
05/22/2022 19:58:41 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.13 on epoch=30
05/22/2022 19:58:43 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.07 on epoch=31
05/22/2022 19:58:46 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.11 on epoch=31
05/22/2022 19:59:11 - INFO - __main__ - Global step 1750 Train loss 0.11 Classification-F1 0.6056019436526648 on epoch=31
05/22/2022 19:59:14 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.13 on epoch=31
05/22/2022 19:59:17 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.10 on epoch=31
05/22/2022 19:59:19 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.04 on epoch=31
05/22/2022 19:59:22 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.08 on epoch=31
05/22/2022 19:59:24 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.09 on epoch=32
05/22/2022 19:59:50 - INFO - __main__ - Global step 1800 Train loss 0.09 Classification-F1 0.6616310781955758 on epoch=32
05/22/2022 19:59:52 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.11 on epoch=32
05/22/2022 19:59:55 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.07 on epoch=32
05/22/2022 19:59:58 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.10 on epoch=32
05/22/2022 20:00:00 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.06 on epoch=32
05/22/2022 20:00:03 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.09 on epoch=33
05/22/2022 20:00:28 - INFO - __main__ - Global step 1850 Train loss 0.09 Classification-F1 0.5667101898543577 on epoch=33
05/22/2022 20:00:30 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.12 on epoch=33
05/22/2022 20:00:33 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.16 on epoch=33
05/22/2022 20:00:35 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.07 on epoch=33
05/22/2022 20:00:38 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.04 on epoch=33
05/22/2022 20:00:41 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.12 on epoch=33
05/22/2022 20:01:07 - INFO - __main__ - Global step 1900 Train loss 0.10 Classification-F1 0.7015635812593866 on epoch=33
05/22/2022 20:01:07 - INFO - __main__ - Saving model with best Classification-F1: 0.6989040698785737 -> 0.7015635812593866 on epoch=33, global_step=1900
05/22/2022 20:01:09 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.08 on epoch=34
05/22/2022 20:01:12 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.07 on epoch=34
05/22/2022 20:01:15 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.14 on epoch=34
05/22/2022 20:01:17 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.06 on epoch=34
05/22/2022 20:01:20 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.10 on epoch=34
05/22/2022 20:01:46 - INFO - __main__ - Global step 1950 Train loss 0.09 Classification-F1 0.6323468498593074 on epoch=34
05/22/2022 20:01:49 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.06 on epoch=34
05/22/2022 20:01:52 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.09 on epoch=35
05/22/2022 20:01:54 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.09 on epoch=35
05/22/2022 20:01:57 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.07 on epoch=35
05/22/2022 20:02:00 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.06 on epoch=35
05/22/2022 20:02:25 - INFO - __main__ - Global step 2000 Train loss 0.08 Classification-F1 0.558904119898143 on epoch=35
05/22/2022 20:02:28 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.14 on epoch=35
05/22/2022 20:02:31 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.08 on epoch=36
05/22/2022 20:02:33 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.19 on epoch=36
05/22/2022 20:02:36 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.10 on epoch=36
05/22/2022 20:02:39 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.05 on epoch=36
05/22/2022 20:03:05 - INFO - __main__ - Global step 2050 Train loss 0.11 Classification-F1 0.6651645366434734 on epoch=36
05/22/2022 20:03:08 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.11 on epoch=36
05/22/2022 20:03:11 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.06 on epoch=36
05/22/2022 20:03:13 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.13 on epoch=37
05/22/2022 20:03:16 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.06 on epoch=37
05/22/2022 20:03:19 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=37
05/22/2022 20:03:47 - INFO - __main__ - Global step 2100 Train loss 0.08 Classification-F1 0.6224916996034777 on epoch=37
05/22/2022 20:03:50 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.05 on epoch=37
05/22/2022 20:03:52 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.07 on epoch=37
05/22/2022 20:03:55 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=38
05/22/2022 20:03:57 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.12 on epoch=38
05/22/2022 20:04:00 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.09 on epoch=38
05/22/2022 20:04:26 - INFO - __main__ - Global step 2150 Train loss 0.07 Classification-F1 0.5493936837533752 on epoch=38
05/22/2022 20:04:28 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.05 on epoch=38
05/22/2022 20:04:31 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.12 on epoch=38
05/22/2022 20:04:34 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.09 on epoch=38
05/22/2022 20:04:36 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.09 on epoch=39
05/22/2022 20:04:39 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.09 on epoch=39
05/22/2022 20:05:04 - INFO - __main__ - Global step 2200 Train loss 0.09 Classification-F1 0.5604047675598679 on epoch=39
05/22/2022 20:05:06 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.06 on epoch=39
05/22/2022 20:05:09 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.06 on epoch=39
05/22/2022 20:05:11 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.05 on epoch=39
05/22/2022 20:05:14 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.05 on epoch=39
05/22/2022 20:05:17 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.05 on epoch=40
05/22/2022 20:05:41 - INFO - __main__ - Global step 2250 Train loss 0.05 Classification-F1 0.4989209944337878 on epoch=40
05/22/2022 20:05:44 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.09 on epoch=40
05/22/2022 20:05:46 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.05 on epoch=40
05/22/2022 20:05:49 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.06 on epoch=40
05/22/2022 20:05:52 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.05 on epoch=40
05/22/2022 20:05:54 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.04 on epoch=41
05/22/2022 20:06:21 - INFO - __main__ - Global step 2300 Train loss 0.06 Classification-F1 0.6781877312525516 on epoch=41
05/22/2022 20:06:24 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.08 on epoch=41
05/22/2022 20:06:26 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.05 on epoch=41
05/22/2022 20:06:29 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.05 on epoch=41
05/22/2022 20:06:31 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.03 on epoch=41
05/22/2022 20:06:34 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.10 on epoch=41
05/22/2022 20:07:00 - INFO - __main__ - Global step 2350 Train loss 0.06 Classification-F1 0.6464534858217039 on epoch=41
05/22/2022 20:07:03 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.07 on epoch=42
05/22/2022 20:07:06 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.14 on epoch=42
05/22/2022 20:07:08 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.05 on epoch=42
05/22/2022 20:07:11 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=42
05/22/2022 20:07:13 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.10 on epoch=42
05/22/2022 20:07:38 - INFO - __main__ - Global step 2400 Train loss 0.08 Classification-F1 0.6291817939558041 on epoch=42
05/22/2022 20:07:40 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.05 on epoch=43
05/22/2022 20:07:43 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.11 on epoch=43
05/22/2022 20:07:46 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=43
05/22/2022 20:07:48 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.04 on epoch=43
05/22/2022 20:07:51 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.09 on epoch=43
05/22/2022 20:08:18 - INFO - __main__ - Global step 2450 Train loss 0.06 Classification-F1 0.5382630290083297 on epoch=43
05/22/2022 20:08:20 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.09 on epoch=43
05/22/2022 20:08:23 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.04 on epoch=44
05/22/2022 20:08:25 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.08 on epoch=44
05/22/2022 20:08:28 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.08 on epoch=44
05/22/2022 20:08:30 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.03 on epoch=44
05/22/2022 20:08:55 - INFO - __main__ - Global step 2500 Train loss 0.07 Classification-F1 0.5577640383795822 on epoch=44
05/22/2022 20:08:58 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.07 on epoch=44
05/22/2022 20:09:00 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.09 on epoch=44
05/22/2022 20:09:03 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.15 on epoch=45
05/22/2022 20:09:06 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.05 on epoch=45
05/22/2022 20:09:08 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.05 on epoch=45
05/22/2022 20:09:33 - INFO - __main__ - Global step 2550 Train loss 0.08 Classification-F1 0.5541643720871957 on epoch=45
05/22/2022 20:09:36 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=45
05/22/2022 20:09:39 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.06 on epoch=45
05/22/2022 20:09:41 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.07 on epoch=46
05/22/2022 20:09:44 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.08 on epoch=46
05/22/2022 20:09:46 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.05 on epoch=46
05/22/2022 20:10:12 - INFO - __main__ - Global step 2600 Train loss 0.06 Classification-F1 0.6100536672427666 on epoch=46
05/22/2022 20:10:14 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.05 on epoch=46
05/22/2022 20:10:17 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.08 on epoch=46
05/22/2022 20:10:20 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.05 on epoch=46
05/22/2022 20:10:22 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.06 on epoch=47
05/22/2022 20:10:25 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.13 on epoch=47
05/22/2022 20:10:51 - INFO - __main__ - Global step 2650 Train loss 0.07 Classification-F1 0.6726598175900895 on epoch=47
05/22/2022 20:10:53 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.06 on epoch=47
05/22/2022 20:10:56 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.03 on epoch=47
05/22/2022 20:10:58 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.03 on epoch=47
05/22/2022 20:11:01 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=48
05/22/2022 20:11:04 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.08 on epoch=48
05/22/2022 20:11:28 - INFO - __main__ - Global step 2700 Train loss 0.04 Classification-F1 0.6074417235862369 on epoch=48
05/22/2022 20:11:31 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.06 on epoch=48
05/22/2022 20:11:34 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.03 on epoch=48
05/22/2022 20:11:36 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.05 on epoch=48
05/22/2022 20:11:39 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.06 on epoch=48
05/22/2022 20:11:41 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.03 on epoch=49
05/22/2022 20:12:06 - INFO - __main__ - Global step 2750 Train loss 0.04 Classification-F1 0.7140668251677933 on epoch=49
05/22/2022 20:12:06 - INFO - __main__ - Saving model with best Classification-F1: 0.7015635812593866 -> 0.7140668251677933 on epoch=49, global_step=2750
05/22/2022 20:12:09 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.06 on epoch=49
05/22/2022 20:12:11 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.05 on epoch=49
05/22/2022 20:12:14 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.10 on epoch=49
05/22/2022 20:12:17 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.06 on epoch=49
05/22/2022 20:12:19 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.04 on epoch=49
05/22/2022 20:12:43 - INFO - __main__ - Global step 2800 Train loss 0.06 Classification-F1 0.6106401156037824 on epoch=49
05/22/2022 20:12:45 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.08 on epoch=50
05/22/2022 20:12:48 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.03 on epoch=50
05/22/2022 20:12:51 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.04 on epoch=50
05/22/2022 20:12:53 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.03 on epoch=50
05/22/2022 20:12:56 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.05 on epoch=50
05/22/2022 20:13:18 - INFO - __main__ - Global step 2850 Train loss 0.05 Classification-F1 0.6252285692152325 on epoch=50
05/22/2022 20:13:21 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.08 on epoch=51
05/22/2022 20:13:24 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.10 on epoch=51
05/22/2022 20:13:26 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.06 on epoch=51
05/22/2022 20:13:29 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.03 on epoch=51
05/22/2022 20:13:32 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.05 on epoch=51
05/22/2022 20:13:55 - INFO - __main__ - Global step 2900 Train loss 0.06 Classification-F1 0.49923068971120443 on epoch=51
05/22/2022 20:13:58 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.08 on epoch=51
05/22/2022 20:14:01 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.05 on epoch=52
05/22/2022 20:14:03 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.10 on epoch=52
05/22/2022 20:14:06 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.07 on epoch=52
05/22/2022 20:14:09 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.05 on epoch=52
05/22/2022 20:14:32 - INFO - __main__ - Global step 2950 Train loss 0.07 Classification-F1 0.5241713352103725 on epoch=52
05/22/2022 20:14:35 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.05 on epoch=52
05/22/2022 20:14:38 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=53
05/22/2022 20:14:40 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.11 on epoch=53
05/22/2022 20:14:43 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.08 on epoch=53
05/22/2022 20:14:45 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.05 on epoch=53
05/22/2022 20:14:47 - INFO - __main__ - Start tokenizing ... 896 instances
05/22/2022 20:14:47 - INFO - __main__ - Printing 3 examples
05/22/2022 20:14:47 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/22/2022 20:14:47 - INFO - __main__ - ['Plant']
05/22/2022 20:14:47 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/22/2022 20:14:47 - INFO - __main__ - ['Plant']
05/22/2022 20:14:47 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/22/2022 20:14:47 - INFO - __main__ - ['Plant']
05/22/2022 20:14:47 - INFO - __main__ - Tokenizing Input ...
05/22/2022 20:14:47 - INFO - __main__ - Tokenizing Output ...
05/22/2022 20:14:48 - INFO - __main__ - Loaded 896 examples from train data
05/22/2022 20:14:48 - INFO - __main__ - Start tokenizing ... 896 instances
05/22/2022 20:14:48 - INFO - __main__ - Printing 3 examples
05/22/2022 20:14:48 - INFO - __main__ -  [dbpedia_14] Hardwickia is a genus of flowering plants in the legume family Fabaceae. It belongs to the sub family Caesalpinioideae.
05/22/2022 20:14:48 - INFO - __main__ - ['Plant']
05/22/2022 20:14:48 - INFO - __main__ -  [dbpedia_14] Eurybia eryngiifolia commonly known as the Thistleleaf Aster or Coyote-thistle Aster is an herbaceous perennial in the composite family. It is native to the eastern United States where it is only present along the Florida panhandle and the nearby areas of southern Alabama and Georgia.
05/22/2022 20:14:48 - INFO - __main__ - ['Plant']
05/22/2022 20:14:48 - INFO - __main__ -  [dbpedia_14] Petraeovitex is a genus of eight climbing shrubs species known to science of the Mint family Lamiaceae (formerly placed within Verbenaceae).Collectively they grow naturally in Borneo Peninsular Malaysia Sumatra the Philippines the Moluccas New Guinea Bismarck Archipelago the Solomon Islands and Cape York Peninsula Australia.
05/22/2022 20:14:48 - INFO - __main__ - ['Plant']
05/22/2022 20:14:48 - INFO - __main__ - Tokenizing Input ...
05/22/2022 20:14:49 - INFO - __main__ - Tokenizing Output ...
05/22/2022 20:14:50 - INFO - __main__ - Loaded 896 examples from dev data
05/22/2022 20:15:06 - INFO - __main__ - try to initialize prompt embeddings
05/22/2022 20:15:06 - INFO - __main__ - task name: dbpedia_14
05/22/2022 20:15:07 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 20:15:07 - INFO - __main__ - Starting training!
05/22/2022 20:15:09 - INFO - __main__ - Global step 3000 Train loss 0.06 Classification-F1 0.6889478805277977 on epoch=53
05/22/2022 20:15:09 - INFO - __main__ - save last model!
05/22/2022 20:15:09 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/22/2022 20:15:09 - INFO - __main__ - Start tokenizing ... 3500 instances
05/22/2022 20:15:09 - INFO - __main__ - Printing 3 examples
05/22/2022 20:15:09 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/22/2022 20:15:09 - INFO - __main__ - ['Animal']
05/22/2022 20:15:09 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/22/2022 20:15:09 - INFO - __main__ - ['Animal']
05/22/2022 20:15:09 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/22/2022 20:15:09 - INFO - __main__ - ['Village']
05/22/2022 20:15:09 - INFO - __main__ - Tokenizing Input ...
05/22/2022 20:15:11 - INFO - __main__ - Tokenizing Output ...
05/22/2022 20:15:14 - INFO - __main__ - Loaded 3500 examples from test data
05/22/2022 20:17:15 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down64shot/singletask-dbpedia_14/dbpedia_14_64_13_0.2_8_predictions.txt
05/22/2022 20:17:15 - INFO - __main__ - Classification-F1 on test data: 0.5453
05/22/2022 20:17:16 - INFO - __main__ - prefix=dbpedia_14_64_13, lr=0.2, bsz=8, dev_performance=0.7140668251677933, test_performance=0.5452558157977221
05/22/2022 20:17:16 - INFO - __main__ - Running ... prefix=dbpedia_14_64_21, lr=0.5, bsz=8 ...
05/22/2022 20:17:17 - INFO - __main__ - Start tokenizing ... 896 instances
05/22/2022 20:17:17 - INFO - __main__ - Printing 3 examples
05/22/2022 20:17:17 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/22/2022 20:17:17 - INFO - __main__ - ['Plant']
05/22/2022 20:17:17 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/22/2022 20:17:17 - INFO - __main__ - ['Plant']
05/22/2022 20:17:17 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/22/2022 20:17:17 - INFO - __main__ - ['Plant']
05/22/2022 20:17:17 - INFO - __main__ - Tokenizing Input ...
05/22/2022 20:17:17 - INFO - __main__ - Tokenizing Output ...
05/22/2022 20:17:18 - INFO - __main__ - Loaded 896 examples from train data
05/22/2022 20:17:18 - INFO - __main__ - Start tokenizing ... 896 instances
05/22/2022 20:17:18 - INFO - __main__ - Printing 3 examples
05/22/2022 20:17:18 - INFO - __main__ -  [dbpedia_14] Hardwickia is a genus of flowering plants in the legume family Fabaceae. It belongs to the sub family Caesalpinioideae.
05/22/2022 20:17:18 - INFO - __main__ - ['Plant']
05/22/2022 20:17:18 - INFO - __main__ -  [dbpedia_14] Eurybia eryngiifolia commonly known as the Thistleleaf Aster or Coyote-thistle Aster is an herbaceous perennial in the composite family. It is native to the eastern United States where it is only present along the Florida panhandle and the nearby areas of southern Alabama and Georgia.
05/22/2022 20:17:18 - INFO - __main__ - ['Plant']
05/22/2022 20:17:18 - INFO - __main__ -  [dbpedia_14] Petraeovitex is a genus of eight climbing shrubs species known to science of the Mint family Lamiaceae (formerly placed within Verbenaceae).Collectively they grow naturally in Borneo Peninsular Malaysia Sumatra the Philippines the Moluccas New Guinea Bismarck Archipelago the Solomon Islands and Cape York Peninsula Australia.
05/22/2022 20:17:18 - INFO - __main__ - ['Plant']
05/22/2022 20:17:18 - INFO - __main__ - Tokenizing Input ...
05/22/2022 20:17:18 - INFO - __main__ - Tokenizing Output ...
05/22/2022 20:17:19 - INFO - __main__ - Loaded 896 examples from dev data
05/22/2022 20:17:34 - INFO - __main__ - try to initialize prompt embeddings
05/22/2022 20:17:34 - INFO - __main__ - task name: dbpedia_14
05/22/2022 20:17:35 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 20:17:35 - INFO - __main__ - Starting training!
05/22/2022 20:17:38 - INFO - __main__ - Step 10 Global step 10 Train loss 6.54 on epoch=0
05/22/2022 20:17:41 - INFO - __main__ - Step 20 Global step 20 Train loss 4.83 on epoch=0
05/22/2022 20:17:43 - INFO - __main__ - Step 30 Global step 30 Train loss 3.07 on epoch=0
05/22/2022 20:17:46 - INFO - __main__ - Step 40 Global step 40 Train loss 2.24 on epoch=0
05/22/2022 20:17:48 - INFO - __main__ - Step 50 Global step 50 Train loss 1.93 on epoch=0
05/22/2022 20:18:12 - INFO - __main__ - Global step 50 Train loss 3.72 Classification-F1 0.20219928846246457 on epoch=0
05/22/2022 20:18:12 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.20219928846246457 on epoch=0, global_step=50
05/22/2022 20:18:14 - INFO - __main__ - Step 60 Global step 60 Train loss 1.39 on epoch=1
05/22/2022 20:18:17 - INFO - __main__ - Step 70 Global step 70 Train loss 1.26 on epoch=1
05/22/2022 20:18:19 - INFO - __main__ - Step 80 Global step 80 Train loss 1.09 on epoch=1
05/22/2022 20:18:22 - INFO - __main__ - Step 90 Global step 90 Train loss 1.11 on epoch=1
05/22/2022 20:18:24 - INFO - __main__ - Step 100 Global step 100 Train loss 1.01 on epoch=1
05/22/2022 20:18:49 - INFO - __main__ - Global step 100 Train loss 1.17 Classification-F1 0.35366174871608913 on epoch=1
05/22/2022 20:18:49 - INFO - __main__ - Saving model with best Classification-F1: 0.20219928846246457 -> 0.35366174871608913 on epoch=1, global_step=100
05/22/2022 20:18:52 - INFO - __main__ - Step 110 Global step 110 Train loss 0.99 on epoch=1
05/22/2022 20:18:55 - INFO - __main__ - Step 120 Global step 120 Train loss 0.72 on epoch=2
05/22/2022 20:18:57 - INFO - __main__ - Step 130 Global step 130 Train loss 0.89 on epoch=2
05/22/2022 20:19:00 - INFO - __main__ - Step 140 Global step 140 Train loss 0.83 on epoch=2
05/22/2022 20:19:03 - INFO - __main__ - Step 150 Global step 150 Train loss 0.70 on epoch=2
05/22/2022 20:19:31 - INFO - __main__ - Global step 150 Train loss 0.83 Classification-F1 0.28749167075158144 on epoch=2
05/22/2022 20:19:34 - INFO - __main__ - Step 160 Global step 160 Train loss 0.78 on epoch=2
05/22/2022 20:19:37 - INFO - __main__ - Step 170 Global step 170 Train loss 0.60 on epoch=3
05/22/2022 20:19:39 - INFO - __main__ - Step 180 Global step 180 Train loss 0.71 on epoch=3
05/22/2022 20:19:42 - INFO - __main__ - Step 190 Global step 190 Train loss 0.59 on epoch=3
05/22/2022 20:19:45 - INFO - __main__ - Step 200 Global step 200 Train loss 0.60 on epoch=3
05/22/2022 20:20:14 - INFO - __main__ - Global step 200 Train loss 0.65 Classification-F1 0.39063011777218815 on epoch=3
05/22/2022 20:20:14 - INFO - __main__ - Saving model with best Classification-F1: 0.35366174871608913 -> 0.39063011777218815 on epoch=3, global_step=200
05/22/2022 20:20:16 - INFO - __main__ - Step 210 Global step 210 Train loss 0.50 on epoch=3
05/22/2022 20:20:19 - INFO - __main__ - Step 220 Global step 220 Train loss 0.57 on epoch=3
05/22/2022 20:20:22 - INFO - __main__ - Step 230 Global step 230 Train loss 0.46 on epoch=4
05/22/2022 20:20:24 - INFO - __main__ - Step 240 Global step 240 Train loss 0.42 on epoch=4
05/22/2022 20:20:27 - INFO - __main__ - Step 250 Global step 250 Train loss 0.51 on epoch=4
05/22/2022 20:20:53 - INFO - __main__ - Global step 250 Train loss 0.49 Classification-F1 0.527727178093229 on epoch=4
05/22/2022 20:20:53 - INFO - __main__ - Saving model with best Classification-F1: 0.39063011777218815 -> 0.527727178093229 on epoch=4, global_step=250
05/22/2022 20:20:56 - INFO - __main__ - Step 260 Global step 260 Train loss 0.38 on epoch=4
05/22/2022 20:20:58 - INFO - __main__ - Step 270 Global step 270 Train loss 0.37 on epoch=4
05/22/2022 20:21:01 - INFO - __main__ - Step 280 Global step 280 Train loss 0.44 on epoch=4
05/22/2022 20:21:04 - INFO - __main__ - Step 290 Global step 290 Train loss 0.34 on epoch=5
05/22/2022 20:21:06 - INFO - __main__ - Step 300 Global step 300 Train loss 0.34 on epoch=5
05/22/2022 20:21:31 - INFO - __main__ - Global step 300 Train loss 0.37 Classification-F1 0.5618897864559872 on epoch=5
05/22/2022 20:21:31 - INFO - __main__ - Saving model with best Classification-F1: 0.527727178093229 -> 0.5618897864559872 on epoch=5, global_step=300
05/22/2022 20:21:34 - INFO - __main__ - Step 310 Global step 310 Train loss 0.34 on epoch=5
05/22/2022 20:21:37 - INFO - __main__ - Step 320 Global step 320 Train loss 0.35 on epoch=5
05/22/2022 20:21:39 - INFO - __main__ - Step 330 Global step 330 Train loss 0.40 on epoch=5
05/22/2022 20:21:42 - INFO - __main__ - Step 340 Global step 340 Train loss 0.34 on epoch=6
05/22/2022 20:21:44 - INFO - __main__ - Step 350 Global step 350 Train loss 0.29 on epoch=6
05/22/2022 20:22:11 - INFO - __main__ - Global step 350 Train loss 0.34 Classification-F1 0.4899108402815526 on epoch=6
05/22/2022 20:22:14 - INFO - __main__ - Step 360 Global step 360 Train loss 0.42 on epoch=6
05/22/2022 20:22:16 - INFO - __main__ - Step 370 Global step 370 Train loss 0.41 on epoch=6
05/22/2022 20:22:19 - INFO - __main__ - Step 380 Global step 380 Train loss 0.35 on epoch=6
05/22/2022 20:22:21 - INFO - __main__ - Step 390 Global step 390 Train loss 0.34 on epoch=6
05/22/2022 20:22:24 - INFO - __main__ - Step 400 Global step 400 Train loss 0.28 on epoch=7
05/22/2022 20:22:49 - INFO - __main__ - Global step 400 Train loss 0.36 Classification-F1 0.4682903148170238 on epoch=7
05/22/2022 20:22:52 - INFO - __main__ - Step 410 Global step 410 Train loss 0.27 on epoch=7
05/22/2022 20:22:55 - INFO - __main__ - Step 420 Global step 420 Train loss 0.22 on epoch=7
05/22/2022 20:22:57 - INFO - __main__ - Step 430 Global step 430 Train loss 0.23 on epoch=7
05/22/2022 20:23:00 - INFO - __main__ - Step 440 Global step 440 Train loss 0.25 on epoch=7
05/22/2022 20:23:03 - INFO - __main__ - Step 450 Global step 450 Train loss 0.22 on epoch=8
05/22/2022 20:23:30 - INFO - __main__ - Global step 450 Train loss 0.24 Classification-F1 0.5474696730952502 on epoch=8
05/22/2022 20:23:32 - INFO - __main__ - Step 460 Global step 460 Train loss 0.24 on epoch=8
05/22/2022 20:23:35 - INFO - __main__ - Step 470 Global step 470 Train loss 0.24 on epoch=8
05/22/2022 20:23:37 - INFO - __main__ - Step 480 Global step 480 Train loss 0.32 on epoch=8
05/22/2022 20:23:40 - INFO - __main__ - Step 490 Global step 490 Train loss 0.38 on epoch=8
05/22/2022 20:23:42 - INFO - __main__ - Step 500 Global step 500 Train loss 0.32 on epoch=8
05/22/2022 20:24:08 - INFO - __main__ - Global step 500 Train loss 0.30 Classification-F1 0.4523645568218465 on epoch=8
05/22/2022 20:24:11 - INFO - __main__ - Step 510 Global step 510 Train loss 0.23 on epoch=9
05/22/2022 20:24:13 - INFO - __main__ - Step 520 Global step 520 Train loss 0.20 on epoch=9
05/22/2022 20:24:16 - INFO - __main__ - Step 530 Global step 530 Train loss 0.20 on epoch=9
05/22/2022 20:24:19 - INFO - __main__ - Step 540 Global step 540 Train loss 0.24 on epoch=9
05/22/2022 20:24:21 - INFO - __main__ - Step 550 Global step 550 Train loss 0.27 on epoch=9
05/22/2022 20:24:47 - INFO - __main__ - Global step 550 Train loss 0.23 Classification-F1 0.4297744759998852 on epoch=9
05/22/2022 20:24:50 - INFO - __main__ - Step 560 Global step 560 Train loss 0.24 on epoch=9
05/22/2022 20:24:52 - INFO - __main__ - Step 570 Global step 570 Train loss 0.20 on epoch=10
05/22/2022 20:24:55 - INFO - __main__ - Step 580 Global step 580 Train loss 0.16 on epoch=10
05/22/2022 20:24:57 - INFO - __main__ - Step 590 Global step 590 Train loss 0.21 on epoch=10
05/22/2022 20:25:00 - INFO - __main__ - Step 600 Global step 600 Train loss 0.14 on epoch=10
05/22/2022 20:25:24 - INFO - __main__ - Global step 600 Train loss 0.19 Classification-F1 0.7227026007627905 on epoch=10
05/22/2022 20:25:24 - INFO - __main__ - Saving model with best Classification-F1: 0.5618897864559872 -> 0.7227026007627905 on epoch=10, global_step=600
05/22/2022 20:25:27 - INFO - __main__ - Step 610 Global step 610 Train loss 0.28 on epoch=10
05/22/2022 20:25:29 - INFO - __main__ - Step 620 Global step 620 Train loss 0.19 on epoch=11
05/22/2022 20:25:32 - INFO - __main__ - Step 630 Global step 630 Train loss 0.10 on epoch=11
05/22/2022 20:25:34 - INFO - __main__ - Step 640 Global step 640 Train loss 0.15 on epoch=11
05/22/2022 20:25:37 - INFO - __main__ - Step 650 Global step 650 Train loss 0.15 on epoch=11
05/22/2022 20:26:01 - INFO - __main__ - Global step 650 Train loss 0.17 Classification-F1 0.590364053009024 on epoch=11
05/22/2022 20:26:03 - INFO - __main__ - Step 660 Global step 660 Train loss 0.15 on epoch=11
05/22/2022 20:26:06 - INFO - __main__ - Step 670 Global step 670 Train loss 0.16 on epoch=11
05/22/2022 20:26:08 - INFO - __main__ - Step 680 Global step 680 Train loss 0.15 on epoch=12
05/22/2022 20:26:11 - INFO - __main__ - Step 690 Global step 690 Train loss 0.13 on epoch=12
05/22/2022 20:26:14 - INFO - __main__ - Step 700 Global step 700 Train loss 0.19 on epoch=12
05/22/2022 20:26:39 - INFO - __main__ - Global step 700 Train loss 0.16 Classification-F1 0.6691443496893672 on epoch=12
05/22/2022 20:26:42 - INFO - __main__ - Step 710 Global step 710 Train loss 0.16 on epoch=12
05/22/2022 20:26:44 - INFO - __main__ - Step 720 Global step 720 Train loss 0.20 on epoch=12
05/22/2022 20:26:47 - INFO - __main__ - Step 730 Global step 730 Train loss 0.12 on epoch=13
05/22/2022 20:26:49 - INFO - __main__ - Step 740 Global step 740 Train loss 0.18 on epoch=13
05/22/2022 20:26:52 - INFO - __main__ - Step 750 Global step 750 Train loss 0.14 on epoch=13
05/22/2022 20:27:17 - INFO - __main__ - Global step 750 Train loss 0.16 Classification-F1 0.5530111935083277 on epoch=13
05/22/2022 20:27:19 - INFO - __main__ - Step 760 Global step 760 Train loss 0.16 on epoch=13
05/22/2022 20:27:22 - INFO - __main__ - Step 770 Global step 770 Train loss 0.11 on epoch=13
05/22/2022 20:27:25 - INFO - __main__ - Step 780 Global step 780 Train loss 0.17 on epoch=13
05/22/2022 20:27:27 - INFO - __main__ - Step 790 Global step 790 Train loss 0.10 on epoch=14
05/22/2022 20:27:30 - INFO - __main__ - Step 800 Global step 800 Train loss 0.11 on epoch=14
05/22/2022 20:27:56 - INFO - __main__ - Global step 800 Train loss 0.13 Classification-F1 0.6853988476749554 on epoch=14
05/22/2022 20:27:58 - INFO - __main__ - Step 810 Global step 810 Train loss 0.17 on epoch=14
05/22/2022 20:28:01 - INFO - __main__ - Step 820 Global step 820 Train loss 0.11 on epoch=14
05/22/2022 20:28:03 - INFO - __main__ - Step 830 Global step 830 Train loss 0.08 on epoch=14
05/22/2022 20:28:06 - INFO - __main__ - Step 840 Global step 840 Train loss 0.13 on epoch=14
05/22/2022 20:28:08 - INFO - __main__ - Step 850 Global step 850 Train loss 0.09 on epoch=15
05/22/2022 20:28:33 - INFO - __main__ - Global step 850 Train loss 0.12 Classification-F1 0.5964122029316314 on epoch=15
05/22/2022 20:28:36 - INFO - __main__ - Step 860 Global step 860 Train loss 0.07 on epoch=15
05/22/2022 20:28:39 - INFO - __main__ - Step 870 Global step 870 Train loss 0.12 on epoch=15
05/22/2022 20:28:41 - INFO - __main__ - Step 880 Global step 880 Train loss 0.11 on epoch=15
05/22/2022 20:28:44 - INFO - __main__ - Step 890 Global step 890 Train loss 0.14 on epoch=15
05/22/2022 20:28:46 - INFO - __main__ - Step 900 Global step 900 Train loss 0.06 on epoch=16
05/22/2022 20:29:09 - INFO - __main__ - Global step 900 Train loss 0.10 Classification-F1 0.5578184982624893 on epoch=16
05/22/2022 20:29:12 - INFO - __main__ - Step 910 Global step 910 Train loss 0.08 on epoch=16
05/22/2022 20:29:15 - INFO - __main__ - Step 920 Global step 920 Train loss 0.08 on epoch=16
05/22/2022 20:29:17 - INFO - __main__ - Step 930 Global step 930 Train loss 0.12 on epoch=16
05/22/2022 20:29:20 - INFO - __main__ - Step 940 Global step 940 Train loss 0.10 on epoch=16
05/22/2022 20:29:22 - INFO - __main__ - Step 950 Global step 950 Train loss 0.09 on epoch=16
05/22/2022 20:29:47 - INFO - __main__ - Global step 950 Train loss 0.09 Classification-F1 0.6435185706383983 on epoch=16
05/22/2022 20:29:50 - INFO - __main__ - Step 960 Global step 960 Train loss 0.08 on epoch=17
05/22/2022 20:29:52 - INFO - __main__ - Step 970 Global step 970 Train loss 0.07 on epoch=17
05/22/2022 20:29:55 - INFO - __main__ - Step 980 Global step 980 Train loss 0.05 on epoch=17
05/22/2022 20:29:57 - INFO - __main__ - Step 990 Global step 990 Train loss 0.02 on epoch=17
05/22/2022 20:30:00 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.04 on epoch=17
05/22/2022 20:30:24 - INFO - __main__ - Global step 1000 Train loss 0.05 Classification-F1 0.8191638304881422 on epoch=17
05/22/2022 20:30:24 - INFO - __main__ - Saving model with best Classification-F1: 0.7227026007627905 -> 0.8191638304881422 on epoch=17, global_step=1000
05/22/2022 20:30:27 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.15 on epoch=18
05/22/2022 20:30:29 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.06 on epoch=18
05/22/2022 20:30:32 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.12 on epoch=18
05/22/2022 20:30:34 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.10 on epoch=18
05/22/2022 20:30:37 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.04 on epoch=18
05/22/2022 20:31:02 - INFO - __main__ - Global step 1050 Train loss 0.10 Classification-F1 0.7394561203024914 on epoch=18
05/22/2022 20:31:05 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.14 on epoch=18
05/22/2022 20:31:07 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.07 on epoch=19
05/22/2022 20:31:10 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.10 on epoch=19
05/22/2022 20:31:12 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.07 on epoch=19
05/22/2022 20:31:15 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.07 on epoch=19
05/22/2022 20:31:40 - INFO - __main__ - Global step 1100 Train loss 0.09 Classification-F1 0.6748145947217772 on epoch=19
05/22/2022 20:31:43 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.04 on epoch=19
05/22/2022 20:31:45 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.11 on epoch=19
05/22/2022 20:31:48 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.07 on epoch=20
05/22/2022 20:31:50 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.08 on epoch=20
05/22/2022 20:31:53 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.09 on epoch=20
05/22/2022 20:32:19 - INFO - __main__ - Global step 1150 Train loss 0.08 Classification-F1 0.7543898324017226 on epoch=20
05/22/2022 20:32:21 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.06 on epoch=20
05/22/2022 20:32:24 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.05 on epoch=20
05/22/2022 20:32:26 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.08 on epoch=21
05/22/2022 20:32:29 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.03 on epoch=21
05/22/2022 20:32:31 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.07 on epoch=21
05/22/2022 20:32:57 - INFO - __main__ - Global step 1200 Train loss 0.06 Classification-F1 0.8617586160196545 on epoch=21
05/22/2022 20:32:57 - INFO - __main__ - Saving model with best Classification-F1: 0.8191638304881422 -> 0.8617586160196545 on epoch=21, global_step=1200
05/22/2022 20:33:00 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.04 on epoch=21
05/22/2022 20:33:02 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.03 on epoch=21
05/22/2022 20:33:05 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.08 on epoch=21
05/22/2022 20:33:07 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.05 on epoch=22
05/22/2022 20:33:10 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.04 on epoch=22
05/22/2022 20:33:34 - INFO - __main__ - Global step 1250 Train loss 0.05 Classification-F1 0.6639315878026867 on epoch=22
05/22/2022 20:33:37 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.04 on epoch=22
05/22/2022 20:33:39 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.03 on epoch=22
05/22/2022 20:33:42 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.06 on epoch=22
05/22/2022 20:33:44 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.04 on epoch=23
05/22/2022 20:33:47 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.05 on epoch=23
05/22/2022 20:34:12 - INFO - __main__ - Global step 1300 Train loss 0.04 Classification-F1 0.7637427497488938 on epoch=23
05/22/2022 20:34:14 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.04 on epoch=23
05/22/2022 20:34:17 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.03 on epoch=23
05/22/2022 20:34:19 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.08 on epoch=23
05/22/2022 20:34:22 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.04 on epoch=23
05/22/2022 20:34:24 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.09 on epoch=24
05/22/2022 20:34:50 - INFO - __main__ - Global step 1350 Train loss 0.06 Classification-F1 0.7222438894282399 on epoch=24
05/22/2022 20:34:52 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.10 on epoch=24
05/22/2022 20:34:55 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.04 on epoch=24
05/22/2022 20:34:57 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.05 on epoch=24
05/22/2022 20:35:00 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.03 on epoch=24
05/22/2022 20:35:02 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.13 on epoch=24
05/22/2022 20:35:27 - INFO - __main__ - Global step 1400 Train loss 0.07 Classification-F1 0.7994124572377653 on epoch=24
05/22/2022 20:35:30 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.03 on epoch=25
05/22/2022 20:35:33 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.05 on epoch=25
05/22/2022 20:35:35 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.06 on epoch=25
05/22/2022 20:35:38 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.03 on epoch=25
05/22/2022 20:35:40 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.03 on epoch=25
05/22/2022 20:36:04 - INFO - __main__ - Global step 1450 Train loss 0.04 Classification-F1 0.8092334441782197 on epoch=25
05/22/2022 20:36:07 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.04 on epoch=26
05/22/2022 20:36:09 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.05 on epoch=26
05/22/2022 20:36:12 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.03 on epoch=26
05/22/2022 20:36:14 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.02 on epoch=26
05/22/2022 20:36:17 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.03 on epoch=26
05/22/2022 20:36:43 - INFO - __main__ - Global step 1500 Train loss 0.04 Classification-F1 0.9204196542141954 on epoch=26
05/22/2022 20:36:43 - INFO - __main__ - Saving model with best Classification-F1: 0.8617586160196545 -> 0.9204196542141954 on epoch=26, global_step=1500
05/22/2022 20:36:45 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=26
05/22/2022 20:36:48 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.03 on epoch=27
05/22/2022 20:36:50 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.04 on epoch=27
05/22/2022 20:36:53 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=27
05/22/2022 20:36:56 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.05 on epoch=27
05/22/2022 20:37:21 - INFO - __main__ - Global step 1550 Train loss 0.04 Classification-F1 0.8096397112681366 on epoch=27
05/22/2022 20:37:24 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.04 on epoch=27
05/22/2022 20:37:26 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.13 on epoch=28
05/22/2022 20:37:29 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.04 on epoch=28
05/22/2022 20:37:31 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.05 on epoch=28
05/22/2022 20:37:34 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.04 on epoch=28
05/22/2022 20:37:59 - INFO - __main__ - Global step 1600 Train loss 0.06 Classification-F1 0.919421439346033 on epoch=28
05/22/2022 20:38:01 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=28
05/22/2022 20:38:04 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.05 on epoch=28
05/22/2022 20:38:06 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.07 on epoch=29
05/22/2022 20:38:09 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.06 on epoch=29
05/22/2022 20:38:11 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.03 on epoch=29
05/22/2022 20:38:36 - INFO - __main__ - Global step 1650 Train loss 0.05 Classification-F1 0.7058979581412376 on epoch=29
05/22/2022 20:38:38 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=29
05/22/2022 20:38:41 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.03 on epoch=29
05/22/2022 20:38:44 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.04 on epoch=29
05/22/2022 20:38:46 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.05 on epoch=30
05/22/2022 20:38:49 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.06 on epoch=30
05/22/2022 20:39:13 - INFO - __main__ - Global step 1700 Train loss 0.04 Classification-F1 0.7215681105375407 on epoch=30
05/22/2022 20:39:15 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=30
05/22/2022 20:39:18 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.08 on epoch=30
05/22/2022 20:39:20 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.05 on epoch=30
05/22/2022 20:39:23 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.04 on epoch=31
05/22/2022 20:39:26 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=31
05/22/2022 20:39:50 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.6723441777820351 on epoch=31
05/22/2022 20:39:53 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.05 on epoch=31
05/22/2022 20:39:55 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=31
05/22/2022 20:39:58 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=31
05/22/2022 20:40:00 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.03 on epoch=31
05/22/2022 20:40:03 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=32
05/22/2022 20:40:28 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.6964933991999888 on epoch=32
05/22/2022 20:40:31 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.03 on epoch=32
05/22/2022 20:40:33 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.04 on epoch=32
05/22/2022 20:40:36 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=32
05/22/2022 20:40:38 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=32
05/22/2022 20:40:41 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=33
05/22/2022 20:41:06 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.7525996154202459 on epoch=33
05/22/2022 20:41:08 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.04 on epoch=33
05/22/2022 20:41:11 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.08 on epoch=33
05/22/2022 20:41:13 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=33
05/22/2022 20:41:16 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=33
05/22/2022 20:41:18 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.04 on epoch=33
05/22/2022 20:41:43 - INFO - __main__ - Global step 1900 Train loss 0.04 Classification-F1 0.855944764425995 on epoch=33
05/22/2022 20:41:46 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.04 on epoch=34
05/22/2022 20:41:48 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=34
05/22/2022 20:41:51 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=34
05/22/2022 20:41:53 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.04 on epoch=34
05/22/2022 20:41:56 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.03 on epoch=34
05/22/2022 20:42:20 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.7641918382006088 on epoch=34
05/22/2022 20:42:22 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=34
05/22/2022 20:42:25 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=35
05/22/2022 20:42:28 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.04 on epoch=35
05/22/2022 20:42:30 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=35
05/22/2022 20:42:33 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=35
05/22/2022 20:42:57 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.7664281646433306 on epoch=35
05/22/2022 20:43:00 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.05 on epoch=35
05/22/2022 20:43:02 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=36
05/22/2022 20:43:05 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.05 on epoch=36
05/22/2022 20:43:07 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=36
05/22/2022 20:43:10 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=36
05/22/2022 20:43:35 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.9192658333144718 on epoch=36
05/22/2022 20:43:38 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=36
05/22/2022 20:43:40 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=36
05/22/2022 20:43:43 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=37
05/22/2022 20:43:45 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=37
05/22/2022 20:43:48 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=37
05/22/2022 20:44:14 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.8613635998324729 on epoch=37
05/22/2022 20:44:16 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=37
05/22/2022 20:44:19 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.05 on epoch=37
05/22/2022 20:44:22 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=38
05/22/2022 20:44:24 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=38
05/22/2022 20:44:27 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=38
05/22/2022 20:44:51 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.9187126872831063 on epoch=38
05/22/2022 20:44:53 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=38
05/22/2022 20:44:56 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=38
05/22/2022 20:44:58 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=38
05/22/2022 20:45:01 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.04 on epoch=39
05/22/2022 20:45:03 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=39
05/22/2022 20:45:28 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.8632577074793759 on epoch=39
05/22/2022 20:45:31 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=39
05/22/2022 20:45:33 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=39
05/22/2022 20:45:36 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=39
05/22/2022 20:45:38 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=39
05/22/2022 20:45:41 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=40
05/22/2022 20:46:07 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.9833085999196912 on epoch=40
05/22/2022 20:46:07 - INFO - __main__ - Saving model with best Classification-F1: 0.9204196542141954 -> 0.9833085999196912 on epoch=40, global_step=2250
05/22/2022 20:46:10 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=40
05/22/2022 20:46:12 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.03 on epoch=40
05/22/2022 20:46:15 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=40
05/22/2022 20:46:17 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.03 on epoch=40
05/22/2022 20:46:20 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=41
05/22/2022 20:46:47 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.9866057834264615 on epoch=41
05/22/2022 20:46:47 - INFO - __main__ - Saving model with best Classification-F1: 0.9833085999196912 -> 0.9866057834264615 on epoch=41, global_step=2300
05/22/2022 20:46:50 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=41
05/22/2022 20:46:52 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=41
05/22/2022 20:46:55 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.06 on epoch=41
05/22/2022 20:46:57 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=41
05/22/2022 20:47:00 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.04 on epoch=41
05/22/2022 20:47:24 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.8613477712920361 on epoch=41
05/22/2022 20:47:27 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=42
05/22/2022 20:47:29 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.03 on epoch=42
05/22/2022 20:47:32 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=42
05/22/2022 20:47:34 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.08 on epoch=42
05/22/2022 20:47:37 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.03 on epoch=42
05/22/2022 20:48:01 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.8618395800666963 on epoch=42
05/22/2022 20:48:03 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=43
05/22/2022 20:48:06 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=43
05/22/2022 20:48:09 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=43
05/22/2022 20:48:11 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=43
05/22/2022 20:48:14 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=43
05/22/2022 20:48:38 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.8111403592678746 on epoch=43
05/22/2022 20:48:41 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.02 on epoch=43
05/22/2022 20:48:43 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.05 on epoch=44
05/22/2022 20:48:46 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.05 on epoch=44
05/22/2022 20:48:49 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.03 on epoch=44
05/22/2022 20:48:51 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=44
05/22/2022 20:49:15 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.9187859916059337 on epoch=44
05/22/2022 20:49:18 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=44
05/22/2022 20:49:21 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=44
05/22/2022 20:49:23 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=45
05/22/2022 20:49:26 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=45
05/22/2022 20:49:29 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=45
05/22/2022 20:49:53 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.8603089539171802 on epoch=45
05/22/2022 20:49:56 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=45
05/22/2022 20:49:58 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=45
05/22/2022 20:50:01 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=46
05/22/2022 20:50:03 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=46
05/22/2022 20:50:06 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=46
05/22/2022 20:50:30 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.7644919314347878 on epoch=46
05/22/2022 20:50:32 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=46
05/22/2022 20:50:35 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=46
05/22/2022 20:50:38 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.03 on epoch=46
05/22/2022 20:50:40 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.04 on epoch=47
05/22/2022 20:50:43 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=47
05/22/2022 20:51:08 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.8123874711663451 on epoch=47
05/22/2022 20:51:11 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.04 on epoch=47
05/22/2022 20:51:14 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=47
05/22/2022 20:51:16 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=47
05/22/2022 20:51:19 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=48
05/22/2022 20:51:22 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=48
05/22/2022 20:51:47 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.9223586665281182 on epoch=48
05/22/2022 20:51:49 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.05 on epoch=48
05/22/2022 20:51:52 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=48
05/22/2022 20:51:55 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=48
05/22/2022 20:51:57 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=48
05/22/2022 20:52:00 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=49
05/22/2022 20:52:24 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.9238652574510477 on epoch=49
05/22/2022 20:52:27 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=49
05/22/2022 20:52:30 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=49
05/22/2022 20:52:32 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.03 on epoch=49
05/22/2022 20:52:35 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=49
05/22/2022 20:52:38 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=49
05/22/2022 20:53:01 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.6123149929634606 on epoch=49
05/22/2022 20:53:03 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=50
05/22/2022 20:53:06 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=50
05/22/2022 20:53:09 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=50
05/22/2022 20:53:11 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=50
05/22/2022 20:53:14 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.03 on epoch=50
05/22/2022 20:53:37 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.6894436905494414 on epoch=50
05/22/2022 20:53:40 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=51
05/22/2022 20:53:43 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=51
05/22/2022 20:53:45 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=51
05/22/2022 20:53:48 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=51
05/22/2022 20:53:51 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=51
05/22/2022 20:54:14 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.6698350228715403 on epoch=51
05/22/2022 20:54:16 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=51
05/22/2022 20:54:19 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=52
05/22/2022 20:54:21 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=52
05/22/2022 20:54:24 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=52
05/22/2022 20:54:27 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=52
05/22/2022 20:54:50 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.807621088853013 on epoch=52
05/22/2022 20:54:53 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=52
05/22/2022 20:54:56 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=53
05/22/2022 20:54:58 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.03 on epoch=53
05/22/2022 20:55:01 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=53
05/22/2022 20:55:03 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=53
05/22/2022 20:55:05 - INFO - __main__ - Start tokenizing ... 896 instances
05/22/2022 20:55:05 - INFO - __main__ - Printing 3 examples
05/22/2022 20:55:05 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/22/2022 20:55:05 - INFO - __main__ - ['Plant']
05/22/2022 20:55:05 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/22/2022 20:55:05 - INFO - __main__ - ['Plant']
05/22/2022 20:55:05 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/22/2022 20:55:05 - INFO - __main__ - ['Plant']
05/22/2022 20:55:05 - INFO - __main__ - Tokenizing Input ...
05/22/2022 20:55:05 - INFO - __main__ - Tokenizing Output ...
05/22/2022 20:55:06 - INFO - __main__ - Loaded 896 examples from train data
05/22/2022 20:55:06 - INFO - __main__ - Start tokenizing ... 896 instances
05/22/2022 20:55:06 - INFO - __main__ - Printing 3 examples
05/22/2022 20:55:06 - INFO - __main__ -  [dbpedia_14] Hardwickia is a genus of flowering plants in the legume family Fabaceae. It belongs to the sub family Caesalpinioideae.
05/22/2022 20:55:06 - INFO - __main__ - ['Plant']
05/22/2022 20:55:06 - INFO - __main__ -  [dbpedia_14] Eurybia eryngiifolia commonly known as the Thistleleaf Aster or Coyote-thistle Aster is an herbaceous perennial in the composite family. It is native to the eastern United States where it is only present along the Florida panhandle and the nearby areas of southern Alabama and Georgia.
05/22/2022 20:55:06 - INFO - __main__ - ['Plant']
05/22/2022 20:55:06 - INFO - __main__ -  [dbpedia_14] Petraeovitex is a genus of eight climbing shrubs species known to science of the Mint family Lamiaceae (formerly placed within Verbenaceae).Collectively they grow naturally in Borneo Peninsular Malaysia Sumatra the Philippines the Moluccas New Guinea Bismarck Archipelago the Solomon Islands and Cape York Peninsula Australia.
05/22/2022 20:55:06 - INFO - __main__ - ['Plant']
05/22/2022 20:55:06 - INFO - __main__ - Tokenizing Input ...
05/22/2022 20:55:06 - INFO - __main__ - Tokenizing Output ...
05/22/2022 20:55:07 - INFO - __main__ - Loaded 896 examples from dev data
05/22/2022 20:55:25 - INFO - __main__ - try to initialize prompt embeddings
05/22/2022 20:55:25 - INFO - __main__ - task name: dbpedia_14
05/22/2022 20:55:26 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 20:55:26 - INFO - __main__ - Starting training!
05/22/2022 20:55:28 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.8625282872526109 on epoch=53
05/22/2022 20:55:28 - INFO - __main__ - save last model!
05/22/2022 20:55:28 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/22/2022 20:55:28 - INFO - __main__ - Start tokenizing ... 3500 instances
05/22/2022 20:55:28 - INFO - __main__ - Printing 3 examples
05/22/2022 20:55:28 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/22/2022 20:55:28 - INFO - __main__ - ['Animal']
05/22/2022 20:55:28 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/22/2022 20:55:28 - INFO - __main__ - ['Animal']
05/22/2022 20:55:28 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/22/2022 20:55:28 - INFO - __main__ - ['Village']
05/22/2022 20:55:28 - INFO - __main__ - Tokenizing Input ...
05/22/2022 20:55:30 - INFO - __main__ - Tokenizing Output ...
05/22/2022 20:55:34 - INFO - __main__ - Loaded 3500 examples from test data
05/22/2022 20:57:38 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down64shot/singletask-dbpedia_14/dbpedia_14_64_21_0.5_8_predictions.txt
05/22/2022 20:57:38 - INFO - __main__ - Classification-F1 on test data: 0.6869
05/22/2022 20:57:39 - INFO - __main__ - prefix=dbpedia_14_64_21, lr=0.5, bsz=8, dev_performance=0.9866057834264615, test_performance=0.6869476711812184
05/22/2022 20:57:39 - INFO - __main__ - Running ... prefix=dbpedia_14_64_21, lr=0.4, bsz=8 ...
05/22/2022 20:57:40 - INFO - __main__ - Start tokenizing ... 896 instances
05/22/2022 20:57:40 - INFO - __main__ - Printing 3 examples
05/22/2022 20:57:40 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/22/2022 20:57:40 - INFO - __main__ - ['Plant']
05/22/2022 20:57:40 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/22/2022 20:57:40 - INFO - __main__ - ['Plant']
05/22/2022 20:57:40 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/22/2022 20:57:40 - INFO - __main__ - ['Plant']
05/22/2022 20:57:40 - INFO - __main__ - Tokenizing Input ...
05/22/2022 20:57:40 - INFO - __main__ - Tokenizing Output ...
05/22/2022 20:57:41 - INFO - __main__ - Loaded 896 examples from train data
05/22/2022 20:57:41 - INFO - __main__ - Start tokenizing ... 896 instances
05/22/2022 20:57:41 - INFO - __main__ - Printing 3 examples
05/22/2022 20:57:41 - INFO - __main__ -  [dbpedia_14] Hardwickia is a genus of flowering plants in the legume family Fabaceae. It belongs to the sub family Caesalpinioideae.
05/22/2022 20:57:41 - INFO - __main__ - ['Plant']
05/22/2022 20:57:41 - INFO - __main__ -  [dbpedia_14] Eurybia eryngiifolia commonly known as the Thistleleaf Aster or Coyote-thistle Aster is an herbaceous perennial in the composite family. It is native to the eastern United States where it is only present along the Florida panhandle and the nearby areas of southern Alabama and Georgia.
05/22/2022 20:57:41 - INFO - __main__ - ['Plant']
05/22/2022 20:57:41 - INFO - __main__ -  [dbpedia_14] Petraeovitex is a genus of eight climbing shrubs species known to science of the Mint family Lamiaceae (formerly placed within Verbenaceae).Collectively they grow naturally in Borneo Peninsular Malaysia Sumatra the Philippines the Moluccas New Guinea Bismarck Archipelago the Solomon Islands and Cape York Peninsula Australia.
05/22/2022 20:57:41 - INFO - __main__ - ['Plant']
05/22/2022 20:57:41 - INFO - __main__ - Tokenizing Input ...
05/22/2022 20:57:41 - INFO - __main__ - Tokenizing Output ...
05/22/2022 20:57:42 - INFO - __main__ - Loaded 896 examples from dev data
05/22/2022 20:57:58 - INFO - __main__ - try to initialize prompt embeddings
05/22/2022 20:57:58 - INFO - __main__ - task name: dbpedia_14
05/22/2022 20:57:59 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 20:57:59 - INFO - __main__ - Starting training!
05/22/2022 20:58:02 - INFO - __main__ - Step 10 Global step 10 Train loss 6.49 on epoch=0
05/22/2022 20:58:04 - INFO - __main__ - Step 20 Global step 20 Train loss 4.75 on epoch=0
05/22/2022 20:58:07 - INFO - __main__ - Step 30 Global step 30 Train loss 3.31 on epoch=0
05/22/2022 20:58:09 - INFO - __main__ - Step 40 Global step 40 Train loss 2.61 on epoch=0
05/22/2022 20:58:12 - INFO - __main__ - Step 50 Global step 50 Train loss 2.27 on epoch=0
05/22/2022 20:58:45 - INFO - __main__ - Global step 50 Train loss 3.89 Classification-F1 0.18451549413680657 on epoch=0
05/22/2022 20:58:45 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.18451549413680657 on epoch=0, global_step=50
05/22/2022 20:58:48 - INFO - __main__ - Step 60 Global step 60 Train loss 1.81 on epoch=1
05/22/2022 20:58:51 - INFO - __main__ - Step 70 Global step 70 Train loss 1.50 on epoch=1
05/22/2022 20:58:53 - INFO - __main__ - Step 80 Global step 80 Train loss 1.32 on epoch=1
05/22/2022 20:58:56 - INFO - __main__ - Step 90 Global step 90 Train loss 1.18 on epoch=1
05/22/2022 20:58:58 - INFO - __main__ - Step 100 Global step 100 Train loss 1.15 on epoch=1
05/22/2022 20:59:37 - INFO - __main__ - Global step 100 Train loss 1.39 Classification-F1 0.38781195616973696 on epoch=1
05/22/2022 20:59:37 - INFO - __main__ - Saving model with best Classification-F1: 0.18451549413680657 -> 0.38781195616973696 on epoch=1, global_step=100
05/22/2022 20:59:40 - INFO - __main__ - Step 110 Global step 110 Train loss 1.01 on epoch=1
05/22/2022 20:59:42 - INFO - __main__ - Step 120 Global step 120 Train loss 0.96 on epoch=2
05/22/2022 20:59:45 - INFO - __main__ - Step 130 Global step 130 Train loss 0.85 on epoch=2
05/22/2022 20:59:48 - INFO - __main__ - Step 140 Global step 140 Train loss 0.81 on epoch=2
05/22/2022 20:59:50 - INFO - __main__ - Step 150 Global step 150 Train loss 0.79 on epoch=2
05/22/2022 21:00:26 - INFO - __main__ - Global step 150 Train loss 0.89 Classification-F1 0.441209928074007 on epoch=2
05/22/2022 21:00:26 - INFO - __main__ - Saving model with best Classification-F1: 0.38781195616973696 -> 0.441209928074007 on epoch=2, global_step=150
05/22/2022 21:00:28 - INFO - __main__ - Step 160 Global step 160 Train loss 0.74 on epoch=2
05/22/2022 21:00:31 - INFO - __main__ - Step 170 Global step 170 Train loss 0.85 on epoch=3
05/22/2022 21:00:34 - INFO - __main__ - Step 180 Global step 180 Train loss 0.68 on epoch=3
05/22/2022 21:00:36 - INFO - __main__ - Step 190 Global step 190 Train loss 0.73 on epoch=3
05/22/2022 21:00:39 - INFO - __main__ - Step 200 Global step 200 Train loss 0.72 on epoch=3
05/22/2022 21:01:36 - INFO - __main__ - Global step 200 Train loss 0.74 Classification-F1 0.5072076461141595 on epoch=3
05/22/2022 21:01:36 - INFO - __main__ - Saving model with best Classification-F1: 0.441209928074007 -> 0.5072076461141595 on epoch=3, global_step=200
05/22/2022 21:01:38 - INFO - __main__ - Step 210 Global step 210 Train loss 0.71 on epoch=3
05/22/2022 21:01:41 - INFO - __main__ - Step 220 Global step 220 Train loss 0.60 on epoch=3
05/22/2022 21:01:43 - INFO - __main__ - Step 230 Global step 230 Train loss 0.61 on epoch=4
05/22/2022 21:01:46 - INFO - __main__ - Step 240 Global step 240 Train loss 0.58 on epoch=4
05/22/2022 21:01:48 - INFO - __main__ - Step 250 Global step 250 Train loss 0.66 on epoch=4
05/22/2022 21:02:30 - INFO - __main__ - Global step 250 Train loss 0.63 Classification-F1 0.47304541536028655 on epoch=4
05/22/2022 21:02:32 - INFO - __main__ - Step 260 Global step 260 Train loss 0.64 on epoch=4
05/22/2022 21:02:35 - INFO - __main__ - Step 270 Global step 270 Train loss 0.54 on epoch=4
05/22/2022 21:02:37 - INFO - __main__ - Step 280 Global step 280 Train loss 0.59 on epoch=4
05/22/2022 21:02:40 - INFO - __main__ - Step 290 Global step 290 Train loss 0.44 on epoch=5
05/22/2022 21:02:43 - INFO - __main__ - Step 300 Global step 300 Train loss 0.44 on epoch=5
05/22/2022 21:03:14 - INFO - __main__ - Global step 300 Train loss 0.53 Classification-F1 0.40949448534845745 on epoch=5
05/22/2022 21:03:17 - INFO - __main__ - Step 310 Global step 310 Train loss 0.54 on epoch=5
05/22/2022 21:03:19 - INFO - __main__ - Step 320 Global step 320 Train loss 0.47 on epoch=5
05/22/2022 21:03:22 - INFO - __main__ - Step 330 Global step 330 Train loss 0.45 on epoch=5
05/22/2022 21:03:24 - INFO - __main__ - Step 340 Global step 340 Train loss 0.43 on epoch=6
05/22/2022 21:03:27 - INFO - __main__ - Step 350 Global step 350 Train loss 0.38 on epoch=6
05/22/2022 21:03:53 - INFO - __main__ - Global step 350 Train loss 0.45 Classification-F1 0.4823598717936349 on epoch=6
05/22/2022 21:03:55 - INFO - __main__ - Step 360 Global step 360 Train loss 0.46 on epoch=6
05/22/2022 21:03:58 - INFO - __main__ - Step 370 Global step 370 Train loss 0.49 on epoch=6
05/22/2022 21:04:01 - INFO - __main__ - Step 380 Global step 380 Train loss 0.40 on epoch=6
05/22/2022 21:04:03 - INFO - __main__ - Step 390 Global step 390 Train loss 0.45 on epoch=6
05/22/2022 21:04:06 - INFO - __main__ - Step 400 Global step 400 Train loss 0.40 on epoch=7
05/22/2022 21:04:31 - INFO - __main__ - Global step 400 Train loss 0.44 Classification-F1 0.5386452828437012 on epoch=7
05/22/2022 21:04:31 - INFO - __main__ - Saving model with best Classification-F1: 0.5072076461141595 -> 0.5386452828437012 on epoch=7, global_step=400
05/22/2022 21:04:34 - INFO - __main__ - Step 410 Global step 410 Train loss 0.29 on epoch=7
05/22/2022 21:04:37 - INFO - __main__ - Step 420 Global step 420 Train loss 0.33 on epoch=7
05/22/2022 21:04:39 - INFO - __main__ - Step 430 Global step 430 Train loss 0.32 on epoch=7
05/22/2022 21:04:42 - INFO - __main__ - Step 440 Global step 440 Train loss 0.33 on epoch=7
05/22/2022 21:04:44 - INFO - __main__ - Step 450 Global step 450 Train loss 0.28 on epoch=8
05/22/2022 21:05:10 - INFO - __main__ - Global step 450 Train loss 0.31 Classification-F1 0.5265878843366449 on epoch=8
05/22/2022 21:05:13 - INFO - __main__ - Step 460 Global step 460 Train loss 0.29 on epoch=8
05/22/2022 21:05:16 - INFO - __main__ - Step 470 Global step 470 Train loss 0.31 on epoch=8
05/22/2022 21:05:18 - INFO - __main__ - Step 480 Global step 480 Train loss 0.37 on epoch=8
05/22/2022 21:05:21 - INFO - __main__ - Step 490 Global step 490 Train loss 0.27 on epoch=8
05/22/2022 21:05:23 - INFO - __main__ - Step 500 Global step 500 Train loss 0.39 on epoch=8
05/22/2022 21:05:49 - INFO - __main__ - Global step 500 Train loss 0.33 Classification-F1 0.5416153504192037 on epoch=8
05/22/2022 21:05:49 - INFO - __main__ - Saving model with best Classification-F1: 0.5386452828437012 -> 0.5416153504192037 on epoch=8, global_step=500
05/22/2022 21:05:52 - INFO - __main__ - Step 510 Global step 510 Train loss 0.21 on epoch=9
05/22/2022 21:05:55 - INFO - __main__ - Step 520 Global step 520 Train loss 0.25 on epoch=9
05/22/2022 21:05:57 - INFO - __main__ - Step 530 Global step 530 Train loss 0.26 on epoch=9
05/22/2022 21:06:00 - INFO - __main__ - Step 540 Global step 540 Train loss 0.32 on epoch=9
05/22/2022 21:06:03 - INFO - __main__ - Step 550 Global step 550 Train loss 0.26 on epoch=9
05/22/2022 21:06:27 - INFO - __main__ - Global step 550 Train loss 0.26 Classification-F1 0.5762146700738053 on epoch=9
05/22/2022 21:06:27 - INFO - __main__ - Saving model with best Classification-F1: 0.5416153504192037 -> 0.5762146700738053 on epoch=9, global_step=550
05/22/2022 21:06:30 - INFO - __main__ - Step 560 Global step 560 Train loss 0.25 on epoch=9
05/22/2022 21:06:32 - INFO - __main__ - Step 570 Global step 570 Train loss 0.26 on epoch=10
05/22/2022 21:06:35 - INFO - __main__ - Step 580 Global step 580 Train loss 0.20 on epoch=10
05/22/2022 21:06:37 - INFO - __main__ - Step 590 Global step 590 Train loss 0.23 on epoch=10
05/22/2022 21:06:40 - INFO - __main__ - Step 600 Global step 600 Train loss 0.21 on epoch=10
05/22/2022 21:07:05 - INFO - __main__ - Global step 600 Train loss 0.23 Classification-F1 0.5709173928351516 on epoch=10
05/22/2022 21:07:08 - INFO - __main__ - Step 610 Global step 610 Train loss 0.26 on epoch=10
05/22/2022 21:07:10 - INFO - __main__ - Step 620 Global step 620 Train loss 0.15 on epoch=11
05/22/2022 21:07:13 - INFO - __main__ - Step 630 Global step 630 Train loss 0.19 on epoch=11
05/22/2022 21:07:16 - INFO - __main__ - Step 640 Global step 640 Train loss 0.17 on epoch=11
05/22/2022 21:07:18 - INFO - __main__ - Step 650 Global step 650 Train loss 0.17 on epoch=11
05/22/2022 21:07:43 - INFO - __main__ - Global step 650 Train loss 0.19 Classification-F1 0.5503216756332806 on epoch=11
05/22/2022 21:07:46 - INFO - __main__ - Step 660 Global step 660 Train loss 0.19 on epoch=11
05/22/2022 21:07:48 - INFO - __main__ - Step 670 Global step 670 Train loss 0.22 on epoch=11
05/22/2022 21:07:51 - INFO - __main__ - Step 680 Global step 680 Train loss 0.19 on epoch=12
05/22/2022 21:07:54 - INFO - __main__ - Step 690 Global step 690 Train loss 0.25 on epoch=12
05/22/2022 21:07:56 - INFO - __main__ - Step 700 Global step 700 Train loss 0.22 on epoch=12
05/22/2022 21:08:21 - INFO - __main__ - Global step 700 Train loss 0.21 Classification-F1 0.5868985128739853 on epoch=12
05/22/2022 21:08:21 - INFO - __main__ - Saving model with best Classification-F1: 0.5762146700738053 -> 0.5868985128739853 on epoch=12, global_step=700
05/22/2022 21:08:24 - INFO - __main__ - Step 710 Global step 710 Train loss 0.15 on epoch=12
05/22/2022 21:08:26 - INFO - __main__ - Step 720 Global step 720 Train loss 0.29 on epoch=12
05/22/2022 21:08:29 - INFO - __main__ - Step 730 Global step 730 Train loss 0.19 on epoch=13
05/22/2022 21:08:32 - INFO - __main__ - Step 740 Global step 740 Train loss 0.18 on epoch=13
05/22/2022 21:08:34 - INFO - __main__ - Step 750 Global step 750 Train loss 0.15 on epoch=13
05/22/2022 21:08:59 - INFO - __main__ - Global step 750 Train loss 0.19 Classification-F1 0.4912194430014845 on epoch=13
05/22/2022 21:09:01 - INFO - __main__ - Step 760 Global step 760 Train loss 0.19 on epoch=13
05/22/2022 21:09:04 - INFO - __main__ - Step 770 Global step 770 Train loss 0.11 on epoch=13
05/22/2022 21:09:07 - INFO - __main__ - Step 780 Global step 780 Train loss 0.19 on epoch=13
05/22/2022 21:09:09 - INFO - __main__ - Step 790 Global step 790 Train loss 0.18 on epoch=14
05/22/2022 21:09:12 - INFO - __main__ - Step 800 Global step 800 Train loss 0.13 on epoch=14
05/22/2022 21:09:36 - INFO - __main__ - Global step 800 Train loss 0.16 Classification-F1 0.6229141948903727 on epoch=14
05/22/2022 21:09:36 - INFO - __main__ - Saving model with best Classification-F1: 0.5868985128739853 -> 0.6229141948903727 on epoch=14, global_step=800
05/22/2022 21:09:38 - INFO - __main__ - Step 810 Global step 810 Train loss 0.15 on epoch=14
05/22/2022 21:09:41 - INFO - __main__ - Step 820 Global step 820 Train loss 0.15 on epoch=14
05/22/2022 21:09:43 - INFO - __main__ - Step 830 Global step 830 Train loss 0.14 on epoch=14
05/22/2022 21:09:46 - INFO - __main__ - Step 840 Global step 840 Train loss 0.22 on epoch=14
05/22/2022 21:09:49 - INFO - __main__ - Step 850 Global step 850 Train loss 0.24 on epoch=15
05/22/2022 21:10:13 - INFO - __main__ - Global step 850 Train loss 0.18 Classification-F1 0.5827023849240829 on epoch=15
05/22/2022 21:10:15 - INFO - __main__ - Step 860 Global step 860 Train loss 0.09 on epoch=15
05/22/2022 21:10:18 - INFO - __main__ - Step 870 Global step 870 Train loss 0.15 on epoch=15
05/22/2022 21:10:20 - INFO - __main__ - Step 880 Global step 880 Train loss 0.19 on epoch=15
05/22/2022 21:10:23 - INFO - __main__ - Step 890 Global step 890 Train loss 0.18 on epoch=15
05/22/2022 21:10:26 - INFO - __main__ - Step 900 Global step 900 Train loss 0.27 on epoch=16
05/22/2022 21:10:50 - INFO - __main__ - Global step 900 Train loss 0.18 Classification-F1 0.6667293080632417 on epoch=16
05/22/2022 21:10:50 - INFO - __main__ - Saving model with best Classification-F1: 0.6229141948903727 -> 0.6667293080632417 on epoch=16, global_step=900
05/22/2022 21:10:53 - INFO - __main__ - Step 910 Global step 910 Train loss 0.14 on epoch=16
05/22/2022 21:10:55 - INFO - __main__ - Step 920 Global step 920 Train loss 0.12 on epoch=16
05/22/2022 21:10:58 - INFO - __main__ - Step 930 Global step 930 Train loss 0.17 on epoch=16
05/22/2022 21:11:00 - INFO - __main__ - Step 940 Global step 940 Train loss 0.12 on epoch=16
05/22/2022 21:11:03 - INFO - __main__ - Step 950 Global step 950 Train loss 0.15 on epoch=16
05/22/2022 21:11:27 - INFO - __main__ - Global step 950 Train loss 0.14 Classification-F1 0.6195805039718997 on epoch=16
05/22/2022 21:11:30 - INFO - __main__ - Step 960 Global step 960 Train loss 0.10 on epoch=17
05/22/2022 21:11:32 - INFO - __main__ - Step 970 Global step 970 Train loss 0.11 on epoch=17
05/22/2022 21:11:35 - INFO - __main__ - Step 980 Global step 980 Train loss 0.13 on epoch=17
05/22/2022 21:11:37 - INFO - __main__ - Step 990 Global step 990 Train loss 0.10 on epoch=17
05/22/2022 21:11:40 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.12 on epoch=17
05/22/2022 21:12:04 - INFO - __main__ - Global step 1000 Train loss 0.11 Classification-F1 0.5748376381487347 on epoch=17
05/22/2022 21:12:06 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.15 on epoch=18
05/22/2022 21:12:09 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.09 on epoch=18
05/22/2022 21:12:12 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.10 on epoch=18
05/22/2022 21:12:14 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.17 on epoch=18
05/22/2022 21:12:17 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.10 on epoch=18
05/22/2022 21:12:41 - INFO - __main__ - Global step 1050 Train loss 0.12 Classification-F1 0.6385445891120526 on epoch=18
05/22/2022 21:12:43 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.14 on epoch=18
05/22/2022 21:12:46 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.14 on epoch=19
05/22/2022 21:12:49 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.11 on epoch=19
05/22/2022 21:12:51 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.09 on epoch=19
05/22/2022 21:12:54 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.11 on epoch=19
05/22/2022 21:13:19 - INFO - __main__ - Global step 1100 Train loss 0.12 Classification-F1 0.6219519650432771 on epoch=19
05/22/2022 21:13:21 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.10 on epoch=19
05/22/2022 21:13:24 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.11 on epoch=19
05/22/2022 21:13:27 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.08 on epoch=20
05/22/2022 21:13:29 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.04 on epoch=20
05/22/2022 21:13:32 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.13 on epoch=20
05/22/2022 21:13:56 - INFO - __main__ - Global step 1150 Train loss 0.09 Classification-F1 0.6040148464852126 on epoch=20
05/22/2022 21:13:59 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.08 on epoch=20
05/22/2022 21:14:02 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.11 on epoch=20
05/22/2022 21:14:04 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.08 on epoch=21
05/22/2022 21:14:07 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.13 on epoch=21
05/22/2022 21:14:10 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.09 on epoch=21
05/22/2022 21:14:34 - INFO - __main__ - Global step 1200 Train loss 0.10 Classification-F1 0.5601203251878402 on epoch=21
05/22/2022 21:14:36 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.11 on epoch=21
05/22/2022 21:14:39 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.08 on epoch=21
05/22/2022 21:14:42 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.13 on epoch=21
05/22/2022 21:14:44 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.04 on epoch=22
05/22/2022 21:14:47 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.05 on epoch=22
05/22/2022 21:15:12 - INFO - __main__ - Global step 1250 Train loss 0.08 Classification-F1 0.6229536754284288 on epoch=22
05/22/2022 21:15:14 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.10 on epoch=22
05/22/2022 21:15:17 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.06 on epoch=22
05/22/2022 21:15:20 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.08 on epoch=22
05/22/2022 21:15:22 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.07 on epoch=23
05/22/2022 21:15:25 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.16 on epoch=23
05/22/2022 21:15:50 - INFO - __main__ - Global step 1300 Train loss 0.09 Classification-F1 0.6111155555646156 on epoch=23
05/22/2022 21:15:53 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.11 on epoch=23
05/22/2022 21:15:56 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.07 on epoch=23
05/22/2022 21:15:58 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.09 on epoch=23
05/22/2022 21:16:01 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.12 on epoch=23
05/22/2022 21:16:03 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.12 on epoch=24
05/22/2022 21:16:29 - INFO - __main__ - Global step 1350 Train loss 0.10 Classification-F1 0.6438951788977221 on epoch=24
05/22/2022 21:16:32 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.05 on epoch=24
05/22/2022 21:16:34 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.11 on epoch=24
05/22/2022 21:16:37 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.11 on epoch=24
05/22/2022 21:16:40 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.06 on epoch=24
05/22/2022 21:16:42 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.14 on epoch=24
05/22/2022 21:17:08 - INFO - __main__ - Global step 1400 Train loss 0.09 Classification-F1 0.693973221436472 on epoch=24
05/22/2022 21:17:08 - INFO - __main__ - Saving model with best Classification-F1: 0.6667293080632417 -> 0.693973221436472 on epoch=24, global_step=1400
05/22/2022 21:17:10 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.05 on epoch=25
05/22/2022 21:17:13 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.10 on epoch=25
05/22/2022 21:17:15 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.09 on epoch=25
05/22/2022 21:17:18 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.08 on epoch=25
05/22/2022 21:17:21 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.04 on epoch=25
05/22/2022 21:17:46 - INFO - __main__ - Global step 1450 Train loss 0.07 Classification-F1 0.7362962058806863 on epoch=25
05/22/2022 21:17:46 - INFO - __main__ - Saving model with best Classification-F1: 0.693973221436472 -> 0.7362962058806863 on epoch=25, global_step=1450
05/22/2022 21:17:48 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.04 on epoch=26
05/22/2022 21:17:51 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.13 on epoch=26
05/22/2022 21:17:54 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.07 on epoch=26
05/22/2022 21:17:56 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.08 on epoch=26
05/22/2022 21:17:59 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.04 on epoch=26
05/22/2022 21:18:22 - INFO - __main__ - Global step 1500 Train loss 0.07 Classification-F1 0.7354144562512791 on epoch=26
05/22/2022 21:18:24 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.09 on epoch=26
05/22/2022 21:18:27 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.05 on epoch=27
05/22/2022 21:18:30 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.05 on epoch=27
05/22/2022 21:18:32 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.10 on epoch=27
05/22/2022 21:18:35 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.04 on epoch=27
05/22/2022 21:18:59 - INFO - __main__ - Global step 1550 Train loss 0.07 Classification-F1 0.5990587130139854 on epoch=27
05/22/2022 21:19:02 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.05 on epoch=27
05/22/2022 21:19:04 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.07 on epoch=28
05/22/2022 21:19:07 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.05 on epoch=28
05/22/2022 21:19:10 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.06 on epoch=28
05/22/2022 21:19:12 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.07 on epoch=28
05/22/2022 21:19:38 - INFO - __main__ - Global step 1600 Train loss 0.06 Classification-F1 0.5524552386433392 on epoch=28
05/22/2022 21:19:40 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.05 on epoch=28
05/22/2022 21:19:43 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.09 on epoch=28
05/22/2022 21:19:46 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.07 on epoch=29
05/22/2022 21:19:48 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.08 on epoch=29
05/22/2022 21:19:51 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=29
05/22/2022 21:20:15 - INFO - __main__ - Global step 1650 Train loss 0.06 Classification-F1 0.759294808847554 on epoch=29
05/22/2022 21:20:15 - INFO - __main__ - Saving model with best Classification-F1: 0.7362962058806863 -> 0.759294808847554 on epoch=29, global_step=1650
05/22/2022 21:20:18 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.07 on epoch=29
05/22/2022 21:20:20 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=29
05/22/2022 21:20:23 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.05 on epoch=29
05/22/2022 21:20:26 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.05 on epoch=30
05/22/2022 21:20:28 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.04 on epoch=30
05/22/2022 21:20:53 - INFO - __main__ - Global step 1700 Train loss 0.05 Classification-F1 0.6834705852814693 on epoch=30
05/22/2022 21:20:56 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.06 on epoch=30
05/22/2022 21:20:58 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.06 on epoch=30
05/22/2022 21:21:01 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.03 on epoch=30
05/22/2022 21:21:04 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.08 on epoch=31
05/22/2022 21:21:06 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.05 on epoch=31
05/22/2022 21:21:32 - INFO - __main__ - Global step 1750 Train loss 0.06 Classification-F1 0.6404796218752115 on epoch=31
05/22/2022 21:21:34 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.06 on epoch=31
05/22/2022 21:21:37 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.03 on epoch=31
05/22/2022 21:21:39 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.07 on epoch=31
05/22/2022 21:21:42 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.04 on epoch=31
05/22/2022 21:21:45 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.03 on epoch=32
05/22/2022 21:22:09 - INFO - __main__ - Global step 1800 Train loss 0.05 Classification-F1 0.7003555221494407 on epoch=32
05/22/2022 21:22:11 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=32
05/22/2022 21:22:14 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.06 on epoch=32
05/22/2022 21:22:17 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.07 on epoch=32
05/22/2022 21:22:19 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=32
05/22/2022 21:22:22 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.08 on epoch=33
05/22/2022 21:22:46 - INFO - __main__ - Global step 1850 Train loss 0.05 Classification-F1 0.6243199677517837 on epoch=33
05/22/2022 21:22:49 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.05 on epoch=33
05/22/2022 21:22:52 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.06 on epoch=33
05/22/2022 21:22:54 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.07 on epoch=33
05/22/2022 21:22:57 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.04 on epoch=33
05/22/2022 21:23:00 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=33
05/22/2022 21:23:24 - INFO - __main__ - Global step 1900 Train loss 0.05 Classification-F1 0.5201872472269278 on epoch=33
05/22/2022 21:23:26 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=34
05/22/2022 21:23:29 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=34
05/22/2022 21:23:32 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=34
05/22/2022 21:23:34 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.05 on epoch=34
05/22/2022 21:23:37 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.11 on epoch=34
05/22/2022 21:24:01 - INFO - __main__ - Global step 1950 Train loss 0.04 Classification-F1 0.6493766245959411 on epoch=34
05/22/2022 21:24:04 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.09 on epoch=34
05/22/2022 21:24:06 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=35
05/22/2022 21:24:09 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=35
05/22/2022 21:24:11 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.06 on epoch=35
05/22/2022 21:24:14 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=35
05/22/2022 21:24:37 - INFO - __main__ - Global step 2000 Train loss 0.04 Classification-F1 0.5220475570416417 on epoch=35
05/22/2022 21:24:40 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.03 on epoch=35
05/22/2022 21:24:42 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.03 on epoch=36
05/22/2022 21:24:45 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=36
05/22/2022 21:24:47 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.05 on epoch=36
05/22/2022 21:24:50 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.04 on epoch=36
05/22/2022 21:25:14 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.7128979903880298 on epoch=36
05/22/2022 21:25:17 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.05 on epoch=36
05/22/2022 21:25:19 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.03 on epoch=36
05/22/2022 21:25:22 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.03 on epoch=37
05/22/2022 21:25:25 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.05 on epoch=37
05/22/2022 21:25:27 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.04 on epoch=37
05/22/2022 21:25:51 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.4573723955443743 on epoch=37
05/22/2022 21:25:53 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=37
05/22/2022 21:25:56 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=37
05/22/2022 21:25:59 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.09 on epoch=38
05/22/2022 21:26:01 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=38
05/22/2022 21:26:04 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=38
05/22/2022 21:26:28 - INFO - __main__ - Global step 2150 Train loss 0.03 Classification-F1 0.6165019396205447 on epoch=38
05/22/2022 21:26:30 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.05 on epoch=38
05/22/2022 21:26:33 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=38
05/22/2022 21:26:35 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=38
05/22/2022 21:26:38 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.04 on epoch=39
05/22/2022 21:26:41 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=39
05/22/2022 21:27:04 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.6642431362273772 on epoch=39
05/22/2022 21:27:06 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.07 on epoch=39
05/22/2022 21:27:09 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=39
05/22/2022 21:27:12 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.03 on epoch=39
05/22/2022 21:27:14 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.05 on epoch=39
05/22/2022 21:27:17 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=40
05/22/2022 21:27:40 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.6130597460091365 on epoch=40
05/22/2022 21:27:43 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.04 on epoch=40
05/22/2022 21:27:46 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=40
05/22/2022 21:27:48 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=40
05/22/2022 21:27:51 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.06 on epoch=40
05/22/2022 21:27:53 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=41
05/22/2022 21:28:17 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.5996177727495562 on epoch=41
05/22/2022 21:28:20 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=41
05/22/2022 21:28:22 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=41
05/22/2022 21:28:25 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=41
05/22/2022 21:28:27 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.07 on epoch=41
05/22/2022 21:28:30 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=41
05/22/2022 21:28:53 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.5736984668264064 on epoch=41
05/22/2022 21:28:55 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.05 on epoch=42
05/22/2022 21:28:58 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.03 on epoch=42
05/22/2022 21:29:01 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.07 on epoch=42
05/22/2022 21:29:03 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=42
05/22/2022 21:29:06 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.05 on epoch=42
05/22/2022 21:29:30 - INFO - __main__ - Global step 2400 Train loss 0.04 Classification-F1 0.5884754459566766 on epoch=42
05/22/2022 21:29:32 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=43
05/22/2022 21:29:35 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.05 on epoch=43
05/22/2022 21:29:38 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=43
05/22/2022 21:29:40 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=43
05/22/2022 21:29:43 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=43
05/22/2022 21:30:06 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.6635598134705647 on epoch=43
05/22/2022 21:30:08 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=43
05/22/2022 21:30:11 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.06 on epoch=44
05/22/2022 21:30:13 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=44
05/22/2022 21:30:16 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=44
05/22/2022 21:30:19 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=44
05/22/2022 21:30:41 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.7419558675526977 on epoch=44
05/22/2022 21:30:44 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=44
05/22/2022 21:30:47 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=44
05/22/2022 21:30:49 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=45
05/22/2022 21:30:52 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=45
05/22/2022 21:30:54 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=45
05/22/2022 21:31:18 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.7539398065311103 on epoch=45
05/22/2022 21:31:21 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=45
05/22/2022 21:31:24 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=45
05/22/2022 21:31:26 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=46
05/22/2022 21:31:29 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=46
05/22/2022 21:31:31 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=46
05/22/2022 21:31:55 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.6666457795854942 on epoch=46
05/22/2022 21:31:58 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=46
05/22/2022 21:32:00 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.04 on epoch=46
05/22/2022 21:32:03 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=46
05/22/2022 21:32:05 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.04 on epoch=47
05/22/2022 21:32:08 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=47
05/22/2022 21:32:31 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.6632154061680842 on epoch=47
05/22/2022 21:32:34 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.05 on epoch=47
05/22/2022 21:32:36 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=47
05/22/2022 21:32:39 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.05 on epoch=47
05/22/2022 21:32:41 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=48
05/22/2022 21:32:44 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=48
05/22/2022 21:33:07 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.694938370273608 on epoch=48
05/22/2022 21:33:09 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.03 on epoch=48
05/22/2022 21:33:12 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.03 on epoch=48
05/22/2022 21:33:15 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.04 on epoch=48
05/22/2022 21:33:17 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=48
05/22/2022 21:33:20 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=49
05/22/2022 21:33:44 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.704450959151033 on epoch=49
05/22/2022 21:33:46 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=49
05/22/2022 21:33:49 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=49
05/22/2022 21:33:51 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=49
05/22/2022 21:33:54 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=49
05/22/2022 21:33:57 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.03 on epoch=49
05/22/2022 21:34:19 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.6613790564774621 on epoch=49
05/22/2022 21:34:21 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.08 on epoch=50
05/22/2022 21:34:24 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=50
05/22/2022 21:34:27 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.03 on epoch=50
05/22/2022 21:34:29 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=50
05/22/2022 21:34:32 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=50
05/22/2022 21:34:54 - INFO - __main__ - Global step 2850 Train loss 0.03 Classification-F1 0.6510665179508246 on epoch=50
05/22/2022 21:34:57 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=51
05/22/2022 21:34:59 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=51
05/22/2022 21:35:02 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=51
05/22/2022 21:35:04 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.04 on epoch=51
05/22/2022 21:35:07 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=51
05/22/2022 21:35:29 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.7446789582727891 on epoch=51
05/22/2022 21:35:32 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=51
05/22/2022 21:35:35 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=52
05/22/2022 21:35:37 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=52
05/22/2022 21:35:40 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.07 on epoch=52
05/22/2022 21:35:42 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=52
05/22/2022 21:36:06 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.5936692779997931 on epoch=52
05/22/2022 21:36:09 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=52
05/22/2022 21:36:11 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=53
05/22/2022 21:36:14 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=53
05/22/2022 21:36:16 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=53
05/22/2022 21:36:19 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=53
05/22/2022 21:36:20 - INFO - __main__ - Start tokenizing ... 896 instances
05/22/2022 21:36:20 - INFO - __main__ - Printing 3 examples
05/22/2022 21:36:20 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/22/2022 21:36:20 - INFO - __main__ - ['Plant']
05/22/2022 21:36:20 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/22/2022 21:36:20 - INFO - __main__ - ['Plant']
05/22/2022 21:36:20 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/22/2022 21:36:20 - INFO - __main__ - ['Plant']
05/22/2022 21:36:20 - INFO - __main__ - Tokenizing Input ...
05/22/2022 21:36:21 - INFO - __main__ - Tokenizing Output ...
05/22/2022 21:36:22 - INFO - __main__ - Loaded 896 examples from train data
05/22/2022 21:36:22 - INFO - __main__ - Start tokenizing ... 896 instances
05/22/2022 21:36:22 - INFO - __main__ - Printing 3 examples
05/22/2022 21:36:22 - INFO - __main__ -  [dbpedia_14] Hardwickia is a genus of flowering plants in the legume family Fabaceae. It belongs to the sub family Caesalpinioideae.
05/22/2022 21:36:22 - INFO - __main__ - ['Plant']
05/22/2022 21:36:22 - INFO - __main__ -  [dbpedia_14] Eurybia eryngiifolia commonly known as the Thistleleaf Aster or Coyote-thistle Aster is an herbaceous perennial in the composite family. It is native to the eastern United States where it is only present along the Florida panhandle and the nearby areas of southern Alabama and Georgia.
05/22/2022 21:36:22 - INFO - __main__ - ['Plant']
05/22/2022 21:36:22 - INFO - __main__ -  [dbpedia_14] Petraeovitex is a genus of eight climbing shrubs species known to science of the Mint family Lamiaceae (formerly placed within Verbenaceae).Collectively they grow naturally in Borneo Peninsular Malaysia Sumatra the Philippines the Moluccas New Guinea Bismarck Archipelago the Solomon Islands and Cape York Peninsula Australia.
05/22/2022 21:36:22 - INFO - __main__ - ['Plant']
05/22/2022 21:36:22 - INFO - __main__ - Tokenizing Input ...
05/22/2022 21:36:22 - INFO - __main__ - Tokenizing Output ...
05/22/2022 21:36:23 - INFO - __main__ - Loaded 896 examples from dev data
05/22/2022 21:36:39 - INFO - __main__ - try to initialize prompt embeddings
05/22/2022 21:36:39 - INFO - __main__ - task name: dbpedia_14
05/22/2022 21:36:40 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 21:36:40 - INFO - __main__ - Starting training!
05/22/2022 21:36:41 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.6415481268720329 on epoch=53
05/22/2022 21:36:41 - INFO - __main__ - save last model!
05/22/2022 21:36:41 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/22/2022 21:36:41 - INFO - __main__ - Start tokenizing ... 3500 instances
05/22/2022 21:36:41 - INFO - __main__ - Printing 3 examples
05/22/2022 21:36:41 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/22/2022 21:36:41 - INFO - __main__ - ['Animal']
05/22/2022 21:36:41 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/22/2022 21:36:41 - INFO - __main__ - ['Animal']
05/22/2022 21:36:41 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/22/2022 21:36:41 - INFO - __main__ - ['Village']
05/22/2022 21:36:41 - INFO - __main__ - Tokenizing Input ...
05/22/2022 21:36:43 - INFO - __main__ - Tokenizing Output ...
05/22/2022 21:36:47 - INFO - __main__ - Loaded 3500 examples from test data
05/22/2022 21:38:28 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down64shot/singletask-dbpedia_14/dbpedia_14_64_21_0.4_8_predictions.txt
05/22/2022 21:38:28 - INFO - __main__ - Classification-F1 on test data: 0.5752
05/22/2022 21:38:28 - INFO - __main__ - prefix=dbpedia_14_64_21, lr=0.4, bsz=8, dev_performance=0.759294808847554, test_performance=0.5751511810101619
05/22/2022 21:38:28 - INFO - __main__ - Running ... prefix=dbpedia_14_64_21, lr=0.3, bsz=8 ...
05/22/2022 21:38:29 - INFO - __main__ - Start tokenizing ... 896 instances
05/22/2022 21:38:29 - INFO - __main__ - Printing 3 examples
05/22/2022 21:38:29 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/22/2022 21:38:29 - INFO - __main__ - ['Plant']
05/22/2022 21:38:29 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/22/2022 21:38:29 - INFO - __main__ - ['Plant']
05/22/2022 21:38:29 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/22/2022 21:38:29 - INFO - __main__ - ['Plant']
05/22/2022 21:38:29 - INFO - __main__ - Tokenizing Input ...
05/22/2022 21:38:30 - INFO - __main__ - Tokenizing Output ...
05/22/2022 21:38:30 - INFO - __main__ - Loaded 896 examples from train data
05/22/2022 21:38:30 - INFO - __main__ - Start tokenizing ... 896 instances
05/22/2022 21:38:30 - INFO - __main__ - Printing 3 examples
05/22/2022 21:38:30 - INFO - __main__ -  [dbpedia_14] Hardwickia is a genus of flowering plants in the legume family Fabaceae. It belongs to the sub family Caesalpinioideae.
05/22/2022 21:38:30 - INFO - __main__ - ['Plant']
05/22/2022 21:38:30 - INFO - __main__ -  [dbpedia_14] Eurybia eryngiifolia commonly known as the Thistleleaf Aster or Coyote-thistle Aster is an herbaceous perennial in the composite family. It is native to the eastern United States where it is only present along the Florida panhandle and the nearby areas of southern Alabama and Georgia.
05/22/2022 21:38:30 - INFO - __main__ - ['Plant']
05/22/2022 21:38:30 - INFO - __main__ -  [dbpedia_14] Petraeovitex is a genus of eight climbing shrubs species known to science of the Mint family Lamiaceae (formerly placed within Verbenaceae).Collectively they grow naturally in Borneo Peninsular Malaysia Sumatra the Philippines the Moluccas New Guinea Bismarck Archipelago the Solomon Islands and Cape York Peninsula Australia.
05/22/2022 21:38:30 - INFO - __main__ - ['Plant']
05/22/2022 21:38:30 - INFO - __main__ - Tokenizing Input ...
05/22/2022 21:38:31 - INFO - __main__ - Tokenizing Output ...
05/22/2022 21:38:32 - INFO - __main__ - Loaded 896 examples from dev data
05/22/2022 21:38:50 - INFO - __main__ - try to initialize prompt embeddings
05/22/2022 21:38:50 - INFO - __main__ - task name: dbpedia_14
05/22/2022 21:38:51 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 21:38:51 - INFO - __main__ - Starting training!
05/22/2022 21:38:55 - INFO - __main__ - Step 10 Global step 10 Train loss 6.93 on epoch=0
05/22/2022 21:38:57 - INFO - __main__ - Step 20 Global step 20 Train loss 5.91 on epoch=0
05/22/2022 21:39:00 - INFO - __main__ - Step 30 Global step 30 Train loss 4.47 on epoch=0
05/22/2022 21:39:03 - INFO - __main__ - Step 40 Global step 40 Train loss 3.50 on epoch=0
05/22/2022 21:39:05 - INFO - __main__ - Step 50 Global step 50 Train loss 2.75 on epoch=0
05/22/2022 21:39:39 - INFO - __main__ - Global step 50 Train loss 4.71 Classification-F1 0.0662344430890384 on epoch=0
05/22/2022 21:39:39 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0662344430890384 on epoch=0, global_step=50
05/22/2022 21:39:42 - INFO - __main__ - Step 60 Global step 60 Train loss 2.17 on epoch=1
05/22/2022 21:39:45 - INFO - __main__ - Step 70 Global step 70 Train loss 1.87 on epoch=1
05/22/2022 21:39:47 - INFO - __main__ - Step 80 Global step 80 Train loss 1.82 on epoch=1
05/22/2022 21:39:50 - INFO - __main__ - Step 90 Global step 90 Train loss 1.47 on epoch=1
05/22/2022 21:39:53 - INFO - __main__ - Step 100 Global step 100 Train loss 1.25 on epoch=1
05/22/2022 21:40:27 - INFO - __main__ - Global step 100 Train loss 1.71 Classification-F1 0.2478712461372415 on epoch=1
05/22/2022 21:40:27 - INFO - __main__ - Saving model with best Classification-F1: 0.0662344430890384 -> 0.2478712461372415 on epoch=1, global_step=100
05/22/2022 21:40:30 - INFO - __main__ - Step 110 Global step 110 Train loss 1.20 on epoch=1
05/22/2022 21:40:33 - INFO - __main__ - Step 120 Global step 120 Train loss 1.13 on epoch=2
05/22/2022 21:40:35 - INFO - __main__ - Step 130 Global step 130 Train loss 1.10 on epoch=2
05/22/2022 21:40:38 - INFO - __main__ - Step 140 Global step 140 Train loss 1.03 on epoch=2
05/22/2022 21:40:40 - INFO - __main__ - Step 150 Global step 150 Train loss 1.00 on epoch=2
05/22/2022 21:41:17 - INFO - __main__ - Global step 150 Train loss 1.09 Classification-F1 0.33424630436988895 on epoch=2
05/22/2022 21:41:17 - INFO - __main__ - Saving model with best Classification-F1: 0.2478712461372415 -> 0.33424630436988895 on epoch=2, global_step=150
05/22/2022 21:41:19 - INFO - __main__ - Step 160 Global step 160 Train loss 0.90 on epoch=2
05/22/2022 21:41:22 - INFO - __main__ - Step 170 Global step 170 Train loss 0.92 on epoch=3
05/22/2022 21:41:25 - INFO - __main__ - Step 180 Global step 180 Train loss 0.83 on epoch=3
05/22/2022 21:41:27 - INFO - __main__ - Step 190 Global step 190 Train loss 0.85 on epoch=3
05/22/2022 21:41:30 - INFO - __main__ - Step 200 Global step 200 Train loss 0.75 on epoch=3
05/22/2022 21:42:10 - INFO - __main__ - Global step 200 Train loss 0.85 Classification-F1 0.3899922794850766 on epoch=3
05/22/2022 21:42:10 - INFO - __main__ - Saving model with best Classification-F1: 0.33424630436988895 -> 0.3899922794850766 on epoch=3, global_step=200
05/22/2022 21:42:12 - INFO - __main__ - Step 210 Global step 210 Train loss 0.76 on epoch=3
05/22/2022 21:42:15 - INFO - __main__ - Step 220 Global step 220 Train loss 0.82 on epoch=3
05/22/2022 21:42:18 - INFO - __main__ - Step 230 Global step 230 Train loss 0.74 on epoch=4
05/22/2022 21:42:20 - INFO - __main__ - Step 240 Global step 240 Train loss 0.60 on epoch=4
05/22/2022 21:42:23 - INFO - __main__ - Step 250 Global step 250 Train loss 0.69 on epoch=4
05/22/2022 21:43:00 - INFO - __main__ - Global step 250 Train loss 0.72 Classification-F1 0.4648532369643777 on epoch=4
05/22/2022 21:43:00 - INFO - __main__ - Saving model with best Classification-F1: 0.3899922794850766 -> 0.4648532369643777 on epoch=4, global_step=250
05/22/2022 21:43:02 - INFO - __main__ - Step 260 Global step 260 Train loss 0.72 on epoch=4
05/22/2022 21:43:05 - INFO - __main__ - Step 270 Global step 270 Train loss 0.55 on epoch=4
05/22/2022 21:43:08 - INFO - __main__ - Step 280 Global step 280 Train loss 0.66 on epoch=4
05/22/2022 21:43:10 - INFO - __main__ - Step 290 Global step 290 Train loss 0.49 on epoch=5
05/22/2022 21:43:13 - INFO - __main__ - Step 300 Global step 300 Train loss 0.53 on epoch=5
05/22/2022 21:43:48 - INFO - __main__ - Global step 300 Train loss 0.59 Classification-F1 0.43655443752681894 on epoch=5
05/22/2022 21:43:50 - INFO - __main__ - Step 310 Global step 310 Train loss 0.61 on epoch=5
05/22/2022 21:43:53 - INFO - __main__ - Step 320 Global step 320 Train loss 0.54 on epoch=5
05/22/2022 21:43:55 - INFO - __main__ - Step 330 Global step 330 Train loss 0.64 on epoch=5
05/22/2022 21:43:58 - INFO - __main__ - Step 340 Global step 340 Train loss 0.54 on epoch=6
05/22/2022 21:44:01 - INFO - __main__ - Step 350 Global step 350 Train loss 0.40 on epoch=6
05/22/2022 21:44:36 - INFO - __main__ - Global step 350 Train loss 0.55 Classification-F1 0.42007684406148826 on epoch=6
05/22/2022 21:44:38 - INFO - __main__ - Step 360 Global step 360 Train loss 0.54 on epoch=6
05/22/2022 21:44:41 - INFO - __main__ - Step 370 Global step 370 Train loss 0.48 on epoch=6
05/22/2022 21:44:44 - INFO - __main__ - Step 380 Global step 380 Train loss 0.45 on epoch=6
05/22/2022 21:44:46 - INFO - __main__ - Step 390 Global step 390 Train loss 0.52 on epoch=6
05/22/2022 21:44:49 - INFO - __main__ - Step 400 Global step 400 Train loss 0.40 on epoch=7
05/22/2022 21:45:18 - INFO - __main__ - Global step 400 Train loss 0.48 Classification-F1 0.4586416607977324 on epoch=7
05/22/2022 21:45:21 - INFO - __main__ - Step 410 Global step 410 Train loss 0.52 on epoch=7
05/22/2022 21:45:23 - INFO - __main__ - Step 420 Global step 420 Train loss 0.51 on epoch=7
05/22/2022 21:45:26 - INFO - __main__ - Step 430 Global step 430 Train loss 0.40 on epoch=7
05/22/2022 21:45:28 - INFO - __main__ - Step 440 Global step 440 Train loss 0.46 on epoch=7
05/22/2022 21:45:31 - INFO - __main__ - Step 450 Global step 450 Train loss 0.39 on epoch=8
05/22/2022 21:46:00 - INFO - __main__ - Global step 450 Train loss 0.46 Classification-F1 0.33334129849117233 on epoch=8
05/22/2022 21:46:03 - INFO - __main__ - Step 460 Global step 460 Train loss 0.42 on epoch=8
05/22/2022 21:46:05 - INFO - __main__ - Step 470 Global step 470 Train loss 0.41 on epoch=8
05/22/2022 21:46:08 - INFO - __main__ - Step 480 Global step 480 Train loss 0.43 on epoch=8
05/22/2022 21:46:10 - INFO - __main__ - Step 490 Global step 490 Train loss 0.37 on epoch=8
05/22/2022 21:46:13 - INFO - __main__ - Step 500 Global step 500 Train loss 0.41 on epoch=8
05/22/2022 21:46:42 - INFO - __main__ - Global step 500 Train loss 0.41 Classification-F1 0.5680280631337128 on epoch=8
05/22/2022 21:46:42 - INFO - __main__ - Saving model with best Classification-F1: 0.4648532369643777 -> 0.5680280631337128 on epoch=8, global_step=500
05/22/2022 21:46:45 - INFO - __main__ - Step 510 Global step 510 Train loss 0.34 on epoch=9
05/22/2022 21:46:48 - INFO - __main__ - Step 520 Global step 520 Train loss 0.33 on epoch=9
05/22/2022 21:46:50 - INFO - __main__ - Step 530 Global step 530 Train loss 0.39 on epoch=9
05/22/2022 21:46:53 - INFO - __main__ - Step 540 Global step 540 Train loss 0.36 on epoch=9
05/22/2022 21:46:56 - INFO - __main__ - Step 550 Global step 550 Train loss 0.28 on epoch=9
05/22/2022 21:47:23 - INFO - __main__ - Global step 550 Train loss 0.34 Classification-F1 0.79974829048392 on epoch=9
05/22/2022 21:47:23 - INFO - __main__ - Saving model with best Classification-F1: 0.5680280631337128 -> 0.79974829048392 on epoch=9, global_step=550
05/22/2022 21:47:26 - INFO - __main__ - Step 560 Global step 560 Train loss 0.32 on epoch=9
05/22/2022 21:47:28 - INFO - __main__ - Step 570 Global step 570 Train loss 0.29 on epoch=10
05/22/2022 21:47:31 - INFO - __main__ - Step 580 Global step 580 Train loss 0.33 on epoch=10
05/22/2022 21:47:34 - INFO - __main__ - Step 590 Global step 590 Train loss 0.33 on epoch=10
05/22/2022 21:47:36 - INFO - __main__ - Step 600 Global step 600 Train loss 0.25 on epoch=10
05/22/2022 21:48:03 - INFO - __main__ - Global step 600 Train loss 0.31 Classification-F1 0.6577372797115867 on epoch=10
05/22/2022 21:48:06 - INFO - __main__ - Step 610 Global step 610 Train loss 0.34 on epoch=10
05/22/2022 21:48:09 - INFO - __main__ - Step 620 Global step 620 Train loss 0.31 on epoch=11
05/22/2022 21:48:11 - INFO - __main__ - Step 630 Global step 630 Train loss 0.26 on epoch=11
05/22/2022 21:48:14 - INFO - __main__ - Step 640 Global step 640 Train loss 0.38 on epoch=11
05/22/2022 21:48:16 - INFO - __main__ - Step 650 Global step 650 Train loss 0.27 on epoch=11
05/22/2022 21:48:44 - INFO - __main__ - Global step 650 Train loss 0.31 Classification-F1 0.5808974016983899 on epoch=11
05/22/2022 21:48:47 - INFO - __main__ - Step 660 Global step 660 Train loss 0.24 on epoch=11
05/22/2022 21:48:50 - INFO - __main__ - Step 670 Global step 670 Train loss 0.36 on epoch=11
05/22/2022 21:48:52 - INFO - __main__ - Step 680 Global step 680 Train loss 0.28 on epoch=12
05/22/2022 21:48:55 - INFO - __main__ - Step 690 Global step 690 Train loss 0.33 on epoch=12
05/22/2022 21:48:57 - INFO - __main__ - Step 700 Global step 700 Train loss 0.25 on epoch=12
05/22/2022 21:49:27 - INFO - __main__ - Global step 700 Train loss 0.29 Classification-F1 0.5742197579165156 on epoch=12
05/22/2022 21:49:30 - INFO - __main__ - Step 710 Global step 710 Train loss 0.23 on epoch=12
05/22/2022 21:49:32 - INFO - __main__ - Step 720 Global step 720 Train loss 0.29 on epoch=12
05/22/2022 21:49:35 - INFO - __main__ - Step 730 Global step 730 Train loss 0.24 on epoch=13
05/22/2022 21:49:37 - INFO - __main__ - Step 740 Global step 740 Train loss 0.19 on epoch=13
05/22/2022 21:49:40 - INFO - __main__ - Step 750 Global step 750 Train loss 0.25 on epoch=13
05/22/2022 21:50:08 - INFO - __main__ - Global step 750 Train loss 0.24 Classification-F1 0.6024957513887449 on epoch=13
05/22/2022 21:50:11 - INFO - __main__ - Step 760 Global step 760 Train loss 0.27 on epoch=13
05/22/2022 21:50:14 - INFO - __main__ - Step 770 Global step 770 Train loss 0.19 on epoch=13
05/22/2022 21:50:16 - INFO - __main__ - Step 780 Global step 780 Train loss 0.22 on epoch=13
05/22/2022 21:50:19 - INFO - __main__ - Step 790 Global step 790 Train loss 0.25 on epoch=14
05/22/2022 21:50:21 - INFO - __main__ - Step 800 Global step 800 Train loss 0.18 on epoch=14
05/22/2022 21:50:50 - INFO - __main__ - Global step 800 Train loss 0.22 Classification-F1 0.6191094136882107 on epoch=14
05/22/2022 21:50:53 - INFO - __main__ - Step 810 Global step 810 Train loss 0.18 on epoch=14
05/22/2022 21:50:55 - INFO - __main__ - Step 820 Global step 820 Train loss 0.25 on epoch=14
05/22/2022 21:50:58 - INFO - __main__ - Step 830 Global step 830 Train loss 0.15 on epoch=14
05/22/2022 21:51:01 - INFO - __main__ - Step 840 Global step 840 Train loss 0.22 on epoch=14
05/22/2022 21:51:03 - INFO - __main__ - Step 850 Global step 850 Train loss 0.16 on epoch=15
05/22/2022 21:51:30 - INFO - __main__ - Global step 850 Train loss 0.19 Classification-F1 0.5870749794601807 on epoch=15
05/22/2022 21:51:33 - INFO - __main__ - Step 860 Global step 860 Train loss 0.17 on epoch=15
05/22/2022 21:51:35 - INFO - __main__ - Step 870 Global step 870 Train loss 0.23 on epoch=15
05/22/2022 21:51:38 - INFO - __main__ - Step 880 Global step 880 Train loss 0.22 on epoch=15
05/22/2022 21:51:40 - INFO - __main__ - Step 890 Global step 890 Train loss 0.17 on epoch=15
05/22/2022 21:51:43 - INFO - __main__ - Step 900 Global step 900 Train loss 0.18 on epoch=16
05/22/2022 21:52:11 - INFO - __main__ - Global step 900 Train loss 0.19 Classification-F1 0.6134063739402527 on epoch=16
05/22/2022 21:52:13 - INFO - __main__ - Step 910 Global step 910 Train loss 0.14 on epoch=16
05/22/2022 21:52:16 - INFO - __main__ - Step 920 Global step 920 Train loss 0.18 on epoch=16
05/22/2022 21:52:19 - INFO - __main__ - Step 930 Global step 930 Train loss 0.16 on epoch=16
05/22/2022 21:52:21 - INFO - __main__ - Step 940 Global step 940 Train loss 0.14 on epoch=16
05/22/2022 21:52:24 - INFO - __main__ - Step 950 Global step 950 Train loss 0.17 on epoch=16
05/22/2022 21:52:55 - INFO - __main__ - Global step 950 Train loss 0.16 Classification-F1 0.9050824750973229 on epoch=16
05/22/2022 21:52:55 - INFO - __main__ - Saving model with best Classification-F1: 0.79974829048392 -> 0.9050824750973229 on epoch=16, global_step=950
05/22/2022 21:52:57 - INFO - __main__ - Step 960 Global step 960 Train loss 0.15 on epoch=17
05/22/2022 21:53:00 - INFO - __main__ - Step 970 Global step 970 Train loss 0.15 on epoch=17
05/22/2022 21:53:02 - INFO - __main__ - Step 980 Global step 980 Train loss 0.14 on epoch=17
05/22/2022 21:53:05 - INFO - __main__ - Step 990 Global step 990 Train loss 0.08 on epoch=17
05/22/2022 21:53:08 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.17 on epoch=17
05/22/2022 21:53:34 - INFO - __main__ - Global step 1000 Train loss 0.14 Classification-F1 0.5359816083922296 on epoch=17
05/22/2022 21:53:37 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.11 on epoch=18
05/22/2022 21:53:40 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.13 on epoch=18
05/22/2022 21:53:42 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.12 on epoch=18
05/22/2022 21:53:45 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.20 on epoch=18
05/22/2022 21:53:47 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.13 on epoch=18
05/22/2022 21:54:14 - INFO - __main__ - Global step 1050 Train loss 0.14 Classification-F1 0.4863549197960706 on epoch=18
05/22/2022 21:54:17 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.15 on epoch=18
05/22/2022 21:54:20 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.12 on epoch=19
05/22/2022 21:54:22 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.15 on epoch=19
05/22/2022 21:54:25 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.11 on epoch=19
05/22/2022 21:54:28 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.13 on epoch=19
05/22/2022 21:54:56 - INFO - __main__ - Global step 1100 Train loss 0.13 Classification-F1 0.5782485070477332 on epoch=19
05/22/2022 21:54:58 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.11 on epoch=19
05/22/2022 21:55:01 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.12 on epoch=19
05/22/2022 21:55:03 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.12 on epoch=20
05/22/2022 21:55:06 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.16 on epoch=20
05/22/2022 21:55:09 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.11 on epoch=20
05/22/2022 21:55:38 - INFO - __main__ - Global step 1150 Train loss 0.12 Classification-F1 0.6564769035032607 on epoch=20
05/22/2022 21:55:40 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.12 on epoch=20
05/22/2022 21:55:43 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.08 on epoch=20
05/22/2022 21:55:46 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.13 on epoch=21
05/22/2022 21:55:48 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.07 on epoch=21
05/22/2022 21:55:51 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.12 on epoch=21
05/22/2022 21:56:20 - INFO - __main__ - Global step 1200 Train loss 0.10 Classification-F1 0.6189705437394318 on epoch=21
05/22/2022 21:56:22 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.09 on epoch=21
05/22/2022 21:56:25 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.07 on epoch=21
05/22/2022 21:56:28 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.11 on epoch=21
05/22/2022 21:56:30 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.09 on epoch=22
05/22/2022 21:56:33 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.10 on epoch=22
05/22/2022 21:57:02 - INFO - __main__ - Global step 1250 Train loss 0.09 Classification-F1 0.5751553450375961 on epoch=22
05/22/2022 21:57:05 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.11 on epoch=22
05/22/2022 21:57:08 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.07 on epoch=22
05/22/2022 21:57:10 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.07 on epoch=22
05/22/2022 21:57:13 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.06 on epoch=23
05/22/2022 21:57:16 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.08 on epoch=23
05/22/2022 21:57:44 - INFO - __main__ - Global step 1300 Train loss 0.08 Classification-F1 0.6286778054058217 on epoch=23
05/22/2022 21:57:46 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.06 on epoch=23
05/22/2022 21:57:49 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.06 on epoch=23
05/22/2022 21:57:51 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.10 on epoch=23
05/22/2022 21:57:54 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.05 on epoch=23
05/22/2022 21:57:57 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.06 on epoch=24
05/22/2022 21:58:24 - INFO - __main__ - Global step 1350 Train loss 0.07 Classification-F1 0.6972946862207635 on epoch=24
05/22/2022 21:58:27 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.07 on epoch=24
05/22/2022 21:58:29 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.11 on epoch=24
05/22/2022 21:58:32 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.12 on epoch=24
05/22/2022 21:58:34 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.05 on epoch=24
05/22/2022 21:58:37 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.07 on epoch=24
05/22/2022 21:59:05 - INFO - __main__ - Global step 1400 Train loss 0.08 Classification-F1 0.7761154177551228 on epoch=24
05/22/2022 21:59:07 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.09 on epoch=25
05/22/2022 21:59:10 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.08 on epoch=25
05/22/2022 21:59:12 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.07 on epoch=25
05/22/2022 21:59:15 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.06 on epoch=25
05/22/2022 21:59:18 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.11 on epoch=25
05/22/2022 21:59:45 - INFO - __main__ - Global step 1450 Train loss 0.08 Classification-F1 0.6822405250910857 on epoch=25
05/22/2022 21:59:48 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.10 on epoch=26
05/22/2022 21:59:51 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.03 on epoch=26
05/22/2022 21:59:53 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.09 on epoch=26
05/22/2022 21:59:56 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.04 on epoch=26
05/22/2022 21:59:58 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.04 on epoch=26
05/22/2022 22:00:26 - INFO - __main__ - Global step 1500 Train loss 0.06 Classification-F1 0.9162419684634205 on epoch=26
05/22/2022 22:00:26 - INFO - __main__ - Saving model with best Classification-F1: 0.9050824750973229 -> 0.9162419684634205 on epoch=26, global_step=1500
05/22/2022 22:00:29 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.15 on epoch=26
05/22/2022 22:00:31 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.05 on epoch=27
05/22/2022 22:00:34 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.08 on epoch=27
05/22/2022 22:00:36 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.08 on epoch=27
05/22/2022 22:00:39 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.11 on epoch=27
05/22/2022 22:01:03 - INFO - __main__ - Global step 1550 Train loss 0.09 Classification-F1 0.7346693932089796 on epoch=27
05/22/2022 22:01:06 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.11 on epoch=27
05/22/2022 22:01:08 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.04 on epoch=28
05/22/2022 22:01:11 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.05 on epoch=28
05/22/2022 22:01:14 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.06 on epoch=28
05/22/2022 22:01:16 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.07 on epoch=28
05/22/2022 22:01:46 - INFO - __main__ - Global step 1600 Train loss 0.07 Classification-F1 0.7575853147692272 on epoch=28
05/22/2022 22:01:49 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.06 on epoch=28
05/22/2022 22:01:52 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.10 on epoch=28
05/22/2022 22:01:54 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.05 on epoch=29
05/22/2022 22:01:57 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.04 on epoch=29
05/22/2022 22:01:59 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.12 on epoch=29
05/22/2022 22:02:25 - INFO - __main__ - Global step 1650 Train loss 0.07 Classification-F1 0.5058496120865624 on epoch=29
05/22/2022 22:02:28 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.08 on epoch=29
05/22/2022 22:02:30 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.05 on epoch=29
05/22/2022 22:02:33 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.12 on epoch=29
05/22/2022 22:02:36 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.09 on epoch=30
05/22/2022 22:02:38 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.11 on epoch=30
05/22/2022 22:03:04 - INFO - __main__ - Global step 1700 Train loss 0.09 Classification-F1 0.5862783551968227 on epoch=30
05/22/2022 22:03:07 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.12 on epoch=30
05/22/2022 22:03:09 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.09 on epoch=30
05/22/2022 22:03:12 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.07 on epoch=30
05/22/2022 22:03:15 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.07 on epoch=31
05/22/2022 22:03:17 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.06 on epoch=31
05/22/2022 22:03:43 - INFO - __main__ - Global step 1750 Train loss 0.08 Classification-F1 0.6047163504898476 on epoch=31
05/22/2022 22:03:46 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.10 on epoch=31
05/22/2022 22:03:48 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.10 on epoch=31
05/22/2022 22:03:51 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.09 on epoch=31
05/22/2022 22:03:54 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.04 on epoch=31
05/22/2022 22:03:56 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.06 on epoch=32
05/22/2022 22:04:24 - INFO - __main__ - Global step 1800 Train loss 0.08 Classification-F1 0.5956601235769823 on epoch=32
05/22/2022 22:04:26 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.04 on epoch=32
05/22/2022 22:04:29 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=32
05/22/2022 22:04:32 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.06 on epoch=32
05/22/2022 22:04:34 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.04 on epoch=32
05/22/2022 22:04:37 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.07 on epoch=33
05/22/2022 22:05:03 - INFO - __main__ - Global step 1850 Train loss 0.05 Classification-F1 0.7145503129631742 on epoch=33
05/22/2022 22:05:05 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.07 on epoch=33
05/22/2022 22:05:08 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.04 on epoch=33
05/22/2022 22:05:11 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.05 on epoch=33
05/22/2022 22:05:13 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.08 on epoch=33
05/22/2022 22:05:16 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=33
05/22/2022 22:05:41 - INFO - __main__ - Global step 1900 Train loss 0.05 Classification-F1 0.6285625755044819 on epoch=33
05/22/2022 22:05:43 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.05 on epoch=34
05/22/2022 22:05:46 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=34
05/22/2022 22:05:48 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.06 on epoch=34
05/22/2022 22:05:51 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.04 on epoch=34
05/22/2022 22:05:54 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.03 on epoch=34
05/22/2022 22:06:20 - INFO - __main__ - Global step 1950 Train loss 0.04 Classification-F1 0.6872320551387117 on epoch=34
05/22/2022 22:06:22 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.04 on epoch=34
05/22/2022 22:06:25 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=35
05/22/2022 22:06:27 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.08 on epoch=35
05/22/2022 22:06:30 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.06 on epoch=35
05/22/2022 22:06:33 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.05 on epoch=35
05/22/2022 22:06:58 - INFO - __main__ - Global step 2000 Train loss 0.05 Classification-F1 0.7614296808539829 on epoch=35
05/22/2022 22:07:01 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.06 on epoch=35
05/22/2022 22:07:04 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.04 on epoch=36
05/22/2022 22:07:06 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.03 on epoch=36
05/22/2022 22:07:09 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=36
05/22/2022 22:07:12 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.03 on epoch=36
05/22/2022 22:07:37 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.6666420265173612 on epoch=36
05/22/2022 22:07:39 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.04 on epoch=36
05/22/2022 22:07:42 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.13 on epoch=36
05/22/2022 22:07:45 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.07 on epoch=37
05/22/2022 22:07:47 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.04 on epoch=37
05/22/2022 22:07:50 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=37
05/22/2022 22:08:15 - INFO - __main__ - Global step 2100 Train loss 0.06 Classification-F1 0.810059297710155 on epoch=37
05/22/2022 22:08:18 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.06 on epoch=37
05/22/2022 22:08:20 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.10 on epoch=37
05/22/2022 22:08:23 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.04 on epoch=38
05/22/2022 22:08:26 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=38
05/22/2022 22:08:28 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.04 on epoch=38
05/22/2022 22:08:54 - INFO - __main__ - Global step 2150 Train loss 0.06 Classification-F1 0.7659796218979138 on epoch=38
05/22/2022 22:08:57 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.04 on epoch=38
05/22/2022 22:08:59 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.05 on epoch=38
05/22/2022 22:09:02 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.04 on epoch=38
05/22/2022 22:09:05 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=39
05/22/2022 22:09:07 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.04 on epoch=39
05/22/2022 22:09:32 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.8418848921604376 on epoch=39
05/22/2022 22:09:35 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.06 on epoch=39
05/22/2022 22:09:37 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.06 on epoch=39
05/22/2022 22:09:40 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.03 on epoch=39
05/22/2022 22:09:42 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.05 on epoch=39
05/22/2022 22:09:45 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=40
05/22/2022 22:10:11 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.794455377120167 on epoch=40
05/22/2022 22:10:13 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.04 on epoch=40
05/22/2022 22:10:16 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=40
05/22/2022 22:10:18 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.05 on epoch=40
05/22/2022 22:10:21 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.04 on epoch=40
05/22/2022 22:10:24 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=41
05/22/2022 22:10:49 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.6670183563113665 on epoch=41
05/22/2022 22:10:52 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.11 on epoch=41
05/22/2022 22:10:54 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.07 on epoch=41
05/22/2022 22:10:57 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.04 on epoch=41
05/22/2022 22:10:59 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.05 on epoch=41
05/22/2022 22:11:02 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.06 on epoch=41
05/22/2022 22:11:29 - INFO - __main__ - Global step 2350 Train loss 0.06 Classification-F1 0.7137506134025264 on epoch=41
05/22/2022 22:11:31 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=42
05/22/2022 22:11:34 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=42
05/22/2022 22:11:37 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=42
05/22/2022 22:11:39 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=42
05/22/2022 22:11:42 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.03 on epoch=42
05/22/2022 22:12:08 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.7107759090402094 on epoch=42
05/22/2022 22:12:11 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=43
05/22/2022 22:12:13 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.03 on epoch=43
05/22/2022 22:12:16 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.04 on epoch=43
05/22/2022 22:12:18 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=43
05/22/2022 22:12:21 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.03 on epoch=43
05/22/2022 22:12:46 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.6401019787337772 on epoch=43
05/22/2022 22:12:49 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=43
05/22/2022 22:12:52 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=44
05/22/2022 22:12:54 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=44
05/22/2022 22:12:57 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.05 on epoch=44
05/22/2022 22:12:59 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=44
05/22/2022 22:13:27 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.7866986395936093 on epoch=44
05/22/2022 22:13:30 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=44
05/22/2022 22:13:32 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.07 on epoch=44
05/22/2022 22:13:35 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.05 on epoch=45
05/22/2022 22:13:38 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.08 on epoch=45
05/22/2022 22:13:40 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.06 on epoch=45
05/22/2022 22:14:05 - INFO - __main__ - Global step 2550 Train loss 0.05 Classification-F1 0.734082551850683 on epoch=45
05/22/2022 22:14:08 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.03 on epoch=45
05/22/2022 22:14:10 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.08 on epoch=45
05/22/2022 22:14:13 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.05 on epoch=46
05/22/2022 22:14:16 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=46
05/22/2022 22:14:18 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=46
05/22/2022 22:14:43 - INFO - __main__ - Global step 2600 Train loss 0.04 Classification-F1 0.7928719108262172 on epoch=46
05/22/2022 22:14:46 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.06 on epoch=46
05/22/2022 22:14:48 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.05 on epoch=46
05/22/2022 22:14:51 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.04 on epoch=46
05/22/2022 22:14:53 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.04 on epoch=47
05/22/2022 22:14:56 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.07 on epoch=47
05/22/2022 22:15:20 - INFO - __main__ - Global step 2650 Train loss 0.05 Classification-F1 0.670489508608174 on epoch=47
05/22/2022 22:15:23 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=47
05/22/2022 22:15:25 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=47
05/22/2022 22:15:28 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.05 on epoch=47
05/22/2022 22:15:31 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=48
05/22/2022 22:15:33 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=48
05/22/2022 22:15:58 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.6077986097660891 on epoch=48
05/22/2022 22:16:00 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.04 on epoch=48
05/22/2022 22:16:03 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.03 on epoch=48
05/22/2022 22:16:05 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.07 on epoch=48
05/22/2022 22:16:08 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=48
05/22/2022 22:16:11 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=49
05/22/2022 22:16:35 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.8060252875881089 on epoch=49
05/22/2022 22:16:37 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.03 on epoch=49
05/22/2022 22:16:40 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.04 on epoch=49
05/22/2022 22:16:42 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.03 on epoch=49
05/22/2022 22:16:45 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=49
05/22/2022 22:16:48 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=49
05/22/2022 22:17:11 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.7800940923165639 on epoch=49
05/22/2022 22:17:14 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=50
05/22/2022 22:17:16 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.05 on epoch=50
05/22/2022 22:17:19 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.03 on epoch=50
05/22/2022 22:17:22 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.04 on epoch=50
05/22/2022 22:17:24 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.05 on epoch=50
05/22/2022 22:17:49 - INFO - __main__ - Global step 2850 Train loss 0.04 Classification-F1 0.7261173200698176 on epoch=50
05/22/2022 22:17:52 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.06 on epoch=51
05/22/2022 22:17:54 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.03 on epoch=51
05/22/2022 22:17:57 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.05 on epoch=51
05/22/2022 22:18:00 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=51
05/22/2022 22:18:02 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.03 on epoch=51
05/22/2022 22:18:25 - INFO - __main__ - Global step 2900 Train loss 0.04 Classification-F1 0.610703841150867 on epoch=51
05/22/2022 22:18:28 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=51
05/22/2022 22:18:30 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=52
05/22/2022 22:18:33 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=52
05/22/2022 22:18:35 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.05 on epoch=52
05/22/2022 22:18:38 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=52
05/22/2022 22:19:03 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.6666746291296981 on epoch=52
05/22/2022 22:19:06 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=52
05/22/2022 22:19:08 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=53
05/22/2022 22:19:11 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=53
05/22/2022 22:19:14 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.03 on epoch=53
05/22/2022 22:19:16 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=53
05/22/2022 22:19:18 - INFO - __main__ - Start tokenizing ... 896 instances
05/22/2022 22:19:18 - INFO - __main__ - Printing 3 examples
05/22/2022 22:19:18 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/22/2022 22:19:18 - INFO - __main__ - ['Plant']
05/22/2022 22:19:18 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/22/2022 22:19:18 - INFO - __main__ - ['Plant']
05/22/2022 22:19:18 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/22/2022 22:19:18 - INFO - __main__ - ['Plant']
05/22/2022 22:19:18 - INFO - __main__ - Tokenizing Input ...
05/22/2022 22:19:18 - INFO - __main__ - Tokenizing Output ...
05/22/2022 22:19:19 - INFO - __main__ - Loaded 896 examples from train data
05/22/2022 22:19:19 - INFO - __main__ - Start tokenizing ... 896 instances
05/22/2022 22:19:19 - INFO - __main__ - Printing 3 examples
05/22/2022 22:19:19 - INFO - __main__ -  [dbpedia_14] Hardwickia is a genus of flowering plants in the legume family Fabaceae. It belongs to the sub family Caesalpinioideae.
05/22/2022 22:19:19 - INFO - __main__ - ['Plant']
05/22/2022 22:19:19 - INFO - __main__ -  [dbpedia_14] Eurybia eryngiifolia commonly known as the Thistleleaf Aster or Coyote-thistle Aster is an herbaceous perennial in the composite family. It is native to the eastern United States where it is only present along the Florida panhandle and the nearby areas of southern Alabama and Georgia.
05/22/2022 22:19:19 - INFO - __main__ - ['Plant']
05/22/2022 22:19:19 - INFO - __main__ -  [dbpedia_14] Petraeovitex is a genus of eight climbing shrubs species known to science of the Mint family Lamiaceae (formerly placed within Verbenaceae).Collectively they grow naturally in Borneo Peninsular Malaysia Sumatra the Philippines the Moluccas New Guinea Bismarck Archipelago the Solomon Islands and Cape York Peninsula Australia.
05/22/2022 22:19:19 - INFO - __main__ - ['Plant']
05/22/2022 22:19:19 - INFO - __main__ - Tokenizing Input ...
05/22/2022 22:19:20 - INFO - __main__ - Tokenizing Output ...
05/22/2022 22:19:20 - INFO - __main__ - Loaded 896 examples from dev data
05/22/2022 22:19:39 - INFO - __main__ - try to initialize prompt embeddings
05/22/2022 22:19:39 - INFO - __main__ - task name: dbpedia_14
05/22/2022 22:19:40 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 22:19:40 - INFO - __main__ - Starting training!
05/22/2022 22:19:40 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.6424299536100427 on epoch=53
05/22/2022 22:19:40 - INFO - __main__ - save last model!
05/22/2022 22:19:40 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/22/2022 22:19:40 - INFO - __main__ - Start tokenizing ... 3500 instances
05/22/2022 22:19:40 - INFO - __main__ - Printing 3 examples
05/22/2022 22:19:40 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/22/2022 22:19:40 - INFO - __main__ - ['Animal']
05/22/2022 22:19:40 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/22/2022 22:19:40 - INFO - __main__ - ['Animal']
05/22/2022 22:19:40 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/22/2022 22:19:40 - INFO - __main__ - ['Village']
05/22/2022 22:19:40 - INFO - __main__ - Tokenizing Input ...
05/22/2022 22:19:42 - INFO - __main__ - Tokenizing Output ...
05/22/2022 22:19:45 - INFO - __main__ - Loaded 3500 examples from test data
05/22/2022 22:21:48 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down64shot/singletask-dbpedia_14/dbpedia_14_64_21_0.3_8_predictions.txt
05/22/2022 22:21:48 - INFO - __main__ - Classification-F1 on test data: 0.5811
05/22/2022 22:21:49 - INFO - __main__ - prefix=dbpedia_14_64_21, lr=0.3, bsz=8, dev_performance=0.9162419684634205, test_performance=0.5811174165451173
05/22/2022 22:21:49 - INFO - __main__ - Running ... prefix=dbpedia_14_64_21, lr=0.2, bsz=8 ...
05/22/2022 22:21:50 - INFO - __main__ - Start tokenizing ... 896 instances
05/22/2022 22:21:50 - INFO - __main__ - Printing 3 examples
05/22/2022 22:21:50 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/22/2022 22:21:50 - INFO - __main__ - ['Plant']
05/22/2022 22:21:50 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/22/2022 22:21:50 - INFO - __main__ - ['Plant']
05/22/2022 22:21:50 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/22/2022 22:21:50 - INFO - __main__ - ['Plant']
05/22/2022 22:21:50 - INFO - __main__ - Tokenizing Input ...
05/22/2022 22:21:50 - INFO - __main__ - Tokenizing Output ...
05/22/2022 22:21:51 - INFO - __main__ - Loaded 896 examples from train data
05/22/2022 22:21:51 - INFO - __main__ - Start tokenizing ... 896 instances
05/22/2022 22:21:51 - INFO - __main__ - Printing 3 examples
05/22/2022 22:21:51 - INFO - __main__ -  [dbpedia_14] Hardwickia is a genus of flowering plants in the legume family Fabaceae. It belongs to the sub family Caesalpinioideae.
05/22/2022 22:21:51 - INFO - __main__ - ['Plant']
05/22/2022 22:21:51 - INFO - __main__ -  [dbpedia_14] Eurybia eryngiifolia commonly known as the Thistleleaf Aster or Coyote-thistle Aster is an herbaceous perennial in the composite family. It is native to the eastern United States where it is only present along the Florida panhandle and the nearby areas of southern Alabama and Georgia.
05/22/2022 22:21:51 - INFO - __main__ - ['Plant']
05/22/2022 22:21:51 - INFO - __main__ -  [dbpedia_14] Petraeovitex is a genus of eight climbing shrubs species known to science of the Mint family Lamiaceae (formerly placed within Verbenaceae).Collectively they grow naturally in Borneo Peninsular Malaysia Sumatra the Philippines the Moluccas New Guinea Bismarck Archipelago the Solomon Islands and Cape York Peninsula Australia.
05/22/2022 22:21:51 - INFO - __main__ - ['Plant']
05/22/2022 22:21:51 - INFO - __main__ - Tokenizing Input ...
05/22/2022 22:21:51 - INFO - __main__ - Tokenizing Output ...
05/22/2022 22:21:52 - INFO - __main__ - Loaded 896 examples from dev data
05/22/2022 22:22:08 - INFO - __main__ - try to initialize prompt embeddings
05/22/2022 22:22:08 - INFO - __main__ - task name: dbpedia_14
05/22/2022 22:22:09 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 22:22:09 - INFO - __main__ - Starting training!
05/22/2022 22:22:12 - INFO - __main__ - Step 10 Global step 10 Train loss 6.90 on epoch=0
05/22/2022 22:22:14 - INFO - __main__ - Step 20 Global step 20 Train loss 5.99 on epoch=0
05/22/2022 22:22:17 - INFO - __main__ - Step 30 Global step 30 Train loss 5.07 on epoch=0
05/22/2022 22:22:19 - INFO - __main__ - Step 40 Global step 40 Train loss 4.34 on epoch=0
05/22/2022 22:22:22 - INFO - __main__ - Step 50 Global step 50 Train loss 3.61 on epoch=0
05/22/2022 22:28:04 - INFO - __main__ - Global step 50 Train loss 5.18 Classification-F1 0.004876794058318534 on epoch=0
05/22/2022 22:28:04 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.004876794058318534 on epoch=0, global_step=50
05/22/2022 22:28:07 - INFO - __main__ - Step 60 Global step 60 Train loss 3.15 on epoch=1
05/22/2022 22:28:09 - INFO - __main__ - Step 70 Global step 70 Train loss 2.78 on epoch=1
05/22/2022 22:28:12 - INFO - __main__ - Step 80 Global step 80 Train loss 2.46 on epoch=1
05/22/2022 22:28:14 - INFO - __main__ - Step 90 Global step 90 Train loss 2.12 on epoch=1
05/22/2022 22:28:17 - INFO - __main__ - Step 100 Global step 100 Train loss 1.97 on epoch=1
05/22/2022 22:28:54 - INFO - __main__ - Global step 100 Train loss 2.50 Classification-F1 0.1456402610255692 on epoch=1
05/22/2022 22:28:54 - INFO - __main__ - Saving model with best Classification-F1: 0.004876794058318534 -> 0.1456402610255692 on epoch=1, global_step=100
05/22/2022 22:28:57 - INFO - __main__ - Step 110 Global step 110 Train loss 1.84 on epoch=1
05/22/2022 22:28:59 - INFO - __main__ - Step 120 Global step 120 Train loss 1.59 on epoch=2
05/22/2022 22:29:02 - INFO - __main__ - Step 130 Global step 130 Train loss 1.54 on epoch=2
05/22/2022 22:29:04 - INFO - __main__ - Step 140 Global step 140 Train loss 1.43 on epoch=2
05/22/2022 22:29:07 - INFO - __main__ - Step 150 Global step 150 Train loss 1.22 on epoch=2
05/22/2022 22:29:29 - INFO - __main__ - Global step 150 Train loss 1.52 Classification-F1 0.3140625223976732 on epoch=2
05/22/2022 22:29:29 - INFO - __main__ - Saving model with best Classification-F1: 0.1456402610255692 -> 0.3140625223976732 on epoch=2, global_step=150
05/22/2022 22:29:31 - INFO - __main__ - Step 160 Global step 160 Train loss 1.20 on epoch=2
05/22/2022 22:29:34 - INFO - __main__ - Step 170 Global step 170 Train loss 1.29 on epoch=3
05/22/2022 22:29:37 - INFO - __main__ - Step 180 Global step 180 Train loss 1.10 on epoch=3
05/22/2022 22:29:39 - INFO - __main__ - Step 190 Global step 190 Train loss 1.08 on epoch=3
05/22/2022 22:29:42 - INFO - __main__ - Step 200 Global step 200 Train loss 1.06 on epoch=3
05/22/2022 22:30:09 - INFO - __main__ - Global step 200 Train loss 1.15 Classification-F1 0.3261193613507057 on epoch=3
05/22/2022 22:30:09 - INFO - __main__ - Saving model with best Classification-F1: 0.3140625223976732 -> 0.3261193613507057 on epoch=3, global_step=200
05/22/2022 22:30:12 - INFO - __main__ - Step 210 Global step 210 Train loss 0.97 on epoch=3
05/22/2022 22:30:14 - INFO - __main__ - Step 220 Global step 220 Train loss 0.89 on epoch=3
05/22/2022 22:30:17 - INFO - __main__ - Step 230 Global step 230 Train loss 0.94 on epoch=4
05/22/2022 22:30:20 - INFO - __main__ - Step 240 Global step 240 Train loss 0.84 on epoch=4
05/22/2022 22:30:22 - INFO - __main__ - Step 250 Global step 250 Train loss 0.85 on epoch=4
05/22/2022 22:30:50 - INFO - __main__ - Global step 250 Train loss 0.90 Classification-F1 0.44776552735943453 on epoch=4
05/22/2022 22:30:50 - INFO - __main__ - Saving model with best Classification-F1: 0.3261193613507057 -> 0.44776552735943453 on epoch=4, global_step=250
05/22/2022 22:30:52 - INFO - __main__ - Step 260 Global step 260 Train loss 0.87 on epoch=4
05/22/2022 22:30:55 - INFO - __main__ - Step 270 Global step 270 Train loss 0.85 on epoch=4
05/22/2022 22:30:57 - INFO - __main__ - Step 280 Global step 280 Train loss 0.88 on epoch=4
05/22/2022 22:31:00 - INFO - __main__ - Step 290 Global step 290 Train loss 0.71 on epoch=5
05/22/2022 22:31:03 - INFO - __main__ - Step 300 Global step 300 Train loss 0.71 on epoch=5
05/22/2022 22:31:31 - INFO - __main__ - Global step 300 Train loss 0.80 Classification-F1 0.3679498548395548 on epoch=5
05/22/2022 22:31:34 - INFO - __main__ - Step 310 Global step 310 Train loss 0.72 on epoch=5
05/22/2022 22:31:36 - INFO - __main__ - Step 320 Global step 320 Train loss 0.72 on epoch=5
05/22/2022 22:31:39 - INFO - __main__ - Step 330 Global step 330 Train loss 0.80 on epoch=5
05/22/2022 22:31:42 - INFO - __main__ - Step 340 Global step 340 Train loss 0.77 on epoch=6
05/22/2022 22:31:44 - INFO - __main__ - Step 350 Global step 350 Train loss 0.64 on epoch=6
05/22/2022 22:32:14 - INFO - __main__ - Global step 350 Train loss 0.73 Classification-F1 0.3887417501013969 on epoch=6
05/22/2022 22:32:16 - INFO - __main__ - Step 360 Global step 360 Train loss 0.73 on epoch=6
05/22/2022 22:32:19 - INFO - __main__ - Step 370 Global step 370 Train loss 0.68 on epoch=6
05/22/2022 22:32:22 - INFO - __main__ - Step 380 Global step 380 Train loss 0.64 on epoch=6
05/22/2022 22:32:24 - INFO - __main__ - Step 390 Global step 390 Train loss 0.67 on epoch=6
05/22/2022 22:32:27 - INFO - __main__ - Step 400 Global step 400 Train loss 0.57 on epoch=7
05/22/2022 22:32:55 - INFO - __main__ - Global step 400 Train loss 0.66 Classification-F1 0.4764835877159719 on epoch=7
05/22/2022 22:32:55 - INFO - __main__ - Saving model with best Classification-F1: 0.44776552735943453 -> 0.4764835877159719 on epoch=7, global_step=400
05/22/2022 22:32:57 - INFO - __main__ - Step 410 Global step 410 Train loss 0.64 on epoch=7
05/22/2022 22:33:00 - INFO - __main__ - Step 420 Global step 420 Train loss 0.63 on epoch=7
05/22/2022 22:33:03 - INFO - __main__ - Step 430 Global step 430 Train loss 0.61 on epoch=7
05/22/2022 22:33:05 - INFO - __main__ - Step 440 Global step 440 Train loss 0.58 on epoch=7
05/22/2022 22:33:08 - INFO - __main__ - Step 450 Global step 450 Train loss 0.57 on epoch=8
05/22/2022 22:33:38 - INFO - __main__ - Global step 450 Train loss 0.60 Classification-F1 0.4511114327415071 on epoch=8
05/22/2022 22:33:40 - INFO - __main__ - Step 460 Global step 460 Train loss 0.62 on epoch=8
05/22/2022 22:33:43 - INFO - __main__ - Step 470 Global step 470 Train loss 0.50 on epoch=8
05/22/2022 22:33:45 - INFO - __main__ - Step 480 Global step 480 Train loss 0.56 on epoch=8
05/22/2022 22:33:48 - INFO - __main__ - Step 490 Global step 490 Train loss 0.65 on epoch=8
05/22/2022 22:33:51 - INFO - __main__ - Step 500 Global step 500 Train loss 0.54 on epoch=8
05/22/2022 22:34:20 - INFO - __main__ - Global step 500 Train loss 0.57 Classification-F1 0.5776090646366622 on epoch=8
05/22/2022 22:34:20 - INFO - __main__ - Saving model with best Classification-F1: 0.4764835877159719 -> 0.5776090646366622 on epoch=8, global_step=500
05/22/2022 22:34:23 - INFO - __main__ - Step 510 Global step 510 Train loss 0.53 on epoch=9
05/22/2022 22:34:25 - INFO - __main__ - Step 520 Global step 520 Train loss 0.51 on epoch=9
05/22/2022 22:34:28 - INFO - __main__ - Step 530 Global step 530 Train loss 0.52 on epoch=9
05/22/2022 22:34:30 - INFO - __main__ - Step 540 Global step 540 Train loss 0.60 on epoch=9
05/22/2022 22:34:33 - INFO - __main__ - Step 550 Global step 550 Train loss 0.49 on epoch=9
05/22/2022 22:35:01 - INFO - __main__ - Global step 550 Train loss 0.53 Classification-F1 0.5834295700170719 on epoch=9
05/22/2022 22:35:02 - INFO - __main__ - Saving model with best Classification-F1: 0.5776090646366622 -> 0.5834295700170719 on epoch=9, global_step=550
05/22/2022 22:35:04 - INFO - __main__ - Step 560 Global step 560 Train loss 0.53 on epoch=9
05/22/2022 22:35:07 - INFO - __main__ - Step 570 Global step 570 Train loss 0.49 on epoch=10
05/22/2022 22:35:09 - INFO - __main__ - Step 580 Global step 580 Train loss 0.51 on epoch=10
05/22/2022 22:35:12 - INFO - __main__ - Step 590 Global step 590 Train loss 0.48 on epoch=10
05/22/2022 22:35:14 - INFO - __main__ - Step 600 Global step 600 Train loss 0.50 on epoch=10
05/22/2022 22:35:43 - INFO - __main__ - Global step 600 Train loss 0.50 Classification-F1 0.5586952142055434 on epoch=10
05/22/2022 22:35:45 - INFO - __main__ - Step 610 Global step 610 Train loss 0.44 on epoch=10
05/22/2022 22:35:48 - INFO - __main__ - Step 620 Global step 620 Train loss 0.55 on epoch=11
05/22/2022 22:35:50 - INFO - __main__ - Step 630 Global step 630 Train loss 0.39 on epoch=11
05/22/2022 22:35:53 - INFO - __main__ - Step 640 Global step 640 Train loss 0.39 on epoch=11
05/22/2022 22:35:56 - INFO - __main__ - Step 650 Global step 650 Train loss 0.52 on epoch=11
05/22/2022 22:36:25 - INFO - __main__ - Global step 650 Train loss 0.46 Classification-F1 0.5356399887799026 on epoch=11
05/22/2022 22:36:27 - INFO - __main__ - Step 660 Global step 660 Train loss 0.41 on epoch=11
05/22/2022 22:36:30 - INFO - __main__ - Step 670 Global step 670 Train loss 0.41 on epoch=11
05/22/2022 22:36:33 - INFO - __main__ - Step 680 Global step 680 Train loss 0.26 on epoch=12
05/22/2022 22:36:35 - INFO - __main__ - Step 690 Global step 690 Train loss 0.40 on epoch=12
05/22/2022 22:36:38 - INFO - __main__ - Step 700 Global step 700 Train loss 0.45 on epoch=12
05/22/2022 22:37:07 - INFO - __main__ - Global step 700 Train loss 0.38 Classification-F1 0.6503147057520794 on epoch=12
05/22/2022 22:37:07 - INFO - __main__ - Saving model with best Classification-F1: 0.5834295700170719 -> 0.6503147057520794 on epoch=12, global_step=700
05/22/2022 22:37:10 - INFO - __main__ - Step 710 Global step 710 Train loss 0.39 on epoch=12
05/22/2022 22:37:12 - INFO - __main__ - Step 720 Global step 720 Train loss 0.36 on epoch=12
05/22/2022 22:37:15 - INFO - __main__ - Step 730 Global step 730 Train loss 0.34 on epoch=13
05/22/2022 22:37:17 - INFO - __main__ - Step 740 Global step 740 Train loss 0.30 on epoch=13
05/22/2022 22:37:20 - INFO - __main__ - Step 750 Global step 750 Train loss 0.34 on epoch=13
05/22/2022 22:37:48 - INFO - __main__ - Global step 750 Train loss 0.35 Classification-F1 0.5451150882179028 on epoch=13
05/22/2022 22:37:50 - INFO - __main__ - Step 760 Global step 760 Train loss 0.31 on epoch=13
05/22/2022 22:37:53 - INFO - __main__ - Step 770 Global step 770 Train loss 0.34 on epoch=13
05/22/2022 22:37:55 - INFO - __main__ - Step 780 Global step 780 Train loss 0.33 on epoch=13
05/22/2022 22:37:58 - INFO - __main__ - Step 790 Global step 790 Train loss 0.32 on epoch=14
05/22/2022 22:38:01 - INFO - __main__ - Step 800 Global step 800 Train loss 0.29 on epoch=14
05/22/2022 22:38:28 - INFO - __main__ - Global step 800 Train loss 0.32 Classification-F1 0.5687516248383596 on epoch=14
05/22/2022 22:38:31 - INFO - __main__ - Step 810 Global step 810 Train loss 0.24 on epoch=14
05/22/2022 22:38:33 - INFO - __main__ - Step 820 Global step 820 Train loss 0.34 on epoch=14
05/22/2022 22:38:36 - INFO - __main__ - Step 830 Global step 830 Train loss 0.22 on epoch=14
05/22/2022 22:38:38 - INFO - __main__ - Step 840 Global step 840 Train loss 0.38 on epoch=14
05/22/2022 22:38:41 - INFO - __main__ - Step 850 Global step 850 Train loss 0.29 on epoch=15
05/22/2022 22:39:08 - INFO - __main__ - Global step 850 Train loss 0.29 Classification-F1 0.5986350831287949 on epoch=15
05/22/2022 22:39:11 - INFO - __main__ - Step 860 Global step 860 Train loss 0.23 on epoch=15
05/22/2022 22:39:13 - INFO - __main__ - Step 870 Global step 870 Train loss 0.28 on epoch=15
05/22/2022 22:39:16 - INFO - __main__ - Step 880 Global step 880 Train loss 0.29 on epoch=15
05/22/2022 22:39:18 - INFO - __main__ - Step 890 Global step 890 Train loss 0.26 on epoch=15
05/22/2022 22:39:21 - INFO - __main__ - Step 900 Global step 900 Train loss 0.24 on epoch=16
05/22/2022 22:39:51 - INFO - __main__ - Global step 900 Train loss 0.26 Classification-F1 0.5583146608145321 on epoch=16
05/22/2022 22:39:54 - INFO - __main__ - Step 910 Global step 910 Train loss 0.22 on epoch=16
05/22/2022 22:39:56 - INFO - __main__ - Step 920 Global step 920 Train loss 0.23 on epoch=16
05/22/2022 22:39:59 - INFO - __main__ - Step 930 Global step 930 Train loss 0.28 on epoch=16
05/22/2022 22:40:01 - INFO - __main__ - Step 940 Global step 940 Train loss 0.23 on epoch=16
05/22/2022 22:40:04 - INFO - __main__ - Step 950 Global step 950 Train loss 0.24 on epoch=16
05/22/2022 22:40:31 - INFO - __main__ - Global step 950 Train loss 0.24 Classification-F1 0.6375082411362886 on epoch=16
05/22/2022 22:40:34 - INFO - __main__ - Step 960 Global step 960 Train loss 0.16 on epoch=17
05/22/2022 22:40:36 - INFO - __main__ - Step 970 Global step 970 Train loss 0.22 on epoch=17
05/22/2022 22:40:39 - INFO - __main__ - Step 980 Global step 980 Train loss 0.21 on epoch=17
05/22/2022 22:40:42 - INFO - __main__ - Step 990 Global step 990 Train loss 0.27 on epoch=17
05/22/2022 22:40:44 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.26 on epoch=17
05/22/2022 22:41:13 - INFO - __main__ - Global step 1000 Train loss 0.22 Classification-F1 0.6458474551877446 on epoch=17
05/22/2022 22:41:16 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.23 on epoch=18
05/22/2022 22:41:18 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.25 on epoch=18
05/22/2022 22:41:21 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.20 on epoch=18
05/22/2022 22:41:23 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.22 on epoch=18
05/22/2022 22:41:26 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.20 on epoch=18
05/22/2022 22:41:54 - INFO - __main__ - Global step 1050 Train loss 0.22 Classification-F1 0.6123622416994976 on epoch=18
05/22/2022 22:41:57 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.24 on epoch=18
05/22/2022 22:41:59 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.18 on epoch=19
05/22/2022 22:42:02 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.16 on epoch=19
05/22/2022 22:42:04 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.14 on epoch=19
05/22/2022 22:42:07 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.21 on epoch=19
05/22/2022 22:42:37 - INFO - __main__ - Global step 1100 Train loss 0.19 Classification-F1 0.7885111685657993 on epoch=19
05/22/2022 22:42:37 - INFO - __main__ - Saving model with best Classification-F1: 0.6503147057520794 -> 0.7885111685657993 on epoch=19, global_step=1100
05/22/2022 22:42:39 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.15 on epoch=19
05/22/2022 22:42:42 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.20 on epoch=19
05/22/2022 22:42:44 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.20 on epoch=20
05/22/2022 22:42:47 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.12 on epoch=20
05/22/2022 22:42:49 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.19 on epoch=20
05/22/2022 22:43:16 - INFO - __main__ - Global step 1150 Train loss 0.17 Classification-F1 0.5800558109894197 on epoch=20
05/22/2022 22:43:18 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.19 on epoch=20
05/22/2022 22:43:21 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.18 on epoch=20
05/22/2022 22:43:23 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.18 on epoch=21
05/22/2022 22:43:26 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.14 on epoch=21
05/22/2022 22:43:29 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.20 on epoch=21
05/22/2022 22:43:56 - INFO - __main__ - Global step 1200 Train loss 0.18 Classification-F1 0.5179568746092104 on epoch=21
05/22/2022 22:43:59 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.20 on epoch=21
05/22/2022 22:44:01 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.16 on epoch=21
05/22/2022 22:44:04 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.23 on epoch=21
05/22/2022 22:44:06 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.16 on epoch=22
05/22/2022 22:44:09 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.19 on epoch=22
05/22/2022 22:44:37 - INFO - __main__ - Global step 1250 Train loss 0.19 Classification-F1 0.6186621997205493 on epoch=22
05/22/2022 22:44:40 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.18 on epoch=22
05/22/2022 22:44:42 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.08 on epoch=22
05/22/2022 22:44:45 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.23 on epoch=22
05/22/2022 22:44:48 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.13 on epoch=23
05/22/2022 22:44:50 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.15 on epoch=23
05/22/2022 22:45:18 - INFO - __main__ - Global step 1300 Train loss 0.15 Classification-F1 0.6415303651261595 on epoch=23
05/22/2022 22:45:21 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.19 on epoch=23
05/22/2022 22:45:24 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.17 on epoch=23
05/22/2022 22:45:26 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.16 on epoch=23
05/22/2022 22:45:29 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.14 on epoch=23
05/22/2022 22:45:31 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.14 on epoch=24
05/22/2022 22:45:59 - INFO - __main__ - Global step 1350 Train loss 0.16 Classification-F1 0.7162708273323404 on epoch=24
05/22/2022 22:46:01 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.21 on epoch=24
05/22/2022 22:46:04 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.14 on epoch=24
05/22/2022 22:46:06 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.10 on epoch=24
05/22/2022 22:46:09 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.11 on epoch=24
05/22/2022 22:46:11 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.17 on epoch=24
05/22/2022 22:46:37 - INFO - __main__ - Global step 1400 Train loss 0.15 Classification-F1 0.6574908680167194 on epoch=24
05/22/2022 22:46:40 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.12 on epoch=25
05/22/2022 22:46:42 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.10 on epoch=25
05/22/2022 22:46:45 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.15 on epoch=25
05/22/2022 22:46:47 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.15 on epoch=25
05/22/2022 22:46:50 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.12 on epoch=25
05/22/2022 22:47:17 - INFO - __main__ - Global step 1450 Train loss 0.13 Classification-F1 0.7162403843515971 on epoch=25
05/22/2022 22:47:19 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.11 on epoch=26
05/22/2022 22:47:22 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.08 on epoch=26
05/22/2022 22:47:24 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.11 on epoch=26
05/22/2022 22:47:27 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.11 on epoch=26
05/22/2022 22:47:30 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.15 on epoch=26
05/22/2022 22:47:55 - INFO - __main__ - Global step 1500 Train loss 0.11 Classification-F1 0.6554921487940163 on epoch=26
05/22/2022 22:47:58 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.12 on epoch=26
05/22/2022 22:48:01 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.12 on epoch=27
05/22/2022 22:48:03 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.10 on epoch=27
05/22/2022 22:48:06 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.11 on epoch=27
05/22/2022 22:48:08 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.11 on epoch=27
05/22/2022 22:48:34 - INFO - __main__ - Global step 1550 Train loss 0.11 Classification-F1 0.6234396964115729 on epoch=27
05/22/2022 22:48:36 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.12 on epoch=27
05/22/2022 22:48:39 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.09 on epoch=28
05/22/2022 22:48:41 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.07 on epoch=28
05/22/2022 22:48:44 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.09 on epoch=28
05/22/2022 22:48:46 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.12 on epoch=28
05/22/2022 22:49:14 - INFO - __main__ - Global step 1600 Train loss 0.10 Classification-F1 0.7619059617797082 on epoch=28
05/22/2022 22:49:16 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.17 on epoch=28
05/22/2022 22:49:19 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.08 on epoch=28
05/22/2022 22:49:21 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.15 on epoch=29
05/22/2022 22:49:24 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.09 on epoch=29
05/22/2022 22:49:27 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.08 on epoch=29
05/22/2022 22:49:54 - INFO - __main__ - Global step 1650 Train loss 0.12 Classification-F1 0.6378435723090117 on epoch=29
05/22/2022 22:49:56 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.06 on epoch=29
05/22/2022 22:49:59 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.09 on epoch=29
05/22/2022 22:50:01 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.10 on epoch=29
05/22/2022 22:50:04 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.09 on epoch=30
05/22/2022 22:50:06 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.09 on epoch=30
05/22/2022 22:50:35 - INFO - __main__ - Global step 1700 Train loss 0.09 Classification-F1 0.6972259532554349 on epoch=30
05/22/2022 22:50:38 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.08 on epoch=30
05/22/2022 22:50:40 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.10 on epoch=30
05/22/2022 22:50:43 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.08 on epoch=30
05/22/2022 22:50:45 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.11 on epoch=31
05/22/2022 22:50:48 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.08 on epoch=31
05/22/2022 22:51:15 - INFO - __main__ - Global step 1750 Train loss 0.09 Classification-F1 0.8325205542206061 on epoch=31
05/22/2022 22:51:15 - INFO - __main__ - Saving model with best Classification-F1: 0.7885111685657993 -> 0.8325205542206061 on epoch=31, global_step=1750
05/22/2022 22:51:18 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.13 on epoch=31
05/22/2022 22:51:20 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.06 on epoch=31
05/22/2022 22:51:23 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.09 on epoch=31
05/22/2022 22:51:26 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.07 on epoch=31
05/22/2022 22:51:28 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.05 on epoch=32
05/22/2022 22:51:55 - INFO - __main__ - Global step 1800 Train loss 0.08 Classification-F1 0.7289516845509839 on epoch=32
05/22/2022 22:51:58 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.08 on epoch=32
05/22/2022 22:52:00 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.09 on epoch=32
05/22/2022 22:52:03 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.08 on epoch=32
05/22/2022 22:52:06 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.08 on epoch=32
05/22/2022 22:52:08 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.05 on epoch=33
05/22/2022 22:52:37 - INFO - __main__ - Global step 1850 Train loss 0.07 Classification-F1 0.7567860552161552 on epoch=33
05/22/2022 22:52:39 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.05 on epoch=33
05/22/2022 22:52:42 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.11 on epoch=33
05/22/2022 22:52:45 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.10 on epoch=33
05/22/2022 22:52:47 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.10 on epoch=33
05/22/2022 22:52:50 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.06 on epoch=33
05/22/2022 22:53:15 - INFO - __main__ - Global step 1900 Train loss 0.08 Classification-F1 0.788437330753063 on epoch=33
05/22/2022 22:53:18 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.07 on epoch=34
05/22/2022 22:53:21 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.06 on epoch=34
05/22/2022 22:53:23 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.06 on epoch=34
05/22/2022 22:53:26 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.09 on epoch=34
05/22/2022 22:53:28 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.06 on epoch=34
05/22/2022 22:53:55 - INFO - __main__ - Global step 1950 Train loss 0.07 Classification-F1 0.7896157145347392 on epoch=34
05/22/2022 22:53:58 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.08 on epoch=34
05/22/2022 22:54:00 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.13 on epoch=35
05/22/2022 22:54:03 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.04 on epoch=35
05/22/2022 22:54:05 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.06 on epoch=35
05/22/2022 22:54:08 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.10 on epoch=35
05/22/2022 22:54:33 - INFO - __main__ - Global step 2000 Train loss 0.08 Classification-F1 0.6064181584246444 on epoch=35
05/22/2022 22:54:35 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.04 on epoch=35
05/22/2022 22:54:38 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.07 on epoch=36
05/22/2022 22:54:41 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.11 on epoch=36
05/22/2022 22:54:43 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.08 on epoch=36
05/22/2022 22:54:46 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.09 on epoch=36
05/22/2022 22:55:13 - INFO - __main__ - Global step 2050 Train loss 0.08 Classification-F1 0.6907393086455127 on epoch=36
05/22/2022 22:55:15 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.06 on epoch=36
05/22/2022 22:55:18 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.07 on epoch=36
05/22/2022 22:55:21 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.07 on epoch=37
05/22/2022 22:55:23 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.05 on epoch=37
05/22/2022 22:55:26 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.06 on epoch=37
05/22/2022 22:55:54 - INFO - __main__ - Global step 2100 Train loss 0.06 Classification-F1 0.8410981028616464 on epoch=37
05/22/2022 22:55:54 - INFO - __main__ - Saving model with best Classification-F1: 0.8325205542206061 -> 0.8410981028616464 on epoch=37, global_step=2100
05/22/2022 22:55:57 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.06 on epoch=37
05/22/2022 22:55:59 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.07 on epoch=37
05/22/2022 22:56:02 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.12 on epoch=38
05/22/2022 22:56:04 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.08 on epoch=38
05/22/2022 22:56:07 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.06 on epoch=38
05/22/2022 22:56:36 - INFO - __main__ - Global step 2150 Train loss 0.08 Classification-F1 0.9187029504923901 on epoch=38
05/22/2022 22:56:36 - INFO - __main__ - Saving model with best Classification-F1: 0.8410981028616464 -> 0.9187029504923901 on epoch=38, global_step=2150
05/22/2022 22:56:38 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.07 on epoch=38
05/22/2022 22:56:41 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.06 on epoch=38
05/22/2022 22:56:44 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.09 on epoch=38
05/22/2022 22:56:46 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.07 on epoch=39
05/22/2022 22:56:49 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.10 on epoch=39
05/22/2022 22:57:17 - INFO - __main__ - Global step 2200 Train loss 0.08 Classification-F1 0.752091136448061 on epoch=39
05/22/2022 22:57:20 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.09 on epoch=39
05/22/2022 22:57:22 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.08 on epoch=39
05/22/2022 22:57:25 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.05 on epoch=39
05/22/2022 22:57:28 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.07 on epoch=39
05/22/2022 22:57:30 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.06 on epoch=40
05/22/2022 22:57:57 - INFO - __main__ - Global step 2250 Train loss 0.07 Classification-F1 0.6399024651165438 on epoch=40
05/22/2022 22:58:00 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.07 on epoch=40
05/22/2022 22:58:03 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.06 on epoch=40
05/22/2022 22:58:05 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.13 on epoch=40
05/22/2022 22:58:08 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.03 on epoch=40
05/22/2022 22:58:10 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.04 on epoch=41
05/22/2022 22:58:37 - INFO - __main__ - Global step 2300 Train loss 0.06 Classification-F1 0.7537050323303603 on epoch=41
05/22/2022 22:58:40 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.09 on epoch=41
05/22/2022 22:58:42 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=41
05/22/2022 22:58:45 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=41
05/22/2022 22:58:47 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.16 on epoch=41
05/22/2022 22:58:50 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.08 on epoch=41
05/22/2022 22:59:17 - INFO - __main__ - Global step 2350 Train loss 0.08 Classification-F1 0.6796846571296544 on epoch=41
05/22/2022 22:59:20 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.06 on epoch=42
05/22/2022 22:59:22 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.03 on epoch=42
05/22/2022 22:59:25 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.07 on epoch=42
05/22/2022 22:59:27 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=42
05/22/2022 22:59:30 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.08 on epoch=42
05/22/2022 22:59:55 - INFO - __main__ - Global step 2400 Train loss 0.05 Classification-F1 0.6135768344635588 on epoch=42
05/22/2022 22:59:58 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.04 on epoch=43
05/22/2022 23:00:00 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.06 on epoch=43
05/22/2022 23:00:03 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=43
05/22/2022 23:00:06 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.07 on epoch=43
05/22/2022 23:00:08 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.05 on epoch=43
05/22/2022 23:00:34 - INFO - __main__ - Global step 2450 Train loss 0.05 Classification-F1 0.6202112881513502 on epoch=43
05/22/2022 23:00:37 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=43
05/22/2022 23:00:39 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=44
05/22/2022 23:00:42 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.04 on epoch=44
05/22/2022 23:00:44 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.08 on epoch=44
05/22/2022 23:00:47 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.03 on epoch=44
05/22/2022 23:01:13 - INFO - __main__ - Global step 2500 Train loss 0.04 Classification-F1 0.6612359369253172 on epoch=44
05/22/2022 23:01:16 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.03 on epoch=44
05/22/2022 23:01:18 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.06 on epoch=44
05/22/2022 23:01:21 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.07 on epoch=45
05/22/2022 23:01:24 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.04 on epoch=45
05/22/2022 23:01:26 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.04 on epoch=45
05/22/2022 23:01:51 - INFO - __main__ - Global step 2550 Train loss 0.05 Classification-F1 0.5706810129469457 on epoch=45
05/22/2022 23:01:54 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.03 on epoch=45
05/22/2022 23:01:56 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.04 on epoch=45
05/22/2022 23:01:59 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.05 on epoch=46
05/22/2022 23:02:02 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.03 on epoch=46
05/22/2022 23:02:04 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.10 on epoch=46
05/22/2022 23:02:29 - INFO - __main__ - Global step 2600 Train loss 0.05 Classification-F1 0.6022482199342947 on epoch=46
05/22/2022 23:02:32 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.05 on epoch=46
05/22/2022 23:02:34 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=46
05/22/2022 23:02:37 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.04 on epoch=46
05/22/2022 23:02:40 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=47
05/22/2022 23:02:42 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.03 on epoch=47
05/22/2022 23:03:07 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.6632716049675538 on epoch=47
05/22/2022 23:03:10 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=47
05/22/2022 23:03:13 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.05 on epoch=47
05/22/2022 23:03:15 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.06 on epoch=47
05/22/2022 23:03:18 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.04 on epoch=48
05/22/2022 23:03:21 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.04 on epoch=48
05/22/2022 23:03:45 - INFO - __main__ - Global step 2700 Train loss 0.05 Classification-F1 0.5767271350984721 on epoch=48
05/22/2022 23:03:48 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.05 on epoch=48
05/22/2022 23:03:51 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.09 on epoch=48
05/22/2022 23:03:53 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.04 on epoch=48
05/22/2022 23:03:56 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.05 on epoch=48
05/22/2022 23:03:59 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.04 on epoch=49
05/22/2022 23:04:23 - INFO - __main__ - Global step 2750 Train loss 0.05 Classification-F1 0.556614764456872 on epoch=49
05/22/2022 23:04:26 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.03 on epoch=49
05/22/2022 23:04:29 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.06 on epoch=49
05/22/2022 23:04:31 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=49
05/22/2022 23:04:34 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.03 on epoch=49
05/22/2022 23:04:37 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=49
05/22/2022 23:05:04 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.6817733753666702 on epoch=49
05/22/2022 23:05:07 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.09 on epoch=50
05/22/2022 23:05:10 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=50
05/22/2022 23:05:12 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.03 on epoch=50
05/22/2022 23:05:15 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.03 on epoch=50
05/22/2022 23:05:18 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.04 on epoch=50
05/22/2022 23:05:43 - INFO - __main__ - Global step 2850 Train loss 0.04 Classification-F1 0.626136412367131 on epoch=50
05/22/2022 23:05:46 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=51
05/22/2022 23:05:48 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.05 on epoch=51
05/22/2022 23:05:51 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.04 on epoch=51
05/22/2022 23:05:54 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.06 on epoch=51
05/22/2022 23:05:56 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.04 on epoch=51
05/22/2022 23:06:21 - INFO - __main__ - Global step 2900 Train loss 0.04 Classification-F1 0.5988072706729513 on epoch=51
05/22/2022 23:06:24 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=51
05/22/2022 23:06:27 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.07 on epoch=52
05/22/2022 23:06:29 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.03 on epoch=52
05/22/2022 23:06:32 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.04 on epoch=52
05/22/2022 23:06:34 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=52
05/22/2022 23:06:59 - INFO - __main__ - Global step 2950 Train loss 0.04 Classification-F1 0.6556708506469868 on epoch=52
05/22/2022 23:07:02 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.05 on epoch=52
05/22/2022 23:07:05 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=53
05/22/2022 23:07:07 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.05 on epoch=53
05/22/2022 23:07:10 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.04 on epoch=53
05/22/2022 23:07:12 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=53
05/22/2022 23:07:14 - INFO - __main__ - Start tokenizing ... 896 instances
05/22/2022 23:07:14 - INFO - __main__ - Printing 3 examples
05/22/2022 23:07:14 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/22/2022 23:07:14 - INFO - __main__ - ['Company']
05/22/2022 23:07:14 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/22/2022 23:07:14 - INFO - __main__ - ['Company']
05/22/2022 23:07:14 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/22/2022 23:07:14 - INFO - __main__ - ['Company']
05/22/2022 23:07:14 - INFO - __main__ - Tokenizing Input ...
05/22/2022 23:07:14 - INFO - __main__ - Tokenizing Output ...
05/22/2022 23:07:15 - INFO - __main__ - Loaded 896 examples from train data
05/22/2022 23:07:15 - INFO - __main__ - Start tokenizing ... 896 instances
05/22/2022 23:07:15 - INFO - __main__ - Printing 3 examples
05/22/2022 23:07:15 - INFO - __main__ -  [dbpedia_14] Shock Records (now part of Shock Entertainment) is Australia's largest independent record label operating for 24 years releasing independent music to the Australian marketplace.Current major music partners include Cooking Vinyl (including Marilyn Manson The Prodigy Groove Armada and Underworld); Sunday Best (Kitty Daisy & Lewis); Rise Records (Of Mice & Men Miss May I Hot Water Music); Vagrant (including Edward Sharpe and the Magnetic Zeros); Sumerian (Asking Alexandria I See Stars Veil of Maya); and Rough Trade (including Belle and Sebastian).
05/22/2022 23:07:15 - INFO - __main__ - ['Company']
05/22/2022 23:07:15 - INFO - __main__ -  [dbpedia_14] Actio Corporation is an American software company founded in 1996. The company began as an MSDS authoring and data management service using a hosted model which is now known as SaaS or software-as-a-service but in the mid-90's was called ASP.
05/22/2022 23:07:15 - INFO - __main__ - ['Company']
05/22/2022 23:07:15 - INFO - __main__ -  [dbpedia_14] Pacific Corporate Group is a global alternative investment management and advisory company headquartered in La Jolla California. PCG together with affiliates and subsidiaries (together the affiliates) currently manage over $17 billion in assets and has invested and advised upon over $44 billion since 1990. PCG and its affiliates operate through offices based out of La Jolla New York Danvers Washington D.C Singapore and Hong Kong
05/22/2022 23:07:15 - INFO - __main__ - ['Company']
05/22/2022 23:07:15 - INFO - __main__ - Tokenizing Input ...
05/22/2022 23:07:16 - INFO - __main__ - Tokenizing Output ...
05/22/2022 23:07:17 - INFO - __main__ - Loaded 896 examples from dev data
05/22/2022 23:07:33 - INFO - __main__ - try to initialize prompt embeddings
05/22/2022 23:07:33 - INFO - __main__ - task name: dbpedia_14
05/22/2022 23:07:33 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 23:07:33 - INFO - __main__ - Starting training!
05/22/2022 23:07:39 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.8051547127318011 on epoch=53
05/22/2022 23:07:39 - INFO - __main__ - save last model!
05/22/2022 23:07:39 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/22/2022 23:07:39 - INFO - __main__ - Start tokenizing ... 3500 instances
05/22/2022 23:07:39 - INFO - __main__ - Printing 3 examples
05/22/2022 23:07:39 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/22/2022 23:07:39 - INFO - __main__ - ['Animal']
05/22/2022 23:07:39 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/22/2022 23:07:39 - INFO - __main__ - ['Animal']
05/22/2022 23:07:39 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/22/2022 23:07:39 - INFO - __main__ - ['Village']
05/22/2022 23:07:39 - INFO - __main__ - Tokenizing Input ...
05/22/2022 23:07:41 - INFO - __main__ - Tokenizing Output ...
05/22/2022 23:07:44 - INFO - __main__ - Loaded 3500 examples from test data
05/22/2022 23:09:52 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down64shot/singletask-dbpedia_14/dbpedia_14_64_21_0.2_8_predictions.txt
05/22/2022 23:09:52 - INFO - __main__ - Classification-F1 on test data: 0.5922
05/22/2022 23:09:52 - INFO - __main__ - prefix=dbpedia_14_64_21, lr=0.2, bsz=8, dev_performance=0.9187029504923901, test_performance=0.5921992083801387
05/22/2022 23:09:52 - INFO - __main__ - Running ... prefix=dbpedia_14_64_42, lr=0.5, bsz=8 ...
05/22/2022 23:09:53 - INFO - __main__ - Start tokenizing ... 896 instances
05/22/2022 23:09:53 - INFO - __main__ - Printing 3 examples
05/22/2022 23:09:53 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/22/2022 23:09:53 - INFO - __main__ - ['Company']
05/22/2022 23:09:53 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/22/2022 23:09:53 - INFO - __main__ - ['Company']
05/22/2022 23:09:53 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/22/2022 23:09:53 - INFO - __main__ - ['Company']
05/22/2022 23:09:53 - INFO - __main__ - Tokenizing Input ...
05/22/2022 23:09:54 - INFO - __main__ - Tokenizing Output ...
05/22/2022 23:09:54 - INFO - __main__ - Loaded 896 examples from train data
05/22/2022 23:09:54 - INFO - __main__ - Start tokenizing ... 896 instances
05/22/2022 23:09:55 - INFO - __main__ - Printing 3 examples
05/22/2022 23:09:55 - INFO - __main__ -  [dbpedia_14] Shock Records (now part of Shock Entertainment) is Australia's largest independent record label operating for 24 years releasing independent music to the Australian marketplace.Current major music partners include Cooking Vinyl (including Marilyn Manson The Prodigy Groove Armada and Underworld); Sunday Best (Kitty Daisy & Lewis); Rise Records (Of Mice & Men Miss May I Hot Water Music); Vagrant (including Edward Sharpe and the Magnetic Zeros); Sumerian (Asking Alexandria I See Stars Veil of Maya); and Rough Trade (including Belle and Sebastian).
05/22/2022 23:09:55 - INFO - __main__ - ['Company']
05/22/2022 23:09:55 - INFO - __main__ -  [dbpedia_14] Actio Corporation is an American software company founded in 1996. The company began as an MSDS authoring and data management service using a hosted model which is now known as SaaS or software-as-a-service but in the mid-90's was called ASP.
05/22/2022 23:09:55 - INFO - __main__ - ['Company']
05/22/2022 23:09:55 - INFO - __main__ -  [dbpedia_14] Pacific Corporate Group is a global alternative investment management and advisory company headquartered in La Jolla California. PCG together with affiliates and subsidiaries (together the affiliates) currently manage over $17 billion in assets and has invested and advised upon over $44 billion since 1990. PCG and its affiliates operate through offices based out of La Jolla New York Danvers Washington D.C Singapore and Hong Kong
05/22/2022 23:09:55 - INFO - __main__ - ['Company']
05/22/2022 23:09:55 - INFO - __main__ - Tokenizing Input ...
05/22/2022 23:09:55 - INFO - __main__ - Tokenizing Output ...
05/22/2022 23:09:56 - INFO - __main__ - Loaded 896 examples from dev data
05/22/2022 23:10:11 - INFO - __main__ - try to initialize prompt embeddings
05/22/2022 23:10:11 - INFO - __main__ - task name: dbpedia_14
05/22/2022 23:10:12 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 23:10:12 - INFO - __main__ - Starting training!
05/22/2022 23:10:15 - INFO - __main__ - Step 10 Global step 10 Train loss 6.64 on epoch=0
05/22/2022 23:10:18 - INFO - __main__ - Step 20 Global step 20 Train loss 4.25 on epoch=0
05/22/2022 23:10:20 - INFO - __main__ - Step 30 Global step 30 Train loss 2.89 on epoch=0
05/22/2022 23:10:23 - INFO - __main__ - Step 40 Global step 40 Train loss 2.26 on epoch=0
05/22/2022 23:10:25 - INFO - __main__ - Step 50 Global step 50 Train loss 2.04 on epoch=0
05/22/2022 23:12:16 - INFO - __main__ - Global step 50 Train loss 3.62 Classification-F1 0.046909370553634214 on epoch=0
05/22/2022 23:12:16 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.046909370553634214 on epoch=0, global_step=50
05/22/2022 23:12:18 - INFO - __main__ - Step 60 Global step 60 Train loss 1.62 on epoch=1
05/22/2022 23:12:21 - INFO - __main__ - Step 70 Global step 70 Train loss 1.48 on epoch=1
05/22/2022 23:12:23 - INFO - __main__ - Step 80 Global step 80 Train loss 1.18 on epoch=1
05/22/2022 23:12:26 - INFO - __main__ - Step 90 Global step 90 Train loss 1.14 on epoch=1
05/22/2022 23:12:28 - INFO - __main__ - Step 100 Global step 100 Train loss 0.94 on epoch=1
05/22/2022 23:12:58 - INFO - __main__ - Global step 100 Train loss 1.27 Classification-F1 0.32804010553519125 on epoch=1
05/22/2022 23:12:58 - INFO - __main__ - Saving model with best Classification-F1: 0.046909370553634214 -> 0.32804010553519125 on epoch=1, global_step=100
05/22/2022 23:13:01 - INFO - __main__ - Step 110 Global step 110 Train loss 1.05 on epoch=1
05/22/2022 23:13:03 - INFO - __main__ - Step 120 Global step 120 Train loss 0.85 on epoch=2
05/22/2022 23:13:06 - INFO - __main__ - Step 130 Global step 130 Train loss 0.86 on epoch=2
05/22/2022 23:13:09 - INFO - __main__ - Step 140 Global step 140 Train loss 0.69 on epoch=2
05/22/2022 23:13:11 - INFO - __main__ - Step 150 Global step 150 Train loss 0.72 on epoch=2
05/22/2022 23:13:38 - INFO - __main__ - Global step 150 Train loss 0.83 Classification-F1 0.47637441869717345 on epoch=2
05/22/2022 23:13:38 - INFO - __main__ - Saving model with best Classification-F1: 0.32804010553519125 -> 0.47637441869717345 on epoch=2, global_step=150
05/22/2022 23:13:41 - INFO - __main__ - Step 160 Global step 160 Train loss 0.72 on epoch=2
05/22/2022 23:13:43 - INFO - __main__ - Step 170 Global step 170 Train loss 0.70 on epoch=3
05/22/2022 23:13:46 - INFO - __main__ - Step 180 Global step 180 Train loss 0.68 on epoch=3
05/22/2022 23:13:48 - INFO - __main__ - Step 190 Global step 190 Train loss 0.83 on epoch=3
05/22/2022 23:13:51 - INFO - __main__ - Step 200 Global step 200 Train loss 0.61 on epoch=3
05/22/2022 23:14:17 - INFO - __main__ - Global step 200 Train loss 0.71 Classification-F1 0.5743254829299119 on epoch=3
05/22/2022 23:14:17 - INFO - __main__ - Saving model with best Classification-F1: 0.47637441869717345 -> 0.5743254829299119 on epoch=3, global_step=200
05/22/2022 23:14:20 - INFO - __main__ - Step 210 Global step 210 Train loss 0.57 on epoch=3
05/22/2022 23:14:22 - INFO - __main__ - Step 220 Global step 220 Train loss 0.63 on epoch=3
05/22/2022 23:14:25 - INFO - __main__ - Step 230 Global step 230 Train loss 0.66 on epoch=4
05/22/2022 23:14:27 - INFO - __main__ - Step 240 Global step 240 Train loss 0.63 on epoch=4
05/22/2022 23:14:30 - INFO - __main__ - Step 250 Global step 250 Train loss 0.58 on epoch=4
05/22/2022 23:14:56 - INFO - __main__ - Global step 250 Train loss 0.61 Classification-F1 0.4970583949225202 on epoch=4
05/22/2022 23:14:58 - INFO - __main__ - Step 260 Global step 260 Train loss 0.58 on epoch=4
05/22/2022 23:15:01 - INFO - __main__ - Step 270 Global step 270 Train loss 0.61 on epoch=4
05/22/2022 23:15:04 - INFO - __main__ - Step 280 Global step 280 Train loss 0.50 on epoch=4
05/22/2022 23:15:06 - INFO - __main__ - Step 290 Global step 290 Train loss 0.50 on epoch=5
05/22/2022 23:15:09 - INFO - __main__ - Step 300 Global step 300 Train loss 0.59 on epoch=5
05/22/2022 23:15:37 - INFO - __main__ - Global step 300 Train loss 0.56 Classification-F1 0.41338473477075444 on epoch=5
05/22/2022 23:15:40 - INFO - __main__ - Step 310 Global step 310 Train loss 0.40 on epoch=5
05/22/2022 23:15:42 - INFO - __main__ - Step 320 Global step 320 Train loss 0.41 on epoch=5
05/22/2022 23:15:45 - INFO - __main__ - Step 330 Global step 330 Train loss 0.49 on epoch=5
05/22/2022 23:15:47 - INFO - __main__ - Step 340 Global step 340 Train loss 0.45 on epoch=6
05/22/2022 23:15:50 - INFO - __main__ - Step 350 Global step 350 Train loss 0.46 on epoch=6
05/22/2022 23:16:16 - INFO - __main__ - Global step 350 Train loss 0.44 Classification-F1 0.5421863981123094 on epoch=6
05/22/2022 23:16:18 - INFO - __main__ - Step 360 Global step 360 Train loss 0.45 on epoch=6
05/22/2022 23:16:21 - INFO - __main__ - Step 370 Global step 370 Train loss 0.30 on epoch=6
05/22/2022 23:16:24 - INFO - __main__ - Step 380 Global step 380 Train loss 0.33 on epoch=6
05/22/2022 23:16:26 - INFO - __main__ - Step 390 Global step 390 Train loss 0.36 on epoch=6
05/22/2022 23:16:29 - INFO - __main__ - Step 400 Global step 400 Train loss 0.44 on epoch=7
05/22/2022 23:16:56 - INFO - __main__ - Global step 400 Train loss 0.38 Classification-F1 0.5283941472303533 on epoch=7
05/22/2022 23:16:58 - INFO - __main__ - Step 410 Global step 410 Train loss 0.37 on epoch=7
05/22/2022 23:17:01 - INFO - __main__ - Step 420 Global step 420 Train loss 0.28 on epoch=7
05/22/2022 23:17:04 - INFO - __main__ - Step 430 Global step 430 Train loss 0.29 on epoch=7
05/22/2022 23:17:06 - INFO - __main__ - Step 440 Global step 440 Train loss 0.30 on epoch=7
05/22/2022 23:17:09 - INFO - __main__ - Step 450 Global step 450 Train loss 0.30 on epoch=8
05/22/2022 23:17:34 - INFO - __main__ - Global step 450 Train loss 0.31 Classification-F1 0.36366198541993905 on epoch=8
05/22/2022 23:17:36 - INFO - __main__ - Step 460 Global step 460 Train loss 0.26 on epoch=8
05/22/2022 23:17:39 - INFO - __main__ - Step 470 Global step 470 Train loss 0.35 on epoch=8
05/22/2022 23:17:41 - INFO - __main__ - Step 480 Global step 480 Train loss 0.28 on epoch=8
05/22/2022 23:17:44 - INFO - __main__ - Step 490 Global step 490 Train loss 0.18 on epoch=8
05/22/2022 23:17:47 - INFO - __main__ - Step 500 Global step 500 Train loss 0.21 on epoch=8
05/22/2022 23:18:12 - INFO - __main__ - Global step 500 Train loss 0.26 Classification-F1 0.47078606320591515 on epoch=8
05/22/2022 23:18:15 - INFO - __main__ - Step 510 Global step 510 Train loss 0.29 on epoch=9
05/22/2022 23:18:17 - INFO - __main__ - Step 520 Global step 520 Train loss 0.28 on epoch=9
05/22/2022 23:18:20 - INFO - __main__ - Step 530 Global step 530 Train loss 0.26 on epoch=9
05/22/2022 23:18:22 - INFO - __main__ - Step 540 Global step 540 Train loss 0.27 on epoch=9
05/22/2022 23:18:25 - INFO - __main__ - Step 550 Global step 550 Train loss 0.22 on epoch=9
05/22/2022 23:18:51 - INFO - __main__ - Global step 550 Train loss 0.26 Classification-F1 0.5507620823933185 on epoch=9
05/22/2022 23:18:54 - INFO - __main__ - Step 560 Global step 560 Train loss 0.26 on epoch=9
05/22/2022 23:18:56 - INFO - __main__ - Step 570 Global step 570 Train loss 0.25 on epoch=10
05/22/2022 23:18:59 - INFO - __main__ - Step 580 Global step 580 Train loss 0.27 on epoch=10
05/22/2022 23:19:02 - INFO - __main__ - Step 590 Global step 590 Train loss 0.16 on epoch=10
05/22/2022 23:19:04 - INFO - __main__ - Step 600 Global step 600 Train loss 0.20 on epoch=10
05/22/2022 23:19:30 - INFO - __main__ - Global step 600 Train loss 0.23 Classification-F1 0.5155993937894565 on epoch=10
05/22/2022 23:19:33 - INFO - __main__ - Step 610 Global step 610 Train loss 0.19 on epoch=10
05/22/2022 23:19:35 - INFO - __main__ - Step 620 Global step 620 Train loss 0.19 on epoch=11
05/22/2022 23:19:38 - INFO - __main__ - Step 630 Global step 630 Train loss 0.22 on epoch=11
05/22/2022 23:19:40 - INFO - __main__ - Step 640 Global step 640 Train loss 0.17 on epoch=11
05/22/2022 23:19:43 - INFO - __main__ - Step 650 Global step 650 Train loss 0.16 on epoch=11
05/22/2022 23:20:10 - INFO - __main__ - Global step 650 Train loss 0.19 Classification-F1 0.6018865505944475 on epoch=11
05/22/2022 23:20:10 - INFO - __main__ - Saving model with best Classification-F1: 0.5743254829299119 -> 0.6018865505944475 on epoch=11, global_step=650
05/22/2022 23:20:12 - INFO - __main__ - Step 660 Global step 660 Train loss 0.17 on epoch=11
05/22/2022 23:20:15 - INFO - __main__ - Step 670 Global step 670 Train loss 0.14 on epoch=11
05/22/2022 23:20:18 - INFO - __main__ - Step 680 Global step 680 Train loss 0.13 on epoch=12
05/22/2022 23:20:20 - INFO - __main__ - Step 690 Global step 690 Train loss 0.19 on epoch=12
05/22/2022 23:20:23 - INFO - __main__ - Step 700 Global step 700 Train loss 0.14 on epoch=12
05/22/2022 23:20:49 - INFO - __main__ - Global step 700 Train loss 0.15 Classification-F1 0.38344703697673876 on epoch=12
05/22/2022 23:20:51 - INFO - __main__ - Step 710 Global step 710 Train loss 0.15 on epoch=12
05/22/2022 23:20:54 - INFO - __main__ - Step 720 Global step 720 Train loss 0.13 on epoch=12
05/22/2022 23:20:56 - INFO - __main__ - Step 730 Global step 730 Train loss 0.08 on epoch=13
05/22/2022 23:20:59 - INFO - __main__ - Step 740 Global step 740 Train loss 0.13 on epoch=13
05/22/2022 23:21:02 - INFO - __main__ - Step 750 Global step 750 Train loss 0.25 on epoch=13
05/22/2022 23:21:27 - INFO - __main__ - Global step 750 Train loss 0.15 Classification-F1 0.565885656420643 on epoch=13
05/22/2022 23:21:30 - INFO - __main__ - Step 760 Global step 760 Train loss 0.10 on epoch=13
05/22/2022 23:21:32 - INFO - __main__ - Step 770 Global step 770 Train loss 0.19 on epoch=13
05/22/2022 23:21:35 - INFO - __main__ - Step 780 Global step 780 Train loss 0.13 on epoch=13
05/22/2022 23:21:37 - INFO - __main__ - Step 790 Global step 790 Train loss 0.23 on epoch=14
05/22/2022 23:21:40 - INFO - __main__ - Step 800 Global step 800 Train loss 0.19 on epoch=14
05/22/2022 23:22:04 - INFO - __main__ - Global step 800 Train loss 0.17 Classification-F1 0.41973165601768947 on epoch=14
05/22/2022 23:22:07 - INFO - __main__ - Step 810 Global step 810 Train loss 0.10 on epoch=14
05/22/2022 23:22:09 - INFO - __main__ - Step 820 Global step 820 Train loss 0.05 on epoch=14
05/22/2022 23:22:12 - INFO - __main__ - Step 830 Global step 830 Train loss 0.07 on epoch=14
05/22/2022 23:22:14 - INFO - __main__ - Step 840 Global step 840 Train loss 0.10 on epoch=14
05/22/2022 23:22:17 - INFO - __main__ - Step 850 Global step 850 Train loss 0.12 on epoch=15
05/22/2022 23:22:41 - INFO - __main__ - Global step 850 Train loss 0.09 Classification-F1 0.6270726610631276 on epoch=15
05/22/2022 23:22:42 - INFO - __main__ - Saving model with best Classification-F1: 0.6018865505944475 -> 0.6270726610631276 on epoch=15, global_step=850
05/22/2022 23:22:44 - INFO - __main__ - Step 860 Global step 860 Train loss 0.13 on epoch=15
05/22/2022 23:22:47 - INFO - __main__ - Step 870 Global step 870 Train loss 0.12 on epoch=15
05/22/2022 23:22:49 - INFO - __main__ - Step 880 Global step 880 Train loss 0.13 on epoch=15
05/22/2022 23:22:52 - INFO - __main__ - Step 890 Global step 890 Train loss 0.10 on epoch=15
05/22/2022 23:22:54 - INFO - __main__ - Step 900 Global step 900 Train loss 0.12 on epoch=16
05/22/2022 23:23:19 - INFO - __main__ - Global step 900 Train loss 0.12 Classification-F1 0.6035515006070266 on epoch=16
05/22/2022 23:23:21 - INFO - __main__ - Step 910 Global step 910 Train loss 0.10 on epoch=16
05/22/2022 23:23:24 - INFO - __main__ - Step 920 Global step 920 Train loss 0.08 on epoch=16
05/22/2022 23:23:26 - INFO - __main__ - Step 930 Global step 930 Train loss 0.05 on epoch=16
05/22/2022 23:23:29 - INFO - __main__ - Step 940 Global step 940 Train loss 0.12 on epoch=16
05/22/2022 23:23:32 - INFO - __main__ - Step 950 Global step 950 Train loss 0.10 on epoch=16
05/22/2022 23:23:56 - INFO - __main__ - Global step 950 Train loss 0.09 Classification-F1 0.5705394783074965 on epoch=16
05/22/2022 23:23:59 - INFO - __main__ - Step 960 Global step 960 Train loss 0.08 on epoch=17
05/22/2022 23:24:02 - INFO - __main__ - Step 970 Global step 970 Train loss 0.07 on epoch=17
05/22/2022 23:24:04 - INFO - __main__ - Step 980 Global step 980 Train loss 0.11 on epoch=17
05/22/2022 23:24:07 - INFO - __main__ - Step 990 Global step 990 Train loss 0.12 on epoch=17
05/22/2022 23:24:09 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.10 on epoch=17
05/22/2022 23:24:34 - INFO - __main__ - Global step 1000 Train loss 0.10 Classification-F1 0.6315225979926116 on epoch=17
05/22/2022 23:24:34 - INFO - __main__ - Saving model with best Classification-F1: 0.6270726610631276 -> 0.6315225979926116 on epoch=17, global_step=1000
05/22/2022 23:24:36 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.05 on epoch=18
05/22/2022 23:24:39 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.08 on epoch=18
05/22/2022 23:24:41 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.10 on epoch=18
05/22/2022 23:24:44 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.05 on epoch=18
05/22/2022 23:24:47 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.07 on epoch=18
05/22/2022 23:25:10 - INFO - __main__ - Global step 1050 Train loss 0.07 Classification-F1 0.5285121222078496 on epoch=18
05/22/2022 23:25:13 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.07 on epoch=18
05/22/2022 23:25:16 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.12 on epoch=19
05/22/2022 23:25:18 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.10 on epoch=19
05/22/2022 23:25:21 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.09 on epoch=19
05/22/2022 23:25:23 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.05 on epoch=19
05/22/2022 23:25:47 - INFO - __main__ - Global step 1100 Train loss 0.08 Classification-F1 0.6564074488233257 on epoch=19
05/22/2022 23:25:47 - INFO - __main__ - Saving model with best Classification-F1: 0.6315225979926116 -> 0.6564074488233257 on epoch=19, global_step=1100
05/22/2022 23:25:49 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.09 on epoch=19
05/22/2022 23:25:52 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.06 on epoch=19
05/22/2022 23:25:55 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.07 on epoch=20
05/22/2022 23:25:57 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.07 on epoch=20
05/22/2022 23:26:00 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.04 on epoch=20
05/22/2022 23:26:24 - INFO - __main__ - Global step 1150 Train loss 0.07 Classification-F1 0.6100479465342059 on epoch=20
05/22/2022 23:26:26 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.12 on epoch=20
05/22/2022 23:26:29 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.11 on epoch=20
05/22/2022 23:26:31 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.06 on epoch=21
05/22/2022 23:26:34 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.13 on epoch=21
05/22/2022 23:26:36 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.06 on epoch=21
05/22/2022 23:27:00 - INFO - __main__ - Global step 1200 Train loss 0.10 Classification-F1 0.6341417874121195 on epoch=21
05/22/2022 23:27:02 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.03 on epoch=21
05/22/2022 23:27:05 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.06 on epoch=21
05/22/2022 23:27:07 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.03 on epoch=21
05/22/2022 23:27:10 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.05 on epoch=22
05/22/2022 23:27:13 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.11 on epoch=22
05/22/2022 23:27:37 - INFO - __main__ - Global step 1250 Train loss 0.06 Classification-F1 0.5764940570080751 on epoch=22
05/22/2022 23:27:39 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.05 on epoch=22
05/22/2022 23:27:42 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.12 on epoch=22
05/22/2022 23:27:45 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.12 on epoch=22
05/22/2022 23:27:47 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.03 on epoch=23
05/22/2022 23:27:50 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.06 on epoch=23
05/22/2022 23:28:14 - INFO - __main__ - Global step 1300 Train loss 0.07 Classification-F1 0.5006114105630425 on epoch=23
05/22/2022 23:28:16 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.07 on epoch=23
05/22/2022 23:28:19 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.02 on epoch=23
05/22/2022 23:28:21 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.08 on epoch=23
05/22/2022 23:28:24 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.04 on epoch=23
05/22/2022 23:28:27 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.07 on epoch=24
05/22/2022 23:28:51 - INFO - __main__ - Global step 1350 Train loss 0.06 Classification-F1 0.7493811712263604 on epoch=24
05/22/2022 23:28:51 - INFO - __main__ - Saving model with best Classification-F1: 0.6564074488233257 -> 0.7493811712263604 on epoch=24, global_step=1350
05/22/2022 23:28:54 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.04 on epoch=24
05/22/2022 23:28:56 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.07 on epoch=24
05/22/2022 23:28:59 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.05 on epoch=24
05/22/2022 23:29:02 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.09 on epoch=24
05/22/2022 23:29:04 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.03 on epoch=24
05/22/2022 23:29:28 - INFO - __main__ - Global step 1400 Train loss 0.06 Classification-F1 0.5408594099033998 on epoch=24
05/22/2022 23:29:31 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.04 on epoch=25
05/22/2022 23:29:34 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.03 on epoch=25
05/22/2022 23:29:36 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.03 on epoch=25
05/22/2022 23:29:39 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.03 on epoch=25
05/22/2022 23:29:41 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=25
05/22/2022 23:30:06 - INFO - __main__ - Global step 1450 Train loss 0.03 Classification-F1 0.7528274157687425 on epoch=25
05/22/2022 23:30:06 - INFO - __main__ - Saving model with best Classification-F1: 0.7493811712263604 -> 0.7528274157687425 on epoch=25, global_step=1450
05/22/2022 23:30:09 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.04 on epoch=26
05/22/2022 23:30:12 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.04 on epoch=26
05/22/2022 23:30:14 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.09 on epoch=26
05/22/2022 23:30:17 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.03 on epoch=26
05/22/2022 23:30:19 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.04 on epoch=26
05/22/2022 23:30:44 - INFO - __main__ - Global step 1500 Train loss 0.05 Classification-F1 0.7935594704971252 on epoch=26
05/22/2022 23:30:44 - INFO - __main__ - Saving model with best Classification-F1: 0.7528274157687425 -> 0.7935594704971252 on epoch=26, global_step=1500
05/22/2022 23:30:47 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=26
05/22/2022 23:30:49 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.02 on epoch=27
05/22/2022 23:30:52 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.08 on epoch=27
05/22/2022 23:30:55 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.04 on epoch=27
05/22/2022 23:30:57 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.05 on epoch=27
05/22/2022 23:31:20 - INFO - __main__ - Global step 1550 Train loss 0.04 Classification-F1 0.8221092727722281 on epoch=27
05/22/2022 23:31:20 - INFO - __main__ - Saving model with best Classification-F1: 0.7935594704971252 -> 0.8221092727722281 on epoch=27, global_step=1550
05/22/2022 23:31:23 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.03 on epoch=27
05/22/2022 23:31:26 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=28
05/22/2022 23:31:28 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.03 on epoch=28
05/22/2022 23:31:31 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.05 on epoch=28
05/22/2022 23:31:33 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=28
05/22/2022 23:31:56 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.5958884881801728 on epoch=28
05/22/2022 23:31:59 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.04 on epoch=28
05/22/2022 23:32:02 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.02 on epoch=28
05/22/2022 23:32:04 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.05 on epoch=29
05/22/2022 23:32:07 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.08 on epoch=29
05/22/2022 23:32:09 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.08 on epoch=29
05/22/2022 23:32:34 - INFO - __main__ - Global step 1650 Train loss 0.05 Classification-F1 0.8460364229861574 on epoch=29
05/22/2022 23:32:34 - INFO - __main__ - Saving model with best Classification-F1: 0.8221092727722281 -> 0.8460364229861574 on epoch=29, global_step=1650
05/22/2022 23:32:36 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.04 on epoch=29
05/22/2022 23:32:39 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.03 on epoch=29
05/22/2022 23:32:41 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=29
05/22/2022 23:32:44 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.04 on epoch=30
05/22/2022 23:32:46 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.08 on epoch=30
05/22/2022 23:33:10 - INFO - __main__ - Global step 1700 Train loss 0.04 Classification-F1 0.7474201840595561 on epoch=30
05/22/2022 23:33:13 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.04 on epoch=30
05/22/2022 23:33:15 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.04 on epoch=30
05/22/2022 23:33:18 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.04 on epoch=30
05/22/2022 23:33:21 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.07 on epoch=31
05/22/2022 23:33:23 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.05 on epoch=31
05/22/2022 23:33:46 - INFO - __main__ - Global step 1750 Train loss 0.05 Classification-F1 0.7457604579538545 on epoch=31
05/22/2022 23:33:49 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.04 on epoch=31
05/22/2022 23:33:51 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=31
05/22/2022 23:33:54 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=31
05/22/2022 23:33:57 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.03 on epoch=31
05/22/2022 23:33:59 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=32
05/22/2022 23:34:23 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.8232715192137487 on epoch=32
05/22/2022 23:34:26 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.07 on epoch=32
05/22/2022 23:34:28 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.04 on epoch=32
05/22/2022 23:34:31 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.05 on epoch=32
05/22/2022 23:34:33 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.05 on epoch=32
05/22/2022 23:34:36 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=33
05/22/2022 23:35:00 - INFO - __main__ - Global step 1850 Train loss 0.05 Classification-F1 0.7795739978011819 on epoch=33
05/22/2022 23:35:02 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=33
05/22/2022 23:35:05 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.04 on epoch=33
05/22/2022 23:35:07 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=33
05/22/2022 23:35:10 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=33
05/22/2022 23:35:12 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=33
05/22/2022 23:35:36 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.7268952543948103 on epoch=33
05/22/2022 23:35:39 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.04 on epoch=34
05/22/2022 23:35:41 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.05 on epoch=34
05/22/2022 23:35:44 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=34
05/22/2022 23:35:47 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=34
05/22/2022 23:35:49 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=34
05/22/2022 23:36:12 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.7182396863750825 on epoch=34
05/22/2022 23:36:15 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=34
05/22/2022 23:36:18 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.04 on epoch=35
05/22/2022 23:36:20 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.06 on epoch=35
05/22/2022 23:36:23 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=35
05/22/2022 23:36:25 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.05 on epoch=35
05/22/2022 23:36:49 - INFO - __main__ - Global step 2000 Train loss 0.04 Classification-F1 0.7967375825393994 on epoch=35
05/22/2022 23:36:52 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=35
05/22/2022 23:36:54 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.05 on epoch=36
05/22/2022 23:36:57 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.06 on epoch=36
05/22/2022 23:37:00 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=36
05/22/2022 23:37:02 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=36
05/22/2022 23:37:26 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.8015600963362222 on epoch=36
05/22/2022 23:37:29 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.02 on epoch=36
05/22/2022 23:37:31 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.03 on epoch=36
05/22/2022 23:37:34 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.06 on epoch=37
05/22/2022 23:37:36 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.11 on epoch=37
05/22/2022 23:37:39 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=37
05/22/2022 23:38:03 - INFO - __main__ - Global step 2100 Train loss 0.05 Classification-F1 0.8587381533564863 on epoch=37
05/22/2022 23:38:03 - INFO - __main__ - Saving model with best Classification-F1: 0.8460364229861574 -> 0.8587381533564863 on epoch=37, global_step=2100
05/22/2022 23:38:05 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=37
05/22/2022 23:38:08 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=37
05/22/2022 23:38:10 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=38
05/22/2022 23:38:13 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=38
05/22/2022 23:38:16 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=38
05/22/2022 23:38:40 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.8076856646333067 on epoch=38
05/22/2022 23:38:42 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=38
05/22/2022 23:38:45 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.04 on epoch=38
05/22/2022 23:38:47 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=38
05/22/2022 23:38:50 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.05 on epoch=39
05/22/2022 23:38:52 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.04 on epoch=39
05/22/2022 23:39:17 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.8402102373201952 on epoch=39
05/22/2022 23:39:19 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=39
05/22/2022 23:39:22 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=39
05/22/2022 23:39:25 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=39
05/22/2022 23:39:27 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=39
05/22/2022 23:39:30 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.07 on epoch=40
05/22/2022 23:39:54 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.9170469462106088 on epoch=40
05/22/2022 23:39:54 - INFO - __main__ - Saving model with best Classification-F1: 0.8587381533564863 -> 0.9170469462106088 on epoch=40, global_step=2250
05/22/2022 23:39:56 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=40
05/22/2022 23:39:59 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.03 on epoch=40
05/22/2022 23:40:02 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.05 on epoch=40
05/22/2022 23:40:04 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=40
05/22/2022 23:40:07 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=41
05/22/2022 23:40:31 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.9013004203325032 on epoch=41
05/22/2022 23:40:33 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=41
05/22/2022 23:40:36 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=41
05/22/2022 23:40:39 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=41
05/22/2022 23:40:41 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.05 on epoch=41
05/22/2022 23:40:44 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=41
05/22/2022 23:41:07 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.8223548634743543 on epoch=41
05/22/2022 23:41:10 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=42
05/22/2022 23:41:13 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.05 on epoch=42
05/22/2022 23:41:15 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=42
05/22/2022 23:41:18 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.04 on epoch=42
05/22/2022 23:41:20 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=42
05/22/2022 23:41:43 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.8298588650932949 on epoch=42
05/22/2022 23:41:46 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.03 on epoch=43
05/22/2022 23:41:48 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=43
05/22/2022 23:41:51 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=43
05/22/2022 23:41:54 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=43
05/22/2022 23:41:56 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=43
05/22/2022 23:42:20 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.8442573528044153 on epoch=43
05/22/2022 23:42:22 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.02 on epoch=43
05/22/2022 23:42:25 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=44
05/22/2022 23:42:27 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.07 on epoch=44
05/22/2022 23:42:30 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.04 on epoch=44
05/22/2022 23:42:33 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=44
05/22/2022 23:42:55 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.859833461364284 on epoch=44
05/22/2022 23:42:58 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=44
05/22/2022 23:43:01 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=44
05/22/2022 23:43:03 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.04 on epoch=45
05/22/2022 23:43:06 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.05 on epoch=45
05/22/2022 23:43:08 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=45
05/22/2022 23:43:32 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.7017096562030515 on epoch=45
05/22/2022 23:43:34 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=45
05/22/2022 23:43:37 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=45
05/22/2022 23:43:39 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=46
05/22/2022 23:43:42 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=46
05/22/2022 23:43:45 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=46
05/22/2022 23:44:08 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.7154534670815761 on epoch=46
05/22/2022 23:44:10 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=46
05/22/2022 23:44:13 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=46
05/22/2022 23:44:16 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=46
05/22/2022 23:44:18 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=47
05/22/2022 23:44:21 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=47
05/22/2022 23:44:44 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.8690075752137648 on epoch=47
05/22/2022 23:44:46 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=47
05/22/2022 23:44:49 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=47
05/22/2022 23:44:51 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=47
05/22/2022 23:44:54 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.03 on epoch=48
05/22/2022 23:44:57 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=48
05/22/2022 23:45:20 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.8420567498655462 on epoch=48
05/22/2022 23:45:23 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.04 on epoch=48
05/22/2022 23:45:25 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=48
05/22/2022 23:45:28 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.04 on epoch=48
05/22/2022 23:45:30 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=48
05/22/2022 23:45:33 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.04 on epoch=49
05/22/2022 23:45:56 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.7536599864565147 on epoch=49
05/22/2022 23:45:58 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.03 on epoch=49
05/22/2022 23:46:01 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=49
05/22/2022 23:46:04 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=49
05/22/2022 23:46:06 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=49
05/22/2022 23:46:09 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.05 on epoch=49
05/22/2022 23:46:33 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.8334059737207936 on epoch=49
05/22/2022 23:46:35 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=50
05/22/2022 23:46:38 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.06 on epoch=50
05/22/2022 23:46:41 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=50
05/22/2022 23:46:43 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=50
05/22/2022 23:46:46 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.03 on epoch=50
05/22/2022 23:47:10 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.8427480533256251 on epoch=50
05/22/2022 23:47:12 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=51
05/22/2022 23:47:15 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.03 on epoch=51
05/22/2022 23:47:17 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=51
05/22/2022 23:47:20 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=51
05/22/2022 23:47:23 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=51
05/22/2022 23:47:46 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.7460352717874188 on epoch=51
05/22/2022 23:47:49 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=51
05/22/2022 23:47:51 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=52
05/22/2022 23:47:54 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.03 on epoch=52
05/22/2022 23:47:57 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=52
05/22/2022 23:47:59 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.03 on epoch=52
05/22/2022 23:48:22 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.865783095959274 on epoch=52
05/22/2022 23:48:25 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=52
05/22/2022 23:48:27 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=53
05/22/2022 23:48:30 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=53
05/22/2022 23:48:33 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.04 on epoch=53
05/22/2022 23:48:35 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=53
05/22/2022 23:48:37 - INFO - __main__ - Start tokenizing ... 896 instances
05/22/2022 23:48:37 - INFO - __main__ - Printing 3 examples
05/22/2022 23:48:37 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/22/2022 23:48:37 - INFO - __main__ - ['Company']
05/22/2022 23:48:37 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/22/2022 23:48:37 - INFO - __main__ - ['Company']
05/22/2022 23:48:37 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/22/2022 23:48:37 - INFO - __main__ - ['Company']
05/22/2022 23:48:37 - INFO - __main__ - Tokenizing Input ...
05/22/2022 23:48:37 - INFO - __main__ - Tokenizing Output ...
05/22/2022 23:48:38 - INFO - __main__ - Loaded 896 examples from train data
05/22/2022 23:48:38 - INFO - __main__ - Start tokenizing ... 896 instances
05/22/2022 23:48:38 - INFO - __main__ - Printing 3 examples
05/22/2022 23:48:38 - INFO - __main__ -  [dbpedia_14] Shock Records (now part of Shock Entertainment) is Australia's largest independent record label operating for 24 years releasing independent music to the Australian marketplace.Current major music partners include Cooking Vinyl (including Marilyn Manson The Prodigy Groove Armada and Underworld); Sunday Best (Kitty Daisy & Lewis); Rise Records (Of Mice & Men Miss May I Hot Water Music); Vagrant (including Edward Sharpe and the Magnetic Zeros); Sumerian (Asking Alexandria I See Stars Veil of Maya); and Rough Trade (including Belle and Sebastian).
05/22/2022 23:48:38 - INFO - __main__ - ['Company']
05/22/2022 23:48:38 - INFO - __main__ -  [dbpedia_14] Actio Corporation is an American software company founded in 1996. The company began as an MSDS authoring and data management service using a hosted model which is now known as SaaS or software-as-a-service but in the mid-90's was called ASP.
05/22/2022 23:48:38 - INFO - __main__ - ['Company']
05/22/2022 23:48:38 - INFO - __main__ -  [dbpedia_14] Pacific Corporate Group is a global alternative investment management and advisory company headquartered in La Jolla California. PCG together with affiliates and subsidiaries (together the affiliates) currently manage over $17 billion in assets and has invested and advised upon over $44 billion since 1990. PCG and its affiliates operate through offices based out of La Jolla New York Danvers Washington D.C Singapore and Hong Kong
05/22/2022 23:48:38 - INFO - __main__ - ['Company']
05/22/2022 23:48:38 - INFO - __main__ - Tokenizing Input ...
05/22/2022 23:48:38 - INFO - __main__ - Tokenizing Output ...
05/22/2022 23:48:39 - INFO - __main__ - Loaded 896 examples from dev data
05/22/2022 23:48:55 - INFO - __main__ - try to initialize prompt embeddings
05/22/2022 23:48:55 - INFO - __main__ - task name: dbpedia_14
05/22/2022 23:48:56 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 23:48:56 - INFO - __main__ - Starting training!
05/22/2022 23:48:58 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.8555752298008593 on epoch=53
05/22/2022 23:48:58 - INFO - __main__ - save last model!
05/22/2022 23:48:59 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/22/2022 23:48:59 - INFO - __main__ - Start tokenizing ... 3500 instances
05/22/2022 23:48:59 - INFO - __main__ - Printing 3 examples
05/22/2022 23:48:59 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/22/2022 23:48:59 - INFO - __main__ - ['Animal']
05/22/2022 23:48:59 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/22/2022 23:48:59 - INFO - __main__ - ['Animal']
05/22/2022 23:48:59 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/22/2022 23:48:59 - INFO - __main__ - ['Village']
05/22/2022 23:48:59 - INFO - __main__ - Tokenizing Input ...
05/22/2022 23:49:00 - INFO - __main__ - Tokenizing Output ...
05/22/2022 23:49:04 - INFO - __main__ - Loaded 3500 examples from test data
05/22/2022 23:51:07 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down64shot/singletask-dbpedia_14/dbpedia_14_64_42_0.5_8_predictions.txt
05/22/2022 23:51:07 - INFO - __main__ - Classification-F1 on test data: 0.6415
05/22/2022 23:51:08 - INFO - __main__ - prefix=dbpedia_14_64_42, lr=0.5, bsz=8, dev_performance=0.9170469462106088, test_performance=0.6415222693604995
05/22/2022 23:51:08 - INFO - __main__ - Running ... prefix=dbpedia_14_64_42, lr=0.4, bsz=8 ...
05/22/2022 23:51:09 - INFO - __main__ - Start tokenizing ... 896 instances
05/22/2022 23:51:09 - INFO - __main__ - Printing 3 examples
05/22/2022 23:51:09 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/22/2022 23:51:09 - INFO - __main__ - ['Company']
05/22/2022 23:51:09 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/22/2022 23:51:09 - INFO - __main__ - ['Company']
05/22/2022 23:51:09 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/22/2022 23:51:09 - INFO - __main__ - ['Company']
05/22/2022 23:51:09 - INFO - __main__ - Tokenizing Input ...
05/22/2022 23:51:09 - INFO - __main__ - Tokenizing Output ...
05/22/2022 23:51:10 - INFO - __main__ - Loaded 896 examples from train data
05/22/2022 23:51:10 - INFO - __main__ - Start tokenizing ... 896 instances
05/22/2022 23:51:10 - INFO - __main__ - Printing 3 examples
05/22/2022 23:51:10 - INFO - __main__ -  [dbpedia_14] Shock Records (now part of Shock Entertainment) is Australia's largest independent record label operating for 24 years releasing independent music to the Australian marketplace.Current major music partners include Cooking Vinyl (including Marilyn Manson The Prodigy Groove Armada and Underworld); Sunday Best (Kitty Daisy & Lewis); Rise Records (Of Mice & Men Miss May I Hot Water Music); Vagrant (including Edward Sharpe and the Magnetic Zeros); Sumerian (Asking Alexandria I See Stars Veil of Maya); and Rough Trade (including Belle and Sebastian).
05/22/2022 23:51:10 - INFO - __main__ - ['Company']
05/22/2022 23:51:10 - INFO - __main__ -  [dbpedia_14] Actio Corporation is an American software company founded in 1996. The company began as an MSDS authoring and data management service using a hosted model which is now known as SaaS or software-as-a-service but in the mid-90's was called ASP.
05/22/2022 23:51:10 - INFO - __main__ - ['Company']
05/22/2022 23:51:10 - INFO - __main__ -  [dbpedia_14] Pacific Corporate Group is a global alternative investment management and advisory company headquartered in La Jolla California. PCG together with affiliates and subsidiaries (together the affiliates) currently manage over $17 billion in assets and has invested and advised upon over $44 billion since 1990. PCG and its affiliates operate through offices based out of La Jolla New York Danvers Washington D.C Singapore and Hong Kong
05/22/2022 23:51:10 - INFO - __main__ - ['Company']
05/22/2022 23:51:10 - INFO - __main__ - Tokenizing Input ...
05/22/2022 23:51:10 - INFO - __main__ - Tokenizing Output ...
05/22/2022 23:51:11 - INFO - __main__ - Loaded 896 examples from dev data
05/22/2022 23:51:30 - INFO - __main__ - try to initialize prompt embeddings
05/22/2022 23:51:30 - INFO - __main__ - task name: dbpedia_14
05/22/2022 23:51:31 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 23:51:31 - INFO - __main__ - Starting training!
05/22/2022 23:51:34 - INFO - __main__ - Step 10 Global step 10 Train loss 7.09 on epoch=0
05/22/2022 23:51:37 - INFO - __main__ - Step 20 Global step 20 Train loss 5.98 on epoch=0
05/22/2022 23:51:39 - INFO - __main__ - Step 30 Global step 30 Train loss 3.95 on epoch=0
05/22/2022 23:51:42 - INFO - __main__ - Step 40 Global step 40 Train loss 2.92 on epoch=0
05/22/2022 23:51:45 - INFO - __main__ - Step 50 Global step 50 Train loss 2.43 on epoch=0
05/22/2022 23:52:27 - INFO - __main__ - Global step 50 Train loss 4.47 Classification-F1 0.04247589484960125 on epoch=0
05/22/2022 23:52:27 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.04247589484960125 on epoch=0, global_step=50
05/22/2022 23:52:30 - INFO - __main__ - Step 60 Global step 60 Train loss 2.24 on epoch=1
05/22/2022 23:52:32 - INFO - __main__ - Step 70 Global step 70 Train loss 1.75 on epoch=1
05/22/2022 23:52:35 - INFO - __main__ - Step 80 Global step 80 Train loss 1.40 on epoch=1
05/22/2022 23:52:37 - INFO - __main__ - Step 90 Global step 90 Train loss 1.29 on epoch=1
05/22/2022 23:52:40 - INFO - __main__ - Step 100 Global step 100 Train loss 1.25 on epoch=1
05/22/2022 23:53:31 - INFO - __main__ - Global step 100 Train loss 1.59 Classification-F1 0.2047393532585097 on epoch=1
05/22/2022 23:53:31 - INFO - __main__ - Saving model with best Classification-F1: 0.04247589484960125 -> 0.2047393532585097 on epoch=1, global_step=100
05/22/2022 23:53:34 - INFO - __main__ - Step 110 Global step 110 Train loss 1.15 on epoch=1
05/22/2022 23:53:37 - INFO - __main__ - Step 120 Global step 120 Train loss 1.06 on epoch=2
05/22/2022 23:53:39 - INFO - __main__ - Step 130 Global step 130 Train loss 0.95 on epoch=2
05/22/2022 23:53:42 - INFO - __main__ - Step 140 Global step 140 Train loss 0.84 on epoch=2
05/22/2022 23:53:45 - INFO - __main__ - Step 150 Global step 150 Train loss 0.76 on epoch=2
05/22/2022 23:54:18 - INFO - __main__ - Global step 150 Train loss 0.95 Classification-F1 0.3288697025663967 on epoch=2
05/22/2022 23:54:18 - INFO - __main__ - Saving model with best Classification-F1: 0.2047393532585097 -> 0.3288697025663967 on epoch=2, global_step=150
05/22/2022 23:54:21 - INFO - __main__ - Step 160 Global step 160 Train loss 0.71 on epoch=2
05/22/2022 23:54:24 - INFO - __main__ - Step 170 Global step 170 Train loss 0.74 on epoch=3
05/22/2022 23:54:26 - INFO - __main__ - Step 180 Global step 180 Train loss 0.85 on epoch=3
05/22/2022 23:54:29 - INFO - __main__ - Step 190 Global step 190 Train loss 0.76 on epoch=3
05/22/2022 23:54:31 - INFO - __main__ - Step 200 Global step 200 Train loss 0.58 on epoch=3
05/22/2022 23:54:58 - INFO - __main__ - Global step 200 Train loss 0.73 Classification-F1 0.431926110666854 on epoch=3
05/22/2022 23:54:58 - INFO - __main__ - Saving model with best Classification-F1: 0.3288697025663967 -> 0.431926110666854 on epoch=3, global_step=200
05/22/2022 23:55:01 - INFO - __main__ - Step 210 Global step 210 Train loss 0.72 on epoch=3
05/22/2022 23:55:04 - INFO - __main__ - Step 220 Global step 220 Train loss 0.62 on epoch=3
05/22/2022 23:55:06 - INFO - __main__ - Step 230 Global step 230 Train loss 0.65 on epoch=4
05/22/2022 23:55:09 - INFO - __main__ - Step 240 Global step 240 Train loss 0.64 on epoch=4
05/22/2022 23:55:12 - INFO - __main__ - Step 250 Global step 250 Train loss 0.62 on epoch=4
05/22/2022 23:55:39 - INFO - __main__ - Global step 250 Train loss 0.65 Classification-F1 0.3052409958779592 on epoch=4
05/22/2022 23:55:41 - INFO - __main__ - Step 260 Global step 260 Train loss 0.56 on epoch=4
05/22/2022 23:55:44 - INFO - __main__ - Step 270 Global step 270 Train loss 0.47 on epoch=4
05/22/2022 23:55:47 - INFO - __main__ - Step 280 Global step 280 Train loss 0.53 on epoch=4
05/22/2022 23:55:49 - INFO - __main__ - Step 290 Global step 290 Train loss 0.58 on epoch=5
05/22/2022 23:55:52 - INFO - __main__ - Step 300 Global step 300 Train loss 0.52 on epoch=5
05/22/2022 23:56:22 - INFO - __main__ - Global step 300 Train loss 0.53 Classification-F1 0.31495199610369073 on epoch=5
05/22/2022 23:56:24 - INFO - __main__ - Step 310 Global step 310 Train loss 0.48 on epoch=5
05/22/2022 23:56:27 - INFO - __main__ - Step 320 Global step 320 Train loss 0.46 on epoch=5
05/22/2022 23:56:30 - INFO - __main__ - Step 330 Global step 330 Train loss 0.40 on epoch=5
05/22/2022 23:56:32 - INFO - __main__ - Step 340 Global step 340 Train loss 0.42 on epoch=6
05/22/2022 23:56:35 - INFO - __main__ - Step 350 Global step 350 Train loss 0.43 on epoch=6
05/22/2022 23:56:59 - INFO - __main__ - Global step 350 Train loss 0.44 Classification-F1 0.44643448414954684 on epoch=6
05/22/2022 23:56:59 - INFO - __main__ - Saving model with best Classification-F1: 0.431926110666854 -> 0.44643448414954684 on epoch=6, global_step=350
05/22/2022 23:57:02 - INFO - __main__ - Step 360 Global step 360 Train loss 0.38 on epoch=6
05/22/2022 23:57:05 - INFO - __main__ - Step 370 Global step 370 Train loss 0.39 on epoch=6
05/22/2022 23:57:07 - INFO - __main__ - Step 380 Global step 380 Train loss 0.44 on epoch=6
05/22/2022 23:57:10 - INFO - __main__ - Step 390 Global step 390 Train loss 0.32 on epoch=6
05/22/2022 23:57:13 - INFO - __main__ - Step 400 Global step 400 Train loss 0.42 on epoch=7
05/22/2022 23:57:39 - INFO - __main__ - Global step 400 Train loss 0.39 Classification-F1 0.5454594245122864 on epoch=7
05/22/2022 23:57:39 - INFO - __main__ - Saving model with best Classification-F1: 0.44643448414954684 -> 0.5454594245122864 on epoch=7, global_step=400
05/22/2022 23:57:42 - INFO - __main__ - Step 410 Global step 410 Train loss 0.43 on epoch=7
05/22/2022 23:57:44 - INFO - __main__ - Step 420 Global step 420 Train loss 0.29 on epoch=7
05/22/2022 23:57:47 - INFO - __main__ - Step 430 Global step 430 Train loss 0.34 on epoch=7
05/22/2022 23:57:50 - INFO - __main__ - Step 440 Global step 440 Train loss 0.31 on epoch=7
05/22/2022 23:57:52 - INFO - __main__ - Step 450 Global step 450 Train loss 0.27 on epoch=8
05/22/2022 23:58:19 - INFO - __main__ - Global step 450 Train loss 0.33 Classification-F1 0.43075219651692065 on epoch=8
05/22/2022 23:58:21 - INFO - __main__ - Step 460 Global step 460 Train loss 0.32 on epoch=8
05/22/2022 23:58:24 - INFO - __main__ - Step 470 Global step 470 Train loss 0.33 on epoch=8
05/22/2022 23:58:27 - INFO - __main__ - Step 480 Global step 480 Train loss 0.32 on epoch=8
05/22/2022 23:58:29 - INFO - __main__ - Step 490 Global step 490 Train loss 0.21 on epoch=8
05/22/2022 23:58:32 - INFO - __main__ - Step 500 Global step 500 Train loss 0.23 on epoch=8
05/22/2022 23:58:57 - INFO - __main__ - Global step 500 Train loss 0.28 Classification-F1 0.44428961352902024 on epoch=8
05/22/2022 23:59:00 - INFO - __main__ - Step 510 Global step 510 Train loss 0.29 on epoch=9
05/22/2022 23:59:02 - INFO - __main__ - Step 520 Global step 520 Train loss 0.35 on epoch=9
05/22/2022 23:59:05 - INFO - __main__ - Step 530 Global step 530 Train loss 0.28 on epoch=9
05/22/2022 23:59:07 - INFO - __main__ - Step 540 Global step 540 Train loss 0.27 on epoch=9
05/22/2022 23:59:10 - INFO - __main__ - Step 550 Global step 550 Train loss 0.27 on epoch=9
05/22/2022 23:59:35 - INFO - __main__ - Global step 550 Train loss 0.29 Classification-F1 0.5385596029868209 on epoch=9
05/22/2022 23:59:38 - INFO - __main__ - Step 560 Global step 560 Train loss 0.20 on epoch=9
05/22/2022 23:59:40 - INFO - __main__ - Step 570 Global step 570 Train loss 0.35 on epoch=10
05/22/2022 23:59:43 - INFO - __main__ - Step 580 Global step 580 Train loss 0.26 on epoch=10
05/22/2022 23:59:46 - INFO - __main__ - Step 590 Global step 590 Train loss 0.21 on epoch=10
05/22/2022 23:59:48 - INFO - __main__ - Step 600 Global step 600 Train loss 0.22 on epoch=10
05/23/2022 00:00:25 - INFO - __main__ - Global step 600 Train loss 0.25 Classification-F1 0.5282128796162197 on epoch=10
05/23/2022 00:00:28 - INFO - __main__ - Step 610 Global step 610 Train loss 0.17 on epoch=10
05/23/2022 00:00:30 - INFO - __main__ - Step 620 Global step 620 Train loss 0.23 on epoch=11
05/23/2022 00:00:33 - INFO - __main__ - Step 630 Global step 630 Train loss 0.29 on epoch=11
05/23/2022 00:00:36 - INFO - __main__ - Step 640 Global step 640 Train loss 0.20 on epoch=11
05/23/2022 00:00:38 - INFO - __main__ - Step 650 Global step 650 Train loss 0.19 on epoch=11
05/23/2022 00:01:04 - INFO - __main__ - Global step 650 Train loss 0.22 Classification-F1 0.39482055681811384 on epoch=11
05/23/2022 00:01:06 - INFO - __main__ - Step 660 Global step 660 Train loss 0.19 on epoch=11
05/23/2022 00:01:09 - INFO - __main__ - Step 670 Global step 670 Train loss 0.20 on epoch=11
05/23/2022 00:01:12 - INFO - __main__ - Step 680 Global step 680 Train loss 0.19 on epoch=12
05/23/2022 00:01:14 - INFO - __main__ - Step 690 Global step 690 Train loss 0.26 on epoch=12
05/23/2022 00:01:17 - INFO - __main__ - Step 700 Global step 700 Train loss 0.18 on epoch=12
05/23/2022 00:01:41 - INFO - __main__ - Global step 700 Train loss 0.20 Classification-F1 0.44863011598041597 on epoch=12
05/23/2022 00:01:44 - INFO - __main__ - Step 710 Global step 710 Train loss 0.20 on epoch=12
05/23/2022 00:01:46 - INFO - __main__ - Step 720 Global step 720 Train loss 0.13 on epoch=12
05/23/2022 00:01:49 - INFO - __main__ - Step 730 Global step 730 Train loss 0.16 on epoch=13
05/23/2022 00:01:52 - INFO - __main__ - Step 740 Global step 740 Train loss 0.25 on epoch=13
05/23/2022 00:01:54 - INFO - __main__ - Step 750 Global step 750 Train loss 0.17 on epoch=13
05/23/2022 00:02:20 - INFO - __main__ - Global step 750 Train loss 0.18 Classification-F1 0.5943516352693918 on epoch=13
05/23/2022 00:02:20 - INFO - __main__ - Saving model with best Classification-F1: 0.5454594245122864 -> 0.5943516352693918 on epoch=13, global_step=750
05/23/2022 00:02:22 - INFO - __main__ - Step 760 Global step 760 Train loss 0.12 on epoch=13
05/23/2022 00:02:25 - INFO - __main__ - Step 770 Global step 770 Train loss 0.17 on epoch=13
05/23/2022 00:02:28 - INFO - __main__ - Step 780 Global step 780 Train loss 0.14 on epoch=13
05/23/2022 00:02:30 - INFO - __main__ - Step 790 Global step 790 Train loss 0.16 on epoch=14
05/23/2022 00:02:33 - INFO - __main__ - Step 800 Global step 800 Train loss 0.23 on epoch=14
05/23/2022 00:02:57 - INFO - __main__ - Global step 800 Train loss 0.17 Classification-F1 0.5762597093125024 on epoch=14
05/23/2022 00:03:00 - INFO - __main__ - Step 810 Global step 810 Train loss 0.15 on epoch=14
05/23/2022 00:03:03 - INFO - __main__ - Step 820 Global step 820 Train loss 0.10 on epoch=14
05/23/2022 00:03:05 - INFO - __main__ - Step 830 Global step 830 Train loss 0.18 on epoch=14
05/23/2022 00:03:08 - INFO - __main__ - Step 840 Global step 840 Train loss 0.11 on epoch=14
05/23/2022 00:03:10 - INFO - __main__ - Step 850 Global step 850 Train loss 0.15 on epoch=15
05/23/2022 00:03:49 - INFO - __main__ - Global step 850 Train loss 0.14 Classification-F1 0.5976741557006229 on epoch=15
05/23/2022 00:03:49 - INFO - __main__ - Saving model with best Classification-F1: 0.5943516352693918 -> 0.5976741557006229 on epoch=15, global_step=850
05/23/2022 00:03:52 - INFO - __main__ - Step 860 Global step 860 Train loss 0.15 on epoch=15
05/23/2022 00:03:54 - INFO - __main__ - Step 870 Global step 870 Train loss 0.25 on epoch=15
05/23/2022 00:03:57 - INFO - __main__ - Step 880 Global step 880 Train loss 0.14 on epoch=15
05/23/2022 00:03:59 - INFO - __main__ - Step 890 Global step 890 Train loss 0.22 on epoch=15
05/23/2022 00:04:02 - INFO - __main__ - Step 900 Global step 900 Train loss 0.11 on epoch=16
05/23/2022 00:04:27 - INFO - __main__ - Global step 900 Train loss 0.17 Classification-F1 0.5841172251516867 on epoch=16
05/23/2022 00:04:30 - INFO - __main__ - Step 910 Global step 910 Train loss 0.21 on epoch=16
05/23/2022 00:04:32 - INFO - __main__ - Step 920 Global step 920 Train loss 0.19 on epoch=16
05/23/2022 00:04:35 - INFO - __main__ - Step 930 Global step 930 Train loss 0.10 on epoch=16
05/23/2022 00:04:38 - INFO - __main__ - Step 940 Global step 940 Train loss 0.17 on epoch=16
05/23/2022 00:04:40 - INFO - __main__ - Step 950 Global step 950 Train loss 0.10 on epoch=16
05/23/2022 00:05:06 - INFO - __main__ - Global step 950 Train loss 0.15 Classification-F1 0.5313469129037074 on epoch=16
05/23/2022 00:05:08 - INFO - __main__ - Step 960 Global step 960 Train loss 0.15 on epoch=17
05/23/2022 00:05:11 - INFO - __main__ - Step 970 Global step 970 Train loss 0.25 on epoch=17
05/23/2022 00:05:14 - INFO - __main__ - Step 980 Global step 980 Train loss 0.12 on epoch=17
05/23/2022 00:05:16 - INFO - __main__ - Step 990 Global step 990 Train loss 0.12 on epoch=17
05/23/2022 00:05:19 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.12 on epoch=17
05/23/2022 00:05:45 - INFO - __main__ - Global step 1000 Train loss 0.15 Classification-F1 0.6283242814228077 on epoch=17
05/23/2022 00:05:45 - INFO - __main__ - Saving model with best Classification-F1: 0.5976741557006229 -> 0.6283242814228077 on epoch=17, global_step=1000
05/23/2022 00:05:48 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.13 on epoch=18
05/23/2022 00:05:50 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.10 on epoch=18
05/23/2022 00:05:53 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.16 on epoch=18
05/23/2022 00:05:56 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.10 on epoch=18
05/23/2022 00:05:58 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.09 on epoch=18
05/23/2022 00:06:28 - INFO - __main__ - Global step 1050 Train loss 0.12 Classification-F1 0.6583444787061866 on epoch=18
05/23/2022 00:06:28 - INFO - __main__ - Saving model with best Classification-F1: 0.6283242814228077 -> 0.6583444787061866 on epoch=18, global_step=1050
05/23/2022 00:06:31 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.08 on epoch=18
05/23/2022 00:06:33 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.10 on epoch=19
05/23/2022 00:06:36 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.13 on epoch=19
05/23/2022 00:06:38 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.08 on epoch=19
05/23/2022 00:06:41 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.08 on epoch=19
05/23/2022 00:07:12 - INFO - __main__ - Global step 1100 Train loss 0.09 Classification-F1 0.7035926767190304 on epoch=19
05/23/2022 00:07:12 - INFO - __main__ - Saving model with best Classification-F1: 0.6583444787061866 -> 0.7035926767190304 on epoch=19, global_step=1100
05/23/2022 00:07:15 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.19 on epoch=19
05/23/2022 00:07:18 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.12 on epoch=19
05/23/2022 00:07:20 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.10 on epoch=20
05/23/2022 00:07:23 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.13 on epoch=20
05/23/2022 00:07:26 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.06 on epoch=20
05/23/2022 00:07:51 - INFO - __main__ - Global step 1150 Train loss 0.12 Classification-F1 0.7456890979217448 on epoch=20
05/23/2022 00:07:51 - INFO - __main__ - Saving model with best Classification-F1: 0.7035926767190304 -> 0.7456890979217448 on epoch=20, global_step=1150
05/23/2022 00:07:53 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.07 on epoch=20
05/23/2022 00:07:56 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.05 on epoch=20
05/23/2022 00:07:59 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.08 on epoch=21
05/23/2022 00:08:01 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.14 on epoch=21
05/23/2022 00:08:04 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.10 on epoch=21
05/23/2022 00:08:28 - INFO - __main__ - Global step 1200 Train loss 0.09 Classification-F1 0.7347620792654901 on epoch=21
05/23/2022 00:08:31 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.11 on epoch=21
05/23/2022 00:08:33 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.07 on epoch=21
05/23/2022 00:08:36 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.07 on epoch=21
05/23/2022 00:08:39 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.10 on epoch=22
05/23/2022 00:08:41 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.21 on epoch=22
05/23/2022 00:09:04 - INFO - __main__ - Global step 1250 Train loss 0.11 Classification-F1 0.5751298454041542 on epoch=22
05/23/2022 00:09:07 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.09 on epoch=22
05/23/2022 00:09:10 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.05 on epoch=22
05/23/2022 00:09:12 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.04 on epoch=22
05/23/2022 00:09:15 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.05 on epoch=23
05/23/2022 00:09:18 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.06 on epoch=23
05/23/2022 00:09:45 - INFO - __main__ - Global step 1300 Train loss 0.06 Classification-F1 0.6811240887545768 on epoch=23
05/23/2022 00:09:48 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.10 on epoch=23
05/23/2022 00:09:51 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.04 on epoch=23
05/23/2022 00:09:53 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.18 on epoch=23
05/23/2022 00:09:56 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.07 on epoch=23
05/23/2022 00:09:59 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.06 on epoch=24
05/23/2022 00:10:24 - INFO - __main__ - Global step 1350 Train loss 0.09 Classification-F1 0.7574064613152057 on epoch=24
05/23/2022 00:10:24 - INFO - __main__ - Saving model with best Classification-F1: 0.7456890979217448 -> 0.7574064613152057 on epoch=24, global_step=1350
05/23/2022 00:10:27 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.18 on epoch=24
05/23/2022 00:10:29 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.07 on epoch=24
05/23/2022 00:10:32 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.06 on epoch=24
05/23/2022 00:10:34 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.05 on epoch=24
05/23/2022 00:10:37 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.06 on epoch=24
05/23/2022 00:11:05 - INFO - __main__ - Global step 1400 Train loss 0.09 Classification-F1 0.8214008793772585 on epoch=24
05/23/2022 00:11:05 - INFO - __main__ - Saving model with best Classification-F1: 0.7574064613152057 -> 0.8214008793772585 on epoch=24, global_step=1400
05/23/2022 00:11:08 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.03 on epoch=25
05/23/2022 00:11:10 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.10 on epoch=25
05/23/2022 00:11:13 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.06 on epoch=25
05/23/2022 00:11:15 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.06 on epoch=25
05/23/2022 00:11:18 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.05 on epoch=25
05/23/2022 00:11:42 - INFO - __main__ - Global step 1450 Train loss 0.06 Classification-F1 0.6972144516945442 on epoch=25
05/23/2022 00:11:45 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.07 on epoch=26
05/23/2022 00:11:48 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.06 on epoch=26
05/23/2022 00:11:50 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.05 on epoch=26
05/23/2022 00:11:53 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.09 on epoch=26
05/23/2022 00:11:56 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.06 on epoch=26
05/23/2022 00:12:20 - INFO - __main__ - Global step 1500 Train loss 0.07 Classification-F1 0.7720709365706672 on epoch=26
05/23/2022 00:12:22 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.04 on epoch=26
05/23/2022 00:12:25 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.07 on epoch=27
05/23/2022 00:12:28 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.08 on epoch=27
05/23/2022 00:12:30 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.05 on epoch=27
05/23/2022 00:12:33 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.03 on epoch=27
05/23/2022 00:12:57 - INFO - __main__ - Global step 1550 Train loss 0.05 Classification-F1 0.6969504335552701 on epoch=27
05/23/2022 00:12:59 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.05 on epoch=27
05/23/2022 00:13:02 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.04 on epoch=28
05/23/2022 00:13:05 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.06 on epoch=28
05/23/2022 00:13:07 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.11 on epoch=28
05/23/2022 00:13:10 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.05 on epoch=28
05/23/2022 00:13:34 - INFO - __main__ - Global step 1600 Train loss 0.06 Classification-F1 0.7937548948745872 on epoch=28
05/23/2022 00:13:36 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.06 on epoch=28
05/23/2022 00:13:39 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.04 on epoch=28
05/23/2022 00:13:42 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.02 on epoch=29
05/23/2022 00:13:44 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.03 on epoch=29
05/23/2022 00:13:47 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.07 on epoch=29
05/23/2022 00:14:11 - INFO - __main__ - Global step 1650 Train loss 0.05 Classification-F1 0.7994613226422796 on epoch=29
05/23/2022 00:14:14 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.04 on epoch=29
05/23/2022 00:14:16 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.08 on epoch=29
05/23/2022 00:14:19 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.08 on epoch=29
05/23/2022 00:14:22 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.07 on epoch=30
05/23/2022 00:14:24 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.07 on epoch=30
05/23/2022 00:14:48 - INFO - __main__ - Global step 1700 Train loss 0.07 Classification-F1 0.7565201667262027 on epoch=30
05/23/2022 00:14:51 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.09 on epoch=30
05/23/2022 00:14:53 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.05 on epoch=30
05/23/2022 00:14:56 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.06 on epoch=30
05/23/2022 00:14:59 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.04 on epoch=31
05/23/2022 00:15:01 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.06 on epoch=31
05/23/2022 00:15:25 - INFO - __main__ - Global step 1750 Train loss 0.06 Classification-F1 0.7192508654590991 on epoch=31
05/23/2022 00:15:28 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.03 on epoch=31
05/23/2022 00:15:30 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.03 on epoch=31
05/23/2022 00:15:33 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.08 on epoch=31
05/23/2022 00:15:36 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.04 on epoch=31
05/23/2022 00:15:38 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.03 on epoch=32
05/23/2022 00:16:03 - INFO - __main__ - Global step 1800 Train loss 0.04 Classification-F1 0.8443359572405638 on epoch=32
05/23/2022 00:16:03 - INFO - __main__ - Saving model with best Classification-F1: 0.8214008793772585 -> 0.8443359572405638 on epoch=32, global_step=1800
05/23/2022 00:16:06 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.09 on epoch=32
05/23/2022 00:16:09 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.04 on epoch=32
05/23/2022 00:16:11 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.06 on epoch=32
05/23/2022 00:16:14 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.05 on epoch=32
05/23/2022 00:16:17 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.04 on epoch=33
05/23/2022 00:16:41 - INFO - __main__ - Global step 1850 Train loss 0.06 Classification-F1 0.7989130408540137 on epoch=33
05/23/2022 00:16:43 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.04 on epoch=33
05/23/2022 00:16:46 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.05 on epoch=33
05/23/2022 00:16:49 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=33
05/23/2022 00:16:51 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.07 on epoch=33
05/23/2022 00:16:54 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=33
05/23/2022 00:17:19 - INFO - __main__ - Global step 1900 Train loss 0.04 Classification-F1 0.7555155160232919 on epoch=33
05/23/2022 00:17:21 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=34
05/23/2022 00:17:24 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.12 on epoch=34
05/23/2022 00:17:27 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=34
05/23/2022 00:17:29 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=34
05/23/2022 00:17:32 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.04 on epoch=34
05/23/2022 00:18:01 - INFO - __main__ - Global step 1950 Train loss 0.05 Classification-F1 0.9820701590680925 on epoch=34
05/23/2022 00:18:01 - INFO - __main__ - Saving model with best Classification-F1: 0.8443359572405638 -> 0.9820701590680925 on epoch=34, global_step=1950
05/23/2022 00:18:04 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=34
05/23/2022 00:18:07 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.06 on epoch=35
05/23/2022 00:18:09 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.05 on epoch=35
05/23/2022 00:18:12 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=35
05/23/2022 00:18:15 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.03 on epoch=35
05/23/2022 00:18:38 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.7954929419753757 on epoch=35
05/23/2022 00:18:41 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.03 on epoch=35
05/23/2022 00:18:44 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.03 on epoch=36
05/23/2022 00:18:46 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.05 on epoch=36
05/23/2022 00:18:49 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.07 on epoch=36
05/23/2022 00:18:52 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.03 on epoch=36
05/23/2022 00:19:21 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.8422016697009049 on epoch=36
05/23/2022 00:19:24 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.05 on epoch=36
05/23/2022 00:19:27 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.04 on epoch=36
05/23/2022 00:19:29 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.06 on epoch=37
05/23/2022 00:19:32 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.04 on epoch=37
05/23/2022 00:19:35 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.04 on epoch=37
05/23/2022 00:19:58 - INFO - __main__ - Global step 2100 Train loss 0.05 Classification-F1 0.57871732675416 on epoch=37
05/23/2022 00:20:01 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=37
05/23/2022 00:20:03 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.03 on epoch=37
05/23/2022 00:20:06 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=38
05/23/2022 00:20:09 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.07 on epoch=38
05/23/2022 00:20:11 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.04 on epoch=38
05/23/2022 00:20:35 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.6526289432552879 on epoch=38
05/23/2022 00:20:38 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.05 on epoch=38
05/23/2022 00:20:40 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.04 on epoch=38
05/23/2022 00:20:43 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=38
05/23/2022 00:20:46 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=39
05/23/2022 00:20:48 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.09 on epoch=39
05/23/2022 00:21:12 - INFO - __main__ - Global step 2200 Train loss 0.05 Classification-F1 0.7125006935101433 on epoch=39
05/23/2022 00:21:14 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=39
05/23/2022 00:21:17 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=39
05/23/2022 00:21:20 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.06 on epoch=39
05/23/2022 00:21:22 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.03 on epoch=39
05/23/2022 00:21:25 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.03 on epoch=40
05/23/2022 00:21:49 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.7546664699342275 on epoch=40
05/23/2022 00:21:51 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.06 on epoch=40
05/23/2022 00:21:54 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=40
05/23/2022 00:21:56 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.16 on epoch=40
05/23/2022 00:21:59 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.04 on epoch=40
05/23/2022 00:22:02 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=41
05/23/2022 00:22:25 - INFO - __main__ - Global step 2300 Train loss 0.06 Classification-F1 0.80343129426314 on epoch=41
05/23/2022 00:22:27 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.04 on epoch=41
05/23/2022 00:22:30 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=41
05/23/2022 00:22:33 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=41
05/23/2022 00:22:35 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=41
05/23/2022 00:22:38 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.05 on epoch=41
05/23/2022 00:23:02 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.7131147665828276 on epoch=41
05/23/2022 00:23:04 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=42
05/23/2022 00:23:07 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.14 on epoch=42
05/23/2022 00:23:10 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=42
05/23/2022 00:23:12 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=42
05/23/2022 00:23:15 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.05 on epoch=42
05/23/2022 00:23:38 - INFO - __main__ - Global step 2400 Train loss 0.05 Classification-F1 0.7985098538334302 on epoch=42
05/23/2022 00:23:41 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=43
05/23/2022 00:23:44 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.03 on epoch=43
05/23/2022 00:23:46 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.04 on epoch=43
05/23/2022 00:23:49 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=43
05/23/2022 00:23:51 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.03 on epoch=43
05/23/2022 00:24:15 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.7238978389690991 on epoch=43
05/23/2022 00:24:18 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.04 on epoch=43
05/23/2022 00:24:21 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=44
05/23/2022 00:24:23 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.04 on epoch=44
05/23/2022 00:24:26 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.03 on epoch=44
05/23/2022 00:24:28 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=44
05/23/2022 00:24:52 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.6879183792217016 on epoch=44
05/23/2022 00:24:54 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.05 on epoch=44
05/23/2022 00:24:57 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=44
05/23/2022 00:24:59 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.03 on epoch=45
05/23/2022 00:25:02 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.06 on epoch=45
05/23/2022 00:25:05 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=45
05/23/2022 00:25:28 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.7228457850064353 on epoch=45
05/23/2022 00:25:31 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.05 on epoch=45
05/23/2022 00:25:33 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=45
05/23/2022 00:25:36 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=46
05/23/2022 00:25:39 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.06 on epoch=46
05/23/2022 00:25:41 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=46
05/23/2022 00:26:04 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.5847946329503694 on epoch=46
05/23/2022 00:26:07 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=46
05/23/2022 00:26:09 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.05 on epoch=46
05/23/2022 00:26:12 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.03 on epoch=46
05/23/2022 00:26:14 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=47
05/23/2022 00:26:17 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.03 on epoch=47
05/23/2022 00:26:40 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.6888393659224632 on epoch=47
05/23/2022 00:26:43 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=47
05/23/2022 00:26:46 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=47
05/23/2022 00:26:48 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.06 on epoch=47
05/23/2022 00:26:51 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=48
05/23/2022 00:26:54 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=48
05/23/2022 00:27:18 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.8475252474544117 on epoch=48
05/23/2022 00:27:20 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=48
05/23/2022 00:27:23 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=48
05/23/2022 00:27:25 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.03 on epoch=48
05/23/2022 00:27:28 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=48
05/23/2022 00:27:31 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=49
05/23/2022 00:27:54 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.8518545557950494 on epoch=49
05/23/2022 00:27:56 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.06 on epoch=49
05/23/2022 00:27:59 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=49
05/23/2022 00:28:02 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.03 on epoch=49
05/23/2022 00:28:04 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=49
05/23/2022 00:28:07 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=49
05/23/2022 00:28:30 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.8033736842541845 on epoch=49
05/23/2022 00:28:33 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=50
05/23/2022 00:28:35 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=50
05/23/2022 00:28:38 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=50
05/23/2022 00:28:41 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.03 on epoch=50
05/23/2022 00:28:43 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=50
05/23/2022 00:29:08 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.6949315695490187 on epoch=50
05/23/2022 00:29:11 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=51
05/23/2022 00:29:13 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.06 on epoch=51
05/23/2022 00:29:16 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.05 on epoch=51
05/23/2022 00:29:18 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=51
05/23/2022 00:29:21 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.03 on epoch=51
05/23/2022 00:29:45 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.7746784482761051 on epoch=51
05/23/2022 00:29:47 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.04 on epoch=51
05/23/2022 00:29:50 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=52
05/23/2022 00:29:52 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=52
05/23/2022 00:29:55 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=52
05/23/2022 00:29:58 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=52
05/23/2022 00:30:21 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.7801421524394186 on epoch=52
05/23/2022 00:30:23 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=52
05/23/2022 00:30:26 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=53
05/23/2022 00:30:29 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.05 on epoch=53
05/23/2022 00:30:31 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.04 on epoch=53
05/23/2022 00:30:34 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=53
05/23/2022 00:30:35 - INFO - __main__ - Start tokenizing ... 896 instances
05/23/2022 00:30:35 - INFO - __main__ - Printing 3 examples
05/23/2022 00:30:35 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/23/2022 00:30:35 - INFO - __main__ - ['Company']
05/23/2022 00:30:35 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/23/2022 00:30:35 - INFO - __main__ - ['Company']
05/23/2022 00:30:35 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/23/2022 00:30:35 - INFO - __main__ - ['Company']
05/23/2022 00:30:35 - INFO - __main__ - Tokenizing Input ...
05/23/2022 00:30:36 - INFO - __main__ - Tokenizing Output ...
05/23/2022 00:30:36 - INFO - __main__ - Loaded 896 examples from train data
05/23/2022 00:30:37 - INFO - __main__ - Start tokenizing ... 896 instances
05/23/2022 00:30:37 - INFO - __main__ - Printing 3 examples
05/23/2022 00:30:37 - INFO - __main__ -  [dbpedia_14] Shock Records (now part of Shock Entertainment) is Australia's largest independent record label operating for 24 years releasing independent music to the Australian marketplace.Current major music partners include Cooking Vinyl (including Marilyn Manson The Prodigy Groove Armada and Underworld); Sunday Best (Kitty Daisy & Lewis); Rise Records (Of Mice & Men Miss May I Hot Water Music); Vagrant (including Edward Sharpe and the Magnetic Zeros); Sumerian (Asking Alexandria I See Stars Veil of Maya); and Rough Trade (including Belle and Sebastian).
05/23/2022 00:30:37 - INFO - __main__ - ['Company']
05/23/2022 00:30:37 - INFO - __main__ -  [dbpedia_14] Actio Corporation is an American software company founded in 1996. The company began as an MSDS authoring and data management service using a hosted model which is now known as SaaS or software-as-a-service but in the mid-90's was called ASP.
05/23/2022 00:30:37 - INFO - __main__ - ['Company']
05/23/2022 00:30:37 - INFO - __main__ -  [dbpedia_14] Pacific Corporate Group is a global alternative investment management and advisory company headquartered in La Jolla California. PCG together with affiliates and subsidiaries (together the affiliates) currently manage over $17 billion in assets and has invested and advised upon over $44 billion since 1990. PCG and its affiliates operate through offices based out of La Jolla New York Danvers Washington D.C Singapore and Hong Kong
05/23/2022 00:30:37 - INFO - __main__ - ['Company']
05/23/2022 00:30:37 - INFO - __main__ - Tokenizing Input ...
05/23/2022 00:30:37 - INFO - __main__ - Tokenizing Output ...
05/23/2022 00:30:38 - INFO - __main__ - Loaded 896 examples from dev data
05/23/2022 00:30:53 - INFO - __main__ - try to initialize prompt embeddings
05/23/2022 00:30:53 - INFO - __main__ - task name: dbpedia_14
05/23/2022 00:30:54 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/23/2022 00:30:54 - INFO - __main__ - Starting training!
05/23/2022 00:30:57 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.7698654708952327 on epoch=53
05/23/2022 00:30:57 - INFO - __main__ - save last model!
05/23/2022 00:30:57 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/23/2022 00:30:57 - INFO - __main__ - Start tokenizing ... 3500 instances
05/23/2022 00:30:57 - INFO - __main__ - Printing 3 examples
05/23/2022 00:30:57 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/23/2022 00:30:57 - INFO - __main__ - ['Animal']
05/23/2022 00:30:57 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/23/2022 00:30:57 - INFO - __main__ - ['Animal']
05/23/2022 00:30:57 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/23/2022 00:30:57 - INFO - __main__ - ['Village']
05/23/2022 00:30:57 - INFO - __main__ - Tokenizing Input ...
05/23/2022 00:30:59 - INFO - __main__ - Tokenizing Output ...
05/23/2022 00:31:03 - INFO - __main__ - Loaded 3500 examples from test data
05/23/2022 00:33:07 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down64shot/singletask-dbpedia_14/dbpedia_14_64_42_0.4_8_predictions.txt
05/23/2022 00:33:07 - INFO - __main__ - Classification-F1 on test data: 0.6546
05/23/2022 00:33:07 - INFO - __main__ - prefix=dbpedia_14_64_42, lr=0.4, bsz=8, dev_performance=0.9820701590680925, test_performance=0.6545723851735561
05/23/2022 00:33:07 - INFO - __main__ - Running ... prefix=dbpedia_14_64_42, lr=0.3, bsz=8 ...
05/23/2022 00:33:08 - INFO - __main__ - Start tokenizing ... 896 instances
05/23/2022 00:33:08 - INFO - __main__ - Printing 3 examples
05/23/2022 00:33:08 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/23/2022 00:33:08 - INFO - __main__ - ['Company']
05/23/2022 00:33:08 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/23/2022 00:33:08 - INFO - __main__ - ['Company']
05/23/2022 00:33:08 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/23/2022 00:33:08 - INFO - __main__ - ['Company']
05/23/2022 00:33:08 - INFO - __main__ - Tokenizing Input ...
05/23/2022 00:33:09 - INFO - __main__ - Tokenizing Output ...
05/23/2022 00:33:09 - INFO - __main__ - Loaded 896 examples from train data
05/23/2022 00:33:09 - INFO - __main__ - Start tokenizing ... 896 instances
05/23/2022 00:33:09 - INFO - __main__ - Printing 3 examples
05/23/2022 00:33:09 - INFO - __main__ -  [dbpedia_14] Shock Records (now part of Shock Entertainment) is Australia's largest independent record label operating for 24 years releasing independent music to the Australian marketplace.Current major music partners include Cooking Vinyl (including Marilyn Manson The Prodigy Groove Armada and Underworld); Sunday Best (Kitty Daisy & Lewis); Rise Records (Of Mice & Men Miss May I Hot Water Music); Vagrant (including Edward Sharpe and the Magnetic Zeros); Sumerian (Asking Alexandria I See Stars Veil of Maya); and Rough Trade (including Belle and Sebastian).
05/23/2022 00:33:09 - INFO - __main__ - ['Company']
05/23/2022 00:33:09 - INFO - __main__ -  [dbpedia_14] Actio Corporation is an American software company founded in 1996. The company began as an MSDS authoring and data management service using a hosted model which is now known as SaaS or software-as-a-service but in the mid-90's was called ASP.
05/23/2022 00:33:09 - INFO - __main__ - ['Company']
05/23/2022 00:33:09 - INFO - __main__ -  [dbpedia_14] Pacific Corporate Group is a global alternative investment management and advisory company headquartered in La Jolla California. PCG together with affiliates and subsidiaries (together the affiliates) currently manage over $17 billion in assets and has invested and advised upon over $44 billion since 1990. PCG and its affiliates operate through offices based out of La Jolla New York Danvers Washington D.C Singapore and Hong Kong
05/23/2022 00:33:09 - INFO - __main__ - ['Company']
05/23/2022 00:33:09 - INFO - __main__ - Tokenizing Input ...
05/23/2022 00:33:10 - INFO - __main__ - Tokenizing Output ...
05/23/2022 00:33:11 - INFO - __main__ - Loaded 896 examples from dev data
05/23/2022 00:33:29 - INFO - __main__ - try to initialize prompt embeddings
05/23/2022 00:33:29 - INFO - __main__ - task name: dbpedia_14
05/23/2022 00:33:31 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/23/2022 00:33:31 - INFO - __main__ - Starting training!
05/23/2022 00:33:34 - INFO - __main__ - Step 10 Global step 10 Train loss 7.08 on epoch=0
05/23/2022 00:33:36 - INFO - __main__ - Step 20 Global step 20 Train loss 6.01 on epoch=0
05/23/2022 00:33:39 - INFO - __main__ - Step 30 Global step 30 Train loss 4.49 on epoch=0
05/23/2022 00:33:42 - INFO - __main__ - Step 40 Global step 40 Train loss 3.73 on epoch=0
05/23/2022 00:33:44 - INFO - __main__ - Step 50 Global step 50 Train loss 3.23 on epoch=0
05/23/2022 00:36:38 - INFO - __main__ - Global step 50 Train loss 4.91 Classification-F1 0.0060311686728203185 on epoch=0
05/23/2022 00:36:38 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0060311686728203185 on epoch=0, global_step=50
05/23/2022 00:36:40 - INFO - __main__ - Step 60 Global step 60 Train loss 2.75 on epoch=1
05/23/2022 00:36:43 - INFO - __main__ - Step 70 Global step 70 Train loss 2.37 on epoch=1
05/23/2022 00:36:46 - INFO - __main__ - Step 80 Global step 80 Train loss 1.91 on epoch=1
05/23/2022 00:36:48 - INFO - __main__ - Step 90 Global step 90 Train loss 1.80 on epoch=1
05/23/2022 00:36:51 - INFO - __main__ - Step 100 Global step 100 Train loss 1.72 on epoch=1
05/23/2022 00:37:27 - INFO - __main__ - Global step 100 Train loss 2.11 Classification-F1 0.14502139232242672 on epoch=1
05/23/2022 00:37:27 - INFO - __main__ - Saving model with best Classification-F1: 0.0060311686728203185 -> 0.14502139232242672 on epoch=1, global_step=100
05/23/2022 00:37:30 - INFO - __main__ - Step 110 Global step 110 Train loss 1.67 on epoch=1
05/23/2022 00:37:32 - INFO - __main__ - Step 120 Global step 120 Train loss 1.40 on epoch=2
05/23/2022 00:37:35 - INFO - __main__ - Step 130 Global step 130 Train loss 1.36 on epoch=2
05/23/2022 00:37:37 - INFO - __main__ - Step 140 Global step 140 Train loss 1.15 on epoch=2
05/23/2022 00:37:40 - INFO - __main__ - Step 150 Global step 150 Train loss 1.07 on epoch=2
05/23/2022 00:38:05 - INFO - __main__ - Global step 150 Train loss 1.33 Classification-F1 0.3086193108014251 on epoch=2
05/23/2022 00:38:05 - INFO - __main__ - Saving model with best Classification-F1: 0.14502139232242672 -> 0.3086193108014251 on epoch=2, global_step=150
05/23/2022 00:38:08 - INFO - __main__ - Step 160 Global step 160 Train loss 1.18 on epoch=2
05/23/2022 00:38:11 - INFO - __main__ - Step 170 Global step 170 Train loss 0.97 on epoch=3
05/23/2022 00:38:13 - INFO - __main__ - Step 180 Global step 180 Train loss 1.05 on epoch=3
05/23/2022 00:38:16 - INFO - __main__ - Step 190 Global step 190 Train loss 1.05 on epoch=3
05/23/2022 00:38:18 - INFO - __main__ - Step 200 Global step 200 Train loss 0.72 on epoch=3
05/23/2022 00:38:53 - INFO - __main__ - Global step 200 Train loss 0.99 Classification-F1 0.3667509877699958 on epoch=3
05/23/2022 00:38:53 - INFO - __main__ - Saving model with best Classification-F1: 0.3086193108014251 -> 0.3667509877699958 on epoch=3, global_step=200
05/23/2022 00:38:56 - INFO - __main__ - Step 210 Global step 210 Train loss 0.98 on epoch=3
05/23/2022 00:38:59 - INFO - __main__ - Step 220 Global step 220 Train loss 0.86 on epoch=3
05/23/2022 00:39:01 - INFO - __main__ - Step 230 Global step 230 Train loss 0.89 on epoch=4
05/23/2022 00:39:04 - INFO - __main__ - Step 240 Global step 240 Train loss 0.87 on epoch=4
05/23/2022 00:39:06 - INFO - __main__ - Step 250 Global step 250 Train loss 0.79 on epoch=4
05/23/2022 00:39:35 - INFO - __main__ - Global step 250 Train loss 0.88 Classification-F1 0.43959077517768874 on epoch=4
05/23/2022 00:39:35 - INFO - __main__ - Saving model with best Classification-F1: 0.3667509877699958 -> 0.43959077517768874 on epoch=4, global_step=250
05/23/2022 00:39:38 - INFO - __main__ - Step 260 Global step 260 Train loss 0.78 on epoch=4
05/23/2022 00:39:40 - INFO - __main__ - Step 270 Global step 270 Train loss 0.78 on epoch=4
05/23/2022 00:39:43 - INFO - __main__ - Step 280 Global step 280 Train loss 0.61 on epoch=4
05/23/2022 00:39:45 - INFO - __main__ - Step 290 Global step 290 Train loss 0.80 on epoch=5
05/23/2022 00:39:48 - INFO - __main__ - Step 300 Global step 300 Train loss 0.80 on epoch=5
05/23/2022 00:40:18 - INFO - __main__ - Global step 300 Train loss 0.75 Classification-F1 0.3170608913920084 on epoch=5
05/23/2022 00:40:20 - INFO - __main__ - Step 310 Global step 310 Train loss 0.63 on epoch=5
05/23/2022 00:40:23 - INFO - __main__ - Step 320 Global step 320 Train loss 0.62 on epoch=5
05/23/2022 00:40:26 - INFO - __main__ - Step 330 Global step 330 Train loss 0.66 on epoch=5
05/23/2022 00:40:28 - INFO - __main__ - Step 340 Global step 340 Train loss 0.69 on epoch=6
05/23/2022 00:40:31 - INFO - __main__ - Step 350 Global step 350 Train loss 0.67 on epoch=6
05/23/2022 00:40:57 - INFO - __main__ - Global step 350 Train loss 0.65 Classification-F1 0.4091318120684342 on epoch=6
05/23/2022 00:40:59 - INFO - __main__ - Step 360 Global step 360 Train loss 0.64 on epoch=6
05/23/2022 00:41:02 - INFO - __main__ - Step 370 Global step 370 Train loss 0.53 on epoch=6
05/23/2022 00:41:04 - INFO - __main__ - Step 380 Global step 380 Train loss 0.52 on epoch=6
05/23/2022 00:41:07 - INFO - __main__ - Step 390 Global step 390 Train loss 0.50 on epoch=6
05/23/2022 00:41:10 - INFO - __main__ - Step 400 Global step 400 Train loss 0.62 on epoch=7
05/23/2022 00:41:37 - INFO - __main__ - Global step 400 Train loss 0.56 Classification-F1 0.3641449247139537 on epoch=7
05/23/2022 00:41:40 - INFO - __main__ - Step 410 Global step 410 Train loss 0.64 on epoch=7
05/23/2022 00:41:42 - INFO - __main__ - Step 420 Global step 420 Train loss 0.47 on epoch=7
05/23/2022 00:41:45 - INFO - __main__ - Step 430 Global step 430 Train loss 0.54 on epoch=7
05/23/2022 00:41:47 - INFO - __main__ - Step 440 Global step 440 Train loss 0.51 on epoch=7
05/23/2022 00:41:50 - INFO - __main__ - Step 450 Global step 450 Train loss 0.47 on epoch=8
05/23/2022 00:42:18 - INFO - __main__ - Global step 450 Train loss 0.53 Classification-F1 0.37564532018127506 on epoch=8
05/23/2022 00:42:21 - INFO - __main__ - Step 460 Global step 460 Train loss 0.47 on epoch=8
05/23/2022 00:42:23 - INFO - __main__ - Step 470 Global step 470 Train loss 0.53 on epoch=8
05/23/2022 00:42:26 - INFO - __main__ - Step 480 Global step 480 Train loss 0.41 on epoch=8
05/23/2022 00:42:29 - INFO - __main__ - Step 490 Global step 490 Train loss 0.42 on epoch=8
05/23/2022 00:42:31 - INFO - __main__ - Step 500 Global step 500 Train loss 0.48 on epoch=8
05/23/2022 00:42:59 - INFO - __main__ - Global step 500 Train loss 0.46 Classification-F1 0.3674176497421852 on epoch=8
05/23/2022 00:43:02 - INFO - __main__ - Step 510 Global step 510 Train loss 0.49 on epoch=9
05/23/2022 00:43:05 - INFO - __main__ - Step 520 Global step 520 Train loss 0.57 on epoch=9
05/23/2022 00:43:07 - INFO - __main__ - Step 530 Global step 530 Train loss 0.46 on epoch=9
05/23/2022 00:43:10 - INFO - __main__ - Step 540 Global step 540 Train loss 0.34 on epoch=9
05/23/2022 00:43:12 - INFO - __main__ - Step 550 Global step 550 Train loss 0.38 on epoch=9
05/23/2022 00:43:39 - INFO - __main__ - Global step 550 Train loss 0.45 Classification-F1 0.4672963063021547 on epoch=9
05/23/2022 00:43:39 - INFO - __main__ - Saving model with best Classification-F1: 0.43959077517768874 -> 0.4672963063021547 on epoch=9, global_step=550
05/23/2022 00:43:41 - INFO - __main__ - Step 560 Global step 560 Train loss 0.42 on epoch=9
05/23/2022 00:43:44 - INFO - __main__ - Step 570 Global step 570 Train loss 0.43 on epoch=10
05/23/2022 00:43:47 - INFO - __main__ - Step 580 Global step 580 Train loss 0.39 on epoch=10
05/23/2022 00:43:49 - INFO - __main__ - Step 590 Global step 590 Train loss 0.39 on epoch=10
05/23/2022 00:43:52 - INFO - __main__ - Step 600 Global step 600 Train loss 0.39 on epoch=10
05/23/2022 00:44:19 - INFO - __main__ - Global step 600 Train loss 0.40 Classification-F1 0.5303677545852002 on epoch=10
05/23/2022 00:44:19 - INFO - __main__ - Saving model with best Classification-F1: 0.4672963063021547 -> 0.5303677545852002 on epoch=10, global_step=600
05/23/2022 00:44:22 - INFO - __main__ - Step 610 Global step 610 Train loss 0.37 on epoch=10
05/23/2022 00:44:24 - INFO - __main__ - Step 620 Global step 620 Train loss 0.31 on epoch=11
05/23/2022 00:44:27 - INFO - __main__ - Step 630 Global step 630 Train loss 0.38 on epoch=11
05/23/2022 00:44:29 - INFO - __main__ - Step 640 Global step 640 Train loss 0.27 on epoch=11
05/23/2022 00:44:32 - INFO - __main__ - Step 650 Global step 650 Train loss 0.35 on epoch=11
05/23/2022 00:44:59 - INFO - __main__ - Global step 650 Train loss 0.34 Classification-F1 0.6259813035800573 on epoch=11
05/23/2022 00:44:59 - INFO - __main__ - Saving model with best Classification-F1: 0.5303677545852002 -> 0.6259813035800573 on epoch=11, global_step=650
05/23/2022 00:45:01 - INFO - __main__ - Step 660 Global step 660 Train loss 0.41 on epoch=11
05/23/2022 00:45:04 - INFO - __main__ - Step 670 Global step 670 Train loss 0.32 on epoch=11
05/23/2022 00:45:07 - INFO - __main__ - Step 680 Global step 680 Train loss 0.34 on epoch=12
05/23/2022 00:45:09 - INFO - __main__ - Step 690 Global step 690 Train loss 0.39 on epoch=12
05/23/2022 00:45:12 - INFO - __main__ - Step 700 Global step 700 Train loss 0.31 on epoch=12
05/23/2022 00:45:39 - INFO - __main__ - Global step 700 Train loss 0.36 Classification-F1 0.7513082668963555 on epoch=12
05/23/2022 00:45:39 - INFO - __main__ - Saving model with best Classification-F1: 0.6259813035800573 -> 0.7513082668963555 on epoch=12, global_step=700
05/23/2022 00:45:41 - INFO - __main__ - Step 710 Global step 710 Train loss 0.35 on epoch=12
05/23/2022 00:45:44 - INFO - __main__ - Step 720 Global step 720 Train loss 0.26 on epoch=12
05/23/2022 00:45:47 - INFO - __main__ - Step 730 Global step 730 Train loss 0.27 on epoch=13
05/23/2022 00:45:49 - INFO - __main__ - Step 740 Global step 740 Train loss 0.26 on epoch=13
05/23/2022 00:45:52 - INFO - __main__ - Step 750 Global step 750 Train loss 0.35 on epoch=13
05/23/2022 00:46:19 - INFO - __main__ - Global step 750 Train loss 0.30 Classification-F1 0.6774770383386401 on epoch=13
05/23/2022 00:46:22 - INFO - __main__ - Step 760 Global step 760 Train loss 0.30 on epoch=13
05/23/2022 00:46:25 - INFO - __main__ - Step 770 Global step 770 Train loss 0.25 on epoch=13
05/23/2022 00:46:27 - INFO - __main__ - Step 780 Global step 780 Train loss 0.28 on epoch=13
05/23/2022 00:46:30 - INFO - __main__ - Step 790 Global step 790 Train loss 0.26 on epoch=14
05/23/2022 00:46:33 - INFO - __main__ - Step 800 Global step 800 Train loss 0.28 on epoch=14
05/23/2022 00:46:59 - INFO - __main__ - Global step 800 Train loss 0.27 Classification-F1 0.5241575418864083 on epoch=14
05/23/2022 00:47:01 - INFO - __main__ - Step 810 Global step 810 Train loss 0.28 on epoch=14
05/23/2022 00:47:04 - INFO - __main__ - Step 820 Global step 820 Train loss 0.22 on epoch=14
05/23/2022 00:47:06 - INFO - __main__ - Step 830 Global step 830 Train loss 0.22 on epoch=14
05/23/2022 00:47:09 - INFO - __main__ - Step 840 Global step 840 Train loss 0.21 on epoch=14
05/23/2022 00:47:12 - INFO - __main__ - Step 850 Global step 850 Train loss 0.19 on epoch=15
05/23/2022 00:47:40 - INFO - __main__ - Global step 850 Train loss 0.22 Classification-F1 0.770530891163686 on epoch=15
05/23/2022 00:47:40 - INFO - __main__ - Saving model with best Classification-F1: 0.7513082668963555 -> 0.770530891163686 on epoch=15, global_step=850
05/23/2022 00:47:42 - INFO - __main__ - Step 860 Global step 860 Train loss 0.22 on epoch=15
05/23/2022 00:47:45 - INFO - __main__ - Step 870 Global step 870 Train loss 0.18 on epoch=15
05/23/2022 00:47:48 - INFO - __main__ - Step 880 Global step 880 Train loss 0.23 on epoch=15
05/23/2022 00:47:50 - INFO - __main__ - Step 890 Global step 890 Train loss 0.17 on epoch=15
05/23/2022 00:47:53 - INFO - __main__ - Step 900 Global step 900 Train loss 0.26 on epoch=16
05/23/2022 00:48:20 - INFO - __main__ - Global step 900 Train loss 0.21 Classification-F1 0.5619679182952143 on epoch=16
05/23/2022 00:48:23 - INFO - __main__ - Step 910 Global step 910 Train loss 0.26 on epoch=16
05/23/2022 00:48:25 - INFO - __main__ - Step 920 Global step 920 Train loss 0.17 on epoch=16
05/23/2022 00:48:28 - INFO - __main__ - Step 930 Global step 930 Train loss 0.24 on epoch=16
05/23/2022 00:48:30 - INFO - __main__ - Step 940 Global step 940 Train loss 0.19 on epoch=16
05/23/2022 00:48:33 - INFO - __main__ - Step 950 Global step 950 Train loss 0.10 on epoch=16
05/23/2022 00:49:00 - INFO - __main__ - Global step 950 Train loss 0.19 Classification-F1 0.6303629779183677 on epoch=16
05/23/2022 00:49:03 - INFO - __main__ - Step 960 Global step 960 Train loss 0.20 on epoch=17
05/23/2022 00:49:05 - INFO - __main__ - Step 970 Global step 970 Train loss 0.24 on epoch=17
05/23/2022 00:49:08 - INFO - __main__ - Step 980 Global step 980 Train loss 0.10 on epoch=17
05/23/2022 00:49:10 - INFO - __main__ - Step 990 Global step 990 Train loss 0.17 on epoch=17
05/23/2022 00:49:13 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.18 on epoch=17
05/23/2022 00:49:39 - INFO - __main__ - Global step 1000 Train loss 0.18 Classification-F1 0.6725136343710153 on epoch=17
05/23/2022 00:49:42 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.12 on epoch=18
05/23/2022 00:49:44 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.13 on epoch=18
05/23/2022 00:49:47 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.17 on epoch=18
05/23/2022 00:49:49 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.11 on epoch=18
05/23/2022 00:49:52 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.13 on epoch=18
05/23/2022 00:50:17 - INFO - __main__ - Global step 1050 Train loss 0.13 Classification-F1 0.7549977972737945 on epoch=18
05/23/2022 00:50:20 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.14 on epoch=18
05/23/2022 00:50:22 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.12 on epoch=19
05/23/2022 00:50:25 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.18 on epoch=19
05/23/2022 00:50:27 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.13 on epoch=19
05/23/2022 00:50:30 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.07 on epoch=19
05/23/2022 00:50:55 - INFO - __main__ - Global step 1100 Train loss 0.13 Classification-F1 0.6734944429200305 on epoch=19
05/23/2022 00:50:57 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.15 on epoch=19
05/23/2022 00:51:00 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.14 on epoch=19
05/23/2022 00:51:03 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.15 on epoch=20
05/23/2022 00:51:05 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.09 on epoch=20
05/23/2022 00:51:08 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.09 on epoch=20
05/23/2022 00:51:33 - INFO - __main__ - Global step 1150 Train loss 0.12 Classification-F1 0.6243288900845565 on epoch=20
05/23/2022 00:51:35 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.16 on epoch=20
05/23/2022 00:51:38 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.09 on epoch=20
05/23/2022 00:51:40 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.15 on epoch=21
05/23/2022 00:51:43 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.13 on epoch=21
05/23/2022 00:51:46 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.08 on epoch=21
05/23/2022 00:52:10 - INFO - __main__ - Global step 1200 Train loss 0.12 Classification-F1 0.7957819454991895 on epoch=21
05/23/2022 00:52:10 - INFO - __main__ - Saving model with best Classification-F1: 0.770530891163686 -> 0.7957819454991895 on epoch=21, global_step=1200
05/23/2022 00:52:12 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.09 on epoch=21
05/23/2022 00:52:15 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.08 on epoch=21
05/23/2022 00:52:18 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.09 on epoch=21
05/23/2022 00:52:20 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.14 on epoch=22
05/23/2022 00:52:23 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.16 on epoch=22
05/23/2022 00:52:47 - INFO - __main__ - Global step 1250 Train loss 0.11 Classification-F1 0.5876795135927554 on epoch=22
05/23/2022 00:52:49 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.07 on epoch=22
05/23/2022 00:52:52 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.06 on epoch=22
05/23/2022 00:52:55 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.08 on epoch=22
05/23/2022 00:52:57 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.08 on epoch=23
05/23/2022 00:53:00 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.09 on epoch=23
05/23/2022 00:53:25 - INFO - __main__ - Global step 1300 Train loss 0.07 Classification-F1 0.7879338520705358 on epoch=23
05/23/2022 00:53:27 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.13 on epoch=23
05/23/2022 00:53:30 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.10 on epoch=23
05/23/2022 00:53:32 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.09 on epoch=23
05/23/2022 00:53:35 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.06 on epoch=23
05/23/2022 00:53:38 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.09 on epoch=24
05/23/2022 00:54:03 - INFO - __main__ - Global step 1350 Train loss 0.09 Classification-F1 0.7131531267827964 on epoch=24
05/23/2022 00:54:06 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.14 on epoch=24
05/23/2022 00:54:08 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.10 on epoch=24
05/23/2022 00:54:11 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.09 on epoch=24
05/23/2022 00:54:14 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.05 on epoch=24
05/23/2022 00:54:16 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.05 on epoch=24
05/23/2022 00:54:40 - INFO - __main__ - Global step 1400 Train loss 0.09 Classification-F1 0.7156963358963704 on epoch=24
05/23/2022 00:54:43 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.10 on epoch=25
05/23/2022 00:54:45 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.08 on epoch=25
05/23/2022 00:54:48 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.08 on epoch=25
05/23/2022 00:54:51 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.06 on epoch=25
05/23/2022 00:54:53 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.11 on epoch=25
05/23/2022 00:55:18 - INFO - __main__ - Global step 1450 Train loss 0.08 Classification-F1 0.7967835360526858 on epoch=25
05/23/2022 00:55:18 - INFO - __main__ - Saving model with best Classification-F1: 0.7957819454991895 -> 0.7967835360526858 on epoch=25, global_step=1450
05/23/2022 00:55:21 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.05 on epoch=26
05/23/2022 00:55:24 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.07 on epoch=26
05/23/2022 00:55:26 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.08 on epoch=26
05/23/2022 00:55:29 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.07 on epoch=26
05/23/2022 00:55:31 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.10 on epoch=26
05/23/2022 00:55:56 - INFO - __main__ - Global step 1500 Train loss 0.07 Classification-F1 0.8054062679716255 on epoch=26
05/23/2022 00:55:56 - INFO - __main__ - Saving model with best Classification-F1: 0.7967835360526858 -> 0.8054062679716255 on epoch=26, global_step=1500
05/23/2022 00:55:59 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.04 on epoch=26
05/23/2022 00:56:01 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.17 on epoch=27
05/23/2022 00:56:04 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.09 on epoch=27
05/23/2022 00:56:07 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.06 on epoch=27
05/23/2022 00:56:09 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.10 on epoch=27
05/23/2022 00:56:34 - INFO - __main__ - Global step 1550 Train loss 0.09 Classification-F1 0.7941758220389538 on epoch=27
05/23/2022 00:56:37 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.05 on epoch=27
05/23/2022 00:56:39 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.05 on epoch=28
05/23/2022 00:56:42 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.05 on epoch=28
05/23/2022 00:56:45 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.07 on epoch=28
05/23/2022 00:56:47 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.05 on epoch=28
05/23/2022 00:57:12 - INFO - __main__ - Global step 1600 Train loss 0.05 Classification-F1 0.7498234310775642 on epoch=28
05/23/2022 00:57:14 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.07 on epoch=28
05/23/2022 00:57:17 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.04 on epoch=28
05/23/2022 00:57:19 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.10 on epoch=29
05/23/2022 00:57:22 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.11 on epoch=29
05/23/2022 00:57:25 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.08 on epoch=29
05/23/2022 00:57:49 - INFO - __main__ - Global step 1650 Train loss 0.08 Classification-F1 0.6789502800592173 on epoch=29
05/23/2022 00:57:52 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.04 on epoch=29
05/23/2022 00:57:54 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=29
05/23/2022 00:57:57 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.04 on epoch=29
05/23/2022 00:58:00 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.05 on epoch=30
05/23/2022 00:58:02 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.06 on epoch=30
05/23/2022 00:58:27 - INFO - __main__ - Global step 1700 Train loss 0.05 Classification-F1 0.7433111162501753 on epoch=30
05/23/2022 00:58:30 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=30
05/23/2022 00:58:32 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.05 on epoch=30
05/23/2022 00:58:35 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.08 on epoch=30
05/23/2022 00:58:38 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.05 on epoch=31
05/23/2022 00:58:40 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.13 on epoch=31
05/23/2022 00:59:05 - INFO - __main__ - Global step 1750 Train loss 0.06 Classification-F1 0.759260789921363 on epoch=31
05/23/2022 00:59:08 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.05 on epoch=31
05/23/2022 00:59:10 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.07 on epoch=31
05/23/2022 00:59:13 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.12 on epoch=31
05/23/2022 00:59:16 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.07 on epoch=31
05/23/2022 00:59:18 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=32
05/23/2022 00:59:43 - INFO - __main__ - Global step 1800 Train loss 0.07 Classification-F1 0.8044748388351909 on epoch=32
05/23/2022 00:59:46 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.08 on epoch=32
05/23/2022 00:59:48 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.08 on epoch=32
05/23/2022 00:59:51 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.04 on epoch=32
05/23/2022 00:59:54 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=32
05/23/2022 00:59:56 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.07 on epoch=33
05/23/2022 01:00:21 - INFO - __main__ - Global step 1850 Train loss 0.06 Classification-F1 0.6394961214789026 on epoch=33
05/23/2022 01:00:23 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.04 on epoch=33
05/23/2022 01:00:26 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.04 on epoch=33
05/23/2022 01:00:29 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.06 on epoch=33
05/23/2022 01:00:31 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.05 on epoch=33
05/23/2022 01:00:34 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.07 on epoch=33
05/23/2022 01:00:58 - INFO - __main__ - Global step 1900 Train loss 0.05 Classification-F1 0.6696723765406956 on epoch=33
05/23/2022 01:01:01 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.06 on epoch=34
05/23/2022 01:01:03 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.05 on epoch=34
05/23/2022 01:01:06 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=34
05/23/2022 01:01:08 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.08 on epoch=34
05/23/2022 01:01:11 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.04 on epoch=34
05/23/2022 01:01:36 - INFO - __main__ - Global step 1950 Train loss 0.05 Classification-F1 0.8502428908480468 on epoch=34
05/23/2022 01:01:36 - INFO - __main__ - Saving model with best Classification-F1: 0.8054062679716255 -> 0.8502428908480468 on epoch=34, global_step=1950
05/23/2022 01:01:39 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.05 on epoch=34
05/23/2022 01:01:41 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.07 on epoch=35
05/23/2022 01:01:44 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.04 on epoch=35
05/23/2022 01:01:46 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.04 on epoch=35
05/23/2022 01:01:49 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.04 on epoch=35
05/23/2022 01:02:14 - INFO - __main__ - Global step 2000 Train loss 0.05 Classification-F1 0.8553957934642152 on epoch=35
05/23/2022 01:02:14 - INFO - __main__ - Saving model with best Classification-F1: 0.8502428908480468 -> 0.8553957934642152 on epoch=35, global_step=2000
05/23/2022 01:02:17 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=35
05/23/2022 01:02:19 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.03 on epoch=36
05/23/2022 01:02:22 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.03 on epoch=36
05/23/2022 01:02:24 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=36
05/23/2022 01:02:27 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.02 on epoch=36
05/23/2022 01:02:52 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.9150936902002605 on epoch=36
05/23/2022 01:02:52 - INFO - __main__ - Saving model with best Classification-F1: 0.8553957934642152 -> 0.9150936902002605 on epoch=36, global_step=2050
05/23/2022 01:02:55 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.07 on epoch=36
05/23/2022 01:02:58 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=36
05/23/2022 01:03:00 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.06 on epoch=37
05/23/2022 01:03:03 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.06 on epoch=37
05/23/2022 01:03:05 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=37
05/23/2022 01:03:31 - INFO - __main__ - Global step 2100 Train loss 0.05 Classification-F1 0.8552527334224675 on epoch=37
05/23/2022 01:03:33 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.04 on epoch=37
05/23/2022 01:03:36 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.03 on epoch=37
05/23/2022 01:03:38 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.06 on epoch=38
05/23/2022 01:03:41 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.08 on epoch=38
05/23/2022 01:03:44 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.08 on epoch=38
05/23/2022 01:04:09 - INFO - __main__ - Global step 2150 Train loss 0.06 Classification-F1 0.7140014672004815 on epoch=38
05/23/2022 01:04:11 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=38
05/23/2022 01:04:14 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=38
05/23/2022 01:04:16 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.05 on epoch=38
05/23/2022 01:04:19 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=39
05/23/2022 01:04:22 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.08 on epoch=39
05/23/2022 01:04:46 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.608816713761347 on epoch=39
05/23/2022 01:04:48 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=39
05/23/2022 01:04:51 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=39
05/23/2022 01:04:53 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.03 on epoch=39
05/23/2022 01:04:56 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.03 on epoch=39
05/23/2022 01:04:58 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.03 on epoch=40
05/23/2022 01:05:24 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.6817291096455278 on epoch=40
05/23/2022 01:05:26 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.07 on epoch=40
05/23/2022 01:05:29 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=40
05/23/2022 01:05:31 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=40
05/23/2022 01:05:34 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=40
05/23/2022 01:05:37 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.04 on epoch=41
05/23/2022 01:06:01 - INFO - __main__ - Global step 2300 Train loss 0.04 Classification-F1 0.8527278513689485 on epoch=41
05/23/2022 01:06:04 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=41
05/23/2022 01:06:07 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.05 on epoch=41
05/23/2022 01:06:09 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=41
05/23/2022 01:06:12 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.05 on epoch=41
05/23/2022 01:06:15 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=41
05/23/2022 01:06:39 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.8547357918908772 on epoch=41
05/23/2022 01:06:42 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=42
05/23/2022 01:06:44 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.07 on epoch=42
05/23/2022 01:06:47 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=42
05/23/2022 01:06:50 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.05 on epoch=42
05/23/2022 01:06:52 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.03 on epoch=42
05/23/2022 01:07:17 - INFO - __main__ - Global step 2400 Train loss 0.04 Classification-F1 0.8543755109348381 on epoch=42
05/23/2022 01:07:20 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.03 on epoch=43
05/23/2022 01:07:22 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.03 on epoch=43
05/23/2022 01:07:25 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.04 on epoch=43
05/23/2022 01:07:27 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=43
05/23/2022 01:07:30 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=43
05/23/2022 01:07:54 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.9764123853914685 on epoch=43
05/23/2022 01:07:54 - INFO - __main__ - Saving model with best Classification-F1: 0.9150936902002605 -> 0.9764123853914685 on epoch=43, global_step=2450
05/23/2022 01:07:57 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.09 on epoch=43
05/23/2022 01:08:00 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=44
05/23/2022 01:08:02 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.04 on epoch=44
05/23/2022 01:08:05 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.04 on epoch=44
05/23/2022 01:08:07 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=44
05/23/2022 01:08:32 - INFO - __main__ - Global step 2500 Train loss 0.04 Classification-F1 0.9139553063073534 on epoch=44
05/23/2022 01:08:35 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=44
05/23/2022 01:08:37 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=44
05/23/2022 01:08:40 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=45
05/23/2022 01:08:43 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=45
05/23/2022 01:08:45 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=45
05/23/2022 01:09:09 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.852743810584006 on epoch=45
05/23/2022 01:09:12 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.07 on epoch=45
05/23/2022 01:09:14 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=45
05/23/2022 01:09:17 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=46
05/23/2022 01:09:20 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.04 on epoch=46
05/23/2022 01:09:22 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.08 on epoch=46
05/23/2022 01:09:46 - INFO - __main__ - Global step 2600 Train loss 0.05 Classification-F1 0.8020216008111335 on epoch=46
05/23/2022 01:09:48 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.03 on epoch=46
05/23/2022 01:09:51 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.03 on epoch=46
05/23/2022 01:09:53 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.06 on epoch=46
05/23/2022 01:09:56 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.07 on epoch=47
05/23/2022 01:09:58 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.07 on epoch=47
05/23/2022 01:10:23 - INFO - __main__ - Global step 2650 Train loss 0.05 Classification-F1 0.796505485863898 on epoch=47
05/23/2022 01:10:25 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.05 on epoch=47
05/23/2022 01:10:28 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=47
05/23/2022 01:10:31 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.04 on epoch=47
05/23/2022 01:10:33 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=48
05/23/2022 01:10:36 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.03 on epoch=48
05/23/2022 01:11:01 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.7070336085218178 on epoch=48
05/23/2022 01:11:03 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.03 on epoch=48
05/23/2022 01:11:06 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=48
05/23/2022 01:11:09 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.04 on epoch=48
05/23/2022 01:11:11 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=48
05/23/2022 01:11:14 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.03 on epoch=49
05/23/2022 01:11:39 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.80395677411386 on epoch=49
05/23/2022 01:11:41 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.03 on epoch=49
05/23/2022 01:11:44 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=49
05/23/2022 01:11:46 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=49
05/23/2022 01:11:49 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.06 on epoch=49
05/23/2022 01:11:52 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.04 on epoch=49
05/23/2022 01:12:16 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.6082194089277995 on epoch=49
05/23/2022 01:12:19 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=50
05/23/2022 01:12:21 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.04 on epoch=50
05/23/2022 01:12:24 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.05 on epoch=50
05/23/2022 01:12:27 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.06 on epoch=50
05/23/2022 01:12:29 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=50
05/23/2022 01:12:54 - INFO - __main__ - Global step 2850 Train loss 0.03 Classification-F1 0.6761008872210449 on epoch=50
05/23/2022 01:12:56 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.04 on epoch=51
05/23/2022 01:12:59 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.03 on epoch=51
05/23/2022 01:13:01 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.06 on epoch=51
05/23/2022 01:13:04 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.06 on epoch=51
05/23/2022 01:13:07 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=51
05/23/2022 01:13:31 - INFO - __main__ - Global step 2900 Train loss 0.04 Classification-F1 0.6745091060326951 on epoch=51
05/23/2022 01:13:33 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=51
05/23/2022 01:13:36 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=52
05/23/2022 01:13:38 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.09 on epoch=52
05/23/2022 01:13:41 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=52
05/23/2022 01:13:44 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.04 on epoch=52
05/23/2022 01:14:07 - INFO - __main__ - Global step 2950 Train loss 0.04 Classification-F1 0.6212379445239818 on epoch=52
05/23/2022 01:14:10 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=52
05/23/2022 01:14:12 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=53
05/23/2022 01:14:15 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=53
05/23/2022 01:14:17 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.03 on epoch=53
05/23/2022 01:14:20 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=53
05/23/2022 01:14:21 - INFO - __main__ - Start tokenizing ... 896 instances
05/23/2022 01:14:21 - INFO - __main__ - Printing 3 examples
05/23/2022 01:14:21 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/23/2022 01:14:21 - INFO - __main__ - ['Company']
05/23/2022 01:14:21 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/23/2022 01:14:21 - INFO - __main__ - ['Company']
05/23/2022 01:14:21 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/23/2022 01:14:21 - INFO - __main__ - ['Company']
05/23/2022 01:14:21 - INFO - __main__ - Tokenizing Input ...
05/23/2022 01:14:22 - INFO - __main__ - Tokenizing Output ...
05/23/2022 01:14:23 - INFO - __main__ - Loaded 896 examples from train data
05/23/2022 01:14:23 - INFO - __main__ - Start tokenizing ... 896 instances
05/23/2022 01:14:23 - INFO - __main__ - Printing 3 examples
05/23/2022 01:14:23 - INFO - __main__ -  [dbpedia_14] Shock Records (now part of Shock Entertainment) is Australia's largest independent record label operating for 24 years releasing independent music to the Australian marketplace.Current major music partners include Cooking Vinyl (including Marilyn Manson The Prodigy Groove Armada and Underworld); Sunday Best (Kitty Daisy & Lewis); Rise Records (Of Mice & Men Miss May I Hot Water Music); Vagrant (including Edward Sharpe and the Magnetic Zeros); Sumerian (Asking Alexandria I See Stars Veil of Maya); and Rough Trade (including Belle and Sebastian).
05/23/2022 01:14:23 - INFO - __main__ - ['Company']
05/23/2022 01:14:23 - INFO - __main__ -  [dbpedia_14] Actio Corporation is an American software company founded in 1996. The company began as an MSDS authoring and data management service using a hosted model which is now known as SaaS or software-as-a-service but in the mid-90's was called ASP.
05/23/2022 01:14:23 - INFO - __main__ - ['Company']
05/23/2022 01:14:23 - INFO - __main__ -  [dbpedia_14] Pacific Corporate Group is a global alternative investment management and advisory company headquartered in La Jolla California. PCG together with affiliates and subsidiaries (together the affiliates) currently manage over $17 billion in assets and has invested and advised upon over $44 billion since 1990. PCG and its affiliates operate through offices based out of La Jolla New York Danvers Washington D.C Singapore and Hong Kong
05/23/2022 01:14:23 - INFO - __main__ - ['Company']
05/23/2022 01:14:23 - INFO - __main__ - Tokenizing Input ...
05/23/2022 01:14:23 - INFO - __main__ - Tokenizing Output ...
05/23/2022 01:14:24 - INFO - __main__ - Loaded 896 examples from dev data
05/23/2022 01:14:40 - INFO - __main__ - try to initialize prompt embeddings
05/23/2022 01:14:40 - INFO - __main__ - task name: dbpedia_14
05/23/2022 01:14:40 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/23/2022 01:14:40 - INFO - __main__ - Starting training!
05/23/2022 01:14:44 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.7628375193120269 on epoch=53
05/23/2022 01:14:44 - INFO - __main__ - save last model!
05/23/2022 01:14:44 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/23/2022 01:14:44 - INFO - __main__ - Start tokenizing ... 3500 instances
05/23/2022 01:14:44 - INFO - __main__ - Printing 3 examples
05/23/2022 01:14:44 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/23/2022 01:14:44 - INFO - __main__ - ['Animal']
05/23/2022 01:14:44 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/23/2022 01:14:44 - INFO - __main__ - ['Animal']
05/23/2022 01:14:44 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/23/2022 01:14:44 - INFO - __main__ - ['Village']
05/23/2022 01:14:44 - INFO - __main__ - Tokenizing Input ...
05/23/2022 01:14:46 - INFO - __main__ - Tokenizing Output ...
05/23/2022 01:14:50 - INFO - __main__ - Loaded 3500 examples from test data
05/23/2022 01:16:57 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down64shot/singletask-dbpedia_14/dbpedia_14_64_42_0.3_8_predictions.txt
05/23/2022 01:16:57 - INFO - __main__ - Classification-F1 on test data: 0.6521
05/23/2022 01:16:58 - INFO - __main__ - prefix=dbpedia_14_64_42, lr=0.3, bsz=8, dev_performance=0.9764123853914685, test_performance=0.6521459755716185
05/23/2022 01:16:58 - INFO - __main__ - Running ... prefix=dbpedia_14_64_42, lr=0.2, bsz=8 ...
05/23/2022 01:16:59 - INFO - __main__ - Start tokenizing ... 896 instances
05/23/2022 01:16:59 - INFO - __main__ - Printing 3 examples
05/23/2022 01:16:59 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/23/2022 01:16:59 - INFO - __main__ - ['Company']
05/23/2022 01:16:59 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/23/2022 01:16:59 - INFO - __main__ - ['Company']
05/23/2022 01:16:59 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/23/2022 01:16:59 - INFO - __main__ - ['Company']
05/23/2022 01:16:59 - INFO - __main__ - Tokenizing Input ...
05/23/2022 01:16:59 - INFO - __main__ - Tokenizing Output ...
05/23/2022 01:17:00 - INFO - __main__ - Loaded 896 examples from train data
05/23/2022 01:17:00 - INFO - __main__ - Start tokenizing ... 896 instances
05/23/2022 01:17:00 - INFO - __main__ - Printing 3 examples
05/23/2022 01:17:00 - INFO - __main__ -  [dbpedia_14] Shock Records (now part of Shock Entertainment) is Australia's largest independent record label operating for 24 years releasing independent music to the Australian marketplace.Current major music partners include Cooking Vinyl (including Marilyn Manson The Prodigy Groove Armada and Underworld); Sunday Best (Kitty Daisy & Lewis); Rise Records (Of Mice & Men Miss May I Hot Water Music); Vagrant (including Edward Sharpe and the Magnetic Zeros); Sumerian (Asking Alexandria I See Stars Veil of Maya); and Rough Trade (including Belle and Sebastian).
05/23/2022 01:17:00 - INFO - __main__ - ['Company']
05/23/2022 01:17:00 - INFO - __main__ -  [dbpedia_14] Actio Corporation is an American software company founded in 1996. The company began as an MSDS authoring and data management service using a hosted model which is now known as SaaS or software-as-a-service but in the mid-90's was called ASP.
05/23/2022 01:17:00 - INFO - __main__ - ['Company']
05/23/2022 01:17:00 - INFO - __main__ -  [dbpedia_14] Pacific Corporate Group is a global alternative investment management and advisory company headquartered in La Jolla California. PCG together with affiliates and subsidiaries (together the affiliates) currently manage over $17 billion in assets and has invested and advised upon over $44 billion since 1990. PCG and its affiliates operate through offices based out of La Jolla New York Danvers Washington D.C Singapore and Hong Kong
05/23/2022 01:17:00 - INFO - __main__ - ['Company']
05/23/2022 01:17:00 - INFO - __main__ - Tokenizing Input ...
05/23/2022 01:17:01 - INFO - __main__ - Tokenizing Output ...
05/23/2022 01:17:01 - INFO - __main__ - Loaded 896 examples from dev data
05/23/2022 01:17:20 - INFO - __main__ - try to initialize prompt embeddings
05/23/2022 01:17:20 - INFO - __main__ - task name: dbpedia_14
05/23/2022 01:17:21 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/23/2022 01:17:21 - INFO - __main__ - Starting training!
05/23/2022 01:17:24 - INFO - __main__ - Step 10 Global step 10 Train loss 7.02 on epoch=0
05/23/2022 01:17:27 - INFO - __main__ - Step 20 Global step 20 Train loss 6.40 on epoch=0
05/23/2022 01:17:30 - INFO - __main__ - Step 30 Global step 30 Train loss 5.14 on epoch=0
05/23/2022 01:17:32 - INFO - __main__ - Step 40 Global step 40 Train loss 4.31 on epoch=0
05/23/2022 01:17:35 - INFO - __main__ - Step 50 Global step 50 Train loss 3.91 on epoch=0
05/23/2022 01:18:44 - INFO - __main__ - Global step 50 Train loss 5.36 Classification-F1 0.02382203187219547 on epoch=0
05/23/2022 01:18:44 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.02382203187219547 on epoch=0, global_step=50
05/23/2022 01:18:47 - INFO - __main__ - Step 60 Global step 60 Train loss 3.33 on epoch=1
05/23/2022 01:18:50 - INFO - __main__ - Step 70 Global step 70 Train loss 2.69 on epoch=1
05/23/2022 01:18:52 - INFO - __main__ - Step 80 Global step 80 Train loss 2.36 on epoch=1
05/23/2022 01:18:55 - INFO - __main__ - Step 90 Global step 90 Train loss 2.29 on epoch=1
05/23/2022 01:18:57 - INFO - __main__ - Step 100 Global step 100 Train loss 2.12 on epoch=1
05/23/2022 01:19:25 - INFO - __main__ - Global step 100 Train loss 2.56 Classification-F1 0.12216345378720038 on epoch=1
05/23/2022 01:19:25 - INFO - __main__ - Saving model with best Classification-F1: 0.02382203187219547 -> 0.12216345378720038 on epoch=1, global_step=100
05/23/2022 01:19:27 - INFO - __main__ - Step 110 Global step 110 Train loss 1.88 on epoch=1
05/23/2022 01:19:30 - INFO - __main__ - Step 120 Global step 120 Train loss 1.84 on epoch=2
05/23/2022 01:19:32 - INFO - __main__ - Step 130 Global step 130 Train loss 1.66 on epoch=2
05/23/2022 01:19:35 - INFO - __main__ - Step 140 Global step 140 Train loss 1.50 on epoch=2
05/23/2022 01:19:38 - INFO - __main__ - Step 150 Global step 150 Train loss 1.40 on epoch=2
05/23/2022 01:20:01 - INFO - __main__ - Global step 150 Train loss 1.65 Classification-F1 0.27931730359354395 on epoch=2
05/23/2022 01:20:01 - INFO - __main__ - Saving model with best Classification-F1: 0.12216345378720038 -> 0.27931730359354395 on epoch=2, global_step=150
05/23/2022 01:20:03 - INFO - __main__ - Step 160 Global step 160 Train loss 1.42 on epoch=2
05/23/2022 01:20:06 - INFO - __main__ - Step 170 Global step 170 Train loss 1.22 on epoch=3
05/23/2022 01:20:08 - INFO - __main__ - Step 180 Global step 180 Train loss 1.11 on epoch=3
05/23/2022 01:20:11 - INFO - __main__ - Step 190 Global step 190 Train loss 1.21 on epoch=3
05/23/2022 01:20:14 - INFO - __main__ - Step 200 Global step 200 Train loss 1.02 on epoch=3
05/23/2022 01:20:40 - INFO - __main__ - Global step 200 Train loss 1.19 Classification-F1 0.418513483521616 on epoch=3
05/23/2022 01:20:40 - INFO - __main__ - Saving model with best Classification-F1: 0.27931730359354395 -> 0.418513483521616 on epoch=3, global_step=200
05/23/2022 01:20:43 - INFO - __main__ - Step 210 Global step 210 Train loss 0.99 on epoch=3
05/23/2022 01:20:45 - INFO - __main__ - Step 220 Global step 220 Train loss 0.98 on epoch=3
05/23/2022 01:20:48 - INFO - __main__ - Step 230 Global step 230 Train loss 1.03 on epoch=4
05/23/2022 01:20:50 - INFO - __main__ - Step 240 Global step 240 Train loss 1.02 on epoch=4
05/23/2022 01:20:53 - INFO - __main__ - Step 250 Global step 250 Train loss 0.89 on epoch=4
05/23/2022 01:21:17 - INFO - __main__ - Global step 250 Train loss 0.98 Classification-F1 0.38835904666911353 on epoch=4
05/23/2022 01:21:20 - INFO - __main__ - Step 260 Global step 260 Train loss 0.77 on epoch=4
05/23/2022 01:21:22 - INFO - __main__ - Step 270 Global step 270 Train loss 0.76 on epoch=4
05/23/2022 01:21:25 - INFO - __main__ - Step 280 Global step 280 Train loss 0.87 on epoch=4
05/23/2022 01:21:28 - INFO - __main__ - Step 290 Global step 290 Train loss 0.76 on epoch=5
05/23/2022 01:21:30 - INFO - __main__ - Step 300 Global step 300 Train loss 0.72 on epoch=5
05/23/2022 01:21:57 - INFO - __main__ - Global step 300 Train loss 0.77 Classification-F1 0.38853692181756083 on epoch=5
05/23/2022 01:22:00 - INFO - __main__ - Step 310 Global step 310 Train loss 0.68 on epoch=5
05/23/2022 01:22:03 - INFO - __main__ - Step 320 Global step 320 Train loss 0.68 on epoch=5
05/23/2022 01:22:05 - INFO - __main__ - Step 330 Global step 330 Train loss 0.64 on epoch=5
05/23/2022 01:22:08 - INFO - __main__ - Step 340 Global step 340 Train loss 0.60 on epoch=6
05/23/2022 01:22:10 - INFO - __main__ - Step 350 Global step 350 Train loss 0.72 on epoch=6
05/23/2022 01:22:36 - INFO - __main__ - Global step 350 Train loss 0.66 Classification-F1 0.38108718830198607 on epoch=6
05/23/2022 01:22:38 - INFO - __main__ - Step 360 Global step 360 Train loss 0.70 on epoch=6
05/23/2022 01:22:41 - INFO - __main__ - Step 370 Global step 370 Train loss 0.62 on epoch=6
05/23/2022 01:22:44 - INFO - __main__ - Step 380 Global step 380 Train loss 0.62 on epoch=6
05/23/2022 01:22:46 - INFO - __main__ - Step 390 Global step 390 Train loss 0.63 on epoch=6
05/23/2022 01:22:49 - INFO - __main__ - Step 400 Global step 400 Train loss 0.60 on epoch=7
05/23/2022 01:23:15 - INFO - __main__ - Global step 400 Train loss 0.63 Classification-F1 0.4167515314472007 on epoch=7
05/23/2022 01:23:18 - INFO - __main__ - Step 410 Global step 410 Train loss 0.59 on epoch=7
05/23/2022 01:23:21 - INFO - __main__ - Step 420 Global step 420 Train loss 0.50 on epoch=7
05/23/2022 01:23:23 - INFO - __main__ - Step 430 Global step 430 Train loss 0.56 on epoch=7
05/23/2022 01:23:26 - INFO - __main__ - Step 440 Global step 440 Train loss 0.54 on epoch=7
05/23/2022 01:23:28 - INFO - __main__ - Step 450 Global step 450 Train loss 0.46 on epoch=8
05/23/2022 01:23:55 - INFO - __main__ - Global step 450 Train loss 0.53 Classification-F1 0.41212054159741174 on epoch=8
05/23/2022 01:23:58 - INFO - __main__ - Step 460 Global step 460 Train loss 0.59 on epoch=8
05/23/2022 01:24:01 - INFO - __main__ - Step 470 Global step 470 Train loss 0.54 on epoch=8
05/23/2022 01:24:03 - INFO - __main__ - Step 480 Global step 480 Train loss 0.48 on epoch=8
05/23/2022 01:24:06 - INFO - __main__ - Step 490 Global step 490 Train loss 0.51 on epoch=8
05/23/2022 01:24:08 - INFO - __main__ - Step 500 Global step 500 Train loss 0.40 on epoch=8
05/23/2022 01:24:35 - INFO - __main__ - Global step 500 Train loss 0.51 Classification-F1 0.5072908673129893 on epoch=8
05/23/2022 01:24:35 - INFO - __main__ - Saving model with best Classification-F1: 0.418513483521616 -> 0.5072908673129893 on epoch=8, global_step=500
05/23/2022 01:24:37 - INFO - __main__ - Step 510 Global step 510 Train loss 0.49 on epoch=9
05/23/2022 01:24:40 - INFO - __main__ - Step 520 Global step 520 Train loss 0.47 on epoch=9
05/23/2022 01:24:43 - INFO - __main__ - Step 530 Global step 530 Train loss 0.43 on epoch=9
05/23/2022 01:24:45 - INFO - __main__ - Step 540 Global step 540 Train loss 0.43 on epoch=9
05/23/2022 01:24:48 - INFO - __main__ - Step 550 Global step 550 Train loss 0.49 on epoch=9
05/23/2022 01:25:13 - INFO - __main__ - Global step 550 Train loss 0.46 Classification-F1 0.41039296996655467 on epoch=9
05/23/2022 01:25:15 - INFO - __main__ - Step 560 Global step 560 Train loss 0.47 on epoch=9
05/23/2022 01:25:18 - INFO - __main__ - Step 570 Global step 570 Train loss 0.48 on epoch=10
05/23/2022 01:25:21 - INFO - __main__ - Step 580 Global step 580 Train loss 0.45 on epoch=10
05/23/2022 01:25:23 - INFO - __main__ - Step 590 Global step 590 Train loss 0.41 on epoch=10
05/23/2022 01:25:26 - INFO - __main__ - Step 600 Global step 600 Train loss 0.40 on epoch=10
05/23/2022 01:25:51 - INFO - __main__ - Global step 600 Train loss 0.44 Classification-F1 0.5943421460275471 on epoch=10
05/23/2022 01:25:51 - INFO - __main__ - Saving model with best Classification-F1: 0.5072908673129893 -> 0.5943421460275471 on epoch=10, global_step=600
05/23/2022 01:25:54 - INFO - __main__ - Step 610 Global step 610 Train loss 0.42 on epoch=10
05/23/2022 01:25:57 - INFO - __main__ - Step 620 Global step 620 Train loss 0.36 on epoch=11
05/23/2022 01:25:59 - INFO - __main__ - Step 630 Global step 630 Train loss 0.36 on epoch=11
05/23/2022 01:26:02 - INFO - __main__ - Step 640 Global step 640 Train loss 0.37 on epoch=11
05/23/2022 01:26:04 - INFO - __main__ - Step 650 Global step 650 Train loss 0.37 on epoch=11
05/23/2022 01:26:30 - INFO - __main__ - Global step 650 Train loss 0.37 Classification-F1 0.6640652942637163 on epoch=11
05/23/2022 01:26:30 - INFO - __main__ - Saving model with best Classification-F1: 0.5943421460275471 -> 0.6640652942637163 on epoch=11, global_step=650
05/23/2022 01:26:33 - INFO - __main__ - Step 660 Global step 660 Train loss 0.43 on epoch=11
05/23/2022 01:26:35 - INFO - __main__ - Step 670 Global step 670 Train loss 0.48 on epoch=11
05/23/2022 01:26:38 - INFO - __main__ - Step 680 Global step 680 Train loss 0.39 on epoch=12
05/23/2022 01:26:41 - INFO - __main__ - Step 690 Global step 690 Train loss 0.44 on epoch=12
05/23/2022 01:26:43 - INFO - __main__ - Step 700 Global step 700 Train loss 0.36 on epoch=12
05/23/2022 01:27:09 - INFO - __main__ - Global step 700 Train loss 0.42 Classification-F1 0.6632270094276335 on epoch=12
05/23/2022 01:27:11 - INFO - __main__ - Step 710 Global step 710 Train loss 0.44 on epoch=12
05/23/2022 01:27:14 - INFO - __main__ - Step 720 Global step 720 Train loss 0.36 on epoch=12
05/23/2022 01:27:16 - INFO - __main__ - Step 730 Global step 730 Train loss 0.28 on epoch=13
05/23/2022 01:27:19 - INFO - __main__ - Step 740 Global step 740 Train loss 0.31 on epoch=13
05/23/2022 01:27:22 - INFO - __main__ - Step 750 Global step 750 Train loss 0.37 on epoch=13
05/23/2022 01:27:47 - INFO - __main__ - Global step 750 Train loss 0.35 Classification-F1 0.5238243495161934 on epoch=13
05/23/2022 01:27:50 - INFO - __main__ - Step 760 Global step 760 Train loss 0.30 on epoch=13
05/23/2022 01:27:52 - INFO - __main__ - Step 770 Global step 770 Train loss 0.38 on epoch=13
05/23/2022 01:27:55 - INFO - __main__ - Step 780 Global step 780 Train loss 0.30 on epoch=13
05/23/2022 01:27:58 - INFO - __main__ - Step 790 Global step 790 Train loss 0.35 on epoch=14
05/23/2022 01:28:00 - INFO - __main__ - Step 800 Global step 800 Train loss 0.44 on epoch=14
05/23/2022 01:28:29 - INFO - __main__ - Global step 800 Train loss 0.35 Classification-F1 0.7510044390327686 on epoch=14
05/23/2022 01:28:29 - INFO - __main__ - Saving model with best Classification-F1: 0.6640652942637163 -> 0.7510044390327686 on epoch=14, global_step=800
05/23/2022 01:28:32 - INFO - __main__ - Step 810 Global step 810 Train loss 0.30 on epoch=14
05/23/2022 01:28:34 - INFO - __main__ - Step 820 Global step 820 Train loss 0.29 on epoch=14
05/23/2022 01:28:37 - INFO - __main__ - Step 830 Global step 830 Train loss 0.39 on epoch=14
05/23/2022 01:28:39 - INFO - __main__ - Step 840 Global step 840 Train loss 0.24 on epoch=14
05/23/2022 01:28:42 - INFO - __main__ - Step 850 Global step 850 Train loss 0.33 on epoch=15
05/23/2022 01:29:12 - INFO - __main__ - Global step 850 Train loss 0.31 Classification-F1 0.7089712097941929 on epoch=15
05/23/2022 01:29:14 - INFO - __main__ - Step 860 Global step 860 Train loss 0.30 on epoch=15
05/23/2022 01:29:17 - INFO - __main__ - Step 870 Global step 870 Train loss 0.31 on epoch=15
05/23/2022 01:29:19 - INFO - __main__ - Step 880 Global step 880 Train loss 0.32 on epoch=15
05/23/2022 01:29:22 - INFO - __main__ - Step 890 Global step 890 Train loss 0.27 on epoch=15
05/23/2022 01:29:25 - INFO - __main__ - Step 900 Global step 900 Train loss 0.25 on epoch=16
05/23/2022 01:29:53 - INFO - __main__ - Global step 900 Train loss 0.29 Classification-F1 0.6743943328679578 on epoch=16
05/23/2022 01:29:56 - INFO - __main__ - Step 910 Global step 910 Train loss 0.40 on epoch=16
05/23/2022 01:29:58 - INFO - __main__ - Step 920 Global step 920 Train loss 0.23 on epoch=16
05/23/2022 01:30:01 - INFO - __main__ - Step 930 Global step 930 Train loss 0.28 on epoch=16
05/23/2022 01:30:04 - INFO - __main__ - Step 940 Global step 940 Train loss 0.25 on epoch=16
05/23/2022 01:30:06 - INFO - __main__ - Step 950 Global step 950 Train loss 0.29 on epoch=16
05/23/2022 01:30:34 - INFO - __main__ - Global step 950 Train loss 0.29 Classification-F1 0.7648440773873028 on epoch=16
05/23/2022 01:30:34 - INFO - __main__ - Saving model with best Classification-F1: 0.7510044390327686 -> 0.7648440773873028 on epoch=16, global_step=950
05/23/2022 01:30:37 - INFO - __main__ - Step 960 Global step 960 Train loss 0.23 on epoch=17
05/23/2022 01:30:40 - INFO - __main__ - Step 970 Global step 970 Train loss 0.27 on epoch=17
05/23/2022 01:30:42 - INFO - __main__ - Step 980 Global step 980 Train loss 0.24 on epoch=17
05/23/2022 01:30:45 - INFO - __main__ - Step 990 Global step 990 Train loss 0.29 on epoch=17
05/23/2022 01:30:47 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.23 on epoch=17
05/23/2022 01:31:15 - INFO - __main__ - Global step 1000 Train loss 0.26 Classification-F1 0.7793640916354374 on epoch=17
05/23/2022 01:31:15 - INFO - __main__ - Saving model with best Classification-F1: 0.7648440773873028 -> 0.7793640916354374 on epoch=17, global_step=1000
05/23/2022 01:31:18 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.21 on epoch=18
05/23/2022 01:31:20 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.23 on epoch=18
05/23/2022 01:31:23 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.29 on epoch=18
05/23/2022 01:31:25 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.26 on epoch=18
05/23/2022 01:31:28 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.19 on epoch=18
05/23/2022 01:31:53 - INFO - __main__ - Global step 1050 Train loss 0.24 Classification-F1 0.6693460261353079 on epoch=18
05/23/2022 01:31:56 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.25 on epoch=18
05/23/2022 01:31:59 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.19 on epoch=19
05/23/2022 01:32:01 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.24 on epoch=19
05/23/2022 01:32:04 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.20 on epoch=19
05/23/2022 01:32:06 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.22 on epoch=19
05/23/2022 01:32:32 - INFO - __main__ - Global step 1100 Train loss 0.22 Classification-F1 0.5765473428599621 on epoch=19
05/23/2022 01:32:35 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.23 on epoch=19
05/23/2022 01:32:37 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.17 on epoch=19
05/23/2022 01:32:40 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.30 on epoch=20
05/23/2022 01:32:43 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.20 on epoch=20
05/23/2022 01:32:45 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.15 on epoch=20
05/23/2022 01:33:10 - INFO - __main__ - Global step 1150 Train loss 0.21 Classification-F1 0.5862727757762972 on epoch=20
05/23/2022 01:33:13 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.25 on epoch=20
05/23/2022 01:33:15 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.16 on epoch=20
05/23/2022 01:33:18 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.20 on epoch=21
05/23/2022 01:33:21 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.22 on epoch=21
05/23/2022 01:33:23 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.14 on epoch=21
05/23/2022 01:33:48 - INFO - __main__ - Global step 1200 Train loss 0.19 Classification-F1 0.68324707441942 on epoch=21
05/23/2022 01:33:50 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.14 on epoch=21
05/23/2022 01:33:53 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.19 on epoch=21
05/23/2022 01:33:55 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.18 on epoch=21
05/23/2022 01:33:58 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.18 on epoch=22
05/23/2022 01:34:01 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.20 on epoch=22
05/23/2022 01:34:25 - INFO - __main__ - Global step 1250 Train loss 0.18 Classification-F1 0.5910260239205689 on epoch=22
05/23/2022 01:34:28 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.13 on epoch=22
05/23/2022 01:34:30 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.18 on epoch=22
05/23/2022 01:34:33 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.16 on epoch=22
05/23/2022 01:34:35 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.12 on epoch=23
05/23/2022 01:34:38 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.16 on epoch=23
05/23/2022 01:35:03 - INFO - __main__ - Global step 1300 Train loss 0.15 Classification-F1 0.8218418208662452 on epoch=23
05/23/2022 01:35:03 - INFO - __main__ - Saving model with best Classification-F1: 0.7793640916354374 -> 0.8218418208662452 on epoch=23, global_step=1300
05/23/2022 01:35:05 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.17 on epoch=23
05/23/2022 01:35:08 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.12 on epoch=23
05/23/2022 01:35:10 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.23 on epoch=23
05/23/2022 01:35:13 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.11 on epoch=23
05/23/2022 01:35:16 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.16 on epoch=24
05/23/2022 01:35:41 - INFO - __main__ - Global step 1350 Train loss 0.16 Classification-F1 0.7686634788345376 on epoch=24
05/23/2022 01:35:44 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.12 on epoch=24
05/23/2022 01:35:47 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.25 on epoch=24
05/23/2022 01:35:49 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.11 on epoch=24
05/23/2022 01:35:52 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.16 on epoch=24
05/23/2022 01:35:54 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.09 on epoch=24
05/23/2022 01:36:19 - INFO - __main__ - Global step 1400 Train loss 0.15 Classification-F1 0.7108273747550844 on epoch=24
05/23/2022 01:36:22 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.19 on epoch=25
05/23/2022 01:36:24 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.19 on epoch=25
05/23/2022 01:36:27 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.14 on epoch=25
05/23/2022 01:36:29 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.13 on epoch=25
05/23/2022 01:36:32 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.19 on epoch=25
05/23/2022 01:36:57 - INFO - __main__ - Global step 1450 Train loss 0.17 Classification-F1 0.6866286076220096 on epoch=25
05/23/2022 01:36:59 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.13 on epoch=26
05/23/2022 01:37:02 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.12 on epoch=26
05/23/2022 01:37:04 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.14 on epoch=26
05/23/2022 01:37:07 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.14 on epoch=26
05/23/2022 01:37:09 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.10 on epoch=26
05/23/2022 01:37:33 - INFO - __main__ - Global step 1500 Train loss 0.13 Classification-F1 0.6733094919352729 on epoch=26
05/23/2022 01:37:36 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.08 on epoch=26
05/23/2022 01:37:39 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.09 on epoch=27
05/23/2022 01:37:41 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.16 on epoch=27
05/23/2022 01:37:44 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.11 on epoch=27
05/23/2022 01:37:46 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.13 on epoch=27
05/23/2022 01:38:11 - INFO - __main__ - Global step 1550 Train loss 0.11 Classification-F1 0.7196280365908638 on epoch=27
05/23/2022 01:38:13 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.20 on epoch=27
05/23/2022 01:38:16 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.08 on epoch=28
05/23/2022 01:38:18 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.12 on epoch=28
05/23/2022 01:38:21 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.17 on epoch=28
05/23/2022 01:38:24 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.16 on epoch=28
05/23/2022 01:38:49 - INFO - __main__ - Global step 1600 Train loss 0.14 Classification-F1 0.6061747184017631 on epoch=28
05/23/2022 01:38:51 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.09 on epoch=28
05/23/2022 01:38:54 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.16 on epoch=28
05/23/2022 01:38:56 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.10 on epoch=29
05/23/2022 01:38:59 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.15 on epoch=29
05/23/2022 01:39:02 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.13 on epoch=29
05/23/2022 01:39:27 - INFO - __main__ - Global step 1650 Train loss 0.13 Classification-F1 0.6293353006126604 on epoch=29
05/23/2022 01:39:30 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.13 on epoch=29
05/23/2022 01:39:33 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.11 on epoch=29
05/23/2022 01:39:35 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.09 on epoch=29
05/23/2022 01:39:38 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.17 on epoch=30
05/23/2022 01:39:40 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.11 on epoch=30
05/23/2022 01:40:06 - INFO - __main__ - Global step 1700 Train loss 0.12 Classification-F1 0.6250122610235582 on epoch=30
05/23/2022 01:40:09 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.15 on epoch=30
05/23/2022 01:40:11 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.10 on epoch=30
05/23/2022 01:40:14 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.07 on epoch=30
05/23/2022 01:40:16 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.12 on epoch=31
05/23/2022 01:40:19 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.11 on epoch=31
05/23/2022 01:40:42 - INFO - __main__ - Global step 1750 Train loss 0.11 Classification-F1 0.612609687527499 on epoch=31
05/23/2022 01:40:44 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.10 on epoch=31
05/23/2022 01:40:47 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.08 on epoch=31
05/23/2022 01:40:49 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.17 on epoch=31
05/23/2022 01:40:52 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.08 on epoch=31
05/23/2022 01:40:54 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.08 on epoch=32
05/23/2022 01:41:19 - INFO - __main__ - Global step 1800 Train loss 0.10 Classification-F1 0.6280558460777507 on epoch=32
05/23/2022 01:41:22 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.09 on epoch=32
05/23/2022 01:41:24 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.04 on epoch=32
05/23/2022 01:41:27 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.11 on epoch=32
05/23/2022 01:41:30 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.07 on epoch=32
05/23/2022 01:41:32 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.05 on epoch=33
05/23/2022 01:42:00 - INFO - __main__ - Global step 1850 Train loss 0.07 Classification-F1 0.834657602816836 on epoch=33
05/23/2022 01:42:00 - INFO - __main__ - Saving model with best Classification-F1: 0.8218418208662452 -> 0.834657602816836 on epoch=33, global_step=1850
05/23/2022 01:42:02 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.10 on epoch=33
05/23/2022 01:42:05 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.11 on epoch=33
05/23/2022 01:42:07 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.05 on epoch=33
05/23/2022 01:42:10 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.10 on epoch=33
05/23/2022 01:42:13 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.06 on epoch=33
05/23/2022 01:42:38 - INFO - __main__ - Global step 1900 Train loss 0.08 Classification-F1 0.6971278183151988 on epoch=33
05/23/2022 01:42:40 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.09 on epoch=34
05/23/2022 01:42:43 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.13 on epoch=34
05/23/2022 01:42:46 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.09 on epoch=34
05/23/2022 01:42:48 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.06 on epoch=34
05/23/2022 01:42:51 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.06 on epoch=34
05/23/2022 01:43:18 - INFO - __main__ - Global step 1950 Train loss 0.09 Classification-F1 0.7035964626631317 on epoch=34
05/23/2022 01:43:21 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.04 on epoch=34
05/23/2022 01:43:23 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.20 on epoch=35
05/23/2022 01:43:26 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.11 on epoch=35
05/23/2022 01:43:28 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.08 on epoch=35
05/23/2022 01:43:31 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.06 on epoch=35
05/23/2022 01:43:58 - INFO - __main__ - Global step 2000 Train loss 0.10 Classification-F1 0.7038178947250686 on epoch=35
05/23/2022 01:44:01 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.05 on epoch=35
05/23/2022 01:44:03 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.08 on epoch=36
05/23/2022 01:44:06 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.07 on epoch=36
05/23/2022 01:44:08 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.09 on epoch=36
05/23/2022 01:44:11 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.04 on epoch=36
05/23/2022 01:44:36 - INFO - __main__ - Global step 2050 Train loss 0.07 Classification-F1 0.7112459757322055 on epoch=36
05/23/2022 01:44:38 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.09 on epoch=36
05/23/2022 01:44:41 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.04 on epoch=36
05/23/2022 01:44:44 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.09 on epoch=37
05/23/2022 01:44:46 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.10 on epoch=37
05/23/2022 01:44:49 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=37
05/23/2022 01:45:16 - INFO - __main__ - Global step 2100 Train loss 0.07 Classification-F1 0.7442338432720452 on epoch=37
05/23/2022 01:45:19 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.05 on epoch=37
05/23/2022 01:45:22 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.09 on epoch=37
05/23/2022 01:45:24 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.05 on epoch=38
05/23/2022 01:45:27 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.04 on epoch=38
05/23/2022 01:45:29 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.07 on epoch=38
05/23/2022 01:45:56 - INFO - __main__ - Global step 2150 Train loss 0.06 Classification-F1 0.8517216451876175 on epoch=38
05/23/2022 01:45:56 - INFO - __main__ - Saving model with best Classification-F1: 0.834657602816836 -> 0.8517216451876175 on epoch=38, global_step=2150
05/23/2022 01:45:59 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.05 on epoch=38
05/23/2022 01:46:02 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.09 on epoch=38
05/23/2022 01:46:04 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=38
05/23/2022 01:46:07 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.04 on epoch=39
05/23/2022 01:46:09 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.11 on epoch=39
05/23/2022 01:46:35 - INFO - __main__ - Global step 2200 Train loss 0.06 Classification-F1 0.8466582059098753 on epoch=39
05/23/2022 01:46:38 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=39
05/23/2022 01:46:40 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.04 on epoch=39
05/23/2022 01:46:43 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.08 on epoch=39
05/23/2022 01:46:45 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.05 on epoch=39
05/23/2022 01:46:48 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.07 on epoch=40
05/23/2022 01:47:13 - INFO - __main__ - Global step 2250 Train loss 0.06 Classification-F1 0.7533541848226952 on epoch=40
05/23/2022 01:47:16 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.09 on epoch=40
05/23/2022 01:47:18 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.06 on epoch=40
05/23/2022 01:47:21 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.08 on epoch=40
05/23/2022 01:47:23 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.07 on epoch=40
05/23/2022 01:47:26 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.05 on epoch=41
05/23/2022 01:47:51 - INFO - __main__ - Global step 2300 Train loss 0.07 Classification-F1 0.6219961240847712 on epoch=41
05/23/2022 01:47:53 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.07 on epoch=41
05/23/2022 01:47:56 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.07 on epoch=41
05/23/2022 01:47:59 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.04 on epoch=41
05/23/2022 01:48:01 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.12 on epoch=41
05/23/2022 01:48:04 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.05 on epoch=41
05/23/2022 01:48:30 - INFO - __main__ - Global step 2350 Train loss 0.07 Classification-F1 0.7051467239655 on epoch=41
05/23/2022 01:48:33 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=42
05/23/2022 01:48:36 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.07 on epoch=42
05/23/2022 01:48:38 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=42
05/23/2022 01:48:41 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.06 on epoch=42
05/23/2022 01:48:43 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.03 on epoch=42
05/23/2022 01:49:11 - INFO - __main__ - Global step 2400 Train loss 0.04 Classification-F1 0.7720699639730423 on epoch=42
05/23/2022 01:49:14 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.07 on epoch=43
05/23/2022 01:49:17 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.03 on epoch=43
05/23/2022 01:49:19 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.20 on epoch=43
05/23/2022 01:49:22 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.04 on epoch=43
05/23/2022 01:49:25 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.06 on epoch=43
05/23/2022 01:49:50 - INFO - __main__ - Global step 2450 Train loss 0.08 Classification-F1 0.6423244222483657 on epoch=43
05/23/2022 01:49:52 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.02 on epoch=43
05/23/2022 01:49:55 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.08 on epoch=44
05/23/2022 01:49:58 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.07 on epoch=44
05/23/2022 01:50:00 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.10 on epoch=44
05/23/2022 01:50:03 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.04 on epoch=44
05/23/2022 01:50:28 - INFO - __main__ - Global step 2500 Train loss 0.06 Classification-F1 0.5201444648051616 on epoch=44
05/23/2022 01:50:31 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.03 on epoch=44
05/23/2022 01:50:34 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.04 on epoch=44
05/23/2022 01:50:36 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.04 on epoch=45
05/23/2022 01:50:39 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.03 on epoch=45
05/23/2022 01:50:42 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=45
05/23/2022 01:51:08 - INFO - __main__ - Global step 2550 Train loss 0.04 Classification-F1 0.6230375976815941 on epoch=45
05/23/2022 01:51:10 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.03 on epoch=45
05/23/2022 01:51:13 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=45
05/23/2022 01:51:15 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.04 on epoch=46
05/23/2022 01:51:18 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.05 on epoch=46
05/23/2022 01:51:21 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.06 on epoch=46
05/23/2022 01:51:49 - INFO - __main__ - Global step 2600 Train loss 0.04 Classification-F1 0.6436297802885796 on epoch=46
05/23/2022 01:51:52 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.05 on epoch=46
05/23/2022 01:51:55 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.03 on epoch=46
05/23/2022 01:51:57 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=46
05/23/2022 01:52:00 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.09 on epoch=47
05/23/2022 01:52:02 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.08 on epoch=47
05/23/2022 01:52:30 - INFO - __main__ - Global step 2650 Train loss 0.05 Classification-F1 0.8416651565246186 on epoch=47
05/23/2022 01:52:32 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=47
05/23/2022 01:52:35 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.06 on epoch=47
05/23/2022 01:52:38 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.03 on epoch=47
05/23/2022 01:52:40 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.03 on epoch=48
05/23/2022 01:52:43 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.04 on epoch=48
05/23/2022 01:53:10 - INFO - __main__ - Global step 2700 Train loss 0.04 Classification-F1 0.7567559024183149 on epoch=48
05/23/2022 01:53:12 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.08 on epoch=48
05/23/2022 01:53:15 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.03 on epoch=48
05/23/2022 01:53:18 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.05 on epoch=48
05/23/2022 01:53:20 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.03 on epoch=48
05/23/2022 01:53:23 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.05 on epoch=49
05/23/2022 01:53:50 - INFO - __main__ - Global step 2750 Train loss 0.05 Classification-F1 0.6021077542799782 on epoch=49
05/23/2022 01:53:52 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.03 on epoch=49
05/23/2022 01:53:55 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.04 on epoch=49
05/23/2022 01:53:57 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.03 on epoch=49
05/23/2022 01:54:00 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.03 on epoch=49
05/23/2022 01:54:03 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.03 on epoch=49
05/23/2022 01:54:27 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.6227908999241251 on epoch=49
05/23/2022 01:54:29 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.04 on epoch=50
05/23/2022 01:54:32 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.04 on epoch=50
05/23/2022 01:54:35 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.06 on epoch=50
05/23/2022 01:54:37 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.03 on epoch=50
05/23/2022 01:54:40 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=50
05/23/2022 01:55:04 - INFO - __main__ - Global step 2850 Train loss 0.03 Classification-F1 0.613418950627448 on epoch=50
05/23/2022 01:55:06 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=51
05/23/2022 01:55:09 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.03 on epoch=51
05/23/2022 01:55:12 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.06 on epoch=51
05/23/2022 01:55:14 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.04 on epoch=51
05/23/2022 01:55:17 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.04 on epoch=51
05/23/2022 01:55:41 - INFO - __main__ - Global step 2900 Train loss 0.04 Classification-F1 0.6386178758144936 on epoch=51
05/23/2022 01:55:44 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=51
05/23/2022 01:55:46 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.08 on epoch=52
05/23/2022 01:55:49 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.03 on epoch=52
05/23/2022 01:55:52 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=52
05/23/2022 01:55:54 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.08 on epoch=52
05/23/2022 01:56:19 - INFO - __main__ - Global step 2950 Train loss 0.05 Classification-F1 0.7168722621935781 on epoch=52
05/23/2022 01:56:22 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=52
05/23/2022 01:56:24 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.03 on epoch=53
05/23/2022 01:56:27 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=53
05/23/2022 01:56:30 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.08 on epoch=53
05/23/2022 01:56:32 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=53
05/23/2022 01:56:34 - INFO - __main__ - Start tokenizing ... 896 instances
05/23/2022 01:56:34 - INFO - __main__ - Printing 3 examples
05/23/2022 01:56:34 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
05/23/2022 01:56:34 - INFO - __main__ - ['Film']
05/23/2022 01:56:34 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/23/2022 01:56:34 - INFO - __main__ - ['Film']
05/23/2022 01:56:34 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/23/2022 01:56:34 - INFO - __main__ - ['Film']
05/23/2022 01:56:34 - INFO - __main__ - Tokenizing Input ...
05/23/2022 01:56:34 - INFO - __main__ - Tokenizing Output ...
05/23/2022 01:56:35 - INFO - __main__ - Loaded 896 examples from train data
05/23/2022 01:56:35 - INFO - __main__ - Start tokenizing ... 896 instances
05/23/2022 01:56:35 - INFO - __main__ - Printing 3 examples
05/23/2022 01:56:35 - INFO - __main__ -  [dbpedia_14] The Minority is a 2007 American film written and directed by Dwayne Buckle and starring Billoah Greene as Jake Jackson. The Minority was Dwayne Buckle's first feature length film which was shot in New York City. The movie had its theatrical motion picture release in 2007 and debuted at the 15th Annual Pan African Film Festival in Los Angeles where it won an Honorable Mention Award. The film had its DVD release in 2009.
05/23/2022 01:56:35 - INFO - __main__ - ['Film']
05/23/2022 01:56:35 - INFO - __main__ -  [dbpedia_14] A Sign Days (A) is a 1989 Japanese film directed by Yichi Sai.
05/23/2022 01:56:35 - INFO - __main__ - ['Film']
05/23/2022 01:56:35 - INFO - __main__ -  [dbpedia_14] That Championship Season is a 1999 television film about a four members of a championship high school basketball team along with their coach that reunite 20 years later. The film is based on Jason Miller's Pulitzer Prize winning play of the same name. Sorvino assumes the role played by Robert Mitchum in the original film with D'Onofrio in his role from that presentation.
05/23/2022 01:56:35 - INFO - __main__ - ['Film']
05/23/2022 01:56:35 - INFO - __main__ - Tokenizing Input ...
05/23/2022 01:56:36 - INFO - __main__ - Tokenizing Output ...
05/23/2022 01:56:36 - INFO - __main__ - Loaded 896 examples from dev data
05/23/2022 01:56:52 - INFO - __main__ - try to initialize prompt embeddings
05/23/2022 01:56:52 - INFO - __main__ - task name: dbpedia_14
05/23/2022 01:56:52 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/23/2022 01:56:52 - INFO - __main__ - Starting training!
05/23/2022 01:57:02 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.6785650888663044 on epoch=53
05/23/2022 01:57:02 - INFO - __main__ - save last model!
05/23/2022 01:57:02 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/23/2022 01:57:02 - INFO - __main__ - Start tokenizing ... 3500 instances
05/23/2022 01:57:02 - INFO - __main__ - Printing 3 examples
05/23/2022 01:57:02 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/23/2022 01:57:02 - INFO - __main__ - ['Animal']
05/23/2022 01:57:02 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/23/2022 01:57:02 - INFO - __main__ - ['Animal']
05/23/2022 01:57:02 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/23/2022 01:57:02 - INFO - __main__ - ['Village']
05/23/2022 01:57:02 - INFO - __main__ - Tokenizing Input ...
05/23/2022 01:57:04 - INFO - __main__ - Tokenizing Output ...
05/23/2022 01:57:07 - INFO - __main__ - Loaded 3500 examples from test data
05/23/2022 01:59:23 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down64shot/singletask-dbpedia_14/dbpedia_14_64_42_0.2_8_predictions.txt
05/23/2022 01:59:23 - INFO - __main__ - Classification-F1 on test data: 0.5598
05/23/2022 01:59:24 - INFO - __main__ - prefix=dbpedia_14_64_42, lr=0.2, bsz=8, dev_performance=0.8517216451876175, test_performance=0.5598335962800062
05/23/2022 01:59:24 - INFO - __main__ - Running ... prefix=dbpedia_14_64_87, lr=0.5, bsz=8 ...
05/23/2022 01:59:24 - INFO - __main__ - Start tokenizing ... 896 instances
05/23/2022 01:59:24 - INFO - __main__ - Printing 3 examples
05/23/2022 01:59:24 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
05/23/2022 01:59:24 - INFO - __main__ - ['Film']
05/23/2022 01:59:24 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/23/2022 01:59:24 - INFO - __main__ - ['Film']
05/23/2022 01:59:24 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/23/2022 01:59:24 - INFO - __main__ - ['Film']
05/23/2022 01:59:24 - INFO - __main__ - Tokenizing Input ...
05/23/2022 01:59:25 - INFO - __main__ - Tokenizing Output ...
05/23/2022 01:59:26 - INFO - __main__ - Loaded 896 examples from train data
05/23/2022 01:59:26 - INFO - __main__ - Start tokenizing ... 896 instances
05/23/2022 01:59:26 - INFO - __main__ - Printing 3 examples
05/23/2022 01:59:26 - INFO - __main__ -  [dbpedia_14] The Minority is a 2007 American film written and directed by Dwayne Buckle and starring Billoah Greene as Jake Jackson. The Minority was Dwayne Buckle's first feature length film which was shot in New York City. The movie had its theatrical motion picture release in 2007 and debuted at the 15th Annual Pan African Film Festival in Los Angeles where it won an Honorable Mention Award. The film had its DVD release in 2009.
05/23/2022 01:59:26 - INFO - __main__ - ['Film']
05/23/2022 01:59:26 - INFO - __main__ -  [dbpedia_14] A Sign Days (A) is a 1989 Japanese film directed by Yichi Sai.
05/23/2022 01:59:26 - INFO - __main__ - ['Film']
05/23/2022 01:59:26 - INFO - __main__ -  [dbpedia_14] That Championship Season is a 1999 television film about a four members of a championship high school basketball team along with their coach that reunite 20 years later. The film is based on Jason Miller's Pulitzer Prize winning play of the same name. Sorvino assumes the role played by Robert Mitchum in the original film with D'Onofrio in his role from that presentation.
05/23/2022 01:59:26 - INFO - __main__ - ['Film']
05/23/2022 01:59:26 - INFO - __main__ - Tokenizing Input ...
05/23/2022 01:59:26 - INFO - __main__ - Tokenizing Output ...
05/23/2022 01:59:27 - INFO - __main__ - Loaded 896 examples from dev data
05/23/2022 01:59:43 - INFO - __main__ - try to initialize prompt embeddings
05/23/2022 01:59:43 - INFO - __main__ - task name: dbpedia_14
05/23/2022 01:59:43 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/23/2022 01:59:43 - INFO - __main__ - Starting training!
05/23/2022 01:59:46 - INFO - __main__ - Step 10 Global step 10 Train loss 6.83 on epoch=0
05/23/2022 01:59:49 - INFO - __main__ - Step 20 Global step 20 Train loss 5.39 on epoch=0
05/23/2022 01:59:52 - INFO - __main__ - Step 30 Global step 30 Train loss 3.74 on epoch=0
05/23/2022 01:59:54 - INFO - __main__ - Step 40 Global step 40 Train loss 2.65 on epoch=0
05/23/2022 01:59:57 - INFO - __main__ - Step 50 Global step 50 Train loss 2.08 on epoch=0
05/23/2022 02:00:32 - INFO - __main__ - Global step 50 Train loss 4.14 Classification-F1 0.17892742323165417 on epoch=0
05/23/2022 02:00:32 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.17892742323165417 on epoch=0, global_step=50
05/23/2022 02:00:34 - INFO - __main__ - Step 60 Global step 60 Train loss 1.57 on epoch=1
05/23/2022 02:00:37 - INFO - __main__ - Step 70 Global step 70 Train loss 1.30 on epoch=1
05/23/2022 02:00:40 - INFO - __main__ - Step 80 Global step 80 Train loss 1.38 on epoch=1
05/23/2022 02:00:42 - INFO - __main__ - Step 90 Global step 90 Train loss 1.23 on epoch=1
05/23/2022 02:00:45 - INFO - __main__ - Step 100 Global step 100 Train loss 0.94 on epoch=1
05/23/2022 02:01:22 - INFO - __main__ - Global step 100 Train loss 1.28 Classification-F1 0.21766281552136874 on epoch=1
05/23/2022 02:01:22 - INFO - __main__ - Saving model with best Classification-F1: 0.17892742323165417 -> 0.21766281552136874 on epoch=1, global_step=100
05/23/2022 02:01:24 - INFO - __main__ - Step 110 Global step 110 Train loss 1.01 on epoch=1
05/23/2022 02:01:27 - INFO - __main__ - Step 120 Global step 120 Train loss 0.84 on epoch=2
05/23/2022 02:01:29 - INFO - __main__ - Step 130 Global step 130 Train loss 0.95 on epoch=2
05/23/2022 02:01:32 - INFO - __main__ - Step 140 Global step 140 Train loss 0.90 on epoch=2
05/23/2022 02:01:35 - INFO - __main__ - Step 150 Global step 150 Train loss 0.73 on epoch=2
05/23/2022 02:02:05 - INFO - __main__ - Global step 150 Train loss 0.89 Classification-F1 0.30707706580053645 on epoch=2
05/23/2022 02:02:05 - INFO - __main__ - Saving model with best Classification-F1: 0.21766281552136874 -> 0.30707706580053645 on epoch=2, global_step=150
05/23/2022 02:02:07 - INFO - __main__ - Step 160 Global step 160 Train loss 0.78 on epoch=2
05/23/2022 02:02:10 - INFO - __main__ - Step 170 Global step 170 Train loss 0.64 on epoch=3
05/23/2022 02:02:13 - INFO - __main__ - Step 180 Global step 180 Train loss 0.67 on epoch=3
05/23/2022 02:02:15 - INFO - __main__ - Step 190 Global step 190 Train loss 0.72 on epoch=3
05/23/2022 02:02:18 - INFO - __main__ - Step 200 Global step 200 Train loss 0.60 on epoch=3
05/23/2022 02:02:43 - INFO - __main__ - Global step 200 Train loss 0.68 Classification-F1 0.4811601652817062 on epoch=3
05/23/2022 02:02:43 - INFO - __main__ - Saving model with best Classification-F1: 0.30707706580053645 -> 0.4811601652817062 on epoch=3, global_step=200
05/23/2022 02:02:46 - INFO - __main__ - Step 210 Global step 210 Train loss 0.63 on epoch=3
05/23/2022 02:02:49 - INFO - __main__ - Step 220 Global step 220 Train loss 0.58 on epoch=3
05/23/2022 02:02:51 - INFO - __main__ - Step 230 Global step 230 Train loss 0.62 on epoch=4
05/23/2022 02:02:54 - INFO - __main__ - Step 240 Global step 240 Train loss 0.43 on epoch=4
05/23/2022 02:02:56 - INFO - __main__ - Step 250 Global step 250 Train loss 0.53 on epoch=4
05/23/2022 02:03:25 - INFO - __main__ - Global step 250 Train loss 0.56 Classification-F1 0.4147159479542584 on epoch=4
05/23/2022 02:03:28 - INFO - __main__ - Step 260 Global step 260 Train loss 0.56 on epoch=4
05/23/2022 02:03:30 - INFO - __main__ - Step 270 Global step 270 Train loss 0.59 on epoch=4
05/23/2022 02:03:33 - INFO - __main__ - Step 280 Global step 280 Train loss 0.35 on epoch=4
05/23/2022 02:03:36 - INFO - __main__ - Step 290 Global step 290 Train loss 0.50 on epoch=5
05/23/2022 02:03:38 - INFO - __main__ - Step 300 Global step 300 Train loss 0.44 on epoch=5
05/23/2022 02:04:06 - INFO - __main__ - Global step 300 Train loss 0.49 Classification-F1 0.537943990203472 on epoch=5
05/23/2022 02:04:06 - INFO - __main__ - Saving model with best Classification-F1: 0.4811601652817062 -> 0.537943990203472 on epoch=5, global_step=300
05/23/2022 02:04:09 - INFO - __main__ - Step 310 Global step 310 Train loss 0.45 on epoch=5
05/23/2022 02:04:11 - INFO - __main__ - Step 320 Global step 320 Train loss 0.42 on epoch=5
05/23/2022 02:04:14 - INFO - __main__ - Step 330 Global step 330 Train loss 0.45 on epoch=5
05/23/2022 02:04:17 - INFO - __main__ - Step 340 Global step 340 Train loss 0.43 on epoch=6
05/23/2022 02:04:19 - INFO - __main__ - Step 350 Global step 350 Train loss 0.33 on epoch=6
05/23/2022 02:04:47 - INFO - __main__ - Global step 350 Train loss 0.42 Classification-F1 0.689877721322084 on epoch=6
05/23/2022 02:04:47 - INFO - __main__ - Saving model with best Classification-F1: 0.537943990203472 -> 0.689877721322084 on epoch=6, global_step=350
05/23/2022 02:04:50 - INFO - __main__ - Step 360 Global step 360 Train loss 0.44 on epoch=6
05/23/2022 02:04:52 - INFO - __main__ - Step 370 Global step 370 Train loss 0.42 on epoch=6
05/23/2022 02:04:55 - INFO - __main__ - Step 380 Global step 380 Train loss 0.38 on epoch=6
05/23/2022 02:04:58 - INFO - __main__ - Step 390 Global step 390 Train loss 0.39 on epoch=6
05/23/2022 02:05:00 - INFO - __main__ - Step 400 Global step 400 Train loss 0.36 on epoch=7
05/23/2022 02:05:27 - INFO - __main__ - Global step 400 Train loss 0.40 Classification-F1 0.36229012407291067 on epoch=7
05/23/2022 02:05:29 - INFO - __main__ - Step 410 Global step 410 Train loss 0.37 on epoch=7
05/23/2022 02:05:32 - INFO - __main__ - Step 420 Global step 420 Train loss 0.36 on epoch=7
05/23/2022 02:05:34 - INFO - __main__ - Step 430 Global step 430 Train loss 0.24 on epoch=7
05/23/2022 02:05:37 - INFO - __main__ - Step 440 Global step 440 Train loss 0.32 on epoch=7
05/23/2022 02:05:40 - INFO - __main__ - Step 450 Global step 450 Train loss 0.28 on epoch=8
05/23/2022 02:06:04 - INFO - __main__ - Global step 450 Train loss 0.31 Classification-F1 0.4977291614989551 on epoch=8
05/23/2022 02:06:06 - INFO - __main__ - Step 460 Global step 460 Train loss 0.26 on epoch=8
05/23/2022 02:06:09 - INFO - __main__ - Step 470 Global step 470 Train loss 0.23 on epoch=8
05/23/2022 02:06:12 - INFO - __main__ - Step 480 Global step 480 Train loss 0.21 on epoch=8
05/23/2022 02:06:14 - INFO - __main__ - Step 490 Global step 490 Train loss 0.21 on epoch=8
05/23/2022 02:06:17 - INFO - __main__ - Step 500 Global step 500 Train loss 0.32 on epoch=8
05/23/2022 02:06:46 - INFO - __main__ - Global step 500 Train loss 0.24 Classification-F1 0.5927206466391264 on epoch=8
05/23/2022 02:06:48 - INFO - __main__ - Step 510 Global step 510 Train loss 0.26 on epoch=9
05/23/2022 02:06:51 - INFO - __main__ - Step 520 Global step 520 Train loss 0.19 on epoch=9
05/23/2022 02:06:54 - INFO - __main__ - Step 530 Global step 530 Train loss 0.22 on epoch=9
05/23/2022 02:06:56 - INFO - __main__ - Step 540 Global step 540 Train loss 0.22 on epoch=9
05/23/2022 02:06:59 - INFO - __main__ - Step 550 Global step 550 Train loss 0.25 on epoch=9
05/23/2022 02:07:23 - INFO - __main__ - Global step 550 Train loss 0.23 Classification-F1 0.4650192956177797 on epoch=9
05/23/2022 02:07:26 - INFO - __main__ - Step 560 Global step 560 Train loss 0.22 on epoch=9
05/23/2022 02:07:29 - INFO - __main__ - Step 570 Global step 570 Train loss 0.28 on epoch=10
05/23/2022 02:07:31 - INFO - __main__ - Step 580 Global step 580 Train loss 0.18 on epoch=10
05/23/2022 02:07:34 - INFO - __main__ - Step 590 Global step 590 Train loss 0.19 on epoch=10
05/23/2022 02:07:36 - INFO - __main__ - Step 600 Global step 600 Train loss 0.21 on epoch=10
05/23/2022 02:08:02 - INFO - __main__ - Global step 600 Train loss 0.21 Classification-F1 0.39030563656061407 on epoch=10
05/23/2022 02:08:04 - INFO - __main__ - Step 610 Global step 610 Train loss 0.22 on epoch=10
05/23/2022 02:08:07 - INFO - __main__ - Step 620 Global step 620 Train loss 0.16 on epoch=11
05/23/2022 02:08:10 - INFO - __main__ - Step 630 Global step 630 Train loss 0.17 on epoch=11
05/23/2022 02:08:12 - INFO - __main__ - Step 640 Global step 640 Train loss 0.17 on epoch=11
05/23/2022 02:08:15 - INFO - __main__ - Step 650 Global step 650 Train loss 0.15 on epoch=11
05/23/2022 02:08:40 - INFO - __main__ - Global step 650 Train loss 0.17 Classification-F1 0.4260398953426369 on epoch=11
05/23/2022 02:08:42 - INFO - __main__ - Step 660 Global step 660 Train loss 0.22 on epoch=11
05/23/2022 02:08:45 - INFO - __main__ - Step 670 Global step 670 Train loss 0.11 on epoch=11
05/23/2022 02:08:48 - INFO - __main__ - Step 680 Global step 680 Train loss 0.16 on epoch=12
05/23/2022 02:08:50 - INFO - __main__ - Step 690 Global step 690 Train loss 0.18 on epoch=12
05/23/2022 02:08:53 - INFO - __main__ - Step 700 Global step 700 Train loss 0.15 on epoch=12
05/23/2022 02:09:18 - INFO - __main__ - Global step 700 Train loss 0.16 Classification-F1 0.4565770331168853 on epoch=12
05/23/2022 02:09:20 - INFO - __main__ - Step 710 Global step 710 Train loss 0.14 on epoch=12
05/23/2022 02:09:23 - INFO - __main__ - Step 720 Global step 720 Train loss 0.16 on epoch=12
05/23/2022 02:09:25 - INFO - __main__ - Step 730 Global step 730 Train loss 0.12 on epoch=13
05/23/2022 02:09:28 - INFO - __main__ - Step 740 Global step 740 Train loss 0.16 on epoch=13
05/23/2022 02:09:30 - INFO - __main__ - Step 750 Global step 750 Train loss 0.15 on epoch=13
05/23/2022 02:09:56 - INFO - __main__ - Global step 750 Train loss 0.15 Classification-F1 0.5749752030431767 on epoch=13
05/23/2022 02:09:59 - INFO - __main__ - Step 760 Global step 760 Train loss 0.15 on epoch=13
05/23/2022 02:10:02 - INFO - __main__ - Step 770 Global step 770 Train loss 0.15 on epoch=13
05/23/2022 02:10:04 - INFO - __main__ - Step 780 Global step 780 Train loss 0.17 on epoch=13
05/23/2022 02:10:07 - INFO - __main__ - Step 790 Global step 790 Train loss 0.13 on epoch=14
05/23/2022 02:10:09 - INFO - __main__ - Step 800 Global step 800 Train loss 0.11 on epoch=14
05/23/2022 02:10:34 - INFO - __main__ - Global step 800 Train loss 0.14 Classification-F1 0.3959864939376833 on epoch=14
05/23/2022 02:10:37 - INFO - __main__ - Step 810 Global step 810 Train loss 0.12 on epoch=14
05/23/2022 02:10:40 - INFO - __main__ - Step 820 Global step 820 Train loss 0.09 on epoch=14
05/23/2022 02:10:42 - INFO - __main__ - Step 830 Global step 830 Train loss 0.09 on epoch=14
05/23/2022 02:10:45 - INFO - __main__ - Step 840 Global step 840 Train loss 0.08 on epoch=14
05/23/2022 02:10:47 - INFO - __main__ - Step 850 Global step 850 Train loss 0.14 on epoch=15
05/23/2022 02:11:12 - INFO - __main__ - Global step 850 Train loss 0.11 Classification-F1 0.5743773717485855 on epoch=15
05/23/2022 02:11:14 - INFO - __main__ - Step 860 Global step 860 Train loss 0.15 on epoch=15
05/23/2022 02:11:17 - INFO - __main__ - Step 870 Global step 870 Train loss 0.13 on epoch=15
05/23/2022 02:11:20 - INFO - __main__ - Step 880 Global step 880 Train loss 0.11 on epoch=15
05/23/2022 02:11:22 - INFO - __main__ - Step 890 Global step 890 Train loss 0.09 on epoch=15
05/23/2022 02:11:25 - INFO - __main__ - Step 900 Global step 900 Train loss 0.10 on epoch=16
05/23/2022 02:11:48 - INFO - __main__ - Global step 900 Train loss 0.11 Classification-F1 0.6315454994864512 on epoch=16
05/23/2022 02:11:51 - INFO - __main__ - Step 910 Global step 910 Train loss 0.20 on epoch=16
05/23/2022 02:11:53 - INFO - __main__ - Step 920 Global step 920 Train loss 0.13 on epoch=16
05/23/2022 02:11:56 - INFO - __main__ - Step 930 Global step 930 Train loss 0.10 on epoch=16
05/23/2022 02:11:59 - INFO - __main__ - Step 940 Global step 940 Train loss 0.08 on epoch=16
05/23/2022 02:12:01 - INFO - __main__ - Step 950 Global step 950 Train loss 0.12 on epoch=16
05/23/2022 02:12:25 - INFO - __main__ - Global step 950 Train loss 0.13 Classification-F1 0.6183074281236335 on epoch=16
05/23/2022 02:12:27 - INFO - __main__ - Step 960 Global step 960 Train loss 0.13 on epoch=17
05/23/2022 02:12:30 - INFO - __main__ - Step 970 Global step 970 Train loss 0.09 on epoch=17
05/23/2022 02:12:33 - INFO - __main__ - Step 980 Global step 980 Train loss 0.07 on epoch=17
05/23/2022 02:12:35 - INFO - __main__ - Step 990 Global step 990 Train loss 0.09 on epoch=17
05/23/2022 02:12:38 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.08 on epoch=17
05/23/2022 02:13:02 - INFO - __main__ - Global step 1000 Train loss 0.09 Classification-F1 0.6615427785424348 on epoch=17
05/23/2022 02:13:05 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.05 on epoch=18
05/23/2022 02:13:07 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.15 on epoch=18
05/23/2022 02:13:10 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.07 on epoch=18
05/23/2022 02:13:12 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.06 on epoch=18
05/23/2022 02:13:15 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.07 on epoch=18
05/23/2022 02:13:39 - INFO - __main__ - Global step 1050 Train loss 0.08 Classification-F1 0.7216711370118749 on epoch=18
05/23/2022 02:13:39 - INFO - __main__ - Saving model with best Classification-F1: 0.689877721322084 -> 0.7216711370118749 on epoch=18, global_step=1050
05/23/2022 02:13:42 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.06 on epoch=18
05/23/2022 02:13:45 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.09 on epoch=19
05/23/2022 02:13:47 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.11 on epoch=19
05/23/2022 02:13:50 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.10 on epoch=19
05/23/2022 02:13:52 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.07 on epoch=19
05/23/2022 02:14:16 - INFO - __main__ - Global step 1100 Train loss 0.09 Classification-F1 0.6030795878812574 on epoch=19
05/23/2022 02:14:19 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.05 on epoch=19
05/23/2022 02:14:21 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.09 on epoch=19
05/23/2022 02:14:24 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.07 on epoch=20
05/23/2022 02:14:26 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.10 on epoch=20
05/23/2022 02:14:29 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.06 on epoch=20
05/23/2022 02:14:52 - INFO - __main__ - Global step 1150 Train loss 0.07 Classification-F1 0.7253149818561986 on epoch=20
05/23/2022 02:14:52 - INFO - __main__ - Saving model with best Classification-F1: 0.7216711370118749 -> 0.7253149818561986 on epoch=20, global_step=1150
05/23/2022 02:14:55 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.08 on epoch=20
05/23/2022 02:14:58 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.08 on epoch=20
05/23/2022 02:15:00 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.04 on epoch=21
05/23/2022 02:15:03 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.08 on epoch=21
05/23/2022 02:15:05 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.07 on epoch=21
05/23/2022 02:15:29 - INFO - __main__ - Global step 1200 Train loss 0.07 Classification-F1 0.5331648411694729 on epoch=21
05/23/2022 02:15:31 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.07 on epoch=21
05/23/2022 02:15:34 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.07 on epoch=21
05/23/2022 02:15:37 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.02 on epoch=21
05/23/2022 02:15:39 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.06 on epoch=22
05/23/2022 02:15:42 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.07 on epoch=22
05/23/2022 02:16:05 - INFO - __main__ - Global step 1250 Train loss 0.06 Classification-F1 0.6681283813902887 on epoch=22
05/23/2022 02:16:08 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.05 on epoch=22
05/23/2022 02:16:10 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.04 on epoch=22
05/23/2022 02:16:13 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.06 on epoch=22
05/23/2022 02:16:16 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.05 on epoch=23
05/23/2022 02:16:18 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.17 on epoch=23
05/23/2022 02:16:42 - INFO - __main__ - Global step 1300 Train loss 0.07 Classification-F1 0.666845664951498 on epoch=23
05/23/2022 02:16:45 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.06 on epoch=23
05/23/2022 02:16:47 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.05 on epoch=23
05/23/2022 02:16:50 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.05 on epoch=23
05/23/2022 02:16:52 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.02 on epoch=23
05/23/2022 02:16:55 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.05 on epoch=24
05/23/2022 02:17:19 - INFO - __main__ - Global step 1350 Train loss 0.05 Classification-F1 0.7524033578558611 on epoch=24
05/23/2022 02:17:19 - INFO - __main__ - Saving model with best Classification-F1: 0.7253149818561986 -> 0.7524033578558611 on epoch=24, global_step=1350
05/23/2022 02:17:22 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.10 on epoch=24
05/23/2022 02:17:24 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.04 on epoch=24
05/23/2022 02:17:27 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=24
05/23/2022 02:17:29 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.06 on epoch=24
05/23/2022 02:17:32 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.04 on epoch=24
05/23/2022 02:17:55 - INFO - __main__ - Global step 1400 Train loss 0.05 Classification-F1 0.6361230022769574 on epoch=24
05/23/2022 02:17:58 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.13 on epoch=25
05/23/2022 02:18:01 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.09 on epoch=25
05/23/2022 02:18:03 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.03 on epoch=25
05/23/2022 02:18:06 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=25
05/23/2022 02:18:08 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.06 on epoch=25
05/23/2022 02:18:32 - INFO - __main__ - Global step 1450 Train loss 0.06 Classification-F1 0.7022727209109059 on epoch=25
05/23/2022 02:18:34 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.08 on epoch=26
05/23/2022 02:18:37 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.04 on epoch=26
05/23/2022 02:18:39 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.04 on epoch=26
05/23/2022 02:18:42 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.02 on epoch=26
05/23/2022 02:18:45 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.04 on epoch=26
05/23/2022 02:19:09 - INFO - __main__ - Global step 1500 Train loss 0.04 Classification-F1 0.8594441403168012 on epoch=26
05/23/2022 02:19:09 - INFO - __main__ - Saving model with best Classification-F1: 0.7524033578558611 -> 0.8594441403168012 on epoch=26, global_step=1500
05/23/2022 02:19:12 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.04 on epoch=26
05/23/2022 02:19:14 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.10 on epoch=27
05/23/2022 02:19:17 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.07 on epoch=27
05/23/2022 02:19:19 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=27
05/23/2022 02:19:22 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.05 on epoch=27
05/23/2022 02:19:46 - INFO - __main__ - Global step 1550 Train loss 0.06 Classification-F1 0.7887483294875779 on epoch=27
05/23/2022 02:19:49 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.03 on epoch=27
05/23/2022 02:19:51 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.03 on epoch=28
05/23/2022 02:19:54 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.06 on epoch=28
05/23/2022 02:19:56 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.05 on epoch=28
05/23/2022 02:19:59 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.06 on epoch=28
05/23/2022 02:20:23 - INFO - __main__ - Global step 1600 Train loss 0.05 Classification-F1 0.7298451723372369 on epoch=28
05/23/2022 02:20:25 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=28
05/23/2022 02:20:28 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.04 on epoch=28
05/23/2022 02:20:30 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.07 on epoch=29
05/23/2022 02:20:33 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.03 on epoch=29
05/23/2022 02:20:36 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.05 on epoch=29
05/23/2022 02:20:59 - INFO - __main__ - Global step 1650 Train loss 0.04 Classification-F1 0.8208478527320014 on epoch=29
05/23/2022 02:21:02 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.03 on epoch=29
05/23/2022 02:21:05 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.03 on epoch=29
05/23/2022 02:21:07 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.08 on epoch=29
05/23/2022 02:21:10 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.04 on epoch=30
05/23/2022 02:21:12 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.06 on epoch=30
05/23/2022 02:21:36 - INFO - __main__ - Global step 1700 Train loss 0.05 Classification-F1 0.8412198273175981 on epoch=30
05/23/2022 02:21:39 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=30
05/23/2022 02:21:42 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.02 on epoch=30
05/23/2022 02:21:44 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.04 on epoch=30
05/23/2022 02:21:47 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.04 on epoch=31
05/23/2022 02:21:49 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=31
05/23/2022 02:22:15 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.7583601240213862 on epoch=31
05/23/2022 02:22:17 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.07 on epoch=31
05/23/2022 02:22:20 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.06 on epoch=31
05/23/2022 02:22:22 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.04 on epoch=31
05/23/2022 02:22:25 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=31
05/23/2022 02:22:28 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=32
05/23/2022 02:22:52 - INFO - __main__ - Global step 1800 Train loss 0.04 Classification-F1 0.9139411733243056 on epoch=32
05/23/2022 02:22:52 - INFO - __main__ - Saving model with best Classification-F1: 0.8594441403168012 -> 0.9139411733243056 on epoch=32, global_step=1800
05/23/2022 02:22:55 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.04 on epoch=32
05/23/2022 02:22:58 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.05 on epoch=32
05/23/2022 02:23:00 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=32
05/23/2022 02:23:03 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=32
05/23/2022 02:23:06 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=33
05/23/2022 02:23:30 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.9202905351090208 on epoch=33
05/23/2022 02:23:30 - INFO - __main__ - Saving model with best Classification-F1: 0.9139411733243056 -> 0.9202905351090208 on epoch=33, global_step=1850
05/23/2022 02:23:33 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=33
05/23/2022 02:23:35 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.06 on epoch=33
05/23/2022 02:23:38 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=33
05/23/2022 02:23:41 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=33
05/23/2022 02:23:43 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.02 on epoch=33
05/23/2022 02:24:08 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.9744015684268945 on epoch=33
05/23/2022 02:24:08 - INFO - __main__ - Saving model with best Classification-F1: 0.9202905351090208 -> 0.9744015684268945 on epoch=33, global_step=1900
05/23/2022 02:24:10 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.04 on epoch=34
05/23/2022 02:24:13 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=34
05/23/2022 02:24:15 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.04 on epoch=34
05/23/2022 02:24:18 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=34
05/23/2022 02:24:21 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.06 on epoch=34
05/23/2022 02:24:45 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.765262692594145 on epoch=34
05/23/2022 02:24:48 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.03 on epoch=34
05/23/2022 02:24:50 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=35
05/23/2022 02:24:53 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=35
05/23/2022 02:24:56 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=35
05/23/2022 02:24:58 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.05 on epoch=35
05/23/2022 02:25:22 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.8101126773516927 on epoch=35
05/23/2022 02:25:24 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=35
05/23/2022 02:25:27 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=36
05/23/2022 02:25:30 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.05 on epoch=36
05/23/2022 02:25:32 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=36
05/23/2022 02:25:35 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=36
05/23/2022 02:26:00 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.8101869480411442 on epoch=36
05/23/2022 02:26:03 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.03 on epoch=36
05/23/2022 02:26:05 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=36
05/23/2022 02:26:08 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=37
05/23/2022 02:26:11 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.04 on epoch=37
05/23/2022 02:26:13 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.06 on epoch=37
05/23/2022 02:26:36 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.7483709618288474 on epoch=37
05/23/2022 02:26:39 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=37
05/23/2022 02:26:42 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.05 on epoch=37
05/23/2022 02:26:44 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=38
05/23/2022 02:26:47 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=38
05/23/2022 02:26:50 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=38
05/23/2022 02:27:14 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.863725154806172 on epoch=38
05/23/2022 02:27:16 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=38
05/23/2022 02:27:19 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=38
05/23/2022 02:27:21 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=38
05/23/2022 02:27:24 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=39
05/23/2022 02:27:27 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.04 on epoch=39
05/23/2022 02:27:51 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.9888563847760309 on epoch=39
05/23/2022 02:27:51 - INFO - __main__ - Saving model with best Classification-F1: 0.9744015684268945 -> 0.9888563847760309 on epoch=39, global_step=2200
05/23/2022 02:27:54 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.03 on epoch=39
05/23/2022 02:27:56 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=39
05/23/2022 02:27:59 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.03 on epoch=39
05/23/2022 02:28:02 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=39
05/23/2022 02:28:04 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=40
05/23/2022 02:28:28 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.861120274919067 on epoch=40
05/23/2022 02:28:31 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.03 on epoch=40
05/23/2022 02:28:34 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=40
05/23/2022 02:28:36 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=40
05/23/2022 02:28:39 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=40
05/23/2022 02:28:42 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=41
05/23/2022 02:29:06 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.9899723199570983 on epoch=41
05/23/2022 02:29:06 - INFO - __main__ - Saving model with best Classification-F1: 0.9888563847760309 -> 0.9899723199570983 on epoch=41, global_step=2300
05/23/2022 02:29:08 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.04 on epoch=41
05/23/2022 02:29:11 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=41
05/23/2022 02:29:13 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=41
05/23/2022 02:29:16 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=41
05/23/2022 02:29:19 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=41
05/23/2022 02:29:42 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.7638425726916077 on epoch=41
05/23/2022 02:29:44 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=42
05/23/2022 02:29:47 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.07 on epoch=42
05/23/2022 02:29:50 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.04 on epoch=42
05/23/2022 02:29:52 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=42
05/23/2022 02:29:55 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=42
05/23/2022 02:30:18 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.917469349295709 on epoch=42
05/23/2022 02:30:21 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=43
05/23/2022 02:30:24 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.03 on epoch=43
05/23/2022 02:30:26 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.14 on epoch=43
05/23/2022 02:30:29 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=43
05/23/2022 02:30:31 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=43
05/23/2022 02:30:54 - INFO - __main__ - Global step 2450 Train loss 0.04 Classification-F1 0.9866326892641327 on epoch=43
05/23/2022 02:30:57 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=43
05/23/2022 02:30:59 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=44
05/23/2022 02:31:02 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=44
05/23/2022 02:31:05 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=44
05/23/2022 02:31:07 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=44
05/23/2022 02:31:30 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.9233916799644231 on epoch=44
05/23/2022 02:31:33 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.04 on epoch=44
05/23/2022 02:31:35 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=44
05/23/2022 02:31:38 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=45
05/23/2022 02:31:41 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.04 on epoch=45
05/23/2022 02:31:43 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=45
05/23/2022 02:32:06 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.9160936194277226 on epoch=45
05/23/2022 02:32:09 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=45
05/23/2022 02:32:11 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=45
05/23/2022 02:32:14 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=46
05/23/2022 02:32:17 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.05 on epoch=46
05/23/2022 02:32:19 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.07 on epoch=46
05/23/2022 02:32:42 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.7673516283622571 on epoch=46
05/23/2022 02:32:44 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=46
05/23/2022 02:32:47 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=46
05/23/2022 02:32:49 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=46
05/23/2022 02:32:52 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=47
05/23/2022 02:32:54 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.05 on epoch=47
05/23/2022 02:33:18 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.9877462143011722 on epoch=47
05/23/2022 02:33:21 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=47
05/23/2022 02:33:23 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=47
05/23/2022 02:33:26 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=47
05/23/2022 02:33:28 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.06 on epoch=48
05/23/2022 02:33:31 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=48
05/23/2022 02:33:53 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.8992974979701072 on epoch=48
05/23/2022 02:33:56 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.03 on epoch=48
05/23/2022 02:33:58 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.03 on epoch=48
05/23/2022 02:34:01 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=48
05/23/2022 02:34:04 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=48
05/23/2022 02:34:06 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.03 on epoch=49
05/23/2022 02:34:28 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.7233991483790092 on epoch=49
05/23/2022 02:34:31 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=49
05/23/2022 02:34:34 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=49
05/23/2022 02:34:36 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.05 on epoch=49
05/23/2022 02:34:39 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=49
05/23/2022 02:34:42 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.06 on epoch=49
05/23/2022 02:35:05 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.8133963374343018 on epoch=49
05/23/2022 02:35:08 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.03 on epoch=50
05/23/2022 02:35:10 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=50
05/23/2022 02:35:13 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=50
05/23/2022 02:35:15 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.03 on epoch=50
05/23/2022 02:35:18 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=50
05/23/2022 02:35:43 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.9234323178669452 on epoch=50
05/23/2022 02:35:45 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=51
05/23/2022 02:35:48 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.05 on epoch=51
05/23/2022 02:35:51 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=51
05/23/2022 02:35:53 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=51
05/23/2022 02:35:56 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=51
05/23/2022 02:36:20 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.8607305307800542 on epoch=51
05/23/2022 02:36:22 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=51
05/23/2022 02:36:25 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.03 on epoch=52
05/23/2022 02:36:28 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.04 on epoch=52
05/23/2022 02:36:30 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=52
05/23/2022 02:36:33 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=52
05/23/2022 02:36:56 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.8642623613408646 on epoch=52
05/23/2022 02:36:59 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.03 on epoch=52
05/23/2022 02:37:01 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=53
05/23/2022 02:37:04 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=53
05/23/2022 02:37:07 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.05 on epoch=53
05/23/2022 02:37:09 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=53
05/23/2022 02:37:10 - INFO - __main__ - Start tokenizing ... 896 instances
05/23/2022 02:37:10 - INFO - __main__ - Printing 3 examples
05/23/2022 02:37:10 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
05/23/2022 02:37:10 - INFO - __main__ - ['Film']
05/23/2022 02:37:10 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/23/2022 02:37:10 - INFO - __main__ - ['Film']
05/23/2022 02:37:10 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/23/2022 02:37:10 - INFO - __main__ - ['Film']
05/23/2022 02:37:10 - INFO - __main__ - Tokenizing Input ...
05/23/2022 02:37:11 - INFO - __main__ - Tokenizing Output ...
05/23/2022 02:37:12 - INFO - __main__ - Loaded 896 examples from train data
05/23/2022 02:37:12 - INFO - __main__ - Start tokenizing ... 896 instances
05/23/2022 02:37:12 - INFO - __main__ - Printing 3 examples
05/23/2022 02:37:12 - INFO - __main__ -  [dbpedia_14] The Minority is a 2007 American film written and directed by Dwayne Buckle and starring Billoah Greene as Jake Jackson. The Minority was Dwayne Buckle's first feature length film which was shot in New York City. The movie had its theatrical motion picture release in 2007 and debuted at the 15th Annual Pan African Film Festival in Los Angeles where it won an Honorable Mention Award. The film had its DVD release in 2009.
05/23/2022 02:37:12 - INFO - __main__ - ['Film']
05/23/2022 02:37:12 - INFO - __main__ -  [dbpedia_14] A Sign Days (A) is a 1989 Japanese film directed by Yichi Sai.
05/23/2022 02:37:12 - INFO - __main__ - ['Film']
05/23/2022 02:37:12 - INFO - __main__ -  [dbpedia_14] That Championship Season is a 1999 television film about a four members of a championship high school basketball team along with their coach that reunite 20 years later. The film is based on Jason Miller's Pulitzer Prize winning play of the same name. Sorvino assumes the role played by Robert Mitchum in the original film with D'Onofrio in his role from that presentation.
05/23/2022 02:37:12 - INFO - __main__ - ['Film']
05/23/2022 02:37:12 - INFO - __main__ - Tokenizing Input ...
05/23/2022 02:37:12 - INFO - __main__ - Tokenizing Output ...
05/23/2022 02:37:13 - INFO - __main__ - Loaded 896 examples from dev data
05/23/2022 02:37:29 - INFO - __main__ - try to initialize prompt embeddings
05/23/2022 02:37:29 - INFO - __main__ - task name: dbpedia_14
05/23/2022 02:37:29 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/23/2022 02:37:29 - INFO - __main__ - Starting training!
05/23/2022 02:37:32 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.985556361799593 on epoch=53
05/23/2022 02:37:32 - INFO - __main__ - save last model!
05/23/2022 02:37:32 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/23/2022 02:37:32 - INFO - __main__ - Start tokenizing ... 3500 instances
05/23/2022 02:37:32 - INFO - __main__ - Printing 3 examples
05/23/2022 02:37:32 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/23/2022 02:37:32 - INFO - __main__ - ['Animal']
05/23/2022 02:37:32 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/23/2022 02:37:32 - INFO - __main__ - ['Animal']
05/23/2022 02:37:32 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/23/2022 02:37:32 - INFO - __main__ - ['Village']
05/23/2022 02:37:32 - INFO - __main__ - Tokenizing Input ...
05/23/2022 02:37:34 - INFO - __main__ - Tokenizing Output ...
05/23/2022 02:37:37 - INFO - __main__ - Loaded 3500 examples from test data
05/23/2022 02:39:41 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down64shot/singletask-dbpedia_14/dbpedia_14_64_87_0.5_8_predictions.txt
05/23/2022 02:39:41 - INFO - __main__ - Classification-F1 on test data: 0.8111
05/23/2022 02:39:42 - INFO - __main__ - prefix=dbpedia_14_64_87, lr=0.5, bsz=8, dev_performance=0.9899723199570983, test_performance=0.8110831619285093
05/23/2022 02:39:42 - INFO - __main__ - Running ... prefix=dbpedia_14_64_87, lr=0.4, bsz=8 ...
05/23/2022 02:39:43 - INFO - __main__ - Start tokenizing ... 896 instances
05/23/2022 02:39:43 - INFO - __main__ - Printing 3 examples
05/23/2022 02:39:43 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
05/23/2022 02:39:43 - INFO - __main__ - ['Film']
05/23/2022 02:39:43 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/23/2022 02:39:43 - INFO - __main__ - ['Film']
05/23/2022 02:39:43 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/23/2022 02:39:43 - INFO - __main__ - ['Film']
05/23/2022 02:39:43 - INFO - __main__ - Tokenizing Input ...
05/23/2022 02:39:43 - INFO - __main__ - Tokenizing Output ...
05/23/2022 02:39:44 - INFO - __main__ - Loaded 896 examples from train data
05/23/2022 02:39:44 - INFO - __main__ - Start tokenizing ... 896 instances
05/23/2022 02:39:44 - INFO - __main__ - Printing 3 examples
05/23/2022 02:39:44 - INFO - __main__ -  [dbpedia_14] The Minority is a 2007 American film written and directed by Dwayne Buckle and starring Billoah Greene as Jake Jackson. The Minority was Dwayne Buckle's first feature length film which was shot in New York City. The movie had its theatrical motion picture release in 2007 and debuted at the 15th Annual Pan African Film Festival in Los Angeles where it won an Honorable Mention Award. The film had its DVD release in 2009.
05/23/2022 02:39:44 - INFO - __main__ - ['Film']
05/23/2022 02:39:44 - INFO - __main__ -  [dbpedia_14] A Sign Days (A) is a 1989 Japanese film directed by Yichi Sai.
05/23/2022 02:39:44 - INFO - __main__ - ['Film']
05/23/2022 02:39:44 - INFO - __main__ -  [dbpedia_14] That Championship Season is a 1999 television film about a four members of a championship high school basketball team along with their coach that reunite 20 years later. The film is based on Jason Miller's Pulitzer Prize winning play of the same name. Sorvino assumes the role played by Robert Mitchum in the original film with D'Onofrio in his role from that presentation.
05/23/2022 02:39:44 - INFO - __main__ - ['Film']
05/23/2022 02:39:44 - INFO - __main__ - Tokenizing Input ...
05/23/2022 02:39:44 - INFO - __main__ - Tokenizing Output ...
05/23/2022 02:39:45 - INFO - __main__ - Loaded 896 examples from dev data
05/23/2022 02:40:04 - INFO - __main__ - try to initialize prompt embeddings
05/23/2022 02:40:04 - INFO - __main__ - task name: dbpedia_14
05/23/2022 02:40:05 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/23/2022 02:40:05 - INFO - __main__ - Starting training!
05/23/2022 02:40:08 - INFO - __main__ - Step 10 Global step 10 Train loss 6.88 on epoch=0
05/23/2022 02:40:11 - INFO - __main__ - Step 20 Global step 20 Train loss 5.74 on epoch=0
05/23/2022 02:40:13 - INFO - __main__ - Step 30 Global step 30 Train loss 4.22 on epoch=0
05/23/2022 02:40:16 - INFO - __main__ - Step 40 Global step 40 Train loss 3.05 on epoch=0
05/23/2022 02:40:19 - INFO - __main__ - Step 50 Global step 50 Train loss 2.64 on epoch=0
05/23/2022 02:40:43 - INFO - __main__ - Global step 50 Train loss 4.51 Classification-F1 0.08805585409381347 on epoch=0
05/23/2022 02:40:43 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.08805585409381347 on epoch=0, global_step=50
05/23/2022 02:40:46 - INFO - __main__ - Step 60 Global step 60 Train loss 1.95 on epoch=1
05/23/2022 02:40:49 - INFO - __main__ - Step 70 Global step 70 Train loss 1.70 on epoch=1
05/23/2022 02:40:51 - INFO - __main__ - Step 80 Global step 80 Train loss 1.52 on epoch=1
05/23/2022 02:40:54 - INFO - __main__ - Step 90 Global step 90 Train loss 1.34 on epoch=1
05/23/2022 02:40:56 - INFO - __main__ - Step 100 Global step 100 Train loss 1.12 on epoch=1
05/23/2022 02:41:24 - INFO - __main__ - Global step 100 Train loss 1.53 Classification-F1 0.25364425757994336 on epoch=1
05/23/2022 02:41:24 - INFO - __main__ - Saving model with best Classification-F1: 0.08805585409381347 -> 0.25364425757994336 on epoch=1, global_step=100
05/23/2022 02:41:27 - INFO - __main__ - Step 110 Global step 110 Train loss 1.14 on epoch=1
05/23/2022 02:41:29 - INFO - __main__ - Step 120 Global step 120 Train loss 0.92 on epoch=2
05/23/2022 02:41:32 - INFO - __main__ - Step 130 Global step 130 Train loss 0.98 on epoch=2
05/23/2022 02:41:34 - INFO - __main__ - Step 140 Global step 140 Train loss 1.02 on epoch=2
05/23/2022 02:41:37 - INFO - __main__ - Step 150 Global step 150 Train loss 0.85 on epoch=2
05/23/2022 02:42:05 - INFO - __main__ - Global step 150 Train loss 0.98 Classification-F1 0.48553151491301694 on epoch=2
05/23/2022 02:42:05 - INFO - __main__ - Saving model with best Classification-F1: 0.25364425757994336 -> 0.48553151491301694 on epoch=2, global_step=150
05/23/2022 02:42:08 - INFO - __main__ - Step 160 Global step 160 Train loss 0.84 on epoch=2
05/23/2022 02:42:10 - INFO - __main__ - Step 170 Global step 170 Train loss 0.82 on epoch=3
05/23/2022 02:42:13 - INFO - __main__ - Step 180 Global step 180 Train loss 0.74 on epoch=3
05/23/2022 02:42:16 - INFO - __main__ - Step 190 Global step 190 Train loss 0.74 on epoch=3
05/23/2022 02:42:18 - INFO - __main__ - Step 200 Global step 200 Train loss 0.70 on epoch=3
05/23/2022 02:42:45 - INFO - __main__ - Global step 200 Train loss 0.77 Classification-F1 0.4867802837412599 on epoch=3
05/23/2022 02:42:45 - INFO - __main__ - Saving model with best Classification-F1: 0.48553151491301694 -> 0.4867802837412599 on epoch=3, global_step=200
05/23/2022 02:42:47 - INFO - __main__ - Step 210 Global step 210 Train loss 0.69 on epoch=3
05/23/2022 02:42:50 - INFO - __main__ - Step 220 Global step 220 Train loss 0.63 on epoch=3
05/23/2022 02:42:53 - INFO - __main__ - Step 230 Global step 230 Train loss 0.62 on epoch=4
05/23/2022 02:42:55 - INFO - __main__ - Step 240 Global step 240 Train loss 0.62 on epoch=4
05/23/2022 02:42:58 - INFO - __main__ - Step 250 Global step 250 Train loss 0.61 on epoch=4
05/23/2022 02:43:25 - INFO - __main__ - Global step 250 Train loss 0.63 Classification-F1 0.5336427261135213 on epoch=4
05/23/2022 02:43:25 - INFO - __main__ - Saving model with best Classification-F1: 0.4867802837412599 -> 0.5336427261135213 on epoch=4, global_step=250
05/23/2022 02:43:27 - INFO - __main__ - Step 260 Global step 260 Train loss 0.56 on epoch=4
05/23/2022 02:43:30 - INFO - __main__ - Step 270 Global step 270 Train loss 0.50 on epoch=4
05/23/2022 02:43:33 - INFO - __main__ - Step 280 Global step 280 Train loss 0.46 on epoch=4
05/23/2022 02:43:35 - INFO - __main__ - Step 290 Global step 290 Train loss 0.56 on epoch=5
05/23/2022 02:43:38 - INFO - __main__ - Step 300 Global step 300 Train loss 0.65 on epoch=5
05/23/2022 02:44:05 - INFO - __main__ - Global step 300 Train loss 0.55 Classification-F1 0.41925609100805183 on epoch=5
05/23/2022 02:44:08 - INFO - __main__ - Step 310 Global step 310 Train loss 0.42 on epoch=5
05/23/2022 02:44:10 - INFO - __main__ - Step 320 Global step 320 Train loss 0.37 on epoch=5
05/23/2022 02:44:13 - INFO - __main__ - Step 330 Global step 330 Train loss 0.41 on epoch=5
05/23/2022 02:44:16 - INFO - __main__ - Step 340 Global step 340 Train loss 0.45 on epoch=6
05/23/2022 02:44:18 - INFO - __main__ - Step 350 Global step 350 Train loss 0.41 on epoch=6
05/23/2022 02:44:45 - INFO - __main__ - Global step 350 Train loss 0.41 Classification-F1 0.6898010614862491 on epoch=6
05/23/2022 02:44:45 - INFO - __main__ - Saving model with best Classification-F1: 0.5336427261135213 -> 0.6898010614862491 on epoch=6, global_step=350
05/23/2022 02:44:48 - INFO - __main__ - Step 360 Global step 360 Train loss 0.35 on epoch=6
05/23/2022 02:44:50 - INFO - __main__ - Step 370 Global step 370 Train loss 0.39 on epoch=6
05/23/2022 02:44:53 - INFO - __main__ - Step 380 Global step 380 Train loss 0.34 on epoch=6
05/23/2022 02:44:56 - INFO - __main__ - Step 390 Global step 390 Train loss 0.37 on epoch=6
05/23/2022 02:44:58 - INFO - __main__ - Step 400 Global step 400 Train loss 0.34 on epoch=7
05/23/2022 02:45:24 - INFO - __main__ - Global step 400 Train loss 0.36 Classification-F1 0.5887723695395148 on epoch=7
05/23/2022 02:45:27 - INFO - __main__ - Step 410 Global step 410 Train loss 0.31 on epoch=7
05/23/2022 02:45:29 - INFO - __main__ - Step 420 Global step 420 Train loss 0.33 on epoch=7
05/23/2022 02:45:32 - INFO - __main__ - Step 430 Global step 430 Train loss 0.31 on epoch=7
05/23/2022 02:45:35 - INFO - __main__ - Step 440 Global step 440 Train loss 0.32 on epoch=7
05/23/2022 02:45:37 - INFO - __main__ - Step 450 Global step 450 Train loss 0.31 on epoch=8
05/23/2022 02:46:02 - INFO - __main__ - Global step 450 Train loss 0.32 Classification-F1 0.686750451398936 on epoch=8
05/23/2022 02:46:04 - INFO - __main__ - Step 460 Global step 460 Train loss 0.28 on epoch=8
05/23/2022 02:46:07 - INFO - __main__ - Step 470 Global step 470 Train loss 0.30 on epoch=8
05/23/2022 02:46:10 - INFO - __main__ - Step 480 Global step 480 Train loss 0.25 on epoch=8
05/23/2022 02:46:12 - INFO - __main__ - Step 490 Global step 490 Train loss 0.25 on epoch=8
05/23/2022 02:46:15 - INFO - __main__ - Step 500 Global step 500 Train loss 0.22 on epoch=8
05/23/2022 02:46:42 - INFO - __main__ - Global step 500 Train loss 0.26 Classification-F1 0.7586059990115501 on epoch=8
05/23/2022 02:46:42 - INFO - __main__ - Saving model with best Classification-F1: 0.6898010614862491 -> 0.7586059990115501 on epoch=8, global_step=500
05/23/2022 02:46:45 - INFO - __main__ - Step 510 Global step 510 Train loss 0.24 on epoch=9
05/23/2022 02:46:48 - INFO - __main__ - Step 520 Global step 520 Train loss 0.26 on epoch=9
05/23/2022 02:46:50 - INFO - __main__ - Step 530 Global step 530 Train loss 0.23 on epoch=9
05/23/2022 02:46:53 - INFO - __main__ - Step 540 Global step 540 Train loss 0.17 on epoch=9
05/23/2022 02:46:55 - INFO - __main__ - Step 550 Global step 550 Train loss 0.19 on epoch=9
05/23/2022 02:47:20 - INFO - __main__ - Global step 550 Train loss 0.22 Classification-F1 0.7870425940861034 on epoch=9
05/23/2022 02:47:20 - INFO - __main__ - Saving model with best Classification-F1: 0.7586059990115501 -> 0.7870425940861034 on epoch=9, global_step=550
05/23/2022 02:47:23 - INFO - __main__ - Step 560 Global step 560 Train loss 0.22 on epoch=9
05/23/2022 02:47:25 - INFO - __main__ - Step 570 Global step 570 Train loss 0.22 on epoch=10
05/23/2022 02:47:28 - INFO - __main__ - Step 580 Global step 580 Train loss 0.25 on epoch=10
05/23/2022 02:47:31 - INFO - __main__ - Step 590 Global step 590 Train loss 0.27 on epoch=10
05/23/2022 02:47:33 - INFO - __main__ - Step 600 Global step 600 Train loss 0.26 on epoch=10
05/23/2022 02:47:57 - INFO - __main__ - Global step 600 Train loss 0.24 Classification-F1 0.5848869454221239 on epoch=10
05/23/2022 02:48:00 - INFO - __main__ - Step 610 Global step 610 Train loss 0.21 on epoch=10
05/23/2022 02:48:02 - INFO - __main__ - Step 620 Global step 620 Train loss 0.12 on epoch=11
05/23/2022 02:48:05 - INFO - __main__ - Step 630 Global step 630 Train loss 0.19 on epoch=11
05/23/2022 02:48:07 - INFO - __main__ - Step 640 Global step 640 Train loss 0.19 on epoch=11
05/23/2022 02:48:10 - INFO - __main__ - Step 650 Global step 650 Train loss 0.25 on epoch=11
05/23/2022 02:48:36 - INFO - __main__ - Global step 650 Train loss 0.19 Classification-F1 0.7105951423225318 on epoch=11
05/23/2022 02:48:38 - INFO - __main__ - Step 660 Global step 660 Train loss 0.16 on epoch=11
05/23/2022 02:48:41 - INFO - __main__ - Step 670 Global step 670 Train loss 0.17 on epoch=11
05/23/2022 02:48:43 - INFO - __main__ - Step 680 Global step 680 Train loss 0.16 on epoch=12
05/23/2022 02:48:46 - INFO - __main__ - Step 690 Global step 690 Train loss 0.19 on epoch=12
05/23/2022 02:48:48 - INFO - __main__ - Step 700 Global step 700 Train loss 0.12 on epoch=12
05/23/2022 02:49:15 - INFO - __main__ - Global step 700 Train loss 0.16 Classification-F1 0.6684044570531097 on epoch=12
05/23/2022 02:49:17 - INFO - __main__ - Step 710 Global step 710 Train loss 0.12 on epoch=12
05/23/2022 02:49:20 - INFO - __main__ - Step 720 Global step 720 Train loss 0.13 on epoch=12
05/23/2022 02:49:23 - INFO - __main__ - Step 730 Global step 730 Train loss 0.12 on epoch=13
05/23/2022 02:49:25 - INFO - __main__ - Step 740 Global step 740 Train loss 0.22 on epoch=13
05/23/2022 02:49:28 - INFO - __main__ - Step 750 Global step 750 Train loss 0.11 on epoch=13
05/23/2022 02:49:53 - INFO - __main__ - Global step 750 Train loss 0.14 Classification-F1 0.7424775554768521 on epoch=13
05/23/2022 02:49:56 - INFO - __main__ - Step 760 Global step 760 Train loss 0.13 on epoch=13
05/23/2022 02:49:58 - INFO - __main__ - Step 770 Global step 770 Train loss 0.06 on epoch=13
05/23/2022 02:50:01 - INFO - __main__ - Step 780 Global step 780 Train loss 0.15 on epoch=13
05/23/2022 02:50:03 - INFO - __main__ - Step 790 Global step 790 Train loss 0.14 on epoch=14
05/23/2022 02:50:06 - INFO - __main__ - Step 800 Global step 800 Train loss 0.14 on epoch=14
05/23/2022 02:50:31 - INFO - __main__ - Global step 800 Train loss 0.12 Classification-F1 0.7436317733465811 on epoch=14
05/23/2022 02:50:33 - INFO - __main__ - Step 810 Global step 810 Train loss 0.14 on epoch=14
05/23/2022 02:50:36 - INFO - __main__ - Step 820 Global step 820 Train loss 0.07 on epoch=14
05/23/2022 02:50:38 - INFO - __main__ - Step 830 Global step 830 Train loss 0.19 on epoch=14
05/23/2022 02:50:41 - INFO - __main__ - Step 840 Global step 840 Train loss 0.13 on epoch=14
05/23/2022 02:50:43 - INFO - __main__ - Step 850 Global step 850 Train loss 0.17 on epoch=15
05/23/2022 02:51:08 - INFO - __main__ - Global step 850 Train loss 0.14 Classification-F1 0.7871190628129882 on epoch=15
05/23/2022 02:51:08 - INFO - __main__ - Saving model with best Classification-F1: 0.7870425940861034 -> 0.7871190628129882 on epoch=15, global_step=850
05/23/2022 02:51:10 - INFO - __main__ - Step 860 Global step 860 Train loss 0.12 on epoch=15
05/23/2022 02:51:13 - INFO - __main__ - Step 870 Global step 870 Train loss 0.09 on epoch=15
05/23/2022 02:51:16 - INFO - __main__ - Step 880 Global step 880 Train loss 0.09 on epoch=15
05/23/2022 02:51:18 - INFO - __main__ - Step 890 Global step 890 Train loss 0.06 on epoch=15
05/23/2022 02:51:21 - INFO - __main__ - Step 900 Global step 900 Train loss 0.08 on epoch=16
05/23/2022 02:51:45 - INFO - __main__ - Global step 900 Train loss 0.09 Classification-F1 0.8211822636481082 on epoch=16
05/23/2022 02:51:45 - INFO - __main__ - Saving model with best Classification-F1: 0.7871190628129882 -> 0.8211822636481082 on epoch=16, global_step=900
05/23/2022 02:51:48 - INFO - __main__ - Step 910 Global step 910 Train loss 0.15 on epoch=16
05/23/2022 02:51:50 - INFO - __main__ - Step 920 Global step 920 Train loss 0.14 on epoch=16
05/23/2022 02:51:53 - INFO - __main__ - Step 930 Global step 930 Train loss 0.10 on epoch=16
05/23/2022 02:51:55 - INFO - __main__ - Step 940 Global step 940 Train loss 0.12 on epoch=16
05/23/2022 02:51:58 - INFO - __main__ - Step 950 Global step 950 Train loss 0.09 on epoch=16
05/23/2022 02:52:23 - INFO - __main__ - Global step 950 Train loss 0.12 Classification-F1 0.6480615402469386 on epoch=16
05/23/2022 02:52:25 - INFO - __main__ - Step 960 Global step 960 Train loss 0.12 on epoch=17
05/23/2022 02:52:28 - INFO - __main__ - Step 970 Global step 970 Train loss 0.12 on epoch=17
05/23/2022 02:52:31 - INFO - __main__ - Step 980 Global step 980 Train loss 0.09 on epoch=17
05/23/2022 02:52:33 - INFO - __main__ - Step 990 Global step 990 Train loss 0.12 on epoch=17
05/23/2022 02:52:36 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.16 on epoch=17
05/23/2022 02:53:00 - INFO - __main__ - Global step 1000 Train loss 0.12 Classification-F1 0.7079403924221763 on epoch=17
05/23/2022 02:53:03 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.08 on epoch=18
05/23/2022 02:53:05 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.12 on epoch=18
05/23/2022 02:53:08 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.08 on epoch=18
05/23/2022 02:53:10 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.08 on epoch=18
05/23/2022 02:53:13 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.09 on epoch=18
05/23/2022 02:53:37 - INFO - __main__ - Global step 1050 Train loss 0.09 Classification-F1 0.739255145519809 on epoch=18
05/23/2022 02:53:39 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.11 on epoch=18
05/23/2022 02:53:42 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.14 on epoch=19
05/23/2022 02:53:45 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.12 on epoch=19
05/23/2022 02:53:47 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.08 on epoch=19
05/23/2022 02:53:50 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.04 on epoch=19
05/23/2022 02:54:13 - INFO - __main__ - Global step 1100 Train loss 0.10 Classification-F1 0.7135618582612189 on epoch=19
05/23/2022 02:54:16 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.03 on epoch=19
05/23/2022 02:54:19 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.06 on epoch=19
05/23/2022 02:54:21 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.05 on epoch=20
05/23/2022 02:54:24 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.14 on epoch=20
05/23/2022 02:54:26 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.11 on epoch=20
05/23/2022 02:54:49 - INFO - __main__ - Global step 1150 Train loss 0.08 Classification-F1 0.8501361432119255 on epoch=20
05/23/2022 02:54:49 - INFO - __main__ - Saving model with best Classification-F1: 0.8211822636481082 -> 0.8501361432119255 on epoch=20, global_step=1150
05/23/2022 02:54:51 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.05 on epoch=20
05/23/2022 02:54:54 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.05 on epoch=20
05/23/2022 02:54:57 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.07 on epoch=21
05/23/2022 02:54:59 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.15 on epoch=21
05/23/2022 02:55:02 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.07 on epoch=21
05/23/2022 02:55:26 - INFO - __main__ - Global step 1200 Train loss 0.08 Classification-F1 0.8351701812576326 on epoch=21
05/23/2022 02:55:29 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.10 on epoch=21
05/23/2022 02:55:31 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.08 on epoch=21
05/23/2022 02:55:34 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.04 on epoch=21
05/23/2022 02:55:36 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.03 on epoch=22
05/23/2022 02:55:39 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.10 on epoch=22
05/23/2022 02:56:03 - INFO - __main__ - Global step 1250 Train loss 0.07 Classification-F1 0.8563335432365873 on epoch=22
05/23/2022 02:56:03 - INFO - __main__ - Saving model with best Classification-F1: 0.8501361432119255 -> 0.8563335432365873 on epoch=22, global_step=1250
05/23/2022 02:56:06 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.08 on epoch=22
05/23/2022 02:56:08 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.07 on epoch=22
05/23/2022 02:56:11 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.04 on epoch=22
05/23/2022 02:56:13 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.05 on epoch=23
05/23/2022 02:56:16 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.10 on epoch=23
05/23/2022 02:56:41 - INFO - __main__ - Global step 1300 Train loss 0.07 Classification-F1 0.839917500747208 on epoch=23
05/23/2022 02:56:43 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.07 on epoch=23
05/23/2022 02:56:46 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.06 on epoch=23
05/23/2022 02:56:48 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.06 on epoch=23
05/23/2022 02:56:51 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.04 on epoch=23
05/23/2022 02:56:53 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.06 on epoch=24
05/23/2022 02:57:17 - INFO - __main__ - Global step 1350 Train loss 0.06 Classification-F1 0.8467809489417691 on epoch=24
05/23/2022 02:57:20 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.07 on epoch=24
05/23/2022 02:57:22 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.05 on epoch=24
05/23/2022 02:57:25 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.05 on epoch=24
05/23/2022 02:57:27 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.10 on epoch=24
05/23/2022 02:57:30 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.03 on epoch=24
05/23/2022 02:57:54 - INFO - __main__ - Global step 1400 Train loss 0.06 Classification-F1 0.8598379327293602 on epoch=24
05/23/2022 02:57:54 - INFO - __main__ - Saving model with best Classification-F1: 0.8563335432365873 -> 0.8598379327293602 on epoch=24, global_step=1400
05/23/2022 02:57:57 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.07 on epoch=25
05/23/2022 02:57:59 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.15 on epoch=25
05/23/2022 02:58:02 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.05 on epoch=25
05/23/2022 02:58:04 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.06 on epoch=25
05/23/2022 02:58:07 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.08 on epoch=25
05/23/2022 02:58:31 - INFO - __main__ - Global step 1450 Train loss 0.08 Classification-F1 0.8402539346224036 on epoch=25
05/23/2022 02:58:34 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=26
05/23/2022 02:58:37 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.06 on epoch=26
05/23/2022 02:58:39 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.07 on epoch=26
05/23/2022 02:58:42 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.06 on epoch=26
05/23/2022 02:58:44 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.07 on epoch=26
05/23/2022 02:59:09 - INFO - __main__ - Global step 1500 Train loss 0.05 Classification-F1 0.8417189743219144 on epoch=26
05/23/2022 02:59:12 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.09 on epoch=26
05/23/2022 02:59:14 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.05 on epoch=27
05/23/2022 02:59:17 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.05 on epoch=27
05/23/2022 02:59:19 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=27
05/23/2022 02:59:22 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=27
05/23/2022 02:59:46 - INFO - __main__ - Global step 1550 Train loss 0.05 Classification-F1 0.8222615525481329 on epoch=27
05/23/2022 02:59:49 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.07 on epoch=27
05/23/2022 02:59:51 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.10 on epoch=28
05/23/2022 02:59:54 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.06 on epoch=28
05/23/2022 02:59:56 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.06 on epoch=28
05/23/2022 02:59:59 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.03 on epoch=28
05/23/2022 03:00:23 - INFO - __main__ - Global step 1600 Train loss 0.06 Classification-F1 0.8545463696201767 on epoch=28
05/23/2022 03:00:25 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.05 on epoch=28
05/23/2022 03:00:28 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.05 on epoch=28
05/23/2022 03:00:31 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.05 on epoch=29
05/23/2022 03:00:33 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.07 on epoch=29
05/23/2022 03:00:36 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.08 on epoch=29
05/23/2022 03:00:59 - INFO - __main__ - Global step 1650 Train loss 0.06 Classification-F1 0.8654082033565534 on epoch=29
05/23/2022 03:00:59 - INFO - __main__ - Saving model with best Classification-F1: 0.8598379327293602 -> 0.8654082033565534 on epoch=29, global_step=1650
05/23/2022 03:01:02 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.03 on epoch=29
05/23/2022 03:01:04 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.05 on epoch=29
05/23/2022 03:01:07 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.03 on epoch=29
05/23/2022 03:01:09 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.04 on epoch=30
05/23/2022 03:01:12 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.18 on epoch=30
05/23/2022 03:01:35 - INFO - __main__ - Global step 1700 Train loss 0.06 Classification-F1 0.7486587500678464 on epoch=30
05/23/2022 03:01:37 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.03 on epoch=30
05/23/2022 03:01:40 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.02 on epoch=30
05/23/2022 03:01:43 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.03 on epoch=30
05/23/2022 03:01:45 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=31
05/23/2022 03:01:48 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=31
05/23/2022 03:02:10 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.7656028444867294 on epoch=31
05/23/2022 03:02:13 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.05 on epoch=31
05/23/2022 03:02:15 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.03 on epoch=31
05/23/2022 03:02:18 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=31
05/23/2022 03:02:21 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=31
05/23/2022 03:02:23 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.08 on epoch=32
05/23/2022 03:02:46 - INFO - __main__ - Global step 1800 Train loss 0.04 Classification-F1 0.8044791892642094 on epoch=32
05/23/2022 03:02:49 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.04 on epoch=32
05/23/2022 03:02:51 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=32
05/23/2022 03:02:54 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.06 on epoch=32
05/23/2022 03:02:56 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.07 on epoch=32
05/23/2022 03:02:59 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.06 on epoch=33
05/23/2022 03:03:22 - INFO - __main__ - Global step 1850 Train loss 0.05 Classification-F1 0.8471091984696844 on epoch=33
05/23/2022 03:03:24 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.03 on epoch=33
05/23/2022 03:03:27 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.03 on epoch=33
05/23/2022 03:03:30 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=33
05/23/2022 03:03:32 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=33
05/23/2022 03:03:35 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.02 on epoch=33
05/23/2022 03:03:58 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.804058051924484 on epoch=33
05/23/2022 03:04:01 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=34
05/23/2022 03:04:03 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.14 on epoch=34
05/23/2022 03:04:06 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.05 on epoch=34
05/23/2022 03:04:09 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=34
05/23/2022 03:04:11 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.03 on epoch=34
05/23/2022 03:04:35 - INFO - __main__ - Global step 1950 Train loss 0.05 Classification-F1 0.7398829056869571 on epoch=34
05/23/2022 03:04:37 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=34
05/23/2022 03:04:40 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.08 on epoch=35
05/23/2022 03:04:42 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.06 on epoch=35
05/23/2022 03:04:45 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=35
05/23/2022 03:04:48 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.08 on epoch=35
05/23/2022 03:05:11 - INFO - __main__ - Global step 2000 Train loss 0.05 Classification-F1 0.8626974836773146 on epoch=35
05/23/2022 03:05:13 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.03 on epoch=35
05/23/2022 03:05:16 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.03 on epoch=36
05/23/2022 03:05:18 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.04 on epoch=36
05/23/2022 03:05:21 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.03 on epoch=36
05/23/2022 03:05:23 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.06 on epoch=36
05/23/2022 03:05:46 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.862024411481585 on epoch=36
05/23/2022 03:05:49 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.02 on epoch=36
05/23/2022 03:05:51 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.05 on epoch=36
05/23/2022 03:05:54 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.05 on epoch=37
05/23/2022 03:05:56 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.04 on epoch=37
05/23/2022 03:05:59 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.05 on epoch=37
05/23/2022 03:06:22 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.7327199630232529 on epoch=37
05/23/2022 03:06:25 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.05 on epoch=37
05/23/2022 03:06:27 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.03 on epoch=37
05/23/2022 03:06:30 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=38
05/23/2022 03:06:33 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.04 on epoch=38
05/23/2022 03:06:35 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.09 on epoch=38
05/23/2022 03:06:59 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.8759115560156747 on epoch=38
05/23/2022 03:06:59 - INFO - __main__ - Saving model with best Classification-F1: 0.8654082033565534 -> 0.8759115560156747 on epoch=38, global_step=2150
05/23/2022 03:07:02 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=38
05/23/2022 03:07:04 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=38
05/23/2022 03:07:07 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=38
05/23/2022 03:07:10 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=39
05/23/2022 03:07:12 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.09 on epoch=39
05/23/2022 03:07:36 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.799883599618175 on epoch=39
05/23/2022 03:07:39 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.09 on epoch=39
05/23/2022 03:07:42 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=39
05/23/2022 03:07:44 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.08 on epoch=39
05/23/2022 03:07:47 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=39
05/23/2022 03:07:49 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.04 on epoch=40
05/23/2022 03:08:13 - INFO - __main__ - Global step 2250 Train loss 0.05 Classification-F1 0.8554666578147712 on epoch=40
05/23/2022 03:08:16 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.04 on epoch=40
05/23/2022 03:08:19 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.03 on epoch=40
05/23/2022 03:08:21 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=40
05/23/2022 03:08:24 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.03 on epoch=40
05/23/2022 03:08:26 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=41
05/23/2022 03:08:51 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.836927170936187 on epoch=41
05/23/2022 03:08:53 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=41
05/23/2022 03:08:56 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=41
05/23/2022 03:08:59 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=41
05/23/2022 03:09:01 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=41
05/23/2022 03:09:04 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=41
05/23/2022 03:09:27 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.9171851982740704 on epoch=41
05/23/2022 03:09:27 - INFO - __main__ - Saving model with best Classification-F1: 0.8759115560156747 -> 0.9171851982740704 on epoch=41, global_step=2350
05/23/2022 03:09:30 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=42
05/23/2022 03:09:33 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=42
05/23/2022 03:09:35 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.06 on epoch=42
05/23/2022 03:09:38 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=42
05/23/2022 03:09:40 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.05 on epoch=42
05/23/2022 03:10:04 - INFO - __main__ - Global step 2400 Train loss 0.04 Classification-F1 0.8391349737619217 on epoch=42
05/23/2022 03:10:07 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=43
05/23/2022 03:10:09 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.03 on epoch=43
05/23/2022 03:10:12 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=43
05/23/2022 03:10:14 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.06 on epoch=43
05/23/2022 03:10:17 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.04 on epoch=43
05/23/2022 03:10:41 - INFO - __main__ - Global step 2450 Train loss 0.04 Classification-F1 0.914597060508313 on epoch=43
05/23/2022 03:10:44 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=43
05/23/2022 03:10:46 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.05 on epoch=44
05/23/2022 03:10:49 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.07 on epoch=44
05/23/2022 03:10:52 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=44
05/23/2022 03:10:54 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=44
05/23/2022 03:11:18 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.8545046992567622 on epoch=44
05/23/2022 03:11:20 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.04 on epoch=44
05/23/2022 03:11:23 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=44
05/23/2022 03:11:26 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=45
05/23/2022 03:11:28 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.04 on epoch=45
05/23/2022 03:11:31 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.04 on epoch=45
05/23/2022 03:11:55 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.8358758311672451 on epoch=45
05/23/2022 03:11:57 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=45
05/23/2022 03:12:00 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=45
05/23/2022 03:12:03 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.04 on epoch=46
05/23/2022 03:12:05 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.06 on epoch=46
05/23/2022 03:12:08 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=46
05/23/2022 03:12:31 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.738645901854003 on epoch=46
05/23/2022 03:12:34 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=46
05/23/2022 03:12:36 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=46
05/23/2022 03:12:39 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=46
05/23/2022 03:12:42 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.04 on epoch=47
05/23/2022 03:12:44 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=47
05/23/2022 03:13:08 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.8082163601673173 on epoch=47
05/23/2022 03:13:10 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.04 on epoch=47
05/23/2022 03:13:13 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.07 on epoch=47
05/23/2022 03:13:15 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.03 on epoch=47
05/23/2022 03:13:18 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=48
05/23/2022 03:13:21 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=48
05/23/2022 03:13:45 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.8377670959460248 on epoch=48
05/23/2022 03:13:47 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=48
05/23/2022 03:13:50 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=48
05/23/2022 03:13:53 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=48
05/23/2022 03:13:56 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=48
05/23/2022 03:13:58 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=49
05/23/2022 03:14:22 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.753246012569898 on epoch=49
05/23/2022 03:14:25 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.06 on epoch=49
05/23/2022 03:14:27 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.04 on epoch=49
05/23/2022 03:14:30 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=49
05/23/2022 03:14:32 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.07 on epoch=49
05/23/2022 03:14:35 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=49
05/23/2022 03:14:59 - INFO - __main__ - Global step 2800 Train loss 0.04 Classification-F1 0.8011123307154189 on epoch=49
05/23/2022 03:15:01 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.04 on epoch=50
05/23/2022 03:15:04 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.05 on epoch=50
05/23/2022 03:15:07 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=50
05/23/2022 03:15:09 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=50
05/23/2022 03:15:12 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=50
05/23/2022 03:15:35 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.7444457236362945 on epoch=50
05/23/2022 03:15:38 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.03 on epoch=51
05/23/2022 03:15:41 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.06 on epoch=51
05/23/2022 03:15:43 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=51
05/23/2022 03:15:46 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=51
05/23/2022 03:15:48 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.04 on epoch=51
05/23/2022 03:16:12 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.7122753791156344 on epoch=51
05/23/2022 03:16:15 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=51
05/23/2022 03:16:18 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=52
05/23/2022 03:16:20 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=52
05/23/2022 03:16:23 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=52
05/23/2022 03:16:25 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=52
05/23/2022 03:16:49 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.8590208048569586 on epoch=52
05/23/2022 03:16:51 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=52
05/23/2022 03:16:54 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=53
05/23/2022 03:16:57 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.03 on epoch=53
05/23/2022 03:16:59 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=53
05/23/2022 03:17:02 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=53
05/23/2022 03:17:03 - INFO - __main__ - Start tokenizing ... 896 instances
05/23/2022 03:17:03 - INFO - __main__ - Printing 3 examples
05/23/2022 03:17:03 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
05/23/2022 03:17:03 - INFO - __main__ - ['Film']
05/23/2022 03:17:03 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/23/2022 03:17:03 - INFO - __main__ - ['Film']
05/23/2022 03:17:03 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/23/2022 03:17:03 - INFO - __main__ - ['Film']
05/23/2022 03:17:03 - INFO - __main__ - Tokenizing Input ...
05/23/2022 03:17:04 - INFO - __main__ - Tokenizing Output ...
05/23/2022 03:17:05 - INFO - __main__ - Loaded 896 examples from train data
05/23/2022 03:17:05 - INFO - __main__ - Start tokenizing ... 896 instances
05/23/2022 03:17:05 - INFO - __main__ - Printing 3 examples
05/23/2022 03:17:05 - INFO - __main__ -  [dbpedia_14] The Minority is a 2007 American film written and directed by Dwayne Buckle and starring Billoah Greene as Jake Jackson. The Minority was Dwayne Buckle's first feature length film which was shot in New York City. The movie had its theatrical motion picture release in 2007 and debuted at the 15th Annual Pan African Film Festival in Los Angeles where it won an Honorable Mention Award. The film had its DVD release in 2009.
05/23/2022 03:17:05 - INFO - __main__ - ['Film']
05/23/2022 03:17:05 - INFO - __main__ -  [dbpedia_14] A Sign Days (A) is a 1989 Japanese film directed by Yichi Sai.
05/23/2022 03:17:05 - INFO - __main__ - ['Film']
05/23/2022 03:17:05 - INFO - __main__ -  [dbpedia_14] That Championship Season is a 1999 television film about a four members of a championship high school basketball team along with their coach that reunite 20 years later. The film is based on Jason Miller's Pulitzer Prize winning play of the same name. Sorvino assumes the role played by Robert Mitchum in the original film with D'Onofrio in his role from that presentation.
05/23/2022 03:17:05 - INFO - __main__ - ['Film']
05/23/2022 03:17:05 - INFO - __main__ - Tokenizing Input ...
05/23/2022 03:17:05 - INFO - __main__ - Tokenizing Output ...
05/23/2022 03:17:06 - INFO - __main__ - Loaded 896 examples from dev data
05/23/2022 03:17:21 - INFO - __main__ - try to initialize prompt embeddings
05/23/2022 03:17:21 - INFO - __main__ - task name: dbpedia_14
05/23/2022 03:17:22 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/23/2022 03:17:22 - INFO - __main__ - Starting training!
05/23/2022 03:17:25 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.7564449056473171 on epoch=53
05/23/2022 03:17:25 - INFO - __main__ - save last model!
05/23/2022 03:17:25 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/23/2022 03:17:25 - INFO - __main__ - Start tokenizing ... 3500 instances
05/23/2022 03:17:25 - INFO - __main__ - Printing 3 examples
05/23/2022 03:17:25 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/23/2022 03:17:25 - INFO - __main__ - ['Animal']
05/23/2022 03:17:25 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/23/2022 03:17:25 - INFO - __main__ - ['Animal']
05/23/2022 03:17:25 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/23/2022 03:17:25 - INFO - __main__ - ['Village']
05/23/2022 03:17:25 - INFO - __main__ - Tokenizing Input ...
05/23/2022 03:17:27 - INFO - __main__ - Tokenizing Output ...
05/23/2022 03:17:31 - INFO - __main__ - Loaded 3500 examples from test data
05/23/2022 03:19:36 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down64shot/singletask-dbpedia_14/dbpedia_14_64_87_0.4_8_predictions.txt
05/23/2022 03:19:36 - INFO - __main__ - Classification-F1 on test data: 0.6366
05/23/2022 03:19:36 - INFO - __main__ - prefix=dbpedia_14_64_87, lr=0.4, bsz=8, dev_performance=0.9171851982740704, test_performance=0.6365752252924429
05/23/2022 03:19:36 - INFO - __main__ - Running ... prefix=dbpedia_14_64_87, lr=0.3, bsz=8 ...
05/23/2022 03:19:37 - INFO - __main__ - Start tokenizing ... 896 instances
05/23/2022 03:19:37 - INFO - __main__ - Printing 3 examples
05/23/2022 03:19:37 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
05/23/2022 03:19:37 - INFO - __main__ - ['Film']
05/23/2022 03:19:37 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/23/2022 03:19:37 - INFO - __main__ - ['Film']
05/23/2022 03:19:37 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/23/2022 03:19:37 - INFO - __main__ - ['Film']
05/23/2022 03:19:37 - INFO - __main__ - Tokenizing Input ...
05/23/2022 03:19:37 - INFO - __main__ - Tokenizing Output ...
05/23/2022 03:19:38 - INFO - __main__ - Loaded 896 examples from train data
05/23/2022 03:19:38 - INFO - __main__ - Start tokenizing ... 896 instances
05/23/2022 03:19:38 - INFO - __main__ - Printing 3 examples
05/23/2022 03:19:38 - INFO - __main__ -  [dbpedia_14] The Minority is a 2007 American film written and directed by Dwayne Buckle and starring Billoah Greene as Jake Jackson. The Minority was Dwayne Buckle's first feature length film which was shot in New York City. The movie had its theatrical motion picture release in 2007 and debuted at the 15th Annual Pan African Film Festival in Los Angeles where it won an Honorable Mention Award. The film had its DVD release in 2009.
05/23/2022 03:19:38 - INFO - __main__ - ['Film']
05/23/2022 03:19:38 - INFO - __main__ -  [dbpedia_14] A Sign Days (A) is a 1989 Japanese film directed by Yichi Sai.
05/23/2022 03:19:38 - INFO - __main__ - ['Film']
05/23/2022 03:19:38 - INFO - __main__ -  [dbpedia_14] That Championship Season is a 1999 television film about a four members of a championship high school basketball team along with their coach that reunite 20 years later. The film is based on Jason Miller's Pulitzer Prize winning play of the same name. Sorvino assumes the role played by Robert Mitchum in the original film with D'Onofrio in his role from that presentation.
05/23/2022 03:19:38 - INFO - __main__ - ['Film']
05/23/2022 03:19:38 - INFO - __main__ - Tokenizing Input ...
05/23/2022 03:19:39 - INFO - __main__ - Tokenizing Output ...
05/23/2022 03:19:40 - INFO - __main__ - Loaded 896 examples from dev data
05/23/2022 03:19:56 - INFO - __main__ - try to initialize prompt embeddings
05/23/2022 03:19:56 - INFO - __main__ - task name: dbpedia_14
05/23/2022 03:19:56 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/23/2022 03:19:56 - INFO - __main__ - Starting training!
05/23/2022 03:19:59 - INFO - __main__ - Step 10 Global step 10 Train loss 6.84 on epoch=0
05/23/2022 03:20:02 - INFO - __main__ - Step 20 Global step 20 Train loss 6.04 on epoch=0
05/23/2022 03:20:05 - INFO - __main__ - Step 30 Global step 30 Train loss 4.62 on epoch=0
05/23/2022 03:20:07 - INFO - __main__ - Step 40 Global step 40 Train loss 3.45 on epoch=0
05/23/2022 03:20:10 - INFO - __main__ - Step 50 Global step 50 Train loss 2.84 on epoch=0
05/23/2022 03:23:03 - INFO - __main__ - Global step 50 Train loss 4.76 Classification-F1 0.00932944970729499 on epoch=0
05/23/2022 03:23:03 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.00932944970729499 on epoch=0, global_step=50
05/23/2022 03:23:06 - INFO - __main__ - Step 60 Global step 60 Train loss 2.17 on epoch=1
05/23/2022 03:23:09 - INFO - __main__ - Step 70 Global step 70 Train loss 1.94 on epoch=1
05/23/2022 03:23:11 - INFO - __main__ - Step 80 Global step 80 Train loss 1.82 on epoch=1
05/23/2022 03:23:14 - INFO - __main__ - Step 90 Global step 90 Train loss 1.58 on epoch=1
05/23/2022 03:23:16 - INFO - __main__ - Step 100 Global step 100 Train loss 1.27 on epoch=1
05/23/2022 03:23:57 - INFO - __main__ - Global step 100 Train loss 1.76 Classification-F1 0.1972978634256506 on epoch=1
05/23/2022 03:23:57 - INFO - __main__ - Saving model with best Classification-F1: 0.00932944970729499 -> 0.1972978634256506 on epoch=1, global_step=100
05/23/2022 03:24:00 - INFO - __main__ - Step 110 Global step 110 Train loss 1.23 on epoch=1
05/23/2022 03:24:02 - INFO - __main__ - Step 120 Global step 120 Train loss 1.15 on epoch=2
05/23/2022 03:24:05 - INFO - __main__ - Step 130 Global step 130 Train loss 1.05 on epoch=2
05/23/2022 03:24:07 - INFO - __main__ - Step 140 Global step 140 Train loss 1.07 on epoch=2
05/23/2022 03:24:10 - INFO - __main__ - Step 150 Global step 150 Train loss 0.96 on epoch=2
05/23/2022 03:24:39 - INFO - __main__ - Global step 150 Train loss 1.09 Classification-F1 0.34091281239663074 on epoch=2
05/23/2022 03:24:39 - INFO - __main__ - Saving model with best Classification-F1: 0.1972978634256506 -> 0.34091281239663074 on epoch=2, global_step=150
05/23/2022 03:24:41 - INFO - __main__ - Step 160 Global step 160 Train loss 0.90 on epoch=2
05/23/2022 03:24:44 - INFO - __main__ - Step 170 Global step 170 Train loss 0.83 on epoch=3
05/23/2022 03:24:46 - INFO - __main__ - Step 180 Global step 180 Train loss 0.79 on epoch=3
05/23/2022 03:24:49 - INFO - __main__ - Step 190 Global step 190 Train loss 0.83 on epoch=3
05/23/2022 03:24:51 - INFO - __main__ - Step 200 Global step 200 Train loss 0.70 on epoch=3
05/23/2022 03:25:20 - INFO - __main__ - Global step 200 Train loss 0.81 Classification-F1 0.4407274237651668 on epoch=3
05/23/2022 03:25:20 - INFO - __main__ - Saving model with best Classification-F1: 0.34091281239663074 -> 0.4407274237651668 on epoch=3, global_step=200
05/23/2022 03:25:23 - INFO - __main__ - Step 210 Global step 210 Train loss 0.74 on epoch=3
05/23/2022 03:25:25 - INFO - __main__ - Step 220 Global step 220 Train loss 0.74 on epoch=3
05/23/2022 03:25:28 - INFO - __main__ - Step 230 Global step 230 Train loss 0.78 on epoch=4
05/23/2022 03:25:30 - INFO - __main__ - Step 240 Global step 240 Train loss 0.66 on epoch=4
05/23/2022 03:25:33 - INFO - __main__ - Step 250 Global step 250 Train loss 0.77 on epoch=4
05/23/2022 03:26:02 - INFO - __main__ - Global step 250 Train loss 0.74 Classification-F1 0.5419044356221696 on epoch=4
05/23/2022 03:26:02 - INFO - __main__ - Saving model with best Classification-F1: 0.4407274237651668 -> 0.5419044356221696 on epoch=4, global_step=250
05/23/2022 03:26:05 - INFO - __main__ - Step 260 Global step 260 Train loss 0.67 on epoch=4
05/23/2022 03:26:07 - INFO - __main__ - Step 270 Global step 270 Train loss 0.65 on epoch=4
05/23/2022 03:26:10 - INFO - __main__ - Step 280 Global step 280 Train loss 0.68 on epoch=4
05/23/2022 03:26:12 - INFO - __main__ - Step 290 Global step 290 Train loss 0.68 on epoch=5
05/23/2022 03:26:15 - INFO - __main__ - Step 300 Global step 300 Train loss 0.63 on epoch=5
05/23/2022 03:26:44 - INFO - __main__ - Global step 300 Train loss 0.66 Classification-F1 0.48384781669076815 on epoch=5
05/23/2022 03:26:46 - INFO - __main__ - Step 310 Global step 310 Train loss 0.65 on epoch=5
05/23/2022 03:26:49 - INFO - __main__ - Step 320 Global step 320 Train loss 0.58 on epoch=5
05/23/2022 03:26:51 - INFO - __main__ - Step 330 Global step 330 Train loss 0.49 on epoch=5
05/23/2022 03:26:54 - INFO - __main__ - Step 340 Global step 340 Train loss 0.54 on epoch=6
05/23/2022 03:26:57 - INFO - __main__ - Step 350 Global step 350 Train loss 0.47 on epoch=6
05/23/2022 03:27:21 - INFO - __main__ - Global step 350 Train loss 0.55 Classification-F1 0.5039934268893421 on epoch=6
05/23/2022 03:27:24 - INFO - __main__ - Step 360 Global step 360 Train loss 0.59 on epoch=6
05/23/2022 03:27:26 - INFO - __main__ - Step 370 Global step 370 Train loss 0.56 on epoch=6
05/23/2022 03:27:29 - INFO - __main__ - Step 380 Global step 380 Train loss 0.45 on epoch=6
05/23/2022 03:27:32 - INFO - __main__ - Step 390 Global step 390 Train loss 0.53 on epoch=6
05/23/2022 03:27:34 - INFO - __main__ - Step 400 Global step 400 Train loss 0.50 on epoch=7
05/23/2022 03:28:00 - INFO - __main__ - Global step 400 Train loss 0.52 Classification-F1 0.45509812381506504 on epoch=7
05/23/2022 03:28:02 - INFO - __main__ - Step 410 Global step 410 Train loss 0.49 on epoch=7
05/23/2022 03:28:05 - INFO - __main__ - Step 420 Global step 420 Train loss 0.52 on epoch=7
05/23/2022 03:28:08 - INFO - __main__ - Step 430 Global step 430 Train loss 0.49 on epoch=7
05/23/2022 03:28:10 - INFO - __main__ - Step 440 Global step 440 Train loss 0.52 on epoch=7
05/23/2022 03:28:13 - INFO - __main__ - Step 450 Global step 450 Train loss 0.36 on epoch=8
05/23/2022 03:28:40 - INFO - __main__ - Global step 450 Train loss 0.48 Classification-F1 0.5683192260919784 on epoch=8
05/23/2022 03:28:40 - INFO - __main__ - Saving model with best Classification-F1: 0.5419044356221696 -> 0.5683192260919784 on epoch=8, global_step=450
05/23/2022 03:28:43 - INFO - __main__ - Step 460 Global step 460 Train loss 0.52 on epoch=8
05/23/2022 03:28:45 - INFO - __main__ - Step 470 Global step 470 Train loss 0.58 on epoch=8
05/23/2022 03:28:48 - INFO - __main__ - Step 480 Global step 480 Train loss 0.41 on epoch=8
05/23/2022 03:28:50 - INFO - __main__ - Step 490 Global step 490 Train loss 0.39 on epoch=8
05/23/2022 03:28:53 - INFO - __main__ - Step 500 Global step 500 Train loss 0.40 on epoch=8
05/23/2022 03:29:23 - INFO - __main__ - Global step 500 Train loss 0.46 Classification-F1 0.5661458708706022 on epoch=8
05/23/2022 03:29:26 - INFO - __main__ - Step 510 Global step 510 Train loss 0.37 on epoch=9
05/23/2022 03:29:29 - INFO - __main__ - Step 520 Global step 520 Train loss 0.40 on epoch=9
05/23/2022 03:29:31 - INFO - __main__ - Step 530 Global step 530 Train loss 0.42 on epoch=9
05/23/2022 03:29:34 - INFO - __main__ - Step 540 Global step 540 Train loss 0.36 on epoch=9
05/23/2022 03:29:36 - INFO - __main__ - Step 550 Global step 550 Train loss 0.37 on epoch=9
05/23/2022 03:30:03 - INFO - __main__ - Global step 550 Train loss 0.38 Classification-F1 0.6141485415212304 on epoch=9
05/23/2022 03:30:03 - INFO - __main__ - Saving model with best Classification-F1: 0.5683192260919784 -> 0.6141485415212304 on epoch=9, global_step=550
05/23/2022 03:30:06 - INFO - __main__ - Step 560 Global step 560 Train loss 0.36 on epoch=9
05/23/2022 03:30:09 - INFO - __main__ - Step 570 Global step 570 Train loss 0.35 on epoch=10
05/23/2022 03:30:11 - INFO - __main__ - Step 580 Global step 580 Train loss 0.37 on epoch=10
05/23/2022 03:30:14 - INFO - __main__ - Step 590 Global step 590 Train loss 0.37 on epoch=10
05/23/2022 03:30:16 - INFO - __main__ - Step 600 Global step 600 Train loss 0.38 on epoch=10
05/23/2022 03:30:43 - INFO - __main__ - Global step 600 Train loss 0.37 Classification-F1 0.5691844814237248 on epoch=10
05/23/2022 03:30:46 - INFO - __main__ - Step 610 Global step 610 Train loss 0.34 on epoch=10
05/23/2022 03:30:48 - INFO - __main__ - Step 620 Global step 620 Train loss 0.29 on epoch=11
05/23/2022 03:30:51 - INFO - __main__ - Step 630 Global step 630 Train loss 0.31 on epoch=11
05/23/2022 03:30:53 - INFO - __main__ - Step 640 Global step 640 Train loss 0.33 on epoch=11
05/23/2022 03:30:56 - INFO - __main__ - Step 650 Global step 650 Train loss 0.29 on epoch=11
05/23/2022 03:31:24 - INFO - __main__ - Global step 650 Train loss 0.31 Classification-F1 0.5621428795191493 on epoch=11
05/23/2022 03:31:27 - INFO - __main__ - Step 660 Global step 660 Train loss 0.30 on epoch=11
05/23/2022 03:31:29 - INFO - __main__ - Step 670 Global step 670 Train loss 0.32 on epoch=11
05/23/2022 03:31:32 - INFO - __main__ - Step 680 Global step 680 Train loss 0.32 on epoch=12
05/23/2022 03:31:34 - INFO - __main__ - Step 690 Global step 690 Train loss 0.43 on epoch=12
05/23/2022 03:31:37 - INFO - __main__ - Step 700 Global step 700 Train loss 0.32 on epoch=12
05/23/2022 03:32:05 - INFO - __main__ - Global step 700 Train loss 0.34 Classification-F1 0.5242404901301598 on epoch=12
05/23/2022 03:32:07 - INFO - __main__ - Step 710 Global step 710 Train loss 0.28 on epoch=12
05/23/2022 03:32:10 - INFO - __main__ - Step 720 Global step 720 Train loss 0.33 on epoch=12
05/23/2022 03:32:13 - INFO - __main__ - Step 730 Global step 730 Train loss 0.28 on epoch=13
05/23/2022 03:32:15 - INFO - __main__ - Step 740 Global step 740 Train loss 0.36 on epoch=13
05/23/2022 03:32:18 - INFO - __main__ - Step 750 Global step 750 Train loss 0.31 on epoch=13
05/23/2022 03:32:42 - INFO - __main__ - Global step 750 Train loss 0.31 Classification-F1 0.6628502587636792 on epoch=13
05/23/2022 03:32:42 - INFO - __main__ - Saving model with best Classification-F1: 0.6141485415212304 -> 0.6628502587636792 on epoch=13, global_step=750
05/23/2022 03:32:44 - INFO - __main__ - Step 760 Global step 760 Train loss 0.25 on epoch=13
05/23/2022 03:32:47 - INFO - __main__ - Step 770 Global step 770 Train loss 0.26 on epoch=13
05/23/2022 03:32:50 - INFO - __main__ - Step 780 Global step 780 Train loss 0.21 on epoch=13
05/23/2022 03:32:52 - INFO - __main__ - Step 790 Global step 790 Train loss 0.27 on epoch=14
05/23/2022 03:32:55 - INFO - __main__ - Step 800 Global step 800 Train loss 0.22 on epoch=14
05/23/2022 03:33:22 - INFO - __main__ - Global step 800 Train loss 0.24 Classification-F1 0.4509496703602279 on epoch=14
05/23/2022 03:33:24 - INFO - __main__ - Step 810 Global step 810 Train loss 0.22 on epoch=14
05/23/2022 03:33:27 - INFO - __main__ - Step 820 Global step 820 Train loss 0.18 on epoch=14
05/23/2022 03:33:29 - INFO - __main__ - Step 830 Global step 830 Train loss 0.23 on epoch=14
05/23/2022 03:33:32 - INFO - __main__ - Step 840 Global step 840 Train loss 0.16 on epoch=14
05/23/2022 03:33:34 - INFO - __main__ - Step 850 Global step 850 Train loss 0.23 on epoch=15
05/23/2022 03:33:59 - INFO - __main__ - Global step 850 Train loss 0.20 Classification-F1 0.5643571026038179 on epoch=15
05/23/2022 03:34:01 - INFO - __main__ - Step 860 Global step 860 Train loss 0.33 on epoch=15
05/23/2022 03:34:04 - INFO - __main__ - Step 870 Global step 870 Train loss 0.23 on epoch=15
05/23/2022 03:34:06 - INFO - __main__ - Step 880 Global step 880 Train loss 0.18 on epoch=15
05/23/2022 03:34:09 - INFO - __main__ - Step 890 Global step 890 Train loss 0.25 on epoch=15
05/23/2022 03:34:12 - INFO - __main__ - Step 900 Global step 900 Train loss 0.17 on epoch=16
05/23/2022 03:34:37 - INFO - __main__ - Global step 900 Train loss 0.23 Classification-F1 0.5226130087234013 on epoch=16
05/23/2022 03:34:39 - INFO - __main__ - Step 910 Global step 910 Train loss 0.20 on epoch=16
05/23/2022 03:34:42 - INFO - __main__ - Step 920 Global step 920 Train loss 0.20 on epoch=16
05/23/2022 03:34:45 - INFO - __main__ - Step 930 Global step 930 Train loss 0.16 on epoch=16
05/23/2022 03:34:47 - INFO - __main__ - Step 940 Global step 940 Train loss 0.16 on epoch=16
05/23/2022 03:34:50 - INFO - __main__ - Step 950 Global step 950 Train loss 0.20 on epoch=16
05/23/2022 03:35:14 - INFO - __main__ - Global step 950 Train loss 0.18 Classification-F1 0.5605609785763526 on epoch=16
05/23/2022 03:35:17 - INFO - __main__ - Step 960 Global step 960 Train loss 0.18 on epoch=17
05/23/2022 03:35:19 - INFO - __main__ - Step 970 Global step 970 Train loss 0.19 on epoch=17
05/23/2022 03:35:22 - INFO - __main__ - Step 980 Global step 980 Train loss 0.18 on epoch=17
05/23/2022 03:35:24 - INFO - __main__ - Step 990 Global step 990 Train loss 0.14 on epoch=17
05/23/2022 03:35:27 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.27 on epoch=17
05/23/2022 03:35:52 - INFO - __main__ - Global step 1000 Train loss 0.19 Classification-F1 0.5338342099727653 on epoch=17
05/23/2022 03:35:54 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.17 on epoch=18
05/23/2022 03:35:57 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.18 on epoch=18
05/23/2022 03:35:59 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.14 on epoch=18
05/23/2022 03:36:02 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.15 on epoch=18
05/23/2022 03:36:05 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.13 on epoch=18
05/23/2022 03:36:30 - INFO - __main__ - Global step 1050 Train loss 0.16 Classification-F1 0.60235747409756 on epoch=18
05/23/2022 03:36:33 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.11 on epoch=18
05/23/2022 03:36:35 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.23 on epoch=19
05/23/2022 03:36:38 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.16 on epoch=19
05/23/2022 03:36:40 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.20 on epoch=19
05/23/2022 03:36:43 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.13 on epoch=19
05/23/2022 03:37:09 - INFO - __main__ - Global step 1100 Train loss 0.17 Classification-F1 0.7916363005886315 on epoch=19
05/23/2022 03:37:09 - INFO - __main__ - Saving model with best Classification-F1: 0.6628502587636792 -> 0.7916363005886315 on epoch=19, global_step=1100
05/23/2022 03:37:12 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.18 on epoch=19
05/23/2022 03:37:14 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.10 on epoch=19
05/23/2022 03:37:17 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.10 on epoch=20
05/23/2022 03:37:20 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.18 on epoch=20
05/23/2022 03:37:22 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.16 on epoch=20
05/23/2022 03:37:49 - INFO - __main__ - Global step 1150 Train loss 0.14 Classification-F1 0.7894755325499739 on epoch=20
05/23/2022 03:37:52 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.10 on epoch=20
05/23/2022 03:37:54 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.15 on epoch=20
05/23/2022 03:37:57 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.15 on epoch=21
05/23/2022 03:38:00 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.12 on epoch=21
05/23/2022 03:38:02 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.16 on epoch=21
05/23/2022 03:38:27 - INFO - __main__ - Global step 1200 Train loss 0.14 Classification-F1 0.7056172023520787 on epoch=21
05/23/2022 03:38:30 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.14 on epoch=21
05/23/2022 03:38:32 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.07 on epoch=21
05/23/2022 03:38:35 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.07 on epoch=21
05/23/2022 03:38:38 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.16 on epoch=22
05/23/2022 03:38:40 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.14 on epoch=22
05/23/2022 03:39:05 - INFO - __main__ - Global step 1250 Train loss 0.12 Classification-F1 0.6895917520163377 on epoch=22
05/23/2022 03:39:08 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.10 on epoch=22
05/23/2022 03:39:10 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.08 on epoch=22
05/23/2022 03:39:13 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.13 on epoch=22
05/23/2022 03:39:16 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.07 on epoch=23
05/23/2022 03:39:18 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.08 on epoch=23
05/23/2022 03:39:42 - INFO - __main__ - Global step 1300 Train loss 0.09 Classification-F1 0.5275675876795455 on epoch=23
05/23/2022 03:39:45 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.12 on epoch=23
05/23/2022 03:39:48 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.07 on epoch=23
05/23/2022 03:39:50 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.11 on epoch=23
05/23/2022 03:39:53 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.14 on epoch=23
05/23/2022 03:39:55 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.09 on epoch=24
05/23/2022 03:40:21 - INFO - __main__ - Global step 1350 Train loss 0.11 Classification-F1 0.5901451622406726 on epoch=24
05/23/2022 03:40:23 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.15 on epoch=24
05/23/2022 03:40:26 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.11 on epoch=24
05/23/2022 03:40:28 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.09 on epoch=24
05/23/2022 03:40:31 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.14 on epoch=24
05/23/2022 03:40:34 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.08 on epoch=24
05/23/2022 03:40:57 - INFO - __main__ - Global step 1400 Train loss 0.12 Classification-F1 0.9052339301412377 on epoch=24
05/23/2022 03:40:57 - INFO - __main__ - Saving model with best Classification-F1: 0.7916363005886315 -> 0.9052339301412377 on epoch=24, global_step=1400
05/23/2022 03:41:00 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.13 on epoch=25
05/23/2022 03:41:03 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.11 on epoch=25
05/23/2022 03:41:05 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.10 on epoch=25
05/23/2022 03:41:08 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.08 on epoch=25
05/23/2022 03:41:11 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.08 on epoch=25
05/23/2022 03:41:34 - INFO - __main__ - Global step 1450 Train loss 0.10 Classification-F1 0.7358167572514925 on epoch=25
05/23/2022 03:41:37 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.12 on epoch=26
05/23/2022 03:41:40 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.08 on epoch=26
05/23/2022 03:41:42 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.08 on epoch=26
05/23/2022 03:41:45 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.10 on epoch=26
05/23/2022 03:41:48 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.12 on epoch=26
05/23/2022 03:42:12 - INFO - __main__ - Global step 1500 Train loss 0.10 Classification-F1 0.7143401214575303 on epoch=26
05/23/2022 03:42:15 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.08 on epoch=26
05/23/2022 03:42:18 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.08 on epoch=27
05/23/2022 03:42:20 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.13 on epoch=27
05/23/2022 03:42:23 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.09 on epoch=27
05/23/2022 03:42:26 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.06 on epoch=27
05/23/2022 03:42:50 - INFO - __main__ - Global step 1550 Train loss 0.09 Classification-F1 0.9173879195520959 on epoch=27
05/23/2022 03:42:50 - INFO - __main__ - Saving model with best Classification-F1: 0.9052339301412377 -> 0.9173879195520959 on epoch=27, global_step=1550
05/23/2022 03:42:53 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.17 on epoch=27
05/23/2022 03:42:56 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.08 on epoch=28
05/23/2022 03:42:58 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.09 on epoch=28
05/23/2022 03:43:01 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.08 on epoch=28
05/23/2022 03:43:04 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.05 on epoch=28
05/23/2022 03:43:35 - INFO - __main__ - Global step 1600 Train loss 0.09 Classification-F1 0.7977264786153031 on epoch=28
05/23/2022 03:43:38 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.08 on epoch=28
05/23/2022 03:43:40 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.06 on epoch=28
05/23/2022 03:43:43 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.09 on epoch=29
05/23/2022 03:43:46 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.09 on epoch=29
05/23/2022 03:43:48 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.06 on epoch=29
05/23/2022 03:44:12 - INFO - __main__ - Global step 1650 Train loss 0.08 Classification-F1 0.7522504220987143 on epoch=29
05/23/2022 03:44:14 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.05 on epoch=29
05/23/2022 03:44:17 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.10 on epoch=29
05/23/2022 03:44:20 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.05 on epoch=29
05/23/2022 03:44:22 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.06 on epoch=30
05/23/2022 03:44:25 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.11 on epoch=30
05/23/2022 03:44:51 - INFO - __main__ - Global step 1700 Train loss 0.07 Classification-F1 0.6389734620069671 on epoch=30
05/23/2022 03:44:54 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.07 on epoch=30
05/23/2022 03:44:56 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.11 on epoch=30
05/23/2022 03:44:59 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.09 on epoch=30
05/23/2022 03:45:02 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.05 on epoch=31
05/23/2022 03:45:04 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.07 on epoch=31
05/23/2022 03:45:29 - INFO - __main__ - Global step 1750 Train loss 0.08 Classification-F1 0.6428977940056149 on epoch=31
05/23/2022 03:45:32 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.08 on epoch=31
05/23/2022 03:45:34 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.05 on epoch=31
05/23/2022 03:45:37 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.07 on epoch=31
05/23/2022 03:45:39 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.05 on epoch=31
05/23/2022 03:45:42 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.11 on epoch=32
05/23/2022 03:46:11 - INFO - __main__ - Global step 1800 Train loss 0.07 Classification-F1 0.7584408983617332 on epoch=32
05/23/2022 03:46:14 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.10 on epoch=32
05/23/2022 03:46:16 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=32
05/23/2022 03:46:19 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.06 on epoch=32
05/23/2022 03:46:21 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.08 on epoch=32
05/23/2022 03:46:24 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=33
05/23/2022 03:46:50 - INFO - __main__ - Global step 1850 Train loss 0.06 Classification-F1 0.8577813696427357 on epoch=33
05/23/2022 03:46:53 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.10 on epoch=33
05/23/2022 03:46:56 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.15 on epoch=33
05/23/2022 03:46:58 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.06 on epoch=33
05/23/2022 03:47:01 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.09 on epoch=33
05/23/2022 03:47:04 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.07 on epoch=33
05/23/2022 03:47:28 - INFO - __main__ - Global step 1900 Train loss 0.10 Classification-F1 0.7080411731107231 on epoch=33
05/23/2022 03:47:30 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.05 on epoch=34
05/23/2022 03:47:33 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.07 on epoch=34
05/23/2022 03:47:35 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.12 on epoch=34
05/23/2022 03:47:38 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=34
05/23/2022 03:47:41 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.06 on epoch=34
05/23/2022 03:48:04 - INFO - __main__ - Global step 1950 Train loss 0.07 Classification-F1 0.7335358484448238 on epoch=34
05/23/2022 03:48:07 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.13 on epoch=34
05/23/2022 03:48:09 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.11 on epoch=35
05/23/2022 03:48:12 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.09 on epoch=35
05/23/2022 03:48:14 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.07 on epoch=35
05/23/2022 03:48:17 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.07 on epoch=35
05/23/2022 03:48:41 - INFO - __main__ - Global step 2000 Train loss 0.09 Classification-F1 0.7962166901069515 on epoch=35
05/23/2022 03:48:44 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.04 on epoch=35
05/23/2022 03:48:47 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.03 on epoch=36
05/23/2022 03:48:49 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.08 on epoch=36
05/23/2022 03:48:52 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.05 on epoch=36
05/23/2022 03:48:54 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.10 on epoch=36
05/23/2022 03:49:25 - INFO - __main__ - Global step 2050 Train loss 0.06 Classification-F1 0.857845309505445 on epoch=36
05/23/2022 03:49:28 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.09 on epoch=36
05/23/2022 03:49:30 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.07 on epoch=36
05/23/2022 03:49:33 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.06 on epoch=37
05/23/2022 03:49:35 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.04 on epoch=37
05/23/2022 03:49:38 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.12 on epoch=37
05/23/2022 03:50:03 - INFO - __main__ - Global step 2100 Train loss 0.08 Classification-F1 0.7620017657097126 on epoch=37
05/23/2022 03:50:05 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.03 on epoch=37
05/23/2022 03:50:08 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.07 on epoch=37
05/23/2022 03:50:11 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.04 on epoch=38
05/23/2022 03:50:13 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.09 on epoch=38
05/23/2022 03:50:16 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.11 on epoch=38
05/23/2022 03:50:41 - INFO - __main__ - Global step 2150 Train loss 0.07 Classification-F1 0.8462854881273019 on epoch=38
05/23/2022 03:50:44 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.03 on epoch=38
05/23/2022 03:50:46 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.06 on epoch=38
05/23/2022 03:50:49 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=38
05/23/2022 03:50:52 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=39
05/23/2022 03:50:54 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.07 on epoch=39
05/23/2022 03:51:25 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.92242289928428 on epoch=39
05/23/2022 03:51:25 - INFO - __main__ - Saving model with best Classification-F1: 0.9173879195520959 -> 0.92242289928428 on epoch=39, global_step=2200
05/23/2022 03:51:28 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=39
05/23/2022 03:51:30 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.06 on epoch=39
05/23/2022 03:51:33 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.08 on epoch=39
05/23/2022 03:51:36 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.05 on epoch=39
05/23/2022 03:51:38 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.04 on epoch=40
05/23/2022 03:52:08 - INFO - __main__ - Global step 2250 Train loss 0.05 Classification-F1 0.6532261986847674 on epoch=40
05/23/2022 03:52:11 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.07 on epoch=40
05/23/2022 03:52:14 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.06 on epoch=40
05/23/2022 03:52:16 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=40
05/23/2022 03:52:19 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=40
05/23/2022 03:52:22 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.04 on epoch=41
05/23/2022 03:53:04 - INFO - __main__ - Global step 2300 Train loss 0.04 Classification-F1 0.7323812629826052 on epoch=41
05/23/2022 03:53:06 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.07 on epoch=41
05/23/2022 03:53:09 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.04 on epoch=41
05/23/2022 03:53:12 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=41
05/23/2022 03:53:14 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.05 on epoch=41
05/23/2022 03:53:17 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.06 on epoch=41
05/23/2022 03:54:14 - INFO - __main__ - Global step 2350 Train loss 0.05 Classification-F1 0.6550335196163188 on epoch=41
05/23/2022 03:54:17 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.07 on epoch=42
05/23/2022 03:54:19 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.12 on epoch=42
05/23/2022 03:54:22 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.10 on epoch=42
05/23/2022 03:54:25 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=42
05/23/2022 03:54:27 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.04 on epoch=42
05/23/2022 03:55:25 - INFO - __main__ - Global step 2400 Train loss 0.07 Classification-F1 0.7564314367221329 on epoch=42
05/23/2022 03:55:28 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.03 on epoch=43
05/23/2022 03:55:31 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.13 on epoch=43
05/23/2022 03:55:33 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.08 on epoch=43
05/23/2022 03:55:36 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.03 on epoch=43
05/23/2022 03:55:38 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.05 on epoch=43
05/23/2022 03:56:22 - INFO - __main__ - Global step 2450 Train loss 0.06 Classification-F1 0.8588084932330748 on epoch=43
05/23/2022 03:56:25 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=43
05/23/2022 03:56:27 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.06 on epoch=44
05/23/2022 03:56:30 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.07 on epoch=44
05/23/2022 03:56:33 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=44
05/23/2022 03:56:35 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=44
05/23/2022 03:57:07 - INFO - __main__ - Global step 2500 Train loss 0.04 Classification-F1 0.6574415788433733 on epoch=44
05/23/2022 03:57:09 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.11 on epoch=44
05/23/2022 03:57:12 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.07 on epoch=44
05/23/2022 03:57:15 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.04 on epoch=45
05/23/2022 03:57:17 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.03 on epoch=45
05/23/2022 03:57:20 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.05 on epoch=45
05/23/2022 03:57:51 - INFO - __main__ - Global step 2550 Train loss 0.06 Classification-F1 0.7544194620674473 on epoch=45
05/23/2022 03:57:54 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.03 on epoch=45
05/23/2022 03:57:57 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=45
05/23/2022 03:57:59 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.06 on epoch=46
05/23/2022 03:58:02 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.07 on epoch=46
05/23/2022 03:58:04 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.10 on epoch=46
05/23/2022 03:58:29 - INFO - __main__ - Global step 2600 Train loss 0.06 Classification-F1 0.7154812806813009 on epoch=46
05/23/2022 03:58:31 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=46
05/23/2022 03:58:34 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.10 on epoch=46
05/23/2022 03:58:36 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=46
05/23/2022 03:58:39 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.08 on epoch=47
05/23/2022 03:58:42 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.05 on epoch=47
05/23/2022 03:59:10 - INFO - __main__ - Global step 2650 Train loss 0.05 Classification-F1 0.7933067398380285 on epoch=47
05/23/2022 03:59:13 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=47
05/23/2022 03:59:16 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=47
05/23/2022 03:59:18 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.05 on epoch=47
05/23/2022 03:59:21 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.05 on epoch=48
05/23/2022 03:59:23 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.03 on epoch=48
05/23/2022 03:59:54 - INFO - __main__ - Global step 2700 Train loss 0.04 Classification-F1 0.7611833827752902 on epoch=48
05/23/2022 03:59:57 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.08 on epoch=48
05/23/2022 03:59:59 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=48
05/23/2022 04:00:02 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.04 on epoch=48
05/23/2022 04:00:04 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.05 on epoch=48
05/23/2022 04:00:07 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.06 on epoch=49
05/23/2022 04:00:32 - INFO - __main__ - Global step 2750 Train loss 0.05 Classification-F1 0.6150550078090227 on epoch=49
05/23/2022 04:00:35 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.06 on epoch=49
05/23/2022 04:00:37 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.06 on epoch=49
05/23/2022 04:00:40 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=49
05/23/2022 04:00:43 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.09 on epoch=49
05/23/2022 04:00:45 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.04 on epoch=49
05/23/2022 04:01:12 - INFO - __main__ - Global step 2800 Train loss 0.05 Classification-F1 0.7622095543895995 on epoch=49
05/23/2022 04:01:14 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.06 on epoch=50
05/23/2022 04:01:17 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.05 on epoch=50
05/23/2022 04:01:19 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=50
05/23/2022 04:01:22 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=50
05/23/2022 04:01:25 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.05 on epoch=50
05/23/2022 04:01:48 - INFO - __main__ - Global step 2850 Train loss 0.04 Classification-F1 0.9187329629134015 on epoch=50
05/23/2022 04:01:50 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.04 on epoch=51
05/23/2022 04:01:53 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.06 on epoch=51
05/23/2022 04:01:56 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.04 on epoch=51
05/23/2022 04:01:58 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.05 on epoch=51
05/23/2022 04:02:01 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.06 on epoch=51
05/23/2022 04:02:23 - INFO - __main__ - Global step 2900 Train loss 0.05 Classification-F1 0.7810345411054157 on epoch=51
05/23/2022 04:02:26 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=51
05/23/2022 04:02:29 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.06 on epoch=52
05/23/2022 04:02:31 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.08 on epoch=52
05/23/2022 04:02:34 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.07 on epoch=52
05/23/2022 04:02:37 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=52
05/23/2022 04:03:01 - INFO - __main__ - Global step 2950 Train loss 0.05 Classification-F1 0.6735185721917266 on epoch=52
05/23/2022 04:03:04 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.05 on epoch=52
05/23/2022 04:03:06 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=53
05/23/2022 04:03:09 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.04 on epoch=53
05/23/2022 04:03:12 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.06 on epoch=53
05/23/2022 04:03:15 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.04 on epoch=53
05/23/2022 04:03:16 - INFO - __main__ - Start tokenizing ... 896 instances
05/23/2022 04:03:16 - INFO - __main__ - Printing 3 examples
05/23/2022 04:03:16 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
05/23/2022 04:03:16 - INFO - __main__ - ['Film']
05/23/2022 04:03:16 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/23/2022 04:03:16 - INFO - __main__ - ['Film']
05/23/2022 04:03:16 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/23/2022 04:03:16 - INFO - __main__ - ['Film']
05/23/2022 04:03:16 - INFO - __main__ - Tokenizing Input ...
05/23/2022 04:03:16 - INFO - __main__ - Tokenizing Output ...
05/23/2022 04:03:17 - INFO - __main__ - Loaded 896 examples from train data
05/23/2022 04:03:17 - INFO - __main__ - Start tokenizing ... 896 instances
05/23/2022 04:03:17 - INFO - __main__ - Printing 3 examples
05/23/2022 04:03:17 - INFO - __main__ -  [dbpedia_14] The Minority is a 2007 American film written and directed by Dwayne Buckle and starring Billoah Greene as Jake Jackson. The Minority was Dwayne Buckle's first feature length film which was shot in New York City. The movie had its theatrical motion picture release in 2007 and debuted at the 15th Annual Pan African Film Festival in Los Angeles where it won an Honorable Mention Award. The film had its DVD release in 2009.
05/23/2022 04:03:17 - INFO - __main__ - ['Film']
05/23/2022 04:03:17 - INFO - __main__ -  [dbpedia_14] A Sign Days (A) is a 1989 Japanese film directed by Yichi Sai.
05/23/2022 04:03:17 - INFO - __main__ - ['Film']
05/23/2022 04:03:17 - INFO - __main__ -  [dbpedia_14] That Championship Season is a 1999 television film about a four members of a championship high school basketball team along with their coach that reunite 20 years later. The film is based on Jason Miller's Pulitzer Prize winning play of the same name. Sorvino assumes the role played by Robert Mitchum in the original film with D'Onofrio in his role from that presentation.
05/23/2022 04:03:17 - INFO - __main__ - ['Film']
05/23/2022 04:03:17 - INFO - __main__ - Tokenizing Input ...
05/23/2022 04:03:18 - INFO - __main__ - Tokenizing Output ...
05/23/2022 04:03:18 - INFO - __main__ - Loaded 896 examples from dev data
05/23/2022 04:03:34 - INFO - __main__ - try to initialize prompt embeddings
05/23/2022 04:03:34 - INFO - __main__ - task name: dbpedia_14
05/23/2022 04:03:34 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/23/2022 04:03:35 - INFO - __main__ - Starting training!
05/23/2022 04:03:38 - INFO - __main__ - Global step 3000 Train loss 0.04 Classification-F1 0.6816361229402234 on epoch=53
05/23/2022 04:03:38 - INFO - __main__ - save last model!
05/23/2022 04:03:38 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/23/2022 04:03:38 - INFO - __main__ - Start tokenizing ... 3500 instances
05/23/2022 04:03:38 - INFO - __main__ - Printing 3 examples
05/23/2022 04:03:38 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/23/2022 04:03:38 - INFO - __main__ - ['Animal']
05/23/2022 04:03:38 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/23/2022 04:03:38 - INFO - __main__ - ['Animal']
05/23/2022 04:03:38 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/23/2022 04:03:38 - INFO - __main__ - ['Village']
05/23/2022 04:03:38 - INFO - __main__ - Tokenizing Input ...
05/23/2022 04:03:40 - INFO - __main__ - Tokenizing Output ...
05/23/2022 04:03:43 - INFO - __main__ - Loaded 3500 examples from test data
05/23/2022 04:05:46 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down64shot/singletask-dbpedia_14/dbpedia_14_64_87_0.3_8_predictions.txt
05/23/2022 04:05:46 - INFO - __main__ - Classification-F1 on test data: 0.5692
05/23/2022 04:05:47 - INFO - __main__ - prefix=dbpedia_14_64_87, lr=0.3, bsz=8, dev_performance=0.92242289928428, test_performance=0.5691733905882771
05/23/2022 04:05:47 - INFO - __main__ - Running ... prefix=dbpedia_14_64_87, lr=0.2, bsz=8 ...
05/23/2022 04:05:48 - INFO - __main__ - Start tokenizing ... 896 instances
05/23/2022 04:05:48 - INFO - __main__ - Printing 3 examples
05/23/2022 04:05:48 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
05/23/2022 04:05:48 - INFO - __main__ - ['Film']
05/23/2022 04:05:48 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/23/2022 04:05:48 - INFO - __main__ - ['Film']
05/23/2022 04:05:48 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/23/2022 04:05:48 - INFO - __main__ - ['Film']
05/23/2022 04:05:48 - INFO - __main__ - Tokenizing Input ...
05/23/2022 04:05:48 - INFO - __main__ - Tokenizing Output ...
05/23/2022 04:05:49 - INFO - __main__ - Loaded 896 examples from train data
05/23/2022 04:05:49 - INFO - __main__ - Start tokenizing ... 896 instances
05/23/2022 04:05:49 - INFO - __main__ - Printing 3 examples
05/23/2022 04:05:49 - INFO - __main__ -  [dbpedia_14] The Minority is a 2007 American film written and directed by Dwayne Buckle and starring Billoah Greene as Jake Jackson. The Minority was Dwayne Buckle's first feature length film which was shot in New York City. The movie had its theatrical motion picture release in 2007 and debuted at the 15th Annual Pan African Film Festival in Los Angeles where it won an Honorable Mention Award. The film had its DVD release in 2009.
05/23/2022 04:05:49 - INFO - __main__ - ['Film']
05/23/2022 04:05:49 - INFO - __main__ -  [dbpedia_14] A Sign Days (A) is a 1989 Japanese film directed by Yichi Sai.
05/23/2022 04:05:49 - INFO - __main__ - ['Film']
05/23/2022 04:05:49 - INFO - __main__ -  [dbpedia_14] That Championship Season is a 1999 television film about a four members of a championship high school basketball team along with their coach that reunite 20 years later. The film is based on Jason Miller's Pulitzer Prize winning play of the same name. Sorvino assumes the role played by Robert Mitchum in the original film with D'Onofrio in his role from that presentation.
05/23/2022 04:05:49 - INFO - __main__ - ['Film']
05/23/2022 04:05:49 - INFO - __main__ - Tokenizing Input ...
05/23/2022 04:05:50 - INFO - __main__ - Tokenizing Output ...
05/23/2022 04:05:51 - INFO - __main__ - Loaded 896 examples from dev data
05/23/2022 04:06:06 - INFO - __main__ - try to initialize prompt embeddings
05/23/2022 04:06:06 - INFO - __main__ - task name: dbpedia_14
05/23/2022 04:06:07 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/23/2022 04:06:07 - INFO - __main__ - Starting training!
05/23/2022 04:06:10 - INFO - __main__ - Step 10 Global step 10 Train loss 7.14 on epoch=0
05/23/2022 04:06:13 - INFO - __main__ - Step 20 Global step 20 Train loss 6.57 on epoch=0
05/23/2022 04:06:15 - INFO - __main__ - Step 30 Global step 30 Train loss 5.82 on epoch=0
05/23/2022 04:06:18 - INFO - __main__ - Step 40 Global step 40 Train loss 4.51 on epoch=0
05/23/2022 04:06:21 - INFO - __main__ - Step 50 Global step 50 Train loss 4.11 on epoch=0
05/23/2022 04:10:34 - INFO - __main__ - Global step 50 Train loss 5.63 Classification-F1 0.0013716621928002875 on epoch=0
05/23/2022 04:10:34 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0013716621928002875 on epoch=0, global_step=50
05/23/2022 04:10:36 - INFO - __main__ - Step 60 Global step 60 Train loss 3.34 on epoch=1
05/23/2022 04:10:39 - INFO - __main__ - Step 70 Global step 70 Train loss 3.10 on epoch=1
05/23/2022 04:10:41 - INFO - __main__ - Step 80 Global step 80 Train loss 2.61 on epoch=1
05/23/2022 04:10:44 - INFO - __main__ - Step 90 Global step 90 Train loss 2.25 on epoch=1
05/23/2022 04:10:47 - INFO - __main__ - Step 100 Global step 100 Train loss 1.83 on epoch=1
05/23/2022 04:11:21 - INFO - __main__ - Global step 100 Train loss 2.63 Classification-F1 0.1804894332289731 on epoch=1
05/23/2022 04:11:21 - INFO - __main__ - Saving model with best Classification-F1: 0.0013716621928002875 -> 0.1804894332289731 on epoch=1, global_step=100
05/23/2022 04:11:24 - INFO - __main__ - Step 110 Global step 110 Train loss 1.66 on epoch=1
05/23/2022 04:11:26 - INFO - __main__ - Step 120 Global step 120 Train loss 1.42 on epoch=2
05/23/2022 04:11:29 - INFO - __main__ - Step 130 Global step 130 Train loss 1.45 on epoch=2
05/23/2022 04:11:32 - INFO - __main__ - Step 140 Global step 140 Train loss 1.28 on epoch=2
05/23/2022 04:11:34 - INFO - __main__ - Step 150 Global step 150 Train loss 1.24 on epoch=2
05/23/2022 04:12:06 - INFO - __main__ - Global step 150 Train loss 1.41 Classification-F1 0.2700395499680775 on epoch=2
05/23/2022 04:12:06 - INFO - __main__ - Saving model with best Classification-F1: 0.1804894332289731 -> 0.2700395499680775 on epoch=2, global_step=150
05/23/2022 04:12:09 - INFO - __main__ - Step 160 Global step 160 Train loss 1.02 on epoch=2
05/23/2022 04:12:11 - INFO - __main__ - Step 170 Global step 170 Train loss 1.08 on epoch=3
05/23/2022 04:12:14 - INFO - __main__ - Step 180 Global step 180 Train loss 1.06 on epoch=3
05/23/2022 04:12:16 - INFO - __main__ - Step 190 Global step 190 Train loss 1.08 on epoch=3
05/23/2022 04:12:19 - INFO - __main__ - Step 200 Global step 200 Train loss 0.94 on epoch=3
05/23/2022 04:12:51 - INFO - __main__ - Global step 200 Train loss 1.03 Classification-F1 0.3856443022994335 on epoch=3
05/23/2022 04:12:51 - INFO - __main__ - Saving model with best Classification-F1: 0.2700395499680775 -> 0.3856443022994335 on epoch=3, global_step=200
05/23/2022 04:12:54 - INFO - __main__ - Step 210 Global step 210 Train loss 0.94 on epoch=3
05/23/2022 04:12:56 - INFO - __main__ - Step 220 Global step 220 Train loss 0.86 on epoch=3
05/23/2022 04:12:59 - INFO - __main__ - Step 230 Global step 230 Train loss 0.97 on epoch=4
05/23/2022 04:13:01 - INFO - __main__ - Step 240 Global step 240 Train loss 0.79 on epoch=4
05/23/2022 04:13:04 - INFO - __main__ - Step 250 Global step 250 Train loss 0.81 on epoch=4
05/23/2022 04:13:37 - INFO - __main__ - Global step 250 Train loss 0.87 Classification-F1 0.3864315410182086 on epoch=4
05/23/2022 04:13:37 - INFO - __main__ - Saving model with best Classification-F1: 0.3856443022994335 -> 0.3864315410182086 on epoch=4, global_step=250
05/23/2022 04:13:40 - INFO - __main__ - Step 260 Global step 260 Train loss 0.79 on epoch=4
05/23/2022 04:13:43 - INFO - __main__ - Step 270 Global step 270 Train loss 0.79 on epoch=4
05/23/2022 04:13:45 - INFO - __main__ - Step 280 Global step 280 Train loss 0.74 on epoch=4
05/23/2022 04:13:48 - INFO - __main__ - Step 290 Global step 290 Train loss 0.72 on epoch=5
05/23/2022 04:13:50 - INFO - __main__ - Step 300 Global step 300 Train loss 0.93 on epoch=5
05/23/2022 04:14:23 - INFO - __main__ - Global step 300 Train loss 0.79 Classification-F1 0.4716834567942759 on epoch=5
05/23/2022 04:14:23 - INFO - __main__ - Saving model with best Classification-F1: 0.3864315410182086 -> 0.4716834567942759 on epoch=5, global_step=300
05/23/2022 04:14:25 - INFO - __main__ - Step 310 Global step 310 Train loss 0.70 on epoch=5
05/23/2022 04:14:28 - INFO - __main__ - Step 320 Global step 320 Train loss 0.65 on epoch=5
05/23/2022 04:14:30 - INFO - __main__ - Step 330 Global step 330 Train loss 0.63 on epoch=5
05/23/2022 04:14:33 - INFO - __main__ - Step 340 Global step 340 Train loss 0.67 on epoch=6
05/23/2022 04:14:35 - INFO - __main__ - Step 350 Global step 350 Train loss 0.78 on epoch=6
05/23/2022 04:15:05 - INFO - __main__ - Global step 350 Train loss 0.68 Classification-F1 0.5499574134947185 on epoch=6
05/23/2022 04:15:05 - INFO - __main__ - Saving model with best Classification-F1: 0.4716834567942759 -> 0.5499574134947185 on epoch=6, global_step=350
05/23/2022 04:15:08 - INFO - __main__ - Step 360 Global step 360 Train loss 0.73 on epoch=6
05/23/2022 04:15:10 - INFO - __main__ - Step 370 Global step 370 Train loss 0.58 on epoch=6
05/23/2022 04:15:13 - INFO - __main__ - Step 380 Global step 380 Train loss 0.64 on epoch=6
05/23/2022 04:15:16 - INFO - __main__ - Step 390 Global step 390 Train loss 0.62 on epoch=6
05/23/2022 04:15:18 - INFO - __main__ - Step 400 Global step 400 Train loss 0.59 on epoch=7
05/23/2022 04:15:47 - INFO - __main__ - Global step 400 Train loss 0.63 Classification-F1 0.4473004456799954 on epoch=7
05/23/2022 04:15:50 - INFO - __main__ - Step 410 Global step 410 Train loss 0.64 on epoch=7
05/23/2022 04:15:52 - INFO - __main__ - Step 420 Global step 420 Train loss 0.61 on epoch=7
05/23/2022 04:15:55 - INFO - __main__ - Step 430 Global step 430 Train loss 0.50 on epoch=7
05/23/2022 04:15:58 - INFO - __main__ - Step 440 Global step 440 Train loss 0.57 on epoch=7
05/23/2022 04:16:00 - INFO - __main__ - Step 450 Global step 450 Train loss 0.56 on epoch=8
05/23/2022 04:16:30 - INFO - __main__ - Global step 450 Train loss 0.58 Classification-F1 0.6256201186113827 on epoch=8
05/23/2022 04:16:30 - INFO - __main__ - Saving model with best Classification-F1: 0.5499574134947185 -> 0.6256201186113827 on epoch=8, global_step=450
05/23/2022 04:16:33 - INFO - __main__ - Step 460 Global step 460 Train loss 0.59 on epoch=8
05/23/2022 04:16:35 - INFO - __main__ - Step 470 Global step 470 Train loss 0.64 on epoch=8
05/23/2022 04:16:38 - INFO - __main__ - Step 480 Global step 480 Train loss 0.60 on epoch=8
05/23/2022 04:16:40 - INFO - __main__ - Step 490 Global step 490 Train loss 0.56 on epoch=8
05/23/2022 04:16:43 - INFO - __main__ - Step 500 Global step 500 Train loss 0.53 on epoch=8
05/23/2022 04:17:14 - INFO - __main__ - Global step 500 Train loss 0.59 Classification-F1 0.5356940490224025 on epoch=8
05/23/2022 04:17:16 - INFO - __main__ - Step 510 Global step 510 Train loss 0.54 on epoch=9
05/23/2022 04:17:19 - INFO - __main__ - Step 520 Global step 520 Train loss 0.58 on epoch=9
05/23/2022 04:17:21 - INFO - __main__ - Step 530 Global step 530 Train loss 0.53 on epoch=9
05/23/2022 04:17:24 - INFO - __main__ - Step 540 Global step 540 Train loss 0.53 on epoch=9
05/23/2022 04:17:27 - INFO - __main__ - Step 550 Global step 550 Train loss 0.44 on epoch=9
05/23/2022 04:17:55 - INFO - __main__ - Global step 550 Train loss 0.52 Classification-F1 0.6557838717620741 on epoch=9
05/23/2022 04:17:55 - INFO - __main__ - Saving model with best Classification-F1: 0.6256201186113827 -> 0.6557838717620741 on epoch=9, global_step=550
05/23/2022 04:17:58 - INFO - __main__ - Step 560 Global step 560 Train loss 0.45 on epoch=9
05/23/2022 04:18:01 - INFO - __main__ - Step 570 Global step 570 Train loss 0.46 on epoch=10
05/23/2022 04:18:03 - INFO - __main__ - Step 580 Global step 580 Train loss 0.55 on epoch=10
05/23/2022 04:18:06 - INFO - __main__ - Step 590 Global step 590 Train loss 0.49 on epoch=10
05/23/2022 04:18:08 - INFO - __main__ - Step 600 Global step 600 Train loss 0.45 on epoch=10
05/23/2022 04:18:39 - INFO - __main__ - Global step 600 Train loss 0.48 Classification-F1 0.7210121994145239 on epoch=10
05/23/2022 04:18:39 - INFO - __main__ - Saving model with best Classification-F1: 0.6557838717620741 -> 0.7210121994145239 on epoch=10, global_step=600
05/23/2022 04:18:42 - INFO - __main__ - Step 610 Global step 610 Train loss 0.34 on epoch=10
05/23/2022 04:18:45 - INFO - __main__ - Step 620 Global step 620 Train loss 0.53 on epoch=11
05/23/2022 04:18:47 - INFO - __main__ - Step 630 Global step 630 Train loss 0.45 on epoch=11
05/23/2022 04:18:50 - INFO - __main__ - Step 640 Global step 640 Train loss 0.48 on epoch=11
05/23/2022 04:18:52 - INFO - __main__ - Step 650 Global step 650 Train loss 0.44 on epoch=11
05/23/2022 04:19:20 - INFO - __main__ - Global step 650 Train loss 0.45 Classification-F1 0.7600453296631321 on epoch=11
05/23/2022 04:19:20 - INFO - __main__ - Saving model with best Classification-F1: 0.7210121994145239 -> 0.7600453296631321 on epoch=11, global_step=650
05/23/2022 04:19:23 - INFO - __main__ - Step 660 Global step 660 Train loss 0.43 on epoch=11
05/23/2022 04:19:25 - INFO - __main__ - Step 670 Global step 670 Train loss 0.33 on epoch=11
05/23/2022 04:19:28 - INFO - __main__ - Step 680 Global step 680 Train loss 0.36 on epoch=12
05/23/2022 04:19:30 - INFO - __main__ - Step 690 Global step 690 Train loss 0.41 on epoch=12
05/23/2022 04:19:33 - INFO - __main__ - Step 700 Global step 700 Train loss 0.38 on epoch=12
05/23/2022 04:20:02 - INFO - __main__ - Global step 700 Train loss 0.38 Classification-F1 0.7341892297105994 on epoch=12
05/23/2022 04:20:05 - INFO - __main__ - Step 710 Global step 710 Train loss 0.33 on epoch=12
05/23/2022 04:20:07 - INFO - __main__ - Step 720 Global step 720 Train loss 0.34 on epoch=12
05/23/2022 04:20:10 - INFO - __main__ - Step 730 Global step 730 Train loss 0.37 on epoch=13
05/23/2022 04:20:13 - INFO - __main__ - Step 740 Global step 740 Train loss 0.32 on epoch=13
05/23/2022 04:20:15 - INFO - __main__ - Step 750 Global step 750 Train loss 0.37 on epoch=13
05/23/2022 04:20:42 - INFO - __main__ - Global step 750 Train loss 0.35 Classification-F1 0.4896726502792936 on epoch=13
05/23/2022 04:20:45 - INFO - __main__ - Step 760 Global step 760 Train loss 0.33 on epoch=13
05/23/2022 04:20:47 - INFO - __main__ - Step 770 Global step 770 Train loss 0.31 on epoch=13
05/23/2022 04:20:50 - INFO - __main__ - Step 780 Global step 780 Train loss 0.32 on epoch=13
05/23/2022 04:20:52 - INFO - __main__ - Step 790 Global step 790 Train loss 0.33 on epoch=14
05/23/2022 04:20:55 - INFO - __main__ - Step 800 Global step 800 Train loss 0.37 on epoch=14
05/23/2022 04:21:23 - INFO - __main__ - Global step 800 Train loss 0.33 Classification-F1 0.7030308097975243 on epoch=14
05/23/2022 04:21:25 - INFO - __main__ - Step 810 Global step 810 Train loss 0.31 on epoch=14
05/23/2022 04:21:28 - INFO - __main__ - Step 820 Global step 820 Train loss 0.24 on epoch=14
05/23/2022 04:21:31 - INFO - __main__ - Step 830 Global step 830 Train loss 0.32 on epoch=14
05/23/2022 04:21:33 - INFO - __main__ - Step 840 Global step 840 Train loss 0.22 on epoch=14
05/23/2022 04:21:36 - INFO - __main__ - Step 850 Global step 850 Train loss 0.29 on epoch=15
05/23/2022 04:22:02 - INFO - __main__ - Global step 850 Train loss 0.28 Classification-F1 0.6032074717321947 on epoch=15
05/23/2022 04:22:05 - INFO - __main__ - Step 860 Global step 860 Train loss 0.31 on epoch=15
05/23/2022 04:22:07 - INFO - __main__ - Step 870 Global step 870 Train loss 0.26 on epoch=15
05/23/2022 04:22:10 - INFO - __main__ - Step 880 Global step 880 Train loss 0.31 on epoch=15
05/23/2022 04:22:12 - INFO - __main__ - Step 890 Global step 890 Train loss 0.25 on epoch=15
05/23/2022 04:22:15 - INFO - __main__ - Step 900 Global step 900 Train loss 0.28 on epoch=16
05/23/2022 04:22:42 - INFO - __main__ - Global step 900 Train loss 0.28 Classification-F1 0.6265871434279819 on epoch=16
05/23/2022 04:22:44 - INFO - __main__ - Step 910 Global step 910 Train loss 0.27 on epoch=16
05/23/2022 04:22:47 - INFO - __main__ - Step 920 Global step 920 Train loss 0.25 on epoch=16
05/23/2022 04:22:50 - INFO - __main__ - Step 930 Global step 930 Train loss 0.25 on epoch=16
05/23/2022 04:22:52 - INFO - __main__ - Step 940 Global step 940 Train loss 0.19 on epoch=16
05/23/2022 04:22:55 - INFO - __main__ - Step 950 Global step 950 Train loss 0.27 on epoch=16
05/23/2022 04:23:22 - INFO - __main__ - Global step 950 Train loss 0.24 Classification-F1 0.6439735655595141 on epoch=16
05/23/2022 04:23:25 - INFO - __main__ - Step 960 Global step 960 Train loss 0.29 on epoch=17
05/23/2022 04:23:27 - INFO - __main__ - Step 970 Global step 970 Train loss 0.21 on epoch=17
05/23/2022 04:23:30 - INFO - __main__ - Step 980 Global step 980 Train loss 0.27 on epoch=17
05/23/2022 04:23:33 - INFO - __main__ - Step 990 Global step 990 Train loss 0.22 on epoch=17
05/23/2022 04:23:35 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.30 on epoch=17
05/23/2022 04:24:03 - INFO - __main__ - Global step 1000 Train loss 0.26 Classification-F1 0.6889472977114965 on epoch=17
05/23/2022 04:24:05 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.20 on epoch=18
05/23/2022 04:24:08 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.34 on epoch=18
05/23/2022 04:24:10 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.21 on epoch=18
05/23/2022 04:24:13 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.19 on epoch=18
05/23/2022 04:24:16 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.17 on epoch=18
05/23/2022 04:24:43 - INFO - __main__ - Global step 1050 Train loss 0.22 Classification-F1 0.6798232716788342 on epoch=18
05/23/2022 04:24:45 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.18 on epoch=18
05/23/2022 04:24:48 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.21 on epoch=19
05/23/2022 04:24:50 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.20 on epoch=19
05/23/2022 04:24:53 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.26 on epoch=19
05/23/2022 04:24:56 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.15 on epoch=19
05/23/2022 04:25:24 - INFO - __main__ - Global step 1100 Train loss 0.20 Classification-F1 0.7083731437577641 on epoch=19
05/23/2022 04:25:27 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.21 on epoch=19
05/23/2022 04:25:29 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.14 on epoch=19
05/23/2022 04:25:32 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.19 on epoch=20
05/23/2022 04:25:35 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.21 on epoch=20
05/23/2022 04:25:37 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.25 on epoch=20
05/23/2022 04:26:05 - INFO - __main__ - Global step 1150 Train loss 0.20 Classification-F1 0.677827326478016 on epoch=20
05/23/2022 04:26:07 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.14 on epoch=20
05/23/2022 04:26:10 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.14 on epoch=20
05/23/2022 04:26:13 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.18 on epoch=21
05/23/2022 04:26:15 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.21 on epoch=21
05/23/2022 04:26:18 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.20 on epoch=21
05/23/2022 04:26:45 - INFO - __main__ - Global step 1200 Train loss 0.17 Classification-F1 0.738343116650772 on epoch=21
05/23/2022 04:26:47 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.14 on epoch=21
05/23/2022 04:26:50 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.14 on epoch=21
05/23/2022 04:26:53 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.11 on epoch=21
05/23/2022 04:26:55 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.16 on epoch=22
05/23/2022 04:26:58 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.19 on epoch=22
05/23/2022 04:27:25 - INFO - __main__ - Global step 1250 Train loss 0.15 Classification-F1 0.734285111280308 on epoch=22
05/23/2022 04:27:28 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.10 on epoch=22
05/23/2022 04:27:31 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.12 on epoch=22
05/23/2022 04:27:33 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.14 on epoch=22
05/23/2022 04:27:36 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.15 on epoch=23
05/23/2022 04:27:39 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.14 on epoch=23
05/23/2022 04:28:04 - INFO - __main__ - Global step 1300 Train loss 0.13 Classification-F1 0.642623096390862 on epoch=23
05/23/2022 04:28:06 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.11 on epoch=23
05/23/2022 04:28:09 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.12 on epoch=23
05/23/2022 04:28:12 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.13 on epoch=23
05/23/2022 04:28:14 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.13 on epoch=23
05/23/2022 04:28:17 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.14 on epoch=24
05/23/2022 04:28:44 - INFO - __main__ - Global step 1350 Train loss 0.13 Classification-F1 0.8365460015592399 on epoch=24
05/23/2022 04:28:44 - INFO - __main__ - Saving model with best Classification-F1: 0.7600453296631321 -> 0.8365460015592399 on epoch=24, global_step=1350
05/23/2022 04:28:46 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.11 on epoch=24
05/23/2022 04:28:49 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.08 on epoch=24
05/23/2022 04:28:51 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.06 on epoch=24
05/23/2022 04:28:54 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.09 on epoch=24
05/23/2022 04:28:57 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.07 on epoch=24
05/23/2022 04:29:23 - INFO - __main__ - Global step 1400 Train loss 0.08 Classification-F1 0.8410454440919293 on epoch=24
05/23/2022 04:29:23 - INFO - __main__ - Saving model with best Classification-F1: 0.8365460015592399 -> 0.8410454440919293 on epoch=24, global_step=1400
05/23/2022 04:29:25 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.11 on epoch=25
05/23/2022 04:29:28 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.13 on epoch=25
05/23/2022 04:29:30 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.12 on epoch=25
05/23/2022 04:29:33 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.11 on epoch=25
05/23/2022 04:29:36 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.05 on epoch=25
05/23/2022 04:29:59 - INFO - __main__ - Global step 1450 Train loss 0.10 Classification-F1 0.7368636358314427 on epoch=25
05/23/2022 04:30:02 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.10 on epoch=26
05/23/2022 04:30:05 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.13 on epoch=26
05/23/2022 04:30:07 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.07 on epoch=26
05/23/2022 04:30:10 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.09 on epoch=26
05/23/2022 04:30:12 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.08 on epoch=26
05/23/2022 04:30:37 - INFO - __main__ - Global step 1500 Train loss 0.09 Classification-F1 0.8488479683313754 on epoch=26
05/23/2022 04:30:37 - INFO - __main__ - Saving model with best Classification-F1: 0.8410454440919293 -> 0.8488479683313754 on epoch=26, global_step=1500
05/23/2022 04:30:40 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.09 on epoch=26
05/23/2022 04:30:42 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.12 on epoch=27
05/23/2022 04:30:45 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.12 on epoch=27
05/23/2022 04:30:47 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.07 on epoch=27
05/23/2022 04:30:50 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.10 on epoch=27
05/23/2022 04:31:14 - INFO - __main__ - Global step 1550 Train loss 0.10 Classification-F1 0.8805177467739098 on epoch=27
05/23/2022 04:31:14 - INFO - __main__ - Saving model with best Classification-F1: 0.8488479683313754 -> 0.8805177467739098 on epoch=27, global_step=1550
05/23/2022 04:31:16 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.10 on epoch=27
05/23/2022 04:31:19 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.05 on epoch=28
05/23/2022 04:31:21 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.12 on epoch=28
05/23/2022 04:31:24 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.14 on epoch=28
05/23/2022 04:31:27 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.07 on epoch=28
05/23/2022 04:31:51 - INFO - __main__ - Global step 1600 Train loss 0.10 Classification-F1 0.7996246337427256 on epoch=28
05/23/2022 04:31:53 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.10 on epoch=28
05/23/2022 04:31:56 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.05 on epoch=28
05/23/2022 04:31:58 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.11 on epoch=29
05/23/2022 04:32:01 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.08 on epoch=29
05/23/2022 04:32:03 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.05 on epoch=29
05/23/2022 04:32:27 - INFO - __main__ - Global step 1650 Train loss 0.08 Classification-F1 0.8492600191133604 on epoch=29
05/23/2022 04:32:30 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.06 on epoch=29
05/23/2022 04:32:33 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.16 on epoch=29
05/23/2022 04:32:35 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.13 on epoch=29
05/23/2022 04:32:38 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.16 on epoch=30
05/23/2022 04:32:40 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.12 on epoch=30
05/23/2022 04:33:04 - INFO - __main__ - Global step 1700 Train loss 0.12 Classification-F1 0.7802629421040356 on epoch=30
05/23/2022 04:33:06 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.17 on epoch=30
05/23/2022 04:33:09 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.05 on epoch=30
05/23/2022 04:33:12 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.06 on epoch=30
05/23/2022 04:33:14 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.10 on epoch=31
05/23/2022 04:33:17 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.10 on epoch=31
05/23/2022 04:33:40 - INFO - __main__ - Global step 1750 Train loss 0.10 Classification-F1 0.8401679926978913 on epoch=31
05/23/2022 04:33:43 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.05 on epoch=31
05/23/2022 04:33:45 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.10 on epoch=31
05/23/2022 04:33:48 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.04 on epoch=31
05/23/2022 04:33:51 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.03 on epoch=31
05/23/2022 04:33:53 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.08 on epoch=32
05/23/2022 04:34:17 - INFO - __main__ - Global step 1800 Train loss 0.06 Classification-F1 0.7844517188935095 on epoch=32
05/23/2022 04:34:20 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.10 on epoch=32
05/23/2022 04:34:22 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.06 on epoch=32
05/23/2022 04:34:25 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.10 on epoch=32
05/23/2022 04:34:27 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.05 on epoch=32
05/23/2022 04:34:30 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.09 on epoch=33
05/23/2022 04:34:54 - INFO - __main__ - Global step 1850 Train loss 0.08 Classification-F1 0.7884891785825836 on epoch=33
05/23/2022 04:34:57 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.08 on epoch=33
05/23/2022 04:34:59 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.07 on epoch=33
05/23/2022 04:35:02 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.05 on epoch=33
05/23/2022 04:35:04 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.03 on epoch=33
05/23/2022 04:35:07 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.05 on epoch=33
05/23/2022 04:35:30 - INFO - __main__ - Global step 1900 Train loss 0.06 Classification-F1 0.7117916845469888 on epoch=33
05/23/2022 04:35:33 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.11 on epoch=34
05/23/2022 04:35:35 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.09 on epoch=34
05/23/2022 04:35:38 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.07 on epoch=34
05/23/2022 04:35:41 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.06 on epoch=34
05/23/2022 04:35:43 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.10 on epoch=34
05/23/2022 04:36:08 - INFO - __main__ - Global step 1950 Train loss 0.09 Classification-F1 0.9067874100217346 on epoch=34
05/23/2022 04:36:08 - INFO - __main__ - Saving model with best Classification-F1: 0.8805177467739098 -> 0.9067874100217346 on epoch=34, global_step=1950
05/23/2022 04:36:10 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=34
05/23/2022 04:36:13 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.06 on epoch=35
05/23/2022 04:36:15 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.05 on epoch=35
05/23/2022 04:36:18 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=35
05/23/2022 04:36:21 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.06 on epoch=35
05/23/2022 04:36:45 - INFO - __main__ - Global step 2000 Train loss 0.04 Classification-F1 0.8493242410567068 on epoch=35
05/23/2022 04:36:48 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.10 on epoch=35
05/23/2022 04:36:51 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.04 on epoch=36
05/23/2022 04:36:53 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.10 on epoch=36
05/23/2022 04:36:56 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.05 on epoch=36
05/23/2022 04:36:59 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.04 on epoch=36
05/23/2022 04:37:23 - INFO - __main__ - Global step 2050 Train loss 0.06 Classification-F1 0.9785967192856834 on epoch=36
05/23/2022 04:37:23 - INFO - __main__ - Saving model with best Classification-F1: 0.9067874100217346 -> 0.9785967192856834 on epoch=36, global_step=2050
05/23/2022 04:37:26 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.08 on epoch=36
05/23/2022 04:37:28 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.05 on epoch=36
05/23/2022 04:37:31 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.08 on epoch=37
05/23/2022 04:37:34 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.08 on epoch=37
05/23/2022 04:37:36 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.09 on epoch=37
05/23/2022 04:38:00 - INFO - __main__ - Global step 2100 Train loss 0.07 Classification-F1 0.8511627575066186 on epoch=37
05/23/2022 04:38:03 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=37
05/23/2022 04:38:06 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.05 on epoch=37
05/23/2022 04:38:08 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.04 on epoch=38
05/23/2022 04:38:11 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.07 on epoch=38
05/23/2022 04:38:14 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.10 on epoch=38
05/23/2022 04:38:38 - INFO - __main__ - Global step 2150 Train loss 0.06 Classification-F1 0.8444974193018808 on epoch=38
05/23/2022 04:38:40 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.03 on epoch=38
05/23/2022 04:38:43 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.06 on epoch=38
05/23/2022 04:38:46 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.04 on epoch=38
05/23/2022 04:38:48 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.07 on epoch=39
05/23/2022 04:38:51 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.10 on epoch=39
05/23/2022 04:39:15 - INFO - __main__ - Global step 2200 Train loss 0.06 Classification-F1 0.8563016943094495 on epoch=39
05/23/2022 04:39:17 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=39
05/23/2022 04:39:20 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=39
05/23/2022 04:39:23 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.08 on epoch=39
05/23/2022 04:39:25 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.04 on epoch=39
05/23/2022 04:39:28 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.08 on epoch=40
05/23/2022 04:39:52 - INFO - __main__ - Global step 2250 Train loss 0.05 Classification-F1 0.8562530892624883 on epoch=40
05/23/2022 04:39:54 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.11 on epoch=40
05/23/2022 04:39:57 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.03 on epoch=40
05/23/2022 04:40:00 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.09 on epoch=40
05/23/2022 04:40:03 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.07 on epoch=40
05/23/2022 04:40:05 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.05 on epoch=41
05/23/2022 04:40:29 - INFO - __main__ - Global step 2300 Train loss 0.07 Classification-F1 0.8532778302561688 on epoch=41
05/23/2022 04:40:31 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.06 on epoch=41
05/23/2022 04:40:34 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=41
05/23/2022 04:40:37 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.05 on epoch=41
05/23/2022 04:40:39 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.12 on epoch=41
05/23/2022 04:40:42 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=41
05/23/2022 04:41:06 - INFO - __main__ - Global step 2350 Train loss 0.05 Classification-F1 0.860764215398707 on epoch=41
05/23/2022 04:41:08 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=42
05/23/2022 04:41:11 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.06 on epoch=42
05/23/2022 04:41:14 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.05 on epoch=42
05/23/2022 04:41:16 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.05 on epoch=42
05/23/2022 04:41:19 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.04 on epoch=42
05/23/2022 04:41:42 - INFO - __main__ - Global step 2400 Train loss 0.05 Classification-F1 0.8573490069437573 on epoch=42
05/23/2022 04:41:44 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.03 on epoch=43
05/23/2022 04:41:47 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.08 on epoch=43
05/23/2022 04:41:50 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.04 on epoch=43
05/23/2022 04:41:53 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.03 on epoch=43
05/23/2022 04:41:55 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=43
05/23/2022 04:42:19 - INFO - __main__ - Global step 2450 Train loss 0.04 Classification-F1 0.8583161005979982 on epoch=43
05/23/2022 04:42:21 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=43
05/23/2022 04:42:24 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.05 on epoch=44
05/23/2022 04:42:27 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.05 on epoch=44
05/23/2022 04:42:29 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.03 on epoch=44
05/23/2022 04:42:32 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.03 on epoch=44
05/23/2022 04:42:56 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.917671483820518 on epoch=44
05/23/2022 04:42:58 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.04 on epoch=44
05/23/2022 04:43:01 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=44
05/23/2022 04:43:04 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.03 on epoch=45
05/23/2022 04:43:06 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.08 on epoch=45
05/23/2022 04:43:09 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.07 on epoch=45
05/23/2022 04:43:31 - INFO - __main__ - Global step 2550 Train loss 0.05 Classification-F1 0.915651969616445 on epoch=45
05/23/2022 04:43:34 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=45
05/23/2022 04:43:37 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.04 on epoch=45
05/23/2022 04:43:40 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.05 on epoch=46
05/23/2022 04:43:42 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.07 on epoch=46
05/23/2022 04:43:45 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.04 on epoch=46
05/23/2022 04:44:08 - INFO - __main__ - Global step 2600 Train loss 0.04 Classification-F1 0.9170618575547945 on epoch=46
05/23/2022 04:44:10 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.03 on epoch=46
05/23/2022 04:44:13 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.09 on epoch=46
05/23/2022 04:44:16 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=46
05/23/2022 04:44:19 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.06 on epoch=47
05/23/2022 04:44:21 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.06 on epoch=47
05/23/2022 04:44:43 - INFO - __main__ - Global step 2650 Train loss 0.05 Classification-F1 0.8579232063854157 on epoch=47
05/23/2022 04:44:46 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.06 on epoch=47
05/23/2022 04:44:49 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.05 on epoch=47
05/23/2022 04:44:51 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.06 on epoch=47
05/23/2022 04:44:54 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.06 on epoch=48
05/23/2022 04:44:57 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.04 on epoch=48
05/23/2022 04:45:19 - INFO - __main__ - Global step 2700 Train loss 0.05 Classification-F1 0.8559907271068902 on epoch=48
05/23/2022 04:45:22 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.07 on epoch=48
05/23/2022 04:45:25 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.03 on epoch=48
05/23/2022 04:45:28 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=48
05/23/2022 04:45:30 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=48
05/23/2022 04:45:33 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.03 on epoch=49
05/23/2022 04:45:56 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.8055684514753797 on epoch=49
05/23/2022 04:45:58 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.07 on epoch=49
05/23/2022 04:46:01 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.04 on epoch=49
05/23/2022 04:46:04 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.04 on epoch=49
05/23/2022 04:46:06 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=49
05/23/2022 04:46:09 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=49
05/23/2022 04:46:32 - INFO - __main__ - Global step 2800 Train loss 0.04 Classification-F1 0.8627714596054659 on epoch=49
05/23/2022 04:46:35 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.03 on epoch=50
05/23/2022 04:46:37 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.05 on epoch=50
05/23/2022 04:46:40 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.04 on epoch=50
05/23/2022 04:46:43 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=50
05/23/2022 04:46:46 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.03 on epoch=50
05/23/2022 04:47:08 - INFO - __main__ - Global step 2850 Train loss 0.03 Classification-F1 0.9140847387134768 on epoch=50
05/23/2022 04:47:10 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.04 on epoch=51
05/23/2022 04:47:13 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=51
05/23/2022 04:47:16 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.04 on epoch=51
05/23/2022 04:47:19 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.04 on epoch=51
05/23/2022 04:47:21 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=51
05/23/2022 04:47:44 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.9161547395084246 on epoch=51
05/23/2022 04:47:46 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=51
05/23/2022 04:47:49 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=52
05/23/2022 04:47:52 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.09 on epoch=52
05/23/2022 04:47:54 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=52
05/23/2022 04:47:57 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.03 on epoch=52
05/23/2022 04:48:19 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.9202986736265898 on epoch=52
05/23/2022 04:48:22 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=52
05/23/2022 04:48:25 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.08 on epoch=53
05/23/2022 04:48:27 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=53
05/23/2022 04:48:30 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.04 on epoch=53
05/23/2022 04:48:33 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.03 on epoch=53
05/23/2022 04:48:56 - INFO - __main__ - Global step 3000 Train loss 0.04 Classification-F1 0.8583942633477051 on epoch=53
05/23/2022 04:48:56 - INFO - __main__ - save last model!
05/23/2022 04:48:56 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/23/2022 04:48:56 - INFO - __main__ - Start tokenizing ... 3500 instances
05/23/2022 04:48:56 - INFO - __main__ - Printing 3 examples
05/23/2022 04:48:56 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/23/2022 04:48:56 - INFO - __main__ - ['Animal']
05/23/2022 04:48:56 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/23/2022 04:48:56 - INFO - __main__ - ['Animal']
05/23/2022 04:48:56 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/23/2022 04:48:56 - INFO - __main__ - ['Village']
05/23/2022 04:48:56 - INFO - __main__ - Tokenizing Input ...
05/23/2022 04:48:58 - INFO - __main__ - Tokenizing Output ...
05/23/2022 04:49:01 - INFO - __main__ - Loaded 3500 examples from test data
05/23/2022 04:51:06 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down64shot/singletask-dbpedia_14/dbpedia_14_64_87_0.2_8_predictions.txt
05/23/2022 04:51:06 - INFO - __main__ - Classification-F1 on test data: 0.8059
05/23/2022 04:51:06 - INFO - __main__ - prefix=dbpedia_14_64_87, lr=0.2, bsz=8, dev_performance=0.9785967192856834, test_performance=0.8058757698326384
