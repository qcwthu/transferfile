04/06/2022 14:10:44 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=False, bsz_list=[4], cache_dir='/data/qin/cache/', checkpoint='None', cuda='4', dataset='nlp_forest_single', debug=False, dev_file='data', do_lowercase=False, do_predict=True, do_train=True, eval_period=50, freeze_embeds=False, gradient_accumulation_steps=2, identifier='T5-large-maml-noqa2qa-3e-5-2-5000-5e-1', learning_rate=0.5, learning_rate_list=[0.5], lm_adapted_path='/data/qin/lm_adapted_t5model/torch_ckpt/large/pytorch_model.bin', local_rank=0, log_step=10, max_grad_norm=1.0, max_input_length=512, max_output_length=128, model='google/t5-v1_1-large', num_beams=4, num_train_epochs=1000.0, output_dir='models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-sciq', predict_batch_size=16, predict_checkpoint='best-model.pt', prefix='', prompt_number=100, quiet=False, seed=42, task_dir='data/sciq/', task_name='sciq', test_file='data', total_steps=3000, train_batch_size=4, train_file='data', wait_step=10000000000, warmup_steps=50, weight_decay=1e-05)
04/06/2022 14:10:44 - INFO - __main__ - models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-sciq
04/27/2022 16:11:32 - INFO - __main__ - Namespace(task_dir='data/sciq/', task_name='sciq', identifier='T5-large-maml-noqa2qa-3e-5-2-5000-5e-1', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-sciq', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-maml-noqa2qa-3e-5-2-5000-5e-1/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='0,1')
04/27/2022 16:11:32 - INFO - __main__ - models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-sciq
04/27/2022 16:11:32 - INFO - __main__ - Namespace(task_dir='data/sciq/', task_name='sciq', identifier='T5-large-maml-noqa2qa-3e-5-2-5000-5e-1', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-sciq', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-maml-noqa2qa-3e-5-2-5000-5e-1/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='0,1')
04/27/2022 16:11:32 - INFO - __main__ - models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-sciq
04/27/2022 16:11:34 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
04/27/2022 16:11:34 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
04/27/2022 16:11:34 - INFO - __main__ - args.device: cuda:0
04/27/2022 16:11:34 - INFO - __main__ - args.device: cuda:1
04/27/2022 16:11:34 - INFO - __main__ - Using 2 gpus
04/27/2022 16:11:34 - INFO - __main__ - Using 2 gpus
04/27/2022 16:11:34 - INFO - __main__ - Fine-tuning the following samples: ['sciq_32_100', 'sciq_32_13', 'sciq_32_21', 'sciq_32_42', 'sciq_32_87']
04/27/2022 16:11:34 - INFO - __main__ - Fine-tuning the following samples: ['sciq_32_100', 'sciq_32_13', 'sciq_32_21', 'sciq_32_42', 'sciq_32_87']
04/27/2022 16:11:39 - INFO - __main__ - Running ... prefix=sciq_32_100, lr=0.5, bsz=8 ...
04/27/2022 16:11:39 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 16:11:39 - INFO - __main__ - Printing 3 examples
04/27/2022 16:11:39 - INFO - __main__ -  [sciq] What zone is outside the radiative zone? (A) diffusion zone (B) peripheral zone (C) activation zone (D) convection zone [SEP] The convection zone is where convection takes place. It is located outward from the radiative zone.
04/27/2022 16:11:39 - INFO - __main__ - ['convection zone']
04/27/2022 16:11:39 - INFO - __main__ -  [sciq] What planet has the most volcanoes? (A) uranus (B) Earth (C) Mars (D) venus [SEP] Venus has more volcanoes than any other planet. There are between 100,000 and one million volcanoes on Venus! Most of the volcanoes are now inactive. There are also a large number of craters. This means that Venus doesn’t have tectonic plates. Plate tectonics on Earth erases features over time. Figure below is an image made using radar data. The volcano is Maat Mons. Lava beds are in the foreground. Scientists think the color of sunlight on Venus is reddish-brown.
04/27/2022 16:11:39 - INFO - __main__ - ['venus']
04/27/2022 16:11:39 - INFO - __main__ -  [sciq] Where are the oceans most polluted? (A) along reefs (B) on the ocean floor (C) along coasts (D) in warmer waters [SEP] The oceans are most polluted along coasts. Why do you think that's the case? Of course, it's because most pollution enters the oceans from the land. Runoff and rivers carry the majority of pollution into the ocean. Many cities dump their wastewater , water mixed with waste, directly into coastal waters. In some parts of the world, raw sewage and trash may be thrown into the water ( Figure below ). Coastal water may become so polluted that people get sick if they swim in it or eat seafood from it. The polluted water may also kill fish and other ocean life.
04/27/2022 16:11:39 - INFO - __main__ - ['along coasts']
04/27/2022 16:11:39 - INFO - __main__ - Tokenizing Input ...
04/27/2022 16:11:39 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 16:11:39 - INFO - __main__ - Printing 3 examples
04/27/2022 16:11:39 - INFO - __main__ -  [sciq] What zone is outside the radiative zone? (A) diffusion zone (B) peripheral zone (C) activation zone (D) convection zone [SEP] The convection zone is where convection takes place. It is located outward from the radiative zone.
04/27/2022 16:11:39 - INFO - __main__ - ['convection zone']
04/27/2022 16:11:39 - INFO - __main__ - Tokenizing Output ...
04/27/2022 16:11:39 - INFO - __main__ -  [sciq] What planet has the most volcanoes? (A) uranus (B) Earth (C) Mars (D) venus [SEP] Venus has more volcanoes than any other planet. There are between 100,000 and one million volcanoes on Venus! Most of the volcanoes are now inactive. There are also a large number of craters. This means that Venus doesn’t have tectonic plates. Plate tectonics on Earth erases features over time. Figure below is an image made using radar data. The volcano is Maat Mons. Lava beds are in the foreground. Scientists think the color of sunlight on Venus is reddish-brown.
04/27/2022 16:11:39 - INFO - __main__ - ['venus']
04/27/2022 16:11:39 - INFO - __main__ -  [sciq] Where are the oceans most polluted? (A) along reefs (B) on the ocean floor (C) along coasts (D) in warmer waters [SEP] The oceans are most polluted along coasts. Why do you think that's the case? Of course, it's because most pollution enters the oceans from the land. Runoff and rivers carry the majority of pollution into the ocean. Many cities dump their wastewater , water mixed with waste, directly into coastal waters. In some parts of the world, raw sewage and trash may be thrown into the water ( Figure below ). Coastal water may become so polluted that people get sick if they swim in it or eat seafood from it. The polluted water may also kill fish and other ocean life.
04/27/2022 16:11:40 - INFO - __main__ - ['along coasts']
04/27/2022 16:11:40 - INFO - __main__ - Tokenizing Input ...
04/27/2022 16:11:40 - INFO - __main__ - Tokenizing Output ...
04/27/2022 16:11:40 - INFO - __main__ - Loaded 32 examples from train data
04/27/2022 16:11:40 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 16:11:40 - INFO - __main__ - Printing 3 examples
04/27/2022 16:11:40 - INFO - __main__ -  [sciq] Viruses depend on what type of cells? (A) anchor cells (B) host cells (C) immune system cells (D) blood cells [SEP] Briefly describe how viruses depend on host cells.
04/27/2022 16:11:40 - INFO - __main__ - ['host cells']
04/27/2022 16:11:40 - INFO - __main__ -  [sciq] What is the time interval required for one complete wave to pass a point called? (A) cycle (B) minute (C) half-life (D) period [SEP] The time interval required for one complete wave to pass a point is called the period . During the period of the wave, an entire wavelength from one crest to the next crest passes a position. The number of waves that pass a single position in one second is called the frequency . The period of a wave and its frequency are reciprocals of each other.
04/27/2022 16:11:40 - INFO - __main__ - ['period']
04/27/2022 16:11:40 - INFO - __main__ -  [sciq] What layer of soil, essential for farming, has the highest proportion of organic material? (A) subsoil (B) bedrock (C) topsoil (D) humus [SEP] Topsoil has the highest proportion of organic material. Topsoil is essential for farming.
04/27/2022 16:11:40 - INFO - __main__ - ['topsoil']
04/27/2022 16:11:40 - INFO - __main__ - Tokenizing Input ...
04/27/2022 16:11:40 - INFO - __main__ - Loaded 32 examples from train data
04/27/2022 16:11:40 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 16:11:40 - INFO - __main__ - Tokenizing Output ...
04/27/2022 16:11:40 - INFO - __main__ - Printing 3 examples
04/27/2022 16:11:40 - INFO - __main__ -  [sciq] Viruses depend on what type of cells? (A) anchor cells (B) host cells (C) immune system cells (D) blood cells [SEP] Briefly describe how viruses depend on host cells.
04/27/2022 16:11:40 - INFO - __main__ - ['host cells']
04/27/2022 16:11:40 - INFO - __main__ -  [sciq] What is the time interval required for one complete wave to pass a point called? (A) cycle (B) minute (C) half-life (D) period [SEP] The time interval required for one complete wave to pass a point is called the period . During the period of the wave, an entire wavelength from one crest to the next crest passes a position. The number of waves that pass a single position in one second is called the frequency . The period of a wave and its frequency are reciprocals of each other.
04/27/2022 16:11:40 - INFO - __main__ - ['period']
04/27/2022 16:11:40 - INFO - __main__ -  [sciq] What layer of soil, essential for farming, has the highest proportion of organic material? (A) subsoil (B) bedrock (C) topsoil (D) humus [SEP] Topsoil has the highest proportion of organic material. Topsoil is essential for farming.
04/27/2022 16:11:40 - INFO - __main__ - ['topsoil']
04/27/2022 16:11:40 - INFO - __main__ - Tokenizing Input ...
04/27/2022 16:11:40 - INFO - __main__ - Loaded 32 examples from dev data
04/27/2022 16:11:40 - INFO - __main__ - Tokenizing Output ...
04/27/2022 16:11:40 - INFO - __main__ - Loaded 32 examples from dev data
04/27/2022 16:11:57 - INFO - __main__ - load prompt embedding from ckpt
04/27/2022 16:12:00 - INFO - __main__ - load prompt embedding from ckpt
04/27/2022 16:12:01 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/27/2022 16:12:01 - INFO - __main__ - Starting training!
04/27/2022 16:12:01 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/27/2022 16:12:01 - INFO - __main__ - Starting training!
04/27/2022 16:12:06 - INFO - __main__ - Step 10 Global step 10 Train loss 2.57 on epoch=4
04/27/2022 16:12:10 - INFO - __main__ - Step 20 Global step 20 Train loss 0.86 on epoch=9
04/27/2022 16:12:14 - INFO - __main__ - Step 30 Global step 30 Train loss 0.47 on epoch=14
04/27/2022 16:12:18 - INFO - __main__ - Step 40 Global step 40 Train loss 0.42 on epoch=19
04/27/2022 16:12:22 - INFO - __main__ - Step 50 Global step 50 Train loss 0.42 on epoch=24
04/27/2022 16:12:23 - INFO - __main__ - Global step 50 Train loss 0.95 ACC 0.5 on epoch=24
04/27/2022 16:12:23 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.5 on epoch=24, global_step=50
04/27/2022 16:12:27 - INFO - __main__ - Step 60 Global step 60 Train loss 0.36 on epoch=29
04/27/2022 16:12:31 - INFO - __main__ - Step 70 Global step 70 Train loss 0.28 on epoch=34
04/27/2022 16:12:35 - INFO - __main__ - Step 80 Global step 80 Train loss 0.27 on epoch=39
04/27/2022 16:12:39 - INFO - __main__ - Step 90 Global step 90 Train loss 0.23 on epoch=44
04/27/2022 16:12:43 - INFO - __main__ - Step 100 Global step 100 Train loss 0.16 on epoch=49
04/27/2022 16:12:44 - INFO - __main__ - Global step 100 Train loss 0.26 ACC 0.5 on epoch=49
04/27/2022 16:12:48 - INFO - __main__ - Step 110 Global step 110 Train loss 0.23 on epoch=54
04/27/2022 16:12:52 - INFO - __main__ - Step 120 Global step 120 Train loss 0.13 on epoch=59
04/27/2022 16:12:56 - INFO - __main__ - Step 130 Global step 130 Train loss 0.18 on epoch=64
04/27/2022 16:13:00 - INFO - __main__ - Step 140 Global step 140 Train loss 0.16 on epoch=69
04/27/2022 16:13:03 - INFO - __main__ - Step 150 Global step 150 Train loss 0.12 on epoch=74
04/27/2022 16:13:05 - INFO - __main__ - Global step 150 Train loss 0.16 ACC 0.46875 on epoch=74
04/27/2022 16:13:09 - INFO - __main__ - Step 160 Global step 160 Train loss 0.07 on epoch=79
04/27/2022 16:13:13 - INFO - __main__ - Step 170 Global step 170 Train loss 0.09 on epoch=84
04/27/2022 16:13:17 - INFO - __main__ - Step 180 Global step 180 Train loss 0.07 on epoch=89
04/27/2022 16:13:20 - INFO - __main__ - Step 190 Global step 190 Train loss 0.07 on epoch=94
04/27/2022 16:13:24 - INFO - __main__ - Step 200 Global step 200 Train loss 0.11 on epoch=99
04/27/2022 16:13:26 - INFO - __main__ - Global step 200 Train loss 0.08 ACC 0.59375 on epoch=99
04/27/2022 16:13:26 - INFO - __main__ - Saving model with best ACC: 0.5 -> 0.59375 on epoch=99, global_step=200
04/27/2022 16:13:30 - INFO - __main__ - Step 210 Global step 210 Train loss 0.06 on epoch=104
04/27/2022 16:13:34 - INFO - __main__ - Step 220 Global step 220 Train loss 0.05 on epoch=109
04/27/2022 16:13:38 - INFO - __main__ - Step 230 Global step 230 Train loss 0.09 on epoch=114
04/27/2022 16:13:41 - INFO - __main__ - Step 240 Global step 240 Train loss 0.04 on epoch=119
04/27/2022 16:13:45 - INFO - __main__ - Step 250 Global step 250 Train loss 0.03 on epoch=124
04/27/2022 16:13:47 - INFO - __main__ - Global step 250 Train loss 0.06 ACC 0.65625 on epoch=124
04/27/2022 16:13:47 - INFO - __main__ - Saving model with best ACC: 0.59375 -> 0.65625 on epoch=124, global_step=250
04/27/2022 16:13:51 - INFO - __main__ - Step 260 Global step 260 Train loss 0.03 on epoch=129
04/27/2022 16:13:55 - INFO - __main__ - Step 270 Global step 270 Train loss 0.07 on epoch=134
04/27/2022 16:13:58 - INFO - __main__ - Step 280 Global step 280 Train loss 0.07 on epoch=139
04/27/2022 16:14:02 - INFO - __main__ - Step 290 Global step 290 Train loss 0.05 on epoch=144
04/27/2022 16:14:06 - INFO - __main__ - Step 300 Global step 300 Train loss 0.06 on epoch=149
04/27/2022 16:14:07 - INFO - __main__ - Global step 300 Train loss 0.06 ACC 0.5625 on epoch=149
04/27/2022 16:14:11 - INFO - __main__ - Step 310 Global step 310 Train loss 0.04 on epoch=154
04/27/2022 16:14:15 - INFO - __main__ - Step 320 Global step 320 Train loss 0.04 on epoch=159
04/27/2022 16:14:19 - INFO - __main__ - Step 330 Global step 330 Train loss 0.05 on epoch=164
04/27/2022 16:14:23 - INFO - __main__ - Step 340 Global step 340 Train loss 0.03 on epoch=169
04/27/2022 16:14:27 - INFO - __main__ - Step 350 Global step 350 Train loss 0.04 on epoch=174
04/27/2022 16:14:28 - INFO - __main__ - Global step 350 Train loss 0.04 ACC 0.5625 on epoch=174
04/27/2022 16:14:32 - INFO - __main__ - Step 360 Global step 360 Train loss 0.02 on epoch=179
04/27/2022 16:14:36 - INFO - __main__ - Step 370 Global step 370 Train loss 0.05 on epoch=184
04/27/2022 16:14:40 - INFO - __main__ - Step 380 Global step 380 Train loss 0.03 on epoch=189
04/27/2022 16:14:44 - INFO - __main__ - Step 390 Global step 390 Train loss 0.05 on epoch=194
04/27/2022 16:14:47 - INFO - __main__ - Step 400 Global step 400 Train loss 0.05 on epoch=199
04/27/2022 16:14:49 - INFO - __main__ - Global step 400 Train loss 0.04 ACC 0.65625 on epoch=199
04/27/2022 16:14:53 - INFO - __main__ - Step 410 Global step 410 Train loss 0.02 on epoch=204
04/27/2022 16:14:57 - INFO - __main__ - Step 420 Global step 420 Train loss 0.02 on epoch=209
04/27/2022 16:15:01 - INFO - __main__ - Step 430 Global step 430 Train loss 0.01 on epoch=214
04/27/2022 16:15:05 - INFO - __main__ - Step 440 Global step 440 Train loss 0.02 on epoch=219
04/27/2022 16:15:08 - INFO - __main__ - Step 450 Global step 450 Train loss 0.02 on epoch=224
04/27/2022 16:15:10 - INFO - __main__ - Global step 450 Train loss 0.02 ACC 0.625 on epoch=224
04/27/2022 16:15:14 - INFO - __main__ - Step 460 Global step 460 Train loss 0.06 on epoch=229
04/27/2022 16:15:18 - INFO - __main__ - Step 470 Global step 470 Train loss 0.01 on epoch=234
04/27/2022 16:15:21 - INFO - __main__ - Step 480 Global step 480 Train loss 0.02 on epoch=239
04/27/2022 16:15:25 - INFO - __main__ - Step 490 Global step 490 Train loss 0.03 on epoch=244
04/27/2022 16:15:29 - INFO - __main__ - Step 500 Global step 500 Train loss 0.03 on epoch=249
04/27/2022 16:15:31 - INFO - __main__ - Global step 500 Train loss 0.03 ACC 0.625 on epoch=249
04/27/2022 16:15:35 - INFO - __main__ - Step 510 Global step 510 Train loss 0.03 on epoch=254
04/27/2022 16:15:39 - INFO - __main__ - Step 520 Global step 520 Train loss 0.02 on epoch=259
04/27/2022 16:15:42 - INFO - __main__ - Step 530 Global step 530 Train loss 0.03 on epoch=264
04/27/2022 16:15:46 - INFO - __main__ - Step 540 Global step 540 Train loss 0.02 on epoch=269
04/27/2022 16:15:50 - INFO - __main__ - Step 550 Global step 550 Train loss 0.01 on epoch=274
04/27/2022 16:15:52 - INFO - __main__ - Global step 550 Train loss 0.02 ACC 0.65625 on epoch=274
04/27/2022 16:15:56 - INFO - __main__ - Step 560 Global step 560 Train loss 0.01 on epoch=279
04/27/2022 16:16:00 - INFO - __main__ - Step 570 Global step 570 Train loss 0.01 on epoch=284
04/27/2022 16:16:03 - INFO - __main__ - Step 580 Global step 580 Train loss 0.02 on epoch=289
04/27/2022 16:16:07 - INFO - __main__ - Step 590 Global step 590 Train loss 0.03 on epoch=294
04/27/2022 16:16:11 - INFO - __main__ - Step 600 Global step 600 Train loss 0.01 on epoch=299
04/27/2022 16:16:13 - INFO - __main__ - Global step 600 Train loss 0.01 ACC 0.65625 on epoch=299
04/27/2022 16:16:17 - INFO - __main__ - Step 610 Global step 610 Train loss 0.02 on epoch=304
04/27/2022 16:16:20 - INFO - __main__ - Step 620 Global step 620 Train loss 0.01 on epoch=309
04/27/2022 16:16:24 - INFO - __main__ - Step 630 Global step 630 Train loss 0.01 on epoch=314
04/27/2022 16:16:28 - INFO - __main__ - Step 640 Global step 640 Train loss 0.02 on epoch=319
04/27/2022 16:16:32 - INFO - __main__ - Step 650 Global step 650 Train loss 0.01 on epoch=324
04/27/2022 16:16:34 - INFO - __main__ - Global step 650 Train loss 0.01 ACC 0.5 on epoch=324
04/27/2022 16:16:38 - INFO - __main__ - Step 660 Global step 660 Train loss 0.00 on epoch=329
04/27/2022 16:16:42 - INFO - __main__ - Step 670 Global step 670 Train loss 0.01 on epoch=334
04/27/2022 16:16:46 - INFO - __main__ - Step 680 Global step 680 Train loss 0.01 on epoch=339
04/27/2022 16:16:50 - INFO - __main__ - Step 690 Global step 690 Train loss 0.01 on epoch=344
04/27/2022 16:16:53 - INFO - __main__ - Step 700 Global step 700 Train loss 0.01 on epoch=349
04/27/2022 16:16:55 - INFO - __main__ - Global step 700 Train loss 0.01 ACC 0.5 on epoch=349
04/27/2022 16:16:59 - INFO - __main__ - Step 710 Global step 710 Train loss 0.01 on epoch=354
04/27/2022 16:17:03 - INFO - __main__ - Step 720 Global step 720 Train loss 0.00 on epoch=359
04/27/2022 16:17:07 - INFO - __main__ - Step 730 Global step 730 Train loss 0.01 on epoch=364
04/27/2022 16:17:10 - INFO - __main__ - Step 740 Global step 740 Train loss 0.01 on epoch=369
04/27/2022 16:17:14 - INFO - __main__ - Step 750 Global step 750 Train loss 0.02 on epoch=374
04/27/2022 16:17:16 - INFO - __main__ - Global step 750 Train loss 0.01 ACC 0.53125 on epoch=374
04/27/2022 16:17:20 - INFO - __main__ - Step 760 Global step 760 Train loss 0.01 on epoch=379
04/27/2022 16:17:24 - INFO - __main__ - Step 770 Global step 770 Train loss 0.00 on epoch=384
04/27/2022 16:17:28 - INFO - __main__ - Step 780 Global step 780 Train loss 0.01 on epoch=389
04/27/2022 16:17:31 - INFO - __main__ - Step 790 Global step 790 Train loss 0.01 on epoch=394
04/27/2022 16:17:35 - INFO - __main__ - Step 800 Global step 800 Train loss 0.00 on epoch=399
04/27/2022 16:17:38 - INFO - __main__ - Global step 800 Train loss 0.01 ACC 0.5 on epoch=399
04/27/2022 16:17:42 - INFO - __main__ - Step 810 Global step 810 Train loss 0.01 on epoch=404
04/27/2022 16:17:46 - INFO - __main__ - Step 820 Global step 820 Train loss 0.00 on epoch=409
04/27/2022 16:17:50 - INFO - __main__ - Step 830 Global step 830 Train loss 0.01 on epoch=414
04/27/2022 16:17:55 - INFO - __main__ - Step 840 Global step 840 Train loss 0.00 on epoch=419
04/27/2022 16:17:59 - INFO - __main__ - Step 850 Global step 850 Train loss 0.00 on epoch=424
04/27/2022 16:18:02 - INFO - __main__ - Global step 850 Train loss 0.01 ACC 0.59375 on epoch=424
04/27/2022 16:18:06 - INFO - __main__ - Step 860 Global step 860 Train loss 0.01 on epoch=429
04/27/2022 16:18:10 - INFO - __main__ - Step 870 Global step 870 Train loss 0.01 on epoch=434
04/27/2022 16:18:15 - INFO - __main__ - Step 880 Global step 880 Train loss 0.00 on epoch=439
04/27/2022 16:18:19 - INFO - __main__ - Step 890 Global step 890 Train loss 0.04 on epoch=444
04/27/2022 16:18:23 - INFO - __main__ - Step 900 Global step 900 Train loss 0.01 on epoch=449
04/27/2022 16:18:26 - INFO - __main__ - Global step 900 Train loss 0.01 ACC 0.6875 on epoch=449
04/27/2022 16:18:26 - INFO - __main__ - Saving model with best ACC: 0.65625 -> 0.6875 on epoch=449, global_step=900
04/27/2022 16:18:30 - INFO - __main__ - Step 910 Global step 910 Train loss 0.00 on epoch=454
04/27/2022 16:18:34 - INFO - __main__ - Step 920 Global step 920 Train loss 0.00 on epoch=459
04/27/2022 16:18:38 - INFO - __main__ - Step 930 Global step 930 Train loss 0.00 on epoch=464
04/27/2022 16:18:43 - INFO - __main__ - Step 940 Global step 940 Train loss 0.01 on epoch=469
04/27/2022 16:18:47 - INFO - __main__ - Step 950 Global step 950 Train loss 0.01 on epoch=474
04/27/2022 16:18:49 - INFO - __main__ - Global step 950 Train loss 0.01 ACC 0.75 on epoch=474
04/27/2022 16:18:49 - INFO - __main__ - Saving model with best ACC: 0.6875 -> 0.75 on epoch=474, global_step=950
04/27/2022 16:18:53 - INFO - __main__ - Step 960 Global step 960 Train loss 0.01 on epoch=479
04/27/2022 16:18:58 - INFO - __main__ - Step 970 Global step 970 Train loss 0.03 on epoch=484
04/27/2022 16:19:02 - INFO - __main__ - Step 980 Global step 980 Train loss 0.00 on epoch=489
04/27/2022 16:19:05 - INFO - __main__ - Step 990 Global step 990 Train loss 0.00 on epoch=494
04/27/2022 16:19:09 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.01 on epoch=499
04/27/2022 16:19:11 - INFO - __main__ - Global step 1000 Train loss 0.01 ACC 0.6875 on epoch=499
04/27/2022 16:19:15 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.01 on epoch=504
04/27/2022 16:19:19 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.01 on epoch=509
04/27/2022 16:19:23 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.00 on epoch=514
04/27/2022 16:19:27 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.01 on epoch=519
04/27/2022 16:19:31 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.01 on epoch=524
04/27/2022 16:19:33 - INFO - __main__ - Global step 1050 Train loss 0.01 ACC 0.53125 on epoch=524
04/27/2022 16:19:37 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.01 on epoch=529
04/27/2022 16:19:41 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.00 on epoch=534
04/27/2022 16:19:45 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.00 on epoch=539
04/27/2022 16:19:49 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.01 on epoch=544
04/27/2022 16:19:53 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.01 on epoch=549
04/27/2022 16:19:55 - INFO - __main__ - Global step 1100 Train loss 0.01 ACC 0.59375 on epoch=549
04/27/2022 16:19:59 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.02 on epoch=554
04/27/2022 16:20:03 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=559
04/27/2022 16:20:07 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.00 on epoch=564
04/27/2022 16:20:11 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.04 on epoch=569
04/27/2022 16:20:15 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=574
04/27/2022 16:20:17 - INFO - __main__ - Global step 1150 Train loss 0.02 ACC 0.6875 on epoch=574
04/27/2022 16:20:21 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.01 on epoch=579
04/27/2022 16:20:25 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.00 on epoch=584
04/27/2022 16:20:29 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.00 on epoch=589
04/27/2022 16:20:33 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.01 on epoch=594
04/27/2022 16:20:37 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.00 on epoch=599
04/27/2022 16:20:39 - INFO - __main__ - Global step 1200 Train loss 0.00 ACC 0.6875 on epoch=599
04/27/2022 16:20:42 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.00 on epoch=604
04/27/2022 16:20:46 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.00 on epoch=609
04/27/2022 16:20:50 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.00 on epoch=614
04/27/2022 16:20:54 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.00 on epoch=619
04/27/2022 16:20:58 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.02 on epoch=624
04/27/2022 16:21:01 - INFO - __main__ - Global step 1250 Train loss 0.01 ACC 0.71875 on epoch=624
04/27/2022 16:21:05 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.00 on epoch=629
04/27/2022 16:21:09 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.00 on epoch=634
04/27/2022 16:21:13 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.00 on epoch=639
04/27/2022 16:21:17 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.00 on epoch=644
04/27/2022 16:21:21 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.00 on epoch=649
04/27/2022 16:21:23 - INFO - __main__ - Global step 1300 Train loss 0.00 ACC 0.625 on epoch=649
04/27/2022 16:21:27 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=654
04/27/2022 16:21:31 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.00 on epoch=659
04/27/2022 16:21:35 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.00 on epoch=664
04/27/2022 16:21:39 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.00 on epoch=669
04/27/2022 16:21:43 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.00 on epoch=674
04/27/2022 16:21:46 - INFO - __main__ - Global step 1350 Train loss 0.00 ACC 0.65625 on epoch=674
04/27/2022 16:21:50 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.00 on epoch=679
04/27/2022 16:21:54 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.00 on epoch=684
04/27/2022 16:21:58 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.00 on epoch=689
04/27/2022 16:22:02 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.00 on epoch=694
04/27/2022 16:22:06 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.00 on epoch=699
04/27/2022 16:22:08 - INFO - __main__ - Global step 1400 Train loss 0.00 ACC 0.6875 on epoch=699
04/27/2022 16:22:12 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=704
04/27/2022 16:22:16 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=709
04/27/2022 16:22:20 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.00 on epoch=714
04/27/2022 16:22:24 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=719
04/27/2022 16:22:28 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.03 on epoch=724
04/27/2022 16:22:30 - INFO - __main__ - Global step 1450 Train loss 0.01 ACC 0.6875 on epoch=724
04/27/2022 16:22:34 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=729
04/27/2022 16:22:38 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=734
04/27/2022 16:22:42 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=739
04/27/2022 16:22:46 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=744
04/27/2022 16:22:50 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=749
04/27/2022 16:22:53 - INFO - __main__ - Global step 1500 Train loss 0.01 ACC 0.5625 on epoch=749
04/27/2022 16:22:57 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=754
04/27/2022 16:23:01 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=759
04/27/2022 16:23:05 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.02 on epoch=764
04/27/2022 16:23:08 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=769
04/27/2022 16:23:12 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=774
04/27/2022 16:23:15 - INFO - __main__ - Global step 1550 Train loss 0.00 ACC 0.625 on epoch=774
04/27/2022 16:23:19 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.02 on epoch=779
04/27/2022 16:23:23 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=784
04/27/2022 16:23:27 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=789
04/27/2022 16:23:31 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=794
04/27/2022 16:23:35 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=799
04/27/2022 16:23:37 - INFO - __main__ - Global step 1600 Train loss 0.01 ACC 0.6875 on epoch=799
04/27/2022 16:23:41 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=804
04/27/2022 16:23:45 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=809
04/27/2022 16:23:49 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=814
04/27/2022 16:23:53 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=819
04/27/2022 16:23:57 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=824
04/27/2022 16:23:59 - INFO - __main__ - Global step 1650 Train loss 0.00 ACC 0.6875 on epoch=824
04/27/2022 16:24:03 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=829
04/27/2022 16:24:07 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=834
04/27/2022 16:24:11 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=839
04/27/2022 16:24:15 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=844
04/27/2022 16:24:19 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=849
04/27/2022 16:24:21 - INFO - __main__ - Global step 1700 Train loss 0.00 ACC 0.625 on epoch=849
04/27/2022 16:24:25 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=854
04/27/2022 16:24:29 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=859
04/27/2022 16:24:33 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=864
04/27/2022 16:24:36 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=869
04/27/2022 16:24:40 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=874
04/27/2022 16:24:43 - INFO - __main__ - Global step 1750 Train loss 0.00 ACC 0.75 on epoch=874
04/27/2022 16:24:46 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=879
04/27/2022 16:24:50 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=884
04/27/2022 16:24:54 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=889
04/27/2022 16:24:58 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=894
04/27/2022 16:25:02 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=899
04/27/2022 16:25:04 - INFO - __main__ - Global step 1800 Train loss 0.00 ACC 0.75 on epoch=899
04/27/2022 16:25:08 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=904
04/27/2022 16:25:12 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=909
04/27/2022 16:25:16 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=914
04/27/2022 16:25:20 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=919
04/27/2022 16:25:24 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=924
04/27/2022 16:25:26 - INFO - __main__ - Global step 1850 Train loss 0.00 ACC 0.6875 on epoch=924
04/27/2022 16:25:30 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.03 on epoch=929
04/27/2022 16:25:34 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=934
04/27/2022 16:25:37 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=939
04/27/2022 16:25:41 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=944
04/27/2022 16:25:45 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=949
04/27/2022 16:25:47 - INFO - __main__ - Global step 1900 Train loss 0.01 ACC 0.75 on epoch=949
04/27/2022 16:25:51 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=954
04/27/2022 16:25:55 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=959
04/27/2022 16:25:59 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=964
04/27/2022 16:26:03 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=969
04/27/2022 16:26:07 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=974
04/27/2022 16:26:09 - INFO - __main__ - Global step 1950 Train loss 0.00 ACC 0.75 on epoch=974
04/27/2022 16:26:13 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=979
04/27/2022 16:26:17 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=984
04/27/2022 16:26:20 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=989
04/27/2022 16:26:24 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=994
04/27/2022 16:26:28 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=999
04/27/2022 16:26:30 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 16:26:30 - INFO - __main__ - Printing 3 examples
04/27/2022 16:26:30 - INFO - __main__ -  [sciq] What zone is outside the radiative zone? (A) diffusion zone (B) peripheral zone (C) activation zone (D) convection zone [SEP] The convection zone is where convection takes place. It is located outward from the radiative zone.
04/27/2022 16:26:30 - INFO - __main__ - ['convection zone']
04/27/2022 16:26:30 - INFO - __main__ -  [sciq] What planet has the most volcanoes? (A) uranus (B) Earth (C) Mars (D) venus [SEP] Venus has more volcanoes than any other planet. There are between 100,000 and one million volcanoes on Venus! Most of the volcanoes are now inactive. There are also a large number of craters. This means that Venus doesn’t have tectonic plates. Plate tectonics on Earth erases features over time. Figure below is an image made using radar data. The volcano is Maat Mons. Lava beds are in the foreground. Scientists think the color of sunlight on Venus is reddish-brown.
04/27/2022 16:26:30 - INFO - __main__ - ['venus']
04/27/2022 16:26:30 - INFO - __main__ -  [sciq] Where are the oceans most polluted? (A) along reefs (B) on the ocean floor (C) along coasts (D) in warmer waters [SEP] The oceans are most polluted along coasts. Why do you think that's the case? Of course, it's because most pollution enters the oceans from the land. Runoff and rivers carry the majority of pollution into the ocean. Many cities dump their wastewater , water mixed with waste, directly into coastal waters. In some parts of the world, raw sewage and trash may be thrown into the water ( Figure below ). Coastal water may become so polluted that people get sick if they swim in it or eat seafood from it. The polluted water may also kill fish and other ocean life.
04/27/2022 16:26:30 - INFO - __main__ - ['along coasts']
04/27/2022 16:26:30 - INFO - __main__ - Tokenizing Input ...
04/27/2022 16:26:30 - INFO - __main__ - Tokenizing Output ...
04/27/2022 16:26:30 - INFO - __main__ - Loaded 32 examples from train data
04/27/2022 16:26:30 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 16:26:30 - INFO - __main__ - Printing 3 examples
04/27/2022 16:26:30 - INFO - __main__ -  [sciq] Viruses depend on what type of cells? (A) anchor cells (B) host cells (C) immune system cells (D) blood cells [SEP] Briefly describe how viruses depend on host cells.
04/27/2022 16:26:30 - INFO - __main__ - ['host cells']
04/27/2022 16:26:30 - INFO - __main__ -  [sciq] What is the time interval required for one complete wave to pass a point called? (A) cycle (B) minute (C) half-life (D) period [SEP] The time interval required for one complete wave to pass a point is called the period . During the period of the wave, an entire wavelength from one crest to the next crest passes a position. The number of waves that pass a single position in one second is called the frequency . The period of a wave and its frequency are reciprocals of each other.
04/27/2022 16:26:30 - INFO - __main__ - ['period']
04/27/2022 16:26:30 - INFO - __main__ -  [sciq] What layer of soil, essential for farming, has the highest proportion of organic material? (A) subsoil (B) bedrock (C) topsoil (D) humus [SEP] Topsoil has the highest proportion of organic material. Topsoil is essential for farming.
04/27/2022 16:26:30 - INFO - __main__ - ['topsoil']
04/27/2022 16:26:30 - INFO - __main__ - Tokenizing Input ...
04/27/2022 16:26:30 - INFO - __main__ - Tokenizing Output ...
04/27/2022 16:26:30 - INFO - __main__ - Loaded 32 examples from dev data
04/27/2022 16:26:30 - INFO - __main__ - Global step 2000 Train loss 0.00 ACC 0.6875 on epoch=999
04/27/2022 16:26:30 - INFO - __main__ - save last model!
04/27/2022 16:26:30 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
04/27/2022 16:26:30 - INFO - __main__ - Start tokenizing ... 887 instances
04/27/2022 16:26:30 - INFO - __main__ - Printing 3 examples
04/27/2022 16:26:30 - INFO - __main__ -  [sciq] A frameshift mutation is a deletion or insertion of one or more of what that changes the reading frame of the base sequence? (A) carotenoids (B) nucleotides (C) proteins (D) genes [SEP] A frameshift mutation is a deletion or insertion of one or more nucleotides that changes the reading frame of the base sequence. Deletions remove nucleotides, and insertions add nucleotides. Consider the following sequence of bases in RNA:.
04/27/2022 16:26:30 - INFO - __main__ - ['nucleotides']
04/27/2022 16:26:30 - INFO - __main__ -  [sciq] What is an area of land called that is wet for all or part of the year? (A) grassland (B) wetland (C) plains (D) tundra [SEP] A wetland is an area that is wet for all or part of the year. Wetlands are home to certain types of plants.
04/27/2022 16:26:31 - INFO - __main__ - ['wetland']
04/27/2022 16:26:31 - INFO - __main__ -  [sciq] What are arteries, veins, and capillaries examples of? (A) blood vessels (B) muscles (C) organs (D) tissue [SEP] Blood vessels include arteries, veins, and capillaries.
04/27/2022 16:26:31 - INFO - __main__ - ['blood vessels']
04/27/2022 16:26:31 - INFO - __main__ - Tokenizing Input ...
04/27/2022 16:26:31 - INFO - __main__ - Tokenizing Output ...
04/27/2022 16:26:32 - INFO - __main__ - Loaded 887 examples from test data
04/27/2022 16:26:48 - INFO - __main__ - load prompt embedding from ckpt
04/27/2022 16:26:49 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/27/2022 16:26:49 - INFO - __main__ - Starting training!
04/27/2022 16:27:18 - INFO - __main__ - Saved prediction in models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-sciq/sciq_32_100_0.5_8_predictions.txt
04/27/2022 16:27:18 - INFO - __main__ - ACC on test data: 0.7441
04/27/2022 16:27:20 - INFO - __main__ - prefix=sciq_32_100, lr=0.5, bsz=8, dev_performance=0.75, test_performance=0.7440811724915445
04/27/2022 16:27:20 - INFO - __main__ - Running ... prefix=sciq_32_100, lr=0.4, bsz=8 ...
04/27/2022 16:27:21 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 16:27:21 - INFO - __main__ - Printing 3 examples
04/27/2022 16:27:21 - INFO - __main__ -  [sciq] What zone is outside the radiative zone? (A) diffusion zone (B) peripheral zone (C) activation zone (D) convection zone [SEP] The convection zone is where convection takes place. It is located outward from the radiative zone.
04/27/2022 16:27:21 - INFO - __main__ - ['convection zone']
04/27/2022 16:27:21 - INFO - __main__ -  [sciq] What planet has the most volcanoes? (A) uranus (B) Earth (C) Mars (D) venus [SEP] Venus has more volcanoes than any other planet. There are between 100,000 and one million volcanoes on Venus! Most of the volcanoes are now inactive. There are also a large number of craters. This means that Venus doesn’t have tectonic plates. Plate tectonics on Earth erases features over time. Figure below is an image made using radar data. The volcano is Maat Mons. Lava beds are in the foreground. Scientists think the color of sunlight on Venus is reddish-brown.
04/27/2022 16:27:21 - INFO - __main__ - ['venus']
04/27/2022 16:27:21 - INFO - __main__ -  [sciq] Where are the oceans most polluted? (A) along reefs (B) on the ocean floor (C) along coasts (D) in warmer waters [SEP] The oceans are most polluted along coasts. Why do you think that's the case? Of course, it's because most pollution enters the oceans from the land. Runoff and rivers carry the majority of pollution into the ocean. Many cities dump their wastewater , water mixed with waste, directly into coastal waters. In some parts of the world, raw sewage and trash may be thrown into the water ( Figure below ). Coastal water may become so polluted that people get sick if they swim in it or eat seafood from it. The polluted water may also kill fish and other ocean life.
04/27/2022 16:27:21 - INFO - __main__ - ['along coasts']
04/27/2022 16:27:21 - INFO - __main__ - Tokenizing Input ...
04/27/2022 16:27:21 - INFO - __main__ - Tokenizing Output ...
04/27/2022 16:27:21 - INFO - __main__ - Loaded 32 examples from train data
04/27/2022 16:27:21 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 16:27:21 - INFO - __main__ - Printing 3 examples
04/27/2022 16:27:21 - INFO - __main__ -  [sciq] Viruses depend on what type of cells? (A) anchor cells (B) host cells (C) immune system cells (D) blood cells [SEP] Briefly describe how viruses depend on host cells.
04/27/2022 16:27:21 - INFO - __main__ - ['host cells']
04/27/2022 16:27:21 - INFO - __main__ -  [sciq] What is the time interval required for one complete wave to pass a point called? (A) cycle (B) minute (C) half-life (D) period [SEP] The time interval required for one complete wave to pass a point is called the period . During the period of the wave, an entire wavelength from one crest to the next crest passes a position. The number of waves that pass a single position in one second is called the frequency . The period of a wave and its frequency are reciprocals of each other.
04/27/2022 16:27:21 - INFO - __main__ - ['period']
04/27/2022 16:27:21 - INFO - __main__ -  [sciq] What layer of soil, essential for farming, has the highest proportion of organic material? (A) subsoil (B) bedrock (C) topsoil (D) humus [SEP] Topsoil has the highest proportion of organic material. Topsoil is essential for farming.
04/27/2022 16:27:21 - INFO - __main__ - ['topsoil']
04/27/2022 16:27:21 - INFO - __main__ - Tokenizing Input ...
04/27/2022 16:27:21 - INFO - __main__ - Tokenizing Output ...
04/27/2022 16:27:21 - INFO - __main__ - Loaded 32 examples from dev data
04/27/2022 16:27:38 - INFO - __main__ - load prompt embedding from ckpt
04/27/2022 16:27:39 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/27/2022 16:27:39 - INFO - __main__ - Starting training!
04/27/2022 16:27:43 - INFO - __main__ - Step 10 Global step 10 Train loss 2.90 on epoch=4
04/27/2022 16:27:47 - INFO - __main__ - Step 20 Global step 20 Train loss 1.24 on epoch=9
04/27/2022 16:27:51 - INFO - __main__ - Step 30 Global step 30 Train loss 0.77 on epoch=14
04/27/2022 16:27:55 - INFO - __main__ - Step 40 Global step 40 Train loss 0.55 on epoch=19
04/27/2022 16:27:59 - INFO - __main__ - Step 50 Global step 50 Train loss 0.38 on epoch=24
04/27/2022 16:28:01 - INFO - __main__ - Global step 50 Train loss 1.17 ACC 0.4375 on epoch=24
04/27/2022 16:28:01 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.4375 on epoch=24, global_step=50
04/27/2022 16:28:05 - INFO - __main__ - Step 60 Global step 60 Train loss 0.36 on epoch=29
04/27/2022 16:28:09 - INFO - __main__ - Step 70 Global step 70 Train loss 0.43 on epoch=34
04/27/2022 16:28:13 - INFO - __main__ - Step 80 Global step 80 Train loss 0.33 on epoch=39
04/27/2022 16:28:17 - INFO - __main__ - Step 90 Global step 90 Train loss 0.23 on epoch=44
04/27/2022 16:28:21 - INFO - __main__ - Step 100 Global step 100 Train loss 0.25 on epoch=49
04/27/2022 16:28:23 - INFO - __main__ - Global step 100 Train loss 0.32 ACC 0.40625 on epoch=49
04/27/2022 16:28:27 - INFO - __main__ - Step 110 Global step 110 Train loss 0.23 on epoch=54
04/27/2022 16:28:31 - INFO - __main__ - Step 120 Global step 120 Train loss 0.19 on epoch=59
04/27/2022 16:28:35 - INFO - __main__ - Step 130 Global step 130 Train loss 0.24 on epoch=64
04/27/2022 16:28:39 - INFO - __main__ - Step 140 Global step 140 Train loss 0.15 on epoch=69
04/27/2022 16:28:42 - INFO - __main__ - Step 150 Global step 150 Train loss 0.14 on epoch=74
04/27/2022 16:28:44 - INFO - __main__ - Global step 150 Train loss 0.19 ACC 0.53125 on epoch=74
04/27/2022 16:28:44 - INFO - __main__ - Saving model with best ACC: 0.4375 -> 0.53125 on epoch=74, global_step=150
04/27/2022 16:28:48 - INFO - __main__ - Step 160 Global step 160 Train loss 0.14 on epoch=79
04/27/2022 16:28:52 - INFO - __main__ - Step 170 Global step 170 Train loss 0.13 on epoch=84
04/27/2022 16:28:56 - INFO - __main__ - Step 180 Global step 180 Train loss 0.12 on epoch=89
04/27/2022 16:29:00 - INFO - __main__ - Step 190 Global step 190 Train loss 0.13 on epoch=94
04/27/2022 16:29:04 - INFO - __main__ - Step 200 Global step 200 Train loss 0.12 on epoch=99
04/27/2022 16:29:05 - INFO - __main__ - Global step 200 Train loss 0.13 ACC 0.53125 on epoch=99
04/27/2022 16:29:09 - INFO - __main__ - Step 210 Global step 210 Train loss 0.10 on epoch=104
04/27/2022 16:29:13 - INFO - __main__ - Step 220 Global step 220 Train loss 0.10 on epoch=109
04/27/2022 16:29:17 - INFO - __main__ - Step 230 Global step 230 Train loss 0.09 on epoch=114
04/27/2022 16:29:21 - INFO - __main__ - Step 240 Global step 240 Train loss 0.08 on epoch=119
04/27/2022 16:29:25 - INFO - __main__ - Step 250 Global step 250 Train loss 0.07 on epoch=124
04/27/2022 16:29:27 - INFO - __main__ - Global step 250 Train loss 0.09 ACC 0.625 on epoch=124
04/27/2022 16:29:27 - INFO - __main__ - Saving model with best ACC: 0.53125 -> 0.625 on epoch=124, global_step=250
04/27/2022 16:29:31 - INFO - __main__ - Step 260 Global step 260 Train loss 0.05 on epoch=129
04/27/2022 16:29:35 - INFO - __main__ - Step 270 Global step 270 Train loss 0.06 on epoch=134
04/27/2022 16:29:39 - INFO - __main__ - Step 280 Global step 280 Train loss 0.05 on epoch=139
04/27/2022 16:29:43 - INFO - __main__ - Step 290 Global step 290 Train loss 0.05 on epoch=144
04/27/2022 16:29:47 - INFO - __main__ - Step 300 Global step 300 Train loss 0.04 on epoch=149
04/27/2022 16:29:48 - INFO - __main__ - Global step 300 Train loss 0.05 ACC 0.59375 on epoch=149
04/27/2022 16:29:52 - INFO - __main__ - Step 310 Global step 310 Train loss 0.05 on epoch=154
04/27/2022 16:29:56 - INFO - __main__ - Step 320 Global step 320 Train loss 0.04 on epoch=159
04/27/2022 16:30:00 - INFO - __main__ - Step 330 Global step 330 Train loss 0.03 on epoch=164
04/27/2022 16:30:04 - INFO - __main__ - Step 340 Global step 340 Train loss 0.07 on epoch=169
04/27/2022 16:30:08 - INFO - __main__ - Step 350 Global step 350 Train loss 0.03 on epoch=174
04/27/2022 16:30:10 - INFO - __main__ - Global step 350 Train loss 0.04 ACC 0.625 on epoch=174
04/27/2022 16:30:13 - INFO - __main__ - Step 360 Global step 360 Train loss 0.03 on epoch=179
04/27/2022 16:30:17 - INFO - __main__ - Step 370 Global step 370 Train loss 0.02 on epoch=184
04/27/2022 16:30:21 - INFO - __main__ - Step 380 Global step 380 Train loss 0.02 on epoch=189
04/27/2022 16:30:25 - INFO - __main__ - Step 390 Global step 390 Train loss 0.02 on epoch=194
04/27/2022 16:30:29 - INFO - __main__ - Step 400 Global step 400 Train loss 0.02 on epoch=199
04/27/2022 16:30:31 - INFO - __main__ - Global step 400 Train loss 0.02 ACC 0.75 on epoch=199
04/27/2022 16:30:31 - INFO - __main__ - Saving model with best ACC: 0.625 -> 0.75 on epoch=199, global_step=400
04/27/2022 16:30:35 - INFO - __main__ - Step 410 Global step 410 Train loss 0.03 on epoch=204
04/27/2022 16:30:39 - INFO - __main__ - Step 420 Global step 420 Train loss 0.02 on epoch=209
04/27/2022 16:30:43 - INFO - __main__ - Step 430 Global step 430 Train loss 0.02 on epoch=214
04/27/2022 16:30:47 - INFO - __main__ - Step 440 Global step 440 Train loss 0.05 on epoch=219
04/27/2022 16:30:51 - INFO - __main__ - Step 450 Global step 450 Train loss 0.05 on epoch=224
04/27/2022 16:30:52 - INFO - __main__ - Global step 450 Train loss 0.04 ACC 0.71875 on epoch=224
04/27/2022 16:30:56 - INFO - __main__ - Step 460 Global step 460 Train loss 0.02 on epoch=229
04/27/2022 16:31:00 - INFO - __main__ - Step 470 Global step 470 Train loss 0.05 on epoch=234
04/27/2022 16:31:04 - INFO - __main__ - Step 480 Global step 480 Train loss 0.01 on epoch=239
04/27/2022 16:31:08 - INFO - __main__ - Step 490 Global step 490 Train loss 0.03 on epoch=244
04/27/2022 16:31:12 - INFO - __main__ - Step 500 Global step 500 Train loss 0.03 on epoch=249
04/27/2022 16:31:14 - INFO - __main__ - Global step 500 Train loss 0.03 ACC 0.78125 on epoch=249
04/27/2022 16:31:14 - INFO - __main__ - Saving model with best ACC: 0.75 -> 0.78125 on epoch=249, global_step=500
04/27/2022 16:31:17 - INFO - __main__ - Step 510 Global step 510 Train loss 0.01 on epoch=254
04/27/2022 16:31:21 - INFO - __main__ - Step 520 Global step 520 Train loss 0.02 on epoch=259
04/27/2022 16:31:25 - INFO - __main__ - Step 530 Global step 530 Train loss 0.04 on epoch=264
04/27/2022 16:31:29 - INFO - __main__ - Step 540 Global step 540 Train loss 0.02 on epoch=269
04/27/2022 16:31:33 - INFO - __main__ - Step 550 Global step 550 Train loss 0.02 on epoch=274
04/27/2022 16:31:36 - INFO - __main__ - Global step 550 Train loss 0.02 ACC 0.65625 on epoch=274
04/27/2022 16:31:40 - INFO - __main__ - Step 560 Global step 560 Train loss 0.02 on epoch=279
04/27/2022 16:31:44 - INFO - __main__ - Step 570 Global step 570 Train loss 0.00 on epoch=284
04/27/2022 16:31:48 - INFO - __main__ - Step 580 Global step 580 Train loss 0.05 on epoch=289
04/27/2022 16:31:52 - INFO - __main__ - Step 590 Global step 590 Train loss 0.01 on epoch=294
04/27/2022 16:31:56 - INFO - __main__ - Step 600 Global step 600 Train loss 0.02 on epoch=299
04/27/2022 16:31:58 - INFO - __main__ - Global step 600 Train loss 0.02 ACC 0.71875 on epoch=299
04/27/2022 16:32:02 - INFO - __main__ - Step 610 Global step 610 Train loss 0.01 on epoch=304
04/27/2022 16:32:06 - INFO - __main__ - Step 620 Global step 620 Train loss 0.04 on epoch=309
04/27/2022 16:32:09 - INFO - __main__ - Step 630 Global step 630 Train loss 0.00 on epoch=314
04/27/2022 16:32:13 - INFO - __main__ - Step 640 Global step 640 Train loss 0.00 on epoch=319
04/27/2022 16:32:17 - INFO - __main__ - Step 650 Global step 650 Train loss 0.01 on epoch=324
04/27/2022 16:32:20 - INFO - __main__ - Global step 650 Train loss 0.01 ACC 0.625 on epoch=324
04/27/2022 16:32:24 - INFO - __main__ - Step 660 Global step 660 Train loss 0.01 on epoch=329
04/27/2022 16:32:28 - INFO - __main__ - Step 670 Global step 670 Train loss 0.02 on epoch=334
04/27/2022 16:32:32 - INFO - __main__ - Step 680 Global step 680 Train loss 0.01 on epoch=339
04/27/2022 16:32:36 - INFO - __main__ - Step 690 Global step 690 Train loss 0.01 on epoch=344
04/27/2022 16:32:40 - INFO - __main__ - Step 700 Global step 700 Train loss 0.02 on epoch=349
04/27/2022 16:32:42 - INFO - __main__ - Global step 700 Train loss 0.01 ACC 0.78125 on epoch=349
04/27/2022 16:32:46 - INFO - __main__ - Step 710 Global step 710 Train loss 0.02 on epoch=354
04/27/2022 16:32:50 - INFO - __main__ - Step 720 Global step 720 Train loss 0.02 on epoch=359
04/27/2022 16:32:54 - INFO - __main__ - Step 730 Global step 730 Train loss 0.01 on epoch=364
04/27/2022 16:32:58 - INFO - __main__ - Step 740 Global step 740 Train loss 0.01 on epoch=369
04/27/2022 16:33:02 - INFO - __main__ - Step 750 Global step 750 Train loss 0.00 on epoch=374
04/27/2022 16:33:04 - INFO - __main__ - Global step 750 Train loss 0.01 ACC 0.78125 on epoch=374
04/27/2022 16:33:08 - INFO - __main__ - Step 760 Global step 760 Train loss 0.01 on epoch=379
04/27/2022 16:33:12 - INFO - __main__ - Step 770 Global step 770 Train loss 0.03 on epoch=384
04/27/2022 16:33:16 - INFO - __main__ - Step 780 Global step 780 Train loss 0.01 on epoch=389
04/27/2022 16:33:20 - INFO - __main__ - Step 790 Global step 790 Train loss 0.01 on epoch=394
04/27/2022 16:33:24 - INFO - __main__ - Step 800 Global step 800 Train loss 0.01 on epoch=399
04/27/2022 16:33:26 - INFO - __main__ - Global step 800 Train loss 0.01 ACC 0.65625 on epoch=399
04/27/2022 16:33:30 - INFO - __main__ - Step 810 Global step 810 Train loss 0.01 on epoch=404
04/27/2022 16:33:34 - INFO - __main__ - Step 820 Global step 820 Train loss 0.01 on epoch=409
04/27/2022 16:33:38 - INFO - __main__ - Step 830 Global step 830 Train loss 0.01 on epoch=414
04/27/2022 16:33:42 - INFO - __main__ - Step 840 Global step 840 Train loss 0.04 on epoch=419
04/27/2022 16:33:46 - INFO - __main__ - Step 850 Global step 850 Train loss 0.01 on epoch=424
04/27/2022 16:33:48 - INFO - __main__ - Global step 850 Train loss 0.01 ACC 0.71875 on epoch=424
04/27/2022 16:33:52 - INFO - __main__ - Step 860 Global step 860 Train loss 0.01 on epoch=429
04/27/2022 16:33:56 - INFO - __main__ - Step 870 Global step 870 Train loss 0.01 on epoch=434
04/27/2022 16:34:00 - INFO - __main__ - Step 880 Global step 880 Train loss 0.01 on epoch=439
04/27/2022 16:34:04 - INFO - __main__ - Step 890 Global step 890 Train loss 0.01 on epoch=444
04/27/2022 16:34:08 - INFO - __main__ - Step 900 Global step 900 Train loss 0.01 on epoch=449
04/27/2022 16:34:10 - INFO - __main__ - Global step 900 Train loss 0.01 ACC 0.75 on epoch=449
04/27/2022 16:34:14 - INFO - __main__ - Step 910 Global step 910 Train loss 0.01 on epoch=454
04/27/2022 16:34:18 - INFO - __main__ - Step 920 Global step 920 Train loss 0.00 on epoch=459
04/27/2022 16:34:22 - INFO - __main__ - Step 930 Global step 930 Train loss 0.01 on epoch=464
04/27/2022 16:34:26 - INFO - __main__ - Step 940 Global step 940 Train loss 0.01 on epoch=469
04/27/2022 16:34:30 - INFO - __main__ - Step 950 Global step 950 Train loss 0.01 on epoch=474
04/27/2022 16:34:32 - INFO - __main__ - Global step 950 Train loss 0.01 ACC 0.71875 on epoch=474
04/27/2022 16:34:36 - INFO - __main__ - Step 960 Global step 960 Train loss 0.00 on epoch=479
04/27/2022 16:34:40 - INFO - __main__ - Step 970 Global step 970 Train loss 0.01 on epoch=484
04/27/2022 16:34:44 - INFO - __main__ - Step 980 Global step 980 Train loss 0.00 on epoch=489
04/27/2022 16:34:48 - INFO - __main__ - Step 990 Global step 990 Train loss 0.03 on epoch=494
04/27/2022 16:34:52 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.01 on epoch=499
04/27/2022 16:34:54 - INFO - __main__ - Global step 1000 Train loss 0.01 ACC 0.78125 on epoch=499
04/27/2022 16:34:58 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.00 on epoch=504
04/27/2022 16:35:01 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.01 on epoch=509
04/27/2022 16:35:05 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.01 on epoch=514
04/27/2022 16:35:09 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.01 on epoch=519
04/27/2022 16:35:13 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.00 on epoch=524
04/27/2022 16:35:15 - INFO - __main__ - Global step 1050 Train loss 0.01 ACC 0.8125 on epoch=524
04/27/2022 16:35:15 - INFO - __main__ - Saving model with best ACC: 0.78125 -> 0.8125 on epoch=524, global_step=1050
04/27/2022 16:35:19 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.00 on epoch=529
04/27/2022 16:35:23 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.00 on epoch=534
04/27/2022 16:35:27 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.01 on epoch=539
04/27/2022 16:35:31 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.00 on epoch=544
04/27/2022 16:35:35 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.00 on epoch=549
04/27/2022 16:35:37 - INFO - __main__ - Global step 1100 Train loss 0.00 ACC 0.65625 on epoch=549
04/27/2022 16:35:41 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.00 on epoch=554
04/27/2022 16:35:45 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.00 on epoch=559
04/27/2022 16:35:49 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=564
04/27/2022 16:35:53 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.01 on epoch=569
04/27/2022 16:35:57 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=574
04/27/2022 16:35:59 - INFO - __main__ - Global step 1150 Train loss 0.01 ACC 0.75 on epoch=574
04/27/2022 16:36:03 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.02 on epoch=579
04/27/2022 16:36:07 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.00 on epoch=584
04/27/2022 16:36:11 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.01 on epoch=589
04/27/2022 16:36:15 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.01 on epoch=594
04/27/2022 16:36:19 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=599
04/27/2022 16:36:21 - INFO - __main__ - Global step 1200 Train loss 0.01 ACC 0.78125 on epoch=599
04/27/2022 16:36:25 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.00 on epoch=604
04/27/2022 16:36:29 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=609
04/27/2022 16:36:33 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.00 on epoch=614
04/27/2022 16:36:37 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.00 on epoch=619
04/27/2022 16:36:41 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.01 on epoch=624
04/27/2022 16:36:43 - INFO - __main__ - Global step 1250 Train loss 0.00 ACC 0.71875 on epoch=624
04/27/2022 16:36:47 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=629
04/27/2022 16:36:51 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.00 on epoch=634
04/27/2022 16:36:55 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=639
04/27/2022 16:36:59 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=644
04/27/2022 16:37:03 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.00 on epoch=649
04/27/2022 16:37:05 - INFO - __main__ - Global step 1300 Train loss 0.00 ACC 0.75 on epoch=649
04/27/2022 16:37:08 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=654
04/27/2022 16:37:12 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=659
04/27/2022 16:37:16 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=664
04/27/2022 16:37:20 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=669
04/27/2022 16:37:24 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.00 on epoch=674
04/27/2022 16:37:27 - INFO - __main__ - Global step 1350 Train loss 0.01 ACC 0.71875 on epoch=674
04/27/2022 16:37:30 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.00 on epoch=679
04/27/2022 16:37:34 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.00 on epoch=684
04/27/2022 16:37:38 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.00 on epoch=689
04/27/2022 16:37:42 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=694
04/27/2022 16:37:46 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=699
04/27/2022 16:37:49 - INFO - __main__ - Global step 1400 Train loss 0.01 ACC 0.71875 on epoch=699
04/27/2022 16:37:53 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=704
04/27/2022 16:37:57 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.05 on epoch=709
04/27/2022 16:38:01 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.00 on epoch=714
04/27/2022 16:38:05 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=719
04/27/2022 16:38:09 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=724
04/27/2022 16:38:12 - INFO - __main__ - Global step 1450 Train loss 0.01 ACC 0.8125 on epoch=724
04/27/2022 16:38:16 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=729
04/27/2022 16:38:20 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=734
04/27/2022 16:38:24 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=739
04/27/2022 16:38:28 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=744
04/27/2022 16:38:32 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=749
04/27/2022 16:38:34 - INFO - __main__ - Global step 1500 Train loss 0.00 ACC 0.78125 on epoch=749
04/27/2022 16:38:38 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=754
04/27/2022 16:38:42 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=759
04/27/2022 16:38:46 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=764
04/27/2022 16:38:50 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=769
04/27/2022 16:38:54 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=774
04/27/2022 16:38:56 - INFO - __main__ - Global step 1550 Train loss 0.00 ACC 0.75 on epoch=774
04/27/2022 16:39:00 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=779
04/27/2022 16:39:04 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=784
04/27/2022 16:39:08 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=789
04/27/2022 16:39:12 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=794
04/27/2022 16:39:16 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=799
04/27/2022 16:39:19 - INFO - __main__ - Global step 1600 Train loss 0.00 ACC 0.71875 on epoch=799
04/27/2022 16:39:23 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=804
04/27/2022 16:39:27 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=809
04/27/2022 16:39:31 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=814
04/27/2022 16:39:35 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=819
04/27/2022 16:39:39 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=824
04/27/2022 16:39:41 - INFO - __main__ - Global step 1650 Train loss 0.00 ACC 0.71875 on epoch=824
04/27/2022 16:39:45 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=829
04/27/2022 16:39:49 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=834
04/27/2022 16:39:53 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=839
04/27/2022 16:39:57 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=844
04/27/2022 16:40:01 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=849
04/27/2022 16:40:04 - INFO - __main__ - Global step 1700 Train loss 0.00 ACC 0.78125 on epoch=849
04/27/2022 16:40:08 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=854
04/27/2022 16:40:12 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=859
04/27/2022 16:40:16 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=864
04/27/2022 16:40:20 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=869
04/27/2022 16:40:24 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=874
04/27/2022 16:40:26 - INFO - __main__ - Global step 1750 Train loss 0.01 ACC 0.71875 on epoch=874
04/27/2022 16:40:30 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=879
04/27/2022 16:40:34 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=884
04/27/2022 16:40:38 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=889
04/27/2022 16:40:42 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=894
04/27/2022 16:40:46 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=899
04/27/2022 16:40:49 - INFO - __main__ - Global step 1800 Train loss 0.01 ACC 0.71875 on epoch=899
04/27/2022 16:40:53 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=904
04/27/2022 16:40:57 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=909
04/27/2022 16:41:01 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=914
04/27/2022 16:41:05 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=919
04/27/2022 16:41:09 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=924
04/27/2022 16:41:12 - INFO - __main__ - Global step 1850 Train loss 0.00 ACC 0.71875 on epoch=924
04/27/2022 16:41:16 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=929
04/27/2022 16:41:20 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=934
04/27/2022 16:41:24 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=939
04/27/2022 16:41:28 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=944
04/27/2022 16:41:32 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=949
04/27/2022 16:41:34 - INFO - __main__ - Global step 1900 Train loss 0.00 ACC 0.8125 on epoch=949
04/27/2022 16:41:38 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=954
04/27/2022 16:41:42 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=959
04/27/2022 16:41:46 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=964
04/27/2022 16:41:50 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=969
04/27/2022 16:41:54 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=974
04/27/2022 16:41:57 - INFO - __main__ - Global step 1950 Train loss 0.00 ACC 0.78125 on epoch=974
04/27/2022 16:42:01 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=979
04/27/2022 16:42:05 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=984
04/27/2022 16:42:09 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=989
04/27/2022 16:42:13 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=994
04/27/2022 16:42:17 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=999
04/27/2022 16:42:20 - INFO - __main__ - Global step 2000 Train loss 0.00 ACC 0.71875 on epoch=999
04/27/2022 16:42:20 - INFO - __main__ - save last model!
04/27/2022 16:42:20 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
04/27/2022 16:42:20 - INFO - __main__ - Start tokenizing ... 887 instances
04/27/2022 16:42:20 - INFO - __main__ - Printing 3 examples
04/27/2022 16:42:20 - INFO - __main__ -  [sciq] A frameshift mutation is a deletion or insertion of one or more of what that changes the reading frame of the base sequence? (A) carotenoids (B) nucleotides (C) proteins (D) genes [SEP] A frameshift mutation is a deletion or insertion of one or more nucleotides that changes the reading frame of the base sequence. Deletions remove nucleotides, and insertions add nucleotides. Consider the following sequence of bases in RNA:.
04/27/2022 16:42:20 - INFO - __main__ - ['nucleotides']
04/27/2022 16:42:20 - INFO - __main__ -  [sciq] What is an area of land called that is wet for all or part of the year? (A) grassland (B) wetland (C) plains (D) tundra [SEP] A wetland is an area that is wet for all or part of the year. Wetlands are home to certain types of plants.
04/27/2022 16:42:20 - INFO - __main__ - ['wetland']
04/27/2022 16:42:20 - INFO - __main__ -  [sciq] What are arteries, veins, and capillaries examples of? (A) blood vessels (B) muscles (C) organs (D) tissue [SEP] Blood vessels include arteries, veins, and capillaries.
04/27/2022 16:42:20 - INFO - __main__ - ['blood vessels']
04/27/2022 16:42:20 - INFO - __main__ - Tokenizing Input ...
04/27/2022 16:42:20 - INFO - __main__ - Tokenizing Output ...
04/27/2022 16:42:21 - INFO - __main__ - Loaded 887 examples from test data
04/27/2022 16:42:22 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 16:42:22 - INFO - __main__ - Printing 3 examples
04/27/2022 16:42:22 - INFO - __main__ -  [sciq] What zone is outside the radiative zone? (A) diffusion zone (B) peripheral zone (C) activation zone (D) convection zone [SEP] The convection zone is where convection takes place. It is located outward from the radiative zone.
04/27/2022 16:42:22 - INFO - __main__ - ['convection zone']
04/27/2022 16:42:22 - INFO - __main__ -  [sciq] What planet has the most volcanoes? (A) uranus (B) Earth (C) Mars (D) venus [SEP] Venus has more volcanoes than any other planet. There are between 100,000 and one million volcanoes on Venus! Most of the volcanoes are now inactive. There are also a large number of craters. This means that Venus doesn’t have tectonic plates. Plate tectonics on Earth erases features over time. Figure below is an image made using radar data. The volcano is Maat Mons. Lava beds are in the foreground. Scientists think the color of sunlight on Venus is reddish-brown.
04/27/2022 16:42:22 - INFO - __main__ - ['venus']
04/27/2022 16:42:22 - INFO - __main__ -  [sciq] Where are the oceans most polluted? (A) along reefs (B) on the ocean floor (C) along coasts (D) in warmer waters [SEP] The oceans are most polluted along coasts. Why do you think that's the case? Of course, it's because most pollution enters the oceans from the land. Runoff and rivers carry the majority of pollution into the ocean. Many cities dump their wastewater , water mixed with waste, directly into coastal waters. In some parts of the world, raw sewage and trash may be thrown into the water ( Figure below ). Coastal water may become so polluted that people get sick if they swim in it or eat seafood from it. The polluted water may also kill fish and other ocean life.
04/27/2022 16:42:22 - INFO - __main__ - ['along coasts']
04/27/2022 16:42:22 - INFO - __main__ - Tokenizing Input ...
04/27/2022 16:42:22 - INFO - __main__ - Tokenizing Output ...
04/27/2022 16:42:22 - INFO - __main__ - Loaded 32 examples from train data
04/27/2022 16:42:22 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 16:42:22 - INFO - __main__ - Printing 3 examples
04/27/2022 16:42:22 - INFO - __main__ -  [sciq] Viruses depend on what type of cells? (A) anchor cells (B) host cells (C) immune system cells (D) blood cells [SEP] Briefly describe how viruses depend on host cells.
04/27/2022 16:42:22 - INFO - __main__ - ['host cells']
04/27/2022 16:42:22 - INFO - __main__ -  [sciq] What is the time interval required for one complete wave to pass a point called? (A) cycle (B) minute (C) half-life (D) period [SEP] The time interval required for one complete wave to pass a point is called the period . During the period of the wave, an entire wavelength from one crest to the next crest passes a position. The number of waves that pass a single position in one second is called the frequency . The period of a wave and its frequency are reciprocals of each other.
04/27/2022 16:42:22 - INFO - __main__ - ['period']
04/27/2022 16:42:22 - INFO - __main__ -  [sciq] What layer of soil, essential for farming, has the highest proportion of organic material? (A) subsoil (B) bedrock (C) topsoil (D) humus [SEP] Topsoil has the highest proportion of organic material. Topsoil is essential for farming.
04/27/2022 16:42:22 - INFO - __main__ - ['topsoil']
04/27/2022 16:42:22 - INFO - __main__ - Tokenizing Input ...
04/27/2022 16:42:22 - INFO - __main__ - Tokenizing Output ...
04/27/2022 16:42:22 - INFO - __main__ - Loaded 32 examples from dev data
04/27/2022 16:42:37 - INFO - __main__ - load prompt embedding from ckpt
04/27/2022 16:42:38 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/27/2022 16:42:38 - INFO - __main__ - Starting training!
04/27/2022 16:43:13 - INFO - __main__ - Saved prediction in models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-sciq/sciq_32_100_0.4_8_predictions.txt
04/27/2022 16:43:13 - INFO - __main__ - ACC on test data: 0.7847
04/27/2022 16:43:13 - INFO - __main__ - prefix=sciq_32_100, lr=0.4, bsz=8, dev_performance=0.8125, test_performance=0.7846674182638106
04/27/2022 16:43:13 - INFO - __main__ - Running ... prefix=sciq_32_100, lr=0.3, bsz=8 ...
04/27/2022 16:43:14 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 16:43:14 - INFO - __main__ - Printing 3 examples
04/27/2022 16:43:14 - INFO - __main__ -  [sciq] What zone is outside the radiative zone? (A) diffusion zone (B) peripheral zone (C) activation zone (D) convection zone [SEP] The convection zone is where convection takes place. It is located outward from the radiative zone.
04/27/2022 16:43:14 - INFO - __main__ - ['convection zone']
04/27/2022 16:43:14 - INFO - __main__ -  [sciq] What planet has the most volcanoes? (A) uranus (B) Earth (C) Mars (D) venus [SEP] Venus has more volcanoes than any other planet. There are between 100,000 and one million volcanoes on Venus! Most of the volcanoes are now inactive. There are also a large number of craters. This means that Venus doesn’t have tectonic plates. Plate tectonics on Earth erases features over time. Figure below is an image made using radar data. The volcano is Maat Mons. Lava beds are in the foreground. Scientists think the color of sunlight on Venus is reddish-brown.
04/27/2022 16:43:14 - INFO - __main__ - ['venus']
04/27/2022 16:43:14 - INFO - __main__ -  [sciq] Where are the oceans most polluted? (A) along reefs (B) on the ocean floor (C) along coasts (D) in warmer waters [SEP] The oceans are most polluted along coasts. Why do you think that's the case? Of course, it's because most pollution enters the oceans from the land. Runoff and rivers carry the majority of pollution into the ocean. Many cities dump their wastewater , water mixed with waste, directly into coastal waters. In some parts of the world, raw sewage and trash may be thrown into the water ( Figure below ). Coastal water may become so polluted that people get sick if they swim in it or eat seafood from it. The polluted water may also kill fish and other ocean life.
04/27/2022 16:43:14 - INFO - __main__ - ['along coasts']
04/27/2022 16:43:14 - INFO - __main__ - Tokenizing Input ...
04/27/2022 16:43:14 - INFO - __main__ - Tokenizing Output ...
04/27/2022 16:43:14 - INFO - __main__ - Loaded 32 examples from train data
04/27/2022 16:43:14 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 16:43:14 - INFO - __main__ - Printing 3 examples
04/27/2022 16:43:14 - INFO - __main__ -  [sciq] Viruses depend on what type of cells? (A) anchor cells (B) host cells (C) immune system cells (D) blood cells [SEP] Briefly describe how viruses depend on host cells.
04/27/2022 16:43:14 - INFO - __main__ - ['host cells']
04/27/2022 16:43:14 - INFO - __main__ -  [sciq] What is the time interval required for one complete wave to pass a point called? (A) cycle (B) minute (C) half-life (D) period [SEP] The time interval required for one complete wave to pass a point is called the period . During the period of the wave, an entire wavelength from one crest to the next crest passes a position. The number of waves that pass a single position in one second is called the frequency . The period of a wave and its frequency are reciprocals of each other.
04/27/2022 16:43:14 - INFO - __main__ - ['period']
04/27/2022 16:43:14 - INFO - __main__ -  [sciq] What layer of soil, essential for farming, has the highest proportion of organic material? (A) subsoil (B) bedrock (C) topsoil (D) humus [SEP] Topsoil has the highest proportion of organic material. Topsoil is essential for farming.
04/27/2022 16:43:14 - INFO - __main__ - ['topsoil']
04/27/2022 16:43:14 - INFO - __main__ - Tokenizing Input ...
04/27/2022 16:43:14 - INFO - __main__ - Tokenizing Output ...
04/27/2022 16:43:14 - INFO - __main__ - Loaded 32 examples from dev data
04/27/2022 16:43:31 - INFO - __main__ - load prompt embedding from ckpt
04/27/2022 16:43:32 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/27/2022 16:43:32 - INFO - __main__ - Starting training!
04/27/2022 16:43:36 - INFO - __main__ - Step 10 Global step 10 Train loss 3.06 on epoch=4
04/27/2022 16:43:40 - INFO - __main__ - Step 20 Global step 20 Train loss 1.41 on epoch=9
04/27/2022 16:43:44 - INFO - __main__ - Step 30 Global step 30 Train loss 0.83 on epoch=14
04/27/2022 16:43:48 - INFO - __main__ - Step 40 Global step 40 Train loss 0.45 on epoch=19
04/27/2022 16:43:52 - INFO - __main__ - Step 50 Global step 50 Train loss 0.49 on epoch=24
04/27/2022 16:43:53 - INFO - __main__ - Global step 50 Train loss 1.25 ACC 0.40625 on epoch=24
04/27/2022 16:43:53 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.40625 on epoch=24, global_step=50
04/27/2022 16:43:57 - INFO - __main__ - Step 60 Global step 60 Train loss 0.39 on epoch=29
04/27/2022 16:44:01 - INFO - __main__ - Step 70 Global step 70 Train loss 0.37 on epoch=34
04/27/2022 16:44:05 - INFO - __main__ - Step 80 Global step 80 Train loss 0.41 on epoch=39
04/27/2022 16:44:09 - INFO - __main__ - Step 90 Global step 90 Train loss 0.32 on epoch=44
04/27/2022 16:44:13 - INFO - __main__ - Step 100 Global step 100 Train loss 0.23 on epoch=49
04/27/2022 16:44:14 - INFO - __main__ - Global step 100 Train loss 0.34 ACC 0.4375 on epoch=49
04/27/2022 16:44:14 - INFO - __main__ - Saving model with best ACC: 0.40625 -> 0.4375 on epoch=49, global_step=100
04/27/2022 16:44:18 - INFO - __main__ - Step 110 Global step 110 Train loss 0.21 on epoch=54
04/27/2022 16:44:22 - INFO - __main__ - Step 120 Global step 120 Train loss 0.23 on epoch=59
04/27/2022 16:44:26 - INFO - __main__ - Step 130 Global step 130 Train loss 0.27 on epoch=64
04/27/2022 16:44:30 - INFO - __main__ - Step 140 Global step 140 Train loss 0.13 on epoch=69
04/27/2022 16:44:34 - INFO - __main__ - Step 150 Global step 150 Train loss 0.23 on epoch=74
04/27/2022 16:44:35 - INFO - __main__ - Global step 150 Train loss 0.21 ACC 0.5 on epoch=74
04/27/2022 16:44:35 - INFO - __main__ - Saving model with best ACC: 0.4375 -> 0.5 on epoch=74, global_step=150
04/27/2022 16:44:39 - INFO - __main__ - Step 160 Global step 160 Train loss 0.24 on epoch=79
04/27/2022 16:44:43 - INFO - __main__ - Step 170 Global step 170 Train loss 0.16 on epoch=84
04/27/2022 16:44:46 - INFO - __main__ - Step 180 Global step 180 Train loss 0.18 on epoch=89
04/27/2022 16:44:50 - INFO - __main__ - Step 190 Global step 190 Train loss 0.13 on epoch=94
04/27/2022 16:44:54 - INFO - __main__ - Step 200 Global step 200 Train loss 0.13 on epoch=99
04/27/2022 16:44:56 - INFO - __main__ - Global step 200 Train loss 0.17 ACC 0.53125 on epoch=99
04/27/2022 16:44:56 - INFO - __main__ - Saving model with best ACC: 0.5 -> 0.53125 on epoch=99, global_step=200
04/27/2022 16:44:59 - INFO - __main__ - Step 210 Global step 210 Train loss 0.09 on epoch=104
04/27/2022 16:45:03 - INFO - __main__ - Step 220 Global step 220 Train loss 0.12 on epoch=109
04/27/2022 16:45:07 - INFO - __main__ - Step 230 Global step 230 Train loss 0.06 on epoch=114
04/27/2022 16:45:11 - INFO - __main__ - Step 240 Global step 240 Train loss 0.05 on epoch=119
04/27/2022 16:45:15 - INFO - __main__ - Step 250 Global step 250 Train loss 0.06 on epoch=124
04/27/2022 16:45:16 - INFO - __main__ - Global step 250 Train loss 0.08 ACC 0.53125 on epoch=124
04/27/2022 16:45:20 - INFO - __main__ - Step 260 Global step 260 Train loss 0.07 on epoch=129
04/27/2022 16:45:24 - INFO - __main__ - Step 270 Global step 270 Train loss 0.08 on epoch=134
04/27/2022 16:45:28 - INFO - __main__ - Step 280 Global step 280 Train loss 0.07 on epoch=139
04/27/2022 16:45:32 - INFO - __main__ - Step 290 Global step 290 Train loss 0.07 on epoch=144
04/27/2022 16:45:36 - INFO - __main__ - Step 300 Global step 300 Train loss 0.04 on epoch=149
04/27/2022 16:45:37 - INFO - __main__ - Global step 300 Train loss 0.07 ACC 0.53125 on epoch=149
04/27/2022 16:45:41 - INFO - __main__ - Step 310 Global step 310 Train loss 0.05 on epoch=154
04/27/2022 16:45:45 - INFO - __main__ - Step 320 Global step 320 Train loss 0.07 on epoch=159
04/27/2022 16:45:49 - INFO - __main__ - Step 330 Global step 330 Train loss 0.05 on epoch=164
04/27/2022 16:45:52 - INFO - __main__ - Step 340 Global step 340 Train loss 0.03 on epoch=169
04/27/2022 16:45:56 - INFO - __main__ - Step 350 Global step 350 Train loss 0.06 on epoch=174
04/27/2022 16:45:58 - INFO - __main__ - Global step 350 Train loss 0.05 ACC 0.59375 on epoch=174
04/27/2022 16:45:58 - INFO - __main__ - Saving model with best ACC: 0.53125 -> 0.59375 on epoch=174, global_step=350
04/27/2022 16:46:02 - INFO - __main__ - Step 360 Global step 360 Train loss 0.07 on epoch=179
04/27/2022 16:46:05 - INFO - __main__ - Step 370 Global step 370 Train loss 0.05 on epoch=184
04/27/2022 16:46:09 - INFO - __main__ - Step 380 Global step 380 Train loss 0.06 on epoch=189
04/27/2022 16:46:13 - INFO - __main__ - Step 390 Global step 390 Train loss 0.04 on epoch=194
04/27/2022 16:46:17 - INFO - __main__ - Step 400 Global step 400 Train loss 0.04 on epoch=199
04/27/2022 16:46:19 - INFO - __main__ - Global step 400 Train loss 0.05 ACC 0.625 on epoch=199
04/27/2022 16:46:19 - INFO - __main__ - Saving model with best ACC: 0.59375 -> 0.625 on epoch=199, global_step=400
04/27/2022 16:46:22 - INFO - __main__ - Step 410 Global step 410 Train loss 0.03 on epoch=204
04/27/2022 16:46:26 - INFO - __main__ - Step 420 Global step 420 Train loss 0.04 on epoch=209
04/27/2022 16:46:30 - INFO - __main__ - Step 430 Global step 430 Train loss 0.02 on epoch=214
04/27/2022 16:46:34 - INFO - __main__ - Step 440 Global step 440 Train loss 0.02 on epoch=219
04/27/2022 16:46:38 - INFO - __main__ - Step 450 Global step 450 Train loss 0.02 on epoch=224
04/27/2022 16:46:39 - INFO - __main__ - Global step 450 Train loss 0.03 ACC 0.5625 on epoch=224
04/27/2022 16:46:43 - INFO - __main__ - Step 460 Global step 460 Train loss 0.05 on epoch=229
04/27/2022 16:46:47 - INFO - __main__ - Step 470 Global step 470 Train loss 0.07 on epoch=234
04/27/2022 16:46:51 - INFO - __main__ - Step 480 Global step 480 Train loss 0.03 on epoch=239
04/27/2022 16:46:55 - INFO - __main__ - Step 490 Global step 490 Train loss 0.05 on epoch=244
04/27/2022 16:46:59 - INFO - __main__ - Step 500 Global step 500 Train loss 0.02 on epoch=249
04/27/2022 16:47:00 - INFO - __main__ - Global step 500 Train loss 0.04 ACC 0.59375 on epoch=249
04/27/2022 16:47:04 - INFO - __main__ - Step 510 Global step 510 Train loss 0.02 on epoch=254
04/27/2022 16:47:08 - INFO - __main__ - Step 520 Global step 520 Train loss 0.02 on epoch=259
04/27/2022 16:47:12 - INFO - __main__ - Step 530 Global step 530 Train loss 0.01 on epoch=264
04/27/2022 16:47:15 - INFO - __main__ - Step 540 Global step 540 Train loss 0.04 on epoch=269
04/27/2022 16:47:19 - INFO - __main__ - Step 550 Global step 550 Train loss 0.02 on epoch=274
04/27/2022 16:47:21 - INFO - __main__ - Global step 550 Train loss 0.02 ACC 0.65625 on epoch=274
04/27/2022 16:47:21 - INFO - __main__ - Saving model with best ACC: 0.625 -> 0.65625 on epoch=274, global_step=550
04/27/2022 16:47:25 - INFO - __main__ - Step 560 Global step 560 Train loss 0.01 on epoch=279
04/27/2022 16:47:29 - INFO - __main__ - Step 570 Global step 570 Train loss 0.02 on epoch=284
04/27/2022 16:47:32 - INFO - __main__ - Step 580 Global step 580 Train loss 0.03 on epoch=289
04/27/2022 16:47:36 - INFO - __main__ - Step 590 Global step 590 Train loss 0.01 on epoch=294
04/27/2022 16:47:40 - INFO - __main__ - Step 600 Global step 600 Train loss 0.01 on epoch=299
04/27/2022 16:47:42 - INFO - __main__ - Global step 600 Train loss 0.02 ACC 0.65625 on epoch=299
04/27/2022 16:47:45 - INFO - __main__ - Step 610 Global step 610 Train loss 0.03 on epoch=304
04/27/2022 16:47:49 - INFO - __main__ - Step 620 Global step 620 Train loss 0.02 on epoch=309
04/27/2022 16:47:53 - INFO - __main__ - Step 630 Global step 630 Train loss 0.02 on epoch=314
04/27/2022 16:47:57 - INFO - __main__ - Step 640 Global step 640 Train loss 0.02 on epoch=319
04/27/2022 16:48:01 - INFO - __main__ - Step 650 Global step 650 Train loss 0.05 on epoch=324
04/27/2022 16:48:03 - INFO - __main__ - Global step 650 Train loss 0.03 ACC 0.625 on epoch=324
04/27/2022 16:48:07 - INFO - __main__ - Step 660 Global step 660 Train loss 0.01 on epoch=329
04/27/2022 16:48:11 - INFO - __main__ - Step 670 Global step 670 Train loss 0.01 on epoch=334
04/27/2022 16:48:15 - INFO - __main__ - Step 680 Global step 680 Train loss 0.01 on epoch=339
04/27/2022 16:48:19 - INFO - __main__ - Step 690 Global step 690 Train loss 0.01 on epoch=344
04/27/2022 16:48:22 - INFO - __main__ - Step 700 Global step 700 Train loss 0.04 on epoch=349
04/27/2022 16:48:24 - INFO - __main__ - Global step 700 Train loss 0.02 ACC 0.59375 on epoch=349
04/27/2022 16:48:28 - INFO - __main__ - Step 710 Global step 710 Train loss 0.01 on epoch=354
04/27/2022 16:48:32 - INFO - __main__ - Step 720 Global step 720 Train loss 0.01 on epoch=359
04/27/2022 16:48:36 - INFO - __main__ - Step 730 Global step 730 Train loss 0.01 on epoch=364
04/27/2022 16:48:40 - INFO - __main__ - Step 740 Global step 740 Train loss 0.01 on epoch=369
04/27/2022 16:48:44 - INFO - __main__ - Step 750 Global step 750 Train loss 0.01 on epoch=374
04/27/2022 16:48:46 - INFO - __main__ - Global step 750 Train loss 0.01 ACC 0.625 on epoch=374
04/27/2022 16:48:49 - INFO - __main__ - Step 760 Global step 760 Train loss 0.02 on epoch=379
04/27/2022 16:48:53 - INFO - __main__ - Step 770 Global step 770 Train loss 0.02 on epoch=384
04/27/2022 16:48:57 - INFO - __main__ - Step 780 Global step 780 Train loss 0.01 on epoch=389
04/27/2022 16:49:01 - INFO - __main__ - Step 790 Global step 790 Train loss 0.02 on epoch=394
04/27/2022 16:49:05 - INFO - __main__ - Step 800 Global step 800 Train loss 0.05 on epoch=399
04/27/2022 16:49:08 - INFO - __main__ - Global step 800 Train loss 0.02 ACC 0.625 on epoch=399
04/27/2022 16:49:12 - INFO - __main__ - Step 810 Global step 810 Train loss 0.00 on epoch=404
04/27/2022 16:49:15 - INFO - __main__ - Step 820 Global step 820 Train loss 0.01 on epoch=409
04/27/2022 16:49:19 - INFO - __main__ - Step 830 Global step 830 Train loss 0.01 on epoch=414
04/27/2022 16:49:23 - INFO - __main__ - Step 840 Global step 840 Train loss 0.00 on epoch=419
04/27/2022 16:49:27 - INFO - __main__ - Step 850 Global step 850 Train loss 0.01 on epoch=424
04/27/2022 16:49:29 - INFO - __main__ - Global step 850 Train loss 0.01 ACC 0.6875 on epoch=424
04/27/2022 16:49:29 - INFO - __main__ - Saving model with best ACC: 0.65625 -> 0.6875 on epoch=424, global_step=850
04/27/2022 16:49:33 - INFO - __main__ - Step 860 Global step 860 Train loss 0.03 on epoch=429
04/27/2022 16:49:37 - INFO - __main__ - Step 870 Global step 870 Train loss 0.01 on epoch=434
04/27/2022 16:49:41 - INFO - __main__ - Step 880 Global step 880 Train loss 0.01 on epoch=439
04/27/2022 16:49:45 - INFO - __main__ - Step 890 Global step 890 Train loss 0.02 on epoch=444
04/27/2022 16:49:49 - INFO - __main__ - Step 900 Global step 900 Train loss 0.02 on epoch=449
04/27/2022 16:49:51 - INFO - __main__ - Global step 900 Train loss 0.02 ACC 0.71875 on epoch=449
04/27/2022 16:49:51 - INFO - __main__ - Saving model with best ACC: 0.6875 -> 0.71875 on epoch=449, global_step=900
04/27/2022 16:49:55 - INFO - __main__ - Step 910 Global step 910 Train loss 0.01 on epoch=454
04/27/2022 16:49:59 - INFO - __main__ - Step 920 Global step 920 Train loss 0.03 on epoch=459
04/27/2022 16:50:03 - INFO - __main__ - Step 930 Global step 930 Train loss 0.02 on epoch=464
04/27/2022 16:50:07 - INFO - __main__ - Step 940 Global step 940 Train loss 0.03 on epoch=469
04/27/2022 16:50:11 - INFO - __main__ - Step 950 Global step 950 Train loss 0.04 on epoch=474
04/27/2022 16:50:13 - INFO - __main__ - Global step 950 Train loss 0.02 ACC 0.65625 on epoch=474
04/27/2022 16:50:17 - INFO - __main__ - Step 960 Global step 960 Train loss 0.01 on epoch=479
04/27/2022 16:50:21 - INFO - __main__ - Step 970 Global step 970 Train loss 0.01 on epoch=484
04/27/2022 16:50:25 - INFO - __main__ - Step 980 Global step 980 Train loss 0.00 on epoch=489
04/27/2022 16:50:29 - INFO - __main__ - Step 990 Global step 990 Train loss 0.01 on epoch=494
04/27/2022 16:50:33 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.00 on epoch=499
04/27/2022 16:50:34 - INFO - __main__ - Global step 1000 Train loss 0.01 ACC 0.65625 on epoch=499
04/27/2022 16:50:38 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.00 on epoch=504
04/27/2022 16:50:42 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.00 on epoch=509
04/27/2022 16:50:46 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.01 on epoch=514
04/27/2022 16:50:50 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.03 on epoch=519
04/27/2022 16:50:54 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.01 on epoch=524
04/27/2022 16:50:56 - INFO - __main__ - Global step 1050 Train loss 0.01 ACC 0.71875 on epoch=524
04/27/2022 16:51:00 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.01 on epoch=529
04/27/2022 16:51:04 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.01 on epoch=534
04/27/2022 16:51:08 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.01 on epoch=539
04/27/2022 16:51:12 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.01 on epoch=544
04/27/2022 16:51:16 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.02 on epoch=549
04/27/2022 16:51:18 - INFO - __main__ - Global step 1100 Train loss 0.01 ACC 0.625 on epoch=549
04/27/2022 16:51:22 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.01 on epoch=554
04/27/2022 16:51:26 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.02 on epoch=559
04/27/2022 16:51:30 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.00 on epoch=564
04/27/2022 16:51:34 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.00 on epoch=569
04/27/2022 16:51:38 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.02 on epoch=574
04/27/2022 16:51:40 - INFO - __main__ - Global step 1150 Train loss 0.01 ACC 0.75 on epoch=574
04/27/2022 16:51:40 - INFO - __main__ - Saving model with best ACC: 0.71875 -> 0.75 on epoch=574, global_step=1150
04/27/2022 16:51:44 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.00 on epoch=579
04/27/2022 16:51:48 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.01 on epoch=584
04/27/2022 16:51:52 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.00 on epoch=589
04/27/2022 16:51:56 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.02 on epoch=594
04/27/2022 16:52:00 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=599
04/27/2022 16:52:02 - INFO - __main__ - Global step 1200 Train loss 0.01 ACC 0.6875 on epoch=599
04/27/2022 16:52:06 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.01 on epoch=604
04/27/2022 16:52:10 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=609
04/27/2022 16:52:14 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=614
04/27/2022 16:52:18 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=619
04/27/2022 16:52:22 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.00 on epoch=624
04/27/2022 16:52:24 - INFO - __main__ - Global step 1250 Train loss 0.01 ACC 0.71875 on epoch=624
04/27/2022 16:52:28 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.00 on epoch=629
04/27/2022 16:52:32 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.01 on epoch=634
04/27/2022 16:52:36 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=639
04/27/2022 16:52:40 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=644
04/27/2022 16:52:44 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=649
04/27/2022 16:52:46 - INFO - __main__ - Global step 1300 Train loss 0.01 ACC 0.71875 on epoch=649
04/27/2022 16:52:50 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=654
04/27/2022 16:52:54 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=659
04/27/2022 16:52:58 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=664
04/27/2022 16:53:01 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=669
04/27/2022 16:53:05 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.00 on epoch=674
04/27/2022 16:53:08 - INFO - __main__ - Global step 1350 Train loss 0.01 ACC 0.65625 on epoch=674
04/27/2022 16:53:12 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.00 on epoch=679
04/27/2022 16:53:16 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.00 on epoch=684
04/27/2022 16:53:20 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.00 on epoch=689
04/27/2022 16:53:24 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=694
04/27/2022 16:53:28 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.00 on epoch=699
04/27/2022 16:53:30 - INFO - __main__ - Global step 1400 Train loss 0.00 ACC 0.625 on epoch=699
04/27/2022 16:53:34 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=704
04/27/2022 16:53:37 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.01 on epoch=709
04/27/2022 16:53:41 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.00 on epoch=714
04/27/2022 16:53:45 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=719
04/27/2022 16:53:49 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=724
04/27/2022 16:53:51 - INFO - __main__ - Global step 1450 Train loss 0.00 ACC 0.6875 on epoch=724
04/27/2022 16:53:55 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=729
04/27/2022 16:53:59 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.05 on epoch=734
04/27/2022 16:54:03 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.05 on epoch=739
04/27/2022 16:54:07 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=744
04/27/2022 16:54:11 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=749
04/27/2022 16:54:13 - INFO - __main__ - Global step 1500 Train loss 0.02 ACC 0.6875 on epoch=749
04/27/2022 16:54:17 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=754
04/27/2022 16:54:21 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=759
04/27/2022 16:54:24 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=764
04/27/2022 16:54:28 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=769
04/27/2022 16:54:32 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=774
04/27/2022 16:54:34 - INFO - __main__ - Global step 1550 Train loss 0.01 ACC 0.625 on epoch=774
04/27/2022 16:54:38 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=779
04/27/2022 16:54:42 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=784
04/27/2022 16:54:46 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=789
04/27/2022 16:54:50 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=794
04/27/2022 16:54:54 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=799
04/27/2022 16:54:56 - INFO - __main__ - Global step 1600 Train loss 0.01 ACC 0.71875 on epoch=799
04/27/2022 16:55:00 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=804
04/27/2022 16:55:03 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=809
04/27/2022 16:55:07 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=814
04/27/2022 16:55:11 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=819
04/27/2022 16:55:15 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=824
04/27/2022 16:55:17 - INFO - __main__ - Global step 1650 Train loss 0.00 ACC 0.65625 on epoch=824
04/27/2022 16:55:21 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=829
04/27/2022 16:55:25 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=834
04/27/2022 16:55:29 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=839
04/27/2022 16:55:33 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=844
04/27/2022 16:55:37 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=849
04/27/2022 16:55:39 - INFO - __main__ - Global step 1700 Train loss 0.01 ACC 0.71875 on epoch=849
04/27/2022 16:55:43 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=854
04/27/2022 16:55:46 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=859
04/27/2022 16:55:50 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=864
04/27/2022 16:55:54 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=869
04/27/2022 16:55:58 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=874
04/27/2022 16:56:00 - INFO - __main__ - Global step 1750 Train loss 0.00 ACC 0.6875 on epoch=874
04/27/2022 16:56:04 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=879
04/27/2022 16:56:08 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=884
04/27/2022 16:56:12 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=889
04/27/2022 16:56:16 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=894
04/27/2022 16:56:20 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=899
04/27/2022 16:56:22 - INFO - __main__ - Global step 1800 Train loss 0.00 ACC 0.65625 on epoch=899
04/27/2022 16:56:26 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=904
04/27/2022 16:56:30 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=909
04/27/2022 16:56:33 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=914
04/27/2022 16:56:37 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=919
04/27/2022 16:56:41 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=924
04/27/2022 16:56:43 - INFO - __main__ - Global step 1850 Train loss 0.01 ACC 0.625 on epoch=924
04/27/2022 16:56:47 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=929
04/27/2022 16:56:51 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=934
04/27/2022 16:56:55 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=939
04/27/2022 16:56:59 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=944
04/27/2022 16:57:03 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=949
04/27/2022 16:57:05 - INFO - __main__ - Global step 1900 Train loss 0.00 ACC 0.6875 on epoch=949
04/27/2022 16:57:09 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=954
04/27/2022 16:57:13 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=959
04/27/2022 16:57:16 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=964
04/27/2022 16:57:20 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=969
04/27/2022 16:57:24 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=974
04/27/2022 16:57:26 - INFO - __main__ - Global step 1950 Train loss 0.00 ACC 0.71875 on epoch=974
04/27/2022 16:57:30 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=979
04/27/2022 16:57:34 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=984
04/27/2022 16:57:38 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=989
04/27/2022 16:57:42 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=994
04/27/2022 16:57:46 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=999
04/27/2022 16:57:48 - INFO - __main__ - Global step 2000 Train loss 0.01 ACC 0.65625 on epoch=999
04/27/2022 16:57:48 - INFO - __main__ - save last model!
04/27/2022 16:57:48 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
04/27/2022 16:57:48 - INFO - __main__ - Start tokenizing ... 887 instances
04/27/2022 16:57:48 - INFO - __main__ - Printing 3 examples
04/27/2022 16:57:48 - INFO - __main__ -  [sciq] A frameshift mutation is a deletion or insertion of one or more of what that changes the reading frame of the base sequence? (A) carotenoids (B) nucleotides (C) proteins (D) genes [SEP] A frameshift mutation is a deletion or insertion of one or more nucleotides that changes the reading frame of the base sequence. Deletions remove nucleotides, and insertions add nucleotides. Consider the following sequence of bases in RNA:.
04/27/2022 16:57:48 - INFO - __main__ - ['nucleotides']
04/27/2022 16:57:48 - INFO - __main__ -  [sciq] What is an area of land called that is wet for all or part of the year? (A) grassland (B) wetland (C) plains (D) tundra [SEP] A wetland is an area that is wet for all or part of the year. Wetlands are home to certain types of plants.
04/27/2022 16:57:48 - INFO - __main__ - ['wetland']
04/27/2022 16:57:48 - INFO - __main__ -  [sciq] What are arteries, veins, and capillaries examples of? (A) blood vessels (B) muscles (C) organs (D) tissue [SEP] Blood vessels include arteries, veins, and capillaries.
04/27/2022 16:57:48 - INFO - __main__ - ['blood vessels']
04/27/2022 16:57:48 - INFO - __main__ - Tokenizing Input ...
04/27/2022 16:57:49 - INFO - __main__ - Tokenizing Output ...
04/27/2022 16:57:49 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 16:57:49 - INFO - __main__ - Printing 3 examples
04/27/2022 16:57:49 - INFO - __main__ -  [sciq] What zone is outside the radiative zone? (A) diffusion zone (B) peripheral zone (C) activation zone (D) convection zone [SEP] The convection zone is where convection takes place. It is located outward from the radiative zone.
04/27/2022 16:57:49 - INFO - __main__ - ['convection zone']
04/27/2022 16:57:49 - INFO - __main__ -  [sciq] What planet has the most volcanoes? (A) uranus (B) Earth (C) Mars (D) venus [SEP] Venus has more volcanoes than any other planet. There are between 100,000 and one million volcanoes on Venus! Most of the volcanoes are now inactive. There are also a large number of craters. This means that Venus doesn’t have tectonic plates. Plate tectonics on Earth erases features over time. Figure below is an image made using radar data. The volcano is Maat Mons. Lava beds are in the foreground. Scientists think the color of sunlight on Venus is reddish-brown.
04/27/2022 16:57:49 - INFO - __main__ - ['venus']
04/27/2022 16:57:49 - INFO - __main__ -  [sciq] Where are the oceans most polluted? (A) along reefs (B) on the ocean floor (C) along coasts (D) in warmer waters [SEP] The oceans are most polluted along coasts. Why do you think that's the case? Of course, it's because most pollution enters the oceans from the land. Runoff and rivers carry the majority of pollution into the ocean. Many cities dump their wastewater , water mixed with waste, directly into coastal waters. In some parts of the world, raw sewage and trash may be thrown into the water ( Figure below ). Coastal water may become so polluted that people get sick if they swim in it or eat seafood from it. The polluted water may also kill fish and other ocean life.
04/27/2022 16:57:49 - INFO - __main__ - ['along coasts']
04/27/2022 16:57:49 - INFO - __main__ - Tokenizing Input ...
04/27/2022 16:57:49 - INFO - __main__ - Tokenizing Output ...
04/27/2022 16:57:49 - INFO - __main__ - Loaded 32 examples from train data
04/27/2022 16:57:49 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 16:57:49 - INFO - __main__ - Printing 3 examples
04/27/2022 16:57:49 - INFO - __main__ -  [sciq] Viruses depend on what type of cells? (A) anchor cells (B) host cells (C) immune system cells (D) blood cells [SEP] Briefly describe how viruses depend on host cells.
04/27/2022 16:57:49 - INFO - __main__ - ['host cells']
04/27/2022 16:57:49 - INFO - __main__ -  [sciq] What is the time interval required for one complete wave to pass a point called? (A) cycle (B) minute (C) half-life (D) period [SEP] The time interval required for one complete wave to pass a point is called the period . During the period of the wave, an entire wavelength from one crest to the next crest passes a position. The number of waves that pass a single position in one second is called the frequency . The period of a wave and its frequency are reciprocals of each other.
04/27/2022 16:57:49 - INFO - __main__ - ['period']
04/27/2022 16:57:49 - INFO - __main__ -  [sciq] What layer of soil, essential for farming, has the highest proportion of organic material? (A) subsoil (B) bedrock (C) topsoil (D) humus [SEP] Topsoil has the highest proportion of organic material. Topsoil is essential for farming.
04/27/2022 16:57:49 - INFO - __main__ - ['topsoil']
04/27/2022 16:57:49 - INFO - __main__ - Tokenizing Input ...
04/27/2022 16:57:49 - INFO - __main__ - Tokenizing Output ...
04/27/2022 16:57:49 - INFO - __main__ - Loaded 32 examples from dev data
04/27/2022 16:57:50 - INFO - __main__ - Loaded 887 examples from test data
04/27/2022 16:58:04 - INFO - __main__ - load prompt embedding from ckpt
04/27/2022 16:58:04 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/27/2022 16:58:04 - INFO - __main__ - Starting training!
04/27/2022 16:58:39 - INFO - __main__ - Saved prediction in models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-sciq/sciq_32_100_0.3_8_predictions.txt
04/27/2022 16:58:39 - INFO - __main__ - ACC on test data: 0.7599
04/27/2022 16:58:39 - INFO - __main__ - prefix=sciq_32_100, lr=0.3, bsz=8, dev_performance=0.75, test_performance=0.7598647125140925
04/27/2022 16:58:39 - INFO - __main__ - Running ... prefix=sciq_32_100, lr=0.2, bsz=8 ...
04/27/2022 16:58:40 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 16:58:40 - INFO - __main__ - Printing 3 examples
04/27/2022 16:58:40 - INFO - __main__ -  [sciq] What zone is outside the radiative zone? (A) diffusion zone (B) peripheral zone (C) activation zone (D) convection zone [SEP] The convection zone is where convection takes place. It is located outward from the radiative zone.
04/27/2022 16:58:40 - INFO - __main__ - ['convection zone']
04/27/2022 16:58:40 - INFO - __main__ -  [sciq] What planet has the most volcanoes? (A) uranus (B) Earth (C) Mars (D) venus [SEP] Venus has more volcanoes than any other planet. There are between 100,000 and one million volcanoes on Venus! Most of the volcanoes are now inactive. There are also a large number of craters. This means that Venus doesn’t have tectonic plates. Plate tectonics on Earth erases features over time. Figure below is an image made using radar data. The volcano is Maat Mons. Lava beds are in the foreground. Scientists think the color of sunlight on Venus is reddish-brown.
04/27/2022 16:58:40 - INFO - __main__ - ['venus']
04/27/2022 16:58:40 - INFO - __main__ -  [sciq] Where are the oceans most polluted? (A) along reefs (B) on the ocean floor (C) along coasts (D) in warmer waters [SEP] The oceans are most polluted along coasts. Why do you think that's the case? Of course, it's because most pollution enters the oceans from the land. Runoff and rivers carry the majority of pollution into the ocean. Many cities dump their wastewater , water mixed with waste, directly into coastal waters. In some parts of the world, raw sewage and trash may be thrown into the water ( Figure below ). Coastal water may become so polluted that people get sick if they swim in it or eat seafood from it. The polluted water may also kill fish and other ocean life.
04/27/2022 16:58:40 - INFO - __main__ - ['along coasts']
04/27/2022 16:58:40 - INFO - __main__ - Tokenizing Input ...
04/27/2022 16:58:40 - INFO - __main__ - Tokenizing Output ...
04/27/2022 16:58:40 - INFO - __main__ - Loaded 32 examples from train data
04/27/2022 16:58:40 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 16:58:40 - INFO - __main__ - Printing 3 examples
04/27/2022 16:58:40 - INFO - __main__ -  [sciq] Viruses depend on what type of cells? (A) anchor cells (B) host cells (C) immune system cells (D) blood cells [SEP] Briefly describe how viruses depend on host cells.
04/27/2022 16:58:40 - INFO - __main__ - ['host cells']
04/27/2022 16:58:40 - INFO - __main__ -  [sciq] What is the time interval required for one complete wave to pass a point called? (A) cycle (B) minute (C) half-life (D) period [SEP] The time interval required for one complete wave to pass a point is called the period . During the period of the wave, an entire wavelength from one crest to the next crest passes a position. The number of waves that pass a single position in one second is called the frequency . The period of a wave and its frequency are reciprocals of each other.
04/27/2022 16:58:40 - INFO - __main__ - ['period']
04/27/2022 16:58:40 - INFO - __main__ -  [sciq] What layer of soil, essential for farming, has the highest proportion of organic material? (A) subsoil (B) bedrock (C) topsoil (D) humus [SEP] Topsoil has the highest proportion of organic material. Topsoil is essential for farming.
04/27/2022 16:58:40 - INFO - __main__ - ['topsoil']
04/27/2022 16:58:40 - INFO - __main__ - Tokenizing Input ...
04/27/2022 16:58:40 - INFO - __main__ - Tokenizing Output ...
04/27/2022 16:58:40 - INFO - __main__ - Loaded 32 examples from dev data
04/27/2022 16:58:57 - INFO - __main__ - load prompt embedding from ckpt
04/27/2022 16:58:58 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/27/2022 16:58:58 - INFO - __main__ - Starting training!
04/27/2022 16:59:02 - INFO - __main__ - Step 10 Global step 10 Train loss 3.15 on epoch=4
04/27/2022 16:59:06 - INFO - __main__ - Step 20 Global step 20 Train loss 2.04 on epoch=9
04/27/2022 16:59:10 - INFO - __main__ - Step 30 Global step 30 Train loss 1.08 on epoch=14
04/27/2022 16:59:14 - INFO - __main__ - Step 40 Global step 40 Train loss 0.86 on epoch=19
04/27/2022 16:59:18 - INFO - __main__ - Step 50 Global step 50 Train loss 0.57 on epoch=24
04/27/2022 16:59:20 - INFO - __main__ - Global step 50 Train loss 1.54 ACC 0.40625 on epoch=24
04/27/2022 16:59:20 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.40625 on epoch=24, global_step=50
04/27/2022 16:59:24 - INFO - __main__ - Step 60 Global step 60 Train loss 0.48 on epoch=29
04/27/2022 16:59:28 - INFO - __main__ - Step 70 Global step 70 Train loss 0.52 on epoch=34
04/27/2022 16:59:32 - INFO - __main__ - Step 80 Global step 80 Train loss 0.42 on epoch=39
04/27/2022 16:59:36 - INFO - __main__ - Step 90 Global step 90 Train loss 0.38 on epoch=44
04/27/2022 16:59:39 - INFO - __main__ - Step 100 Global step 100 Train loss 0.37 on epoch=49
04/27/2022 16:59:41 - INFO - __main__ - Global step 100 Train loss 0.44 ACC 0.5 on epoch=49
04/27/2022 16:59:41 - INFO - __main__ - Saving model with best ACC: 0.40625 -> 0.5 on epoch=49, global_step=100
04/27/2022 16:59:45 - INFO - __main__ - Step 110 Global step 110 Train loss 0.29 on epoch=54
04/27/2022 16:59:49 - INFO - __main__ - Step 120 Global step 120 Train loss 0.32 on epoch=59
04/27/2022 16:59:53 - INFO - __main__ - Step 130 Global step 130 Train loss 0.25 on epoch=64
04/27/2022 16:59:56 - INFO - __main__ - Step 140 Global step 140 Train loss 0.25 on epoch=69
04/27/2022 17:00:00 - INFO - __main__ - Step 150 Global step 150 Train loss 0.27 on epoch=74
04/27/2022 17:00:02 - INFO - __main__ - Global step 150 Train loss 0.28 ACC 0.5 on epoch=74
04/27/2022 17:00:06 - INFO - __main__ - Step 160 Global step 160 Train loss 0.22 on epoch=79
04/27/2022 17:00:10 - INFO - __main__ - Step 170 Global step 170 Train loss 0.27 on epoch=84
04/27/2022 17:00:13 - INFO - __main__ - Step 180 Global step 180 Train loss 0.20 on epoch=89
04/27/2022 17:00:17 - INFO - __main__ - Step 190 Global step 190 Train loss 0.21 on epoch=94
04/27/2022 17:00:21 - INFO - __main__ - Step 200 Global step 200 Train loss 0.22 on epoch=99
04/27/2022 17:00:22 - INFO - __main__ - Global step 200 Train loss 0.22 ACC 0.46875 on epoch=99
04/27/2022 17:00:26 - INFO - __main__ - Step 210 Global step 210 Train loss 0.24 on epoch=104
04/27/2022 17:00:30 - INFO - __main__ - Step 220 Global step 220 Train loss 0.20 on epoch=109
04/27/2022 17:00:34 - INFO - __main__ - Step 230 Global step 230 Train loss 0.16 on epoch=114
04/27/2022 17:00:38 - INFO - __main__ - Step 240 Global step 240 Train loss 0.14 on epoch=119
04/27/2022 17:00:42 - INFO - __main__ - Step 250 Global step 250 Train loss 0.13 on epoch=124
04/27/2022 17:00:43 - INFO - __main__ - Global step 250 Train loss 0.18 ACC 0.5 on epoch=124
04/27/2022 17:00:47 - INFO - __main__ - Step 260 Global step 260 Train loss 0.13 on epoch=129
04/27/2022 17:00:51 - INFO - __main__ - Step 270 Global step 270 Train loss 0.13 on epoch=134
04/27/2022 17:00:55 - INFO - __main__ - Step 280 Global step 280 Train loss 0.13 on epoch=139
04/27/2022 17:00:59 - INFO - __main__ - Step 290 Global step 290 Train loss 0.08 on epoch=144
04/27/2022 17:01:03 - INFO - __main__ - Step 300 Global step 300 Train loss 0.11 on epoch=149
04/27/2022 17:01:04 - INFO - __main__ - Global step 300 Train loss 0.12 ACC 0.4375 on epoch=149
04/27/2022 17:01:08 - INFO - __main__ - Step 310 Global step 310 Train loss 0.08 on epoch=154
04/27/2022 17:01:12 - INFO - __main__ - Step 320 Global step 320 Train loss 0.11 on epoch=159
04/27/2022 17:01:15 - INFO - __main__ - Step 330 Global step 330 Train loss 0.14 on epoch=164
04/27/2022 17:01:19 - INFO - __main__ - Step 340 Global step 340 Train loss 0.07 on epoch=169
04/27/2022 17:01:23 - INFO - __main__ - Step 350 Global step 350 Train loss 0.06 on epoch=174
04/27/2022 17:01:24 - INFO - __main__ - Global step 350 Train loss 0.09 ACC 0.5 on epoch=174
04/27/2022 17:01:28 - INFO - __main__ - Step 360 Global step 360 Train loss 0.11 on epoch=179
04/27/2022 17:01:32 - INFO - __main__ - Step 370 Global step 370 Train loss 0.08 on epoch=184
04/27/2022 17:01:36 - INFO - __main__ - Step 380 Global step 380 Train loss 0.13 on epoch=189
04/27/2022 17:01:40 - INFO - __main__ - Step 390 Global step 390 Train loss 0.05 on epoch=194
04/27/2022 17:01:44 - INFO - __main__ - Step 400 Global step 400 Train loss 0.07 on epoch=199
04/27/2022 17:01:45 - INFO - __main__ - Global step 400 Train loss 0.09 ACC 0.5625 on epoch=199
04/27/2022 17:01:45 - INFO - __main__ - Saving model with best ACC: 0.5 -> 0.5625 on epoch=199, global_step=400
04/27/2022 17:01:49 - INFO - __main__ - Step 410 Global step 410 Train loss 0.07 on epoch=204
04/27/2022 17:01:53 - INFO - __main__ - Step 420 Global step 420 Train loss 0.07 on epoch=209
04/27/2022 17:01:57 - INFO - __main__ - Step 430 Global step 430 Train loss 0.05 on epoch=214
04/27/2022 17:02:01 - INFO - __main__ - Step 440 Global step 440 Train loss 0.05 on epoch=219
04/27/2022 17:02:05 - INFO - __main__ - Step 450 Global step 450 Train loss 0.07 on epoch=224
04/27/2022 17:02:06 - INFO - __main__ - Global step 450 Train loss 0.06 ACC 0.59375 on epoch=224
04/27/2022 17:02:06 - INFO - __main__ - Saving model with best ACC: 0.5625 -> 0.59375 on epoch=224, global_step=450
04/27/2022 17:02:10 - INFO - __main__ - Step 460 Global step 460 Train loss 0.07 on epoch=229
04/27/2022 17:02:14 - INFO - __main__ - Step 470 Global step 470 Train loss 0.06 on epoch=234
04/27/2022 17:02:18 - INFO - __main__ - Step 480 Global step 480 Train loss 0.04 on epoch=239
04/27/2022 17:02:22 - INFO - __main__ - Step 490 Global step 490 Train loss 0.05 on epoch=244
04/27/2022 17:02:26 - INFO - __main__ - Step 500 Global step 500 Train loss 0.03 on epoch=249
04/27/2022 17:02:27 - INFO - __main__ - Global step 500 Train loss 0.05 ACC 0.625 on epoch=249
04/27/2022 17:02:27 - INFO - __main__ - Saving model with best ACC: 0.59375 -> 0.625 on epoch=249, global_step=500
04/27/2022 17:02:31 - INFO - __main__ - Step 510 Global step 510 Train loss 0.04 on epoch=254
04/27/2022 17:02:35 - INFO - __main__ - Step 520 Global step 520 Train loss 0.03 on epoch=259
04/27/2022 17:02:39 - INFO - __main__ - Step 530 Global step 530 Train loss 0.05 on epoch=264
04/27/2022 17:02:42 - INFO - __main__ - Step 540 Global step 540 Train loss 0.05 on epoch=269
04/27/2022 17:02:46 - INFO - __main__ - Step 550 Global step 550 Train loss 0.03 on epoch=274
04/27/2022 17:02:48 - INFO - __main__ - Global step 550 Train loss 0.04 ACC 0.53125 on epoch=274
04/27/2022 17:02:51 - INFO - __main__ - Step 560 Global step 560 Train loss 0.04 on epoch=279
04/27/2022 17:02:55 - INFO - __main__ - Step 570 Global step 570 Train loss 0.02 on epoch=284
04/27/2022 17:02:59 - INFO - __main__ - Step 580 Global step 580 Train loss 0.05 on epoch=289
04/27/2022 17:03:03 - INFO - __main__ - Step 590 Global step 590 Train loss 0.02 on epoch=294
04/27/2022 17:03:07 - INFO - __main__ - Step 600 Global step 600 Train loss 0.03 on epoch=299
04/27/2022 17:03:09 - INFO - __main__ - Global step 600 Train loss 0.03 ACC 0.5625 on epoch=299
04/27/2022 17:03:12 - INFO - __main__ - Step 610 Global step 610 Train loss 0.03 on epoch=304
04/27/2022 17:03:16 - INFO - __main__ - Step 620 Global step 620 Train loss 0.02 on epoch=309
04/27/2022 17:03:20 - INFO - __main__ - Step 630 Global step 630 Train loss 0.03 on epoch=314
04/27/2022 17:03:24 - INFO - __main__ - Step 640 Global step 640 Train loss 0.02 on epoch=319
04/27/2022 17:03:28 - INFO - __main__ - Step 650 Global step 650 Train loss 0.03 on epoch=324
04/27/2022 17:03:29 - INFO - __main__ - Global step 650 Train loss 0.03 ACC 0.65625 on epoch=324
04/27/2022 17:03:29 - INFO - __main__ - Saving model with best ACC: 0.625 -> 0.65625 on epoch=324, global_step=650
04/27/2022 17:03:33 - INFO - __main__ - Step 660 Global step 660 Train loss 0.03 on epoch=329
04/27/2022 17:03:37 - INFO - __main__ - Step 670 Global step 670 Train loss 0.04 on epoch=334
04/27/2022 17:03:41 - INFO - __main__ - Step 680 Global step 680 Train loss 0.04 on epoch=339
04/27/2022 17:03:45 - INFO - __main__ - Step 690 Global step 690 Train loss 0.04 on epoch=344
04/27/2022 17:03:49 - INFO - __main__ - Step 700 Global step 700 Train loss 0.04 on epoch=349
04/27/2022 17:03:50 - INFO - __main__ - Global step 700 Train loss 0.04 ACC 0.59375 on epoch=349
04/27/2022 17:03:54 - INFO - __main__ - Step 710 Global step 710 Train loss 0.02 on epoch=354
04/27/2022 17:03:58 - INFO - __main__ - Step 720 Global step 720 Train loss 0.03 on epoch=359
04/27/2022 17:04:02 - INFO - __main__ - Step 730 Global step 730 Train loss 0.03 on epoch=364
04/27/2022 17:04:06 - INFO - __main__ - Step 740 Global step 740 Train loss 0.03 on epoch=369
04/27/2022 17:04:10 - INFO - __main__ - Step 750 Global step 750 Train loss 0.03 on epoch=374
04/27/2022 17:04:11 - INFO - __main__ - Global step 750 Train loss 0.03 ACC 0.5625 on epoch=374
04/27/2022 17:04:15 - INFO - __main__ - Step 760 Global step 760 Train loss 0.02 on epoch=379
04/27/2022 17:04:19 - INFO - __main__ - Step 770 Global step 770 Train loss 0.02 on epoch=384
04/27/2022 17:04:23 - INFO - __main__ - Step 780 Global step 780 Train loss 0.02 on epoch=389
04/27/2022 17:04:27 - INFO - __main__ - Step 790 Global step 790 Train loss 0.04 on epoch=394
04/27/2022 17:04:31 - INFO - __main__ - Step 800 Global step 800 Train loss 0.03 on epoch=399
04/27/2022 17:04:33 - INFO - __main__ - Global step 800 Train loss 0.03 ACC 0.625 on epoch=399
04/27/2022 17:04:37 - INFO - __main__ - Step 810 Global step 810 Train loss 0.02 on epoch=404
04/27/2022 17:04:40 - INFO - __main__ - Step 820 Global step 820 Train loss 0.05 on epoch=409
04/27/2022 17:04:44 - INFO - __main__ - Step 830 Global step 830 Train loss 0.02 on epoch=414
04/27/2022 17:04:48 - INFO - __main__ - Step 840 Global step 840 Train loss 0.01 on epoch=419
04/27/2022 17:04:52 - INFO - __main__ - Step 850 Global step 850 Train loss 0.02 on epoch=424
04/27/2022 17:04:54 - INFO - __main__ - Global step 850 Train loss 0.03 ACC 0.5625 on epoch=424
04/27/2022 17:04:58 - INFO - __main__ - Step 860 Global step 860 Train loss 0.02 on epoch=429
04/27/2022 17:05:02 - INFO - __main__ - Step 870 Global step 870 Train loss 0.02 on epoch=434
04/27/2022 17:05:06 - INFO - __main__ - Step 880 Global step 880 Train loss 0.06 on epoch=439
04/27/2022 17:05:10 - INFO - __main__ - Step 890 Global step 890 Train loss 0.03 on epoch=444
04/27/2022 17:05:13 - INFO - __main__ - Step 900 Global step 900 Train loss 0.02 on epoch=449
04/27/2022 17:05:15 - INFO - __main__ - Global step 900 Train loss 0.03 ACC 0.71875 on epoch=449
04/27/2022 17:05:15 - INFO - __main__ - Saving model with best ACC: 0.65625 -> 0.71875 on epoch=449, global_step=900
04/27/2022 17:05:19 - INFO - __main__ - Step 910 Global step 910 Train loss 0.01 on epoch=454
04/27/2022 17:05:23 - INFO - __main__ - Step 920 Global step 920 Train loss 0.01 on epoch=459
04/27/2022 17:05:27 - INFO - __main__ - Step 930 Global step 930 Train loss 0.03 on epoch=464
04/27/2022 17:05:31 - INFO - __main__ - Step 940 Global step 940 Train loss 0.01 on epoch=469
04/27/2022 17:05:35 - INFO - __main__ - Step 950 Global step 950 Train loss 0.01 on epoch=474
04/27/2022 17:05:36 - INFO - __main__ - Global step 950 Train loss 0.02 ACC 0.59375 on epoch=474
04/27/2022 17:05:40 - INFO - __main__ - Step 960 Global step 960 Train loss 0.01 on epoch=479
04/27/2022 17:05:44 - INFO - __main__ - Step 970 Global step 970 Train loss 0.03 on epoch=484
04/27/2022 17:05:48 - INFO - __main__ - Step 980 Global step 980 Train loss 0.01 on epoch=489
04/27/2022 17:05:52 - INFO - __main__ - Step 990 Global step 990 Train loss 0.01 on epoch=494
04/27/2022 17:05:56 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.01 on epoch=499
04/27/2022 17:05:58 - INFO - __main__ - Global step 1000 Train loss 0.01 ACC 0.5625 on epoch=499
04/27/2022 17:06:02 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.05 on epoch=504
04/27/2022 17:06:05 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.02 on epoch=509
04/27/2022 17:06:09 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.01 on epoch=514
04/27/2022 17:06:13 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.02 on epoch=519
04/27/2022 17:06:17 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.02 on epoch=524
04/27/2022 17:06:19 - INFO - __main__ - Global step 1050 Train loss 0.02 ACC 0.65625 on epoch=524
04/27/2022 17:06:23 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.02 on epoch=529
04/27/2022 17:06:27 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.04 on epoch=534
04/27/2022 17:06:31 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.01 on epoch=539
04/27/2022 17:06:35 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.01 on epoch=544
04/27/2022 17:06:39 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.01 on epoch=549
04/27/2022 17:06:40 - INFO - __main__ - Global step 1100 Train loss 0.02 ACC 0.75 on epoch=549
04/27/2022 17:06:40 - INFO - __main__ - Saving model with best ACC: 0.71875 -> 0.75 on epoch=549, global_step=1100
04/27/2022 17:06:44 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.01 on epoch=554
04/27/2022 17:06:48 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=559
04/27/2022 17:06:52 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=564
04/27/2022 17:06:56 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.01 on epoch=569
04/27/2022 17:07:00 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=574
04/27/2022 17:07:02 - INFO - __main__ - Global step 1150 Train loss 0.01 ACC 0.71875 on epoch=574
04/27/2022 17:07:06 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.02 on epoch=579
04/27/2022 17:07:10 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.02 on epoch=584
04/27/2022 17:07:14 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.01 on epoch=589
04/27/2022 17:07:17 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.02 on epoch=594
04/27/2022 17:07:21 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=599
04/27/2022 17:07:23 - INFO - __main__ - Global step 1200 Train loss 0.01 ACC 0.6875 on epoch=599
04/27/2022 17:07:27 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.03 on epoch=604
04/27/2022 17:07:31 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=609
04/27/2022 17:07:35 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.02 on epoch=614
04/27/2022 17:07:39 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=619
04/27/2022 17:07:43 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.01 on epoch=624
04/27/2022 17:07:44 - INFO - __main__ - Global step 1250 Train loss 0.02 ACC 0.65625 on epoch=624
04/27/2022 17:07:48 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=629
04/27/2022 17:07:52 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.03 on epoch=634
04/27/2022 17:07:56 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=639
04/27/2022 17:08:00 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.00 on epoch=644
04/27/2022 17:08:04 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.02 on epoch=649
04/27/2022 17:08:06 - INFO - __main__ - Global step 1300 Train loss 0.01 ACC 0.71875 on epoch=649
04/27/2022 17:08:10 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=654
04/27/2022 17:08:14 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.07 on epoch=659
04/27/2022 17:08:18 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=664
04/27/2022 17:08:22 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=669
04/27/2022 17:08:26 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=674
04/27/2022 17:08:27 - INFO - __main__ - Global step 1350 Train loss 0.02 ACC 0.6875 on epoch=674
04/27/2022 17:08:31 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=679
04/27/2022 17:08:35 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=684
04/27/2022 17:08:39 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=689
04/27/2022 17:08:43 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=694
04/27/2022 17:08:47 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=699
04/27/2022 17:08:49 - INFO - __main__ - Global step 1400 Train loss 0.01 ACC 0.75 on epoch=699
04/27/2022 17:08:53 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=704
04/27/2022 17:08:57 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=709
04/27/2022 17:09:01 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=714
04/27/2022 17:09:05 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=719
04/27/2022 17:09:09 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=724
04/27/2022 17:09:11 - INFO - __main__ - Global step 1450 Train loss 0.01 ACC 0.71875 on epoch=724
04/27/2022 17:09:15 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=729
04/27/2022 17:09:19 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=734
04/27/2022 17:09:23 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=739
04/27/2022 17:09:27 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=744
04/27/2022 17:09:31 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=749
04/27/2022 17:09:34 - INFO - __main__ - Global step 1500 Train loss 0.01 ACC 0.6875 on epoch=749
04/27/2022 17:09:37 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=754
04/27/2022 17:09:41 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=759
04/27/2022 17:09:45 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=764
04/27/2022 17:09:49 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=769
04/27/2022 17:09:53 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.03 on epoch=774
04/27/2022 17:09:55 - INFO - __main__ - Global step 1550 Train loss 0.01 ACC 0.6875 on epoch=774
04/27/2022 17:09:59 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.02 on epoch=779
04/27/2022 17:10:03 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=784
04/27/2022 17:10:07 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=789
04/27/2022 17:10:11 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.03 on epoch=794
04/27/2022 17:10:15 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=799
04/27/2022 17:10:17 - INFO - __main__ - Global step 1600 Train loss 0.01 ACC 0.6875 on epoch=799
04/27/2022 17:10:20 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=804
04/27/2022 17:10:24 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=809
04/27/2022 17:10:28 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=814
04/27/2022 17:10:32 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.02 on epoch=819
04/27/2022 17:10:36 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=824
04/27/2022 17:10:38 - INFO - __main__ - Global step 1650 Train loss 0.01 ACC 0.78125 on epoch=824
04/27/2022 17:10:38 - INFO - __main__ - Saving model with best ACC: 0.75 -> 0.78125 on epoch=824, global_step=1650
04/27/2022 17:10:42 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=829
04/27/2022 17:10:46 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=834
04/27/2022 17:10:50 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=839
04/27/2022 17:10:54 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=844
04/27/2022 17:10:58 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=849
04/27/2022 17:11:00 - INFO - __main__ - Global step 1700 Train loss 0.01 ACC 0.84375 on epoch=849
04/27/2022 17:11:01 - INFO - __main__ - Saving model with best ACC: 0.78125 -> 0.84375 on epoch=849, global_step=1700
04/27/2022 17:11:04 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=854
04/27/2022 17:11:08 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=859
04/27/2022 17:11:12 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.04 on epoch=864
04/27/2022 17:11:16 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=869
04/27/2022 17:11:20 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=874
04/27/2022 17:11:22 - INFO - __main__ - Global step 1750 Train loss 0.01 ACC 0.75 on epoch=874
04/27/2022 17:11:26 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=879
04/27/2022 17:11:30 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=884
04/27/2022 17:11:34 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=889
04/27/2022 17:11:38 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.03 on epoch=894
04/27/2022 17:11:42 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=899
04/27/2022 17:11:44 - INFO - __main__ - Global step 1800 Train loss 0.01 ACC 0.8125 on epoch=899
04/27/2022 17:11:48 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=904
04/27/2022 17:11:52 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=909
04/27/2022 17:11:56 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=914
04/27/2022 17:12:00 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=919
04/27/2022 17:12:04 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=924
04/27/2022 17:12:07 - INFO - __main__ - Global step 1850 Train loss 0.01 ACC 0.78125 on epoch=924
04/27/2022 17:12:11 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=929
04/27/2022 17:12:15 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=934
04/27/2022 17:12:19 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=939
04/27/2022 17:12:23 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=944
04/27/2022 17:12:27 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=949
04/27/2022 17:12:29 - INFO - __main__ - Global step 1900 Train loss 0.01 ACC 0.71875 on epoch=949
04/27/2022 17:12:33 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=954
04/27/2022 17:12:37 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=959
04/27/2022 17:12:41 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=964
04/27/2022 17:12:45 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=969
04/27/2022 17:12:49 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=974
04/27/2022 17:12:52 - INFO - __main__ - Global step 1950 Train loss 0.01 ACC 0.71875 on epoch=974
04/27/2022 17:12:55 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=979
04/27/2022 17:12:59 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=984
04/27/2022 17:13:03 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=989
04/27/2022 17:13:07 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=994
04/27/2022 17:13:11 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=999
04/27/2022 17:13:13 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 17:13:13 - INFO - __main__ - Printing 3 examples
04/27/2022 17:13:13 - INFO - __main__ -  [sciq] Fractures, rickets, and osteoarthritis all affect what part(s) of the body? (A) fossils (B) Heart (C) bones (D) animals [SEP] Despite their hardness and strength, bones can suffer from injury and disease. Bone problems include fractures, osteoarthritis, and rickets.
04/27/2022 17:13:13 - INFO - __main__ - ['bones']
04/27/2022 17:13:13 - INFO - __main__ -  [sciq] What does a keratometer measure in the cornea? (A) diameter (B) curve (C) Lenght (D) Width [SEP] 25.7 Image Formation by Mirrors 53. What is the focal length of a makeup mirror that has a power of 1.50 D? 54. Some telephoto cameras use a mirror rather than a lens. What radius of curvature mirror is needed to replace a 800 mm focal length telephoto lens? 55. (a) Calculate the focal length of the mirror formed by the shiny back of a spoon that has a 3.00 cm radius of curvature. (b) What is its power in diopters? 56. Find the magnification of the heater element in Example 25.9. Note that its large magnitude helps spread out the reflected energy. What is the focal length of a makeup mirror that produces a magnification of 1.50 when a person’s face is 12.0 cm away? Explicitly show how you follow the steps in the Problem-Solving Strategy for Mirrors. A shopper standing 3.00 m from a convex security mirror sees his image with a magnification of 0.250. (a) Where is his image? (b) What is the focal length of the mirror? (c) What is its radius of curvature? Explicitly show how you follow the steps in the Problem-Solving Strategy for Mirrors. An object 1.50 cm high is held 3.00 cm from a person’s cornea, and its reflected image is measured to be 0.167 cm high. (a) What is the magnification? (b) Where is the image? (c) Find the radius of curvature of the convex mirror formed by the cornea. (Note that this technique is used by optometrists to measure the curvature of the cornea for contact lens fitting. The instrument used is called a keratometer, or curve measurer. ) 60. Ray tracing for a flat mirror shows that the image is located a distance behind the mirror equal to the distance of the object from the mirror. This is stated d i = –d o , since this is a negative image distance (it is a virtual image). (a) What is the focal length of a flat mirror? (b) What is its power?.
04/27/2022 17:13:13 - INFO - __main__ - ['curve']
04/27/2022 17:13:13 - INFO - __main__ -  [sciq] Most carcinogens produce mutations in genes that control what? (A) proteins cycle (B) cell cycle (C) ubiquitous cycle (D) digestive cycle [SEP] Most carcinogens produce mutations in genes that control the cell cycle.
04/27/2022 17:13:13 - INFO - __main__ - ['cell cycle']
04/27/2022 17:13:13 - INFO - __main__ - Tokenizing Input ...
04/27/2022 17:13:13 - INFO - __main__ - Tokenizing Output ...
04/27/2022 17:13:13 - INFO - __main__ - Loaded 32 examples from train data
04/27/2022 17:13:13 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 17:13:13 - INFO - __main__ - Printing 3 examples
04/27/2022 17:13:13 - INFO - __main__ -  [sciq] The cerebellum is associated with what major human organ? (A) bladder (B) heart (C) liver (D) brain [SEP] Figure 13.13 The Cerebellum The cerebellum is situated on the posterior surface of the brain stem. Descending input from the cerebellum enters through the large white matter structure of the pons. Ascending input from the periphery and spinal cord enters through the fibers of the inferior olive. Output goes to the midbrain, which sends a descending signal to the spinal cord.
04/27/2022 17:13:13 - INFO - __main__ - ['brain']
04/27/2022 17:13:13 - INFO - __main__ -  [sciq] What is the term for the energy of motion, which is exhibited by the speed of an object? (A) inertia (B) kinetic energy (C) mechanical energy (D) residual energy [SEP] The energy of motion is kinetic energy, KE. Whenever an object is in motion it has kinetic energy. The faster it is going, the more energy it has.
04/27/2022 17:13:13 - INFO - __main__ - ['kinetic energy']
04/27/2022 17:13:13 - INFO - __main__ -  [sciq] The following definition relates to which term: the application of knowledge to real-world problems? (A) capitalism (B) industry (C) invention (D) technology [SEP] Technology is the application of knowledge to real-world problems. It includes methods and processes as well as devices like computers and cars. An example is the Bessemer process. It is a cheap method of making steel that was invented in the 1850s. It is just one of many technological advances that have occurred in manufacturing. Technology is also responsible for most of the major advances in agriculture, transportation, communications, and medicine. Clearly, technology has had a huge impact on people and society. It is hard to imagine what life would be like without it.
04/27/2022 17:13:13 - INFO - __main__ - ['technology']
04/27/2022 17:13:13 - INFO - __main__ - Tokenizing Input ...
04/27/2022 17:13:13 - INFO - __main__ - Tokenizing Output ...
04/27/2022 17:13:13 - INFO - __main__ - Loaded 32 examples from dev data
04/27/2022 17:13:14 - INFO - __main__ - Global step 2000 Train loss 0.01 ACC 0.75 on epoch=999
04/27/2022 17:13:14 - INFO - __main__ - save last model!
04/27/2022 17:13:14 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
04/27/2022 17:13:14 - INFO - __main__ - Start tokenizing ... 887 instances
04/27/2022 17:13:14 - INFO - __main__ - Printing 3 examples
04/27/2022 17:13:14 - INFO - __main__ -  [sciq] A frameshift mutation is a deletion or insertion of one or more of what that changes the reading frame of the base sequence? (A) carotenoids (B) nucleotides (C) proteins (D) genes [SEP] A frameshift mutation is a deletion or insertion of one or more nucleotides that changes the reading frame of the base sequence. Deletions remove nucleotides, and insertions add nucleotides. Consider the following sequence of bases in RNA:.
04/27/2022 17:13:14 - INFO - __main__ - ['nucleotides']
04/27/2022 17:13:14 - INFO - __main__ -  [sciq] What is an area of land called that is wet for all or part of the year? (A) grassland (B) wetland (C) plains (D) tundra [SEP] A wetland is an area that is wet for all or part of the year. Wetlands are home to certain types of plants.
04/27/2022 17:13:14 - INFO - __main__ - ['wetland']
04/27/2022 17:13:14 - INFO - __main__ -  [sciq] What are arteries, veins, and capillaries examples of? (A) blood vessels (B) muscles (C) organs (D) tissue [SEP] Blood vessels include arteries, veins, and capillaries.
04/27/2022 17:13:14 - INFO - __main__ - ['blood vessels']
04/27/2022 17:13:14 - INFO - __main__ - Tokenizing Input ...
04/27/2022 17:13:15 - INFO - __main__ - Tokenizing Output ...
04/27/2022 17:13:16 - INFO - __main__ - Loaded 887 examples from test data
04/27/2022 17:13:31 - INFO - __main__ - load prompt embedding from ckpt
04/27/2022 17:13:32 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/27/2022 17:13:32 - INFO - __main__ - Starting training!
04/27/2022 17:14:06 - INFO - __main__ - Saved prediction in models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-sciq/sciq_32_100_0.2_8_predictions.txt
04/27/2022 17:14:06 - INFO - __main__ - ACC on test data: 0.7542
04/27/2022 17:14:06 - INFO - __main__ - prefix=sciq_32_100, lr=0.2, bsz=8, dev_performance=0.84375, test_performance=0.7542277339346111
04/27/2022 17:14:06 - INFO - __main__ - Running ... prefix=sciq_32_13, lr=0.5, bsz=8 ...
04/27/2022 17:14:07 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 17:14:07 - INFO - __main__ - Printing 3 examples
04/27/2022 17:14:07 - INFO - __main__ -  [sciq] Fractures, rickets, and osteoarthritis all affect what part(s) of the body? (A) fossils (B) Heart (C) bones (D) animals [SEP] Despite their hardness and strength, bones can suffer from injury and disease. Bone problems include fractures, osteoarthritis, and rickets.
04/27/2022 17:14:07 - INFO - __main__ - ['bones']
04/27/2022 17:14:07 - INFO - __main__ -  [sciq] What does a keratometer measure in the cornea? (A) diameter (B) curve (C) Lenght (D) Width [SEP] 25.7 Image Formation by Mirrors 53. What is the focal length of a makeup mirror that has a power of 1.50 D? 54. Some telephoto cameras use a mirror rather than a lens. What radius of curvature mirror is needed to replace a 800 mm focal length telephoto lens? 55. (a) Calculate the focal length of the mirror formed by the shiny back of a spoon that has a 3.00 cm radius of curvature. (b) What is its power in diopters? 56. Find the magnification of the heater element in Example 25.9. Note that its large magnitude helps spread out the reflected energy. What is the focal length of a makeup mirror that produces a magnification of 1.50 when a person’s face is 12.0 cm away? Explicitly show how you follow the steps in the Problem-Solving Strategy for Mirrors. A shopper standing 3.00 m from a convex security mirror sees his image with a magnification of 0.250. (a) Where is his image? (b) What is the focal length of the mirror? (c) What is its radius of curvature? Explicitly show how you follow the steps in the Problem-Solving Strategy for Mirrors. An object 1.50 cm high is held 3.00 cm from a person’s cornea, and its reflected image is measured to be 0.167 cm high. (a) What is the magnification? (b) Where is the image? (c) Find the radius of curvature of the convex mirror formed by the cornea. (Note that this technique is used by optometrists to measure the curvature of the cornea for contact lens fitting. The instrument used is called a keratometer, or curve measurer. ) 60. Ray tracing for a flat mirror shows that the image is located a distance behind the mirror equal to the distance of the object from the mirror. This is stated d i = –d o , since this is a negative image distance (it is a virtual image). (a) What is the focal length of a flat mirror? (b) What is its power?.
04/27/2022 17:14:07 - INFO - __main__ - ['curve']
04/27/2022 17:14:07 - INFO - __main__ -  [sciq] Most carcinogens produce mutations in genes that control what? (A) proteins cycle (B) cell cycle (C) ubiquitous cycle (D) digestive cycle [SEP] Most carcinogens produce mutations in genes that control the cell cycle.
04/27/2022 17:14:07 - INFO - __main__ - ['cell cycle']
04/27/2022 17:14:07 - INFO - __main__ - Tokenizing Input ...
04/27/2022 17:14:07 - INFO - __main__ - Tokenizing Output ...
04/27/2022 17:14:07 - INFO - __main__ - Loaded 32 examples from train data
04/27/2022 17:14:07 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 17:14:07 - INFO - __main__ - Printing 3 examples
04/27/2022 17:14:07 - INFO - __main__ -  [sciq] The cerebellum is associated with what major human organ? (A) bladder (B) heart (C) liver (D) brain [SEP] Figure 13.13 The Cerebellum The cerebellum is situated on the posterior surface of the brain stem. Descending input from the cerebellum enters through the large white matter structure of the pons. Ascending input from the periphery and spinal cord enters through the fibers of the inferior olive. Output goes to the midbrain, which sends a descending signal to the spinal cord.
04/27/2022 17:14:07 - INFO - __main__ - ['brain']
04/27/2022 17:14:07 - INFO - __main__ -  [sciq] What is the term for the energy of motion, which is exhibited by the speed of an object? (A) inertia (B) kinetic energy (C) mechanical energy (D) residual energy [SEP] The energy of motion is kinetic energy, KE. Whenever an object is in motion it has kinetic energy. The faster it is going, the more energy it has.
04/27/2022 17:14:07 - INFO - __main__ - ['kinetic energy']
04/27/2022 17:14:07 - INFO - __main__ -  [sciq] The following definition relates to which term: the application of knowledge to real-world problems? (A) capitalism (B) industry (C) invention (D) technology [SEP] Technology is the application of knowledge to real-world problems. It includes methods and processes as well as devices like computers and cars. An example is the Bessemer process. It is a cheap method of making steel that was invented in the 1850s. It is just one of many technological advances that have occurred in manufacturing. Technology is also responsible for most of the major advances in agriculture, transportation, communications, and medicine. Clearly, technology has had a huge impact on people and society. It is hard to imagine what life would be like without it.
04/27/2022 17:14:07 - INFO - __main__ - ['technology']
04/27/2022 17:14:07 - INFO - __main__ - Tokenizing Input ...
04/27/2022 17:14:07 - INFO - __main__ - Tokenizing Output ...
04/27/2022 17:14:07 - INFO - __main__ - Loaded 32 examples from dev data
04/27/2022 17:14:24 - INFO - __main__ - load prompt embedding from ckpt
04/27/2022 17:14:25 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/27/2022 17:14:25 - INFO - __main__ - Starting training!
04/27/2022 17:14:30 - INFO - __main__ - Step 10 Global step 10 Train loss 2.96 on epoch=4
04/27/2022 17:14:34 - INFO - __main__ - Step 20 Global step 20 Train loss 1.57 on epoch=9
04/27/2022 17:14:38 - INFO - __main__ - Step 30 Global step 30 Train loss 1.07 on epoch=14
04/27/2022 17:14:42 - INFO - __main__ - Step 40 Global step 40 Train loss 0.84 on epoch=19
04/27/2022 17:14:46 - INFO - __main__ - Step 50 Global step 50 Train loss 0.60 on epoch=24
04/27/2022 17:14:48 - INFO - __main__ - Global step 50 Train loss 1.41 ACC 0.40625 on epoch=24
04/27/2022 17:14:48 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.40625 on epoch=24, global_step=50
04/27/2022 17:14:52 - INFO - __main__ - Step 60 Global step 60 Train loss 0.53 on epoch=29
04/27/2022 17:14:56 - INFO - __main__ - Step 70 Global step 70 Train loss 0.41 on epoch=34
04/27/2022 17:15:00 - INFO - __main__ - Step 80 Global step 80 Train loss 0.29 on epoch=39
04/27/2022 17:15:04 - INFO - __main__ - Step 90 Global step 90 Train loss 0.31 on epoch=44
04/27/2022 17:15:08 - INFO - __main__ - Step 100 Global step 100 Train loss 0.21 on epoch=49
04/27/2022 17:15:09 - INFO - __main__ - Global step 100 Train loss 0.35 ACC 0.625 on epoch=49
04/27/2022 17:15:09 - INFO - __main__ - Saving model with best ACC: 0.40625 -> 0.625 on epoch=49, global_step=100
04/27/2022 17:15:13 - INFO - __main__ - Step 110 Global step 110 Train loss 0.18 on epoch=54
04/27/2022 17:15:17 - INFO - __main__ - Step 120 Global step 120 Train loss 0.18 on epoch=59
04/27/2022 17:15:21 - INFO - __main__ - Step 130 Global step 130 Train loss 0.20 on epoch=64
04/27/2022 17:15:25 - INFO - __main__ - Step 140 Global step 140 Train loss 0.12 on epoch=69
04/27/2022 17:15:29 - INFO - __main__ - Step 150 Global step 150 Train loss 0.19 on epoch=74
04/27/2022 17:15:31 - INFO - __main__ - Global step 150 Train loss 0.17 ACC 0.6875 on epoch=74
04/27/2022 17:15:31 - INFO - __main__ - Saving model with best ACC: 0.625 -> 0.6875 on epoch=74, global_step=150
04/27/2022 17:15:35 - INFO - __main__ - Step 160 Global step 160 Train loss 0.15 on epoch=79
04/27/2022 17:15:39 - INFO - __main__ - Step 170 Global step 170 Train loss 0.09 on epoch=84
04/27/2022 17:15:43 - INFO - __main__ - Step 180 Global step 180 Train loss 0.09 on epoch=89
04/27/2022 17:15:47 - INFO - __main__ - Step 190 Global step 190 Train loss 0.10 on epoch=94
04/27/2022 17:15:51 - INFO - __main__ - Step 200 Global step 200 Train loss 0.06 on epoch=99
04/27/2022 17:15:53 - INFO - __main__ - Global step 200 Train loss 0.10 ACC 0.8125 on epoch=99
04/27/2022 17:15:53 - INFO - __main__ - Saving model with best ACC: 0.6875 -> 0.8125 on epoch=99, global_step=200
04/27/2022 17:15:57 - INFO - __main__ - Step 210 Global step 210 Train loss 0.07 on epoch=104
04/27/2022 17:16:01 - INFO - __main__ - Step 220 Global step 220 Train loss 0.06 on epoch=109
04/27/2022 17:16:05 - INFO - __main__ - Step 230 Global step 230 Train loss 0.05 on epoch=114
04/27/2022 17:16:09 - INFO - __main__ - Step 240 Global step 240 Train loss 0.13 on epoch=119
04/27/2022 17:16:13 - INFO - __main__ - Step 250 Global step 250 Train loss 0.06 on epoch=124
04/27/2022 17:16:14 - INFO - __main__ - Global step 250 Train loss 0.07 ACC 0.6875 on epoch=124
04/27/2022 17:16:18 - INFO - __main__ - Step 260 Global step 260 Train loss 0.07 on epoch=129
04/27/2022 17:16:22 - INFO - __main__ - Step 270 Global step 270 Train loss 0.03 on epoch=134
04/27/2022 17:16:26 - INFO - __main__ - Step 280 Global step 280 Train loss 0.03 on epoch=139
04/27/2022 17:16:30 - INFO - __main__ - Step 290 Global step 290 Train loss 0.03 on epoch=144
04/27/2022 17:16:34 - INFO - __main__ - Step 300 Global step 300 Train loss 0.07 on epoch=149
04/27/2022 17:16:36 - INFO - __main__ - Global step 300 Train loss 0.05 ACC 0.6875 on epoch=149
04/27/2022 17:16:40 - INFO - __main__ - Step 310 Global step 310 Train loss 0.04 on epoch=154
04/27/2022 17:16:44 - INFO - __main__ - Step 320 Global step 320 Train loss 0.06 on epoch=159
04/27/2022 17:16:48 - INFO - __main__ - Step 330 Global step 330 Train loss 0.02 on epoch=164
04/27/2022 17:16:52 - INFO - __main__ - Step 340 Global step 340 Train loss 0.03 on epoch=169
04/27/2022 17:16:56 - INFO - __main__ - Step 350 Global step 350 Train loss 0.04 on epoch=174
04/27/2022 17:16:58 - INFO - __main__ - Global step 350 Train loss 0.04 ACC 0.8125 on epoch=174
04/27/2022 17:17:02 - INFO - __main__ - Step 360 Global step 360 Train loss 0.06 on epoch=179
04/27/2022 17:17:06 - INFO - __main__ - Step 370 Global step 370 Train loss 0.01 on epoch=184
04/27/2022 17:17:10 - INFO - __main__ - Step 380 Global step 380 Train loss 0.05 on epoch=189
04/27/2022 17:17:14 - INFO - __main__ - Step 390 Global step 390 Train loss 0.09 on epoch=194
04/27/2022 17:17:18 - INFO - __main__ - Step 400 Global step 400 Train loss 0.03 on epoch=199
04/27/2022 17:17:19 - INFO - __main__ - Global step 400 Train loss 0.05 ACC 0.71875 on epoch=199
04/27/2022 17:17:23 - INFO - __main__ - Step 410 Global step 410 Train loss 0.02 on epoch=204
04/27/2022 17:17:27 - INFO - __main__ - Step 420 Global step 420 Train loss 0.01 on epoch=209
04/27/2022 17:17:31 - INFO - __main__ - Step 430 Global step 430 Train loss 0.03 on epoch=214
04/27/2022 17:17:35 - INFO - __main__ - Step 440 Global step 440 Train loss 0.03 on epoch=219
04/27/2022 17:17:39 - INFO - __main__ - Step 450 Global step 450 Train loss 0.03 on epoch=224
04/27/2022 17:17:41 - INFO - __main__ - Global step 450 Train loss 0.02 ACC 0.71875 on epoch=224
04/27/2022 17:17:45 - INFO - __main__ - Step 460 Global step 460 Train loss 0.02 on epoch=229
04/27/2022 17:17:49 - INFO - __main__ - Step 470 Global step 470 Train loss 0.01 on epoch=234
04/27/2022 17:17:53 - INFO - __main__ - Step 480 Global step 480 Train loss 0.10 on epoch=239
04/27/2022 17:17:57 - INFO - __main__ - Step 490 Global step 490 Train loss 0.03 on epoch=244
04/27/2022 17:18:01 - INFO - __main__ - Step 500 Global step 500 Train loss 0.04 on epoch=249
04/27/2022 17:18:03 - INFO - __main__ - Global step 500 Train loss 0.04 ACC 0.78125 on epoch=249
04/27/2022 17:18:07 - INFO - __main__ - Step 510 Global step 510 Train loss 0.01 on epoch=254
04/27/2022 17:18:11 - INFO - __main__ - Step 520 Global step 520 Train loss 0.01 on epoch=259
04/27/2022 17:18:15 - INFO - __main__ - Step 530 Global step 530 Train loss 0.02 on epoch=264
04/27/2022 17:18:19 - INFO - __main__ - Step 540 Global step 540 Train loss 0.02 on epoch=269
04/27/2022 17:18:23 - INFO - __main__ - Step 550 Global step 550 Train loss 0.02 on epoch=274
04/27/2022 17:18:25 - INFO - __main__ - Global step 550 Train loss 0.02 ACC 0.71875 on epoch=274
04/27/2022 17:18:29 - INFO - __main__ - Step 560 Global step 560 Train loss 0.03 on epoch=279
04/27/2022 17:18:33 - INFO - __main__ - Step 570 Global step 570 Train loss 0.02 on epoch=284
04/27/2022 17:18:37 - INFO - __main__ - Step 580 Global step 580 Train loss 0.01 on epoch=289
04/27/2022 17:18:41 - INFO - __main__ - Step 590 Global step 590 Train loss 0.01 on epoch=294
04/27/2022 17:18:45 - INFO - __main__ - Step 600 Global step 600 Train loss 0.02 on epoch=299
04/27/2022 17:18:47 - INFO - __main__ - Global step 600 Train loss 0.02 ACC 0.875 on epoch=299
04/27/2022 17:18:47 - INFO - __main__ - Saving model with best ACC: 0.8125 -> 0.875 on epoch=299, global_step=600
04/27/2022 17:18:51 - INFO - __main__ - Step 610 Global step 610 Train loss 0.01 on epoch=304
04/27/2022 17:18:55 - INFO - __main__ - Step 620 Global step 620 Train loss 0.04 on epoch=309
04/27/2022 17:18:58 - INFO - __main__ - Step 630 Global step 630 Train loss 0.01 on epoch=314
04/27/2022 17:19:02 - INFO - __main__ - Step 640 Global step 640 Train loss 0.02 on epoch=319
04/27/2022 17:19:06 - INFO - __main__ - Step 650 Global step 650 Train loss 0.02 on epoch=324
04/27/2022 17:19:08 - INFO - __main__ - Global step 650 Train loss 0.02 ACC 0.78125 on epoch=324
04/27/2022 17:19:12 - INFO - __main__ - Step 660 Global step 660 Train loss 0.01 on epoch=329
04/27/2022 17:19:16 - INFO - __main__ - Step 670 Global step 670 Train loss 0.02 on epoch=334
04/27/2022 17:19:20 - INFO - __main__ - Step 680 Global step 680 Train loss 0.00 on epoch=339
04/27/2022 17:19:24 - INFO - __main__ - Step 690 Global step 690 Train loss 0.01 on epoch=344
04/27/2022 17:19:28 - INFO - __main__ - Step 700 Global step 700 Train loss 0.05 on epoch=349
04/27/2022 17:19:30 - INFO - __main__ - Global step 700 Train loss 0.02 ACC 0.84375 on epoch=349
04/27/2022 17:19:34 - INFO - __main__ - Step 710 Global step 710 Train loss 0.01 on epoch=354
04/27/2022 17:19:38 - INFO - __main__ - Step 720 Global step 720 Train loss 0.04 on epoch=359
04/27/2022 17:19:42 - INFO - __main__ - Step 730 Global step 730 Train loss 0.02 on epoch=364
04/27/2022 17:19:46 - INFO - __main__ - Step 740 Global step 740 Train loss 0.01 on epoch=369
04/27/2022 17:19:50 - INFO - __main__ - Step 750 Global step 750 Train loss 0.00 on epoch=374
04/27/2022 17:19:52 - INFO - __main__ - Global step 750 Train loss 0.02 ACC 0.84375 on epoch=374
04/27/2022 17:19:56 - INFO - __main__ - Step 760 Global step 760 Train loss 0.01 on epoch=379
04/27/2022 17:20:00 - INFO - __main__ - Step 770 Global step 770 Train loss 0.01 on epoch=384
04/27/2022 17:20:04 - INFO - __main__ - Step 780 Global step 780 Train loss 0.01 on epoch=389
04/27/2022 17:20:08 - INFO - __main__ - Step 790 Global step 790 Train loss 0.00 on epoch=394
04/27/2022 17:20:12 - INFO - __main__ - Step 800 Global step 800 Train loss 0.01 on epoch=399
04/27/2022 17:20:14 - INFO - __main__ - Global step 800 Train loss 0.01 ACC 0.8125 on epoch=399
04/27/2022 17:20:18 - INFO - __main__ - Step 810 Global step 810 Train loss 0.01 on epoch=404
04/27/2022 17:20:22 - INFO - __main__ - Step 820 Global step 820 Train loss 0.01 on epoch=409
04/27/2022 17:20:26 - INFO - __main__ - Step 830 Global step 830 Train loss 0.01 on epoch=414
04/27/2022 17:20:29 - INFO - __main__ - Step 840 Global step 840 Train loss 0.01 on epoch=419
04/27/2022 17:20:33 - INFO - __main__ - Step 850 Global step 850 Train loss 0.00 on epoch=424
04/27/2022 17:20:35 - INFO - __main__ - Global step 850 Train loss 0.01 ACC 0.84375 on epoch=424
04/27/2022 17:20:39 - INFO - __main__ - Step 860 Global step 860 Train loss 0.01 on epoch=429
04/27/2022 17:20:43 - INFO - __main__ - Step 870 Global step 870 Train loss 0.00 on epoch=434
04/27/2022 17:20:47 - INFO - __main__ - Step 880 Global step 880 Train loss 0.01 on epoch=439
04/27/2022 17:20:51 - INFO - __main__ - Step 890 Global step 890 Train loss 0.02 on epoch=444
04/27/2022 17:20:55 - INFO - __main__ - Step 900 Global step 900 Train loss 0.01 on epoch=449
04/27/2022 17:20:57 - INFO - __main__ - Global step 900 Train loss 0.01 ACC 0.875 on epoch=449
04/27/2022 17:21:01 - INFO - __main__ - Step 910 Global step 910 Train loss 0.02 on epoch=454
04/27/2022 17:21:05 - INFO - __main__ - Step 920 Global step 920 Train loss 0.02 on epoch=459
04/27/2022 17:21:09 - INFO - __main__ - Step 930 Global step 930 Train loss 0.01 on epoch=464
04/27/2022 17:21:13 - INFO - __main__ - Step 940 Global step 940 Train loss 0.02 on epoch=469
04/27/2022 17:21:17 - INFO - __main__ - Step 950 Global step 950 Train loss 0.01 on epoch=474
04/27/2022 17:21:19 - INFO - __main__ - Global step 950 Train loss 0.01 ACC 0.84375 on epoch=474
04/27/2022 17:21:23 - INFO - __main__ - Step 960 Global step 960 Train loss 0.01 on epoch=479
04/27/2022 17:21:27 - INFO - __main__ - Step 970 Global step 970 Train loss 0.00 on epoch=484
04/27/2022 17:21:31 - INFO - __main__ - Step 980 Global step 980 Train loss 0.00 on epoch=489
04/27/2022 17:21:35 - INFO - __main__ - Step 990 Global step 990 Train loss 0.01 on epoch=494
04/27/2022 17:21:39 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.01 on epoch=499
04/27/2022 17:21:41 - INFO - __main__ - Global step 1000 Train loss 0.01 ACC 0.84375 on epoch=499
04/27/2022 17:21:45 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.01 on epoch=504
04/27/2022 17:21:49 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.00 on epoch=509
04/27/2022 17:21:53 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.01 on epoch=514
04/27/2022 17:21:57 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.01 on epoch=519
04/27/2022 17:22:00 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.01 on epoch=524
04/27/2022 17:22:02 - INFO - __main__ - Global step 1050 Train loss 0.01 ACC 0.8125 on epoch=524
04/27/2022 17:22:06 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.01 on epoch=529
04/27/2022 17:22:10 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.00 on epoch=534
04/27/2022 17:22:14 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.01 on epoch=539
04/27/2022 17:22:18 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.02 on epoch=544
04/27/2022 17:22:22 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.05 on epoch=549
04/27/2022 17:22:24 - INFO - __main__ - Global step 1100 Train loss 0.02 ACC 0.8125 on epoch=549
04/27/2022 17:22:28 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.03 on epoch=554
04/27/2022 17:22:32 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=559
04/27/2022 17:22:36 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.00 on epoch=564
04/27/2022 17:22:40 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.00 on epoch=569
04/27/2022 17:22:44 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=574
04/27/2022 17:22:46 - INFO - __main__ - Global step 1150 Train loss 0.01 ACC 0.8125 on epoch=574
04/27/2022 17:22:50 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.01 on epoch=579
04/27/2022 17:22:54 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.01 on epoch=584
04/27/2022 17:22:58 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.00 on epoch=589
04/27/2022 17:23:02 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.01 on epoch=594
04/27/2022 17:23:06 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.00 on epoch=599
04/27/2022 17:23:08 - INFO - __main__ - Global step 1200 Train loss 0.01 ACC 0.84375 on epoch=599
04/27/2022 17:23:12 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.00 on epoch=604
04/27/2022 17:23:16 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.00 on epoch=609
04/27/2022 17:23:19 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=614
04/27/2022 17:23:23 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=619
04/27/2022 17:23:27 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.00 on epoch=624
04/27/2022 17:23:29 - INFO - __main__ - Global step 1250 Train loss 0.01 ACC 0.90625 on epoch=624
04/27/2022 17:23:29 - INFO - __main__ - Saving model with best ACC: 0.875 -> 0.90625 on epoch=624, global_step=1250
04/27/2022 17:23:33 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.00 on epoch=629
04/27/2022 17:23:37 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.00 on epoch=634
04/27/2022 17:23:41 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=639
04/27/2022 17:23:45 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.02 on epoch=644
04/27/2022 17:23:49 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=649
04/27/2022 17:23:51 - INFO - __main__ - Global step 1300 Train loss 0.01 ACC 0.84375 on epoch=649
04/27/2022 17:23:55 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.00 on epoch=654
04/27/2022 17:23:59 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.00 on epoch=659
04/27/2022 17:24:03 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.00 on epoch=664
04/27/2022 17:24:07 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.00 on epoch=669
04/27/2022 17:24:11 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=674
04/27/2022 17:24:13 - INFO - __main__ - Global step 1350 Train loss 0.00 ACC 0.84375 on epoch=674
04/27/2022 17:24:17 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=679
04/27/2022 17:24:21 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=684
04/27/2022 17:24:25 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=689
04/27/2022 17:24:29 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.00 on epoch=694
04/27/2022 17:24:33 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=699
04/27/2022 17:24:35 - INFO - __main__ - Global step 1400 Train loss 0.01 ACC 0.875 on epoch=699
04/27/2022 17:24:39 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=704
04/27/2022 17:24:43 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=709
04/27/2022 17:24:46 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.00 on epoch=714
04/27/2022 17:24:50 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=719
04/27/2022 17:24:54 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=724
04/27/2022 17:24:56 - INFO - __main__ - Global step 1450 Train loss 0.01 ACC 0.78125 on epoch=724
04/27/2022 17:25:00 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=729
04/27/2022 17:25:04 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=734
04/27/2022 17:25:08 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=739
04/27/2022 17:25:12 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=744
04/27/2022 17:25:16 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=749
04/27/2022 17:25:18 - INFO - __main__ - Global step 1500 Train loss 0.01 ACC 0.8125 on epoch=749
04/27/2022 17:25:22 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=754
04/27/2022 17:25:26 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=759
04/27/2022 17:25:30 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=764
04/27/2022 17:25:34 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=769
04/27/2022 17:25:38 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=774
04/27/2022 17:25:40 - INFO - __main__ - Global step 1550 Train loss 0.01 ACC 0.84375 on epoch=774
04/27/2022 17:25:44 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=779
04/27/2022 17:25:48 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.04 on epoch=784
04/27/2022 17:25:52 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=789
04/27/2022 17:25:56 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=794
04/27/2022 17:26:00 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=799
04/27/2022 17:26:02 - INFO - __main__ - Global step 1600 Train loss 0.01 ACC 0.8125 on epoch=799
04/27/2022 17:26:06 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=804
04/27/2022 17:26:10 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=809
04/27/2022 17:26:14 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=814
04/27/2022 17:26:18 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.02 on epoch=819
04/27/2022 17:26:22 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=824
04/27/2022 17:26:24 - INFO - __main__ - Global step 1650 Train loss 0.01 ACC 0.8125 on epoch=824
04/27/2022 17:26:28 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=829
04/27/2022 17:26:32 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=834
04/27/2022 17:26:36 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=839
04/27/2022 17:26:40 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=844
04/27/2022 17:26:44 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=849
04/27/2022 17:26:45 - INFO - __main__ - Global step 1700 Train loss 0.00 ACC 0.8125 on epoch=849
04/27/2022 17:26:49 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=854
04/27/2022 17:26:53 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=859
04/27/2022 17:26:57 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=864
04/27/2022 17:27:01 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=869
04/27/2022 17:27:05 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=874
04/27/2022 17:27:07 - INFO - __main__ - Global step 1750 Train loss 0.01 ACC 0.75 on epoch=874
04/27/2022 17:27:11 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=879
04/27/2022 17:27:15 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=884
04/27/2022 17:27:19 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=889
04/27/2022 17:27:23 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=894
04/27/2022 17:27:27 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=899
04/27/2022 17:27:29 - INFO - __main__ - Global step 1800 Train loss 0.00 ACC 0.78125 on epoch=899
04/27/2022 17:27:33 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=904
04/27/2022 17:27:37 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=909
04/27/2022 17:27:41 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=914
04/27/2022 17:27:45 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=919
04/27/2022 17:27:49 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=924
04/27/2022 17:27:51 - INFO - __main__ - Global step 1850 Train loss 0.01 ACC 0.8125 on epoch=924
04/27/2022 17:27:55 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=929
04/27/2022 17:27:59 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=934
04/27/2022 17:28:03 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=939
04/27/2022 17:28:07 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=944
04/27/2022 17:28:11 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=949
04/27/2022 17:28:13 - INFO - __main__ - Global step 1900 Train loss 0.00 ACC 0.875 on epoch=949
04/27/2022 17:28:17 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=954
04/27/2022 17:28:21 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=959
04/27/2022 17:28:25 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=964
04/27/2022 17:28:29 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=969
04/27/2022 17:28:33 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=974
04/27/2022 17:28:35 - INFO - __main__ - Global step 1950 Train loss 0.00 ACC 0.84375 on epoch=974
04/27/2022 17:28:39 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=979
04/27/2022 17:28:43 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=984
04/27/2022 17:28:47 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=989
04/27/2022 17:28:51 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=994
04/27/2022 17:28:55 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=999
04/27/2022 17:28:56 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 17:28:56 - INFO - __main__ - Printing 3 examples
04/27/2022 17:28:56 - INFO - __main__ -  [sciq] Fractures, rickets, and osteoarthritis all affect what part(s) of the body? (A) fossils (B) Heart (C) bones (D) animals [SEP] Despite their hardness and strength, bones can suffer from injury and disease. Bone problems include fractures, osteoarthritis, and rickets.
04/27/2022 17:28:56 - INFO - __main__ - ['bones']
04/27/2022 17:28:56 - INFO - __main__ -  [sciq] What does a keratometer measure in the cornea? (A) diameter (B) curve (C) Lenght (D) Width [SEP] 25.7 Image Formation by Mirrors 53. What is the focal length of a makeup mirror that has a power of 1.50 D? 54. Some telephoto cameras use a mirror rather than a lens. What radius of curvature mirror is needed to replace a 800 mm focal length telephoto lens? 55. (a) Calculate the focal length of the mirror formed by the shiny back of a spoon that has a 3.00 cm radius of curvature. (b) What is its power in diopters? 56. Find the magnification of the heater element in Example 25.9. Note that its large magnitude helps spread out the reflected energy. What is the focal length of a makeup mirror that produces a magnification of 1.50 when a person’s face is 12.0 cm away? Explicitly show how you follow the steps in the Problem-Solving Strategy for Mirrors. A shopper standing 3.00 m from a convex security mirror sees his image with a magnification of 0.250. (a) Where is his image? (b) What is the focal length of the mirror? (c) What is its radius of curvature? Explicitly show how you follow the steps in the Problem-Solving Strategy for Mirrors. An object 1.50 cm high is held 3.00 cm from a person’s cornea, and its reflected image is measured to be 0.167 cm high. (a) What is the magnification? (b) Where is the image? (c) Find the radius of curvature of the convex mirror formed by the cornea. (Note that this technique is used by optometrists to measure the curvature of the cornea for contact lens fitting. The instrument used is called a keratometer, or curve measurer. ) 60. Ray tracing for a flat mirror shows that the image is located a distance behind the mirror equal to the distance of the object from the mirror. This is stated d i = –d o , since this is a negative image distance (it is a virtual image). (a) What is the focal length of a flat mirror? (b) What is its power?.
04/27/2022 17:28:56 - INFO - __main__ - ['curve']
04/27/2022 17:28:56 - INFO - __main__ -  [sciq] Most carcinogens produce mutations in genes that control what? (A) proteins cycle (B) cell cycle (C) ubiquitous cycle (D) digestive cycle [SEP] Most carcinogens produce mutations in genes that control the cell cycle.
04/27/2022 17:28:56 - INFO - __main__ - ['cell cycle']
04/27/2022 17:28:56 - INFO - __main__ - Tokenizing Input ...
04/27/2022 17:28:56 - INFO - __main__ - Tokenizing Output ...
04/27/2022 17:28:56 - INFO - __main__ - Loaded 32 examples from train data
04/27/2022 17:28:56 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 17:28:56 - INFO - __main__ - Printing 3 examples
04/27/2022 17:28:56 - INFO - __main__ -  [sciq] The cerebellum is associated with what major human organ? (A) bladder (B) heart (C) liver (D) brain [SEP] Figure 13.13 The Cerebellum The cerebellum is situated on the posterior surface of the brain stem. Descending input from the cerebellum enters through the large white matter structure of the pons. Ascending input from the periphery and spinal cord enters through the fibers of the inferior olive. Output goes to the midbrain, which sends a descending signal to the spinal cord.
04/27/2022 17:28:56 - INFO - __main__ - ['brain']
04/27/2022 17:28:56 - INFO - __main__ -  [sciq] What is the term for the energy of motion, which is exhibited by the speed of an object? (A) inertia (B) kinetic energy (C) mechanical energy (D) residual energy [SEP] The energy of motion is kinetic energy, KE. Whenever an object is in motion it has kinetic energy. The faster it is going, the more energy it has.
04/27/2022 17:28:56 - INFO - __main__ - ['kinetic energy']
04/27/2022 17:28:56 - INFO - __main__ -  [sciq] The following definition relates to which term: the application of knowledge to real-world problems? (A) capitalism (B) industry (C) invention (D) technology [SEP] Technology is the application of knowledge to real-world problems. It includes methods and processes as well as devices like computers and cars. An example is the Bessemer process. It is a cheap method of making steel that was invented in the 1850s. It is just one of many technological advances that have occurred in manufacturing. Technology is also responsible for most of the major advances in agriculture, transportation, communications, and medicine. Clearly, technology has had a huge impact on people and society. It is hard to imagine what life would be like without it.
04/27/2022 17:28:56 - INFO - __main__ - ['technology']
04/27/2022 17:28:56 - INFO - __main__ - Tokenizing Input ...
04/27/2022 17:28:56 - INFO - __main__ - Tokenizing Output ...
04/27/2022 17:28:57 - INFO - __main__ - Loaded 32 examples from dev data
04/27/2022 17:28:57 - INFO - __main__ - Global step 2000 Train loss 0.00 ACC 0.78125 on epoch=999
04/27/2022 17:28:57 - INFO - __main__ - save last model!
04/27/2022 17:28:57 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
04/27/2022 17:28:57 - INFO - __main__ - Start tokenizing ... 887 instances
04/27/2022 17:28:57 - INFO - __main__ - Printing 3 examples
04/27/2022 17:28:57 - INFO - __main__ -  [sciq] A frameshift mutation is a deletion or insertion of one or more of what that changes the reading frame of the base sequence? (A) carotenoids (B) nucleotides (C) proteins (D) genes [SEP] A frameshift mutation is a deletion or insertion of one or more nucleotides that changes the reading frame of the base sequence. Deletions remove nucleotides, and insertions add nucleotides. Consider the following sequence of bases in RNA:.
04/27/2022 17:28:57 - INFO - __main__ - ['nucleotides']
04/27/2022 17:28:57 - INFO - __main__ -  [sciq] What is an area of land called that is wet for all or part of the year? (A) grassland (B) wetland (C) plains (D) tundra [SEP] A wetland is an area that is wet for all or part of the year. Wetlands are home to certain types of plants.
04/27/2022 17:28:57 - INFO - __main__ - ['wetland']
04/27/2022 17:28:57 - INFO - __main__ -  [sciq] What are arteries, veins, and capillaries examples of? (A) blood vessels (B) muscles (C) organs (D) tissue [SEP] Blood vessels include arteries, veins, and capillaries.
04/27/2022 17:28:57 - INFO - __main__ - ['blood vessels']
04/27/2022 17:28:57 - INFO - __main__ - Tokenizing Input ...
04/27/2022 17:28:58 - INFO - __main__ - Tokenizing Output ...
04/27/2022 17:28:58 - INFO - __main__ - Loaded 887 examples from test data
04/27/2022 17:29:15 - INFO - __main__ - load prompt embedding from ckpt
04/27/2022 17:29:16 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/27/2022 17:29:16 - INFO - __main__ - Starting training!
04/27/2022 17:29:43 - INFO - __main__ - Saved prediction in models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-sciq/sciq_32_13_0.5_8_predictions.txt
04/27/2022 17:29:43 - INFO - __main__ - ACC on test data: 0.8050
04/27/2022 17:29:44 - INFO - __main__ - prefix=sciq_32_13, lr=0.5, bsz=8, dev_performance=0.90625, test_performance=0.8049605411499436
04/27/2022 17:29:44 - INFO - __main__ - Running ... prefix=sciq_32_13, lr=0.4, bsz=8 ...
04/27/2022 17:29:45 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 17:29:45 - INFO - __main__ - Printing 3 examples
04/27/2022 17:29:45 - INFO - __main__ -  [sciq] Fractures, rickets, and osteoarthritis all affect what part(s) of the body? (A) fossils (B) Heart (C) bones (D) animals [SEP] Despite their hardness and strength, bones can suffer from injury and disease. Bone problems include fractures, osteoarthritis, and rickets.
04/27/2022 17:29:45 - INFO - __main__ - ['bones']
04/27/2022 17:29:45 - INFO - __main__ -  [sciq] What does a keratometer measure in the cornea? (A) diameter (B) curve (C) Lenght (D) Width [SEP] 25.7 Image Formation by Mirrors 53. What is the focal length of a makeup mirror that has a power of 1.50 D? 54. Some telephoto cameras use a mirror rather than a lens. What radius of curvature mirror is needed to replace a 800 mm focal length telephoto lens? 55. (a) Calculate the focal length of the mirror formed by the shiny back of a spoon that has a 3.00 cm radius of curvature. (b) What is its power in diopters? 56. Find the magnification of the heater element in Example 25.9. Note that its large magnitude helps spread out the reflected energy. What is the focal length of a makeup mirror that produces a magnification of 1.50 when a person’s face is 12.0 cm away? Explicitly show how you follow the steps in the Problem-Solving Strategy for Mirrors. A shopper standing 3.00 m from a convex security mirror sees his image with a magnification of 0.250. (a) Where is his image? (b) What is the focal length of the mirror? (c) What is its radius of curvature? Explicitly show how you follow the steps in the Problem-Solving Strategy for Mirrors. An object 1.50 cm high is held 3.00 cm from a person’s cornea, and its reflected image is measured to be 0.167 cm high. (a) What is the magnification? (b) Where is the image? (c) Find the radius of curvature of the convex mirror formed by the cornea. (Note that this technique is used by optometrists to measure the curvature of the cornea for contact lens fitting. The instrument used is called a keratometer, or curve measurer. ) 60. Ray tracing for a flat mirror shows that the image is located a distance behind the mirror equal to the distance of the object from the mirror. This is stated d i = –d o , since this is a negative image distance (it is a virtual image). (a) What is the focal length of a flat mirror? (b) What is its power?.
04/27/2022 17:29:45 - INFO - __main__ - ['curve']
04/27/2022 17:29:45 - INFO - __main__ -  [sciq] Most carcinogens produce mutations in genes that control what? (A) proteins cycle (B) cell cycle (C) ubiquitous cycle (D) digestive cycle [SEP] Most carcinogens produce mutations in genes that control the cell cycle.
04/27/2022 17:29:45 - INFO - __main__ - ['cell cycle']
04/27/2022 17:29:45 - INFO - __main__ - Tokenizing Input ...
04/27/2022 17:29:45 - INFO - __main__ - Tokenizing Output ...
04/27/2022 17:29:45 - INFO - __main__ - Loaded 32 examples from train data
04/27/2022 17:29:45 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 17:29:45 - INFO - __main__ - Printing 3 examples
04/27/2022 17:29:45 - INFO - __main__ -  [sciq] The cerebellum is associated with what major human organ? (A) bladder (B) heart (C) liver (D) brain [SEP] Figure 13.13 The Cerebellum The cerebellum is situated on the posterior surface of the brain stem. Descending input from the cerebellum enters through the large white matter structure of the pons. Ascending input from the periphery and spinal cord enters through the fibers of the inferior olive. Output goes to the midbrain, which sends a descending signal to the spinal cord.
04/27/2022 17:29:45 - INFO - __main__ - ['brain']
04/27/2022 17:29:45 - INFO - __main__ -  [sciq] What is the term for the energy of motion, which is exhibited by the speed of an object? (A) inertia (B) kinetic energy (C) mechanical energy (D) residual energy [SEP] The energy of motion is kinetic energy, KE. Whenever an object is in motion it has kinetic energy. The faster it is going, the more energy it has.
04/27/2022 17:29:45 - INFO - __main__ - ['kinetic energy']
04/27/2022 17:29:45 - INFO - __main__ -  [sciq] The following definition relates to which term: the application of knowledge to real-world problems? (A) capitalism (B) industry (C) invention (D) technology [SEP] Technology is the application of knowledge to real-world problems. It includes methods and processes as well as devices like computers and cars. An example is the Bessemer process. It is a cheap method of making steel that was invented in the 1850s. It is just one of many technological advances that have occurred in manufacturing. Technology is also responsible for most of the major advances in agriculture, transportation, communications, and medicine. Clearly, technology has had a huge impact on people and society. It is hard to imagine what life would be like without it.
04/27/2022 17:29:45 - INFO - __main__ - ['technology']
04/27/2022 17:29:45 - INFO - __main__ - Tokenizing Input ...
04/27/2022 17:29:45 - INFO - __main__ - Tokenizing Output ...
04/27/2022 17:29:45 - INFO - __main__ - Loaded 32 examples from dev data
04/27/2022 17:30:01 - INFO - __main__ - load prompt embedding from ckpt
04/27/2022 17:30:02 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/27/2022 17:30:02 - INFO - __main__ - Starting training!
04/27/2022 17:30:07 - INFO - __main__ - Step 10 Global step 10 Train loss 2.87 on epoch=4
04/27/2022 17:30:11 - INFO - __main__ - Step 20 Global step 20 Train loss 1.61 on epoch=9
04/27/2022 17:30:15 - INFO - __main__ - Step 30 Global step 30 Train loss 1.09 on epoch=14
04/27/2022 17:30:19 - INFO - __main__ - Step 40 Global step 40 Train loss 0.79 on epoch=19
04/27/2022 17:30:23 - INFO - __main__ - Step 50 Global step 50 Train loss 0.57 on epoch=24
04/27/2022 17:30:25 - INFO - __main__ - Global step 50 Train loss 1.39 ACC 0.4375 on epoch=24
04/27/2022 17:30:25 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.4375 on epoch=24, global_step=50
04/27/2022 17:30:29 - INFO - __main__ - Step 60 Global step 60 Train loss 0.55 on epoch=29
04/27/2022 17:30:33 - INFO - __main__ - Step 70 Global step 70 Train loss 0.38 on epoch=34
04/27/2022 17:30:37 - INFO - __main__ - Step 80 Global step 80 Train loss 0.42 on epoch=39
04/27/2022 17:30:41 - INFO - __main__ - Step 90 Global step 90 Train loss 0.36 on epoch=44
04/27/2022 17:30:45 - INFO - __main__ - Step 100 Global step 100 Train loss 0.42 on epoch=49
04/27/2022 17:30:46 - INFO - __main__ - Global step 100 Train loss 0.43 ACC 0.5625 on epoch=49
04/27/2022 17:30:46 - INFO - __main__ - Saving model with best ACC: 0.4375 -> 0.5625 on epoch=49, global_step=100
04/27/2022 17:30:50 - INFO - __main__ - Step 110 Global step 110 Train loss 0.24 on epoch=54
04/27/2022 17:30:54 - INFO - __main__ - Step 120 Global step 120 Train loss 0.25 on epoch=59
04/27/2022 17:30:58 - INFO - __main__ - Step 130 Global step 130 Train loss 0.26 on epoch=64
04/27/2022 17:31:02 - INFO - __main__ - Step 140 Global step 140 Train loss 0.15 on epoch=69
04/27/2022 17:31:06 - INFO - __main__ - Step 150 Global step 150 Train loss 0.18 on epoch=74
04/27/2022 17:31:07 - INFO - __main__ - Global step 150 Train loss 0.22 ACC 0.53125 on epoch=74
04/27/2022 17:31:11 - INFO - __main__ - Step 160 Global step 160 Train loss 0.22 on epoch=79
04/27/2022 17:31:15 - INFO - __main__ - Step 170 Global step 170 Train loss 0.18 on epoch=84
04/27/2022 17:31:19 - INFO - __main__ - Step 180 Global step 180 Train loss 0.15 on epoch=89
04/27/2022 17:31:23 - INFO - __main__ - Step 190 Global step 190 Train loss 0.14 on epoch=94
04/27/2022 17:31:27 - INFO - __main__ - Step 200 Global step 200 Train loss 0.10 on epoch=99
04/27/2022 17:31:29 - INFO - __main__ - Global step 200 Train loss 0.16 ACC 0.59375 on epoch=99
04/27/2022 17:31:29 - INFO - __main__ - Saving model with best ACC: 0.5625 -> 0.59375 on epoch=99, global_step=200
04/27/2022 17:31:33 - INFO - __main__ - Step 210 Global step 210 Train loss 0.12 on epoch=104
04/27/2022 17:31:37 - INFO - __main__ - Step 220 Global step 220 Train loss 0.11 on epoch=109
04/27/2022 17:31:41 - INFO - __main__ - Step 230 Global step 230 Train loss 0.09 on epoch=114
04/27/2022 17:31:45 - INFO - __main__ - Step 240 Global step 240 Train loss 0.17 on epoch=119
04/27/2022 17:31:49 - INFO - __main__ - Step 250 Global step 250 Train loss 0.08 on epoch=124
04/27/2022 17:31:51 - INFO - __main__ - Global step 250 Train loss 0.12 ACC 0.5625 on epoch=124
04/27/2022 17:31:55 - INFO - __main__ - Step 260 Global step 260 Train loss 0.11 on epoch=129
04/27/2022 17:31:59 - INFO - __main__ - Step 270 Global step 270 Train loss 0.09 on epoch=134
04/27/2022 17:32:03 - INFO - __main__ - Step 280 Global step 280 Train loss 0.05 on epoch=139
04/27/2022 17:32:07 - INFO - __main__ - Step 290 Global step 290 Train loss 0.10 on epoch=144
04/27/2022 17:32:11 - INFO - __main__ - Step 300 Global step 300 Train loss 0.09 on epoch=149
04/27/2022 17:32:13 - INFO - __main__ - Global step 300 Train loss 0.09 ACC 0.65625 on epoch=149
04/27/2022 17:32:13 - INFO - __main__ - Saving model with best ACC: 0.59375 -> 0.65625 on epoch=149, global_step=300
04/27/2022 17:32:17 - INFO - __main__ - Step 310 Global step 310 Train loss 0.11 on epoch=154
04/27/2022 17:32:21 - INFO - __main__ - Step 320 Global step 320 Train loss 0.08 on epoch=159
04/27/2022 17:32:25 - INFO - __main__ - Step 330 Global step 330 Train loss 0.04 on epoch=164
04/27/2022 17:32:29 - INFO - __main__ - Step 340 Global step 340 Train loss 0.08 on epoch=169
04/27/2022 17:32:33 - INFO - __main__ - Step 350 Global step 350 Train loss 0.04 on epoch=174
04/27/2022 17:32:35 - INFO - __main__ - Global step 350 Train loss 0.07 ACC 0.71875 on epoch=174
04/27/2022 17:32:35 - INFO - __main__ - Saving model with best ACC: 0.65625 -> 0.71875 on epoch=174, global_step=350
04/27/2022 17:32:39 - INFO - __main__ - Step 360 Global step 360 Train loss 0.03 on epoch=179
04/27/2022 17:32:43 - INFO - __main__ - Step 370 Global step 370 Train loss 0.04 on epoch=184
04/27/2022 17:32:47 - INFO - __main__ - Step 380 Global step 380 Train loss 0.05 on epoch=189
04/27/2022 17:32:51 - INFO - __main__ - Step 390 Global step 390 Train loss 0.06 on epoch=194
04/27/2022 17:32:55 - INFO - __main__ - Step 400 Global step 400 Train loss 0.07 on epoch=199
04/27/2022 17:32:57 - INFO - __main__ - Global step 400 Train loss 0.05 ACC 0.84375 on epoch=199
04/27/2022 17:32:57 - INFO - __main__ - Saving model with best ACC: 0.71875 -> 0.84375 on epoch=199, global_step=400
04/27/2022 17:33:01 - INFO - __main__ - Step 410 Global step 410 Train loss 0.03 on epoch=204
04/27/2022 17:33:05 - INFO - __main__ - Step 420 Global step 420 Train loss 0.06 on epoch=209
04/27/2022 17:33:09 - INFO - __main__ - Step 430 Global step 430 Train loss 0.04 on epoch=214
04/27/2022 17:33:13 - INFO - __main__ - Step 440 Global step 440 Train loss 0.07 on epoch=219
04/27/2022 17:33:17 - INFO - __main__ - Step 450 Global step 450 Train loss 0.04 on epoch=224
04/27/2022 17:33:18 - INFO - __main__ - Global step 450 Train loss 0.05 ACC 0.75 on epoch=224
04/27/2022 17:33:22 - INFO - __main__ - Step 460 Global step 460 Train loss 0.03 on epoch=229
04/27/2022 17:33:26 - INFO - __main__ - Step 470 Global step 470 Train loss 0.03 on epoch=234
04/27/2022 17:33:30 - INFO - __main__ - Step 480 Global step 480 Train loss 0.02 on epoch=239
04/27/2022 17:33:34 - INFO - __main__ - Step 490 Global step 490 Train loss 0.03 on epoch=244
04/27/2022 17:33:38 - INFO - __main__ - Step 500 Global step 500 Train loss 0.04 on epoch=249
04/27/2022 17:33:40 - INFO - __main__ - Global step 500 Train loss 0.03 ACC 0.75 on epoch=249
04/27/2022 17:33:44 - INFO - __main__ - Step 510 Global step 510 Train loss 0.01 on epoch=254
04/27/2022 17:33:48 - INFO - __main__ - Step 520 Global step 520 Train loss 0.01 on epoch=259
04/27/2022 17:33:52 - INFO - __main__ - Step 530 Global step 530 Train loss 0.02 on epoch=264
04/27/2022 17:33:56 - INFO - __main__ - Step 540 Global step 540 Train loss 0.06 on epoch=269
04/27/2022 17:34:00 - INFO - __main__ - Step 550 Global step 550 Train loss 0.02 on epoch=274
04/27/2022 17:34:01 - INFO - __main__ - Global step 550 Train loss 0.03 ACC 0.78125 on epoch=274
04/27/2022 17:34:05 - INFO - __main__ - Step 560 Global step 560 Train loss 0.02 on epoch=279
04/27/2022 17:34:09 - INFO - __main__ - Step 570 Global step 570 Train loss 0.02 on epoch=284
04/27/2022 17:34:13 - INFO - __main__ - Step 580 Global step 580 Train loss 0.03 on epoch=289
04/27/2022 17:34:17 - INFO - __main__ - Step 590 Global step 590 Train loss 0.02 on epoch=294
04/27/2022 17:34:21 - INFO - __main__ - Step 600 Global step 600 Train loss 0.01 on epoch=299
04/27/2022 17:34:23 - INFO - __main__ - Global step 600 Train loss 0.02 ACC 0.78125 on epoch=299
04/27/2022 17:34:27 - INFO - __main__ - Step 610 Global step 610 Train loss 0.03 on epoch=304
04/27/2022 17:34:31 - INFO - __main__ - Step 620 Global step 620 Train loss 0.02 on epoch=309
04/27/2022 17:34:35 - INFO - __main__ - Step 630 Global step 630 Train loss 0.03 on epoch=314
04/27/2022 17:34:39 - INFO - __main__ - Step 640 Global step 640 Train loss 0.01 on epoch=319
04/27/2022 17:34:43 - INFO - __main__ - Step 650 Global step 650 Train loss 0.01 on epoch=324
04/27/2022 17:34:45 - INFO - __main__ - Global step 650 Train loss 0.02 ACC 0.75 on epoch=324
04/27/2022 17:34:49 - INFO - __main__ - Step 660 Global step 660 Train loss 0.04 on epoch=329
04/27/2022 17:34:53 - INFO - __main__ - Step 670 Global step 670 Train loss 0.01 on epoch=334
04/27/2022 17:34:57 - INFO - __main__ - Step 680 Global step 680 Train loss 0.01 on epoch=339
04/27/2022 17:35:01 - INFO - __main__ - Step 690 Global step 690 Train loss 0.01 on epoch=344
04/27/2022 17:35:05 - INFO - __main__ - Step 700 Global step 700 Train loss 0.01 on epoch=349
04/27/2022 17:35:07 - INFO - __main__ - Global step 700 Train loss 0.02 ACC 0.75 on epoch=349
04/27/2022 17:35:11 - INFO - __main__ - Step 710 Global step 710 Train loss 0.01 on epoch=354
04/27/2022 17:35:15 - INFO - __main__ - Step 720 Global step 720 Train loss 0.03 on epoch=359
04/27/2022 17:35:19 - INFO - __main__ - Step 730 Global step 730 Train loss 0.01 on epoch=364
04/27/2022 17:35:23 - INFO - __main__ - Step 740 Global step 740 Train loss 0.02 on epoch=369
04/27/2022 17:35:27 - INFO - __main__ - Step 750 Global step 750 Train loss 0.02 on epoch=374
04/27/2022 17:35:29 - INFO - __main__ - Global step 750 Train loss 0.02 ACC 0.65625 on epoch=374
04/27/2022 17:35:33 - INFO - __main__ - Step 760 Global step 760 Train loss 0.03 on epoch=379
04/27/2022 17:35:37 - INFO - __main__ - Step 770 Global step 770 Train loss 0.01 on epoch=384
04/27/2022 17:35:41 - INFO - __main__ - Step 780 Global step 780 Train loss 0.01 on epoch=389
04/27/2022 17:35:45 - INFO - __main__ - Step 790 Global step 790 Train loss 0.02 on epoch=394
04/27/2022 17:35:49 - INFO - __main__ - Step 800 Global step 800 Train loss 0.00 on epoch=399
04/27/2022 17:35:51 - INFO - __main__ - Global step 800 Train loss 0.01 ACC 0.6875 on epoch=399
04/27/2022 17:35:55 - INFO - __main__ - Step 810 Global step 810 Train loss 0.02 on epoch=404
04/27/2022 17:35:59 - INFO - __main__ - Step 820 Global step 820 Train loss 0.01 on epoch=409
04/27/2022 17:36:03 - INFO - __main__ - Step 830 Global step 830 Train loss 0.02 on epoch=414
04/27/2022 17:36:07 - INFO - __main__ - Step 840 Global step 840 Train loss 0.01 on epoch=419
04/27/2022 17:36:11 - INFO - __main__ - Step 850 Global step 850 Train loss 0.04 on epoch=424
04/27/2022 17:36:12 - INFO - __main__ - Global step 850 Train loss 0.02 ACC 0.8125 on epoch=424
04/27/2022 17:36:16 - INFO - __main__ - Step 860 Global step 860 Train loss 0.01 on epoch=429
04/27/2022 17:36:20 - INFO - __main__ - Step 870 Global step 870 Train loss 0.02 on epoch=434
04/27/2022 17:36:24 - INFO - __main__ - Step 880 Global step 880 Train loss 0.02 on epoch=439
04/27/2022 17:36:28 - INFO - __main__ - Step 890 Global step 890 Train loss 0.04 on epoch=444
04/27/2022 17:36:32 - INFO - __main__ - Step 900 Global step 900 Train loss 0.01 on epoch=449
04/27/2022 17:36:34 - INFO - __main__ - Global step 900 Train loss 0.02 ACC 0.84375 on epoch=449
04/27/2022 17:36:38 - INFO - __main__ - Step 910 Global step 910 Train loss 0.01 on epoch=454
04/27/2022 17:36:42 - INFO - __main__ - Step 920 Global step 920 Train loss 0.03 on epoch=459
04/27/2022 17:36:46 - INFO - __main__ - Step 930 Global step 930 Train loss 0.01 on epoch=464
04/27/2022 17:36:50 - INFO - __main__ - Step 940 Global step 940 Train loss 0.01 on epoch=469
04/27/2022 17:36:54 - INFO - __main__ - Step 950 Global step 950 Train loss 0.01 on epoch=474
04/27/2022 17:36:56 - INFO - __main__ - Global step 950 Train loss 0.01 ACC 0.875 on epoch=474
04/27/2022 17:36:56 - INFO - __main__ - Saving model with best ACC: 0.84375 -> 0.875 on epoch=474, global_step=950
04/27/2022 17:37:00 - INFO - __main__ - Step 960 Global step 960 Train loss 0.03 on epoch=479
04/27/2022 17:37:04 - INFO - __main__ - Step 970 Global step 970 Train loss 0.01 on epoch=484
04/27/2022 17:37:08 - INFO - __main__ - Step 980 Global step 980 Train loss 0.01 on epoch=489
04/27/2022 17:37:12 - INFO - __main__ - Step 990 Global step 990 Train loss 0.01 on epoch=494
04/27/2022 17:37:16 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.02 on epoch=499
04/27/2022 17:37:18 - INFO - __main__ - Global step 1000 Train loss 0.01 ACC 0.875 on epoch=499
04/27/2022 17:37:22 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.01 on epoch=504
04/27/2022 17:37:26 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.02 on epoch=509
04/27/2022 17:37:30 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.01 on epoch=514
04/27/2022 17:37:34 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.01 on epoch=519
04/27/2022 17:37:38 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.01 on epoch=524
04/27/2022 17:37:40 - INFO - __main__ - Global step 1050 Train loss 0.01 ACC 0.75 on epoch=524
04/27/2022 17:37:44 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.01 on epoch=529
04/27/2022 17:37:48 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.02 on epoch=534
04/27/2022 17:37:52 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.01 on epoch=539
04/27/2022 17:37:56 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.00 on epoch=544
04/27/2022 17:38:00 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.00 on epoch=549
04/27/2022 17:38:02 - INFO - __main__ - Global step 1100 Train loss 0.01 ACC 0.84375 on epoch=549
04/27/2022 17:38:06 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.01 on epoch=554
04/27/2022 17:38:10 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=559
04/27/2022 17:38:14 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=564
04/27/2022 17:38:18 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.01 on epoch=569
04/27/2022 17:38:22 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=574
04/27/2022 17:38:24 - INFO - __main__ - Global step 1150 Train loss 0.01 ACC 0.8125 on epoch=574
04/27/2022 17:38:28 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.01 on epoch=579
04/27/2022 17:38:32 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.01 on epoch=584
04/27/2022 17:38:36 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.01 on epoch=589
04/27/2022 17:38:40 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.01 on epoch=594
04/27/2022 17:38:44 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.00 on epoch=599
04/27/2022 17:38:46 - INFO - __main__ - Global step 1200 Train loss 0.01 ACC 0.78125 on epoch=599
04/27/2022 17:38:50 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.00 on epoch=604
04/27/2022 17:38:54 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=609
04/27/2022 17:38:58 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.03 on epoch=614
04/27/2022 17:39:02 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=619
04/27/2022 17:39:06 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.00 on epoch=624
04/27/2022 17:39:08 - INFO - __main__ - Global step 1250 Train loss 0.01 ACC 0.6875 on epoch=624
04/27/2022 17:39:12 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=629
04/27/2022 17:39:16 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.01 on epoch=634
04/27/2022 17:39:20 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.00 on epoch=639
04/27/2022 17:39:24 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.00 on epoch=644
04/27/2022 17:39:28 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.02 on epoch=649
04/27/2022 17:39:30 - INFO - __main__ - Global step 1300 Train loss 0.01 ACC 0.78125 on epoch=649
04/27/2022 17:39:34 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=654
04/27/2022 17:39:38 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=659
04/27/2022 17:39:42 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.00 on epoch=664
04/27/2022 17:39:46 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.00 on epoch=669
04/27/2022 17:39:50 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=674
04/27/2022 17:39:52 - INFO - __main__ - Global step 1350 Train loss 0.01 ACC 0.78125 on epoch=674
04/27/2022 17:39:56 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=679
04/27/2022 17:40:00 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=684
04/27/2022 17:40:04 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=689
04/27/2022 17:40:08 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.00 on epoch=694
04/27/2022 17:40:12 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.00 on epoch=699
04/27/2022 17:40:14 - INFO - __main__ - Global step 1400 Train loss 0.01 ACC 0.875 on epoch=699
04/27/2022 17:40:18 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=704
04/27/2022 17:40:22 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=709
04/27/2022 17:40:26 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.00 on epoch=714
04/27/2022 17:40:30 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=719
04/27/2022 17:40:34 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=724
04/27/2022 17:40:36 - INFO - __main__ - Global step 1450 Train loss 0.00 ACC 0.8125 on epoch=724
04/27/2022 17:40:40 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=729
04/27/2022 17:40:43 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=734
04/27/2022 17:40:47 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=739
04/27/2022 17:40:51 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=744
04/27/2022 17:40:55 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=749
04/27/2022 17:40:57 - INFO - __main__ - Global step 1500 Train loss 0.01 ACC 0.84375 on epoch=749
04/27/2022 17:41:01 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=754
04/27/2022 17:41:05 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=759
04/27/2022 17:41:09 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=764
04/27/2022 17:41:13 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=769
04/27/2022 17:41:17 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=774
04/27/2022 17:41:19 - INFO - __main__ - Global step 1550 Train loss 0.01 ACC 0.78125 on epoch=774
04/27/2022 17:41:23 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=779
04/27/2022 17:41:27 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=784
04/27/2022 17:41:31 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=789
04/27/2022 17:41:35 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=794
04/27/2022 17:41:39 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=799
04/27/2022 17:41:41 - INFO - __main__ - Global step 1600 Train loss 0.01 ACC 0.84375 on epoch=799
04/27/2022 17:41:45 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=804
04/27/2022 17:41:49 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=809
04/27/2022 17:41:53 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=814
04/27/2022 17:41:57 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=819
04/27/2022 17:42:01 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=824
04/27/2022 17:42:03 - INFO - __main__ - Global step 1650 Train loss 0.00 ACC 0.75 on epoch=824
04/27/2022 17:42:07 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=829
04/27/2022 17:42:11 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=834
04/27/2022 17:42:15 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.03 on epoch=839
04/27/2022 17:42:19 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=844
04/27/2022 17:42:23 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=849
04/27/2022 17:42:25 - INFO - __main__ - Global step 1700 Train loss 0.01 ACC 0.78125 on epoch=849
04/27/2022 17:42:29 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=854
04/27/2022 17:42:33 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=859
04/27/2022 17:42:37 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=864
04/27/2022 17:42:41 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=869
04/27/2022 17:42:45 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=874
04/27/2022 17:42:47 - INFO - __main__ - Global step 1750 Train loss 0.01 ACC 0.8125 on epoch=874
04/27/2022 17:42:51 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=879
04/27/2022 17:42:55 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=884
04/27/2022 17:42:58 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=889
04/27/2022 17:43:02 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=894
04/27/2022 17:43:06 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=899
04/27/2022 17:43:08 - INFO - __main__ - Global step 1800 Train loss 0.01 ACC 0.84375 on epoch=899
04/27/2022 17:43:12 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=904
04/27/2022 17:43:16 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=909
04/27/2022 17:43:20 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=914
04/27/2022 17:43:24 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=919
04/27/2022 17:43:28 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=924
04/27/2022 17:43:30 - INFO - __main__ - Global step 1850 Train loss 0.01 ACC 0.8125 on epoch=924
04/27/2022 17:43:34 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=929
04/27/2022 17:43:38 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=934
04/27/2022 17:43:42 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=939
04/27/2022 17:43:46 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=944
04/27/2022 17:43:50 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=949
04/27/2022 17:43:52 - INFO - __main__ - Global step 1900 Train loss 0.01 ACC 0.8125 on epoch=949
04/27/2022 17:43:56 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=954
04/27/2022 17:44:00 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=959
04/27/2022 17:44:04 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=964
04/27/2022 17:44:08 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=969
04/27/2022 17:44:12 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=974
04/27/2022 17:44:14 - INFO - __main__ - Global step 1950 Train loss 0.00 ACC 0.84375 on epoch=974
04/27/2022 17:44:18 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=979
04/27/2022 17:44:22 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=984
04/27/2022 17:44:26 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=989
04/27/2022 17:44:30 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=994
04/27/2022 17:44:34 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=999
04/27/2022 17:44:35 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 17:44:35 - INFO - __main__ - Printing 3 examples
04/27/2022 17:44:35 - INFO - __main__ -  [sciq] Fractures, rickets, and osteoarthritis all affect what part(s) of the body? (A) fossils (B) Heart (C) bones (D) animals [SEP] Despite their hardness and strength, bones can suffer from injury and disease. Bone problems include fractures, osteoarthritis, and rickets.
04/27/2022 17:44:35 - INFO - __main__ - ['bones']
04/27/2022 17:44:35 - INFO - __main__ -  [sciq] What does a keratometer measure in the cornea? (A) diameter (B) curve (C) Lenght (D) Width [SEP] 25.7 Image Formation by Mirrors 53. What is the focal length of a makeup mirror that has a power of 1.50 D? 54. Some telephoto cameras use a mirror rather than a lens. What radius of curvature mirror is needed to replace a 800 mm focal length telephoto lens? 55. (a) Calculate the focal length of the mirror formed by the shiny back of a spoon that has a 3.00 cm radius of curvature. (b) What is its power in diopters? 56. Find the magnification of the heater element in Example 25.9. Note that its large magnitude helps spread out the reflected energy. What is the focal length of a makeup mirror that produces a magnification of 1.50 when a person’s face is 12.0 cm away? Explicitly show how you follow the steps in the Problem-Solving Strategy for Mirrors. A shopper standing 3.00 m from a convex security mirror sees his image with a magnification of 0.250. (a) Where is his image? (b) What is the focal length of the mirror? (c) What is its radius of curvature? Explicitly show how you follow the steps in the Problem-Solving Strategy for Mirrors. An object 1.50 cm high is held 3.00 cm from a person’s cornea, and its reflected image is measured to be 0.167 cm high. (a) What is the magnification? (b) Where is the image? (c) Find the radius of curvature of the convex mirror formed by the cornea. (Note that this technique is used by optometrists to measure the curvature of the cornea for contact lens fitting. The instrument used is called a keratometer, or curve measurer. ) 60. Ray tracing for a flat mirror shows that the image is located a distance behind the mirror equal to the distance of the object from the mirror. This is stated d i = –d o , since this is a negative image distance (it is a virtual image). (a) What is the focal length of a flat mirror? (b) What is its power?.
04/27/2022 17:44:35 - INFO - __main__ - ['curve']
04/27/2022 17:44:35 - INFO - __main__ -  [sciq] Most carcinogens produce mutations in genes that control what? (A) proteins cycle (B) cell cycle (C) ubiquitous cycle (D) digestive cycle [SEP] Most carcinogens produce mutations in genes that control the cell cycle.
04/27/2022 17:44:35 - INFO - __main__ - ['cell cycle']
04/27/2022 17:44:35 - INFO - __main__ - Tokenizing Input ...
04/27/2022 17:44:35 - INFO - __main__ - Tokenizing Output ...
04/27/2022 17:44:35 - INFO - __main__ - Loaded 32 examples from train data
04/27/2022 17:44:35 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 17:44:35 - INFO - __main__ - Printing 3 examples
04/27/2022 17:44:35 - INFO - __main__ -  [sciq] The cerebellum is associated with what major human organ? (A) bladder (B) heart (C) liver (D) brain [SEP] Figure 13.13 The Cerebellum The cerebellum is situated on the posterior surface of the brain stem. Descending input from the cerebellum enters through the large white matter structure of the pons. Ascending input from the periphery and spinal cord enters through the fibers of the inferior olive. Output goes to the midbrain, which sends a descending signal to the spinal cord.
04/27/2022 17:44:35 - INFO - __main__ - ['brain']
04/27/2022 17:44:35 - INFO - __main__ -  [sciq] What is the term for the energy of motion, which is exhibited by the speed of an object? (A) inertia (B) kinetic energy (C) mechanical energy (D) residual energy [SEP] The energy of motion is kinetic energy, KE. Whenever an object is in motion it has kinetic energy. The faster it is going, the more energy it has.
04/27/2022 17:44:35 - INFO - __main__ - ['kinetic energy']
04/27/2022 17:44:35 - INFO - __main__ -  [sciq] The following definition relates to which term: the application of knowledge to real-world problems? (A) capitalism (B) industry (C) invention (D) technology [SEP] Technology is the application of knowledge to real-world problems. It includes methods and processes as well as devices like computers and cars. An example is the Bessemer process. It is a cheap method of making steel that was invented in the 1850s. It is just one of many technological advances that have occurred in manufacturing. Technology is also responsible for most of the major advances in agriculture, transportation, communications, and medicine. Clearly, technology has had a huge impact on people and society. It is hard to imagine what life would be like without it.
04/27/2022 17:44:35 - INFO - __main__ - ['technology']
04/27/2022 17:44:35 - INFO - __main__ - Tokenizing Input ...
04/27/2022 17:44:35 - INFO - __main__ - Tokenizing Output ...
04/27/2022 17:44:35 - INFO - __main__ - Loaded 32 examples from dev data
04/27/2022 17:44:36 - INFO - __main__ - Global step 2000 Train loss 0.01 ACC 0.75 on epoch=999
04/27/2022 17:44:36 - INFO - __main__ - save last model!
04/27/2022 17:44:36 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
04/27/2022 17:44:36 - INFO - __main__ - Start tokenizing ... 887 instances
04/27/2022 17:44:36 - INFO - __main__ - Printing 3 examples
04/27/2022 17:44:36 - INFO - __main__ -  [sciq] A frameshift mutation is a deletion or insertion of one or more of what that changes the reading frame of the base sequence? (A) carotenoids (B) nucleotides (C) proteins (D) genes [SEP] A frameshift mutation is a deletion or insertion of one or more nucleotides that changes the reading frame of the base sequence. Deletions remove nucleotides, and insertions add nucleotides. Consider the following sequence of bases in RNA:.
04/27/2022 17:44:36 - INFO - __main__ - ['nucleotides']
04/27/2022 17:44:36 - INFO - __main__ -  [sciq] What is an area of land called that is wet for all or part of the year? (A) grassland (B) wetland (C) plains (D) tundra [SEP] A wetland is an area that is wet for all or part of the year. Wetlands are home to certain types of plants.
04/27/2022 17:44:36 - INFO - __main__ - ['wetland']
04/27/2022 17:44:36 - INFO - __main__ -  [sciq] What are arteries, veins, and capillaries examples of? (A) blood vessels (B) muscles (C) organs (D) tissue [SEP] Blood vessels include arteries, veins, and capillaries.
04/27/2022 17:44:36 - INFO - __main__ - ['blood vessels']
04/27/2022 17:44:36 - INFO - __main__ - Tokenizing Input ...
04/27/2022 17:44:36 - INFO - __main__ - Tokenizing Output ...
04/27/2022 17:44:37 - INFO - __main__ - Loaded 887 examples from test data
04/27/2022 17:44:54 - INFO - __main__ - load prompt embedding from ckpt
04/27/2022 17:44:55 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/27/2022 17:44:55 - INFO - __main__ - Starting training!
04/27/2022 17:45:22 - INFO - __main__ - Saved prediction in models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-sciq/sciq_32_13_0.4_8_predictions.txt
04/27/2022 17:45:22 - INFO - __main__ - ACC on test data: 0.7790
04/27/2022 17:45:22 - INFO - __main__ - prefix=sciq_32_13, lr=0.4, bsz=8, dev_performance=0.875, test_performance=0.7790304396843292
04/27/2022 17:45:22 - INFO - __main__ - Running ... prefix=sciq_32_13, lr=0.3, bsz=8 ...
04/27/2022 17:45:23 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 17:45:23 - INFO - __main__ - Printing 3 examples
04/27/2022 17:45:23 - INFO - __main__ -  [sciq] Fractures, rickets, and osteoarthritis all affect what part(s) of the body? (A) fossils (B) Heart (C) bones (D) animals [SEP] Despite their hardness and strength, bones can suffer from injury and disease. Bone problems include fractures, osteoarthritis, and rickets.
04/27/2022 17:45:23 - INFO - __main__ - ['bones']
04/27/2022 17:45:23 - INFO - __main__ -  [sciq] What does a keratometer measure in the cornea? (A) diameter (B) curve (C) Lenght (D) Width [SEP] 25.7 Image Formation by Mirrors 53. What is the focal length of a makeup mirror that has a power of 1.50 D? 54. Some telephoto cameras use a mirror rather than a lens. What radius of curvature mirror is needed to replace a 800 mm focal length telephoto lens? 55. (a) Calculate the focal length of the mirror formed by the shiny back of a spoon that has a 3.00 cm radius of curvature. (b) What is its power in diopters? 56. Find the magnification of the heater element in Example 25.9. Note that its large magnitude helps spread out the reflected energy. What is the focal length of a makeup mirror that produces a magnification of 1.50 when a person’s face is 12.0 cm away? Explicitly show how you follow the steps in the Problem-Solving Strategy for Mirrors. A shopper standing 3.00 m from a convex security mirror sees his image with a magnification of 0.250. (a) Where is his image? (b) What is the focal length of the mirror? (c) What is its radius of curvature? Explicitly show how you follow the steps in the Problem-Solving Strategy for Mirrors. An object 1.50 cm high is held 3.00 cm from a person’s cornea, and its reflected image is measured to be 0.167 cm high. (a) What is the magnification? (b) Where is the image? (c) Find the radius of curvature of the convex mirror formed by the cornea. (Note that this technique is used by optometrists to measure the curvature of the cornea for contact lens fitting. The instrument used is called a keratometer, or curve measurer. ) 60. Ray tracing for a flat mirror shows that the image is located a distance behind the mirror equal to the distance of the object from the mirror. This is stated d i = –d o , since this is a negative image distance (it is a virtual image). (a) What is the focal length of a flat mirror? (b) What is its power?.
04/27/2022 17:45:23 - INFO - __main__ - ['curve']
04/27/2022 17:45:23 - INFO - __main__ -  [sciq] Most carcinogens produce mutations in genes that control what? (A) proteins cycle (B) cell cycle (C) ubiquitous cycle (D) digestive cycle [SEP] Most carcinogens produce mutations in genes that control the cell cycle.
04/27/2022 17:45:23 - INFO - __main__ - ['cell cycle']
04/27/2022 17:45:23 - INFO - __main__ - Tokenizing Input ...
04/27/2022 17:45:23 - INFO - __main__ - Tokenizing Output ...
04/27/2022 17:45:23 - INFO - __main__ - Loaded 32 examples from train data
04/27/2022 17:45:23 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 17:45:23 - INFO - __main__ - Printing 3 examples
04/27/2022 17:45:23 - INFO - __main__ -  [sciq] The cerebellum is associated with what major human organ? (A) bladder (B) heart (C) liver (D) brain [SEP] Figure 13.13 The Cerebellum The cerebellum is situated on the posterior surface of the brain stem. Descending input from the cerebellum enters through the large white matter structure of the pons. Ascending input from the periphery and spinal cord enters through the fibers of the inferior olive. Output goes to the midbrain, which sends a descending signal to the spinal cord.
04/27/2022 17:45:23 - INFO - __main__ - ['brain']
04/27/2022 17:45:23 - INFO - __main__ -  [sciq] What is the term for the energy of motion, which is exhibited by the speed of an object? (A) inertia (B) kinetic energy (C) mechanical energy (D) residual energy [SEP] The energy of motion is kinetic energy, KE. Whenever an object is in motion it has kinetic energy. The faster it is going, the more energy it has.
04/27/2022 17:45:23 - INFO - __main__ - ['kinetic energy']
04/27/2022 17:45:23 - INFO - __main__ -  [sciq] The following definition relates to which term: the application of knowledge to real-world problems? (A) capitalism (B) industry (C) invention (D) technology [SEP] Technology is the application of knowledge to real-world problems. It includes methods and processes as well as devices like computers and cars. An example is the Bessemer process. It is a cheap method of making steel that was invented in the 1850s. It is just one of many technological advances that have occurred in manufacturing. Technology is also responsible for most of the major advances in agriculture, transportation, communications, and medicine. Clearly, technology has had a huge impact on people and society. It is hard to imagine what life would be like without it.
04/27/2022 17:45:23 - INFO - __main__ - ['technology']
04/27/2022 17:45:23 - INFO - __main__ - Tokenizing Input ...
04/27/2022 17:45:23 - INFO - __main__ - Tokenizing Output ...
04/27/2022 17:45:23 - INFO - __main__ - Loaded 32 examples from dev data
04/27/2022 17:45:40 - INFO - __main__ - load prompt embedding from ckpt
04/27/2022 17:45:41 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/27/2022 17:45:41 - INFO - __main__ - Starting training!
04/27/2022 17:45:46 - INFO - __main__ - Step 10 Global step 10 Train loss 2.91 on epoch=4
04/27/2022 17:45:50 - INFO - __main__ - Step 20 Global step 20 Train loss 1.76 on epoch=9
04/27/2022 17:45:54 - INFO - __main__ - Step 30 Global step 30 Train loss 1.16 on epoch=14
04/27/2022 17:45:58 - INFO - __main__ - Step 40 Global step 40 Train loss 0.83 on epoch=19
04/27/2022 17:46:02 - INFO - __main__ - Step 50 Global step 50 Train loss 0.72 on epoch=24
04/27/2022 17:46:03 - INFO - __main__ - Global step 50 Train loss 1.48 ACC 0.40625 on epoch=24
04/27/2022 17:46:03 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.40625 on epoch=24, global_step=50
04/27/2022 17:46:07 - INFO - __main__ - Step 60 Global step 60 Train loss 0.64 on epoch=29
04/27/2022 17:46:11 - INFO - __main__ - Step 70 Global step 70 Train loss 0.46 on epoch=34
04/27/2022 17:46:15 - INFO - __main__ - Step 80 Global step 80 Train loss 0.47 on epoch=39
04/27/2022 17:46:19 - INFO - __main__ - Step 90 Global step 90 Train loss 0.46 on epoch=44
04/27/2022 17:46:23 - INFO - __main__ - Step 100 Global step 100 Train loss 0.38 on epoch=49
04/27/2022 17:46:24 - INFO - __main__ - Global step 100 Train loss 0.48 ACC 0.46875 on epoch=49
04/27/2022 17:46:24 - INFO - __main__ - Saving model with best ACC: 0.40625 -> 0.46875 on epoch=49, global_step=100
04/27/2022 17:46:28 - INFO - __main__ - Step 110 Global step 110 Train loss 0.38 on epoch=54
04/27/2022 17:46:32 - INFO - __main__ - Step 120 Global step 120 Train loss 0.30 on epoch=59
04/27/2022 17:46:36 - INFO - __main__ - Step 130 Global step 130 Train loss 0.24 on epoch=64
04/27/2022 17:46:40 - INFO - __main__ - Step 140 Global step 140 Train loss 0.24 on epoch=69
04/27/2022 17:46:44 - INFO - __main__ - Step 150 Global step 150 Train loss 0.22 on epoch=74
04/27/2022 17:46:46 - INFO - __main__ - Global step 150 Train loss 0.28 ACC 0.6875 on epoch=74
04/27/2022 17:46:46 - INFO - __main__ - Saving model with best ACC: 0.46875 -> 0.6875 on epoch=74, global_step=150
04/27/2022 17:46:50 - INFO - __main__ - Step 160 Global step 160 Train loss 0.20 on epoch=79
04/27/2022 17:46:54 - INFO - __main__ - Step 170 Global step 170 Train loss 0.16 on epoch=84
04/27/2022 17:46:58 - INFO - __main__ - Step 180 Global step 180 Train loss 0.13 on epoch=89
04/27/2022 17:47:02 - INFO - __main__ - Step 190 Global step 190 Train loss 0.12 on epoch=94
04/27/2022 17:47:06 - INFO - __main__ - Step 200 Global step 200 Train loss 0.21 on epoch=99
04/27/2022 17:47:07 - INFO - __main__ - Global step 200 Train loss 0.16 ACC 0.6875 on epoch=99
04/27/2022 17:47:11 - INFO - __main__ - Step 210 Global step 210 Train loss 0.12 on epoch=104
04/27/2022 17:47:15 - INFO - __main__ - Step 220 Global step 220 Train loss 0.16 on epoch=109
04/27/2022 17:47:19 - INFO - __main__ - Step 230 Global step 230 Train loss 0.11 on epoch=114
04/27/2022 17:47:23 - INFO - __main__ - Step 240 Global step 240 Train loss 0.10 on epoch=119
04/27/2022 17:47:27 - INFO - __main__ - Step 250 Global step 250 Train loss 0.16 on epoch=124
04/27/2022 17:47:29 - INFO - __main__ - Global step 250 Train loss 0.13 ACC 0.75 on epoch=124
04/27/2022 17:47:29 - INFO - __main__ - Saving model with best ACC: 0.6875 -> 0.75 on epoch=124, global_step=250
04/27/2022 17:47:33 - INFO - __main__ - Step 260 Global step 260 Train loss 0.10 on epoch=129
04/27/2022 17:47:37 - INFO - __main__ - Step 270 Global step 270 Train loss 0.08 on epoch=134
04/27/2022 17:47:41 - INFO - __main__ - Step 280 Global step 280 Train loss 0.06 on epoch=139
04/27/2022 17:47:45 - INFO - __main__ - Step 290 Global step 290 Train loss 0.07 on epoch=144
04/27/2022 17:47:49 - INFO - __main__ - Step 300 Global step 300 Train loss 0.10 on epoch=149
04/27/2022 17:47:50 - INFO - __main__ - Global step 300 Train loss 0.08 ACC 0.75 on epoch=149
04/27/2022 17:47:54 - INFO - __main__ - Step 310 Global step 310 Train loss 0.07 on epoch=154
04/27/2022 17:47:58 - INFO - __main__ - Step 320 Global step 320 Train loss 0.12 on epoch=159
04/27/2022 17:48:02 - INFO - __main__ - Step 330 Global step 330 Train loss 0.12 on epoch=164
04/27/2022 17:48:06 - INFO - __main__ - Step 340 Global step 340 Train loss 0.08 on epoch=169
04/27/2022 17:48:10 - INFO - __main__ - Step 350 Global step 350 Train loss 0.06 on epoch=174
04/27/2022 17:48:12 - INFO - __main__ - Global step 350 Train loss 0.09 ACC 0.71875 on epoch=174
04/27/2022 17:48:16 - INFO - __main__ - Step 360 Global step 360 Train loss 0.08 on epoch=179
04/27/2022 17:48:20 - INFO - __main__ - Step 370 Global step 370 Train loss 0.07 on epoch=184
04/27/2022 17:48:24 - INFO - __main__ - Step 380 Global step 380 Train loss 0.08 on epoch=189
04/27/2022 17:48:28 - INFO - __main__ - Step 390 Global step 390 Train loss 0.07 on epoch=194
04/27/2022 17:48:32 - INFO - __main__ - Step 400 Global step 400 Train loss 0.11 on epoch=199
04/27/2022 17:48:34 - INFO - __main__ - Global step 400 Train loss 0.08 ACC 0.71875 on epoch=199
04/27/2022 17:48:38 - INFO - __main__ - Step 410 Global step 410 Train loss 0.05 on epoch=204
04/27/2022 17:48:42 - INFO - __main__ - Step 420 Global step 420 Train loss 0.05 on epoch=209
04/27/2022 17:48:46 - INFO - __main__ - Step 430 Global step 430 Train loss 0.06 on epoch=214
04/27/2022 17:48:50 - INFO - __main__ - Step 440 Global step 440 Train loss 0.04 on epoch=219
04/27/2022 17:48:54 - INFO - __main__ - Step 450 Global step 450 Train loss 0.05 on epoch=224
04/27/2022 17:48:55 - INFO - __main__ - Global step 450 Train loss 0.05 ACC 0.71875 on epoch=224
04/27/2022 17:48:59 - INFO - __main__ - Step 460 Global step 460 Train loss 0.07 on epoch=229
04/27/2022 17:49:03 - INFO - __main__ - Step 470 Global step 470 Train loss 0.03 on epoch=234
04/27/2022 17:49:07 - INFO - __main__ - Step 480 Global step 480 Train loss 0.03 on epoch=239
04/27/2022 17:49:11 - INFO - __main__ - Step 490 Global step 490 Train loss 0.03 on epoch=244
04/27/2022 17:49:15 - INFO - __main__ - Step 500 Global step 500 Train loss 0.05 on epoch=249
04/27/2022 17:49:17 - INFO - __main__ - Global step 500 Train loss 0.04 ACC 0.6875 on epoch=249
04/27/2022 17:49:21 - INFO - __main__ - Step 510 Global step 510 Train loss 0.04 on epoch=254
04/27/2022 17:49:25 - INFO - __main__ - Step 520 Global step 520 Train loss 0.05 on epoch=259
04/27/2022 17:49:29 - INFO - __main__ - Step 530 Global step 530 Train loss 0.03 on epoch=264
04/27/2022 17:49:33 - INFO - __main__ - Step 540 Global step 540 Train loss 0.06 on epoch=269
04/27/2022 17:49:37 - INFO - __main__ - Step 550 Global step 550 Train loss 0.02 on epoch=274
04/27/2022 17:49:39 - INFO - __main__ - Global step 550 Train loss 0.04 ACC 0.75 on epoch=274
04/27/2022 17:49:43 - INFO - __main__ - Step 560 Global step 560 Train loss 0.04 on epoch=279
04/27/2022 17:49:47 - INFO - __main__ - Step 570 Global step 570 Train loss 0.03 on epoch=284
04/27/2022 17:49:51 - INFO - __main__ - Step 580 Global step 580 Train loss 0.02 on epoch=289
04/27/2022 17:49:55 - INFO - __main__ - Step 590 Global step 590 Train loss 0.04 on epoch=294
04/27/2022 17:49:59 - INFO - __main__ - Step 600 Global step 600 Train loss 0.05 on epoch=299
04/27/2022 17:50:01 - INFO - __main__ - Global step 600 Train loss 0.04 ACC 0.8125 on epoch=299
04/27/2022 17:50:01 - INFO - __main__ - Saving model with best ACC: 0.75 -> 0.8125 on epoch=299, global_step=600
04/27/2022 17:50:05 - INFO - __main__ - Step 610 Global step 610 Train loss 0.03 on epoch=304
04/27/2022 17:50:09 - INFO - __main__ - Step 620 Global step 620 Train loss 0.03 on epoch=309
04/27/2022 17:50:13 - INFO - __main__ - Step 630 Global step 630 Train loss 0.03 on epoch=314
04/27/2022 17:50:17 - INFO - __main__ - Step 640 Global step 640 Train loss 0.02 on epoch=319
04/27/2022 17:50:21 - INFO - __main__ - Step 650 Global step 650 Train loss 0.07 on epoch=324
04/27/2022 17:50:23 - INFO - __main__ - Global step 650 Train loss 0.04 ACC 0.875 on epoch=324
04/27/2022 17:50:23 - INFO - __main__ - Saving model with best ACC: 0.8125 -> 0.875 on epoch=324, global_step=650
04/27/2022 17:50:27 - INFO - __main__ - Step 660 Global step 660 Train loss 0.03 on epoch=329
04/27/2022 17:50:31 - INFO - __main__ - Step 670 Global step 670 Train loss 0.01 on epoch=334
04/27/2022 17:50:35 - INFO - __main__ - Step 680 Global step 680 Train loss 0.02 on epoch=339
04/27/2022 17:50:39 - INFO - __main__ - Step 690 Global step 690 Train loss 0.02 on epoch=344
04/27/2022 17:50:43 - INFO - __main__ - Step 700 Global step 700 Train loss 0.01 on epoch=349
04/27/2022 17:50:45 - INFO - __main__ - Global step 700 Train loss 0.02 ACC 0.75 on epoch=349
04/27/2022 17:50:49 - INFO - __main__ - Step 710 Global step 710 Train loss 0.02 on epoch=354
04/27/2022 17:50:53 - INFO - __main__ - Step 720 Global step 720 Train loss 0.01 on epoch=359
04/27/2022 17:50:57 - INFO - __main__ - Step 730 Global step 730 Train loss 0.01 on epoch=364
04/27/2022 17:51:01 - INFO - __main__ - Step 740 Global step 740 Train loss 0.02 on epoch=369
04/27/2022 17:51:05 - INFO - __main__ - Step 750 Global step 750 Train loss 0.01 on epoch=374
04/27/2022 17:51:07 - INFO - __main__ - Global step 750 Train loss 0.01 ACC 0.8125 on epoch=374
04/27/2022 17:51:11 - INFO - __main__ - Step 760 Global step 760 Train loss 0.01 on epoch=379
04/27/2022 17:51:15 - INFO - __main__ - Step 770 Global step 770 Train loss 0.04 on epoch=384
04/27/2022 17:51:19 - INFO - __main__ - Step 780 Global step 780 Train loss 0.01 on epoch=389
04/27/2022 17:51:23 - INFO - __main__ - Step 790 Global step 790 Train loss 0.01 on epoch=394
04/27/2022 17:51:27 - INFO - __main__ - Step 800 Global step 800 Train loss 0.02 on epoch=399
04/27/2022 17:51:29 - INFO - __main__ - Global step 800 Train loss 0.02 ACC 0.78125 on epoch=399
04/27/2022 17:51:33 - INFO - __main__ - Step 810 Global step 810 Train loss 0.10 on epoch=404
04/27/2022 17:51:37 - INFO - __main__ - Step 820 Global step 820 Train loss 0.02 on epoch=409
04/27/2022 17:51:41 - INFO - __main__ - Step 830 Global step 830 Train loss 0.01 on epoch=414
04/27/2022 17:51:45 - INFO - __main__ - Step 840 Global step 840 Train loss 0.01 on epoch=419
04/27/2022 17:51:49 - INFO - __main__ - Step 850 Global step 850 Train loss 0.01 on epoch=424
04/27/2022 17:51:51 - INFO - __main__ - Global step 850 Train loss 0.03 ACC 0.75 on epoch=424
04/27/2022 17:51:55 - INFO - __main__ - Step 860 Global step 860 Train loss 0.02 on epoch=429
04/27/2022 17:51:59 - INFO - __main__ - Step 870 Global step 870 Train loss 0.03 on epoch=434
04/27/2022 17:52:03 - INFO - __main__ - Step 880 Global step 880 Train loss 0.01 on epoch=439
04/27/2022 17:52:07 - INFO - __main__ - Step 890 Global step 890 Train loss 0.03 on epoch=444
04/27/2022 17:52:11 - INFO - __main__ - Step 900 Global step 900 Train loss 0.01 on epoch=449
04/27/2022 17:52:13 - INFO - __main__ - Global step 900 Train loss 0.02 ACC 0.8125 on epoch=449
04/27/2022 17:52:17 - INFO - __main__ - Step 910 Global step 910 Train loss 0.06 on epoch=454
04/27/2022 17:52:21 - INFO - __main__ - Step 920 Global step 920 Train loss 0.02 on epoch=459
04/27/2022 17:52:25 - INFO - __main__ - Step 930 Global step 930 Train loss 0.01 on epoch=464
04/27/2022 17:52:29 - INFO - __main__ - Step 940 Global step 940 Train loss 0.01 on epoch=469
04/27/2022 17:52:33 - INFO - __main__ - Step 950 Global step 950 Train loss 0.01 on epoch=474
04/27/2022 17:52:36 - INFO - __main__ - Global step 950 Train loss 0.02 ACC 0.8125 on epoch=474
04/27/2022 17:52:40 - INFO - __main__ - Step 960 Global step 960 Train loss 0.01 on epoch=479
04/27/2022 17:52:44 - INFO - __main__ - Step 970 Global step 970 Train loss 0.01 on epoch=484
04/27/2022 17:52:48 - INFO - __main__ - Step 980 Global step 980 Train loss 0.01 on epoch=489
04/27/2022 17:52:52 - INFO - __main__ - Step 990 Global step 990 Train loss 0.01 on epoch=494
04/27/2022 17:52:56 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.01 on epoch=499
04/27/2022 17:52:58 - INFO - __main__ - Global step 1000 Train loss 0.01 ACC 0.84375 on epoch=499
04/27/2022 17:53:02 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.01 on epoch=504
04/27/2022 17:53:06 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.02 on epoch=509
04/27/2022 17:53:10 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.02 on epoch=514
04/27/2022 17:53:14 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.02 on epoch=519
04/27/2022 17:53:18 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.01 on epoch=524
04/27/2022 17:53:21 - INFO - __main__ - Global step 1050 Train loss 0.01 ACC 0.8125 on epoch=524
04/27/2022 17:53:24 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.01 on epoch=529
04/27/2022 17:53:28 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.01 on epoch=534
04/27/2022 17:53:32 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.02 on epoch=539
04/27/2022 17:53:37 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.01 on epoch=544
04/27/2022 17:53:41 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.02 on epoch=549
04/27/2022 17:53:43 - INFO - __main__ - Global step 1100 Train loss 0.01 ACC 0.8125 on epoch=549
04/27/2022 17:53:47 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.01 on epoch=554
04/27/2022 17:53:51 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.02 on epoch=559
04/27/2022 17:53:55 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.04 on epoch=564
04/27/2022 17:53:59 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.02 on epoch=569
04/27/2022 17:54:03 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=574
04/27/2022 17:54:05 - INFO - __main__ - Global step 1150 Train loss 0.02 ACC 0.8125 on epoch=574
04/27/2022 17:54:09 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.02 on epoch=579
04/27/2022 17:54:13 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.03 on epoch=584
04/27/2022 17:54:17 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.02 on epoch=589
04/27/2022 17:54:21 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.01 on epoch=594
04/27/2022 17:54:25 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=599
04/27/2022 17:54:27 - INFO - __main__ - Global step 1200 Train loss 0.02 ACC 0.8125 on epoch=599
04/27/2022 17:54:31 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.02 on epoch=604
04/27/2022 17:54:35 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=609
04/27/2022 17:54:39 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=614
04/27/2022 17:54:43 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=619
04/27/2022 17:54:47 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.02 on epoch=624
04/27/2022 17:54:49 - INFO - __main__ - Global step 1250 Train loss 0.01 ACC 0.78125 on epoch=624
04/27/2022 17:54:53 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.02 on epoch=629
04/27/2022 17:54:57 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.04 on epoch=634
04/27/2022 17:55:01 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=639
04/27/2022 17:55:05 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=644
04/27/2022 17:55:09 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.02 on epoch=649
04/27/2022 17:55:10 - INFO - __main__ - Global step 1300 Train loss 0.02 ACC 0.78125 on epoch=649
04/27/2022 17:55:14 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=654
04/27/2022 17:55:18 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=659
04/27/2022 17:55:22 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=664
04/27/2022 17:55:26 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.02 on epoch=669
04/27/2022 17:55:30 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=674
04/27/2022 17:55:32 - INFO - __main__ - Global step 1350 Train loss 0.01 ACC 0.75 on epoch=674
04/27/2022 17:55:36 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=679
04/27/2022 17:55:40 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=684
04/27/2022 17:55:44 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.02 on epoch=689
04/27/2022 17:55:48 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=694
04/27/2022 17:55:52 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.03 on epoch=699
04/27/2022 17:55:54 - INFO - __main__ - Global step 1400 Train loss 0.02 ACC 0.78125 on epoch=699
04/27/2022 17:55:58 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=704
04/27/2022 17:56:02 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.01 on epoch=709
04/27/2022 17:56:06 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.02 on epoch=714
04/27/2022 17:56:10 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=719
04/27/2022 17:56:14 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=724
04/27/2022 17:56:16 - INFO - __main__ - Global step 1450 Train loss 0.01 ACC 0.8125 on epoch=724
04/27/2022 17:56:20 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=729
04/27/2022 17:56:24 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.03 on epoch=734
04/27/2022 17:56:28 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=739
04/27/2022 17:56:32 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=744
04/27/2022 17:56:36 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=749
04/27/2022 17:56:38 - INFO - __main__ - Global step 1500 Train loss 0.01 ACC 0.8125 on epoch=749
04/27/2022 17:56:42 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.03 on epoch=754
04/27/2022 17:56:46 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.02 on epoch=759
04/27/2022 17:56:50 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=764
04/27/2022 17:56:54 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=769
04/27/2022 17:56:58 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=774
04/27/2022 17:57:00 - INFO - __main__ - Global step 1550 Train loss 0.01 ACC 0.78125 on epoch=774
04/27/2022 17:57:04 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=779
04/27/2022 17:57:08 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=784
04/27/2022 17:57:12 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=789
04/27/2022 17:57:16 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=794
04/27/2022 17:57:20 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=799
04/27/2022 17:57:22 - INFO - __main__ - Global step 1600 Train loss 0.00 ACC 0.78125 on epoch=799
04/27/2022 17:57:26 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=804
04/27/2022 17:57:30 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=809
04/27/2022 17:57:34 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=814
04/27/2022 17:57:38 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=819
04/27/2022 17:57:42 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.03 on epoch=824
04/27/2022 17:57:44 - INFO - __main__ - Global step 1650 Train loss 0.01 ACC 0.78125 on epoch=824
04/27/2022 17:57:48 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=829
04/27/2022 17:57:52 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=834
04/27/2022 17:57:56 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=839
04/27/2022 17:58:00 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=844
04/27/2022 17:58:04 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=849
04/27/2022 17:58:06 - INFO - __main__ - Global step 1700 Train loss 0.01 ACC 0.78125 on epoch=849
04/27/2022 17:58:10 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=854
04/27/2022 17:58:14 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=859
04/27/2022 17:58:18 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=864
04/27/2022 17:58:22 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=869
04/27/2022 17:58:26 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=874
04/27/2022 17:58:28 - INFO - __main__ - Global step 1750 Train loss 0.01 ACC 0.8125 on epoch=874
04/27/2022 17:58:32 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=879
04/27/2022 17:58:36 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=884
04/27/2022 17:58:40 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=889
04/27/2022 17:58:44 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=894
04/27/2022 17:58:48 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=899
04/27/2022 17:58:49 - INFO - __main__ - Global step 1800 Train loss 0.00 ACC 0.8125 on epoch=899
04/27/2022 17:58:53 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=904
04/27/2022 17:58:57 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=909
04/27/2022 17:59:01 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=914
04/27/2022 17:59:05 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=919
04/27/2022 17:59:09 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=924
04/27/2022 17:59:11 - INFO - __main__ - Global step 1850 Train loss 0.01 ACC 0.84375 on epoch=924
04/27/2022 17:59:15 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=929
04/27/2022 17:59:19 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=934
04/27/2022 17:59:23 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=939
04/27/2022 17:59:27 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=944
04/27/2022 17:59:31 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=949
04/27/2022 17:59:33 - INFO - __main__ - Global step 1900 Train loss 0.01 ACC 0.8125 on epoch=949
04/27/2022 17:59:38 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=954
04/27/2022 17:59:42 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=959
04/27/2022 17:59:46 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=964
04/27/2022 17:59:50 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=969
04/27/2022 17:59:54 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=974
04/27/2022 17:59:56 - INFO - __main__ - Global step 1950 Train loss 0.01 ACC 0.8125 on epoch=974
04/27/2022 18:00:00 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=979
04/27/2022 18:00:04 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=984
04/27/2022 18:00:08 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=989
04/27/2022 18:00:12 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=994
04/27/2022 18:00:16 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=999
04/27/2022 18:00:18 - INFO - __main__ - Global step 2000 Train loss 0.01 ACC 0.8125 on epoch=999
04/27/2022 18:00:18 - INFO - __main__ - save last model!
04/27/2022 18:00:18 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
04/27/2022 18:00:18 - INFO - __main__ - Start tokenizing ... 887 instances
04/27/2022 18:00:18 - INFO - __main__ - Printing 3 examples
04/27/2022 18:00:18 - INFO - __main__ -  [sciq] A frameshift mutation is a deletion or insertion of one or more of what that changes the reading frame of the base sequence? (A) carotenoids (B) nucleotides (C) proteins (D) genes [SEP] A frameshift mutation is a deletion or insertion of one or more nucleotides that changes the reading frame of the base sequence. Deletions remove nucleotides, and insertions add nucleotides. Consider the following sequence of bases in RNA:.
04/27/2022 18:00:18 - INFO - __main__ - ['nucleotides']
04/27/2022 18:00:18 - INFO - __main__ -  [sciq] What is an area of land called that is wet for all or part of the year? (A) grassland (B) wetland (C) plains (D) tundra [SEP] A wetland is an area that is wet for all or part of the year. Wetlands are home to certain types of plants.
04/27/2022 18:00:18 - INFO - __main__ - ['wetland']
04/27/2022 18:00:18 - INFO - __main__ -  [sciq] What are arteries, veins, and capillaries examples of? (A) blood vessels (B) muscles (C) organs (D) tissue [SEP] Blood vessels include arteries, veins, and capillaries.
04/27/2022 18:00:18 - INFO - __main__ - ['blood vessels']
04/27/2022 18:00:18 - INFO - __main__ - Tokenizing Input ...
04/27/2022 18:00:18 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 18:00:18 - INFO - __main__ - Printing 3 examples
04/27/2022 18:00:18 - INFO - __main__ -  [sciq] Fractures, rickets, and osteoarthritis all affect what part(s) of the body? (A) fossils (B) Heart (C) bones (D) animals [SEP] Despite their hardness and strength, bones can suffer from injury and disease. Bone problems include fractures, osteoarthritis, and rickets.
04/27/2022 18:00:18 - INFO - __main__ - ['bones']
04/27/2022 18:00:18 - INFO - __main__ -  [sciq] What does a keratometer measure in the cornea? (A) diameter (B) curve (C) Lenght (D) Width [SEP] 25.7 Image Formation by Mirrors 53. What is the focal length of a makeup mirror that has a power of 1.50 D? 54. Some telephoto cameras use a mirror rather than a lens. What radius of curvature mirror is needed to replace a 800 mm focal length telephoto lens? 55. (a) Calculate the focal length of the mirror formed by the shiny back of a spoon that has a 3.00 cm radius of curvature. (b) What is its power in diopters? 56. Find the magnification of the heater element in Example 25.9. Note that its large magnitude helps spread out the reflected energy. What is the focal length of a makeup mirror that produces a magnification of 1.50 when a person’s face is 12.0 cm away? Explicitly show how you follow the steps in the Problem-Solving Strategy for Mirrors. A shopper standing 3.00 m from a convex security mirror sees his image with a magnification of 0.250. (a) Where is his image? (b) What is the focal length of the mirror? (c) What is its radius of curvature? Explicitly show how you follow the steps in the Problem-Solving Strategy for Mirrors. An object 1.50 cm high is held 3.00 cm from a person’s cornea, and its reflected image is measured to be 0.167 cm high. (a) What is the magnification? (b) Where is the image? (c) Find the radius of curvature of the convex mirror formed by the cornea. (Note that this technique is used by optometrists to measure the curvature of the cornea for contact lens fitting. The instrument used is called a keratometer, or curve measurer. ) 60. Ray tracing for a flat mirror shows that the image is located a distance behind the mirror equal to the distance of the object from the mirror. This is stated d i = –d o , since this is a negative image distance (it is a virtual image). (a) What is the focal length of a flat mirror? (b) What is its power?.
04/27/2022 18:00:18 - INFO - __main__ - ['curve']
04/27/2022 18:00:18 - INFO - __main__ -  [sciq] Most carcinogens produce mutations in genes that control what? (A) proteins cycle (B) cell cycle (C) ubiquitous cycle (D) digestive cycle [SEP] Most carcinogens produce mutations in genes that control the cell cycle.
04/27/2022 18:00:18 - INFO - __main__ - ['cell cycle']
04/27/2022 18:00:18 - INFO - __main__ - Tokenizing Input ...
04/27/2022 18:00:18 - INFO - __main__ - Tokenizing Output ...
04/27/2022 18:00:18 - INFO - __main__ - Loaded 32 examples from train data
04/27/2022 18:00:18 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 18:00:18 - INFO - __main__ - Printing 3 examples
04/27/2022 18:00:18 - INFO - __main__ -  [sciq] The cerebellum is associated with what major human organ? (A) bladder (B) heart (C) liver (D) brain [SEP] Figure 13.13 The Cerebellum The cerebellum is situated on the posterior surface of the brain stem. Descending input from the cerebellum enters through the large white matter structure of the pons. Ascending input from the periphery and spinal cord enters through the fibers of the inferior olive. Output goes to the midbrain, which sends a descending signal to the spinal cord.
04/27/2022 18:00:18 - INFO - __main__ - ['brain']
04/27/2022 18:00:18 - INFO - __main__ -  [sciq] What is the term for the energy of motion, which is exhibited by the speed of an object? (A) inertia (B) kinetic energy (C) mechanical energy (D) residual energy [SEP] The energy of motion is kinetic energy, KE. Whenever an object is in motion it has kinetic energy. The faster it is going, the more energy it has.
04/27/2022 18:00:18 - INFO - __main__ - ['kinetic energy']
04/27/2022 18:00:18 - INFO - __main__ -  [sciq] The following definition relates to which term: the application of knowledge to real-world problems? (A) capitalism (B) industry (C) invention (D) technology [SEP] Technology is the application of knowledge to real-world problems. It includes methods and processes as well as devices like computers and cars. An example is the Bessemer process. It is a cheap method of making steel that was invented in the 1850s. It is just one of many technological advances that have occurred in manufacturing. Technology is also responsible for most of the major advances in agriculture, transportation, communications, and medicine. Clearly, technology has had a huge impact on people and society. It is hard to imagine what life would be like without it.
04/27/2022 18:00:18 - INFO - __main__ - ['technology']
04/27/2022 18:00:18 - INFO - __main__ - Tokenizing Input ...
04/27/2022 18:00:18 - INFO - __main__ - Tokenizing Output ...
04/27/2022 18:00:18 - INFO - __main__ - Tokenizing Output ...
04/27/2022 18:00:18 - INFO - __main__ - Loaded 32 examples from dev data
04/27/2022 18:00:19 - INFO - __main__ - Loaded 887 examples from test data
04/27/2022 18:00:34 - INFO - __main__ - load prompt embedding from ckpt
04/27/2022 18:00:34 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/27/2022 18:00:34 - INFO - __main__ - Starting training!
04/27/2022 18:01:08 - INFO - __main__ - Saved prediction in models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-sciq/sciq_32_13_0.3_8_predictions.txt
04/27/2022 18:01:08 - INFO - __main__ - ACC on test data: 0.8050
04/27/2022 18:01:09 - INFO - __main__ - prefix=sciq_32_13, lr=0.3, bsz=8, dev_performance=0.875, test_performance=0.8049605411499436
04/27/2022 18:01:09 - INFO - __main__ - Running ... prefix=sciq_32_13, lr=0.2, bsz=8 ...
04/27/2022 18:01:10 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 18:01:10 - INFO - __main__ - Printing 3 examples
04/27/2022 18:01:10 - INFO - __main__ -  [sciq] Fractures, rickets, and osteoarthritis all affect what part(s) of the body? (A) fossils (B) Heart (C) bones (D) animals [SEP] Despite their hardness and strength, bones can suffer from injury and disease. Bone problems include fractures, osteoarthritis, and rickets.
04/27/2022 18:01:10 - INFO - __main__ - ['bones']
04/27/2022 18:01:10 - INFO - __main__ -  [sciq] What does a keratometer measure in the cornea? (A) diameter (B) curve (C) Lenght (D) Width [SEP] 25.7 Image Formation by Mirrors 53. What is the focal length of a makeup mirror that has a power of 1.50 D? 54. Some telephoto cameras use a mirror rather than a lens. What radius of curvature mirror is needed to replace a 800 mm focal length telephoto lens? 55. (a) Calculate the focal length of the mirror formed by the shiny back of a spoon that has a 3.00 cm radius of curvature. (b) What is its power in diopters? 56. Find the magnification of the heater element in Example 25.9. Note that its large magnitude helps spread out the reflected energy. What is the focal length of a makeup mirror that produces a magnification of 1.50 when a person’s face is 12.0 cm away? Explicitly show how you follow the steps in the Problem-Solving Strategy for Mirrors. A shopper standing 3.00 m from a convex security mirror sees his image with a magnification of 0.250. (a) Where is his image? (b) What is the focal length of the mirror? (c) What is its radius of curvature? Explicitly show how you follow the steps in the Problem-Solving Strategy for Mirrors. An object 1.50 cm high is held 3.00 cm from a person’s cornea, and its reflected image is measured to be 0.167 cm high. (a) What is the magnification? (b) Where is the image? (c) Find the radius of curvature of the convex mirror formed by the cornea. (Note that this technique is used by optometrists to measure the curvature of the cornea for contact lens fitting. The instrument used is called a keratometer, or curve measurer. ) 60. Ray tracing for a flat mirror shows that the image is located a distance behind the mirror equal to the distance of the object from the mirror. This is stated d i = –d o , since this is a negative image distance (it is a virtual image). (a) What is the focal length of a flat mirror? (b) What is its power?.
04/27/2022 18:01:10 - INFO - __main__ - ['curve']
04/27/2022 18:01:10 - INFO - __main__ -  [sciq] Most carcinogens produce mutations in genes that control what? (A) proteins cycle (B) cell cycle (C) ubiquitous cycle (D) digestive cycle [SEP] Most carcinogens produce mutations in genes that control the cell cycle.
04/27/2022 18:01:10 - INFO - __main__ - ['cell cycle']
04/27/2022 18:01:10 - INFO - __main__ - Tokenizing Input ...
04/27/2022 18:01:10 - INFO - __main__ - Tokenizing Output ...
04/27/2022 18:01:10 - INFO - __main__ - Loaded 32 examples from train data
04/27/2022 18:01:10 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 18:01:10 - INFO - __main__ - Printing 3 examples
04/27/2022 18:01:10 - INFO - __main__ -  [sciq] The cerebellum is associated with what major human organ? (A) bladder (B) heart (C) liver (D) brain [SEP] Figure 13.13 The Cerebellum The cerebellum is situated on the posterior surface of the brain stem. Descending input from the cerebellum enters through the large white matter structure of the pons. Ascending input from the periphery and spinal cord enters through the fibers of the inferior olive. Output goes to the midbrain, which sends a descending signal to the spinal cord.
04/27/2022 18:01:10 - INFO - __main__ - ['brain']
04/27/2022 18:01:10 - INFO - __main__ -  [sciq] What is the term for the energy of motion, which is exhibited by the speed of an object? (A) inertia (B) kinetic energy (C) mechanical energy (D) residual energy [SEP] The energy of motion is kinetic energy, KE. Whenever an object is in motion it has kinetic energy. The faster it is going, the more energy it has.
04/27/2022 18:01:10 - INFO - __main__ - ['kinetic energy']
04/27/2022 18:01:10 - INFO - __main__ -  [sciq] The following definition relates to which term: the application of knowledge to real-world problems? (A) capitalism (B) industry (C) invention (D) technology [SEP] Technology is the application of knowledge to real-world problems. It includes methods and processes as well as devices like computers and cars. An example is the Bessemer process. It is a cheap method of making steel that was invented in the 1850s. It is just one of many technological advances that have occurred in manufacturing. Technology is also responsible for most of the major advances in agriculture, transportation, communications, and medicine. Clearly, technology has had a huge impact on people and society. It is hard to imagine what life would be like without it.
04/27/2022 18:01:10 - INFO - __main__ - ['technology']
04/27/2022 18:01:10 - INFO - __main__ - Tokenizing Input ...
04/27/2022 18:01:10 - INFO - __main__ - Tokenizing Output ...
04/27/2022 18:01:10 - INFO - __main__ - Loaded 32 examples from dev data
04/27/2022 18:01:27 - INFO - __main__ - load prompt embedding from ckpt
04/27/2022 18:01:27 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/27/2022 18:01:27 - INFO - __main__ - Starting training!
04/27/2022 18:01:32 - INFO - __main__ - Step 10 Global step 10 Train loss 3.22 on epoch=4
04/27/2022 18:01:36 - INFO - __main__ - Step 20 Global step 20 Train loss 2.30 on epoch=9
04/27/2022 18:01:40 - INFO - __main__ - Step 30 Global step 30 Train loss 1.67 on epoch=14
04/27/2022 18:01:44 - INFO - __main__ - Step 40 Global step 40 Train loss 1.28 on epoch=19
04/27/2022 18:01:48 - INFO - __main__ - Step 50 Global step 50 Train loss 1.09 on epoch=24
04/27/2022 18:01:50 - INFO - __main__ - Global step 50 Train loss 1.91 ACC 0.46875 on epoch=24
04/27/2022 18:01:50 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.46875 on epoch=24, global_step=50
04/27/2022 18:01:54 - INFO - __main__ - Step 60 Global step 60 Train loss 0.79 on epoch=29
04/27/2022 18:01:58 - INFO - __main__ - Step 70 Global step 70 Train loss 0.75 on epoch=34
04/27/2022 18:02:02 - INFO - __main__ - Step 80 Global step 80 Train loss 0.68 on epoch=39
04/27/2022 18:02:06 - INFO - __main__ - Step 90 Global step 90 Train loss 0.70 on epoch=44
04/27/2022 18:02:10 - INFO - __main__ - Step 100 Global step 100 Train loss 0.52 on epoch=49
04/27/2022 18:02:12 - INFO - __main__ - Global step 100 Train loss 0.69 ACC 0.34375 on epoch=49
04/27/2022 18:02:16 - INFO - __main__ - Step 110 Global step 110 Train loss 0.43 on epoch=54
04/27/2022 18:02:20 - INFO - __main__ - Step 120 Global step 120 Train loss 0.54 on epoch=59
04/27/2022 18:02:24 - INFO - __main__ - Step 130 Global step 130 Train loss 0.45 on epoch=64
04/27/2022 18:02:27 - INFO - __main__ - Step 140 Global step 140 Train loss 0.38 on epoch=69
04/27/2022 18:02:31 - INFO - __main__ - Step 150 Global step 150 Train loss 0.37 on epoch=74
04/27/2022 18:02:33 - INFO - __main__ - Global step 150 Train loss 0.43 ACC 0.4375 on epoch=74
04/27/2022 18:02:37 - INFO - __main__ - Step 160 Global step 160 Train loss 0.40 on epoch=79
04/27/2022 18:02:41 - INFO - __main__ - Step 170 Global step 170 Train loss 0.32 on epoch=84
04/27/2022 18:02:45 - INFO - __main__ - Step 180 Global step 180 Train loss 0.24 on epoch=89
04/27/2022 18:02:49 - INFO - __main__ - Step 190 Global step 190 Train loss 0.28 on epoch=94
04/27/2022 18:02:53 - INFO - __main__ - Step 200 Global step 200 Train loss 0.27 on epoch=99
04/27/2022 18:02:55 - INFO - __main__ - Global step 200 Train loss 0.30 ACC 0.53125 on epoch=99
04/27/2022 18:02:55 - INFO - __main__ - Saving model with best ACC: 0.46875 -> 0.53125 on epoch=99, global_step=200
04/27/2022 18:02:59 - INFO - __main__ - Step 210 Global step 210 Train loss 0.25 on epoch=104
04/27/2022 18:03:03 - INFO - __main__ - Step 220 Global step 220 Train loss 0.29 on epoch=109
04/27/2022 18:03:07 - INFO - __main__ - Step 230 Global step 230 Train loss 0.20 on epoch=114
04/27/2022 18:03:11 - INFO - __main__ - Step 240 Global step 240 Train loss 0.17 on epoch=119
04/27/2022 18:03:15 - INFO - __main__ - Step 250 Global step 250 Train loss 0.17 on epoch=124
04/27/2022 18:03:18 - INFO - __main__ - Global step 250 Train loss 0.22 ACC 0.625 on epoch=124
04/27/2022 18:03:18 - INFO - __main__ - Saving model with best ACC: 0.53125 -> 0.625 on epoch=124, global_step=250
04/27/2022 18:03:22 - INFO - __main__ - Step 260 Global step 260 Train loss 0.20 on epoch=129
04/27/2022 18:03:26 - INFO - __main__ - Step 270 Global step 270 Train loss 0.20 on epoch=134
04/27/2022 18:03:30 - INFO - __main__ - Step 280 Global step 280 Train loss 0.17 on epoch=139
04/27/2022 18:03:34 - INFO - __main__ - Step 290 Global step 290 Train loss 0.16 on epoch=144
04/27/2022 18:03:38 - INFO - __main__ - Step 300 Global step 300 Train loss 0.10 on epoch=149
04/27/2022 18:03:40 - INFO - __main__ - Global step 300 Train loss 0.17 ACC 0.6875 on epoch=149
04/27/2022 18:03:40 - INFO - __main__ - Saving model with best ACC: 0.625 -> 0.6875 on epoch=149, global_step=300
04/27/2022 18:03:44 - INFO - __main__ - Step 310 Global step 310 Train loss 0.09 on epoch=154
04/27/2022 18:03:48 - INFO - __main__ - Step 320 Global step 320 Train loss 0.11 on epoch=159
04/27/2022 18:03:52 - INFO - __main__ - Step 330 Global step 330 Train loss 0.06 on epoch=164
04/27/2022 18:03:56 - INFO - __main__ - Step 340 Global step 340 Train loss 0.16 on epoch=169
04/27/2022 18:04:00 - INFO - __main__ - Step 350 Global step 350 Train loss 0.11 on epoch=174
04/27/2022 18:04:02 - INFO - __main__ - Global step 350 Train loss 0.11 ACC 0.75 on epoch=174
04/27/2022 18:04:03 - INFO - __main__ - Saving model with best ACC: 0.6875 -> 0.75 on epoch=174, global_step=350
04/27/2022 18:04:07 - INFO - __main__ - Step 360 Global step 360 Train loss 0.09 on epoch=179
04/27/2022 18:04:11 - INFO - __main__ - Step 370 Global step 370 Train loss 0.08 on epoch=184
04/27/2022 18:04:14 - INFO - __main__ - Step 380 Global step 380 Train loss 0.12 on epoch=189
04/27/2022 18:04:18 - INFO - __main__ - Step 390 Global step 390 Train loss 0.11 on epoch=194
04/27/2022 18:04:22 - INFO - __main__ - Step 400 Global step 400 Train loss 0.07 on epoch=199
04/27/2022 18:04:25 - INFO - __main__ - Global step 400 Train loss 0.09 ACC 0.65625 on epoch=199
04/27/2022 18:04:29 - INFO - __main__ - Step 410 Global step 410 Train loss 0.06 on epoch=204
04/27/2022 18:04:33 - INFO - __main__ - Step 420 Global step 420 Train loss 0.10 on epoch=209
04/27/2022 18:04:37 - INFO - __main__ - Step 430 Global step 430 Train loss 0.13 on epoch=214
04/27/2022 18:04:41 - INFO - __main__ - Step 440 Global step 440 Train loss 0.10 on epoch=219
04/27/2022 18:04:45 - INFO - __main__ - Step 450 Global step 450 Train loss 0.07 on epoch=224
04/27/2022 18:04:48 - INFO - __main__ - Global step 450 Train loss 0.09 ACC 0.75 on epoch=224
04/27/2022 18:04:52 - INFO - __main__ - Step 460 Global step 460 Train loss 0.06 on epoch=229
04/27/2022 18:04:56 - INFO - __main__ - Step 470 Global step 470 Train loss 0.08 on epoch=234
04/27/2022 18:05:00 - INFO - __main__ - Step 480 Global step 480 Train loss 0.09 on epoch=239
04/27/2022 18:05:04 - INFO - __main__ - Step 490 Global step 490 Train loss 0.11 on epoch=244
04/27/2022 18:05:08 - INFO - __main__ - Step 500 Global step 500 Train loss 0.08 on epoch=249
04/27/2022 18:05:11 - INFO - __main__ - Global step 500 Train loss 0.08 ACC 0.71875 on epoch=249
04/27/2022 18:05:15 - INFO - __main__ - Step 510 Global step 510 Train loss 0.05 on epoch=254
04/27/2022 18:05:19 - INFO - __main__ - Step 520 Global step 520 Train loss 0.07 on epoch=259
04/27/2022 18:05:23 - INFO - __main__ - Step 530 Global step 530 Train loss 0.05 on epoch=264
04/27/2022 18:05:27 - INFO - __main__ - Step 540 Global step 540 Train loss 0.06 on epoch=269
04/27/2022 18:05:31 - INFO - __main__ - Step 550 Global step 550 Train loss 0.07 on epoch=274
04/27/2022 18:05:32 - INFO - __main__ - Global step 550 Train loss 0.06 ACC 0.71875 on epoch=274
04/27/2022 18:05:36 - INFO - __main__ - Step 560 Global step 560 Train loss 0.10 on epoch=279
04/27/2022 18:05:40 - INFO - __main__ - Step 570 Global step 570 Train loss 0.04 on epoch=284
04/27/2022 18:05:44 - INFO - __main__ - Step 580 Global step 580 Train loss 0.03 on epoch=289
04/27/2022 18:05:48 - INFO - __main__ - Step 590 Global step 590 Train loss 0.04 on epoch=294
04/27/2022 18:05:52 - INFO - __main__ - Step 600 Global step 600 Train loss 0.04 on epoch=299
04/27/2022 18:05:56 - INFO - __main__ - Global step 600 Train loss 0.05 ACC 0.8125 on epoch=299
04/27/2022 18:05:56 - INFO - __main__ - Saving model with best ACC: 0.75 -> 0.8125 on epoch=299, global_step=600
04/27/2022 18:06:00 - INFO - __main__ - Step 610 Global step 610 Train loss 0.08 on epoch=304
04/27/2022 18:06:04 - INFO - __main__ - Step 620 Global step 620 Train loss 0.11 on epoch=309
04/27/2022 18:06:08 - INFO - __main__ - Step 630 Global step 630 Train loss 0.05 on epoch=314
04/27/2022 18:06:12 - INFO - __main__ - Step 640 Global step 640 Train loss 0.05 on epoch=319
04/27/2022 18:06:16 - INFO - __main__ - Step 650 Global step 650 Train loss 0.05 on epoch=324
04/27/2022 18:06:19 - INFO - __main__ - Global step 650 Train loss 0.07 ACC 0.6875 on epoch=324
04/27/2022 18:06:23 - INFO - __main__ - Step 660 Global step 660 Train loss 0.03 on epoch=329
04/27/2022 18:06:27 - INFO - __main__ - Step 670 Global step 670 Train loss 0.03 on epoch=334
04/27/2022 18:06:31 - INFO - __main__ - Step 680 Global step 680 Train loss 0.06 on epoch=339
04/27/2022 18:06:35 - INFO - __main__ - Step 690 Global step 690 Train loss 0.04 on epoch=344
04/27/2022 18:06:39 - INFO - __main__ - Step 700 Global step 700 Train loss 0.04 on epoch=349
04/27/2022 18:06:42 - INFO - __main__ - Global step 700 Train loss 0.04 ACC 0.71875 on epoch=349
04/27/2022 18:06:46 - INFO - __main__ - Step 710 Global step 710 Train loss 0.05 on epoch=354
04/27/2022 18:06:50 - INFO - __main__ - Step 720 Global step 720 Train loss 0.03 on epoch=359
04/27/2022 18:06:54 - INFO - __main__ - Step 730 Global step 730 Train loss 0.02 on epoch=364
04/27/2022 18:06:58 - INFO - __main__ - Step 740 Global step 740 Train loss 0.02 on epoch=369
04/27/2022 18:07:02 - INFO - __main__ - Step 750 Global step 750 Train loss 0.03 on epoch=374
04/27/2022 18:07:05 - INFO - __main__ - Global step 750 Train loss 0.03 ACC 0.75 on epoch=374
04/27/2022 18:07:09 - INFO - __main__ - Step 760 Global step 760 Train loss 0.04 on epoch=379
04/27/2022 18:07:13 - INFO - __main__ - Step 770 Global step 770 Train loss 0.06 on epoch=384
04/27/2022 18:07:17 - INFO - __main__ - Step 780 Global step 780 Train loss 0.02 on epoch=389
04/27/2022 18:07:21 - INFO - __main__ - Step 790 Global step 790 Train loss 0.03 on epoch=394
04/27/2022 18:07:25 - INFO - __main__ - Step 800 Global step 800 Train loss 0.04 on epoch=399
04/27/2022 18:07:27 - INFO - __main__ - Global step 800 Train loss 0.04 ACC 0.75 on epoch=399
04/27/2022 18:07:31 - INFO - __main__ - Step 810 Global step 810 Train loss 0.03 on epoch=404
04/27/2022 18:07:36 - INFO - __main__ - Step 820 Global step 820 Train loss 0.04 on epoch=409
04/27/2022 18:07:40 - INFO - __main__ - Step 830 Global step 830 Train loss 0.03 on epoch=414
04/27/2022 18:07:44 - INFO - __main__ - Step 840 Global step 840 Train loss 0.04 on epoch=419
04/27/2022 18:07:48 - INFO - __main__ - Step 850 Global step 850 Train loss 0.03 on epoch=424
04/27/2022 18:07:49 - INFO - __main__ - Global step 850 Train loss 0.03 ACC 0.71875 on epoch=424
04/27/2022 18:07:53 - INFO - __main__ - Step 860 Global step 860 Train loss 0.05 on epoch=429
04/27/2022 18:07:57 - INFO - __main__ - Step 870 Global step 870 Train loss 0.05 on epoch=434
04/27/2022 18:08:01 - INFO - __main__ - Step 880 Global step 880 Train loss 0.02 on epoch=439
04/27/2022 18:08:05 - INFO - __main__ - Step 890 Global step 890 Train loss 0.03 on epoch=444
04/27/2022 18:08:09 - INFO - __main__ - Step 900 Global step 900 Train loss 0.03 on epoch=449
04/27/2022 18:08:11 - INFO - __main__ - Global step 900 Train loss 0.03 ACC 0.65625 on epoch=449
04/27/2022 18:08:15 - INFO - __main__ - Step 910 Global step 910 Train loss 0.02 on epoch=454
04/27/2022 18:08:19 - INFO - __main__ - Step 920 Global step 920 Train loss 0.03 on epoch=459
04/27/2022 18:08:23 - INFO - __main__ - Step 930 Global step 930 Train loss 0.05 on epoch=464
04/27/2022 18:08:27 - INFO - __main__ - Step 940 Global step 940 Train loss 0.04 on epoch=469
04/27/2022 18:08:31 - INFO - __main__ - Step 950 Global step 950 Train loss 0.02 on epoch=474
04/27/2022 18:08:33 - INFO - __main__ - Global step 950 Train loss 0.03 ACC 0.8125 on epoch=474
04/27/2022 18:08:37 - INFO - __main__ - Step 960 Global step 960 Train loss 0.02 on epoch=479
04/27/2022 18:08:41 - INFO - __main__ - Step 970 Global step 970 Train loss 0.02 on epoch=484
04/27/2022 18:08:45 - INFO - __main__ - Step 980 Global step 980 Train loss 0.03 on epoch=489
04/27/2022 18:08:49 - INFO - __main__ - Step 990 Global step 990 Train loss 0.02 on epoch=494
04/27/2022 18:08:53 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.02 on epoch=499
04/27/2022 18:08:55 - INFO - __main__ - Global step 1000 Train loss 0.02 ACC 0.75 on epoch=499
04/27/2022 18:08:59 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.01 on epoch=504
04/27/2022 18:09:03 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.05 on epoch=509
04/27/2022 18:09:07 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.04 on epoch=514
04/27/2022 18:09:11 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.02 on epoch=519
04/27/2022 18:09:15 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.02 on epoch=524
04/27/2022 18:09:17 - INFO - __main__ - Global step 1050 Train loss 0.03 ACC 0.78125 on epoch=524
04/27/2022 18:09:21 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.03 on epoch=529
04/27/2022 18:09:25 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.04 on epoch=534
04/27/2022 18:09:29 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.01 on epoch=539
04/27/2022 18:09:33 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.03 on epoch=544
04/27/2022 18:09:37 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.02 on epoch=549
04/27/2022 18:09:38 - INFO - __main__ - Global step 1100 Train loss 0.02 ACC 0.71875 on epoch=549
04/27/2022 18:09:42 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.02 on epoch=554
04/27/2022 18:09:46 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.05 on epoch=559
04/27/2022 18:09:50 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=564
04/27/2022 18:09:54 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.01 on epoch=569
04/27/2022 18:09:58 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=574
04/27/2022 18:10:00 - INFO - __main__ - Global step 1150 Train loss 0.02 ACC 0.75 on epoch=574
04/27/2022 18:10:04 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.04 on epoch=579
04/27/2022 18:10:08 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.01 on epoch=584
04/27/2022 18:10:12 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.07 on epoch=589
04/27/2022 18:10:16 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.00 on epoch=594
04/27/2022 18:10:20 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=599
04/27/2022 18:10:22 - INFO - __main__ - Global step 1200 Train loss 0.02 ACC 0.6875 on epoch=599
04/27/2022 18:10:26 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.02 on epoch=604
04/27/2022 18:10:30 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.02 on epoch=609
04/27/2022 18:10:34 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.02 on epoch=614
04/27/2022 18:10:38 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=619
04/27/2022 18:10:42 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.02 on epoch=624
04/27/2022 18:10:43 - INFO - __main__ - Global step 1250 Train loss 0.02 ACC 0.71875 on epoch=624
04/27/2022 18:10:47 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.02 on epoch=629
04/27/2022 18:10:51 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.01 on epoch=634
04/27/2022 18:10:55 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.02 on epoch=639
04/27/2022 18:10:59 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.03 on epoch=644
04/27/2022 18:11:03 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.02 on epoch=649
04/27/2022 18:11:05 - INFO - __main__ - Global step 1300 Train loss 0.02 ACC 0.71875 on epoch=649
04/27/2022 18:11:09 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=654
04/27/2022 18:11:13 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=659
04/27/2022 18:11:17 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.03 on epoch=664
04/27/2022 18:11:21 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.02 on epoch=669
04/27/2022 18:11:25 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.03 on epoch=674
04/27/2022 18:11:27 - INFO - __main__ - Global step 1350 Train loss 0.02 ACC 0.6875 on epoch=674
04/27/2022 18:11:31 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=679
04/27/2022 18:11:35 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.02 on epoch=684
04/27/2022 18:11:39 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=689
04/27/2022 18:11:43 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=694
04/27/2022 18:11:47 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=699
04/27/2022 18:11:48 - INFO - __main__ - Global step 1400 Train loss 0.01 ACC 0.6875 on epoch=699
04/27/2022 18:11:52 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=704
04/27/2022 18:11:56 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.01 on epoch=709
04/27/2022 18:12:00 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=714
04/27/2022 18:12:04 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.03 on epoch=719
04/27/2022 18:12:08 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=724
04/27/2022 18:12:10 - INFO - __main__ - Global step 1450 Train loss 0.01 ACC 0.78125 on epoch=724
04/27/2022 18:12:14 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.02 on epoch=729
04/27/2022 18:12:18 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.03 on epoch=734
04/27/2022 18:12:22 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.02 on epoch=739
04/27/2022 18:12:26 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.02 on epoch=744
04/27/2022 18:12:30 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.03 on epoch=749
04/27/2022 18:12:32 - INFO - __main__ - Global step 1500 Train loss 0.02 ACC 0.84375 on epoch=749
04/27/2022 18:12:32 - INFO - __main__ - Saving model with best ACC: 0.8125 -> 0.84375 on epoch=749, global_step=1500
04/27/2022 18:12:36 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.04 on epoch=754
04/27/2022 18:12:40 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.02 on epoch=759
04/27/2022 18:12:44 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.02 on epoch=764
04/27/2022 18:12:48 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=769
04/27/2022 18:12:52 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=774
04/27/2022 18:12:54 - INFO - __main__ - Global step 1550 Train loss 0.02 ACC 0.8125 on epoch=774
04/27/2022 18:12:58 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=779
04/27/2022 18:13:02 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=784
04/27/2022 18:13:06 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=789
04/27/2022 18:13:10 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.02 on epoch=794
04/27/2022 18:13:14 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=799
04/27/2022 18:13:16 - INFO - __main__ - Global step 1600 Train loss 0.01 ACC 0.8125 on epoch=799
04/27/2022 18:13:20 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=804
04/27/2022 18:13:24 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=809
04/27/2022 18:13:28 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.03 on epoch=814
04/27/2022 18:13:32 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=819
04/27/2022 18:13:36 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=824
04/27/2022 18:13:38 - INFO - __main__ - Global step 1650 Train loss 0.01 ACC 0.8125 on epoch=824
04/27/2022 18:13:42 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=829
04/27/2022 18:13:46 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=834
04/27/2022 18:13:50 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=839
04/27/2022 18:13:54 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=844
04/27/2022 18:13:58 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=849
04/27/2022 18:13:59 - INFO - __main__ - Global step 1700 Train loss 0.01 ACC 0.8125 on epoch=849
04/27/2022 18:14:03 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=854
04/27/2022 18:14:07 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=859
04/27/2022 18:14:11 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=864
04/27/2022 18:14:15 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=869
04/27/2022 18:14:19 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=874
04/27/2022 18:14:21 - INFO - __main__ - Global step 1750 Train loss 0.01 ACC 0.8125 on epoch=874
04/27/2022 18:14:25 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=879
04/27/2022 18:14:29 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=884
04/27/2022 18:14:33 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=889
04/27/2022 18:14:37 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=894
04/27/2022 18:14:41 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=899
04/27/2022 18:14:43 - INFO - __main__ - Global step 1800 Train loss 0.01 ACC 0.84375 on epoch=899
04/27/2022 18:14:47 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=904
04/27/2022 18:14:51 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=909
04/27/2022 18:14:55 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=914
04/27/2022 18:14:59 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=919
04/27/2022 18:15:03 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=924
04/27/2022 18:15:05 - INFO - __main__ - Global step 1850 Train loss 0.01 ACC 0.84375 on epoch=924
04/27/2022 18:15:09 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=929
04/27/2022 18:15:13 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=934
04/27/2022 18:15:17 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=939
04/27/2022 18:15:21 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.04 on epoch=944
04/27/2022 18:15:25 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.05 on epoch=949
04/27/2022 18:15:27 - INFO - __main__ - Global step 1900 Train loss 0.02 ACC 0.8125 on epoch=949
04/27/2022 18:15:31 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=954
04/27/2022 18:15:35 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=959
04/27/2022 18:15:39 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=964
04/27/2022 18:15:43 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=969
04/27/2022 18:15:47 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=974
04/27/2022 18:15:48 - INFO - __main__ - Global step 1950 Train loss 0.01 ACC 0.8125 on epoch=974
04/27/2022 18:15:52 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=979
04/27/2022 18:15:56 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=984
04/27/2022 18:16:00 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=989
04/27/2022 18:16:05 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=994
04/27/2022 18:16:09 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=999
04/27/2022 18:16:10 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 18:16:10 - INFO - __main__ - Printing 3 examples
04/27/2022 18:16:10 - INFO - __main__ -  [sciq] What source of ocean pollution kills animals by coating them? (A) grain spill (B) oil spill (C) plants spill (D) chemical spill [SEP] Oil spills are another source of ocean pollution. To get at oil buried beneath the seafloor, oil rigs are built in the oceans. These rigs pump oil from beneath the ocean floor. Huge ocean tankers carry oil around the world. If something goes wrong with a rig on a tanker, millions of barrels of oil may end up in the water. The oil may coat and kill ocean animals. Some of the oil will wash ashore. This oil may destroy coastal wetlands and ruin beaches.
04/27/2022 18:16:10 - INFO - __main__ - ['oil spill']
04/27/2022 18:16:10 - INFO - __main__ -  [sciq] Smog is a visible form of what? (A) water pollution (B) condensation (C) air pollution (D) oxidation [SEP] Smog clouds the city of Los Angeles, California. Visible air pollution in the form of smog is a sign that the air is unhealthy.
04/27/2022 18:16:10 - INFO - __main__ - ['air pollution']
04/27/2022 18:16:10 - INFO - __main__ -  [sciq] What makes up the central nervous system? (A) brain and spinal cord (B) spine and lungs (C) heart and lungs (D) brain and heart [SEP] The central nervous system is made up of the brain and the spinal cord.
04/27/2022 18:16:10 - INFO - __main__ - ['brain and spinal cord']
04/27/2022 18:16:10 - INFO - __main__ - Tokenizing Input ...
04/27/2022 18:16:10 - INFO - __main__ - Tokenizing Output ...
04/27/2022 18:16:10 - INFO - __main__ - Loaded 32 examples from train data
04/27/2022 18:16:10 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 18:16:10 - INFO - __main__ - Printing 3 examples
04/27/2022 18:16:10 - INFO - __main__ -  [sciq] When energy is captured or transformed, it inevitably degrades and becomes what less useful form of energy? (A) chemical (B) motion (C) temperature (D) heat [SEP] Physics also tells us that, although energy can be captured or transformed, it inevitably degrades, becoming heat, a less useful form of energy. This is why organisms require a constant input of energy; the work they must do uses up the energy they take in. Energy, unlike materials, cannot be recycled. The story of life is a story of energy flow – its capture, transformation, use for work, and loss as heat.
04/27/2022 18:16:10 - INFO - __main__ - ['heat']
04/27/2022 18:16:10 - INFO - __main__ -  [sciq] Zeros that appear in front of all of the nonzero digits are called what? (A) zero sum game (B) left-end zeros (C) significant digits (D) non-numbers [SEP] 3. Zeros that appear in front of all of the nonzero digits are called left-end zeros. Left-end zeros are never significant. A. 0.008 has one significant figure.
04/27/2022 18:16:10 - INFO - __main__ - ['left-end zeros']
04/27/2022 18:16:10 - INFO - __main__ -  [sciq] What can be defined simply, as a change in position? (A) motion (B) gravity (C) velocity (D) speed [SEP] You can see several examples of people or things in motion in Figure below . You can probably think of many other examples. You know from experience what motion is, so it may seem like a straightforward concept. Motion can also be defined simply, as a change in position. But if you think about examples of motion in more depth, you’ll find that the idea of motion is not quite as simple and straightforward as it seems.
04/27/2022 18:16:10 - INFO - __main__ - ['motion']
04/27/2022 18:16:10 - INFO - __main__ - Tokenizing Input ...
04/27/2022 18:16:10 - INFO - __main__ - Tokenizing Output ...
04/27/2022 18:16:10 - INFO - __main__ - Loaded 32 examples from dev data
04/27/2022 18:16:10 - INFO - __main__ - Global step 2000 Train loss 0.01 ACC 0.8125 on epoch=999
04/27/2022 18:16:10 - INFO - __main__ - save last model!
04/27/2022 18:16:10 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
04/27/2022 18:16:10 - INFO - __main__ - Start tokenizing ... 887 instances
04/27/2022 18:16:10 - INFO - __main__ - Printing 3 examples
04/27/2022 18:16:10 - INFO - __main__ -  [sciq] A frameshift mutation is a deletion or insertion of one or more of what that changes the reading frame of the base sequence? (A) carotenoids (B) nucleotides (C) proteins (D) genes [SEP] A frameshift mutation is a deletion or insertion of one or more nucleotides that changes the reading frame of the base sequence. Deletions remove nucleotides, and insertions add nucleotides. Consider the following sequence of bases in RNA:.
04/27/2022 18:16:11 - INFO - __main__ - ['nucleotides']
04/27/2022 18:16:11 - INFO - __main__ -  [sciq] What is an area of land called that is wet for all or part of the year? (A) grassland (B) wetland (C) plains (D) tundra [SEP] A wetland is an area that is wet for all or part of the year. Wetlands are home to certain types of plants.
04/27/2022 18:16:11 - INFO - __main__ - ['wetland']
04/27/2022 18:16:11 - INFO - __main__ -  [sciq] What are arteries, veins, and capillaries examples of? (A) blood vessels (B) muscles (C) organs (D) tissue [SEP] Blood vessels include arteries, veins, and capillaries.
04/27/2022 18:16:11 - INFO - __main__ - ['blood vessels']
04/27/2022 18:16:11 - INFO - __main__ - Tokenizing Input ...
04/27/2022 18:16:11 - INFO - __main__ - Tokenizing Output ...
04/27/2022 18:16:12 - INFO - __main__ - Loaded 887 examples from test data
04/27/2022 18:16:29 - INFO - __main__ - load prompt embedding from ckpt
04/27/2022 18:16:30 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/27/2022 18:16:30 - INFO - __main__ - Starting training!
04/27/2022 18:16:56 - INFO - __main__ - Saved prediction in models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-sciq/sciq_32_13_0.2_8_predictions.txt
04/27/2022 18:16:56 - INFO - __main__ - ACC on test data: 0.8264
04/27/2022 18:16:56 - INFO - __main__ - prefix=sciq_32_13, lr=0.2, bsz=8, dev_performance=0.84375, test_performance=0.826381059751973
04/27/2022 18:16:56 - INFO - __main__ - Running ... prefix=sciq_32_21, lr=0.5, bsz=8 ...
04/27/2022 18:16:57 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 18:16:57 - INFO - __main__ - Printing 3 examples
04/27/2022 18:16:57 - INFO - __main__ -  [sciq] What source of ocean pollution kills animals by coating them? (A) grain spill (B) oil spill (C) plants spill (D) chemical spill [SEP] Oil spills are another source of ocean pollution. To get at oil buried beneath the seafloor, oil rigs are built in the oceans. These rigs pump oil from beneath the ocean floor. Huge ocean tankers carry oil around the world. If something goes wrong with a rig on a tanker, millions of barrels of oil may end up in the water. The oil may coat and kill ocean animals. Some of the oil will wash ashore. This oil may destroy coastal wetlands and ruin beaches.
04/27/2022 18:16:57 - INFO - __main__ - ['oil spill']
04/27/2022 18:16:57 - INFO - __main__ -  [sciq] Smog is a visible form of what? (A) water pollution (B) condensation (C) air pollution (D) oxidation [SEP] Smog clouds the city of Los Angeles, California. Visible air pollution in the form of smog is a sign that the air is unhealthy.
04/27/2022 18:16:57 - INFO - __main__ - ['air pollution']
04/27/2022 18:16:57 - INFO - __main__ -  [sciq] What makes up the central nervous system? (A) brain and spinal cord (B) spine and lungs (C) heart and lungs (D) brain and heart [SEP] The central nervous system is made up of the brain and the spinal cord.
04/27/2022 18:16:57 - INFO - __main__ - ['brain and spinal cord']
04/27/2022 18:16:57 - INFO - __main__ - Tokenizing Input ...
04/27/2022 18:16:57 - INFO - __main__ - Tokenizing Output ...
04/27/2022 18:16:57 - INFO - __main__ - Loaded 32 examples from train data
04/27/2022 18:16:57 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 18:16:57 - INFO - __main__ - Printing 3 examples
04/27/2022 18:16:57 - INFO - __main__ -  [sciq] When energy is captured or transformed, it inevitably degrades and becomes what less useful form of energy? (A) chemical (B) motion (C) temperature (D) heat [SEP] Physics also tells us that, although energy can be captured or transformed, it inevitably degrades, becoming heat, a less useful form of energy. This is why organisms require a constant input of energy; the work they must do uses up the energy they take in. Energy, unlike materials, cannot be recycled. The story of life is a story of energy flow – its capture, transformation, use for work, and loss as heat.
04/27/2022 18:16:57 - INFO - __main__ - ['heat']
04/27/2022 18:16:57 - INFO - __main__ -  [sciq] Zeros that appear in front of all of the nonzero digits are called what? (A) zero sum game (B) left-end zeros (C) significant digits (D) non-numbers [SEP] 3. Zeros that appear in front of all of the nonzero digits are called left-end zeros. Left-end zeros are never significant. A. 0.008 has one significant figure.
04/27/2022 18:16:57 - INFO - __main__ - ['left-end zeros']
04/27/2022 18:16:57 - INFO - __main__ -  [sciq] What can be defined simply, as a change in position? (A) motion (B) gravity (C) velocity (D) speed [SEP] You can see several examples of people or things in motion in Figure below . You can probably think of many other examples. You know from experience what motion is, so it may seem like a straightforward concept. Motion can also be defined simply, as a change in position. But if you think about examples of motion in more depth, you’ll find that the idea of motion is not quite as simple and straightforward as it seems.
04/27/2022 18:16:57 - INFO - __main__ - ['motion']
04/27/2022 18:16:57 - INFO - __main__ - Tokenizing Input ...
04/27/2022 18:16:58 - INFO - __main__ - Tokenizing Output ...
04/27/2022 18:16:58 - INFO - __main__ - Loaded 32 examples from dev data
04/27/2022 18:17:14 - INFO - __main__ - load prompt embedding from ckpt
04/27/2022 18:17:15 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/27/2022 18:17:15 - INFO - __main__ - Starting training!
04/27/2022 18:17:23 - INFO - __main__ - Step 10 Global step 10 Train loss 1.93 on epoch=4
04/27/2022 18:17:28 - INFO - __main__ - Step 20 Global step 20 Train loss 1.02 on epoch=9
04/27/2022 18:17:32 - INFO - __main__ - Step 30 Global step 30 Train loss 0.84 on epoch=14
04/27/2022 18:17:36 - INFO - __main__ - Step 40 Global step 40 Train loss 0.60 on epoch=19
04/27/2022 18:17:41 - INFO - __main__ - Step 50 Global step 50 Train loss 1.73 on epoch=24
04/27/2022 18:17:42 - INFO - __main__ - Global step 50 Train loss 1.22 ACC 0.65625 on epoch=24
04/27/2022 18:17:42 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.65625 on epoch=24, global_step=50
04/27/2022 18:17:46 - INFO - __main__ - Step 60 Global step 60 Train loss 0.59 on epoch=29
04/27/2022 18:17:50 - INFO - __main__ - Step 70 Global step 70 Train loss 0.50 on epoch=34
04/27/2022 18:17:55 - INFO - __main__ - Step 80 Global step 80 Train loss 0.42 on epoch=39
04/27/2022 18:17:59 - INFO - __main__ - Step 90 Global step 90 Train loss 0.45 on epoch=44
04/27/2022 18:18:03 - INFO - __main__ - Step 100 Global step 100 Train loss 0.42 on epoch=49
04/27/2022 18:18:05 - INFO - __main__ - Global step 100 Train loss 0.48 ACC 0.78125 on epoch=49
04/27/2022 18:18:05 - INFO - __main__ - Saving model with best ACC: 0.65625 -> 0.78125 on epoch=49, global_step=100
04/27/2022 18:18:09 - INFO - __main__ - Step 110 Global step 110 Train loss 0.38 on epoch=54
04/27/2022 18:18:13 - INFO - __main__ - Step 120 Global step 120 Train loss 0.41 on epoch=59
04/27/2022 18:18:17 - INFO - __main__ - Step 130 Global step 130 Train loss 0.35 on epoch=64
04/27/2022 18:18:22 - INFO - __main__ - Step 140 Global step 140 Train loss 0.32 on epoch=69
04/27/2022 18:18:26 - INFO - __main__ - Step 150 Global step 150 Train loss 0.30 on epoch=74
04/27/2022 18:18:27 - INFO - __main__ - Global step 150 Train loss 0.35 ACC 0.6875 on epoch=74
04/27/2022 18:18:32 - INFO - __main__ - Step 160 Global step 160 Train loss 0.33 on epoch=79
04/27/2022 18:18:36 - INFO - __main__ - Step 170 Global step 170 Train loss 0.29 on epoch=84
04/27/2022 18:18:40 - INFO - __main__ - Step 180 Global step 180 Train loss 0.31 on epoch=89
04/27/2022 18:18:45 - INFO - __main__ - Step 190 Global step 190 Train loss 0.31 on epoch=94
04/27/2022 18:18:49 - INFO - __main__ - Step 200 Global step 200 Train loss 0.27 on epoch=99
04/27/2022 18:18:50 - INFO - __main__ - Global step 200 Train loss 0.30 ACC 0.78125 on epoch=99
04/27/2022 18:18:54 - INFO - __main__ - Step 210 Global step 210 Train loss 0.29 on epoch=104
04/27/2022 18:18:59 - INFO - __main__ - Step 220 Global step 220 Train loss 0.22 on epoch=109
04/27/2022 18:19:03 - INFO - __main__ - Step 230 Global step 230 Train loss 0.22 on epoch=114
04/27/2022 18:19:07 - INFO - __main__ - Step 240 Global step 240 Train loss 0.21 on epoch=119
04/27/2022 18:19:12 - INFO - __main__ - Step 250 Global step 250 Train loss 0.24 on epoch=124
04/27/2022 18:19:13 - INFO - __main__ - Global step 250 Train loss 0.23 ACC 0.78125 on epoch=124
04/27/2022 18:19:17 - INFO - __main__ - Step 260 Global step 260 Train loss 0.20 on epoch=129
04/27/2022 18:19:22 - INFO - __main__ - Step 270 Global step 270 Train loss 0.15 on epoch=134
04/27/2022 18:19:26 - INFO - __main__ - Step 280 Global step 280 Train loss 0.14 on epoch=139
04/27/2022 18:19:30 - INFO - __main__ - Step 290 Global step 290 Train loss 0.15 on epoch=144
04/27/2022 18:19:35 - INFO - __main__ - Step 300 Global step 300 Train loss 0.18 on epoch=149
04/27/2022 18:19:36 - INFO - __main__ - Global step 300 Train loss 0.17 ACC 0.90625 on epoch=149
04/27/2022 18:19:36 - INFO - __main__ - Saving model with best ACC: 0.78125 -> 0.90625 on epoch=149, global_step=300
04/27/2022 18:19:40 - INFO - __main__ - Step 310 Global step 310 Train loss 0.11 on epoch=154
04/27/2022 18:19:45 - INFO - __main__ - Step 320 Global step 320 Train loss 0.15 on epoch=159
04/27/2022 18:19:49 - INFO - __main__ - Step 330 Global step 330 Train loss 0.12 on epoch=164
04/27/2022 18:19:53 - INFO - __main__ - Step 340 Global step 340 Train loss 0.10 on epoch=169
04/27/2022 18:19:58 - INFO - __main__ - Step 350 Global step 350 Train loss 0.07 on epoch=174
04/27/2022 18:19:59 - INFO - __main__ - Global step 350 Train loss 0.11 ACC 0.875 on epoch=174
04/27/2022 18:20:03 - INFO - __main__ - Step 360 Global step 360 Train loss 0.11 on epoch=179
04/27/2022 18:20:08 - INFO - __main__ - Step 370 Global step 370 Train loss 0.07 on epoch=184
04/27/2022 18:20:12 - INFO - __main__ - Step 380 Global step 380 Train loss 0.10 on epoch=189
04/27/2022 18:20:16 - INFO - __main__ - Step 390 Global step 390 Train loss 0.12 on epoch=194
04/27/2022 18:20:20 - INFO - __main__ - Step 400 Global step 400 Train loss 0.12 on epoch=199
04/27/2022 18:20:22 - INFO - __main__ - Global step 400 Train loss 0.10 ACC 0.90625 on epoch=199
04/27/2022 18:20:26 - INFO - __main__ - Step 410 Global step 410 Train loss 0.06 on epoch=204
04/27/2022 18:20:30 - INFO - __main__ - Step 420 Global step 420 Train loss 0.08 on epoch=209
04/27/2022 18:20:35 - INFO - __main__ - Step 430 Global step 430 Train loss 0.09 on epoch=214
04/27/2022 18:20:39 - INFO - __main__ - Step 440 Global step 440 Train loss 0.06 on epoch=219
04/27/2022 18:20:43 - INFO - __main__ - Step 450 Global step 450 Train loss 0.10 on epoch=224
04/27/2022 18:20:45 - INFO - __main__ - Global step 450 Train loss 0.08 ACC 0.84375 on epoch=224
04/27/2022 18:20:49 - INFO - __main__ - Step 460 Global step 460 Train loss 0.06 on epoch=229
04/27/2022 18:20:53 - INFO - __main__ - Step 470 Global step 470 Train loss 0.04 on epoch=234
04/27/2022 18:20:58 - INFO - __main__ - Step 480 Global step 480 Train loss 0.08 on epoch=239
04/27/2022 18:21:02 - INFO - __main__ - Step 490 Global step 490 Train loss 0.05 on epoch=244
04/27/2022 18:21:06 - INFO - __main__ - Step 500 Global step 500 Train loss 0.11 on epoch=249
04/27/2022 18:21:08 - INFO - __main__ - Global step 500 Train loss 0.07 ACC 0.9375 on epoch=249
04/27/2022 18:21:08 - INFO - __main__ - Saving model with best ACC: 0.90625 -> 0.9375 on epoch=249, global_step=500
04/27/2022 18:21:12 - INFO - __main__ - Step 510 Global step 510 Train loss 0.06 on epoch=254
04/27/2022 18:21:16 - INFO - __main__ - Step 520 Global step 520 Train loss 0.05 on epoch=259
04/27/2022 18:21:20 - INFO - __main__ - Step 530 Global step 530 Train loss 0.04 on epoch=264
04/27/2022 18:21:25 - INFO - __main__ - Step 540 Global step 540 Train loss 0.04 on epoch=269
04/27/2022 18:21:29 - INFO - __main__ - Step 550 Global step 550 Train loss 0.05 on epoch=274
04/27/2022 18:21:31 - INFO - __main__ - Global step 550 Train loss 0.05 ACC 0.875 on epoch=274
04/27/2022 18:21:35 - INFO - __main__ - Step 560 Global step 560 Train loss 0.04 on epoch=279
04/27/2022 18:21:39 - INFO - __main__ - Step 570 Global step 570 Train loss 0.05 on epoch=284
04/27/2022 18:21:43 - INFO - __main__ - Step 580 Global step 580 Train loss 0.05 on epoch=289
04/27/2022 18:21:48 - INFO - __main__ - Step 590 Global step 590 Train loss 0.04 on epoch=294
04/27/2022 18:21:52 - INFO - __main__ - Step 600 Global step 600 Train loss 0.04 on epoch=299
04/27/2022 18:21:53 - INFO - __main__ - Global step 600 Train loss 0.04 ACC 0.875 on epoch=299
04/27/2022 18:21:58 - INFO - __main__ - Step 610 Global step 610 Train loss 0.04 on epoch=304
04/27/2022 18:22:02 - INFO - __main__ - Step 620 Global step 620 Train loss 0.06 on epoch=309
04/27/2022 18:22:06 - INFO - __main__ - Step 630 Global step 630 Train loss 0.02 on epoch=314
04/27/2022 18:22:11 - INFO - __main__ - Step 640 Global step 640 Train loss 0.03 on epoch=319
04/27/2022 18:22:15 - INFO - __main__ - Step 650 Global step 650 Train loss 0.03 on epoch=324
04/27/2022 18:22:16 - INFO - __main__ - Global step 650 Train loss 0.04 ACC 0.875 on epoch=324
04/27/2022 18:22:21 - INFO - __main__ - Step 660 Global step 660 Train loss 0.04 on epoch=329
04/27/2022 18:22:25 - INFO - __main__ - Step 670 Global step 670 Train loss 0.05 on epoch=334
04/27/2022 18:22:29 - INFO - __main__ - Step 680 Global step 680 Train loss 0.04 on epoch=339
04/27/2022 18:22:33 - INFO - __main__ - Step 690 Global step 690 Train loss 0.02 on epoch=344
04/27/2022 18:22:38 - INFO - __main__ - Step 700 Global step 700 Train loss 0.03 on epoch=349
04/27/2022 18:22:39 - INFO - __main__ - Global step 700 Train loss 0.04 ACC 0.875 on epoch=349
04/27/2022 18:22:43 - INFO - __main__ - Step 710 Global step 710 Train loss 0.06 on epoch=354
04/27/2022 18:22:48 - INFO - __main__ - Step 720 Global step 720 Train loss 0.03 on epoch=359
04/27/2022 18:22:52 - INFO - __main__ - Step 730 Global step 730 Train loss 0.02 on epoch=364
04/27/2022 18:22:56 - INFO - __main__ - Step 740 Global step 740 Train loss 0.04 on epoch=369
04/27/2022 18:23:01 - INFO - __main__ - Step 750 Global step 750 Train loss 0.01 on epoch=374
04/27/2022 18:23:02 - INFO - __main__ - Global step 750 Train loss 0.03 ACC 0.875 on epoch=374
04/27/2022 18:23:06 - INFO - __main__ - Step 760 Global step 760 Train loss 0.02 on epoch=379
04/27/2022 18:23:11 - INFO - __main__ - Step 770 Global step 770 Train loss 0.01 on epoch=384
04/27/2022 18:23:15 - INFO - __main__ - Step 780 Global step 780 Train loss 0.01 on epoch=389
04/27/2022 18:23:19 - INFO - __main__ - Step 790 Global step 790 Train loss 0.03 on epoch=394
04/27/2022 18:23:23 - INFO - __main__ - Step 800 Global step 800 Train loss 0.03 on epoch=399
04/27/2022 18:23:25 - INFO - __main__ - Global step 800 Train loss 0.02 ACC 0.90625 on epoch=399
04/27/2022 18:23:29 - INFO - __main__ - Step 810 Global step 810 Train loss 0.01 on epoch=404
04/27/2022 18:23:33 - INFO - __main__ - Step 820 Global step 820 Train loss 0.03 on epoch=409
04/27/2022 18:23:38 - INFO - __main__ - Step 830 Global step 830 Train loss 0.03 on epoch=414
04/27/2022 18:23:42 - INFO - __main__ - Step 840 Global step 840 Train loss 0.03 on epoch=419
04/27/2022 18:23:46 - INFO - __main__ - Step 850 Global step 850 Train loss 0.01 on epoch=424
04/27/2022 18:23:48 - INFO - __main__ - Global step 850 Train loss 0.02 ACC 0.90625 on epoch=424
04/27/2022 18:23:52 - INFO - __main__ - Step 860 Global step 860 Train loss 0.03 on epoch=429
04/27/2022 18:23:56 - INFO - __main__ - Step 870 Global step 870 Train loss 0.01 on epoch=434
04/27/2022 18:24:01 - INFO - __main__ - Step 880 Global step 880 Train loss 0.02 on epoch=439
04/27/2022 18:24:05 - INFO - __main__ - Step 890 Global step 890 Train loss 0.01 on epoch=444
04/27/2022 18:24:09 - INFO - __main__ - Step 900 Global step 900 Train loss 0.01 on epoch=449
04/27/2022 18:24:11 - INFO - __main__ - Global step 900 Train loss 0.02 ACC 0.9375 on epoch=449
04/27/2022 18:24:15 - INFO - __main__ - Step 910 Global step 910 Train loss 0.01 on epoch=454
04/27/2022 18:24:19 - INFO - __main__ - Step 920 Global step 920 Train loss 0.02 on epoch=459
04/27/2022 18:24:24 - INFO - __main__ - Step 930 Global step 930 Train loss 0.03 on epoch=464
04/27/2022 18:24:28 - INFO - __main__ - Step 940 Global step 940 Train loss 0.02 on epoch=469
04/27/2022 18:24:32 - INFO - __main__ - Step 950 Global step 950 Train loss 0.01 on epoch=474
04/27/2022 18:24:34 - INFO - __main__ - Global step 950 Train loss 0.02 ACC 0.90625 on epoch=474
04/27/2022 18:24:38 - INFO - __main__ - Step 960 Global step 960 Train loss 0.02 on epoch=479
04/27/2022 18:24:42 - INFO - __main__ - Step 970 Global step 970 Train loss 0.02 on epoch=484
04/27/2022 18:24:47 - INFO - __main__ - Step 980 Global step 980 Train loss 0.02 on epoch=489
04/27/2022 18:24:51 - INFO - __main__ - Step 990 Global step 990 Train loss 0.02 on epoch=494
04/27/2022 18:24:55 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.01 on epoch=499
04/27/2022 18:24:57 - INFO - __main__ - Global step 1000 Train loss 0.02 ACC 0.9375 on epoch=499
04/27/2022 18:25:01 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.01 on epoch=504
04/27/2022 18:25:05 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.01 on epoch=509
04/27/2022 18:25:10 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.01 on epoch=514
04/27/2022 18:25:14 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.01 on epoch=519
04/27/2022 18:25:18 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.01 on epoch=524
04/27/2022 18:25:20 - INFO - __main__ - Global step 1050 Train loss 0.01 ACC 0.84375 on epoch=524
04/27/2022 18:25:24 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.01 on epoch=529
04/27/2022 18:25:28 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.01 on epoch=534
04/27/2022 18:25:33 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.01 on epoch=539
04/27/2022 18:25:37 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.00 on epoch=544
04/27/2022 18:25:41 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.02 on epoch=549
04/27/2022 18:25:43 - INFO - __main__ - Global step 1100 Train loss 0.01 ACC 0.875 on epoch=549
04/27/2022 18:25:47 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.01 on epoch=554
04/27/2022 18:25:51 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=559
04/27/2022 18:25:56 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.00 on epoch=564
04/27/2022 18:26:00 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.01 on epoch=569
04/27/2022 18:26:04 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.02 on epoch=574
04/27/2022 18:26:06 - INFO - __main__ - Global step 1150 Train loss 0.01 ACC 0.90625 on epoch=574
04/27/2022 18:26:10 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.01 on epoch=579
04/27/2022 18:26:14 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.01 on epoch=584
04/27/2022 18:26:19 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.01 on epoch=589
04/27/2022 18:26:23 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.00 on epoch=594
04/27/2022 18:26:27 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.02 on epoch=599
04/27/2022 18:26:29 - INFO - __main__ - Global step 1200 Train loss 0.01 ACC 0.9375 on epoch=599
04/27/2022 18:26:33 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.01 on epoch=604
04/27/2022 18:26:37 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=609
04/27/2022 18:26:42 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=614
04/27/2022 18:26:46 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=619
04/27/2022 18:26:50 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.01 on epoch=624
04/27/2022 18:26:52 - INFO - __main__ - Global step 1250 Train loss 0.01 ACC 0.875 on epoch=624
04/27/2022 18:26:56 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.00 on epoch=629
04/27/2022 18:27:00 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.00 on epoch=634
04/27/2022 18:27:05 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.00 on epoch=639
04/27/2022 18:27:09 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.00 on epoch=644
04/27/2022 18:27:13 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.00 on epoch=649
04/27/2022 18:27:15 - INFO - __main__ - Global step 1300 Train loss 0.00 ACC 0.90625 on epoch=649
04/27/2022 18:27:19 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=654
04/27/2022 18:27:23 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.00 on epoch=659
04/27/2022 18:27:28 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=664
04/27/2022 18:27:32 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=669
04/27/2022 18:27:36 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.00 on epoch=674
04/27/2022 18:27:38 - INFO - __main__ - Global step 1350 Train loss 0.01 ACC 0.84375 on epoch=674
04/27/2022 18:27:42 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.00 on epoch=679
04/27/2022 18:27:46 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=684
04/27/2022 18:27:51 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.02 on epoch=689
04/27/2022 18:27:55 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.00 on epoch=694
04/27/2022 18:27:59 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=699
04/27/2022 18:28:01 - INFO - __main__ - Global step 1400 Train loss 0.01 ACC 0.875 on epoch=699
04/27/2022 18:28:05 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=704
04/27/2022 18:28:09 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.01 on epoch=709
04/27/2022 18:28:14 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=714
04/27/2022 18:28:18 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=719
04/27/2022 18:28:22 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=724
04/27/2022 18:28:24 - INFO - __main__ - Global step 1450 Train loss 0.01 ACC 0.84375 on epoch=724
04/27/2022 18:28:28 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=729
04/27/2022 18:28:32 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=734
04/27/2022 18:28:37 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=739
04/27/2022 18:28:41 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=744
04/27/2022 18:28:45 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=749
04/27/2022 18:28:47 - INFO - __main__ - Global step 1500 Train loss 0.00 ACC 0.875 on epoch=749
04/27/2022 18:28:51 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=754
04/27/2022 18:28:55 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=759
04/27/2022 18:29:00 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.02 on epoch=764
04/27/2022 18:29:04 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=769
04/27/2022 18:29:08 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=774
04/27/2022 18:29:10 - INFO - __main__ - Global step 1550 Train loss 0.01 ACC 0.875 on epoch=774
04/27/2022 18:29:14 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=779
04/27/2022 18:29:18 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=784
04/27/2022 18:29:23 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=789
04/27/2022 18:29:27 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=794
04/27/2022 18:29:31 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=799
04/27/2022 18:29:33 - INFO - __main__ - Global step 1600 Train loss 0.01 ACC 0.875 on epoch=799
04/27/2022 18:29:37 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=804
04/27/2022 18:29:41 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=809
04/27/2022 18:29:46 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=814
04/27/2022 18:29:50 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=819
04/27/2022 18:29:54 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=824
04/27/2022 18:29:56 - INFO - __main__ - Global step 1650 Train loss 0.00 ACC 0.90625 on epoch=824
04/27/2022 18:30:00 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=829
04/27/2022 18:30:04 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=834
04/27/2022 18:30:08 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=839
04/27/2022 18:30:13 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=844
04/27/2022 18:30:17 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=849
04/27/2022 18:30:18 - INFO - __main__ - Global step 1700 Train loss 0.00 ACC 0.875 on epoch=849
04/27/2022 18:30:23 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=854
04/27/2022 18:30:27 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=859
04/27/2022 18:30:31 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=864
04/27/2022 18:30:35 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=869
04/27/2022 18:30:40 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=874
04/27/2022 18:30:41 - INFO - __main__ - Global step 1750 Train loss 0.00 ACC 0.84375 on epoch=874
04/27/2022 18:30:45 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=879
04/27/2022 18:30:50 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=884
04/27/2022 18:30:54 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=889
04/27/2022 18:30:58 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=894
04/27/2022 18:31:03 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=899
04/27/2022 18:31:04 - INFO - __main__ - Global step 1800 Train loss 0.01 ACC 0.84375 on epoch=899
04/27/2022 18:31:08 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=904
04/27/2022 18:31:13 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=909
04/27/2022 18:31:17 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=914
04/27/2022 18:31:21 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=919
04/27/2022 18:31:25 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=924
04/27/2022 18:31:27 - INFO - __main__ - Global step 1850 Train loss 0.00 ACC 0.90625 on epoch=924
04/27/2022 18:31:31 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=929
04/27/2022 18:31:35 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=934
04/27/2022 18:31:40 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=939
04/27/2022 18:31:44 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=944
04/27/2022 18:31:48 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=949
04/27/2022 18:31:50 - INFO - __main__ - Global step 1900 Train loss 0.00 ACC 0.84375 on epoch=949
04/27/2022 18:31:54 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=954
04/27/2022 18:31:58 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=959
04/27/2022 18:32:02 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=964
04/27/2022 18:32:07 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=969
04/27/2022 18:32:11 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=974
04/27/2022 18:32:12 - INFO - __main__ - Global step 1950 Train loss 0.00 ACC 0.84375 on epoch=974
04/27/2022 18:32:17 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=979
04/27/2022 18:32:21 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=984
04/27/2022 18:32:25 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=989
04/27/2022 18:32:29 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=994
04/27/2022 18:32:34 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=999
04/27/2022 18:32:35 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 18:32:35 - INFO - __main__ - Printing 3 examples
04/27/2022 18:32:35 - INFO - __main__ -  [sciq] What source of ocean pollution kills animals by coating them? (A) grain spill (B) oil spill (C) plants spill (D) chemical spill [SEP] Oil spills are another source of ocean pollution. To get at oil buried beneath the seafloor, oil rigs are built in the oceans. These rigs pump oil from beneath the ocean floor. Huge ocean tankers carry oil around the world. If something goes wrong with a rig on a tanker, millions of barrels of oil may end up in the water. The oil may coat and kill ocean animals. Some of the oil will wash ashore. This oil may destroy coastal wetlands and ruin beaches.
04/27/2022 18:32:35 - INFO - __main__ - ['oil spill']
04/27/2022 18:32:35 - INFO - __main__ -  [sciq] Smog is a visible form of what? (A) water pollution (B) condensation (C) air pollution (D) oxidation [SEP] Smog clouds the city of Los Angeles, California. Visible air pollution in the form of smog is a sign that the air is unhealthy.
04/27/2022 18:32:35 - INFO - __main__ - ['air pollution']
04/27/2022 18:32:35 - INFO - __main__ -  [sciq] What makes up the central nervous system? (A) brain and spinal cord (B) spine and lungs (C) heart and lungs (D) brain and heart [SEP] The central nervous system is made up of the brain and the spinal cord.
04/27/2022 18:32:35 - INFO - __main__ - ['brain and spinal cord']
04/27/2022 18:32:35 - INFO - __main__ - Tokenizing Input ...
04/27/2022 18:32:35 - INFO - __main__ - Tokenizing Output ...
04/27/2022 18:32:35 - INFO - __main__ - Global step 2000 Train loss 0.01 ACC 0.875 on epoch=999
04/27/2022 18:32:35 - INFO - __main__ - Loaded 32 examples from train data
04/27/2022 18:32:35 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 18:32:35 - INFO - __main__ - Printing 3 examples
04/27/2022 18:32:35 - INFO - __main__ - save last model!
04/27/2022 18:32:35 - INFO - __main__ -  [sciq] When energy is captured or transformed, it inevitably degrades and becomes what less useful form of energy? (A) chemical (B) motion (C) temperature (D) heat [SEP] Physics also tells us that, although energy can be captured or transformed, it inevitably degrades, becoming heat, a less useful form of energy. This is why organisms require a constant input of energy; the work they must do uses up the energy they take in. Energy, unlike materials, cannot be recycled. The story of life is a story of energy flow – its capture, transformation, use for work, and loss as heat.
04/27/2022 18:32:35 - INFO - __main__ - ['heat']
04/27/2022 18:32:35 - INFO - __main__ -  [sciq] Zeros that appear in front of all of the nonzero digits are called what? (A) zero sum game (B) left-end zeros (C) significant digits (D) non-numbers [SEP] 3. Zeros that appear in front of all of the nonzero digits are called left-end zeros. Left-end zeros are never significant. A. 0.008 has one significant figure.
04/27/2022 18:32:35 - INFO - __main__ - ['left-end zeros']
04/27/2022 18:32:35 - INFO - __main__ -  [sciq] What can be defined simply, as a change in position? (A) motion (B) gravity (C) velocity (D) speed [SEP] You can see several examples of people or things in motion in Figure below . You can probably think of many other examples. You know from experience what motion is, so it may seem like a straightforward concept. Motion can also be defined simply, as a change in position. But if you think about examples of motion in more depth, you’ll find that the idea of motion is not quite as simple and straightforward as it seems.
04/27/2022 18:32:35 - INFO - __main__ - ['motion']
04/27/2022 18:32:35 - INFO - __main__ - Tokenizing Input ...
04/27/2022 18:32:35 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
04/27/2022 18:32:35 - INFO - __main__ - Tokenizing Output ...
04/27/2022 18:32:35 - INFO - __main__ - Start tokenizing ... 887 instances
04/27/2022 18:32:35 - INFO - __main__ - Printing 3 examples
04/27/2022 18:32:35 - INFO - __main__ -  [sciq] A frameshift mutation is a deletion or insertion of one or more of what that changes the reading frame of the base sequence? (A) carotenoids (B) nucleotides (C) proteins (D) genes [SEP] A frameshift mutation is a deletion or insertion of one or more nucleotides that changes the reading frame of the base sequence. Deletions remove nucleotides, and insertions add nucleotides. Consider the following sequence of bases in RNA:.
04/27/2022 18:32:35 - INFO - __main__ - ['nucleotides']
04/27/2022 18:32:35 - INFO - __main__ -  [sciq] What is an area of land called that is wet for all or part of the year? (A) grassland (B) wetland (C) plains (D) tundra [SEP] A wetland is an area that is wet for all or part of the year. Wetlands are home to certain types of plants.
04/27/2022 18:32:35 - INFO - __main__ - ['wetland']
04/27/2022 18:32:35 - INFO - __main__ -  [sciq] What are arteries, veins, and capillaries examples of? (A) blood vessels (B) muscles (C) organs (D) tissue [SEP] Blood vessels include arteries, veins, and capillaries.
04/27/2022 18:32:35 - INFO - __main__ - ['blood vessels']
04/27/2022 18:32:35 - INFO - __main__ - Tokenizing Input ...
04/27/2022 18:32:35 - INFO - __main__ - Loaded 32 examples from dev data
04/27/2022 18:32:36 - INFO - __main__ - Tokenizing Output ...
04/27/2022 18:32:37 - INFO - __main__ - Loaded 887 examples from test data
04/27/2022 18:32:54 - INFO - __main__ - load prompt embedding from ckpt
04/27/2022 18:32:55 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/27/2022 18:32:55 - INFO - __main__ - Starting training!
04/27/2022 18:33:22 - INFO - __main__ - Saved prediction in models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-sciq/sciq_32_21_0.5_8_predictions.txt
04/27/2022 18:33:22 - INFO - __main__ - ACC on test data: 0.8546
04/27/2022 18:33:22 - INFO - __main__ - prefix=sciq_32_21, lr=0.5, bsz=8, dev_performance=0.9375, test_performance=0.85456595264938
04/27/2022 18:33:22 - INFO - __main__ - Running ... prefix=sciq_32_21, lr=0.4, bsz=8 ...
04/27/2022 18:33:23 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 18:33:23 - INFO - __main__ - Printing 3 examples
04/27/2022 18:33:23 - INFO - __main__ -  [sciq] What source of ocean pollution kills animals by coating them? (A) grain spill (B) oil spill (C) plants spill (D) chemical spill [SEP] Oil spills are another source of ocean pollution. To get at oil buried beneath the seafloor, oil rigs are built in the oceans. These rigs pump oil from beneath the ocean floor. Huge ocean tankers carry oil around the world. If something goes wrong with a rig on a tanker, millions of barrels of oil may end up in the water. The oil may coat and kill ocean animals. Some of the oil will wash ashore. This oil may destroy coastal wetlands and ruin beaches.
04/27/2022 18:33:23 - INFO - __main__ - ['oil spill']
04/27/2022 18:33:23 - INFO - __main__ -  [sciq] Smog is a visible form of what? (A) water pollution (B) condensation (C) air pollution (D) oxidation [SEP] Smog clouds the city of Los Angeles, California. Visible air pollution in the form of smog is a sign that the air is unhealthy.
04/27/2022 18:33:23 - INFO - __main__ - ['air pollution']
04/27/2022 18:33:23 - INFO - __main__ -  [sciq] What makes up the central nervous system? (A) brain and spinal cord (B) spine and lungs (C) heart and lungs (D) brain and heart [SEP] The central nervous system is made up of the brain and the spinal cord.
04/27/2022 18:33:23 - INFO - __main__ - ['brain and spinal cord']
04/27/2022 18:33:23 - INFO - __main__ - Tokenizing Input ...
04/27/2022 18:33:23 - INFO - __main__ - Tokenizing Output ...
04/27/2022 18:33:23 - INFO - __main__ - Loaded 32 examples from train data
04/27/2022 18:33:23 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 18:33:23 - INFO - __main__ - Printing 3 examples
04/27/2022 18:33:23 - INFO - __main__ -  [sciq] When energy is captured or transformed, it inevitably degrades and becomes what less useful form of energy? (A) chemical (B) motion (C) temperature (D) heat [SEP] Physics also tells us that, although energy can be captured or transformed, it inevitably degrades, becoming heat, a less useful form of energy. This is why organisms require a constant input of energy; the work they must do uses up the energy they take in. Energy, unlike materials, cannot be recycled. The story of life is a story of energy flow – its capture, transformation, use for work, and loss as heat.
04/27/2022 18:33:23 - INFO - __main__ - ['heat']
04/27/2022 18:33:23 - INFO - __main__ -  [sciq] Zeros that appear in front of all of the nonzero digits are called what? (A) zero sum game (B) left-end zeros (C) significant digits (D) non-numbers [SEP] 3. Zeros that appear in front of all of the nonzero digits are called left-end zeros. Left-end zeros are never significant. A. 0.008 has one significant figure.
04/27/2022 18:33:23 - INFO - __main__ - ['left-end zeros']
04/27/2022 18:33:23 - INFO - __main__ -  [sciq] What can be defined simply, as a change in position? (A) motion (B) gravity (C) velocity (D) speed [SEP] You can see several examples of people or things in motion in Figure below . You can probably think of many other examples. You know from experience what motion is, so it may seem like a straightforward concept. Motion can also be defined simply, as a change in position. But if you think about examples of motion in more depth, you’ll find that the idea of motion is not quite as simple and straightforward as it seems.
04/27/2022 18:33:23 - INFO - __main__ - ['motion']
04/27/2022 18:33:23 - INFO - __main__ - Tokenizing Input ...
04/27/2022 18:33:23 - INFO - __main__ - Tokenizing Output ...
04/27/2022 18:33:23 - INFO - __main__ - Loaded 32 examples from dev data
04/27/2022 18:33:40 - INFO - __main__ - load prompt embedding from ckpt
04/27/2022 18:33:40 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/27/2022 18:33:40 - INFO - __main__ - Starting training!
04/27/2022 18:33:45 - INFO - __main__ - Step 10 Global step 10 Train loss 2.13 on epoch=4
04/27/2022 18:33:50 - INFO - __main__ - Step 20 Global step 20 Train loss 1.15 on epoch=9
04/27/2022 18:33:54 - INFO - __main__ - Step 30 Global step 30 Train loss 0.86 on epoch=14
04/27/2022 18:33:58 - INFO - __main__ - Step 40 Global step 40 Train loss 0.71 on epoch=19
04/27/2022 18:34:02 - INFO - __main__ - Step 50 Global step 50 Train loss 0.59 on epoch=24
04/27/2022 18:34:04 - INFO - __main__ - Global step 50 Train loss 1.09 ACC 0.59375 on epoch=24
04/27/2022 18:34:04 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.59375 on epoch=24, global_step=50
04/27/2022 18:34:08 - INFO - __main__ - Step 60 Global step 60 Train loss 0.50 on epoch=29
04/27/2022 18:34:12 - INFO - __main__ - Step 70 Global step 70 Train loss 0.42 on epoch=34
04/27/2022 18:34:16 - INFO - __main__ - Step 80 Global step 80 Train loss 0.33 on epoch=39
04/27/2022 18:34:21 - INFO - __main__ - Step 90 Global step 90 Train loss 0.35 on epoch=44
04/27/2022 18:34:25 - INFO - __main__ - Step 100 Global step 100 Train loss 0.28 on epoch=49
04/27/2022 18:34:26 - INFO - __main__ - Global step 100 Train loss 0.38 ACC 0.71875 on epoch=49
04/27/2022 18:34:26 - INFO - __main__ - Saving model with best ACC: 0.59375 -> 0.71875 on epoch=49, global_step=100
04/27/2022 18:34:30 - INFO - __main__ - Step 110 Global step 110 Train loss 0.23 on epoch=54
04/27/2022 18:34:35 - INFO - __main__ - Step 120 Global step 120 Train loss 0.19 on epoch=59
04/27/2022 18:34:39 - INFO - __main__ - Step 130 Global step 130 Train loss 0.17 on epoch=64
04/27/2022 18:34:43 - INFO - __main__ - Step 140 Global step 140 Train loss 0.22 on epoch=69
04/27/2022 18:34:47 - INFO - __main__ - Step 150 Global step 150 Train loss 0.18 on epoch=74
04/27/2022 18:34:49 - INFO - __main__ - Global step 150 Train loss 0.20 ACC 0.8125 on epoch=74
04/27/2022 18:34:49 - INFO - __main__ - Saving model with best ACC: 0.71875 -> 0.8125 on epoch=74, global_step=150
04/27/2022 18:34:53 - INFO - __main__ - Step 160 Global step 160 Train loss 0.17 on epoch=79
04/27/2022 18:34:57 - INFO - __main__ - Step 170 Global step 170 Train loss 0.16 on epoch=84
04/27/2022 18:35:02 - INFO - __main__ - Step 180 Global step 180 Train loss 0.08 on epoch=89
04/27/2022 18:35:06 - INFO - __main__ - Step 190 Global step 190 Train loss 0.09 on epoch=94
04/27/2022 18:35:10 - INFO - __main__ - Step 200 Global step 200 Train loss 0.06 on epoch=99
04/27/2022 18:35:11 - INFO - __main__ - Global step 200 Train loss 0.11 ACC 0.875 on epoch=99
04/27/2022 18:35:11 - INFO - __main__ - Saving model with best ACC: 0.8125 -> 0.875 on epoch=99, global_step=200
04/27/2022 18:35:16 - INFO - __main__ - Step 210 Global step 210 Train loss 0.08 on epoch=104
04/27/2022 18:35:20 - INFO - __main__ - Step 220 Global step 220 Train loss 0.12 on epoch=109
04/27/2022 18:35:24 - INFO - __main__ - Step 230 Global step 230 Train loss 0.06 on epoch=114
04/27/2022 18:35:28 - INFO - __main__ - Step 240 Global step 240 Train loss 0.08 on epoch=119
04/27/2022 18:35:33 - INFO - __main__ - Step 250 Global step 250 Train loss 0.05 on epoch=124
04/27/2022 18:35:34 - INFO - __main__ - Global step 250 Train loss 0.08 ACC 0.90625 on epoch=124
04/27/2022 18:35:34 - INFO - __main__ - Saving model with best ACC: 0.875 -> 0.90625 on epoch=124, global_step=250
04/27/2022 18:35:38 - INFO - __main__ - Step 260 Global step 260 Train loss 0.06 on epoch=129
04/27/2022 18:35:43 - INFO - __main__ - Step 270 Global step 270 Train loss 0.04 on epoch=134
04/27/2022 18:35:47 - INFO - __main__ - Step 280 Global step 280 Train loss 0.09 on epoch=139
04/27/2022 18:35:51 - INFO - __main__ - Step 290 Global step 290 Train loss 0.05 on epoch=144
04/27/2022 18:35:55 - INFO - __main__ - Step 300 Global step 300 Train loss 0.06 on epoch=149
04/27/2022 18:35:57 - INFO - __main__ - Global step 300 Train loss 0.06 ACC 0.875 on epoch=149
04/27/2022 18:36:01 - INFO - __main__ - Step 310 Global step 310 Train loss 0.03 on epoch=154
04/27/2022 18:36:05 - INFO - __main__ - Step 320 Global step 320 Train loss 0.03 on epoch=159
04/27/2022 18:36:10 - INFO - __main__ - Step 330 Global step 330 Train loss 0.04 on epoch=164
04/27/2022 18:36:14 - INFO - __main__ - Step 340 Global step 340 Train loss 0.06 on epoch=169
04/27/2022 18:36:18 - INFO - __main__ - Step 350 Global step 350 Train loss 0.05 on epoch=174
04/27/2022 18:36:20 - INFO - __main__ - Global step 350 Train loss 0.04 ACC 0.84375 on epoch=174
04/27/2022 18:36:24 - INFO - __main__ - Step 360 Global step 360 Train loss 0.03 on epoch=179
04/27/2022 18:36:28 - INFO - __main__ - Step 370 Global step 370 Train loss 0.06 on epoch=184
04/27/2022 18:36:32 - INFO - __main__ - Step 380 Global step 380 Train loss 0.02 on epoch=189
04/27/2022 18:36:37 - INFO - __main__ - Step 390 Global step 390 Train loss 0.02 on epoch=194
04/27/2022 18:36:41 - INFO - __main__ - Step 400 Global step 400 Train loss 0.07 on epoch=199
04/27/2022 18:36:42 - INFO - __main__ - Global step 400 Train loss 0.04 ACC 0.90625 on epoch=199
04/27/2022 18:36:46 - INFO - __main__ - Step 410 Global step 410 Train loss 0.02 on epoch=204
04/27/2022 18:36:51 - INFO - __main__ - Step 420 Global step 420 Train loss 0.07 on epoch=209
04/27/2022 18:36:55 - INFO - __main__ - Step 430 Global step 430 Train loss 0.01 on epoch=214
04/27/2022 18:36:59 - INFO - __main__ - Step 440 Global step 440 Train loss 0.02 on epoch=219
04/27/2022 18:37:03 - INFO - __main__ - Step 450 Global step 450 Train loss 0.02 on epoch=224
04/27/2022 18:37:05 - INFO - __main__ - Global step 450 Train loss 0.03 ACC 0.9375 on epoch=224
04/27/2022 18:37:05 - INFO - __main__ - Saving model with best ACC: 0.90625 -> 0.9375 on epoch=224, global_step=450
04/27/2022 18:37:09 - INFO - __main__ - Step 460 Global step 460 Train loss 0.02 on epoch=229
04/27/2022 18:37:13 - INFO - __main__ - Step 470 Global step 470 Train loss 0.03 on epoch=234
04/27/2022 18:37:18 - INFO - __main__ - Step 480 Global step 480 Train loss 0.02 on epoch=239
04/27/2022 18:37:22 - INFO - __main__ - Step 490 Global step 490 Train loss 0.02 on epoch=244
04/27/2022 18:37:26 - INFO - __main__ - Step 500 Global step 500 Train loss 0.02 on epoch=249
04/27/2022 18:37:28 - INFO - __main__ - Global step 500 Train loss 0.02 ACC 0.84375 on epoch=249
04/27/2022 18:37:32 - INFO - __main__ - Step 510 Global step 510 Train loss 0.03 on epoch=254
04/27/2022 18:37:36 - INFO - __main__ - Step 520 Global step 520 Train loss 0.01 on epoch=259
04/27/2022 18:37:40 - INFO - __main__ - Step 530 Global step 530 Train loss 0.04 on epoch=264
04/27/2022 18:37:45 - INFO - __main__ - Step 540 Global step 540 Train loss 0.02 on epoch=269
04/27/2022 18:37:49 - INFO - __main__ - Step 550 Global step 550 Train loss 0.04 on epoch=274
04/27/2022 18:37:50 - INFO - __main__ - Global step 550 Train loss 0.03 ACC 0.75 on epoch=274
04/27/2022 18:37:54 - INFO - __main__ - Step 560 Global step 560 Train loss 0.02 on epoch=279
04/27/2022 18:37:59 - INFO - __main__ - Step 570 Global step 570 Train loss 0.03 on epoch=284
04/27/2022 18:38:03 - INFO - __main__ - Step 580 Global step 580 Train loss 0.02 on epoch=289
04/27/2022 18:38:07 - INFO - __main__ - Step 590 Global step 590 Train loss 0.01 on epoch=294
04/27/2022 18:38:11 - INFO - __main__ - Step 600 Global step 600 Train loss 0.01 on epoch=299
04/27/2022 18:38:13 - INFO - __main__ - Global step 600 Train loss 0.02 ACC 0.9375 on epoch=299
04/27/2022 18:38:17 - INFO - __main__ - Step 610 Global step 610 Train loss 0.01 on epoch=304
04/27/2022 18:38:21 - INFO - __main__ - Step 620 Global step 620 Train loss 0.03 on epoch=309
04/27/2022 18:38:26 - INFO - __main__ - Step 630 Global step 630 Train loss 0.02 on epoch=314
04/27/2022 18:38:30 - INFO - __main__ - Step 640 Global step 640 Train loss 0.02 on epoch=319
04/27/2022 18:38:34 - INFO - __main__ - Step 650 Global step 650 Train loss 0.02 on epoch=324
04/27/2022 18:38:36 - INFO - __main__ - Global step 650 Train loss 0.02 ACC 0.84375 on epoch=324
04/27/2022 18:38:40 - INFO - __main__ - Step 660 Global step 660 Train loss 0.01 on epoch=329
04/27/2022 18:38:44 - INFO - __main__ - Step 670 Global step 670 Train loss 0.02 on epoch=334
04/27/2022 18:38:48 - INFO - __main__ - Step 680 Global step 680 Train loss 0.03 on epoch=339
04/27/2022 18:38:53 - INFO - __main__ - Step 690 Global step 690 Train loss 0.01 on epoch=344
04/27/2022 18:38:57 - INFO - __main__ - Step 700 Global step 700 Train loss 0.02 on epoch=349
04/27/2022 18:38:58 - INFO - __main__ - Global step 700 Train loss 0.02 ACC 0.875 on epoch=349
04/27/2022 18:39:03 - INFO - __main__ - Step 710 Global step 710 Train loss 0.01 on epoch=354
04/27/2022 18:39:07 - INFO - __main__ - Step 720 Global step 720 Train loss 0.01 on epoch=359
04/27/2022 18:39:11 - INFO - __main__ - Step 730 Global step 730 Train loss 0.02 on epoch=364
04/27/2022 18:39:15 - INFO - __main__ - Step 740 Global step 740 Train loss 0.00 on epoch=369
04/27/2022 18:39:20 - INFO - __main__ - Step 750 Global step 750 Train loss 0.01 on epoch=374
04/27/2022 18:39:21 - INFO - __main__ - Global step 750 Train loss 0.01 ACC 0.875 on epoch=374
04/27/2022 18:39:25 - INFO - __main__ - Step 760 Global step 760 Train loss 0.01 on epoch=379
04/27/2022 18:39:30 - INFO - __main__ - Step 770 Global step 770 Train loss 0.01 on epoch=384
04/27/2022 18:39:34 - INFO - __main__ - Step 780 Global step 780 Train loss 0.01 on epoch=389
04/27/2022 18:39:38 - INFO - __main__ - Step 790 Global step 790 Train loss 0.01 on epoch=394
04/27/2022 18:39:43 - INFO - __main__ - Step 800 Global step 800 Train loss 0.01 on epoch=399
04/27/2022 18:39:44 - INFO - __main__ - Global step 800 Train loss 0.01 ACC 0.875 on epoch=399
04/27/2022 18:39:48 - INFO - __main__ - Step 810 Global step 810 Train loss 0.02 on epoch=404
04/27/2022 18:39:53 - INFO - __main__ - Step 820 Global step 820 Train loss 0.02 on epoch=409
04/27/2022 18:39:57 - INFO - __main__ - Step 830 Global step 830 Train loss 0.01 on epoch=414
04/27/2022 18:40:01 - INFO - __main__ - Step 840 Global step 840 Train loss 0.01 on epoch=419
04/27/2022 18:40:05 - INFO - __main__ - Step 850 Global step 850 Train loss 0.00 on epoch=424
04/27/2022 18:40:07 - INFO - __main__ - Global step 850 Train loss 0.01 ACC 0.9375 on epoch=424
04/27/2022 18:40:11 - INFO - __main__ - Step 860 Global step 860 Train loss 0.02 on epoch=429
04/27/2022 18:40:16 - INFO - __main__ - Step 870 Global step 870 Train loss 0.01 on epoch=434
04/27/2022 18:40:20 - INFO - __main__ - Step 880 Global step 880 Train loss 0.01 on epoch=439
04/27/2022 18:40:24 - INFO - __main__ - Step 890 Global step 890 Train loss 0.01 on epoch=444
04/27/2022 18:40:28 - INFO - __main__ - Step 900 Global step 900 Train loss 0.01 on epoch=449
04/27/2022 18:40:30 - INFO - __main__ - Global step 900 Train loss 0.01 ACC 0.90625 on epoch=449
04/27/2022 18:40:34 - INFO - __main__ - Step 910 Global step 910 Train loss 0.01 on epoch=454
04/27/2022 18:40:38 - INFO - __main__ - Step 920 Global step 920 Train loss 0.03 on epoch=459
04/27/2022 18:40:43 - INFO - __main__ - Step 930 Global step 930 Train loss 0.01 on epoch=464
04/27/2022 18:40:47 - INFO - __main__ - Step 940 Global step 940 Train loss 0.01 on epoch=469
04/27/2022 18:40:51 - INFO - __main__ - Step 950 Global step 950 Train loss 0.02 on epoch=474
04/27/2022 18:40:53 - INFO - __main__ - Global step 950 Train loss 0.01 ACC 0.9375 on epoch=474
04/27/2022 18:40:57 - INFO - __main__ - Step 960 Global step 960 Train loss 0.01 on epoch=479
04/27/2022 18:41:01 - INFO - __main__ - Step 970 Global step 970 Train loss 0.01 on epoch=484
04/27/2022 18:41:05 - INFO - __main__ - Step 980 Global step 980 Train loss 0.00 on epoch=489
04/27/2022 18:41:10 - INFO - __main__ - Step 990 Global step 990 Train loss 0.02 on epoch=494
04/27/2022 18:41:14 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.01 on epoch=499
04/27/2022 18:41:15 - INFO - __main__ - Global step 1000 Train loss 0.01 ACC 0.875 on epoch=499
04/27/2022 18:41:20 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.01 on epoch=504
04/27/2022 18:41:24 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.01 on epoch=509
04/27/2022 18:41:28 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.00 on epoch=514
04/27/2022 18:41:32 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.01 on epoch=519
04/27/2022 18:41:37 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.01 on epoch=524
04/27/2022 18:41:38 - INFO - __main__ - Global step 1050 Train loss 0.01 ACC 0.90625 on epoch=524
04/27/2022 18:41:42 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.01 on epoch=529
04/27/2022 18:41:47 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.01 on epoch=534
04/27/2022 18:41:51 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.00 on epoch=539
04/27/2022 18:41:55 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.01 on epoch=544
04/27/2022 18:41:59 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.01 on epoch=549
04/27/2022 18:42:01 - INFO - __main__ - Global step 1100 Train loss 0.01 ACC 0.90625 on epoch=549
04/27/2022 18:42:05 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.01 on epoch=554
04/27/2022 18:42:10 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=559
04/27/2022 18:42:14 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.00 on epoch=564
04/27/2022 18:42:18 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.00 on epoch=569
04/27/2022 18:42:22 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=574
04/27/2022 18:42:24 - INFO - __main__ - Global step 1150 Train loss 0.01 ACC 0.90625 on epoch=574
04/27/2022 18:42:28 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.00 on epoch=579
04/27/2022 18:42:32 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.00 on epoch=584
04/27/2022 18:42:37 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.00 on epoch=589
04/27/2022 18:42:41 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.01 on epoch=594
04/27/2022 18:42:45 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=599
04/27/2022 18:42:47 - INFO - __main__ - Global step 1200 Train loss 0.00 ACC 0.90625 on epoch=599
04/27/2022 18:42:51 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.01 on epoch=604
04/27/2022 18:42:55 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.00 on epoch=609
04/27/2022 18:42:59 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=614
04/27/2022 18:43:04 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.00 on epoch=619
04/27/2022 18:43:08 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.00 on epoch=624
04/27/2022 18:43:09 - INFO - __main__ - Global step 1250 Train loss 0.01 ACC 0.90625 on epoch=624
04/27/2022 18:43:14 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.00 on epoch=629
04/27/2022 18:43:18 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.01 on epoch=634
04/27/2022 18:43:22 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=639
04/27/2022 18:43:26 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.00 on epoch=644
04/27/2022 18:43:31 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=649
04/27/2022 18:43:32 - INFO - __main__ - Global step 1300 Train loss 0.01 ACC 0.9375 on epoch=649
04/27/2022 18:43:36 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.00 on epoch=654
04/27/2022 18:43:41 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=659
04/27/2022 18:43:45 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=664
04/27/2022 18:43:49 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.00 on epoch=669
04/27/2022 18:43:53 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=674
04/27/2022 18:43:55 - INFO - __main__ - Global step 1350 Train loss 0.01 ACC 0.90625 on epoch=674
04/27/2022 18:43:59 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=679
04/27/2022 18:44:03 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.00 on epoch=684
04/27/2022 18:44:07 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.00 on epoch=689
04/27/2022 18:44:12 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.00 on epoch=694
04/27/2022 18:44:16 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=699
04/27/2022 18:44:17 - INFO - __main__ - Global step 1400 Train loss 0.01 ACC 0.90625 on epoch=699
04/27/2022 18:44:22 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=704
04/27/2022 18:44:26 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=709
04/27/2022 18:44:30 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=714
04/27/2022 18:44:34 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=719
04/27/2022 18:44:39 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=724
04/27/2022 18:44:40 - INFO - __main__ - Global step 1450 Train loss 0.00 ACC 0.84375 on epoch=724
04/27/2022 18:44:45 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=729
04/27/2022 18:44:49 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=734
04/27/2022 18:44:53 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=739
04/27/2022 18:44:57 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=744
04/27/2022 18:45:02 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=749
04/27/2022 18:45:03 - INFO - __main__ - Global step 1500 Train loss 0.00 ACC 0.84375 on epoch=749
04/27/2022 18:45:08 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=754
04/27/2022 18:45:12 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.03 on epoch=759
04/27/2022 18:45:16 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=764
04/27/2022 18:45:21 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=769
04/27/2022 18:45:25 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=774
04/27/2022 18:45:27 - INFO - __main__ - Global step 1550 Train loss 0.01 ACC 0.90625 on epoch=774
04/27/2022 18:45:31 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=779
04/27/2022 18:45:35 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=784
04/27/2022 18:45:39 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=789
04/27/2022 18:45:44 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=794
04/27/2022 18:45:48 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=799
04/27/2022 18:45:49 - INFO - __main__ - Global step 1600 Train loss 0.00 ACC 0.90625 on epoch=799
04/27/2022 18:45:54 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=804
04/27/2022 18:45:58 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=809
04/27/2022 18:46:02 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=814
04/27/2022 18:46:07 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.03 on epoch=819
04/27/2022 18:46:11 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=824
04/27/2022 18:46:13 - INFO - __main__ - Global step 1650 Train loss 0.01 ACC 0.875 on epoch=824
04/27/2022 18:46:17 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=829
04/27/2022 18:46:21 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=834
04/27/2022 18:46:26 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=839
04/27/2022 18:46:30 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=844
04/27/2022 18:46:34 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=849
04/27/2022 18:46:36 - INFO - __main__ - Global step 1700 Train loss 0.00 ACC 0.875 on epoch=849
04/27/2022 18:46:40 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=854
04/27/2022 18:46:45 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=859
04/27/2022 18:46:49 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=864
04/27/2022 18:46:53 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=869
04/27/2022 18:46:57 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=874
04/27/2022 18:46:59 - INFO - __main__ - Global step 1750 Train loss 0.00 ACC 0.875 on epoch=874
04/27/2022 18:47:04 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=879
04/27/2022 18:47:08 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=884
04/27/2022 18:47:12 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=889
04/27/2022 18:47:16 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=894
04/27/2022 18:47:21 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=899
04/27/2022 18:47:23 - INFO - __main__ - Global step 1800 Train loss 0.00 ACC 0.84375 on epoch=899
04/27/2022 18:47:27 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=904
04/27/2022 18:47:31 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=909
04/27/2022 18:47:35 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=914
04/27/2022 18:47:40 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=919
04/27/2022 18:47:44 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=924
04/27/2022 18:47:45 - INFO - __main__ - Global step 1850 Train loss 0.00 ACC 0.875 on epoch=924
04/27/2022 18:47:49 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=929
04/27/2022 18:47:54 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=934
04/27/2022 18:47:58 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=939
04/27/2022 18:48:02 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=944
04/27/2022 18:48:07 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=949
04/27/2022 18:48:08 - INFO - __main__ - Global step 1900 Train loss 0.00 ACC 0.84375 on epoch=949
04/27/2022 18:48:12 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=954
04/27/2022 18:48:17 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=959
04/27/2022 18:48:21 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=964
04/27/2022 18:48:25 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=969
04/27/2022 18:48:29 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=974
04/27/2022 18:48:31 - INFO - __main__ - Global step 1950 Train loss 0.01 ACC 0.84375 on epoch=974
04/27/2022 18:48:35 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=979
04/27/2022 18:48:39 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=984
04/27/2022 18:48:44 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=989
04/27/2022 18:48:48 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=994
04/27/2022 18:48:52 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=999
04/27/2022 18:48:53 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 18:48:53 - INFO - __main__ - Printing 3 examples
04/27/2022 18:48:53 - INFO - __main__ -  [sciq] What source of ocean pollution kills animals by coating them? (A) grain spill (B) oil spill (C) plants spill (D) chemical spill [SEP] Oil spills are another source of ocean pollution. To get at oil buried beneath the seafloor, oil rigs are built in the oceans. These rigs pump oil from beneath the ocean floor. Huge ocean tankers carry oil around the world. If something goes wrong with a rig on a tanker, millions of barrels of oil may end up in the water. The oil may coat and kill ocean animals. Some of the oil will wash ashore. This oil may destroy coastal wetlands and ruin beaches.
04/27/2022 18:48:53 - INFO - __main__ - ['oil spill']
04/27/2022 18:48:53 - INFO - __main__ -  [sciq] Smog is a visible form of what? (A) water pollution (B) condensation (C) air pollution (D) oxidation [SEP] Smog clouds the city of Los Angeles, California. Visible air pollution in the form of smog is a sign that the air is unhealthy.
04/27/2022 18:48:54 - INFO - __main__ - ['air pollution']
04/27/2022 18:48:54 - INFO - __main__ -  [sciq] What makes up the central nervous system? (A) brain and spinal cord (B) spine and lungs (C) heart and lungs (D) brain and heart [SEP] The central nervous system is made up of the brain and the spinal cord.
04/27/2022 18:48:54 - INFO - __main__ - ['brain and spinal cord']
04/27/2022 18:48:54 - INFO - __main__ - Tokenizing Input ...
04/27/2022 18:48:54 - INFO - __main__ - Tokenizing Output ...
04/27/2022 18:48:54 - INFO - __main__ - Loaded 32 examples from train data
04/27/2022 18:48:54 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 18:48:54 - INFO - __main__ - Printing 3 examples
04/27/2022 18:48:54 - INFO - __main__ -  [sciq] When energy is captured or transformed, it inevitably degrades and becomes what less useful form of energy? (A) chemical (B) motion (C) temperature (D) heat [SEP] Physics also tells us that, although energy can be captured or transformed, it inevitably degrades, becoming heat, a less useful form of energy. This is why organisms require a constant input of energy; the work they must do uses up the energy they take in. Energy, unlike materials, cannot be recycled. The story of life is a story of energy flow – its capture, transformation, use for work, and loss as heat.
04/27/2022 18:48:54 - INFO - __main__ - ['heat']
04/27/2022 18:48:54 - INFO - __main__ -  [sciq] Zeros that appear in front of all of the nonzero digits are called what? (A) zero sum game (B) left-end zeros (C) significant digits (D) non-numbers [SEP] 3. Zeros that appear in front of all of the nonzero digits are called left-end zeros. Left-end zeros are never significant. A. 0.008 has one significant figure.
04/27/2022 18:48:54 - INFO - __main__ - ['left-end zeros']
04/27/2022 18:48:54 - INFO - __main__ -  [sciq] What can be defined simply, as a change in position? (A) motion (B) gravity (C) velocity (D) speed [SEP] You can see several examples of people or things in motion in Figure below . You can probably think of many other examples. You know from experience what motion is, so it may seem like a straightforward concept. Motion can also be defined simply, as a change in position. But if you think about examples of motion in more depth, you’ll find that the idea of motion is not quite as simple and straightforward as it seems.
04/27/2022 18:48:54 - INFO - __main__ - ['motion']
04/27/2022 18:48:54 - INFO - __main__ - Tokenizing Input ...
04/27/2022 18:48:54 - INFO - __main__ - Tokenizing Output ...
04/27/2022 18:48:54 - INFO - __main__ - Loaded 32 examples from dev data
04/27/2022 18:48:54 - INFO - __main__ - Global step 2000 Train loss 0.00 ACC 0.875 on epoch=999
04/27/2022 18:48:54 - INFO - __main__ - save last model!
04/27/2022 18:48:54 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
04/27/2022 18:48:54 - INFO - __main__ - Start tokenizing ... 887 instances
04/27/2022 18:48:54 - INFO - __main__ - Printing 3 examples
04/27/2022 18:48:54 - INFO - __main__ -  [sciq] A frameshift mutation is a deletion or insertion of one or more of what that changes the reading frame of the base sequence? (A) carotenoids (B) nucleotides (C) proteins (D) genes [SEP] A frameshift mutation is a deletion or insertion of one or more nucleotides that changes the reading frame of the base sequence. Deletions remove nucleotides, and insertions add nucleotides. Consider the following sequence of bases in RNA:.
04/27/2022 18:48:54 - INFO - __main__ - ['nucleotides']
04/27/2022 18:48:54 - INFO - __main__ -  [sciq] What is an area of land called that is wet for all or part of the year? (A) grassland (B) wetland (C) plains (D) tundra [SEP] A wetland is an area that is wet for all or part of the year. Wetlands are home to certain types of plants.
04/27/2022 18:48:54 - INFO - __main__ - ['wetland']
04/27/2022 18:48:54 - INFO - __main__ -  [sciq] What are arteries, veins, and capillaries examples of? (A) blood vessels (B) muscles (C) organs (D) tissue [SEP] Blood vessels include arteries, veins, and capillaries.
04/27/2022 18:48:54 - INFO - __main__ - ['blood vessels']
04/27/2022 18:48:54 - INFO - __main__ - Tokenizing Input ...
04/27/2022 18:48:54 - INFO - __main__ - Tokenizing Output ...
04/27/2022 18:48:55 - INFO - __main__ - Loaded 887 examples from test data
04/27/2022 18:49:09 - INFO - __main__ - load prompt embedding from ckpt
04/27/2022 18:49:09 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/27/2022 18:49:10 - INFO - __main__ - Starting training!
04/27/2022 18:49:41 - INFO - __main__ - Saved prediction in models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-sciq/sciq_32_21_0.4_8_predictions.txt
04/27/2022 18:49:41 - INFO - __main__ - ACC on test data: 0.8005
04/27/2022 18:49:41 - INFO - __main__ - prefix=sciq_32_21, lr=0.4, bsz=8, dev_performance=0.9375, test_performance=0.8004509582863585
04/27/2022 18:49:41 - INFO - __main__ - Running ... prefix=sciq_32_21, lr=0.3, bsz=8 ...
04/27/2022 18:49:42 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 18:49:42 - INFO - __main__ - Printing 3 examples
04/27/2022 18:49:42 - INFO - __main__ -  [sciq] What source of ocean pollution kills animals by coating them? (A) grain spill (B) oil spill (C) plants spill (D) chemical spill [SEP] Oil spills are another source of ocean pollution. To get at oil buried beneath the seafloor, oil rigs are built in the oceans. These rigs pump oil from beneath the ocean floor. Huge ocean tankers carry oil around the world. If something goes wrong with a rig on a tanker, millions of barrels of oil may end up in the water. The oil may coat and kill ocean animals. Some of the oil will wash ashore. This oil may destroy coastal wetlands and ruin beaches.
04/27/2022 18:49:42 - INFO - __main__ - ['oil spill']
04/27/2022 18:49:42 - INFO - __main__ -  [sciq] Smog is a visible form of what? (A) water pollution (B) condensation (C) air pollution (D) oxidation [SEP] Smog clouds the city of Los Angeles, California. Visible air pollution in the form of smog is a sign that the air is unhealthy.
04/27/2022 18:49:42 - INFO - __main__ - ['air pollution']
04/27/2022 18:49:42 - INFO - __main__ -  [sciq] What makes up the central nervous system? (A) brain and spinal cord (B) spine and lungs (C) heart and lungs (D) brain and heart [SEP] The central nervous system is made up of the brain and the spinal cord.
04/27/2022 18:49:42 - INFO - __main__ - ['brain and spinal cord']
04/27/2022 18:49:42 - INFO - __main__ - Tokenizing Input ...
04/27/2022 18:49:42 - INFO - __main__ - Tokenizing Output ...
04/27/2022 18:49:42 - INFO - __main__ - Loaded 32 examples from train data
04/27/2022 18:49:42 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 18:49:42 - INFO - __main__ - Printing 3 examples
04/27/2022 18:49:42 - INFO - __main__ -  [sciq] When energy is captured or transformed, it inevitably degrades and becomes what less useful form of energy? (A) chemical (B) motion (C) temperature (D) heat [SEP] Physics also tells us that, although energy can be captured or transformed, it inevitably degrades, becoming heat, a less useful form of energy. This is why organisms require a constant input of energy; the work they must do uses up the energy they take in. Energy, unlike materials, cannot be recycled. The story of life is a story of energy flow – its capture, transformation, use for work, and loss as heat.
04/27/2022 18:49:42 - INFO - __main__ - ['heat']
04/27/2022 18:49:42 - INFO - __main__ -  [sciq] Zeros that appear in front of all of the nonzero digits are called what? (A) zero sum game (B) left-end zeros (C) significant digits (D) non-numbers [SEP] 3. Zeros that appear in front of all of the nonzero digits are called left-end zeros. Left-end zeros are never significant. A. 0.008 has one significant figure.
04/27/2022 18:49:42 - INFO - __main__ - ['left-end zeros']
04/27/2022 18:49:42 - INFO - __main__ -  [sciq] What can be defined simply, as a change in position? (A) motion (B) gravity (C) velocity (D) speed [SEP] You can see several examples of people or things in motion in Figure below . You can probably think of many other examples. You know from experience what motion is, so it may seem like a straightforward concept. Motion can also be defined simply, as a change in position. But if you think about examples of motion in more depth, you’ll find that the idea of motion is not quite as simple and straightforward as it seems.
04/27/2022 18:49:42 - INFO - __main__ - ['motion']
04/27/2022 18:49:42 - INFO - __main__ - Tokenizing Input ...
04/27/2022 18:49:42 - INFO - __main__ - Tokenizing Output ...
04/27/2022 18:49:42 - INFO - __main__ - Loaded 32 examples from dev data
04/27/2022 18:49:59 - INFO - __main__ - load prompt embedding from ckpt
04/27/2022 18:50:00 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/27/2022 18:50:00 - INFO - __main__ - Starting training!
04/27/2022 18:50:05 - INFO - __main__ - Step 10 Global step 10 Train loss 2.19 on epoch=4
04/27/2022 18:50:09 - INFO - __main__ - Step 20 Global step 20 Train loss 1.18 on epoch=9
04/27/2022 18:50:14 - INFO - __main__ - Step 30 Global step 30 Train loss 0.99 on epoch=14
04/27/2022 18:50:18 - INFO - __main__ - Step 40 Global step 40 Train loss 0.84 on epoch=19
04/27/2022 18:50:22 - INFO - __main__ - Step 50 Global step 50 Train loss 0.70 on epoch=24
04/27/2022 18:50:24 - INFO - __main__ - Global step 50 Train loss 1.18 ACC 0.53125 on epoch=24
04/27/2022 18:50:24 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.53125 on epoch=24, global_step=50
04/27/2022 18:50:28 - INFO - __main__ - Step 60 Global step 60 Train loss 0.55 on epoch=29
04/27/2022 18:50:32 - INFO - __main__ - Step 70 Global step 70 Train loss 0.48 on epoch=34
04/27/2022 18:50:36 - INFO - __main__ - Step 80 Global step 80 Train loss 0.39 on epoch=39
04/27/2022 18:50:41 - INFO - __main__ - Step 90 Global step 90 Train loss 0.36 on epoch=44
04/27/2022 18:50:45 - INFO - __main__ - Step 100 Global step 100 Train loss 0.29 on epoch=49
04/27/2022 18:50:46 - INFO - __main__ - Global step 100 Train loss 0.41 ACC 0.75 on epoch=49
04/27/2022 18:50:46 - INFO - __main__ - Saving model with best ACC: 0.53125 -> 0.75 on epoch=49, global_step=100
04/27/2022 18:50:51 - INFO - __main__ - Step 110 Global step 110 Train loss 0.34 on epoch=54
04/27/2022 18:50:55 - INFO - __main__ - Step 120 Global step 120 Train loss 0.30 on epoch=59
04/27/2022 18:50:59 - INFO - __main__ - Step 130 Global step 130 Train loss 0.24 on epoch=64
04/27/2022 18:51:03 - INFO - __main__ - Step 140 Global step 140 Train loss 0.19 on epoch=69
04/27/2022 18:51:08 - INFO - __main__ - Step 150 Global step 150 Train loss 0.20 on epoch=74
04/27/2022 18:51:09 - INFO - __main__ - Global step 150 Train loss 0.26 ACC 0.71875 on epoch=74
04/27/2022 18:51:14 - INFO - __main__ - Step 160 Global step 160 Train loss 0.24 on epoch=79
04/27/2022 18:51:18 - INFO - __main__ - Step 170 Global step 170 Train loss 0.80 on epoch=84
04/27/2022 18:51:22 - INFO - __main__ - Step 180 Global step 180 Train loss 0.35 on epoch=89
04/27/2022 18:51:26 - INFO - __main__ - Step 190 Global step 190 Train loss 0.21 on epoch=94
04/27/2022 18:51:31 - INFO - __main__ - Step 200 Global step 200 Train loss 0.17 on epoch=99
04/27/2022 18:51:32 - INFO - __main__ - Global step 200 Train loss 0.35 ACC 0.78125 on epoch=99
04/27/2022 18:51:32 - INFO - __main__ - Saving model with best ACC: 0.75 -> 0.78125 on epoch=99, global_step=200
04/27/2022 18:51:36 - INFO - __main__ - Step 210 Global step 210 Train loss 0.18 on epoch=104
04/27/2022 18:51:41 - INFO - __main__ - Step 220 Global step 220 Train loss 0.20 on epoch=109
04/27/2022 18:51:45 - INFO - __main__ - Step 230 Global step 230 Train loss 0.18 on epoch=114
04/27/2022 18:51:49 - INFO - __main__ - Step 240 Global step 240 Train loss 0.17 on epoch=119
04/27/2022 18:51:53 - INFO - __main__ - Step 250 Global step 250 Train loss 0.14 on epoch=124
04/27/2022 18:51:55 - INFO - __main__ - Global step 250 Train loss 0.17 ACC 0.78125 on epoch=124
04/27/2022 18:51:59 - INFO - __main__ - Step 260 Global step 260 Train loss 0.14 on epoch=129
04/27/2022 18:52:03 - INFO - __main__ - Step 270 Global step 270 Train loss 0.16 on epoch=134
04/27/2022 18:52:08 - INFO - __main__ - Step 280 Global step 280 Train loss 0.15 on epoch=139
04/27/2022 18:52:12 - INFO - __main__ - Step 290 Global step 290 Train loss 0.14 on epoch=144
04/27/2022 18:52:16 - INFO - __main__ - Step 300 Global step 300 Train loss 0.13 on epoch=149
04/27/2022 18:52:17 - INFO - __main__ - Global step 300 Train loss 0.14 ACC 0.78125 on epoch=149
04/27/2022 18:52:22 - INFO - __main__ - Step 310 Global step 310 Train loss 0.17 on epoch=154
04/27/2022 18:52:26 - INFO - __main__ - Step 320 Global step 320 Train loss 0.15 on epoch=159
04/27/2022 18:52:30 - INFO - __main__ - Step 330 Global step 330 Train loss 0.13 on epoch=164
04/27/2022 18:52:34 - INFO - __main__ - Step 340 Global step 340 Train loss 0.16 on epoch=169
04/27/2022 18:52:39 - INFO - __main__ - Step 350 Global step 350 Train loss 0.17 on epoch=174
04/27/2022 18:52:40 - INFO - __main__ - Global step 350 Train loss 0.16 ACC 0.78125 on epoch=174
04/27/2022 18:52:44 - INFO - __main__ - Step 360 Global step 360 Train loss 0.14 on epoch=179
04/27/2022 18:52:49 - INFO - __main__ - Step 370 Global step 370 Train loss 0.12 on epoch=184
04/27/2022 18:52:53 - INFO - __main__ - Step 380 Global step 380 Train loss 0.12 on epoch=189
04/27/2022 18:52:57 - INFO - __main__ - Step 390 Global step 390 Train loss 0.15 on epoch=194
04/27/2022 18:53:01 - INFO - __main__ - Step 400 Global step 400 Train loss 0.12 on epoch=199
04/27/2022 18:53:03 - INFO - __main__ - Global step 400 Train loss 0.13 ACC 0.78125 on epoch=199
04/27/2022 18:53:07 - INFO - __main__ - Step 410 Global step 410 Train loss 0.11 on epoch=204
04/27/2022 18:53:11 - INFO - __main__ - Step 420 Global step 420 Train loss 0.10 on epoch=209
04/27/2022 18:53:16 - INFO - __main__ - Step 430 Global step 430 Train loss 0.09 on epoch=214
04/27/2022 18:53:20 - INFO - __main__ - Step 440 Global step 440 Train loss 0.11 on epoch=219
04/27/2022 18:53:24 - INFO - __main__ - Step 450 Global step 450 Train loss 0.09 on epoch=224
04/27/2022 18:53:26 - INFO - __main__ - Global step 450 Train loss 0.10 ACC 0.78125 on epoch=224
04/27/2022 18:53:30 - INFO - __main__ - Step 460 Global step 460 Train loss 0.12 on epoch=229
04/27/2022 18:53:34 - INFO - __main__ - Step 470 Global step 470 Train loss 0.10 on epoch=234
04/27/2022 18:53:38 - INFO - __main__ - Step 480 Global step 480 Train loss 0.13 on epoch=239
04/27/2022 18:53:42 - INFO - __main__ - Step 490 Global step 490 Train loss 0.11 on epoch=244
04/27/2022 18:53:47 - INFO - __main__ - Step 500 Global step 500 Train loss 0.08 on epoch=249
04/27/2022 18:53:48 - INFO - __main__ - Global step 500 Train loss 0.11 ACC 0.78125 on epoch=249
04/27/2022 18:53:52 - INFO - __main__ - Step 510 Global step 510 Train loss 0.08 on epoch=254
04/27/2022 18:53:57 - INFO - __main__ - Step 520 Global step 520 Train loss 0.08 on epoch=259
04/27/2022 18:54:01 - INFO - __main__ - Step 530 Global step 530 Train loss 0.07 on epoch=264
04/27/2022 18:54:05 - INFO - __main__ - Step 540 Global step 540 Train loss 0.06 on epoch=269
04/27/2022 18:54:09 - INFO - __main__ - Step 550 Global step 550 Train loss 0.10 on epoch=274
04/27/2022 18:54:11 - INFO - __main__ - Global step 550 Train loss 0.08 ACC 0.78125 on epoch=274
04/27/2022 18:54:15 - INFO - __main__ - Step 560 Global step 560 Train loss 0.13 on epoch=279
04/27/2022 18:54:19 - INFO - __main__ - Step 570 Global step 570 Train loss 0.09 on epoch=284
04/27/2022 18:54:23 - INFO - __main__ - Step 580 Global step 580 Train loss 0.08 on epoch=289
04/27/2022 18:54:27 - INFO - __main__ - Step 590 Global step 590 Train loss 0.06 on epoch=294
04/27/2022 18:54:32 - INFO - __main__ - Step 600 Global step 600 Train loss 0.08 on epoch=299
04/27/2022 18:54:33 - INFO - __main__ - Global step 600 Train loss 0.09 ACC 0.75 on epoch=299
04/27/2022 18:54:37 - INFO - __main__ - Step 610 Global step 610 Train loss 0.06 on epoch=304
04/27/2022 18:54:41 - INFO - __main__ - Step 620 Global step 620 Train loss 0.06 on epoch=309
04/27/2022 18:54:46 - INFO - __main__ - Step 630 Global step 630 Train loss 0.12 on epoch=314
04/27/2022 18:54:50 - INFO - __main__ - Step 640 Global step 640 Train loss 0.09 on epoch=319
04/27/2022 18:54:54 - INFO - __main__ - Step 650 Global step 650 Train loss 0.06 on epoch=324
04/27/2022 18:54:55 - INFO - __main__ - Global step 650 Train loss 0.08 ACC 0.78125 on epoch=324
04/27/2022 18:55:00 - INFO - __main__ - Step 660 Global step 660 Train loss 0.07 on epoch=329
04/27/2022 18:55:04 - INFO - __main__ - Step 670 Global step 670 Train loss 0.07 on epoch=334
04/27/2022 18:55:08 - INFO - __main__ - Step 680 Global step 680 Train loss 0.07 on epoch=339
04/27/2022 18:55:12 - INFO - __main__ - Step 690 Global step 690 Train loss 0.06 on epoch=344
04/27/2022 18:55:16 - INFO - __main__ - Step 700 Global step 700 Train loss 0.09 on epoch=349
04/27/2022 18:55:18 - INFO - __main__ - Global step 700 Train loss 0.07 ACC 0.78125 on epoch=349
04/27/2022 18:55:22 - INFO - __main__ - Step 710 Global step 710 Train loss 0.06 on epoch=354
04/27/2022 18:55:26 - INFO - __main__ - Step 720 Global step 720 Train loss 0.03 on epoch=359
04/27/2022 18:55:31 - INFO - __main__ - Step 730 Global step 730 Train loss 0.05 on epoch=364
04/27/2022 18:55:35 - INFO - __main__ - Step 740 Global step 740 Train loss 0.09 on epoch=369
04/27/2022 18:55:39 - INFO - __main__ - Step 750 Global step 750 Train loss 0.06 on epoch=374
04/27/2022 18:55:41 - INFO - __main__ - Global step 750 Train loss 0.06 ACC 0.75 on epoch=374
04/27/2022 18:55:45 - INFO - __main__ - Step 760 Global step 760 Train loss 0.07 on epoch=379
04/27/2022 18:55:49 - INFO - __main__ - Step 770 Global step 770 Train loss 0.05 on epoch=384
04/27/2022 18:55:53 - INFO - __main__ - Step 780 Global step 780 Train loss 0.07 on epoch=389
04/27/2022 18:55:58 - INFO - __main__ - Step 790 Global step 790 Train loss 0.04 on epoch=394
04/27/2022 18:56:02 - INFO - __main__ - Step 800 Global step 800 Train loss 0.05 on epoch=399
04/27/2022 18:56:03 - INFO - __main__ - Global step 800 Train loss 0.06 ACC 0.875 on epoch=399
04/27/2022 18:56:03 - INFO - __main__ - Saving model with best ACC: 0.78125 -> 0.875 on epoch=399, global_step=800
04/27/2022 18:56:08 - INFO - __main__ - Step 810 Global step 810 Train loss 0.04 on epoch=404
04/27/2022 18:56:12 - INFO - __main__ - Step 820 Global step 820 Train loss 0.07 on epoch=409
04/27/2022 18:56:16 - INFO - __main__ - Step 830 Global step 830 Train loss 0.09 on epoch=414
04/27/2022 18:56:20 - INFO - __main__ - Step 840 Global step 840 Train loss 0.06 on epoch=419
04/27/2022 18:56:24 - INFO - __main__ - Step 850 Global step 850 Train loss 0.06 on epoch=424
04/27/2022 18:56:26 - INFO - __main__ - Global step 850 Train loss 0.06 ACC 0.84375 on epoch=424
04/27/2022 18:56:30 - INFO - __main__ - Step 860 Global step 860 Train loss 0.08 on epoch=429
04/27/2022 18:56:34 - INFO - __main__ - Step 870 Global step 870 Train loss 0.04 on epoch=434
04/27/2022 18:56:38 - INFO - __main__ - Step 880 Global step 880 Train loss 0.04 on epoch=439
04/27/2022 18:56:43 - INFO - __main__ - Step 890 Global step 890 Train loss 0.06 on epoch=444
04/27/2022 18:56:47 - INFO - __main__ - Step 900 Global step 900 Train loss 0.07 on epoch=449
04/27/2022 18:56:48 - INFO - __main__ - Global step 900 Train loss 0.06 ACC 0.84375 on epoch=449
04/27/2022 18:56:53 - INFO - __main__ - Step 910 Global step 910 Train loss 0.04 on epoch=454
04/27/2022 18:56:57 - INFO - __main__ - Step 920 Global step 920 Train loss 0.05 on epoch=459
04/27/2022 18:57:01 - INFO - __main__ - Step 930 Global step 930 Train loss 0.03 on epoch=464
04/27/2022 18:57:05 - INFO - __main__ - Step 940 Global step 940 Train loss 0.03 on epoch=469
04/27/2022 18:57:10 - INFO - __main__ - Step 950 Global step 950 Train loss 0.04 on epoch=474
04/27/2022 18:57:11 - INFO - __main__ - Global step 950 Train loss 0.04 ACC 0.875 on epoch=474
04/27/2022 18:57:15 - INFO - __main__ - Step 960 Global step 960 Train loss 0.03 on epoch=479
04/27/2022 18:57:20 - INFO - __main__ - Step 970 Global step 970 Train loss 0.04 on epoch=484
04/27/2022 18:57:24 - INFO - __main__ - Step 980 Global step 980 Train loss 0.04 on epoch=489
04/27/2022 18:57:28 - INFO - __main__ - Step 990 Global step 990 Train loss 0.05 on epoch=494
04/27/2022 18:57:32 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.04 on epoch=499
04/27/2022 18:57:34 - INFO - __main__ - Global step 1000 Train loss 0.04 ACC 0.84375 on epoch=499
04/27/2022 18:57:38 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.02 on epoch=504
04/27/2022 18:57:42 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.03 on epoch=509
04/27/2022 18:57:46 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.04 on epoch=514
04/27/2022 18:57:51 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.03 on epoch=519
04/27/2022 18:57:55 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.04 on epoch=524
04/27/2022 18:57:56 - INFO - __main__ - Global step 1050 Train loss 0.03 ACC 0.78125 on epoch=524
04/27/2022 18:58:00 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.01 on epoch=529
04/27/2022 18:58:05 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.03 on epoch=534
04/27/2022 18:58:09 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.04 on epoch=539
04/27/2022 18:58:13 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.04 on epoch=544
04/27/2022 18:58:17 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.04 on epoch=549
04/27/2022 18:58:19 - INFO - __main__ - Global step 1100 Train loss 0.03 ACC 0.75 on epoch=549
04/27/2022 18:58:23 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.02 on epoch=554
04/27/2022 18:58:27 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.02 on epoch=559
04/27/2022 18:58:31 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.04 on epoch=564
04/27/2022 18:58:36 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.02 on epoch=569
04/27/2022 18:58:40 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.02 on epoch=574
04/27/2022 18:58:41 - INFO - __main__ - Global step 1150 Train loss 0.02 ACC 0.875 on epoch=574
04/27/2022 18:58:45 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.02 on epoch=579
04/27/2022 18:58:50 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.05 on epoch=584
04/27/2022 18:58:54 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.03 on epoch=589
04/27/2022 18:58:58 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.03 on epoch=594
04/27/2022 18:59:02 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.02 on epoch=599
04/27/2022 18:59:04 - INFO - __main__ - Global step 1200 Train loss 0.03 ACC 0.90625 on epoch=599
04/27/2022 18:59:04 - INFO - __main__ - Saving model with best ACC: 0.875 -> 0.90625 on epoch=599, global_step=1200
04/27/2022 18:59:08 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.03 on epoch=604
04/27/2022 18:59:12 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=609
04/27/2022 18:59:16 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.03 on epoch=614
04/27/2022 18:59:21 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.03 on epoch=619
04/27/2022 18:59:25 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.02 on epoch=624
04/27/2022 18:59:26 - INFO - __main__ - Global step 1250 Train loss 0.02 ACC 0.78125 on epoch=624
04/27/2022 18:59:30 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.03 on epoch=629
04/27/2022 18:59:35 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.04 on epoch=634
04/27/2022 18:59:39 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.03 on epoch=639
04/27/2022 18:59:43 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.04 on epoch=644
04/27/2022 18:59:47 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.02 on epoch=649
04/27/2022 18:59:49 - INFO - __main__ - Global step 1300 Train loss 0.03 ACC 0.8125 on epoch=649
04/27/2022 18:59:53 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.02 on epoch=654
04/27/2022 18:59:57 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=659
04/27/2022 19:00:02 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.03 on epoch=664
04/27/2022 19:00:06 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=669
04/27/2022 19:00:10 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.05 on epoch=674
04/27/2022 19:00:11 - INFO - __main__ - Global step 1350 Train loss 0.02 ACC 0.8125 on epoch=674
04/27/2022 19:00:16 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.03 on epoch=679
04/27/2022 19:00:20 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.02 on epoch=684
04/27/2022 19:00:24 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=689
04/27/2022 19:00:28 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.03 on epoch=694
04/27/2022 19:00:33 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=699
04/27/2022 19:00:34 - INFO - __main__ - Global step 1400 Train loss 0.02 ACC 0.75 on epoch=699
04/27/2022 19:00:38 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.03 on epoch=704
04/27/2022 19:00:42 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.04 on epoch=709
04/27/2022 19:00:47 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.02 on epoch=714
04/27/2022 19:00:51 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=719
04/27/2022 19:00:55 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=724
04/27/2022 19:00:57 - INFO - __main__ - Global step 1450 Train loss 0.02 ACC 0.84375 on epoch=724
04/27/2022 19:01:01 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.03 on epoch=729
04/27/2022 19:01:05 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=734
04/27/2022 19:01:09 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=739
04/27/2022 19:01:13 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=744
04/27/2022 19:01:18 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=749
04/27/2022 19:01:19 - INFO - __main__ - Global step 1500 Train loss 0.01 ACC 0.84375 on epoch=749
04/27/2022 19:01:23 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=754
04/27/2022 19:01:28 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=759
04/27/2022 19:01:32 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.02 on epoch=764
04/27/2022 19:01:36 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=769
04/27/2022 19:01:40 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=774
04/27/2022 19:01:42 - INFO - __main__ - Global step 1550 Train loss 0.01 ACC 0.84375 on epoch=774
04/27/2022 19:01:46 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=779
04/27/2022 19:01:50 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=784
04/27/2022 19:01:54 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=789
04/27/2022 19:01:59 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=794
04/27/2022 19:02:03 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=799
04/27/2022 19:02:05 - INFO - __main__ - Global step 1600 Train loss 0.01 ACC 0.875 on epoch=799
04/27/2022 19:02:09 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=804
04/27/2022 19:02:13 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=809
04/27/2022 19:02:17 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.02 on epoch=814
04/27/2022 19:02:21 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.02 on epoch=819
04/27/2022 19:02:26 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=824
04/27/2022 19:02:27 - INFO - __main__ - Global step 1650 Train loss 0.02 ACC 0.90625 on epoch=824
04/27/2022 19:02:32 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.06 on epoch=829
04/27/2022 19:02:36 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=834
04/27/2022 19:02:40 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=839
04/27/2022 19:02:44 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=844
04/27/2022 19:02:49 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=849
04/27/2022 19:02:50 - INFO - __main__ - Global step 1700 Train loss 0.02 ACC 0.84375 on epoch=849
04/27/2022 19:02:54 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.04 on epoch=854
04/27/2022 19:02:59 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=859
04/27/2022 19:03:03 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=864
04/27/2022 19:03:07 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=869
04/27/2022 19:03:11 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=874
04/27/2022 19:03:13 - INFO - __main__ - Global step 1750 Train loss 0.02 ACC 0.84375 on epoch=874
04/27/2022 19:03:17 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=879
04/27/2022 19:03:22 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=884
04/27/2022 19:03:26 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=889
04/27/2022 19:03:30 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.03 on epoch=894
04/27/2022 19:03:34 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=899
04/27/2022 19:03:36 - INFO - __main__ - Global step 1800 Train loss 0.01 ACC 0.875 on epoch=899
04/27/2022 19:03:40 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=904
04/27/2022 19:03:44 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=909
04/27/2022 19:03:49 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=914
04/27/2022 19:03:53 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=919
04/27/2022 19:03:57 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.59 on epoch=924
04/27/2022 19:03:59 - INFO - __main__ - Global step 1850 Train loss 0.13 ACC 0.78125 on epoch=924
04/27/2022 19:04:03 - INFO - __main__ - Step 1860 Global step 1860 Train loss 2.13 on epoch=929
04/27/2022 19:04:07 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.53 on epoch=934
04/27/2022 19:04:11 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.19 on epoch=939
04/27/2022 19:04:16 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.38 on epoch=944
04/27/2022 19:04:20 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.15 on epoch=949
04/27/2022 19:04:21 - INFO - __main__ - Global step 1900 Train loss 1.07 ACC 0.84375 on epoch=949
04/27/2022 19:04:26 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.05 on epoch=954
04/27/2022 19:04:30 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=959
04/27/2022 19:04:34 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.05 on epoch=964
04/27/2022 19:04:38 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=969
04/27/2022 19:04:43 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=974
04/27/2022 19:04:44 - INFO - __main__ - Global step 1950 Train loss 0.03 ACC 0.90625 on epoch=974
04/27/2022 19:04:48 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.05 on epoch=979
04/27/2022 19:04:52 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=984
04/27/2022 19:04:57 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=989
04/27/2022 19:05:01 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=994
04/27/2022 19:05:05 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=999
04/27/2022 19:05:06 - INFO - __main__ - Global step 2000 Train loss 0.03 ACC 0.84375 on epoch=999
04/27/2022 19:05:06 - INFO - __main__ - save last model!
04/27/2022 19:05:06 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 19:05:06 - INFO - __main__ - Printing 3 examples
04/27/2022 19:05:06 - INFO - __main__ -  [sciq] What source of ocean pollution kills animals by coating them? (A) grain spill (B) oil spill (C) plants spill (D) chemical spill [SEP] Oil spills are another source of ocean pollution. To get at oil buried beneath the seafloor, oil rigs are built in the oceans. These rigs pump oil from beneath the ocean floor. Huge ocean tankers carry oil around the world. If something goes wrong with a rig on a tanker, millions of barrels of oil may end up in the water. The oil may coat and kill ocean animals. Some of the oil will wash ashore. This oil may destroy coastal wetlands and ruin beaches.
04/27/2022 19:05:06 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
04/27/2022 19:05:06 - INFO - __main__ - ['oil spill']
04/27/2022 19:05:06 - INFO - __main__ -  [sciq] Smog is a visible form of what? (A) water pollution (B) condensation (C) air pollution (D) oxidation [SEP] Smog clouds the city of Los Angeles, California. Visible air pollution in the form of smog is a sign that the air is unhealthy.
04/27/2022 19:05:06 - INFO - __main__ - ['air pollution']
04/27/2022 19:05:06 - INFO - __main__ -  [sciq] What makes up the central nervous system? (A) brain and spinal cord (B) spine and lungs (C) heart and lungs (D) brain and heart [SEP] The central nervous system is made up of the brain and the spinal cord.
04/27/2022 19:05:06 - INFO - __main__ - ['brain and spinal cord']
04/27/2022 19:05:06 - INFO - __main__ - Tokenizing Input ...
04/27/2022 19:05:06 - INFO - __main__ - Start tokenizing ... 887 instances
04/27/2022 19:05:06 - INFO - __main__ - Printing 3 examples
04/27/2022 19:05:06 - INFO - __main__ -  [sciq] A frameshift mutation is a deletion or insertion of one or more of what that changes the reading frame of the base sequence? (A) carotenoids (B) nucleotides (C) proteins (D) genes [SEP] A frameshift mutation is a deletion or insertion of one or more nucleotides that changes the reading frame of the base sequence. Deletions remove nucleotides, and insertions add nucleotides. Consider the following sequence of bases in RNA:.
04/27/2022 19:05:06 - INFO - __main__ - ['nucleotides']
04/27/2022 19:05:06 - INFO - __main__ -  [sciq] What is an area of land called that is wet for all or part of the year? (A) grassland (B) wetland (C) plains (D) tundra [SEP] A wetland is an area that is wet for all or part of the year. Wetlands are home to certain types of plants.
04/27/2022 19:05:07 - INFO - __main__ - ['wetland']
04/27/2022 19:05:07 - INFO - __main__ -  [sciq] What are arteries, veins, and capillaries examples of? (A) blood vessels (B) muscles (C) organs (D) tissue [SEP] Blood vessels include arteries, veins, and capillaries.
04/27/2022 19:05:07 - INFO - __main__ - ['blood vessels']
04/27/2022 19:05:07 - INFO - __main__ - Tokenizing Input ...
04/27/2022 19:05:07 - INFO - __main__ - Tokenizing Output ...
04/27/2022 19:05:07 - INFO - __main__ - Loaded 32 examples from train data
04/27/2022 19:05:07 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 19:05:07 - INFO - __main__ - Printing 3 examples
04/27/2022 19:05:07 - INFO - __main__ -  [sciq] When energy is captured or transformed, it inevitably degrades and becomes what less useful form of energy? (A) chemical (B) motion (C) temperature (D) heat [SEP] Physics also tells us that, although energy can be captured or transformed, it inevitably degrades, becoming heat, a less useful form of energy. This is why organisms require a constant input of energy; the work they must do uses up the energy they take in. Energy, unlike materials, cannot be recycled. The story of life is a story of energy flow – its capture, transformation, use for work, and loss as heat.
04/27/2022 19:05:07 - INFO - __main__ - ['heat']
04/27/2022 19:05:07 - INFO - __main__ -  [sciq] Zeros that appear in front of all of the nonzero digits are called what? (A) zero sum game (B) left-end zeros (C) significant digits (D) non-numbers [SEP] 3. Zeros that appear in front of all of the nonzero digits are called left-end zeros. Left-end zeros are never significant. A. 0.008 has one significant figure.
04/27/2022 19:05:07 - INFO - __main__ - ['left-end zeros']
04/27/2022 19:05:07 - INFO - __main__ -  [sciq] What can be defined simply, as a change in position? (A) motion (B) gravity (C) velocity (D) speed [SEP] You can see several examples of people or things in motion in Figure below . You can probably think of many other examples. You know from experience what motion is, so it may seem like a straightforward concept. Motion can also be defined simply, as a change in position. But if you think about examples of motion in more depth, you’ll find that the idea of motion is not quite as simple and straightforward as it seems.
04/27/2022 19:05:07 - INFO - __main__ - ['motion']
04/27/2022 19:05:07 - INFO - __main__ - Tokenizing Input ...
04/27/2022 19:05:07 - INFO - __main__ - Tokenizing Output ...
04/27/2022 19:05:07 - INFO - __main__ - Loaded 32 examples from dev data
04/27/2022 19:05:07 - INFO - __main__ - Tokenizing Output ...
04/27/2022 19:05:08 - INFO - __main__ - Loaded 887 examples from test data
04/27/2022 19:05:25 - INFO - __main__ - load prompt embedding from ckpt
04/27/2022 19:05:26 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/27/2022 19:05:26 - INFO - __main__ - Starting training!
04/27/2022 19:05:52 - INFO - __main__ - Saved prediction in models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-sciq/sciq_32_21_0.3_8_predictions.txt
04/27/2022 19:05:52 - INFO - __main__ - ACC on test data: 0.7971
04/27/2022 19:05:52 - INFO - __main__ - prefix=sciq_32_21, lr=0.3, bsz=8, dev_performance=0.90625, test_performance=0.7970687711386697
04/27/2022 19:05:52 - INFO - __main__ - Running ... prefix=sciq_32_21, lr=0.2, bsz=8 ...
04/27/2022 19:05:53 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 19:05:53 - INFO - __main__ - Printing 3 examples
04/27/2022 19:05:53 - INFO - __main__ -  [sciq] What source of ocean pollution kills animals by coating them? (A) grain spill (B) oil spill (C) plants spill (D) chemical spill [SEP] Oil spills are another source of ocean pollution. To get at oil buried beneath the seafloor, oil rigs are built in the oceans. These rigs pump oil from beneath the ocean floor. Huge ocean tankers carry oil around the world. If something goes wrong with a rig on a tanker, millions of barrels of oil may end up in the water. The oil may coat and kill ocean animals. Some of the oil will wash ashore. This oil may destroy coastal wetlands and ruin beaches.
04/27/2022 19:05:53 - INFO - __main__ - ['oil spill']
04/27/2022 19:05:53 - INFO - __main__ -  [sciq] Smog is a visible form of what? (A) water pollution (B) condensation (C) air pollution (D) oxidation [SEP] Smog clouds the city of Los Angeles, California. Visible air pollution in the form of smog is a sign that the air is unhealthy.
04/27/2022 19:05:53 - INFO - __main__ - ['air pollution']
04/27/2022 19:05:53 - INFO - __main__ -  [sciq] What makes up the central nervous system? (A) brain and spinal cord (B) spine and lungs (C) heart and lungs (D) brain and heart [SEP] The central nervous system is made up of the brain and the spinal cord.
04/27/2022 19:05:53 - INFO - __main__ - ['brain and spinal cord']
04/27/2022 19:05:53 - INFO - __main__ - Tokenizing Input ...
04/27/2022 19:05:53 - INFO - __main__ - Tokenizing Output ...
04/27/2022 19:05:53 - INFO - __main__ - Loaded 32 examples from train data
04/27/2022 19:05:53 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 19:05:53 - INFO - __main__ - Printing 3 examples
04/27/2022 19:05:53 - INFO - __main__ -  [sciq] When energy is captured or transformed, it inevitably degrades and becomes what less useful form of energy? (A) chemical (B) motion (C) temperature (D) heat [SEP] Physics also tells us that, although energy can be captured or transformed, it inevitably degrades, becoming heat, a less useful form of energy. This is why organisms require a constant input of energy; the work they must do uses up the energy they take in. Energy, unlike materials, cannot be recycled. The story of life is a story of energy flow – its capture, transformation, use for work, and loss as heat.
04/27/2022 19:05:53 - INFO - __main__ - ['heat']
04/27/2022 19:05:53 - INFO - __main__ -  [sciq] Zeros that appear in front of all of the nonzero digits are called what? (A) zero sum game (B) left-end zeros (C) significant digits (D) non-numbers [SEP] 3. Zeros that appear in front of all of the nonzero digits are called left-end zeros. Left-end zeros are never significant. A. 0.008 has one significant figure.
04/27/2022 19:05:53 - INFO - __main__ - ['left-end zeros']
04/27/2022 19:05:53 - INFO - __main__ -  [sciq] What can be defined simply, as a change in position? (A) motion (B) gravity (C) velocity (D) speed [SEP] You can see several examples of people or things in motion in Figure below . You can probably think of many other examples. You know from experience what motion is, so it may seem like a straightforward concept. Motion can also be defined simply, as a change in position. But if you think about examples of motion in more depth, you’ll find that the idea of motion is not quite as simple and straightforward as it seems.
04/27/2022 19:05:53 - INFO - __main__ - ['motion']
04/27/2022 19:05:53 - INFO - __main__ - Tokenizing Input ...
04/27/2022 19:05:53 - INFO - __main__ - Tokenizing Output ...
04/27/2022 19:05:53 - INFO - __main__ - Loaded 32 examples from dev data
04/27/2022 19:06:10 - INFO - __main__ - load prompt embedding from ckpt
04/27/2022 19:06:11 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/27/2022 19:06:11 - INFO - __main__ - Starting training!
04/27/2022 19:06:16 - INFO - __main__ - Step 10 Global step 10 Train loss 2.41 on epoch=4
04/27/2022 19:06:20 - INFO - __main__ - Step 20 Global step 20 Train loss 1.63 on epoch=9
04/27/2022 19:06:24 - INFO - __main__ - Step 30 Global step 30 Train loss 1.16 on epoch=14
04/27/2022 19:06:29 - INFO - __main__ - Step 40 Global step 40 Train loss 0.92 on epoch=19
04/27/2022 19:06:33 - INFO - __main__ - Step 50 Global step 50 Train loss 0.84 on epoch=24
04/27/2022 19:06:34 - INFO - __main__ - Global step 50 Train loss 1.39 ACC 0.46875 on epoch=24
04/27/2022 19:06:34 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.46875 on epoch=24, global_step=50
04/27/2022 19:06:38 - INFO - __main__ - Step 60 Global step 60 Train loss 0.73 on epoch=29
04/27/2022 19:06:43 - INFO - __main__ - Step 70 Global step 70 Train loss 0.67 on epoch=34
04/27/2022 19:06:47 - INFO - __main__ - Step 80 Global step 80 Train loss 0.56 on epoch=39
04/27/2022 19:06:51 - INFO - __main__ - Step 90 Global step 90 Train loss 0.54 on epoch=44
04/27/2022 19:06:55 - INFO - __main__ - Step 100 Global step 100 Train loss 0.49 on epoch=49
04/27/2022 19:06:57 - INFO - __main__ - Global step 100 Train loss 0.60 ACC 0.65625 on epoch=49
04/27/2022 19:06:57 - INFO - __main__ - Saving model with best ACC: 0.46875 -> 0.65625 on epoch=49, global_step=100
04/27/2022 19:07:01 - INFO - __main__ - Step 110 Global step 110 Train loss 0.43 on epoch=54
04/27/2022 19:07:05 - INFO - __main__ - Step 120 Global step 120 Train loss 0.32 on epoch=59
04/27/2022 19:07:10 - INFO - __main__ - Step 130 Global step 130 Train loss 0.35 on epoch=64
04/27/2022 19:07:14 - INFO - __main__ - Step 140 Global step 140 Train loss 0.26 on epoch=69
04/27/2022 19:07:18 - INFO - __main__ - Step 150 Global step 150 Train loss 0.29 on epoch=74
04/27/2022 19:07:20 - INFO - __main__ - Global step 150 Train loss 0.33 ACC 0.78125 on epoch=74
04/27/2022 19:07:20 - INFO - __main__ - Saving model with best ACC: 0.65625 -> 0.78125 on epoch=74, global_step=150
04/27/2022 19:07:24 - INFO - __main__ - Step 160 Global step 160 Train loss 0.21 on epoch=79
04/27/2022 19:07:28 - INFO - __main__ - Step 170 Global step 170 Train loss 0.22 on epoch=84
04/27/2022 19:07:32 - INFO - __main__ - Step 180 Global step 180 Train loss 0.25 on epoch=89
04/27/2022 19:07:37 - INFO - __main__ - Step 190 Global step 190 Train loss 0.19 on epoch=94
04/27/2022 19:07:41 - INFO - __main__ - Step 200 Global step 200 Train loss 0.16 on epoch=99
04/27/2022 19:07:42 - INFO - __main__ - Global step 200 Train loss 0.21 ACC 0.8125 on epoch=99
04/27/2022 19:07:42 - INFO - __main__ - Saving model with best ACC: 0.78125 -> 0.8125 on epoch=99, global_step=200
04/27/2022 19:07:47 - INFO - __main__ - Step 210 Global step 210 Train loss 0.21 on epoch=104
04/27/2022 19:07:51 - INFO - __main__ - Step 220 Global step 220 Train loss 0.13 on epoch=109
04/27/2022 19:07:55 - INFO - __main__ - Step 230 Global step 230 Train loss 0.18 on epoch=114
04/27/2022 19:07:59 - INFO - __main__ - Step 240 Global step 240 Train loss 0.15 on epoch=119
04/27/2022 19:08:04 - INFO - __main__ - Step 250 Global step 250 Train loss 0.17 on epoch=124
04/27/2022 19:08:05 - INFO - __main__ - Global step 250 Train loss 0.17 ACC 0.84375 on epoch=124
04/27/2022 19:08:05 - INFO - __main__ - Saving model with best ACC: 0.8125 -> 0.84375 on epoch=124, global_step=250
04/27/2022 19:08:09 - INFO - __main__ - Step 260 Global step 260 Train loss 0.11 on epoch=129
04/27/2022 19:08:14 - INFO - __main__ - Step 270 Global step 270 Train loss 0.15 on epoch=134
04/27/2022 19:08:18 - INFO - __main__ - Step 280 Global step 280 Train loss 0.13 on epoch=139
04/27/2022 19:08:22 - INFO - __main__ - Step 290 Global step 290 Train loss 0.07 on epoch=144
04/27/2022 19:08:26 - INFO - __main__ - Step 300 Global step 300 Train loss 0.08 on epoch=149
04/27/2022 19:08:28 - INFO - __main__ - Global step 300 Train loss 0.11 ACC 0.84375 on epoch=149
04/27/2022 19:08:32 - INFO - __main__ - Step 310 Global step 310 Train loss 0.08 on epoch=154
04/27/2022 19:08:36 - INFO - __main__ - Step 320 Global step 320 Train loss 0.11 on epoch=159
04/27/2022 19:08:41 - INFO - __main__ - Step 330 Global step 330 Train loss 0.06 on epoch=164
04/27/2022 19:08:45 - INFO - __main__ - Step 340 Global step 340 Train loss 0.09 on epoch=169
04/27/2022 19:08:49 - INFO - __main__ - Step 350 Global step 350 Train loss 0.10 on epoch=174
04/27/2022 19:08:51 - INFO - __main__ - Global step 350 Train loss 0.09 ACC 0.90625 on epoch=174
04/27/2022 19:08:51 - INFO - __main__ - Saving model with best ACC: 0.84375 -> 0.90625 on epoch=174, global_step=350
04/27/2022 19:08:55 - INFO - __main__ - Step 360 Global step 360 Train loss 0.07 on epoch=179
04/27/2022 19:08:59 - INFO - __main__ - Step 370 Global step 370 Train loss 0.10 on epoch=184
04/27/2022 19:09:03 - INFO - __main__ - Step 380 Global step 380 Train loss 0.05 on epoch=189
04/27/2022 19:09:08 - INFO - __main__ - Step 390 Global step 390 Train loss 0.08 on epoch=194
04/27/2022 19:09:12 - INFO - __main__ - Step 400 Global step 400 Train loss 0.08 on epoch=199
04/27/2022 19:09:13 - INFO - __main__ - Global step 400 Train loss 0.08 ACC 0.90625 on epoch=199
04/27/2022 19:09:18 - INFO - __main__ - Step 410 Global step 410 Train loss 0.08 on epoch=204
04/27/2022 19:09:22 - INFO - __main__ - Step 420 Global step 420 Train loss 0.05 on epoch=209
04/27/2022 19:09:26 - INFO - __main__ - Step 430 Global step 430 Train loss 0.06 on epoch=214
04/27/2022 19:09:30 - INFO - __main__ - Step 440 Global step 440 Train loss 0.06 on epoch=219
04/27/2022 19:09:35 - INFO - __main__ - Step 450 Global step 450 Train loss 0.08 on epoch=224
04/27/2022 19:09:36 - INFO - __main__ - Global step 450 Train loss 0.07 ACC 0.90625 on epoch=224
04/27/2022 19:09:41 - INFO - __main__ - Step 460 Global step 460 Train loss 0.04 on epoch=229
04/27/2022 19:09:45 - INFO - __main__ - Step 470 Global step 470 Train loss 0.04 on epoch=234
04/27/2022 19:09:49 - INFO - __main__ - Step 480 Global step 480 Train loss 0.04 on epoch=239
04/27/2022 19:09:53 - INFO - __main__ - Step 490 Global step 490 Train loss 0.05 on epoch=244
04/27/2022 19:09:58 - INFO - __main__ - Step 500 Global step 500 Train loss 0.04 on epoch=249
04/27/2022 19:09:59 - INFO - __main__ - Global step 500 Train loss 0.04 ACC 0.90625 on epoch=249
04/27/2022 19:10:03 - INFO - __main__ - Step 510 Global step 510 Train loss 0.05 on epoch=254
04/27/2022 19:10:08 - INFO - __main__ - Step 520 Global step 520 Train loss 0.03 on epoch=259
04/27/2022 19:10:12 - INFO - __main__ - Step 530 Global step 530 Train loss 0.03 on epoch=264
04/27/2022 19:10:16 - INFO - __main__ - Step 540 Global step 540 Train loss 0.05 on epoch=269
04/27/2022 19:10:21 - INFO - __main__ - Step 550 Global step 550 Train loss 0.03 on epoch=274
04/27/2022 19:10:22 - INFO - __main__ - Global step 550 Train loss 0.04 ACC 0.875 on epoch=274
04/27/2022 19:10:26 - INFO - __main__ - Step 560 Global step 560 Train loss 0.05 on epoch=279
04/27/2022 19:10:30 - INFO - __main__ - Step 570 Global step 570 Train loss 0.05 on epoch=284
04/27/2022 19:10:35 - INFO - __main__ - Step 580 Global step 580 Train loss 0.05 on epoch=289
04/27/2022 19:10:39 - INFO - __main__ - Step 590 Global step 590 Train loss 0.02 on epoch=294
04/27/2022 19:10:43 - INFO - __main__ - Step 600 Global step 600 Train loss 0.03 on epoch=299
04/27/2022 19:10:45 - INFO - __main__ - Global step 600 Train loss 0.04 ACC 0.9375 on epoch=299
04/27/2022 19:10:45 - INFO - __main__ - Saving model with best ACC: 0.90625 -> 0.9375 on epoch=299, global_step=600
04/27/2022 19:10:49 - INFO - __main__ - Step 610 Global step 610 Train loss 0.06 on epoch=304
04/27/2022 19:10:53 - INFO - __main__ - Step 620 Global step 620 Train loss 0.02 on epoch=309
04/27/2022 19:10:58 - INFO - __main__ - Step 630 Global step 630 Train loss 0.03 on epoch=314
04/27/2022 19:11:02 - INFO - __main__ - Step 640 Global step 640 Train loss 0.03 on epoch=319
04/27/2022 19:11:06 - INFO - __main__ - Step 650 Global step 650 Train loss 0.04 on epoch=324
04/27/2022 19:11:08 - INFO - __main__ - Global step 650 Train loss 0.04 ACC 0.875 on epoch=324
04/27/2022 19:11:12 - INFO - __main__ - Step 660 Global step 660 Train loss 0.03 on epoch=329
04/27/2022 19:11:16 - INFO - __main__ - Step 670 Global step 670 Train loss 0.04 on epoch=334
04/27/2022 19:11:21 - INFO - __main__ - Step 680 Global step 680 Train loss 0.05 on epoch=339
04/27/2022 19:11:25 - INFO - __main__ - Step 690 Global step 690 Train loss 0.02 on epoch=344
04/27/2022 19:11:29 - INFO - __main__ - Step 700 Global step 700 Train loss 0.03 on epoch=349
04/27/2022 19:11:31 - INFO - __main__ - Global step 700 Train loss 0.03 ACC 0.875 on epoch=349
04/27/2022 19:11:35 - INFO - __main__ - Step 710 Global step 710 Train loss 0.02 on epoch=354
04/27/2022 19:11:39 - INFO - __main__ - Step 720 Global step 720 Train loss 0.03 on epoch=359
04/27/2022 19:11:44 - INFO - __main__ - Step 730 Global step 730 Train loss 0.04 on epoch=364
04/27/2022 19:11:48 - INFO - __main__ - Step 740 Global step 740 Train loss 0.03 on epoch=369
04/27/2022 19:11:52 - INFO - __main__ - Step 750 Global step 750 Train loss 0.02 on epoch=374
04/27/2022 19:11:54 - INFO - __main__ - Global step 750 Train loss 0.03 ACC 0.84375 on epoch=374
04/27/2022 19:11:58 - INFO - __main__ - Step 760 Global step 760 Train loss 0.02 on epoch=379
04/27/2022 19:12:02 - INFO - __main__ - Step 770 Global step 770 Train loss 0.03 on epoch=384
04/27/2022 19:12:07 - INFO - __main__ - Step 780 Global step 780 Train loss 0.03 on epoch=389
04/27/2022 19:12:11 - INFO - __main__ - Step 790 Global step 790 Train loss 0.03 on epoch=394
04/27/2022 19:12:15 - INFO - __main__ - Step 800 Global step 800 Train loss 0.02 on epoch=399
04/27/2022 19:12:17 - INFO - __main__ - Global step 800 Train loss 0.02 ACC 0.84375 on epoch=399
04/27/2022 19:12:21 - INFO - __main__ - Step 810 Global step 810 Train loss 0.02 on epoch=404
04/27/2022 19:12:25 - INFO - __main__ - Step 820 Global step 820 Train loss 0.04 on epoch=409
04/27/2022 19:12:29 - INFO - __main__ - Step 830 Global step 830 Train loss 0.03 on epoch=414
04/27/2022 19:12:34 - INFO - __main__ - Step 840 Global step 840 Train loss 0.03 on epoch=419
04/27/2022 19:12:38 - INFO - __main__ - Step 850 Global step 850 Train loss 0.03 on epoch=424
04/27/2022 19:12:40 - INFO - __main__ - Global step 850 Train loss 0.03 ACC 0.90625 on epoch=424
04/27/2022 19:12:44 - INFO - __main__ - Step 860 Global step 860 Train loss 0.03 on epoch=429
04/27/2022 19:12:48 - INFO - __main__ - Step 870 Global step 870 Train loss 0.01 on epoch=434
04/27/2022 19:12:52 - INFO - __main__ - Step 880 Global step 880 Train loss 0.05 on epoch=439
04/27/2022 19:12:57 - INFO - __main__ - Step 890 Global step 890 Train loss 0.03 on epoch=444
04/27/2022 19:13:01 - INFO - __main__ - Step 900 Global step 900 Train loss 0.02 on epoch=449
04/27/2022 19:13:02 - INFO - __main__ - Global step 900 Train loss 0.03 ACC 0.84375 on epoch=449
04/27/2022 19:13:07 - INFO - __main__ - Step 910 Global step 910 Train loss 0.02 on epoch=454
04/27/2022 19:13:11 - INFO - __main__ - Step 920 Global step 920 Train loss 0.02 on epoch=459
04/27/2022 19:13:15 - INFO - __main__ - Step 930 Global step 930 Train loss 0.01 on epoch=464
04/27/2022 19:13:19 - INFO - __main__ - Step 940 Global step 940 Train loss 0.01 on epoch=469
04/27/2022 19:13:24 - INFO - __main__ - Step 950 Global step 950 Train loss 0.04 on epoch=474
04/27/2022 19:13:25 - INFO - __main__ - Global step 950 Train loss 0.02 ACC 0.84375 on epoch=474
04/27/2022 19:13:29 - INFO - __main__ - Step 960 Global step 960 Train loss 0.01 on epoch=479
04/27/2022 19:13:34 - INFO - __main__ - Step 970 Global step 970 Train loss 0.01 on epoch=484
04/27/2022 19:13:38 - INFO - __main__ - Step 980 Global step 980 Train loss 0.02 on epoch=489
04/27/2022 19:13:42 - INFO - __main__ - Step 990 Global step 990 Train loss 0.01 on epoch=494
04/27/2022 19:13:46 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.02 on epoch=499
04/27/2022 19:13:48 - INFO - __main__ - Global step 1000 Train loss 0.01 ACC 0.84375 on epoch=499
04/27/2022 19:13:52 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.02 on epoch=504
04/27/2022 19:13:56 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.02 on epoch=509
04/27/2022 19:14:00 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.02 on epoch=514
04/27/2022 19:14:05 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.02 on epoch=519
04/27/2022 19:14:09 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.02 on epoch=524
04/27/2022 19:14:10 - INFO - __main__ - Global step 1050 Train loss 0.02 ACC 0.875 on epoch=524
04/27/2022 19:14:15 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.01 on epoch=529
04/27/2022 19:14:19 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.01 on epoch=534
04/27/2022 19:14:23 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.01 on epoch=539
04/27/2022 19:14:27 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.01 on epoch=544
04/27/2022 19:14:31 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.02 on epoch=549
04/27/2022 19:14:33 - INFO - __main__ - Global step 1100 Train loss 0.01 ACC 0.875 on epoch=549
04/27/2022 19:14:37 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.01 on epoch=554
04/27/2022 19:14:42 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.00 on epoch=559
04/27/2022 19:14:46 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=564
04/27/2022 19:14:50 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.01 on epoch=569
04/27/2022 19:14:54 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=574
04/27/2022 19:14:56 - INFO - __main__ - Global step 1150 Train loss 0.01 ACC 0.875 on epoch=574
04/27/2022 19:15:00 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.01 on epoch=579
04/27/2022 19:15:04 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.03 on epoch=584
04/27/2022 19:15:08 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.02 on epoch=589
04/27/2022 19:15:13 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.05 on epoch=594
04/27/2022 19:15:17 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.03 on epoch=599
04/27/2022 19:15:18 - INFO - __main__ - Global step 1200 Train loss 0.03 ACC 0.875 on epoch=599
04/27/2022 19:15:23 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.01 on epoch=604
04/27/2022 19:15:27 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=609
04/27/2022 19:15:31 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=614
04/27/2022 19:15:35 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=619
04/27/2022 19:15:40 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.03 on epoch=624
04/27/2022 19:15:41 - INFO - __main__ - Global step 1250 Train loss 0.01 ACC 0.875 on epoch=624
04/27/2022 19:15:45 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=629
04/27/2022 19:15:50 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.01 on epoch=634
04/27/2022 19:15:54 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.02 on epoch=639
04/27/2022 19:15:58 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=644
04/27/2022 19:16:02 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=649
04/27/2022 19:16:04 - INFO - __main__ - Global step 1300 Train loss 0.01 ACC 0.875 on epoch=649
04/27/2022 19:16:08 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=654
04/27/2022 19:16:12 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=659
04/27/2022 19:16:16 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=664
04/27/2022 19:16:21 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=669
04/27/2022 19:16:25 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=674
04/27/2022 19:16:26 - INFO - __main__ - Global step 1350 Train loss 0.01 ACC 0.875 on epoch=674
04/27/2022 19:16:30 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.02 on epoch=679
04/27/2022 19:16:35 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.00 on epoch=684
04/27/2022 19:16:39 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=689
04/27/2022 19:16:43 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=694
04/27/2022 19:16:47 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=699
04/27/2022 19:16:49 - INFO - __main__ - Global step 1400 Train loss 0.01 ACC 0.84375 on epoch=699
04/27/2022 19:16:53 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=704
04/27/2022 19:16:57 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.03 on epoch=709
04/27/2022 19:17:01 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=714
04/27/2022 19:17:06 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=719
04/27/2022 19:17:10 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=724
04/27/2022 19:17:11 - INFO - __main__ - Global step 1450 Train loss 0.01 ACC 0.90625 on epoch=724
04/27/2022 19:17:15 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.02 on epoch=729
04/27/2022 19:17:20 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=734
04/27/2022 19:17:24 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=739
04/27/2022 19:17:28 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=744
04/27/2022 19:17:32 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=749
04/27/2022 19:17:34 - INFO - __main__ - Global step 1500 Train loss 0.01 ACC 0.875 on epoch=749
04/27/2022 19:17:38 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=754
04/27/2022 19:17:42 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.02 on epoch=759
04/27/2022 19:17:47 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=764
04/27/2022 19:17:51 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=769
04/27/2022 19:17:55 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=774
04/27/2022 19:17:57 - INFO - __main__ - Global step 1550 Train loss 0.01 ACC 0.90625 on epoch=774
04/27/2022 19:18:01 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=779
04/27/2022 19:18:05 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=784
04/27/2022 19:18:09 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=789
04/27/2022 19:18:13 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=794
04/27/2022 19:18:18 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=799
04/27/2022 19:18:19 - INFO - __main__ - Global step 1600 Train loss 0.01 ACC 0.875 on epoch=799
04/27/2022 19:18:23 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=804
04/27/2022 19:18:27 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=809
04/27/2022 19:18:32 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=814
04/27/2022 19:18:36 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=819
04/27/2022 19:18:40 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=824
04/27/2022 19:18:42 - INFO - __main__ - Global step 1650 Train loss 0.01 ACC 0.78125 on epoch=824
04/27/2022 19:18:46 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=829
04/27/2022 19:18:50 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=834
04/27/2022 19:18:55 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=839
04/27/2022 19:18:59 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=844
04/27/2022 19:19:03 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=849
04/27/2022 19:19:04 - INFO - __main__ - Global step 1700 Train loss 0.01 ACC 0.84375 on epoch=849
04/27/2022 19:19:09 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=854
04/27/2022 19:19:13 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=859
04/27/2022 19:19:17 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.06 on epoch=864
04/27/2022 19:19:21 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=869
04/27/2022 19:19:25 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=874
04/27/2022 19:19:27 - INFO - __main__ - Global step 1750 Train loss 0.02 ACC 0.875 on epoch=874
04/27/2022 19:19:31 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=879
04/27/2022 19:19:35 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=884
04/27/2022 19:19:39 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=889
04/27/2022 19:19:44 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=894
04/27/2022 19:19:48 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=899
04/27/2022 19:19:49 - INFO - __main__ - Global step 1800 Train loss 0.01 ACC 0.875 on epoch=899
04/27/2022 19:19:54 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=904
04/27/2022 19:19:58 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=909
04/27/2022 19:20:02 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=914
04/27/2022 19:20:06 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=919
04/27/2022 19:20:10 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=924
04/27/2022 19:20:12 - INFO - __main__ - Global step 1850 Train loss 0.01 ACC 0.875 on epoch=924
04/27/2022 19:20:16 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=929
04/27/2022 19:20:20 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=934
04/27/2022 19:20:25 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=939
04/27/2022 19:20:29 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=944
04/27/2022 19:20:33 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=949
04/27/2022 19:20:35 - INFO - __main__ - Global step 1900 Train loss 0.01 ACC 0.875 on epoch=949
04/27/2022 19:20:39 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=954
04/27/2022 19:20:43 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=959
04/27/2022 19:20:47 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=964
04/27/2022 19:20:52 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=969
04/27/2022 19:20:56 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=974
04/27/2022 19:20:57 - INFO - __main__ - Global step 1950 Train loss 0.01 ACC 0.875 on epoch=974
04/27/2022 19:21:02 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=979
04/27/2022 19:21:06 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=984
04/27/2022 19:21:10 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=989
04/27/2022 19:21:14 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=994
04/27/2022 19:21:18 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=999
04/27/2022 19:21:20 - INFO - __main__ - Global step 2000 Train loss 0.01 ACC 0.90625 on epoch=999
04/27/2022 19:21:20 - INFO - __main__ - save last model!
04/27/2022 19:21:20 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
04/27/2022 19:21:20 - INFO - __main__ - Start tokenizing ... 887 instances
04/27/2022 19:21:20 - INFO - __main__ - Printing 3 examples
04/27/2022 19:21:20 - INFO - __main__ -  [sciq] A frameshift mutation is a deletion or insertion of one or more of what that changes the reading frame of the base sequence? (A) carotenoids (B) nucleotides (C) proteins (D) genes [SEP] A frameshift mutation is a deletion or insertion of one or more nucleotides that changes the reading frame of the base sequence. Deletions remove nucleotides, and insertions add nucleotides. Consider the following sequence of bases in RNA:.
04/27/2022 19:21:20 - INFO - __main__ - ['nucleotides']
04/27/2022 19:21:20 - INFO - __main__ -  [sciq] What is an area of land called that is wet for all or part of the year? (A) grassland (B) wetland (C) plains (D) tundra [SEP] A wetland is an area that is wet for all or part of the year. Wetlands are home to certain types of plants.
04/27/2022 19:21:20 - INFO - __main__ - ['wetland']
04/27/2022 19:21:20 - INFO - __main__ -  [sciq] What are arteries, veins, and capillaries examples of? (A) blood vessels (B) muscles (C) organs (D) tissue [SEP] Blood vessels include arteries, veins, and capillaries.
04/27/2022 19:21:20 - INFO - __main__ - ['blood vessels']
04/27/2022 19:21:20 - INFO - __main__ - Tokenizing Input ...
04/27/2022 19:21:21 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 19:21:21 - INFO - __main__ - Printing 3 examples
04/27/2022 19:21:21 - INFO - __main__ -  [sciq] A circuit must be what in order for electric devices such as light bulbs to work? (A) closed (B) cyclical (C) down (D) open [SEP] A circuit must be closed for electric devices such as light bulbs to work. The arrows in the diagram show the direction in which electrons flow through the circuit. The current is considered to flow in the opposite direction.
04/27/2022 19:21:21 - INFO - __main__ - ['closed']
04/27/2022 19:21:21 - INFO - __main__ -  [sciq] Deficiency of what is symptomized by nausea, fatigue and dizziness, and can be triggered by excessive sweating? (A) calories (B) electrolytes (C) salts (D) impurities [SEP] An alkaline battery is a variation on the zinc-carbon dry cell. The alkaline battery has no carbon rod and uses a paste of zinc metal and potassium hydroxide instead of a solid metal anode. The cathode half-reaction is the same, but the anode half-reaction is different.
04/27/2022 19:21:21 - INFO - __main__ - ['electrolytes']
04/27/2022 19:21:21 - INFO - __main__ -  [sciq] What organs filter wastes from blood so they can be excreted from the body? (A) liver (B) kidneys (C) lungs (D) pancreas [SEP] Vertebrates have an excretory system that includes a pair of kidneys. Kidneys are organs that filter wastes from blood so they can be excreted from the body.
04/27/2022 19:21:21 - INFO - __main__ - ['kidneys']
04/27/2022 19:21:21 - INFO - __main__ - Tokenizing Input ...
04/27/2022 19:21:21 - INFO - __main__ - Tokenizing Output ...
04/27/2022 19:21:21 - INFO - __main__ - Loaded 32 examples from train data
04/27/2022 19:21:21 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 19:21:21 - INFO - __main__ - Printing 3 examples
04/27/2022 19:21:21 - INFO - __main__ -  [sciq] On top of the otolithic membrane is a layer of calcium carbonate crystals, called what? (A) cones (B) calcites (C) gonads (D) otoliths [SEP] Equilibrium (Balance) Along with audition, the inner ear is responsible for encoding information about equilibrium, the sense of balance. A similar mechanoreceptor—a hair cell with stereocilia—senses head position, head movement, and whether our bodies are in motion. These cells are located within the vestibule of the inner ear. Head position is sensed by the utricle and saccule, whereas head movement is sensed by the semicircular canals. The neural signals generated in the vestibular ganglion are transmitted through the vestibulocochlear nerve to the brain stem and cerebellum. The utricle and saccule are both largely composed of macula tissue (plural = maculae). The macula is composed of hair cells surrounded by support cells. The stereocilia of the hair cells extend into a viscous gel called the otolithic membrane (Figure 14.11). On top of the otolithic membrane is a layer of calcium carbonate crystals, called otoliths. The otoliths essentially make the otolithic membrane top-heavy. The otolithic membrane moves separately from the macula in response to head movements. Tilting the head causes the otolithic membrane to slide over the macula in the direction of gravity. The moving otolithic membrane, in turn, bends the sterocilia, causing some hair cells to depolarize as others hyperpolarize. The exact position of the head is interpreted by the brain based on the pattern of hair-cell depolarization.
04/27/2022 19:21:21 - INFO - __main__ - ['otoliths']
04/27/2022 19:21:21 - INFO - __main__ -  [sciq] How does alcohol expand over a wide range of temperatures? (A) variably (B) uniformly (C) exponentially (D) erratically [SEP] The red liquid in this thermometer is alcohol. Alcohol expands uniformly over a wide range of temperatures. This makes it ideal for use in thermometers.
04/27/2022 19:21:21 - INFO - __main__ - ['uniformly']
04/27/2022 19:21:21 - INFO - __main__ -  [sciq] Addiction affects what type of chemical receptors within the brain? (A) bind receptors (B) serotonin receptors (C) dopamine receptors (D) mitochondria receptors [SEP] Figure above shows the accumulation of radioactive compounds that bind to dopamine receptors. The non-addicted individuals have large numbers of receptors for dopamine. The addicted persons show less binding to these receptors, indicating that fewer receptors are present.
04/27/2022 19:21:21 - INFO - __main__ - ['dopamine receptors']
04/27/2022 19:21:21 - INFO - __main__ - Tokenizing Input ...
04/27/2022 19:21:21 - INFO - __main__ - Tokenizing Output ...
04/27/2022 19:21:21 - INFO - __main__ - Loaded 32 examples from dev data
04/27/2022 19:21:21 - INFO - __main__ - Tokenizing Output ...
04/27/2022 19:21:22 - INFO - __main__ - Loaded 887 examples from test data
04/27/2022 19:21:39 - INFO - __main__ - load prompt embedding from ckpt
04/27/2022 19:21:40 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/27/2022 19:21:40 - INFO - __main__ - Starting training!
04/27/2022 19:22:12 - INFO - __main__ - Saved prediction in models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-sciq/sciq_32_21_0.2_8_predictions.txt
04/27/2022 19:22:12 - INFO - __main__ - ACC on test data: 0.8298
04/27/2022 19:22:12 - INFO - __main__ - prefix=sciq_32_21, lr=0.2, bsz=8, dev_performance=0.9375, test_performance=0.8297632468996617
04/27/2022 19:22:12 - INFO - __main__ - Running ... prefix=sciq_32_42, lr=0.5, bsz=8 ...
04/27/2022 19:22:13 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 19:22:13 - INFO - __main__ - Printing 3 examples
04/27/2022 19:22:13 - INFO - __main__ -  [sciq] A circuit must be what in order for electric devices such as light bulbs to work? (A) closed (B) cyclical (C) down (D) open [SEP] A circuit must be closed for electric devices such as light bulbs to work. The arrows in the diagram show the direction in which electrons flow through the circuit. The current is considered to flow in the opposite direction.
04/27/2022 19:22:13 - INFO - __main__ - ['closed']
04/27/2022 19:22:13 - INFO - __main__ -  [sciq] Deficiency of what is symptomized by nausea, fatigue and dizziness, and can be triggered by excessive sweating? (A) calories (B) electrolytes (C) salts (D) impurities [SEP] An alkaline battery is a variation on the zinc-carbon dry cell. The alkaline battery has no carbon rod and uses a paste of zinc metal and potassium hydroxide instead of a solid metal anode. The cathode half-reaction is the same, but the anode half-reaction is different.
04/27/2022 19:22:13 - INFO - __main__ - ['electrolytes']
04/27/2022 19:22:13 - INFO - __main__ -  [sciq] What organs filter wastes from blood so they can be excreted from the body? (A) liver (B) kidneys (C) lungs (D) pancreas [SEP] Vertebrates have an excretory system that includes a pair of kidneys. Kidneys are organs that filter wastes from blood so they can be excreted from the body.
04/27/2022 19:22:13 - INFO - __main__ - ['kidneys']
04/27/2022 19:22:13 - INFO - __main__ - Tokenizing Input ...
04/27/2022 19:22:13 - INFO - __main__ - Tokenizing Output ...
04/27/2022 19:22:13 - INFO - __main__ - Loaded 32 examples from train data
04/27/2022 19:22:13 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 19:22:13 - INFO - __main__ - Printing 3 examples
04/27/2022 19:22:13 - INFO - __main__ -  [sciq] On top of the otolithic membrane is a layer of calcium carbonate crystals, called what? (A) cones (B) calcites (C) gonads (D) otoliths [SEP] Equilibrium (Balance) Along with audition, the inner ear is responsible for encoding information about equilibrium, the sense of balance. A similar mechanoreceptor—a hair cell with stereocilia—senses head position, head movement, and whether our bodies are in motion. These cells are located within the vestibule of the inner ear. Head position is sensed by the utricle and saccule, whereas head movement is sensed by the semicircular canals. The neural signals generated in the vestibular ganglion are transmitted through the vestibulocochlear nerve to the brain stem and cerebellum. The utricle and saccule are both largely composed of macula tissue (plural = maculae). The macula is composed of hair cells surrounded by support cells. The stereocilia of the hair cells extend into a viscous gel called the otolithic membrane (Figure 14.11). On top of the otolithic membrane is a layer of calcium carbonate crystals, called otoliths. The otoliths essentially make the otolithic membrane top-heavy. The otolithic membrane moves separately from the macula in response to head movements. Tilting the head causes the otolithic membrane to slide over the macula in the direction of gravity. The moving otolithic membrane, in turn, bends the sterocilia, causing some hair cells to depolarize as others hyperpolarize. The exact position of the head is interpreted by the brain based on the pattern of hair-cell depolarization.
04/27/2022 19:22:13 - INFO - __main__ - ['otoliths']
04/27/2022 19:22:13 - INFO - __main__ -  [sciq] How does alcohol expand over a wide range of temperatures? (A) variably (B) uniformly (C) exponentially (D) erratically [SEP] The red liquid in this thermometer is alcohol. Alcohol expands uniformly over a wide range of temperatures. This makes it ideal for use in thermometers.
04/27/2022 19:22:13 - INFO - __main__ - ['uniformly']
04/27/2022 19:22:13 - INFO - __main__ -  [sciq] Addiction affects what type of chemical receptors within the brain? (A) bind receptors (B) serotonin receptors (C) dopamine receptors (D) mitochondria receptors [SEP] Figure above shows the accumulation of radioactive compounds that bind to dopamine receptors. The non-addicted individuals have large numbers of receptors for dopamine. The addicted persons show less binding to these receptors, indicating that fewer receptors are present.
04/27/2022 19:22:13 - INFO - __main__ - ['dopamine receptors']
04/27/2022 19:22:13 - INFO - __main__ - Tokenizing Input ...
04/27/2022 19:22:13 - INFO - __main__ - Tokenizing Output ...
04/27/2022 19:22:13 - INFO - __main__ - Loaded 32 examples from dev data
04/27/2022 19:22:30 - INFO - __main__ - load prompt embedding from ckpt
04/27/2022 19:22:31 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/27/2022 19:22:31 - INFO - __main__ - Starting training!
04/27/2022 19:22:36 - INFO - __main__ - Step 10 Global step 10 Train loss 2.51 on epoch=4
04/27/2022 19:22:40 - INFO - __main__ - Step 20 Global step 20 Train loss 1.25 on epoch=9
04/27/2022 19:22:44 - INFO - __main__ - Step 30 Global step 30 Train loss 0.83 on epoch=14
04/27/2022 19:22:48 - INFO - __main__ - Step 40 Global step 40 Train loss 0.68 on epoch=19
04/27/2022 19:22:52 - INFO - __main__ - Step 50 Global step 50 Train loss 0.55 on epoch=24
04/27/2022 19:22:53 - INFO - __main__ - Global step 50 Train loss 1.16 ACC 0.53125 on epoch=24
04/27/2022 19:22:53 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.53125 on epoch=24, global_step=50
04/27/2022 19:22:58 - INFO - __main__ - Step 60 Global step 60 Train loss 0.51 on epoch=29
04/27/2022 19:23:02 - INFO - __main__ - Step 70 Global step 70 Train loss 0.36 on epoch=34
04/27/2022 19:23:06 - INFO - __main__ - Step 80 Global step 80 Train loss 0.35 on epoch=39
04/27/2022 19:23:10 - INFO - __main__ - Step 90 Global step 90 Train loss 0.35 on epoch=44
04/27/2022 19:23:14 - INFO - __main__ - Step 100 Global step 100 Train loss 0.21 on epoch=49
04/27/2022 19:23:15 - INFO - __main__ - Global step 100 Train loss 0.36 ACC 0.46875 on epoch=49
04/27/2022 19:23:20 - INFO - __main__ - Step 110 Global step 110 Train loss 0.18 on epoch=54
04/27/2022 19:23:24 - INFO - __main__ - Step 120 Global step 120 Train loss 0.17 on epoch=59
04/27/2022 19:23:28 - INFO - __main__ - Step 130 Global step 130 Train loss 0.13 on epoch=64
04/27/2022 19:23:32 - INFO - __main__ - Step 140 Global step 140 Train loss 0.16 on epoch=69
04/27/2022 19:23:36 - INFO - __main__ - Step 150 Global step 150 Train loss 0.08 on epoch=74
04/27/2022 19:23:37 - INFO - __main__ - Global step 150 Train loss 0.14 ACC 0.59375 on epoch=74
04/27/2022 19:23:37 - INFO - __main__ - Saving model with best ACC: 0.53125 -> 0.59375 on epoch=74, global_step=150
04/27/2022 19:23:42 - INFO - __main__ - Step 160 Global step 160 Train loss 0.09 on epoch=79
04/27/2022 19:23:46 - INFO - __main__ - Step 170 Global step 170 Train loss 0.10 on epoch=84
04/27/2022 19:23:50 - INFO - __main__ - Step 180 Global step 180 Train loss 0.15 on epoch=89
04/27/2022 19:23:54 - INFO - __main__ - Step 190 Global step 190 Train loss 0.08 on epoch=94
04/27/2022 19:23:58 - INFO - __main__ - Step 200 Global step 200 Train loss 0.10 on epoch=99
04/27/2022 19:23:59 - INFO - __main__ - Global step 200 Train loss 0.10 ACC 0.59375 on epoch=99
04/27/2022 19:24:03 - INFO - __main__ - Step 210 Global step 210 Train loss 0.10 on epoch=104
04/27/2022 19:24:07 - INFO - __main__ - Step 220 Global step 220 Train loss 0.05 on epoch=109
04/27/2022 19:24:12 - INFO - __main__ - Step 230 Global step 230 Train loss 0.04 on epoch=114
04/27/2022 19:24:16 - INFO - __main__ - Step 240 Global step 240 Train loss 0.08 on epoch=119
04/27/2022 19:24:20 - INFO - __main__ - Step 250 Global step 250 Train loss 0.08 on epoch=124
04/27/2022 19:24:21 - INFO - __main__ - Global step 250 Train loss 0.07 ACC 0.625 on epoch=124
04/27/2022 19:24:21 - INFO - __main__ - Saving model with best ACC: 0.59375 -> 0.625 on epoch=124, global_step=250
04/27/2022 19:24:25 - INFO - __main__ - Step 260 Global step 260 Train loss 0.09 on epoch=129
04/27/2022 19:24:30 - INFO - __main__ - Step 270 Global step 270 Train loss 0.05 on epoch=134
04/27/2022 19:24:34 - INFO - __main__ - Step 280 Global step 280 Train loss 0.03 on epoch=139
04/27/2022 19:24:38 - INFO - __main__ - Step 290 Global step 290 Train loss 0.03 on epoch=144
04/27/2022 19:24:42 - INFO - __main__ - Step 300 Global step 300 Train loss 0.07 on epoch=149
04/27/2022 19:24:44 - INFO - __main__ - Global step 300 Train loss 0.05 ACC 0.65625 on epoch=149
04/27/2022 19:24:44 - INFO - __main__ - Saving model with best ACC: 0.625 -> 0.65625 on epoch=149, global_step=300
04/27/2022 19:24:48 - INFO - __main__ - Step 310 Global step 310 Train loss 0.06 on epoch=154
04/27/2022 19:24:52 - INFO - __main__ - Step 320 Global step 320 Train loss 0.03 on epoch=159
04/27/2022 19:24:56 - INFO - __main__ - Step 330 Global step 330 Train loss 0.03 on epoch=164
04/27/2022 19:25:00 - INFO - __main__ - Step 340 Global step 340 Train loss 0.04 on epoch=169
04/27/2022 19:25:04 - INFO - __main__ - Step 350 Global step 350 Train loss 0.02 on epoch=174
04/27/2022 19:25:06 - INFO - __main__ - Global step 350 Train loss 0.04 ACC 0.6875 on epoch=174
04/27/2022 19:25:06 - INFO - __main__ - Saving model with best ACC: 0.65625 -> 0.6875 on epoch=174, global_step=350
04/27/2022 19:25:10 - INFO - __main__ - Step 360 Global step 360 Train loss 0.05 on epoch=179
04/27/2022 19:25:14 - INFO - __main__ - Step 370 Global step 370 Train loss 0.05 on epoch=184
04/27/2022 19:25:18 - INFO - __main__ - Step 380 Global step 380 Train loss 0.03 on epoch=189
04/27/2022 19:25:22 - INFO - __main__ - Step 390 Global step 390 Train loss 0.04 on epoch=194
04/27/2022 19:25:27 - INFO - __main__ - Step 400 Global step 400 Train loss 0.05 on epoch=199
04/27/2022 19:25:29 - INFO - __main__ - Global step 400 Train loss 0.04 ACC 0.71875 on epoch=199
04/27/2022 19:25:29 - INFO - __main__ - Saving model with best ACC: 0.6875 -> 0.71875 on epoch=199, global_step=400
04/27/2022 19:25:33 - INFO - __main__ - Step 410 Global step 410 Train loss 0.04 on epoch=204
04/27/2022 19:25:37 - INFO - __main__ - Step 420 Global step 420 Train loss 0.04 on epoch=209
04/27/2022 19:25:41 - INFO - __main__ - Step 430 Global step 430 Train loss 0.03 on epoch=214
04/27/2022 19:25:45 - INFO - __main__ - Step 440 Global step 440 Train loss 0.05 on epoch=219
04/27/2022 19:25:49 - INFO - __main__ - Step 450 Global step 450 Train loss 0.03 on epoch=224
04/27/2022 19:25:51 - INFO - __main__ - Global step 450 Train loss 0.04 ACC 0.75 on epoch=224
04/27/2022 19:25:51 - INFO - __main__ - Saving model with best ACC: 0.71875 -> 0.75 on epoch=224, global_step=450
04/27/2022 19:25:55 - INFO - __main__ - Step 460 Global step 460 Train loss 0.03 on epoch=229
04/27/2022 19:25:59 - INFO - __main__ - Step 470 Global step 470 Train loss 0.03 on epoch=234
04/27/2022 19:26:03 - INFO - __main__ - Step 480 Global step 480 Train loss 0.04 on epoch=239
04/27/2022 19:26:07 - INFO - __main__ - Step 490 Global step 490 Train loss 0.04 on epoch=244
04/27/2022 19:26:11 - INFO - __main__ - Step 500 Global step 500 Train loss 0.03 on epoch=249
04/27/2022 19:26:13 - INFO - __main__ - Global step 500 Train loss 0.03 ACC 0.6875 on epoch=249
04/27/2022 19:26:18 - INFO - __main__ - Step 510 Global step 510 Train loss 0.03 on epoch=254
04/27/2022 19:26:22 - INFO - __main__ - Step 520 Global step 520 Train loss 0.02 on epoch=259
04/27/2022 19:26:26 - INFO - __main__ - Step 530 Global step 530 Train loss 0.03 on epoch=264
04/27/2022 19:26:30 - INFO - __main__ - Step 540 Global step 540 Train loss 0.02 on epoch=269
04/27/2022 19:26:34 - INFO - __main__ - Step 550 Global step 550 Train loss 0.02 on epoch=274
04/27/2022 19:26:36 - INFO - __main__ - Global step 550 Train loss 0.02 ACC 0.75 on epoch=274
04/27/2022 19:26:40 - INFO - __main__ - Step 560 Global step 560 Train loss 0.03 on epoch=279
04/27/2022 19:26:44 - INFO - __main__ - Step 570 Global step 570 Train loss 0.02 on epoch=284
04/27/2022 19:26:48 - INFO - __main__ - Step 580 Global step 580 Train loss 0.01 on epoch=289
04/27/2022 19:26:52 - INFO - __main__ - Step 590 Global step 590 Train loss 0.01 on epoch=294
04/27/2022 19:26:56 - INFO - __main__ - Step 600 Global step 600 Train loss 0.03 on epoch=299
04/27/2022 19:26:58 - INFO - __main__ - Global step 600 Train loss 0.02 ACC 0.78125 on epoch=299
04/27/2022 19:26:58 - INFO - __main__ - Saving model with best ACC: 0.75 -> 0.78125 on epoch=299, global_step=600
04/27/2022 19:27:02 - INFO - __main__ - Step 610 Global step 610 Train loss 0.04 on epoch=304
04/27/2022 19:27:06 - INFO - __main__ - Step 620 Global step 620 Train loss 0.02 on epoch=309
04/27/2022 19:27:10 - INFO - __main__ - Step 630 Global step 630 Train loss 0.01 on epoch=314
04/27/2022 19:27:14 - INFO - __main__ - Step 640 Global step 640 Train loss 0.01 on epoch=319
04/27/2022 19:27:18 - INFO - __main__ - Step 650 Global step 650 Train loss 0.02 on epoch=324
04/27/2022 19:27:20 - INFO - __main__ - Global step 650 Train loss 0.02 ACC 0.6875 on epoch=324
04/27/2022 19:27:24 - INFO - __main__ - Step 660 Global step 660 Train loss 0.04 on epoch=329
04/27/2022 19:27:28 - INFO - __main__ - Step 670 Global step 670 Train loss 0.02 on epoch=334
04/27/2022 19:27:32 - INFO - __main__ - Step 680 Global step 680 Train loss 0.03 on epoch=339
04/27/2022 19:27:36 - INFO - __main__ - Step 690 Global step 690 Train loss 0.02 on epoch=344
04/27/2022 19:27:40 - INFO - __main__ - Step 700 Global step 700 Train loss 0.02 on epoch=349
04/27/2022 19:27:42 - INFO - __main__ - Global step 700 Train loss 0.03 ACC 0.6875 on epoch=349
04/27/2022 19:27:46 - INFO - __main__ - Step 710 Global step 710 Train loss 0.01 on epoch=354
04/27/2022 19:27:50 - INFO - __main__ - Step 720 Global step 720 Train loss 0.02 on epoch=359
04/27/2022 19:27:54 - INFO - __main__ - Step 730 Global step 730 Train loss 0.02 on epoch=364
04/27/2022 19:27:58 - INFO - __main__ - Step 740 Global step 740 Train loss 0.02 on epoch=369
04/27/2022 19:28:02 - INFO - __main__ - Step 750 Global step 750 Train loss 0.02 on epoch=374
04/27/2022 19:28:04 - INFO - __main__ - Global step 750 Train loss 0.02 ACC 0.6875 on epoch=374
04/27/2022 19:28:09 - INFO - __main__ - Step 760 Global step 760 Train loss 0.03 on epoch=379
04/27/2022 19:28:13 - INFO - __main__ - Step 770 Global step 770 Train loss 0.01 on epoch=384
04/27/2022 19:28:17 - INFO - __main__ - Step 780 Global step 780 Train loss 0.02 on epoch=389
04/27/2022 19:28:21 - INFO - __main__ - Step 790 Global step 790 Train loss 0.02 on epoch=394
04/27/2022 19:28:25 - INFO - __main__ - Step 800 Global step 800 Train loss 0.01 on epoch=399
04/27/2022 19:28:26 - INFO - __main__ - Global step 800 Train loss 0.02 ACC 0.65625 on epoch=399
04/27/2022 19:28:30 - INFO - __main__ - Step 810 Global step 810 Train loss 0.01 on epoch=404
04/27/2022 19:28:34 - INFO - __main__ - Step 820 Global step 820 Train loss 0.02 on epoch=409
04/27/2022 19:28:39 - INFO - __main__ - Step 830 Global step 830 Train loss 0.01 on epoch=414
04/27/2022 19:28:43 - INFO - __main__ - Step 840 Global step 840 Train loss 0.01 on epoch=419
04/27/2022 19:28:47 - INFO - __main__ - Step 850 Global step 850 Train loss 0.01 on epoch=424
04/27/2022 19:28:48 - INFO - __main__ - Global step 850 Train loss 0.01 ACC 0.65625 on epoch=424
04/27/2022 19:28:52 - INFO - __main__ - Step 860 Global step 860 Train loss 0.02 on epoch=429
04/27/2022 19:28:56 - INFO - __main__ - Step 870 Global step 870 Train loss 0.01 on epoch=434
04/27/2022 19:29:01 - INFO - __main__ - Step 880 Global step 880 Train loss 0.01 on epoch=439
04/27/2022 19:29:05 - INFO - __main__ - Step 890 Global step 890 Train loss 0.01 on epoch=444
04/27/2022 19:29:09 - INFO - __main__ - Step 900 Global step 900 Train loss 0.04 on epoch=449
04/27/2022 19:29:10 - INFO - __main__ - Global step 900 Train loss 0.02 ACC 0.71875 on epoch=449
04/27/2022 19:29:14 - INFO - __main__ - Step 910 Global step 910 Train loss 0.01 on epoch=454
04/27/2022 19:29:19 - INFO - __main__ - Step 920 Global step 920 Train loss 0.01 on epoch=459
04/27/2022 19:29:23 - INFO - __main__ - Step 930 Global step 930 Train loss 0.00 on epoch=464
04/27/2022 19:29:27 - INFO - __main__ - Step 940 Global step 940 Train loss 0.01 on epoch=469
04/27/2022 19:29:31 - INFO - __main__ - Step 950 Global step 950 Train loss 0.01 on epoch=474
04/27/2022 19:29:33 - INFO - __main__ - Global step 950 Train loss 0.01 ACC 0.71875 on epoch=474
04/27/2022 19:29:37 - INFO - __main__ - Step 960 Global step 960 Train loss 0.00 on epoch=479
04/27/2022 19:29:42 - INFO - __main__ - Step 970 Global step 970 Train loss 0.01 on epoch=484
04/27/2022 19:29:46 - INFO - __main__ - Step 980 Global step 980 Train loss 0.01 on epoch=489
04/27/2022 19:29:50 - INFO - __main__ - Step 990 Global step 990 Train loss 0.00 on epoch=494
04/27/2022 19:29:54 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.00 on epoch=499
04/27/2022 19:29:56 - INFO - __main__ - Global step 1000 Train loss 0.01 ACC 0.71875 on epoch=499
04/27/2022 19:30:00 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.01 on epoch=504
04/27/2022 19:30:04 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.01 on epoch=509
04/27/2022 19:30:08 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.01 on epoch=514
04/27/2022 19:30:12 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.00 on epoch=519
04/27/2022 19:30:16 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.01 on epoch=524
04/27/2022 19:30:18 - INFO - __main__ - Global step 1050 Train loss 0.01 ACC 0.6875 on epoch=524
04/27/2022 19:30:22 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.00 on epoch=529
04/27/2022 19:30:26 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.00 on epoch=534
04/27/2022 19:30:30 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.00 on epoch=539
04/27/2022 19:30:35 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.00 on epoch=544
04/27/2022 19:30:39 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.00 on epoch=549
04/27/2022 19:30:40 - INFO - __main__ - Global step 1100 Train loss 0.00 ACC 0.6875 on epoch=549
04/27/2022 19:30:45 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.00 on epoch=554
04/27/2022 19:30:49 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=559
04/27/2022 19:30:53 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.00 on epoch=564
04/27/2022 19:30:57 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.01 on epoch=569
04/27/2022 19:31:01 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=574
04/27/2022 19:31:03 - INFO - __main__ - Global step 1150 Train loss 0.01 ACC 0.5625 on epoch=574
04/27/2022 19:31:07 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.00 on epoch=579
04/27/2022 19:31:11 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.03 on epoch=584
04/27/2022 19:31:15 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.00 on epoch=589
04/27/2022 19:31:19 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.00 on epoch=594
04/27/2022 19:31:23 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.00 on epoch=599
04/27/2022 19:31:25 - INFO - __main__ - Global step 1200 Train loss 0.01 ACC 0.625 on epoch=599
04/27/2022 19:31:29 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.01 on epoch=604
04/27/2022 19:31:33 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.02 on epoch=609
04/27/2022 19:31:37 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.00 on epoch=614
04/27/2022 19:31:41 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=619
04/27/2022 19:31:46 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.01 on epoch=624
04/27/2022 19:31:47 - INFO - __main__ - Global step 1250 Train loss 0.01 ACC 0.5 on epoch=624
04/27/2022 19:31:51 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.03 on epoch=629
04/27/2022 19:31:55 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.00 on epoch=634
04/27/2022 19:32:00 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=639
04/27/2022 19:32:04 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.00 on epoch=644
04/27/2022 19:32:08 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=649
04/27/2022 19:32:09 - INFO - __main__ - Global step 1300 Train loss 0.01 ACC 0.65625 on epoch=649
04/27/2022 19:32:13 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.00 on epoch=654
04/27/2022 19:32:18 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=659
04/27/2022 19:32:22 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=664
04/27/2022 19:32:26 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.00 on epoch=669
04/27/2022 19:32:30 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=674
04/27/2022 19:32:32 - INFO - __main__ - Global step 1350 Train loss 0.01 ACC 0.625 on epoch=674
04/27/2022 19:32:36 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.00 on epoch=679
04/27/2022 19:32:40 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.00 on epoch=684
04/27/2022 19:32:44 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.05 on epoch=689
04/27/2022 19:32:48 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=694
04/27/2022 19:32:52 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.00 on epoch=699
04/27/2022 19:32:54 - INFO - __main__ - Global step 1400 Train loss 0.01 ACC 0.6875 on epoch=699
04/27/2022 19:32:58 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=704
04/27/2022 19:33:02 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=709
04/27/2022 19:33:06 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.02 on epoch=714
04/27/2022 19:33:10 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=719
04/27/2022 19:33:14 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=724
04/27/2022 19:33:16 - INFO - __main__ - Global step 1450 Train loss 0.01 ACC 0.625 on epoch=724
04/27/2022 19:33:20 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=729
04/27/2022 19:33:24 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=734
04/27/2022 19:33:28 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=739
04/27/2022 19:33:32 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=744
04/27/2022 19:33:36 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=749
04/27/2022 19:33:38 - INFO - __main__ - Global step 1500 Train loss 0.00 ACC 0.6875 on epoch=749
04/27/2022 19:33:42 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=754
04/27/2022 19:33:46 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=759
04/27/2022 19:33:50 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=764
04/27/2022 19:33:54 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=769
04/27/2022 19:33:59 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=774
04/27/2022 19:34:00 - INFO - __main__ - Global step 1550 Train loss 0.01 ACC 0.71875 on epoch=774
04/27/2022 19:34:04 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=779
04/27/2022 19:34:08 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=784
04/27/2022 19:34:13 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=789
04/27/2022 19:34:17 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=794
04/27/2022 19:34:21 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=799
04/27/2022 19:34:22 - INFO - __main__ - Global step 1600 Train loss 0.01 ACC 0.6875 on epoch=799
04/27/2022 19:34:27 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=804
04/27/2022 19:34:31 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=809
04/27/2022 19:34:35 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=814
04/27/2022 19:34:39 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=819
04/27/2022 19:34:43 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=824
04/27/2022 19:34:45 - INFO - __main__ - Global step 1650 Train loss 0.01 ACC 0.75 on epoch=824
04/27/2022 19:34:49 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=829
04/27/2022 19:34:53 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=834
04/27/2022 19:34:57 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=839
04/27/2022 19:35:01 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=844
04/27/2022 19:35:05 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=849
04/27/2022 19:35:07 - INFO - __main__ - Global step 1700 Train loss 0.00 ACC 0.65625 on epoch=849
04/27/2022 19:35:12 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=854
04/27/2022 19:35:16 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=859
04/27/2022 19:35:20 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=864
04/27/2022 19:35:24 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=869
04/27/2022 19:35:28 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=874
04/27/2022 19:35:30 - INFO - __main__ - Global step 1750 Train loss 0.00 ACC 0.5625 on epoch=874
04/27/2022 19:35:34 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=879
04/27/2022 19:35:38 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=884
04/27/2022 19:35:42 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=889
04/27/2022 19:35:46 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=894
04/27/2022 19:35:50 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=899
04/27/2022 19:35:52 - INFO - __main__ - Global step 1800 Train loss 0.01 ACC 0.65625 on epoch=899
04/27/2022 19:35:56 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=904
04/27/2022 19:36:00 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=909
04/27/2022 19:36:04 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=914
04/27/2022 19:36:09 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=919
04/27/2022 19:36:13 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=924
04/27/2022 19:36:14 - INFO - __main__ - Global step 1850 Train loss 0.00 ACC 0.6875 on epoch=924
04/27/2022 19:36:18 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=929
04/27/2022 19:36:23 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=934
04/27/2022 19:36:27 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=939
04/27/2022 19:36:31 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=944
04/27/2022 19:36:35 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=949
04/27/2022 19:36:36 - INFO - __main__ - Global step 1900 Train loss 0.00 ACC 0.71875 on epoch=949
04/27/2022 19:36:40 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=954
04/27/2022 19:36:44 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=959
04/27/2022 19:36:49 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=964
04/27/2022 19:36:53 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=969
04/27/2022 19:36:57 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=974
04/27/2022 19:36:58 - INFO - __main__ - Global step 1950 Train loss 0.00 ACC 0.75 on epoch=974
04/27/2022 19:37:02 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=979
04/27/2022 19:37:06 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=984
04/27/2022 19:37:11 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=989
04/27/2022 19:37:15 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=994
04/27/2022 19:37:19 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=999
04/27/2022 19:37:20 - INFO - __main__ - Global step 2000 Train loss 0.00 ACC 0.78125 on epoch=999
04/27/2022 19:37:20 - INFO - __main__ - save last model!
04/27/2022 19:37:20 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
04/27/2022 19:37:20 - INFO - __main__ - Start tokenizing ... 887 instances
04/27/2022 19:37:20 - INFO - __main__ - Printing 3 examples
04/27/2022 19:37:20 - INFO - __main__ -  [sciq] A frameshift mutation is a deletion or insertion of one or more of what that changes the reading frame of the base sequence? (A) carotenoids (B) nucleotides (C) proteins (D) genes [SEP] A frameshift mutation is a deletion or insertion of one or more nucleotides that changes the reading frame of the base sequence. Deletions remove nucleotides, and insertions add nucleotides. Consider the following sequence of bases in RNA:.
04/27/2022 19:37:20 - INFO - __main__ - ['nucleotides']
04/27/2022 19:37:20 - INFO - __main__ -  [sciq] What is an area of land called that is wet for all or part of the year? (A) grassland (B) wetland (C) plains (D) tundra [SEP] A wetland is an area that is wet for all or part of the year. Wetlands are home to certain types of plants.
04/27/2022 19:37:20 - INFO - __main__ - ['wetland']
04/27/2022 19:37:20 - INFO - __main__ -  [sciq] What are arteries, veins, and capillaries examples of? (A) blood vessels (B) muscles (C) organs (D) tissue [SEP] Blood vessels include arteries, veins, and capillaries.
04/27/2022 19:37:20 - INFO - __main__ - ['blood vessels']
04/27/2022 19:37:20 - INFO - __main__ - Tokenizing Input ...
04/27/2022 19:37:21 - INFO - __main__ - Tokenizing Output ...
04/27/2022 19:37:21 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 19:37:21 - INFO - __main__ - Printing 3 examples
04/27/2022 19:37:21 - INFO - __main__ -  [sciq] A circuit must be what in order for electric devices such as light bulbs to work? (A) closed (B) cyclical (C) down (D) open [SEP] A circuit must be closed for electric devices such as light bulbs to work. The arrows in the diagram show the direction in which electrons flow through the circuit. The current is considered to flow in the opposite direction.
04/27/2022 19:37:21 - INFO - __main__ - ['closed']
04/27/2022 19:37:21 - INFO - __main__ -  [sciq] Deficiency of what is symptomized by nausea, fatigue and dizziness, and can be triggered by excessive sweating? (A) calories (B) electrolytes (C) salts (D) impurities [SEP] An alkaline battery is a variation on the zinc-carbon dry cell. The alkaline battery has no carbon rod and uses a paste of zinc metal and potassium hydroxide instead of a solid metal anode. The cathode half-reaction is the same, but the anode half-reaction is different.
04/27/2022 19:37:21 - INFO - __main__ - ['electrolytes']
04/27/2022 19:37:21 - INFO - __main__ -  [sciq] What organs filter wastes from blood so they can be excreted from the body? (A) liver (B) kidneys (C) lungs (D) pancreas [SEP] Vertebrates have an excretory system that includes a pair of kidneys. Kidneys are organs that filter wastes from blood so they can be excreted from the body.
04/27/2022 19:37:21 - INFO - __main__ - ['kidneys']
04/27/2022 19:37:21 - INFO - __main__ - Tokenizing Input ...
04/27/2022 19:37:21 - INFO - __main__ - Tokenizing Output ...
04/27/2022 19:37:21 - INFO - __main__ - Loaded 32 examples from train data
04/27/2022 19:37:21 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 19:37:21 - INFO - __main__ - Printing 3 examples
04/27/2022 19:37:21 - INFO - __main__ -  [sciq] On top of the otolithic membrane is a layer of calcium carbonate crystals, called what? (A) cones (B) calcites (C) gonads (D) otoliths [SEP] Equilibrium (Balance) Along with audition, the inner ear is responsible for encoding information about equilibrium, the sense of balance. A similar mechanoreceptor—a hair cell with stereocilia—senses head position, head movement, and whether our bodies are in motion. These cells are located within the vestibule of the inner ear. Head position is sensed by the utricle and saccule, whereas head movement is sensed by the semicircular canals. The neural signals generated in the vestibular ganglion are transmitted through the vestibulocochlear nerve to the brain stem and cerebellum. The utricle and saccule are both largely composed of macula tissue (plural = maculae). The macula is composed of hair cells surrounded by support cells. The stereocilia of the hair cells extend into a viscous gel called the otolithic membrane (Figure 14.11). On top of the otolithic membrane is a layer of calcium carbonate crystals, called otoliths. The otoliths essentially make the otolithic membrane top-heavy. The otolithic membrane moves separately from the macula in response to head movements. Tilting the head causes the otolithic membrane to slide over the macula in the direction of gravity. The moving otolithic membrane, in turn, bends the sterocilia, causing some hair cells to depolarize as others hyperpolarize. The exact position of the head is interpreted by the brain based on the pattern of hair-cell depolarization.
04/27/2022 19:37:21 - INFO - __main__ - ['otoliths']
04/27/2022 19:37:21 - INFO - __main__ -  [sciq] How does alcohol expand over a wide range of temperatures? (A) variably (B) uniformly (C) exponentially (D) erratically [SEP] The red liquid in this thermometer is alcohol. Alcohol expands uniformly over a wide range of temperatures. This makes it ideal for use in thermometers.
04/27/2022 19:37:21 - INFO - __main__ - ['uniformly']
04/27/2022 19:37:21 - INFO - __main__ -  [sciq] Addiction affects what type of chemical receptors within the brain? (A) bind receptors (B) serotonin receptors (C) dopamine receptors (D) mitochondria receptors [SEP] Figure above shows the accumulation of radioactive compounds that bind to dopamine receptors. The non-addicted individuals have large numbers of receptors for dopamine. The addicted persons show less binding to these receptors, indicating that fewer receptors are present.
04/27/2022 19:37:21 - INFO - __main__ - ['dopamine receptors']
04/27/2022 19:37:21 - INFO - __main__ - Tokenizing Input ...
04/27/2022 19:37:21 - INFO - __main__ - Tokenizing Output ...
04/27/2022 19:37:21 - INFO - __main__ - Loaded 32 examples from dev data
04/27/2022 19:37:22 - INFO - __main__ - Loaded 887 examples from test data
04/27/2022 19:37:37 - INFO - __main__ - load prompt embedding from ckpt
04/27/2022 19:37:37 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/27/2022 19:37:37 - INFO - __main__ - Starting training!
04/27/2022 19:38:08 - INFO - __main__ - Saved prediction in models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-sciq/sciq_32_42_0.5_8_predictions.txt
04/27/2022 19:38:08 - INFO - __main__ - ACC on test data: 0.7711
04/27/2022 19:38:08 - INFO - __main__ - prefix=sciq_32_42, lr=0.5, bsz=8, dev_performance=0.78125, test_performance=0.7711386696730552
04/27/2022 19:38:08 - INFO - __main__ - Running ... prefix=sciq_32_42, lr=0.4, bsz=8 ...
04/27/2022 19:38:09 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 19:38:09 - INFO - __main__ - Printing 3 examples
04/27/2022 19:38:09 - INFO - __main__ -  [sciq] A circuit must be what in order for electric devices such as light bulbs to work? (A) closed (B) cyclical (C) down (D) open [SEP] A circuit must be closed for electric devices such as light bulbs to work. The arrows in the diagram show the direction in which electrons flow through the circuit. The current is considered to flow in the opposite direction.
04/27/2022 19:38:09 - INFO - __main__ - ['closed']
04/27/2022 19:38:09 - INFO - __main__ -  [sciq] Deficiency of what is symptomized by nausea, fatigue and dizziness, and can be triggered by excessive sweating? (A) calories (B) electrolytes (C) salts (D) impurities [SEP] An alkaline battery is a variation on the zinc-carbon dry cell. The alkaline battery has no carbon rod and uses a paste of zinc metal and potassium hydroxide instead of a solid metal anode. The cathode half-reaction is the same, but the anode half-reaction is different.
04/27/2022 19:38:09 - INFO - __main__ - ['electrolytes']
04/27/2022 19:38:09 - INFO - __main__ -  [sciq] What organs filter wastes from blood so they can be excreted from the body? (A) liver (B) kidneys (C) lungs (D) pancreas [SEP] Vertebrates have an excretory system that includes a pair of kidneys. Kidneys are organs that filter wastes from blood so they can be excreted from the body.
04/27/2022 19:38:09 - INFO - __main__ - ['kidneys']
04/27/2022 19:38:09 - INFO - __main__ - Tokenizing Input ...
04/27/2022 19:38:09 - INFO - __main__ - Tokenizing Output ...
04/27/2022 19:38:09 - INFO - __main__ - Loaded 32 examples from train data
04/27/2022 19:38:09 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 19:38:09 - INFO - __main__ - Printing 3 examples
04/27/2022 19:38:09 - INFO - __main__ -  [sciq] On top of the otolithic membrane is a layer of calcium carbonate crystals, called what? (A) cones (B) calcites (C) gonads (D) otoliths [SEP] Equilibrium (Balance) Along with audition, the inner ear is responsible for encoding information about equilibrium, the sense of balance. A similar mechanoreceptor—a hair cell with stereocilia—senses head position, head movement, and whether our bodies are in motion. These cells are located within the vestibule of the inner ear. Head position is sensed by the utricle and saccule, whereas head movement is sensed by the semicircular canals. The neural signals generated in the vestibular ganglion are transmitted through the vestibulocochlear nerve to the brain stem and cerebellum. The utricle and saccule are both largely composed of macula tissue (plural = maculae). The macula is composed of hair cells surrounded by support cells. The stereocilia of the hair cells extend into a viscous gel called the otolithic membrane (Figure 14.11). On top of the otolithic membrane is a layer of calcium carbonate crystals, called otoliths. The otoliths essentially make the otolithic membrane top-heavy. The otolithic membrane moves separately from the macula in response to head movements. Tilting the head causes the otolithic membrane to slide over the macula in the direction of gravity. The moving otolithic membrane, in turn, bends the sterocilia, causing some hair cells to depolarize as others hyperpolarize. The exact position of the head is interpreted by the brain based on the pattern of hair-cell depolarization.
04/27/2022 19:38:09 - INFO - __main__ - ['otoliths']
04/27/2022 19:38:09 - INFO - __main__ -  [sciq] How does alcohol expand over a wide range of temperatures? (A) variably (B) uniformly (C) exponentially (D) erratically [SEP] The red liquid in this thermometer is alcohol. Alcohol expands uniformly over a wide range of temperatures. This makes it ideal for use in thermometers.
04/27/2022 19:38:09 - INFO - __main__ - ['uniformly']
04/27/2022 19:38:09 - INFO - __main__ -  [sciq] Addiction affects what type of chemical receptors within the brain? (A) bind receptors (B) serotonin receptors (C) dopamine receptors (D) mitochondria receptors [SEP] Figure above shows the accumulation of radioactive compounds that bind to dopamine receptors. The non-addicted individuals have large numbers of receptors for dopamine. The addicted persons show less binding to these receptors, indicating that fewer receptors are present.
04/27/2022 19:38:09 - INFO - __main__ - ['dopamine receptors']
04/27/2022 19:38:09 - INFO - __main__ - Tokenizing Input ...
04/27/2022 19:38:09 - INFO - __main__ - Tokenizing Output ...
04/27/2022 19:38:09 - INFO - __main__ - Loaded 32 examples from dev data
04/27/2022 19:38:26 - INFO - __main__ - load prompt embedding from ckpt
04/27/2022 19:38:27 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/27/2022 19:38:27 - INFO - __main__ - Starting training!
04/27/2022 19:38:32 - INFO - __main__ - Step 10 Global step 10 Train loss 2.56 on epoch=4
04/27/2022 19:38:36 - INFO - __main__ - Step 20 Global step 20 Train loss 1.21 on epoch=9
04/27/2022 19:38:40 - INFO - __main__ - Step 30 Global step 30 Train loss 0.84 on epoch=14
04/27/2022 19:38:44 - INFO - __main__ - Step 40 Global step 40 Train loss 0.71 on epoch=19
04/27/2022 19:38:48 - INFO - __main__ - Step 50 Global step 50 Train loss 0.52 on epoch=24
04/27/2022 19:38:51 - INFO - __main__ - Global step 50 Train loss 1.17 ACC 0.625 on epoch=24
04/27/2022 19:38:51 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.625 on epoch=24, global_step=50
04/27/2022 19:38:55 - INFO - __main__ - Step 60 Global step 60 Train loss 0.50 on epoch=29
04/27/2022 19:38:59 - INFO - __main__ - Step 70 Global step 70 Train loss 0.39 on epoch=34
04/27/2022 19:39:03 - INFO - __main__ - Step 80 Global step 80 Train loss 0.37 on epoch=39
04/27/2022 19:39:07 - INFO - __main__ - Step 90 Global step 90 Train loss 0.34 on epoch=44
04/27/2022 19:39:11 - INFO - __main__ - Step 100 Global step 100 Train loss 0.29 on epoch=49
04/27/2022 19:39:13 - INFO - __main__ - Global step 100 Train loss 0.38 ACC 0.59375 on epoch=49
04/27/2022 19:39:17 - INFO - __main__ - Step 110 Global step 110 Train loss 0.22 on epoch=54
04/27/2022 19:39:21 - INFO - __main__ - Step 120 Global step 120 Train loss 0.23 on epoch=59
04/27/2022 19:39:25 - INFO - __main__ - Step 130 Global step 130 Train loss 0.20 on epoch=64
04/27/2022 19:39:29 - INFO - __main__ - Step 140 Global step 140 Train loss 0.20 on epoch=69
04/27/2022 19:39:33 - INFO - __main__ - Step 150 Global step 150 Train loss 0.18 on epoch=74
04/27/2022 19:39:35 - INFO - __main__ - Global step 150 Train loss 0.21 ACC 0.53125 on epoch=74
04/27/2022 19:39:39 - INFO - __main__ - Step 160 Global step 160 Train loss 0.18 on epoch=79
04/27/2022 19:39:43 - INFO - __main__ - Step 170 Global step 170 Train loss 0.13 on epoch=84
04/27/2022 19:39:47 - INFO - __main__ - Step 180 Global step 180 Train loss 0.14 on epoch=89
04/27/2022 19:39:51 - INFO - __main__ - Step 190 Global step 190 Train loss 0.13 on epoch=94
04/27/2022 19:39:55 - INFO - __main__ - Step 200 Global step 200 Train loss 0.11 on epoch=99
04/27/2022 19:39:57 - INFO - __main__ - Global step 200 Train loss 0.14 ACC 0.5 on epoch=99
04/27/2022 19:40:01 - INFO - __main__ - Step 210 Global step 210 Train loss 0.17 on epoch=104
04/27/2022 19:40:05 - INFO - __main__ - Step 220 Global step 220 Train loss 0.12 on epoch=109
04/27/2022 19:40:09 - INFO - __main__ - Step 230 Global step 230 Train loss 0.17 on epoch=114
04/27/2022 19:40:13 - INFO - __main__ - Step 240 Global step 240 Train loss 0.11 on epoch=119
04/27/2022 19:40:17 - INFO - __main__ - Step 250 Global step 250 Train loss 0.05 on epoch=124
04/27/2022 19:40:20 - INFO - __main__ - Global step 250 Train loss 0.12 ACC 0.6875 on epoch=124
04/27/2022 19:40:20 - INFO - __main__ - Saving model with best ACC: 0.625 -> 0.6875 on epoch=124, global_step=250
04/27/2022 19:40:24 - INFO - __main__ - Step 260 Global step 260 Train loss 0.10 on epoch=129
04/27/2022 19:40:28 - INFO - __main__ - Step 270 Global step 270 Train loss 0.09 on epoch=134
04/27/2022 19:40:32 - INFO - __main__ - Step 280 Global step 280 Train loss 0.07 on epoch=139
04/27/2022 19:40:36 - INFO - __main__ - Step 290 Global step 290 Train loss 0.11 on epoch=144
04/27/2022 19:40:41 - INFO - __main__ - Step 300 Global step 300 Train loss 0.06 on epoch=149
04/27/2022 19:40:44 - INFO - __main__ - Global step 300 Train loss 0.09 ACC 0.65625 on epoch=149
04/27/2022 19:40:48 - INFO - __main__ - Step 310 Global step 310 Train loss 0.07 on epoch=154
04/27/2022 19:40:52 - INFO - __main__ - Step 320 Global step 320 Train loss 0.14 on epoch=159
04/27/2022 19:40:56 - INFO - __main__ - Step 330 Global step 330 Train loss 0.05 on epoch=164
04/27/2022 19:41:00 - INFO - __main__ - Step 340 Global step 340 Train loss 0.04 on epoch=169
04/27/2022 19:41:04 - INFO - __main__ - Step 350 Global step 350 Train loss 0.05 on epoch=174
04/27/2022 19:41:07 - INFO - __main__ - Global step 350 Train loss 0.07 ACC 0.625 on epoch=174
04/27/2022 19:41:11 - INFO - __main__ - Step 360 Global step 360 Train loss 0.06 on epoch=179
04/27/2022 19:41:15 - INFO - __main__ - Step 370 Global step 370 Train loss 0.07 on epoch=184
04/27/2022 19:41:19 - INFO - __main__ - Step 380 Global step 380 Train loss 0.08 on epoch=189
04/27/2022 19:41:24 - INFO - __main__ - Step 390 Global step 390 Train loss 0.07 on epoch=194
04/27/2022 19:41:28 - INFO - __main__ - Step 400 Global step 400 Train loss 0.04 on epoch=199
04/27/2022 19:41:29 - INFO - __main__ - Global step 400 Train loss 0.06 ACC 0.6875 on epoch=199
04/27/2022 19:41:33 - INFO - __main__ - Step 410 Global step 410 Train loss 0.03 on epoch=204
04/27/2022 19:41:37 - INFO - __main__ - Step 420 Global step 420 Train loss 0.04 on epoch=209
04/27/2022 19:41:41 - INFO - __main__ - Step 430 Global step 430 Train loss 0.04 on epoch=214
04/27/2022 19:41:46 - INFO - __main__ - Step 440 Global step 440 Train loss 0.17 on epoch=219
04/27/2022 19:41:50 - INFO - __main__ - Step 450 Global step 450 Train loss 0.02 on epoch=224
04/27/2022 19:41:51 - INFO - __main__ - Global step 450 Train loss 0.06 ACC 0.625 on epoch=224
04/27/2022 19:41:55 - INFO - __main__ - Step 460 Global step 460 Train loss 0.04 on epoch=229
04/27/2022 19:42:00 - INFO - __main__ - Step 470 Global step 470 Train loss 0.06 on epoch=234
04/27/2022 19:42:04 - INFO - __main__ - Step 480 Global step 480 Train loss 0.06 on epoch=239
04/27/2022 19:42:08 - INFO - __main__ - Step 490 Global step 490 Train loss 0.03 on epoch=244
04/27/2022 19:42:12 - INFO - __main__ - Step 500 Global step 500 Train loss 0.03 on epoch=249
04/27/2022 19:42:14 - INFO - __main__ - Global step 500 Train loss 0.04 ACC 0.65625 on epoch=249
04/27/2022 19:42:18 - INFO - __main__ - Step 510 Global step 510 Train loss 0.02 on epoch=254
04/27/2022 19:42:22 - INFO - __main__ - Step 520 Global step 520 Train loss 0.02 on epoch=259
04/27/2022 19:42:26 - INFO - __main__ - Step 530 Global step 530 Train loss 0.04 on epoch=264
04/27/2022 19:42:31 - INFO - __main__ - Step 540 Global step 540 Train loss 0.02 on epoch=269
04/27/2022 19:42:35 - INFO - __main__ - Step 550 Global step 550 Train loss 0.03 on epoch=274
04/27/2022 19:42:36 - INFO - __main__ - Global step 550 Train loss 0.03 ACC 0.65625 on epoch=274
04/27/2022 19:42:40 - INFO - __main__ - Step 560 Global step 560 Train loss 0.03 on epoch=279
04/27/2022 19:42:44 - INFO - __main__ - Step 570 Global step 570 Train loss 0.02 on epoch=284
04/27/2022 19:42:48 - INFO - __main__ - Step 580 Global step 580 Train loss 0.02 on epoch=289
04/27/2022 19:42:52 - INFO - __main__ - Step 590 Global step 590 Train loss 0.02 on epoch=294
04/27/2022 19:42:57 - INFO - __main__ - Step 600 Global step 600 Train loss 0.02 on epoch=299
04/27/2022 19:42:58 - INFO - __main__ - Global step 600 Train loss 0.02 ACC 0.6875 on epoch=299
04/27/2022 19:43:02 - INFO - __main__ - Step 610 Global step 610 Train loss 0.04 on epoch=304
04/27/2022 19:43:06 - INFO - __main__ - Step 620 Global step 620 Train loss 0.03 on epoch=309
04/27/2022 19:43:10 - INFO - __main__ - Step 630 Global step 630 Train loss 0.04 on epoch=314
04/27/2022 19:43:15 - INFO - __main__ - Step 640 Global step 640 Train loss 0.01 on epoch=319
04/27/2022 19:43:19 - INFO - __main__ - Step 650 Global step 650 Train loss 0.02 on epoch=324
04/27/2022 19:43:20 - INFO - __main__ - Global step 650 Train loss 0.03 ACC 0.71875 on epoch=324
04/27/2022 19:43:20 - INFO - __main__ - Saving model with best ACC: 0.6875 -> 0.71875 on epoch=324, global_step=650
04/27/2022 19:43:24 - INFO - __main__ - Step 660 Global step 660 Train loss 0.01 on epoch=329
04/27/2022 19:43:28 - INFO - __main__ - Step 670 Global step 670 Train loss 0.02 on epoch=334
04/27/2022 19:43:32 - INFO - __main__ - Step 680 Global step 680 Train loss 0.02 on epoch=339
04/27/2022 19:43:37 - INFO - __main__ - Step 690 Global step 690 Train loss 0.01 on epoch=344
04/27/2022 19:43:41 - INFO - __main__ - Step 700 Global step 700 Train loss 0.01 on epoch=349
04/27/2022 19:43:43 - INFO - __main__ - Global step 700 Train loss 0.02 ACC 0.65625 on epoch=349
04/27/2022 19:43:48 - INFO - __main__ - Step 710 Global step 710 Train loss 0.04 on epoch=354
04/27/2022 19:43:52 - INFO - __main__ - Step 720 Global step 720 Train loss 0.02 on epoch=359
04/27/2022 19:43:56 - INFO - __main__ - Step 730 Global step 730 Train loss 0.01 on epoch=364
04/27/2022 19:44:00 - INFO - __main__ - Step 740 Global step 740 Train loss 0.01 on epoch=369
04/27/2022 19:44:04 - INFO - __main__ - Step 750 Global step 750 Train loss 0.03 on epoch=374
04/27/2022 19:44:07 - INFO - __main__ - Global step 750 Train loss 0.02 ACC 0.6875 on epoch=374
04/27/2022 19:44:11 - INFO - __main__ - Step 760 Global step 760 Train loss 0.03 on epoch=379
04/27/2022 19:44:15 - INFO - __main__ - Step 770 Global step 770 Train loss 0.01 on epoch=384
04/27/2022 19:44:19 - INFO - __main__ - Step 780 Global step 780 Train loss 0.01 on epoch=389
04/27/2022 19:44:23 - INFO - __main__ - Step 790 Global step 790 Train loss 0.02 on epoch=394
04/27/2022 19:44:27 - INFO - __main__ - Step 800 Global step 800 Train loss 0.03 on epoch=399
04/27/2022 19:44:29 - INFO - __main__ - Global step 800 Train loss 0.02 ACC 0.6875 on epoch=399
04/27/2022 19:44:33 - INFO - __main__ - Step 810 Global step 810 Train loss 0.01 on epoch=404
04/27/2022 19:44:37 - INFO - __main__ - Step 820 Global step 820 Train loss 0.02 on epoch=409
04/27/2022 19:44:41 - INFO - __main__ - Step 830 Global step 830 Train loss 0.02 on epoch=414
04/27/2022 19:44:45 - INFO - __main__ - Step 840 Global step 840 Train loss 0.01 on epoch=419
04/27/2022 19:44:49 - INFO - __main__ - Step 850 Global step 850 Train loss 0.01 on epoch=424
04/27/2022 19:44:52 - INFO - __main__ - Global step 850 Train loss 0.01 ACC 0.71875 on epoch=424
04/27/2022 19:44:56 - INFO - __main__ - Step 860 Global step 860 Train loss 0.01 on epoch=429
04/27/2022 19:45:00 - INFO - __main__ - Step 870 Global step 870 Train loss 0.01 on epoch=434
04/27/2022 19:45:04 - INFO - __main__ - Step 880 Global step 880 Train loss 0.01 on epoch=439
04/27/2022 19:45:08 - INFO - __main__ - Step 890 Global step 890 Train loss 0.01 on epoch=444
04/27/2022 19:45:13 - INFO - __main__ - Step 900 Global step 900 Train loss 0.04 on epoch=449
04/27/2022 19:45:15 - INFO - __main__ - Global step 900 Train loss 0.02 ACC 0.75 on epoch=449
04/27/2022 19:45:15 - INFO - __main__ - Saving model with best ACC: 0.71875 -> 0.75 on epoch=449, global_step=900
04/27/2022 19:45:19 - INFO - __main__ - Step 910 Global step 910 Train loss 0.01 on epoch=454
04/27/2022 19:45:24 - INFO - __main__ - Step 920 Global step 920 Train loss 0.01 on epoch=459
04/27/2022 19:45:28 - INFO - __main__ - Step 930 Global step 930 Train loss 0.02 on epoch=464
04/27/2022 19:45:32 - INFO - __main__ - Step 940 Global step 940 Train loss 0.01 on epoch=469
04/27/2022 19:45:36 - INFO - __main__ - Step 950 Global step 950 Train loss 0.00 on epoch=474
04/27/2022 19:45:39 - INFO - __main__ - Global step 950 Train loss 0.01 ACC 0.71875 on epoch=474
04/27/2022 19:45:43 - INFO - __main__ - Step 960 Global step 960 Train loss 0.01 on epoch=479
04/27/2022 19:45:47 - INFO - __main__ - Step 970 Global step 970 Train loss 0.01 on epoch=484
04/27/2022 19:45:51 - INFO - __main__ - Step 980 Global step 980 Train loss 0.01 on epoch=489
04/27/2022 19:45:55 - INFO - __main__ - Step 990 Global step 990 Train loss 0.01 on epoch=494
04/27/2022 19:45:59 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.01 on epoch=499
04/27/2022 19:46:02 - INFO - __main__ - Global step 1000 Train loss 0.01 ACC 0.71875 on epoch=499
04/27/2022 19:46:06 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.01 on epoch=504
04/27/2022 19:46:10 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.01 on epoch=509
04/27/2022 19:46:14 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.01 on epoch=514
04/27/2022 19:46:18 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.02 on epoch=519
04/27/2022 19:46:23 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.01 on epoch=524
04/27/2022 19:46:24 - INFO - __main__ - Global step 1050 Train loss 0.01 ACC 0.75 on epoch=524
04/27/2022 19:46:28 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.01 on epoch=529
04/27/2022 19:46:32 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.02 on epoch=534
04/27/2022 19:46:36 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.00 on epoch=539
04/27/2022 19:46:40 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.01 on epoch=544
04/27/2022 19:46:45 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.03 on epoch=549
04/27/2022 19:46:47 - INFO - __main__ - Global step 1100 Train loss 0.02 ACC 0.75 on epoch=549
04/27/2022 19:46:51 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.00 on epoch=554
04/27/2022 19:46:56 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=559
04/27/2022 19:47:00 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=564
04/27/2022 19:47:04 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.01 on epoch=569
04/27/2022 19:47:08 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.02 on epoch=574
04/27/2022 19:47:12 - INFO - __main__ - Global step 1150 Train loss 0.01 ACC 0.71875 on epoch=574
04/27/2022 19:47:16 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.01 on epoch=579
04/27/2022 19:47:20 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.01 on epoch=584
04/27/2022 19:47:24 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.00 on epoch=589
04/27/2022 19:47:28 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.01 on epoch=594
04/27/2022 19:47:32 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=599
04/27/2022 19:47:35 - INFO - __main__ - Global step 1200 Train loss 0.01 ACC 0.78125 on epoch=599
04/27/2022 19:47:35 - INFO - __main__ - Saving model with best ACC: 0.75 -> 0.78125 on epoch=599, global_step=1200
04/27/2022 19:47:39 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.01 on epoch=604
04/27/2022 19:47:43 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.02 on epoch=609
04/27/2022 19:47:47 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=614
04/27/2022 19:47:51 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.00 on epoch=619
04/27/2022 19:47:55 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.01 on epoch=624
04/27/2022 19:47:58 - INFO - __main__ - Global step 1250 Train loss 0.01 ACC 0.75 on epoch=624
04/27/2022 19:48:02 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.00 on epoch=629
04/27/2022 19:48:06 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.00 on epoch=634
04/27/2022 19:48:10 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=639
04/27/2022 19:48:14 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=644
04/27/2022 19:48:19 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.00 on epoch=649
04/27/2022 19:48:21 - INFO - __main__ - Global step 1300 Train loss 0.01 ACC 0.75 on epoch=649
04/27/2022 19:48:25 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.00 on epoch=654
04/27/2022 19:48:30 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.00 on epoch=659
04/27/2022 19:48:34 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.03 on epoch=664
04/27/2022 19:48:38 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=669
04/27/2022 19:48:42 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.00 on epoch=674
04/27/2022 19:48:45 - INFO - __main__ - Global step 1350 Train loss 0.01 ACC 0.6875 on epoch=674
04/27/2022 19:48:49 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.00 on epoch=679
04/27/2022 19:48:53 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.00 on epoch=684
04/27/2022 19:48:57 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.00 on epoch=689
04/27/2022 19:49:01 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.00 on epoch=694
04/27/2022 19:49:05 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.00 on epoch=699
04/27/2022 19:49:08 - INFO - __main__ - Global step 1400 Train loss 0.00 ACC 0.75 on epoch=699
04/27/2022 19:49:12 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=704
04/27/2022 19:49:16 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=709
04/27/2022 19:49:20 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=714
04/27/2022 19:49:24 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=719
04/27/2022 19:49:28 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=724
04/27/2022 19:49:31 - INFO - __main__ - Global step 1450 Train loss 0.01 ACC 0.75 on epoch=724
04/27/2022 19:49:35 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=729
04/27/2022 19:49:39 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=734
04/27/2022 19:49:43 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=739
04/27/2022 19:49:48 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=744
04/27/2022 19:49:52 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=749
04/27/2022 19:49:53 - INFO - __main__ - Global step 1500 Train loss 0.00 ACC 0.71875 on epoch=749
04/27/2022 19:49:57 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=754
04/27/2022 19:50:01 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=759
04/27/2022 19:50:05 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=764
04/27/2022 19:50:10 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.06 on epoch=769
04/27/2022 19:50:14 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=774
04/27/2022 19:50:15 - INFO - __main__ - Global step 1550 Train loss 0.02 ACC 0.75 on epoch=774
04/27/2022 19:50:19 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=779
04/27/2022 19:50:24 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=784
04/27/2022 19:50:28 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=789
04/27/2022 19:50:32 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=794
04/27/2022 19:50:36 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=799
04/27/2022 19:50:38 - INFO - __main__ - Global step 1600 Train loss 0.00 ACC 0.78125 on epoch=799
04/27/2022 19:50:42 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=804
04/27/2022 19:50:46 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=809
04/27/2022 19:50:50 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=814
04/27/2022 19:50:54 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=819
04/27/2022 19:50:58 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=824
04/27/2022 19:51:00 - INFO - __main__ - Global step 1650 Train loss 0.00 ACC 0.75 on epoch=824
04/27/2022 19:51:04 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=829
04/27/2022 19:51:08 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=834
04/27/2022 19:51:12 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=839
04/27/2022 19:51:16 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.03 on epoch=844
04/27/2022 19:51:20 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=849
04/27/2022 19:51:21 - INFO - __main__ - Global step 1700 Train loss 0.01 ACC 0.78125 on epoch=849
04/27/2022 19:51:25 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=854
04/27/2022 19:51:29 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=859
04/27/2022 19:51:33 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=864
04/27/2022 19:51:37 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=869
04/27/2022 19:51:42 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=874
04/27/2022 19:51:43 - INFO - __main__ - Global step 1750 Train loss 0.00 ACC 0.8125 on epoch=874
04/27/2022 19:51:43 - INFO - __main__ - Saving model with best ACC: 0.78125 -> 0.8125 on epoch=874, global_step=1750
04/27/2022 19:51:47 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=879
04/27/2022 19:51:51 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=884
04/27/2022 19:51:55 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=889
04/27/2022 19:51:59 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=894
04/27/2022 19:52:03 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=899
04/27/2022 19:52:05 - INFO - __main__ - Global step 1800 Train loss 0.00 ACC 0.78125 on epoch=899
04/27/2022 19:52:09 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=904
04/27/2022 19:52:13 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=909
04/27/2022 19:52:17 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=914
04/27/2022 19:52:21 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=919
04/27/2022 19:52:25 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=924
04/27/2022 19:52:27 - INFO - __main__ - Global step 1850 Train loss 0.00 ACC 0.71875 on epoch=924
04/27/2022 19:52:31 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=929
04/27/2022 19:52:35 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=934
04/27/2022 19:52:39 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=939
04/27/2022 19:52:43 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=944
04/27/2022 19:52:47 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=949
04/27/2022 19:52:50 - INFO - __main__ - Global step 1900 Train loss 0.00 ACC 0.78125 on epoch=949
04/27/2022 19:52:54 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=954
04/27/2022 19:52:58 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=959
04/27/2022 19:53:02 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=964
04/27/2022 19:53:06 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=969
04/27/2022 19:53:10 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=974
04/27/2022 19:53:11 - INFO - __main__ - Global step 1950 Train loss 0.00 ACC 0.75 on epoch=974
04/27/2022 19:53:15 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=979
04/27/2022 19:53:19 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=984
04/27/2022 19:53:24 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=989
04/27/2022 19:53:28 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=994
04/27/2022 19:53:32 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=999
04/27/2022 19:53:33 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 19:53:33 - INFO - __main__ - Printing 3 examples
04/27/2022 19:53:33 - INFO - __main__ -  [sciq] A circuit must be what in order for electric devices such as light bulbs to work? (A) closed (B) cyclical (C) down (D) open [SEP] A circuit must be closed for electric devices such as light bulbs to work. The arrows in the diagram show the direction in which electrons flow through the circuit. The current is considered to flow in the opposite direction.
04/27/2022 19:53:33 - INFO - __main__ - ['closed']
04/27/2022 19:53:33 - INFO - __main__ -  [sciq] Deficiency of what is symptomized by nausea, fatigue and dizziness, and can be triggered by excessive sweating? (A) calories (B) electrolytes (C) salts (D) impurities [SEP] An alkaline battery is a variation on the zinc-carbon dry cell. The alkaline battery has no carbon rod and uses a paste of zinc metal and potassium hydroxide instead of a solid metal anode. The cathode half-reaction is the same, but the anode half-reaction is different.
04/27/2022 19:53:33 - INFO - __main__ - ['electrolytes']
04/27/2022 19:53:33 - INFO - __main__ -  [sciq] What organs filter wastes from blood so they can be excreted from the body? (A) liver (B) kidneys (C) lungs (D) pancreas [SEP] Vertebrates have an excretory system that includes a pair of kidneys. Kidneys are organs that filter wastes from blood so they can be excreted from the body.
04/27/2022 19:53:33 - INFO - __main__ - ['kidneys']
04/27/2022 19:53:33 - INFO - __main__ - Tokenizing Input ...
04/27/2022 19:53:33 - INFO - __main__ - Tokenizing Output ...
04/27/2022 19:53:33 - INFO - __main__ - Global step 2000 Train loss 0.00 ACC 0.78125 on epoch=999
04/27/2022 19:53:33 - INFO - __main__ - save last model!
04/27/2022 19:53:33 - INFO - __main__ - Loaded 32 examples from train data
04/27/2022 19:53:33 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 19:53:33 - INFO - __main__ - Printing 3 examples
04/27/2022 19:53:33 - INFO - __main__ -  [sciq] On top of the otolithic membrane is a layer of calcium carbonate crystals, called what? (A) cones (B) calcites (C) gonads (D) otoliths [SEP] Equilibrium (Balance) Along with audition, the inner ear is responsible for encoding information about equilibrium, the sense of balance. A similar mechanoreceptor—a hair cell with stereocilia—senses head position, head movement, and whether our bodies are in motion. These cells are located within the vestibule of the inner ear. Head position is sensed by the utricle and saccule, whereas head movement is sensed by the semicircular canals. The neural signals generated in the vestibular ganglion are transmitted through the vestibulocochlear nerve to the brain stem and cerebellum. The utricle and saccule are both largely composed of macula tissue (plural = maculae). The macula is composed of hair cells surrounded by support cells. The stereocilia of the hair cells extend into a viscous gel called the otolithic membrane (Figure 14.11). On top of the otolithic membrane is a layer of calcium carbonate crystals, called otoliths. The otoliths essentially make the otolithic membrane top-heavy. The otolithic membrane moves separately from the macula in response to head movements. Tilting the head causes the otolithic membrane to slide over the macula in the direction of gravity. The moving otolithic membrane, in turn, bends the sterocilia, causing some hair cells to depolarize as others hyperpolarize. The exact position of the head is interpreted by the brain based on the pattern of hair-cell depolarization.
04/27/2022 19:53:33 - INFO - __main__ - ['otoliths']
04/27/2022 19:53:33 - INFO - __main__ -  [sciq] How does alcohol expand over a wide range of temperatures? (A) variably (B) uniformly (C) exponentially (D) erratically [SEP] The red liquid in this thermometer is alcohol. Alcohol expands uniformly over a wide range of temperatures. This makes it ideal for use in thermometers.
04/27/2022 19:53:33 - INFO - __main__ - ['uniformly']
04/27/2022 19:53:33 - INFO - __main__ -  [sciq] Addiction affects what type of chemical receptors within the brain? (A) bind receptors (B) serotonin receptors (C) dopamine receptors (D) mitochondria receptors [SEP] Figure above shows the accumulation of radioactive compounds that bind to dopamine receptors. The non-addicted individuals have large numbers of receptors for dopamine. The addicted persons show less binding to these receptors, indicating that fewer receptors are present.
04/27/2022 19:53:33 - INFO - __main__ - ['dopamine receptors']
04/27/2022 19:53:33 - INFO - __main__ - Tokenizing Input ...
04/27/2022 19:53:33 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
04/27/2022 19:53:33 - INFO - __main__ - Tokenizing Output ...
04/27/2022 19:53:33 - INFO - __main__ - Start tokenizing ... 887 instances
04/27/2022 19:53:33 - INFO - __main__ - Printing 3 examples
04/27/2022 19:53:33 - INFO - __main__ -  [sciq] A frameshift mutation is a deletion or insertion of one or more of what that changes the reading frame of the base sequence? (A) carotenoids (B) nucleotides (C) proteins (D) genes [SEP] A frameshift mutation is a deletion or insertion of one or more nucleotides that changes the reading frame of the base sequence. Deletions remove nucleotides, and insertions add nucleotides. Consider the following sequence of bases in RNA:.
04/27/2022 19:53:33 - INFO - __main__ - ['nucleotides']
04/27/2022 19:53:33 - INFO - __main__ -  [sciq] What is an area of land called that is wet for all or part of the year? (A) grassland (B) wetland (C) plains (D) tundra [SEP] A wetland is an area that is wet for all or part of the year. Wetlands are home to certain types of plants.
04/27/2022 19:53:33 - INFO - __main__ - ['wetland']
04/27/2022 19:53:33 - INFO - __main__ -  [sciq] What are arteries, veins, and capillaries examples of? (A) blood vessels (B) muscles (C) organs (D) tissue [SEP] Blood vessels include arteries, veins, and capillaries.
04/27/2022 19:53:33 - INFO - __main__ - ['blood vessels']
04/27/2022 19:53:33 - INFO - __main__ - Loaded 32 examples from dev data
04/27/2022 19:53:33 - INFO - __main__ - Tokenizing Input ...
04/27/2022 19:53:34 - INFO - __main__ - Tokenizing Output ...
04/27/2022 19:53:35 - INFO - __main__ - Loaded 887 examples from test data
04/27/2022 19:53:52 - INFO - __main__ - load prompt embedding from ckpt
04/27/2022 19:53:53 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/27/2022 19:53:53 - INFO - __main__ - Starting training!
04/27/2022 19:54:24 - INFO - __main__ - Saved prediction in models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-sciq/sciq_32_42_0.4_8_predictions.txt
04/27/2022 19:54:24 - INFO - __main__ - ACC on test data: 0.7666
04/27/2022 19:54:25 - INFO - __main__ - prefix=sciq_32_42, lr=0.4, bsz=8, dev_performance=0.8125, test_performance=0.7666290868094702
04/27/2022 19:54:25 - INFO - __main__ - Running ... prefix=sciq_32_42, lr=0.3, bsz=8 ...
04/27/2022 19:54:26 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 19:54:26 - INFO - __main__ - Printing 3 examples
04/27/2022 19:54:26 - INFO - __main__ -  [sciq] A circuit must be what in order for electric devices such as light bulbs to work? (A) closed (B) cyclical (C) down (D) open [SEP] A circuit must be closed for electric devices such as light bulbs to work. The arrows in the diagram show the direction in which electrons flow through the circuit. The current is considered to flow in the opposite direction.
04/27/2022 19:54:26 - INFO - __main__ - ['closed']
04/27/2022 19:54:26 - INFO - __main__ -  [sciq] Deficiency of what is symptomized by nausea, fatigue and dizziness, and can be triggered by excessive sweating? (A) calories (B) electrolytes (C) salts (D) impurities [SEP] An alkaline battery is a variation on the zinc-carbon dry cell. The alkaline battery has no carbon rod and uses a paste of zinc metal and potassium hydroxide instead of a solid metal anode. The cathode half-reaction is the same, but the anode half-reaction is different.
04/27/2022 19:54:26 - INFO - __main__ - ['electrolytes']
04/27/2022 19:54:26 - INFO - __main__ -  [sciq] What organs filter wastes from blood so they can be excreted from the body? (A) liver (B) kidneys (C) lungs (D) pancreas [SEP] Vertebrates have an excretory system that includes a pair of kidneys. Kidneys are organs that filter wastes from blood so they can be excreted from the body.
04/27/2022 19:54:26 - INFO - __main__ - ['kidneys']
04/27/2022 19:54:26 - INFO - __main__ - Tokenizing Input ...
04/27/2022 19:54:26 - INFO - __main__ - Tokenizing Output ...
04/27/2022 19:54:26 - INFO - __main__ - Loaded 32 examples from train data
04/27/2022 19:54:26 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 19:54:26 - INFO - __main__ - Printing 3 examples
04/27/2022 19:54:26 - INFO - __main__ -  [sciq] On top of the otolithic membrane is a layer of calcium carbonate crystals, called what? (A) cones (B) calcites (C) gonads (D) otoliths [SEP] Equilibrium (Balance) Along with audition, the inner ear is responsible for encoding information about equilibrium, the sense of balance. A similar mechanoreceptor—a hair cell with stereocilia—senses head position, head movement, and whether our bodies are in motion. These cells are located within the vestibule of the inner ear. Head position is sensed by the utricle and saccule, whereas head movement is sensed by the semicircular canals. The neural signals generated in the vestibular ganglion are transmitted through the vestibulocochlear nerve to the brain stem and cerebellum. The utricle and saccule are both largely composed of macula tissue (plural = maculae). The macula is composed of hair cells surrounded by support cells. The stereocilia of the hair cells extend into a viscous gel called the otolithic membrane (Figure 14.11). On top of the otolithic membrane is a layer of calcium carbonate crystals, called otoliths. The otoliths essentially make the otolithic membrane top-heavy. The otolithic membrane moves separately from the macula in response to head movements. Tilting the head causes the otolithic membrane to slide over the macula in the direction of gravity. The moving otolithic membrane, in turn, bends the sterocilia, causing some hair cells to depolarize as others hyperpolarize. The exact position of the head is interpreted by the brain based on the pattern of hair-cell depolarization.
04/27/2022 19:54:26 - INFO - __main__ - ['otoliths']
04/27/2022 19:54:26 - INFO - __main__ -  [sciq] How does alcohol expand over a wide range of temperatures? (A) variably (B) uniformly (C) exponentially (D) erratically [SEP] The red liquid in this thermometer is alcohol. Alcohol expands uniformly over a wide range of temperatures. This makes it ideal for use in thermometers.
04/27/2022 19:54:26 - INFO - __main__ - ['uniformly']
04/27/2022 19:54:26 - INFO - __main__ -  [sciq] Addiction affects what type of chemical receptors within the brain? (A) bind receptors (B) serotonin receptors (C) dopamine receptors (D) mitochondria receptors [SEP] Figure above shows the accumulation of radioactive compounds that bind to dopamine receptors. The non-addicted individuals have large numbers of receptors for dopamine. The addicted persons show less binding to these receptors, indicating that fewer receptors are present.
04/27/2022 19:54:26 - INFO - __main__ - ['dopamine receptors']
04/27/2022 19:54:26 - INFO - __main__ - Tokenizing Input ...
04/27/2022 19:54:26 - INFO - __main__ - Tokenizing Output ...
04/27/2022 19:54:26 - INFO - __main__ - Loaded 32 examples from dev data
04/27/2022 19:54:43 - INFO - __main__ - load prompt embedding from ckpt
04/27/2022 19:54:44 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/27/2022 19:54:44 - INFO - __main__ - Starting training!
04/27/2022 19:54:48 - INFO - __main__ - Step 10 Global step 10 Train loss 2.89 on epoch=4
04/27/2022 19:54:53 - INFO - __main__ - Step 20 Global step 20 Train loss 1.67 on epoch=9
04/27/2022 19:54:57 - INFO - __main__ - Step 30 Global step 30 Train loss 1.20 on epoch=14
04/27/2022 19:55:01 - INFO - __main__ - Step 40 Global step 40 Train loss 0.95 on epoch=19
04/27/2022 19:55:05 - INFO - __main__ - Step 50 Global step 50 Train loss 0.70 on epoch=24
04/27/2022 19:55:07 - INFO - __main__ - Global step 50 Train loss 1.48 ACC 0.28125 on epoch=24
04/27/2022 19:55:07 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.28125 on epoch=24, global_step=50
04/27/2022 19:55:11 - INFO - __main__ - Step 60 Global step 60 Train loss 0.61 on epoch=29
04/27/2022 19:55:15 - INFO - __main__ - Step 70 Global step 70 Train loss 0.58 on epoch=34
04/27/2022 19:55:19 - INFO - __main__ - Step 80 Global step 80 Train loss 0.54 on epoch=39
04/27/2022 19:55:23 - INFO - __main__ - Step 90 Global step 90 Train loss 0.41 on epoch=44
04/27/2022 19:55:27 - INFO - __main__ - Step 100 Global step 100 Train loss 0.38 on epoch=49
04/27/2022 19:55:29 - INFO - __main__ - Global step 100 Train loss 0.50 ACC 0.46875 on epoch=49
04/27/2022 19:55:29 - INFO - __main__ - Saving model with best ACC: 0.28125 -> 0.46875 on epoch=49, global_step=100
04/27/2022 19:55:33 - INFO - __main__ - Step 110 Global step 110 Train loss 0.28 on epoch=54
04/27/2022 19:55:37 - INFO - __main__ - Step 120 Global step 120 Train loss 0.32 on epoch=59
04/27/2022 19:55:41 - INFO - __main__ - Step 130 Global step 130 Train loss 0.26 on epoch=64
04/27/2022 19:55:45 - INFO - __main__ - Step 140 Global step 140 Train loss 0.21 on epoch=69
04/27/2022 19:55:49 - INFO - __main__ - Step 150 Global step 150 Train loss 0.24 on epoch=74
04/27/2022 19:55:51 - INFO - __main__ - Global step 150 Train loss 0.26 ACC 0.5 on epoch=74
04/27/2022 19:55:51 - INFO - __main__ - Saving model with best ACC: 0.46875 -> 0.5 on epoch=74, global_step=150
04/27/2022 19:55:55 - INFO - __main__ - Step 160 Global step 160 Train loss 0.21 on epoch=79
04/27/2022 19:55:59 - INFO - __main__ - Step 170 Global step 170 Train loss 0.19 on epoch=84
04/27/2022 19:56:03 - INFO - __main__ - Step 180 Global step 180 Train loss 0.14 on epoch=89
04/27/2022 19:56:07 - INFO - __main__ - Step 190 Global step 190 Train loss 0.15 on epoch=94
04/27/2022 19:56:11 - INFO - __main__ - Step 200 Global step 200 Train loss 0.15 on epoch=99
04/27/2022 19:56:13 - INFO - __main__ - Global step 200 Train loss 0.17 ACC 0.5625 on epoch=99
04/27/2022 19:56:13 - INFO - __main__ - Saving model with best ACC: 0.5 -> 0.5625 on epoch=99, global_step=200
04/27/2022 19:56:17 - INFO - __main__ - Step 210 Global step 210 Train loss 0.14 on epoch=104
04/27/2022 19:56:21 - INFO - __main__ - Step 220 Global step 220 Train loss 0.12 on epoch=109
04/27/2022 19:56:25 - INFO - __main__ - Step 230 Global step 230 Train loss 0.12 on epoch=114
04/27/2022 19:56:29 - INFO - __main__ - Step 240 Global step 240 Train loss 0.12 on epoch=119
04/27/2022 19:56:34 - INFO - __main__ - Step 250 Global step 250 Train loss 0.10 on epoch=124
04/27/2022 19:56:35 - INFO - __main__ - Global step 250 Train loss 0.12 ACC 0.59375 on epoch=124
04/27/2022 19:56:35 - INFO - __main__ - Saving model with best ACC: 0.5625 -> 0.59375 on epoch=124, global_step=250
04/27/2022 19:56:39 - INFO - __main__ - Step 260 Global step 260 Train loss 0.20 on epoch=129
04/27/2022 19:56:43 - INFO - __main__ - Step 270 Global step 270 Train loss 0.08 on epoch=134
04/27/2022 19:56:48 - INFO - __main__ - Step 280 Global step 280 Train loss 0.09 on epoch=139
04/27/2022 19:56:52 - INFO - __main__ - Step 290 Global step 290 Train loss 0.08 on epoch=144
04/27/2022 19:56:56 - INFO - __main__ - Step 300 Global step 300 Train loss 0.13 on epoch=149
04/27/2022 19:56:57 - INFO - __main__ - Global step 300 Train loss 0.12 ACC 0.65625 on epoch=149
04/27/2022 19:56:57 - INFO - __main__ - Saving model with best ACC: 0.59375 -> 0.65625 on epoch=149, global_step=300
04/27/2022 19:57:01 - INFO - __main__ - Step 310 Global step 310 Train loss 0.07 on epoch=154
04/27/2022 19:57:06 - INFO - __main__ - Step 320 Global step 320 Train loss 0.09 on epoch=159
04/27/2022 19:57:10 - INFO - __main__ - Step 330 Global step 330 Train loss 0.10 on epoch=164
04/27/2022 19:57:14 - INFO - __main__ - Step 340 Global step 340 Train loss 0.08 on epoch=169
04/27/2022 19:57:18 - INFO - __main__ - Step 350 Global step 350 Train loss 0.08 on epoch=174
04/27/2022 19:57:19 - INFO - __main__ - Global step 350 Train loss 0.08 ACC 0.625 on epoch=174
04/27/2022 19:57:24 - INFO - __main__ - Step 360 Global step 360 Train loss 0.07 on epoch=179
04/27/2022 19:57:28 - INFO - __main__ - Step 370 Global step 370 Train loss 0.09 on epoch=184
04/27/2022 19:57:32 - INFO - __main__ - Step 380 Global step 380 Train loss 0.07 on epoch=189
04/27/2022 19:57:36 - INFO - __main__ - Step 390 Global step 390 Train loss 0.05 on epoch=194
04/27/2022 19:57:40 - INFO - __main__ - Step 400 Global step 400 Train loss 0.06 on epoch=199
04/27/2022 19:57:42 - INFO - __main__ - Global step 400 Train loss 0.07 ACC 0.59375 on epoch=199
04/27/2022 19:57:46 - INFO - __main__ - Step 410 Global step 410 Train loss 0.03 on epoch=204
04/27/2022 19:57:50 - INFO - __main__ - Step 420 Global step 420 Train loss 0.06 on epoch=209
04/27/2022 19:57:54 - INFO - __main__ - Step 430 Global step 430 Train loss 0.05 on epoch=214
04/27/2022 19:57:59 - INFO - __main__ - Step 440 Global step 440 Train loss 0.08 on epoch=219
04/27/2022 19:58:03 - INFO - __main__ - Step 450 Global step 450 Train loss 0.05 on epoch=224
04/27/2022 19:58:04 - INFO - __main__ - Global step 450 Train loss 0.06 ACC 0.6875 on epoch=224
04/27/2022 19:58:04 - INFO - __main__ - Saving model with best ACC: 0.65625 -> 0.6875 on epoch=224, global_step=450
04/27/2022 19:58:08 - INFO - __main__ - Step 460 Global step 460 Train loss 0.04 on epoch=229
04/27/2022 19:58:13 - INFO - __main__ - Step 470 Global step 470 Train loss 0.06 on epoch=234
04/27/2022 19:58:17 - INFO - __main__ - Step 480 Global step 480 Train loss 0.05 on epoch=239
04/27/2022 19:58:21 - INFO - __main__ - Step 490 Global step 490 Train loss 0.03 on epoch=244
04/27/2022 19:58:25 - INFO - __main__ - Step 500 Global step 500 Train loss 0.05 on epoch=249
04/27/2022 19:58:27 - INFO - __main__ - Global step 500 Train loss 0.05 ACC 0.6875 on epoch=249
04/27/2022 19:58:31 - INFO - __main__ - Step 510 Global step 510 Train loss 0.04 on epoch=254
04/27/2022 19:58:35 - INFO - __main__ - Step 520 Global step 520 Train loss 0.04 on epoch=259
04/27/2022 19:58:39 - INFO - __main__ - Step 530 Global step 530 Train loss 0.03 on epoch=264
04/27/2022 19:58:43 - INFO - __main__ - Step 540 Global step 540 Train loss 0.07 on epoch=269
04/27/2022 19:58:47 - INFO - __main__ - Step 550 Global step 550 Train loss 0.03 on epoch=274
04/27/2022 19:58:48 - INFO - __main__ - Global step 550 Train loss 0.04 ACC 0.625 on epoch=274
04/27/2022 19:58:52 - INFO - __main__ - Step 560 Global step 560 Train loss 0.03 on epoch=279
04/27/2022 19:58:56 - INFO - __main__ - Step 570 Global step 570 Train loss 0.03 on epoch=284
04/27/2022 19:59:00 - INFO - __main__ - Step 580 Global step 580 Train loss 0.06 on epoch=289
04/27/2022 19:59:05 - INFO - __main__ - Step 590 Global step 590 Train loss 0.03 on epoch=294
04/27/2022 19:59:09 - INFO - __main__ - Step 600 Global step 600 Train loss 0.03 on epoch=299
04/27/2022 19:59:10 - INFO - __main__ - Global step 600 Train loss 0.03 ACC 0.59375 on epoch=299
04/27/2022 19:59:14 - INFO - __main__ - Step 610 Global step 610 Train loss 0.03 on epoch=304
04/27/2022 19:59:18 - INFO - __main__ - Step 620 Global step 620 Train loss 0.04 on epoch=309
04/27/2022 19:59:22 - INFO - __main__ - Step 630 Global step 630 Train loss 0.02 on epoch=314
04/27/2022 19:59:27 - INFO - __main__ - Step 640 Global step 640 Train loss 0.03 on epoch=319
04/27/2022 19:59:31 - INFO - __main__ - Step 650 Global step 650 Train loss 0.05 on epoch=324
04/27/2022 19:59:32 - INFO - __main__ - Global step 650 Train loss 0.03 ACC 0.75 on epoch=324
04/27/2022 19:59:32 - INFO - __main__ - Saving model with best ACC: 0.6875 -> 0.75 on epoch=324, global_step=650
04/27/2022 19:59:36 - INFO - __main__ - Step 660 Global step 660 Train loss 0.04 on epoch=329
04/27/2022 19:59:40 - INFO - __main__ - Step 670 Global step 670 Train loss 0.01 on epoch=334
04/27/2022 19:59:45 - INFO - __main__ - Step 680 Global step 680 Train loss 0.03 on epoch=339
04/27/2022 19:59:49 - INFO - __main__ - Step 690 Global step 690 Train loss 0.03 on epoch=344
04/27/2022 19:59:53 - INFO - __main__ - Step 700 Global step 700 Train loss 0.07 on epoch=349
04/27/2022 19:59:55 - INFO - __main__ - Global step 700 Train loss 0.04 ACC 0.65625 on epoch=349
04/27/2022 19:59:59 - INFO - __main__ - Step 710 Global step 710 Train loss 0.01 on epoch=354
04/27/2022 20:00:03 - INFO - __main__ - Step 720 Global step 720 Train loss 0.02 on epoch=359
04/27/2022 20:00:07 - INFO - __main__ - Step 730 Global step 730 Train loss 0.03 on epoch=364
04/27/2022 20:00:11 - INFO - __main__ - Step 740 Global step 740 Train loss 0.02 on epoch=369
04/27/2022 20:00:15 - INFO - __main__ - Step 750 Global step 750 Train loss 0.05 on epoch=374
04/27/2022 20:00:17 - INFO - __main__ - Global step 750 Train loss 0.03 ACC 0.6875 on epoch=374
04/27/2022 20:00:21 - INFO - __main__ - Step 760 Global step 760 Train loss 0.01 on epoch=379
04/27/2022 20:00:25 - INFO - __main__ - Step 770 Global step 770 Train loss 0.02 on epoch=384
04/27/2022 20:00:29 - INFO - __main__ - Step 780 Global step 780 Train loss 0.02 on epoch=389
04/27/2022 20:00:33 - INFO - __main__ - Step 790 Global step 790 Train loss 0.01 on epoch=394
04/27/2022 20:00:37 - INFO - __main__ - Step 800 Global step 800 Train loss 0.01 on epoch=399
04/27/2022 20:00:39 - INFO - __main__ - Global step 800 Train loss 0.02 ACC 0.6875 on epoch=399
04/27/2022 20:00:43 - INFO - __main__ - Step 810 Global step 810 Train loss 0.01 on epoch=404
04/27/2022 20:00:48 - INFO - __main__ - Step 820 Global step 820 Train loss 0.03 on epoch=409
04/27/2022 20:00:52 - INFO - __main__ - Step 830 Global step 830 Train loss 0.01 on epoch=414
04/27/2022 20:00:56 - INFO - __main__ - Step 840 Global step 840 Train loss 0.02 on epoch=419
04/27/2022 20:01:00 - INFO - __main__ - Step 850 Global step 850 Train loss 0.01 on epoch=424
04/27/2022 20:01:01 - INFO - __main__ - Global step 850 Train loss 0.02 ACC 0.65625 on epoch=424
04/27/2022 20:01:05 - INFO - __main__ - Step 860 Global step 860 Train loss 0.02 on epoch=429
04/27/2022 20:01:10 - INFO - __main__ - Step 870 Global step 870 Train loss 0.01 on epoch=434
04/27/2022 20:01:14 - INFO - __main__ - Step 880 Global step 880 Train loss 0.01 on epoch=439
04/27/2022 20:01:18 - INFO - __main__ - Step 890 Global step 890 Train loss 0.01 on epoch=444
04/27/2022 20:01:22 - INFO - __main__ - Step 900 Global step 900 Train loss 0.01 on epoch=449
04/27/2022 20:01:24 - INFO - __main__ - Global step 900 Train loss 0.01 ACC 0.625 on epoch=449
04/27/2022 20:01:28 - INFO - __main__ - Step 910 Global step 910 Train loss 0.02 on epoch=454
04/27/2022 20:01:32 - INFO - __main__ - Step 920 Global step 920 Train loss 0.01 on epoch=459
04/27/2022 20:01:36 - INFO - __main__ - Step 930 Global step 930 Train loss 0.01 on epoch=464
04/27/2022 20:01:40 - INFO - __main__ - Step 940 Global step 940 Train loss 0.02 on epoch=469
04/27/2022 20:01:44 - INFO - __main__ - Step 950 Global step 950 Train loss 0.01 on epoch=474
04/27/2022 20:01:46 - INFO - __main__ - Global step 950 Train loss 0.01 ACC 0.59375 on epoch=474
04/27/2022 20:01:50 - INFO - __main__ - Step 960 Global step 960 Train loss 0.01 on epoch=479
04/27/2022 20:01:55 - INFO - __main__ - Step 970 Global step 970 Train loss 0.02 on epoch=484
04/27/2022 20:01:59 - INFO - __main__ - Step 980 Global step 980 Train loss 0.01 on epoch=489
04/27/2022 20:02:03 - INFO - __main__ - Step 990 Global step 990 Train loss 0.02 on epoch=494
04/27/2022 20:02:07 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.02 on epoch=499
04/27/2022 20:02:09 - INFO - __main__ - Global step 1000 Train loss 0.01 ACC 0.59375 on epoch=499
04/27/2022 20:02:14 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.02 on epoch=504
04/27/2022 20:02:18 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.01 on epoch=509
04/27/2022 20:02:22 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.03 on epoch=514
04/27/2022 20:02:26 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.01 on epoch=519
04/27/2022 20:02:30 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.02 on epoch=524
04/27/2022 20:02:32 - INFO - __main__ - Global step 1050 Train loss 0.02 ACC 0.6875 on epoch=524
04/27/2022 20:02:36 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.01 on epoch=529
04/27/2022 20:02:40 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.01 on epoch=534
04/27/2022 20:02:44 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.01 on epoch=539
04/27/2022 20:02:48 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.01 on epoch=544
04/27/2022 20:02:52 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.01 on epoch=549
04/27/2022 20:02:54 - INFO - __main__ - Global step 1100 Train loss 0.01 ACC 0.625 on epoch=549
04/27/2022 20:02:59 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.01 on epoch=554
04/27/2022 20:03:03 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=559
04/27/2022 20:03:07 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=564
04/27/2022 20:03:11 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.01 on epoch=569
04/27/2022 20:03:15 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.02 on epoch=574
04/27/2022 20:03:17 - INFO - __main__ - Global step 1150 Train loss 0.01 ACC 0.65625 on epoch=574
04/27/2022 20:03:21 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.01 on epoch=579
04/27/2022 20:03:26 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.01 on epoch=584
04/27/2022 20:03:30 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.01 on epoch=589
04/27/2022 20:03:34 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.01 on epoch=594
04/27/2022 20:03:38 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=599
04/27/2022 20:03:41 - INFO - __main__ - Global step 1200 Train loss 0.01 ACC 0.78125 on epoch=599
04/27/2022 20:03:41 - INFO - __main__ - Saving model with best ACC: 0.75 -> 0.78125 on epoch=599, global_step=1200
04/27/2022 20:03:45 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.02 on epoch=604
04/27/2022 20:03:49 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=609
04/27/2022 20:03:53 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.03 on epoch=614
04/27/2022 20:03:57 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=619
04/27/2022 20:04:01 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.01 on epoch=624
04/27/2022 20:04:03 - INFO - __main__ - Global step 1250 Train loss 0.02 ACC 0.75 on epoch=624
04/27/2022 20:04:07 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=629
04/27/2022 20:04:12 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.01 on epoch=634
04/27/2022 20:04:16 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.00 on epoch=639
04/27/2022 20:04:20 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=644
04/27/2022 20:04:24 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.00 on epoch=649
04/27/2022 20:04:25 - INFO - __main__ - Global step 1300 Train loss 0.01 ACC 0.71875 on epoch=649
04/27/2022 20:04:30 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.00 on epoch=654
04/27/2022 20:04:34 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=659
04/27/2022 20:04:38 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=664
04/27/2022 20:04:42 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=669
04/27/2022 20:04:46 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=674
04/27/2022 20:04:49 - INFO - __main__ - Global step 1350 Train loss 0.01 ACC 0.71875 on epoch=674
04/27/2022 20:04:53 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=679
04/27/2022 20:04:57 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.02 on epoch=684
04/27/2022 20:05:01 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=689
04/27/2022 20:05:05 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=694
04/27/2022 20:05:09 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=699
04/27/2022 20:05:12 - INFO - __main__ - Global step 1400 Train loss 0.01 ACC 0.65625 on epoch=699
04/27/2022 20:05:16 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=704
04/27/2022 20:05:20 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.01 on epoch=709
04/27/2022 20:05:24 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=714
04/27/2022 20:05:28 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=719
04/27/2022 20:05:32 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=724
04/27/2022 20:05:35 - INFO - __main__ - Global step 1450 Train loss 0.01 ACC 0.71875 on epoch=724
04/27/2022 20:05:39 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=729
04/27/2022 20:05:43 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.02 on epoch=734
04/27/2022 20:05:47 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=739
04/27/2022 20:05:51 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=744
04/27/2022 20:05:55 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=749
04/27/2022 20:05:58 - INFO - __main__ - Global step 1500 Train loss 0.01 ACC 0.75 on epoch=749
04/27/2022 20:06:02 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=754
04/27/2022 20:06:06 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=759
04/27/2022 20:06:10 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=764
04/27/2022 20:06:14 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=769
04/27/2022 20:06:18 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=774
04/27/2022 20:06:20 - INFO - __main__ - Global step 1550 Train loss 0.01 ACC 0.6875 on epoch=774
04/27/2022 20:06:24 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=779
04/27/2022 20:06:28 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=784
04/27/2022 20:06:32 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=789
04/27/2022 20:06:36 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=794
04/27/2022 20:06:40 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=799
04/27/2022 20:06:43 - INFO - __main__ - Global step 1600 Train loss 0.01 ACC 0.8125 on epoch=799
04/27/2022 20:06:43 - INFO - __main__ - Saving model with best ACC: 0.78125 -> 0.8125 on epoch=799, global_step=1600
04/27/2022 20:06:47 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=804
04/27/2022 20:06:52 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=809
04/27/2022 20:06:56 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=814
04/27/2022 20:07:00 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=819
04/27/2022 20:07:04 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=824
04/27/2022 20:07:06 - INFO - __main__ - Global step 1650 Train loss 0.01 ACC 0.8125 on epoch=824
04/27/2022 20:07:10 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=829
04/27/2022 20:07:14 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=834
04/27/2022 20:07:18 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=839
04/27/2022 20:07:22 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=844
04/27/2022 20:07:26 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=849
04/27/2022 20:07:28 - INFO - __main__ - Global step 1700 Train loss 0.01 ACC 0.71875 on epoch=849
04/27/2022 20:07:32 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=854
04/27/2022 20:07:36 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=859
04/27/2022 20:07:40 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=864
04/27/2022 20:07:44 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=869
04/27/2022 20:07:48 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=874
04/27/2022 20:07:50 - INFO - __main__ - Global step 1750 Train loss 0.01 ACC 0.71875 on epoch=874
04/27/2022 20:07:54 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=879
04/27/2022 20:07:58 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=884
04/27/2022 20:08:02 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=889
04/27/2022 20:08:06 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=894
04/27/2022 20:08:10 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=899
04/27/2022 20:08:13 - INFO - __main__ - Global step 1800 Train loss 0.01 ACC 0.78125 on epoch=899
04/27/2022 20:08:17 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=904
04/27/2022 20:08:21 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=909
04/27/2022 20:08:25 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=914
04/27/2022 20:08:29 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=919
04/27/2022 20:08:33 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=924
04/27/2022 20:08:34 - INFO - __main__ - Global step 1850 Train loss 0.01 ACC 0.78125 on epoch=924
04/27/2022 20:08:38 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=929
04/27/2022 20:08:42 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=934
04/27/2022 20:08:47 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=939
04/27/2022 20:08:51 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=944
04/27/2022 20:08:55 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=949
04/27/2022 20:08:56 - INFO - __main__ - Global step 1900 Train loss 0.01 ACC 0.75 on epoch=949
04/27/2022 20:09:00 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=954
04/27/2022 20:09:04 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=959
04/27/2022 20:09:08 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=964
04/27/2022 20:09:12 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=969
04/27/2022 20:09:17 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=974
04/27/2022 20:09:18 - INFO - __main__ - Global step 1950 Train loss 0.00 ACC 0.8125 on epoch=974
04/27/2022 20:09:22 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=979
04/27/2022 20:09:26 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=984
04/27/2022 20:09:30 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=989
04/27/2022 20:09:34 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=994
04/27/2022 20:09:38 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=999
04/27/2022 20:09:40 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 20:09:40 - INFO - __main__ - Printing 3 examples
04/27/2022 20:09:40 - INFO - __main__ -  [sciq] A circuit must be what in order for electric devices such as light bulbs to work? (A) closed (B) cyclical (C) down (D) open [SEP] A circuit must be closed for electric devices such as light bulbs to work. The arrows in the diagram show the direction in which electrons flow through the circuit. The current is considered to flow in the opposite direction.
04/27/2022 20:09:40 - INFO - __main__ - ['closed']
04/27/2022 20:09:40 - INFO - __main__ -  [sciq] Deficiency of what is symptomized by nausea, fatigue and dizziness, and can be triggered by excessive sweating? (A) calories (B) electrolytes (C) salts (D) impurities [SEP] An alkaline battery is a variation on the zinc-carbon dry cell. The alkaline battery has no carbon rod and uses a paste of zinc metal and potassium hydroxide instead of a solid metal anode. The cathode half-reaction is the same, but the anode half-reaction is different.
04/27/2022 20:09:40 - INFO - __main__ - ['electrolytes']
04/27/2022 20:09:40 - INFO - __main__ -  [sciq] What organs filter wastes from blood so they can be excreted from the body? (A) liver (B) kidneys (C) lungs (D) pancreas [SEP] Vertebrates have an excretory system that includes a pair of kidneys. Kidneys are organs that filter wastes from blood so they can be excreted from the body.
04/27/2022 20:09:40 - INFO - __main__ - ['kidneys']
04/27/2022 20:09:40 - INFO - __main__ - Tokenizing Input ...
04/27/2022 20:09:40 - INFO - __main__ - Tokenizing Output ...
04/27/2022 20:09:40 - INFO - __main__ - Loaded 32 examples from train data
04/27/2022 20:09:40 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 20:09:40 - INFO - __main__ - Printing 3 examples
04/27/2022 20:09:40 - INFO - __main__ -  [sciq] On top of the otolithic membrane is a layer of calcium carbonate crystals, called what? (A) cones (B) calcites (C) gonads (D) otoliths [SEP] Equilibrium (Balance) Along with audition, the inner ear is responsible for encoding information about equilibrium, the sense of balance. A similar mechanoreceptor—a hair cell with stereocilia—senses head position, head movement, and whether our bodies are in motion. These cells are located within the vestibule of the inner ear. Head position is sensed by the utricle and saccule, whereas head movement is sensed by the semicircular canals. The neural signals generated in the vestibular ganglion are transmitted through the vestibulocochlear nerve to the brain stem and cerebellum. The utricle and saccule are both largely composed of macula tissue (plural = maculae). The macula is composed of hair cells surrounded by support cells. The stereocilia of the hair cells extend into a viscous gel called the otolithic membrane (Figure 14.11). On top of the otolithic membrane is a layer of calcium carbonate crystals, called otoliths. The otoliths essentially make the otolithic membrane top-heavy. The otolithic membrane moves separately from the macula in response to head movements. Tilting the head causes the otolithic membrane to slide over the macula in the direction of gravity. The moving otolithic membrane, in turn, bends the sterocilia, causing some hair cells to depolarize as others hyperpolarize. The exact position of the head is interpreted by the brain based on the pattern of hair-cell depolarization.
04/27/2022 20:09:40 - INFO - __main__ - ['otoliths']
04/27/2022 20:09:40 - INFO - __main__ -  [sciq] How does alcohol expand over a wide range of temperatures? (A) variably (B) uniformly (C) exponentially (D) erratically [SEP] The red liquid in this thermometer is alcohol. Alcohol expands uniformly over a wide range of temperatures. This makes it ideal for use in thermometers.
04/27/2022 20:09:40 - INFO - __main__ - ['uniformly']
04/27/2022 20:09:40 - INFO - __main__ -  [sciq] Addiction affects what type of chemical receptors within the brain? (A) bind receptors (B) serotonin receptors (C) dopamine receptors (D) mitochondria receptors [SEP] Figure above shows the accumulation of radioactive compounds that bind to dopamine receptors. The non-addicted individuals have large numbers of receptors for dopamine. The addicted persons show less binding to these receptors, indicating that fewer receptors are present.
04/27/2022 20:09:40 - INFO - __main__ - ['dopamine receptors']
04/27/2022 20:09:40 - INFO - __main__ - Tokenizing Input ...
04/27/2022 20:09:40 - INFO - __main__ - Tokenizing Output ...
04/27/2022 20:09:40 - INFO - __main__ - Loaded 32 examples from dev data
04/27/2022 20:09:40 - INFO - __main__ - Global step 2000 Train loss 0.00 ACC 0.90625 on epoch=999
04/27/2022 20:09:40 - INFO - __main__ - Saving model with best ACC: 0.8125 -> 0.90625 on epoch=999, global_step=2000
04/27/2022 20:09:40 - INFO - __main__ - save last model!
04/27/2022 20:09:40 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
04/27/2022 20:09:40 - INFO - __main__ - Start tokenizing ... 887 instances
04/27/2022 20:09:40 - INFO - __main__ - Printing 3 examples
04/27/2022 20:09:40 - INFO - __main__ -  [sciq] A frameshift mutation is a deletion or insertion of one or more of what that changes the reading frame of the base sequence? (A) carotenoids (B) nucleotides (C) proteins (D) genes [SEP] A frameshift mutation is a deletion or insertion of one or more nucleotides that changes the reading frame of the base sequence. Deletions remove nucleotides, and insertions add nucleotides. Consider the following sequence of bases in RNA:.
04/27/2022 20:09:40 - INFO - __main__ - ['nucleotides']
04/27/2022 20:09:40 - INFO - __main__ -  [sciq] What is an area of land called that is wet for all or part of the year? (A) grassland (B) wetland (C) plains (D) tundra [SEP] A wetland is an area that is wet for all or part of the year. Wetlands are home to certain types of plants.
04/27/2022 20:09:40 - INFO - __main__ - ['wetland']
04/27/2022 20:09:40 - INFO - __main__ -  [sciq] What are arteries, veins, and capillaries examples of? (A) blood vessels (B) muscles (C) organs (D) tissue [SEP] Blood vessels include arteries, veins, and capillaries.
04/27/2022 20:09:40 - INFO - __main__ - ['blood vessels']
04/27/2022 20:09:40 - INFO - __main__ - Tokenizing Input ...
04/27/2022 20:09:41 - INFO - __main__ - Tokenizing Output ...
04/27/2022 20:09:42 - INFO - __main__ - Loaded 887 examples from test data
04/27/2022 20:09:59 - INFO - __main__ - load prompt embedding from ckpt
04/27/2022 20:09:59 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/27/2022 20:09:59 - INFO - __main__ - Starting training!
04/27/2022 20:10:27 - INFO - __main__ - Saved prediction in models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-sciq/sciq_32_42_0.3_8_predictions.txt
04/27/2022 20:10:27 - INFO - __main__ - ACC on test data: 0.8072
04/27/2022 20:10:28 - INFO - __main__ - prefix=sciq_32_42, lr=0.3, bsz=8, dev_performance=0.90625, test_performance=0.8072153325817362
04/27/2022 20:10:28 - INFO - __main__ - Running ... prefix=sciq_32_42, lr=0.2, bsz=8 ...
04/27/2022 20:10:29 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 20:10:29 - INFO - __main__ - Printing 3 examples
04/27/2022 20:10:29 - INFO - __main__ -  [sciq] A circuit must be what in order for electric devices such as light bulbs to work? (A) closed (B) cyclical (C) down (D) open [SEP] A circuit must be closed for electric devices such as light bulbs to work. The arrows in the diagram show the direction in which electrons flow through the circuit. The current is considered to flow in the opposite direction.
04/27/2022 20:10:29 - INFO - __main__ - ['closed']
04/27/2022 20:10:29 - INFO - __main__ -  [sciq] Deficiency of what is symptomized by nausea, fatigue and dizziness, and can be triggered by excessive sweating? (A) calories (B) electrolytes (C) salts (D) impurities [SEP] An alkaline battery is a variation on the zinc-carbon dry cell. The alkaline battery has no carbon rod and uses a paste of zinc metal and potassium hydroxide instead of a solid metal anode. The cathode half-reaction is the same, but the anode half-reaction is different.
04/27/2022 20:10:29 - INFO - __main__ - ['electrolytes']
04/27/2022 20:10:29 - INFO - __main__ -  [sciq] What organs filter wastes from blood so they can be excreted from the body? (A) liver (B) kidneys (C) lungs (D) pancreas [SEP] Vertebrates have an excretory system that includes a pair of kidneys. Kidneys are organs that filter wastes from blood so they can be excreted from the body.
04/27/2022 20:10:29 - INFO - __main__ - ['kidneys']
04/27/2022 20:10:29 - INFO - __main__ - Tokenizing Input ...
04/27/2022 20:10:29 - INFO - __main__ - Tokenizing Output ...
04/27/2022 20:10:29 - INFO - __main__ - Loaded 32 examples from train data
04/27/2022 20:10:29 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 20:10:29 - INFO - __main__ - Printing 3 examples
04/27/2022 20:10:29 - INFO - __main__ -  [sciq] On top of the otolithic membrane is a layer of calcium carbonate crystals, called what? (A) cones (B) calcites (C) gonads (D) otoliths [SEP] Equilibrium (Balance) Along with audition, the inner ear is responsible for encoding information about equilibrium, the sense of balance. A similar mechanoreceptor—a hair cell with stereocilia—senses head position, head movement, and whether our bodies are in motion. These cells are located within the vestibule of the inner ear. Head position is sensed by the utricle and saccule, whereas head movement is sensed by the semicircular canals. The neural signals generated in the vestibular ganglion are transmitted through the vestibulocochlear nerve to the brain stem and cerebellum. The utricle and saccule are both largely composed of macula tissue (plural = maculae). The macula is composed of hair cells surrounded by support cells. The stereocilia of the hair cells extend into a viscous gel called the otolithic membrane (Figure 14.11). On top of the otolithic membrane is a layer of calcium carbonate crystals, called otoliths. The otoliths essentially make the otolithic membrane top-heavy. The otolithic membrane moves separately from the macula in response to head movements. Tilting the head causes the otolithic membrane to slide over the macula in the direction of gravity. The moving otolithic membrane, in turn, bends the sterocilia, causing some hair cells to depolarize as others hyperpolarize. The exact position of the head is interpreted by the brain based on the pattern of hair-cell depolarization.
04/27/2022 20:10:29 - INFO - __main__ - ['otoliths']
04/27/2022 20:10:29 - INFO - __main__ -  [sciq] How does alcohol expand over a wide range of temperatures? (A) variably (B) uniformly (C) exponentially (D) erratically [SEP] The red liquid in this thermometer is alcohol. Alcohol expands uniformly over a wide range of temperatures. This makes it ideal for use in thermometers.
04/27/2022 20:10:29 - INFO - __main__ - ['uniformly']
04/27/2022 20:10:29 - INFO - __main__ -  [sciq] Addiction affects what type of chemical receptors within the brain? (A) bind receptors (B) serotonin receptors (C) dopamine receptors (D) mitochondria receptors [SEP] Figure above shows the accumulation of radioactive compounds that bind to dopamine receptors. The non-addicted individuals have large numbers of receptors for dopamine. The addicted persons show less binding to these receptors, indicating that fewer receptors are present.
04/27/2022 20:10:29 - INFO - __main__ - ['dopamine receptors']
04/27/2022 20:10:29 - INFO - __main__ - Tokenizing Input ...
04/27/2022 20:10:29 - INFO - __main__ - Tokenizing Output ...
04/27/2022 20:10:29 - INFO - __main__ - Loaded 32 examples from dev data
04/27/2022 20:10:46 - INFO - __main__ - load prompt embedding from ckpt
04/27/2022 20:10:47 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/27/2022 20:10:47 - INFO - __main__ - Starting training!
04/27/2022 20:10:54 - INFO - __main__ - Step 10 Global step 10 Train loss 3.08 on epoch=4
04/27/2022 20:10:58 - INFO - __main__ - Step 20 Global step 20 Train loss 2.34 on epoch=9
04/27/2022 20:11:02 - INFO - __main__ - Step 30 Global step 30 Train loss 1.49 on epoch=14
04/27/2022 20:11:06 - INFO - __main__ - Step 40 Global step 40 Train loss 1.13 on epoch=19
04/27/2022 20:11:10 - INFO - __main__ - Step 50 Global step 50 Train loss 0.93 on epoch=24
04/27/2022 20:11:12 - INFO - __main__ - Global step 50 Train loss 1.80 ACC 0.34375 on epoch=24
04/27/2022 20:11:12 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.34375 on epoch=24, global_step=50
04/27/2022 20:11:16 - INFO - __main__ - Step 60 Global step 60 Train loss 0.81 on epoch=29
04/27/2022 20:11:20 - INFO - __main__ - Step 70 Global step 70 Train loss 0.69 on epoch=34
04/27/2022 20:11:24 - INFO - __main__ - Step 80 Global step 80 Train loss 0.48 on epoch=39
04/27/2022 20:11:28 - INFO - __main__ - Step 90 Global step 90 Train loss 0.52 on epoch=44
04/27/2022 20:11:32 - INFO - __main__ - Step 100 Global step 100 Train loss 0.53 on epoch=49
04/27/2022 20:11:34 - INFO - __main__ - Global step 100 Train loss 0.61 ACC 0.53125 on epoch=49
04/27/2022 20:11:34 - INFO - __main__ - Saving model with best ACC: 0.34375 -> 0.53125 on epoch=49, global_step=100
04/27/2022 20:11:38 - INFO - __main__ - Step 110 Global step 110 Train loss 0.48 on epoch=54
04/27/2022 20:11:42 - INFO - __main__ - Step 120 Global step 120 Train loss 0.50 on epoch=59
04/27/2022 20:11:46 - INFO - __main__ - Step 130 Global step 130 Train loss 0.35 on epoch=64
04/27/2022 20:11:50 - INFO - __main__ - Step 140 Global step 140 Train loss 0.34 on epoch=69
04/27/2022 20:11:55 - INFO - __main__ - Step 150 Global step 150 Train loss 0.29 on epoch=74
04/27/2022 20:11:56 - INFO - __main__ - Global step 150 Train loss 0.39 ACC 0.5 on epoch=74
04/27/2022 20:12:00 - INFO - __main__ - Step 160 Global step 160 Train loss 0.27 on epoch=79
04/27/2022 20:12:04 - INFO - __main__ - Step 170 Global step 170 Train loss 0.31 on epoch=84
04/27/2022 20:12:08 - INFO - __main__ - Step 180 Global step 180 Train loss 0.24 on epoch=89
04/27/2022 20:12:13 - INFO - __main__ - Step 190 Global step 190 Train loss 0.32 on epoch=94
04/27/2022 20:12:17 - INFO - __main__ - Step 200 Global step 200 Train loss 0.22 on epoch=99
04/27/2022 20:12:18 - INFO - __main__ - Global step 200 Train loss 0.27 ACC 0.5625 on epoch=99
04/27/2022 20:12:18 - INFO - __main__ - Saving model with best ACC: 0.53125 -> 0.5625 on epoch=99, global_step=200
04/27/2022 20:12:22 - INFO - __main__ - Step 210 Global step 210 Train loss 0.22 on epoch=104
04/27/2022 20:12:26 - INFO - __main__ - Step 220 Global step 220 Train loss 0.25 on epoch=109
04/27/2022 20:12:31 - INFO - __main__ - Step 230 Global step 230 Train loss 0.23 on epoch=114
04/27/2022 20:12:35 - INFO - __main__ - Step 240 Global step 240 Train loss 0.16 on epoch=119
04/27/2022 20:12:39 - INFO - __main__ - Step 250 Global step 250 Train loss 0.15 on epoch=124
04/27/2022 20:12:40 - INFO - __main__ - Global step 250 Train loss 0.20 ACC 0.625 on epoch=124
04/27/2022 20:12:40 - INFO - __main__ - Saving model with best ACC: 0.5625 -> 0.625 on epoch=124, global_step=250
04/27/2022 20:12:44 - INFO - __main__ - Step 260 Global step 260 Train loss 0.13 on epoch=129
04/27/2022 20:12:49 - INFO - __main__ - Step 270 Global step 270 Train loss 0.21 on epoch=134
04/27/2022 20:12:53 - INFO - __main__ - Step 280 Global step 280 Train loss 0.19 on epoch=139
04/27/2022 20:12:57 - INFO - __main__ - Step 290 Global step 290 Train loss 0.13 on epoch=144
04/27/2022 20:13:01 - INFO - __main__ - Step 300 Global step 300 Train loss 0.10 on epoch=149
04/27/2022 20:13:02 - INFO - __main__ - Global step 300 Train loss 0.15 ACC 0.59375 on epoch=149
04/27/2022 20:13:06 - INFO - __main__ - Step 310 Global step 310 Train loss 0.15 on epoch=154
04/27/2022 20:13:11 - INFO - __main__ - Step 320 Global step 320 Train loss 0.11 on epoch=159
04/27/2022 20:13:15 - INFO - __main__ - Step 330 Global step 330 Train loss 0.13 on epoch=164
04/27/2022 20:13:19 - INFO - __main__ - Step 340 Global step 340 Train loss 0.08 on epoch=169
04/27/2022 20:13:23 - INFO - __main__ - Step 350 Global step 350 Train loss 0.14 on epoch=174
04/27/2022 20:13:24 - INFO - __main__ - Global step 350 Train loss 0.12 ACC 0.5625 on epoch=174
04/27/2022 20:13:28 - INFO - __main__ - Step 360 Global step 360 Train loss 0.10 on epoch=179
04/27/2022 20:13:33 - INFO - __main__ - Step 370 Global step 370 Train loss 0.10 on epoch=184
04/27/2022 20:13:37 - INFO - __main__ - Step 380 Global step 380 Train loss 0.11 on epoch=189
04/27/2022 20:13:41 - INFO - __main__ - Step 390 Global step 390 Train loss 0.08 on epoch=194
04/27/2022 20:13:45 - INFO - __main__ - Step 400 Global step 400 Train loss 0.12 on epoch=199
04/27/2022 20:13:46 - INFO - __main__ - Global step 400 Train loss 0.10 ACC 0.65625 on epoch=199
04/27/2022 20:13:46 - INFO - __main__ - Saving model with best ACC: 0.625 -> 0.65625 on epoch=199, global_step=400
04/27/2022 20:13:51 - INFO - __main__ - Step 410 Global step 410 Train loss 0.10 on epoch=204
04/27/2022 20:13:55 - INFO - __main__ - Step 420 Global step 420 Train loss 0.07 on epoch=209
04/27/2022 20:13:59 - INFO - __main__ - Step 430 Global step 430 Train loss 0.08 on epoch=214
04/27/2022 20:14:03 - INFO - __main__ - Step 440 Global step 440 Train loss 0.07 on epoch=219
04/27/2022 20:14:07 - INFO - __main__ - Step 450 Global step 450 Train loss 0.05 on epoch=224
04/27/2022 20:14:09 - INFO - __main__ - Global step 450 Train loss 0.07 ACC 0.65625 on epoch=224
04/27/2022 20:14:13 - INFO - __main__ - Step 460 Global step 460 Train loss 0.04 on epoch=229
04/27/2022 20:14:17 - INFO - __main__ - Step 470 Global step 470 Train loss 0.08 on epoch=234
04/27/2022 20:14:21 - INFO - __main__ - Step 480 Global step 480 Train loss 0.07 on epoch=239
04/27/2022 20:14:25 - INFO - __main__ - Step 490 Global step 490 Train loss 0.09 on epoch=244
04/27/2022 20:14:29 - INFO - __main__ - Step 500 Global step 500 Train loss 0.09 on epoch=249
04/27/2022 20:14:31 - INFO - __main__ - Global step 500 Train loss 0.07 ACC 0.625 on epoch=249
04/27/2022 20:14:35 - INFO - __main__ - Step 510 Global step 510 Train loss 0.09 on epoch=254
04/27/2022 20:14:40 - INFO - __main__ - Step 520 Global step 520 Train loss 0.06 on epoch=259
04/27/2022 20:14:44 - INFO - __main__ - Step 530 Global step 530 Train loss 0.05 on epoch=264
04/27/2022 20:14:48 - INFO - __main__ - Step 540 Global step 540 Train loss 0.05 on epoch=269
04/27/2022 20:14:52 - INFO - __main__ - Step 550 Global step 550 Train loss 0.05 on epoch=274
04/27/2022 20:14:53 - INFO - __main__ - Global step 550 Train loss 0.06 ACC 0.6875 on epoch=274
04/27/2022 20:14:53 - INFO - __main__ - Saving model with best ACC: 0.65625 -> 0.6875 on epoch=274, global_step=550
04/27/2022 20:14:57 - INFO - __main__ - Step 560 Global step 560 Train loss 0.04 on epoch=279
04/27/2022 20:15:02 - INFO - __main__ - Step 570 Global step 570 Train loss 0.05 on epoch=284
04/27/2022 20:15:06 - INFO - __main__ - Step 580 Global step 580 Train loss 0.04 on epoch=289
04/27/2022 20:15:10 - INFO - __main__ - Step 590 Global step 590 Train loss 0.05 on epoch=294
04/27/2022 20:15:14 - INFO - __main__ - Step 600 Global step 600 Train loss 0.03 on epoch=299
04/27/2022 20:15:16 - INFO - __main__ - Global step 600 Train loss 0.04 ACC 0.71875 on epoch=299
04/27/2022 20:15:16 - INFO - __main__ - Saving model with best ACC: 0.6875 -> 0.71875 on epoch=299, global_step=600
04/27/2022 20:15:20 - INFO - __main__ - Step 610 Global step 610 Train loss 0.04 on epoch=304
04/27/2022 20:15:24 - INFO - __main__ - Step 620 Global step 620 Train loss 0.05 on epoch=309
04/27/2022 20:15:28 - INFO - __main__ - Step 630 Global step 630 Train loss 0.09 on epoch=314
04/27/2022 20:15:32 - INFO - __main__ - Step 640 Global step 640 Train loss 0.05 on epoch=319
04/27/2022 20:15:36 - INFO - __main__ - Step 650 Global step 650 Train loss 0.04 on epoch=324
04/27/2022 20:15:38 - INFO - __main__ - Global step 650 Train loss 0.05 ACC 0.625 on epoch=324
04/27/2022 20:15:42 - INFO - __main__ - Step 660 Global step 660 Train loss 0.03 on epoch=329
04/27/2022 20:15:46 - INFO - __main__ - Step 670 Global step 670 Train loss 0.02 on epoch=334
04/27/2022 20:15:50 - INFO - __main__ - Step 680 Global step 680 Train loss 0.02 on epoch=339
04/27/2022 20:15:54 - INFO - __main__ - Step 690 Global step 690 Train loss 0.08 on epoch=344
04/27/2022 20:15:58 - INFO - __main__ - Step 700 Global step 700 Train loss 0.07 on epoch=349
04/27/2022 20:16:00 - INFO - __main__ - Global step 700 Train loss 0.05 ACC 0.6875 on epoch=349
04/27/2022 20:16:05 - INFO - __main__ - Step 710 Global step 710 Train loss 0.03 on epoch=354
04/27/2022 20:16:09 - INFO - __main__ - Step 720 Global step 720 Train loss 0.03 on epoch=359
04/27/2022 20:16:13 - INFO - __main__ - Step 730 Global step 730 Train loss 0.04 on epoch=364
04/27/2022 20:16:17 - INFO - __main__ - Step 740 Global step 740 Train loss 0.06 on epoch=369
04/27/2022 20:16:21 - INFO - __main__ - Step 750 Global step 750 Train loss 0.03 on epoch=374
04/27/2022 20:16:23 - INFO - __main__ - Global step 750 Train loss 0.04 ACC 0.6875 on epoch=374
04/27/2022 20:16:27 - INFO - __main__ - Step 760 Global step 760 Train loss 0.03 on epoch=379
04/27/2022 20:16:31 - INFO - __main__ - Step 770 Global step 770 Train loss 0.04 on epoch=384
04/27/2022 20:16:35 - INFO - __main__ - Step 780 Global step 780 Train loss 0.02 on epoch=389
04/27/2022 20:16:39 - INFO - __main__ - Step 790 Global step 790 Train loss 0.02 on epoch=394
04/27/2022 20:16:43 - INFO - __main__ - Step 800 Global step 800 Train loss 0.03 on epoch=399
04/27/2022 20:16:46 - INFO - __main__ - Global step 800 Train loss 0.03 ACC 0.6875 on epoch=399
04/27/2022 20:16:50 - INFO - __main__ - Step 810 Global step 810 Train loss 0.03 on epoch=404
04/27/2022 20:16:54 - INFO - __main__ - Step 820 Global step 820 Train loss 0.02 on epoch=409
04/27/2022 20:16:58 - INFO - __main__ - Step 830 Global step 830 Train loss 0.03 on epoch=414
04/27/2022 20:17:02 - INFO - __main__ - Step 840 Global step 840 Train loss 0.02 on epoch=419
04/27/2022 20:17:06 - INFO - __main__ - Step 850 Global step 850 Train loss 0.02 on epoch=424
04/27/2022 20:17:08 - INFO - __main__ - Global step 850 Train loss 0.03 ACC 0.59375 on epoch=424
04/27/2022 20:17:12 - INFO - __main__ - Step 860 Global step 860 Train loss 0.03 on epoch=429
04/27/2022 20:17:16 - INFO - __main__ - Step 870 Global step 870 Train loss 0.02 on epoch=434
04/27/2022 20:17:20 - INFO - __main__ - Step 880 Global step 880 Train loss 0.04 on epoch=439
04/27/2022 20:17:24 - INFO - __main__ - Step 890 Global step 890 Train loss 0.02 on epoch=444
04/27/2022 20:17:28 - INFO - __main__ - Step 900 Global step 900 Train loss 0.02 on epoch=449
04/27/2022 20:17:30 - INFO - __main__ - Global step 900 Train loss 0.03 ACC 0.59375 on epoch=449
04/27/2022 20:17:34 - INFO - __main__ - Step 910 Global step 910 Train loss 0.01 on epoch=454
04/27/2022 20:17:38 - INFO - __main__ - Step 920 Global step 920 Train loss 0.02 on epoch=459
04/27/2022 20:17:42 - INFO - __main__ - Step 930 Global step 930 Train loss 0.03 on epoch=464
04/27/2022 20:17:46 - INFO - __main__ - Step 940 Global step 940 Train loss 0.01 on epoch=469
04/27/2022 20:17:50 - INFO - __main__ - Step 950 Global step 950 Train loss 0.03 on epoch=474
04/27/2022 20:17:52 - INFO - __main__ - Global step 950 Train loss 0.02 ACC 0.71875 on epoch=474
04/27/2022 20:17:56 - INFO - __main__ - Step 960 Global step 960 Train loss 0.02 on epoch=479
04/27/2022 20:18:00 - INFO - __main__ - Step 970 Global step 970 Train loss 0.04 on epoch=484
04/27/2022 20:18:04 - INFO - __main__ - Step 980 Global step 980 Train loss 0.03 on epoch=489
04/27/2022 20:18:08 - INFO - __main__ - Step 990 Global step 990 Train loss 0.02 on epoch=494
04/27/2022 20:18:12 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.01 on epoch=499
04/27/2022 20:18:14 - INFO - __main__ - Global step 1000 Train loss 0.02 ACC 0.71875 on epoch=499
04/27/2022 20:18:18 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.02 on epoch=504
04/27/2022 20:18:22 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.03 on epoch=509
04/27/2022 20:18:26 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.01 on epoch=514
04/27/2022 20:18:30 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.01 on epoch=519
04/27/2022 20:18:34 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.02 on epoch=524
04/27/2022 20:18:35 - INFO - __main__ - Global step 1050 Train loss 0.02 ACC 0.625 on epoch=524
04/27/2022 20:18:40 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.03 on epoch=529
04/27/2022 20:18:44 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.05 on epoch=534
04/27/2022 20:18:48 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.01 on epoch=539
04/27/2022 20:18:52 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.01 on epoch=544
04/27/2022 20:18:56 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.01 on epoch=549
04/27/2022 20:18:58 - INFO - __main__ - Global step 1100 Train loss 0.02 ACC 0.71875 on epoch=549
04/27/2022 20:19:02 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.05 on epoch=554
04/27/2022 20:19:06 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=559
04/27/2022 20:19:10 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=564
04/27/2022 20:19:14 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.02 on epoch=569
04/27/2022 20:19:18 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=574
04/27/2022 20:19:19 - INFO - __main__ - Global step 1150 Train loss 0.02 ACC 0.6875 on epoch=574
04/27/2022 20:19:23 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.01 on epoch=579
04/27/2022 20:19:27 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.02 on epoch=584
04/27/2022 20:19:31 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.04 on epoch=589
04/27/2022 20:19:35 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.01 on epoch=594
04/27/2022 20:19:39 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=599
04/27/2022 20:19:41 - INFO - __main__ - Global step 1200 Train loss 0.02 ACC 0.65625 on epoch=599
04/27/2022 20:19:45 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.02 on epoch=604
04/27/2022 20:19:49 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=609
04/27/2022 20:19:54 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=614
04/27/2022 20:19:58 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=619
04/27/2022 20:20:02 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.01 on epoch=624
04/27/2022 20:20:03 - INFO - __main__ - Global step 1250 Train loss 0.01 ACC 0.6875 on epoch=624
04/27/2022 20:20:07 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=629
04/27/2022 20:20:11 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.01 on epoch=634
04/27/2022 20:20:16 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.05 on epoch=639
04/27/2022 20:20:20 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.00 on epoch=644
04/27/2022 20:20:24 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.05 on epoch=649
04/27/2022 20:20:25 - INFO - __main__ - Global step 1300 Train loss 0.02 ACC 0.6875 on epoch=649
04/27/2022 20:20:29 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=654
04/27/2022 20:20:33 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=659
04/27/2022 20:20:37 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=664
04/27/2022 20:20:41 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.02 on epoch=669
04/27/2022 20:20:45 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.02 on epoch=674
04/27/2022 20:20:47 - INFO - __main__ - Global step 1350 Train loss 0.01 ACC 0.71875 on epoch=674
04/27/2022 20:20:51 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=679
04/27/2022 20:20:55 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=684
04/27/2022 20:20:59 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=689
04/27/2022 20:21:03 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.02 on epoch=694
04/27/2022 20:21:07 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=699
04/27/2022 20:21:09 - INFO - __main__ - Global step 1400 Train loss 0.01 ACC 0.75 on epoch=699
04/27/2022 20:21:09 - INFO - __main__ - Saving model with best ACC: 0.71875 -> 0.75 on epoch=699, global_step=1400
04/27/2022 20:21:13 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=704
04/27/2022 20:21:17 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.01 on epoch=709
04/27/2022 20:21:21 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.02 on epoch=714
04/27/2022 20:21:25 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.03 on epoch=719
04/27/2022 20:21:29 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=724
04/27/2022 20:21:31 - INFO - __main__ - Global step 1450 Train loss 0.01 ACC 0.71875 on epoch=724
04/27/2022 20:21:35 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=729
04/27/2022 20:21:39 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=734
04/27/2022 20:21:43 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=739
04/27/2022 20:21:47 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=744
04/27/2022 20:21:51 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=749
04/27/2022 20:21:52 - INFO - __main__ - Global step 1500 Train loss 0.01 ACC 0.6875 on epoch=749
04/27/2022 20:21:56 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=754
04/27/2022 20:22:00 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.04 on epoch=759
04/27/2022 20:22:04 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=764
04/27/2022 20:22:08 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=769
04/27/2022 20:22:12 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=774
04/27/2022 20:22:15 - INFO - __main__ - Global step 1550 Train loss 0.01 ACC 0.6875 on epoch=774
04/27/2022 20:22:19 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=779
04/27/2022 20:22:23 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=784
04/27/2022 20:22:27 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.03 on epoch=789
04/27/2022 20:22:31 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.03 on epoch=794
04/27/2022 20:22:35 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=799
04/27/2022 20:22:38 - INFO - __main__ - Global step 1600 Train loss 0.02 ACC 0.71875 on epoch=799
04/27/2022 20:22:42 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=804
04/27/2022 20:22:46 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=809
04/27/2022 20:22:50 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=814
04/27/2022 20:22:54 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=819
04/27/2022 20:22:58 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=824
04/27/2022 20:23:01 - INFO - __main__ - Global step 1650 Train loss 0.01 ACC 0.65625 on epoch=824
04/27/2022 20:23:05 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=829
04/27/2022 20:23:09 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=834
04/27/2022 20:23:13 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=839
04/27/2022 20:23:17 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.02 on epoch=844
04/27/2022 20:23:21 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=849
04/27/2022 20:23:23 - INFO - __main__ - Global step 1700 Train loss 0.01 ACC 0.71875 on epoch=849
04/27/2022 20:23:27 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=854
04/27/2022 20:23:31 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.02 on epoch=859
04/27/2022 20:23:35 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=864
04/27/2022 20:23:39 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=869
04/27/2022 20:23:43 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=874
04/27/2022 20:23:45 - INFO - __main__ - Global step 1750 Train loss 0.01 ACC 0.71875 on epoch=874
04/27/2022 20:23:49 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=879
04/27/2022 20:23:53 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=884
04/27/2022 20:23:57 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=889
04/27/2022 20:24:01 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=894
04/27/2022 20:24:05 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=899
04/27/2022 20:24:07 - INFO - __main__ - Global step 1800 Train loss 0.01 ACC 0.8125 on epoch=899
04/27/2022 20:24:08 - INFO - __main__ - Saving model with best ACC: 0.75 -> 0.8125 on epoch=899, global_step=1800
04/27/2022 20:24:12 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=904
04/27/2022 20:24:16 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=909
04/27/2022 20:24:20 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=914
04/27/2022 20:24:24 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=919
04/27/2022 20:24:28 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=924
04/27/2022 20:24:29 - INFO - __main__ - Global step 1850 Train loss 0.01 ACC 0.71875 on epoch=924
04/27/2022 20:24:33 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=929
04/27/2022 20:24:37 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=934
04/27/2022 20:24:41 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=939
04/27/2022 20:24:46 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=944
04/27/2022 20:24:50 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=949
04/27/2022 20:24:51 - INFO - __main__ - Global step 1900 Train loss 0.01 ACC 0.6875 on epoch=949
04/27/2022 20:24:55 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=954
04/27/2022 20:24:59 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=959
04/27/2022 20:25:03 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=964
04/27/2022 20:25:07 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=969
04/27/2022 20:25:11 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=974
04/27/2022 20:25:13 - INFO - __main__ - Global step 1950 Train loss 0.01 ACC 0.78125 on epoch=974
04/27/2022 20:25:17 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=979
04/27/2022 20:25:21 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=984
04/27/2022 20:25:25 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=989
04/27/2022 20:25:29 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=994
04/27/2022 20:25:33 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=999
04/27/2022 20:25:34 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 20:25:34 - INFO - __main__ - Printing 3 examples
04/27/2022 20:25:34 - INFO - __main__ -  [sciq] What distant and extraordinarily energetic objects now seem to be early stages of galactic evolution with a supermassive black-hole-devouring material? (A) stars (B) neutrinos (C) quasars (D) pulsars [SEP] the history of galactic evolution has been, and the nature of space in their vicinity. However, so many black holes are now known that correlations between black hole mass and galactic nuclei characteristics are being studied. What is the mechanism for the energy output of quasars? These distant and extraordinarily energetic objects now seem to be early stages of galactic evolution with a supermassive black-hole-devouring material. Connections are now being made with galaxies having energetic cores, and there is evidence consistent with less consuming, supermassive black holes at the center of older galaxies. New instruments are allowing us to see deeper into our own galaxy for evidence of our own massive black hole.
04/27/2022 20:25:34 - INFO - __main__ - ['quasars']
04/27/2022 20:25:34 - INFO - __main__ -  [sciq] Alpha particles, beta particles, and gamma particles are major types of what? (A) radioactivity (B) microscopy (C) sound waves (D) visible light [SEP] The major types of radioactivity include alpha particles, beta particles, and gamma rays.
04/27/2022 20:25:34 - INFO - __main__ - ['radioactivity']
04/27/2022 20:25:34 - INFO - __main__ -  [sciq] The average number of individuals per unit of area can be expressed as what? (A) the percent of population (B) percent density (C) population density (D) total density [SEP] Population density just gives the average number of individuals per unit of area or volume. Often, individuals in a population are not spread out evenly. Instead, they may live in clumps or some other pattern (see Figure below ). The pattern may reflect characteristics of the species or its environment. Population distribution describes how the individuals are distributed, or spread throughout their habitat.
04/27/2022 20:25:34 - INFO - __main__ - ['population density']
04/27/2022 20:25:34 - INFO - __main__ - Tokenizing Input ...
04/27/2022 20:25:34 - INFO - __main__ - Tokenizing Output ...
04/27/2022 20:25:34 - INFO - __main__ - Loaded 32 examples from train data
04/27/2022 20:25:34 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 20:25:34 - INFO - __main__ - Printing 3 examples
04/27/2022 20:25:34 - INFO - __main__ -  [sciq] Why can't fungi make their own food like plants do? (A) no hydrogen (B) no chloroplasts (C) no organelles (D) no cells [SEP] Fungi cannot make their own food like plants can, since they do not have chloroplasts and cannot carry out photosynthesis. Fungi are more like animals because they are heterotrophs, as opposed to autotrophs, like plants, that make their own food. Fungi have to obtain their food, nutrients and glucose, from outside sources.
04/27/2022 20:25:34 - INFO - __main__ - ['no chloroplasts']
04/27/2022 20:25:34 - INFO - __main__ -  [sciq] In what kind of bond does one atom contribute both of the electrons in the shared pair? (A) a covalent bond (B) a metallic bond (C) an ionic bond (D) a valence bond [SEP] The carbon monoxide molecule is correctly represented by a triple covalent bond between the carbon and oxygen atoms. One of the bonds is a coordinate covalent bond , a covalent bond in which one of the atoms contributes both of the electrons in the shared pair.
04/27/2022 20:25:34 - INFO - __main__ - ['a covalent bond']
04/27/2022 20:25:34 - INFO - __main__ -  [sciq] The modern atomic theory states that all matter is composed of what? (A) ions (B) quarks (C) atoms (D) molecules [SEP] The modern atomic theory states that all matter is composed of atoms.
04/27/2022 20:25:34 - INFO - __main__ - ['atoms']
04/27/2022 20:25:34 - INFO - __main__ - Tokenizing Input ...
04/27/2022 20:25:34 - INFO - __main__ - Tokenizing Output ...
04/27/2022 20:25:34 - INFO - __main__ - Loaded 32 examples from dev data
04/27/2022 20:25:34 - INFO - __main__ - Global step 2000 Train loss 0.00 ACC 0.75 on epoch=999
04/27/2022 20:25:35 - INFO - __main__ - save last model!
04/27/2022 20:25:35 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
04/27/2022 20:25:35 - INFO - __main__ - Start tokenizing ... 887 instances
04/27/2022 20:25:35 - INFO - __main__ - Printing 3 examples
04/27/2022 20:25:35 - INFO - __main__ -  [sciq] A frameshift mutation is a deletion or insertion of one or more of what that changes the reading frame of the base sequence? (A) carotenoids (B) nucleotides (C) proteins (D) genes [SEP] A frameshift mutation is a deletion or insertion of one or more nucleotides that changes the reading frame of the base sequence. Deletions remove nucleotides, and insertions add nucleotides. Consider the following sequence of bases in RNA:.
04/27/2022 20:25:35 - INFO - __main__ - ['nucleotides']
04/27/2022 20:25:35 - INFO - __main__ -  [sciq] What is an area of land called that is wet for all or part of the year? (A) grassland (B) wetland (C) plains (D) tundra [SEP] A wetland is an area that is wet for all or part of the year. Wetlands are home to certain types of plants.
04/27/2022 20:25:35 - INFO - __main__ - ['wetland']
04/27/2022 20:25:35 - INFO - __main__ -  [sciq] What are arteries, veins, and capillaries examples of? (A) blood vessels (B) muscles (C) organs (D) tissue [SEP] Blood vessels include arteries, veins, and capillaries.
04/27/2022 20:25:35 - INFO - __main__ - ['blood vessels']
04/27/2022 20:25:35 - INFO - __main__ - Tokenizing Input ...
04/27/2022 20:25:35 - INFO - __main__ - Tokenizing Output ...
04/27/2022 20:25:36 - INFO - __main__ - Loaded 887 examples from test data
04/27/2022 20:25:53 - INFO - __main__ - load prompt embedding from ckpt
04/27/2022 20:25:54 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/27/2022 20:25:54 - INFO - __main__ - Starting training!
04/27/2022 20:26:26 - INFO - __main__ - Saved prediction in models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-sciq/sciq_32_42_0.2_8_predictions.txt
04/27/2022 20:26:26 - INFO - __main__ - ACC on test data: 0.7531
04/27/2022 20:26:26 - INFO - __main__ - prefix=sciq_32_42, lr=0.2, bsz=8, dev_performance=0.8125, test_performance=0.7531003382187148
04/27/2022 20:26:26 - INFO - __main__ - Running ... prefix=sciq_32_87, lr=0.5, bsz=8 ...
04/27/2022 20:26:27 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 20:26:27 - INFO - __main__ - Printing 3 examples
04/27/2022 20:26:27 - INFO - __main__ -  [sciq] What distant and extraordinarily energetic objects now seem to be early stages of galactic evolution with a supermassive black-hole-devouring material? (A) stars (B) neutrinos (C) quasars (D) pulsars [SEP] the history of galactic evolution has been, and the nature of space in their vicinity. However, so many black holes are now known that correlations between black hole mass and galactic nuclei characteristics are being studied. What is the mechanism for the energy output of quasars? These distant and extraordinarily energetic objects now seem to be early stages of galactic evolution with a supermassive black-hole-devouring material. Connections are now being made with galaxies having energetic cores, and there is evidence consistent with less consuming, supermassive black holes at the center of older galaxies. New instruments are allowing us to see deeper into our own galaxy for evidence of our own massive black hole.
04/27/2022 20:26:27 - INFO - __main__ - ['quasars']
04/27/2022 20:26:27 - INFO - __main__ -  [sciq] Alpha particles, beta particles, and gamma particles are major types of what? (A) radioactivity (B) microscopy (C) sound waves (D) visible light [SEP] The major types of radioactivity include alpha particles, beta particles, and gamma rays.
04/27/2022 20:26:27 - INFO - __main__ - ['radioactivity']
04/27/2022 20:26:27 - INFO - __main__ -  [sciq] The average number of individuals per unit of area can be expressed as what? (A) the percent of population (B) percent density (C) population density (D) total density [SEP] Population density just gives the average number of individuals per unit of area or volume. Often, individuals in a population are not spread out evenly. Instead, they may live in clumps or some other pattern (see Figure below ). The pattern may reflect characteristics of the species or its environment. Population distribution describes how the individuals are distributed, or spread throughout their habitat.
04/27/2022 20:26:27 - INFO - __main__ - ['population density']
04/27/2022 20:26:27 - INFO - __main__ - Tokenizing Input ...
04/27/2022 20:26:27 - INFO - __main__ - Tokenizing Output ...
04/27/2022 20:26:27 - INFO - __main__ - Loaded 32 examples from train data
04/27/2022 20:26:27 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 20:26:27 - INFO - __main__ - Printing 3 examples
04/27/2022 20:26:27 - INFO - __main__ -  [sciq] Why can't fungi make their own food like plants do? (A) no hydrogen (B) no chloroplasts (C) no organelles (D) no cells [SEP] Fungi cannot make their own food like plants can, since they do not have chloroplasts and cannot carry out photosynthesis. Fungi are more like animals because they are heterotrophs, as opposed to autotrophs, like plants, that make their own food. Fungi have to obtain their food, nutrients and glucose, from outside sources.
04/27/2022 20:26:27 - INFO - __main__ - ['no chloroplasts']
04/27/2022 20:26:27 - INFO - __main__ -  [sciq] In what kind of bond does one atom contribute both of the electrons in the shared pair? (A) a covalent bond (B) a metallic bond (C) an ionic bond (D) a valence bond [SEP] The carbon monoxide molecule is correctly represented by a triple covalent bond between the carbon and oxygen atoms. One of the bonds is a coordinate covalent bond , a covalent bond in which one of the atoms contributes both of the electrons in the shared pair.
04/27/2022 20:26:27 - INFO - __main__ - ['a covalent bond']
04/27/2022 20:26:27 - INFO - __main__ -  [sciq] The modern atomic theory states that all matter is composed of what? (A) ions (B) quarks (C) atoms (D) molecules [SEP] The modern atomic theory states that all matter is composed of atoms.
04/27/2022 20:26:27 - INFO - __main__ - ['atoms']
04/27/2022 20:26:27 - INFO - __main__ - Tokenizing Input ...
04/27/2022 20:26:27 - INFO - __main__ - Tokenizing Output ...
04/27/2022 20:26:27 - INFO - __main__ - Loaded 32 examples from dev data
04/27/2022 20:26:44 - INFO - __main__ - load prompt embedding from ckpt
04/27/2022 20:26:45 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/27/2022 20:26:45 - INFO - __main__ - Starting training!
04/27/2022 20:26:53 - INFO - __main__ - Step 10 Global step 10 Train loss 2.11 on epoch=4
04/27/2022 20:26:57 - INFO - __main__ - Step 20 Global step 20 Train loss 0.96 on epoch=9
04/27/2022 20:27:01 - INFO - __main__ - Step 30 Global step 30 Train loss 0.61 on epoch=14
04/27/2022 20:27:05 - INFO - __main__ - Step 40 Global step 40 Train loss 0.50 on epoch=19
04/27/2022 20:27:09 - INFO - __main__ - Step 50 Global step 50 Train loss 0.43 on epoch=24
04/27/2022 20:27:10 - INFO - __main__ - Global step 50 Train loss 0.92 ACC 0.4375 on epoch=24
04/27/2022 20:27:10 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.4375 on epoch=24, global_step=50
04/27/2022 20:27:14 - INFO - __main__ - Step 60 Global step 60 Train loss 0.36 on epoch=29
04/27/2022 20:27:18 - INFO - __main__ - Step 70 Global step 70 Train loss 0.26 on epoch=34
04/27/2022 20:27:22 - INFO - __main__ - Step 80 Global step 80 Train loss 0.28 on epoch=39
04/27/2022 20:27:26 - INFO - __main__ - Step 90 Global step 90 Train loss 0.29 on epoch=44
04/27/2022 20:27:30 - INFO - __main__ - Step 100 Global step 100 Train loss 0.23 on epoch=49
04/27/2022 20:27:32 - INFO - __main__ - Global step 100 Train loss 0.29 ACC 0.65625 on epoch=49
04/27/2022 20:27:32 - INFO - __main__ - Saving model with best ACC: 0.4375 -> 0.65625 on epoch=49, global_step=100
04/27/2022 20:27:36 - INFO - __main__ - Step 110 Global step 110 Train loss 0.11 on epoch=54
04/27/2022 20:27:40 - INFO - __main__ - Step 120 Global step 120 Train loss 0.17 on epoch=59
04/27/2022 20:27:44 - INFO - __main__ - Step 130 Global step 130 Train loss 0.10 on epoch=64
04/27/2022 20:27:48 - INFO - __main__ - Step 140 Global step 140 Train loss 0.16 on epoch=69
04/27/2022 20:27:52 - INFO - __main__ - Step 150 Global step 150 Train loss 0.09 on epoch=74
04/27/2022 20:27:53 - INFO - __main__ - Global step 150 Train loss 0.13 ACC 0.78125 on epoch=74
04/27/2022 20:27:53 - INFO - __main__ - Saving model with best ACC: 0.65625 -> 0.78125 on epoch=74, global_step=150
04/27/2022 20:27:58 - INFO - __main__ - Step 160 Global step 160 Train loss 0.11 on epoch=79
04/27/2022 20:28:02 - INFO - __main__ - Step 170 Global step 170 Train loss 0.09 on epoch=84
04/27/2022 20:28:06 - INFO - __main__ - Step 180 Global step 180 Train loss 0.06 on epoch=89
04/27/2022 20:28:10 - INFO - __main__ - Step 190 Global step 190 Train loss 0.05 on epoch=94
04/27/2022 20:28:14 - INFO - __main__ - Step 200 Global step 200 Train loss 0.10 on epoch=99
04/27/2022 20:28:15 - INFO - __main__ - Global step 200 Train loss 0.08 ACC 0.78125 on epoch=99
04/27/2022 20:28:19 - INFO - __main__ - Step 210 Global step 210 Train loss 0.11 on epoch=104
04/27/2022 20:28:23 - INFO - __main__ - Step 220 Global step 220 Train loss 0.04 on epoch=109
04/27/2022 20:28:27 - INFO - __main__ - Step 230 Global step 230 Train loss 0.04 on epoch=114
04/27/2022 20:28:31 - INFO - __main__ - Step 240 Global step 240 Train loss 0.06 on epoch=119
04/27/2022 20:28:36 - INFO - __main__ - Step 250 Global step 250 Train loss 0.05 on epoch=124
04/27/2022 20:28:37 - INFO - __main__ - Global step 250 Train loss 0.06 ACC 0.71875 on epoch=124
04/27/2022 20:28:41 - INFO - __main__ - Step 260 Global step 260 Train loss 0.03 on epoch=129
04/27/2022 20:28:45 - INFO - __main__ - Step 270 Global step 270 Train loss 0.03 on epoch=134
04/27/2022 20:28:49 - INFO - __main__ - Step 280 Global step 280 Train loss 0.05 on epoch=139
04/27/2022 20:28:53 - INFO - __main__ - Step 290 Global step 290 Train loss 0.05 on epoch=144
04/27/2022 20:28:57 - INFO - __main__ - Step 300 Global step 300 Train loss 0.03 on epoch=149
04/27/2022 20:28:59 - INFO - __main__ - Global step 300 Train loss 0.04 ACC 0.6875 on epoch=149
04/27/2022 20:29:03 - INFO - __main__ - Step 310 Global step 310 Train loss 0.02 on epoch=154
04/27/2022 20:29:07 - INFO - __main__ - Step 320 Global step 320 Train loss 0.04 on epoch=159
04/27/2022 20:29:11 - INFO - __main__ - Step 330 Global step 330 Train loss 0.02 on epoch=164
04/27/2022 20:29:15 - INFO - __main__ - Step 340 Global step 340 Train loss 0.03 on epoch=169
04/27/2022 20:29:19 - INFO - __main__ - Step 350 Global step 350 Train loss 0.02 on epoch=174
04/27/2022 20:29:21 - INFO - __main__ - Global step 350 Train loss 0.03 ACC 0.875 on epoch=174
04/27/2022 20:29:21 - INFO - __main__ - Saving model with best ACC: 0.78125 -> 0.875 on epoch=174, global_step=350
04/27/2022 20:29:25 - INFO - __main__ - Step 360 Global step 360 Train loss 0.03 on epoch=179
04/27/2022 20:29:29 - INFO - __main__ - Step 370 Global step 370 Train loss 0.03 on epoch=184
04/27/2022 20:29:33 - INFO - __main__ - Step 380 Global step 380 Train loss 0.05 on epoch=189
04/27/2022 20:29:37 - INFO - __main__ - Step 390 Global step 390 Train loss 0.04 on epoch=194
04/27/2022 20:29:41 - INFO - __main__ - Step 400 Global step 400 Train loss 0.05 on epoch=199
04/27/2022 20:29:42 - INFO - __main__ - Global step 400 Train loss 0.04 ACC 0.78125 on epoch=199
04/27/2022 20:29:46 - INFO - __main__ - Step 410 Global step 410 Train loss 0.06 on epoch=204
04/27/2022 20:29:51 - INFO - __main__ - Step 420 Global step 420 Train loss 0.03 on epoch=209
04/27/2022 20:29:55 - INFO - __main__ - Step 430 Global step 430 Train loss 0.04 on epoch=214
04/27/2022 20:29:59 - INFO - __main__ - Step 440 Global step 440 Train loss 0.01 on epoch=219
04/27/2022 20:30:03 - INFO - __main__ - Step 450 Global step 450 Train loss 0.02 on epoch=224
04/27/2022 20:30:04 - INFO - __main__ - Global step 450 Train loss 0.03 ACC 0.84375 on epoch=224
04/27/2022 20:30:08 - INFO - __main__ - Step 460 Global step 460 Train loss 0.03 on epoch=229
04/27/2022 20:30:12 - INFO - __main__ - Step 470 Global step 470 Train loss 0.10 on epoch=234
04/27/2022 20:30:16 - INFO - __main__ - Step 480 Global step 480 Train loss 0.08 on epoch=239
04/27/2022 20:30:20 - INFO - __main__ - Step 490 Global step 490 Train loss 0.01 on epoch=244
04/27/2022 20:30:25 - INFO - __main__ - Step 500 Global step 500 Train loss 0.01 on epoch=249
04/27/2022 20:30:26 - INFO - __main__ - Global step 500 Train loss 0.05 ACC 0.78125 on epoch=249
04/27/2022 20:30:30 - INFO - __main__ - Step 510 Global step 510 Train loss 0.02 on epoch=254
04/27/2022 20:30:34 - INFO - __main__ - Step 520 Global step 520 Train loss 0.02 on epoch=259
04/27/2022 20:30:38 - INFO - __main__ - Step 530 Global step 530 Train loss 0.01 on epoch=264
04/27/2022 20:30:42 - INFO - __main__ - Step 540 Global step 540 Train loss 0.04 on epoch=269
04/27/2022 20:30:46 - INFO - __main__ - Step 550 Global step 550 Train loss 0.19 on epoch=274
04/27/2022 20:30:48 - INFO - __main__ - Global step 550 Train loss 0.06 ACC 0.875 on epoch=274
04/27/2022 20:30:52 - INFO - __main__ - Step 560 Global step 560 Train loss 0.02 on epoch=279
04/27/2022 20:30:56 - INFO - __main__ - Step 570 Global step 570 Train loss 0.00 on epoch=284
04/27/2022 20:31:00 - INFO - __main__ - Step 580 Global step 580 Train loss 0.03 on epoch=289
04/27/2022 20:31:04 - INFO - __main__ - Step 590 Global step 590 Train loss 0.01 on epoch=294
04/27/2022 20:31:08 - INFO - __main__ - Step 600 Global step 600 Train loss 0.01 on epoch=299
04/27/2022 20:31:09 - INFO - __main__ - Global step 600 Train loss 0.02 ACC 0.78125 on epoch=299
04/27/2022 20:31:13 - INFO - __main__ - Step 610 Global step 610 Train loss 0.01 on epoch=304
04/27/2022 20:31:17 - INFO - __main__ - Step 620 Global step 620 Train loss 0.01 on epoch=309
04/27/2022 20:31:21 - INFO - __main__ - Step 630 Global step 630 Train loss 0.01 on epoch=314
04/27/2022 20:31:25 - INFO - __main__ - Step 640 Global step 640 Train loss 0.03 on epoch=319
04/27/2022 20:31:29 - INFO - __main__ - Step 650 Global step 650 Train loss 0.02 on epoch=324
04/27/2022 20:31:31 - INFO - __main__ - Global step 650 Train loss 0.01 ACC 0.8125 on epoch=324
04/27/2022 20:31:35 - INFO - __main__ - Step 660 Global step 660 Train loss 0.01 on epoch=329
04/27/2022 20:31:39 - INFO - __main__ - Step 670 Global step 670 Train loss 0.01 on epoch=334
04/27/2022 20:31:43 - INFO - __main__ - Step 680 Global step 680 Train loss 0.02 on epoch=339
04/27/2022 20:31:47 - INFO - __main__ - Step 690 Global step 690 Train loss 0.01 on epoch=344
04/27/2022 20:31:51 - INFO - __main__ - Step 700 Global step 700 Train loss 0.00 on epoch=349
04/27/2022 20:31:52 - INFO - __main__ - Global step 700 Train loss 0.01 ACC 0.90625 on epoch=349
04/27/2022 20:31:52 - INFO - __main__ - Saving model with best ACC: 0.875 -> 0.90625 on epoch=349, global_step=700
04/27/2022 20:31:56 - INFO - __main__ - Step 710 Global step 710 Train loss 0.01 on epoch=354
04/27/2022 20:32:00 - INFO - __main__ - Step 720 Global step 720 Train loss 0.02 on epoch=359
04/27/2022 20:32:04 - INFO - __main__ - Step 730 Global step 730 Train loss 0.01 on epoch=364
04/27/2022 20:32:08 - INFO - __main__ - Step 740 Global step 740 Train loss 0.00 on epoch=369
04/27/2022 20:32:12 - INFO - __main__ - Step 750 Global step 750 Train loss 0.01 on epoch=374
04/27/2022 20:32:14 - INFO - __main__ - Global step 750 Train loss 0.01 ACC 0.78125 on epoch=374
04/27/2022 20:32:18 - INFO - __main__ - Step 760 Global step 760 Train loss 0.01 on epoch=379
04/27/2022 20:32:22 - INFO - __main__ - Step 770 Global step 770 Train loss 0.03 on epoch=384
04/27/2022 20:32:26 - INFO - __main__ - Step 780 Global step 780 Train loss 0.00 on epoch=389
04/27/2022 20:32:30 - INFO - __main__ - Step 790 Global step 790 Train loss 0.00 on epoch=394
04/27/2022 20:32:34 - INFO - __main__ - Step 800 Global step 800 Train loss 0.01 on epoch=399
04/27/2022 20:32:35 - INFO - __main__ - Global step 800 Train loss 0.01 ACC 0.84375 on epoch=399
04/27/2022 20:32:39 - INFO - __main__ - Step 810 Global step 810 Train loss 0.01 on epoch=404
04/27/2022 20:32:43 - INFO - __main__ - Step 820 Global step 820 Train loss 0.00 on epoch=409
04/27/2022 20:32:47 - INFO - __main__ - Step 830 Global step 830 Train loss 0.00 on epoch=414
04/27/2022 20:32:51 - INFO - __main__ - Step 840 Global step 840 Train loss 0.00 on epoch=419
04/27/2022 20:32:56 - INFO - __main__ - Step 850 Global step 850 Train loss 0.01 on epoch=424
04/27/2022 20:32:57 - INFO - __main__ - Global step 850 Train loss 0.01 ACC 0.84375 on epoch=424
04/27/2022 20:33:01 - INFO - __main__ - Step 860 Global step 860 Train loss 0.01 on epoch=429
04/27/2022 20:33:05 - INFO - __main__ - Step 870 Global step 870 Train loss 0.01 on epoch=434
04/27/2022 20:33:09 - INFO - __main__ - Step 880 Global step 880 Train loss 0.01 on epoch=439
04/27/2022 20:33:13 - INFO - __main__ - Step 890 Global step 890 Train loss 0.01 on epoch=444
04/27/2022 20:33:17 - INFO - __main__ - Step 900 Global step 900 Train loss 0.03 on epoch=449
04/27/2022 20:33:19 - INFO - __main__ - Global step 900 Train loss 0.01 ACC 0.90625 on epoch=449
04/27/2022 20:33:23 - INFO - __main__ - Step 910 Global step 910 Train loss 0.00 on epoch=454
04/27/2022 20:33:27 - INFO - __main__ - Step 920 Global step 920 Train loss 0.00 on epoch=459
04/27/2022 20:33:31 - INFO - __main__ - Step 930 Global step 930 Train loss 0.05 on epoch=464
04/27/2022 20:33:35 - INFO - __main__ - Step 940 Global step 940 Train loss 0.01 on epoch=469
04/27/2022 20:33:39 - INFO - __main__ - Step 950 Global step 950 Train loss 0.00 on epoch=474
04/27/2022 20:33:40 - INFO - __main__ - Global step 950 Train loss 0.01 ACC 0.875 on epoch=474
04/27/2022 20:33:44 - INFO - __main__ - Step 960 Global step 960 Train loss 0.01 on epoch=479
04/27/2022 20:33:48 - INFO - __main__ - Step 970 Global step 970 Train loss 0.02 on epoch=484
04/27/2022 20:33:53 - INFO - __main__ - Step 980 Global step 980 Train loss 0.00 on epoch=489
04/27/2022 20:33:57 - INFO - __main__ - Step 990 Global step 990 Train loss 0.00 on epoch=494
04/27/2022 20:34:01 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.02 on epoch=499
04/27/2022 20:34:02 - INFO - __main__ - Global step 1000 Train loss 0.01 ACC 0.875 on epoch=499
04/27/2022 20:34:06 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.03 on epoch=504
04/27/2022 20:34:10 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.01 on epoch=509
04/27/2022 20:34:14 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.01 on epoch=514
04/27/2022 20:34:18 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.01 on epoch=519
04/27/2022 20:34:22 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.01 on epoch=524
04/27/2022 20:34:24 - INFO - __main__ - Global step 1050 Train loss 0.01 ACC 0.84375 on epoch=524
04/27/2022 20:34:28 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.02 on epoch=529
04/27/2022 20:34:32 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.03 on epoch=534
04/27/2022 20:34:36 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.01 on epoch=539
04/27/2022 20:34:40 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.00 on epoch=544
04/27/2022 20:34:44 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.00 on epoch=549
04/27/2022 20:34:45 - INFO - __main__ - Global step 1100 Train loss 0.01 ACC 0.875 on epoch=549
04/27/2022 20:34:49 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.01 on epoch=554
04/27/2022 20:34:53 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.00 on epoch=559
04/27/2022 20:34:57 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=564
04/27/2022 20:35:01 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.01 on epoch=569
04/27/2022 20:35:05 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=574
04/27/2022 20:35:07 - INFO - __main__ - Global step 1150 Train loss 0.01 ACC 0.84375 on epoch=574
04/27/2022 20:35:11 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.01 on epoch=579
04/27/2022 20:35:15 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.00 on epoch=584
04/27/2022 20:35:19 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.01 on epoch=589
04/27/2022 20:35:23 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.00 on epoch=594
04/27/2022 20:35:27 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.00 on epoch=599
04/27/2022 20:35:28 - INFO - __main__ - Global step 1200 Train loss 0.00 ACC 0.90625 on epoch=599
04/27/2022 20:35:32 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.00 on epoch=604
04/27/2022 20:35:36 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.02 on epoch=609
04/27/2022 20:35:40 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.00 on epoch=614
04/27/2022 20:35:44 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.00 on epoch=619
04/27/2022 20:35:48 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.01 on epoch=624
04/27/2022 20:35:50 - INFO - __main__ - Global step 1250 Train loss 0.01 ACC 0.84375 on epoch=624
04/27/2022 20:35:54 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.25 on epoch=629
04/27/2022 20:35:58 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.00 on epoch=634
04/27/2022 20:36:02 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.18 on epoch=639
04/27/2022 20:36:06 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.10 on epoch=644
04/27/2022 20:36:10 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.00 on epoch=649
04/27/2022 20:36:11 - INFO - __main__ - Global step 1300 Train loss 0.11 ACC 0.8125 on epoch=649
04/27/2022 20:36:15 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.00 on epoch=654
04/27/2022 20:36:19 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.00 on epoch=659
04/27/2022 20:36:23 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=664
04/27/2022 20:36:27 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=669
04/27/2022 20:36:31 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.04 on epoch=674
04/27/2022 20:36:33 - INFO - __main__ - Global step 1350 Train loss 0.01 ACC 0.8125 on epoch=674
04/27/2022 20:36:37 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.00 on epoch=679
04/27/2022 20:36:41 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.00 on epoch=684
04/27/2022 20:36:45 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.00 on epoch=689
04/27/2022 20:36:49 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.00 on epoch=694
04/27/2022 20:36:53 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.00 on epoch=699
04/27/2022 20:36:54 - INFO - __main__ - Global step 1400 Train loss 0.00 ACC 0.78125 on epoch=699
04/27/2022 20:36:58 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=704
04/27/2022 20:37:02 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=709
04/27/2022 20:37:06 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.00 on epoch=714
04/27/2022 20:37:10 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=719
04/27/2022 20:37:14 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=724
04/27/2022 20:37:16 - INFO - __main__ - Global step 1450 Train loss 0.00 ACC 0.8125 on epoch=724
04/27/2022 20:37:20 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=729
04/27/2022 20:37:24 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=734
04/27/2022 20:37:28 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=739
04/27/2022 20:37:32 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=744
04/27/2022 20:37:36 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=749
04/27/2022 20:37:37 - INFO - __main__ - Global step 1500 Train loss 0.01 ACC 0.8125 on epoch=749
04/27/2022 20:37:42 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=754
04/27/2022 20:37:46 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=759
04/27/2022 20:37:50 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=764
04/27/2022 20:37:54 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=769
04/27/2022 20:37:58 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=774
04/27/2022 20:37:59 - INFO - __main__ - Global step 1550 Train loss 0.01 ACC 0.875 on epoch=774
04/27/2022 20:38:03 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=779
04/27/2022 20:38:07 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=784
04/27/2022 20:38:11 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=789
04/27/2022 20:38:15 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=794
04/27/2022 20:38:19 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=799
04/27/2022 20:38:20 - INFO - __main__ - Global step 1600 Train loss 0.00 ACC 0.84375 on epoch=799
04/27/2022 20:38:24 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=804
04/27/2022 20:38:28 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=809
04/27/2022 20:38:32 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=814
04/27/2022 20:38:36 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=819
04/27/2022 20:38:40 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=824
04/27/2022 20:38:42 - INFO - __main__ - Global step 1650 Train loss 0.00 ACC 0.8125 on epoch=824
04/27/2022 20:38:46 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=829
04/27/2022 20:38:50 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.03 on epoch=834
04/27/2022 20:38:54 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=839
04/27/2022 20:38:58 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=844
04/27/2022 20:39:02 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=849
04/27/2022 20:39:03 - INFO - __main__ - Global step 1700 Train loss 0.01 ACC 0.875 on epoch=849
04/27/2022 20:39:07 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=854
04/27/2022 20:39:11 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=859
04/27/2022 20:39:15 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=864
04/27/2022 20:39:19 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=869
04/27/2022 20:39:23 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=874
04/27/2022 20:39:26 - INFO - __main__ - Global step 1750 Train loss 0.00 ACC 0.90625 on epoch=874
04/27/2022 20:39:30 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=879
04/27/2022 20:39:34 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=884
04/27/2022 20:39:38 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=889
04/27/2022 20:39:42 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=894
04/27/2022 20:39:46 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=899
04/27/2022 20:39:47 - INFO - __main__ - Global step 1800 Train loss 0.00 ACC 0.875 on epoch=899
04/27/2022 20:39:51 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=904
04/27/2022 20:39:55 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=909
04/27/2022 20:39:59 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=914
04/27/2022 20:40:03 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=919
04/27/2022 20:40:07 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=924
04/27/2022 20:40:09 - INFO - __main__ - Global step 1850 Train loss 0.00 ACC 0.8125 on epoch=924
04/27/2022 20:40:13 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=929
04/27/2022 20:40:17 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=934
04/27/2022 20:40:21 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=939
04/27/2022 20:40:25 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=944
04/27/2022 20:40:29 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=949
04/27/2022 20:40:30 - INFO - __main__ - Global step 1900 Train loss 0.01 ACC 0.90625 on epoch=949
04/27/2022 20:40:34 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=954
04/27/2022 20:40:38 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=959
04/27/2022 20:40:42 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=964
04/27/2022 20:40:46 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=969
04/27/2022 20:40:50 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=974
04/27/2022 20:40:51 - INFO - __main__ - Global step 1950 Train loss 0.00 ACC 0.875 on epoch=974
04/27/2022 20:40:55 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=979
04/27/2022 20:40:59 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=984
04/27/2022 20:41:03 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=989
04/27/2022 20:41:07 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=994
04/27/2022 20:41:11 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=999
04/27/2022 20:41:13 - INFO - __main__ - Global step 2000 Train loss 0.00 ACC 0.875 on epoch=999
04/27/2022 20:41:13 - INFO - __main__ - save last model!
04/27/2022 20:41:13 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
04/27/2022 20:41:13 - INFO - __main__ - Start tokenizing ... 887 instances
04/27/2022 20:41:13 - INFO - __main__ - Printing 3 examples
04/27/2022 20:41:13 - INFO - __main__ -  [sciq] A frameshift mutation is a deletion or insertion of one or more of what that changes the reading frame of the base sequence? (A) carotenoids (B) nucleotides (C) proteins (D) genes [SEP] A frameshift mutation is a deletion or insertion of one or more nucleotides that changes the reading frame of the base sequence. Deletions remove nucleotides, and insertions add nucleotides. Consider the following sequence of bases in RNA:.
04/27/2022 20:41:13 - INFO - __main__ - ['nucleotides']
04/27/2022 20:41:13 - INFO - __main__ -  [sciq] What is an area of land called that is wet for all or part of the year? (A) grassland (B) wetland (C) plains (D) tundra [SEP] A wetland is an area that is wet for all or part of the year. Wetlands are home to certain types of plants.
04/27/2022 20:41:13 - INFO - __main__ - ['wetland']
04/27/2022 20:41:13 - INFO - __main__ -  [sciq] What are arteries, veins, and capillaries examples of? (A) blood vessels (B) muscles (C) organs (D) tissue [SEP] Blood vessels include arteries, veins, and capillaries.
04/27/2022 20:41:13 - INFO - __main__ - ['blood vessels']
04/27/2022 20:41:13 - INFO - __main__ - Tokenizing Input ...
04/27/2022 20:41:13 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 20:41:13 - INFO - __main__ - Printing 3 examples
04/27/2022 20:41:13 - INFO - __main__ -  [sciq] What distant and extraordinarily energetic objects now seem to be early stages of galactic evolution with a supermassive black-hole-devouring material? (A) stars (B) neutrinos (C) quasars (D) pulsars [SEP] the history of galactic evolution has been, and the nature of space in their vicinity. However, so many black holes are now known that correlations between black hole mass and galactic nuclei characteristics are being studied. What is the mechanism for the energy output of quasars? These distant and extraordinarily energetic objects now seem to be early stages of galactic evolution with a supermassive black-hole-devouring material. Connections are now being made with galaxies having energetic cores, and there is evidence consistent with less consuming, supermassive black holes at the center of older galaxies. New instruments are allowing us to see deeper into our own galaxy for evidence of our own massive black hole.
04/27/2022 20:41:13 - INFO - __main__ - ['quasars']
04/27/2022 20:41:13 - INFO - __main__ -  [sciq] Alpha particles, beta particles, and gamma particles are major types of what? (A) radioactivity (B) microscopy (C) sound waves (D) visible light [SEP] The major types of radioactivity include alpha particles, beta particles, and gamma rays.
04/27/2022 20:41:13 - INFO - __main__ - ['radioactivity']
04/27/2022 20:41:13 - INFO - __main__ -  [sciq] The average number of individuals per unit of area can be expressed as what? (A) the percent of population (B) percent density (C) population density (D) total density [SEP] Population density just gives the average number of individuals per unit of area or volume. Often, individuals in a population are not spread out evenly. Instead, they may live in clumps or some other pattern (see Figure below ). The pattern may reflect characteristics of the species or its environment. Population distribution describes how the individuals are distributed, or spread throughout their habitat.
04/27/2022 20:41:13 - INFO - __main__ - ['population density']
04/27/2022 20:41:13 - INFO - __main__ - Tokenizing Input ...
04/27/2022 20:41:13 - INFO - __main__ - Tokenizing Output ...
04/27/2022 20:41:13 - INFO - __main__ - Loaded 32 examples from train data
04/27/2022 20:41:13 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 20:41:13 - INFO - __main__ - Printing 3 examples
04/27/2022 20:41:13 - INFO - __main__ -  [sciq] Why can't fungi make their own food like plants do? (A) no hydrogen (B) no chloroplasts (C) no organelles (D) no cells [SEP] Fungi cannot make their own food like plants can, since they do not have chloroplasts and cannot carry out photosynthesis. Fungi are more like animals because they are heterotrophs, as opposed to autotrophs, like plants, that make their own food. Fungi have to obtain their food, nutrients and glucose, from outside sources.
04/27/2022 20:41:13 - INFO - __main__ - ['no chloroplasts']
04/27/2022 20:41:13 - INFO - __main__ -  [sciq] In what kind of bond does one atom contribute both of the electrons in the shared pair? (A) a covalent bond (B) a metallic bond (C) an ionic bond (D) a valence bond [SEP] The carbon monoxide molecule is correctly represented by a triple covalent bond between the carbon and oxygen atoms. One of the bonds is a coordinate covalent bond , a covalent bond in which one of the atoms contributes both of the electrons in the shared pair.
04/27/2022 20:41:13 - INFO - __main__ - ['a covalent bond']
04/27/2022 20:41:13 - INFO - __main__ -  [sciq] The modern atomic theory states that all matter is composed of what? (A) ions (B) quarks (C) atoms (D) molecules [SEP] The modern atomic theory states that all matter is composed of atoms.
04/27/2022 20:41:13 - INFO - __main__ - ['atoms']
04/27/2022 20:41:13 - INFO - __main__ - Tokenizing Input ...
04/27/2022 20:41:13 - INFO - __main__ - Tokenizing Output ...
04/27/2022 20:41:13 - INFO - __main__ - Loaded 32 examples from dev data
04/27/2022 20:41:13 - INFO - __main__ - Tokenizing Output ...
04/27/2022 20:41:14 - INFO - __main__ - Loaded 887 examples from test data
04/27/2022 20:41:32 - INFO - __main__ - load prompt embedding from ckpt
04/27/2022 20:41:33 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/27/2022 20:41:33 - INFO - __main__ - Starting training!
04/27/2022 20:42:00 - INFO - __main__ - Saved prediction in models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-sciq/sciq_32_87_0.5_8_predictions.txt
04/27/2022 20:42:00 - INFO - __main__ - ACC on test data: 0.8658
04/27/2022 20:42:00 - INFO - __main__ - prefix=sciq_32_87, lr=0.5, bsz=8, dev_performance=0.90625, test_performance=0.8658399098083427
04/27/2022 20:42:00 - INFO - __main__ - Running ... prefix=sciq_32_87, lr=0.4, bsz=8 ...
04/27/2022 20:42:01 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 20:42:01 - INFO - __main__ - Printing 3 examples
04/27/2022 20:42:01 - INFO - __main__ -  [sciq] What distant and extraordinarily energetic objects now seem to be early stages of galactic evolution with a supermassive black-hole-devouring material? (A) stars (B) neutrinos (C) quasars (D) pulsars [SEP] the history of galactic evolution has been, and the nature of space in their vicinity. However, so many black holes are now known that correlations between black hole mass and galactic nuclei characteristics are being studied. What is the mechanism for the energy output of quasars? These distant and extraordinarily energetic objects now seem to be early stages of galactic evolution with a supermassive black-hole-devouring material. Connections are now being made with galaxies having energetic cores, and there is evidence consistent with less consuming, supermassive black holes at the center of older galaxies. New instruments are allowing us to see deeper into our own galaxy for evidence of our own massive black hole.
04/27/2022 20:42:01 - INFO - __main__ - ['quasars']
04/27/2022 20:42:01 - INFO - __main__ -  [sciq] Alpha particles, beta particles, and gamma particles are major types of what? (A) radioactivity (B) microscopy (C) sound waves (D) visible light [SEP] The major types of radioactivity include alpha particles, beta particles, and gamma rays.
04/27/2022 20:42:01 - INFO - __main__ - ['radioactivity']
04/27/2022 20:42:01 - INFO - __main__ -  [sciq] The average number of individuals per unit of area can be expressed as what? (A) the percent of population (B) percent density (C) population density (D) total density [SEP] Population density just gives the average number of individuals per unit of area or volume. Often, individuals in a population are not spread out evenly. Instead, they may live in clumps or some other pattern (see Figure below ). The pattern may reflect characteristics of the species or its environment. Population distribution describes how the individuals are distributed, or spread throughout their habitat.
04/27/2022 20:42:01 - INFO - __main__ - ['population density']
04/27/2022 20:42:01 - INFO - __main__ - Tokenizing Input ...
04/27/2022 20:42:01 - INFO - __main__ - Tokenizing Output ...
04/27/2022 20:42:01 - INFO - __main__ - Loaded 32 examples from train data
04/27/2022 20:42:01 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 20:42:01 - INFO - __main__ - Printing 3 examples
04/27/2022 20:42:01 - INFO - __main__ -  [sciq] Why can't fungi make their own food like plants do? (A) no hydrogen (B) no chloroplasts (C) no organelles (D) no cells [SEP] Fungi cannot make their own food like plants can, since they do not have chloroplasts and cannot carry out photosynthesis. Fungi are more like animals because they are heterotrophs, as opposed to autotrophs, like plants, that make their own food. Fungi have to obtain their food, nutrients and glucose, from outside sources.
04/27/2022 20:42:01 - INFO - __main__ - ['no chloroplasts']
04/27/2022 20:42:01 - INFO - __main__ -  [sciq] In what kind of bond does one atom contribute both of the electrons in the shared pair? (A) a covalent bond (B) a metallic bond (C) an ionic bond (D) a valence bond [SEP] The carbon monoxide molecule is correctly represented by a triple covalent bond between the carbon and oxygen atoms. One of the bonds is a coordinate covalent bond , a covalent bond in which one of the atoms contributes both of the electrons in the shared pair.
04/27/2022 20:42:01 - INFO - __main__ - ['a covalent bond']
04/27/2022 20:42:01 - INFO - __main__ -  [sciq] The modern atomic theory states that all matter is composed of what? (A) ions (B) quarks (C) atoms (D) molecules [SEP] The modern atomic theory states that all matter is composed of atoms.
04/27/2022 20:42:01 - INFO - __main__ - ['atoms']
04/27/2022 20:42:01 - INFO - __main__ - Tokenizing Input ...
04/27/2022 20:42:01 - INFO - __main__ - Tokenizing Output ...
04/27/2022 20:42:01 - INFO - __main__ - Loaded 32 examples from dev data
04/27/2022 20:42:18 - INFO - __main__ - load prompt embedding from ckpt
04/27/2022 20:42:19 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/27/2022 20:42:19 - INFO - __main__ - Starting training!
04/27/2022 20:42:25 - INFO - __main__ - Step 10 Global step 10 Train loss 2.29 on epoch=4
04/27/2022 20:42:29 - INFO - __main__ - Step 20 Global step 20 Train loss 1.18 on epoch=9
04/27/2022 20:42:33 - INFO - __main__ - Step 30 Global step 30 Train loss 0.83 on epoch=14
04/27/2022 20:42:37 - INFO - __main__ - Step 40 Global step 40 Train loss 1.59 on epoch=19
04/27/2022 20:42:41 - INFO - __main__ - Step 50 Global step 50 Train loss 1.52 on epoch=24
04/27/2022 20:42:42 - INFO - __main__ - Global step 50 Train loss 1.48 ACC 0.53125 on epoch=24
04/27/2022 20:42:42 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.53125 on epoch=24, global_step=50
04/27/2022 20:42:46 - INFO - __main__ - Step 60 Global step 60 Train loss 0.60 on epoch=29
04/27/2022 20:42:50 - INFO - __main__ - Step 70 Global step 70 Train loss 0.63 on epoch=34
04/27/2022 20:42:54 - INFO - __main__ - Step 80 Global step 80 Train loss 0.78 on epoch=39
04/27/2022 20:42:58 - INFO - __main__ - Step 90 Global step 90 Train loss 0.61 on epoch=44
04/27/2022 20:43:02 - INFO - __main__ - Step 100 Global step 100 Train loss 0.67 on epoch=49
04/27/2022 20:43:04 - INFO - __main__ - Global step 100 Train loss 0.66 ACC 0.4375 on epoch=49
04/27/2022 20:43:08 - INFO - __main__ - Step 110 Global step 110 Train loss 0.58 on epoch=54
04/27/2022 20:43:12 - INFO - __main__ - Step 120 Global step 120 Train loss 0.57 on epoch=59
04/27/2022 20:43:16 - INFO - __main__ - Step 130 Global step 130 Train loss 0.60 on epoch=64
04/27/2022 20:43:20 - INFO - __main__ - Step 140 Global step 140 Train loss 0.52 on epoch=69
04/27/2022 20:43:24 - INFO - __main__ - Step 150 Global step 150 Train loss 0.41 on epoch=74
04/27/2022 20:43:25 - INFO - __main__ - Global step 150 Train loss 0.54 ACC 0.5625 on epoch=74
04/27/2022 20:43:25 - INFO - __main__ - Saving model with best ACC: 0.53125 -> 0.5625 on epoch=74, global_step=150
04/27/2022 20:43:29 - INFO - __main__ - Step 160 Global step 160 Train loss 0.56 on epoch=79
04/27/2022 20:43:33 - INFO - __main__ - Step 170 Global step 170 Train loss 0.47 on epoch=84
04/27/2022 20:43:37 - INFO - __main__ - Step 180 Global step 180 Train loss 0.42 on epoch=89
04/27/2022 20:43:41 - INFO - __main__ - Step 190 Global step 190 Train loss 0.38 on epoch=94
04/27/2022 20:43:45 - INFO - __main__ - Step 200 Global step 200 Train loss 0.43 on epoch=99
04/27/2022 20:43:46 - INFO - __main__ - Global step 200 Train loss 0.45 ACC 0.40625 on epoch=99
04/27/2022 20:43:50 - INFO - __main__ - Step 210 Global step 210 Train loss 0.35 on epoch=104
04/27/2022 20:43:54 - INFO - __main__ - Step 220 Global step 220 Train loss 0.35 on epoch=109
04/27/2022 20:43:58 - INFO - __main__ - Step 230 Global step 230 Train loss 0.40 on epoch=114
04/27/2022 20:44:02 - INFO - __main__ - Step 240 Global step 240 Train loss 0.37 on epoch=119
04/27/2022 20:44:06 - INFO - __main__ - Step 250 Global step 250 Train loss 0.29 on epoch=124
04/27/2022 20:44:08 - INFO - __main__ - Global step 250 Train loss 0.35 ACC 0.5 on epoch=124
04/27/2022 20:44:12 - INFO - __main__ - Step 260 Global step 260 Train loss 0.35 on epoch=129
04/27/2022 20:44:16 - INFO - __main__ - Step 270 Global step 270 Train loss 0.37 on epoch=134
04/27/2022 20:44:20 - INFO - __main__ - Step 280 Global step 280 Train loss 0.26 on epoch=139
04/27/2022 20:44:24 - INFO - __main__ - Step 290 Global step 290 Train loss 0.21 on epoch=144
04/27/2022 20:44:28 - INFO - __main__ - Step 300 Global step 300 Train loss 0.22 on epoch=149
04/27/2022 20:44:29 - INFO - __main__ - Global step 300 Train loss 0.28 ACC 0.59375 on epoch=149
04/27/2022 20:44:29 - INFO - __main__ - Saving model with best ACC: 0.5625 -> 0.59375 on epoch=149, global_step=300
04/27/2022 20:44:33 - INFO - __main__ - Step 310 Global step 310 Train loss 0.23 on epoch=154
04/27/2022 20:44:37 - INFO - __main__ - Step 320 Global step 320 Train loss 0.24 on epoch=159
04/27/2022 20:44:41 - INFO - __main__ - Step 330 Global step 330 Train loss 0.22 on epoch=164
04/27/2022 20:44:45 - INFO - __main__ - Step 340 Global step 340 Train loss 0.23 on epoch=169
04/27/2022 20:44:49 - INFO - __main__ - Step 350 Global step 350 Train loss 0.19 on epoch=174
04/27/2022 20:44:50 - INFO - __main__ - Global step 350 Train loss 0.22 ACC 0.65625 on epoch=174
04/27/2022 20:44:51 - INFO - __main__ - Saving model with best ACC: 0.59375 -> 0.65625 on epoch=174, global_step=350
04/27/2022 20:44:55 - INFO - __main__ - Step 360 Global step 360 Train loss 0.19 on epoch=179
04/27/2022 20:44:59 - INFO - __main__ - Step 370 Global step 370 Train loss 0.24 on epoch=184
04/27/2022 20:45:03 - INFO - __main__ - Step 380 Global step 380 Train loss 0.22 on epoch=189
04/27/2022 20:45:06 - INFO - __main__ - Step 390 Global step 390 Train loss 0.17 on epoch=194
04/27/2022 20:45:10 - INFO - __main__ - Step 400 Global step 400 Train loss 0.18 on epoch=199
04/27/2022 20:45:12 - INFO - __main__ - Global step 400 Train loss 0.20 ACC 0.75 on epoch=199
04/27/2022 20:45:12 - INFO - __main__ - Saving model with best ACC: 0.65625 -> 0.75 on epoch=199, global_step=400
04/27/2022 20:45:16 - INFO - __main__ - Step 410 Global step 410 Train loss 0.19 on epoch=204
04/27/2022 20:45:20 - INFO - __main__ - Step 420 Global step 420 Train loss 0.13 on epoch=209
04/27/2022 20:45:24 - INFO - __main__ - Step 430 Global step 430 Train loss 0.12 on epoch=214
04/27/2022 20:45:28 - INFO - __main__ - Step 440 Global step 440 Train loss 0.11 on epoch=219
04/27/2022 20:45:32 - INFO - __main__ - Step 450 Global step 450 Train loss 0.11 on epoch=224
04/27/2022 20:45:33 - INFO - __main__ - Global step 450 Train loss 0.13 ACC 0.8125 on epoch=224
04/27/2022 20:45:33 - INFO - __main__ - Saving model with best ACC: 0.75 -> 0.8125 on epoch=224, global_step=450
04/27/2022 20:45:37 - INFO - __main__ - Step 460 Global step 460 Train loss 0.11 on epoch=229
04/27/2022 20:45:41 - INFO - __main__ - Step 470 Global step 470 Train loss 0.11 on epoch=234
04/27/2022 20:45:45 - INFO - __main__ - Step 480 Global step 480 Train loss 0.16 on epoch=239
04/27/2022 20:45:49 - INFO - __main__ - Step 490 Global step 490 Train loss 0.11 on epoch=244
04/27/2022 20:45:53 - INFO - __main__ - Step 500 Global step 500 Train loss 0.08 on epoch=249
04/27/2022 20:45:55 - INFO - __main__ - Global step 500 Train loss 0.11 ACC 0.78125 on epoch=249
04/27/2022 20:45:59 - INFO - __main__ - Step 510 Global step 510 Train loss 0.14 on epoch=254
04/27/2022 20:46:03 - INFO - __main__ - Step 520 Global step 520 Train loss 0.10 on epoch=259
04/27/2022 20:46:07 - INFO - __main__ - Step 530 Global step 530 Train loss 0.09 on epoch=264
04/27/2022 20:46:11 - INFO - __main__ - Step 540 Global step 540 Train loss 0.14 on epoch=269
04/27/2022 20:46:15 - INFO - __main__ - Step 550 Global step 550 Train loss 0.09 on epoch=274
04/27/2022 20:46:16 - INFO - __main__ - Global step 550 Train loss 0.11 ACC 0.8125 on epoch=274
04/27/2022 20:46:20 - INFO - __main__ - Step 560 Global step 560 Train loss 0.07 on epoch=279
04/27/2022 20:46:24 - INFO - __main__ - Step 570 Global step 570 Train loss 0.10 on epoch=284
04/27/2022 20:46:28 - INFO - __main__ - Step 580 Global step 580 Train loss 0.06 on epoch=289
04/27/2022 20:46:32 - INFO - __main__ - Step 590 Global step 590 Train loss 0.06 on epoch=294
04/27/2022 20:46:36 - INFO - __main__ - Step 600 Global step 600 Train loss 0.09 on epoch=299
04/27/2022 20:46:37 - INFO - __main__ - Global step 600 Train loss 0.08 ACC 0.84375 on epoch=299
04/27/2022 20:46:37 - INFO - __main__ - Saving model with best ACC: 0.8125 -> 0.84375 on epoch=299, global_step=600
04/27/2022 20:46:42 - INFO - __main__ - Step 610 Global step 610 Train loss 0.05 on epoch=304
04/27/2022 20:46:46 - INFO - __main__ - Step 620 Global step 620 Train loss 0.08 on epoch=309
04/27/2022 20:46:50 - INFO - __main__ - Step 630 Global step 630 Train loss 0.04 on epoch=314
04/27/2022 20:46:54 - INFO - __main__ - Step 640 Global step 640 Train loss 0.05 on epoch=319
04/27/2022 20:46:58 - INFO - __main__ - Step 650 Global step 650 Train loss 0.10 on epoch=324
04/27/2022 20:46:59 - INFO - __main__ - Global step 650 Train loss 0.06 ACC 0.78125 on epoch=324
04/27/2022 20:47:03 - INFO - __main__ - Step 660 Global step 660 Train loss 0.06 on epoch=329
04/27/2022 20:47:07 - INFO - __main__ - Step 670 Global step 670 Train loss 0.08 on epoch=334
04/27/2022 20:47:11 - INFO - __main__ - Step 680 Global step 680 Train loss 0.04 on epoch=339
04/27/2022 20:47:15 - INFO - __main__ - Step 690 Global step 690 Train loss 0.07 on epoch=344
04/27/2022 20:47:19 - INFO - __main__ - Step 700 Global step 700 Train loss 0.07 on epoch=349
04/27/2022 20:47:20 - INFO - __main__ - Global step 700 Train loss 0.07 ACC 0.8125 on epoch=349
04/27/2022 20:47:24 - INFO - __main__ - Step 710 Global step 710 Train loss 0.07 on epoch=354
04/27/2022 20:47:28 - INFO - __main__ - Step 720 Global step 720 Train loss 0.05 on epoch=359
04/27/2022 20:47:32 - INFO - __main__ - Step 730 Global step 730 Train loss 0.04 on epoch=364
04/27/2022 20:47:36 - INFO - __main__ - Step 740 Global step 740 Train loss 0.05 on epoch=369
04/27/2022 20:47:40 - INFO - __main__ - Step 750 Global step 750 Train loss 0.05 on epoch=374
04/27/2022 20:47:42 - INFO - __main__ - Global step 750 Train loss 0.05 ACC 0.90625 on epoch=374
04/27/2022 20:47:42 - INFO - __main__ - Saving model with best ACC: 0.84375 -> 0.90625 on epoch=374, global_step=750
04/27/2022 20:47:46 - INFO - __main__ - Step 760 Global step 760 Train loss 0.04 on epoch=379
04/27/2022 20:47:50 - INFO - __main__ - Step 770 Global step 770 Train loss 0.05 on epoch=384
04/27/2022 20:47:54 - INFO - __main__ - Step 780 Global step 780 Train loss 0.03 on epoch=389
04/27/2022 20:47:58 - INFO - __main__ - Step 790 Global step 790 Train loss 0.02 on epoch=394
04/27/2022 20:48:02 - INFO - __main__ - Step 800 Global step 800 Train loss 0.07 on epoch=399
04/27/2022 20:48:03 - INFO - __main__ - Global step 800 Train loss 0.04 ACC 0.90625 on epoch=399
04/27/2022 20:48:07 - INFO - __main__ - Step 810 Global step 810 Train loss 0.06 on epoch=404
04/27/2022 20:48:11 - INFO - __main__ - Step 820 Global step 820 Train loss 0.02 on epoch=409
04/27/2022 20:48:15 - INFO - __main__ - Step 830 Global step 830 Train loss 0.05 on epoch=414
04/27/2022 20:48:19 - INFO - __main__ - Step 840 Global step 840 Train loss 0.03 on epoch=419
04/27/2022 20:48:23 - INFO - __main__ - Step 850 Global step 850 Train loss 0.02 on epoch=424
04/27/2022 20:48:24 - INFO - __main__ - Global step 850 Train loss 0.04 ACC 0.78125 on epoch=424
04/27/2022 20:48:28 - INFO - __main__ - Step 860 Global step 860 Train loss 0.08 on epoch=429
04/27/2022 20:48:32 - INFO - __main__ - Step 870 Global step 870 Train loss 0.03 on epoch=434
04/27/2022 20:48:36 - INFO - __main__ - Step 880 Global step 880 Train loss 0.03 on epoch=439
04/27/2022 20:48:40 - INFO - __main__ - Step 890 Global step 890 Train loss 0.01 on epoch=444
04/27/2022 20:48:44 - INFO - __main__ - Step 900 Global step 900 Train loss 0.02 on epoch=449
04/27/2022 20:48:46 - INFO - __main__ - Global step 900 Train loss 0.04 ACC 0.875 on epoch=449
04/27/2022 20:48:50 - INFO - __main__ - Step 910 Global step 910 Train loss 0.04 on epoch=454
04/27/2022 20:48:54 - INFO - __main__ - Step 920 Global step 920 Train loss 0.04 on epoch=459
04/27/2022 20:48:58 - INFO - __main__ - Step 930 Global step 930 Train loss 0.01 on epoch=464
04/27/2022 20:49:02 - INFO - __main__ - Step 940 Global step 940 Train loss 0.04 on epoch=469
04/27/2022 20:49:06 - INFO - __main__ - Step 950 Global step 950 Train loss 0.02 on epoch=474
04/27/2022 20:49:07 - INFO - __main__ - Global step 950 Train loss 0.03 ACC 0.875 on epoch=474
04/27/2022 20:49:11 - INFO - __main__ - Step 960 Global step 960 Train loss 0.02 on epoch=479
04/27/2022 20:49:15 - INFO - __main__ - Step 970 Global step 970 Train loss 0.03 on epoch=484
04/27/2022 20:49:19 - INFO - __main__ - Step 980 Global step 980 Train loss 0.02 on epoch=489
04/27/2022 20:49:23 - INFO - __main__ - Step 990 Global step 990 Train loss 0.02 on epoch=494
04/27/2022 20:49:27 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.02 on epoch=499
04/27/2022 20:49:28 - INFO - __main__ - Global step 1000 Train loss 0.02 ACC 0.84375 on epoch=499
04/27/2022 20:49:32 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.01 on epoch=504
04/27/2022 20:49:36 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.01 on epoch=509
04/27/2022 20:49:40 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.02 on epoch=514
04/27/2022 20:49:44 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.01 on epoch=519
04/27/2022 20:49:48 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.04 on epoch=524
04/27/2022 20:49:50 - INFO - __main__ - Global step 1050 Train loss 0.02 ACC 0.9375 on epoch=524
04/27/2022 20:49:50 - INFO - __main__ - Saving model with best ACC: 0.90625 -> 0.9375 on epoch=524, global_step=1050
04/27/2022 20:49:54 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.03 on epoch=529
04/27/2022 20:49:58 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.01 on epoch=534
04/27/2022 20:50:02 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.02 on epoch=539
04/27/2022 20:50:06 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.02 on epoch=544
04/27/2022 20:50:10 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.02 on epoch=549
04/27/2022 20:50:11 - INFO - __main__ - Global step 1100 Train loss 0.02 ACC 0.90625 on epoch=549
04/27/2022 20:50:15 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.02 on epoch=554
04/27/2022 20:50:19 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.02 on epoch=559
04/27/2022 20:50:23 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=564
04/27/2022 20:50:28 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.01 on epoch=569
04/27/2022 20:50:32 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=574
04/27/2022 20:50:33 - INFO - __main__ - Global step 1150 Train loss 0.02 ACC 0.875 on epoch=574
04/27/2022 20:50:37 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.01 on epoch=579
04/27/2022 20:50:41 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.01 on epoch=584
04/27/2022 20:50:45 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.04 on epoch=589
04/27/2022 20:50:49 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.01 on epoch=594
04/27/2022 20:50:53 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.02 on epoch=599
04/27/2022 20:50:54 - INFO - __main__ - Global step 1200 Train loss 0.02 ACC 0.90625 on epoch=599
04/27/2022 20:50:58 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.01 on epoch=604
04/27/2022 20:51:02 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.02 on epoch=609
04/27/2022 20:51:06 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.02 on epoch=614
04/27/2022 20:51:10 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=619
04/27/2022 20:51:14 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.02 on epoch=624
04/27/2022 20:51:16 - INFO - __main__ - Global step 1250 Train loss 0.02 ACC 0.9375 on epoch=624
04/27/2022 20:51:20 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=629
04/27/2022 20:51:24 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.01 on epoch=634
04/27/2022 20:51:28 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.03 on epoch=639
04/27/2022 20:51:32 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=644
04/27/2022 20:51:36 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=649
04/27/2022 20:51:37 - INFO - __main__ - Global step 1300 Train loss 0.01 ACC 0.90625 on epoch=649
04/27/2022 20:51:41 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.04 on epoch=654
04/27/2022 20:51:45 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.02 on epoch=659
04/27/2022 20:51:49 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=664
04/27/2022 20:51:53 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.07 on epoch=669
04/27/2022 20:51:57 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=674
04/27/2022 20:51:58 - INFO - __main__ - Global step 1350 Train loss 0.03 ACC 0.90625 on epoch=674
04/27/2022 20:52:02 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.02 on epoch=679
04/27/2022 20:52:06 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=684
04/27/2022 20:52:10 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=689
04/27/2022 20:52:14 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=694
04/27/2022 20:52:18 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=699
04/27/2022 20:52:20 - INFO - __main__ - Global step 1400 Train loss 0.01 ACC 0.84375 on epoch=699
04/27/2022 20:52:24 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=704
04/27/2022 20:52:28 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=709
04/27/2022 20:52:32 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=714
04/27/2022 20:52:36 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=719
04/27/2022 20:52:40 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=724
04/27/2022 20:52:41 - INFO - __main__ - Global step 1450 Train loss 0.01 ACC 0.90625 on epoch=724
04/27/2022 20:52:45 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=729
04/27/2022 20:52:49 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=734
04/27/2022 20:52:53 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.02 on epoch=739
04/27/2022 20:52:57 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=744
04/27/2022 20:53:01 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=749
04/27/2022 20:53:03 - INFO - __main__ - Global step 1500 Train loss 0.01 ACC 0.875 on epoch=749
04/27/2022 20:53:07 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=754
04/27/2022 20:53:11 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.02 on epoch=759
04/27/2022 20:53:15 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=764
04/27/2022 20:53:19 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=769
04/27/2022 20:53:23 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=774
04/27/2022 20:53:24 - INFO - __main__ - Global step 1550 Train loss 0.01 ACC 0.8125 on epoch=774
04/27/2022 20:53:28 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=779
04/27/2022 20:53:32 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=784
04/27/2022 20:53:36 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=789
04/27/2022 20:53:40 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=794
04/27/2022 20:53:44 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=799
04/27/2022 20:53:46 - INFO - __main__ - Global step 1600 Train loss 0.01 ACC 0.875 on epoch=799
04/27/2022 20:53:50 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=804
04/27/2022 20:53:54 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=809
04/27/2022 20:53:58 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=814
04/27/2022 20:54:02 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=819
04/27/2022 20:54:06 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=824
04/27/2022 20:54:07 - INFO - __main__ - Global step 1650 Train loss 0.01 ACC 0.875 on epoch=824
04/27/2022 20:54:11 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=829
04/27/2022 20:54:15 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=834
04/27/2022 20:54:19 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=839
04/27/2022 20:54:23 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=844
04/27/2022 20:54:27 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=849
04/27/2022 20:54:29 - INFO - __main__ - Global step 1700 Train loss 0.01 ACC 0.90625 on epoch=849
04/27/2022 20:54:33 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=854
04/27/2022 20:54:37 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=859
04/27/2022 20:54:41 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=864
04/27/2022 20:54:45 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=869
04/27/2022 20:54:49 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=874
04/27/2022 20:54:50 - INFO - __main__ - Global step 1750 Train loss 0.01 ACC 0.875 on epoch=874
04/27/2022 20:54:54 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=879
04/27/2022 20:54:58 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=884
04/27/2022 20:55:02 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=889
04/27/2022 20:55:06 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=894
04/27/2022 20:55:10 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=899
04/27/2022 20:55:12 - INFO - __main__ - Global step 1800 Train loss 0.01 ACC 0.90625 on epoch=899
04/27/2022 20:55:16 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=904
04/27/2022 20:55:20 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=909
04/27/2022 20:55:24 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=914
04/27/2022 20:55:28 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=919
04/27/2022 20:55:32 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=924
04/27/2022 20:55:33 - INFO - __main__ - Global step 1850 Train loss 0.01 ACC 0.9375 on epoch=924
04/27/2022 20:55:37 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=929
04/27/2022 20:55:41 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=934
04/27/2022 20:55:45 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=939
04/27/2022 20:55:49 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=944
04/27/2022 20:55:53 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=949
04/27/2022 20:55:55 - INFO - __main__ - Global step 1900 Train loss 0.01 ACC 0.9375 on epoch=949
04/27/2022 20:55:59 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=954
04/27/2022 20:56:03 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=959
04/27/2022 20:56:07 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.05 on epoch=964
04/27/2022 20:56:11 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=969
04/27/2022 20:56:15 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=974
04/27/2022 20:56:16 - INFO - __main__ - Global step 1950 Train loss 0.01 ACC 0.84375 on epoch=974
04/27/2022 20:56:20 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=979
04/27/2022 20:56:24 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=984
04/27/2022 20:56:28 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=989
04/27/2022 20:56:32 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.04 on epoch=994
04/27/2022 20:56:36 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=999
04/27/2022 20:56:38 - INFO - __main__ - Global step 2000 Train loss 0.02 ACC 0.875 on epoch=999
04/27/2022 20:56:38 - INFO - __main__ - save last model!
04/27/2022 20:56:38 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 20:56:38 - INFO - __main__ - Printing 3 examples
04/27/2022 20:56:38 - INFO - __main__ -  [sciq] What distant and extraordinarily energetic objects now seem to be early stages of galactic evolution with a supermassive black-hole-devouring material? (A) stars (B) neutrinos (C) quasars (D) pulsars [SEP] the history of galactic evolution has been, and the nature of space in their vicinity. However, so many black holes are now known that correlations between black hole mass and galactic nuclei characteristics are being studied. What is the mechanism for the energy output of quasars? These distant and extraordinarily energetic objects now seem to be early stages of galactic evolution with a supermassive black-hole-devouring material. Connections are now being made with galaxies having energetic cores, and there is evidence consistent with less consuming, supermassive black holes at the center of older galaxies. New instruments are allowing us to see deeper into our own galaxy for evidence of our own massive black hole.
04/27/2022 20:56:38 - INFO - __main__ - ['quasars']
04/27/2022 20:56:38 - INFO - __main__ -  [sciq] Alpha particles, beta particles, and gamma particles are major types of what? (A) radioactivity (B) microscopy (C) sound waves (D) visible light [SEP] The major types of radioactivity include alpha particles, beta particles, and gamma rays.
04/27/2022 20:56:38 - INFO - __main__ - ['radioactivity']
04/27/2022 20:56:38 - INFO - __main__ -  [sciq] The average number of individuals per unit of area can be expressed as what? (A) the percent of population (B) percent density (C) population density (D) total density [SEP] Population density just gives the average number of individuals per unit of area or volume. Often, individuals in a population are not spread out evenly. Instead, they may live in clumps or some other pattern (see Figure below ). The pattern may reflect characteristics of the species or its environment. Population distribution describes how the individuals are distributed, or spread throughout their habitat.
04/27/2022 20:56:38 - INFO - __main__ - ['population density']
04/27/2022 20:56:38 - INFO - __main__ - Tokenizing Input ...
04/27/2022 20:56:38 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
04/27/2022 20:56:38 - INFO - __main__ - Start tokenizing ... 887 instances
04/27/2022 20:56:38 - INFO - __main__ - Printing 3 examples
04/27/2022 20:56:38 - INFO - __main__ -  [sciq] A frameshift mutation is a deletion or insertion of one or more of what that changes the reading frame of the base sequence? (A) carotenoids (B) nucleotides (C) proteins (D) genes [SEP] A frameshift mutation is a deletion or insertion of one or more nucleotides that changes the reading frame of the base sequence. Deletions remove nucleotides, and insertions add nucleotides. Consider the following sequence of bases in RNA:.
04/27/2022 20:56:38 - INFO - __main__ - ['nucleotides']
04/27/2022 20:56:38 - INFO - __main__ - Tokenizing Output ...
04/27/2022 20:56:38 - INFO - __main__ -  [sciq] What is an area of land called that is wet for all or part of the year? (A) grassland (B) wetland (C) plains (D) tundra [SEP] A wetland is an area that is wet for all or part of the year. Wetlands are home to certain types of plants.
04/27/2022 20:56:38 - INFO - __main__ - ['wetland']
04/27/2022 20:56:38 - INFO - __main__ -  [sciq] What are arteries, veins, and capillaries examples of? (A) blood vessels (B) muscles (C) organs (D) tissue [SEP] Blood vessels include arteries, veins, and capillaries.
04/27/2022 20:56:38 - INFO - __main__ - ['blood vessels']
04/27/2022 20:56:38 - INFO - __main__ - Tokenizing Input ...
04/27/2022 20:56:38 - INFO - __main__ - Loaded 32 examples from train data
04/27/2022 20:56:38 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 20:56:38 - INFO - __main__ - Printing 3 examples
04/27/2022 20:56:38 - INFO - __main__ -  [sciq] Why can't fungi make their own food like plants do? (A) no hydrogen (B) no chloroplasts (C) no organelles (D) no cells [SEP] Fungi cannot make their own food like plants can, since they do not have chloroplasts and cannot carry out photosynthesis. Fungi are more like animals because they are heterotrophs, as opposed to autotrophs, like plants, that make their own food. Fungi have to obtain their food, nutrients and glucose, from outside sources.
04/27/2022 20:56:38 - INFO - __main__ - ['no chloroplasts']
04/27/2022 20:56:38 - INFO - __main__ -  [sciq] In what kind of bond does one atom contribute both of the electrons in the shared pair? (A) a covalent bond (B) a metallic bond (C) an ionic bond (D) a valence bond [SEP] The carbon monoxide molecule is correctly represented by a triple covalent bond between the carbon and oxygen atoms. One of the bonds is a coordinate covalent bond , a covalent bond in which one of the atoms contributes both of the electrons in the shared pair.
04/27/2022 20:56:38 - INFO - __main__ - ['a covalent bond']
04/27/2022 20:56:38 - INFO - __main__ -  [sciq] The modern atomic theory states that all matter is composed of what? (A) ions (B) quarks (C) atoms (D) molecules [SEP] The modern atomic theory states that all matter is composed of atoms.
04/27/2022 20:56:38 - INFO - __main__ - ['atoms']
04/27/2022 20:56:38 - INFO - __main__ - Tokenizing Input ...
04/27/2022 20:56:38 - INFO - __main__ - Tokenizing Output ...
04/27/2022 20:56:38 - INFO - __main__ - Loaded 32 examples from dev data
04/27/2022 20:56:38 - INFO - __main__ - Tokenizing Output ...
04/27/2022 20:56:39 - INFO - __main__ - Loaded 887 examples from test data
04/27/2022 20:56:56 - INFO - __main__ - load prompt embedding from ckpt
04/27/2022 20:56:57 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/27/2022 20:56:57 - INFO - __main__ - Starting training!
04/27/2022 20:57:27 - INFO - __main__ - Saved prediction in models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-sciq/sciq_32_87_0.4_8_predictions.txt
04/27/2022 20:57:27 - INFO - __main__ - ACC on test data: 0.8726
04/27/2022 20:57:27 - INFO - __main__ - prefix=sciq_32_87, lr=0.4, bsz=8, dev_performance=0.9375, test_performance=0.8726042841037204
04/27/2022 20:57:27 - INFO - __main__ - Running ... prefix=sciq_32_87, lr=0.3, bsz=8 ...
04/27/2022 20:57:28 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 20:57:28 - INFO - __main__ - Printing 3 examples
04/27/2022 20:57:28 - INFO - __main__ -  [sciq] What distant and extraordinarily energetic objects now seem to be early stages of galactic evolution with a supermassive black-hole-devouring material? (A) stars (B) neutrinos (C) quasars (D) pulsars [SEP] the history of galactic evolution has been, and the nature of space in their vicinity. However, so many black holes are now known that correlations between black hole mass and galactic nuclei characteristics are being studied. What is the mechanism for the energy output of quasars? These distant and extraordinarily energetic objects now seem to be early stages of galactic evolution with a supermassive black-hole-devouring material. Connections are now being made with galaxies having energetic cores, and there is evidence consistent with less consuming, supermassive black holes at the center of older galaxies. New instruments are allowing us to see deeper into our own galaxy for evidence of our own massive black hole.
04/27/2022 20:57:28 - INFO - __main__ - ['quasars']
04/27/2022 20:57:28 - INFO - __main__ -  [sciq] Alpha particles, beta particles, and gamma particles are major types of what? (A) radioactivity (B) microscopy (C) sound waves (D) visible light [SEP] The major types of radioactivity include alpha particles, beta particles, and gamma rays.
04/27/2022 20:57:28 - INFO - __main__ - ['radioactivity']
04/27/2022 20:57:28 - INFO - __main__ -  [sciq] The average number of individuals per unit of area can be expressed as what? (A) the percent of population (B) percent density (C) population density (D) total density [SEP] Population density just gives the average number of individuals per unit of area or volume. Often, individuals in a population are not spread out evenly. Instead, they may live in clumps or some other pattern (see Figure below ). The pattern may reflect characteristics of the species or its environment. Population distribution describes how the individuals are distributed, or spread throughout their habitat.
04/27/2022 20:57:28 - INFO - __main__ - ['population density']
04/27/2022 20:57:28 - INFO - __main__ - Tokenizing Input ...
04/27/2022 20:57:28 - INFO - __main__ - Tokenizing Output ...
04/27/2022 20:57:29 - INFO - __main__ - Loaded 32 examples from train data
04/27/2022 20:57:29 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 20:57:29 - INFO - __main__ - Printing 3 examples
04/27/2022 20:57:29 - INFO - __main__ -  [sciq] Why can't fungi make their own food like plants do? (A) no hydrogen (B) no chloroplasts (C) no organelles (D) no cells [SEP] Fungi cannot make their own food like plants can, since they do not have chloroplasts and cannot carry out photosynthesis. Fungi are more like animals because they are heterotrophs, as opposed to autotrophs, like plants, that make their own food. Fungi have to obtain their food, nutrients and glucose, from outside sources.
04/27/2022 20:57:29 - INFO - __main__ - ['no chloroplasts']
04/27/2022 20:57:29 - INFO - __main__ -  [sciq] In what kind of bond does one atom contribute both of the electrons in the shared pair? (A) a covalent bond (B) a metallic bond (C) an ionic bond (D) a valence bond [SEP] The carbon monoxide molecule is correctly represented by a triple covalent bond between the carbon and oxygen atoms. One of the bonds is a coordinate covalent bond , a covalent bond in which one of the atoms contributes both of the electrons in the shared pair.
04/27/2022 20:57:29 - INFO - __main__ - ['a covalent bond']
04/27/2022 20:57:29 - INFO - __main__ -  [sciq] The modern atomic theory states that all matter is composed of what? (A) ions (B) quarks (C) atoms (D) molecules [SEP] The modern atomic theory states that all matter is composed of atoms.
04/27/2022 20:57:29 - INFO - __main__ - ['atoms']
04/27/2022 20:57:29 - INFO - __main__ - Tokenizing Input ...
04/27/2022 20:57:29 - INFO - __main__ - Tokenizing Output ...
04/27/2022 20:57:29 - INFO - __main__ - Loaded 32 examples from dev data
04/27/2022 20:57:46 - INFO - __main__ - load prompt embedding from ckpt
04/27/2022 20:57:47 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/27/2022 20:57:47 - INFO - __main__ - Starting training!
04/27/2022 20:57:54 - INFO - __main__ - Step 10 Global step 10 Train loss 2.37 on epoch=4
04/27/2022 20:57:58 - INFO - __main__ - Step 20 Global step 20 Train loss 1.34 on epoch=9
04/27/2022 20:58:02 - INFO - __main__ - Step 30 Global step 30 Train loss 0.93 on epoch=14
04/27/2022 20:58:06 - INFO - __main__ - Step 40 Global step 40 Train loss 0.73 on epoch=19
04/27/2022 20:58:11 - INFO - __main__ - Step 50 Global step 50 Train loss 0.55 on epoch=24
04/27/2022 20:58:12 - INFO - __main__ - Global step 50 Train loss 1.18 ACC 0.4375 on epoch=24
04/27/2022 20:58:12 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.4375 on epoch=24, global_step=50
04/27/2022 20:58:16 - INFO - __main__ - Step 60 Global step 60 Train loss 0.51 on epoch=29
04/27/2022 20:58:20 - INFO - __main__ - Step 70 Global step 70 Train loss 0.45 on epoch=34
04/27/2022 20:58:25 - INFO - __main__ - Step 80 Global step 80 Train loss 0.38 on epoch=39
04/27/2022 20:58:29 - INFO - __main__ - Step 90 Global step 90 Train loss 0.35 on epoch=44
04/27/2022 20:58:34 - INFO - __main__ - Step 100 Global step 100 Train loss 0.34 on epoch=49
04/27/2022 20:58:35 - INFO - __main__ - Global step 100 Train loss 0.41 ACC 0.65625 on epoch=49
04/27/2022 20:58:35 - INFO - __main__ - Saving model with best ACC: 0.4375 -> 0.65625 on epoch=49, global_step=100
04/27/2022 20:58:39 - INFO - __main__ - Step 110 Global step 110 Train loss 0.24 on epoch=54
04/27/2022 20:58:43 - INFO - __main__ - Step 120 Global step 120 Train loss 0.19 on epoch=59
04/27/2022 20:58:47 - INFO - __main__ - Step 130 Global step 130 Train loss 0.20 on epoch=64
04/27/2022 20:58:51 - INFO - __main__ - Step 140 Global step 140 Train loss 0.24 on epoch=69
04/27/2022 20:58:56 - INFO - __main__ - Step 150 Global step 150 Train loss 0.15 on epoch=74
04/27/2022 20:58:57 - INFO - __main__ - Global step 150 Train loss 0.20 ACC 0.59375 on epoch=74
04/27/2022 20:59:01 - INFO - __main__ - Step 160 Global step 160 Train loss 0.12 on epoch=79
04/27/2022 20:59:05 - INFO - __main__ - Step 170 Global step 170 Train loss 0.19 on epoch=84
04/27/2022 20:59:09 - INFO - __main__ - Step 180 Global step 180 Train loss 0.17 on epoch=89
04/27/2022 20:59:13 - INFO - __main__ - Step 190 Global step 190 Train loss 0.10 on epoch=94
04/27/2022 20:59:17 - INFO - __main__ - Step 200 Global step 200 Train loss 0.12 on epoch=99
04/27/2022 20:59:18 - INFO - __main__ - Global step 200 Train loss 0.14 ACC 0.71875 on epoch=99
04/27/2022 20:59:18 - INFO - __main__ - Saving model with best ACC: 0.65625 -> 0.71875 on epoch=99, global_step=200
04/27/2022 20:59:23 - INFO - __main__ - Step 210 Global step 210 Train loss 0.15 on epoch=104
04/27/2022 20:59:27 - INFO - __main__ - Step 220 Global step 220 Train loss 0.13 on epoch=109
04/27/2022 20:59:31 - INFO - __main__ - Step 230 Global step 230 Train loss 0.08 on epoch=114
04/27/2022 20:59:35 - INFO - __main__ - Step 240 Global step 240 Train loss 0.07 on epoch=119
04/27/2022 20:59:39 - INFO - __main__ - Step 250 Global step 250 Train loss 0.10 on epoch=124
04/27/2022 20:59:40 - INFO - __main__ - Global step 250 Train loss 0.11 ACC 0.78125 on epoch=124
04/27/2022 20:59:40 - INFO - __main__ - Saving model with best ACC: 0.71875 -> 0.78125 on epoch=124, global_step=250
04/27/2022 20:59:44 - INFO - __main__ - Step 260 Global step 260 Train loss 0.06 on epoch=129
04/27/2022 20:59:48 - INFO - __main__ - Step 270 Global step 270 Train loss 0.06 on epoch=134
04/27/2022 20:59:52 - INFO - __main__ - Step 280 Global step 280 Train loss 0.06 on epoch=139
04/27/2022 20:59:57 - INFO - __main__ - Step 290 Global step 290 Train loss 0.06 on epoch=144
04/27/2022 21:00:01 - INFO - __main__ - Step 300 Global step 300 Train loss 0.09 on epoch=149
04/27/2022 21:00:02 - INFO - __main__ - Global step 300 Train loss 0.07 ACC 0.78125 on epoch=149
04/27/2022 21:00:06 - INFO - __main__ - Step 310 Global step 310 Train loss 0.07 on epoch=154
04/27/2022 21:00:10 - INFO - __main__ - Step 320 Global step 320 Train loss 0.08 on epoch=159
04/27/2022 21:00:14 - INFO - __main__ - Step 330 Global step 330 Train loss 0.08 on epoch=164
04/27/2022 21:00:18 - INFO - __main__ - Step 340 Global step 340 Train loss 0.06 on epoch=169
04/27/2022 21:00:22 - INFO - __main__ - Step 350 Global step 350 Train loss 0.05 on epoch=174
04/27/2022 21:00:24 - INFO - __main__ - Global step 350 Train loss 0.07 ACC 0.84375 on epoch=174
04/27/2022 21:00:24 - INFO - __main__ - Saving model with best ACC: 0.78125 -> 0.84375 on epoch=174, global_step=350
04/27/2022 21:00:28 - INFO - __main__ - Step 360 Global step 360 Train loss 0.10 on epoch=179
04/27/2022 21:00:32 - INFO - __main__ - Step 370 Global step 370 Train loss 0.04 on epoch=184
04/27/2022 21:00:36 - INFO - __main__ - Step 380 Global step 380 Train loss 0.02 on epoch=189
04/27/2022 21:00:40 - INFO - __main__ - Step 390 Global step 390 Train loss 0.05 on epoch=194
04/27/2022 21:00:44 - INFO - __main__ - Step 400 Global step 400 Train loss 0.06 on epoch=199
04/27/2022 21:00:46 - INFO - __main__ - Global step 400 Train loss 0.06 ACC 0.84375 on epoch=199
04/27/2022 21:00:50 - INFO - __main__ - Step 410 Global step 410 Train loss 0.03 on epoch=204
04/27/2022 21:00:54 - INFO - __main__ - Step 420 Global step 420 Train loss 0.03 on epoch=209
04/27/2022 21:00:59 - INFO - __main__ - Step 430 Global step 430 Train loss 0.04 on epoch=214
04/27/2022 21:01:03 - INFO - __main__ - Step 440 Global step 440 Train loss 0.03 on epoch=219
04/27/2022 21:01:07 - INFO - __main__ - Step 450 Global step 450 Train loss 0.02 on epoch=224
04/27/2022 21:01:08 - INFO - __main__ - Global step 450 Train loss 0.03 ACC 0.875 on epoch=224
04/27/2022 21:01:08 - INFO - __main__ - Saving model with best ACC: 0.84375 -> 0.875 on epoch=224, global_step=450
04/27/2022 21:01:12 - INFO - __main__ - Step 460 Global step 460 Train loss 0.05 on epoch=229
04/27/2022 21:01:16 - INFO - __main__ - Step 470 Global step 470 Train loss 0.03 on epoch=234
04/27/2022 21:01:21 - INFO - __main__ - Step 480 Global step 480 Train loss 0.04 on epoch=239
04/27/2022 21:01:25 - INFO - __main__ - Step 490 Global step 490 Train loss 0.02 on epoch=244
04/27/2022 21:01:29 - INFO - __main__ - Step 500 Global step 500 Train loss 0.02 on epoch=249
04/27/2022 21:01:31 - INFO - __main__ - Global step 500 Train loss 0.03 ACC 0.875 on epoch=249
04/27/2022 21:01:35 - INFO - __main__ - Step 510 Global step 510 Train loss 0.02 on epoch=254
04/27/2022 21:01:39 - INFO - __main__ - Step 520 Global step 520 Train loss 0.02 on epoch=259
04/27/2022 21:01:43 - INFO - __main__ - Step 530 Global step 530 Train loss 0.03 on epoch=264
04/27/2022 21:01:47 - INFO - __main__ - Step 540 Global step 540 Train loss 0.02 on epoch=269
04/27/2022 21:01:52 - INFO - __main__ - Step 550 Global step 550 Train loss 0.01 on epoch=274
04/27/2022 21:01:53 - INFO - __main__ - Global step 550 Train loss 0.02 ACC 0.78125 on epoch=274
04/27/2022 21:01:57 - INFO - __main__ - Step 560 Global step 560 Train loss 0.03 on epoch=279
04/27/2022 21:02:01 - INFO - __main__ - Step 570 Global step 570 Train loss 0.01 on epoch=284
04/27/2022 21:02:05 - INFO - __main__ - Step 580 Global step 580 Train loss 0.02 on epoch=289
04/27/2022 21:02:09 - INFO - __main__ - Step 590 Global step 590 Train loss 0.03 on epoch=294
04/27/2022 21:02:13 - INFO - __main__ - Step 600 Global step 600 Train loss 0.06 on epoch=299
04/27/2022 21:02:15 - INFO - __main__ - Global step 600 Train loss 0.03 ACC 0.84375 on epoch=299
04/27/2022 21:02:19 - INFO - __main__ - Step 610 Global step 610 Train loss 0.02 on epoch=304
04/27/2022 21:02:23 - INFO - __main__ - Step 620 Global step 620 Train loss 0.01 on epoch=309
04/27/2022 21:02:27 - INFO - __main__ - Step 630 Global step 630 Train loss 0.02 on epoch=314
04/27/2022 21:02:31 - INFO - __main__ - Step 640 Global step 640 Train loss 0.02 on epoch=319
04/27/2022 21:02:35 - INFO - __main__ - Step 650 Global step 650 Train loss 0.02 on epoch=324
04/27/2022 21:02:37 - INFO - __main__ - Global step 650 Train loss 0.02 ACC 0.875 on epoch=324
04/27/2022 21:02:41 - INFO - __main__ - Step 660 Global step 660 Train loss 0.02 on epoch=329
04/27/2022 21:02:45 - INFO - __main__ - Step 670 Global step 670 Train loss 0.02 on epoch=334
04/27/2022 21:02:49 - INFO - __main__ - Step 680 Global step 680 Train loss 0.01 on epoch=339
04/27/2022 21:02:53 - INFO - __main__ - Step 690 Global step 690 Train loss 0.01 on epoch=344
04/27/2022 21:02:57 - INFO - __main__ - Step 700 Global step 700 Train loss 0.01 on epoch=349
04/27/2022 21:02:59 - INFO - __main__ - Global step 700 Train loss 0.01 ACC 0.90625 on epoch=349
04/27/2022 21:02:59 - INFO - __main__ - Saving model with best ACC: 0.875 -> 0.90625 on epoch=349, global_step=700
04/27/2022 21:03:03 - INFO - __main__ - Step 710 Global step 710 Train loss 0.02 on epoch=354
04/27/2022 21:03:07 - INFO - __main__ - Step 720 Global step 720 Train loss 0.03 on epoch=359
04/27/2022 21:03:11 - INFO - __main__ - Step 730 Global step 730 Train loss 0.03 on epoch=364
04/27/2022 21:03:16 - INFO - __main__ - Step 740 Global step 740 Train loss 0.02 on epoch=369
04/27/2022 21:03:20 - INFO - __main__ - Step 750 Global step 750 Train loss 0.02 on epoch=374
04/27/2022 21:03:22 - INFO - __main__ - Global step 750 Train loss 0.02 ACC 0.9375 on epoch=374
04/27/2022 21:03:22 - INFO - __main__ - Saving model with best ACC: 0.90625 -> 0.9375 on epoch=374, global_step=750
04/27/2022 21:03:26 - INFO - __main__ - Step 760 Global step 760 Train loss 0.01 on epoch=379
04/27/2022 21:03:30 - INFO - __main__ - Step 770 Global step 770 Train loss 0.02 on epoch=384
04/27/2022 21:03:34 - INFO - __main__ - Step 780 Global step 780 Train loss 0.01 on epoch=389
04/27/2022 21:03:38 - INFO - __main__ - Step 790 Global step 790 Train loss 0.05 on epoch=394
04/27/2022 21:03:42 - INFO - __main__ - Step 800 Global step 800 Train loss 0.02 on epoch=399
04/27/2022 21:03:44 - INFO - __main__ - Global step 800 Train loss 0.02 ACC 0.84375 on epoch=399
04/27/2022 21:03:48 - INFO - __main__ - Step 810 Global step 810 Train loss 0.02 on epoch=404
04/27/2022 21:03:52 - INFO - __main__ - Step 820 Global step 820 Train loss 0.01 on epoch=409
04/27/2022 21:03:56 - INFO - __main__ - Step 830 Global step 830 Train loss 0.02 on epoch=414
04/27/2022 21:04:00 - INFO - __main__ - Step 840 Global step 840 Train loss 0.01 on epoch=419
04/27/2022 21:04:04 - INFO - __main__ - Step 850 Global step 850 Train loss 0.01 on epoch=424
04/27/2022 21:04:05 - INFO - __main__ - Global step 850 Train loss 0.02 ACC 0.90625 on epoch=424
04/27/2022 21:04:09 - INFO - __main__ - Step 860 Global step 860 Train loss 0.00 on epoch=429
04/27/2022 21:04:14 - INFO - __main__ - Step 870 Global step 870 Train loss 0.01 on epoch=434
04/27/2022 21:04:18 - INFO - __main__ - Step 880 Global step 880 Train loss 0.01 on epoch=439
04/27/2022 21:04:22 - INFO - __main__ - Step 890 Global step 890 Train loss 0.02 on epoch=444
04/27/2022 21:04:26 - INFO - __main__ - Step 900 Global step 900 Train loss 0.01 on epoch=449
04/27/2022 21:04:27 - INFO - __main__ - Global step 900 Train loss 0.01 ACC 0.875 on epoch=449
04/27/2022 21:04:31 - INFO - __main__ - Step 910 Global step 910 Train loss 0.02 on epoch=454
04/27/2022 21:04:35 - INFO - __main__ - Step 920 Global step 920 Train loss 0.01 on epoch=459
04/27/2022 21:04:39 - INFO - __main__ - Step 930 Global step 930 Train loss 0.01 on epoch=464
04/27/2022 21:04:44 - INFO - __main__ - Step 940 Global step 940 Train loss 0.02 on epoch=469
04/27/2022 21:04:48 - INFO - __main__ - Step 950 Global step 950 Train loss 0.01 on epoch=474
04/27/2022 21:04:49 - INFO - __main__ - Global step 950 Train loss 0.01 ACC 0.8125 on epoch=474
04/27/2022 21:04:53 - INFO - __main__ - Step 960 Global step 960 Train loss 0.01 on epoch=479
04/27/2022 21:04:57 - INFO - __main__ - Step 970 Global step 970 Train loss 0.01 on epoch=484
04/27/2022 21:05:01 - INFO - __main__ - Step 980 Global step 980 Train loss 0.02 on epoch=489
04/27/2022 21:05:05 - INFO - __main__ - Step 990 Global step 990 Train loss 0.01 on epoch=494
04/27/2022 21:05:09 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.02 on epoch=499
04/27/2022 21:05:11 - INFO - __main__ - Global step 1000 Train loss 0.01 ACC 0.875 on epoch=499
04/27/2022 21:05:15 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.01 on epoch=504
04/27/2022 21:05:19 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.01 on epoch=509
04/27/2022 21:05:23 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.00 on epoch=514
04/27/2022 21:05:27 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.01 on epoch=519
04/27/2022 21:05:31 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.00 on epoch=524
04/27/2022 21:05:33 - INFO - __main__ - Global step 1050 Train loss 0.01 ACC 0.90625 on epoch=524
04/27/2022 21:05:37 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.01 on epoch=529
04/27/2022 21:05:41 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.03 on epoch=534
04/27/2022 21:05:45 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.03 on epoch=539
04/27/2022 21:05:49 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.01 on epoch=544
04/27/2022 21:05:53 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.03 on epoch=549
04/27/2022 21:05:54 - INFO - __main__ - Global step 1100 Train loss 0.02 ACC 0.84375 on epoch=549
04/27/2022 21:05:59 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.01 on epoch=554
04/27/2022 21:06:03 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.02 on epoch=559
04/27/2022 21:06:07 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=564
04/27/2022 21:06:11 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.00 on epoch=569
04/27/2022 21:06:15 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=574
04/27/2022 21:06:16 - INFO - __main__ - Global step 1150 Train loss 0.01 ACC 0.84375 on epoch=574
04/27/2022 21:06:20 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.01 on epoch=579
04/27/2022 21:06:24 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.00 on epoch=584
04/27/2022 21:06:28 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.01 on epoch=589
04/27/2022 21:06:33 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.01 on epoch=594
04/27/2022 21:06:37 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.00 on epoch=599
04/27/2022 21:06:38 - INFO - __main__ - Global step 1200 Train loss 0.01 ACC 0.90625 on epoch=599
04/27/2022 21:06:42 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.01 on epoch=604
04/27/2022 21:06:46 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=609
04/27/2022 21:06:50 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.00 on epoch=614
04/27/2022 21:06:54 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.02 on epoch=619
04/27/2022 21:06:58 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.01 on epoch=624
04/27/2022 21:07:00 - INFO - __main__ - Global step 1250 Train loss 0.01 ACC 0.90625 on epoch=624
04/27/2022 21:07:04 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.00 on epoch=629
04/27/2022 21:07:08 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.00 on epoch=634
04/27/2022 21:07:12 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=639
04/27/2022 21:07:16 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=644
04/27/2022 21:07:20 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=649
04/27/2022 21:07:22 - INFO - __main__ - Global step 1300 Train loss 0.01 ACC 0.84375 on epoch=649
04/27/2022 21:07:26 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=654
04/27/2022 21:07:30 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.00 on epoch=659
04/27/2022 21:07:34 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=664
04/27/2022 21:07:38 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.00 on epoch=669
04/27/2022 21:07:42 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.02 on epoch=674
04/27/2022 21:07:44 - INFO - __main__ - Global step 1350 Train loss 0.01 ACC 0.875 on epoch=674
04/27/2022 21:07:48 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=679
04/27/2022 21:07:52 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=684
04/27/2022 21:07:56 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.00 on epoch=689
04/27/2022 21:08:00 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=694
04/27/2022 21:08:04 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.00 on epoch=699
04/27/2022 21:08:05 - INFO - __main__ - Global step 1400 Train loss 0.01 ACC 0.9375 on epoch=699
04/27/2022 21:08:10 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=704
04/27/2022 21:08:14 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.01 on epoch=709
04/27/2022 21:08:18 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=714
04/27/2022 21:08:22 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=719
04/27/2022 21:08:26 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=724
04/27/2022 21:08:27 - INFO - __main__ - Global step 1450 Train loss 0.01 ACC 0.9375 on epoch=724
04/27/2022 21:08:31 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=729
04/27/2022 21:08:36 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=734
04/27/2022 21:08:40 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=739
04/27/2022 21:08:44 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=744
04/27/2022 21:08:48 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=749
04/27/2022 21:08:49 - INFO - __main__ - Global step 1500 Train loss 0.00 ACC 0.90625 on epoch=749
04/27/2022 21:08:53 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=754
04/27/2022 21:08:57 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=759
04/27/2022 21:09:01 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=764
04/27/2022 21:09:05 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=769
04/27/2022 21:09:10 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=774
04/27/2022 21:09:11 - INFO - __main__ - Global step 1550 Train loss 0.00 ACC 0.90625 on epoch=774
04/27/2022 21:09:15 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=779
04/27/2022 21:09:19 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=784
04/27/2022 21:09:23 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=789
04/27/2022 21:09:27 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=794
04/27/2022 21:09:31 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=799
04/27/2022 21:09:33 - INFO - __main__ - Global step 1600 Train loss 0.00 ACC 0.84375 on epoch=799
04/27/2022 21:09:37 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=804
04/27/2022 21:09:41 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=809
04/27/2022 21:09:45 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=814
04/27/2022 21:09:49 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=819
04/27/2022 21:09:53 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=824
04/27/2022 21:09:55 - INFO - __main__ - Global step 1650 Train loss 0.00 ACC 0.96875 on epoch=824
04/27/2022 21:09:55 - INFO - __main__ - Saving model with best ACC: 0.9375 -> 0.96875 on epoch=824, global_step=1650
04/27/2022 21:09:59 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=829
04/27/2022 21:10:03 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=834
04/27/2022 21:10:07 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=839
04/27/2022 21:10:11 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=844
04/27/2022 21:10:15 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=849
04/27/2022 21:10:16 - INFO - __main__ - Global step 1700 Train loss 0.00 ACC 0.875 on epoch=849
04/27/2022 21:10:21 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=854
04/27/2022 21:10:25 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.02 on epoch=859
04/27/2022 21:10:29 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=864
04/27/2022 21:10:33 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=869
04/27/2022 21:10:37 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=874
04/27/2022 21:10:38 - INFO - __main__ - Global step 1750 Train loss 0.01 ACC 0.84375 on epoch=874
04/27/2022 21:10:42 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=879
04/27/2022 21:10:46 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=884
04/27/2022 21:10:50 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=889
04/27/2022 21:10:54 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=894
04/27/2022 21:10:59 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=899
04/27/2022 21:11:00 - INFO - __main__ - Global step 1800 Train loss 0.01 ACC 0.875 on epoch=899
04/27/2022 21:11:04 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=904
04/27/2022 21:11:08 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=909
04/27/2022 21:11:12 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=914
04/27/2022 21:11:16 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=919
04/27/2022 21:11:20 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=924
04/27/2022 21:11:22 - INFO - __main__ - Global step 1850 Train loss 0.01 ACC 0.8125 on epoch=924
04/27/2022 21:11:26 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=929
04/27/2022 21:11:30 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=934
04/27/2022 21:11:34 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=939
04/27/2022 21:11:38 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=944
04/27/2022 21:11:42 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=949
04/27/2022 21:11:43 - INFO - __main__ - Global step 1900 Train loss 0.01 ACC 0.8125 on epoch=949
04/27/2022 21:11:48 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=954
04/27/2022 21:11:52 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=959
04/27/2022 21:11:56 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=964
04/27/2022 21:12:00 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=969
04/27/2022 21:12:04 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=974
04/27/2022 21:12:05 - INFO - __main__ - Global step 1950 Train loss 0.00 ACC 0.8125 on epoch=974
04/27/2022 21:12:09 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=979
04/27/2022 21:12:13 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=984
04/27/2022 21:12:17 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=989
04/27/2022 21:12:22 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=994
04/27/2022 21:12:26 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=999
04/27/2022 21:12:27 - INFO - __main__ - Global step 2000 Train loss 0.00 ACC 0.875 on epoch=999
04/27/2022 21:12:27 - INFO - __main__ - save last model!
04/27/2022 21:12:27 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
04/27/2022 21:12:27 - INFO - __main__ - Start tokenizing ... 887 instances
04/27/2022 21:12:27 - INFO - __main__ - Printing 3 examples
04/27/2022 21:12:27 - INFO - __main__ -  [sciq] A frameshift mutation is a deletion or insertion of one or more of what that changes the reading frame of the base sequence? (A) carotenoids (B) nucleotides (C) proteins (D) genes [SEP] A frameshift mutation is a deletion or insertion of one or more nucleotides that changes the reading frame of the base sequence. Deletions remove nucleotides, and insertions add nucleotides. Consider the following sequence of bases in RNA:.
04/27/2022 21:12:27 - INFO - __main__ - ['nucleotides']
04/27/2022 21:12:27 - INFO - __main__ -  [sciq] What is an area of land called that is wet for all or part of the year? (A) grassland (B) wetland (C) plains (D) tundra [SEP] A wetland is an area that is wet for all or part of the year. Wetlands are home to certain types of plants.
04/27/2022 21:12:27 - INFO - __main__ - ['wetland']
04/27/2022 21:12:27 - INFO - __main__ -  [sciq] What are arteries, veins, and capillaries examples of? (A) blood vessels (B) muscles (C) organs (D) tissue [SEP] Blood vessels include arteries, veins, and capillaries.
04/27/2022 21:12:27 - INFO - __main__ - ['blood vessels']
04/27/2022 21:12:27 - INFO - __main__ - Tokenizing Input ...
04/27/2022 21:12:27 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 21:12:27 - INFO - __main__ - Printing 3 examples
04/27/2022 21:12:27 - INFO - __main__ -  [sciq] What distant and extraordinarily energetic objects now seem to be early stages of galactic evolution with a supermassive black-hole-devouring material? (A) stars (B) neutrinos (C) quasars (D) pulsars [SEP] the history of galactic evolution has been, and the nature of space in their vicinity. However, so many black holes are now known that correlations between black hole mass and galactic nuclei characteristics are being studied. What is the mechanism for the energy output of quasars? These distant and extraordinarily energetic objects now seem to be early stages of galactic evolution with a supermassive black-hole-devouring material. Connections are now being made with galaxies having energetic cores, and there is evidence consistent with less consuming, supermassive black holes at the center of older galaxies. New instruments are allowing us to see deeper into our own galaxy for evidence of our own massive black hole.
04/27/2022 21:12:27 - INFO - __main__ - ['quasars']
04/27/2022 21:12:27 - INFO - __main__ -  [sciq] Alpha particles, beta particles, and gamma particles are major types of what? (A) radioactivity (B) microscopy (C) sound waves (D) visible light [SEP] The major types of radioactivity include alpha particles, beta particles, and gamma rays.
04/27/2022 21:12:27 - INFO - __main__ - ['radioactivity']
04/27/2022 21:12:27 - INFO - __main__ -  [sciq] The average number of individuals per unit of area can be expressed as what? (A) the percent of population (B) percent density (C) population density (D) total density [SEP] Population density just gives the average number of individuals per unit of area or volume. Often, individuals in a population are not spread out evenly. Instead, they may live in clumps or some other pattern (see Figure below ). The pattern may reflect characteristics of the species or its environment. Population distribution describes how the individuals are distributed, or spread throughout their habitat.
04/27/2022 21:12:27 - INFO - __main__ - ['population density']
04/27/2022 21:12:27 - INFO - __main__ - Tokenizing Input ...
04/27/2022 21:12:27 - INFO - __main__ - Tokenizing Output ...
04/27/2022 21:12:27 - INFO - __main__ - Loaded 32 examples from train data
04/27/2022 21:12:27 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 21:12:27 - INFO - __main__ - Printing 3 examples
04/27/2022 21:12:27 - INFO - __main__ -  [sciq] Why can't fungi make their own food like plants do? (A) no hydrogen (B) no chloroplasts (C) no organelles (D) no cells [SEP] Fungi cannot make their own food like plants can, since they do not have chloroplasts and cannot carry out photosynthesis. Fungi are more like animals because they are heterotrophs, as opposed to autotrophs, like plants, that make their own food. Fungi have to obtain their food, nutrients and glucose, from outside sources.
04/27/2022 21:12:27 - INFO - __main__ - ['no chloroplasts']
04/27/2022 21:12:27 - INFO - __main__ -  [sciq] In what kind of bond does one atom contribute both of the electrons in the shared pair? (A) a covalent bond (B) a metallic bond (C) an ionic bond (D) a valence bond [SEP] The carbon monoxide molecule is correctly represented by a triple covalent bond between the carbon and oxygen atoms. One of the bonds is a coordinate covalent bond , a covalent bond in which one of the atoms contributes both of the electrons in the shared pair.
04/27/2022 21:12:27 - INFO - __main__ - ['a covalent bond']
04/27/2022 21:12:27 - INFO - __main__ -  [sciq] The modern atomic theory states that all matter is composed of what? (A) ions (B) quarks (C) atoms (D) molecules [SEP] The modern atomic theory states that all matter is composed of atoms.
04/27/2022 21:12:27 - INFO - __main__ - ['atoms']
04/27/2022 21:12:27 - INFO - __main__ - Tokenizing Input ...
04/27/2022 21:12:27 - INFO - __main__ - Tokenizing Output ...
04/27/2022 21:12:27 - INFO - __main__ - Loaded 32 examples from dev data
04/27/2022 21:12:28 - INFO - __main__ - Tokenizing Output ...
04/27/2022 21:12:29 - INFO - __main__ - Loaded 887 examples from test data
04/27/2022 21:12:43 - INFO - __main__ - load prompt embedding from ckpt
04/27/2022 21:12:43 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/27/2022 21:12:43 - INFO - __main__ - Starting training!
04/27/2022 21:13:15 - INFO - __main__ - Saved prediction in models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-sciq/sciq_32_87_0.3_8_predictions.txt
04/27/2022 21:13:15 - INFO - __main__ - ACC on test data: 0.8523
04/27/2022 21:13:15 - INFO - __main__ - prefix=sciq_32_87, lr=0.3, bsz=8, dev_performance=0.96875, test_performance=0.8523111612175873
04/27/2022 21:13:15 - INFO - __main__ - Running ... prefix=sciq_32_87, lr=0.2, bsz=8 ...
04/27/2022 21:13:16 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 21:13:16 - INFO - __main__ - Printing 3 examples
04/27/2022 21:13:16 - INFO - __main__ -  [sciq] What distant and extraordinarily energetic objects now seem to be early stages of galactic evolution with a supermassive black-hole-devouring material? (A) stars (B) neutrinos (C) quasars (D) pulsars [SEP] the history of galactic evolution has been, and the nature of space in their vicinity. However, so many black holes are now known that correlations between black hole mass and galactic nuclei characteristics are being studied. What is the mechanism for the energy output of quasars? These distant and extraordinarily energetic objects now seem to be early stages of galactic evolution with a supermassive black-hole-devouring material. Connections are now being made with galaxies having energetic cores, and there is evidence consistent with less consuming, supermassive black holes at the center of older galaxies. New instruments are allowing us to see deeper into our own galaxy for evidence of our own massive black hole.
04/27/2022 21:13:16 - INFO - __main__ - ['quasars']
04/27/2022 21:13:16 - INFO - __main__ -  [sciq] Alpha particles, beta particles, and gamma particles are major types of what? (A) radioactivity (B) microscopy (C) sound waves (D) visible light [SEP] The major types of radioactivity include alpha particles, beta particles, and gamma rays.
04/27/2022 21:13:16 - INFO - __main__ - ['radioactivity']
04/27/2022 21:13:16 - INFO - __main__ -  [sciq] The average number of individuals per unit of area can be expressed as what? (A) the percent of population (B) percent density (C) population density (D) total density [SEP] Population density just gives the average number of individuals per unit of area or volume. Often, individuals in a population are not spread out evenly. Instead, they may live in clumps or some other pattern (see Figure below ). The pattern may reflect characteristics of the species or its environment. Population distribution describes how the individuals are distributed, or spread throughout their habitat.
04/27/2022 21:13:16 - INFO - __main__ - ['population density']
04/27/2022 21:13:16 - INFO - __main__ - Tokenizing Input ...
04/27/2022 21:13:16 - INFO - __main__ - Tokenizing Output ...
04/27/2022 21:13:16 - INFO - __main__ - Loaded 32 examples from train data
04/27/2022 21:13:16 - INFO - __main__ - Start tokenizing ... 32 instances
04/27/2022 21:13:16 - INFO - __main__ - Printing 3 examples
04/27/2022 21:13:16 - INFO - __main__ -  [sciq] Why can't fungi make their own food like plants do? (A) no hydrogen (B) no chloroplasts (C) no organelles (D) no cells [SEP] Fungi cannot make their own food like plants can, since they do not have chloroplasts and cannot carry out photosynthesis. Fungi are more like animals because they are heterotrophs, as opposed to autotrophs, like plants, that make their own food. Fungi have to obtain their food, nutrients and glucose, from outside sources.
04/27/2022 21:13:16 - INFO - __main__ - ['no chloroplasts']
04/27/2022 21:13:16 - INFO - __main__ -  [sciq] In what kind of bond does one atom contribute both of the electrons in the shared pair? (A) a covalent bond (B) a metallic bond (C) an ionic bond (D) a valence bond [SEP] The carbon monoxide molecule is correctly represented by a triple covalent bond between the carbon and oxygen atoms. One of the bonds is a coordinate covalent bond , a covalent bond in which one of the atoms contributes both of the electrons in the shared pair.
04/27/2022 21:13:16 - INFO - __main__ - ['a covalent bond']
04/27/2022 21:13:16 - INFO - __main__ -  [sciq] The modern atomic theory states that all matter is composed of what? (A) ions (B) quarks (C) atoms (D) molecules [SEP] The modern atomic theory states that all matter is composed of atoms.
04/27/2022 21:13:16 - INFO - __main__ - ['atoms']
04/27/2022 21:13:16 - INFO - __main__ - Tokenizing Input ...
04/27/2022 21:13:16 - INFO - __main__ - Tokenizing Output ...
04/27/2022 21:13:16 - INFO - __main__ - Loaded 32 examples from dev data
04/27/2022 21:13:33 - INFO - __main__ - load prompt embedding from ckpt
04/27/2022 21:13:34 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
04/27/2022 21:13:34 - INFO - __main__ - Starting training!
04/27/2022 21:13:39 - INFO - __main__ - Step 10 Global step 10 Train loss 2.63 on epoch=4
04/27/2022 21:13:43 - INFO - __main__ - Step 20 Global step 20 Train loss 1.75 on epoch=9
04/27/2022 21:13:47 - INFO - __main__ - Step 30 Global step 30 Train loss 1.18 on epoch=14
04/27/2022 21:13:51 - INFO - __main__ - Step 40 Global step 40 Train loss 0.97 on epoch=19
04/27/2022 21:13:55 - INFO - __main__ - Step 50 Global step 50 Train loss 0.70 on epoch=24
04/27/2022 21:13:57 - INFO - __main__ - Global step 50 Train loss 1.45 ACC 0.4375 on epoch=24
04/27/2022 21:13:57 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.4375 on epoch=24, global_step=50
04/27/2022 21:14:01 - INFO - __main__ - Step 60 Global step 60 Train loss 0.61 on epoch=29
04/27/2022 21:14:05 - INFO - __main__ - Step 70 Global step 70 Train loss 0.52 on epoch=34
04/27/2022 21:14:09 - INFO - __main__ - Step 80 Global step 80 Train loss 0.47 on epoch=39
04/27/2022 21:14:13 - INFO - __main__ - Step 90 Global step 90 Train loss 0.43 on epoch=44
04/27/2022 21:14:17 - INFO - __main__ - Step 100 Global step 100 Train loss 0.39 on epoch=49
04/27/2022 21:14:19 - INFO - __main__ - Global step 100 Train loss 0.48 ACC 0.59375 on epoch=49
04/27/2022 21:14:19 - INFO - __main__ - Saving model with best ACC: 0.4375 -> 0.59375 on epoch=49, global_step=100
04/27/2022 21:14:23 - INFO - __main__ - Step 110 Global step 110 Train loss 0.38 on epoch=54
04/27/2022 21:14:27 - INFO - __main__ - Step 120 Global step 120 Train loss 0.52 on epoch=59
04/27/2022 21:14:31 - INFO - __main__ - Step 130 Global step 130 Train loss 0.31 on epoch=64
04/27/2022 21:14:35 - INFO - __main__ - Step 140 Global step 140 Train loss 0.26 on epoch=69
04/27/2022 21:14:39 - INFO - __main__ - Step 150 Global step 150 Train loss 0.25 on epoch=74
04/27/2022 21:14:41 - INFO - __main__ - Global step 150 Train loss 0.35 ACC 0.65625 on epoch=74
04/27/2022 21:14:41 - INFO - __main__ - Saving model with best ACC: 0.59375 -> 0.65625 on epoch=74, global_step=150
04/27/2022 21:14:45 - INFO - __main__ - Step 160 Global step 160 Train loss 0.24 on epoch=79
04/27/2022 21:14:49 - INFO - __main__ - Step 170 Global step 170 Train loss 0.24 on epoch=84
04/27/2022 21:14:53 - INFO - __main__ - Step 180 Global step 180 Train loss 0.21 on epoch=89
04/27/2022 21:14:57 - INFO - __main__ - Step 190 Global step 190 Train loss 0.17 on epoch=94
04/27/2022 21:15:01 - INFO - __main__ - Step 200 Global step 200 Train loss 0.19 on epoch=99
04/27/2022 21:15:02 - INFO - __main__ - Global step 200 Train loss 0.21 ACC 0.71875 on epoch=99
04/27/2022 21:15:03 - INFO - __main__ - Saving model with best ACC: 0.65625 -> 0.71875 on epoch=99, global_step=200
04/27/2022 21:15:07 - INFO - __main__ - Step 210 Global step 210 Train loss 0.17 on epoch=104
04/27/2022 21:15:11 - INFO - __main__ - Step 220 Global step 220 Train loss 0.16 on epoch=109
04/27/2022 21:15:15 - INFO - __main__ - Step 230 Global step 230 Train loss 0.14 on epoch=114
04/27/2022 21:15:19 - INFO - __main__ - Step 240 Global step 240 Train loss 0.09 on epoch=119
04/27/2022 21:15:23 - INFO - __main__ - Step 250 Global step 250 Train loss 0.09 on epoch=124
04/27/2022 21:15:24 - INFO - __main__ - Global step 250 Train loss 0.13 ACC 0.78125 on epoch=124
04/27/2022 21:15:24 - INFO - __main__ - Saving model with best ACC: 0.71875 -> 0.78125 on epoch=124, global_step=250
04/27/2022 21:15:28 - INFO - __main__ - Step 260 Global step 260 Train loss 0.16 on epoch=129
04/27/2022 21:15:32 - INFO - __main__ - Step 270 Global step 270 Train loss 0.14 on epoch=134
04/27/2022 21:15:37 - INFO - __main__ - Step 280 Global step 280 Train loss 0.08 on epoch=139
04/27/2022 21:15:41 - INFO - __main__ - Step 290 Global step 290 Train loss 0.14 on epoch=144
04/27/2022 21:15:45 - INFO - __main__ - Step 300 Global step 300 Train loss 0.12 on epoch=149
04/27/2022 21:15:46 - INFO - __main__ - Global step 300 Train loss 0.13 ACC 0.78125 on epoch=149
04/27/2022 21:15:50 - INFO - __main__ - Step 310 Global step 310 Train loss 0.10 on epoch=154
04/27/2022 21:15:54 - INFO - __main__ - Step 320 Global step 320 Train loss 0.09 on epoch=159
04/27/2022 21:15:59 - INFO - __main__ - Step 330 Global step 330 Train loss 0.13 on epoch=164
04/27/2022 21:16:03 - INFO - __main__ - Step 340 Global step 340 Train loss 0.06 on epoch=169
04/27/2022 21:16:07 - INFO - __main__ - Step 350 Global step 350 Train loss 0.06 on epoch=174
04/27/2022 21:16:08 - INFO - __main__ - Global step 350 Train loss 0.09 ACC 0.84375 on epoch=174
04/27/2022 21:16:08 - INFO - __main__ - Saving model with best ACC: 0.78125 -> 0.84375 on epoch=174, global_step=350
04/27/2022 21:16:12 - INFO - __main__ - Step 360 Global step 360 Train loss 0.09 on epoch=179
04/27/2022 21:16:16 - INFO - __main__ - Step 370 Global step 370 Train loss 0.08 on epoch=184
04/27/2022 21:16:20 - INFO - __main__ - Step 380 Global step 380 Train loss 0.06 on epoch=189
04/27/2022 21:16:24 - INFO - __main__ - Step 390 Global step 390 Train loss 0.07 on epoch=194
04/27/2022 21:16:29 - INFO - __main__ - Step 400 Global step 400 Train loss 0.05 on epoch=199
04/27/2022 21:16:30 - INFO - __main__ - Global step 400 Train loss 0.07 ACC 0.75 on epoch=199
04/27/2022 21:16:34 - INFO - __main__ - Step 410 Global step 410 Train loss 0.04 on epoch=204
04/27/2022 21:16:38 - INFO - __main__ - Step 420 Global step 420 Train loss 0.07 on epoch=209
04/27/2022 21:16:42 - INFO - __main__ - Step 430 Global step 430 Train loss 0.05 on epoch=214
04/27/2022 21:16:46 - INFO - __main__ - Step 440 Global step 440 Train loss 0.06 on epoch=219
04/27/2022 21:16:50 - INFO - __main__ - Step 450 Global step 450 Train loss 0.06 on epoch=224
04/27/2022 21:16:52 - INFO - __main__ - Global step 450 Train loss 0.06 ACC 0.8125 on epoch=224
04/27/2022 21:16:56 - INFO - __main__ - Step 460 Global step 460 Train loss 0.05 on epoch=229
04/27/2022 21:17:00 - INFO - __main__ - Step 470 Global step 470 Train loss 0.05 on epoch=234
04/27/2022 21:17:04 - INFO - __main__ - Step 480 Global step 480 Train loss 0.10 on epoch=239
04/27/2022 21:17:08 - INFO - __main__ - Step 490 Global step 490 Train loss 0.04 on epoch=244
04/27/2022 21:17:13 - INFO - __main__ - Step 500 Global step 500 Train loss 0.04 on epoch=249
04/27/2022 21:17:14 - INFO - __main__ - Global step 500 Train loss 0.05 ACC 0.71875 on epoch=249
04/27/2022 21:17:18 - INFO - __main__ - Step 510 Global step 510 Train loss 0.04 on epoch=254
04/27/2022 21:17:22 - INFO - __main__ - Step 520 Global step 520 Train loss 0.05 on epoch=259
04/27/2022 21:17:26 - INFO - __main__ - Step 530 Global step 530 Train loss 0.03 on epoch=264
04/27/2022 21:17:30 - INFO - __main__ - Step 540 Global step 540 Train loss 0.04 on epoch=269
04/27/2022 21:17:34 - INFO - __main__ - Step 550 Global step 550 Train loss 0.03 on epoch=274
04/27/2022 21:17:36 - INFO - __main__ - Global step 550 Train loss 0.04 ACC 0.84375 on epoch=274
04/27/2022 21:17:40 - INFO - __main__ - Step 560 Global step 560 Train loss 0.04 on epoch=279
04/27/2022 21:17:44 - INFO - __main__ - Step 570 Global step 570 Train loss 0.06 on epoch=284
04/27/2022 21:17:48 - INFO - __main__ - Step 580 Global step 580 Train loss 0.02 on epoch=289
04/27/2022 21:17:52 - INFO - __main__ - Step 590 Global step 590 Train loss 0.03 on epoch=294
04/27/2022 21:17:56 - INFO - __main__ - Step 600 Global step 600 Train loss 0.02 on epoch=299
04/27/2022 21:17:57 - INFO - __main__ - Global step 600 Train loss 0.04 ACC 0.875 on epoch=299
04/27/2022 21:17:58 - INFO - __main__ - Saving model with best ACC: 0.84375 -> 0.875 on epoch=299, global_step=600
04/27/2022 21:18:02 - INFO - __main__ - Step 610 Global step 610 Train loss 0.05 on epoch=304
04/27/2022 21:18:06 - INFO - __main__ - Step 620 Global step 620 Train loss 0.04 on epoch=309
04/27/2022 21:18:10 - INFO - __main__ - Step 630 Global step 630 Train loss 0.03 on epoch=314
04/27/2022 21:18:14 - INFO - __main__ - Step 640 Global step 640 Train loss 0.03 on epoch=319
04/27/2022 21:18:18 - INFO - __main__ - Step 650 Global step 650 Train loss 0.05 on epoch=324
04/27/2022 21:18:20 - INFO - __main__ - Global step 650 Train loss 0.04 ACC 0.875 on epoch=324
04/27/2022 21:18:24 - INFO - __main__ - Step 660 Global step 660 Train loss 0.03 on epoch=329
04/27/2022 21:18:28 - INFO - __main__ - Step 670 Global step 670 Train loss 0.03 on epoch=334
04/27/2022 21:18:32 - INFO - __main__ - Step 680 Global step 680 Train loss 0.03 on epoch=339
04/27/2022 21:18:36 - INFO - __main__ - Step 690 Global step 690 Train loss 0.07 on epoch=344
04/27/2022 21:18:40 - INFO - __main__ - Step 700 Global step 700 Train loss 0.06 on epoch=349
04/27/2022 21:18:42 - INFO - __main__ - Global step 700 Train loss 0.04 ACC 0.8125 on epoch=349
04/27/2022 21:18:46 - INFO - __main__ - Step 710 Global step 710 Train loss 0.02 on epoch=354
04/27/2022 21:18:50 - INFO - __main__ - Step 720 Global step 720 Train loss 0.02 on epoch=359
04/27/2022 21:18:54 - INFO - __main__ - Step 730 Global step 730 Train loss 0.03 on epoch=364
04/27/2022 21:18:58 - INFO - __main__ - Step 740 Global step 740 Train loss 0.02 on epoch=369
04/27/2022 21:19:02 - INFO - __main__ - Step 750 Global step 750 Train loss 0.03 on epoch=374
04/27/2022 21:19:03 - INFO - __main__ - Global step 750 Train loss 0.02 ACC 0.875 on epoch=374
04/27/2022 21:19:07 - INFO - __main__ - Step 760 Global step 760 Train loss 0.01 on epoch=379
04/27/2022 21:19:11 - INFO - __main__ - Step 770 Global step 770 Train loss 0.01 on epoch=384
04/27/2022 21:19:16 - INFO - __main__ - Step 780 Global step 780 Train loss 0.02 on epoch=389
04/27/2022 21:19:20 - INFO - __main__ - Step 790 Global step 790 Train loss 0.02 on epoch=394
04/27/2022 21:19:24 - INFO - __main__ - Step 800 Global step 800 Train loss 0.02 on epoch=399
04/27/2022 21:19:25 - INFO - __main__ - Global step 800 Train loss 0.02 ACC 0.71875 on epoch=399
04/27/2022 21:19:29 - INFO - __main__ - Step 810 Global step 810 Train loss 0.02 on epoch=404
04/27/2022 21:19:33 - INFO - __main__ - Step 820 Global step 820 Train loss 0.08 on epoch=409
04/27/2022 21:19:37 - INFO - __main__ - Step 830 Global step 830 Train loss 0.01 on epoch=414
04/27/2022 21:19:41 - INFO - __main__ - Step 840 Global step 840 Train loss 0.02 on epoch=419
04/27/2022 21:19:45 - INFO - __main__ - Step 850 Global step 850 Train loss 0.01 on epoch=424
04/27/2022 21:19:47 - INFO - __main__ - Global step 850 Train loss 0.03 ACC 0.8125 on epoch=424
04/27/2022 21:19:51 - INFO - __main__ - Step 860 Global step 860 Train loss 0.05 on epoch=429
04/27/2022 21:19:55 - INFO - __main__ - Step 870 Global step 870 Train loss 0.02 on epoch=434
04/27/2022 21:19:59 - INFO - __main__ - Step 880 Global step 880 Train loss 0.02 on epoch=439
04/27/2022 21:20:03 - INFO - __main__ - Step 890 Global step 890 Train loss 0.02 on epoch=444
04/27/2022 21:20:07 - INFO - __main__ - Step 900 Global step 900 Train loss 0.05 on epoch=449
04/27/2022 21:20:09 - INFO - __main__ - Global step 900 Train loss 0.03 ACC 0.84375 on epoch=449
04/27/2022 21:20:13 - INFO - __main__ - Step 910 Global step 910 Train loss 0.02 on epoch=454
04/27/2022 21:20:17 - INFO - __main__ - Step 920 Global step 920 Train loss 0.02 on epoch=459
04/27/2022 21:20:21 - INFO - __main__ - Step 930 Global step 930 Train loss 0.02 on epoch=464
04/27/2022 21:20:25 - INFO - __main__ - Step 940 Global step 940 Train loss 0.02 on epoch=469
04/27/2022 21:20:29 - INFO - __main__ - Step 950 Global step 950 Train loss 0.02 on epoch=474
04/27/2022 21:20:30 - INFO - __main__ - Global step 950 Train loss 0.02 ACC 0.8125 on epoch=474
04/27/2022 21:20:35 - INFO - __main__ - Step 960 Global step 960 Train loss 0.03 on epoch=479
04/27/2022 21:20:39 - INFO - __main__ - Step 970 Global step 970 Train loss 0.02 on epoch=484
04/27/2022 21:20:43 - INFO - __main__ - Step 980 Global step 980 Train loss 0.01 on epoch=489
04/27/2022 21:20:47 - INFO - __main__ - Step 990 Global step 990 Train loss 0.00 on epoch=494
04/27/2022 21:20:51 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.02 on epoch=499
04/27/2022 21:20:52 - INFO - __main__ - Global step 1000 Train loss 0.02 ACC 0.71875 on epoch=499
04/27/2022 21:20:56 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.01 on epoch=504
04/27/2022 21:21:01 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.01 on epoch=509
04/27/2022 21:21:05 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.01 on epoch=514
04/27/2022 21:21:09 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.01 on epoch=519
04/27/2022 21:21:13 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.01 on epoch=524
04/27/2022 21:21:14 - INFO - __main__ - Global step 1050 Train loss 0.01 ACC 0.84375 on epoch=524
04/27/2022 21:21:18 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.01 on epoch=529
04/27/2022 21:21:23 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.00 on epoch=534
04/27/2022 21:21:27 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.02 on epoch=539
04/27/2022 21:21:31 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.01 on epoch=544
04/27/2022 21:21:35 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.01 on epoch=549
04/27/2022 21:21:36 - INFO - __main__ - Global step 1100 Train loss 0.01 ACC 0.8125 on epoch=549
04/27/2022 21:21:40 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.01 on epoch=554
04/27/2022 21:21:44 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=559
04/27/2022 21:21:48 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=564
04/27/2022 21:21:53 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.01 on epoch=569
04/27/2022 21:21:57 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=574
04/27/2022 21:21:58 - INFO - __main__ - Global step 1150 Train loss 0.01 ACC 0.84375 on epoch=574
04/27/2022 21:22:02 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.02 on epoch=579
04/27/2022 21:22:06 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.01 on epoch=584
04/27/2022 21:22:10 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.02 on epoch=589
04/27/2022 21:22:14 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.01 on epoch=594
04/27/2022 21:22:18 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=599
04/27/2022 21:22:20 - INFO - __main__ - Global step 1200 Train loss 0.01 ACC 0.78125 on epoch=599
04/27/2022 21:22:24 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.00 on epoch=604
04/27/2022 21:22:28 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=609
04/27/2022 21:22:32 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=614
04/27/2022 21:22:36 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.02 on epoch=619
04/27/2022 21:22:40 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.01 on epoch=624
04/27/2022 21:22:42 - INFO - __main__ - Global step 1250 Train loss 0.01 ACC 0.84375 on epoch=624
04/27/2022 21:22:46 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=629
04/27/2022 21:22:50 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.01 on epoch=634
04/27/2022 21:22:54 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.00 on epoch=639
04/27/2022 21:22:58 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=644
04/27/2022 21:23:02 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.00 on epoch=649
04/27/2022 21:23:03 - INFO - __main__ - Global step 1300 Train loss 0.01 ACC 0.71875 on epoch=649
04/27/2022 21:23:08 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=654
04/27/2022 21:23:12 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=659
04/27/2022 21:23:16 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.04 on epoch=664
04/27/2022 21:23:20 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=669
04/27/2022 21:23:24 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=674
04/27/2022 21:23:25 - INFO - __main__ - Global step 1350 Train loss 0.01 ACC 0.84375 on epoch=674
04/27/2022 21:23:29 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.00 on epoch=679
04/27/2022 21:23:33 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=684
04/27/2022 21:23:37 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=689
04/27/2022 21:23:42 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=694
04/27/2022 21:23:46 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=699
04/27/2022 21:23:47 - INFO - __main__ - Global step 1400 Train loss 0.01 ACC 0.78125 on epoch=699
04/27/2022 21:23:51 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=704
04/27/2022 21:23:55 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.01 on epoch=709
04/27/2022 21:23:59 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=714
04/27/2022 21:24:03 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=719
04/27/2022 21:24:07 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=724
04/27/2022 21:24:09 - INFO - __main__ - Global step 1450 Train loss 0.01 ACC 0.84375 on epoch=724
04/27/2022 21:24:13 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=729
04/27/2022 21:24:17 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=734
04/27/2022 21:24:21 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=739
04/27/2022 21:24:25 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=744
04/27/2022 21:24:29 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=749
04/27/2022 21:24:30 - INFO - __main__ - Global step 1500 Train loss 0.01 ACC 0.875 on epoch=749
04/27/2022 21:24:35 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=754
04/27/2022 21:24:39 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=759
04/27/2022 21:24:43 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=764
04/27/2022 21:24:47 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=769
04/27/2022 21:24:51 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=774
04/27/2022 21:24:52 - INFO - __main__ - Global step 1550 Train loss 0.00 ACC 0.84375 on epoch=774
04/27/2022 21:24:56 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=779
04/27/2022 21:25:01 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=784
04/27/2022 21:25:05 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.02 on epoch=789
04/27/2022 21:25:09 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=794
04/27/2022 21:25:13 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=799
04/27/2022 21:25:14 - INFO - __main__ - Global step 1600 Train loss 0.01 ACC 0.8125 on epoch=799
04/27/2022 21:25:18 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=804
04/27/2022 21:25:22 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.02 on epoch=809
04/27/2022 21:25:26 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=814
04/27/2022 21:25:31 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=819
04/27/2022 21:25:35 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=824
04/27/2022 21:25:36 - INFO - __main__ - Global step 1650 Train loss 0.01 ACC 0.90625 on epoch=824
04/27/2022 21:25:36 - INFO - __main__ - Saving model with best ACC: 0.875 -> 0.90625 on epoch=824, global_step=1650
04/27/2022 21:25:40 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=829
04/27/2022 21:25:44 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=834
04/27/2022 21:25:48 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=839
04/27/2022 21:25:53 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=844
04/27/2022 21:25:57 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=849
04/27/2022 21:25:58 - INFO - __main__ - Global step 1700 Train loss 0.01 ACC 0.875 on epoch=849
04/27/2022 21:26:02 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.06 on epoch=854
04/27/2022 21:26:06 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=859
04/27/2022 21:26:10 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=864
04/27/2022 21:26:14 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=869
04/27/2022 21:26:18 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=874
04/27/2022 21:26:20 - INFO - __main__ - Global step 1750 Train loss 0.02 ACC 0.9375 on epoch=874
04/27/2022 21:26:20 - INFO - __main__ - Saving model with best ACC: 0.90625 -> 0.9375 on epoch=874, global_step=1750
04/27/2022 21:26:24 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=879
04/27/2022 21:26:28 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=884
04/27/2022 21:26:32 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=889
04/27/2022 21:26:36 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=894
04/27/2022 21:26:40 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.03 on epoch=899
04/27/2022 21:26:42 - INFO - __main__ - Global step 1800 Train loss 0.01 ACC 0.90625 on epoch=899
04/27/2022 21:26:46 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=904
04/27/2022 21:26:50 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=909
04/27/2022 21:26:54 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=914
04/27/2022 21:26:58 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=919
04/27/2022 21:27:02 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=924
04/27/2022 21:27:04 - INFO - __main__ - Global step 1850 Train loss 0.00 ACC 0.9375 on epoch=924
04/27/2022 21:27:08 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=929
04/27/2022 21:27:12 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=934
04/27/2022 21:27:16 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=939
04/27/2022 21:27:20 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=944
04/27/2022 21:27:24 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=949
04/27/2022 21:27:26 - INFO - __main__ - Global step 1900 Train loss 0.01 ACC 0.90625 on epoch=949
04/27/2022 21:27:30 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=954
04/27/2022 21:27:34 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=959
04/27/2022 21:27:38 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=964
04/27/2022 21:27:42 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=969
04/27/2022 21:27:46 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=974
04/27/2022 21:27:47 - INFO - __main__ - Global step 1950 Train loss 0.00 ACC 0.84375 on epoch=974
04/27/2022 21:27:51 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=979
04/27/2022 21:27:56 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=984
04/27/2022 21:28:00 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=989
04/27/2022 21:28:04 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=994
04/27/2022 21:28:08 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=999
04/27/2022 21:28:09 - INFO - __main__ - Global step 2000 Train loss 0.01 ACC 0.84375 on epoch=999
04/27/2022 21:28:09 - INFO - __main__ - save last model!
04/27/2022 21:28:09 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
04/27/2022 21:28:09 - INFO - __main__ - Start tokenizing ... 887 instances
04/27/2022 21:28:09 - INFO - __main__ - Printing 3 examples
04/27/2022 21:28:09 - INFO - __main__ -  [sciq] A frameshift mutation is a deletion or insertion of one or more of what that changes the reading frame of the base sequence? (A) carotenoids (B) nucleotides (C) proteins (D) genes [SEP] A frameshift mutation is a deletion or insertion of one or more nucleotides that changes the reading frame of the base sequence. Deletions remove nucleotides, and insertions add nucleotides. Consider the following sequence of bases in RNA:.
04/27/2022 21:28:09 - INFO - __main__ - ['nucleotides']
04/27/2022 21:28:09 - INFO - __main__ -  [sciq] What is an area of land called that is wet for all or part of the year? (A) grassland (B) wetland (C) plains (D) tundra [SEP] A wetland is an area that is wet for all or part of the year. Wetlands are home to certain types of plants.
04/27/2022 21:28:09 - INFO - __main__ - ['wetland']
04/27/2022 21:28:09 - INFO - __main__ -  [sciq] What are arteries, veins, and capillaries examples of? (A) blood vessels (B) muscles (C) organs (D) tissue [SEP] Blood vessels include arteries, veins, and capillaries.
04/27/2022 21:28:09 - INFO - __main__ - ['blood vessels']
04/27/2022 21:28:09 - INFO - __main__ - Tokenizing Input ...
04/27/2022 21:28:10 - INFO - __main__ - Tokenizing Output ...
04/27/2022 21:28:11 - INFO - __main__ - Loaded 887 examples from test data
04/27/2022 21:29:01 - INFO - __main__ - Saved prediction in models/T5-large-maml-noqa2qa-3e-5-2-5000-5e-1/singletask-sciq/sciq_32_87_0.2_8_predictions.txt
04/27/2022 21:29:01 - INFO - __main__ - ACC on test data: 0.8253
04/27/2022 21:29:01 - INFO - __main__ - prefix=sciq_32_87, lr=0.2, bsz=8, dev_performance=0.9375, test_performance=0.8252536640360767
